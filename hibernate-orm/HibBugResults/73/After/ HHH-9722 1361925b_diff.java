diff --git a/hibernate-core/src/main/java/org/hibernate/CacheMode.java b/hibernate-core/src/main/java/org/hibernate/CacheMode.java
index 54ebf079a9..4c2247e0b9 100755
--- a/hibernate-core/src/main/java/org/hibernate/CacheMode.java
+++ b/hibernate-core/src/main/java/org/hibernate/CacheMode.java
@@ -1,109 +1,111 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc..
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
+import java.util.Locale;
+
 /**
  * Controls how the session interacts with the second-level cache and query cache.
  *
  * @author Gavin King
  * @author Strong Liu
  * @see Session#setCacheMode(CacheMode)
  */
 public enum CacheMode {
 	/**
 	 * The session may read items from the cache, and add items to the cache.
 	 */
 	NORMAL( true, true ),
 	/**
 	 * The session will never interact with the cache, except to invalidate
 	 * cache items when updates occur.
 	 */
 	IGNORE( false, false ),
 	/**
 	 * The session may read items from the cache, but will not add items,
 	 * except to invalidate items when updates occur.
 	 */
 	GET( false, true ),
 	/**
 	 * The session will never read items from the cache, but will add items
 	 * to the cache as it reads them from the database.
 	 */
 	PUT( true, false ),
 	/**
 	 * The session will never read items from the cache, but will add items
 	 * to the cache as it reads them from the database.  In this mode, the
 	 * effect of <tt>hibernate.cache.use_minimal_puts</tt> is bypassed, in
 	 * order to <em>force</em> a cache refresh.
 	 */
 	REFRESH( true, false );
 
 
 	private final boolean isPutEnabled;
 	private final boolean isGetEnabled;
 
 	private CacheMode( boolean isPutEnabled, boolean isGetEnabled) {
 		this.isPutEnabled = isPutEnabled;
 		this.isGetEnabled = isGetEnabled;
 	}
 
 	/**
 	 * Does this cache mode indicate that reads are allowed?
 	 *
 	 * @return {@code true} if cache reads are allowed; {@code false} otherwise.
 	 */
 	public boolean isGetEnabled() {
 		return isGetEnabled;
 	}
 
 	/**
 	 * Does this cache mode indicate that writes are allowed?
 	 *
 	 * @return {@code true} if cache writes are allowed; {@code false} otherwise.
 	 */
 	public boolean isPutEnabled() {
 		return isPutEnabled;
 	}
 
 	/**
 	 * Used to interpret externalized forms of this enum.
 	 *
 	 * @param setting The externalized form.
 	 *
 	 * @return The matching enum value.
 	 *
 	 * @throws MappingException Indicates the external form was not recognized as a valid enum value.
 	 */
 	public static CacheMode interpretExternalSetting(String setting) {
 		if (setting == null) {
 			return null;
 		}
 
 		try {
-			return CacheMode.valueOf( setting.toUpperCase() );
+			return CacheMode.valueOf( setting.toUpperCase(Locale.ROOT) );
 		}
 		catch ( IllegalArgumentException e ) {
 			throw new MappingException( "Unknown Cache Mode: " + setting );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/ConnectionReleaseMode.java b/hibernate-core/src/main/java/org/hibernate/ConnectionReleaseMode.java
index 25309ca10e..189b52c984 100644
--- a/hibernate-core/src/main/java/org/hibernate/ConnectionReleaseMode.java
+++ b/hibernate-core/src/main/java/org/hibernate/ConnectionReleaseMode.java
@@ -1,66 +1,68 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
+import java.util.Locale;
+
 /**
  * Defines the various policies by which Hibernate might release its underlying
  * JDBC connection.
  *
  * @author Steve Ebersole
  */
 public enum ConnectionReleaseMode{
 	/**
 	 * Indicates that JDBC connection should be aggressively released after each 
 	 * SQL statement is executed. In this mode, the application <em>must</em>
 	 * explicitly close all iterators and scrollable results. This mode may
 	 * only be used with a JTA datasource.
 	 */
 	AFTER_STATEMENT,
 
 	/**
 	 * Indicates that JDBC connections should be released after each transaction 
 	 * ends (works with both JTA-registered synch and HibernateTransaction API).
 	 * This mode may not be used with an application server JTA datasource.
 	 * <p/>
 	 * This is the default mode starting in 3.1; was previously {@link #ON_CLOSE}.
 	 */
 	AFTER_TRANSACTION,
 
 	/**
 	 * Indicates that connections should only be released when the Session is explicitly closed 
 	 * or disconnected; this is the legacy (Hibernate2 and pre-3.1) behavior.
 	 */
 	ON_CLOSE;
 
 	/**
 	 * Alias for {@link ConnectionReleaseMode#valueOf(String)} using upper-case version of the incoming name.
 	 *
 	 * @param name The name to parse
 	 *
 	 * @return The matched enum value.
 	 */
 	public static ConnectionReleaseMode parse(final String name) {
-		return ConnectionReleaseMode.valueOf( name.toUpperCase() );
+		return ConnectionReleaseMode.valueOf( name.toUpperCase(Locale.ROOT) );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/FlushMode.java b/hibernate-core/src/main/java/org/hibernate/FlushMode.java
index 8a0dbacb93..8af4adb00f 100644
--- a/hibernate-core/src/main/java/org/hibernate/FlushMode.java
+++ b/hibernate-core/src/main/java/org/hibernate/FlushMode.java
@@ -1,128 +1,130 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008 Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
+import java.util.Locale;
+
 /**
  * Represents a flushing strategy. The flush process synchronizes
  * database state with session state by detecting state changes
  * and executing SQL statements.
  *
  * @see Session#setFlushMode(FlushMode)
  * @see Query#setFlushMode(FlushMode)
  * @see Criteria#setFlushMode(FlushMode)
  *
  * @author Gavin King
  */
 public enum FlushMode {
 	/**
 	 * The {@link Session} is never flushed unless {@link Session#flush}
 	 * is explicitly called by the application. This mode is very
 	 * efficient for read only transactions.
 	 *
 	 * @deprecated use {@link #MANUAL} instead.
 	 */
 	@Deprecated
 	NEVER ( 0 ),
 
 	/**
 	 * The {@link Session} is only ever flushed when {@link Session#flush}
 	 * is explicitly called by the application. This mode is very
 	 * efficient for read only transactions.
 	 */
 	MANUAL( 0 ),
 
 	/**
 	 * The {@link Session} is flushed when {@link Transaction#commit}
 	 * is called.
 	 */
 	COMMIT(5 ),
 
 	/**
 	 * The {@link Session} is sometimes flushed before query execution
 	 * in order to ensure that queries never return stale state. This
 	 * is the default flush mode.
 	 */
 	AUTO(10 ),
 
 	/**
 	 * The {@link Session} is flushed before every query. This is
 	 * almost always unnecessary and inefficient.
 	 */
 	ALWAYS(20 );
 
 	private final int level;
 
 	private FlushMode(int level) {
 		this.level = level;
 	}
 
 	/**
 	 * Checks to see if {@code this} flush mode is less than the given flush mode.
 	 *
 	 * @param other THe flush mode value to be checked against {@code this}
 	 *
 	 * @return {@code true} indicates {@code other} is less than {@code this}; {@code false} otherwise
 	 */
 	public boolean lessThan(FlushMode other) {
 		return this.level < other.level;
 	}
 
 	/**
 	 * Checks to see if the given mode is the same as {@link #MANUAL}.
 	 *
 	 * @param mode The mode to check
 	 *
 	 * @return true/false
 	 *
 	 * @deprecated Just use equality check against {@link #MANUAL}.  Legacy from before this was an enum
 	 */
 	@Deprecated
 	public static boolean isManualFlushMode(FlushMode mode) {
 		return MANUAL.level == mode.level;
 	}
 
 	/**
 	 * Interprets an external representation of the flush mode.  {@code null} is returned as {@code null}, otherwise
 	 * {@link FlushMode#valueOf(String)} is used with the upper-case version of the incoming value.  An unknown,
 	 * non-null value results in a MappingException being thrown.
 	 *
 	 * @param externalName The external representation
 	 *
 	 * @return The interpreted FlushMode value.
 	 *
 	 * @throws MappingException Indicates an unrecognized external representation
 	 */
 	public static FlushMode interpretExternalSetting(String externalName) {
 		if ( externalName == null ) {
 			return null;
 		}
 
 		try {
-			return FlushMode.valueOf( externalName.toUpperCase() );
+			return FlushMode.valueOf( externalName.toUpperCase(Locale.ROOT) );
 		}
 		catch ( IllegalArgumentException e ) {
 			throw new MappingException( "unknown FlushMode : " + externalName );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/MultiTenancyStrategy.java b/hibernate-core/src/main/java/org/hibernate/MultiTenancyStrategy.java
index 5f0f74f6cf..1c212c64c0 100644
--- a/hibernate-core/src/main/java/org/hibernate/MultiTenancyStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/MultiTenancyStrategy.java
@@ -1,98 +1,99 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
+import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * Describes the methods for multi-tenancy understood by Hibernate.
  *
  * @author Steve Ebersole
  */
 public enum MultiTenancyStrategy {
 	/**
 	 * Multi-tenancy implemented by use of discriminator columns.
 	 */
 	DISCRIMINATOR,
 	/**
 	 * Multi-tenancy implemented as separate schemas.
 	 */
 	SCHEMA,
 	/**
 	 * Multi-tenancy implemented as separate databases.
 	 */
 	DATABASE,
 	/**
 	 * No multi-tenancy.
 	 */
 	NONE;
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			MultiTenancyStrategy.class.getName()
 	);
 
 	/**
 	 * Does this strategy indicate a requirement for the specialized
 	 * {@link org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider}, rather than the
 	 * traditional {@link org.hibernate.engine.jdbc.connections.spi.ConnectionProvider}?
 	 *
 	 * @return {@code true} indicates a MultiTenantConnectionProvider is required; {@code false} indicates it is not.
 	 */
 	public boolean requiresMultiTenantConnectionProvider() {
 		return this == DATABASE || this == SCHEMA;
 	}
 
 	/**
 	 * Extract the MultiTenancyStrategy from the setting map.
 	 *
 	 * @param properties The map of settings.
 	 *
 	 * @return The selected strategy.  {@link #NONE} is always the default.
 	 */
 	public static MultiTenancyStrategy determineMultiTenancyStrategy(Map properties) {
 		final Object strategy = properties.get( Environment.MULTI_TENANT );
 		if ( strategy == null ) {
 			return MultiTenancyStrategy.NONE;
 		}
 
 		if ( MultiTenancyStrategy.class.isInstance( strategy ) ) {
 			return (MultiTenancyStrategy) strategy;
 		}
 
 		final String strategyName = strategy.toString();
 		try {
-			return MultiTenancyStrategy.valueOf( strategyName.toUpperCase() );
+			return MultiTenancyStrategy.valueOf( strategyName.toUpperCase(Locale.ROOT) );
 		}
 		catch ( RuntimeException e ) {
 			LOG.warn( "Unknown multi tenancy strategy [ " +strategyName +" ], using MultiTenancyStrategy.NONE." );
 			return MultiTenancyStrategy.NONE;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/internal/MetadataBuilderImpl.java b/hibernate-core/src/main/java/org/hibernate/boot/internal/MetadataBuilderImpl.java
index 631d0c290f..0d268e1fdc 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/internal/MetadataBuilderImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/internal/MetadataBuilderImpl.java
@@ -1,930 +1,931 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.internal;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
+import java.util.Locale;
 import java.util.Map;
 import javax.persistence.AttributeConverter;
 import javax.persistence.SharedCacheMode;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.annotations.CacheConcurrencyStrategy;
 import org.hibernate.annotations.common.reflection.ClassLoaderDelegate;
 import org.hibernate.annotations.common.reflection.ClassLoadingException;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.java.JavaReflectionManager;
 import org.hibernate.annotations.common.util.StandardClassLoaderDelegateImpl;
 import org.hibernate.boot.CacheRegionDefinition;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.archive.scan.internal.StandardScanOptions;
 import org.hibernate.boot.archive.scan.spi.ScanEnvironment;
 import org.hibernate.boot.archive.scan.spi.ScanOptions;
 import org.hibernate.boot.archive.scan.spi.Scanner;
 import org.hibernate.boot.archive.spi.ArchiveDescriptorFactory;
 import org.hibernate.boot.cfgxml.spi.CfgXmlAccessService;
 import org.hibernate.boot.cfgxml.spi.LoadedConfig;
 import org.hibernate.boot.cfgxml.spi.MappingReference;
 import org.hibernate.boot.model.IdGeneratorStrategyInterpreter;
 import org.hibernate.boot.model.TypeContributions;
 import org.hibernate.boot.model.TypeContributor;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategy;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategy;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl;
 import org.hibernate.boot.model.relational.AuxiliaryDatabaseObject;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.boot.spi.MappingDefaults;
 import org.hibernate.boot.spi.MetadataBuilderInitializer;
 import org.hibernate.boot.spi.MetadataBuildingOptions;
 import org.hibernate.boot.spi.MetadataSourcesContributor;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cfg.AttributeConverterDefinition;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.MetadataSourceType;
 import org.hibernate.cfg.annotations.reflection.JPAMetadataProvider;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.config.spi.StandardConverters;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.type.BasicType;
 import org.hibernate.type.CompositeCustomType;
 import org.hibernate.type.CustomType;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
 
 import org.jboss.jandex.IndexView;
 
 import static org.hibernate.internal.log.DeprecationLogger.DEPRECATION_LOGGER;
 
 /**
  * @author Steve Ebersole
  */
 public class MetadataBuilderImpl implements MetadataBuilder, TypeContributions {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( MetadataBuilderImpl.class );
 
 	private final MetadataSources sources;
 	private final MetadataBuildingOptionsImpl options;
 
 	public MetadataBuilderImpl(MetadataSources sources) {
 		this(
 				sources,
 				getStandardServiceRegistry( sources.getServiceRegistry() )
 		);
 	}
 
 	private static StandardServiceRegistry getStandardServiceRegistry(ServiceRegistry serviceRegistry) {
 		if ( serviceRegistry == null ) {
 			throw new HibernateException( "ServiceRegistry passed to MetadataBuilder cannot be null" );
 		}
 
 		if ( StandardServiceRegistry.class.isInstance( serviceRegistry ) ) {
 			return ( StandardServiceRegistry ) serviceRegistry;
 		}
 		else if ( BootstrapServiceRegistry.class.isInstance( serviceRegistry ) ) {
 			log.debugf(
 					"ServiceRegistry passed to MetadataBuilder was a BootstrapServiceRegistry; this likely wont end well" +
 							"if attempt is made to build SessionFactory"
 			);
 			return new StandardServiceRegistryBuilder( (BootstrapServiceRegistry) serviceRegistry ).build();
 		}
 		else {
 			throw new HibernateException(
 					String.format(
 							"Unexpected type of ServiceRegistry [%s] encountered in attempt to build MetadataBuilder",
 							serviceRegistry.getClass().getName()
 					)
 			);
 		}
 	}
 
 	public MetadataBuilderImpl(MetadataSources sources, StandardServiceRegistry serviceRegistry) {
 		this.sources = sources;
 		this.options = new MetadataBuildingOptionsImpl( serviceRegistry );
 
 		for ( MetadataSourcesContributor contributor :
 				sources.getServiceRegistry()
 						.getService( ClassLoaderService.class )
 						.loadJavaServices( MetadataSourcesContributor.class ) ) {
 			contributor.contribute( sources );
 		}
 
 		// todo : not so sure this is needed anymore.
 		//		these should be set during the StandardServiceRegistryBuilder.configure call
 		applyCfgXmlValues( serviceRegistry.getService( CfgXmlAccessService.class ) );
 
 		final ClassLoaderService classLoaderService = serviceRegistry.getService( ClassLoaderService.class );
 		for ( MetadataBuilderInitializer contributor : classLoaderService.loadJavaServices( MetadataBuilderInitializer.class ) ) {
 			contributor.contribute( this, serviceRegistry );
 		}
 	}
 
 	private void applyCfgXmlValues(CfgXmlAccessService service) {
 		final LoadedConfig aggregatedConfig = service.getAggregatedConfig();
 		if ( aggregatedConfig == null ) {
 			return;
 		}
 
 		for ( CacheRegionDefinition cacheRegionDefinition : aggregatedConfig.getCacheRegionDefinitions() ) {
 			applyCacheRegionDefinition( cacheRegionDefinition );
 		}
 	}
 
 	@Override
 	public MetadataBuilder applyImplicitSchemaName(String implicitSchemaName) {
 		options.mappingDefaults.implicitSchemaName = implicitSchemaName;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyImplicitCatalogName(String implicitCatalogName) {
 		options.mappingDefaults.implicitCatalogName = implicitCatalogName;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyImplicitNamingStrategy(ImplicitNamingStrategy namingStrategy) {
 		this.options.implicitNamingStrategy = namingStrategy;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyPhysicalNamingStrategy(PhysicalNamingStrategy namingStrategy) {
 		this.options.physicalNamingStrategy = namingStrategy;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyReflectionManager(ReflectionManager reflectionManager) {
 		this.options.reflectionManager = reflectionManager;
 		this.options.reflectionManager.injectClassLoaderDelegate( this.options.getHcannClassLoaderDelegate() );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applySharedCacheMode(SharedCacheMode sharedCacheMode) {
 		this.options.sharedCacheMode = sharedCacheMode;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyAccessType(AccessType implicitCacheAccessType) {
 		this.options.mappingDefaults.implicitCacheAccessType = implicitCacheAccessType;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyIndexView(IndexView jandexView) {
 		this.options.jandexView = jandexView;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyScanOptions(ScanOptions scanOptions) {
 		this.options.scanOptions = scanOptions;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyScanEnvironment(ScanEnvironment scanEnvironment) {
 		this.options.scanEnvironment = scanEnvironment;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyScanner(Scanner scanner) {
 		this.options.scannerSetting = scanner;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyArchiveDescriptorFactory(ArchiveDescriptorFactory factory) {
 		this.options.archiveDescriptorFactory = factory;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder enableExplicitDiscriminatorsForJoinedSubclassSupport(boolean supported) {
 		options.explicitDiscriminatorsForJoinedInheritanceSupported = supported;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder enableImplicitDiscriminatorsForJoinedSubclassSupport(boolean supported) {
 		options.implicitDiscriminatorsForJoinedInheritanceSupported = supported;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder enableImplicitForcingOfDiscriminatorsInSelect(boolean supported) {
 		options.implicitlyForceDiscriminatorInSelect = supported;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder enableGlobalNationalizedCharacterDataSupport(boolean enabled) {
 		options.useNationalizedCharacterData = enabled;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyBasicType(BasicType type) {
 		options.basicTypeRegistrations.add( type );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyBasicType(UserType type, String[] keys) {
 		options.basicTypeRegistrations.add( new CustomType( type, keys ) );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyBasicType(CompositeUserType type, String[] keys) {
 		options.basicTypeRegistrations.add( new CompositeCustomType( type, keys ) );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyTypes(TypeContributor typeContributor) {
 		typeContributor.contribute( this, options.serviceRegistry );
 		return this;
 	}
 
 	@Override
 	public void contributeType(BasicType type) {
 		options.basicTypeRegistrations.add( type );
 	}
 
 	@Override
 	public void contributeType(UserType type, String[] keys) {
 		options.basicTypeRegistrations.add( new CustomType( type, keys ) );
 	}
 
 	@Override
 	public void contributeType(CompositeUserType type, String[] keys) {
 		options.basicTypeRegistrations.add( new CompositeCustomType( type, keys ) );
 	}
 
 	@Override
 	public MetadataBuilder applyCacheRegionDefinition(CacheRegionDefinition cacheRegionDefinition) {
 		if ( options.cacheRegionDefinitions == null ) {
 			options.cacheRegionDefinitions = new ArrayList<CacheRegionDefinition>();
 		}
 		options.cacheRegionDefinitions.add( cacheRegionDefinition );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyTempClassLoader(ClassLoader tempClassLoader) {
 		options.tempClassLoader = tempClassLoader;
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applySourceProcessOrdering(MetadataSourceType... sourceTypes) {
 		options.sourceProcessOrdering.addAll( Arrays.asList( sourceTypes ) );
 		return this;
 	}
 
 	public MetadataBuilder allowSpecjSyntax() {
 		this.options.specjProprietarySyntaxEnabled = true;
 		return this;
 	}
 
 
 	@Override
 	public MetadataBuilder applySqlFunction(String functionName, SQLFunction function) {
 		if ( this.options.sqlFunctionMap == null ) {
 			// need to use this form as we want to specify the "concurrency level" as 1
 			// since only one thread will ever (should) be updating this
 			this.options.sqlFunctionMap = new HashMap<String, SQLFunction>();
 		}
 
 		// HHH-7721: SQLFunctionRegistry expects all lowercase.  Enforce,
 		// just in case a user's customer dialect uses mixed cases.
-		this.options.sqlFunctionMap.put( functionName.toLowerCase(), function );
+		this.options.sqlFunctionMap.put( functionName.toLowerCase(Locale.ROOT), function );
 
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyAuxiliaryDatabaseObject(AuxiliaryDatabaseObject auxiliaryDatabaseObject) {
 		if ( this.options.auxiliaryDatabaseObjectList == null ) {
 			this.options.auxiliaryDatabaseObjectList = new ArrayList<AuxiliaryDatabaseObject>();
 		}
 		this.options.auxiliaryDatabaseObjectList.add( auxiliaryDatabaseObject );
 
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyAttributeConverter(AttributeConverterDefinition definition) {
 		this.options.addAttributeConverterDefinition( definition );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyAttributeConverter(Class<? extends AttributeConverter> attributeConverterClass) {
 		applyAttributeConverter( AttributeConverterDefinition.from( attributeConverterClass ) );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyAttributeConverter(Class<? extends AttributeConverter> attributeConverterClass, boolean autoApply) {
 		applyAttributeConverter( AttributeConverterDefinition.from( attributeConverterClass, autoApply ) );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyAttributeConverter(AttributeConverter attributeConverter) {
 		applyAttributeConverter( AttributeConverterDefinition.from( attributeConverter ) );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyAttributeConverter(AttributeConverter attributeConverter, boolean autoApply) {
 		applyAttributeConverter( AttributeConverterDefinition.from( attributeConverter, autoApply ) );
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder enableNewIdentifierGeneratorSupport(boolean enabled) {
 		if ( enabled ) {
 			this.options.idGenerationTypeInterpreter.disableLegacyFallback();
 		}
 		else {
 			this.options.idGenerationTypeInterpreter.enableLegacyFallback();
 		}
 		return this;
 	}
 
 	@Override
 	public MetadataBuilder applyIdGenerationTypeInterpreter(IdGeneratorStrategyInterpreter interpreter) {
 		this.options.idGenerationTypeInterpreter.addInterpreterDelegate( interpreter );
 		return this;
 	}
 
 //	public MetadataBuilder with(PersistentAttributeMemberResolver resolver) {
 //		options.persistentAttributeMemberResolver = resolver;
 //		return this;
 //	}
 
 	@Override
 	public MetadataImpl build() {
 		final CfgXmlAccessService cfgXmlAccessService = options.serviceRegistry.getService( CfgXmlAccessService.class );
 		if ( cfgXmlAccessService.getAggregatedConfig() != null ) {
 			if ( cfgXmlAccessService.getAggregatedConfig().getMappingReferences() != null ) {
 				for ( MappingReference mappingReference : cfgXmlAccessService.getAggregatedConfig().getMappingReferences() ) {
 					mappingReference.apply( sources );
 				}
 			}
 		}
 
 		return MetadataBuildingProcess.build( sources, options );
 	}
 
 	public static class MappingDefaultsImpl implements MappingDefaults {
 		private String implicitSchemaName;
 		private String implicitCatalogName;
 		private boolean implicitlyQuoteIdentifiers;
 
 		private AccessType implicitCacheAccessType;
 
 		public MappingDefaultsImpl(StandardServiceRegistry serviceRegistry) {
 			final ConfigurationService configService = serviceRegistry.getService( ConfigurationService.class );
 
 			this.implicitSchemaName = configService.getSetting(
 					AvailableSettings.DEFAULT_SCHEMA,
 					StandardConverters.STRING,
 					null
 			);
 
 			this.implicitCatalogName = configService.getSetting(
 					AvailableSettings.DEFAULT_CATALOG,
 					StandardConverters.STRING,
 					null
 			);
 
 			this.implicitlyQuoteIdentifiers = configService.getSetting(
 					AvailableSettings.GLOBALLY_QUOTED_IDENTIFIERS,
 					StandardConverters.BOOLEAN,
 					false
 			);
 
 			this.implicitCacheAccessType = configService.getSetting(
 					AvailableSettings.DEFAULT_CACHE_CONCURRENCY_STRATEGY,
 					new ConfigurationService.Converter<AccessType>() {
 						@Override
 						public AccessType convert(Object value) {
 							return AccessType.fromExternalName( value.toString() );
 						}
 					}
 			);
 		}
 
 		@Override
 		public String getImplicitSchemaName() {
 			return implicitSchemaName;
 		}
 
 		@Override
 		public String getImplicitCatalogName() {
 			return implicitCatalogName;
 		}
 
 		@Override
 		public boolean shouldImplicitlyQuoteIdentifiers() {
 			return implicitlyQuoteIdentifiers;
 		}
 
 		@Override
 		public String getImplicitIdColumnName() {
 			return DEFAULT_IDENTIFIER_COLUMN_NAME;
 		}
 
 		@Override
 		public String getImplicitTenantIdColumnName() {
 			return DEFAULT_TENANT_IDENTIFIER_COLUMN_NAME;
 		}
 
 		@Override
 		public String getImplicitDiscriminatorColumnName() {
 			return DEFAULT_DISCRIMINATOR_COLUMN_NAME;
 		}
 
 		@Override
 		public String getImplicitPackageName() {
 			return null;
 		}
 
 		@Override
 		public boolean isAutoImportEnabled() {
 			return true;
 		}
 
 		@Override
 		public String getImplicitCascadeStyleName() {
 			return DEFAULT_CASCADE_NAME;
 		}
 
 		@Override
 		public String getImplicitPropertyAccessorName() {
 			return DEFAULT_PROPERTY_ACCESS_NAME;
 		}
 
 		@Override
 		public boolean areEntitiesImplicitlyLazy() {
 			// for now, just hard-code
 			return false;
 		}
 
 		@Override
 		public boolean areCollectionsImplicitlyLazy() {
 			// for now, just hard-code
 			return true;
 		}
 
 		@Override
 		public AccessType getImplicitCacheAccessType() {
 			return implicitCacheAccessType;
 		}
 	}
 
 	public static class MetadataBuildingOptionsImpl implements MetadataBuildingOptions {
 		private final StandardServiceRegistry serviceRegistry;
 		private final MappingDefaultsImpl mappingDefaults;
 
 		private ArrayList<BasicType> basicTypeRegistrations = new ArrayList<BasicType>();
 
 		private IndexView jandexView;
 		private ClassLoader tempClassLoader;
 
 		private ScanOptions scanOptions;
 		private ScanEnvironment scanEnvironment;
 		private Object scannerSetting;
 		private ArchiveDescriptorFactory archiveDescriptorFactory;
 
 		private ImplicitNamingStrategy implicitNamingStrategy;
 		private PhysicalNamingStrategy physicalNamingStrategy;
 
 		private ReflectionManager reflectionManager;
 		private ClassLoaderDelegate hcannClassLoaderDelegate;
 
 		private SharedCacheMode sharedCacheMode;
 		private AccessType defaultCacheAccessType;
 		private MultiTenancyStrategy multiTenancyStrategy;
 		private ArrayList<CacheRegionDefinition> cacheRegionDefinitions;
 		private boolean explicitDiscriminatorsForJoinedInheritanceSupported;
 		private boolean implicitDiscriminatorsForJoinedInheritanceSupported;
 		private boolean implicitlyForceDiscriminatorInSelect;
 		private boolean useNationalizedCharacterData;
 		private boolean specjProprietarySyntaxEnabled;
 		private ArrayList<MetadataSourceType> sourceProcessOrdering;
 
 		private HashMap<String,SQLFunction> sqlFunctionMap;
 		private ArrayList<AuxiliaryDatabaseObject> auxiliaryDatabaseObjectList;
 		private HashMap<Class,AttributeConverterDefinition> attributeConverterDefinitionsByClass;
 
 		private IdGeneratorInterpreterImpl idGenerationTypeInterpreter = new IdGeneratorInterpreterImpl();
 
 //		private PersistentAttributeMemberResolver persistentAttributeMemberResolver =
 //				StandardPersistentAttributeMemberResolver.INSTANCE;
 
 		public MetadataBuildingOptionsImpl(StandardServiceRegistry serviceRegistry) {
 			this.serviceRegistry = serviceRegistry;
 
 			final StrategySelector strategySelector = serviceRegistry.getService( StrategySelector.class );
 			final ConfigurationService configService = serviceRegistry.getService( ConfigurationService.class );
 
 			this.mappingDefaults = new MappingDefaultsImpl( serviceRegistry );
 
 //			jandexView = (IndexView) configService.getSettings().get( AvailableSettings.JANDEX_INDEX );
 
 			scanOptions = new StandardScanOptions(
 					(String) configService.getSettings().get( AvailableSettings.SCANNER_DISCOVERY ),
 					false
 			);
 			// ScanEnvironment must be set explicitly
 			scannerSetting = configService.getSettings().get( AvailableSettings.SCANNER );
 			if ( scannerSetting == null ) {
 				scannerSetting = configService.getSettings().get( AvailableSettings.SCANNER_DEPRECATED );
 				if ( scannerSetting != null ) {
 					DEPRECATION_LOGGER.logDeprecatedScannerSetting();
 				}
 			}
 			archiveDescriptorFactory = strategySelector.resolveStrategy(
 					ArchiveDescriptorFactory.class,
 					configService.getSettings().get( AvailableSettings.SCANNER_ARCHIVE_INTERPRETER )
 			);
 
 			multiTenancyStrategy =  MultiTenancyStrategy.determineMultiTenancyStrategy( configService.getSettings() );
 
 			implicitDiscriminatorsForJoinedInheritanceSupported = configService.getSetting(
 					AvailableSettings.IMPLICIT_DISCRIMINATOR_COLUMNS_FOR_JOINED_SUBCLASS,
 					StandardConverters.BOOLEAN,
 					false
 			);
 
 			explicitDiscriminatorsForJoinedInheritanceSupported = !configService.getSetting(
 					AvailableSettings.IGNORE_EXPLICIT_DISCRIMINATOR_COLUMNS_FOR_JOINED_SUBCLASS,
 					StandardConverters.BOOLEAN,
 					false
 			);
 
 			implicitlyForceDiscriminatorInSelect = configService.getSetting(
 					AvailableSettings.FORCE_DISCRIMINATOR_IN_SELECTS_BY_DEFAULT,
 					StandardConverters.BOOLEAN,
 					false
 			);
 
 			sharedCacheMode = configService.getSetting(
 					"javax.persistence.sharedCache.mode",
 					new ConfigurationService.Converter<SharedCacheMode>() {
 						@Override
 						public SharedCacheMode convert(Object value) {
 							if ( value == null ) {
 								return null;
 							}
 
 							if ( SharedCacheMode.class.isInstance( value ) ) {
 								return (SharedCacheMode) value;
 							}
 
 							return SharedCacheMode.valueOf( value.toString() );
 						}
 					},
 					SharedCacheMode.UNSPECIFIED
 			);
 
 			defaultCacheAccessType = configService.getSetting(
 					AvailableSettings.DEFAULT_CACHE_CONCURRENCY_STRATEGY,
 					new ConfigurationService.Converter<AccessType>() {
 						@Override
 						public AccessType convert(Object value) {
 							if ( value == null ) {
 								return null;
 							}
 
 							if ( CacheConcurrencyStrategy.class.isInstance( value ) ) {
 								return ( (CacheConcurrencyStrategy) value ).toAccessType();
 							}
 
 							if ( AccessType.class.isInstance( value ) ) {
 								return (AccessType) value;
 							}
 
 							return AccessType.fromExternalName( value.toString() );
 						}
 					},
 					// by default, see if the defined RegionFactory (if one) defines a default
 					serviceRegistry.getService( RegionFactory.class ) == null
 							? null
 							: serviceRegistry.getService( RegionFactory.class ).getDefaultAccessType()
 			);
 
 			specjProprietarySyntaxEnabled = configService.getSetting(
 					"hibernate.enable_specj_proprietary_syntax",
 					StandardConverters.BOOLEAN,
 					false
 			);
 
 			implicitNamingStrategy = strategySelector.resolveDefaultableStrategy(
 					ImplicitNamingStrategy.class,
 					configService.getSettings().get( AvailableSettings.IMPLICIT_NAMING_STRATEGY ),
 					ImplicitNamingStrategyLegacyJpaImpl.INSTANCE
 			);
 
 			physicalNamingStrategy = strategySelector.resolveDefaultableStrategy(
 					PhysicalNamingStrategy.class,
 					configService.getSettings().get( AvailableSettings.PHYSICAL_NAMING_STRATEGY ),
 					PhysicalNamingStrategyStandardImpl.INSTANCE
 			);
 
 			sourceProcessOrdering = resolveInitialSourceProcessOrdering( configService );
 
 			final boolean useNewIdentifierGenerators = configService.getSetting(
 					AvailableSettings.USE_NEW_ID_GENERATOR_MAPPINGS,
 					StandardConverters.BOOLEAN,
 					false
 			);
 			if ( useNewIdentifierGenerators ) {
 				idGenerationTypeInterpreter.disableLegacyFallback();
 			}
 			else {
 				idGenerationTypeInterpreter.enableLegacyFallback();
 			}
 
 			reflectionManager = generateDefaultReflectionManager();
 		}
 
 		private ArrayList<MetadataSourceType> resolveInitialSourceProcessOrdering(ConfigurationService configService) {
 			final ArrayList<MetadataSourceType> initialSelections = new ArrayList<MetadataSourceType>();
 
 			final String sourceProcessOrderingSetting = configService.getSetting(
 					AvailableSettings.ARTIFACT_PROCESSING_ORDER,
 					StandardConverters.STRING
 			);
 			if ( sourceProcessOrderingSetting != null ) {
 				final String[] orderChoices = StringHelper.split( ",; ", sourceProcessOrderingSetting, false );
 				initialSelections.addAll( CollectionHelper.<MetadataSourceType>arrayList( orderChoices.length ) );
 				for ( String orderChoice : orderChoices ) {
 					initialSelections.add( MetadataSourceType.parsePrecedence( orderChoice ) );
 				}
 			}
 			if ( initialSelections.isEmpty() ) {
 				initialSelections.add( MetadataSourceType.HBM );
 				initialSelections.add( MetadataSourceType.CLASS );
 			}
 
 			return initialSelections;
 		}
 
 		private ReflectionManager generateDefaultReflectionManager() {
 			final JavaReflectionManager reflectionManager = new JavaReflectionManager();
 			reflectionManager.setMetadataProvider( new JPAMetadataProvider() );
 			reflectionManager.injectClassLoaderDelegate( getHcannClassLoaderDelegate() );
 			return reflectionManager;
 		}
 
 		public ClassLoaderDelegate getHcannClassLoaderDelegate() {
 			if ( hcannClassLoaderDelegate == null ) {
 				hcannClassLoaderDelegate = new ClassLoaderDelegate() {
 					private final  ClassLoaderService classLoaderService = getServiceRegistry().getService( ClassLoaderService.class );
 
 					@Override
 					public <T> Class<T> classForName(String className) throws ClassLoadingException {
 						try {
 							return classLoaderService.classForName( className );
 						}
 						catch (org.hibernate.boot.registry.classloading.spi.ClassLoadingException e) {
 							return StandardClassLoaderDelegateImpl.INSTANCE.classForName( className );
 						}
 					}
 				};
 			}
 			return hcannClassLoaderDelegate;
 		}
 
 		@Override
 		public StandardServiceRegistry getServiceRegistry() {
 			return serviceRegistry;
 		}
 
 		@Override
 		public MappingDefaults getMappingDefaults() {
 			return mappingDefaults;
 		}
 
 		@Override
 		public List<BasicType> getBasicTypeRegistrations() {
 			return basicTypeRegistrations;
 		}
 
 		@Override
 		public IndexView getJandexView() {
 			return jandexView;
 		}
 
 		@Override
 		public ScanOptions getScanOptions() {
 			return scanOptions;
 		}
 
 		@Override
 		public ScanEnvironment getScanEnvironment() {
 			return scanEnvironment;
 		}
 
 		@Override
 		public Object getScanner() {
 			return scannerSetting;
 		}
 
 		@Override
 		public ArchiveDescriptorFactory getArchiveDescriptorFactory() {
 			return archiveDescriptorFactory;
 		}
 
 		@Override
 		public ClassLoader getTempClassLoader() {
 			return tempClassLoader;
 		}
 
 		@Override
 		public ImplicitNamingStrategy getImplicitNamingStrategy() {
 			return implicitNamingStrategy;
 		}
 
 		@Override
 		public PhysicalNamingStrategy getPhysicalNamingStrategy() {
 			return physicalNamingStrategy;
 		}
 
 		@Override
 		public ReflectionManager getReflectionManager() {
 			return reflectionManager;
 		}
 
 		@Override
 		public SharedCacheMode getSharedCacheMode() {
 			return sharedCacheMode;
 		}
 
 		@Override
 		public AccessType getImplicitCacheAccessType() {
 			return defaultCacheAccessType;
 		}
 
 		@Override
 		public MultiTenancyStrategy getMultiTenancyStrategy() {
 			return multiTenancyStrategy;
 		}
 
 		@Override
 		public IdGeneratorStrategyInterpreter getIdGenerationTypeInterpreter() {
 			return idGenerationTypeInterpreter;
 		}
 
 		@Override
 		public List<CacheRegionDefinition> getCacheRegionDefinitions() {
 			return cacheRegionDefinitions;
 		}
 
 		@Override
 		public boolean ignoreExplicitDiscriminatorsForJoinedInheritance() {
 			return !explicitDiscriminatorsForJoinedInheritanceSupported;
 		}
 
 		@Override
 		public boolean createImplicitDiscriminatorsForJoinedInheritance() {
 			return implicitDiscriminatorsForJoinedInheritanceSupported;
 		}
 
 		@Override
 		public boolean shouldImplicitlyForceDiscriminatorInSelect() {
 			return implicitlyForceDiscriminatorInSelect;
 		}
 
 		@Override
 		public boolean useNationalizedCharacterData() {
 			return useNationalizedCharacterData;
 		}
 
 		@Override
 		public boolean isSpecjProprietarySyntaxEnabled() {
 			return specjProprietarySyntaxEnabled;
 		}
 
 		@Override
 		public List<MetadataSourceType> getSourceProcessOrdering() {
 			return sourceProcessOrdering;
 		}
 
 		@Override
 		public Map<String, SQLFunction> getSqlFunctions() {
 			return sqlFunctionMap == null ? Collections.<String, SQLFunction>emptyMap() : sqlFunctionMap;
 		}
 
 		@Override
 		public List<AuxiliaryDatabaseObject> getAuxiliaryDatabaseObjectList() {
 			return auxiliaryDatabaseObjectList == null
 					? Collections.<AuxiliaryDatabaseObject>emptyList()
 					: auxiliaryDatabaseObjectList;
 		}
 
 		@Override
 		public List<AttributeConverterDefinition> getAttributeConverters() {
 			return attributeConverterDefinitionsByClass == null
 					? Collections.<AttributeConverterDefinition>emptyList()
 					: new ArrayList<AttributeConverterDefinition>( attributeConverterDefinitionsByClass.values() );
 		}
 
 		public void addAttributeConverterDefinition(AttributeConverterDefinition definition) {
 			if ( this.attributeConverterDefinitionsByClass == null ) {
 				this.attributeConverterDefinitionsByClass = new HashMap<Class, AttributeConverterDefinition>();
 			}
 
 			final Object old = this.attributeConverterDefinitionsByClass.put( definition.getAttributeConverter().getClass(), definition );
 
 			if ( old != null ) {
 				throw new AssertionFailure(
 						String.format(
 								"AttributeConverter class [%s] registered multiple times",
 								definition.getAttributeConverter().getClass()
 						)
 				);
 			}
 		}
 
 		public static interface JpaOrmXmlPersistenceUnitDefaults {
 			public String getDefaultSchemaName();
 			public String getDefaultCatalogName();
 			public boolean shouldImplicitlyQuoteIdentifiers();
 		}
 
 		/**
 		 * Yuck.  This is needed because JPA lets users define "global building options"
 		 * in {@code orm.xml} mappings.  Forget that there are generally multiple
 		 * {@code orm.xml} mappings if using XML approach...  Ugh
 		 */
 		public void apply(JpaOrmXmlPersistenceUnitDefaults jpaOrmXmlPersistenceUnitDefaults) {
 			if ( !mappingDefaults.shouldImplicitlyQuoteIdentifiers() ) {
 				mappingDefaults.implicitlyQuoteIdentifiers = jpaOrmXmlPersistenceUnitDefaults.shouldImplicitlyQuoteIdentifiers();
 			}
 
 			if ( mappingDefaults.getImplicitCatalogName() == null ) {
 				mappingDefaults.implicitCatalogName = StringHelper.nullIfEmpty(
 						jpaOrmXmlPersistenceUnitDefaults.getDefaultCatalogName()
 				);
 			}
 
 			if ( mappingDefaults.getImplicitSchemaName() == null ) {
 				mappingDefaults.implicitSchemaName = StringHelper.nullIfEmpty(
 						jpaOrmXmlPersistenceUnitDefaults.getDefaultSchemaName()
 				);
 			}
 		}
 
 		//		@Override
 //		public PersistentAttributeMemberResolver getPersistentAttributeMemberResolver() {
 //			return persistentAttributeMemberResolver;
 //		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ModelBinder.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ModelBinder.java
index 5d7f966a2d..d3228203c6 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ModelBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ModelBinder.java
@@ -1503,2023 +1503,2023 @@ public class ModelBinder {
 				typeName = mappingDocument.qualifyClassName( typeName );
 			}
 		}
 		if ( source.getTypeInformation().getParameters() != null ) {
 			typeParameters.putAll( source.getTypeInformation().getParameters() );
 		}
 
 		binding.setTypeName( typeName );
 		binding.setTypeParameters( typeParameters );
 
 		if ( source.getFetchCharacteristics().getFetchTiming() == FetchTiming.DELAYED ) {
 			binding.setLazy( true );
 			binding.setExtraLazy( source.getFetchCharacteristics().isExtraLazy() );
 		}
 		else {
 			binding.setLazy( false );
 		}
 
 		switch ( source.getFetchCharacteristics().getFetchStyle() ) {
 			case SELECT: {
 				binding.setFetchMode( FetchMode.SELECT );
 				break;
 			}
 			case JOIN: {
 				binding.setFetchMode( FetchMode.JOIN );
 				break;
 			}
 			case BATCH: {
 				binding.setFetchMode( FetchMode.SELECT );
 				binding.setBatchSize( source.getFetchCharacteristics().getBatchSize() );
 				break;
 			}
 			case SUBSELECT: {
 				binding.setFetchMode( FetchMode.SELECT );
 				binding.setSubselectLoadable( true );
 				// todo : this could totally be done using a "symbol map" approach
 				binding.getOwner().setSubselectLoadableCollections( true );
 				break;
 			}
 			default: {
 				throw new AssertionFailure( "Unexpected FetchStyle : " + source.getFetchCharacteristics().getFetchStyle().name() );
 			}
 		}
 
 		for ( String name : source.getSynchronizedTableNames() ) {
 			binding.getSynchronizedTables().add( name );
 		}
 
 		binding.setWhere( source.getWhere() );
 		binding.setLoaderName( source.getCustomLoaderName() );
 		if ( source.getCustomSqlInsert() != null ) {
 			binding.setCustomSQLInsert(
 					source.getCustomSqlInsert().getSql(),
 					source.getCustomSqlInsert().isCallable(),
 					source.getCustomSqlInsert().getCheckStyle()
 			);
 		}
 		if ( source.getCustomSqlUpdate() != null ) {
 			binding.setCustomSQLUpdate(
 					source.getCustomSqlUpdate().getSql(),
 					source.getCustomSqlUpdate().isCallable(),
 					source.getCustomSqlUpdate().getCheckStyle()
 			);
 		}
 		if ( source.getCustomSqlDelete() != null ) {
 			binding.setCustomSQLDelete(
 					source.getCustomSqlDelete().getSql(),
 					source.getCustomSqlDelete().isCallable(),
 					source.getCustomSqlDelete().getCheckStyle()
 			);
 		}
 		if ( source.getCustomSqlDeleteAll() != null ) {
 			binding.setCustomSQLDeleteAll(
 					source.getCustomSqlDeleteAll().getSql(),
 					source.getCustomSqlDeleteAll().isCallable(),
 					source.getCustomSqlDeleteAll().getCheckStyle()
 			);
 		}
 
 		if ( source instanceof Sortable ) {
 			final Sortable sortable = (Sortable) source;
 			if ( sortable.isSorted() ) {
 				binding.setSorted( true );
 				if ( ! sortable.getComparatorName().equals( "natural" ) ) {
 					binding.setComparatorClassName( sortable.getComparatorName() );
 				}
 			}
 			else {
 				binding.setSorted( false );
 			}
 		}
 
 		if ( source instanceof Orderable ) {
 			if ( ( (Orderable) source ).isOrdered() ) {
 				binding.setOrderBy( ( (Orderable) source ).getOrder() );
 			}
 		}
 
 		final String cascadeStyle = source.getCascadeStyleName();
 		if ( cascadeStyle != null && cascadeStyle.contains( "delete-orphan" ) ) {
 			binding.setOrphanDelete( true );
 		}
 
 		for ( FilterSource filterSource : source.getFilterSources() ) {
 			String condition = filterSource.getCondition();
 			if ( condition == null ) {
 				final FilterDefinition filterDefinition = mappingDocument.getMetadataCollector().getFilterDefinition( filterSource.getName() );
 				if ( filterDefinition != null ) {
 					condition = filterDefinition.getDefaultFilterCondition();
 				}
 			}
 
 			binding.addFilter(
 					filterSource.getName(),
 					condition,
 					filterSource.shouldAutoInjectAliases(),
 					filterSource.getAliasToTableMap(),
 					filterSource.getAliasToEntityMap()
 			);
 		}
 	}
 
 	private void applyCaching(MappingDocument mappingDocument, Caching caching, Collection collection) {
 		if ( caching == null || caching.getRequested() == TruthValue.UNKNOWN ) {
 			// see if JPA's SharedCacheMode indicates we should implicitly apply caching
 			switch ( mappingDocument.getBuildingOptions().getSharedCacheMode() ) {
 				case ALL: {
 					caching = new Caching(
 							null,
 							mappingDocument.getBuildingOptions().getImplicitCacheAccessType(),
 							false,
 							TruthValue.UNKNOWN
 					);
 				}
 				case NONE: {
 					// Ideally we'd disable all caching...
 					break;
 				}
 				case ENABLE_SELECTIVE: {
 					// this is default behavior for hbm.xml
 					break;
 				}
 				case DISABLE_SELECTIVE: {
 					// really makes no sense for hbm.xml
 					break;
 				}
 				default: {
 					// null or UNSPECIFIED, nothing to do.  IMO for hbm.xml this is equivalent
 					// to ENABLE_SELECTIVE
 					break;
 				}
 			}
 		}
 
 		if ( caching == null || caching.getRequested() == TruthValue.FALSE ) {
 			return;
 		}
 
 		if ( caching.getAccessType() != null ) {
 			collection.setCacheConcurrencyStrategy( caching.getAccessType().getExternalName() );
 		}
 		else {
 			collection.setCacheConcurrencyStrategy( mappingDocument.getBuildingOptions().getImplicitCacheAccessType().getExternalName() );
 		}
 		collection.setCacheRegionName( caching.getRegion() );
 //		collection.setCachingExplicitlyRequested( caching.getRequested() != TruthValue.UNKNOWN );
 	}
 
 	private Identifier determineTable(
 			MappingDocument sourceDocument,
 			String attributeName,
 			RelationalValueSourceContainer relationalValueSourceContainer) {
 		return determineTable( sourceDocument, attributeName, relationalValueSourceContainer.getRelationalValueSources() );
 	}
 
 	private Identifier determineTable(
 			MappingDocument mappingDocument,
 			SingularAttributeSourceEmbedded embeddedAttributeSource) {
 		Identifier tableName = null;
 		for ( AttributeSource attributeSource : embeddedAttributeSource.getEmbeddableSource().attributeSources() ) {
 			final Identifier determinedName;
 			if ( RelationalValueSourceContainer.class.isInstance( attributeSource ) ) {
 				determinedName = determineTable(
 						mappingDocument,
 						embeddedAttributeSource.getAttributeRole().getFullPath(),
 						(RelationalValueSourceContainer) attributeSource
 
 				);
 			}
 			else if ( SingularAttributeSourceEmbedded.class.isInstance( attributeSource ) ) {
 				determinedName = determineTable( mappingDocument, (SingularAttributeSourceEmbedded) attributeSource );
 			}
 			else if ( SingularAttributeSourceAny.class.isInstance( attributeSource ) ) {
 				determinedName = determineTable(
 						mappingDocument,
 						attributeSource.getAttributeRole().getFullPath(),
 						( (SingularAttributeSourceAny) attributeSource ).getKeySource().getRelationalValueSources()
 				);
 			}
 			else {
 				continue;
 			}
 
 			if (  EqualsHelper.equals( tableName, determinedName ) ) {
 				continue;
 			}
 
 			if ( tableName != null ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Attribute [%s] referenced columns from multiple tables: %s, %s",
 								embeddedAttributeSource.getAttributeRole().getFullPath(),
 								tableName,
 								determinedName
 						),
 						mappingDocument.getOrigin()
 				);
 			}
 
 			tableName = determinedName;
 		}
 
 		return tableName;
 	}
 
 	private Identifier determineTable(
 			MappingDocument mappingDocument,
 			String attributeName,
 			List<RelationalValueSource> relationalValueSources) {
 		String tableName = null;
 		for ( RelationalValueSource relationalValueSource : relationalValueSources ) {
 			if ( ColumnSource.class.isInstance( relationalValueSource ) ) {
 				final ColumnSource columnSource = (ColumnSource) relationalValueSource;
 				if ( EqualsHelper.equals( tableName, columnSource.getContainingTableName() ) ) {
 					continue;
 				}
 
 				if ( tableName != null ) {
 					throw new MappingException(
 							String.format(
 									Locale.ENGLISH,
 									"Attribute [%s] referenced columns from multiple tables: %s, %s",
 									attributeName,
 									tableName,
 									columnSource.getContainingTableName()
 							),
 							mappingDocument.getOrigin()
 					);
 				}
 
 				tableName = columnSource.getContainingTableName();
 			}
 		}
 
 		return database.toIdentifier( tableName );
 	}
 
 	private void bindSecondaryTable(
 			MappingDocument mappingDocument,
 			SecondaryTableSource secondaryTableSource,
 			Join secondaryTableJoin,
 			final EntityTableXref entityTableXref) {
 		final PersistentClass persistentClass = secondaryTableJoin.getPersistentClass();
 
 		final Identifier catalogName = determineCatalogName( secondaryTableSource.getTableSource() );
 		final Identifier schemaName = determineSchemaName( secondaryTableSource.getTableSource() );
 		final Schema schema = database.locateSchema( catalogName, schemaName );
 
 		Table secondaryTable;
 		final Identifier logicalTableName;
 
 		if ( TableSource.class.isInstance( secondaryTableSource.getTableSource() ) ) {
 			final TableSource tableSource = (TableSource) secondaryTableSource.getTableSource();
 			logicalTableName = database.toIdentifier( tableSource.getExplicitTableName() );
 			secondaryTable = schema.locateTable( logicalTableName );
 			if ( secondaryTable == null ) {
 				secondaryTable = schema.createTable( logicalTableName, false );
 			}
 			else {
 				secondaryTable.setAbstract( false );
 			}
 
 			secondaryTable.setComment( tableSource.getComment() );
 		}
 		else {
 			final InLineViewSource inLineViewSource = (InLineViewSource) secondaryTableSource.getTableSource();
 			secondaryTable = new Table(
 					schema,
 					inLineViewSource.getSelectStatement(),
 					false
 			);
 			logicalTableName = Identifier.toIdentifier( inLineViewSource.getLogicalName() );
 		}
 
 		secondaryTableJoin.setTable( secondaryTable );
 		entityTableXref.addSecondaryTable( mappingDocument, logicalTableName, secondaryTableJoin );
 
 		bindCustomSql(
 				mappingDocument,
 				secondaryTableSource,
 				secondaryTableJoin
 		);
 
 		secondaryTableJoin.setSequentialSelect( secondaryTableSource.getFetchStyle() == FetchStyle.SELECT );
 		secondaryTableJoin.setInverse( secondaryTableSource.isInverse() );
 		secondaryTableJoin.setOptional( secondaryTableSource.isOptional() );
 
 		if ( log.isDebugEnabled() ) {
 			log.debugf(
 					"Mapping entity secondary-table: %s -> %s",
 					persistentClass.getEntityName(),
 					secondaryTable.getName()
 			);
 		}
 
 		final SimpleValue keyBinding = new DependantValue(
 				mappingDocument.getMetadataCollector(),
 				secondaryTable,
 				persistentClass.getIdentifier()
 		);
 		if ( mappingDocument.getBuildingOptions().useNationalizedCharacterData() ) {
 			keyBinding.makeNationalized();
 		}
 		secondaryTableJoin.setKey( keyBinding );
 
 		keyBinding.setCascadeDeleteEnabled( secondaryTableSource.isCascadeDeleteEnabled() );
 
 		// NOTE : no Type info to bind...
 
 		relationalObjectBinder.bindColumns(
 				mappingDocument,
 				secondaryTableSource.getPrimaryKeyColumnSources(),
 				keyBinding,
 				secondaryTableSource.isOptional(),
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					int count = 0;
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						final Column correspondingColumn = entityTableXref.getPrimaryTable().getPrimaryKey().getColumn( count++ );
 						return database.toIdentifier( correspondingColumn.getQuotedName() );
 					}
 				}
 		);
 
 		keyBinding.setForeignKeyName( secondaryTableSource.getExplicitForeignKeyName() );
 
 		secondaryTableJoin.createPrimaryKey();
 		secondaryTableJoin.createForeignKey();
 	}
 
 	private Property createEmbeddedAttribute(
 			MappingDocument sourceDocument,
 			SingularAttributeSourceEmbedded embeddedSource,
 			Component componentBinding,
 			String containingClassName) {
 		final String attributeName = embeddedSource.getName();
 
 		bindComponent(
 				sourceDocument,
 				embeddedSource.getEmbeddableSource(),
 				componentBinding,
 				containingClassName,
 				attributeName,
 				embeddedSource.getXmlNodeName(),
 				embeddedSource.isVirtualAttribute()
 		);
 
 		prepareValueTypeViaReflection(
 				sourceDocument,
 				componentBinding,
 				componentBinding.getComponentClassName(),
 				attributeName,
 				embeddedSource.getAttributeRole()
 		);
 
 		componentBinding.createForeignKey();
 
 		final Property attribute;
 		if ( embeddedSource.isVirtualAttribute() ) {
 			attribute = new SyntheticProperty() {
 				@Override
 				public String getPropertyAccessorName() {
 					return "embedded";
 				}
 			};
 		}
 		else {
 			attribute = new Property();
 		}
 		attribute.setValue( componentBinding );
 		bindProperty(
 				sourceDocument,
 				embeddedSource,
 				attribute
 		);
 
 		final String xmlNodeName = determineXmlNodeName( embeddedSource, componentBinding.getOwner().getNodeName() );
 		componentBinding.setNodeName( xmlNodeName );
 		attribute.setNodeName( xmlNodeName );
 
 		return attribute;
 	}
 
 	private Property createBasicAttribute(
 			MappingDocument sourceDocument,
 			final SingularAttributeSourceBasic attributeSource,
 			SimpleValue value,
 			String containingClassName) {
 		final String attributeName = attributeSource.getName();
 
 		bindSimpleValueType(
 				sourceDocument,
 				attributeSource.getTypeInformation(),
 				value
 		);
 
 		relationalObjectBinder.bindColumnsAndFormulas(
 				sourceDocument,
 				attributeSource.getRelationalValueSources(),
 				value,
 				true,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						return implicitNamingStrategy.determineBasicColumnName( attributeSource );
 					}
 				}
 		);
 
 
 		prepareValueTypeViaReflection(
 				sourceDocument,
 				value,
 				containingClassName,
 				attributeName,
 				attributeSource.getAttributeRole()
 		);
 
 //		// this is done here 'cos we might only know the type here (ugly!)
 //		// TODO: improve this a lot:
 //		if ( value instanceof ToOne ) {
 //			ToOne toOne = (ToOne) value;
 //			String propertyRef = toOne.getReferencedEntityAttributeName();
 //			if ( propertyRef != null ) {
 //				mappings.addUniquePropertyReference( toOne.getReferencedEntityName(), propertyRef );
 //			}
 //			toOne.setCascadeDeleteEnabled( "cascade".equals( subnode.attributeValue( "on-delete" ) ) );
 //		}
 //		else if ( value instanceof Collection ) {
 //			Collection coll = (Collection) value;
 //			String propertyRef = coll.getReferencedEntityAttributeName();
 //			// not necessarily a *unique* property reference
 //			if ( propertyRef != null ) {
 //				mappings.addPropertyReference( coll.getOwnerEntityName(), propertyRef );
 //			}
 //		}
 
 		value.createForeignKey();
 
 		Property property = new Property();
 		property.setValue( value );
 		bindProperty(
 				sourceDocument,
 				attributeSource,
 				property
 		);
 
 		return property;
 	}
 
 	private Property createOneToOneAttribute(
 			MappingDocument sourceDocument,
 			SingularAttributeSourceOneToOne oneToOneSource,
 			OneToOne oneToOneBinding,
 			String containingClassName) {
 		bindOneToOne( sourceDocument, oneToOneSource, oneToOneBinding );
 
 		prepareValueTypeViaReflection(
 				sourceDocument,
 				oneToOneBinding,
 				containingClassName,
 				oneToOneSource.getName(),
 				oneToOneSource.getAttributeRole()
 		);
 
 		final String propertyRef = oneToOneBinding.getReferencedPropertyName();
 		if ( propertyRef != null ) {
 			handlePropertyReference(
 					sourceDocument,
 					oneToOneBinding.getReferencedEntityName(),
 					propertyRef,
 					true,
 					"<one-to-one name=\"" + oneToOneSource.getName() + "\"/>"
 			);
 		}
 
 		oneToOneBinding.createForeignKey();
 
 		Property prop = new Property();
 		prop.setValue( oneToOneBinding );
 		bindProperty(
 				sourceDocument,
 				oneToOneSource,
 				prop
 		);
 
 		return prop;
 	}
 
 	private void handlePropertyReference(
 			MappingDocument mappingDocument,
 			String referencedEntityName,
 			String referencedPropertyName,
 			boolean isUnique,
 			String sourceElementSynopsis) {
 		PersistentClass entityBinding = mappingDocument.getMetadataCollector().getEntityBinding( referencedEntityName );
 		if ( entityBinding == null ) {
 			// entity may just not have been processed yet - set up a delayed handler
 			registerDelayedPropertyReferenceHandler(
 					new DelayedPropertyReferenceHandlerImpl(
 							referencedEntityName,
 							referencedPropertyName,
 							isUnique,
 							sourceElementSynopsis,
 							mappingDocument.getOrigin()
 					),
 					mappingDocument
 			);
 		}
 		else {
 			Property propertyBinding = entityBinding.getReferencedProperty( referencedPropertyName );
 			if ( propertyBinding == null ) {
 				// attribute may just not have been processed yet - set up a delayed handler
 				registerDelayedPropertyReferenceHandler(
 						new DelayedPropertyReferenceHandlerImpl(
 								referencedEntityName,
 								referencedPropertyName,
 								isUnique,
 								sourceElementSynopsis,
 								mappingDocument.getOrigin()
 						),
 						mappingDocument
 				);
 			}
 			else {
 				log.tracef(
 						"Property [%s.%s] referenced by property-ref [%s] was available - no need for delayed handling",
 						referencedEntityName,
 						referencedPropertyName,
 						sourceElementSynopsis
 				);
 				if ( isUnique ) {
 					( (SimpleValue) propertyBinding.getValue() ).setAlternateUniqueKey( true );
 				}
 			}
 		}
 	}
 
 	private void registerDelayedPropertyReferenceHandler(
 			DelayedPropertyReferenceHandlerImpl handler,
 			MetadataBuildingContext buildingContext) {
 		log.tracef(
 				"Property [%s.%s] referenced by property-ref [%s] was not yet available - creating delayed handler",
 				handler.referencedEntityName,
 				handler.referencedPropertyName,
 				handler.sourceElementSynopsis
 		);
 		buildingContext.getMetadataCollector().addDelayedPropertyReferenceHandler( handler );
 	}
 
 	public void bindOneToOne(
 			final MappingDocument sourceDocument,
 			final SingularAttributeSourceOneToOne oneToOneSource,
 			final OneToOne oneToOneBinding) {
 		oneToOneBinding.setPropertyName( oneToOneSource.getName() );
 
 		relationalObjectBinder.bindFormulas(
 				sourceDocument,
 				oneToOneSource.getFormulaSources(),
 				oneToOneBinding
 		);
 
 
 		if ( oneToOneSource.isConstrained() ) {
 			if ( oneToOneSource.getCascadeStyleName() != null
 					&& oneToOneSource.getCascadeStyleName().contains( "delete-orphan" ) ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"one-to-one attribute [%s] cannot specify orphan delete cascading as it is constrained",
 								oneToOneSource.getAttributeRole().getFullPath()
 						),
 						sourceDocument.getOrigin()
 				);
 			}
 			oneToOneBinding.setConstrained( true );
 			oneToOneBinding.setForeignKeyType( ForeignKeyDirection.FROM_PARENT );
 		}
 		else {
 			oneToOneBinding.setForeignKeyType( ForeignKeyDirection.TO_PARENT );
 		}
 
 		oneToOneBinding.setLazy( oneToOneSource.getFetchCharacteristics().getFetchTiming() == FetchTiming.DELAYED );
 		oneToOneBinding.setFetchMode(
 				oneToOneSource.getFetchCharacteristics().getFetchStyle() == FetchStyle.SELECT
 						? FetchMode.SELECT
 						: FetchMode.JOIN
 		);
 		oneToOneBinding.setUnwrapProxy( oneToOneSource.getFetchCharacteristics().isUnwrapProxies() );
 
 
 		if ( StringHelper.isNotEmpty( oneToOneSource.getReferencedEntityAttributeName() ) ) {
 			oneToOneBinding.setReferencedPropertyName( oneToOneSource.getReferencedEntityAttributeName() );
 			oneToOneBinding.setReferenceToPrimaryKey( false );
 		}
 		else {
 			oneToOneBinding.setReferenceToPrimaryKey( true );
 		}
 
 		// todo : probably need some reflection here if null
 		oneToOneBinding.setReferencedEntityName( oneToOneSource.getReferencedEntityName() );
 
 		if ( oneToOneSource.isEmbedXml() ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfEmbedXmlSupport();
 		}
 		oneToOneBinding.setEmbedded( oneToOneSource.isEmbedXml() );
 
 		if ( StringHelper.isNotEmpty( oneToOneSource.getExplicitForeignKeyName() ) ) {
 			oneToOneBinding.setForeignKeyName( oneToOneSource.getExplicitForeignKeyName() );
 		}
 
 		oneToOneBinding.setCascadeDeleteEnabled( oneToOneSource.isCascadeDeleteEnabled() );
 	}
 
 	private Property createManyToOneAttribute(
 			MappingDocument sourceDocument,
 			SingularAttributeSourceManyToOne manyToOneSource,
 			ManyToOne manyToOneBinding,
 			String containingClassName) {
 		final String attributeName = manyToOneSource.getName();
 
 		final String referencedEntityName;
 		if ( manyToOneSource.getReferencedEntityName() != null ) {
 			referencedEntityName = manyToOneSource.getReferencedEntityName();
 		}
 		else {
 			Class reflectedPropertyClass = Helper.reflectedPropertyClass( sourceDocument, containingClassName, attributeName );
 			if ( reflectedPropertyClass != null ) {
 				referencedEntityName = reflectedPropertyClass.getName();
 			}
 			else {
 				prepareValueTypeViaReflection(
 						sourceDocument,
 						manyToOneBinding,
 						containingClassName,
 						attributeName,
 						manyToOneSource.getAttributeRole()
 				);
 				referencedEntityName = manyToOneBinding.getTypeName();
 			}
 		}
 
 		if ( manyToOneSource.isUnique() ) {
 			manyToOneBinding.markAsLogicalOneToOne();
 		}
 
 		bindManyToOneAttribute( sourceDocument, manyToOneSource, manyToOneBinding, referencedEntityName );
 
 		final String propertyRef = manyToOneBinding.getReferencedPropertyName();
 
 		if ( propertyRef != null ) {
 			handlePropertyReference(
 					sourceDocument,
 					manyToOneBinding.getReferencedEntityName(),
 					propertyRef,
 					true,
 					"<many-to-one name=\"" + manyToOneSource.getName() + "\"/>"
 			);
 		}
 
 		Property prop = new Property();
 		prop.setValue( manyToOneBinding );
 		bindProperty(
 				sourceDocument,
 				manyToOneSource,
 				prop
 		);
 
 		if ( StringHelper.isNotEmpty( manyToOneSource.getCascadeStyleName() ) ) {
 			// todo : would be better to delay this the end of binding (second pass, etc)
 			// in order to properly allow for a singular unique column for a many-to-one to
 			// also trigger a "logical one-to-one".  As-is, this can occasionally lead to
 			// false exceptions if the many-to-one column binding is delayed and the
 			// uniqueness is indicated on the <column/> rather than on the <many-to-one/>
 			//
 			// Ideally, would love to see a SimpleValue#validate approach, rather than a
 			// SimpleValue#isValid that is then handled at a higher level (Property, etc).
 			// The reason being that the current approach misses the exact reason
 			// a "validation" fails since it loses "context"
 			if ( manyToOneSource.getCascadeStyleName().contains( "delete-orphan" ) ) {
 				if ( !manyToOneBinding.isLogicalOneToOne() ) {
 					throw new MappingException(
 							String.format(
 									Locale.ENGLISH,
 									"many-to-one attribute [%s] specified delete-orphan but is not specified as unique; " +
 											"remove delete-orphan cascading or specify unique=\"true\"",
 									manyToOneSource.getAttributeRole().getFullPath()
 							),
 							sourceDocument.getOrigin()
 					);
 				}
 			}
 		}
 
 		return prop;
 	}
 
 	private void bindManyToOneAttribute(
 			final MappingDocument sourceDocument,
 			final SingularAttributeSourceManyToOne manyToOneSource,
 			ManyToOne manyToOneBinding,
 			String referencedEntityName) {
 		// NOTE : no type information to bind
 
 		manyToOneBinding.setReferencedEntityName( referencedEntityName );
 		if ( StringHelper.isNotEmpty( manyToOneSource.getReferencedEntityAttributeName() ) ) {
 			manyToOneBinding.setReferencedPropertyName( manyToOneSource.getReferencedEntityAttributeName() );
 			manyToOneBinding.setReferenceToPrimaryKey( false );
 		}
 		else {
 			manyToOneBinding.setReferenceToPrimaryKey( true );
 		}
 
 		manyToOneBinding.setLazy( manyToOneSource.getFetchCharacteristics().getFetchTiming() == FetchTiming.DELAYED );
 		manyToOneBinding.setUnwrapProxy( manyToOneSource.getFetchCharacteristics().isUnwrapProxies() );
 		manyToOneBinding.setFetchMode(
 				manyToOneSource.getFetchCharacteristics().getFetchStyle() == FetchStyle.SELECT
 						? FetchMode.SELECT
 						: FetchMode.JOIN
 		);
 
 		if ( manyToOneSource.isEmbedXml() ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfEmbedXmlSupport();
 		}
 		manyToOneBinding.setEmbedded( manyToOneSource.isEmbedXml() );
 
 		manyToOneBinding.setIgnoreNotFound( manyToOneSource.isIgnoreNotFound() );
 
 		if ( StringHelper.isNotEmpty( manyToOneSource.getExplicitForeignKeyName() ) ) {
 			manyToOneBinding.setForeignKeyName( manyToOneSource.getExplicitForeignKeyName() );
 		}
 
 		final ManyToOneColumnBinder columnBinder = new ManyToOneColumnBinder(
 				sourceDocument,
 				manyToOneSource,
 				manyToOneBinding,
 				referencedEntityName
 		);
 		final boolean canBindColumnsImmediately = columnBinder.canProcessImmediately();
 		if ( canBindColumnsImmediately ) {
 			columnBinder.doSecondPass( null );
 		}
 		else {
 			sourceDocument.getMetadataCollector().addSecondPass( columnBinder );
 		}
 
 		if ( !manyToOneSource.isIgnoreNotFound() ) {
 			// we skip creating the FK here since this setting tells us there
 			// cannot be a suitable/proper FK
 			final ManyToOneFkSecondPass fkSecondPass = new ManyToOneFkSecondPass(
 					sourceDocument,
 					manyToOneSource,
 					manyToOneBinding,
 					referencedEntityName
 			);
 
 			if ( canBindColumnsImmediately && fkSecondPass.canProcessImmediately() ) {
 				fkSecondPass.doSecondPass( null );
 			}
 			else {
 				sourceDocument.getMetadataCollector().addSecondPass( fkSecondPass );
 			}
 		}
 
 		manyToOneBinding.setCascadeDeleteEnabled( manyToOneSource.isCascadeDeleteEnabled() );
 	}
 
 	private Property createAnyAssociationAttribute(
 			MappingDocument sourceDocument,
 			SingularAttributeSourceAny anyMapping,
 			Any anyBinding,
 			String entityName) {
 		final String attributeName = anyMapping.getName();
 
 		bindAny( sourceDocument, anyMapping, anyBinding, anyMapping.getAttributeRole(), anyMapping.getAttributePath() );
 
 		prepareValueTypeViaReflection( sourceDocument, anyBinding, entityName, attributeName, anyMapping.getAttributeRole() );
 
 		anyBinding.createForeignKey();
 
 		Property prop = new Property();
 		prop.setValue( anyBinding );
 		bindProperty(
 				sourceDocument,
 				anyMapping,
 				prop
 		);
 
 		return prop;
 	}
 
 	private void bindAny(
 			MappingDocument sourceDocument,
 			final AnyMappingSource anyMapping,
 			Any anyBinding,
 			final AttributeRole attributeRole,
 			AttributePath attributePath) {
 		final TypeResolution keyTypeResolution = resolveType(
 				sourceDocument,
 				anyMapping.getKeySource().getTypeSource()
 		);
 		if ( keyTypeResolution != null ) {
 			anyBinding.setIdentifierType( keyTypeResolution.typeName );
 		}
 
 		final TypeResolution discriminatorTypeResolution = resolveType(
 				sourceDocument,
 				anyMapping.getDiscriminatorSource().getTypeSource()
 		);
 
 		if ( discriminatorTypeResolution != null ) {
 			anyBinding.setMetaType( discriminatorTypeResolution.typeName );
 			try {
 				final DiscriminatorType metaType = (DiscriminatorType) sourceDocument.getMetadataCollector()
 						.getTypeResolver()
 						.heuristicType( discriminatorTypeResolution.typeName );
 
 				final HashMap anyValueBindingMap = new HashMap();
 				for ( Map.Entry<String,String> discriminatorValueMappings : anyMapping.getDiscriminatorSource().getValueMappings().entrySet() ) {
 					try {
 						final Object discriminatorValue = metaType.stringToObject( discriminatorValueMappings.getKey() );
 						final String mappedEntityName = sourceDocument.qualifyClassName( discriminatorValueMappings.getValue() );
 
 						//noinspection unchecked
 						anyValueBindingMap.put( discriminatorValue, mappedEntityName );
 					}
 					catch (Exception e) {
 						throw new MappingException(
 								String.format(
 										Locale.ENGLISH,
 										"Unable to interpret <meta-value value=\"%s\" class=\"%s\"/> defined as part of <any/> attribute [%s]",
 										discriminatorValueMappings.getKey(),
 										discriminatorValueMappings.getValue(),
 										attributeRole.getFullPath()
 								),
 								e,
 								sourceDocument.getOrigin()
 						);
 					}
 
 				}
 				anyBinding.setMetaValues( anyValueBindingMap );
 			}
 			catch (ClassCastException e) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Specified meta-type [%s] for <any/> attribute [%s] did not implement DiscriminatorType",
 								discriminatorTypeResolution.typeName,
 								attributeRole.getFullPath()
 						),
 						e,
 						sourceDocument.getOrigin()
 				);
 			}
 		}
 
 		relationalObjectBinder.bindColumnOrFormula(
 				sourceDocument,
 				anyMapping.getDiscriminatorSource().getRelationalValueSource(),
 				anyBinding,
 				true,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						return implicitNamingStrategy.determineAnyDiscriminatorColumnName(
 								anyMapping.getDiscriminatorSource()
 						);
 					}
 				}
 		);
 
 		relationalObjectBinder.bindColumnsAndFormulas(
 				sourceDocument,
 				anyMapping.getKeySource().getRelationalValueSources(),
 				anyBinding,
 				true,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						return implicitNamingStrategy.determineAnyKeyColumnName(
 								anyMapping.getKeySource()
 						);
 					}
 				}
 		);
 	}
 
 	private void prepareValueTypeViaReflection(
 			MappingDocument sourceDocument,
 			Value value,
 			String containingClassName,
 			String propertyName,
 			AttributeRole attributeRole) {
 		if ( StringHelper.isEmpty( propertyName ) ) {
 			throw new MappingException(
 					String.format(
 							Locale.ENGLISH,
 							"Attribute mapping must define a name attribute: containingClassName=[%s], propertyName=[%s], role=[%s]",
 							containingClassName,
 							propertyName,
 							attributeRole.getFullPath()
 					),
 					sourceDocument.getOrigin()
 			);
 		}
 
 		try {
 			value.setTypeUsingReflection( containingClassName, propertyName );
 		}
 		catch (org.hibernate.MappingException ome) {
 			throw new MappingException(
 					String.format(
 							Locale.ENGLISH,
 							"Error calling Value#setTypeUsingReflection: containingClassName=[%s], propertyName=[%s], role=[%s]",
 							containingClassName,
 							propertyName,
 							attributeRole.getFullPath()
 					),
 					ome,
 					sourceDocument.getOrigin()
 			);
 		}
 	}
 
 	private void bindProperty(
 			MappingDocument mappingDocument,
 			AttributeSource propertySource,
 			Property property) {
 		property.setName( propertySource.getName() );
 		property.setNodeName( determineXmlNodeName( propertySource, null ) );
 
 		property.setPropertyAccessorName(
 				StringHelper.isNotEmpty( propertySource.getPropertyAccessorName() )
 						? propertySource.getPropertyAccessorName()
 						: mappingDocument.getMappingDefaults().getImplicitPropertyAccessorName()
 		);
 
 		if ( propertySource instanceof CascadeStyleSource ) {
 			final CascadeStyleSource cascadeStyleSource = (CascadeStyleSource) propertySource;
 
 			property.setCascade(
 					StringHelper.isNotEmpty( cascadeStyleSource.getCascadeStyleName() )
 							? cascadeStyleSource.getCascadeStyleName()
 							: mappingDocument.getMappingDefaults().getImplicitCascadeStyleName()
 			);
 		}
 
 		property.setOptimisticLocked( propertySource.isIncludedInOptimisticLocking() );
 
 		if ( propertySource.isSingular() ) {
 			final SingularAttributeSource singularAttributeSource = (SingularAttributeSource) propertySource;
 
 			property.setInsertable( singularAttributeSource.isInsertable() );
 			property.setUpdateable( singularAttributeSource.isUpdatable() );
 
 			// NOTE : Property#is refers to whether a property is lazy via bytecode enhancement (not proxies)
 			property.setLazy( singularAttributeSource.isBytecodeLazy() );
 
 			final GenerationTiming generationTiming = singularAttributeSource.getGenerationTiming();
 			if ( generationTiming == GenerationTiming.ALWAYS || generationTiming == GenerationTiming.INSERT ) {
 				// we had generation specified...
 				//   	HBM only supports "database generated values"
 				property.setValueGenerationStrategy( new GeneratedValueGeneration( generationTiming ) );
 
 				// generated properties can *never* be insertable...
 				if ( property.isInsertable() ) {
 					if ( singularAttributeSource.isInsertable() == null ) {
 						// insertable simply because that is the user did not specify
 						// anything; just override it
 						property.setInsertable( false );
 					}
 					else {
 						// the user specifically supplied insert="true",
 						// which constitutes an illegal combo
 						throw new MappingException(
 								String.format(
 										Locale.ENGLISH,
 										"Cannot specify both insert=\"true\" and generated=\"%s\" for property %s",
-										generationTiming.name().toLowerCase(),
+										generationTiming.name().toLowerCase(Locale.ROOT),
 										propertySource.getName()
 								),
 								mappingDocument.getOrigin()
 						);
 					}
 				}
 
 				// properties generated on update can never be updatable...
 				if ( property.isUpdateable() && generationTiming == GenerationTiming.ALWAYS ) {
 					if ( singularAttributeSource.isUpdatable() == null ) {
 						// updatable only because the user did not specify
 						// anything; just override it
 						property.setUpdateable( false );
 					}
 					else {
 						// the user specifically supplied update="true",
 						// which constitutes an illegal combo
 						throw new MappingException(
 								String.format(
 										Locale.ENGLISH,
 										"Cannot specify both update=\"true\" and generated=\"%s\" for property %s",
-										generationTiming.name().toLowerCase(),
+										generationTiming.name().toLowerCase(Locale.ROOT),
 										propertySource.getName()
 								),
 								mappingDocument.getOrigin()
 						);
 					}
 				}
 			}
 		}
 
 		property.setMetaAttributes( propertySource.getToolingHintContext().getMetaAttributeMap() );
 
 		if ( log.isDebugEnabled() ) {
 			final StringBuilder message = new StringBuilder()
 					.append( "Mapped property: " )
 					.append( propertySource.getName() )
 					.append( " -> [" );
 			final Iterator itr = property.getValue().getColumnIterator();
 			while ( itr.hasNext() ) {
 				message.append( ( (Selectable) itr.next() ).getText() );
 				if ( itr.hasNext() ) {
 					message.append( ", " );
 				}
 			}
 			message.append( "]" );
 			log.debug( message.toString() );
 		}
 	}
 
 	private String determineXmlNodeName(AttributeSource propertySource, String fallbackXmlNodeName) {
 		String nodeName = propertySource.getXmlNodeName();
 		if ( StringHelper.isNotEmpty( nodeName ) ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfDomEntityModeSupport();
 		}
 		else {
 			nodeName = propertySource.getName();
 		}
 		if ( nodeName == null ) {
 			nodeName = fallbackXmlNodeName;
 		}
 
 		return nodeName;
 	}
 
 	private void bindComponent(
 			MappingDocument sourceDocument,
 			EmbeddableSource embeddableSource,
 			Component component,
 			String containingClassName,
 			String propertyName,
 			String xmlNodeName,
 			boolean isVirtual) {
 		final String fullRole = embeddableSource.getAttributeRoleBase().getFullPath();
 		final String explicitComponentClassName = extractExplicitComponentClassName( embeddableSource );
 
 		bindComponent(
 				sourceDocument,
 				fullRole,
 				embeddableSource,
 				component,
 				explicitComponentClassName,
 				containingClassName,
 				propertyName,
 				isVirtual,
 				embeddableSource.isDynamic(),
 				xmlNodeName
 		);
 	}
 
 	private String extractExplicitComponentClassName(EmbeddableSource embeddableSource) {
 		if ( embeddableSource.getTypeDescriptor() == null ) {
 			return null;
 		}
 
 		return embeddableSource.getTypeDescriptor().getName();
 	}
 
 	private void bindComponent(
 			MappingDocument sourceDocument,
 			String role,
 			EmbeddableSource embeddableSource,
 			Component componentBinding,
 			String explicitComponentClassName,
 			String containingClassName,
 			String propertyName,
 			boolean isVirtual,
 			boolean isDynamic,
 			String xmlNodeName) {
 
 		componentBinding.setMetaAttributes( embeddableSource.getToolingHintContext().getMetaAttributeMap() );
 
 		componentBinding.setRoleName( role );
 
 		componentBinding.setEmbedded( isVirtual );
 
 		// todo : better define the conditions in this if/else
 		if ( isDynamic ) {
 			// dynamic is represented as a Map
 			log.debugf( "Binding dynamic-component [%s]", role );
 			componentBinding.setDynamic( true );
 		}
 		else if ( isVirtual ) {
 			// virtual (what used to be called embedded) is just a conceptual composition...
 			// <properties/> for example
 			if ( componentBinding.getOwner().hasPojoRepresentation() ) {
 				log.debugf( "Binding virtual component [%s] to owner class [%s]", role, componentBinding.getOwner().getClassName() );
 				componentBinding.setComponentClassName( componentBinding.getOwner().getClassName() );
 			}
 			else {
 				log.debugf( "Binding virtual component [%s] as dynamic", role );
 				componentBinding.setDynamic( true );
 			}
 		}
 		else {
 			log.debugf( "Binding component [%s]", role );
 			if ( StringHelper.isNotEmpty( explicitComponentClassName ) ) {
 				log.debugf( "Binding component [%s] to explicitly specified class", role, explicitComponentClassName );
 				componentBinding.setComponentClassName( explicitComponentClassName );
 			}
 			else if ( componentBinding.getOwner().hasPojoRepresentation() ) {
 				log.tracef( "Attempting to determine component class by reflection %s", role );
 				final Class reflectedComponentClass;
 				if ( StringHelper.isNotEmpty( containingClassName ) && StringHelper.isNotEmpty( propertyName ) ) {
 					reflectedComponentClass = Helper.reflectedPropertyClass(
 							sourceDocument,
 							containingClassName,
 							propertyName
 					);
 				}
 				else {
 					reflectedComponentClass = null;
 				}
 
 				if ( reflectedComponentClass == null ) {
 					log.debugf(
 							"Unable to determine component class name via reflection, and explicit " +
 									"class name not given; role=[%s]",
 							role
 					);
 				}
 				else {
 					componentBinding.setComponentClassName( reflectedComponentClass.getName() );
 				}
 			}
 			else {
 				componentBinding.setDynamic( true );
 			}
 		}
 
 		String nodeName = xmlNodeName;
 		if ( StringHelper.isNotEmpty( nodeName ) ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfDomEntityModeSupport();
 		}
 		else {
 			nodeName = propertyName;
 		}
 		if ( nodeName == null ) {
 			nodeName = componentBinding.getOwner().getNodeName();
 		}
 		componentBinding.setNodeName( nodeName );
 
 		// todo : anything else to pass along?
 		bindAllCompositeAttributes(
 				sourceDocument,
 				embeddableSource,
 				componentBinding
 		);
 
 		if ( embeddableSource.getParentReferenceAttributeName() != null ) {
 			componentBinding.setParentProperty( embeddableSource.getParentReferenceAttributeName() );
 		}
 
 		if ( embeddableSource.isUnique() ) {
 			final ArrayList<Column> cols = new ArrayList<Column>();
 			final Iterator itr = componentBinding.getColumnIterator();
 			while ( itr.hasNext() ) {
 				final Object selectable = itr.next();
 				// skip formulas.  ugh, yes terrible naming of these methods :(
 				if ( !Column.class.isInstance( selectable ) ) {
 					continue;
 				}
 				cols.add( (Column) selectable );
 			}
 			// todo : we may need to delay this
 			componentBinding.getOwner().getTable().createUniqueKey( cols );
 		}
 
 		if ( embeddableSource.getTuplizerClassMap() != null ) {
 			if ( embeddableSource.getTuplizerClassMap().size() > 1 ) {
 				DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfMultipleEntityModeSupport();
 			}
 			for ( Map.Entry<EntityMode,String> tuplizerEntry : embeddableSource.getTuplizerClassMap().entrySet() ) {
 				componentBinding.addTuplizer(
 						tuplizerEntry.getKey(),
 						tuplizerEntry.getValue()
 				);
 			}
 		}
 	}
 
 	private void prepareComponentType(
 			MappingDocument sourceDocument,
 			String fullRole,
 			Component componentBinding,
 			String explicitComponentClassName,
 			String containingClassName,
 			String propertyName,
 			boolean isVirtual,
 			boolean isDynamic) {
 	}
 
 	private void bindAllCompositeAttributes(
 			MappingDocument sourceDocument,
 			EmbeddableSource embeddableSource,
 			Component component) {
 
 		for ( AttributeSource attributeSource : embeddableSource.attributeSources() ) {
 			Property attribute = null;
 
 			if ( SingularAttributeSourceBasic.class.isInstance( attributeSource ) ) {
 				attribute = createBasicAttribute(
 						sourceDocument,
 						(SingularAttributeSourceBasic) attributeSource,
 						new SimpleValue( sourceDocument.getMetadataCollector(), component.getTable() ),
 						component.getComponentClassName()
 				);
 			}
 			else if ( SingularAttributeSourceEmbedded.class.isInstance( attributeSource ) ) {
 				attribute = createEmbeddedAttribute(
 						sourceDocument,
 						(SingularAttributeSourceEmbedded) attributeSource,
 						new Component( sourceDocument.getMetadataCollector(), component ),
 						component.getComponentClassName()
 				);
 			}
 			else if ( SingularAttributeSourceManyToOne.class.isInstance( attributeSource ) ) {
 				attribute = createManyToOneAttribute(
 						sourceDocument,
 						(SingularAttributeSourceManyToOne) attributeSource,
 						new ManyToOne( sourceDocument.getMetadataCollector(), component.getTable() ),
 						component.getComponentClassName()
 				);
 			}
 			else if ( SingularAttributeSourceOneToOne.class.isInstance( attributeSource ) ) {
 				attribute = createOneToOneAttribute(
 						sourceDocument,
 						(SingularAttributeSourceOneToOne) attributeSource,
 						new OneToOne( sourceDocument.getMetadataCollector(), component.getTable(), component.getOwner() ),
 						component.getComponentClassName()
 				);
 			}
 			else if ( SingularAttributeSourceAny.class.isInstance( attributeSource ) ) {
 				attribute = createAnyAssociationAttribute(
 						sourceDocument,
 						(SingularAttributeSourceAny) attributeSource,
 						new Any( sourceDocument.getMetadataCollector(), component.getTable() ),
 						component.getComponentClassName()
 				);
 			}
 			else if ( PluralAttributeSource.class.isInstance( attributeSource ) ) {
 				attribute = createPluralAttribute(
 						sourceDocument,
 						(PluralAttributeSource) attributeSource,
 						component.getOwner()
 				);
 			}
 			else {
 				throw new AssertionFailure(
 						String.format(
 								Locale.ENGLISH,
 								"Unexpected AttributeSource sub-type [%s] as part of composite [%s]",
 								attributeSource.getClass().getName(),
 								attributeSource.getAttributeRole().getFullPath()
 						)
 
 				);
 			}
 
 			component.addProperty( attribute );
 		}
 	}
 
 	private static void bindSimpleValueType(
 			MappingDocument mappingDocument,
 			HibernateTypeSource typeSource,
 			SimpleValue simpleValue) {
 		if ( mappingDocument.getBuildingOptions().useNationalizedCharacterData() ) {
 			simpleValue.makeNationalized();
 		}
 
 		final TypeResolution typeResolution = resolveType( mappingDocument, typeSource );
 		if ( typeResolution == null ) {
 			// no explicit type info was found
 			return;
 		}
 
 		if ( CollectionHelper.isNotEmpty( typeResolution.parameters ) ) {
 			simpleValue.setTypeParameters( typeResolution.parameters );
 		}
 
 		if ( typeResolution.typeName != null ) {
 			simpleValue.setTypeName( typeResolution.typeName );
 		}
 	}
 
 	private static class TypeResolution {
 		private final String typeName;
 		private final Properties parameters;
 
 		public TypeResolution(String typeName, Properties parameters) {
 			this.typeName = typeName;
 			this.parameters = parameters;
 		}
 	}
 
 	private static TypeResolution resolveType(
 			MappingDocument sourceDocument,
 			HibernateTypeSource typeSource) {
 		if ( StringHelper.isEmpty( typeSource.getName() ) ) {
 			return null;
 		}
 
 		String typeName = typeSource.getName();
 		Properties typeParameters = new Properties();;
 
 		final TypeDefinition typeDefinition = sourceDocument.getMetadataCollector().getTypeDefinition( typeName );
 		if ( typeDefinition != null ) {
 			// the explicit name referred to a type-def
 			typeName = typeDefinition.getTypeImplementorClass().getName();
 			if ( typeDefinition.getParameters() != null ) {
 				typeParameters.putAll( typeDefinition.getParameters() );
 			}
 		}
 //		else {
 //			final BasicType basicType = sourceDocument.getMetadataCollector().getTypeResolver().basic( typeName );
 //			if ( basicType == null ) {
 //				throw new MappingException(
 //						String.format(
 //								Locale.ENGLISH,
 //								"Mapping named an explicit type [%s] which could not be resolved",
 //								typeName
 //						),
 //						sourceDocument.getOrigin()
 //				);
 //			}
 //		}
 
 		// parameters on the property mapping should override parameters in the type-def
 		if ( typeSource.getParameters() != null ) {
 			typeParameters.putAll( typeSource.getParameters() );
 		}
 
 		return new TypeResolution( typeName, typeParameters );
 	}
 
 	private Table bindEntityTableSpecification(
 			final MappingDocument mappingDocument,
 			TableSpecificationSource tableSpecSource,
 			Table denormalizedSuperTable,
 			final EntitySource entitySource,
 			PersistentClass entityDescriptor) {
 		final Schema schema = database.locateSchema(
 				determineCatalogName( tableSpecSource ),
 				determineSchemaName( tableSpecSource )
 		);
 
 		final boolean isTable = TableSource.class.isInstance( tableSpecSource );
 		final boolean isAbstract = entityDescriptor.isAbstract() == null ? false : entityDescriptor.isAbstract();
 		final String subselect;
 		final Identifier logicalTableName;
 		final Table table;
 		if ( isTable ) {
 			final TableSource tableSource = (TableSource) tableSpecSource;
 
 			if ( StringHelper.isNotEmpty( tableSource.getExplicitTableName() ) ) {
 				logicalTableName = database.toIdentifier( tableSource.getExplicitTableName() );
 			}
 			else {
 				final ImplicitEntityNameSource implicitNamingSource = new ImplicitEntityNameSource() {
 					@Override
 					public EntityNaming getEntityNaming() {
 						return entitySource.getEntityNamingSource();
 					}
 
 					@Override
 					public MetadataBuildingContext getBuildingContext() {
 						return mappingDocument;
 					}
 				};
 				logicalTableName = mappingDocument.getBuildingOptions()
 						.getImplicitNamingStrategy()
 						.determinePrimaryTableName( implicitNamingSource );
 			}
 
 			if ( denormalizedSuperTable == null ) {
 				table = schema.createTable( logicalTableName, isAbstract );
 			}
 			else {
 				table = schema.createDenormalizedTable(
 						logicalTableName,
 						isAbstract,
 						denormalizedSuperTable
 				);
 			}
 		}
 		else {
 			final InLineViewSource inLineViewSource = (InLineViewSource) tableSpecSource;
 			subselect = inLineViewSource.getSelectStatement();
 			logicalTableName = database.toIdentifier( inLineViewSource.getLogicalName() );
 			if ( denormalizedSuperTable == null ) {
 				table = new Table( schema, subselect, isAbstract );
 			}
 			else {
 				table = new DenormalizedTable( schema, subselect, isAbstract, denormalizedSuperTable );
 			}
 			table.setName( logicalTableName.render() );
 		}
 
 		EntityTableXref superEntityTableXref = null;
 
 		if ( entitySource.getSuperType() != null ) {
 			//noinspection SuspiciousMethodCalls
 			final String superEntityName = ( (EntitySource) entitySource.getSuperType() ).getEntityNamingSource()
 					.getEntityName();
 			superEntityTableXref = mappingDocument.getMetadataCollector().getEntityTableXref( superEntityName );
 			if ( superEntityTableXref == null ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Unable to locate entity table xref for entity [%s] super-type [%s]",
 								entityDescriptor.getEntityName(),
 								superEntityName
 						),
 						mappingDocument.getOrigin()
 				);
 			}
 		}
 
 		mappingDocument.getMetadataCollector().addEntityTableXref(
 				entitySource.getEntityNamingSource().getEntityName(),
 				logicalTableName,
 				table,
 				superEntityTableXref
 		);
 
 		if ( isTable ) {
 			final TableSource tableSource = (TableSource) tableSpecSource;
 			table.setRowId( tableSource.getRowId() );
 			table.setComment( tableSource.getComment() );
 			if ( StringHelper.isNotEmpty( tableSource.getCheckConstraint() ) ) {
 				table.addCheckConstraint( tableSource.getCheckConstraint() );
 			}
 		}
 
 		mappingDocument.getMetadataCollector().addTableNameBinding( logicalTableName, table );
 
 		return table;
 	}
 
 	private Identifier determineCatalogName(TableSpecificationSource tableSpecSource) {
 		if ( StringHelper.isNotEmpty( tableSpecSource.getExplicitCatalogName() ) ) {
 			return database.toIdentifier( tableSpecSource.getExplicitCatalogName() );
 		}
 		else {
 			return database.getDefaultSchema().getName().getCatalog();
 		}
 	}
 
 	private Identifier determineSchemaName(TableSpecificationSource tableSpecSource) {
 		if ( StringHelper.isNotEmpty( tableSpecSource.getExplicitSchemaName() ) ) {
 			return database.toIdentifier( tableSpecSource.getExplicitSchemaName() );
 		}
 		else {
 			return database.getDefaultSchema().getName().getSchema();
 		}
 	}
 
 	private static void bindCustomSql(
 			MappingDocument sourceDocument,
 			EntitySource entitySource,
 			PersistentClass entityDescriptor) {
 		if ( entitySource.getCustomSqlInsert() != null ) {
 			entityDescriptor.setCustomSQLInsert(
 					entitySource.getCustomSqlInsert().getSql(),
 					entitySource.getCustomSqlInsert().isCallable(),
 					entitySource.getCustomSqlInsert().getCheckStyle()
 			);
 		}
 
 		if ( entitySource.getCustomSqlUpdate() != null ) {
 			entityDescriptor.setCustomSQLUpdate(
 					entitySource.getCustomSqlUpdate().getSql(),
 					entitySource.getCustomSqlUpdate().isCallable(),
 					entitySource.getCustomSqlUpdate().getCheckStyle()
 			);
 		}
 
 		if ( entitySource.getCustomSqlDelete() != null ) {
 			entityDescriptor.setCustomSQLDelete(
 					entitySource.getCustomSqlDelete().getSql(),
 					entitySource.getCustomSqlDelete().isCallable(),
 					entitySource.getCustomSqlDelete().getCheckStyle()
 			);
 		}
 
 		entityDescriptor.setLoaderName( entitySource.getCustomLoaderName() );
 	}
 
 	private static void bindCustomSql(
 			MappingDocument sourceDocument,
 			SecondaryTableSource secondaryTableSource,
 			Join secondaryTable) {
 		if ( secondaryTableSource.getCustomSqlInsert() != null ) {
 			secondaryTable.setCustomSQLInsert(
 					secondaryTableSource.getCustomSqlInsert().getSql(),
 					secondaryTableSource.getCustomSqlInsert().isCallable(),
 					secondaryTableSource.getCustomSqlInsert().getCheckStyle()
 			);
 		}
 
 		if ( secondaryTableSource.getCustomSqlUpdate() != null ) {
 			secondaryTable.setCustomSQLUpdate(
 					secondaryTableSource.getCustomSqlUpdate().getSql(),
 					secondaryTableSource.getCustomSqlUpdate().isCallable(),
 					secondaryTableSource.getCustomSqlUpdate().getCheckStyle()
 			);
 		}
 
 		if ( secondaryTableSource.getCustomSqlDelete() != null ) {
 			secondaryTable.setCustomSQLDelete(
 					secondaryTableSource.getCustomSqlDelete().getSql(),
 					secondaryTableSource.getCustomSqlDelete().isCallable(),
 					secondaryTableSource.getCustomSqlDelete().getCheckStyle()
 			);
 		}
 	}
 
 	private void registerSecondPass(SecondPass secondPass, MetadataBuildingContext context) {
 		context.getMetadataCollector().addSecondPass( secondPass );
 	}
 
 
 
 	public static final class DelayedPropertyReferenceHandlerImpl implements InFlightMetadataCollector.DelayedPropertyReferenceHandler {
 		public final String referencedEntityName;
 		public final String referencedPropertyName;
 		public final boolean isUnique;
 		private final String sourceElementSynopsis;
 		public final Origin propertyRefOrigin;
 
 		public DelayedPropertyReferenceHandlerImpl(
 				String referencedEntityName,
 				String referencedPropertyName,
 				boolean isUnique,
 				String sourceElementSynopsis,
 				Origin propertyRefOrigin) {
 			this.referencedEntityName = referencedEntityName;
 			this.referencedPropertyName = referencedPropertyName;
 			this.isUnique = isUnique;
 			this.sourceElementSynopsis = sourceElementSynopsis;
 			this.propertyRefOrigin = propertyRefOrigin;
 		}
 
 		public void process(InFlightMetadataCollector metadataCollector) {
 			log.tracef(
 					"Performing delayed property-ref handling [%s, %s, %s]",
 					referencedEntityName,
 					referencedPropertyName,
 					sourceElementSynopsis
 			);
 
 			PersistentClass entityBinding = metadataCollector.getEntityBinding( referencedEntityName );
 			if ( entityBinding == null ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"property-ref [%s] referenced an unmapped entity [%s]",
 								sourceElementSynopsis,
 								referencedEntityName
 						),
 						propertyRefOrigin
 				);
 			}
 
 			Property propertyBinding = entityBinding.getReferencedProperty( referencedPropertyName );
 			if ( propertyBinding == null ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"property-ref [%s] referenced an unknown entity property [%s#%s]",
 								sourceElementSynopsis,
 								referencedEntityName,
 								referencedPropertyName
 						),
 						propertyRefOrigin
 				);
 			}
 
 			if ( isUnique ) {
 				( (SimpleValue) propertyBinding.getValue() ).setAlternateUniqueKey( true );
 			}
 		}
 	}
 
 
 	private abstract class AbstractPluralAttributeSecondPass implements SecondPass {
 		private final MappingDocument mappingDocument;
 		private final PluralAttributeSource pluralAttributeSource;
 		private final Collection collectionBinding;
 
 		protected AbstractPluralAttributeSecondPass(
 				MappingDocument mappingDocument,
 				PluralAttributeSource pluralAttributeSource,
 				Collection collectionBinding) {
 			this.mappingDocument = mappingDocument;
 			this.pluralAttributeSource = pluralAttributeSource;
 			this.collectionBinding = collectionBinding;
 		}
 
 		public MappingDocument getMappingDocument() {
 			return mappingDocument;
 		}
 
 		public PluralAttributeSource getPluralAttributeSource() {
 			return pluralAttributeSource;
 		}
 
 		public Collection getCollectionBinding() {
 			return collectionBinding;
 		}
 
 		@Override
 		public void doSecondPass(Map persistentClasses) throws org.hibernate.MappingException {
 			bindCollectionTable();
 
 			bindCollectionKey();
 			bindCollectionIdentifier();
 			bindCollectionIndex();
 			bindCollectionElement();
 
 			createBackReferences();
 
 			collectionBinding.createAllKeys();
 
 			if ( debugEnabled ) {
 				log.debugf( "Mapped collection : " + getPluralAttributeSource().getAttributeRole().getFullPath() );
 				log.debugf( "   + table -> " + getCollectionBinding().getTable().getName() );
 				log.debugf( "   + key -> " + columns( getCollectionBinding().getKey() ) );
 				if ( getCollectionBinding().isIndexed() ) {
 					log.debugf( "   + index -> " + columns( ( (IndexedCollection) getCollectionBinding() ).getIndex() ) );
 				}
 				if ( getCollectionBinding().isOneToMany() ) {
 					log.debugf( "   + one-to-many -> " + ( (OneToMany) getCollectionBinding().getElement() ).getReferencedEntityName() );
 				}
 				else {
 					log.debugf( "   + element -> " + columns( getCollectionBinding().getElement() ) );
 				}
 			}
 		}
 
 		private String columns(Value value) {
 			final StringBuilder builder = new StringBuilder();
 			final Iterator<Selectable> selectableItr = value.getColumnIterator();
 			while ( selectableItr.hasNext() ) {
 				builder.append( selectableItr.next().getText() );
 				if ( selectableItr.hasNext() ) {
 					builder.append( ", " );
 				}
 			}
 			return builder.toString();
 		}
 
 		private void bindCollectionTable() {
 			// 2 main branches here:
 			//		1) one-to-many
 			//		2) everything else
 
 			if ( pluralAttributeSource.getElementSource() instanceof PluralAttributeElementSourceOneToMany ) {
 				// For one-to-many mappings, the "collection table" is the same as the table
 				// of the associated entity (the entity making up the collection elements).
 				// So lookup the associated entity and use its table here
 
 				final PluralAttributeElementSourceOneToMany elementSource =
 						(PluralAttributeElementSourceOneToMany) pluralAttributeSource.getElementSource();
 
 				final PersistentClass persistentClass = mappingDocument.getMetadataCollector()
 						.getEntityBinding( elementSource.getReferencedEntityName() );
 				if ( persistentClass == null ) {
 					throw new MappingException(
 							String.format(
 									Locale.ENGLISH,
 									"Association [%s] references an unmapped entity [%s]",
 									pluralAttributeSource.getAttributeRole().getFullPath(),
 									pluralAttributeSource.getAttributeRole().getFullPath()
 							),
 							mappingDocument.getOrigin()
 					);
 				}
 
 				// even though <key/> defines a property-ref I do not see where legacy
 				// code ever attempts to use that to "adjust" the table in its use to
 				// the actual table the referenced property belongs to.
 				// todo : for correctness, though, we should look into that ^^
 				collectionBinding.setCollectionTable( persistentClass.getTable() );
 			}
 			else {
 				final TableSpecificationSource tableSpecSource = pluralAttributeSource.getCollectionTableSpecificationSource();
 				final Identifier logicalCatalogName = determineCatalogName( tableSpecSource );
 				final Identifier logicalSchemaName = determineSchemaName( tableSpecSource );
 				final Schema schema = database.locateSchema( logicalCatalogName, logicalSchemaName );
 
 				final Table collectionTable;
 
 				if ( tableSpecSource instanceof TableSource ) {
 					final TableSource tableSource = (TableSource) tableSpecSource;
 					Identifier logicalName;
 
 					if ( StringHelper.isNotEmpty( tableSource.getExplicitTableName() ) ) {
 						logicalName = Identifier.toIdentifier(
 								tableSource.getExplicitTableName(),
 								mappingDocument.getMappingDefaults().shouldImplicitlyQuoteIdentifiers()
 						);
 					}
 					else {
 						final EntityNaming ownerEntityNaming = new EntityNamingSourceImpl(
 								collectionBinding.getOwner().getEntityName(),
 								collectionBinding.getOwner().getClassName(),
 								collectionBinding.getOwner().getJpaEntityName()
 						);
 						final ImplicitCollectionTableNameSource implicitNamingSource = new ImplicitCollectionTableNameSource() {
 							@Override
 							public Identifier getOwningPhysicalTableName() {
 								return collectionBinding.getOwner().getTable().getNameIdentifier();
 							}
 
 							@Override
 							public EntityNaming getOwningEntityNaming() {
 								return ownerEntityNaming;
 							}
 
 							@Override
 							public AttributePath getOwningAttributePath() {
 								return pluralAttributeSource.getAttributePath();
 							}
 
 							@Override
 							public MetadataBuildingContext getBuildingContext() {
 								return mappingDocument;
 							}
 						};
 						logicalName = mappingDocument.getBuildingOptions()
 								.getImplicitNamingStrategy()
 								.determineCollectionTableName( implicitNamingSource );
 					}
 
 					collectionTable = schema.createTable( logicalName, false );
 				}
 				else {
 					collectionTable = new Table(
 							schema,
 							( (InLineViewSource) tableSpecSource ).getSelectStatement(),
 							false
 					);
 				}
 
 				collectionBinding.setCollectionTable( collectionTable );
 			}
 
 
 			if ( debugEnabled ) {
 				log.debugf( "Mapping collection: %s -> %s", collectionBinding.getRole(), collectionBinding.getCollectionTable().getName() );
 			}
 
 			if ( pluralAttributeSource.getCollectionTableComment() != null ) {
 				collectionBinding.getCollectionTable().setComment( pluralAttributeSource.getCollectionTableComment() );
 			}
 			if ( pluralAttributeSource.getCollectionTableCheck() != null ) {
 				collectionBinding.getCollectionTable().addCheckConstraint( pluralAttributeSource.getCollectionTableCheck() );
 			}
 		}
 
 		protected void createBackReferences() {
 			if ( collectionBinding.isOneToMany()
 					&& !collectionBinding.isInverse()
 					&& !collectionBinding.getKey().isNullable() ) {
 				// for non-inverse one-to-many, with a not-null fk, add a backref!
 				String entityName = ( (OneToMany) collectionBinding.getElement() ).getReferencedEntityName();
 				PersistentClass referenced = mappingDocument.getMetadataCollector().getEntityBinding( entityName );
 				Backref prop = new Backref();
 				prop.setName( '_' + collectionBinding.getOwnerEntityName() + "." + pluralAttributeSource.getName() + "Backref" );
 				prop.setUpdateable( false );
 				prop.setSelectable( false );
 				prop.setCollectionRole( collectionBinding.getRole() );
 				prop.setEntityName( collectionBinding.getOwner().getEntityName() );
 				prop.setValue( collectionBinding.getKey() );
 				referenced.addProperty( prop );
 
 				log.debugf(
 						"Added virtual backref property [%s] : %s",
 						prop.getName(),
 						pluralAttributeSource.getAttributeRole().getFullPath()
 				);
 			}
 		}
 
 		protected void bindCollectionKey() {
 			final String propRef = getPluralAttributeSource().getKeySource().getReferencedPropertyName();
 			getCollectionBinding().setReferencedPropertyName( propRef );
 
 			final KeyValue keyVal;
 			if ( propRef == null ) {
 				keyVal = getCollectionBinding().getOwner().getIdentifier();
 			}
 			else {
 				keyVal = (KeyValue) getCollectionBinding().getOwner().getRecursiveProperty( propRef ).getValue();
 			}
 			final DependantValue key = new DependantValue(
 					mappingDocument.getMetadataCollector(),
 					getCollectionBinding().getCollectionTable(),
 					keyVal
 			);
 			key.setCascadeDeleteEnabled( getPluralAttributeSource().getKeySource().isCascadeDeleteEnabled() );
 
 			final ImplicitJoinColumnNameSource.Nature implicitNamingNature;
 			if ( getPluralAttributeSource().getElementSource() instanceof PluralAttributeElementSourceManyToMany
 					|| getPluralAttributeSource().getElementSource() instanceof PluralAttributeElementSourceOneToMany ) {
 				implicitNamingNature = ImplicitJoinColumnNameSource.Nature.ENTITY_COLLECTION;
 			}
 			else {
 				implicitNamingNature = ImplicitJoinColumnNameSource.Nature.ELEMENT_COLLECTION;
 			}
 
 			relationalObjectBinder.bindColumnsAndFormulas(
 					mappingDocument,
 					getPluralAttributeSource().getKeySource().getRelationalValueSources(),
 					key,
 					getPluralAttributeSource().getKeySource().areValuesNullableByDefault(),
 					new RelationalObjectBinder.ColumnNamingDelegate() {
 						@Override
 						public Identifier determineImplicitName(final LocalMetadataBuildingContext context) {
 							// another case where HbmBinder was not adjusted to make use of NamingStrategy#foreignKeyColumnName
 							// when that was added in developing annotation binding :(
 //							return implicitNamingStrategy.determineJoinColumnName(
 //									new ImplicitJoinColumnNameSource() {
 //										private EntityNamingSourceImpl entityNamingSource;
 //										private Identifier referencedColumnName;
 //
 //										@Override
 //										public Nature getNature() {
 //											return implicitNamingNature;
 //										}
 //
 //										@Override
 //										public EntityNaming getEntityNaming() {
 //											if ( entityNamingSource == null ) {
 //												entityNamingSource = new EntityNamingSourceImpl(
 //														getCollectionBinding().getOwner().getEntityName(),
 //														getCollectionBinding().getOwner().getClassName(),
 //														getCollectionBinding().getOwner().getJpaEntityName()
 //												);
 //											}
 //											return entityNamingSource;
 //										}
 //
 //										@Override
 //										public AttributePath getAttributePath() {
 //											return getPluralAttributeSource().getAttributePath();
 //										}
 //
 //										@Override
 //										public Identifier getReferencedTableName() {
 //											return getCollectionBinding().getCollectionTable().getNameIdentifier();
 //										}
 //
 //										@Override
 //										public Identifier getReferencedColumnName() {
 //											if ( referencedColumnName == null ) {
 //												final Iterator<Selectable> selectableItr = keyVal.getColumnIterator();
 //												// assume there is just one, and that its a column...
 //												final Column column = (Column) selectableItr.next();
 //												referencedColumnName = getMappingDocument().getMetadataCollector()
 //														.getDatabase()
 //														.toIdentifier( column.getQuotedName() );
 //											}
 //											return referencedColumnName;
 //										}
 //
 //										@Override
 //										public MetadataBuildingContext getBuildingContext() {
 //											return context;
 //										}
 //									}
 //							);
 							return context.getMetadataCollector().getDatabase().toIdentifier( Collection.DEFAULT_KEY_COLUMN_NAME );
 						}
 					}
 			);
 
 			key.createForeignKey();
 			getCollectionBinding().setKey( key );
 
 			key.setNullable( getPluralAttributeSource().getKeySource().areValuesNullableByDefault() );
 			key.setUpdateable( getPluralAttributeSource().getKeySource().areValuesIncludedInUpdateByDefault() );
 		}
 
 		protected void bindCollectionIdentifier() {
 			final CollectionIdSource idSource = getPluralAttributeSource().getCollectionIdSource();
 			if ( idSource != null ) {
 				final IdentifierCollection idBagBinding = (IdentifierCollection) getCollectionBinding();
 				final SimpleValue idBinding = new SimpleValue(
 						mappingDocument.getMetadataCollector(),
 						idBagBinding.getCollectionTable()
 				);
 
 				bindSimpleValueType(
 						mappingDocument,
 						idSource.getTypeInformation(),
 						idBinding
 				);
 
 				relationalObjectBinder.bindColumn(
 						mappingDocument,
 						idSource.getColumnSource(),
 						idBinding,
 						false,
 						new RelationalObjectBinder.ColumnNamingDelegate() {
 							@Override
 							public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 								return database.toIdentifier( IdentifierCollection.DEFAULT_IDENTIFIER_COLUMN_NAME );
 							}
 						}
 				);
 
 				idBagBinding.setIdentifier( idBinding );
 
 				makeIdentifier(
 						mappingDocument,
 						new IdentifierGeneratorDefinition( idSource.getGeneratorName() ),
 						null,
 						idBinding
 				);
 			}
 		}
 
 		protected void bindCollectionIndex() {
 		}
 
 		protected void bindCollectionElement() {
 			if ( getPluralAttributeSource().getElementSource() instanceof PluralAttributeElementSourceBasic ) {
 				final PluralAttributeElementSourceBasic elementSource =
 						(PluralAttributeElementSourceBasic) getPluralAttributeSource().getElementSource();
 				final SimpleValue elementBinding = new SimpleValue(
 						getMappingDocument().getMetadataCollector(),
 						getCollectionBinding().getCollectionTable()
 				);
 
 				bindSimpleValueType(
 						getMappingDocument(),
 						elementSource.getExplicitHibernateTypeSource(),
 						elementBinding
 				);
 
 				relationalObjectBinder.bindColumnsAndFormulas(
 						mappingDocument,
 						elementSource.getRelationalValueSources(),
 						elementBinding,
 						elementSource.areValuesNullableByDefault(),
 						new RelationalObjectBinder.ColumnNamingDelegate() {
 							@Override
 							public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 //								return implicitNamingStrategy.determineBasicColumnName(
 //										elementSource
 //								);
 								return context.getMetadataCollector().getDatabase().toIdentifier( Collection.DEFAULT_ELEMENT_COLUMN_NAME );
 							}
 						}
 				);
 
 				getCollectionBinding().setElement( elementBinding );
 			}
 			else if ( getPluralAttributeSource().getElementSource() instanceof PluralAttributeElementSourceEmbedded ) {
 				final PluralAttributeElementSourceEmbedded elementSource =
 						(PluralAttributeElementSourceEmbedded) getPluralAttributeSource().getElementSource();
 				final Component elementBinding = new Component(
 						getMappingDocument().getMetadataCollector(),
 						getCollectionBinding()
 				);
 
 				final EmbeddableSource embeddableSource = elementSource.getEmbeddableSource();
 				bindComponent(
 						mappingDocument,
 						embeddableSource,
 						elementBinding,
 						null,
 						embeddableSource.getAttributePathBase().getProperty(),
 						getPluralAttributeSource().getXmlNodeName(),
 						false
 				);
 
 				getCollectionBinding().setElement( elementBinding );
 			}
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/XmlElementMetadata.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/XmlElementMetadata.java
index a3ad6350cf..57d1856f7f 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/XmlElementMetadata.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/XmlElementMetadata.java
@@ -1,198 +1,200 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.internal.hbm;
 
+import java.util.Locale;
+
 /**
  * Provides meta-information about XML elements.
  *
  * @author Steve Ebersole
  */
 public enum XmlElementMetadata {
 	/**
 	 * Describes the {@code <id/>} element
 	 */
 	ID( true, true ),
 	/**
 	 * Describes the {@code <composite-id/>} element
 	 */
 	COMPOSITE_ID( false, true ),
 	/**
 	 * Describes the {@code <discriminator/>} element
 	 */
 	DISCRIMINATOR( true, false ),
 	/**
 	 * Describes the {@code <multi-tenancy/>} element
 	 */
 	MULTI_TENANCY( true, false ),
 	/**
 	 * Describes the {@code <version/>} element
 	 */
 	VERSION( true, true ),
 	/**
 	 * Describes the {@code <timestamp/>} element
 	 */
 	TIMESTAMP( true, true ),
 	/**
 	 * Describes the {@code <natural-id/>} element
 	 */
 	NATURAL_ID( false, false ),
 	/**
 	 * Describes the {@code <properties/>} element
 	 */
 	PROPERTIES( false, true ),
 	/**
 	 * Describes the {@code <property/>} element
 	 */
 	PROPERTY( false, true ),
 	/**
 	 * Describes the {@code <key-property/>} element
 	 */
 	KEY_PROPERTY( false, true ),
 	/**
 	 * Describes the {@code <many-to-one/>} element
 	 */
 	MANY_TO_ONE( false, true ),
 	/**
 	 * Describes the {@code <key-many-to-one/>} element
 	 */
 	KEY_MANY_TO_ONE( false, true ),
 	/**
 	 * Describes the {@code <one-to-one/>} element
 	 */
 	ONE_TO_ONE( false, true ),
 	/**
 	 * Describes the {@code <any/>} element
 	 */
 	ANY( false, true ),
 	/**
 	 * Describes the {@code <component/>} element
 	 */
 	COMPONENT( false, true ),
 	/**
 	 * Describes the {@code <key/>} element
 	 */
 	KEY( false, false ),
 	/**
 	 * Describes the {@code <set/>} element
 	 */
 	SET( false, true ),
 	/**
 	 * Describes the {@code <list/>} element
 	 */
 	LIST( false, true ),
 	/**
 	 * Describes the {@code <bag/>} element
 	 */
 	BAG( false, true ),
 	/**
 	 * Describes the {@code <id-bag/>} element
 	 */
 	ID_BAG( false, true ),
 	/**
 	 * Describes the {@code <map/>} element
 	 */
 	MAP( false, true ),
 	/**
 	 * Describes the {@code <array/>} element
 	 */
 	ARRAY( false, true ),
 	/**
 	 * Describes the {@code <primitive-array/>} element
 	 */
 	PRIMITIVE_ARRAY( false, true ),
 	/**
 	 * Describes the {@code <collection-id/>} element
 	 */
 	COLLECTION_ID( true, false ),
 	/**
 	 * Describes the {@code <element/>} element
 	 */
 	ELEMENT( false, false ),
 	/**
 	 * Describes the {@code <many-to-many/>} element
 	 */
 	MANY_TO_MANY( false, false ),
 	/**
 	 * Describes the {@code <many-to-aany/>} element
 	 */
 	MANY_TO_ANY( false, false ),
 	/**
 	 * Describes the {@code <map-key/>} element
 	 */
 	MAP_KEY( false, false ),
 	/**
 	 * Describes the {@code <map-key-many-to-many/>} element
 	 */
 	MAP_KEY_MANY_TO_MANY( false, false ),
 
 	/**
 	 * Describes the {@code <index/>} element
 	 */
 	INDEX( false, false ),
 	/**
 	 * Describes the {@code <index-many-to-many/>} element
 	 */
 	INDEX_MANY_TO_MANY( false, false ),
 	/**
 	 * Describes the {@code <list-index/>} element
 	 */
 	LIST_INDEX( true, false );
 
 	private final boolean inherentlySingleColumn;
 	private final boolean canBeNamed;
 
 	XmlElementMetadata(boolean inherentlySingleColumn, boolean canBeNamed) {
 		this.inherentlySingleColumn = inherentlySingleColumn;
 		this.canBeNamed = canBeNamed;
 	}
 
 	/**
 	 * The corresponding {@code hbm.xml} element name.  Used in error reporting
 	 *
 	 * @return The {@code hbm.xml} element name
 	 */
 	public String getElementName() {
-		return name().toLowerCase();
+		return name().toLowerCase(Locale.ROOT);
 	}
 
 	/**
 	 * Can this source, by nature, define just a single column/formula?
 	 *
 	 * @return {@code true} indicates that the source will refer to just a
 	 * single column.
 	 */
 	public boolean isInherentlySingleColumn() {
 		return inherentlySingleColumn;
 	}
 
 	/**
 	 * Can the source be named.  This is used in implicit naming (naming strategy).
 	 *
 	 * @return {@code true} indicates that the source can be named and therefore
 	 * the column (assuming just one) is eligible for implicit naming.
 	 */
 	public boolean canBeNamed() {
 		return canBeNamed;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/bytecode/enhance/internal/AttributeTypeDescriptor.java b/hibernate-core/src/main/java/org/hibernate/bytecode/enhance/internal/AttributeTypeDescriptor.java
index a75f95abd6..145e964f3b 100644
--- a/hibernate-core/src/main/java/org/hibernate/bytecode/enhance/internal/AttributeTypeDescriptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/bytecode/enhance/internal/AttributeTypeDescriptor.java
@@ -1,207 +1,208 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.bytecode.enhance.internal;
 
 import javassist.CtClass;
 import javassist.CtField;
 import javassist.NotFoundException;
 import org.hibernate.bytecode.enhance.spi.EnhancementContext;
 import org.hibernate.bytecode.enhance.spi.EnhancerConstants;
 
 import javax.persistence.Id;
 import java.util.Collection;
+import java.util.Locale;
 
 /**
  * utility class to generate interceptor methods
  * @see org.hibernate.engine.spi.PersistentAttributeInterceptor
  * 
  * @author <a href="mailto:lbarreiro@redhat.com">Luis Barreiro</a>
  */
 public abstract class AttributeTypeDescriptor {
 
 	public abstract String buildReadInterceptionBodyFragment(String fieldName);
 
 	public abstract String buildWriteInterceptionBodyFragment(String fieldName);
 
 	public String buildInLineDirtyCheckingBodyFragment(EnhancementContext context, CtField currentValue) {
 		final StringBuilder builder = new StringBuilder();
 		try {
 			// should ignore primary keys
 			for ( Object o : currentValue.getType().getAnnotations() ) {
 				if ( o instanceof Id) {
 					return "";
 				}
 			}
 			builder.append( String.format( "if (%s() != null", EnhancerConstants.INTERCEPTOR_GETTER_NAME ) );
 
 			// primitives || enums
 			if ( currentValue.getType().isPrimitive() || currentValue.getType().isEnum() ) {
 				builder.append( String.format( " && %s != $1)", currentValue.getName()) );
 			}
 			// simple data types
 			else if ( currentValue.getType().getName().startsWith( "java.lang" )
 					|| currentValue.getType().getName().startsWith( "java.math.Big" )
 					|| currentValue.getType().getName().startsWith( "java.sql.Time" )
 					|| currentValue.getType().getName().startsWith( "java.sql.Date" )
 					|| currentValue.getType().getName().startsWith( "java.util.Date" )
 					|| currentValue.getType().getName().startsWith( "java.util.Calendar" ) ) {
 				builder.append( String.format( "&& ((%s == null) || (!%<s.equals($1))))", currentValue.getName() ) );
 			}
 			// all other objects
 			else {
 				// if the field is a collection we return since we handle that in a separate method
 				for ( CtClass ctClass : currentValue.getType().getInterfaces() ) {
 					if ( ctClass.getName().equals( Collection.class.getName() ) ) {
 						// if the collection is not managed we should write it to the tracker
 						if ( context.isMappedCollection( currentValue ) ) {
 							return "";
 						}
 					}
 				}
 				// TODO: for now just call equals, should probably do something else here
 				builder.append( String.format( "&& ((%s == null) || (!%<s.equals($1))))", currentValue.getName() ) );
 			}
 			builder.append( String.format( " { %s(\"%s\"); }", EnhancerConstants.TRACKER_CHANGER_NAME, currentValue.getName() ) );
 		}
 		catch (ClassNotFoundException e) {
 			e.printStackTrace();
 		}
 		catch (NotFoundException e) {
 			e.printStackTrace();
 		}
 		return builder.toString();
 	}
 
 	/* --- */
 
 	/**
 	 * factory method to get the AttributeTypeDescriptor for a particular field type
 	 */
 	public static AttributeTypeDescriptor resolve(CtField persistentField) throws NotFoundException {
 		if ( persistentField.getType() == CtClass.booleanType ) {
 			return new PrimitiveAttributeTypeDescriptor( Boolean.TYPE );
 		}
 		else if ( persistentField.getType() == CtClass.byteType ) {
 			return new PrimitiveAttributeTypeDescriptor( Byte.TYPE );
 		}
 		else if ( persistentField.getType() == CtClass.charType ) {
 			return new PrimitiveAttributeTypeDescriptor( Character.TYPE );
 		}
 		else if ( persistentField.getType() == CtClass.shortType ) {
 			return new PrimitiveAttributeTypeDescriptor( Short.TYPE );
 		}
 		else if ( persistentField.getType() == CtClass.intType ) {
 			return new PrimitiveAttributeTypeDescriptor( Integer.TYPE );
 		}
 		else if ( persistentField.getType() == CtClass.longType ) {
 			return new PrimitiveAttributeTypeDescriptor( Long.TYPE );
 		}
 		else if ( persistentField.getType() == CtClass.doubleType ) {
 			return new PrimitiveAttributeTypeDescriptor( Double.TYPE );
 		}
 		else if ( persistentField.getType() == CtClass.floatType ) {
 			return new PrimitiveAttributeTypeDescriptor( Float.TYPE );
 		}
 		else {
 			return new ObjectAttributeTypeDescriptor( persistentField.getType() );
 		}
 	}
 
 	/* --- */
 
 	/**
 	 * AttributeTypeDescriptor for non primitive types
 	 */
 	private static class ObjectAttributeTypeDescriptor extends AttributeTypeDescriptor {
 
 		private final String type;
 
 		private ObjectAttributeTypeDescriptor(CtClass concreteType) {
 			this.type = concreteType.getName();
 		}
 
 		public String buildReadInterceptionBodyFragment(String fieldName) {
 			return String.format( "" +
 							"if ( %3$s() != null ) {%n" +
 							"  this.%1$s = (%2$s) %3$s().readObject(this, \"%1$s\", this.%1$s);%n" +
 							"}",
 					fieldName,
 					type,
 					EnhancerConstants.INTERCEPTOR_GETTER_NAME);
 		}
 
 		public String buildWriteInterceptionBodyFragment(String fieldName) {
 			return String.format( "" +
 							"%2$s localVar = $1;%n" +
 							"if ( %3$s() != null ) {%n" +
 							"  localVar = (%2$s) %3$s().writeObject(this, \"%1$s\", this.%1$s, $1);%n" +
 							"}%n" +
 							"this.%1$s = localVar;",
 					fieldName,
 					type,
 					EnhancerConstants.INTERCEPTOR_GETTER_NAME);
 		}
 	}
 
 	/**
 	 * AttributeTypeDescriptor for primitive types
 	 */
 	private static class PrimitiveAttributeTypeDescriptor extends AttributeTypeDescriptor {
 
 		private final String type;
 
 		private PrimitiveAttributeTypeDescriptor(Class<?> primitiveType) {
 			if ( !primitiveType.isPrimitive() ) {
 				throw new IllegalArgumentException( "Primitive attribute type descriptor can only be used on primitive types" );
 			}
 			// capitalize first letter
-			this.type = primitiveType.getSimpleName().substring( 0, 1 ).toUpperCase() + primitiveType.getSimpleName().substring( 1 );
+			this.type = primitiveType.getSimpleName().substring( 0, 1 ).toUpperCase(Locale.ROOT) + primitiveType.getSimpleName().substring( 1 );
 		}
 
 		public String buildReadInterceptionBodyFragment(String fieldName) {
 			return String.format( "" +
 							"if (%3$s() != null ) {%n" +
 							"  this.%1$s = %3$s().read%2$s(this, \"%1$s\", this.%1$s);%n" +
 							"}",
 					fieldName,
 					type,
 					EnhancerConstants.INTERCEPTOR_GETTER_NAME );
 		}
 
 		public String buildWriteInterceptionBodyFragment(String fieldName) {
 			return String.format( "" +
 							"%2$s localVar = $1;%n" +
 							"if ( %4$s() != null ) {%n" +
 							"  localVar = %4$s().write%3$s(this, \"%1$s\", this.%1$s, $1);%n" +
 							"}%n" +
 							"this.%1$s = localVar;",
 					fieldName,
-					type.toLowerCase(),
+					type.toLowerCase(Locale.ROOT ),
 					type,
 					EnhancerConstants.INTERCEPTOR_GETTER_NAME
 			);
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/CopyIdentifierComponentSecondPass.java b/hibernate-core/src/main/java/org/hibernate/cfg/CopyIdentifierComponentSecondPass.java
index 37b4311ca5..62ee0821bc 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/CopyIdentifierComponentSecondPass.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/CopyIdentifierComponentSecondPass.java
@@ -1,172 +1,173 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.util.HashMap;
 import java.util.Iterator;
+import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
 import org.hibernate.MappingException;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.SimpleValue;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 public class CopyIdentifierComponentSecondPass implements SecondPass {
 	private static final Logger log = Logger.getLogger( CopyIdentifierComponentSecondPass.class );
 
 	private final String referencedEntityName;
 	private final Component component;
 	private final MetadataBuildingContext buildingContext;
 	private final Ejb3JoinColumn[] joinColumns;
 
 	public CopyIdentifierComponentSecondPass(
 			Component comp,
 			String referencedEntityName,
 			Ejb3JoinColumn[] joinColumns,
 			MetadataBuildingContext buildingContext) {
 		this.component = comp;
 		this.referencedEntityName = referencedEntityName;
 		this.buildingContext = buildingContext;
 		this.joinColumns = joinColumns;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void doSecondPass(Map persistentClasses) throws MappingException {
 		PersistentClass referencedPersistentClass = (PersistentClass) persistentClasses.get( referencedEntityName );
 		// TODO better error names
 		if ( referencedPersistentClass == null ) {
 			throw new AnnotationException( "Unknown entity name: " + referencedEntityName );
 		}
 		if ( ! ( referencedPersistentClass.getIdentifier() instanceof Component ) ) {
 			throw new AssertionFailure(
 					"Unexpected identifier type on the referenced entity when mapping a @MapsId: "
 							+ referencedEntityName
 			);
 		}
 		Component referencedComponent = (Component) referencedPersistentClass.getIdentifier();
 		Iterator<Property> properties = referencedComponent.getPropertyIterator();
 
 
 		//prepare column name structure
 		boolean isExplicitReference = true;
 		Map<String, Ejb3JoinColumn> columnByReferencedName = new HashMap<String, Ejb3JoinColumn>(joinColumns.length);
 		for (Ejb3JoinColumn joinColumn : joinColumns) {
 			final String referencedColumnName = joinColumn.getReferencedColumn();
 			if ( referencedColumnName == null || BinderHelper.isEmptyAnnotationValue( referencedColumnName ) ) {
 				break;
 			}
 			//JPA 2 requires referencedColumnNames to be case insensitive
-			columnByReferencedName.put( referencedColumnName.toLowerCase(), joinColumn );
+			columnByReferencedName.put( referencedColumnName.toLowerCase(Locale.ROOT), joinColumn );
 		}
 		//try default column orientation
 		int index = 0;
 		if ( columnByReferencedName.isEmpty() ) {
 			isExplicitReference = false;
 			for (Ejb3JoinColumn joinColumn : joinColumns) {
 				columnByReferencedName.put( "" + index, joinColumn );
 				index++;
 			}
 			index = 0;
 		}
 
 		while ( properties.hasNext() ) {
 			Property referencedProperty = properties.next();
 			if ( referencedProperty.isComposite() ) {
 				throw new AssertionFailure( "Unexpected nested component on the referenced entity when mapping a @MapsId: "
 						+ referencedEntityName);
 			}
 			else {
 				Property property = new Property();
 				property.setName( referencedProperty.getName() );
 				property.setNodeName( referencedProperty.getNodeName() );
 				//FIXME set optional?
 				//property.setOptional( property.isOptional() );
 				property.setPersistentClass( component.getOwner() );
 				property.setPropertyAccessorName( referencedProperty.getPropertyAccessorName() );
 				SimpleValue value = new SimpleValue( buildingContext.getMetadataCollector(), component.getTable() );
 				property.setValue( value );
 				final SimpleValue referencedValue = (SimpleValue) referencedProperty.getValue();
 				value.setTypeName( referencedValue.getTypeName() );
 				value.setTypeParameters( referencedValue.getTypeParameters() );
 				final Iterator<Selectable> columns = referencedValue.getColumnIterator();
 
 				if ( joinColumns[0].isNameDeferred() ) {
 					joinColumns[0].copyReferencedStructureAndCreateDefaultJoinColumns(
 						referencedPersistentClass,
 						columns,
 						value);
 				}
 				else {
 					//FIXME take care of Formula
 					while ( columns.hasNext() ) {
 						final Selectable selectable = columns.next();
 						if ( ! Column.class.isInstance( selectable ) ) {
 							log.debug( "Encountered formula definition; skipping" );
 							continue;
 						}
 						final Column column = (Column) selectable;
 						final Ejb3JoinColumn joinColumn;
 						String logicalColumnName = null;
 						if ( isExplicitReference ) {
 							final String columnName = column.getName();
 							logicalColumnName = buildingContext.getMetadataCollector().getLogicalColumnName(
 									referencedPersistentClass.getTable(),
 									columnName
 							);
 							//JPA 2 requires referencedColumnNames to be case insensitive
-							joinColumn = columnByReferencedName.get( logicalColumnName.toLowerCase() );
+							joinColumn = columnByReferencedName.get( logicalColumnName.toLowerCase(Locale.ROOT ) );
 						}
 						else {
 							joinColumn = columnByReferencedName.get( "" + index );
 							index++;
 						}
 						if ( joinColumn == null && ! joinColumns[0].isNameDeferred() ) {
 							throw new AnnotationException(
 									isExplicitReference ?
 											"Unable to find column reference in the @MapsId mapping: " + logicalColumnName :
 											"Implicit column reference in the @MapsId mapping fails, try to use explicit referenceColumnNames: " + referencedEntityName
 							);
 						}
 						final String columnName = joinColumn == null || joinColumn.isNameDeferred() ? "tata_" + column.getName() : joinColumn
 								.getName();
 						value.addColumn( new Column( columnName ) );
 						column.setValue( value );
 					}
 				}
 				component.addProperty( property );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/DefaultComponentSafeNamingStrategy.java b/hibernate-core/src/main/java/org/hibernate/cfg/DefaultComponentSafeNamingStrategy.java
index 805d7cd02f..c6c69da015 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/DefaultComponentSafeNamingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/DefaultComponentSafeNamingStrategy.java
@@ -1,98 +1,99 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
+import java.util.Locale;
 import org.hibernate.AssertionFailure;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * @author Emmanuel Bernard
  */
 public class DefaultComponentSafeNamingStrategy extends EJB3NamingStrategy {
 	public static final NamingStrategy INSTANCE = new DefaultComponentSafeNamingStrategy();
 
 	protected static String addUnderscores(String name) {
-		return name.replace( '.', '_' ).toLowerCase();
+		return name.replace( '.', '_' ).toLowerCase(Locale.ROOT);
 	}
 
 	@Override
 	public String propertyToColumnName(String propertyName) {
 		return addUnderscores( propertyName );
 	}
 
 	@Override
 	public String collectionTableName(
 			String ownerEntity, String ownerEntityTable, String associatedEntity, String associatedEntityTable,
 			String propertyName
 	) {
 		return tableName(
 				new StringBuilder( ownerEntityTable ).append( "_" )
 						.append(
 								associatedEntityTable != null ?
 										associatedEntityTable :
 										addUnderscores( propertyName )
 						).toString()
 		);
 	}
 
 
 	public String foreignKeyColumnName(
 			String propertyName, String propertyEntityName, String propertyTableName, String referencedColumnName
 	) {
 		String header = propertyName != null ? addUnderscores( propertyName ) : propertyTableName;
 		if ( header == null ) throw new AssertionFailure( "NamingStrategy not properly filled" );
 		return columnName( header + "_" + referencedColumnName );
 	}
 
 	@Override
 	public String logicalColumnName(String columnName, String propertyName) {
 		return StringHelper.isNotEmpty( columnName ) ? columnName : propertyName;
 	}
 
 	@Override
 	public String logicalCollectionTableName(
 			String tableName, String ownerEntityTable, String associatedEntityTable, String propertyName
 	) {
 		if ( tableName != null ) {
 			return tableName;
 		}
 		else {
 			//use of a stringbuffer to workaround a JDK bug
 			return new StringBuffer( ownerEntityTable ).append( "_" )
 					.append(
 							associatedEntityTable != null ?
 									associatedEntityTable :
 									propertyName
 					).toString();
 		}
 
 	}
 
 	@Override
 	public String logicalCollectionColumnName(String columnName, String propertyName, String referencedColumn) {
 		return StringHelper.isNotEmpty( columnName ) ?
 				columnName :
 				propertyName + "_" + referencedColumn;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/ImprovedNamingStrategy.java b/hibernate-core/src/main/java/org/hibernate/cfg/ImprovedNamingStrategy.java
index b9be3483c7..42ee43d672 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/ImprovedNamingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/ImprovedNamingStrategy.java
@@ -1,146 +1,147 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.Serializable;
+import java.util.Locale;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * An improved naming strategy that prefers embedded
  * underscores to mixed case names
  * @see DefaultNamingStrategy the default strategy
  * @author Gavin King
  */
 public class ImprovedNamingStrategy implements NamingStrategy, Serializable {
 
 	/**
 	 * A convenient singleton instance
 	 */
 	public static final NamingStrategy INSTANCE = new ImprovedNamingStrategy();
 
 	/**
 	 * Return the unqualified class name, mixed case converted to
 	 * underscores
 	 */
 	public String classToTableName(String className) {
 		return addUnderscores( StringHelper.unqualify(className) );
 	}
 	/**
 	 * Return the full property path with underscore seperators, mixed
 	 * case converted to underscores
 	 */
 	public String propertyToColumnName(String propertyName) {
 		return addUnderscores( StringHelper.unqualify(propertyName) );
 	}
 	/**
 	 * Convert mixed case to underscores
 	 */
 	public String tableName(String tableName) {
 		return addUnderscores(tableName);
 	}
 	/**
 	 * Convert mixed case to underscores
 	 */
 	public String columnName(String columnName) {
 		return addUnderscores(columnName);
 	}
 
 	protected static String addUnderscores(String name) {
 		StringBuilder buf = new StringBuilder( name.replace('.', '_') );
 		for (int i=1; i<buf.length()-1; i++) {
 			if (
 				Character.isLowerCase( buf.charAt(i-1) ) &&
 				Character.isUpperCase( buf.charAt(i) ) &&
 				Character.isLowerCase( buf.charAt(i+1) )
 			) {
 				buf.insert(i++, '_');
 			}
 		}
-		return buf.toString().toLowerCase();
+		return buf.toString().toLowerCase(Locale.ROOT);
 	}
 
 	public String collectionTableName(
 			String ownerEntity, String ownerEntityTable, String associatedEntity, String associatedEntityTable,
 			String propertyName
 	) {
 		return tableName( ownerEntityTable + '_' + propertyToColumnName(propertyName) );
 	}
 
 	/**
 	 * Return the argument
 	 */
 	public String joinKeyColumnName(String joinedColumn, String joinedTable) {
 		return columnName( joinedColumn );
 	}
 
 	/**
 	 * Return the property name or propertyTableName
 	 */
 	public String foreignKeyColumnName(
 			String propertyName, String propertyEntityName, String propertyTableName, String referencedColumnName
 	) {
 		String header = propertyName != null ? StringHelper.unqualify( propertyName ) : propertyTableName;
 		if (header == null) throw new AssertionFailure("NamingStrategy not properly filled");
 		return columnName( header ); //+ "_" + referencedColumnName not used for backward compatibility
 	}
 
 	/**
 	 * Return the column name or the unqualified property name
 	 */
 	public String logicalColumnName(String columnName, String propertyName) {
 		return StringHelper.isNotEmpty( columnName ) ? columnName : StringHelper.unqualify( propertyName );
 	}
 
 	/**
 	 * Returns either the table name if explicit or
 	 * if there is an associated table, the concatenation of owner entity table and associated table
 	 * otherwise the concatenation of owner entity table and the unqualified property name
 	 */
 	public String logicalCollectionTableName(String tableName,
 											 String ownerEntityTable, String associatedEntityTable, String propertyName
 	) {
 		if ( tableName != null ) {
 			return tableName;
 		}
 		else {
 			//use of a stringbuffer to workaround a JDK bug
 			return new StringBuffer(ownerEntityTable).append("_")
 					.append(
 						associatedEntityTable != null ?
 						associatedEntityTable :
 						StringHelper.unqualify( propertyName )
 					).toString();
 		}
 	}
 	/**
 	 * Return the column name if explicit or the concatenation of the property name and the referenced column
 	 */
 	public String logicalCollectionColumnName(String columnName, String propertyName, String referencedColumn) {
 		return StringHelper.isNotEmpty( columnName ) ?
 				columnName :
 				StringHelper.unqualify( propertyName ) + "_" + referencedColumn;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/JPAIndexHolder.java b/hibernate-core/src/main/java/org/hibernate/cfg/JPAIndexHolder.java
index fa1fbe7881..0d2c8dc176 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/JPAIndexHolder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/JPAIndexHolder.java
@@ -1,87 +1,88 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.util.ArrayList;
 import java.util.List;
+import java.util.Locale;
 import java.util.StringTokenizer;
 import javax.persistence.Index;
 
 /**
  * @author Strong Liu <stliu@hibernate.org>
  */
 public class JPAIndexHolder {
 	private final String name;
 	private final String[] columns;
 	private final String[] ordering;
 	private final boolean unique;
 
 	public JPAIndexHolder(Index index) {
 		StringTokenizer tokenizer = new StringTokenizer( index.columnList(), "," );
 		List<String> tmp = new ArrayList<String>();
 		while ( tokenizer.hasMoreElements() ) {
 			tmp.add( tokenizer.nextToken().trim() );
 		}
 		this.name = index.name();
 		this.columns = new String[tmp.size()];
 		this.ordering = new String[tmp.size()];
 		this.unique = index.unique();
 		initializeColumns( columns, ordering, tmp );
 	}
 
 	public String[] getColumns() {
 		return columns;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public String[] getOrdering() {
 		return ordering;
 	}
 
 	public boolean isUnique() {
 		return unique;
 	}
 
 	private void initializeColumns(String[] columns, String[] ordering, List<String> list) {
 		for ( int i = 0, size = list.size(); i < size; i++ ) {
 			final String description = list.get( i );
-			final String tmp = description.toLowerCase();
+			final String tmp = description.toLowerCase(Locale.ROOT);
 			if ( tmp.endsWith( " desc" ) ) {
 				columns[i] = description.substring( 0, description.length() - 5 );
 				ordering[i] = "desc";
 			}
 			else if ( tmp.endsWith( " asc" ) ) {
 				columns[i] = description.substring( 0, description.length() - 4 );
 				ordering[i] = "asc";
 			}
 			else {
 				columns[i] = description;
 				ordering[i] = null;
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/VerifyFetchProfileReferenceSecondPass.java b/hibernate-core/src/main/java/org/hibernate/cfg/VerifyFetchProfileReferenceSecondPass.java
index 9d03d8098c..5785b9a2de 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/VerifyFetchProfileReferenceSecondPass.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/VerifyFetchProfileReferenceSecondPass.java
@@ -1,74 +1,75 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
+import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.MappingException;
 import org.hibernate.annotations.FetchProfile;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.mapping.MetadataSource;
 import org.hibernate.mapping.PersistentClass;
 
 /**
  * @author Hardy Ferentschik
  */
 public class VerifyFetchProfileReferenceSecondPass implements SecondPass {
 	private String fetchProfileName;
 	private FetchProfile.FetchOverride fetch;
 	private MetadataBuildingContext buildingContext;
 
 	public VerifyFetchProfileReferenceSecondPass(
 			String fetchProfileName,
 			FetchProfile.FetchOverride fetch,
 			MetadataBuildingContext buildingContext) {
 		this.fetchProfileName = fetchProfileName;
 		this.fetch = fetch;
 		this.buildingContext = buildingContext;
 	}
 
 	public void doSecondPass(Map persistentClasses) throws MappingException {
 		org.hibernate.mapping.FetchProfile profile = buildingContext.getMetadataCollector().getFetchProfile(
 				fetchProfileName
 		);
 		if ( profile != null ) {
 			if ( profile.getSource() != MetadataSource.ANNOTATIONS ) {
 				return;
 			}
 		}
 		else {
 			profile = new org.hibernate.mapping.FetchProfile( fetchProfileName, MetadataSource.ANNOTATIONS );
 			buildingContext.getMetadataCollector().addFetchProfile( profile );
 		}
 
 		PersistentClass clazz = buildingContext.getMetadataCollector().getEntityBinding( fetch.entity().getName() );
 		// throws MappingException in case the property does not exist
 		clazz.getProperty( fetch.association() );
 
 		profile.addFetch(
-				fetch.entity().getName(), fetch.association(), fetch.mode().toString().toLowerCase()
+				fetch.entity().getName(), fetch.association(), fetch.mode().toString().toLowerCase(Locale.ROOT)
 		);
 	}
 }
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/CollectionBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/CollectionBinder.java
index 1b5ac58e6b..9734dda278 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/CollectionBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/CollectionBinder.java
@@ -1,1482 +1,1483 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.Iterator;
+import java.util.Locale;
 import java.util.Map;
 import java.util.Properties;
 import javax.persistence.AttributeOverride;
 import javax.persistence.AttributeOverrides;
 import javax.persistence.CollectionTable;
 import javax.persistence.ConstraintMode;
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.FetchType;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinColumns;
 import javax.persistence.JoinTable;
 import javax.persistence.ManyToMany;
 import javax.persistence.MapKey;
 import javax.persistence.MapKeyColumn;
 import javax.persistence.OneToMany;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.FetchMode;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.BatchSize;
 import org.hibernate.annotations.Cache;
 import org.hibernate.annotations.CollectionId;
 import org.hibernate.annotations.CollectionType;
 import org.hibernate.annotations.Fetch;
 import org.hibernate.annotations.Filter;
 import org.hibernate.annotations.FilterJoinTable;
 import org.hibernate.annotations.FilterJoinTables;
 import org.hibernate.annotations.Filters;
 import org.hibernate.annotations.ForeignKey;
 import org.hibernate.annotations.Immutable;
 import org.hibernate.annotations.LazyCollection;
 import org.hibernate.annotations.LazyCollectionOption;
 import org.hibernate.annotations.Loader;
 import org.hibernate.annotations.ManyToAny;
 import org.hibernate.annotations.OptimisticLock;
 import org.hibernate.annotations.OrderBy;
 import org.hibernate.annotations.Parameter;
 import org.hibernate.annotations.Persister;
 import org.hibernate.annotations.SQLDelete;
 import org.hibernate.annotations.SQLDeleteAll;
 import org.hibernate.annotations.SQLInsert;
 import org.hibernate.annotations.SQLUpdate;
 import org.hibernate.annotations.Sort;
 import org.hibernate.annotations.SortComparator;
 import org.hibernate.annotations.SortNatural;
 import org.hibernate.annotations.SortType;
 import org.hibernate.annotations.Where;
 import org.hibernate.annotations.WhereJoinTable;
 import org.hibernate.annotations.common.AssertionFailure;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.boot.model.IdentifierGeneratorDefinition;
 import org.hibernate.boot.model.TypeDefinition;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.cfg.AccessType;
 import org.hibernate.cfg.AnnotatedClassType;
 import org.hibernate.cfg.AnnotationBinder;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.CollectionPropertyHolder;
 import org.hibernate.cfg.CollectionSecondPass;
 import org.hibernate.cfg.Ejb3Column;
 import org.hibernate.cfg.Ejb3JoinColumn;
 import org.hibernate.cfg.IndexColumn;
 import org.hibernate.cfg.InheritanceState;
 import org.hibernate.cfg.PropertyData;
 import org.hibernate.cfg.PropertyHolder;
 import org.hibernate.cfg.PropertyHolderBuilder;
 import org.hibernate.cfg.PropertyInferredData;
 import org.hibernate.cfg.PropertyPreloadedData;
 import org.hibernate.cfg.SecondPass;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Any;
 import org.hibernate.mapping.Backref;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.ManyToOne;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Table;
 
 import org.jboss.logging.Logger;
 
 import static org.hibernate.cfg.BinderHelper.toAliasEntityMap;
 import static org.hibernate.cfg.BinderHelper.toAliasTableMap;
 
 /**
  * Base class for binding different types of collections to Hibernate configuration objects.
  *
  * @author inger
  * @author Emmanuel Bernard
  */
 @SuppressWarnings({"unchecked", "serial"})
 public abstract class CollectionBinder {
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CollectionBinder.class.getName());
 
 	private MetadataBuildingContext buildingContext;
 
 	protected Collection collection;
 	protected String propertyName;
 	PropertyHolder propertyHolder;
 	int batchSize;
 	private String mappedBy;
 	private XClass collectionType;
 	private XClass targetEntity;
 	private Ejb3JoinColumn[] inverseJoinColumns;
 	private String cascadeStrategy;
 	String cacheConcurrencyStrategy;
 	String cacheRegionName;
 	private boolean oneToMany;
 	protected IndexColumn indexColumn;
 	protected boolean cascadeDeleteEnabled;
 	protected String mapKeyPropertyName;
 	private boolean insertable = true;
 	private boolean updatable = true;
 	private Ejb3JoinColumn[] fkJoinColumns;
 	private boolean isExplicitAssociationTable;
 	private Ejb3Column[] elementColumns;
 	private boolean isEmbedded;
 	private XProperty property;
 	private boolean ignoreNotFound;
 	private TableBinder tableBinder;
 	private Ejb3Column[] mapKeyColumns;
 	private Ejb3JoinColumn[] mapKeyManyToManyColumns;
 	protected HashMap<String, IdentifierGeneratorDefinition> localGenerators;
 	protected Map<XClass, InheritanceState> inheritanceStatePerClass;
 	private XClass declaringClass;
 	private boolean declaringClassSet;
 	private AccessType accessType;
 	private boolean hibernateExtensionMapping;
 
 	private boolean isSortedCollection;
 	private javax.persistence.OrderBy jpaOrderBy;
 	private OrderBy sqlOrderBy;
 	private Sort deprecatedSort;
 	private SortNatural naturalSort;
 	private SortComparator comparatorSort;
 
 	private String explicitType;
 	private Properties explicitTypeParameters = new Properties();
 
 	protected MetadataBuildingContext getBuildingContext() {
 		return buildingContext;
 	}
 
 	public void setBuildingContext(MetadataBuildingContext buildingContext) {
 		this.buildingContext = buildingContext;
 	}
 
 	public boolean isMap() {
 		return false;
 	}
 
 	public void setIsHibernateExtensionMapping(boolean hibernateExtensionMapping) {
 		this.hibernateExtensionMapping = hibernateExtensionMapping;
 	}
 
 	protected boolean isHibernateExtensionMapping() {
 		return hibernateExtensionMapping;
 	}
 
 	public void setUpdatable(boolean updatable) {
 		this.updatable = updatable;
 	}
 
 	public void setInheritanceStatePerClass(Map<XClass, InheritanceState> inheritanceStatePerClass) {
 		this.inheritanceStatePerClass = inheritanceStatePerClass;
 	}
 
 	public void setInsertable(boolean insertable) {
 		this.insertable = insertable;
 	}
 
 	public void setCascadeStrategy(String cascadeStrategy) {
 		this.cascadeStrategy = cascadeStrategy;
 	}
 
 	public void setAccessType(AccessType accessType) {
 		this.accessType = accessType;
 	}
 
 	public void setInverseJoinColumns(Ejb3JoinColumn[] inverseJoinColumns) {
 		this.inverseJoinColumns = inverseJoinColumns;
 	}
 
 	public void setJoinColumns(Ejb3JoinColumn[] joinColumns) {
 		this.joinColumns = joinColumns;
 	}
 
 	private Ejb3JoinColumn[] joinColumns;
 
 	public void setPropertyHolder(PropertyHolder propertyHolder) {
 		this.propertyHolder = propertyHolder;
 	}
 
 	public void setBatchSize(BatchSize batchSize) {
 		this.batchSize = batchSize == null ? -1 : batchSize.size();
 	}
 
 	public void setJpaOrderBy(javax.persistence.OrderBy jpaOrderBy) {
 		this.jpaOrderBy = jpaOrderBy;
 	}
 
 	public void setSqlOrderBy(OrderBy sqlOrderBy) {
 		this.sqlOrderBy = sqlOrderBy;
 	}
 
 	public void setSort(Sort deprecatedSort) {
 		this.deprecatedSort = deprecatedSort;
 	}
 
 	public void setNaturalSort(SortNatural naturalSort) {
 		this.naturalSort = naturalSort;
 	}
 
 	public void setComparatorSort(SortComparator comparatorSort) {
 		this.comparatorSort = comparatorSort;
 	}
 
 	/**
 	 * collection binder factory
 	 */
 	public static CollectionBinder getCollectionBinder(
 			String entityName,
 			XProperty property,
 			boolean isIndexed,
 			boolean isHibernateExtensionMapping,
 			MetadataBuildingContext buildingContext) {
 		final CollectionBinder result;
 		if ( property.isArray() ) {
 			if ( property.getElementClass().isPrimitive() ) {
 				result = new PrimitiveArrayBinder();
 			}
 			else {
 				result = new ArrayBinder();
 			}
 		}
 		else if ( property.isCollection() ) {
 			//TODO consider using an XClass
 			Class returnedClass = property.getCollectionClass();
 			if ( java.util.Set.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					throw new AnnotationException( "Set do not support @CollectionId: "
 							+ StringHelper.qualify( entityName, property.getName() ) );
 				}
 				result = new SetBinder( false );
 			}
 			else if ( java.util.SortedSet.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					throw new AnnotationException( "Set do not support @CollectionId: "
 							+ StringHelper.qualify( entityName, property.getName() ) );
 				}
 				result = new SetBinder( true );
 			}
 			else if ( java.util.Map.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					throw new AnnotationException( "Map do not support @CollectionId: "
 							+ StringHelper.qualify( entityName, property.getName() ) );
 				}
 				result = new MapBinder( false );
 			}
 			else if ( java.util.SortedMap.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					throw new AnnotationException( "Map do not support @CollectionId: "
 							+ StringHelper.qualify( entityName, property.getName() ) );
 				}
 				result = new MapBinder( true );
 			}
 			else if ( java.util.Collection.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					result = new IdBagBinder();
 				}
 				else {
 					result = new BagBinder();
 				}
 			}
 			else if ( java.util.List.class.equals( returnedClass ) ) {
 				if ( isIndexed ) {
 					if ( property.isAnnotationPresent( CollectionId.class ) ) {
 						throw new AnnotationException(
 								"List do not support @CollectionId and @OrderColumn (or @IndexColumn) at the same time: "
 								+ StringHelper.qualify( entityName, property.getName() ) );
 					}
 					result = new ListBinder();
 				}
 				else if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					result = new IdBagBinder();
 				}
 				else {
 					result = new BagBinder();
 				}
 			}
 			else {
 				throw new AnnotationException(
 						returnedClass.getName() + " collection not yet supported: "
 								+ StringHelper.qualify( entityName, property.getName() )
 				);
 			}
 		}
 		else {
 			throw new AnnotationException(
 					"Illegal attempt to map a non collection as a @OneToMany, @ManyToMany or @CollectionOfElements: "
 							+ StringHelper.qualify( entityName, property.getName() )
 			);
 		}
 		result.setIsHibernateExtensionMapping( isHibernateExtensionMapping );
 
 		final CollectionType typeAnnotation = property.getAnnotation( CollectionType.class );
 		if ( typeAnnotation != null ) {
 			final String typeName = typeAnnotation.type();
 			// see if it names a type-def
 			final TypeDefinition typeDef = buildingContext.getMetadataCollector().getTypeDefinition( typeName );
 			if ( typeDef != null ) {
 				result.explicitType = typeDef.getTypeImplementorClass().getName();
 				result.explicitTypeParameters.putAll( typeDef.getParameters() );
 			}
 			else {
 				result.explicitType = typeName;
 				for ( Parameter param : typeAnnotation.parameters() ) {
 					result.explicitTypeParameters.setProperty( param.name(), param.value() );
 				}
 			}
 		}
 
 		return result;
 	}
 
 	protected CollectionBinder(boolean isSortedCollection) {
 		this.isSortedCollection = isSortedCollection;
 	}
 
 	public void setMappedBy(String mappedBy) {
 		this.mappedBy = mappedBy;
 	}
 
 	public void setTableBinder(TableBinder tableBinder) {
 		this.tableBinder = tableBinder;
 	}
 
 	public void setCollectionType(XClass collectionType) {
 		// NOTE: really really badly named.  This is actually NOT the collection-type, but rather the collection-element-type!
 		this.collectionType = collectionType;
 	}
 
 	public void setTargetEntity(XClass targetEntity) {
 		this.targetEntity = targetEntity;
 	}
 
 	protected abstract Collection createCollection(PersistentClass persistentClass);
 
 	public Collection getCollection() {
 		return collection;
 	}
 
 	public void setPropertyName(String propertyName) {
 		this.propertyName = propertyName;
 	}
 
 	public void setDeclaringClass(XClass declaringClass) {
 		this.declaringClass = declaringClass;
 		this.declaringClassSet = true;
 	}
 
 	public void bind() {
 		this.collection = createCollection( propertyHolder.getPersistentClass() );
 		String role = StringHelper.qualify( propertyHolder.getPath(), propertyName );
 		LOG.debugf( "Collection role: %s", role );
 		collection.setRole( role );
 		collection.setNodeName( propertyName );
 		collection.setMappedByProperty( mappedBy );
 
 		if ( property.isAnnotationPresent( MapKeyColumn.class )
 			&& mapKeyPropertyName != null ) {
 			throw new AnnotationException(
 					"Cannot mix @javax.persistence.MapKey and @MapKeyColumn or @org.hibernate.annotations.MapKey "
 							+ "on the same collection: " + StringHelper.qualify(
 							propertyHolder.getPath(), propertyName
 					)
 			);
 		}
 
 		// set explicit type information
 		if ( explicitType != null ) {
 			final TypeDefinition typeDef = buildingContext.getMetadataCollector().getTypeDefinition( explicitType );
 			if ( typeDef == null ) {
 				collection.setTypeName( explicitType );
 				collection.setTypeParameters( explicitTypeParameters );
 			}
 			else {
 				collection.setTypeName( typeDef.getTypeImplementorClass().getName() );
 				collection.setTypeParameters( typeDef.getParameters() );
 			}
 		}
 
 		//set laziness
 		defineFetchingStrategy();
 		collection.setBatchSize( batchSize );
 
 		collection.setMutable( !property.isAnnotationPresent( Immutable.class ) );
 
 		//work on association
 		boolean isMappedBy = !BinderHelper.isEmptyAnnotationValue( mappedBy );
 
 		final OptimisticLock lockAnn = property.getAnnotation( OptimisticLock.class );
 		final boolean includeInOptimisticLockChecks = ( lockAnn != null )
 				? ! lockAnn.excluded()
 				: ! isMappedBy;
 		collection.setOptimisticLocked( includeInOptimisticLockChecks );
 
 		Persister persisterAnn = property.getAnnotation( Persister.class );
 		if ( persisterAnn != null ) {
 			collection.setCollectionPersisterClass( persisterAnn.impl() );
 		}
 
 		applySortingAndOrdering( collection );
 
 		//set cache
 		if ( StringHelper.isNotEmpty( cacheConcurrencyStrategy ) ) {
 			collection.setCacheConcurrencyStrategy( cacheConcurrencyStrategy );
 			collection.setCacheRegionName( cacheRegionName );
 		}
 
 		//SQL overriding
 		SQLInsert sqlInsert = property.getAnnotation( SQLInsert.class );
 		SQLUpdate sqlUpdate = property.getAnnotation( SQLUpdate.class );
 		SQLDelete sqlDelete = property.getAnnotation( SQLDelete.class );
 		SQLDeleteAll sqlDeleteAll = property.getAnnotation( SQLDeleteAll.class );
 		Loader loader = property.getAnnotation( Loader.class );
 		if ( sqlInsert != null ) {
 			collection.setCustomSQLInsert( sqlInsert.sql().trim(), sqlInsert.callable(),
-					ExecuteUpdateResultCheckStyle.fromExternalName( sqlInsert.check().toString().toLowerCase() )
+					ExecuteUpdateResultCheckStyle.fromExternalName( sqlInsert.check().toString().toLowerCase(Locale.ROOT) )
 			);
 
 		}
 		if ( sqlUpdate != null ) {
 			collection.setCustomSQLUpdate( sqlUpdate.sql(), sqlUpdate.callable(),
-					ExecuteUpdateResultCheckStyle.fromExternalName( sqlUpdate.check().toString().toLowerCase() )
+					ExecuteUpdateResultCheckStyle.fromExternalName( sqlUpdate.check().toString().toLowerCase(Locale.ROOT) )
 			);
 		}
 		if ( sqlDelete != null ) {
 			collection.setCustomSQLDelete( sqlDelete.sql(), sqlDelete.callable(),
-					ExecuteUpdateResultCheckStyle.fromExternalName( sqlDelete.check().toString().toLowerCase() )
+					ExecuteUpdateResultCheckStyle.fromExternalName( sqlDelete.check().toString().toLowerCase(Locale.ROOT) )
 			);
 		}
 		if ( sqlDeleteAll != null ) {
 			collection.setCustomSQLDeleteAll( sqlDeleteAll.sql(), sqlDeleteAll.callable(),
-					ExecuteUpdateResultCheckStyle.fromExternalName( sqlDeleteAll.check().toString().toLowerCase() )
+					ExecuteUpdateResultCheckStyle.fromExternalName( sqlDeleteAll.check().toString().toLowerCase(Locale.ROOT) )
 			);
 		}
 		if ( loader != null ) {
 			collection.setLoaderName( loader.namedQuery() );
 		}
 
 		if (isMappedBy
 				&& (property.isAnnotationPresent( JoinColumn.class )
 					|| property.isAnnotationPresent( JoinColumns.class )
 					|| propertyHolder.getJoinTable( property ) != null ) ) {
 			String message = "Associations marked as mappedBy must not define database mappings like @JoinTable or @JoinColumn: ";
 			message += StringHelper.qualify( propertyHolder.getPath(), propertyName );
 			throw new AnnotationException( message );
 		}
 
 		collection.setInverse( isMappedBy );
 
 		//many to many may need some second pass informations
 		if ( !oneToMany && isMappedBy ) {
 			buildingContext.getMetadataCollector().addMappedBy( getCollectionType().getName(), mappedBy, propertyName );
 		}
 		//TODO reducce tableBinder != null and oneToMany
 		XClass collectionType = getCollectionType();
 		if ( inheritanceStatePerClass == null) throw new AssertionFailure( "inheritanceStatePerClass not set" );
 		SecondPass sp = getSecondPass(
 				fkJoinColumns,
 				joinColumns,
 				inverseJoinColumns,
 				elementColumns,
 				mapKeyColumns,
 				mapKeyManyToManyColumns,
 				isEmbedded,
 				property,
 				collectionType,
 				ignoreNotFound,
 				oneToMany,
 				tableBinder,
 				buildingContext
 		);
 		if ( collectionType.isAnnotationPresent( Embeddable.class )
 				|| property.isAnnotationPresent( ElementCollection.class ) //JPA 2
 				) {
 			// do it right away, otherwise @ManyToOne on composite element call addSecondPass
 			// and raise a ConcurrentModificationException
 			//sp.doSecondPass( CollectionHelper.EMPTY_MAP );
 			buildingContext.getMetadataCollector().addSecondPass( sp, !isMappedBy );
 		}
 		else {
 			buildingContext.getMetadataCollector().addSecondPass( sp, !isMappedBy );
 		}
 
 		buildingContext.getMetadataCollector().addCollectionBinding( collection );
 
 		//property building
 		PropertyBinder binder = new PropertyBinder();
 		binder.setName( propertyName );
 		binder.setValue( collection );
 		binder.setCascade( cascadeStrategy );
 		if ( cascadeStrategy != null && cascadeStrategy.indexOf( "delete-orphan" ) >= 0 ) {
 			collection.setOrphanDelete( true );
 		}
 		binder.setAccessType( accessType );
 		binder.setProperty( property );
 		binder.setInsertable( insertable );
 		binder.setUpdatable( updatable );
 		Property prop = binder.makeProperty();
 		//we don't care about the join stuffs because the column is on the association table.
 		if (! declaringClassSet) throw new AssertionFailure( "DeclaringClass is not set in CollectionBinder while binding" );
 		propertyHolder.addProperty( prop, declaringClass );
 	}
 
 	private void applySortingAndOrdering(Collection collection) {
 		boolean isSorted = isSortedCollection;
 
 		boolean hadOrderBy = false;
 		boolean hadExplicitSort = false;
 
 		Class<? extends Comparator> comparatorClass = null;
 
 		if ( jpaOrderBy == null && sqlOrderBy == null ) {
 			if ( deprecatedSort != null ) {
 				LOG.debug( "Encountered deprecated @Sort annotation; use @SortNatural or @SortComparator instead." );
 				if ( naturalSort != null || comparatorSort != null ) {
 					throw buildIllegalSortCombination();
 				}
 				hadExplicitSort = deprecatedSort.type() != SortType.UNSORTED;
 				if ( deprecatedSort.type() == SortType.NATURAL ) {
 					isSorted = true;
 				}
 				else if ( deprecatedSort.type() == SortType.COMPARATOR ) {
 					isSorted = true;
 					comparatorClass = deprecatedSort.comparator();
 				}
 			}
 			else if ( naturalSort != null ) {
 				if ( comparatorSort != null ) {
 					throw buildIllegalSortCombination();
 				}
 				hadExplicitSort = true;
 			}
 			else if ( comparatorSort != null ) {
 				hadExplicitSort = true;
 				comparatorClass = comparatorSort.value();
 			}
 		}
 		else {
 			if ( jpaOrderBy != null && sqlOrderBy != null ) {
 				throw new AnnotationException(
 						String.format(
 								"Illegal combination of @%s and @%s on %s",
 								javax.persistence.OrderBy.class.getName(),
 								OrderBy.class.getName(),
 								safeCollectionRole()
 						)
 				);
 			}
 
 			hadOrderBy = true;
 			hadExplicitSort = false;
 
 			// we can only apply the sql-based order by up front.  The jpa order by has to wait for second pass
 			if ( sqlOrderBy != null ) {
 				collection.setOrderBy( sqlOrderBy.clause() );
 			}
 		}
 
 		if ( isSortedCollection ) {
 			if ( ! hadExplicitSort && !hadOrderBy ) {
 				throw new AnnotationException(
 						"A sorted collection must define and ordering or sorting : " + safeCollectionRole()
 				);
 			}
 		}
 
 		collection.setSorted( isSortedCollection || hadExplicitSort );
 
 		if ( comparatorClass != null ) {
 			try {
 				collection.setComparator( comparatorClass.newInstance() );
 			}
 			catch (Exception e) {
 				throw new AnnotationException(
 						String.format(
 								"Could not instantiate comparator class [%s] for %s",
 								comparatorClass.getName(),
 								safeCollectionRole()
 						)
 				);
 			}
 		}
 	}
 
 	private AnnotationException buildIllegalSortCombination() {
 		return new AnnotationException(
 				String.format(
 						"Illegal combination of annotations on %s.  Only one of @%s, @%s and @%s can be used",
 						safeCollectionRole(),
 						Sort.class.getName(),
 						SortNatural.class.getName(),
 						SortComparator.class.getName()
 				)
 		);
 	}
 
 	private void defineFetchingStrategy() {
 		LazyCollection lazy = property.getAnnotation( LazyCollection.class );
 		Fetch fetch = property.getAnnotation( Fetch.class );
 		OneToMany oneToMany = property.getAnnotation( OneToMany.class );
 		ManyToMany manyToMany = property.getAnnotation( ManyToMany.class );
 		ElementCollection elementCollection = property.getAnnotation( ElementCollection.class ); //jpa 2
 		ManyToAny manyToAny = property.getAnnotation( ManyToAny.class );
 		FetchType fetchType;
 		if ( oneToMany != null ) {
 			fetchType = oneToMany.fetch();
 		}
 		else if ( manyToMany != null ) {
 			fetchType = manyToMany.fetch();
 		}
 		else if ( elementCollection != null ) {
 			fetchType = elementCollection.fetch();
 		}
 		else if ( manyToAny != null ) {
 			fetchType = FetchType.LAZY;
 		}
 		else {
 			throw new AssertionFailure(
 					"Define fetch strategy on a property not annotated with @ManyToOne nor @OneToMany nor @CollectionOfElements"
 			);
 		}
 		if ( lazy != null ) {
 			collection.setLazy( !( lazy.value() == LazyCollectionOption.FALSE ) );
 			collection.setExtraLazy( lazy.value() == LazyCollectionOption.EXTRA );
 		}
 		else {
 			collection.setLazy( fetchType == FetchType.LAZY );
 			collection.setExtraLazy( false );
 		}
 		if ( fetch != null ) {
 			if ( fetch.value() == org.hibernate.annotations.FetchMode.JOIN ) {
 				collection.setFetchMode( FetchMode.JOIN );
 				collection.setLazy( false );
 			}
 			else if ( fetch.value() == org.hibernate.annotations.FetchMode.SELECT ) {
 				collection.setFetchMode( FetchMode.SELECT );
 			}
 			else if ( fetch.value() == org.hibernate.annotations.FetchMode.SUBSELECT ) {
 				collection.setFetchMode( FetchMode.SELECT );
 				collection.setSubselectLoadable( true );
 				collection.getOwner().setSubselectLoadableCollections( true );
 			}
 			else {
 				throw new AssertionFailure( "Unknown FetchMode: " + fetch.value() );
 			}
 		}
 		else {
 			collection.setFetchMode( AnnotationBinder.getFetchMode( fetchType ) );
 		}
 	}
 
 	private XClass getCollectionType() {
 		if ( AnnotationBinder.isDefault( targetEntity, buildingContext ) ) {
 			if ( collectionType != null ) {
 				return collectionType;
 			}
 			else {
 				String errorMsg = "Collection has neither generic type or OneToMany.targetEntity() defined: "
 						+ safeCollectionRole();
 				throw new AnnotationException( errorMsg );
 			}
 		}
 		else {
 			return targetEntity;
 		}
 	}
 
 	public SecondPass getSecondPass(
 			final Ejb3JoinColumn[] fkJoinColumns,
 			final Ejb3JoinColumn[] keyColumns,
 			final Ejb3JoinColumn[] inverseColumns,
 			final Ejb3Column[] elementColumns,
 			final Ejb3Column[] mapKeyColumns,
 			final Ejb3JoinColumn[] mapKeyManyToManyColumns,
 			final boolean isEmbedded,
 			final XProperty property,
 			final XClass collType,
 			final boolean ignoreNotFound,
 			final boolean unique,
 			final TableBinder assocTableBinder,
 			final MetadataBuildingContext buildingContext) {
 		return new CollectionSecondPass( buildingContext, collection ) {
 			@Override
             public void secondPass(java.util.Map persistentClasses, java.util.Map inheritedMetas) throws MappingException {
 				bindStarToManySecondPass(
 						persistentClasses,
 						collType,
 						fkJoinColumns,
 						keyColumns,
 						inverseColumns,
 						elementColumns,
 						isEmbedded,
 						property,
 						unique,
 						assocTableBinder,
 						ignoreNotFound,
 						buildingContext
 				);
 			}
 		};
 	}
 
 	/**
 	 * return true if it's a Fk, false if it's an association table
 	 */
 	protected boolean bindStarToManySecondPass(
 			Map persistentClasses,
 			XClass collType,
 			Ejb3JoinColumn[] fkJoinColumns,
 			Ejb3JoinColumn[] keyColumns,
 			Ejb3JoinColumn[] inverseColumns,
 			Ejb3Column[] elementColumns,
 			boolean isEmbedded,
 			XProperty property,
 			boolean unique,
 			TableBinder associationTableBinder,
 			boolean ignoreNotFound,
 			MetadataBuildingContext buildingContext) {
 		PersistentClass persistentClass = (PersistentClass) persistentClasses.get( collType.getName() );
 		boolean reversePropertyInJoin = false;
 		if ( persistentClass != null && StringHelper.isNotEmpty( this.mappedBy ) ) {
 			try {
 				reversePropertyInJoin = 0 != persistentClass.getJoinNumber(
 						persistentClass.getRecursiveProperty( this.mappedBy )
 				);
 			}
 			catch (MappingException e) {
 				StringBuilder error = new StringBuilder( 80 );
 				error.append( "mappedBy reference an unknown target entity property: " )
 						.append( collType ).append( "." ).append( this.mappedBy )
 						.append( " in " )
 						.append( collection.getOwnerEntityName() )
 						.append( "." )
 						.append( property.getName() );
 				throw new AnnotationException( error.toString() );
 			}
 		}
 		if ( persistentClass != null
 				&& !reversePropertyInJoin
 				&& oneToMany
 				&& !this.isExplicitAssociationTable
 				&& ( joinColumns[0].isImplicit() && !BinderHelper.isEmptyAnnotationValue( this.mappedBy ) //implicit @JoinColumn
 				|| !fkJoinColumns[0].isImplicit() ) //this is an explicit @JoinColumn
 				) {
 			//this is a Foreign key
 			bindOneToManySecondPass(
 					getCollection(),
 					persistentClasses,
 					fkJoinColumns,
 					collType,
 					cascadeDeleteEnabled,
 					ignoreNotFound,
 					buildingContext,
 					inheritanceStatePerClass
 			);
 			return true;
 		}
 		else {
 			//this is an association table
 			bindManyToManySecondPass(
 					this.collection,
 					persistentClasses,
 					keyColumns,
 					inverseColumns,
 					elementColumns,
 					isEmbedded, collType,
 					ignoreNotFound, unique,
 					cascadeDeleteEnabled,
 					associationTableBinder,
 					property,
 					propertyHolder,
 					buildingContext
 			);
 			return false;
 		}
 	}
 
 	protected void bindOneToManySecondPass(
 			Collection collection,
 			Map persistentClasses,
 			Ejb3JoinColumn[] fkJoinColumns,
 			XClass collectionType,
 			boolean cascadeDeleteEnabled,
 			boolean ignoreNotFound,
 			MetadataBuildingContext buildingContext,
 			Map<XClass, InheritanceState> inheritanceStatePerClass) {
 
 		final boolean debugEnabled = LOG.isDebugEnabled();
 		if ( debugEnabled ) {
 			LOG.debugf( "Binding a OneToMany: %s.%s through a foreign key", propertyHolder.getEntityName(), propertyName );
 		}
 		org.hibernate.mapping.OneToMany oneToMany = new org.hibernate.mapping.OneToMany( buildingContext.getMetadataCollector(), collection.getOwner() );
 		collection.setElement( oneToMany );
 		oneToMany.setReferencedEntityName( collectionType.getName() );
 		oneToMany.setIgnoreNotFound( ignoreNotFound );
 
 		String assocClass = oneToMany.getReferencedEntityName();
 		PersistentClass associatedClass = (PersistentClass) persistentClasses.get( assocClass );
 		if ( jpaOrderBy != null ) {
 			final String orderByFragment = buildOrderByClauseFromHql(
 					jpaOrderBy.value(),
 					associatedClass,
 					collection.getRole()
 			);
 			if ( StringHelper.isNotEmpty( orderByFragment ) ) {
 				collection.setOrderBy( orderByFragment );
 			}
 		}
 
 		if ( buildingContext == null ) {
 			throw new AssertionFailure(
 					"CollectionSecondPass for oneToMany should not be called with null mappings"
 			);
 		}
 		Map<String, Join> joins = buildingContext.getMetadataCollector().getJoins( assocClass );
 		if ( associatedClass == null ) {
 			throw new MappingException(
 					"Association references unmapped class: " + assocClass
 			);
 		}
 		oneToMany.setAssociatedClass( associatedClass );
 		for (Ejb3JoinColumn column : fkJoinColumns) {
 			column.setPersistentClass( associatedClass, joins, inheritanceStatePerClass );
 			column.setJoins( joins );
 			collection.setCollectionTable( column.getTable() );
 		}
 		if ( debugEnabled ) {
 			LOG.debugf( "Mapping collection: %s -> %s", collection.getRole(), collection.getCollectionTable().getName() );
 		}
 		bindFilters( false );
 		bindCollectionSecondPass( collection, null, fkJoinColumns, cascadeDeleteEnabled, property, buildingContext );
 		if ( !collection.isInverse()
 				&& !collection.getKey().isNullable() ) {
 			// for non-inverse one-to-many, with a not-null fk, add a backref!
 			String entityName = oneToMany.getReferencedEntityName();
 			PersistentClass referenced = buildingContext.getMetadataCollector().getEntityBinding( entityName );
 			Backref prop = new Backref();
 			prop.setName( '_' + fkJoinColumns[0].getPropertyName() + '_' + fkJoinColumns[0].getLogicalColumnName() + "Backref" );
 			prop.setUpdateable( false );
 			prop.setSelectable( false );
 			prop.setCollectionRole( collection.getRole() );
 			prop.setEntityName( collection.getOwner().getEntityName() );
 			prop.setValue( collection.getKey() );
 			referenced.addProperty( prop );
 		}
 	}
 
 
 	private void bindFilters(boolean hasAssociationTable) {
 		Filter simpleFilter = property.getAnnotation( Filter.class );
 		//set filtering
 		//test incompatible choices
 		//if ( StringHelper.isNotEmpty( where ) ) collection.setWhere( where );
 		if ( simpleFilter != null ) {
 			if ( hasAssociationTable ) {
 				collection.addManyToManyFilter(simpleFilter.name(), getCondition(simpleFilter), simpleFilter.deduceAliasInjectionPoints(),
 						toAliasTableMap(simpleFilter.aliases()), toAliasEntityMap(simpleFilter.aliases()));
 			}
 			else {
 				collection.addFilter(simpleFilter.name(), getCondition(simpleFilter), simpleFilter.deduceAliasInjectionPoints(),
 						toAliasTableMap(simpleFilter.aliases()), toAliasEntityMap(simpleFilter.aliases()));
 			}
 		}
 		Filters filters = property.getAnnotation( Filters.class );
 		if ( filters != null ) {
 			for (Filter filter : filters.value()) {
 				if ( hasAssociationTable ) {
 					collection.addManyToManyFilter( filter.name(), getCondition(filter), filter.deduceAliasInjectionPoints(),
 							toAliasTableMap(filter.aliases()), toAliasEntityMap(filter.aliases()));
 				}
 				else {
 					collection.addFilter(filter.name(), getCondition(filter), filter.deduceAliasInjectionPoints(),
 							toAliasTableMap(filter.aliases()), toAliasEntityMap(filter.aliases()));
 				}
 			}
 		}
 		FilterJoinTable simpleFilterJoinTable = property.getAnnotation( FilterJoinTable.class );
 		if ( simpleFilterJoinTable != null ) {
 			if ( hasAssociationTable ) {
 				collection.addFilter(simpleFilterJoinTable.name(), simpleFilterJoinTable.condition(), 
 						simpleFilterJoinTable.deduceAliasInjectionPoints(), 
 						toAliasTableMap(simpleFilterJoinTable.aliases()), toAliasEntityMap(simpleFilterJoinTable.aliases()));
 					}
 			else {
 				throw new AnnotationException(
 						"Illegal use of @FilterJoinTable on an association without join table:"
 								+ StringHelper.qualify( propertyHolder.getPath(), propertyName )
 				);
 			}
 		}
 		FilterJoinTables filterJoinTables = property.getAnnotation( FilterJoinTables.class );
 		if ( filterJoinTables != null ) {
 			for (FilterJoinTable filter : filterJoinTables.value()) {
 				if ( hasAssociationTable ) {
 					collection.addFilter(filter.name(), filter.condition(), 
 							filter.deduceAliasInjectionPoints(), 
 							toAliasTableMap(filter.aliases()), toAliasEntityMap(filter.aliases()));
 				}
 				else {
 					throw new AnnotationException(
 							"Illegal use of @FilterJoinTable on an association without join table:"
 									+ StringHelper.qualify( propertyHolder.getPath(), propertyName )
 					);
 				}
 			}
 		}
 
 		Where where = property.getAnnotation( Where.class );
 		String whereClause = where == null ? null : where.clause();
 		if ( StringHelper.isNotEmpty( whereClause ) ) {
 			if ( hasAssociationTable ) {
 				collection.setManyToManyWhere( whereClause );
 			}
 			else {
 				collection.setWhere( whereClause );
 			}
 		}
 
 		WhereJoinTable whereJoinTable = property.getAnnotation( WhereJoinTable.class );
 		String whereJoinTableClause = whereJoinTable == null ? null : whereJoinTable.clause();
 		if ( StringHelper.isNotEmpty( whereJoinTableClause ) ) {
 			if ( hasAssociationTable ) {
 				collection.setWhere( whereJoinTableClause );
 			}
 			else {
 				throw new AnnotationException(
 						"Illegal use of @WhereJoinTable on an association without join table:"
 								+ StringHelper.qualify( propertyHolder.getPath(), propertyName )
 				);
 			}
 		}
 //		This cannot happen in annotations since the second fetch is hardcoded to join
 //		if ( ( ! collection.getManyToManyFilterMap().isEmpty() || collection.getManyToManyWhere() != null ) &&
 //		        collection.getFetchMode() == FetchMode.JOIN &&
 //		        collection.getElement().getFetchMode() != FetchMode.JOIN ) {
 //			throw new MappingException(
 //			        "association with join table  defining filter or where without join fetching " +
 //			        "not valid within collection using join fetching [" + collection.getRole() + "]"
 //				);
 //		}
 	}
 	
 	private String getCondition(FilterJoinTable filter) {
 		//set filtering
 		String name = filter.name();
 		String cond = filter.condition();
 		return getCondition( cond, name );
 	}
 	
 	private String getCondition(Filter filter) {
 		//set filtering
 		String name = filter.name();
 		String cond = filter.condition();
 		return getCondition( cond, name );
 	}
 
 	private String getCondition(String cond, String name) {
 		if ( BinderHelper.isEmptyAnnotationValue( cond ) ) {
 			cond = buildingContext.getMetadataCollector().getFilterDefinition( name ).getDefaultFilterCondition();
 			if ( StringHelper.isEmpty( cond ) ) {
 				throw new AnnotationException(
 						"no filter condition found for filter " + name + " in "
 								+ StringHelper.qualify( propertyHolder.getPath(), propertyName )
 				);
 			}
 		}
 		return cond;
 	}
 
 	public void setCache(Cache cacheAnn) {
 		if ( cacheAnn != null ) {
 			cacheRegionName = BinderHelper.isEmptyAnnotationValue( cacheAnn.region() ) ? null : cacheAnn.region();
 			cacheConcurrencyStrategy = EntityBinder.getCacheConcurrencyStrategy( cacheAnn.usage() );
 		}
 		else {
 			cacheConcurrencyStrategy = null;
 			cacheRegionName = null;
 		}
 	}
 
 	public void setOneToMany(boolean oneToMany) {
 		this.oneToMany = oneToMany;
 	}
 
 	public void setIndexColumn(IndexColumn indexColumn) {
 		this.indexColumn = indexColumn;
 	}
 
 	public void setMapKey(MapKey key) {
 		if ( key != null ) {
 			mapKeyPropertyName = key.name();
 		}
 	}
 
 	private static String buildOrderByClauseFromHql(String orderByFragment, PersistentClass associatedClass, String role) {
 		if ( orderByFragment != null ) {
 			if ( orderByFragment.length() == 0 ) {
 				//order by id
 				return "id asc";
 			}
 			else if ( "desc".equals( orderByFragment ) ) {
 				return "id desc";
 			}
 		}
 		return orderByFragment;
 	}
 
 	private static String adjustUserSuppliedValueCollectionOrderingFragment(String orderByFragment) {
 		if ( orderByFragment != null ) {
 			// NOTE: "$element$" is a specially recognized collection property recognized by the collection persister
 			if ( orderByFragment.length() == 0 ) {
 				//order by element
 				return "$element$ asc";
 			}
 			else if ( "desc".equals( orderByFragment ) ) {
 				return "$element$ desc";
 			}
 		}
 		return orderByFragment;
 	}
 
 	private static SimpleValue buildCollectionKey(
 			Collection collValue,
 			Ejb3JoinColumn[] joinColumns,
 			boolean cascadeDeleteEnabled,
 			XProperty property,
 			MetadataBuildingContext buildingContext) {
 		//binding key reference using column
 		KeyValue keyVal;
 		//give a chance to override the referenced property name
 		//has to do that here because the referencedProperty creation happens in a FKSecondPass for Many to one yuk!
 		if ( joinColumns.length > 0 && StringHelper.isNotEmpty( joinColumns[0].getMappedBy() ) ) {
 			String entityName = joinColumns[0].getManyToManyOwnerSideEntityName() != null ?
 					"inverse__" + joinColumns[0].getManyToManyOwnerSideEntityName() :
 					joinColumns[0].getPropertyHolder().getEntityName();
 			String propRef = buildingContext.getMetadataCollector().getPropertyReferencedAssociation(
 					entityName,
 					joinColumns[0].getMappedBy()
 			);
 			if ( propRef != null ) {
 				collValue.setReferencedPropertyName( propRef );
 				buildingContext.getMetadataCollector().addPropertyReference( collValue.getOwnerEntityName(), propRef );
 			}
 		}
 		String propRef = collValue.getReferencedPropertyName();
 		if ( propRef == null ) {
 			keyVal = collValue.getOwner().getIdentifier();
 		}
 		else {
 			keyVal = (KeyValue) collValue.getOwner()
 					.getReferencedProperty( propRef )
 					.getValue();
 		}
 		DependantValue key = new DependantValue( buildingContext.getMetadataCollector(), collValue.getCollectionTable(), keyVal );
 		key.setTypeName( null );
 		Ejb3Column.checkPropertyConsistency( joinColumns, collValue.getOwnerEntityName() );
 		key.setNullable( joinColumns.length == 0 || joinColumns[0].isNullable() );
 		key.setUpdateable( joinColumns.length == 0 || joinColumns[0].isUpdatable() );
 		key.setCascadeDeleteEnabled( cascadeDeleteEnabled );
 		collValue.setKey( key );
 
 		if ( property != null ) {
 			final ForeignKey fk = property.getAnnotation( ForeignKey.class );
 			if ( fk != null && !BinderHelper.isEmptyAnnotationValue( fk.name() ) ) {
 				key.setForeignKeyName( fk.name() );
 			}
 			else {
 				final CollectionTable collectionTableAnn = property.getAnnotation( CollectionTable.class );
 				if ( collectionTableAnn != null ) {
 					if ( collectionTableAnn.foreignKey().value() == ConstraintMode.NO_CONSTRAINT ) {
 						key.setForeignKeyName( "none" );
 					}
 					else {
 						key.setForeignKeyName( StringHelper.nullIfEmpty( collectionTableAnn.foreignKey().name() ) );
 					}
 				}
 				else {
 					final JoinTable joinTableAnn = property.getAnnotation( JoinTable.class );
 					if ( joinTableAnn != null ) {
 						if ( joinTableAnn.foreignKey().value() == ConstraintMode.NO_CONSTRAINT ) {
 							key.setForeignKeyName( "none" );
 						}
 						else {
 							key.setForeignKeyName( StringHelper.nullIfEmpty( joinTableAnn.foreignKey().name() ) );
 
 						}
 					}
 				}
 			}
 		}
 
 		return key;
 	}
 
 	protected void bindManyToManySecondPass(
 			Collection collValue,
 			Map persistentClasses,
 			Ejb3JoinColumn[] joinColumns,
 			Ejb3JoinColumn[] inverseJoinColumns,
 			Ejb3Column[] elementColumns,
 			boolean isEmbedded,
 			XClass collType,
 			boolean ignoreNotFound, boolean unique,
 			boolean cascadeDeleteEnabled,
 			TableBinder associationTableBinder,
 			XProperty property,
 			PropertyHolder parentPropertyHolder,
 			MetadataBuildingContext buildingContext) throws MappingException {
 		if ( property == null ) {
 			throw new IllegalArgumentException( "null was passed for argument property" );
 		}
 
 		final PersistentClass collectionEntity = (PersistentClass) persistentClasses.get( collType.getName() );
 		final String hqlOrderBy = extractHqlOrderBy( jpaOrderBy );
 
 		boolean isCollectionOfEntities = collectionEntity != null;
 		ManyToAny anyAnn = property.getAnnotation( ManyToAny.class );
         if ( LOG.isDebugEnabled() ) {
 			String path = collValue.getOwnerEntityName() + "." + joinColumns[0].getPropertyName();
             if ( isCollectionOfEntities && unique ) {
 				LOG.debugf("Binding a OneToMany: %s through an association table", path);
 			}
             else if (isCollectionOfEntities) {
 				LOG.debugf("Binding as ManyToMany: %s", path);
 			}
             else if (anyAnn != null) {
 				LOG.debugf("Binding a ManyToAny: %s", path);
 			}
             else {
 				LOG.debugf("Binding a collection of element: %s", path);
 			}
 		}
 		//check for user error
 		if ( !isCollectionOfEntities ) {
 			if ( property.isAnnotationPresent( ManyToMany.class ) || property.isAnnotationPresent( OneToMany.class ) ) {
 				String path = collValue.getOwnerEntityName() + "." + joinColumns[0].getPropertyName();
 				throw new AnnotationException(
 						"Use of @OneToMany or @ManyToMany targeting an unmapped class: " + path + "[" + collType + "]"
 				);
 			}
 			else if ( anyAnn != null ) {
 				if ( parentPropertyHolder.getJoinTable( property ) == null ) {
 					String path = collValue.getOwnerEntityName() + "." + joinColumns[0].getPropertyName();
 					throw new AnnotationException(
 							"@JoinTable is mandatory when @ManyToAny is used: " + path
 					);
 				}
 			}
 			else {
 				JoinTable joinTableAnn = parentPropertyHolder.getJoinTable( property );
 				if ( joinTableAnn != null && joinTableAnn.inverseJoinColumns().length > 0 ) {
 					String path = collValue.getOwnerEntityName() + "." + joinColumns[0].getPropertyName();
 					throw new AnnotationException(
 							"Use of @JoinTable.inverseJoinColumns targeting an unmapped class: " + path + "[" + collType + "]"
 					);
 				}
 			}
 		}
 
 		boolean mappedBy = !BinderHelper.isEmptyAnnotationValue( joinColumns[0].getMappedBy() );
 		if ( mappedBy ) {
 			if ( !isCollectionOfEntities ) {
 				StringBuilder error = new StringBuilder( 80 )
 						.append(
 								"Collection of elements must not have mappedBy or association reference an unmapped entity: "
 						)
 						.append( collValue.getOwnerEntityName() )
 						.append( "." )
 						.append( joinColumns[0].getPropertyName() );
 				throw new AnnotationException( error.toString() );
 			}
 			Property otherSideProperty;
 			try {
 				otherSideProperty = collectionEntity.getRecursiveProperty( joinColumns[0].getMappedBy() );
 			}
 			catch (MappingException e) {
 				throw new AnnotationException(
 						"mappedBy reference an unknown target entity property: "
 								+ collType + "." + joinColumns[0].getMappedBy() + " in "
 								+ collValue.getOwnerEntityName() + "." + joinColumns[0].getPropertyName()
 				);
 			}
 			Table table;
 			if ( otherSideProperty.getValue() instanceof Collection ) {
 				//this is a collection on the other side
 				table = ( (Collection) otherSideProperty.getValue() ).getCollectionTable();
 			}
 			else {
 				//This is a ToOne with a @JoinTable or a regular property
 				table = otherSideProperty.getValue().getTable();
 			}
 			collValue.setCollectionTable( table );
 			String entityName = collectionEntity.getEntityName();
 			for (Ejb3JoinColumn column : joinColumns) {
 				//column.setDefaultColumnHeader( joinColumns[0].getMappedBy() ); //seems not to be used, make sense
 				column.setManyToManyOwnerSideEntityName( entityName );
 			}
 		}
 		else {
 			//TODO: only for implicit columns?
 			//FIXME NamingStrategy
 			for (Ejb3JoinColumn column : joinColumns) {
 				String mappedByProperty = buildingContext.getMetadataCollector().getFromMappedBy(
 						collValue.getOwnerEntityName(), column.getPropertyName()
 				);
 				Table ownerTable = collValue.getOwner().getTable();
 				column.setMappedBy(
 						collValue.getOwner().getEntityName(),
 						collValue.getOwner().getJpaEntityName(),
 						buildingContext.getMetadataCollector().getLogicalTableName( ownerTable ),
 						mappedByProperty
 				);
 //				String header = ( mappedByProperty == null ) ? mappings.getLogicalTableName( ownerTable ) : mappedByProperty;
 //				column.setDefaultColumnHeader( header );
 			}
 			if ( StringHelper.isEmpty( associationTableBinder.getName() ) ) {
 				//default value
 				associationTableBinder.setDefaultName(
 						collValue.getOwner().getClassName(),
 						collValue.getOwner().getEntityName(),
 						collValue.getOwner().getJpaEntityName(),
 						buildingContext.getMetadataCollector().getLogicalTableName( collValue.getOwner().getTable() ),
 						collectionEntity != null ? collectionEntity.getClassName() : null,
 						collectionEntity != null ? collectionEntity.getEntityName() : null,
 						collectionEntity != null ? collectionEntity.getJpaEntityName() : null,
 						collectionEntity != null ? buildingContext.getMetadataCollector().getLogicalTableName(
 								collectionEntity.getTable()
 						) : null,
 						joinColumns[0].getPropertyName()
 				);
 			}
 			associationTableBinder.setJPA2ElementCollection( !isCollectionOfEntities && property.isAnnotationPresent( ElementCollection.class ));
 			collValue.setCollectionTable( associationTableBinder.bind() );
 		}
 		bindFilters( isCollectionOfEntities );
 		bindCollectionSecondPass( collValue, collectionEntity, joinColumns, cascadeDeleteEnabled, property, buildingContext );
 
 		ManyToOne element = null;
 		if ( isCollectionOfEntities ) {
 			element = new ManyToOne( buildingContext.getMetadataCollector(),  collValue.getCollectionTable() );
 			collValue.setElement( element );
 			element.setReferencedEntityName( collType.getName() );
 			//element.setFetchMode( fetchMode );
 			//element.setLazy( fetchMode != FetchMode.JOIN );
 			//make the second join non lazy
 			element.setFetchMode( FetchMode.JOIN );
 			element.setLazy( false );
 			element.setIgnoreNotFound( ignoreNotFound );
 			// as per 11.1.38 of JPA 2.0 spec, default to primary key if no column is specified by @OrderBy.
 			if ( hqlOrderBy != null ) {
 				collValue.setManyToManyOrdering(
 						buildOrderByClauseFromHql( hqlOrderBy, collectionEntity, collValue.getRole() )
 				);
 			}
 
 			final ForeignKey fk = property.getAnnotation( ForeignKey.class );
 			if ( fk != null && !BinderHelper.isEmptyAnnotationValue( fk.name() ) ) {
 				element.setForeignKeyName( fk.name() );
 			}
 			else {
 				final JoinTable joinTableAnn = property.getAnnotation( JoinTable.class );
 				if ( joinTableAnn != null ) {
 					if ( joinTableAnn.foreignKey().value() == ConstraintMode.NO_CONSTRAINT ) {
 						element.setForeignKeyName( "none" );
 					}
 					else {
 						element.setForeignKeyName( StringHelper.nullIfEmpty( joinTableAnn.inverseForeignKey().name() ) );
 					}
 				}
 			}
 		}
 		else if ( anyAnn != null ) {
 			//@ManyToAny
 			//Make sure that collTyp is never used during the @ManyToAny branch: it will be set to void.class
 			PropertyData inferredData = new PropertyInferredData(null, property, "unsupported", buildingContext.getBuildingOptions().getReflectionManager() );
 			//override the table
 			for (Ejb3Column column : inverseJoinColumns) {
 				column.setTable( collValue.getCollectionTable() );
 			}
 			Any any = BinderHelper.buildAnyValue(
 					anyAnn.metaDef(),
 					inverseJoinColumns,
 					anyAnn.metaColumn(),
 					inferredData,
 					cascadeDeleteEnabled,
 					Nullability.NO_CONSTRAINT,
 					propertyHolder,
 					new EntityBinder(),
 					true,
 					buildingContext
 			);
 			collValue.setElement( any );
 		}
 		else {
 			XClass elementClass;
 			AnnotatedClassType classType;
 
 			CollectionPropertyHolder holder = null;
 			if ( BinderHelper.PRIMITIVE_NAMES.contains( collType.getName() ) ) {
 				classType = AnnotatedClassType.NONE;
 				elementClass = null;
 
 				holder = PropertyHolderBuilder.buildPropertyHolder(
 						collValue,
 						collValue.getRole(),
 						null,
 						property,
 						parentPropertyHolder,
 						buildingContext
 				);
 			}
 			else {
 				elementClass = collType;
 				classType = buildingContext.getMetadataCollector().getClassType( elementClass );
 
 				holder = PropertyHolderBuilder.buildPropertyHolder(
 						collValue,
 						collValue.getRole(),
 						elementClass,
 						property,
 						parentPropertyHolder,
 						buildingContext
 				);
 
 				// 'parentPropertyHolder' is the PropertyHolder for the owner of the collection
 				// 'holder' is the CollectionPropertyHolder.
 				// 'property' is the collection XProperty
 				parentPropertyHolder.startingProperty( property );
 
 				//force in case of attribute override
 				boolean attributeOverride = property.isAnnotationPresent( AttributeOverride.class )
 						|| property.isAnnotationPresent( AttributeOverrides.class );
 				// todo : force in the case of Convert annotation(s) with embedded paths (beyond key/value prefixes)?
 				if ( isEmbedded || attributeOverride ) {
 					classType = AnnotatedClassType.EMBEDDABLE;
 				}
 			}
 
 			if ( AnnotatedClassType.EMBEDDABLE.equals( classType ) ) {
 				EntityBinder entityBinder = new EntityBinder();
 				PersistentClass owner = collValue.getOwner();
 				boolean isPropertyAnnotated;
 				//FIXME support @Access for collection of elements
 				//String accessType = access != null ? access.value() : null;
 				if ( owner.getIdentifierProperty() != null ) {
 					isPropertyAnnotated = owner.getIdentifierProperty().getPropertyAccessorName().equals( "property" );
 				}
 				else if ( owner.getIdentifierMapper() != null && owner.getIdentifierMapper().getPropertySpan() > 0 ) {
 					Property prop = (Property) owner.getIdentifierMapper().getPropertyIterator().next();
 					isPropertyAnnotated = prop.getPropertyAccessorName().equals( "property" );
 				}
 				else {
 					throw new AssertionFailure( "Unable to guess collection property accessor name" );
 				}
 
 				PropertyData inferredData;
 				if ( isMap() ) {
 					//"value" is the JPA 2 prefix for map values (used to be "element")
 					if ( isHibernateExtensionMapping() ) {
 						inferredData = new PropertyPreloadedData( AccessType.PROPERTY, "element", elementClass );
 					}
 					else {
 						inferredData = new PropertyPreloadedData( AccessType.PROPERTY, "value", elementClass );
 					}
 				}
 				else {
 					if ( isHibernateExtensionMapping() ) {
 						inferredData = new PropertyPreloadedData( AccessType.PROPERTY, "element", elementClass );
 					}
 					else {
 						//"collection&&element" is not a valid property name => placeholder
 						inferredData = new PropertyPreloadedData( AccessType.PROPERTY, "collection&&element", elementClass );
 					}
 				}
 				//TODO be smart with isNullable
 				boolean isNullable = true;
 				Component component = AnnotationBinder.fillComponent(
 						holder,
 						inferredData,
 						isPropertyAnnotated ? AccessType.PROPERTY : AccessType.FIELD,
 						isNullable,
 						entityBinder,
 						false,
 						false,
 						true,
 						buildingContext,
 						inheritanceStatePerClass
 				);
 
 				collValue.setElement( component );
 
 				if ( StringHelper.isNotEmpty( hqlOrderBy ) ) {
 					String path = collValue.getOwnerEntityName() + "." + joinColumns[0].getPropertyName();
 					String orderBy = adjustUserSuppliedValueCollectionOrderingFragment( hqlOrderBy );
 					if ( orderBy != null ) {
 						collValue.setOrderBy( orderBy );
 					}
 				}
 			}
 			else {
 				holder.prepare( property );
 
 				SimpleValueBinder elementBinder = new SimpleValueBinder();
 				elementBinder.setBuildingContext( buildingContext );
 				elementBinder.setReturnedClassName( collType.getName() );
 				if ( elementColumns == null || elementColumns.length == 0 ) {
 					elementColumns = new Ejb3Column[1];
 					Ejb3Column column = new Ejb3Column();
 					column.setImplicit( false );
 					//not following the spec but more clean
 					column.setNullable( true );
 					column.setLength( Ejb3Column.DEFAULT_COLUMN_LENGTH );
 					column.setLogicalColumnName( Collection.DEFAULT_ELEMENT_COLUMN_NAME );
 					//TODO create an EMPTY_JOINS collection
 					column.setJoins( new HashMap<String, Join>() );
 					column.setBuildingContext( buildingContext );
 					column.bind();
 					elementColumns[0] = column;
 				}
 				//override the table
 				for (Ejb3Column column : elementColumns) {
 					column.setTable( collValue.getCollectionTable() );
 				}
 				elementBinder.setColumns( elementColumns );
 				elementBinder.setType(
 						property,
 						elementClass,
 						collValue.getOwnerEntityName(),
 						holder.resolveElementAttributeConverterDefinition( elementClass )
 				);
 				elementBinder.setPersistentClassName( propertyHolder.getEntityName() );
 				elementBinder.setAccessType( accessType );
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
index a58bc593bf..f8fc843a5d 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
@@ -1,1189 +1,1190 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Locale;
 import javax.persistence.Access;
 import javax.persistence.ConstraintMode;
 import javax.persistence.Entity;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinTable;
 import javax.persistence.NamedEntityGraph;
 import javax.persistence.NamedEntityGraphs;
 import javax.persistence.PrimaryKeyJoinColumn;
 import javax.persistence.SecondaryTable;
 import javax.persistence.SecondaryTables;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.BatchSize;
 import org.hibernate.annotations.Cache;
 import org.hibernate.annotations.CacheConcurrencyStrategy;
 import org.hibernate.annotations.DynamicInsert;
 import org.hibernate.annotations.DynamicUpdate;
 import org.hibernate.annotations.FetchMode;
 import org.hibernate.annotations.Filter;
 import org.hibernate.annotations.Immutable;
 import org.hibernate.annotations.Loader;
 import org.hibernate.annotations.NaturalIdCache;
 import org.hibernate.annotations.OptimisticLockType;
 import org.hibernate.annotations.OptimisticLocking;
 import org.hibernate.annotations.Persister;
 import org.hibernate.annotations.Polymorphism;
 import org.hibernate.annotations.PolymorphismType;
 import org.hibernate.annotations.Proxy;
 import org.hibernate.annotations.RowId;
 import org.hibernate.annotations.SQLDelete;
 import org.hibernate.annotations.SQLDeleteAll;
 import org.hibernate.annotations.SQLInsert;
 import org.hibernate.annotations.SQLUpdate;
 import org.hibernate.annotations.SelectBeforeUpdate;
 import org.hibernate.annotations.Subselect;
 import org.hibernate.annotations.Synchronize;
 import org.hibernate.annotations.Tables;
 import org.hibernate.annotations.Tuplizer;
 import org.hibernate.annotations.Tuplizers;
 import org.hibernate.annotations.Where;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XAnnotatedElement;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.boot.model.naming.EntityNaming;
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.model.naming.ImplicitEntityNameSource;
 import org.hibernate.boot.model.naming.NamingStrategyHelper;
 import org.hibernate.boot.spi.InFlightMetadataCollector;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.cfg.AccessType;
 import org.hibernate.cfg.AnnotationBinder;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.Ejb3JoinColumn;
 import org.hibernate.cfg.InheritanceState;
 import org.hibernate.cfg.ObjectNameSource;
 import org.hibernate.cfg.PropertyHolder;
 import org.hibernate.cfg.UniqueConstraintHolder;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.FilterDefinition;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.SingleTableSubclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.TableOwner;
 import org.hibernate.mapping.Value;
 
 import org.jboss.logging.Logger;
 
 import static org.hibernate.cfg.BinderHelper.toAliasEntityMap;
 import static org.hibernate.cfg.BinderHelper.toAliasTableMap;
 
 
 /**
  * Stateful holder and processor for binding Entity information
  *
  * @author Emmanuel Bernard
  */
 public class EntityBinder {
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityBinder.class.getName());
     private static final String NATURAL_ID_CACHE_SUFFIX = "##NaturalId";
 
 	private MetadataBuildingContext context;
 
 	private String name;
 	private XClass annotatedClass;
 	private PersistentClass persistentClass;
 	private String discriminatorValue = "";
 	private Boolean forceDiscriminator;
 	private Boolean insertableDiscriminator;
 	private boolean dynamicInsert;
 	private boolean dynamicUpdate;
 	private boolean explicitHibernateEntityAnnotation;
 	private OptimisticLockType optimisticLockType;
 	private PolymorphismType polymorphismType;
 	private boolean selectBeforeUpdate;
 	private int batchSize;
 	private boolean lazy;
 	private XClass proxyClass;
 	private String where;
 	private java.util.Map<String, Join> secondaryTables = new HashMap<String, Join>();
 	private java.util.Map<String, Object> secondaryTableJoins = new HashMap<String, Object>();
 	private String cacheConcurrentStrategy;
 	private String cacheRegion;
 	private String naturalIdCacheRegion;
 	private List<Filter> filters = new ArrayList<Filter>();
 	private InheritanceState inheritanceState;
 	private boolean ignoreIdAnnotations;
 	private boolean cacheLazyProperty;
 	private AccessType propertyAccessType = AccessType.DEFAULT;
 	private boolean wrapIdsInEmbeddedComponents;
 	private String subselect;
 
 	public boolean wrapIdsInEmbeddedComponents() {
 		return wrapIdsInEmbeddedComponents;
 	}
 
 	/**
 	 * Use as a fake one for Collection of elements
 	 */
 	public EntityBinder() {
 	}
 
 	public EntityBinder(
 			Entity ejb3Ann,
 			org.hibernate.annotations.Entity hibAnn,
 			XClass annotatedClass,
 			PersistentClass persistentClass,
 			MetadataBuildingContext context) {
 		this.context = context;
 		this.persistentClass = persistentClass;
 		this.annotatedClass = annotatedClass;
 		bindEjb3Annotation( ejb3Ann );
 		bindHibernateAnnotation( hibAnn );
 	}
 
 
 	@SuppressWarnings("SimplifiableConditionalExpression")
 	private void bindHibernateAnnotation(org.hibernate.annotations.Entity hibAnn) {
 		{
 			final DynamicInsert dynamicInsertAnn = annotatedClass.getAnnotation( DynamicInsert.class );
 			this.dynamicInsert = dynamicInsertAnn == null
 					? ( hibAnn == null ? false : hibAnn.dynamicInsert() )
 					: dynamicInsertAnn.value();
 		}
 
 		{
 			final DynamicUpdate dynamicUpdateAnn = annotatedClass.getAnnotation( DynamicUpdate.class );
 			this.dynamicUpdate = dynamicUpdateAnn == null
 					? ( hibAnn == null ? false : hibAnn.dynamicUpdate() )
 					: dynamicUpdateAnn.value();
 		}
 
 		{
 			final SelectBeforeUpdate selectBeforeUpdateAnn = annotatedClass.getAnnotation( SelectBeforeUpdate.class );
 			this.selectBeforeUpdate = selectBeforeUpdateAnn == null
 					? ( hibAnn == null ? false : hibAnn.selectBeforeUpdate() )
 					: selectBeforeUpdateAnn.value();
 		}
 
 		{
 			final OptimisticLocking optimisticLockingAnn = annotatedClass.getAnnotation( OptimisticLocking.class );
 			this.optimisticLockType = optimisticLockingAnn == null
 					? ( hibAnn == null ? OptimisticLockType.VERSION : hibAnn.optimisticLock() )
 					: optimisticLockingAnn.type();
 		}
 
 		{
 			final Polymorphism polymorphismAnn = annotatedClass.getAnnotation( Polymorphism.class );
 			this.polymorphismType = polymorphismAnn == null
 					? ( hibAnn == null ? PolymorphismType.IMPLICIT : hibAnn.polymorphism() )
 					: polymorphismAnn.type();
 		}
 
 		if ( hibAnn != null ) {
 			// used later in bind for logging
 			explicitHibernateEntityAnnotation = true;
 			//persister handled in bind
 		}
 	}
 
 	private void bindEjb3Annotation(Entity ejb3Ann) {
 		if ( ejb3Ann == null ) throw new AssertionFailure( "@Entity should always be not null" );
 		if ( BinderHelper.isEmptyAnnotationValue( ejb3Ann.name() ) ) {
 			name = StringHelper.unqualify( annotatedClass.getName() );
 		}
 		else {
 			name = ejb3Ann.name();
 		}
 	}
 
 	public boolean isRootEntity() {
 		// This is the best option I can think of here since PersistentClass is most likely not yet fully populated
 		return persistentClass instanceof RootClass;
 	}
 
 	public void setDiscriminatorValue(String discriminatorValue) {
 		this.discriminatorValue = discriminatorValue;
 	}
 
 	public void setForceDiscriminator(boolean forceDiscriminator) {
 		this.forceDiscriminator = forceDiscriminator;
 	}
 
 	public void setInsertableDiscriminator(boolean insertableDiscriminator) {
 		this.insertableDiscriminator = insertableDiscriminator;
 	}
 
 	public void bindEntity() {
 		persistentClass.setAbstract( annotatedClass.isAbstract() );
 		persistentClass.setClassName( annotatedClass.getName() );
 		persistentClass.setNodeName( name );
 		persistentClass.setJpaEntityName(name);
 		//persistentClass.setDynamic(false); //no longer needed with the Entity name refactoring?
 		persistentClass.setEntityName( annotatedClass.getName() );
 		bindDiscriminatorValue();
 
 		persistentClass.setLazy( lazy );
 		if ( proxyClass != null ) {
 			persistentClass.setProxyInterfaceName( proxyClass.getName() );
 		}
 		persistentClass.setDynamicInsert( dynamicInsert );
 		persistentClass.setDynamicUpdate( dynamicUpdate );
 
 		if ( persistentClass instanceof RootClass ) {
 			RootClass rootClass = (RootClass) persistentClass;
 			boolean mutable = true;
 			//priority on @Immutable, then @Entity.mutable()
 			if ( annotatedClass.isAnnotationPresent( Immutable.class ) ) {
 				mutable = false;
 			}
 			else {
 				org.hibernate.annotations.Entity entityAnn =
 						annotatedClass.getAnnotation( org.hibernate.annotations.Entity.class );
 				if ( entityAnn != null ) {
 					mutable = entityAnn.mutable();
 				}
 			}
 			rootClass.setMutable( mutable );
 			rootClass.setExplicitPolymorphism( isExplicitPolymorphism( polymorphismType ) );
 			if ( StringHelper.isNotEmpty( where ) ) rootClass.setWhere( where );
 			if ( cacheConcurrentStrategy != null ) {
 				rootClass.setCacheConcurrencyStrategy( cacheConcurrentStrategy );
 				rootClass.setCacheRegionName( cacheRegion );
 				rootClass.setLazyPropertiesCacheable( cacheLazyProperty );
 			}
 			rootClass.setNaturalIdCacheRegionName( naturalIdCacheRegion );
 			boolean forceDiscriminatorInSelects = forceDiscriminator == null
 					? context.getBuildingOptions().shouldImplicitlyForceDiscriminatorInSelect()
 					: forceDiscriminator;
 			rootClass.setForceDiscriminator( forceDiscriminatorInSelects );
 			if( insertableDiscriminator != null) {
 				rootClass.setDiscriminatorInsertable( insertableDiscriminator );
 			}
 		}
 		else {
             if (explicitHibernateEntityAnnotation) {
 				LOG.entityAnnotationOnNonRoot(annotatedClass.getName());
 			}
             if (annotatedClass.isAnnotationPresent(Immutable.class)) {
 				LOG.immutableAnnotationOnNonRoot(annotatedClass.getName());
 			}
 		}
 		persistentClass.setOptimisticLockStyle( getVersioning( optimisticLockType ) );
 		persistentClass.setSelectBeforeUpdate( selectBeforeUpdate );
 
 		//set persister if needed
 		Persister persisterAnn = annotatedClass.getAnnotation( Persister.class );
 		Class persister = null;
 		if ( persisterAnn != null ) {
 			persister = persisterAnn.impl();
 		}
 		else {
 			org.hibernate.annotations.Entity entityAnn = annotatedClass.getAnnotation( org.hibernate.annotations.Entity.class );
 			if ( entityAnn != null && !BinderHelper.isEmptyAnnotationValue( entityAnn.persister() ) ) {
 				try {
 					persister = ReflectHelper.classForName( entityAnn.persister() );
 				}
 				catch (ClassNotFoundException cnfe) {
 					throw new AnnotationException( "Could not find persister class: " + persister );
 				}
 			}
 		}
 		if ( persister != null ) {
 			persistentClass.setEntityPersisterClass( persister );
 		}
 
 		persistentClass.setBatchSize( batchSize );
 
 		//SQL overriding
 		SQLInsert sqlInsert = annotatedClass.getAnnotation( SQLInsert.class );
 		SQLUpdate sqlUpdate = annotatedClass.getAnnotation( SQLUpdate.class );
 		SQLDelete sqlDelete = annotatedClass.getAnnotation( SQLDelete.class );
 		SQLDeleteAll sqlDeleteAll = annotatedClass.getAnnotation( SQLDeleteAll.class );
 		Loader loader = annotatedClass.getAnnotation( Loader.class );
 
 		if ( sqlInsert != null ) {
 			persistentClass.setCustomSQLInsert( sqlInsert.sql().trim(), sqlInsert.callable(),
-					ExecuteUpdateResultCheckStyle.fromExternalName( sqlInsert.check().toString().toLowerCase() )
+					ExecuteUpdateResultCheckStyle.fromExternalName( sqlInsert.check().toString().toLowerCase(Locale.ROOT) )
 			);
 
 		}
 		if ( sqlUpdate != null ) {
 			persistentClass.setCustomSQLUpdate( sqlUpdate.sql(), sqlUpdate.callable(),
-					ExecuteUpdateResultCheckStyle.fromExternalName( sqlUpdate.check().toString().toLowerCase() )
-			);
+					ExecuteUpdateResultCheckStyle.fromExternalName( sqlUpdate.check().toString().toLowerCase(Locale.ROOT) )
+			);Locale.ROOT
 		}
 		if ( sqlDelete != null ) {
 			persistentClass.setCustomSQLDelete( sqlDelete.sql(), sqlDelete.callable(),
-					ExecuteUpdateResultCheckStyle.fromExternalName( sqlDelete.check().toString().toLowerCase() )
+					ExecuteUpdateResultCheckStyle.fromExternalName( sqlDelete.check().toString().toLowerCase(Locale.ROOT) )
 			);
 		}
 		if ( sqlDeleteAll != null ) {
 			persistentClass.setCustomSQLDelete( sqlDeleteAll.sql(), sqlDeleteAll.callable(),
-					ExecuteUpdateResultCheckStyle.fromExternalName( sqlDeleteAll.check().toString().toLowerCase() )
+					ExecuteUpdateResultCheckStyle.fromExternalName( sqlDeleteAll.check().toString().toLowerCase(Locale.ROOT) )
 			);
 		}
 		if ( loader != null ) {
 			persistentClass.setLoaderName( loader.namedQuery() );
 		}
 
 		if ( annotatedClass.isAnnotationPresent( Synchronize.class )) {
 			Synchronize synchronizedWith = annotatedClass.getAnnotation(Synchronize.class);
 
 			String [] tables = synchronizedWith.value();
 			for (String table : tables) {
 				persistentClass.addSynchronizedTable(table);
 			}
 		}
 
 		if ( annotatedClass.isAnnotationPresent(Subselect.class )) {
 			Subselect subselect = annotatedClass.getAnnotation(Subselect.class);
 			this.subselect = subselect.value();
 		}
 
 		//tuplizers
 		if ( annotatedClass.isAnnotationPresent( Tuplizers.class ) ) {
 			for (Tuplizer tuplizer : annotatedClass.getAnnotation( Tuplizers.class ).value()) {
 				EntityMode mode = EntityMode.parse( tuplizer.entityMode() );
 				//todo tuplizer.entityModeType
 				persistentClass.addTuplizer( mode, tuplizer.impl().getName() );
 			}
 		}
 		if ( annotatedClass.isAnnotationPresent( Tuplizer.class ) ) {
 			Tuplizer tuplizer = annotatedClass.getAnnotation( Tuplizer.class );
 			EntityMode mode = EntityMode.parse( tuplizer.entityMode() );
 			//todo tuplizer.entityModeType
 			persistentClass.addTuplizer( mode, tuplizer.impl().getName() );
 		}
 
 		for ( Filter filter : filters ) {
 			String filterName = filter.name();
 			String cond = filter.condition();
 			if ( BinderHelper.isEmptyAnnotationValue( cond ) ) {
 				FilterDefinition definition = context.getMetadataCollector().getFilterDefinition( filterName );
 				cond = definition == null ? null : definition.getDefaultFilterCondition();
 				if ( StringHelper.isEmpty( cond ) ) {
 					throw new AnnotationException(
 							"no filter condition found for filter " + filterName + " in " + this.name
 					);
 				}
 			}
 			persistentClass.addFilter(filterName, cond, filter.deduceAliasInjectionPoints(), 
 					toAliasTableMap(filter.aliases()), toAliasEntityMap(filter.aliases()));
 		}
 		LOG.debugf( "Import with entity name %s", name );
 		try {
 			context.getMetadataCollector().addImport( name, persistentClass.getEntityName() );
 			String entityName = persistentClass.getEntityName();
 			if ( !entityName.equals( name ) ) {
 				context.getMetadataCollector().addImport( entityName, entityName );
 			}
 		}
 		catch (MappingException me) {
 			throw new AnnotationException( "Use of the same entity name twice: " + name, me );
 		}
 
 		processNamedEntityGraphs();
 	}
 
 	private void processNamedEntityGraphs() {
 		processNamedEntityGraph( annotatedClass.getAnnotation( NamedEntityGraph.class ) );
 		final NamedEntityGraphs graphs = annotatedClass.getAnnotation( NamedEntityGraphs.class );
 		if ( graphs != null ) {
 			for ( NamedEntityGraph graph : graphs.value() ) {
 				processNamedEntityGraph( graph );
 			}
 		}
 	}
 
 	private void processNamedEntityGraph(NamedEntityGraph annotation) {
 		if ( annotation == null ) {
 			return;
 		}
 		context.getMetadataCollector().addNamedEntityGraph(
 				new NamedEntityGraphDefinition( annotation, name, persistentClass.getEntityName() )
 		);
 	}
 	
 	public void bindDiscriminatorValue() {
 		if ( StringHelper.isEmpty( discriminatorValue ) ) {
 			Value discriminator = persistentClass.getDiscriminator();
 			if ( discriminator == null ) {
 				persistentClass.setDiscriminatorValue( name );
 			}
 			else if ( "character".equals( discriminator.getType().getName() ) ) {
 				throw new AnnotationException(
 						"Using default @DiscriminatorValue for a discriminator of type CHAR is not safe"
 				);
 			}
 			else if ( "integer".equals( discriminator.getType().getName() ) ) {
 				persistentClass.setDiscriminatorValue( String.valueOf( name.hashCode() ) );
 			}
 			else {
 				persistentClass.setDiscriminatorValue( name ); //Spec compliant
 			}
 		}
 		else {
 			//persistentClass.getDiscriminator()
 			persistentClass.setDiscriminatorValue( discriminatorValue );
 		}
 	}
 
 	OptimisticLockStyle getVersioning(OptimisticLockType type) {
 		switch ( type ) {
 			case VERSION:
 				return OptimisticLockStyle.VERSION;
 			case NONE:
 				return OptimisticLockStyle.NONE;
 			case DIRTY:
 				return OptimisticLockStyle.DIRTY;
 			case ALL:
 				return OptimisticLockStyle.ALL;
 			default:
 				throw new AssertionFailure( "optimistic locking not supported: " + type );
 		}
 	}
 
 	private boolean isExplicitPolymorphism(PolymorphismType type) {
 		switch ( type ) {
 			case IMPLICIT:
 				return false;
 			case EXPLICIT:
 				return true;
 			default:
 				throw new AssertionFailure( "Unknown polymorphism type: " + type );
 		}
 	}
 
 	public void setBatchSize(BatchSize sizeAnn) {
 		if ( sizeAnn != null ) {
 			batchSize = sizeAnn.size();
 		}
 		else {
 			batchSize = -1;
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void setProxy(Proxy proxy) {
 		if ( proxy != null ) {
 			lazy = proxy.lazy();
 			if ( !lazy ) {
 				proxyClass = null;
 			}
 			else {
 				final ReflectionManager reflectionManager = context.getBuildingOptions().getReflectionManager();
 				if ( AnnotationBinder.isDefault( reflectionManager.toXClass( proxy.proxyClass() ), context ) ) {
 					proxyClass = annotatedClass;
 				}
 				else {
 					proxyClass = reflectionManager.toXClass( proxy.proxyClass() );
 				}
 			}
 		}
 		else {
 			lazy = true; //needed to allow association lazy loading.
 			proxyClass = annotatedClass;
 		}
 	}
 
 	public void setWhere(Where whereAnn) {
 		if ( whereAnn != null ) {
 			where = whereAnn.clause();
 		}
 	}
 
 	public void setWrapIdsInEmbeddedComponents(boolean wrapIdsInEmbeddedComponents) {
 		this.wrapIdsInEmbeddedComponents = wrapIdsInEmbeddedComponents;
 	}
 
 
 	private static class EntityTableObjectNameSource implements ObjectNameSource {
 		private final String explicitName;
 		private final String logicalName;
 
 		private EntityTableObjectNameSource(String explicitName, String entityName) {
 			this.explicitName = explicitName;
 			this.logicalName = StringHelper.isNotEmpty( explicitName )
 					? explicitName
 					: StringHelper.unqualify( entityName );
 		}
 
 		public String getExplicitName() {
 			return explicitName;
 		}
 
 		public String getLogicalName() {
 			return logicalName;
 		}
 	}
 
 	private static class EntityTableNamingStrategyHelper implements NamingStrategyHelper {
 		private final String className;
 		private final String entityName;
 		private final String jpaEntityName;
 
 		private EntityTableNamingStrategyHelper(String className, String entityName, String jpaEntityName) {
 			this.className = className;
 			this.entityName = entityName;
 			this.jpaEntityName = jpaEntityName;
 		}
 
 		public Identifier determineImplicitName(final MetadataBuildingContext buildingContext) {
 			return buildingContext.getBuildingOptions().getImplicitNamingStrategy().determinePrimaryTableName(
 					new ImplicitEntityNameSource() {
 						private final EntityNaming entityNaming = new EntityNaming() {
 							@Override
 							public String getClassName() {
 								return className;
 							}
 
 							@Override
 							public String getEntityName() {
 								return entityName;
 							}
 
 							@Override
 							public String getJpaEntityName() {
 								return jpaEntityName;
 							}
 						};
 
 						@Override
 						public EntityNaming getEntityNaming() {
 							return entityNaming;
 						}
 
 						@Override
 						public MetadataBuildingContext getBuildingContext() {
 							return buildingContext;
 						}
 					}
 			);
 		}
 
 		@Override
 		public Identifier handleExplicitName(String explicitName, MetadataBuildingContext buildingContext) {
 			return buildingContext.getMetadataCollector()
 					.getDatabase()
 					.getJdbcEnvironment()
 					.getIdentifierHelper()
 					.toIdentifier( explicitName );
 		}
 
 		@Override
 		public Identifier toPhysicalName(Identifier logicalName, MetadataBuildingContext buildingContext) {
 			return buildingContext.getBuildingOptions().getPhysicalNamingStrategy().toPhysicalTableName(
 					logicalName,
 					buildingContext.getMetadataCollector().getDatabase().getJdbcEnvironment()
 			);
 		}
 	}
 
 	public void bindTableForDiscriminatedSubclass(InFlightMetadataCollector.EntityTableXref superTableXref) {
 		if ( !SingleTableSubclass.class.isInstance( persistentClass ) ) {
 			throw new AssertionFailure(
 					"Was expecting a discriminated subclass [" + SingleTableSubclass.class.getName() +
 							"] but found [" + persistentClass.getClass().getName() + "] for entity [" +
 							persistentClass.getEntityName() + "]"
 			);
 		}
 
 		context.getMetadataCollector().addEntityTableXref(
 				persistentClass.getEntityName(),
 				context.getMetadataCollector().getDatabase().toIdentifier(
 						context.getMetadataCollector().getLogicalTableName(
 								superTableXref.getPrimaryTable()
 						)
 				),
 				superTableXref.getPrimaryTable(),
 				superTableXref
 		);
 	}
 
 	public void bindTable(
 			String schema,
 			String catalog,
 			String tableName,
 			List<UniqueConstraintHolder> uniqueConstraints,
 			String constraints,
 			InFlightMetadataCollector.EntityTableXref denormalizedSuperTableXref) {
 		EntityTableNamingStrategyHelper namingStrategyHelper = new EntityTableNamingStrategyHelper(
 				persistentClass.getClassName(),
 				persistentClass.getEntityName(),
 				name
 		);
 
 		final Identifier logicalName;
 		if ( StringHelper.isNotEmpty( tableName ) ) {
 			logicalName = namingStrategyHelper.handleExplicitName( tableName, context );
 		}
 		else {
 			logicalName = namingStrategyHelper.determineImplicitName( context );
 		}
 
 		final Table table = TableBinder.buildAndFillTable(
 				schema,
 				catalog,
 				logicalName,
 				persistentClass.isAbstract(),
 				uniqueConstraints,
 				null,
 				constraints,
 				context,
 				this.subselect,
 				denormalizedSuperTableXref
 		);
 		final RowId rowId = annotatedClass.getAnnotation( RowId.class );
 		if ( rowId != null ) {
 			table.setRowId( rowId.value() );
 		}
 
 		context.getMetadataCollector().addEntityTableXref(
 				persistentClass.getEntityName(),
 				logicalName,
 				table,
 				denormalizedSuperTableXref
 		);
 
 		if ( persistentClass instanceof TableOwner ) {
 			LOG.debugf( "Bind entity %s on table %s", persistentClass.getEntityName(), table.getName() );
 			( (TableOwner) persistentClass ).setTable( table );
 		}
 		else {
 			throw new AssertionFailure( "binding a table for a subclass" );
 		}
 	}
 
 	public void finalSecondaryTableBinding(PropertyHolder propertyHolder) {
 		/*
 		 * Those operations has to be done after the id definition of the persistence class.
 		 * ie after the properties parsing
 		 */
 		Iterator joins = secondaryTables.values().iterator();
 		Iterator joinColumns = secondaryTableJoins.values().iterator();
 
 		while ( joins.hasNext() ) {
 			Object uncastedColumn = joinColumns.next();
 			Join join = (Join) joins.next();
 			createPrimaryColumnsToSecondaryTable( uncastedColumn, propertyHolder, join );
 		}
 		context.getMetadataCollector().addJoins( persistentClass, secondaryTables );
 	}
 
 	private void createPrimaryColumnsToSecondaryTable(Object uncastedColumn, PropertyHolder propertyHolder, Join join) {
 		Ejb3JoinColumn[] ejb3JoinColumns;
 		PrimaryKeyJoinColumn[] pkColumnsAnn = null;
 		JoinColumn[] joinColumnsAnn = null;
 		if ( uncastedColumn instanceof PrimaryKeyJoinColumn[] ) {
 			pkColumnsAnn = (PrimaryKeyJoinColumn[]) uncastedColumn;
 		}
 		if ( uncastedColumn instanceof JoinColumn[] ) {
 			joinColumnsAnn = (JoinColumn[]) uncastedColumn;
 		}
 		if ( pkColumnsAnn == null && joinColumnsAnn == null ) {
 			ejb3JoinColumns = new Ejb3JoinColumn[1];
 			ejb3JoinColumns[0] = Ejb3JoinColumn.buildJoinColumn(
 					null,
 					null,
 					persistentClass.getIdentifier(),
 					secondaryTables,
 					propertyHolder,
 					context
 			);
 		}
 		else {
 			int nbrOfJoinColumns = pkColumnsAnn != null ?
 					pkColumnsAnn.length :
 					joinColumnsAnn.length;
 			if ( nbrOfJoinColumns == 0 ) {
 				ejb3JoinColumns = new Ejb3JoinColumn[1];
 				ejb3JoinColumns[0] = Ejb3JoinColumn.buildJoinColumn(
 						null,
 						null,
 						persistentClass.getIdentifier(),
 						secondaryTables,
 						propertyHolder,
 						context
 				);
 			}
 			else {
 				ejb3JoinColumns = new Ejb3JoinColumn[nbrOfJoinColumns];
 				if ( pkColumnsAnn != null ) {
 					for (int colIndex = 0; colIndex < nbrOfJoinColumns; colIndex++) {
 						ejb3JoinColumns[colIndex] = Ejb3JoinColumn.buildJoinColumn(
 								pkColumnsAnn[colIndex],
 								null,
 								persistentClass.getIdentifier(),
 								secondaryTables,
 								propertyHolder,
 								context
 						);
 					}
 				}
 				else {
 					for (int colIndex = 0; colIndex < nbrOfJoinColumns; colIndex++) {
 						ejb3JoinColumns[colIndex] = Ejb3JoinColumn.buildJoinColumn(
 								null,
 								joinColumnsAnn[colIndex],
 								persistentClass.getIdentifier(),
 								secondaryTables,
 								propertyHolder,
 								context
 						);
 					}
 				}
 			}
 		}
 
 		for (Ejb3JoinColumn joinColumn : ejb3JoinColumns) {
 			joinColumn.forceNotNull();
 		}
 		bindJoinToPersistentClass( join, ejb3JoinColumns, context );
 	}
 
 	private void bindJoinToPersistentClass(Join join, Ejb3JoinColumn[] ejb3JoinColumns, MetadataBuildingContext buildingContext) {
 		SimpleValue key = new DependantValue( buildingContext.getMetadataCollector(), join.getTable(), persistentClass.getIdentifier() );
 		join.setKey( key );
 		setFKNameIfDefined( join );
 		key.setCascadeDeleteEnabled( false );
 		TableBinder.bindFk( persistentClass, null, ejb3JoinColumns, key, false, buildingContext );
 		join.createPrimaryKey();
 		join.createForeignKey();
 		persistentClass.addJoin( join );
 	}
 
 	private void setFKNameIfDefined(Join join) {
 		// just awful..
 
 		org.hibernate.annotations.Table matchingTable = findMatchingComplimentTableAnnotation( join );
 		if ( matchingTable != null && !BinderHelper.isEmptyAnnotationValue( matchingTable.foreignKey().name() ) ) {
 			( (SimpleValue) join.getKey() ).setForeignKeyName( matchingTable.foreignKey().name() );
 		}
 		else {
 			javax.persistence.SecondaryTable jpaSecondaryTable = findMatchingSecondaryTable( join );
 			if ( jpaSecondaryTable != null ) {
 				if ( jpaSecondaryTable.foreignKey().value() == ConstraintMode.NO_CONSTRAINT ) {
 					( (SimpleValue) join.getKey() ).setForeignKeyName( "none" );
 				}
 				else {
 					( (SimpleValue) join.getKey() ).setForeignKeyName( StringHelper.nullIfEmpty( jpaSecondaryTable.foreignKey().name() ) );
 				}
 			}
 		}
 	}
 
 	private SecondaryTable findMatchingSecondaryTable(Join join) {
 		final String nameToMatch = join.getTable().getQuotedName();
 
 		SecondaryTable secondaryTable = annotatedClass.getAnnotation( SecondaryTable.class );
 		if ( secondaryTable != null && nameToMatch.equals( secondaryTable.name() ) ) {
 			return secondaryTable;
 		}
 
 		SecondaryTables secondaryTables = annotatedClass.getAnnotation( SecondaryTables.class );
 		if ( secondaryTables != null ) {
 			for ( SecondaryTable secondaryTable2 : secondaryTables.value() ) {
 				if ( secondaryTable != null && nameToMatch.equals( secondaryTable.name() ) ) {
 					return secondaryTable;
 				}
 			}
 
 		}
 
 		return null;
 	}
 
 	private org.hibernate.annotations.Table findMatchingComplimentTableAnnotation(Join join) {
 		String tableName = join.getTable().getQuotedName();
 		org.hibernate.annotations.Table table = annotatedClass.getAnnotation( org.hibernate.annotations.Table.class );
 		org.hibernate.annotations.Table matchingTable = null;
 		if ( table != null && tableName.equals( table.appliesTo() ) ) {
 			matchingTable = table;
 		}
 		else {
 			Tables tables = annotatedClass.getAnnotation( Tables.class );
 			if ( tables != null ) {
 				for (org.hibernate.annotations.Table current : tables.value()) {
 					if ( tableName.equals( current.appliesTo() ) ) {
 						matchingTable = current;
 						break;
 					}
 				}
 			}
 		}
 		return matchingTable;
 	}
 
 	public void firstLevelSecondaryTablesBinding(
 			SecondaryTable secTable, SecondaryTables secTables
 	) {
 		if ( secTables != null ) {
 			//loop through it
 			for (SecondaryTable tab : secTables.value()) {
 				addJoin( tab, null, null, false );
 			}
 		}
 		else {
 			if ( secTable != null ) addJoin( secTable, null, null, false );
 		}
 	}
 
 	//Used for @*ToMany @JoinTable
 	public Join addJoin(JoinTable joinTable, PropertyHolder holder, boolean noDelayInPkColumnCreation) {
 		return addJoin( null, joinTable, holder, noDelayInPkColumnCreation );
 	}
 
 	private static class SecondaryTableNameSource implements ObjectNameSource {
 		// always has an explicit name
 		private final String explicitName;
 
 		private SecondaryTableNameSource(String explicitName) {
 			this.explicitName = explicitName;
 		}
 
 		public String getExplicitName() {
 			return explicitName;
 		}
 
 		public String getLogicalName() {
 			return explicitName;
 		}
 	}
 
 	private static class SecondaryTableNamingStrategyHelper implements NamingStrategyHelper {
 		@Override
 		public Identifier determineImplicitName(MetadataBuildingContext buildingContext) {
 			// should maybe throw an exception here
 			return null;
 		}
 
 		@Override
 		public Identifier handleExplicitName(String explicitName, MetadataBuildingContext buildingContext) {
 			return buildingContext.getMetadataCollector()
 					.getDatabase()
 					.getJdbcEnvironment()
 					.getIdentifierHelper()
 					.toIdentifier( explicitName );
 		}
 
 		@Override
 		public Identifier toPhysicalName(Identifier logicalName, MetadataBuildingContext buildingContext) {
 			return buildingContext.getBuildingOptions().getPhysicalNamingStrategy().toPhysicalTableName(
 					logicalName,
 					buildingContext.getMetadataCollector().getDatabase().getJdbcEnvironment()
 			);
 		}
 	}
 
 	private static SecondaryTableNamingStrategyHelper SEC_TBL_NS_HELPER = new SecondaryTableNamingStrategyHelper();
 
 	private Join addJoin(
 			SecondaryTable secondaryTable,
 			JoinTable joinTable,
 			PropertyHolder propertyHolder,
 			boolean noDelayInPkColumnCreation) {
 		// A non null propertyHolder means than we process the Pk creation without delay
 		Join join = new Join();
 		join.setPersistentClass( persistentClass );
 
 		final String schema;
 		final String catalog;
 		final SecondaryTableNameSource secondaryTableNameContext;
 		final Object joinColumns;
 		final List<UniqueConstraintHolder> uniqueConstraintHolders;
 
 		final Identifier logicalName;
 		if ( secondaryTable != null ) {
 			schema = secondaryTable.schema();
 			catalog = secondaryTable.catalog();
 			logicalName = context.getMetadataCollector()
 					.getDatabase()
 					.getJdbcEnvironment()
 					.getIdentifierHelper()
 					.toIdentifier( secondaryTable.name() );
 			joinColumns = secondaryTable.pkJoinColumns();
 			uniqueConstraintHolders = TableBinder.buildUniqueConstraintHolders( secondaryTable.uniqueConstraints() );
 		}
 		else if ( joinTable != null ) {
 			schema = joinTable.schema();
 			catalog = joinTable.catalog();
 			logicalName = context.getMetadataCollector()
 					.getDatabase()
 					.getJdbcEnvironment()
 					.getIdentifierHelper()
 					.toIdentifier( joinTable.name() );
 			joinColumns = joinTable.joinColumns();
 			uniqueConstraintHolders = TableBinder.buildUniqueConstraintHolders( joinTable.uniqueConstraints() );
 		}
 		else {
 			throw new AssertionFailure( "Both JoinTable and SecondaryTable are null" );
 		}
 
 		final Table table = TableBinder.buildAndFillTable(
 				schema,
 				catalog,
 				logicalName,
 				false,
 				uniqueConstraintHolders,
 				null,
 				null,
 				context,
 				null,
 				null
 		);
 
 		final InFlightMetadataCollector.EntityTableXref tableXref = context.getMetadataCollector().getEntityTableXref( persistentClass.getEntityName() );
 		assert tableXref != null : "Could not locate EntityTableXref for entity [" + persistentClass.getEntityName() + "]";
 		tableXref.addSecondaryTable( logicalName, join );
 
 		if ( secondaryTable != null ) {
 			TableBinder.addIndexes( table, secondaryTable.indexes(), context );
 		}
 
 			//no check constraints available on joins
 		join.setTable( table );
 
 		//somehow keep joins() for later.
 		//Has to do the work later because it needs persistentClass id!
 		LOG.debugf( "Adding secondary table to entity %s -> %s", persistentClass.getEntityName(), join.getTable().getName() );
 		org.hibernate.annotations.Table matchingTable = findMatchingComplimentTableAnnotation( join );
 		if ( matchingTable != null ) {
 			join.setSequentialSelect( FetchMode.JOIN != matchingTable.fetch() );
 			join.setInverse( matchingTable.inverse() );
 			join.setOptional( matchingTable.optional() );
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlInsert().sql() ) ) {
 				join.setCustomSQLInsert( matchingTable.sqlInsert().sql().trim(),
 						matchingTable.sqlInsert().callable(),
 						ExecuteUpdateResultCheckStyle.fromExternalName(
-								matchingTable.sqlInsert().check().toString().toLowerCase()
+								matchingTable.sqlInsert().check().toString().toLowerCase(Locale.ROOT)
 						)
 				);
 			}
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlUpdate().sql() ) ) {
 				join.setCustomSQLUpdate( matchingTable.sqlUpdate().sql().trim(),
 						matchingTable.sqlUpdate().callable(),
 						ExecuteUpdateResultCheckStyle.fromExternalName(
-								matchingTable.sqlUpdate().check().toString().toLowerCase()
+								matchingTable.sqlUpdate().check().toString().toLowerCase(Locale.ROOT)
 						)
 				);
 			}
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlDelete().sql() ) ) {
 				join.setCustomSQLDelete( matchingTable.sqlDelete().sql().trim(),
 						matchingTable.sqlDelete().callable(),
 						ExecuteUpdateResultCheckStyle.fromExternalName(
-								matchingTable.sqlDelete().check().toString().toLowerCase()
+								matchingTable.sqlDelete().check().toString().toLowerCase(Locale.ROOT)
 						)
 				);
 			}
 		}
 		else {
 			//default
 			join.setSequentialSelect( false );
 			join.setInverse( false );
 			join.setOptional( true ); //perhaps not quite per-spec, but a Good Thing anyway
 		}
 
 		if ( noDelayInPkColumnCreation ) {
 			createPrimaryColumnsToSecondaryTable( joinColumns, propertyHolder, join );
 		}
 		else {
 			secondaryTables.put( table.getQuotedName(), join );
 			secondaryTableJoins.put( table.getQuotedName(), joinColumns );
 		}
 
 		return join;
 	}
 
 	public java.util.Map<String, Join> getSecondaryTables() {
 		return secondaryTables;
 	}
 
 	public void setCache(Cache cacheAnn) {
 		if ( cacheAnn != null ) {
 			cacheRegion = BinderHelper.isEmptyAnnotationValue( cacheAnn.region() ) ?
 					null :
 					cacheAnn.region();
 			cacheConcurrentStrategy = getCacheConcurrencyStrategy( cacheAnn.usage() );
 			if ( "all".equalsIgnoreCase( cacheAnn.include() ) ) {
 				cacheLazyProperty = true;
 			}
 			else if ( "non-lazy".equalsIgnoreCase( cacheAnn.include() ) ) {
 				cacheLazyProperty = false;
 			}
 			else {
 				throw new AnnotationException( "Unknown lazy property annotations: " + cacheAnn.include() );
 			}
 		}
 		else {
 			cacheConcurrentStrategy = null;
 			cacheRegion = null;
 			cacheLazyProperty = true;
 		}
 	}
 	
 	public void setNaturalIdCache(XClass clazzToProcess, NaturalIdCache naturalIdCacheAnn) {
 		if ( naturalIdCacheAnn != null ) {
 			if ( BinderHelper.isEmptyAnnotationValue( naturalIdCacheAnn.region() ) ) {
 				if (cacheRegion != null) {
 					naturalIdCacheRegion = cacheRegion + NATURAL_ID_CACHE_SUFFIX;
 				}
 				else {
 					naturalIdCacheRegion = clazzToProcess.getName() + NATURAL_ID_CACHE_SUFFIX;
 				}
 			}
 			else {
 				naturalIdCacheRegion = naturalIdCacheAnn.region();
 			}
 		}
 		else {
 			naturalIdCacheRegion = null;
 		}
 	}
 
 	public static String getCacheConcurrencyStrategy(CacheConcurrencyStrategy strategy) {
 		org.hibernate.cache.spi.access.AccessType accessType = strategy.toAccessType();
 		return accessType == null ? null : accessType.getExternalName();
 	}
 
 	public void addFilter(Filter filter) {
 		filters.add(filter);
 	}
 
 	public void setInheritanceState(InheritanceState inheritanceState) {
 		this.inheritanceState = inheritanceState;
 	}
 
 	public boolean isIgnoreIdAnnotations() {
 		return ignoreIdAnnotations;
 	}
 
 	public void setIgnoreIdAnnotations(boolean ignoreIdAnnotations) {
 		this.ignoreIdAnnotations = ignoreIdAnnotations;
 	}
 	public void processComplementaryTableDefinitions(javax.persistence.Table table) {
 		if ( table == null ) return;
 		TableBinder.addIndexes( persistentClass.getTable(), table.indexes(), context );
 	}
 	public void processComplementaryTableDefinitions(org.hibernate.annotations.Table table) {
 		//comment and index are processed here
 		if ( table == null ) return;
 		String appliedTable = table.appliesTo();
 		Iterator tables = persistentClass.getTableClosureIterator();
 		Table hibTable = null;
 		while ( tables.hasNext() ) {
 			Table pcTable = (Table) tables.next();
 			if ( pcTable.getQuotedName().equals( appliedTable ) ) {
 				//we are in the correct table to find columns
 				hibTable = pcTable;
 				break;
 			}
 			hibTable = null;
 		}
 		if ( hibTable == null ) {
 			//maybe a join/secondary table
 			for ( Join join : secondaryTables.values() ) {
 				if ( join.getTable().getQuotedName().equals( appliedTable ) ) {
 					hibTable = join.getTable();
 					break;
 				}
 			}
 		}
 		if ( hibTable == null ) {
 			throw new AnnotationException(
 					"@org.hibernate.annotations.Table references an unknown table: " + appliedTable
 			);
 		}
 		if ( !BinderHelper.isEmptyAnnotationValue( table.comment() ) ) hibTable.setComment( table.comment() );
 		TableBinder.addIndexes( hibTable, table.indexes(), context );
 	}
 
 	public void processComplementaryTableDefinitions(Tables tables) {
 		if ( tables == null ) return;
 		for (org.hibernate.annotations.Table table : tables.value()) {
 			processComplementaryTableDefinitions( table );
 		}
 	}
 
 	public AccessType getPropertyAccessType() {
 		return propertyAccessType;
 	}
 
 	public void setPropertyAccessType(AccessType propertyAccessor) {
 		this.propertyAccessType = getExplicitAccessType( annotatedClass );
 		// only set the access type if there is no explicit access type for this class
 		if( this.propertyAccessType == null ) {
 			this.propertyAccessType = propertyAccessor;
 		}
 	}
 
 	public AccessType getPropertyAccessor(XAnnotatedElement element) {
 		AccessType accessType = getExplicitAccessType( element );
 		if ( accessType == null ) {
 		   accessType = propertyAccessType;
 		}
 		return accessType;
 	}
 
 	public AccessType getExplicitAccessType(XAnnotatedElement element) {
 		AccessType accessType = null;
 
 		AccessType hibernateAccessType = null;
 		AccessType jpaAccessType = null;
 
 		org.hibernate.annotations.AccessType accessTypeAnnotation = element.getAnnotation( org.hibernate.annotations.AccessType.class );
 		if ( accessTypeAnnotation != null ) {
 			hibernateAccessType = AccessType.getAccessStrategy( accessTypeAnnotation.value() );
 		}
 
 		Access access = element.getAnnotation( Access.class );
 		if ( access != null ) {
 			jpaAccessType = AccessType.getAccessStrategy( access.value() );
 		}
 
 		if ( hibernateAccessType != null && jpaAccessType != null && hibernateAccessType != jpaAccessType ) {
 			throw new MappingException(
 					"Found @Access and @AccessType with conflicting values on a property in class " + annotatedClass.toString()
 			);
 		}
 
 		if ( hibernateAccessType != null ) {
 			accessType = hibernateAccessType;
 		}
 		else if ( jpaAccessType != null ) {
 			accessType = jpaAccessType;
 		}
 
 		return accessType;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/JPAOverriddenAnnotationReader.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/JPAOverriddenAnnotationReader.java
index b9c1d123af..6d16dffd64 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/JPAOverriddenAnnotationReader.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/JPAOverriddenAnnotationReader.java
@@ -1,2983 +1,2984 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations.reflection;
 
 import java.beans.Introspector;
 import java.lang.annotation.Annotation;
 import java.lang.reflect.AccessibleObject;
 import java.lang.reflect.AnnotatedElement;
 import java.lang.reflect.Field;
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.Access;
 import javax.persistence.AccessType;
 import javax.persistence.AssociationOverride;
 import javax.persistence.AssociationOverrides;
 import javax.persistence.AttributeOverride;
 import javax.persistence.AttributeOverrides;
 import javax.persistence.Basic;
 import javax.persistence.Cacheable;
 import javax.persistence.CascadeType;
 import javax.persistence.CollectionTable;
 import javax.persistence.Column;
 import javax.persistence.ColumnResult;
 import javax.persistence.ConstructorResult;
 import javax.persistence.Convert;
 import javax.persistence.Converts;
 import javax.persistence.DiscriminatorColumn;
 import javax.persistence.DiscriminatorType;
 import javax.persistence.DiscriminatorValue;
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.Embedded;
 import javax.persistence.EmbeddedId;
 import javax.persistence.Entity;
 import javax.persistence.EntityListeners;
 import javax.persistence.EntityResult;
 import javax.persistence.EnumType;
 import javax.persistence.Enumerated;
 import javax.persistence.ExcludeDefaultListeners;
 import javax.persistence.ExcludeSuperclassListeners;
 import javax.persistence.FetchType;
 import javax.persistence.FieldResult;
 import javax.persistence.ForeignKey;
 import javax.persistence.GeneratedValue;
 import javax.persistence.GenerationType;
 import javax.persistence.Id;
 import javax.persistence.IdClass;
 import javax.persistence.Index;
 import javax.persistence.Inheritance;
 import javax.persistence.InheritanceType;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinColumns;
 import javax.persistence.JoinTable;
 import javax.persistence.Lob;
 import javax.persistence.ManyToMany;
 import javax.persistence.ManyToOne;
 import javax.persistence.MapKey;
 import javax.persistence.MapKeyClass;
 import javax.persistence.MapKeyColumn;
 import javax.persistence.MapKeyEnumerated;
 import javax.persistence.MapKeyJoinColumn;
 import javax.persistence.MapKeyJoinColumns;
 import javax.persistence.MapKeyTemporal;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.MapsId;
 import javax.persistence.NamedAttributeNode;
 import javax.persistence.NamedEntityGraph;
 import javax.persistence.NamedEntityGraphs;
 import javax.persistence.NamedNativeQueries;
 import javax.persistence.NamedNativeQuery;
 import javax.persistence.NamedQueries;
 import javax.persistence.NamedQuery;
 import javax.persistence.NamedStoredProcedureQueries;
 import javax.persistence.NamedStoredProcedureQuery;
 import javax.persistence.NamedSubgraph;
 import javax.persistence.OneToMany;
 import javax.persistence.OneToOne;
 import javax.persistence.OrderBy;
 import javax.persistence.OrderColumn;
 import javax.persistence.ParameterMode;
 import javax.persistence.PostLoad;
 import javax.persistence.PostPersist;
 import javax.persistence.PostRemove;
 import javax.persistence.PostUpdate;
 import javax.persistence.PrePersist;
 import javax.persistence.PreRemove;
 import javax.persistence.PreUpdate;
 import javax.persistence.PrimaryKeyJoinColumn;
 import javax.persistence.PrimaryKeyJoinColumns;
 import javax.persistence.QueryHint;
 import javax.persistence.SecondaryTable;
 import javax.persistence.SecondaryTables;
 import javax.persistence.SequenceGenerator;
 import javax.persistence.SqlResultSetMapping;
 import javax.persistence.SqlResultSetMappings;
 import javax.persistence.StoredProcedureParameter;
 import javax.persistence.Table;
 import javax.persistence.TableGenerator;
 import javax.persistence.Temporal;
 import javax.persistence.TemporalType;
 import javax.persistence.Transient;
 import javax.persistence.UniqueConstraint;
 import javax.persistence.Version;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.annotations.Any;
 import org.hibernate.annotations.Cascade;
 import org.hibernate.annotations.Columns;
 import org.hibernate.annotations.ManyToAny;
 import org.hibernate.annotations.common.annotationfactory.AnnotationDescriptor;
 import org.hibernate.annotations.common.annotationfactory.AnnotationFactory;
 import org.hibernate.annotations.common.reflection.AnnotationReader;
 import org.hibernate.annotations.common.reflection.ReflectionUtil;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 
 import org.dom4j.Attribute;
 import org.dom4j.Element;
 
 /**
  * Encapsulates the overriding of Java annotations from an EJB 3.0 descriptor.
  *
  * @author Paolo Perrotta
  * @author Davide Marchignoli
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class JPAOverriddenAnnotationReader implements AnnotationReader {
     private static final CoreMessageLogger LOG = CoreLogging.messageLogger( JPAOverriddenAnnotationReader.class );
 
 	private static final String SCHEMA_VALIDATION = "Activate schema validation for more information";
 	private static final String WORD_SEPARATOR = "-";
 
 	private static enum PropertyType {
 		PROPERTY,
 		FIELD,
 		METHOD
 	}
 
 	private static final Map<Class, String> annotationToXml;
 
 	static {
 		annotationToXml = new HashMap<Class, String>();
 		annotationToXml.put( Entity.class, "entity" );
 		annotationToXml.put( MappedSuperclass.class, "mapped-superclass" );
 		annotationToXml.put( Embeddable.class, "embeddable" );
 		annotationToXml.put( Table.class, "table" );
 		annotationToXml.put( SecondaryTable.class, "secondary-table" );
 		annotationToXml.put( SecondaryTables.class, "secondary-table" );
 		annotationToXml.put( PrimaryKeyJoinColumn.class, "primary-key-join-column" );
 		annotationToXml.put( PrimaryKeyJoinColumns.class, "primary-key-join-column" );
 		annotationToXml.put( IdClass.class, "id-class" );
 		annotationToXml.put( Inheritance.class, "inheritance" );
 		annotationToXml.put( DiscriminatorValue.class, "discriminator-value" );
 		annotationToXml.put( DiscriminatorColumn.class, "discriminator-column" );
 		annotationToXml.put( SequenceGenerator.class, "sequence-generator" );
 		annotationToXml.put( TableGenerator.class, "table-generator" );
 		annotationToXml.put( NamedEntityGraph.class, "named-entity-graph" );
 		annotationToXml.put( NamedEntityGraphs.class, "named-entity-graph" );
 		annotationToXml.put( NamedQuery.class, "named-query" );
 		annotationToXml.put( NamedQueries.class, "named-query" );
 		annotationToXml.put( NamedNativeQuery.class, "named-native-query" );
 		annotationToXml.put( NamedNativeQueries.class, "named-native-query" );
 		annotationToXml.put( NamedStoredProcedureQuery.class, "named-stored-procedure-query" );
 		annotationToXml.put( NamedStoredProcedureQueries.class, "named-stored-procedure-query" );
 		annotationToXml.put( SqlResultSetMapping.class, "sql-result-set-mapping" );
 		annotationToXml.put( SqlResultSetMappings.class, "sql-result-set-mapping" );
 		annotationToXml.put( ExcludeDefaultListeners.class, "exclude-default-listeners" );
 		annotationToXml.put( ExcludeSuperclassListeners.class, "exclude-superclass-listeners" );
 		annotationToXml.put( AccessType.class, "access" );
 		annotationToXml.put( AttributeOverride.class, "attribute-override" );
 		annotationToXml.put( AttributeOverrides.class, "attribute-override" );
 		annotationToXml.put( AttributeOverride.class, "association-override" );
 		annotationToXml.put( AttributeOverrides.class, "association-override" );
 		annotationToXml.put( AttributeOverride.class, "map-key-attribute-override" );
 		annotationToXml.put( AttributeOverrides.class, "map-key-attribute-override" );
 		annotationToXml.put( Id.class, "id" );
 		annotationToXml.put( EmbeddedId.class, "embedded-id" );
 		annotationToXml.put( GeneratedValue.class, "generated-value" );
 		annotationToXml.put( Column.class, "column" );
 		annotationToXml.put( Columns.class, "column" );
 		annotationToXml.put( Temporal.class, "temporal" );
 		annotationToXml.put( Lob.class, "lob" );
 		annotationToXml.put( Enumerated.class, "enumerated" );
 		annotationToXml.put( Version.class, "version" );
 		annotationToXml.put( Transient.class, "transient" );
 		annotationToXml.put( Basic.class, "basic" );
 		annotationToXml.put( Embedded.class, "embedded" );
 		annotationToXml.put( ManyToOne.class, "many-to-one" );
 		annotationToXml.put( OneToOne.class, "one-to-one" );
 		annotationToXml.put( OneToMany.class, "one-to-many" );
 		annotationToXml.put( ManyToMany.class, "many-to-many" );
 		annotationToXml.put( Any.class, "any" );
 		annotationToXml.put( ManyToAny.class, "many-to-any" );
 		annotationToXml.put( JoinTable.class, "join-table" );
 		annotationToXml.put( JoinColumn.class, "join-column" );
 		annotationToXml.put( JoinColumns.class, "join-column" );
 		annotationToXml.put( MapKey.class, "map-key" );
 		annotationToXml.put( OrderBy.class, "order-by" );
 		annotationToXml.put( EntityListeners.class, "entity-listeners" );
 		annotationToXml.put( PrePersist.class, "pre-persist" );
 		annotationToXml.put( PreRemove.class, "pre-remove" );
 		annotationToXml.put( PreUpdate.class, "pre-update" );
 		annotationToXml.put( PostPersist.class, "post-persist" );
 		annotationToXml.put( PostRemove.class, "post-remove" );
 		annotationToXml.put( PostUpdate.class, "post-update" );
 		annotationToXml.put( PostLoad.class, "post-load" );
 		annotationToXml.put( CollectionTable.class, "collection-table" );
 		annotationToXml.put( MapKeyClass.class, "map-key-class" );
 		annotationToXml.put( MapKeyTemporal.class, "map-key-temporal" );
 		annotationToXml.put( MapKeyEnumerated.class, "map-key-enumerated" );
 		annotationToXml.put( MapKeyColumn.class, "map-key-column" );
 		annotationToXml.put( MapKeyJoinColumn.class, "map-key-join-column" );
 		annotationToXml.put( MapKeyJoinColumns.class, "map-key-join-column" );
 		annotationToXml.put( OrderColumn.class, "order-column" );
 		annotationToXml.put( Cacheable.class, "cacheable" );
 		annotationToXml.put( Index.class, "index" );
 		annotationToXml.put( ForeignKey.class, "foreign-key" );
 		annotationToXml.put( Convert.class, "convert" );
 		annotationToXml.put( Converts.class, "convert" );
 		annotationToXml.put( ConstructorResult.class, "constructor-result" );
 	}
 
 	private XMLContext xmlContext;
 	private final AnnotatedElement element;
 	private String className;
 	private String propertyName;
 	private PropertyType propertyType;
 	private transient Annotation[] annotations;
 	private transient Map<Class, Annotation> annotationsMap;
 	private transient List<Element> elementsForProperty;
 	private AccessibleObject mirroredAttribute;
 
 	public JPAOverriddenAnnotationReader(AnnotatedElement el, XMLContext xmlContext) {
 		this.element = el;
 		this.xmlContext = xmlContext;
 		if ( el instanceof Class ) {
 			Class clazz = (Class) el;
 			className = clazz.getName();
 		}
 		else if ( el instanceof Field ) {
 			Field field = (Field) el;
 			className = field.getDeclaringClass().getName();
 			propertyName = field.getName();
 			propertyType = PropertyType.FIELD;
 			String expectedGetter = "get" + Character.toUpperCase( propertyName.charAt( 0 ) ) + propertyName.substring(
 					1
 			);
 			try {
 				mirroredAttribute = field.getDeclaringClass().getDeclaredMethod( expectedGetter );
 			}
 			catch ( NoSuchMethodException e ) {
 				//no method
 			}
 		}
 		else if ( el instanceof Method ) {
 			Method method = (Method) el;
 			className = method.getDeclaringClass().getName();
 			propertyName = method.getName();
 
 			// YUCK!  The null here is the 'boundType', we'd rather get the TypeEnvironment()
 			if ( ReflectionUtil.isProperty( method, null, PersistentAttributeFilter.INSTANCE ) ) {
 				if ( propertyName.startsWith( "get" ) ) {
 					propertyName = Introspector.decapitalize( propertyName.substring( "get".length() ) );
 				}
 				else if ( propertyName.startsWith( "is" ) ) {
 					propertyName = Introspector.decapitalize( propertyName.substring( "is".length() ) );
 				}
 				else {
 					throw new RuntimeException( "Method " + propertyName + " is not a property getter" );
 				}
 				propertyType = PropertyType.PROPERTY;
 				try {
 					mirroredAttribute = method.getDeclaringClass().getDeclaredField( propertyName );
 				}
 				catch ( NoSuchFieldException e ) {
 					//no method
 				}
 			}
 			else {
 				propertyType = PropertyType.METHOD;
 			}
 		}
 		else {
 			className = null;
 			propertyName = null;
 		}
 	}
 
 	public <T extends Annotation> T getAnnotation(Class<T> annotationType) {
 		initAnnotations();
 		return (T) annotationsMap.get( annotationType );
 	}
 
 	public <T extends Annotation> boolean isAnnotationPresent(Class<T> annotationType) {
 		initAnnotations();
 		return annotationsMap.containsKey( annotationType );
 	}
 
 	public Annotation[] getAnnotations() {
 		initAnnotations();
 		return annotations;
 	}
 
 	/*
 	 * The idea is to create annotation proxies for the xml configuration elements. Using this proxy annotations together
 	 * with the {@link JPAMetadataProvider} allows to handle xml configuration the same way as annotation configuration.
 	 */
 	private void initAnnotations() {
 		if ( annotations == null ) {
 			XMLContext.Default defaults = xmlContext.getDefault( className );
 			if ( className != null && propertyName == null ) {
 				//is a class
 				Element tree = xmlContext.getXMLTree( className );
 				Annotation[] annotations = getPhysicalAnnotations();
 				List<Annotation> annotationList = new ArrayList<Annotation>( annotations.length + 5 );
 				annotationsMap = new HashMap<Class, Annotation>( annotations.length + 5 );
 				for ( Annotation annotation : annotations ) {
 					if ( !annotationToXml.containsKey( annotation.annotationType() ) ) {
 						//unknown annotations are left over
 						annotationList.add( annotation );
 					}
 				}
 				addIfNotNull( annotationList, getEntity( tree, defaults ) );
 				addIfNotNull( annotationList, getMappedSuperclass( tree, defaults ) );
 				addIfNotNull( annotationList, getEmbeddable( tree, defaults ) );
 				addIfNotNull( annotationList, getTable( tree, defaults ) );
 				addIfNotNull( annotationList, getSecondaryTables( tree, defaults ) );
 				addIfNotNull( annotationList, getPrimaryKeyJoinColumns( tree, defaults, true ) );
 				addIfNotNull( annotationList, getIdClass( tree, defaults ) );
 				addIfNotNull( annotationList, getCacheable( tree, defaults ) );
 				addIfNotNull( annotationList, getInheritance( tree, defaults ) );
 				addIfNotNull( annotationList, getDiscriminatorValue( tree, defaults ) );
 				addIfNotNull( annotationList, getDiscriminatorColumn( tree, defaults ) );
 				addIfNotNull( annotationList, getSequenceGenerator( tree, defaults ) );
 				addIfNotNull( annotationList, getTableGenerator( tree, defaults ) );
 				addIfNotNull( annotationList, getNamedQueries( tree, defaults ) );
 				addIfNotNull( annotationList, getNamedNativeQueries( tree, defaults ) );
 				addIfNotNull( annotationList, getNamedStoredProcedureQueries( tree, defaults ) );
 				addIfNotNull( annotationList, getNamedEntityGraphs( tree, defaults ) );
 				addIfNotNull( annotationList, getSqlResultSetMappings( tree, defaults ) );
 				addIfNotNull( annotationList, getExcludeDefaultListeners( tree, defaults ) );
 				addIfNotNull( annotationList, getExcludeSuperclassListeners( tree, defaults ) );
 				addIfNotNull( annotationList, getAccessType( tree, defaults ) );
 				addIfNotNull( annotationList, getAttributeOverrides( tree, defaults, true ) );
 				addIfNotNull( annotationList, getAssociationOverrides( tree, defaults, true ) );
 				addIfNotNull( annotationList, getEntityListeners( tree, defaults ) );
 				addIfNotNull( annotationList, getConverts( tree, defaults ) );
 
 				this.annotations = annotationList.toArray( new Annotation[annotationList.size()] );
 				for ( Annotation ann : this.annotations ) {
 					annotationsMap.put( ann.annotationType(), ann );
 				}
 				checkForOrphanProperties( tree );
 			}
 			else if ( className != null ) { //&& propertyName != null ) { //always true but less confusing
 				Element tree = xmlContext.getXMLTree( className );
 				Annotation[] annotations = getPhysicalAnnotations();
 				List<Annotation> annotationList = new ArrayList<Annotation>( annotations.length + 5 );
 				annotationsMap = new HashMap<Class, Annotation>( annotations.length + 5 );
 				for ( Annotation annotation : annotations ) {
 					if ( !annotationToXml.containsKey( annotation.annotationType() ) ) {
 						//unknown annotations are left over
 						annotationList.add( annotation );
 					}
 				}
 				preCalculateElementsForProperty( tree );
 				Transient transientAnn = getTransient( defaults );
 				if ( transientAnn != null ) {
 					annotationList.add( transientAnn );
 				}
 				else {
 					if ( defaults.canUseJavaAnnotations() ) {
 						Annotation annotation = getPhysicalAnnotation( Access.class );
 						addIfNotNull( annotationList, annotation );
 					}
 					getId( annotationList, defaults );
 					getEmbeddedId( annotationList, defaults );
 					getEmbedded( annotationList, defaults );
 					getBasic( annotationList, defaults );
 					getVersion( annotationList, defaults );
 					getAssociation( ManyToOne.class, annotationList, defaults );
 					getAssociation( OneToOne.class, annotationList, defaults );
 					getAssociation( OneToMany.class, annotationList, defaults );
 					getAssociation( ManyToMany.class, annotationList, defaults );
 					getAssociation( Any.class, annotationList, defaults );
 					getAssociation( ManyToAny.class, annotationList, defaults );
 					getElementCollection( annotationList, defaults );
 					addIfNotNull( annotationList, getSequenceGenerator( elementsForProperty, defaults ) );
 					addIfNotNull( annotationList, getTableGenerator( elementsForProperty, defaults ) );
 					addIfNotNull( annotationList, getConvertsForAttribute( elementsForProperty, defaults ) );
 				}
 				processEventAnnotations( annotationList, defaults );
 				//FIXME use annotationsMap rather than annotationList this will be faster since the annotation type is usually known at put() time
 				this.annotations = annotationList.toArray( new Annotation[annotationList.size()] );
 				for ( Annotation ann : this.annotations ) {
 					annotationsMap.put( ann.annotationType(), ann );
 				}
 			}
 			else {
 				this.annotations = getPhysicalAnnotations();
 				annotationsMap = new HashMap<Class, Annotation>( annotations.length + 5 );
 				for ( Annotation ann : this.annotations ) {
 					annotationsMap.put( ann.annotationType(), ann );
 				}
 			}
 		}
 	}
 
 	private Annotation getConvertsForAttribute(List<Element> elementsForProperty, XMLContext.Default defaults) {
 		// NOTE : we use a map here to make sure that an xml and annotation referring to the same attribute
 		// properly overrides.  Very sparse map, yes, but easy setup.
 		// todo : revisit this
 		// although bear in mind that this code is no longer used in 5.0...
 
 		final Map<String,Convert> convertAnnotationsMap = new HashMap<String, Convert>();
 
 		for ( Element element : elementsForProperty ) {
 			final boolean isBasic = "basic".equals( element.getName() );
 			final boolean isEmbedded = "embedded".equals( element.getName() );
 
 			// todo : can be collections too
 
 			final boolean canHaveConverts = isBasic || isEmbedded;
 
 			if ( !canHaveConverts ) {
 				continue;
 			}
 
 			final String attributeNamePrefix = isBasic ? null : propertyName;
 			applyXmlDefinedConverts( element, defaults, attributeNamePrefix, convertAnnotationsMap );
 		}
 
 		// NOTE : per section 12.2.3.16 of the spec <convert/> is additive, although only if "metadata-complete" is not
 		// specified in the XML
 
 		if ( defaults.canUseJavaAnnotations() ) {
 			// todo : note sure how to best handle attributeNamePrefix here
 			applyPhysicalConvertAnnotations( propertyName, convertAnnotationsMap );
 		}
 
 		if ( !convertAnnotationsMap.isEmpty() ) {
 			final AnnotationDescriptor groupingDescriptor = new AnnotationDescriptor( Converts.class );
 			groupingDescriptor.setValue( "value", convertAnnotationsMap.values().toArray( new Convert[convertAnnotationsMap.size()]) );
 			return AnnotationFactory.create( groupingDescriptor );
 		}
 
 		return null;
 	}
 
 	private Converts getConverts(Element tree, XMLContext.Default defaults) {
 		// NOTE : we use a map here to make sure that an xml and annotation referring to the same attribute
 		// properly overrides.  Bit sparse, but easy...
 		final Map<String,Convert> convertAnnotationsMap = new HashMap<String, Convert>();
 
 		if ( tree != null ) {
 			applyXmlDefinedConverts( tree, defaults, null, convertAnnotationsMap );
 		}
 
 		// NOTE : per section 12.2.3.16 of the spec <convert/> is additive, although only if "metadata-complete" is not
 		// specified in the XML
 
 		if ( defaults.canUseJavaAnnotations() ) {
 			applyPhysicalConvertAnnotations( null, convertAnnotationsMap );
 		}
 
 		if ( !convertAnnotationsMap.isEmpty() ) {
 			final AnnotationDescriptor groupingDescriptor = new AnnotationDescriptor( Converts.class );
 			groupingDescriptor.setValue( "value", convertAnnotationsMap.values().toArray( new Convert[convertAnnotationsMap.size()]) );
 			return AnnotationFactory.create( groupingDescriptor );
 		}
 
 		return null;
 	}
 
 	private void applyXmlDefinedConverts(
 			Element containingElement,
 			XMLContext.Default defaults,
 			String attributeNamePrefix,
 			Map<String,Convert> convertAnnotationsMap) {
 		final List<Element> convertElements = containingElement.elements( "convert" );
 		for ( Element convertElement : convertElements ) {
 			final AnnotationDescriptor convertAnnotationDescriptor = new AnnotationDescriptor( Convert.class );
 			copyStringAttribute( convertAnnotationDescriptor, convertElement, "attribute-name", false );
 			copyBooleanAttribute( convertAnnotationDescriptor, convertElement, "disable-conversion" );
 
 			final Attribute converterClassAttr = convertElement.attribute( "converter" );
 			if ( converterClassAttr != null ) {
 				final String converterClassName = XMLContext.buildSafeClassName(
 						converterClassAttr.getValue(),
 						defaults
 				);
 				try {
 					final Class converterClass = ReflectHelper.classForName( converterClassName, this.getClass() );
 					convertAnnotationDescriptor.setValue( "converter", converterClass );
 				}
 				catch (ClassNotFoundException e) {
 					throw new AnnotationException( "Unable to find specified converter class id-class: " + converterClassName, e );
 				}
 			}
 			final Convert convertAnnotation = AnnotationFactory.create( convertAnnotationDescriptor );
 			final String qualifiedAttributeName = qualifyConverterAttributeName(
 					attributeNamePrefix,
 					convertAnnotation.attributeName()
 			);
 			convertAnnotationsMap.put( qualifiedAttributeName, convertAnnotation );
 		}
 
 	}
 
 	private String qualifyConverterAttributeName(String attributeNamePrefix, String specifiedAttributeName) {
 		String qualifiedAttributeName;
 		if ( StringHelper.isNotEmpty( specifiedAttributeName ) ) {
 			if ( StringHelper.isNotEmpty( attributeNamePrefix ) ) {
 				qualifiedAttributeName = attributeNamePrefix + '.' + specifiedAttributeName;
 			}
 			else {
 				qualifiedAttributeName = specifiedAttributeName;
 			}
 		}
 		else {
 			qualifiedAttributeName = "";
 		}
 		return qualifiedAttributeName;
 	}
 
 	private void applyPhysicalConvertAnnotations(
 			String attributeNamePrefix,
 			Map<String, Convert> convertAnnotationsMap) {
 		final Convert physicalAnnotation = getPhysicalAnnotation( Convert.class );
 		if ( physicalAnnotation != null ) {
 			// only add if no XML element named a converter for this attribute
 			final String qualifiedAttributeName = qualifyConverterAttributeName( attributeNamePrefix, physicalAnnotation.attributeName() );
 			if ( ! convertAnnotationsMap.containsKey( qualifiedAttributeName ) ) {
 				convertAnnotationsMap.put( qualifiedAttributeName, physicalAnnotation );
 			}
 		}
 		final Converts physicalGroupingAnnotation = getPhysicalAnnotation( Converts.class );
 		if ( physicalGroupingAnnotation != null ) {
 			for ( Convert convertAnnotation : physicalGroupingAnnotation.value() ) {
 				// again, only add if no XML element named a converter for this attribute
 				final String qualifiedAttributeName = qualifyConverterAttributeName( attributeNamePrefix, convertAnnotation.attributeName() );
 				if ( ! convertAnnotationsMap.containsKey( qualifiedAttributeName ) ) {
 					convertAnnotationsMap.put( qualifiedAttributeName, convertAnnotation );
 				}
 			}
 		}
 	}
 
 	private void checkForOrphanProperties(Element tree) {
 		Class clazz;
 		try {
 			clazz = ReflectHelper.classForName( className, this.getClass() );
 		}
 		catch ( ClassNotFoundException e ) {
 			return; //a primitive type most likely
 		}
 		Element element = tree != null ? tree.element( "attributes" ) : null;
 		//put entity.attributes elements
 		if ( element != null ) {
 			//precompute the list of properties
 			//TODO is it really useful...
 			Set<String> properties = new HashSet<String>();
 			for ( Field field : clazz.getFields() ) {
 				properties.add( field.getName() );
 			}
 			for ( Method method : clazz.getMethods() ) {
 				String name = method.getName();
 				if ( name.startsWith( "get" ) ) {
 					properties.add( Introspector.decapitalize( name.substring( "get".length() ) ) );
 				}
 				else if ( name.startsWith( "is" ) ) {
 					properties.add( Introspector.decapitalize( name.substring( "is".length() ) ) );
 				}
 			}
 			for ( Element subelement : (List<Element>) element.elements() ) {
 				String propertyName = subelement.attributeValue( "name" );
 				if ( !properties.contains( propertyName ) ) {
 					LOG.propertyNotFound( StringHelper.qualify( className, propertyName ) );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Adds {@code annotation} to the list (only if it's not null) and then returns it.
 	 *
 	 * @param annotationList The list of annotations.
 	 * @param annotation The annotation to add to the list.
 	 *
 	 * @return The annotation which was added to the list or {@code null}.
 	 */
 	private Annotation addIfNotNull(List<Annotation> annotationList, Annotation annotation) {
 		if ( annotation != null ) {
 			annotationList.add( annotation );
 		}
 		return annotation;
 	}
 
 	//TODO mutualize the next 2 methods
 	private Annotation getTableGenerator(List<Element> elementsForProperty, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			Element subelement = element != null ? element.element( annotationToXml.get( TableGenerator.class ) ) : null;
 			if ( subelement != null ) {
 				return buildTableGeneratorAnnotation( subelement, defaults );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( TableGenerator.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private Annotation getSequenceGenerator(List<Element> elementsForProperty, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			Element subelement = element != null ? element.element( annotationToXml.get( SequenceGenerator.class ) ) : null;
 			if ( subelement != null ) {
 				return buildSequenceGeneratorAnnotation( subelement );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( SequenceGenerator.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void processEventAnnotations(List<Annotation> annotationList, XMLContext.Default defaults) {
 		boolean eventElement = false;
 		for ( Element element : elementsForProperty ) {
 			String elementName = element.getName();
 			if ( "pre-persist".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PrePersist.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "pre-remove".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PreRemove.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "pre-update".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PreUpdate.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "post-persist".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PostPersist.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "post-remove".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PostRemove.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "post-update".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PostUpdate.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "post-load".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PostLoad.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 		}
 		if ( !eventElement && defaults.canUseJavaAnnotations() ) {
 			Annotation ann = getPhysicalAnnotation( PrePersist.class );
 			addIfNotNull( annotationList, ann );
 			ann = getPhysicalAnnotation( PreRemove.class );
 			addIfNotNull( annotationList, ann );
 			ann = getPhysicalAnnotation( PreUpdate.class );
 			addIfNotNull( annotationList, ann );
 			ann = getPhysicalAnnotation( PostPersist.class );
 			addIfNotNull( annotationList, ann );
 			ann = getPhysicalAnnotation( PostRemove.class );
 			addIfNotNull( annotationList, ann );
 			ann = getPhysicalAnnotation( PostUpdate.class );
 			addIfNotNull( annotationList, ann );
 			ann = getPhysicalAnnotation( PostLoad.class );
 			addIfNotNull( annotationList, ann );
 		}
 	}
 
 	private EntityListeners getEntityListeners(Element tree, XMLContext.Default defaults) {
 		Element element = tree != null ? tree.element( "entity-listeners" ) : null;
 		if ( element != null ) {
 			List<Class> entityListenerClasses = new ArrayList<Class>();
 			for ( Element subelement : (List<Element>) element.elements( "entity-listener" ) ) {
 				String className = subelement.attributeValue( "class" );
 				try {
 					entityListenerClasses.add(
 							ReflectHelper.classForName(
 									XMLContext.buildSafeClassName( className, defaults ),
 									this.getClass()
 							)
 					);
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException(
 							"Unable to find " + element.getPath() + ".class: " + className, e
 					);
 				}
 			}
 			AnnotationDescriptor ad = new AnnotationDescriptor( EntityListeners.class );
 			ad.setValue( "value", entityListenerClasses.toArray( new Class[entityListenerClasses.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( EntityListeners.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private JoinTable overridesDefaultsInJoinTable(Annotation annotation, XMLContext.Default defaults) {
 		//no element but might have some default or some annotation
 		boolean defaultToJoinTable = !( isPhysicalAnnotationPresent( JoinColumn.class )
 				|| isPhysicalAnnotationPresent( JoinColumns.class ) );
 		final Class<? extends Annotation> annotationClass = annotation.annotationType();
 		defaultToJoinTable = defaultToJoinTable &&
 				( ( annotationClass == ManyToMany.class && StringHelper.isEmpty( ( (ManyToMany) annotation ).mappedBy() ) )
 						|| ( annotationClass == OneToMany.class && StringHelper.isEmpty( ( (OneToMany) annotation ).mappedBy() ) )
 						|| ( annotationClass == ElementCollection.class )
 				);
 		final Class<JoinTable> annotationType = JoinTable.class;
 		if ( defaultToJoinTable
 				&& ( StringHelper.isNotEmpty( defaults.getCatalog() )
 				|| StringHelper.isNotEmpty( defaults.getSchema() ) ) ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( annotationType );
 			if ( defaults.canUseJavaAnnotations() ) {
 				JoinTable table = getPhysicalAnnotation( annotationType );
 				if ( table != null ) {
 					ad.setValue( "name", table.name() );
 					ad.setValue( "schema", table.schema() );
 					ad.setValue( "catalog", table.catalog() );
 					ad.setValue( "uniqueConstraints", table.uniqueConstraints() );
 					ad.setValue( "joinColumns", table.joinColumns() );
 					ad.setValue( "inverseJoinColumns", table.inverseJoinColumns() );
 				}
 			}
 			if ( StringHelper.isEmpty( (String) ad.valueOf( "schema" ) )
 					&& StringHelper.isNotEmpty( defaults.getSchema() ) ) {
 				ad.setValue( "schema", defaults.getSchema() );
 			}
 			if ( StringHelper.isEmpty( (String) ad.valueOf( "catalog" ) )
 					&& StringHelper.isNotEmpty( defaults.getCatalog() ) ) {
 				ad.setValue( "catalog", defaults.getCatalog() );
 			}
 			return AnnotationFactory.create( ad );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( annotationType );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void getJoinTable(List<Annotation> annotationList, Element tree, XMLContext.Default defaults) {
 		addIfNotNull( annotationList, buildJoinTable( tree, defaults ) );
 	}
 
 	/*
 	 * no partial overriding possible
 	 */
 	private JoinTable buildJoinTable(Element tree, XMLContext.Default defaults) {
 		Element subelement = tree == null ? null : tree.element( "join-table" );
 		final Class<JoinTable> annotationType = JoinTable.class;
 		if ( subelement == null ) {
 			return null;
 		}
 		//ignore java annotation, an element is defined
 		AnnotationDescriptor annotation = new AnnotationDescriptor( annotationType );
 		copyStringAttribute( annotation, subelement, "name", false );
 		copyStringAttribute( annotation, subelement, "catalog", false );
 		if ( StringHelper.isNotEmpty( defaults.getCatalog() )
 				&& StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) ) ) {
 			annotation.setValue( "catalog", defaults.getCatalog() );
 		}
 		copyStringAttribute( annotation, subelement, "schema", false );
 		if ( StringHelper.isNotEmpty( defaults.getSchema() )
 				&& StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) ) ) {
 			annotation.setValue( "schema", defaults.getSchema() );
 		}
 		buildUniqueConstraints( annotation, subelement );
 		buildIndex( annotation, subelement );
 		annotation.setValue( "joinColumns", getJoinColumns( subelement, false ) );
 		annotation.setValue( "inverseJoinColumns", getJoinColumns( subelement, true ) );
 		return AnnotationFactory.create( annotation );
 	}
 
 	/**
 	 * As per section 12.2 of the JPA 2.0 specification, the association
 	 * subelements (many-to-one, one-to-many, one-to-one, many-to-many,
 	 * element-collection) completely override the mapping for the specified
 	 * field or property.  Thus, any methods which might in some contexts merge
 	 * with annotations must not do so in this context.
 	 *
 	 * @see #getElementCollection(List, org.hibernate.cfg.annotations.reflection.XMLContext.Default)
 	 */
 	private void getAssociation(
 			Class<? extends Annotation> annotationType, List<Annotation> annotationList, XMLContext.Default defaults
 	) {
 		String xmlName = annotationToXml.get( annotationType );
 		for ( Element element : elementsForProperty ) {
 			if ( xmlName.equals( element.getName() ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( annotationType );
 				addTargetClass( element, ad, "target-entity", defaults );
 				getFetchType( ad, element );
 				getCascades( ad, element, defaults );
 				getJoinTable( annotationList, element, defaults );
 				buildJoinColumns( annotationList, element );
 				Annotation annotation = getPrimaryKeyJoinColumns( element, defaults, false );
 				addIfNotNull( annotationList, annotation );
 				copyBooleanAttribute( ad, element, "optional" );
 				copyBooleanAttribute( ad, element, "orphan-removal" );
 				copyStringAttribute( ad, element, "mapped-by", false );
 				getOrderBy( annotationList, element );
 				getMapKey( annotationList, element );
 				getMapKeyClass( annotationList, element, defaults );
 				getMapKeyColumn( annotationList, element );
 				getOrderColumn( annotationList, element );
 				getMapKeyTemporal( annotationList, element );
 				getMapKeyEnumerated( annotationList, element );
 				annotation = getMapKeyAttributeOverrides( element, defaults );
 				addIfNotNull( annotationList, annotation );
 				buildMapKeyJoinColumns( annotationList, element );
 				getAssociationId( annotationList, element );
 				getMapsId( annotationList, element );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				getAccessType( annotationList, element );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			Annotation annotation = getPhysicalAnnotation( annotationType );
 			if ( annotation != null ) {
 				annotationList.add( annotation );
 				annotation = overridesDefaultsInJoinTable( annotation, defaults );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( JoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( JoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( PrimaryKeyJoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( PrimaryKeyJoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKey.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( OrderBy.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Lob.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Enumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Temporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Column.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Columns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyClass.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyTemporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyEnumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyJoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyJoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( OrderColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Cascade.class );
 				addIfNotNull( annotationList, annotation );
 			}
 			else if ( isPhysicalAnnotationPresent( ElementCollection.class ) ) { //JPA2
 				annotation = overridesDefaultsInJoinTable( getPhysicalAnnotation( ElementCollection.class ), defaults );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKey.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( OrderBy.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Lob.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Enumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Temporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Column.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( OrderColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyClass.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyTemporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyEnumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyJoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( MapKeyJoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( CollectionTable.class );
 				addIfNotNull( annotationList, annotation );
 			}
 		}
 	}
 
 	private void buildMapKeyJoinColumns(List<Annotation> annotationList, Element element) {
 		MapKeyJoinColumn[] joinColumns = getMapKeyJoinColumns( element );
 		if ( joinColumns.length > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyJoinColumns.class );
 			ad.setValue( "value", joinColumns );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private MapKeyJoinColumn[] getMapKeyJoinColumns(Element element) {
 		List<Element> subelements = element != null ? element.elements( "map-key-join-column" ) : null;
 		List<MapKeyJoinColumn> joinColumns = new ArrayList<MapKeyJoinColumn>();
 		if ( subelements != null ) {
 			for ( Element subelement : subelements ) {
 				AnnotationDescriptor column = new AnnotationDescriptor( MapKeyJoinColumn.class );
 				copyStringAttribute( column, subelement, "name", false );
 				copyStringAttribute( column, subelement, "referenced-column-name", false );
 				copyBooleanAttribute( column, subelement, "unique" );
 				copyBooleanAttribute( column, subelement, "nullable" );
 				copyBooleanAttribute( column, subelement, "insertable" );
 				copyBooleanAttribute( column, subelement, "updatable" );
 				copyStringAttribute( column, subelement, "column-definition", false );
 				copyStringAttribute( column, subelement, "table", false );
 				joinColumns.add( (MapKeyJoinColumn) AnnotationFactory.create( column ) );
 			}
 		}
 		return joinColumns.toArray( new MapKeyJoinColumn[joinColumns.size()] );
 	}
 
 	private AttributeOverrides getMapKeyAttributeOverrides(Element tree, XMLContext.Default defaults) {
 		List<AttributeOverride> attributes = buildAttributeOverrides( tree, "map-key-attribute-override" );
 		return mergeAttributeOverrides( defaults, attributes, false );
 	}
 
 	private Cacheable getCacheable(Element element, XMLContext.Default defaults){
 		if ( element != null ) {
 			String attValue = element.attributeValue( "cacheable" );
 			if ( attValue != null ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( Cacheable.class );
 				ad.setValue( "value", Boolean.valueOf( attValue ) );
 				return AnnotationFactory.create( ad );
 			}
 		}
 		if ( defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( Cacheable.class );
 		}
 		else {
 			return null;
 		}
 	}
 	/**
 	 * Adds a @MapKeyEnumerated annotation to the specified annotationList if the specified element
 	 * contains a map-key-enumerated sub-element. This should only be the case for
 	 * element-collection, many-to-many, or one-to-many associations.
 	 */
 	private void getMapKeyEnumerated(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "map-key-enumerated" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyEnumerated.class );
 			EnumType value = EnumType.valueOf( subelement.getTextTrim() );
 			ad.setValue( "value", value );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * Adds a @MapKeyTemporal annotation to the specified annotationList if the specified element
 	 * contains a map-key-temporal sub-element. This should only be the case for element-collection,
 	 * many-to-many, or one-to-many associations.
 	 */
 	private void getMapKeyTemporal(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "map-key-temporal" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyTemporal.class );
 			TemporalType value = TemporalType.valueOf( subelement.getTextTrim() );
 			ad.setValue( "value", value );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * Adds an @OrderColumn annotation to the specified annotationList if the specified element
 	 * contains an order-column sub-element. This should only be the case for element-collection,
 	 * many-to-many, or one-to-many associations.
 	 */
 	private void getOrderColumn(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "order-column" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( OrderColumn.class );
 			copyStringAttribute( ad, subelement, "name", false );
 			copyBooleanAttribute( ad, subelement, "nullable" );
 			copyBooleanAttribute( ad, subelement, "insertable" );
 			copyBooleanAttribute( ad, subelement, "updatable" );
 			copyStringAttribute( ad, subelement, "column-definition", false );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * Adds a @MapsId annotation to the specified annotationList if the specified element has the
 	 * maps-id attribute set. This should only be the case for many-to-one or one-to-one
 	 * associations.
 	 */
 	private void getMapsId(List<Annotation> annotationList, Element element) {
 		String attrVal = element.attributeValue( "maps-id" );
 		if ( attrVal != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapsId.class );
 			ad.setValue( "value", attrVal );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * Adds an @Id annotation to the specified annotationList if the specified element has the id
 	 * attribute set to true. This should only be the case for many-to-one or one-to-one
 	 * associations.
 	 */
 	private void getAssociationId(List<Annotation> annotationList, Element element) {
 		String attrVal = element.attributeValue( "id" );
 		if ( "true".equals( attrVal ) ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( Id.class );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void addTargetClass(Element element, AnnotationDescriptor ad, String nodeName, XMLContext.Default defaults) {
 		String className = element.attributeValue( nodeName );
 		if ( className != null ) {
 			Class clazz;
 			try {
 				clazz = ReflectHelper.classForName(
 						XMLContext.buildSafeClassName( className, defaults ), this.getClass()
 				);
 			}
 			catch ( ClassNotFoundException e ) {
 				throw new AnnotationException(
 						"Unable to find " + element.getPath() + " " + nodeName + ": " + className, e
 				);
 			}
 			ad.setValue( getJavaAttributeNameFromXMLOne( nodeName ), clazz );
 		}
 	}
 
 	/**
 	 * As per sections 12.2.3.23.9, 12.2.4.8.9 and 12.2.5.3.6 of the JPA 2.0
 	 * specification, the element-collection subelement completely overrides the
 	 * mapping for the specified field or property.  Thus, any methods which
 	 * might in some contexts merge with annotations must not do so in this
 	 * context.
 	 */
 	private void getElementCollection(List<Annotation> annotationList, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "element-collection".equals( element.getName() ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( ElementCollection.class );
 				addTargetClass( element, ad, "target-class", defaults );
 				getFetchType( ad, element );
 				getOrderBy( annotationList, element );
 				getOrderColumn( annotationList, element );
 				getMapKey( annotationList, element );
 				getMapKeyClass( annotationList, element, defaults );
 				getMapKeyTemporal( annotationList, element );
 				getMapKeyEnumerated( annotationList, element );
 				getMapKeyColumn( annotationList, element );
 				buildMapKeyJoinColumns( annotationList, element );
 				Annotation annotation = getColumn( element.element( "column" ), false, element );
 				addIfNotNull( annotationList, annotation );
 				getTemporal( annotationList, element );
 				getEnumerated( annotationList, element );
 				getLob( annotationList, element );
 				//Both map-key-attribute-overrides and attribute-overrides
 				//translate into AttributeOverride annotations, which need
 				//need to be wrapped in the same AttributeOverrides annotation.
 				List<AttributeOverride> attributes = new ArrayList<AttributeOverride>();
 				attributes.addAll( buildAttributeOverrides( element, "map-key-attribute-override" ) );
 				attributes.addAll( buildAttributeOverrides( element, "attribute-override" ) );
 				annotation = mergeAttributeOverrides( defaults, attributes, false );
 				addIfNotNull( annotationList, annotation );
 				annotation = getAssociationOverrides( element, defaults, false );
 				addIfNotNull( annotationList, annotation );
 				getCollectionTable( annotationList, element, defaults );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				getAccessType( annotationList, element );
 			}
 		}
 	}
 
 	private void getOrderBy(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "order-by" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( OrderBy.class );
 			copyStringElement( subelement, ad, "value" );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getMapKey(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "map-key" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKey.class );
 			copyStringAttribute( ad, subelement, "name", false );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getMapKeyColumn(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "map-key-column" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyColumn.class );
 			copyStringAttribute( ad, subelement, "name", false );
 			copyBooleanAttribute( ad, subelement, "unique" );
 			copyBooleanAttribute( ad, subelement, "nullable" );
 			copyBooleanAttribute( ad, subelement, "insertable" );
 			copyBooleanAttribute( ad, subelement, "updatable" );
 			copyStringAttribute( ad, subelement, "column-definition", false );
 			copyStringAttribute( ad, subelement, "table", false );
 			copyIntegerAttribute( ad, subelement, "length" );
 			copyIntegerAttribute( ad, subelement, "precision" );
 			copyIntegerAttribute( ad, subelement, "scale" );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getMapKeyClass(List<Annotation> annotationList, Element element, XMLContext.Default defaults) {
 		String nodeName = "map-key-class";
 		Element subelement = element != null ? element.element( nodeName ) : null;
 		if ( subelement != null ) {
 			String mapKeyClassName = subelement.attributeValue( "class" );
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyClass.class );
 			if ( StringHelper.isNotEmpty( mapKeyClassName ) ) {
 				Class clazz;
 				try {
 					clazz = ReflectHelper.classForName(
 							XMLContext.buildSafeClassName( mapKeyClassName, defaults ),
 							this.getClass()
 					);
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException(
 							"Unable to find " + element.getPath() + " " + nodeName + ": " + mapKeyClassName, e
 					);
 				}
 				ad.setValue( "value", clazz );
 			}
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getCollectionTable(List<Annotation> annotationList, Element element, XMLContext.Default defaults) {
 		Element subelement = element != null ? element.element( "collection-table" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor annotation = new AnnotationDescriptor( CollectionTable.class );
 			copyStringAttribute( annotation, subelement, "name", false );
 			copyStringAttribute( annotation, subelement, "catalog", false );
 			if ( StringHelper.isNotEmpty( defaults.getCatalog() )
 					&& StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) ) ) {
 				annotation.setValue( "catalog", defaults.getCatalog() );
 			}
 			copyStringAttribute( annotation, subelement, "schema", false );
 			if ( StringHelper.isNotEmpty( defaults.getSchema() )
 					&& StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) ) ) {
 				annotation.setValue( "schema", defaults.getSchema() );
 			}
 			JoinColumn[] joinColumns = getJoinColumns( subelement, false );
 			if ( joinColumns.length > 0 ) {
 				annotation.setValue( "joinColumns", joinColumns );
 			}
 			buildUniqueConstraints( annotation, subelement );
 			buildIndex( annotation, subelement );
 			annotationList.add( AnnotationFactory.create( annotation ) );
 		}
 	}
 
 	private void buildJoinColumns(List<Annotation> annotationList, Element element) {
 		JoinColumn[] joinColumns = getJoinColumns( element, false );
 		if ( joinColumns.length > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( JoinColumns.class );
 			ad.setValue( "value", joinColumns );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getCascades(AnnotationDescriptor ad, Element element, XMLContext.Default defaults) {
 		List<Element> elements = element != null ? element.elements( "cascade" ) : new ArrayList<Element>( 0 );
 		List<CascadeType> cascades = new ArrayList<CascadeType>();
 		for ( Element subelement : elements ) {
 			if ( subelement.element( "cascade-all" ) != null ) {
 				cascades.add( CascadeType.ALL );
 			}
 			if ( subelement.element( "cascade-persist" ) != null ) {
 				cascades.add( CascadeType.PERSIST );
 			}
 			if ( subelement.element( "cascade-merge" ) != null ) {
 				cascades.add( CascadeType.MERGE );
 			}
 			if ( subelement.element( "cascade-remove" ) != null ) {
 				cascades.add( CascadeType.REMOVE );
 			}
 			if ( subelement.element( "cascade-refresh" ) != null ) {
 				cascades.add( CascadeType.REFRESH );
 			}
 			if ( subelement.element( "cascade-detach" ) != null ) {
 				cascades.add( CascadeType.DETACH );
 			}
 		}
 		if ( Boolean.TRUE.equals( defaults.getCascadePersist() )
 				&& !cascades.contains( CascadeType.ALL ) && !cascades.contains( CascadeType.PERSIST ) ) {
 			cascades.add( CascadeType.PERSIST );
 		}
 		if ( cascades.size() > 0 ) {
 			ad.setValue( "cascade", cascades.toArray( new CascadeType[cascades.size()] ) );
 		}
 	}
 
 	private void getEmbedded(List<Annotation> annotationList, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "embedded".equals( element.getName() ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( Embedded.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				Annotation annotation = getAttributeOverrides( element, defaults, false );
 				addIfNotNull( annotationList, annotation );
 				annotation = getAssociationOverrides( element, defaults, false );
 				addIfNotNull( annotationList, annotation );
 				getAccessType( annotationList, element );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			Annotation annotation = getPhysicalAnnotation( Embedded.class );
 			if ( annotation != null ) {
 				annotationList.add( annotation );
 				annotation = getPhysicalAnnotation( AttributeOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverrides.class );
 				addIfNotNull( annotationList, annotation );
 			}
 		}
 	}
 
 	private Transient getTransient(XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "transient".equals( element.getName() ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( Transient.class );
 				return AnnotationFactory.create( ad );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( Transient.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void getVersion(List<Annotation> annotationList, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "version".equals( element.getName() ) ) {
 				Annotation annotation = buildColumns( element );
 				addIfNotNull( annotationList, annotation );
 				getTemporal( annotationList, element );
 				AnnotationDescriptor basic = new AnnotationDescriptor( Version.class );
 				annotationList.add( AnnotationFactory.create( basic ) );
 				getAccessType( annotationList, element );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			//we have nothing, so Java annotations might occurs
 			Annotation annotation = getPhysicalAnnotation( Version.class );
 			if ( annotation != null ) {
 				annotationList.add( annotation );
 				annotation = getPhysicalAnnotation( Column.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Columns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Temporal.class );
 				addIfNotNull( annotationList, annotation );
 			}
 		}
 	}
 
 	private void getBasic(List<Annotation> annotationList, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "basic".equals( element.getName() ) ) {
 				Annotation annotation = buildColumns( element );
 				addIfNotNull( annotationList, annotation );
 				getAccessType( annotationList, element );
 				getTemporal( annotationList, element );
 				getLob( annotationList, element );
 				getEnumerated( annotationList, element );
 				AnnotationDescriptor basic = new AnnotationDescriptor( Basic.class );
 				getFetchType( basic, element );
 				copyBooleanAttribute( basic, element, "optional" );
 				annotationList.add( AnnotationFactory.create( basic ) );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			//no annotation presence constraint, basic is the default
 			Annotation annotation = getPhysicalAnnotation( Basic.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( Lob.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( Enumerated.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( Temporal.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( Column.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( Columns.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( AttributeOverride.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( AttributeOverrides.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( AssociationOverride.class );
 			addIfNotNull( annotationList, annotation );
 			annotation = getPhysicalAnnotation( AssociationOverrides.class );
 			addIfNotNull( annotationList, annotation );
 		}
 	}
 
 	private void getEnumerated(List<Annotation> annotationList, Element element) {
 		Element subElement = element != null ? element.element( "enumerated" ) : null;
 		if ( subElement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( Enumerated.class );
 			String enumerated = subElement.getTextTrim();
 			if ( "ORDINAL".equalsIgnoreCase( enumerated ) ) {
 				ad.setValue( "value", EnumType.ORDINAL );
 			}
 			else if ( "STRING".equalsIgnoreCase( enumerated ) ) {
 				ad.setValue( "value", EnumType.STRING );
 			}
 			else if ( StringHelper.isNotEmpty( enumerated ) ) {
 				throw new AnnotationException( "Unknown EnumType: " + enumerated + ". " + SCHEMA_VALIDATION );
 			}
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getLob(List<Annotation> annotationList, Element element) {
 		Element subElement = element != null ? element.element( "lob" ) : null;
 		if ( subElement != null ) {
 			annotationList.add( AnnotationFactory.create( new AnnotationDescriptor( Lob.class ) ) );
 		}
 	}
 
 	private void getFetchType(AnnotationDescriptor descriptor, Element element) {
 		String fetchString = element != null ? element.attributeValue( "fetch" ) : null;
 		if ( fetchString != null ) {
 			if ( "eager".equalsIgnoreCase( fetchString ) ) {
 				descriptor.setValue( "fetch", FetchType.EAGER );
 			}
 			else if ( "lazy".equalsIgnoreCase( fetchString ) ) {
 				descriptor.setValue( "fetch", FetchType.LAZY );
 			}
 		}
 	}
 
 	private void getEmbeddedId(List<Annotation> annotationList, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "embedded-id".equals( element.getName() ) ) {
 				if ( isProcessingId( defaults ) ) {
 					Annotation annotation = getAttributeOverrides( element, defaults, false );
 					addIfNotNull( annotationList, annotation );
 					annotation = getAssociationOverrides( element, defaults, false );
 					addIfNotNull( annotationList, annotation );
 					AnnotationDescriptor ad = new AnnotationDescriptor( EmbeddedId.class );
 					annotationList.add( AnnotationFactory.create( ad ) );
 					getAccessType( annotationList, element );
 				}
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			Annotation annotation = getPhysicalAnnotation( EmbeddedId.class );
 			if ( annotation != null ) {
 				annotationList.add( annotation );
 				annotation = getPhysicalAnnotation( Column.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Columns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( GeneratedValue.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Temporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( TableGenerator.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( SequenceGenerator.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverrides.class );
 				addIfNotNull( annotationList, annotation );
 			}
 		}
 	}
 
 	private void preCalculateElementsForProperty(Element tree) {
 		elementsForProperty = new ArrayList<Element>();
 		Element element = tree != null ? tree.element( "attributes" ) : null;
 		//put entity.attributes elements
 		if ( element != null ) {
 			for ( Element subelement : (List<Element>) element.elements() ) {
 				if ( propertyName.equals( subelement.attributeValue( "name" ) ) ) {
 					elementsForProperty.add( subelement );
 				}
 			}
 		}
 		//add pre-* etc from entity and pure entity listener classes
 		if ( tree != null ) {
 			for ( Element subelement : (List<Element>) tree.elements() ) {
 				if ( propertyName.equals( subelement.attributeValue( "method-name" ) ) ) {
 					elementsForProperty.add( subelement );
 				}
 			}
 		}
 	}
 
 	private void getId(List<Annotation> annotationList, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "id".equals( element.getName() ) ) {
 				boolean processId = isProcessingId( defaults );
 				if ( processId ) {
 					Annotation annotation = buildColumns( element );
 					addIfNotNull( annotationList, annotation );
 					annotation = buildGeneratedValue( element );
 					addIfNotNull( annotationList, annotation );
 					getTemporal( annotationList, element );
 					//FIXME: fix the priority of xml over java for generator names
 					annotation = getTableGenerator( element, defaults );
 					addIfNotNull( annotationList, annotation );
 					annotation = getSequenceGenerator( element, defaults );
 					addIfNotNull( annotationList, annotation );
 					AnnotationDescriptor id = new AnnotationDescriptor( Id.class );
 					annotationList.add( AnnotationFactory.create( id ) );
 					getAccessType( annotationList, element );
 				}
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			Annotation annotation = getPhysicalAnnotation( Id.class );
 			if ( annotation != null ) {
 				annotationList.add( annotation );
 				annotation = getPhysicalAnnotation( Column.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Columns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( GeneratedValue.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( Temporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( TableGenerator.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( SequenceGenerator.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AttributeOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getPhysicalAnnotation( AssociationOverrides.class );
 				addIfNotNull( annotationList, annotation );
 			}
 		}
 	}
 
 	private boolean isProcessingId(XMLContext.Default defaults) {
 		boolean isExplicit = defaults.getAccess() != null;
 		boolean correctAccess =
 				( PropertyType.PROPERTY.equals( propertyType ) && AccessType.PROPERTY.equals( defaults.getAccess() ) )
 						|| ( PropertyType.FIELD.equals( propertyType ) && AccessType.FIELD
 						.equals( defaults.getAccess() ) );
 		boolean hasId = defaults.canUseJavaAnnotations()
 				&& ( isPhysicalAnnotationPresent( Id.class ) || isPhysicalAnnotationPresent( EmbeddedId.class ) );
 		//if ( properAccessOnMetadataComplete || properOverridingOnMetadataNonComplete ) {
 		boolean mirrorAttributeIsId = defaults.canUseJavaAnnotations() &&
 				( mirroredAttribute != null &&
 						( mirroredAttribute.isAnnotationPresent( Id.class )
 								|| mirroredAttribute.isAnnotationPresent( EmbeddedId.class ) ) );
 		boolean propertyIsDefault = PropertyType.PROPERTY.equals( propertyType )
 				&& !mirrorAttributeIsId;
 		return correctAccess || ( !isExplicit && hasId ) || ( !isExplicit && propertyIsDefault );
 	}
 
 	private Columns buildColumns(Element element) {
 		List<Element> subelements = element.elements( "column" );
 		List<Column> columns = new ArrayList<Column>( subelements.size() );
 		for ( Element subelement : subelements ) {
 			columns.add( getColumn( subelement, false, element ) );
 		}
 		if ( columns.size() > 0 ) {
 			AnnotationDescriptor columnsDescr = new AnnotationDescriptor( Columns.class );
 			columnsDescr.setValue( "columns", columns.toArray( new Column[columns.size()] ) );
 			return AnnotationFactory.create( columnsDescr );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private GeneratedValue buildGeneratedValue(Element element) {
 		Element subElement = element != null ? element.element( "generated-value" ) : null;
 		if ( subElement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( GeneratedValue.class );
 			String strategy = subElement.attributeValue( "strategy" );
 			if ( "TABLE".equalsIgnoreCase( strategy ) ) {
 				ad.setValue( "strategy", GenerationType.TABLE );
 			}
 			else if ( "SEQUENCE".equalsIgnoreCase( strategy ) ) {
 				ad.setValue( "strategy", GenerationType.SEQUENCE );
 			}
 			else if ( "IDENTITY".equalsIgnoreCase( strategy ) ) {
 				ad.setValue( "strategy", GenerationType.IDENTITY );
 			}
 			else if ( "AUTO".equalsIgnoreCase( strategy ) ) {
 				ad.setValue( "strategy", GenerationType.AUTO );
 			}
 			else if ( StringHelper.isNotEmpty( strategy ) ) {
 				throw new AnnotationException( "Unknown GenerationType: " + strategy + ". " + SCHEMA_VALIDATION );
 			}
 			copyStringAttribute( ad, subElement, "generator", false );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void getTemporal(List<Annotation> annotationList, Element element) {
 		Element subElement = element != null ? element.element( "temporal" ) : null;
 		if ( subElement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( Temporal.class );
 			String temporal = subElement.getTextTrim();
 			if ( "DATE".equalsIgnoreCase( temporal ) ) {
 				ad.setValue( "value", TemporalType.DATE );
 			}
 			else if ( "TIME".equalsIgnoreCase( temporal ) ) {
 				ad.setValue( "value", TemporalType.TIME );
 			}
 			else if ( "TIMESTAMP".equalsIgnoreCase( temporal ) ) {
 				ad.setValue( "value", TemporalType.TIMESTAMP );
 			}
 			else if ( StringHelper.isNotEmpty( temporal ) ) {
 				throw new AnnotationException( "Unknown TemporalType: " + temporal + ". " + SCHEMA_VALIDATION );
 			}
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getAccessType(List<Annotation> annotationList, Element element) {
 		if ( element == null ) {
 			return;
 		}
 		String access = element.attributeValue( "access" );
 		if ( access != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( Access.class );
 			AccessType type;
 			try {
 				type = AccessType.valueOf( access );
 			}
 			catch ( IllegalArgumentException e ) {
 				throw new AnnotationException( access + " is not a valid access type. Check you xml confguration." );
 			}
 
 			if ( ( AccessType.PROPERTY.equals( type ) && this.element instanceof Method ) ||
 					( AccessType.FIELD.equals( type ) && this.element instanceof Field ) ) {
 				return;
 			}
 
 			ad.setValue( "value", type );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * @param mergeWithAnnotations Whether to use Java annotations for this
 	 * element, if present and not disabled by the XMLContext defaults.
 	 * In some contexts (such as an element-collection mapping) merging
 	 * with annotations is never allowed.
 	 */
 	private AssociationOverrides getAssociationOverrides(Element tree, XMLContext.Default defaults, boolean mergeWithAnnotations) {
 		List<AssociationOverride> attributes = buildAssociationOverrides( tree, defaults );
 		if ( mergeWithAnnotations && defaults.canUseJavaAnnotations() ) {
 			AssociationOverride annotation = getPhysicalAnnotation( AssociationOverride.class );
 			addAssociationOverrideIfNeeded( annotation, attributes );
 			AssociationOverrides annotations = getPhysicalAnnotation( AssociationOverrides.class );
 			if ( annotations != null ) {
 				for ( AssociationOverride current : annotations.value() ) {
 					addAssociationOverrideIfNeeded( current, attributes );
 				}
 			}
 		}
 		if ( attributes.size() > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( AssociationOverrides.class );
 			ad.setValue( "value", attributes.toArray( new AssociationOverride[attributes.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private List<AssociationOverride> buildAssociationOverrides(Element element, XMLContext.Default defaults) {
 		List<Element> subelements = element == null ? null : element.elements( "association-override" );
 		List<AssociationOverride> overrides = new ArrayList<AssociationOverride>();
 		if ( subelements != null && subelements.size() > 0 ) {
 			for ( Element current : subelements ) {
 				AnnotationDescriptor override = new AnnotationDescriptor( AssociationOverride.class );
 				copyStringAttribute( override, current, "name", true );
 				override.setValue( "joinColumns", getJoinColumns( current, false ) );
 				JoinTable joinTable = buildJoinTable( current, defaults );
 				if ( joinTable != null ) {
 					override.setValue( "joinTable", joinTable );
 				}
 				overrides.add( (AssociationOverride) AnnotationFactory.create( override ) );
 			}
 		}
 		return overrides;
 	}
 
 	private JoinColumn[] getJoinColumns(Element element, boolean isInverse) {
 		List<Element> subelements = element != null ?
 				element.elements( isInverse ? "inverse-join-column" : "join-column" ) :
 				null;
 		List<JoinColumn> joinColumns = new ArrayList<JoinColumn>();
 		if ( subelements != null ) {
 			for ( Element subelement : subelements ) {
 				AnnotationDescriptor column = new AnnotationDescriptor( JoinColumn.class );
 				copyStringAttribute( column, subelement, "name", false );
 				copyStringAttribute( column, subelement, "referenced-column-name", false );
 				copyBooleanAttribute( column, subelement, "unique" );
 				copyBooleanAttribute( column, subelement, "nullable" );
 				copyBooleanAttribute( column, subelement, "insertable" );
 				copyBooleanAttribute( column, subelement, "updatable" );
 				copyStringAttribute( column, subelement, "column-definition", false );
 				copyStringAttribute( column, subelement, "table", false );
 				joinColumns.add( (JoinColumn) AnnotationFactory.create( column ) );
 			}
 		}
 		return joinColumns.toArray( new JoinColumn[joinColumns.size()] );
 	}
 
 	private void addAssociationOverrideIfNeeded(AssociationOverride annotation, List<AssociationOverride> overrides) {
 		if ( annotation != null ) {
 			String overrideName = annotation.name();
 			boolean present = false;
 			for ( AssociationOverride current : overrides ) {
 				if ( current.name().equals( overrideName ) ) {
 					present = true;
 					break;
 				}
 			}
 			if ( !present ) {
 				overrides.add( annotation );
 			}
 		}
 	}
 
 	/**
 	 * @param mergeWithAnnotations Whether to use Java annotations for this
 	 * element, if present and not disabled by the XMLContext defaults.
 	 * In some contexts (such as an association mapping) merging with
 	 * annotations is never allowed.
 	 */
 	private AttributeOverrides getAttributeOverrides(Element tree, XMLContext.Default defaults, boolean mergeWithAnnotations) {
 		List<AttributeOverride> attributes = buildAttributeOverrides( tree, "attribute-override" );
 		return mergeAttributeOverrides( defaults, attributes, mergeWithAnnotations );
 	}
 
 	/**
 	 * @param mergeWithAnnotations Whether to use Java annotations for this
 	 * element, if present and not disabled by the XMLContext defaults.
 	 * In some contexts (such as an association mapping) merging with
 	 * annotations is never allowed.
 	 */
 	private AttributeOverrides mergeAttributeOverrides(XMLContext.Default defaults, List<AttributeOverride> attributes, boolean mergeWithAnnotations) {
 		if ( mergeWithAnnotations && defaults.canUseJavaAnnotations() ) {
 			AttributeOverride annotation = getPhysicalAnnotation( AttributeOverride.class );
 			addAttributeOverrideIfNeeded( annotation, attributes );
 			AttributeOverrides annotations = getPhysicalAnnotation( AttributeOverrides.class );
 			if ( annotations != null ) {
 				for ( AttributeOverride current : annotations.value() ) {
 					addAttributeOverrideIfNeeded( current, attributes );
 				}
 			}
 		}
 		if ( attributes.size() > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( AttributeOverrides.class );
 			ad.setValue( "value", attributes.toArray( new AttributeOverride[attributes.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private List<AttributeOverride> buildAttributeOverrides(Element element, String nodeName) {
 		List<Element> subelements = element == null ? null : element.elements( nodeName );
 		return buildAttributeOverrides( subelements, nodeName );
 	}
 
 	private List<AttributeOverride> buildAttributeOverrides(List<Element> subelements, String nodeName) {
 		List<AttributeOverride> overrides = new ArrayList<AttributeOverride>();
 		if ( subelements != null && subelements.size() > 0 ) {
 			for ( Element current : subelements ) {
 				if ( !current.getName().equals( nodeName ) ) {
 					continue;
 				}
 				AnnotationDescriptor override = new AnnotationDescriptor( AttributeOverride.class );
 				copyStringAttribute( override, current, "name", true );
 				Element column = current.element( "column" );
 				override.setValue( "column", getColumn( column, true, current ) );
 				overrides.add( (AttributeOverride) AnnotationFactory.create( override ) );
 			}
 		}
 		return overrides;
 	}
 
 	private Column getColumn(Element element, boolean isMandatory, Element current) {
 		//Element subelement = element != null ? element.element( "column" ) : null;
 		if ( element != null ) {
 			AnnotationDescriptor column = new AnnotationDescriptor( Column.class );
 			copyStringAttribute( column, element, "name", false );
 			copyBooleanAttribute( column, element, "unique" );
 			copyBooleanAttribute( column, element, "nullable" );
 			copyBooleanAttribute( column, element, "insertable" );
 			copyBooleanAttribute( column, element, "updatable" );
 			copyStringAttribute( column, element, "column-definition", false );
 			copyStringAttribute( column, element, "table", false );
 			copyIntegerAttribute( column, element, "length" );
 			copyIntegerAttribute( column, element, "precision" );
 			copyIntegerAttribute( column, element, "scale" );
 			return (Column) AnnotationFactory.create( column );
 		}
 		else {
 			if ( isMandatory ) {
 				throw new AnnotationException( current.getPath() + ".column is mandatory. " + SCHEMA_VALIDATION );
 			}
 			return null;
 		}
 	}
 
 	private void addAttributeOverrideIfNeeded(AttributeOverride annotation, List<AttributeOverride> overrides) {
 		if ( annotation != null ) {
 			String overrideName = annotation.name();
 			boolean present = false;
 			for ( AttributeOverride current : overrides ) {
 				if ( current.name().equals( overrideName ) ) {
 					present = true;
 					break;
 				}
 			}
 			if ( !present ) {
 				overrides.add( annotation );
 			}
 		}
 	}
 
 	private Access getAccessType(Element tree, XMLContext.Default defaults) {
 		String access = tree == null ? null : tree.attributeValue( "access" );
 		if ( access != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( Access.class );
 			AccessType type;
 			try {
 				type = AccessType.valueOf( access );
 			}
 			catch ( IllegalArgumentException e ) {
 				throw new AnnotationException( access + " is not a valid access type. Check you xml confguration." );
 			}
 			ad.setValue( "value", type );
 			return AnnotationFactory.create( ad );
 		}
 		else if ( defaults.canUseJavaAnnotations() && isPhysicalAnnotationPresent( Access.class ) ) {
 			return getPhysicalAnnotation( Access.class );
 		}
 		else if ( defaults.getAccess() != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( Access.class );
 			ad.setValue( "value", defaults.getAccess() );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private ExcludeSuperclassListeners getExcludeSuperclassListeners(Element tree, XMLContext.Default defaults) {
 		return (ExcludeSuperclassListeners) getMarkerAnnotation( ExcludeSuperclassListeners.class, tree, defaults );
 	}
 
 	private ExcludeDefaultListeners getExcludeDefaultListeners(Element tree, XMLContext.Default defaults) {
 		return (ExcludeDefaultListeners) getMarkerAnnotation( ExcludeDefaultListeners.class, tree, defaults );
 	}
 
 	private Annotation getMarkerAnnotation(
 			Class<? extends Annotation> clazz, Element element, XMLContext.Default defaults
 	) {
 		Element subelement = element == null ? null : element.element( annotationToXml.get( clazz ) );
 		if ( subelement != null ) {
 			return AnnotationFactory.create( new AnnotationDescriptor( clazz ) );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			//TODO wonder whether it should be excluded so that user can undone it
 			return getPhysicalAnnotation( clazz );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private SqlResultSetMappings getSqlResultSetMappings(Element tree, XMLContext.Default defaults) {
 		List<SqlResultSetMapping> results = buildSqlResultsetMappings( tree, defaults );
 		if ( defaults.canUseJavaAnnotations() ) {
 			SqlResultSetMapping annotation = getPhysicalAnnotation( SqlResultSetMapping.class );
 			addSqlResultsetMappingIfNeeded( annotation, results );
 			SqlResultSetMappings annotations = getPhysicalAnnotation( SqlResultSetMappings.class );
 			if ( annotations != null ) {
 				for ( SqlResultSetMapping current : annotations.value() ) {
 					addSqlResultsetMappingIfNeeded( current, results );
 				}
 			}
 		}
 		if ( results.size() > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( SqlResultSetMappings.class );
 			ad.setValue( "value", results.toArray( new SqlResultSetMapping[results.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public static List<NamedEntityGraph> buildNamedEntityGraph(Element element, XMLContext.Default defaults) {
 		if ( element == null ) {
 			return new ArrayList<NamedEntityGraph>();
 		}
 		List<NamedEntityGraph> namedEntityGraphList = new ArrayList<NamedEntityGraph>();
 		List<Element> namedEntityGraphElements = element.elements( "named-entity-graph" );
 		for ( Element subElement : namedEntityGraphElements ) {
 			AnnotationDescriptor ann = new AnnotationDescriptor( NamedEntityGraph.class );
 			copyStringAttribute( ann, subElement, "name", false );
 			copyBooleanAttribute( ann, subElement, "include-all-attributes" );
 			bindNamedAttributeNodes( subElement, ann );
 
 			List<Element> subgraphNodes = subElement.elements( "subgraph" );
 			bindNamedSubgraph( defaults, ann, subgraphNodes );
 			List<Element> subclassSubgraphNodes = subElement.elements( "subclass-subgraph" );
 			bindNamedSubgraph( defaults, ann, subclassSubgraphNodes );
 			namedEntityGraphList.add( (NamedEntityGraph) AnnotationFactory.create( ann ) );
 		}
 		//TODO
 		return namedEntityGraphList;
 	}
 
 	private static void bindNamedSubgraph(XMLContext.Default defaults, AnnotationDescriptor ann, List<Element> subgraphNodes) {
 		List<NamedSubgraph> annSubgraphNodes = new ArrayList<NamedSubgraph>(  );
 		for(Element subgraphNode : subgraphNodes){
 			AnnotationDescriptor annSubgraphNode = new AnnotationDescriptor( NamedSubgraph.class );
 			copyStringAttribute( annSubgraphNode, subgraphNode, "name", true );
 			String clazzName = subgraphNode.attributeValue( "class" );
 			Class clazz;
 			try {
 				clazz = ReflectHelper.classForName(
 						XMLContext.buildSafeClassName( clazzName, defaults ),
 						JPAOverriddenAnnotationReader.class
 				);
 			}
 			catch ( ClassNotFoundException e ) {
 				throw new AnnotationException( "Unable to find entity-class: " + clazzName, e );
 			}
 			annSubgraphNode.setValue( "type", clazz );
 			bindNamedAttributeNodes(subgraphNode, annSubgraphNode);
 			annSubgraphNodes.add( (NamedSubgraph) AnnotationFactory.create( annSubgraphNode ) );
 		}
 		ann.setValue( "subgraphs", annSubgraphNodes.toArray( new NamedSubgraph[annSubgraphNodes.size()] ) );
 	}
 
 	private static void bindNamedAttributeNodes(Element subElement, AnnotationDescriptor ann) {
 		List<Element> namedAttributeNodes = subElement.elements("named-attribute-node");
 		List<NamedAttributeNode> annNamedAttributeNodes = new ArrayList<NamedAttributeNode>(  );
 		for(Element namedAttributeNode : namedAttributeNodes){
 			AnnotationDescriptor annNamedAttributeNode = new AnnotationDescriptor( NamedAttributeNode.class );
 			copyStringAttribute( annNamedAttributeNode, namedAttributeNode, "value", "name", true );
 			copyStringAttribute( annNamedAttributeNode, namedAttributeNode, "subgraph", false );
 			copyStringAttribute( annNamedAttributeNode, namedAttributeNode, "key-subgraph", false );
 			annNamedAttributeNodes.add( (NamedAttributeNode) AnnotationFactory.create( annNamedAttributeNode ) );
 		}
 		ann.setValue( "attributeNodes", annNamedAttributeNodes.toArray( new NamedAttributeNode[annNamedAttributeNodes.size()] ) );
 	}
 
 	public static List<NamedStoredProcedureQuery> buildNamedStoreProcedureQueries(Element element, XMLContext.Default defaults) {
 		if ( element == null ) {
 			return new ArrayList<NamedStoredProcedureQuery>();
 		}
 		List namedStoredProcedureElements = element.elements( "named-stored-procedure-query" );
 		List<NamedStoredProcedureQuery> namedStoredProcedureQueries = new ArrayList<NamedStoredProcedureQuery>();
 		for ( Object obj : namedStoredProcedureElements ) {
 			Element subElement = (Element) obj;
 			AnnotationDescriptor ann = new AnnotationDescriptor( NamedStoredProcedureQuery.class );
 			copyStringAttribute( ann, subElement, "name", true );
 			copyStringAttribute( ann, subElement, "procedure-name", true );
 
 			List<Element> elements = subElement.elements( "parameter" );
 			List<StoredProcedureParameter> storedProcedureParameters = new ArrayList<StoredProcedureParameter>();
 
 			for ( Element parameterElement : elements ) {
 				AnnotationDescriptor parameterDescriptor = new AnnotationDescriptor( StoredProcedureParameter.class );
 				copyStringAttribute( parameterDescriptor, parameterElement, "name", false );
 				String modeValue = parameterElement.attributeValue( "mode" );
 				if ( modeValue == null ) {
 					parameterDescriptor.setValue( "mode", ParameterMode.IN );
 				}
 				else {
-					parameterDescriptor.setValue( "mode", ParameterMode.valueOf( modeValue.toUpperCase() ) );
+					parameterDescriptor.setValue( "mode", ParameterMode.valueOf( modeValue.toUpperCase(Locale.ROOT) ) );
 				}
 				String clazzName = parameterElement.attributeValue( "class" );
 				Class clazz;
 				try {
 					clazz = ReflectHelper.classForName(
 							XMLContext.buildSafeClassName( clazzName, defaults ),
 							JPAOverriddenAnnotationReader.class
 					);
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException( "Unable to find entity-class: " + clazzName, e );
 				}
 				parameterDescriptor.setValue( "type", clazz );
 				storedProcedureParameters.add( (StoredProcedureParameter) AnnotationFactory.create( parameterDescriptor ) );
 			}
 
 			ann.setValue(
 					"parameters",
 					storedProcedureParameters.toArray( new StoredProcedureParameter[storedProcedureParameters.size()] )
 			);
 
 			elements = subElement.elements( "result-class" );
 			List<Class> returnClasses = new ArrayList<Class>();
 			for ( Element classElement : elements ) {
 				String clazzName = classElement.getTextTrim();
 				Class clazz;
 				try {
 					clazz = ReflectHelper.classForName(
 							XMLContext.buildSafeClassName( clazzName, defaults ),
 							JPAOverriddenAnnotationReader.class
 					);
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException( "Unable to find entity-class: " + clazzName, e );
 				}
 				returnClasses.add( clazz );
 			}
 			ann.setValue( "resultClasses", returnClasses.toArray( new Class[returnClasses.size()] ) );
 
 
 			elements = subElement.elements( "result-set-mapping" );
 			List<String> resultSetMappings = new ArrayList<String>();
 			for ( Element resultSetMappingElement : elements ) {
 				resultSetMappings.add( resultSetMappingElement.getTextTrim() );
 			}
 			ann.setValue( "resultSetMappings", resultSetMappings.toArray( new String[resultSetMappings.size()] ) );
 			elements = subElement.elements( "hint" );
 			buildQueryHints( elements, ann );
 			namedStoredProcedureQueries.add( (NamedStoredProcedureQuery) AnnotationFactory.create( ann ) );
 		}
 		return namedStoredProcedureQueries;
 
 	}
 
 	public static List<SqlResultSetMapping> buildSqlResultsetMappings(Element element, XMLContext.Default defaults) {
 		final List<SqlResultSetMapping> builtResultSetMappings = new ArrayList<SqlResultSetMapping>();
 		if ( element == null ) {
 			return builtResultSetMappings;
 		}
 
 		// iterate over each <sql-result-set-mapping/> element
 		for ( Object resultSetMappingElementObject : element.elements( "sql-result-set-mapping" ) ) {
 			final Element resultSetMappingElement = (Element) resultSetMappingElementObject;
 
 			final AnnotationDescriptor resultSetMappingAnnotation = new AnnotationDescriptor( SqlResultSetMapping.class );
 			copyStringAttribute( resultSetMappingAnnotation, resultSetMappingElement, "name", true );
 
 			// iterate over the <sql-result-set-mapping/> sub-elements, which should include:
 			//		* <entity-result/>
 			//		* <column-result/>
 			//		* <constructor-result/>
 
 			List<EntityResult> entityResultAnnotations = null;
 			List<ColumnResult> columnResultAnnotations = null;
 			List<ConstructorResult> constructorResultAnnotations = null;
 
 			for ( Object resultElementObject : resultSetMappingElement.elements() ) {
 				final Element resultElement = (Element) resultElementObject;
 
 				if ( "entity-result".equals( resultElement.getName() ) ) {
 					if ( entityResultAnnotations == null ) {
 						entityResultAnnotations = new ArrayList<EntityResult>();
 					}
 					// process the <entity-result/>
 					entityResultAnnotations.add( buildEntityResult( resultElement, defaults ) );
 				}
 				else if ( "column-result".equals( resultElement.getName() ) ) {
 					if ( columnResultAnnotations == null ) {
 						columnResultAnnotations = new ArrayList<ColumnResult>();
 					}
 					columnResultAnnotations.add( buildColumnResult( resultElement, defaults ) );
 				}
 				else if ( "constructor-result".equals( resultElement.getName() ) ) {
 					if ( constructorResultAnnotations == null ) {
 						constructorResultAnnotations = new ArrayList<ConstructorResult>();
 					}
 					constructorResultAnnotations.add( buildConstructorResult( resultElement, defaults ) );
 				}
 				else {
 					// most likely the <result-class/> this code used to handle.  I have left the code here,
 					// but commented it out for now.  I'll just log a warning for now.
 					LOG.debug( "Encountered unrecognized sql-result-set-mapping sub-element : " + resultElement.getName() );
 
 //					String clazzName = subelement.attributeValue( "result-class" );
 //					if ( StringHelper.isNotEmpty( clazzName ) ) {
 //						Class clazz;
 //						try {
 //							clazz = ReflectHelper.classForName(
 //									XMLContext.buildSafeClassName( clazzName, defaults ),
 //									JPAOverriddenAnnotationReader.class
 //							);
 //						}
 //						catch ( ClassNotFoundException e ) {
 //							throw new AnnotationException( "Unable to find entity-class: " + clazzName, e );
 //						}
 //						ann.setValue( "resultClass", clazz );
 //					}
 				}
 			}
 
 			if ( entityResultAnnotations != null && !entityResultAnnotations.isEmpty() ) {
 				resultSetMappingAnnotation.setValue(
 						"entities",
 						entityResultAnnotations.toArray( new EntityResult[entityResultAnnotations.size()] )
 				);
 			}
 			if ( columnResultAnnotations != null && !columnResultAnnotations.isEmpty() ) {
 				resultSetMappingAnnotation.setValue(
 						"columns",
 						columnResultAnnotations.toArray( new ColumnResult[columnResultAnnotations.size()] )
 				);
 			}
 			if ( constructorResultAnnotations != null && !constructorResultAnnotations.isEmpty() ) {
 				resultSetMappingAnnotation.setValue(
 						"classes",
 						constructorResultAnnotations.toArray( new ConstructorResult[constructorResultAnnotations.size()] )
 				);
 			}
 
 
 			// this was part of the old code too, but could never figure out what it is supposed to do...
 			// copyStringAttribute( ann, subelement, "result-set-mapping", false );
 
 			builtResultSetMappings.add( (SqlResultSetMapping) AnnotationFactory.create( resultSetMappingAnnotation ) );
 		}
 
 		return builtResultSetMappings;
 	}
 
 	private static EntityResult buildEntityResult(Element entityResultElement, XMLContext.Default defaults) {
 		final AnnotationDescriptor entityResultDescriptor = new AnnotationDescriptor( EntityResult.class );
 
 		final Class entityClass = resolveClassReference( entityResultElement.attributeValue( "entity-class" ), defaults );
 		entityResultDescriptor.setValue( "entityClass", entityClass );
 
 		copyStringAttribute( entityResultDescriptor, entityResultElement, "discriminator-column", false );
 
 		// process the <field-result/> sub-elements
 		List<FieldResult> fieldResultAnnotations = new ArrayList<FieldResult>();
 		for ( Element fieldResult : (List<Element>) entityResultElement.elements( "field-result" ) ) {
 			AnnotationDescriptor fieldResultDescriptor = new AnnotationDescriptor( FieldResult.class );
 			copyStringAttribute( fieldResultDescriptor, fieldResult, "name", true );
 			copyStringAttribute( fieldResultDescriptor, fieldResult, "column", true );
 			fieldResultAnnotations.add( (FieldResult) AnnotationFactory.create( fieldResultDescriptor ) );
 		}
 		entityResultDescriptor.setValue(
 				"fields", fieldResultAnnotations.toArray( new FieldResult[fieldResultAnnotations.size()] )
 		);
 		return AnnotationFactory.create( entityResultDescriptor );
 	}
 
 	private static Class resolveClassReference(String className, XMLContext.Default defaults) {
 		if ( className == null ) {
 			throw new AnnotationException( "<entity-result> without entity-class. " + SCHEMA_VALIDATION );
 		}
 		try {
 			return ReflectHelper.classForName(
 					XMLContext.buildSafeClassName( className, defaults ),
 					JPAOverriddenAnnotationReader.class
 			);
 		}
 		catch ( ClassNotFoundException e ) {
 			throw new AnnotationException( "Unable to find specified class: " + className, e );
 		}
 	}
 
 	private static ColumnResult buildColumnResult(Element columnResultElement, XMLContext.Default defaults) {
 //		AnnotationDescriptor columnResultDescriptor = new AnnotationDescriptor( ColumnResult.class );
 //		copyStringAttribute( columnResultDescriptor, columnResultElement, "name", true );
 //		return AnnotationFactory.create( columnResultDescriptor );
 
 		AnnotationDescriptor columnResultDescriptor = new AnnotationDescriptor( ColumnResult.class );
 		copyStringAttribute( columnResultDescriptor, columnResultElement, "name", true );
 		final String columnTypeName = columnResultElement.attributeValue( "class" );
 		if ( StringHelper.isNotEmpty( columnTypeName ) ) {
 			columnResultDescriptor.setValue( "type", resolveClassReference( columnTypeName, defaults ) );
 		}
 		return AnnotationFactory.create( columnResultDescriptor );
 	}
 
 	private static ConstructorResult buildConstructorResult(Element constructorResultElement, XMLContext.Default defaults) {
 		AnnotationDescriptor constructorResultDescriptor = new AnnotationDescriptor( ConstructorResult.class );
 
 		final Class entityClass = resolveClassReference( constructorResultElement.attributeValue( "target-class" ), defaults );
 		constructorResultDescriptor.setValue( "targetClass", entityClass );
 
 		List<ColumnResult> columnResultAnnotations = new ArrayList<ColumnResult>();
 		for ( Element columnResultElement : (List<Element>) constructorResultElement.elements( "column" ) ) {
 			columnResultAnnotations.add( buildColumnResult( columnResultElement, defaults ) );
 		}
 		constructorResultDescriptor.setValue(
 				"columns",
 				columnResultAnnotations.toArray( new ColumnResult[ columnResultAnnotations.size() ] )
 		);
 
 		return AnnotationFactory.create( constructorResultDescriptor );
 	}
 
 	private void addSqlResultsetMappingIfNeeded(SqlResultSetMapping annotation, List<SqlResultSetMapping> resultsets) {
 		if ( annotation != null ) {
 			String resultsetName = annotation.name();
 			boolean present = false;
 			for ( SqlResultSetMapping current : resultsets ) {
 				if ( current.name().equals( resultsetName ) ) {
 					present = true;
 					break;
 				}
 			}
 			if ( !present ) {
 				resultsets.add( annotation );
 			}
 		}
 	}
 
 	private NamedQueries getNamedQueries(Element tree, XMLContext.Default defaults) {
 		//TODO avoid the Proxy Creation (@NamedQueries) when possible
 		List<NamedQuery> queries = (List<NamedQuery>) buildNamedQueries( tree, false, defaults );
 		if ( defaults.canUseJavaAnnotations() ) {
 			NamedQuery annotation = getPhysicalAnnotation( NamedQuery.class );
 			addNamedQueryIfNeeded( annotation, queries );
 			NamedQueries annotations = getPhysicalAnnotation( NamedQueries.class );
 			if ( annotations != null ) {
 				for ( NamedQuery current : annotations.value() ) {
 					addNamedQueryIfNeeded( current, queries );
 				}
 			}
 		}
 		if ( queries.size() > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( NamedQueries.class );
 			ad.setValue( "value", queries.toArray( new NamedQuery[queries.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void addNamedQueryIfNeeded(NamedQuery annotation, List<NamedQuery> queries) {
 		if ( annotation != null ) {
 			String queryName = annotation.name();
 			boolean present = false;
 			for ( NamedQuery current : queries ) {
 				if ( current.name().equals( queryName ) ) {
 					present = true;
 					break;
 				}
 			}
 			if ( !present ) {
 				queries.add( annotation );
 			}
 		}
 	}
 
 	private NamedEntityGraphs getNamedEntityGraphs(Element tree, XMLContext.Default defaults) {
 		List<NamedEntityGraph> queries = buildNamedEntityGraph( tree, defaults );
 		if ( defaults.canUseJavaAnnotations() ) {
 			NamedEntityGraph annotation = getPhysicalAnnotation( NamedEntityGraph.class );
 			addNamedEntityGraphIfNeeded( annotation, queries );
 			NamedEntityGraphs annotations = getPhysicalAnnotation( NamedEntityGraphs.class );
 			if ( annotations != null ) {
 				for ( NamedEntityGraph current : annotations.value() ) {
 					addNamedEntityGraphIfNeeded( current, queries );
 				}
 			}
 		}
 		if ( queries.size() > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( NamedEntityGraphs.class );
 			ad.setValue( "value", queries.toArray( new NamedEntityGraph[queries.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void addNamedEntityGraphIfNeeded(NamedEntityGraph annotation, List<NamedEntityGraph> queries) {
 		if ( annotation != null ) {
 			String queryName = annotation.name();
 			boolean present = false;
 			for ( NamedEntityGraph current : queries ) {
 				if ( current.name().equals( queryName ) ) {
 					present = true;
 					break;
 				}
 			}
 			if ( !present ) {
 				queries.add( annotation );
 			}
 		}
 
 	}
 
 	private NamedStoredProcedureQueries getNamedStoredProcedureQueries(Element tree, XMLContext.Default defaults) {
 		List<NamedStoredProcedureQuery> queries = buildNamedStoreProcedureQueries( tree, defaults );
 		if ( defaults.canUseJavaAnnotations() ) {
 			NamedStoredProcedureQuery annotation = getPhysicalAnnotation( NamedStoredProcedureQuery.class );
 			addNamedStoredProcedureQueryIfNeeded( annotation, queries );
 			NamedStoredProcedureQueries annotations = getPhysicalAnnotation( NamedStoredProcedureQueries.class );
 			if ( annotations != null ) {
 				for ( NamedStoredProcedureQuery current : annotations.value() ) {
 					addNamedStoredProcedureQueryIfNeeded( current, queries );
 				}
 			}
 		}
 		if ( queries.size() > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( NamedStoredProcedureQueries.class );
 			ad.setValue( "value", queries.toArray( new NamedStoredProcedureQuery[queries.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void addNamedStoredProcedureQueryIfNeeded(NamedStoredProcedureQuery annotation, List<NamedStoredProcedureQuery> queries) {
 		if ( annotation != null ) {
 			String queryName = annotation.name();
 			boolean present = false;
 			for ( NamedStoredProcedureQuery current : queries ) {
 				if ( current.name().equals( queryName ) ) {
 					present = true;
 					break;
 				}
 			}
 			if ( !present ) {
 				queries.add( annotation );
 			}
 		}
 	}
 
 
 	private NamedNativeQueries getNamedNativeQueries(Element tree, XMLContext.Default defaults) {
 		List<NamedNativeQuery> queries = (List<NamedNativeQuery>) buildNamedQueries( tree, true, defaults );
 		if ( defaults.canUseJavaAnnotations() ) {
 			NamedNativeQuery annotation = getPhysicalAnnotation( NamedNativeQuery.class );
 			addNamedNativeQueryIfNeeded( annotation, queries );
 			NamedNativeQueries annotations = getPhysicalAnnotation( NamedNativeQueries.class );
 			if ( annotations != null ) {
 				for ( NamedNativeQuery current : annotations.value() ) {
 					addNamedNativeQueryIfNeeded( current, queries );
 				}
 			}
 		}
 		if ( queries.size() > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( NamedNativeQueries.class );
 			ad.setValue( "value", queries.toArray( new NamedNativeQuery[queries.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void addNamedNativeQueryIfNeeded(NamedNativeQuery annotation, List<NamedNativeQuery> queries) {
 		if ( annotation != null ) {
 			String queryName = annotation.name();
 			boolean present = false;
 			for ( NamedNativeQuery current : queries ) {
 				if ( current.name().equals( queryName ) ) {
 					present = true;
 					break;
 				}
 			}
 			if ( !present ) {
 				queries.add( annotation );
 			}
 		}
 	}
 
 	private static void buildQueryHints(List<Element> elements, AnnotationDescriptor ann){
 		List<QueryHint> queryHints = new ArrayList<QueryHint>( elements.size() );
 		for ( Element hint : elements ) {
 			AnnotationDescriptor hintDescriptor = new AnnotationDescriptor( QueryHint.class );
 			String value = hint.attributeValue( "name" );
 			if ( value == null ) {
 				throw new AnnotationException( "<hint> without name. " + SCHEMA_VALIDATION );
 			}
 			hintDescriptor.setValue( "name", value );
 			value = hint.attributeValue( "value" );
 			if ( value == null ) {
 				throw new AnnotationException( "<hint> without value. " + SCHEMA_VALIDATION );
 			}
 			hintDescriptor.setValue( "value", value );
 			queryHints.add( (QueryHint) AnnotationFactory.create( hintDescriptor ) );
 		}
 		ann.setValue( "hints", queryHints.toArray( new QueryHint[queryHints.size()] ) );
 	}
 
 	public static List buildNamedQueries(Element element, boolean isNative, XMLContext.Default defaults) {
 		if ( element == null ) {
 			return new ArrayList();
 		}
 		List namedQueryElementList = isNative ?
 				element.elements( "named-native-query" ) :
 				element.elements( "named-query" );
 		List namedQueries = new ArrayList();
 		Iterator it = namedQueryElementList.listIterator();
 		while ( it.hasNext() ) {
 			Element subelement = (Element) it.next();
 			AnnotationDescriptor ann = new AnnotationDescriptor(
 					isNative ? NamedNativeQuery.class : NamedQuery.class
 			);
 			copyStringAttribute( ann, subelement, "name", false );
 			Element queryElt = subelement.element( "query" );
 			if ( queryElt == null ) {
 				throw new AnnotationException( "No <query> element found." + SCHEMA_VALIDATION );
 			}
 			copyStringElement( queryElt, ann, "query" );
 			List<Element> elements = subelement.elements( "hint" );
 			buildQueryHints( elements, ann );
 			String clazzName = subelement.attributeValue( "result-class" );
 			if ( StringHelper.isNotEmpty( clazzName ) ) {
 				Class clazz;
 				try {
 					clazz = ReflectHelper.classForName(
 							XMLContext.buildSafeClassName( clazzName, defaults ),
 							JPAOverriddenAnnotationReader.class
 					);
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException( "Unable to find entity-class: " + clazzName, e );
 				}
 				ann.setValue( "resultClass", clazz );
 			}
 			copyStringAttribute( ann, subelement, "result-set-mapping", false );
 			namedQueries.add( AnnotationFactory.create( ann ) );
 		}
 		return namedQueries;
 	}
 
 	private TableGenerator getTableGenerator(Element tree, XMLContext.Default defaults) {
 		Element element = tree != null ? tree.element( annotationToXml.get( TableGenerator.class ) ) : null;
 		if ( element != null ) {
 			return buildTableGeneratorAnnotation( element, defaults );
 		}
 		else if ( defaults.canUseJavaAnnotations() && isPhysicalAnnotationPresent( TableGenerator.class ) ) {
 			TableGenerator tableAnn = getPhysicalAnnotation( TableGenerator.class );
 			if ( StringHelper.isNotEmpty( defaults.getSchema() )
 					|| StringHelper.isNotEmpty( defaults.getCatalog() ) ) {
 				AnnotationDescriptor annotation = new AnnotationDescriptor( TableGenerator.class );
 				annotation.setValue( "name", tableAnn.name() );
 				annotation.setValue( "table", tableAnn.table() );
 				annotation.setValue( "catalog", tableAnn.table() );
 				if ( StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) )
 						&& StringHelper.isNotEmpty( defaults.getCatalog() ) ) {
 					annotation.setValue( "catalog", defaults.getCatalog() );
 				}
 				annotation.setValue( "schema", tableAnn.table() );
 				if ( StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) )
 						&& StringHelper.isNotEmpty( defaults.getSchema() ) ) {
 					annotation.setValue( "catalog", defaults.getSchema() );
 				}
 				annotation.setValue( "pkColumnName", tableAnn.pkColumnName() );
 				annotation.setValue( "valueColumnName", tableAnn.valueColumnName() );
 				annotation.setValue( "pkColumnValue", tableAnn.pkColumnValue() );
 				annotation.setValue( "initialValue", tableAnn.initialValue() );
 				annotation.setValue( "allocationSize", tableAnn.allocationSize() );
 				annotation.setValue( "uniqueConstraints", tableAnn.uniqueConstraints() );
 				return AnnotationFactory.create( annotation );
 			}
 			else {
 				return tableAnn;
 			}
 		}
 		else {
 			return null;
 		}
 	}
 
 	public static TableGenerator buildTableGeneratorAnnotation(Element element, XMLContext.Default defaults) {
 		AnnotationDescriptor ad = new AnnotationDescriptor( TableGenerator.class );
 		copyStringAttribute( ad, element, "name", false );
 		copyStringAttribute( ad, element, "table", false );
 		copyStringAttribute( ad, element, "catalog", false );
 		copyStringAttribute( ad, element, "schema", false );
 		copyStringAttribute( ad, element, "pk-column-name", false );
 		copyStringAttribute( ad, element, "value-column-name", false );
 		copyStringAttribute( ad, element, "pk-column-value", false );
 		copyIntegerAttribute( ad, element, "initial-value" );
 		copyIntegerAttribute( ad, element, "allocation-size" );
 		buildUniqueConstraints( ad, element );
 		if ( StringHelper.isEmpty( (String) ad.valueOf( "schema" ) )
 				&& StringHelper.isNotEmpty( defaults.getSchema() ) ) {
 			ad.setValue( "schema", defaults.getSchema() );
 		}
 		if ( StringHelper.isEmpty( (String) ad.valueOf( "catalog" ) )
 				&& StringHelper.isNotEmpty( defaults.getCatalog() ) ) {
 			ad.setValue( "catalog", defaults.getCatalog() );
 		}
 		return AnnotationFactory.create( ad );
 	}
 
 	private SequenceGenerator getSequenceGenerator(Element tree, XMLContext.Default defaults) {
 		Element element = tree != null ? tree.element( annotationToXml.get( SequenceGenerator.class ) ) : null;
 		if ( element != null ) {
 			return buildSequenceGeneratorAnnotation( element );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( SequenceGenerator.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public static SequenceGenerator buildSequenceGeneratorAnnotation(Element element) {
 		if ( element != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( SequenceGenerator.class );
 			copyStringAttribute( ad, element, "name", false );
 			copyStringAttribute( ad, element, "sequence-name", false );
 			copyIntegerAttribute( ad, element, "initial-value" );
 			copyIntegerAttribute( ad, element, "allocation-size" );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private DiscriminatorColumn getDiscriminatorColumn(Element tree, XMLContext.Default defaults) {
 		Element element = tree != null ? tree.element( "discriminator-column" ) : null;
 		if ( element != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( DiscriminatorColumn.class );
 			copyStringAttribute( ad, element, "name", false );
 			copyStringAttribute( ad, element, "column-definition", false );
 			String value = element.attributeValue( "discriminator-type" );
 			DiscriminatorType type = DiscriminatorType.STRING;
 			if ( value != null ) {
 				if ( "STRING".equals( value ) ) {
 					type = DiscriminatorType.STRING;
 				}
 				else if ( "CHAR".equals( value ) ) {
 					type = DiscriminatorType.CHAR;
 				}
 				else if ( "INTEGER".equals( value ) ) {
 					type = DiscriminatorType.INTEGER;
 				}
 				else {
 					throw new AnnotationException(
 							"Unknown DiscrimiatorType in XML: " + value + " (" + SCHEMA_VALIDATION + ")"
 					);
 				}
 			}
 			ad.setValue( "discriminatorType", type );
 			copyIntegerAttribute( ad, element, "length" );
 			return AnnotationFactory.create( ad );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( DiscriminatorColumn.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private DiscriminatorValue getDiscriminatorValue(Element tree, XMLContext.Default defaults) {
 		Element element = tree != null ? tree.element( "discriminator-value" ) : null;
 		if ( element != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( DiscriminatorValue.class );
 			copyStringElement( element, ad, "value" );
 			return AnnotationFactory.create( ad );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( DiscriminatorValue.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private Inheritance getInheritance(Element tree, XMLContext.Default defaults) {
 		Element element = tree != null ? tree.element( "inheritance" ) : null;
 		if ( element != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( Inheritance.class );
 			Attribute attr = element.attribute( "strategy" );
 			InheritanceType strategy = InheritanceType.SINGLE_TABLE;
 			if ( attr != null ) {
 				String value = attr.getValue();
 				if ( "SINGLE_TABLE".equals( value ) ) {
 					strategy = InheritanceType.SINGLE_TABLE;
 				}
 				else if ( "JOINED".equals( value ) ) {
 					strategy = InheritanceType.JOINED;
 				}
 				else if ( "TABLE_PER_CLASS".equals( value ) ) {
 					strategy = InheritanceType.TABLE_PER_CLASS;
 				}
 				else {
 					throw new AnnotationException(
 							"Unknown InheritanceType in XML: " + value + " (" + SCHEMA_VALIDATION + ")"
 					);
 				}
 			}
 			ad.setValue( "strategy", strategy );
 			return AnnotationFactory.create( ad );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( Inheritance.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private IdClass getIdClass(Element tree, XMLContext.Default defaults) {
 		Element element = tree == null ? null : tree.element( "id-class" );
 		if ( element != null ) {
 			Attribute attr = element.attribute( "class" );
 			if ( attr != null ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( IdClass.class );
 				Class clazz;
 				try {
 					clazz = ReflectHelper.classForName(
 							XMLContext.buildSafeClassName( attr.getValue(), defaults ),
 							this.getClass()
 					);
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException( "Unable to find id-class: " + attr.getValue(), e );
 				}
 				ad.setValue( "value", clazz );
 				return AnnotationFactory.create( ad );
 			}
 			else {
 				throw new AnnotationException( "id-class without class. " + SCHEMA_VALIDATION );
 			}
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getPhysicalAnnotation( IdClass.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	/**
 	 * @param mergeWithAnnotations Whether to use Java annotations for this
 	 * element, if present and not disabled by the XMLContext defaults.
 	 * In some contexts (such as an association mapping) merging with
 	 * annotations is never allowed.
 	 */
 	private PrimaryKeyJoinColumns getPrimaryKeyJoinColumns(Element element, XMLContext.Default defaults, boolean mergeWithAnnotations) {
 		PrimaryKeyJoinColumn[] columns = buildPrimaryKeyJoinColumns( element );
 		if ( mergeWithAnnotations ) {
 			if ( columns.length == 0 && defaults.canUseJavaAnnotations() ) {
 				PrimaryKeyJoinColumn annotation = getPhysicalAnnotation( PrimaryKeyJoinColumn.class );
 				if ( annotation != null ) {
 					columns = new PrimaryKeyJoinColumn[] { annotation };
 				}
 				else {
 					PrimaryKeyJoinColumns annotations = getPhysicalAnnotation( PrimaryKeyJoinColumns.class );
 					columns = annotations != null ? annotations.value() : columns;
 				}
 			}
 		}
 		if ( columns.length > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( PrimaryKeyJoinColumns.class );
 			ad.setValue( "value", columns );
 			return AnnotationFactory.create( ad );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private Entity getEntity(Element tree, XMLContext.Default defaults) {
 		if ( tree == null ) {
 			return defaults.canUseJavaAnnotations() ? getPhysicalAnnotation( Entity.class ) : null;
 		}
 		else {
 			if ( "entity".equals( tree.getName() ) ) {
 				AnnotationDescriptor entity = new AnnotationDescriptor( Entity.class );
 				copyStringAttribute( entity, tree, "name", false );
 				if ( defaults.canUseJavaAnnotations()
 						&& StringHelper.isEmpty( (String) entity.valueOf( "name" ) ) ) {
 					Entity javaAnn = getPhysicalAnnotation( Entity.class );
 					if ( javaAnn != null ) {
 						entity.setValue( "name", javaAnn.name() );
 					}
 				}
 				return AnnotationFactory.create( entity );
 			}
 			else {
 				return null; //this is not an entity
 			}
 		}
 	}
 
 	private MappedSuperclass getMappedSuperclass(Element tree, XMLContext.Default defaults) {
 		if ( tree == null ) {
 			return defaults.canUseJavaAnnotations() ? getPhysicalAnnotation( MappedSuperclass.class ) : null;
 		}
 		else {
 			if ( "mapped-superclass".equals( tree.getName() ) ) {
 				AnnotationDescriptor entity = new AnnotationDescriptor( MappedSuperclass.class );
 				return AnnotationFactory.create( entity );
 			}
 			else {
 				return null; //this is not an entity
 			}
 		}
 	}
 
 	private Embeddable getEmbeddable(Element tree, XMLContext.Default defaults) {
 		if ( tree == null ) {
 			return defaults.canUseJavaAnnotations() ? getPhysicalAnnotation( Embeddable.class ) : null;
 		}
 		else {
 			if ( "embeddable".equals( tree.getName() ) ) {
 				AnnotationDescriptor entity = new AnnotationDescriptor( Embeddable.class );
 				return AnnotationFactory.create( entity );
 			}
 			else {
 				return null; //this is not an entity
 			}
 		}
 	}
 
 	private Table getTable(Element tree, XMLContext.Default defaults) {
 		Element subelement = tree == null ? null : tree.element( "table" );
 		if ( subelement == null ) {
 			//no element but might have some default or some annotation
 			if ( StringHelper.isNotEmpty( defaults.getCatalog() )
 					|| StringHelper.isNotEmpty( defaults.getSchema() ) ) {
 				AnnotationDescriptor annotation = new AnnotationDescriptor( Table.class );
 				if ( defaults.canUseJavaAnnotations() ) {
 					Table table = getPhysicalAnnotation( Table.class );
 					if ( table != null ) {
 						annotation.setValue( "name", table.name() );
 						annotation.setValue( "schema", table.schema() );
 						annotation.setValue( "catalog", table.catalog() );
 						annotation.setValue( "uniqueConstraints", table.uniqueConstraints() );
 						annotation.setValue( "indexes", table.indexes() );
 					}
 				}
 				if ( StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) )
 						&& StringHelper.isNotEmpty( defaults.getSchema() ) ) {
 					annotation.setValue( "schema", defaults.getSchema() );
 				}
 				if ( StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) )
 						&& StringHelper.isNotEmpty( defaults.getCatalog() ) ) {
 					annotation.setValue( "catalog", defaults.getCatalog() );
 				}
 				return AnnotationFactory.create( annotation );
 			}
 			else if ( defaults.canUseJavaAnnotations() ) {
 				return getPhysicalAnnotation( Table.class );
 			}
 			else {
 				return null;
 			}
 		}
 		else {
 			//ignore java annotation, an element is defined
 			AnnotationDescriptor annotation = new AnnotationDescriptor( Table.class );
 			copyStringAttribute( annotation, subelement, "name", false );
 			copyStringAttribute( annotation, subelement, "catalog", false );
 			if ( StringHelper.isNotEmpty( defaults.getCatalog() )
 					&& StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) ) ) {
 				annotation.setValue( "catalog", defaults.getCatalog() );
 			}
 			copyStringAttribute( annotation, subelement, "schema", false );
 			if ( StringHelper.isNotEmpty( defaults.getSchema() )
 					&& StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) ) ) {
 				annotation.setValue( "schema", defaults.getSchema() );
 			}
 			buildUniqueConstraints( annotation, subelement );
 			buildIndex( annotation, subelement );
 			return AnnotationFactory.create( annotation );
 		}
 	}
 
 	private SecondaryTables getSecondaryTables(Element tree, XMLContext.Default defaults) {
 		List<Element> elements = tree == null ?
 				new ArrayList<Element>() :
 				(List<Element>) tree.elements( "secondary-table" );
 		List<SecondaryTable> secondaryTables = new ArrayList<SecondaryTable>( 3 );
 		for ( Element element : elements ) {
 			AnnotationDescriptor annotation = new AnnotationDescriptor( SecondaryTable.class );
 			copyStringAttribute( annotation, element, "name", false );
 			copyStringAttribute( annotation, element, "catalog", false );
 			if ( StringHelper.isNotEmpty( defaults.getCatalog() )
 					&& StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) ) ) {
 				annotation.setValue( "catalog", defaults.getCatalog() );
 			}
 			copyStringAttribute( annotation, element, "schema", false );
 			if ( StringHelper.isNotEmpty( defaults.getSchema() )
 					&& StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) ) ) {
 				annotation.setValue( "schema", defaults.getSchema() );
 			}
 			buildUniqueConstraints( annotation, element );
 			buildIndex( annotation, element );
 			annotation.setValue( "pkJoinColumns", buildPrimaryKeyJoinColumns( element ) );
 			secondaryTables.add( (SecondaryTable) AnnotationFactory.create( annotation ) );
 		}
 		/*
 		 * You can't have both secondary table in XML and Java,
 		 * since there would be no way to "remove" a secondary table
 		 */
 		if ( secondaryTables.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			SecondaryTable secTableAnn = getPhysicalAnnotation( SecondaryTable.class );
 			overridesDefaultInSecondaryTable( secTableAnn, defaults, secondaryTables );
 			SecondaryTables secTablesAnn = getPhysicalAnnotation( SecondaryTables.class );
 			if ( secTablesAnn != null ) {
 				for ( SecondaryTable table : secTablesAnn.value() ) {
 					overridesDefaultInSecondaryTable( table, defaults, secondaryTables );
 				}
 			}
 		}
 		if ( secondaryTables.size() > 0 ) {
 			AnnotationDescriptor descriptor = new AnnotationDescriptor( SecondaryTables.class );
 			descriptor.setValue( "value", secondaryTables.toArray( new SecondaryTable[secondaryTables.size()] ) );
 			return AnnotationFactory.create( descriptor );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void overridesDefaultInSecondaryTable(
 			SecondaryTable secTableAnn, XMLContext.Default defaults, List<SecondaryTable> secondaryTables
 	) {
 		if ( secTableAnn != null ) {
 			//handle default values
 			if ( StringHelper.isNotEmpty( defaults.getCatalog() )
 					|| StringHelper.isNotEmpty( defaults.getSchema() ) ) {
 				AnnotationDescriptor annotation = new AnnotationDescriptor( SecondaryTable.class );
 				annotation.setValue( "name", secTableAnn.name() );
 				annotation.setValue( "schema", secTableAnn.schema() );
 				annotation.setValue( "catalog", secTableAnn.catalog() );
 				annotation.setValue( "uniqueConstraints", secTableAnn.uniqueConstraints() );
 				annotation.setValue( "pkJoinColumns", secTableAnn.pkJoinColumns() );
 				if ( StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) )
 						&& StringHelper.isNotEmpty( defaults.getSchema() ) ) {
 					annotation.setValue( "schema", defaults.getSchema() );
 				}
 				if ( StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) )
 						&& StringHelper.isNotEmpty( defaults.getCatalog() ) ) {
 					annotation.setValue( "catalog", defaults.getCatalog() );
 				}
 				secondaryTables.add( (SecondaryTable) AnnotationFactory.create( annotation ) );
 			}
 			else {
 				secondaryTables.add( secTableAnn );
 			}
 		}
 	}
 	private static void buildIndex(AnnotationDescriptor annotation, Element element){
 		List indexElementList = element.elements( "index" );
 		Index[] indexes = new Index[indexElementList.size()];
 		for(int i=0;i<indexElementList.size();i++){
 			Element subelement = (Element)indexElementList.get( i );
 			AnnotationDescriptor indexAnn = new AnnotationDescriptor( Index.class );
 			copyStringAttribute( indexAnn, subelement, "name", false );
 			copyStringAttribute( indexAnn, subelement, "column-list", true );
 			copyBooleanAttribute( indexAnn, subelement, "unique" );
 			indexes[i] = AnnotationFactory.create( indexAnn );
 		}
 		annotation.setValue( "indexes", indexes );
 	}
 	private static void buildUniqueConstraints(AnnotationDescriptor annotation, Element element) {
 		List uniqueConstraintElementList = element.elements( "unique-constraint" );
 		UniqueConstraint[] uniqueConstraints = new UniqueConstraint[uniqueConstraintElementList.size()];
 		int ucIndex = 0;
 		Iterator ucIt = uniqueConstraintElementList.listIterator();
 		while ( ucIt.hasNext() ) {
 			Element subelement = (Element) ucIt.next();
 			List<Element> columnNamesElements = subelement.elements( "column-name" );
 			String[] columnNames = new String[columnNamesElements.size()];
 			int columnNameIndex = 0;
 			Iterator it = columnNamesElements.listIterator();
 			while ( it.hasNext() ) {
 				Element columnNameElt = (Element) it.next();
 				columnNames[columnNameIndex++] = columnNameElt.getTextTrim();
 			}
 			AnnotationDescriptor ucAnn = new AnnotationDescriptor( UniqueConstraint.class );
 			copyStringAttribute( ucAnn, subelement, "name", false );
 			ucAnn.setValue( "columnNames", columnNames );
 			uniqueConstraints[ucIndex++] = AnnotationFactory.create( ucAnn );
 		}
 		annotation.setValue( "uniqueConstraints", uniqueConstraints );
 	}
 
 	private PrimaryKeyJoinColumn[] buildPrimaryKeyJoinColumns(Element element) {
 		if ( element == null ) {
 			return new PrimaryKeyJoinColumn[] { };
 		}
 		List pkJoinColumnElementList = element.elements( "primary-key-join-column" );
 		PrimaryKeyJoinColumn[] pkJoinColumns = new PrimaryKeyJoinColumn[pkJoinColumnElementList.size()];
 		int index = 0;
 		Iterator pkIt = pkJoinColumnElementList.listIterator();
 		while ( pkIt.hasNext() ) {
 			Element subelement = (Element) pkIt.next();
 			AnnotationDescriptor pkAnn = new AnnotationDescriptor( PrimaryKeyJoinColumn.class );
 			copyStringAttribute( pkAnn, subelement, "name", false );
 			copyStringAttribute( pkAnn, subelement, "referenced-column-name", false );
 			copyStringAttribute( pkAnn, subelement, "column-definition", false );
 			pkJoinColumns[index++] = AnnotationFactory.create( pkAnn );
 		}
 		return pkJoinColumns;
 	}
 
 	/**
 	 * Copy a string attribute from an XML element to an annotation descriptor. The name of the annotation attribute is
 	 * computed from the name of the XML attribute by {@link #getJavaAttributeNameFromXMLOne(String)}.
 	 *
 	 * @param annotation annotation descriptor where to copy to the attribute.
 	 * @param element XML element from where to copy the attribute.
 	 * @param attributeName name of the XML attribute to copy.
 	 * @param mandatory whether the attribute is mandatory.
 	 */
 	private static void copyStringAttribute(
 			final AnnotationDescriptor annotation, final Element element,
 			final String attributeName, final boolean mandatory) {
 		copyStringAttribute(
 				annotation,
 				element,
 				getJavaAttributeNameFromXMLOne( attributeName ),
 				attributeName,
 				mandatory
 		);
 	}
 
 	/**
 	 * Copy a string attribute from an XML element to an annotation descriptor. The name of the annotation attribute is
 	 * explicitely given.
 	 *
 	 * @param annotation annotation where to copy to the attribute.
 	 * @param element XML element from where to copy the attribute.
 	 * @param annotationAttributeName name of the annotation attribute where to copy.
 	 * @param attributeName name of the XML attribute to copy.
 	 * @param mandatory whether the attribute is mandatory.
 	 */
 	private static void copyStringAttribute(
 			final AnnotationDescriptor annotation, final Element element,
 			final String annotationAttributeName, final String attributeName, boolean mandatory) {
 		String attribute = element.attributeValue( attributeName );
 		if ( attribute != null ) {
 			annotation.setValue( annotationAttributeName, attribute );
 		}
 		else {
 			if ( mandatory ) {
 				throw new AnnotationException(
 						element.getName() + "." + attributeName + " is mandatory in XML overriding. " + SCHEMA_VALIDATION
 				);
 			}
 		}
 	}
 
 	private static void copyIntegerAttribute(AnnotationDescriptor annotation, Element element, String attributeName) {
 		String attribute = element.attributeValue( attributeName );
 		if ( attribute != null ) {
 			String annotationAttributeName = getJavaAttributeNameFromXMLOne( attributeName );
 			annotation.setValue( annotationAttributeName, attribute );
 			try {
 				int length = Integer.parseInt( attribute );
 				annotation.setValue( annotationAttributeName, length );
 			}
 			catch ( NumberFormatException e ) {
 				throw new AnnotationException(
 						element.getPath() + attributeName + " not parseable: " + attribute + " (" + SCHEMA_VALIDATION + ")"
 				);
 			}
 		}
 	}
 
 	private static String getJavaAttributeNameFromXMLOne(String attributeName) {
 		StringBuilder annotationAttributeName = new StringBuilder( attributeName );
 		int index = annotationAttributeName.indexOf( WORD_SEPARATOR );
 		while ( index != -1 ) {
 			annotationAttributeName.deleteCharAt( index );
 			annotationAttributeName.setCharAt(
 					index, Character.toUpperCase( annotationAttributeName.charAt( index ) )
 			);
 			index = annotationAttributeName.indexOf( WORD_SEPARATOR );
 		}
 		return annotationAttributeName.toString();
 	}
 
 	private static void copyStringElement(Element element, AnnotationDescriptor ad, String annotationAttribute) {
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/ValidationMode.java b/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/ValidationMode.java
index 29bbda0413..2e5be99edd 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/ValidationMode.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/ValidationMode.java
@@ -1,91 +1,92 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.beanvalidation;
 
 import java.util.HashSet;
+import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 
 /**
  * Duplicates the javax.validation enum (because javax validation might not be on the runtime classpath)
  *
  * @author Steve Ebersole
  */
 public enum ValidationMode {
 	AUTO( "auto" ),
 	CALLBACK( "callback" ),
 	NONE( "none" ),
 	DDL( "ddl" );
 
 	private final String externalForm;
 
 	private ValidationMode(String externalForm) {
 		this.externalForm = externalForm;
 	}
 
 	public static Set<ValidationMode> getModes(Object modeProperty) {
 		Set<ValidationMode> modes = new HashSet<ValidationMode>(3);
 		if (modeProperty == null) {
 			modes.add( ValidationMode.AUTO );
 		}
 		else {
 			final String[] modesInString = modeProperty.toString().split( "," );
 			for ( String modeInString : modesInString ) {
 				modes.add( getMode(modeInString) );
 			}
 		}
 		if ( modes.size() > 1 && ( modes.contains( ValidationMode.AUTO ) || modes.contains( ValidationMode.NONE ) ) ) {
 			throw new HibernateException( "Incompatible validation modes mixed: " +  loggable( modes ) );
 		}
 		return modes;
 	}
 
 	private static ValidationMode getMode(String modeProperty) {
 		if (modeProperty == null || modeProperty.length() == 0) {
 			return AUTO;
 		}
 		else {
 			try {
-				return valueOf( modeProperty.trim().toUpperCase() );
+				return valueOf( modeProperty.trim().toUpperCase(Locale.ROOT) );
 			}
 			catch ( IllegalArgumentException e ) {
 				throw new HibernateException( "Unknown validation mode in " + BeanValidationIntegrator.MODE_PROPERTY + ": " + modeProperty );
 			}
 		}
 	}
 
 	public static String loggable(Set<ValidationMode> modes) {
 		if ( modes == null || modes.isEmpty() ) {
 			return "[<empty>]";
 		}
 		StringBuilder buffer = new StringBuilder( "[" );
 		String sep = "";
 		for ( ValidationMode mode : modes ) {
 			buffer.append( sep ).append( mode.externalForm );
 			sep = ", ";
 		}
 		return buffer.append( "]" ).toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/criterion/Example.java b/hibernate-core/src/main/java/org/hibernate/criterion/Example.java
index 44a9abc6fe..2ba7beee50 100644
--- a/hibernate-core/src/main/java/org/hibernate/criterion/Example.java
+++ b/hibernate-core/src/main/java/org/hibernate/criterion/Example.java
@@ -1,500 +1,501 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.criterion;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
+import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.Criteria;
 import org.hibernate.EntityMode;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 
 /**
  * Support for query by example.
  *
  * <pre>
  * List results = session.createCriteria(Parent.class)
  *     .add( Example.create(parent).ignoreCase() )
  *     .createCriteria("child")
  *         .add( Example.create( parent.getChild() ) )
  *     .list();
  * </pre>
  *
  * "Examples" may be mixed and matched with "Expressions" in the same Criteria.
  *
  * @see org.hibernate.Criteria
  * @author Gavin King
  */
 
 public class Example implements Criterion {
 	private final Object exampleEntity;
 	private PropertySelector selector;
 
 	private boolean isLikeEnabled;
 	private Character escapeCharacter;
 	private boolean isIgnoreCaseEnabled;
 	private MatchMode matchMode;
 
 	private final Set<String> excludedProperties = new HashSet<String>();
 
 	/**
 	 * Create a new Example criterion instance, which includes all non-null properties by default
 	 *
 	 * @param exampleEntity The example bean to use.
 	 *
 	 * @return a new instance of Example
 	 */
 	public static Example create(Object exampleEntity) {
 		if ( exampleEntity == null ) {
 			throw new NullPointerException( "null example entity" );
 		}
 		return new Example( exampleEntity, NotNullPropertySelector.INSTANCE );
 	}
 
 	/**
 	 * Allow subclasses to instantiate as needed.
 	 *
 	 * @param exampleEntity The example bean
 	 * @param selector The property selector to use
 	 */
 	protected Example(Object exampleEntity, PropertySelector selector) {
 		this.exampleEntity = exampleEntity;
 		this.selector = selector;
 	}
 
 	/**
 	 * Set escape character for "like" clause if like matching was enabled
 	 *
 	 * @param escapeCharacter The escape character
 	 *
 	 * @return {@code this}, for method chaining
 	 *
 	 * @see #enableLike
 	 */
 	public Example setEscapeCharacter(Character escapeCharacter) {
 		this.escapeCharacter = escapeCharacter;
 		return this;
 	}
 
 	/**
 	 * Use the "like" operator for all string-valued properties.  This form implicitly uses {@link MatchMode#EXACT}
 	 *
 	 * @return {@code this}, for method chaining
 	 */
 	public Example enableLike() {
 		return enableLike( MatchMode.EXACT );
 	}
 
 	/**
 	 * Use the "like" operator for all string-valued properties
 	 *
 	 * @param matchMode The match mode to use.
 	 *
 	 * @return {@code this}, for method chaining
 	 */
 	public Example enableLike(MatchMode matchMode) {
 		this.isLikeEnabled = true;
 		this.matchMode = matchMode;
 		return this;
 	}
 
 	/**
 	 * Ignore case for all string-valued properties
 	 *
 	 * @return {@code this}, for method chaining
 	 */
 	public Example ignoreCase() {
 		this.isIgnoreCaseEnabled = true;
 		return this;
 	}
 
 	/**
 	 * Set the property selector to use.
 	 *
 	 * The property selector operates separate from excluding a property.
 	 *
 	 * @param selector The selector to use
 	 *
 	 * @return {@code this}, for method chaining
 	 *
 	 * @see #excludeProperty
 	 */
 	public Example setPropertySelector(PropertySelector selector) {
 		this.selector = selector;
 		return this;
 	}
 
 	/**
 	 * Exclude zero-valued properties.
 	 *
 	 * Equivalent to calling {@link #setPropertySelector} passing in {@link NotNullOrZeroPropertySelector#INSTANCE}
 	 *
 	 * @return {@code this}, for method chaining
 	 *
 	 * @see #setPropertySelector
 	 */
 	public Example excludeZeroes() {
 		setPropertySelector( NotNullOrZeroPropertySelector.INSTANCE );
 		return this;
 	}
 
 	/**
 	 * Include all properties.
 	 *
 	 * Equivalent to calling {@link #setPropertySelector} passing in {@link AllPropertySelector#INSTANCE}
 	 *
 	 * @return {@code this}, for method chaining
 	 *
 	 * @see #setPropertySelector
 	 */
 	public Example excludeNone() {
 		setPropertySelector( AllPropertySelector.INSTANCE );
 		return this;
 	}
 
 	/**
 	 * Exclude a particular property by name.
 	 *
 	 * @param name The name of the property to exclude
 	 *
 	 * @return {@code this}, for method chaining
 	 *
 	 * @see #setPropertySelector
 	 */
 	public Example excludeProperty(String name) {
 		excludedProperties.add( name );
 		return this;
 	}
 
 	@Override
 	public String toSqlString(Criteria criteria, CriteriaQuery criteriaQuery) {
 		final StringBuilder buf = new StringBuilder().append( '(' );
 		final EntityPersister meta = criteriaQuery.getFactory().getEntityPersister(
 				criteriaQuery.getEntityName( criteria )
 		);
 		final String[] propertyNames = meta.getPropertyNames();
 		final Type[] propertyTypes = meta.getPropertyTypes();
 
 		final Object[] propertyValues = meta.getPropertyValues( exampleEntity );
 		for ( int i=0; i<propertyNames.length; i++ ) {
 			final Object propertyValue = propertyValues[i];
 			final String propertyName = propertyNames[i];
 
 			final boolean isVersionProperty = i == meta.getVersionProperty();
 			if ( ! isVersionProperty && isPropertyIncluded( propertyValue, propertyName, propertyTypes[i] ) ) {
 				if ( propertyTypes[i].isComponentType() ) {
 					appendComponentCondition(
 						propertyName,
 						propertyValue,
 						(CompositeType) propertyTypes[i],
 						criteria,
 						criteriaQuery,
 						buf
 					);
 				}
 				else {
 					appendPropertyCondition(
 						propertyName,
 						propertyValue,
 						criteria,
 						criteriaQuery,
 						buf
 					);
 				}
 			}
 		}
 
 		if ( buf.length()==1 ) {
 			buf.append( "1=1" );
 		}
 
 		return buf.append( ')' ).toString();
 	}
 
 	@SuppressWarnings("SimplifiableIfStatement")
 	private boolean isPropertyIncluded(Object value, String name, Type type) {
 		if ( excludedProperties.contains( name ) ) {
 			// was explicitly excluded
 			return false;
 		}
 
 		if ( type.isAssociationType() ) {
 			// associations are implicitly excluded
 			return false;
 		}
 
 		return selector.include( value, name, type );
 	}
 
 	@Override
 	public TypedValue[] getTypedValues(Criteria criteria, CriteriaQuery criteriaQuery) {
 		final EntityPersister meta = criteriaQuery.getFactory().getEntityPersister(
 				criteriaQuery.getEntityName( criteria )
 		);
 		final String[] propertyNames = meta.getPropertyNames();
 		final Type[] propertyTypes = meta.getPropertyTypes();
 
 		final Object[] values = meta.getPropertyValues( exampleEntity );
 		final List<TypedValue> list = new ArrayList<TypedValue>();
 		for ( int i=0; i<propertyNames.length; i++ ) {
 			final Object value = values[i];
 			final Type type = propertyTypes[i];
 			final String name = propertyNames[i];
 
 			final boolean isVersionProperty = i == meta.getVersionProperty();
 
 			if ( ! isVersionProperty && isPropertyIncluded( value, name, type ) ) {
 				if ( propertyTypes[i].isComponentType() ) {
 					addComponentTypedValues( name, value, (CompositeType) type, list, criteria, criteriaQuery );
 				}
 				else {
 					addPropertyTypedValue( value, type, list );
 				}
 			}
 		}
 
 		return list.toArray( new TypedValue[ list.size() ] );
 	}
 
 	protected void addPropertyTypedValue(Object value, Type type, List<TypedValue> list) {
 		if ( value != null ) {
 			if ( value instanceof String ) {
 				String string = (String) value;
 				if ( isIgnoreCaseEnabled ) {
-					string = string.toLowerCase();
+					string = string.toLowerCase(Locale.ROOT);
 				}
 				if ( isLikeEnabled ) {
 					string = matchMode.toMatchString( string );
 				}
 				value = string;
 			}
 			list.add( new TypedValue( type, value ) );
 		}
 	}
 
 	protected void addComponentTypedValues(
 			String path, 
 			Object component, 
 			CompositeType type,
 			List<TypedValue> list,
 			Criteria criteria, 
 			CriteriaQuery criteriaQuery) {
 		if ( component != null ) {
 			final String[] propertyNames = type.getPropertyNames();
 			final Type[] subtypes = type.getSubtypes();
 			final Object[] values = type.getPropertyValues( component, getEntityMode( criteria, criteriaQuery ) );
 			for ( int i=0; i<propertyNames.length; i++ ) {
 				final Object value = values[i];
 				final Type subtype = subtypes[i];
 				final String subpath = StringHelper.qualify( path, propertyNames[i] );
 				if ( isPropertyIncluded( value, subpath, subtype ) ) {
 					if ( subtype.isComponentType() ) {
 						addComponentTypedValues( subpath, value, (CompositeType) subtype, list, criteria, criteriaQuery );
 					}
 					else {
 						addPropertyTypedValue( value, subtype, list );
 					}
 				}
 			}
 		}
 	}
 
 	private EntityMode getEntityMode(Criteria criteria, CriteriaQuery criteriaQuery) {
 		final EntityPersister meta = criteriaQuery.getFactory().getEntityPersister(
 				criteriaQuery.getEntityName( criteria )
 		);
 		final EntityMode result = meta.getEntityMode();
 		if ( ! meta.getEntityMetamodel().getTuplizer().isInstance( exampleEntity ) ) {
 			throw new ClassCastException( exampleEntity.getClass().getName() );
 		}
 		return result;
 	}
 
 	protected void appendPropertyCondition(
 			String propertyName,
 			Object propertyValue,
 			Criteria criteria,
 			CriteriaQuery cq,
 			StringBuilder buf) {
 		final Criterion condition;
 		if ( propertyValue != null ) {
 			final boolean isString = propertyValue instanceof String;
 			if ( isLikeEnabled && isString ) {
 				condition = new LikeExpression(
 						propertyName,
 						(String) propertyValue,
 						matchMode,
 						escapeCharacter,
 						isIgnoreCaseEnabled
 				);
 			}
 			else {
 				condition = new SimpleExpression( propertyName, propertyValue, "=", isIgnoreCaseEnabled && isString );
 			}
 		}
 		else {
 			condition = new NullExpression(propertyName);
 		}
 
 		final String conditionFragment = condition.toSqlString( criteria, cq );
 		if ( conditionFragment.trim().length() > 0 ) {
 			if ( buf.length() > 1 ) {
 				buf.append( " and " );
 			}
 			buf.append( conditionFragment );
 		}
 	}
 
 	protected void appendComponentCondition(
 			String path,
 			Object component,
 			CompositeType type,
 			Criteria criteria,
 			CriteriaQuery criteriaQuery,
 			StringBuilder buf) {
 		if ( component != null ) {
 			final String[] propertyNames = type.getPropertyNames();
 			final Object[] values = type.getPropertyValues( component, getEntityMode( criteria, criteriaQuery ) );
 			final Type[] subtypes = type.getSubtypes();
 			for ( int i=0; i<propertyNames.length; i++ ) {
 				final String subPath = StringHelper.qualify( path, propertyNames[i] );
 				final Object value = values[i];
 				if ( isPropertyIncluded( value, subPath, subtypes[i] ) ) {
 					final Type subtype = subtypes[i];
 					if ( subtype.isComponentType() ) {
 						appendComponentCondition(
 								subPath,
 								value,
 								(CompositeType) subtype,
 								criteria,
 								criteriaQuery,
 								buf
 						);
 					}
 					else {
 						appendPropertyCondition(
 								subPath,
 								value,
 								criteria,
 								criteriaQuery,
 								buf
 						);
 					}
 				}
 			}
 		}
 	}
 
 	@Override
 	public String toString() {
 		return "example (" + exampleEntity + ')';
 	}
 
 
 	// PropertySelector definitions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * A strategy for choosing property values for inclusion in the query criteria.  Note that
 	 * property selection (for inclusion) operates separately from excluding a property.  Excluded
 	 * properties are not even passed in to the PropertySelector for consideration.
 	 */
 	public static interface PropertySelector extends Serializable {
 		/**
 		 * Determine whether the given property should be used in the criteria.
 		 *
 		 * @param propertyValue The property value (from the example bean)
 		 * @param propertyName The name of the property
 		 * @param type The type of the property
 		 *
 		 * @return {@code true} indicates the property should be included; {@code false} indiates it should not.
 		 */
 		public boolean include(Object propertyValue, String propertyName, Type type);
 	}
 
 	/**
 	 * Property selector that includes all properties
 	 */
 	public static final class AllPropertySelector implements PropertySelector {
 		/**
 		 * Singleton access
 		 */
 		public static final AllPropertySelector INSTANCE = new AllPropertySelector();
 
 		@Override
 		public boolean include(Object object, String propertyName, Type type) {
 			return true;
 		}
 
 		private Object readResolve() {
 			return INSTANCE;
 		}
 	}
 
 	/**
 	 * Property selector that includes only properties that are not {@code null}
 	 */
 	public static final class NotNullPropertySelector implements PropertySelector {
 		/**
 		 * Singleton access
 		 */
 		public static final NotNullPropertySelector INSTANCE = new NotNullPropertySelector();
 
 		@Override
 		public boolean include(Object object, String propertyName, Type type) {
 			return object!=null;
 		}
 
 		private Object readResolve() {
 			return INSTANCE;
 		}
 	}
 
 	/**
 	 * Property selector that includes only properties that are not {@code null} and non-zero (if numeric)
 	 */
 	public static final class NotNullOrZeroPropertySelector implements PropertySelector {
 		/**
 		 * Singleton access
 		 */
 		public static final NotNullOrZeroPropertySelector INSTANCE = new NotNullOrZeroPropertySelector();
 
 		@Override
 		public boolean include(Object object, String propertyName, Type type) {
 			return object != null
 					&& ( !(object instanceof Number) || ( (Number) object ).longValue()!=0
 			);
 		}
 
 		private Object readResolve() {
 			return INSTANCE;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/criterion/IlikeExpression.java b/hibernate-core/src/main/java/org/hibernate/criterion/IlikeExpression.java
index 923890bcaf..62a4f3d684 100644
--- a/hibernate-core/src/main/java/org/hibernate/criterion/IlikeExpression.java
+++ b/hibernate-core/src/main/java/org/hibernate/criterion/IlikeExpression.java
@@ -1,87 +1,88 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.criterion;
 
+import java.util.Locale;
 import org.hibernate.Criteria;
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.PostgreSQL81Dialect;
 import org.hibernate.dialect.PostgreSQLDialect;
 import org.hibernate.engine.spi.TypedValue;
 
 /**
  * A case-insensitive "like".
  *
  * @author Gavin King
  *
  * @deprecated Prefer {@link LikeExpression} which now has case-insensitivity capability.
  */
 @Deprecated
 @SuppressWarnings({"deprecation", "UnusedDeclaration"})
 public class IlikeExpression implements Criterion {
 	private final String propertyName;
 	private final Object value;
 
 	protected IlikeExpression(String propertyName, Object value) {
 		this.propertyName = propertyName;
 		this.value = value;
 	}
 
 	protected IlikeExpression(String propertyName, String value, MatchMode matchMode) {
 		this( propertyName, matchMode.toMatchString( value ) );
 	}
 
 	@Override
 	public String toSqlString(Criteria criteria, CriteriaQuery criteriaQuery) {
 		final Dialect dialect = criteriaQuery.getFactory().getDialect();
 		final String[] columns = criteriaQuery.findColumns( propertyName, criteria );
 		if ( columns.length != 1 ) {
 			throw new HibernateException( "ilike may only be used with single-column properties" );
 		}
 		if ( dialect instanceof PostgreSQLDialect || dialect instanceof PostgreSQL81Dialect) {
 			return columns[0] + " ilike ?";
 		}
 		else {
 			return dialect.getLowercaseFunction() + '(' + columns[0] + ") like ?";
 		}
 	}
 
 	@Override
 	public TypedValue[] getTypedValues(Criteria criteria, CriteriaQuery criteriaQuery) {
 		return new TypedValue[] {
 				criteriaQuery.getTypedValue(
 						criteria,
 						propertyName,
-						value.toString().toLowerCase()
+						value.toString().toLowerCase(Locale.ROOT)
 				)
 		};
 	}
 
 	@Override
 	public String toString() {
 		return propertyName + " ilike " + value;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/criterion/Junction.java b/hibernate-core/src/main/java/org/hibernate/criterion/Junction.java
index d9cde4b3b3..3f85e45531 100644
--- a/hibernate-core/src/main/java/org/hibernate/criterion/Junction.java
+++ b/hibernate-core/src/main/java/org/hibernate/criterion/Junction.java
@@ -1,138 +1,139 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.criterion;
 
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Locale;
 
 import org.hibernate.Criteria;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A sequence of a logical expressions combined by some
  * associative logical operator
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class Junction implements Criterion {
 	private final Nature nature;
 	private final List<Criterion> conditions = new ArrayList<Criterion>();
 
 	protected Junction(Nature nature) {
 		this.nature = nature;
 	}
 
 	protected Junction(Nature nature, Criterion... criterion) {
 		this( nature );
 		Collections.addAll( conditions, criterion );
 	}
 
 	/**
 	 * Adds a criterion to the junction (and/or)
 	 *
 	 * @param criterion The criterion to add
 	 *
 	 * @return {@code this}, for method chaining
 	 */
 	public Junction add(Criterion criterion) {
 		conditions.add( criterion );
 		return this;
 	}
 
 	public Nature getNature() {
 		return nature;
 	}
 
 	/**
 	 * Access the conditions making up the junction
 	 *
 	 * @return the criterion
 	 */
 	public Iterable<Criterion> conditions() {
 		return conditions;
 	}
 
 	@Override
 	public TypedValue[] getTypedValues(Criteria crit, CriteriaQuery criteriaQuery) throws HibernateException {
 		final ArrayList<TypedValue> typedValues = new ArrayList<TypedValue>();
 		for ( Criterion condition : conditions ) {
 			final TypedValue[] subValues = condition.getTypedValues( crit, criteriaQuery );
 			Collections.addAll( typedValues, subValues );
 		}
 		return typedValues.toArray( new TypedValue[ typedValues.size() ] );
 	}
 
 	@Override
 	public String toSqlString(Criteria crit, CriteriaQuery criteriaQuery) throws HibernateException {
 		if ( conditions.size()==0 ) {
 			return "1=1";
 		}
 
 		final StringBuilder buffer = new StringBuilder().append( '(' );
 		final Iterator itr = conditions.iterator();
 		while ( itr.hasNext() ) {
 			buffer.append( ( (Criterion) itr.next() ).toSqlString( crit, criteriaQuery ) );
 			if ( itr.hasNext() ) {
 				buffer.append( ' ' )
 						.append( nature.getOperator() )
 						.append( ' ' );
 			}
 		}
 
 		return buffer.append( ')' ).toString();
 	}
 
 	@Override
 	public String toString() {
 		return '(' + StringHelper.join( ' ' + nature.getOperator() + ' ', conditions.iterator() ) + ')';
 	}
 
 	/**
 	 * The type of junction
 	 */
 	public static enum Nature {
 		/**
 		 * An AND
 		 */
 		AND,
 		/**
 		 * An OR
 		 */
 		OR;
 
 		/**
 		 * The corresponding SQL operator
 		 *
 		 * @return SQL operator
 		 */
 		public String getOperator() {
-			return name().toLowerCase();
+			return name().toLowerCase(Locale.ROOT);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/criterion/LikeExpression.java b/hibernate-core/src/main/java/org/hibernate/criterion/LikeExpression.java
index eb71480ab2..1de76ad7c8 100644
--- a/hibernate-core/src/main/java/org/hibernate/criterion/LikeExpression.java
+++ b/hibernate-core/src/main/java/org/hibernate/criterion/LikeExpression.java
@@ -1,101 +1,102 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.criterion;
 
+import java.util.Locale;
 import org.hibernate.Criteria;
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.TypedValue;
 
 /**
  * A criterion representing a "like" expression
  *
  * @author Scott Marlow
  * @author Steve Ebersole
  */
 public class LikeExpression implements Criterion {
 	private final String propertyName;
 	private final Object value;
 	private final Character escapeChar;
 	private final boolean ignoreCase;
 
 	protected LikeExpression(
 			String propertyName,
 			String value,
 			Character escapeChar,
 			boolean ignoreCase) {
 		this.propertyName = propertyName;
 		this.value = value;
 		this.escapeChar = escapeChar;
 		this.ignoreCase = ignoreCase;
 	}
 
 	protected LikeExpression(String propertyName, String value) {
 		this( propertyName, value, null, false );
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	protected LikeExpression(String propertyName, String value, MatchMode matchMode) {
 		this( propertyName, matchMode.toMatchString( value ) );
 	}
 
 	protected LikeExpression(
 			String propertyName,
 			String value,
 			MatchMode matchMode,
 			Character escapeChar,
 			boolean ignoreCase) {
 		this( propertyName, matchMode.toMatchString( value ), escapeChar, ignoreCase );
 	}
 
 	@Override
 	public String toSqlString(Criteria criteria,CriteriaQuery criteriaQuery) {
 		final Dialect dialect = criteriaQuery.getFactory().getDialect();
 		final String[] columns = criteriaQuery.findColumns( propertyName, criteria );
 		if ( columns.length != 1 ) {
 			throw new HibernateException( "Like may only be used with single-column properties" );
 		}
 
 		final String escape = escapeChar == null ? "" : " escape \'" + escapeChar + "\'";
 		final String column = columns[0];
 		if ( ignoreCase ) {
 			if ( dialect.supportsCaseInsensitiveLike() ) {
 				return column +" " + dialect.getCaseInsensitiveLike() + " ?" + escape;
 			}
 			else {
 				return dialect.getLowercaseFunction() + '(' + column + ')' + " like ?" + escape;
 			}
 		}
 		else {
 			return column + " like ?" + escape;
 		}
 	}
 
 	@Override
 	public TypedValue[] getTypedValues(Criteria criteria, CriteriaQuery criteriaQuery) {
-		final String matchValue = ignoreCase ? value.toString().toLowerCase() : value.toString();
+		final String matchValue = ignoreCase ? value.toString().toLowerCase(Locale.ROOT) : value.toString();
 
 		return new TypedValue[] { criteriaQuery.getTypedValue( criteria, propertyName, matchValue ) };
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/criterion/Order.java b/hibernate-core/src/main/java/org/hibernate/criterion/Order.java
index dd3adccccb..979a10d296 100644
--- a/hibernate-core/src/main/java/org/hibernate/criterion/Order.java
+++ b/hibernate-core/src/main/java/org/hibernate/criterion/Order.java
@@ -1,172 +1,173 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.criterion;
 
 import java.io.Serializable;
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.Criteria;
 import org.hibernate.NullPrecedence;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.type.Type;
 
 /**
  * Represents an ordering imposed upon the results of a Criteria
  * 
  * @author Gavin King
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class Order implements Serializable {
 	private boolean ascending;
 	private boolean ignoreCase;
 	private String propertyName;
 	private NullPrecedence nullPrecedence;
 
 	/**
 	 * Ascending order
 	 *
 	 * @param propertyName The property to order on
 	 *
 	 * @return The build Order instance
 	 */
 	public static Order asc(String propertyName) {
 		return new Order( propertyName, true );
 	}
 
 	/**
 	 * Descending order.
 	 *
 	 * @param propertyName The property to order on
 	 *
 	 * @return The build Order instance
 	 */
 	public static Order desc(String propertyName) {
 		return new Order( propertyName, false );
 	}
 
 	/**
 	 * Constructor for Order.  Order instances are generally created by factory methods.
 	 *
 	 * @see #asc
 	 * @see #desc
 	 */
 	protected Order(String propertyName, boolean ascending) {
 		this.propertyName = propertyName;
 		this.ascending = ascending;
 	}
 
 	/**
 	 * Should this ordering ignore case?  Has no effect on non-character properties.
 	 *
 	 * @return {@code this}, for method chaining
 	 */
 	public Order ignoreCase() {
 		ignoreCase = true;
 		return this;
 	}
 
 	/**
 	 * Defines precedence for nulls.
 	 *
 	 * @param nullPrecedence The null precedence to use
 	 *
 	 * @return {@code this}, for method chaining
 	 */
 	public Order nulls(NullPrecedence nullPrecedence) {
 		this.nullPrecedence = nullPrecedence;
 		return this;
 	}
 
 	public String getPropertyName() {
 		return propertyName;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public boolean isAscending() {
 		return ascending;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public boolean isIgnoreCase() {
 		return ignoreCase;
 	}
 
 
 	/**
 	 * Render the SQL fragment
 	 *
 	 * @param criteria The criteria
 	 * @param criteriaQuery The overall query
 	 *
 	 * @return The ORDER BY fragment for this ordering
 	 */
 	public String toSqlString(Criteria criteria, CriteriaQuery criteriaQuery) {
 		final String[] columns = criteriaQuery.getColumnsUsingProjection( criteria, propertyName );
 		final Type type = criteriaQuery.getTypeUsingProjection( criteria, propertyName );
 		final SessionFactoryImplementor factory = criteriaQuery.getFactory();
 		final int[] sqlTypes = type.sqlTypes( factory );
 
 		final StringBuilder fragment = new StringBuilder();
 		for ( int i=0; i<columns.length; i++ ) {
 			final StringBuilder expression = new StringBuilder();
 			boolean lower = false;
 			if ( ignoreCase ) {
 				final int sqlType = sqlTypes[i];
 				lower = sqlType == Types.VARCHAR
 						|| sqlType == Types.CHAR
 						|| sqlType == Types.LONGVARCHAR;
 			}
 			
 			if ( lower ) {
 				expression.append( factory.getDialect().getLowercaseFunction() )
 						.append( '(' );
 			}
 			expression.append( columns[i] );
 			if ( lower ) {
 				expression.append( ')' );
 			}
 
 			fragment.append(
 					factory.getDialect().renderOrderByElement(
 							expression.toString(),
 							null,
 							ascending ? "asc" : "desc",
 							nullPrecedence != null ? nullPrecedence : factory.getSettings().getDefaultNullPrecedence()
 					)
 			);
 			if ( i < columns.length-1 ) {
 				fragment.append( ", " );
 			}
 		}
 
 		return fragment.toString();
 	}
 	
 	@Override
 	public String toString() {
 		return propertyName + ' '
 				+ ( ascending ? "asc" : "desc" )
-				+ ( nullPrecedence != null ? ' ' + nullPrecedence.name().toLowerCase() : "" );
+				+ ( nullPrecedence != null ? ' ' + nullPrecedence.name().toLowerCase(Locale.ROOT) : "" );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/criterion/SimpleExpression.java b/hibernate-core/src/main/java/org/hibernate/criterion/SimpleExpression.java
index b8d80f0651..b1ef137a1e 100644
--- a/hibernate-core/src/main/java/org/hibernate/criterion/SimpleExpression.java
+++ b/hibernate-core/src/main/java/org/hibernate/criterion/SimpleExpression.java
@@ -1,123 +1,124 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.criterion;
 
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.Criteria;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.type.Type;
 
 /**
  * superclass for "simple" comparisons (with SQL binary operators)
  *
  * @author Gavin King
  */
 public class SimpleExpression implements Criterion {
 	private final String propertyName;
 	private final Object value;
 	private boolean ignoreCase;
 	private final String op;
 
 	protected SimpleExpression(String propertyName, Object value, String op) {
 		this.propertyName = propertyName;
 		this.value = value;
 		this.op = op;
 	}
 
 	protected SimpleExpression(String propertyName, Object value, String op, boolean ignoreCase) {
 		this.propertyName = propertyName;
 		this.value = value;
 		this.ignoreCase = ignoreCase;
 		this.op = op;
 	}
 
 	protected final String getOp() {
 		return op;
 	}
 
 	public String getPropertyName() {
 		return propertyName;
 	}
 
 	public Object getValue() {
 		return value;
 	}
 
 	/**
 	 * Make case insensitive.  No effect for non-String values
 	 *
 	 * @return {@code this}, for method chaining
 	 */
 	public SimpleExpression ignoreCase() {
 		ignoreCase = true;
 		return this;
 	}
 
 	@Override
 	public String toSqlString(Criteria criteria, CriteriaQuery criteriaQuery) throws HibernateException {
 		final String[] columns = criteriaQuery.findColumns( propertyName, criteria );
 		final Type type = criteriaQuery.getTypeUsingProjection( criteria, propertyName );
 		final StringBuilder fragment = new StringBuilder();
 
 		if ( columns.length > 1 ) {
 			fragment.append( '(' );
 		}
 		final SessionFactoryImplementor factory = criteriaQuery.getFactory();
 		final int[] sqlTypes = type.sqlTypes( factory );
 		for ( int i = 0; i < columns.length; i++ ) {
 			final boolean lower = ignoreCase && (sqlTypes[i] == Types.VARCHAR || sqlTypes[i] == Types.CHAR);
 			if ( lower ) {
 				fragment.append( factory.getDialect().getLowercaseFunction() ).append( '(' );
 			}
 			fragment.append( columns[i] );
 			if ( lower ) {
 				fragment.append( ')' );
 			}
 
 			fragment.append( getOp() ).append( "?" );
 			if ( i < columns.length - 1 ) {
 				fragment.append( " and " );
 			}
 		}
 		if ( columns.length > 1 ) {
 			fragment.append( ')' );
 		}
 		return fragment.toString();
 	}
 
 	@Override
 	public TypedValue[] getTypedValues(Criteria criteria, CriteriaQuery criteriaQuery) throws HibernateException {
-		final Object casedValue = ignoreCase ? value.toString().toLowerCase() : value;
+		final Object casedValue = ignoreCase ? value.toString().toLowerCase(Locale.ROOT) : value;
 		return new TypedValue[] { criteriaQuery.getTypedValue( criteria, propertyName, casedValue ) };
 	}
 
 	@Override
 	public String toString() {
 		return propertyName + getOp() + value;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/DerbyDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/DerbyDialect.java
index 09e5913836..b386e69607 100755
--- a/hibernate-core/src/main/java/org/hibernate/dialect/DerbyDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/DerbyDialect.java
@@ -1,339 +1,340 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.lang.reflect.Method;
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.MappingException;
 import org.hibernate.dialect.function.AnsiTrimFunction;
 import org.hibernate.dialect.function.DerbyConcatFunction;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.DerbyCaseFragment;
 
 import org.jboss.logging.Logger;
 
 /**
  * Hibernate Dialect for Cloudscape 10 - aka Derby. This implements both an
  * override for the identity column generator as well as for the case statement
  * issue documented at:
  * http://www.jroller.com/comments/kenlars99/Weblog/cloudscape_soon_to_be_derby
  *
  * @author Simon Johnston
  *
  * @deprecated HHH-6073
  */
 @Deprecated
 public class DerbyDialect extends DB2Dialect {
 	@SuppressWarnings("deprecation")
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			DerbyDialect.class.getName()
 	);
 
 	private int driverVersionMajor;
 	private int driverVersionMinor;
 	private final LimitHandler limitHandler;
 
 	/**
 	 * Constructs a DerbyDialect
 	 */
 	@SuppressWarnings("deprecation")
 	public DerbyDialect() {
 		super();
 		if ( this.getClass() == DerbyDialect.class ) {
 			LOG.deprecatedDerbyDialect();
 		}
 
 		registerFunction( "concat", new DerbyConcatFunction() );
 		registerFunction( "trim", new AnsiTrimFunction() );
 		registerColumnType( Types.BLOB, "blob" );
 		determineDriverVersion();
 
 		if ( driverVersionMajor > 10 || ( driverVersionMajor == 10 && driverVersionMinor >= 7 ) ) {
 			registerColumnType( Types.BOOLEAN, "boolean" );
 		}
 
 		this.limitHandler = new DerbyLimitHandler();
 	}
 
 	private void determineDriverVersion() {
 		try {
 			// locate the derby sysinfo class and query its version info
 			final Class sysinfoClass = ReflectHelper.classForName( "org.apache.derby.tools.sysinfo", this.getClass() );
 			final Method majorVersionGetter = sysinfoClass.getMethod( "getMajorVersion", ReflectHelper.NO_PARAM_SIGNATURE );
 			final Method minorVersionGetter = sysinfoClass.getMethod( "getMinorVersion", ReflectHelper.NO_PARAM_SIGNATURE );
 			driverVersionMajor = (Integer) majorVersionGetter.invoke( null, ReflectHelper.NO_PARAMS );
 			driverVersionMinor = (Integer) minorVersionGetter.invoke( null, ReflectHelper.NO_PARAMS );
 		}
 		catch ( Exception e ) {
 			LOG.unableToLoadDerbyDriver( e.getMessage() );
 			driverVersionMajor = -1;
 			driverVersionMinor = -1;
 		}
 	}
 
 	private boolean isTenPointFiveReleaseOrNewer() {
 		return driverVersionMajor > 10 || ( driverVersionMajor == 10 && driverVersionMinor >= 5 );
 	}
 
 	@Override
 	public String getCrossJoinSeparator() {
 		return ", ";
 	}
 
 	@Override
 	public CaseFragment createCaseFragment() {
 		return new DerbyCaseFragment();
 	}
 
 	@Override
 	public boolean dropConstraints() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		// technically sequence support was added in 10.6.1.0...
 		//
 		// The problem though is that I am not exactly sure how to differentiate 10.6.1.0 from any other 10.6.x release.
 		//
 		// http://db.apache.org/derby/docs/10.0/publishedapi/org/apache/derby/tools/sysinfo.html seems incorrect.  It
 		// states that derby's versioning scheme is major.minor.maintenance, but obviously 10.6.1.0 has 4 components
 		// to it, not 3.
 		//
 		// Let alone the fact that it states that versions with the matching major.minor are 'feature
 		// compatible' which is clearly not the case here (sequence support is a new feature...)
 		return driverVersionMajor > 10 || ( driverVersionMajor == 10 && driverVersionMinor >= 6 );
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		if ( supportsSequences() ) {
 			return "values next value for " + sequenceName;
 		}
 		else {
 			throw new MappingException( "Derby does not support sequence prior to release 10.6.1.0" );
 		}
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return isTenPointFiveReleaseOrNewer();
 	}
 
 	@Override
 	public boolean supportsCommentOn() {
 		//HHH-4531
 		return false;
 	}
 
 	@Override
 	@SuppressWarnings("deprecation")
 	public boolean supportsLimitOffset() {
 		return isTenPointFiveReleaseOrNewer();
 	}
 
 	@Override
 	public String getForUpdateString() {
 		return " for update with rs";
 	}
 
 	@Override
 	public String getWriteLockString(int timeout) {
 		return " for update with rs";
 	}
 
 	@Override
 	public String getReadLockString(int timeout) {
 		return " for read only with rs";
 	}
 
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return limitHandler;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 * <p/>
 	 * From Derby 10.5 Docs:
 	 * <pre>
 	 * Query
 	 * [ORDER BY clause]
 	 * [result offset clause]
 	 * [fetch first clause]
 	 * [FOR UPDATE clause]
 	 * [WITH {RR|RS|CS|UR}]
 	 * </pre>
 	 */
 	@Override
 	public String getLimitString(String query, final int offset, final int limit) {
 		final StringBuilder sb = new StringBuilder(query.length() + 50);
-		final String normalizedSelect = query.toLowerCase().trim();
+		final String normalizedSelect = query.toLowerCase(Locale.ROOT).trim();
 		final int forUpdateIndex = normalizedSelect.lastIndexOf( "for update") ;
 
 		if ( hasForUpdateClause( forUpdateIndex ) ) {
 			sb.append( query.substring( 0, forUpdateIndex-1 ) );
 		}
 		else if ( hasWithClause( normalizedSelect ) ) {
 			sb.append( query.substring( 0, getWithIndex( query ) - 1 ) );
 		}
 		else {
 			sb.append( query );
 		}
 
 		if ( offset == 0 ) {
 			sb.append( " fetch first " );
 		}
 		else {
 			sb.append( " offset " ).append( offset ).append( " rows fetch next " );
 		}
 
 		sb.append( limit ).append( " rows only" );
 
 		if ( hasForUpdateClause( forUpdateIndex ) ) {
 			sb.append( ' ' );
 			sb.append( query.substring( forUpdateIndex ) );
 		}
 		else if ( hasWithClause( normalizedSelect ) ) {
 			sb.append( ' ' ).append( query.substring( getWithIndex( query ) ) );
 		}
 		return sb.toString();
 	}
 
 	@Override
 	public boolean supportsVariableLimit() {
 		// we bind the limit and offset values directly into the sql...
 		return false;
 	}
 
 	private boolean hasForUpdateClause(int forUpdateIndex) {
 		return forUpdateIndex >= 0;
 	}
 
 	private boolean hasWithClause(String normalizedSelect){
 		return normalizedSelect.startsWith( "with ", normalizedSelect.length()-7 );
 	}
 
 	private int getWithIndex(String querySelect) {
 		int i = querySelect.lastIndexOf( "with " );
 		if ( i < 0 ) {
 			i = querySelect.lastIndexOf( "WITH " );
 		}
 		return i;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return null ;
 	}
 
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean supportsLobValueChangePropogation() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsUnboundedLobLocatorMaterialization() {
 		return false;
 	}
 
 	private final class DerbyLimitHandler extends AbstractLimitHandler {
 		/**
 		 * {@inheritDoc}
 		 * <p/>
 		 * From Derby 10.5 Docs:
 		 * <pre>
 		 * Query
 		 * [ORDER BY clause]
 		 * [result offset clause]
 		 * [fetch first clause]
 		 * [FOR UPDATE clause]
 		 * [WITH {RR|RS|CS|UR}]
 		 * </pre>
 		 */
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final StringBuilder sb = new StringBuilder( sql.length() + 50 );
-			final String normalizedSelect = sql.toLowerCase().trim();
+			final String normalizedSelect = sql.toLowerCase(Locale.ROOT).trim();
 			final int forUpdateIndex = normalizedSelect.lastIndexOf( "for update" );
 
 			if (hasForUpdateClause( forUpdateIndex )) {
 				sb.append( sql.substring( 0, forUpdateIndex - 1 ) );
 			}
 			else if (hasWithClause( normalizedSelect )) {
 				sb.append( sql.substring( 0, getWithIndex( sql ) - 1 ) );
 			}
 			else {
 				sb.append( sql );
 			}
 
 			if (LimitHelper.hasFirstRow( selection )) {
 				sb.append( " offset ? rows fetch next " );
 			}
 			else {
 				sb.append( " fetch first " );
 			}
 
 			sb.append( "? rows only" );
 
 			if (hasForUpdateClause( forUpdateIndex )) {
 				sb.append( ' ' );
 				sb.append( sql.substring( forUpdateIndex ) );
 			}
 			else if (hasWithClause( normalizedSelect )) {
 				sb.append( ' ' ).append( sql.substring( getWithIndex( sql ) ) );
 			}
 			return sb.toString();
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return isTenPointFiveReleaseOrNewer();
 		}
 
 		@Override
 		@SuppressWarnings("deprecation")
 		public boolean supportsLimitOffset() {
 			return isTenPointFiveReleaseOrNewer();
 		}
 
 		@Override
 		public boolean supportsVariableLimit() {
 			return false;
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Dialect.java
index 71bd55e164..8dda1949c4 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Dialect.java
@@ -1,2816 +1,2817 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.NullPrecedence;
 import org.hibernate.ScrollMode;
 import org.hibernate.boot.model.TypeContributions;
 import org.hibernate.boot.model.relational.AuxiliaryDatabaseObject;
 import org.hibernate.boot.model.relational.Sequence;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.CastFunction;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardAnsiSqlAggregationFunctions;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.dialect.lock.OptimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.OptimisticLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticReadSelectLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticWriteSelectLockingStrategy;
 import org.hibernate.dialect.lock.SelectLockingStrategy;
 import org.hibernate.dialect.pagination.LegacyLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.unique.DefaultUniqueDelegate;
 import org.hibernate.dialect.unique.UniqueDelegate;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.env.internal.DefaultSchemaNameResolver;
 import org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;
 import org.hibernate.engine.jdbc.env.spi.SchemaNameResolver;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.exception.spi.ConversionContext;
 import org.hibernate.exception.spi.SQLExceptionConversionDelegate;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.id.SequenceGenerator;
 import org.hibernate.id.enhanced.SequenceStyleGenerator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.io.StreamCopier;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Constraint;
 import org.hibernate.mapping.ForeignKey;
 import org.hibernate.mapping.Index;
 import org.hibernate.mapping.Table;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.procedure.internal.StandardCallableStatementSupport;
 import org.hibernate.procedure.spi.CallableStatementSupport;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.sql.ANSICaseFragment;
 import org.hibernate.sql.ANSIJoinFragment;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.ForUpdateFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.tool.schema.extract.internal.SequenceInformationExtractorLegacyImpl;
 import org.hibernate.tool.schema.extract.internal.SequenceInformationExtractorNoOpImpl;
 import org.hibernate.tool.schema.extract.spi.SequenceInformationExtractor;
 import org.hibernate.tool.schema.internal.StandardAuxiliaryDatabaseObjectExporter;
 import org.hibernate.tool.schema.internal.StandardForeignKeyExporter;
 import org.hibernate.tool.schema.internal.StandardIndexExporter;
 import org.hibernate.tool.schema.internal.StandardSequenceExporter;
 import org.hibernate.tool.schema.internal.StandardTableExporter;
 import org.hibernate.tool.schema.internal.StandardUniqueKeyExporter;
 import org.hibernate.tool.schema.internal.TemporaryTableExporter;
 import org.hibernate.tool.schema.spi.Exporter;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.descriptor.sql.ClobTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 import org.jboss.logging.Logger;
 
 import java.io.InputStream;
 import java.io.OutputStream;
 import java.sql.Blob;
 import java.sql.CallableStatement;
 import java.sql.Clob;
 import java.sql.NClob;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Locale;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 
 /**
  * Represents a dialect of SQL implemented by a particular RDBMS.  Subclasses implement Hibernate compatibility
  * with different systems.  Subclasses should provide a public default constructor that register a set of type
  * mappings and default Hibernate properties.  Subclasses should be immutable.
  *
  * @author Gavin King, David Channon
  */
 @SuppressWarnings("deprecation")
 public abstract class Dialect implements ConversionContext {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			Dialect.class.getName()
 	);
 
 	/**
 	 * Defines a default batch size constant
 	 */
 	public static final String DEFAULT_BATCH_SIZE = "15";
 
 	/**
 	 * Defines a "no batching" batch size constant
 	 */
 	public static final String NO_BATCH = "0";
 
 	/**
 	 * Characters used as opening for quoting SQL identifiers
 	 */
 	public static final String QUOTE = "`\"[";
 
 	/**
 	 * Characters used as closing for quoting SQL identifiers
 	 */
 	public static final String CLOSED_QUOTE = "`\"]";
 
 	private final TypeNames typeNames = new TypeNames();
 	private final TypeNames hibernateTypeNames = new TypeNames();
 
 	private final Properties properties = new Properties();
 	private final Map<String, SQLFunction> sqlFunctions = new HashMap<String, SQLFunction>();
 	private final Set<String> sqlKeywords = new HashSet<String>();
 
 	private final UniqueDelegate uniqueDelegate;
 
 
 	// constructors and factory methods ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	protected Dialect() {
 		LOG.usingDialect( this );
 		StandardAnsiSqlAggregationFunctions.primeFunctionMap( sqlFunctions );
 
 		// standard sql92 functions (can be overridden by subclasses)
 		registerFunction( "substring", new SQLFunctionTemplate( StandardBasicTypes.STRING, "substring(?1, ?2, ?3)" ) );
 		registerFunction( "locate", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "locate(?1, ?2, ?3)" ) );
 		registerFunction( "trim", new SQLFunctionTemplate( StandardBasicTypes.STRING, "trim(?1 ?2 ?3 ?4)" ) );
 		registerFunction( "length", new StandardSQLFunction( "length", StandardBasicTypes.INTEGER ) );
 		registerFunction( "bit_length", new StandardSQLFunction( "bit_length", StandardBasicTypes.INTEGER ) );
 		registerFunction( "coalesce", new StandardSQLFunction( "coalesce" ) );
 		registerFunction( "nullif", new StandardSQLFunction( "nullif" ) );
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "mod", new StandardSQLFunction( "mod", StandardBasicTypes.INTEGER) );
 		registerFunction( "sqrt", new StandardSQLFunction( "sqrt", StandardBasicTypes.DOUBLE) );
 		registerFunction( "upper", new StandardSQLFunction("upper") );
 		registerFunction( "lower", new StandardSQLFunction("lower") );
 		registerFunction( "cast", new CastFunction() );
 		registerFunction( "extract", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(?1 ?2 ?3)") );
 
 		//map second/minute/hour/day/month/year to ANSI extract(), override on subclasses
 		registerFunction( "second", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(second from ?1)") );
 		registerFunction( "minute", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(minute from ?1)") );
 		registerFunction( "hour", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(hour from ?1)") );
 		registerFunction( "day", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(day from ?1)") );
 		registerFunction( "month", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(month from ?1)") );
 		registerFunction( "year", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(year from ?1)") );
 
 		registerFunction( "str", new SQLFunctionTemplate(StandardBasicTypes.STRING, "cast(?1 as char)") );
 
 		registerColumnType( Types.BIT, "bit" );
 		registerColumnType( Types.BOOLEAN, "boolean" );
 		registerColumnType( Types.TINYINT, "tinyint" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.INTEGER, "integer" );
 		registerColumnType( Types.BIGINT, "bigint" );
 		registerColumnType( Types.FLOAT, "float($p)" );
 		registerColumnType( Types.DOUBLE, "double precision" );
 		registerColumnType( Types.NUMERIC, "numeric($p,$s)" );
 		registerColumnType( Types.REAL, "real" );
 
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 
 		registerColumnType( Types.VARBINARY, "bit varying($l)" );
 		registerColumnType( Types.LONGVARBINARY, "bit varying($l)" );
 		registerColumnType( Types.BLOB, "blob" );
 
 		registerColumnType( Types.CHAR, "char($l)" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.LONGVARCHAR, "varchar($l)" );
 		registerColumnType( Types.CLOB, "clob" );
 
 		registerColumnType( Types.NCHAR, "nchar($l)" );
 		registerColumnType( Types.NVARCHAR, "nvarchar($l)" );
 		registerColumnType( Types.LONGNVARCHAR, "nvarchar($l)" );
 		registerColumnType( Types.NCLOB, "nclob" );
 
 		// register hibernate types for default use in scalar sqlquery type auto detection
 		registerHibernateType( Types.BIGINT, StandardBasicTypes.BIG_INTEGER.getName() );
 		registerHibernateType( Types.BINARY, StandardBasicTypes.BINARY.getName() );
 		registerHibernateType( Types.BIT, StandardBasicTypes.BOOLEAN.getName() );
 		registerHibernateType( Types.BOOLEAN, StandardBasicTypes.BOOLEAN.getName() );
 		registerHibernateType( Types.CHAR, StandardBasicTypes.CHARACTER.getName() );
 		registerHibernateType( Types.CHAR, 1, StandardBasicTypes.CHARACTER.getName() );
 		registerHibernateType( Types.CHAR, 255, StandardBasicTypes.STRING.getName() );
 		registerHibernateType( Types.DATE, StandardBasicTypes.DATE.getName() );
 		registerHibernateType( Types.DOUBLE, StandardBasicTypes.DOUBLE.getName() );
 		registerHibernateType( Types.FLOAT, StandardBasicTypes.FLOAT.getName() );
 		registerHibernateType( Types.INTEGER, StandardBasicTypes.INTEGER.getName() );
 		registerHibernateType( Types.SMALLINT, StandardBasicTypes.SHORT.getName() );
 		registerHibernateType( Types.TINYINT, StandardBasicTypes.BYTE.getName() );
 		registerHibernateType( Types.TIME, StandardBasicTypes.TIME.getName() );
 		registerHibernateType( Types.TIMESTAMP, StandardBasicTypes.TIMESTAMP.getName() );
 		registerHibernateType( Types.VARCHAR, StandardBasicTypes.STRING.getName() );
 		registerHibernateType( Types.VARBINARY, StandardBasicTypes.BINARY.getName() );
 		registerHibernateType( Types.LONGVARCHAR, StandardBasicTypes.TEXT.getName() );
 		registerHibernateType( Types.LONGVARBINARY, StandardBasicTypes.IMAGE.getName() );
 		registerHibernateType( Types.NUMERIC, StandardBasicTypes.BIG_DECIMAL.getName() );
 		registerHibernateType( Types.DECIMAL, StandardBasicTypes.BIG_DECIMAL.getName() );
 		registerHibernateType( Types.BLOB, StandardBasicTypes.BLOB.getName() );
 		registerHibernateType( Types.CLOB, StandardBasicTypes.CLOB.getName() );
 		registerHibernateType( Types.REAL, StandardBasicTypes.FLOAT.getName() );
 
 		uniqueDelegate = new DefaultUniqueDelegate( this );
 	}
 
 	/**
 	 * Get an instance of the dialect specified by the current <tt>System</tt> properties.
 	 *
 	 * @return The specified Dialect
 	 * @throws HibernateException If no dialect was specified, or if it could not be instantiated.
 	 */
 	public static Dialect getDialect() throws HibernateException {
 		return instantiateDialect( Environment.getProperties().getProperty( Environment.DIALECT ) );
 	}
 
 
 	/**
 	 * Get an instance of the dialect specified by the given properties or by
 	 * the current <tt>System</tt> properties.
 	 *
 	 * @param props The properties to use for finding the dialect class to use.
 	 * @return The specified Dialect
 	 * @throws HibernateException If no dialect was specified, or if it could not be instantiated.
 	 */
 	public static Dialect getDialect(Properties props) throws HibernateException {
 		final String dialectName = props.getProperty( Environment.DIALECT );
 		if ( dialectName == null ) {
 			return getDialect();
 		}
 		return instantiateDialect( dialectName );
 	}
 
 	private static Dialect instantiateDialect(String dialectName) throws HibernateException {
 		if ( dialectName == null ) {
 			throw new HibernateException( "The dialect was not set. Set the property hibernate.dialect." );
 		}
 		try {
 			return (Dialect) ReflectHelper.classForName( dialectName ).newInstance();
 		}
 		catch ( ClassNotFoundException cnfe ) {
 			throw new HibernateException( "Dialect class not found: " + dialectName );
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Could not instantiate given dialect class: " + dialectName, e );
 		}
 	}
 
 	/**
 	 * Retrieve a set of default Hibernate properties for this database.
 	 *
 	 * @return a set of Hibernate properties
 	 */
 	public final Properties getDefaultProperties() {
 		return properties;
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName();
 	}
 
 
 	// database type mapping support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Allows the Dialect to contribute additional types
 	 *
 	 * @param typeContributions Callback to contribute the types
 	 * @param serviceRegistry The service registry
 	 */
 	public void contributeTypes(TypeContributions typeContributions, ServiceRegistry serviceRegistry) {
 		// by default, nothing to do
 	}
 
 	/**
 	 * Get the name of the database type associated with the given
 	 * {@link java.sql.Types} typecode.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @return the database type name
 	 * @throws HibernateException If no mapping was specified for that type.
 	 */
 	public String getTypeName(int code) throws HibernateException {
 		final String result = typeNames.get( code );
 		if ( result == null ) {
 			throw new HibernateException( "No default type mapping for (java.sql.Types) " + code );
 		}
 		return result;
 	}
 
 	/**
 	 * Get the name of the database type associated with the given
 	 * {@link java.sql.Types} typecode with the given storage specification
 	 * parameters.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param length The datatype length
 	 * @param precision The datatype precision
 	 * @param scale The datatype scale
 	 * @return the database type name
 	 * @throws HibernateException If no mapping was specified for that type.
 	 */
 	public String getTypeName(int code, long length, int precision, int scale) throws HibernateException {
 		final String result = typeNames.get( code, length, precision, scale );
 		if ( result == null ) {
 			throw new HibernateException(
 					String.format( "No type mapping for java.sql.Types code: %s, length: %s", code, length )
 			);
 		}
 		return result;
 	}
 
 	/**
 	 * Get the name of the database type appropriate for casting operations
 	 * (via the CAST() SQL function) for the given {@link java.sql.Types} typecode.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @return The database type name
 	 */
 	public String getCastTypeName(int code) {
 		return getTypeName( code, Column.DEFAULT_LENGTH, Column.DEFAULT_PRECISION, Column.DEFAULT_SCALE );
 	}
 
 	/**
 	 * Return an expression casting the value to the specified type
 	 *
 	 * @param value The value to cast
 	 * @param jdbcTypeCode The JDBC type code to cast to
 	 * @param length The type length
 	 * @param precision The type precision
 	 * @param scale The type scale
 	 *
 	 * @return The cast expression
 	 */
 	public String cast(String value, int jdbcTypeCode, int length, int precision, int scale) {
 		if ( jdbcTypeCode == Types.CHAR ) {
 			return "cast(" + value + " as char(" + length + "))";
 		}
 		else {
 			return "cast(" + value + "as " + getTypeName( jdbcTypeCode, length, precision, scale ) + ")";
 		}
 	}
 
 	/**
 	 * Return an expression casting the value to the specified type.  Simply calls
 	 * {@link #cast(String, int, int, int, int)} passing {@link Column#DEFAULT_PRECISION} and
 	 * {@link Column#DEFAULT_SCALE} as the precision/scale.
 	 *
 	 * @param value The value to cast
 	 * @param jdbcTypeCode The JDBC type code to cast to
 	 * @param length The type length
 	 *
 	 * @return The cast expression
 	 */
 	public String cast(String value, int jdbcTypeCode, int length) {
 		return cast( value, jdbcTypeCode, length, Column.DEFAULT_PRECISION, Column.DEFAULT_SCALE );
 	}
 
 	/**
 	 * Return an expression casting the value to the specified type.  Simply calls
 	 * {@link #cast(String, int, int, int, int)} passing {@link Column#DEFAULT_LENGTH} as the length
 	 *
 	 * @param value The value to cast
 	 * @param jdbcTypeCode The JDBC type code to cast to
 	 * @param precision The type precision
 	 * @param scale The type scale
 	 *
 	 * @return The cast expression
 	 */
 	public String cast(String value, int jdbcTypeCode, int precision, int scale) {
 		return cast( value, jdbcTypeCode, Column.DEFAULT_LENGTH, precision, scale );
 	}
 
 	/**
 	 * Subclasses register a type name for the given type code and maximum
 	 * column length. <tt>$l</tt> in the type name with be replaced by the
 	 * column length (if appropriate).
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param capacity The maximum length of database type
 	 * @param name The database type name
 	 */
 	protected void registerColumnType(int code, long capacity, String name) {
 		typeNames.put( code, capacity, name );
 	}
 
 	/**
 	 * Subclasses register a type name for the given type code. <tt>$l</tt> in
 	 * the type name with be replaced by the column length (if appropriate).
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param name The database type name
 	 */
 	protected void registerColumnType(int code, String name) {
 		typeNames.put( code, name );
 	}
 
 	/**
 	 * Allows the dialect to override a {@link SqlTypeDescriptor}.
 	 * <p/>
 	 * If the passed {@code sqlTypeDescriptor} allows itself to be remapped (per
 	 * {@link org.hibernate.type.descriptor.sql.SqlTypeDescriptor#canBeRemapped()}), then this method uses
 	 * {@link #getSqlTypeDescriptorOverride}  to get an optional override based on the SQL code returned by
 	 * {@link SqlTypeDescriptor#getSqlType()}.
 	 * <p/>
 	 * If this dialect does not provide an override or if the {@code sqlTypeDescriptor} doe not allow itself to be
 	 * remapped, then this method simply returns the original passed {@code sqlTypeDescriptor}
 	 *
 	 * @param sqlTypeDescriptor The {@link SqlTypeDescriptor} to override
 	 * @return The {@link SqlTypeDescriptor} that should be used for this dialect;
 	 *         if there is no override, then original {@code sqlTypeDescriptor} is returned.
 	 * @throws IllegalArgumentException if {@code sqlTypeDescriptor} is null.
 	 *
 	 * @see #getSqlTypeDescriptorOverride
 	 */
 	public SqlTypeDescriptor remapSqlTypeDescriptor(SqlTypeDescriptor sqlTypeDescriptor) {
 		if ( sqlTypeDescriptor == null ) {
 			throw new IllegalArgumentException( "sqlTypeDescriptor is null" );
 		}
 		if ( ! sqlTypeDescriptor.canBeRemapped() ) {
 			return sqlTypeDescriptor;
 		}
 
 		final SqlTypeDescriptor overridden = getSqlTypeDescriptorOverride( sqlTypeDescriptor.getSqlType() );
 		return overridden == null ? sqlTypeDescriptor : overridden;
 	}
 
 	/**
 	 * Returns the {@link SqlTypeDescriptor} that should be used to handle the given JDBC type code.  Returns
 	 * {@code null} if there is no override.
 	 *
 	 * @param sqlCode A {@link Types} constant indicating the SQL column type
 	 * @return The {@link SqlTypeDescriptor} to use as an override, or {@code null} if there is no override.
 	 */
 	protected SqlTypeDescriptor getSqlTypeDescriptorOverride(int sqlCode) {
 		SqlTypeDescriptor descriptor;
 		switch ( sqlCode ) {
 			case Types.CLOB: {
 				descriptor = useInputStreamToInsertBlob() ? ClobTypeDescriptor.STREAM_BINDING : null;
 				break;
 			}
 			default: {
 				descriptor = null;
 				break;
 			}
 		}
 		return descriptor;
 	}
 
 	/**
 	 * The legacy behavior of Hibernate.  LOBs are not processed by merge
 	 */
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected static final LobMergeStrategy LEGACY_LOB_MERGE_STRATEGY = new LobMergeStrategy() {
 		@Override
 		public Blob mergeBlob(Blob original, Blob target, SessionImplementor session) {
 			return target;
 		}
 
 		@Override
 		public Clob mergeClob(Clob original, Clob target, SessionImplementor session) {
 			return target;
 		}
 
 		@Override
 		public NClob mergeNClob(NClob original, NClob target, SessionImplementor session) {
 			return target;
 		}
 	};
 
 	/**
 	 * Merge strategy based on transferring contents based on streams.
 	 */
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected static final LobMergeStrategy STREAM_XFER_LOB_MERGE_STRATEGY = new LobMergeStrategy() {
 		@Override
 		public Blob mergeBlob(Blob original, Blob target, SessionImplementor session) {
 			if ( original != target ) {
 				try {
 					// the BLOB just read during the load phase of merge
 					final OutputStream connectedStream = target.setBinaryStream( 1L );
 					// the BLOB from the detached state
 					final InputStream detachedStream = original.getBinaryStream();
 					StreamCopier.copy( detachedStream, connectedStream );
 					return target;
 				}
 				catch (SQLException e ) {
 					throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge BLOB data" );
 				}
 			}
 			else {
 				return NEW_LOCATOR_LOB_MERGE_STRATEGY.mergeBlob( original, target, session );
 			}
 		}
 
 		@Override
 		public Clob mergeClob(Clob original, Clob target, SessionImplementor session) {
 			if ( original != target ) {
 				try {
 					// the CLOB just read during the load phase of merge
 					final OutputStream connectedStream = target.setAsciiStream( 1L );
 					// the CLOB from the detached state
 					final InputStream detachedStream = original.getAsciiStream();
 					StreamCopier.copy( detachedStream, connectedStream );
 					return target;
 				}
 				catch (SQLException e ) {
 					throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge CLOB data" );
 				}
 			}
 			else {
 				return NEW_LOCATOR_LOB_MERGE_STRATEGY.mergeClob( original, target, session );
 			}
 		}
 
 		@Override
 		public NClob mergeNClob(NClob original, NClob target, SessionImplementor session) {
 			if ( original != target ) {
 				try {
 					// the NCLOB just read during the load phase of merge
 					final OutputStream connectedStream = target.setAsciiStream( 1L );
 					// the NCLOB from the detached state
 					final InputStream detachedStream = original.getAsciiStream();
 					StreamCopier.copy( detachedStream, connectedStream );
 					return target;
 				}
 				catch (SQLException e ) {
 					throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge NCLOB data" );
 				}
 			}
 			else {
 				return NEW_LOCATOR_LOB_MERGE_STRATEGY.mergeNClob( original, target, session );
 			}
 		}
 	};
 
 	/**
 	 * Merge strategy based on creating a new LOB locator.
 	 */
 	protected static final LobMergeStrategy NEW_LOCATOR_LOB_MERGE_STRATEGY = new LobMergeStrategy() {
 		@Override
 		public Blob mergeBlob(Blob original, Blob target, SessionImplementor session) {
 			if ( original == null && target == null ) {
 				return null;
 			}
 			try {
 				final LobCreator lobCreator = session.getFactory().getJdbcServices().getLobCreator( session );
 				return original == null
 						? lobCreator.createBlob( ArrayHelper.EMPTY_BYTE_ARRAY )
 						: lobCreator.createBlob( original.getBinaryStream(), original.length() );
 			}
 			catch (SQLException e) {
 				throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge BLOB data" );
 			}
 		}
 
 		@Override
 		public Clob mergeClob(Clob original, Clob target, SessionImplementor session) {
 			if ( original == null && target == null ) {
 				return null;
 			}
 			try {
 				final LobCreator lobCreator = session.getFactory().getJdbcServices().getLobCreator( session );
 				return original == null
 						? lobCreator.createClob( "" )
 						: lobCreator.createClob( original.getCharacterStream(), original.length() );
 			}
 			catch (SQLException e) {
 				throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge CLOB data" );
 			}
 		}
 
 		@Override
 		public NClob mergeNClob(NClob original, NClob target, SessionImplementor session) {
 			if ( original == null && target == null ) {
 				return null;
 			}
 			try {
 				final LobCreator lobCreator = session.getFactory().getJdbcServices().getLobCreator( session );
 				return original == null
 						? lobCreator.createNClob( "" )
 						: lobCreator.createNClob( original.getCharacterStream(), original.length() );
 			}
 			catch (SQLException e) {
 				throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge NCLOB data" );
 			}
 		}
 	};
 
 	public LobMergeStrategy getLobMergeStrategy() {
 		return NEW_LOCATOR_LOB_MERGE_STRATEGY;
 	}
 
 
 	// hibernate type mapping support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Get the name of the Hibernate {@link org.hibernate.type.Type} associated with the given
 	 * {@link java.sql.Types} type code.
 	 *
 	 * @param code The {@link java.sql.Types} type code
 	 * @return The Hibernate {@link org.hibernate.type.Type} name.
 	 * @throws HibernateException If no mapping was specified for that type.
 	 */
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public String getHibernateTypeName(int code) throws HibernateException {
 		final String result = hibernateTypeNames.get( code );
 		if ( result == null ) {
 			throw new HibernateException( "No Hibernate type mapping for java.sql.Types code: " + code );
 		}
 		return result;
 	}
 
 	/**
 	 * Get the name of the Hibernate {@link org.hibernate.type.Type} associated
 	 * with the given {@link java.sql.Types} typecode with the given storage
 	 * specification parameters.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param length The datatype length
 	 * @param precision The datatype precision
 	 * @param scale The datatype scale
 	 * @return The Hibernate {@link org.hibernate.type.Type} name.
 	 * @throws HibernateException If no mapping was specified for that type.
 	 */
 	public String getHibernateTypeName(int code, int length, int precision, int scale) throws HibernateException {
 		final String result = hibernateTypeNames.get( code, length, precision, scale );
 		if ( result == null ) {
 			throw new HibernateException(
 					String.format(
 							"No Hibernate type mapping for type [code=%s, length=%s]",
 							code,
 							length
 					)
 			);
 		}
 		return result;
 	}
 
 	/**
 	 * Registers a Hibernate {@link org.hibernate.type.Type} name for the given
 	 * {@link java.sql.Types} type code and maximum column length.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param capacity The maximum length of database type
 	 * @param name The Hibernate {@link org.hibernate.type.Type} name
 	 */
 	protected void registerHibernateType(int code, long capacity, String name) {
 		hibernateTypeNames.put( code, capacity, name);
 	}
 
 	/**
 	 * Registers a Hibernate {@link org.hibernate.type.Type} name for the given
 	 * {@link java.sql.Types} type code.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param name The Hibernate {@link org.hibernate.type.Type} name
 	 */
 	protected void registerHibernateType(int code, String name) {
 		hibernateTypeNames.put( code, name);
 	}
 
 
 	// function support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	protected void registerFunction(String name, SQLFunction function) {
 		// HHH-7721: SQLFunctionRegistry expects all lowercase.  Enforce,
 		// just in case a user's customer dialect uses mixed cases.
-		sqlFunctions.put( name.toLowerCase(), function );
+		sqlFunctions.put( name.toLowerCase(Locale.ROOT), function );
 	}
 
 	/**
 	 * Retrieves a map of the dialect's registered functions
 	 * (functionName => {@link org.hibernate.dialect.function.SQLFunction}).
 	 *
 	 * @return The map of registered functions.
 	 */
 	public final Map<String, SQLFunction> getFunctions() {
 		return sqlFunctions;
 	}
 
 
 	// keyword support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	protected void registerKeyword(String word) {
 		sqlKeywords.add( word );
 	}
 
 	public Set<String> getKeywords() {
 		return sqlKeywords;
 	}
 
 
 	// native identifier generation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * The class (which implements {@link org.hibernate.id.IdentifierGenerator})
 	 * which acts as this dialects native generation strategy.
 	 * <p/>
 	 * Comes into play whenever the user specifies the native generator.
 	 *
 	 * @return The native generator class.
 	 */
 	public Class getNativeIdentifierGeneratorClass() {
 		if ( supportsIdentityColumns() ) {
 			return IdentityGenerator.class;
 		}
 		else if ( supportsSequences() ) {
 			return SequenceGenerator.class;
 		}
 		else {
 			return SequenceStyleGenerator.class;
 		}
 	}
 
 
 	// IDENTITY support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Does this dialect support identity column key generation?
 	 *
 	 * @return True if IDENTITY columns are supported; false otherwise.
 	 */
 	public boolean supportsIdentityColumns() {
 		return false;
 	}
 
 	/**
 	 * Does the dialect support some form of inserting and selecting
 	 * the generated IDENTITY value all in the same statement.
 	 *
 	 * @return True if the dialect supports selecting the just
 	 * generated IDENTITY in the insert statement.
 	 */
 	public boolean supportsInsertSelectIdentity() {
 		return false;
 	}
 
 	/**
 	 * Whether this dialect have an Identity clause added to the data type or a
 	 * completely separate identity data type
 	 *
 	 * @return boolean
 	 */
 	public boolean hasDataTypeInIdentityColumn() {
 		return true;
 	}
 
 	/**
 	 * Provided we {@link #supportsInsertSelectIdentity}, then attach the
 	 * "select identity" clause to the  insert statement.
 	 *  <p/>
 	 * Note, if {@link #supportsInsertSelectIdentity} == false then
 	 * the insert-string should be returned without modification.
 	 *
 	 * @param insertString The insert command
 	 * @return The insert command with any necessary identity select
 	 * clause attached.
 	 */
 	public String appendIdentitySelectToInsert(String insertString) {
 		return insertString;
 	}
 
 	/**
 	 * Get the select command to use to retrieve the last generated IDENTITY
 	 * value for a particular table
 	 *
 	 * @param table The table into which the insert was done
 	 * @param column The PK column.
 	 * @param type The {@link java.sql.Types} type code.
 	 * @return The appropriate select command
 	 * @throws MappingException If IDENTITY generation is not supported.
 	 */
 	public String getIdentitySelectString(String table, String column, int type) throws MappingException {
 		return getIdentitySelectString();
 	}
 
 	/**
 	 * Get the select command to use to retrieve the last generated IDENTITY
 	 * value.
 	 *
 	 * @return The appropriate select command
 	 * @throws MappingException If IDENTITY generation is not supported.
 	 */
 	protected String getIdentitySelectString() throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support identity key generation" );
 	}
 
 	/**
 	 * The syntax used during DDL to define a column as being an IDENTITY of
 	 * a particular type.
 	 *
 	 * @param type The {@link java.sql.Types} type code.
 	 * @return The appropriate DDL fragment.
 	 * @throws MappingException If IDENTITY generation is not supported.
 	 */
 	public String getIdentityColumnString(int type) throws MappingException {
 		return getIdentityColumnString();
 	}
 
 	/**
 	 * The syntax used during DDL to define a column as being an IDENTITY.
 	 *
 	 * @return The appropriate DDL fragment.
 	 * @throws MappingException If IDENTITY generation is not supported.
 	 */
 	protected String getIdentityColumnString() throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support identity key generation" );
 	}
 
 	/**
 	 * The keyword used to insert a generated value into an identity column (or null).
 	 * Need if the dialect does not support inserts that specify no column values.
 	 *
 	 * @return The appropriate keyword.
 	 */
 	public String getIdentityInsertString() {
 		return null;
 	}
 
 
 	// SEQUENCE support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Does this dialect support sequences?
 	 *
 	 * @return True if sequences supported; false otherwise.
 	 */
 	public boolean supportsSequences() {
 		return false;
 	}
 
 	/**
 	 * Does this dialect support "pooled" sequences.  Not aware of a better
 	 * name for this.  Essentially can we specify the initial and increment values?
 	 *
 	 * @return True if such "pooled" sequences are supported; false otherwise.
 	 * @see #getCreateSequenceStrings(String, int, int)
 	 * @see #getCreateSequenceString(String, int, int)
 	 */
 	public boolean supportsPooledSequences() {
 		return false;
 	}
 
 	/**
 	 * Generate the appropriate select statement to to retrieve the next value
 	 * of a sequence.
 	 * <p/>
 	 * This should be a "stand alone" select statement.
 	 *
 	 * @param sequenceName the name of the sequence
 	 * @return String The "nextval" select string.
 	 * @throws MappingException If sequences are not supported.
 	 */
 	public String getSequenceNextValString(String sequenceName) throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support sequences" );
 	}
 
 	/**
 	 * Generate the select expression fragment that will retrieve the next
 	 * value of a sequence as part of another (typically DML) statement.
 	 * <p/>
 	 * This differs from {@link #getSequenceNextValString(String)} in that this
 	 * should return an expression usable within another statement.
 	 *
 	 * @param sequenceName the name of the sequence
 	 * @return The "nextval" fragment.
 	 * @throws MappingException If sequences are not supported.
 	 */
 	public String getSelectSequenceNextValString(String sequenceName) throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support sequences" );
 	}
 
 	/**
 	 * The multiline script used to create a sequence.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @return The sequence creation commands
 	 * @throws MappingException If sequences are not supported.
 	 * @deprecated Use {@link #getCreateSequenceString(String, int, int)} instead
 	 */
 	@Deprecated
 	public String[] getCreateSequenceStrings(String sequenceName) throws MappingException {
 		return new String[] { getCreateSequenceString( sequenceName ) };
 	}
 
 	/**
 	 * An optional multi-line form for databases which {@link #supportsPooledSequences()}.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @param initialValue The initial value to apply to 'create sequence' statement
 	 * @param incrementSize The increment value to apply to 'create sequence' statement
 	 * @return The sequence creation commands
 	 * @throws MappingException If sequences are not supported.
 	 */
 	public String[] getCreateSequenceStrings(String sequenceName, int initialValue, int incrementSize) throws MappingException {
 		return new String[] { getCreateSequenceString( sequenceName, initialValue, incrementSize ) };
 	}
 
 	/**
 	 * Typically dialects which support sequences can create a sequence
 	 * with a single command.  This is convenience form of
 	 * {@link #getCreateSequenceStrings} to help facilitate that.
 	 * <p/>
 	 * Dialects which support sequences and can create a sequence in a
 	 * single command need *only* override this method.  Dialects
 	 * which support sequences but require multiple commands to create
 	 * a sequence should instead override {@link #getCreateSequenceStrings}.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @return The sequence creation command
 	 * @throws MappingException If sequences are not supported.
 	 */
 	protected String getCreateSequenceString(String sequenceName) throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support sequences" );
 	}
 
 	/**
 	 * Overloaded form of {@link #getCreateSequenceString(String)}, additionally
 	 * taking the initial value and increment size to be applied to the sequence
 	 * definition.
 	 * </p>
 	 * The default definition is to suffix {@link #getCreateSequenceString(String)}
 	 * with the string: " start with {initialValue} increment by {incrementSize}" where
 	 * {initialValue} and {incrementSize} are replacement placeholders.  Generally
 	 * dialects should only need to override this method if different key phrases
 	 * are used to apply the allocation information.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @param initialValue The initial value to apply to 'create sequence' statement
 	 * @param incrementSize The increment value to apply to 'create sequence' statement
 	 * @return The sequence creation command
 	 * @throws MappingException If sequences are not supported.
 	 */
 	protected String getCreateSequenceString(String sequenceName, int initialValue, int incrementSize) throws MappingException {
 		if ( supportsPooledSequences() ) {
 			return getCreateSequenceString( sequenceName ) + " start with " + initialValue + " increment by " + incrementSize;
 		}
 		throw new MappingException( getClass().getName() + " does not support pooled sequences" );
 	}
 
 	/**
 	 * The multiline script used to drop a sequence.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @return The sequence drop commands
 	 * @throws MappingException If sequences are not supported.
 	 */
 	public String[] getDropSequenceStrings(String sequenceName) throws MappingException {
 		return new String[]{getDropSequenceString( sequenceName )};
 	}
 
 	/**
 	 * Typically dialects which support sequences can drop a sequence
 	 * with a single command.  This is convenience form of
 	 * {@link #getDropSequenceStrings} to help facilitate that.
 	 * <p/>
 	 * Dialects which support sequences and can drop a sequence in a
 	 * single command need *only* override this method.  Dialects
 	 * which support sequences but require multiple commands to drop
 	 * a sequence should instead override {@link #getDropSequenceStrings}.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @return The sequence drop commands
 	 * @throws MappingException If sequences are not supported.
 	 */
 	protected String getDropSequenceString(String sequenceName) throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support sequences" );
 	}
 
 	/**
 	 * Get the select command used retrieve the names of all sequences.
 	 *
 	 * @return The select command; or null if sequences are not supported.
 	 * @see org.hibernate.tool.hbm2ddl.SchemaUpdate
 	 */
 	public String getQuerySequencesString() {
 		return null;
 	}
 
 	public SequenceInformationExtractor getSequenceInformationExtractor() {
 		if ( getQuerySequencesString() == null ) {
 			return SequenceInformationExtractorNoOpImpl.INSTANCE;
 		}
 		else {
 			return SequenceInformationExtractorLegacyImpl.INSTANCE;
 		}
 	}
 
 
 	// GUID support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Get the command used to select a GUID from the underlying database.
 	 * <p/>
 	 * Optional operation.
 	 *
 	 * @return The appropriate command.
 	 */
 	public String getSelectGUIDString() {
 		throw new UnsupportedOperationException( getClass().getName() + " does not support GUIDs" );
 	}
 
 
 	// limit/offset support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Returns the delegate managing LIMIT clause.
 	 *
 	 * @return LIMIT clause delegate.
 	 */
 	public LimitHandler getLimitHandler() {
 		return new LegacyLimitHandler( this );
 	}
 
 	/**
 	 * Does this dialect support some form of limiting query results
 	 * via a SQL clause?
 	 *
 	 * @return True if this dialect supports some form of LIMIT.
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean supportsLimit() {
 		return false;
 	}
 
 	/**
 	 * Does this dialect's LIMIT support (if any) additionally
 	 * support specifying an offset?
 	 *
 	 * @return True if the dialect supports an offset within the limit support.
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean supportsLimitOffset() {
 		return supportsLimit();
 	}
 
 	/**
 	 * Does this dialect support bind variables (i.e., prepared statement
 	 * parameters) for its limit/offset?
 	 *
 	 * @return True if bind variables can be used; false otherwise.
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean supportsVariableLimit() {
 		return supportsLimit();
 	}
 
 	/**
 	 * ANSI SQL defines the LIMIT clause to be in the form LIMIT offset, limit.
 	 * Does this dialect require us to bind the parameters in reverse order?
 	 *
 	 * @return true if the correct order is limit, offset
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean bindLimitParametersInReverseOrder() {
 		return false;
 	}
 
 	/**
 	 * Does the <tt>LIMIT</tt> clause come at the start of the
 	 * <tt>SELECT</tt> statement, rather than at the end?
 	 *
 	 * @return true if limit parameters should come before other parameters
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean bindLimitParametersFirst() {
 		return false;
 	}
 
 	/**
 	 * Does the <tt>LIMIT</tt> clause take a "maximum" row number instead
 	 * of a total number of returned rows?
 	 * <p/>
 	 * This is easiest understood via an example.  Consider you have a table
 	 * with 20 rows, but you only want to retrieve rows number 11 through 20.
 	 * Generally, a limit with offset would say that the offset = 11 and the
 	 * limit = 10 (we only want 10 rows at a time); this is specifying the
 	 * total number of returned rows.  Some dialects require that we instead
 	 * specify offset = 11 and limit = 20, where 20 is the "last" row we want
 	 * relative to offset (i.e. total number of rows = 20 - 11 = 9)
 	 * <p/>
 	 * So essentially, is limit relative from offset?  Or is limit absolute?
 	 *
 	 * @return True if limit is relative from offset; false otherwise.
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean useMaxForLimit() {
 		return false;
 	}
 
 	/**
 	 * Generally, if there is no limit applied to a Hibernate query we do not apply any limits
 	 * to the SQL query.  This option forces that the limit be written to the SQL query.
 	 *
 	 * @return True to force limit into SQL query even if none specified in Hibernate query; false otherwise.
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean forceLimitUsage() {
 		return false;
 	}
 
 	/**
 	 * Given a limit and an offset, apply the limit clause to the query.
 	 *
 	 * @param query The query to which to apply the limit.
 	 * @param offset The offset of the limit
 	 * @param limit The limit of the limit ;)
 	 * @return The modified query statement with the limit applied.
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public String getLimitString(String query, int offset, int limit) {
 		return getLimitString( query, ( offset > 0 || forceLimitUsage() )  );
 	}
 
 	/**
 	 * Apply s limit clause to the query.
 	 * <p/>
 	 * Typically dialects utilize {@link #supportsVariableLimit() variable}
 	 * limit clauses when they support limits.  Thus, when building the
 	 * select command we do not actually need to know the limit or the offest
 	 * since we will just be using placeholders.
 	 * <p/>
 	 * Here we do still pass along whether or not an offset was specified
 	 * so that dialects not supporting offsets can generate proper exceptions.
 	 * In general, dialects will override one or the other of this method and
 	 * {@link #getLimitString(String, int, int)}.
 	 *
 	 * @param query The query to which to apply the limit.
 	 * @param hasOffset Is the query requesting an offset?
 	 * @return the modified SQL
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	protected String getLimitString(String query, boolean hasOffset) {
 		throw new UnsupportedOperationException( "Paged queries not supported by " + getClass().getName());
 	}
 
 	/**
 	 * Hibernate APIs explicitly state that setFirstResult() should be a zero-based offset. Here we allow the
 	 * Dialect a chance to convert that value based on what the underlying db or driver will expect.
 	 * <p/>
 	 * NOTE: what gets passed into {@link #getLimitString(String,int,int)} is the zero-based offset.  Dialects which
 	 * do not {@link #supportsVariableLimit} should take care to perform any needed first-row-conversion calls prior
 	 * to injecting the limit values into the SQL string.
 	 *
 	 * @param zeroBasedFirstResult The user-supplied, zero-based first row offset.
 	 * @return The corresponding db/dialect specific offset.
 	 * @see org.hibernate.Query#setFirstResult
 	 * @see org.hibernate.Criteria#setFirstResult
 	 * @deprecated {@link #getLimitHandler()} should be overridden instead.
 	 */
 	@Deprecated
 	public int convertToFirstRowValue(int zeroBasedFirstResult) {
 		return zeroBasedFirstResult;
 	}
 
 
 	// lock acquisition support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Informational metadata about whether this dialect is known to support
 	 * specifying timeouts for requested lock acquisitions.
 	 *
 	 * @return True is this dialect supports specifying lock timeouts.
 	 */
 	public boolean supportsLockTimeouts() {
 		return true;
 
 	}
 
 	/**
 	 * If this dialect supports specifying lock timeouts, are those timeouts
 	 * rendered into the <tt>SQL</tt> string as parameters.  The implication
 	 * is that Hibernate will need to bind the timeout value as a parameter
 	 * in the {@link java.sql.PreparedStatement}.  If true, the param position
 	 * is always handled as the last parameter; if the dialect specifies the
 	 * lock timeout elsewhere in the <tt>SQL</tt> statement then the timeout
 	 * value should be directly rendered into the statement and this method
 	 * should return false.
 	 *
 	 * @return True if the lock timeout is rendered into the <tt>SQL</tt>
 	 * string as a parameter; false otherwise.
 	 */
 	public boolean isLockTimeoutParameterized() {
 		return false;
 	}
 
 	/**
 	 * Get a strategy instance which knows how to acquire a database-level lock
 	 * of the specified mode for this dialect.
 	 *
 	 * @param lockable The persister for the entity to be locked.
 	 * @param lockMode The type of lock to be acquired.
 	 * @return The appropriate locking strategy.
 	 * @since 3.2
 	 */
 	public LockingStrategy getLockingStrategy(Lockable lockable, LockMode lockMode) {
 		switch ( lockMode ) {
 			case PESSIMISTIC_FORCE_INCREMENT:
 				return new PessimisticForceIncrementLockingStrategy( lockable, lockMode );
 			case PESSIMISTIC_WRITE:
 				return new PessimisticWriteSelectLockingStrategy( lockable, lockMode );
 			case PESSIMISTIC_READ:
 				return new PessimisticReadSelectLockingStrategy( lockable, lockMode );
 			case OPTIMISTIC:
 				return new OptimisticLockingStrategy( lockable, lockMode );
 			case OPTIMISTIC_FORCE_INCREMENT:
 				return new OptimisticForceIncrementLockingStrategy( lockable, lockMode );
 			default:
 				return new SelectLockingStrategy( lockable, lockMode );
 		}
 	}
 
 	/**
 	 * Given LockOptions (lockMode, timeout), determine the appropriate for update fragment to use.
 	 *
 	 * @param lockOptions contains the lock mode to apply.
 	 * @return The appropriate for update fragment.
 	 */
 	public String getForUpdateString(LockOptions lockOptions) {
 		final LockMode lockMode = lockOptions.getLockMode();
 		return getForUpdateString( lockMode, lockOptions.getTimeOut() );
 	}
 
 	@SuppressWarnings( {"deprecation"})
 	private String getForUpdateString(LockMode lockMode, int timeout){
 		switch ( lockMode ) {
 			case UPGRADE:
 				return getForUpdateString();
 			case PESSIMISTIC_READ:
 				return getReadLockString( timeout );
 			case PESSIMISTIC_WRITE:
 				return getWriteLockString( timeout );
 			case UPGRADE_NOWAIT:
 			case FORCE:
 			case PESSIMISTIC_FORCE_INCREMENT:
 				return getForUpdateNowaitString();
 			case UPGRADE_SKIPLOCKED:
 				return getForUpdateSkipLockedString();
 			default:
 				return "";
 		}
 	}
 
 	/**
 	 * Given a lock mode, determine the appropriate for update fragment to use.
 	 *
 	 * @param lockMode The lock mode to apply.
 	 * @return The appropriate for update fragment.
 	 */
 	public String getForUpdateString(LockMode lockMode) {
 		return getForUpdateString( lockMode, LockOptions.WAIT_FOREVER );
 	}
 
 	/**
 	 * Get the string to append to SELECT statements to acquire locks
 	 * for this dialect.
 	 *
 	 * @return The appropriate <tt>FOR UPDATE</tt> clause string.
 	 */
 	public String getForUpdateString() {
 		return " for update";
 	}
 
 	/**
 	 * Get the string to append to SELECT statements to acquire WRITE locks
 	 * for this dialect.  Location of the of the returned string is treated
 	 * the same as getForUpdateString.
 	 *
 	 * @param timeout in milliseconds, -1 for indefinite wait and 0 for no wait.
 	 * @return The appropriate <tt>LOCK</tt> clause string.
 	 */
 	public String getWriteLockString(int timeout) {
 		return getForUpdateString();
 	}
 
 	/**
 	 * Get the string to append to SELECT statements to acquire WRITE locks
 	 * for this dialect.  Location of the of the returned string is treated
 	 * the same as getForUpdateString.
 	 *
 	 * @param timeout in milliseconds, -1 for indefinite wait and 0 for no wait.
 	 * @return The appropriate <tt>LOCK</tt> clause string.
 	 */
 	public String getReadLockString(int timeout) {
 		return getForUpdateString();
 	}
 
 
 	/**
 	 * Is <tt>FOR UPDATE OF</tt> syntax supported?
 	 *
 	 * @return True if the database supports <tt>FOR UPDATE OF</tt> syntax;
 	 * false otherwise.
 	 */
 	public boolean forUpdateOfColumns() {
 		// by default we report no support
 		return false;
 	}
 
 	/**
 	 * Does this dialect support <tt>FOR UPDATE</tt> in conjunction with
 	 * outer joined rows?
 	 *
 	 * @return True if outer joined rows can be locked via <tt>FOR UPDATE</tt>.
 	 */
 	public boolean supportsOuterJoinForUpdate() {
 		return true;
 	}
 
 	/**
 	 * Get the <tt>FOR UPDATE OF column_list</tt> fragment appropriate for this
 	 * dialect given the aliases of the columns to be write locked.
 	 *
 	 * @param aliases The columns to be write locked.
 	 * @return The appropriate <tt>FOR UPDATE OF column_list</tt> clause string.
 	 */
 	public String getForUpdateString(String aliases) {
 		// by default we simply return the getForUpdateString() result since
 		// the default is to say no support for "FOR UPDATE OF ..."
 		return getForUpdateString();
 	}
 
 	/**
 	 * Get the <tt>FOR UPDATE OF column_list</tt> fragment appropriate for this
 	 * dialect given the aliases of the columns to be write locked.
 	 *
 	 * @param aliases The columns to be write locked.
 	 * @param lockOptions the lock options to apply
 	 * @return The appropriate <tt>FOR UPDATE OF column_list</tt> clause string.
 	 */
 	@SuppressWarnings({"unchecked", "UnusedParameters"})
 	public String getForUpdateString(String aliases, LockOptions lockOptions) {
 		LockMode lockMode = lockOptions.getLockMode();
 		final Iterator<Map.Entry<String, LockMode>> itr = lockOptions.getAliasLockIterator();
 		while ( itr.hasNext() ) {
 			// seek the highest lock mode
 			final Map.Entry<String, LockMode>entry = itr.next();
 			final LockMode lm = entry.getValue();
 			if ( lm.greaterThan( lockMode ) ) {
 				lockMode = lm;
 			}
 		}
 		lockOptions.setLockMode( lockMode );
 		return getForUpdateString( lockOptions );
 	}
 
 	/**
 	 * Retrieves the <tt>FOR UPDATE NOWAIT</tt> syntax specific to this dialect.
 	 *
 	 * @return The appropriate <tt>FOR UPDATE NOWAIT</tt> clause string.
 	 */
 	public String getForUpdateNowaitString() {
 		// by default we report no support for NOWAIT lock semantics
 		return getForUpdateString();
 	}
 
 	/**
 	 * Retrieves the <tt>FOR UPDATE SKIP LOCKED</tt> syntax specific to this dialect.
 	 *
 	 * @return The appropriate <tt>FOR UPDATE SKIP LOCKED</tt> clause string.
 	 */
 	public String getForUpdateSkipLockedString() {
 		// by default we report no support for SKIP_LOCKED lock semantics
 		return getForUpdateString();
 	}
 
 	/**
 	 * Get the <tt>FOR UPDATE OF column_list NOWAIT</tt> fragment appropriate
 	 * for this dialect given the aliases of the columns to be write locked.
 	 *
 	 * @param aliases The columns to be write locked.
 	 * @return The appropriate <tt>FOR UPDATE OF colunm_list NOWAIT</tt> clause string.
 	 */
 	public String getForUpdateNowaitString(String aliases) {
 		return getForUpdateString( aliases );
 	}
 
 	/**
 	 * Get the <tt>FOR UPDATE OF column_list SKIP LOCKED</tt> fragment appropriate
 	 * for this dialect given the aliases of the columns to be write locked.
 	 *
 	 * @param aliases The columns to be write locked.
 	 * @return The appropriate <tt>FOR UPDATE colunm_list SKIP LOCKED</tt> clause string.
 	 */
 	public String getForUpdateSkipLockedString(String aliases) {
 		return getForUpdateString( aliases );
 	}
 
 	/**
 	 * Some dialects support an alternative means to <tt>SELECT FOR UPDATE</tt>,
 	 * whereby a "lock hint" is appends to the table name in the from clause.
 	 * <p/>
 	 * contributed by <a href="http://sourceforge.net/users/heschulz">Helge Schulz</a>
 	 *
 	 * @param mode The lock mode to apply
 	 * @param tableName The name of the table to which to apply the lock hint.
 	 * @return The table with any required lock hints.
 	 * @deprecated use {@code appendLockHint(LockOptions,String)} instead
 	 */
 	@Deprecated
 	public String appendLockHint(LockMode mode, String tableName) {
 		return appendLockHint( new LockOptions( mode ), tableName );
 	}
 	/**
 	 * Some dialects support an alternative means to <tt>SELECT FOR UPDATE</tt>,
 	 * whereby a "lock hint" is appends to the table name in the from clause.
 	 * <p/>
 	 * contributed by <a href="http://sourceforge.net/users/heschulz">Helge Schulz</a>
 	 *
 	 * @param lockOptions The lock options to apply
 	 * @param tableName The name of the table to which to apply the lock hint.
 	 * @return The table with any required lock hints.
 	 */
 	public String appendLockHint(LockOptions lockOptions, String tableName){
 		return tableName;
 	}
 
 	/**
 	 * Modifies the given SQL by applying the appropriate updates for the specified
 	 * lock modes and key columns.
 	 * <p/>
 	 * The behavior here is that of an ANSI SQL <tt>SELECT FOR UPDATE</tt>.  This
 	 * method is really intended to allow dialects which do not support
 	 * <tt>SELECT FOR UPDATE</tt> to achieve this in their own fashion.
 	 *
 	 * @param sql the SQL string to modify
 	 * @param aliasedLockOptions lock options indexed by aliased table names.
 	 * @param keyColumnNames a map of key columns indexed by aliased table names.
 	 * @return the modified SQL string.
 	 */
 	public String applyLocksToSql(String sql, LockOptions aliasedLockOptions, Map<String, String[]> keyColumnNames) {
 		return sql + new ForUpdateFragment( this, aliasedLockOptions, keyColumnNames ).toFragmentString();
 	}
 
 
 	// table support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Command used to create a table.
 	 *
 	 * @return The command used to create a table.
 	 */
 	public String getCreateTableString() {
 		return "create table";
 	}
 
 	/**
 	 * Slight variation on {@link #getCreateTableString}.  Here, we have the
 	 * command used to create a table when there is no primary key and
 	 * duplicate rows are expected.
 	 * <p/>
 	 * Most databases do not care about the distinction; originally added for
 	 * Teradata support which does care.
 	 *
 	 * @return The command used to create a multiset table.
 	 */
 	public String getCreateMultisetTableString() {
 		return getCreateTableString();
 	}
 
 
 	// temporary table support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Does this dialect support temporary tables?
 	 *
 	 * @return True if temp tables are supported; false otherwise.
 	 */
 	public boolean supportsTemporaryTables() {
 		return false;
 	}
 
 	/**
 	 * Generate a temporary table name given the base table.
 	 *
 	 * @param baseTableName The table name from which to base the temp table name.
 	 * @return The generated temp table name.
 	 */
 	public String generateTemporaryTableName(String baseTableName) {
 		return "HT_" + baseTableName;
 	}
 
 	/**
 	 * Command used to create a temporary table.
 	 *
 	 * @return The command used to create a temporary table.
 	 */
 	public String getCreateTemporaryTableString() {
 		return "create table";
 	}
 
 	/**
 	 * Get any fragments needing to be postfixed to the command for
 	 * temporary table creation.
 	 *
 	 * @return Any required postfix.
 	 */
 	public String getCreateTemporaryTablePostfix() {
 		return "";
 	}
 
 	/**
 	 * Command used to drop a temporary table.
 	 *
 	 * @return The command used to drop a temporary table.
 	 */
 	public String getDropTemporaryTableString() {
 		return "drop table";
 	}
 
 	/**
 	 * Does the dialect require that temporary table DDL statements occur in
 	 * isolation from other statements?  This would be the case if the creation
 	 * would cause any current transaction to get committed implicitly.
 	 * <p/>
 	 * JDBC defines a standard way to query for this information via the
 	 * {@link java.sql.DatabaseMetaData#dataDefinitionCausesTransactionCommit()}
 	 * method.  However, that does not distinguish between temporary table
 	 * DDL and other forms of DDL; MySQL, for example, reports DDL causing a
 	 * transaction commit via its driver, even though that is not the case for
 	 * temporary table DDL.
 	 * <p/>
 	 * Possible return values and their meanings:<ul>
 	 * <li>{@link Boolean#TRUE} - Unequivocally, perform the temporary table DDL
 	 * in isolation.</li>
 	 * <li>{@link Boolean#FALSE} - Unequivocally, do <b>not</b> perform the
 	 * temporary table DDL in isolation.</li>
 	 * <li><i>null</i> - defer to the JDBC driver response in regards to
 	 * {@link java.sql.DatabaseMetaData#dataDefinitionCausesTransactionCommit()}</li>
 	 * </ul>
 	 *
 	 * @return see the result matrix above.
 	 */
 	public Boolean performTemporaryTableDDLInIsolation() {
 		return null;
 	}
 
 	/**
 	 * Do we need to drop the temporary table after use?
 	 *
 	 * @return True if the table should be dropped.
 	 */
 	public boolean dropTemporaryTableAfterUse() {
 		return true;
 	}
 
 
 	// callable statement support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Registers a parameter (either OUT, or the new REF_CURSOR param type available in Java 8) capable of
 	 * returning {@link java.sql.ResultSet} *by position*.  Pre-Java 8, registering such ResultSet-returning
 	 * parameters varied greatly across database and drivers; hence its inclusion as part of the Dialect contract.
 	 *
 	 * @param statement The callable statement.
 	 * @param position The bind position at which to register the output param.
 	 *
 	 * @return The number of (contiguous) bind positions used.
 	 *
 	 * @throws SQLException Indicates problems registering the param.
 	 */
 	public int registerResultSetOutParameter(CallableStatement statement, int position) throws SQLException {
 		throw new UnsupportedOperationException(
 				getClass().getName() +
 						" does not support resultsets via stored procedures"
 		);
 	}
 
 	/**
 	 * Registers a parameter (either OUT, or the new REF_CURSOR param type available in Java 8) capable of
 	 * returning {@link java.sql.ResultSet} *by name*.  Pre-Java 8, registering such ResultSet-returning
 	 * parameters varied greatly across database and drivers; hence its inclusion as part of the Dialect contract.
 	 *
 	 * @param statement The callable statement.
 	 * @param name The parameter name (for drivers which support named parameters).
 	 *
 	 * @return The number of (contiguous) bind positions used.
 	 *
 	 * @throws SQLException Indicates problems registering the param.
 	 */
 	@SuppressWarnings("UnusedParameters")
 	public int registerResultSetOutParameter(CallableStatement statement, String name) throws SQLException {
 		throw new UnsupportedOperationException(
 				getClass().getName() +
 						" does not support resultsets via stored procedures"
 		);
 	}
 
 	/**
 	 * Given a callable statement previously processed by {@link #registerResultSetOutParameter},
 	 * extract the {@link java.sql.ResultSet} from the OUT parameter.
 	 *
 	 * @param statement The callable statement.
 	 * @return The extracted result set.
 	 * @throws SQLException Indicates problems extracting the result set.
 	 */
 	public ResultSet getResultSet(CallableStatement statement) throws SQLException {
 		throw new UnsupportedOperationException(
 				getClass().getName() + " does not support resultsets via stored procedures"
 		);
 	}
 
 	/**
 	 * Given a callable statement previously processed by {@link #registerResultSetOutParameter},
 	 * extract the {@link java.sql.ResultSet}.
 	 *
 	 * @param statement The callable statement.
 	 * @param position The bind position at which to register the output param.
 	 *
 	 * @return The extracted result set.
 	 *
 	 * @throws SQLException Indicates problems extracting the result set.
 	 */
 	@SuppressWarnings("UnusedParameters")
 	public ResultSet getResultSet(CallableStatement statement, int position) throws SQLException {
 		throw new UnsupportedOperationException(
 				getClass().getName() + " does not support resultsets via stored procedures"
 		);
 	}
 
 	/**
 	 * Given a callable statement previously processed by {@link #registerResultSetOutParameter},
 	 * extract the {@link java.sql.ResultSet} from the OUT parameter.
 	 *
 	 * @param statement The callable statement.
 	 * @param name The parameter name (for drivers which support named parameters).
 	 *
 	 * @return The extracted result set.
 	 *
 	 * @throws SQLException Indicates problems extracting the result set.
 	 */
 	@SuppressWarnings("UnusedParameters")
 	public ResultSet getResultSet(CallableStatement statement, String name) throws SQLException {
 		throw new UnsupportedOperationException(
 				getClass().getName() + " does not support resultsets via stored procedures"
 		);
 	}
 
 	// current timestamp support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Does this dialect support a way to retrieve the database's current
 	 * timestamp value?
 	 *
 	 * @return True if the current timestamp can be retrieved; false otherwise.
 	 */
 	public boolean supportsCurrentTimestampSelection() {
 		return false;
 	}
 
 	/**
 	 * Should the value returned by {@link #getCurrentTimestampSelectString}
 	 * be treated as callable.  Typically this indicates that JDBC escape
 	 * syntax is being used...
 	 *
 	 * @return True if the {@link #getCurrentTimestampSelectString} return
 	 * is callable; false otherwise.
 	 */
 	public boolean isCurrentTimestampSelectStringCallable() {
 		throw new UnsupportedOperationException( "Database not known to define a current timestamp function" );
 	}
 
 	/**
 	 * Retrieve the command used to retrieve the current timestamp from the
 	 * database.
 	 *
 	 * @return The command.
 	 */
 	public String getCurrentTimestampSelectString() {
 		throw new UnsupportedOperationException( "Database not known to define a current timestamp function" );
 	}
 
 	/**
 	 * The name of the database-specific SQL function for retrieving the
 	 * current timestamp.
 	 *
 	 * @return The function name.
 	 */
 	public String getCurrentTimestampSQLFunctionName() {
 		// the standard SQL function name is current_timestamp...
 		return "current_timestamp";
 	}
 
 
 	// SQLException support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Build an instance of the SQLExceptionConverter preferred by this dialect for
 	 * converting SQLExceptions into Hibernate's JDBCException hierarchy.
 	 * <p/>
 	 * The preferred method is to not override this method; if possible,
 	 * {@link #buildSQLExceptionConversionDelegate()} should be overridden
 	 * instead.
 	 *
 	 * If this method is not overridden, the default SQLExceptionConverter
 	 * implementation executes 3 SQLException converter delegates:
 	 * <ol>
 	 *     <li>a "static" delegate based on the JDBC 4 defined SQLException hierarchy;</li>
 	 *     <li>the vendor-specific delegate returned by {@link #buildSQLExceptionConversionDelegate()};
 	 *         (it is strongly recommended that specific Dialect implementations
 	 *         override {@link #buildSQLExceptionConversionDelegate()})</li>
 	 *     <li>a delegate that interprets SQLState codes for either X/Open or SQL-2003 codes,
 	 *         depending on java.sql.DatabaseMetaData#getSQLStateType</li>
 	 * </ol>
 	 * <p/>
 	 * If this method is overridden, it is strongly recommended that the
 	 * returned {@link SQLExceptionConverter} interpret SQL errors based on
 	 * vendor-specific error codes rather than the SQLState since the
 	 * interpretation is more accurate when using vendor-specific ErrorCodes.
 	 *
 	 * @return The Dialect's preferred SQLExceptionConverter, or null to
 	 * indicate that the default {@link SQLExceptionConverter} should be used.
 	 *
 	 * @see {@link #buildSQLExceptionConversionDelegate()}
 	 * @deprecated {@link #buildSQLExceptionConversionDelegate()} should be
 	 * overridden instead.
 	 */
 	@Deprecated
 	public SQLExceptionConverter buildSQLExceptionConverter() {
 		return null;
 	}
 
 	/**
 	 * Build an instance of a {@link SQLExceptionConversionDelegate} for
 	 * interpreting dialect-specific error or SQLState codes.
 	 * <p/>
 	 * When {@link #buildSQLExceptionConverter} returns null, the default 
 	 * {@link SQLExceptionConverter} is used to interpret SQLState and
 	 * error codes. If this method is overridden to return a non-null value,
 	 * the default {@link SQLExceptionConverter} will use the returned
 	 * {@link SQLExceptionConversionDelegate} in addition to the following 
 	 * standard delegates:
 	 * <ol>
 	 *     <li>a "static" delegate based on the JDBC 4 defined SQLException hierarchy;</li>
 	 *     <li>a delegate that interprets SQLState codes for either X/Open or SQL-2003 codes,
 	 *         depending on java.sql.DatabaseMetaData#getSQLStateType</li>
 	 * </ol>
 	 * <p/>
 	 * It is strongly recommended that specific Dialect implementations override this
 	 * method, since interpretation of a SQL error is much more accurate when based on
 	 * the a vendor-specific ErrorCode rather than the SQLState.
 	 * <p/>
 	 * Specific Dialects may override to return whatever is most appropriate for that vendor.
 	 *
 	 * @return The SQLExceptionConversionDelegate for this dialect
 	 */
 	public SQLExceptionConversionDelegate buildSQLExceptionConversionDelegate() {
 		return null;
 	}
 
 	private static final ViolatedConstraintNameExtracter EXTRACTER = new ViolatedConstraintNameExtracter() {
 		public String extractConstraintName(SQLException sqle) {
 			return null;
 		}
 	};
 
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 
 	// union subclass support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Given a {@link java.sql.Types} type code, determine an appropriate
 	 * null value to use in a select clause.
 	 * <p/>
 	 * One thing to consider here is that certain databases might
 	 * require proper casting for the nulls here since the select here
 	 * will be part of a UNION/UNION ALL.
 	 *
 	 * @param sqlType The {@link java.sql.Types} type code.
 	 * @return The appropriate select clause value fragment.
 	 */
 	public String getSelectClauseNullString(int sqlType) {
 		return "null";
 	}
 
 	/**
 	 * Does this dialect support UNION ALL, which is generally a faster
 	 * variant of UNION?
 	 *
 	 * @return True if UNION ALL is supported; false otherwise.
 	 */
 	public boolean supportsUnionAll() {
 		return false;
 	}
 
 
 	// miscellaneous support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 
 	/**
 	 * Create a {@link org.hibernate.sql.JoinFragment} strategy responsible
 	 * for handling this dialect's variations in how joins are handled.
 	 *
 	 * @return This dialect's {@link org.hibernate.sql.JoinFragment} strategy.
 	 */
 	public JoinFragment createOuterJoinFragment() {
 		return new ANSIJoinFragment();
 	}
 
 	/**
 	 * Create a {@link org.hibernate.sql.CaseFragment} strategy responsible
 	 * for handling this dialect's variations in how CASE statements are
 	 * handled.
 	 *
 	 * @return This dialect's {@link org.hibernate.sql.CaseFragment} strategy.
 	 */
 	public CaseFragment createCaseFragment() {
 		return new ANSICaseFragment();
 	}
 
 	/**
 	 * The fragment used to insert a row without specifying any column values.
 	 * This is not possible on some databases.
 	 *
 	 * @return The appropriate empty values clause.
 	 */
 	public String getNoColumnsInsertString() {
 		return "values ( )";
 	}
 
 	/**
 	 * The name of the SQL function that transforms a string to
 	 * lowercase
 	 *
 	 * @return The dialect-specific lowercase function.
 	 */
 	public String getLowercaseFunction() {
 		return "lower";
 	}
 
 	/**
 	 * The name of the SQL function that can do case insensitive <b>like</b> comparison.
 	 *
 	 * @return  The dialect-specific "case insensitive" like function.
 	 */
 	public String getCaseInsensitiveLike(){
 		return "like";
 	}
 
 	/**
 	 * Does this dialect support case insensitive LIKE restrictions?
 	 *
 	 * @return {@code true} if the underlying database supports case insensitive like comparison,
 	 * {@code false} otherwise.  The default is {@code false}.
 	 */
 	public boolean supportsCaseInsensitiveLike(){
 		return false;
 	}
 
 	/**
 	 * Meant as a means for end users to affect the select strings being sent
 	 * to the database and perhaps manipulate them in some fashion.
 	 * <p/>
 	 * The recommend approach is to instead use
 	 * {@link org.hibernate.Interceptor#onPrepareStatement(String)}.
 	 *
 	 * @param select The select command
 	 * @return The mutated select command, or the same as was passed in.
 	 */
 	public String transformSelectString(String select) {
 		return select;
 	}
 
 	/**
 	 * What is the maximum length Hibernate can use for generated aliases?
 	 * <p/>
 	 * The maximum here should account for the fact that Hibernate often needs to append "uniqueing" information
 	 * to the end of generated aliases.  That "uniqueing" information will be added to the end of a identifier
 	 * generated to the length specified here; so be sure to leave some room (generally speaking 5 positions will
 	 * suffice).
 	 *
 	 * @return The maximum length.
 	 */
 	public int getMaxAliasLength() {
 		return 10;
 	}
 
 	/**
 	 * The SQL literal value to which this database maps boolean values.
 	 *
 	 * @param bool The boolean value
 	 * @return The appropriate SQL literal.
 	 */
 	public String toBooleanValueString(boolean bool) {
 		return bool ? "1" : "0";
 	}
 
 
 	// identifier quoting support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * The character specific to this dialect used to begin a quoted identifier.
 	 *
 	 * @return The dialect's specific open quote character.
 	 */
 	public char openQuote() {
 		return '"';
 	}
 
 	/**
 	 * The character specific to this dialect used to close a quoted identifier.
 	 *
 	 * @return The dialect's specific close quote character.
 	 */
 	public char closeQuote() {
 		return '"';
 	}
 
 	/**
 	 * Apply dialect-specific quoting.
 	 * <p/>
 	 * By default, the incoming value is checked to see if its first character
 	 * is the back-tick (`).  If so, the dialect specific quoting is applied.
 	 *
 	 * @param name The value to be quoted.
 	 * @return The quoted (or unmodified, if not starting with back-tick) value.
 	 * @see #openQuote()
 	 * @see #closeQuote()
 	 */
 	public final String quote(String name) {
 		if ( name == null ) {
 			return null;
 		}
 
 		if ( name.charAt( 0 ) == '`' ) {
 			return openQuote() + name.substring( 1, name.length() - 1 ) + closeQuote();
 		}
 		else {
 			return name;
 		}
 	}
 
 
 	// DDL support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private StandardTableExporter tableExporter = new StandardTableExporter( this );
 	private StandardSequenceExporter sequenceExporter = new StandardSequenceExporter( this );
 	private StandardIndexExporter indexExporter = new StandardIndexExporter( this );
 	private StandardForeignKeyExporter foreignKeyExporter = new StandardForeignKeyExporter( this );
 	private StandardUniqueKeyExporter uniqueKeyExporter = new StandardUniqueKeyExporter( this );
 	private StandardAuxiliaryDatabaseObjectExporter auxiliaryObjectExporter = new StandardAuxiliaryDatabaseObjectExporter( this );
 	private TemporaryTableExporter temporaryTableExporter = new TemporaryTableExporter( this );
 
 	public Exporter<Table> getTableExporter() {
 		return tableExporter;
 	}
 
 	public Exporter<Table> getTemporaryTableExporter() {
 		return temporaryTableExporter;
 	}
 
 	public Exporter<Sequence> getSequenceExporter() {
 		return sequenceExporter;
 	}
 
 	public Exporter<Index> getIndexExporter() {
 		return indexExporter;
 	}
 
 	public Exporter<ForeignKey> getForeignKeyExporter() {
 		return foreignKeyExporter;
 	}
 
 	public Exporter<Constraint> getUniqueKeyExporter() {
 		return uniqueKeyExporter;
 	}
 
 	public Exporter<AuxiliaryDatabaseObject> getAuxiliaryDatabaseObjectExporter() {
 		return auxiliaryObjectExporter;
 	}
 
 	/**
 	 * Get the SQL command used to create the named schema
 	 *
 	 * @param schemaName The name of the schema to be created.
 	 *
 	 * @return The creation command
 	 */
 	public String getCreateSchemaCommand(String schemaName) {
 		return "create schema " + schemaName;
 	}
 
 	/**
 	 * Get the SQL command used to drop the named schema
 	 *
 	 * @param schemaName The name of the schema to be dropped.
 	 *
 	 * @return The drop command
 	 */
 	public String getDropSchemaCommand(String schemaName) {
 		return "drop schema " + schemaName;
 	}
 
 	/**
 	 * Get the SQL command used to retrieve the current schema name.  Works in conjunction
 	 * with {@link #getSchemaNameResolver()}, unless the return from there does not need this
 	 * information.  E.g., a custom impl might make use of the Java 1.7 addition of
 	 * the {@link java.sql.Connection#getSchema()} method
 	 *
 	 * @return The current schema retrieval SQL
 	 */
 	public String getCurrentSchemaCommand() {
 		return null;
 	}
 
 	/**
 	 * Get the strategy for determining the schema name of a Connection
 	 *
 	 * @return The schema name resolver strategy
 	 */
 	public SchemaNameResolver getSchemaNameResolver() {
 		return DefaultSchemaNameResolver.INSTANCE;
 	}
 
 	/**
 	 * Does this dialect support the <tt>ALTER TABLE</tt> syntax?
 	 *
 	 * @return True if we support altering of tables; false otherwise.
 	 */
 	public boolean hasAlterTable() {
 		return true;
 	}
 
 	/**
 	 * Do we need to drop constraints before dropping tables in this dialect?
 	 *
 	 * @return True if constraints must be dropped prior to dropping
 	 * the table; false otherwise.
 	 */
 	public boolean dropConstraints() {
 		return true;
 	}
 
 	/**
 	 * Do we need to qualify index names with the schema name?
 	 *
 	 * @return boolean
 	 */
 	public boolean qualifyIndexName() {
 		return true;
 	}
 
 	/**
 	 * The syntax used to add a column to a table (optional).
 	 *
 	 * @return The "add column" fragment.
 	 */
 	public String getAddColumnString() {
 		throw new UnsupportedOperationException( "No add column syntax supported by " + getClass().getName() );
 	}
 
 	/**
 	 * The syntax for the suffix used to add a column to a table (optional).
 	 *
 	 * @return The suffix "add column" fragment.
 	 */
 	public String getAddColumnSuffixString() {
 		return "";
 	}
 
 	public String getDropForeignKeyString() {
 		return " drop constraint ";
 	}
 
 	public String getTableTypeString() {
 		// grrr... for differentiation of mysql storage engines
 		return "";
 	}
 
 	/**
 	 * The syntax used to add a foreign key constraint to a table.
 	 *
 	 * @param constraintName The FK constraint name.
 	 * @param foreignKey The names of the columns comprising the FK
 	 * @param referencedTable The table referenced by the FK
 	 * @param primaryKey The explicit columns in the referencedTable referenced
 	 * by this FK.
 	 * @param referencesPrimaryKey if false, constraint should be
 	 * explicit about which column names the constraint refers to
 	 *
 	 * @return the "add FK" fragment
 	 */
 	public String getAddForeignKeyConstraintString(
 			String constraintName,
 			String[] foreignKey,
 			String referencedTable,
 			String[] primaryKey,
 			boolean referencesPrimaryKey) {
 		final StringBuilder res = new StringBuilder( 30 );
 
 		res.append( " add constraint " )
 				.append( quote( constraintName ) )
 				.append( " foreign key (" )
 				.append( StringHelper.join( ", ", foreignKey ) )
 				.append( ") references " )
 				.append( referencedTable );
 
 		if ( !referencesPrimaryKey ) {
 			res.append( " (" )
 					.append( StringHelper.join( ", ", primaryKey ) )
 					.append( ')' );
 		}
 
 		return res.toString();
 	}
 
 	/**
 	 * The syntax used to add a primary key constraint to a table.
 	 *
 	 * @param constraintName The name of the PK constraint.
 	 * @return The "add PK" fragment
 	 */
 	public String getAddPrimaryKeyConstraintString(String constraintName) {
 		return " add constraint " + constraintName + " primary key ";
 	}
 
 	/**
 	 * Does the database/driver have bug in deleting rows that refer to other rows being deleted in the same query?
 	 *
 	 * @return {@code true} if the database/driver has this bug
 	 */
 	public boolean hasSelfReferentialForeignKeyBug() {
 		return false;
 	}
 
 	/**
 	 * The keyword used to specify a nullable column.
 	 *
 	 * @return String
 	 */
 	public String getNullColumnString() {
 		return "";
 	}
 
 	/**
 	 * Does this dialect/database support commenting on tables, columns, etc?
 	 *
 	 * @return {@code true} if commenting is supported
 	 */
 	public boolean supportsCommentOn() {
 		return false;
 	}
 
 	/**
 	 * Get the comment into a form supported for table definition.
 	 *
 	 * @param comment The comment to apply
 	 *
 	 * @return The comment fragment
 	 */
 	public String getTableComment(String comment) {
 		return "";
 	}
 
 	/**
 	 * Get the comment into a form supported for column definition.
 	 *
 	 * @param comment The comment to apply
 	 *
 	 * @return The comment fragment
 	 */
 	public String getColumnComment(String comment) {
 		return "";
 	}
 
 	/**
 	 * For dropping a table, can the phrase "if exists" be applied before the table name?
 	 * <p/>
 	 * NOTE : Only one or the other (or neither) of this and {@link #supportsIfExistsAfterTableName} should return true
 	 *
 	 * @return {@code true} if the "if exists" can be applied before the table name
 	 */
 	public boolean supportsIfExistsBeforeTableName() {
 		return false;
 	}
 
 	/**
 	 * For dropping a table, can the phrase "if exists" be applied after the table name?
 	 * <p/>
 	 * NOTE : Only one or the other (or neither) of this and {@link #supportsIfExistsBeforeTableName} should return true
 	 *
 	 * @return {@code true} if the "if exists" can be applied after the table name
 	 */
 	public boolean supportsIfExistsAfterTableName() {
 		return false;
 	}
 
 	/**
 	 * For dropping a constraint with an "alter table", can the phrase "if exists" be applied before the constraint name?
 	 * <p/>
 	 * NOTE : Only one or the other (or neither) of this and {@link #supportsIfExistsAfterConstraintName} should return true
 	 *
 	 * @return {@code true} if the "if exists" can be applied before the constraint name
 	 */
 	public boolean supportsIfExistsBeforeConstraintName() {
 		return false;
 	}
 
 	/**
 	 * For dropping a constraint with an "alter table", can the phrase "if exists" be applied after the constraint name?
 	 * <p/>
 	 * NOTE : Only one or the other (or neither) of this and {@link #supportsIfExistsBeforeConstraintName} should return true
 	 *
 	 * @return {@code true} if the "if exists" can be applied after the constraint name
 	 */
 	public boolean supportsIfExistsAfterConstraintName() {
 		return false;
 	}
 
 	/**
 	 * Generate a DROP TABLE statement
 	 *
 	 * @param tableName The name of the table to drop
 	 *
 	 * @return The DROP TABLE command
 	 */
 	public String getDropTableString(String tableName) {
 		final StringBuilder buf = new StringBuilder( "drop table " );
 		if ( supportsIfExistsBeforeTableName() ) {
 			buf.append( "if exists " );
 		}
 		buf.append( tableName ).append( getCascadeConstraintsString() );
 		if ( supportsIfExistsAfterTableName() ) {
 			buf.append( " if exists" );
 		}
 		return buf.toString();
 	}
 
 	/**
 	 * Does this dialect support column-level check constraints?
 	 *
 	 * @return True if column-level CHECK constraints are supported; false
 	 * otherwise.
 	 */
 	public boolean supportsColumnCheck() {
 		return true;
 	}
 
 	/**
 	 * Does this dialect support table-level check constraints?
 	 *
 	 * @return True if table-level CHECK constraints are supported; false
 	 * otherwise.
 	 */
 	public boolean supportsTableCheck() {
 		return true;
 	}
 
 	/**
 	 * Does this dialect support cascaded delete on foreign key definitions?
 	 *
 	 * @return {@code true} indicates that the dialect does support cascaded delete on foreign keys.
 	 */
 	public boolean supportsCascadeDelete() {
 		return true;
 	}
 
 	/**
 	 * Completely optional cascading drop clause
 	 *
 	 * @return String
 	 */
 	public String getCascadeConstraintsString() {
 		return "";
 	}
 
 	/**
 	 * Returns the separator to use for defining cross joins when translating HQL queries.
 	 * <p/>
 	 * Typically this will be either [<tt> cross join </tt>] or [<tt>, </tt>]
 	 * <p/>
 	 * Note that the spaces are important!
 	 *
 	 * @return The cross join separator
 	 */
 	public String getCrossJoinSeparator() {
 		return " cross join ";
 	}
 
 	public ColumnAliasExtractor getColumnAliasExtractor() {
 		return ColumnAliasExtractor.COLUMN_LABEL_EXTRACTOR;
 	}
 
 
 	// Informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Does this dialect support empty IN lists?
 	 * <p/>
 	 * For example, is [where XYZ in ()] a supported construct?
 	 *
 	 * @return True if empty in lists are supported; false otherwise.
 	 * @since 3.2
 	 */
 	public boolean supportsEmptyInList() {
 		return true;
 	}
 
 	/**
 	 * Are string comparisons implicitly case insensitive.
 	 * <p/>
 	 * In other words, does [where 'XYZ' = 'xyz'] resolve to true?
 	 *
 	 * @return True if comparisons are case insensitive.
 	 * @since 3.2
 	 */
 	public boolean areStringComparisonsCaseInsensitive() {
 		return false;
 	}
 
 	/**
 	 * Is this dialect known to support what ANSI-SQL terms "row value
 	 * constructor" syntax; sometimes called tuple syntax.
 	 * <p/>
 	 * Basically, does it support syntax like
 	 * "... where (FIRST_NAME, LAST_NAME) = ('Steve', 'Ebersole') ...".
 	 *
 	 * @return True if this SQL dialect is known to support "row value
 	 * constructor" syntax; false otherwise.
 	 * @since 3.2
 	 */
 	public boolean supportsRowValueConstructorSyntax() {
 		// return false here, as most databases do not properly support this construct...
 		return false;
 	}
 
 	/**
 	 * If the dialect supports {@link #supportsRowValueConstructorSyntax() row values},
 	 * does it offer such support in IN lists as well?
 	 * <p/>
 	 * For example, "... where (FIRST_NAME, LAST_NAME) IN ( (?, ?), (?, ?) ) ..."
 	 *
 	 * @return True if this SQL dialect is known to support "row value
 	 * constructor" syntax in the IN list; false otherwise.
 	 * @since 3.2
 	 */
 	public boolean supportsRowValueConstructorSyntaxInInList() {
 		return false;
 	}
 
 	/**
 	 * Should LOBs (both BLOB and CLOB) be bound using stream operations (i.e.
 	 * {@link java.sql.PreparedStatement#setBinaryStream}).
 	 *
 	 * @return True if BLOBs and CLOBs should be bound using stream operations.
 	 * @since 3.2
 	 */
 	public boolean useInputStreamToInsertBlob() {
 		return true;
 	}
 
 	/**
 	 * Does this dialect support parameters within the <tt>SELECT</tt> clause of
 	 * <tt>INSERT ... SELECT ...</tt> statements?
 	 *
 	 * @return True if this is supported; false otherwise.
 	 * @since 3.2
 	 */
 	public boolean supportsParametersInInsertSelect() {
 		return true;
 	}
 
 	/**
 	 * Does this dialect require that references to result variables
 	 * (i.e, select expresssion aliases) in an ORDER BY clause be
 	 * replaced by column positions (1-origin) as defined
 	 * by the select clause?
 
 	 * @return true if result variable references in the ORDER BY
 	 *              clause should be replaced by column positions;
 	 *         false otherwise.
 	 */
 	public boolean replaceResultVariableInOrderByClauseWithPosition() {
 		return false;
 	}
 
 	/**
 	 * Renders an ordering fragment
 	 *
 	 * @param expression The SQL order expression. In case of {@code @OrderBy} annotation user receives property placeholder
 	 * (e.g. attribute name enclosed in '{' and '}' signs).
 	 * @param collation Collation string in format {@code collate IDENTIFIER}, or {@code null}
 	 * if expression has not been explicitly specified.
 	 * @param order Order direction. Possible values: {@code asc}, {@code desc}, or {@code null}
 	 * if expression has not been explicitly specified.
 	 * @param nulls Nulls precedence. Default value: {@link NullPrecedence#NONE}.
 	 * @return Renders single element of {@code ORDER BY} clause.
 	 */
 	public String renderOrderByElement(String expression, String collation, String order, NullPrecedence nulls) {
 		final StringBuilder orderByElement = new StringBuilder( expression );
 		if ( collation != null ) {
 			orderByElement.append( " " ).append( collation );
 		}
 		if ( order != null ) {
 			orderByElement.append( " " ).append( order );
 		}
 		if ( nulls != NullPrecedence.NONE ) {
-			orderByElement.append( " nulls " ).append( nulls.name().toLowerCase() );
+			orderByElement.append( " nulls " ).append( nulls.name().toLowerCase(Locale.ROOT) );
 		}
 		return orderByElement.toString();
 	}
 
 	/**
 	 * Does this dialect require that parameters appearing in the <tt>SELECT</tt> clause be wrapped in <tt>cast()</tt>
 	 * calls to tell the db parser the expected type.
 	 *
 	 * @return True if select clause parameter must be cast()ed
 	 * @since 3.2
 	 */
 	public boolean requiresCastingOfParametersInSelectClause() {
 		return false;
 	}
 
 	/**
 	 * Does this dialect support asking the result set its positioning
 	 * information on forward only cursors.  Specifically, in the case of
 	 * scrolling fetches, Hibernate needs to use
 	 * {@link java.sql.ResultSet#isAfterLast} and
 	 * {@link java.sql.ResultSet#isBeforeFirst}.  Certain drivers do not
 	 * allow access to these methods for forward only cursors.
 	 * <p/>
 	 * NOTE : this is highly driver dependent!
 	 *
 	 * @return True if methods like {@link java.sql.ResultSet#isAfterLast} and
 	 * {@link java.sql.ResultSet#isBeforeFirst} are supported for forward
 	 * only cursors; false otherwise.
 	 * @since 3.2
 	 */
 	public boolean supportsResultSetPositionQueryMethodsOnForwardOnlyCursor() {
 		return true;
 	}
 
 	/**
 	 * Does this dialect support definition of cascade delete constraints
 	 * which can cause circular chains?
 	 *
 	 * @return True if circular cascade delete constraints are supported; false
 	 * otherwise.
 	 * @since 3.2
 	 */
 	public boolean supportsCircularCascadeDeleteConstraints() {
 		return true;
 	}
 
 	/**
 	 * Are subselects supported as the left-hand-side (LHS) of
 	 * IN-predicates.
 	 * <p/>
 	 * In other words, is syntax like "... <subquery> IN (1, 2, 3) ..." supported?
 	 *
 	 * @return True if subselects can appear as the LHS of an in-predicate;
 	 * false otherwise.
 	 * @since 3.2
 	 */
 	public boolean  supportsSubselectAsInPredicateLHS() {
 		return true;
 	}
 
 	/**
 	 * Expected LOB usage pattern is such that I can perform an insert
 	 * via prepared statement with a parameter binding for a LOB value
 	 * without crazy casting to JDBC driver implementation-specific classes...
 	 * <p/>
 	 * Part of the trickiness here is the fact that this is largely
 	 * driver dependent.  For example, Oracle (which is notoriously bad with
 	 * LOB support in their drivers historically) actually does a pretty good
 	 * job with LOB support as of the 10.2.x versions of their drivers...
 	 *
 	 * @return True if normal LOB usage patterns can be used with this driver;
 	 * false if driver-specific hookiness needs to be applied.
 	 * @since 3.2
 	 */
 	public boolean supportsExpectedLobUsagePattern() {
 		return true;
 	}
 
 	/**
 	 * Does the dialect support propagating changes to LOB
 	 * values back to the database?  Talking about mutating the
 	 * internal value of the locator as opposed to supplying a new
 	 * locator instance...
 	 * <p/>
 	 * For BLOBs, the internal value might be changed by:
 	 * {@link java.sql.Blob#setBinaryStream},
 	 * {@link java.sql.Blob#setBytes(long, byte[])},
 	 * {@link java.sql.Blob#setBytes(long, byte[], int, int)},
 	 * or {@link java.sql.Blob#truncate(long)}.
 	 * <p/>
 	 * For CLOBs, the internal value might be changed by:
 	 * {@link java.sql.Clob#setAsciiStream(long)},
 	 * {@link java.sql.Clob#setCharacterStream(long)},
 	 * {@link java.sql.Clob#setString(long, String)},
 	 * {@link java.sql.Clob#setString(long, String, int, int)},
 	 * or {@link java.sql.Clob#truncate(long)}.
 	 * <p/>
 	 * NOTE : I do not know the correct answer currently for
 	 * databases which (1) are not part of the cruise control process
 	 * or (2) do not {@link #supportsExpectedLobUsagePattern}.
 	 *
 	 * @return True if the changes are propagated back to the
 	 * database; false otherwise.
 	 * @since 3.2
 	 */
 	public boolean supportsLobValueChangePropogation() {
 		// todo : pretty sure this is the same as the java.sql.DatabaseMetaData.locatorsUpdateCopy method added in JDBC 4, see HHH-6046
 		return true;
 	}
 
 	/**
 	 * Is it supported to materialize a LOB locator outside the transaction in
 	 * which it was created?
 	 * <p/>
 	 * Again, part of the trickiness here is the fact that this is largely
 	 * driver dependent.
 	 * <p/>
 	 * NOTE: all database I have tested which {@link #supportsExpectedLobUsagePattern()}
 	 * also support the ability to materialize a LOB outside the owning transaction...
 	 *
 	 * @return True if unbounded materialization is supported; false otherwise.
 	 * @since 3.2
 	 */
 	public boolean supportsUnboundedLobLocatorMaterialization() {
 		return true;
 	}
 
 	/**
 	 * Does this dialect support referencing the table being mutated in
 	 * a subquery.  The "table being mutated" is the table referenced in
 	 * an UPDATE or a DELETE query.  And so can that table then be
 	 * referenced in a subquery of said UPDATE/DELETE query.
 	 * <p/>
 	 * For example, would the following two syntaxes be supported:<ul>
 	 * <li>delete from TABLE_A where ID not in ( select ID from TABLE_A )</li>
 	 * <li>update TABLE_A set NON_ID = 'something' where ID in ( select ID from TABLE_A)</li>
 	 * </ul>
 	 *
 	 * @return True if this dialect allows references the mutating table from
 	 * a subquery.
 	 */
 	public boolean supportsSubqueryOnMutatingTable() {
 		return true;
 	}
 
 	/**
 	 * Does the dialect support an exists statement in the select clause?
 	 *
 	 * @return True if exists checks are allowed in the select clause; false otherwise.
 	 */
 	public boolean supportsExistsInSelect() {
 		return true;
 	}
 
 	/**
 	 * For the underlying database, is READ_COMMITTED isolation implemented by
 	 * forcing readers to wait for write locks to be released?
 	 *
 	 * @return True if writers block readers to achieve READ_COMMITTED; false otherwise.
 	 */
 	public boolean doesReadCommittedCauseWritersToBlockReaders() {
 		return false;
 	}
 
 	/**
 	 * For the underlying database, is REPEATABLE_READ isolation implemented by
 	 * forcing writers to wait for read locks to be released?
 	 *
 	 * @return True if readers block writers to achieve REPEATABLE_READ; false otherwise.
 	 */
 	public boolean doesRepeatableReadCauseReadersToBlockWriters() {
 		return false;
 	}
 
 	/**
 	 * Does this dialect support using a JDBC bind parameter as an argument
 	 * to a function or procedure call?
 	 *
 	 * @return Returns {@code true} if the database supports accepting bind params as args, {@code false} otherwise. The
 	 * default is {@code true}.
 	 */
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public boolean supportsBindAsCallableArgument() {
 		return true;
 	}
 
 	/**
 	 * Does this dialect support `count(a,b)`?
 	 *
 	 * @return True if the database supports counting tuples; false otherwise.
 	 */
 	public boolean supportsTupleCounts() {
 		return false;
 	}
 
 	/**
 	 * Does this dialect support `count(distinct a,b)`?
 	 *
 	 * @return True if the database supports counting distinct tuples; false otherwise.
 	 */
 	public boolean supportsTupleDistinctCounts() {
 		// oddly most database in fact seem to, so true is the default.
 		return true;
 	}
 
 	/**
 	 * If {@link #supportsTupleDistinctCounts()} is true, does the Dialect require the tuple to be wrapped with parens?
 	 *
 	 * @return boolean
 	 */
 	public boolean requiresParensForTupleDistinctCounts() {
 		return false;
 	}
 
 	/**
 	 * Return the limit that the underlying database places on the number elements in an {@code IN} predicate.
 	 * If the database defines no such limits, simply return zero or less-than-zero.
 	 *
 	 * @return int The limit, or zero-or-less to indicate no limit.
 	 */
 	public int getInExpressionCountLimit() {
 		return 0;
 	}
 
 	/**
 	 * HHH-4635
 	 * Oracle expects all Lob values to be last in inserts and updates.
 	 *
 	 * @return boolean True of Lob values should be last, false if it
 	 * does not matter.
 	 */
 	public boolean forceLobAsLastValue() {
 		return false;
 	}
 
 	/**
 	 * Some dialects have trouble applying pessimistic locking depending upon what other query options are
 	 * specified (paging, ordering, etc).  This method allows these dialects to request that locking be applied
 	 * by subsequent selects.
 	 *
 	 * @return {@code true} indicates that the dialect requests that locking be applied by subsequent select;
 	 * {@code false} (the default) indicates that locking should be applied to the main SQL statement..
 	 */
 	public boolean useFollowOnLocking() {
 		return false;
 	}
 
 	/**
 	 * Negate an expression
 	 *
 	 * @param expression The expression to negate
 	 *
 	 * @return The negated expression
 	 */
 	public String getNotExpression(String expression) {
 		return "not " + expression;
 	}
 
 	/**
 	 * Get the UniqueDelegate supported by this dialect
 	 *
 	 * @return The UniqueDelegate
 	 */
 	public UniqueDelegate getUniqueDelegate() {
 		return uniqueDelegate;
 	}
 
 	/**
 	 * Does this dialect support the <tt>UNIQUE</tt> column syntax?
 	 *
 	 * @return boolean
 	 *
 	 * @deprecated {@link #getUniqueDelegate()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean supportsUnique() {
 		return true;
 	}
 
 	/**
 	 * Does this dialect support adding Unique constraints via create and alter table ?
 	 *
 	 * @return boolean
 	 *
 	 * @deprecated {@link #getUniqueDelegate()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean supportsUniqueConstraintInCreateAlterTable() {
 		return true;
 	}
 
 	/**
 	 * The syntax used to add a unique constraint to a table.
 	 *
 	 * @param constraintName The name of the unique constraint.
 	 * @return The "add unique" fragment
 	 *
 	 * @deprecated {@link #getUniqueDelegate()} should be overridden instead.
 	 */
 	@Deprecated
 	public String getAddUniqueConstraintString(String constraintName) {
 		return " add constraint " + constraintName + " unique ";
 	}
 
 	/**
 	 * Is the combination of not-null and unique supported?
 	 *
 	 * @return deprecated
 	 *
 	 * @deprecated {@link #getUniqueDelegate()} should be overridden instead.
 	 */
 	@Deprecated
 	public boolean supportsNotNullUnique() {
 		return true;
 	}
 
 	/**
 	 * Apply a hint to the query.  The entire query is provided, allowing the Dialect full control over the placement
 	 * and syntax of the hint.  By default, ignore the hint and simply return the query.
 	 *
 	 * @param query The query to which to apply the hint.
 	 * @param hints The  hints to apply
 	 * @return The modified SQL
 	 */
 	public String getQueryHintString(String query, List<String> hints) {
 		return query;
 	}
 
 	/**
 	 * Certain dialects support a subset of ScrollModes.  Provide a default to be used by Criteria and Query.
 	 *
 	 * @return ScrollMode
 	 */
 	public ScrollMode defaultScrollMode() {
 		return ScrollMode.SCROLL_INSENSITIVE;
 	}
 
 	/**
 	 * Does this dialect support tuples in subqueries?  Ex:
 	 * delete from Table1 where (col1, col2) in (select col1, col2 from Table2)
 	 *
 	 * @return boolean
 	 */
 	public boolean supportsTuplesInSubqueries() {
 		return true;
 	}
 
 	public CallableStatementSupport getCallableStatementSupport() {
 		// most databases do not support returning cursors (ref_cursor)...
 		return StandardCallableStatementSupport.NO_REF_CURSOR_INSTANCE;
 	}
 
 	/**
 	 * By default interpret this based on DatabaseMetaData.
 	 *
 	 * @return
 	 */
 	public NameQualifierSupport getNameQualifierSupport() {
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/HSQLDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/HSQLDialect.java
index d8a9f1019b..693fd1591b 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/HSQLDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/HSQLDialect.java
@@ -1,705 +1,706 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.io.Serializable;
 import java.sql.SQLException;
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.AvgWithArgumentCastFunction;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.dialect.lock.OptimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.OptimisticLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticReadSelectLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticWriteSelectLockingStrategy;
 import org.hibernate.dialect.lock.SelectLockingStrategy;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.exception.spi.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.type.StandardBasicTypes;
 
 import org.jboss.logging.Logger;
 
 /**
  * An SQL dialect compatible with HSQLDB (HyperSQL).
  * <p/>
  * Note this version supports HSQLDB version 1.8 and higher, only.
  * <p/>
  * Enhancements to version 3.5.0 GA to provide basic support for both HSQLDB 1.8.x and 2.x
  * Does not works with Hibernate 3.2 - 3.4 without alteration.
  *
  * @author Christoph Sturm
  * @author Phillip Baird
  * @author Fred Toussi
  */
 @SuppressWarnings("deprecation")
 public class HSQLDialect extends Dialect {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			HSQLDialect.class.getName()
 	);
 
 	private final class HSQLLimitHandler extends AbstractLimitHandler {
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final boolean hasOffset = LimitHelper.hasFirstRow( selection );
 			if (hsqldbVersion < 20) {
 				return new StringBuilder( sql.length() + 10 )
 						.append( sql )
 						.insert(
-								sql.toLowerCase().indexOf( "select" ) + 6,
+								sql.toLowerCase(Locale.ROOT).indexOf( "select" ) + 6,
 								hasOffset ? " limit ? ?" : " top ?"
 						)
 						.toString();
 			}
 			else {
 				return sql + (hasOffset ? " offset ? limit ?" : " limit ?");
 			}
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return true;
 		}
 
 		@Override
 		public boolean bindLimitParametersFirst() {
 			return hsqldbVersion < 20;
 		}
 	}
 
 	/**
 	 * version is 18 for 1.8 or 20 for 2.0
 	 */
 	private int hsqldbVersion = 18;
 	private final LimitHandler limitHandler;
 
 
 	/**
 	 * Constructs a HSQLDialect
 	 */
 	public HSQLDialect() {
 		super();
 
 		try {
 			final Class props = ReflectHelper.classForName( "org.hsqldb.persist.HsqlDatabaseProperties" );
 			final String versionString = (String) props.getDeclaredField( "THIS_VERSION" ).get( null );
 
 			hsqldbVersion = Integer.parseInt( versionString.substring( 0, 1 ) ) * 10;
 			hsqldbVersion += Integer.parseInt( versionString.substring( 2, 3 ) );
 		}
 		catch ( Throwable e ) {
 			// must be a very old version
 		}
 
 		registerColumnType( Types.BIGINT, "bigint" );
 		registerColumnType( Types.BINARY, "binary($l)" );
 		registerColumnType( Types.BIT, "bit" );
 		registerColumnType( Types.BOOLEAN, "boolean" );
 		registerColumnType( Types.CHAR, "char($l)" );
 		registerColumnType( Types.DATE, "date" );
 
 		registerColumnType( Types.DECIMAL, "decimal($p,$s)" );
 		registerColumnType( Types.DOUBLE, "double" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.INTEGER, "integer" );
 		registerColumnType( Types.LONGVARBINARY, "longvarbinary" );
 		registerColumnType( Types.LONGVARCHAR, "longvarchar" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.TINYINT, "tinyint" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.VARBINARY, "varbinary($l)" );
 
 		if ( hsqldbVersion < 20 ) {
 			registerColumnType( Types.NUMERIC, "numeric" );
 		}
 		else {
 			registerColumnType( Types.NUMERIC, "numeric($p,$s)" );
 		}
 
 		//HSQL has no Blob/Clob support .... but just put these here for now!
 		if ( hsqldbVersion < 20 ) {
 			registerColumnType( Types.BLOB, "longvarbinary" );
 			registerColumnType( Types.CLOB, "longvarchar" );
 		}
 		else {
 			registerColumnType( Types.BLOB, "blob($l)" );
 			registerColumnType( Types.CLOB, "clob($l)" );
 		}
 
 		// aggregate functions
 		registerFunction( "avg", new AvgWithArgumentCastFunction( "double" ) );
 
 		// string functions
 		registerFunction( "ascii", new StandardSQLFunction( "ascii", StandardBasicTypes.INTEGER ) );
 		registerFunction( "char", new StandardSQLFunction( "char", StandardBasicTypes.CHARACTER ) );
 		registerFunction( "lower", new StandardSQLFunction( "lower" ) );
 		registerFunction( "upper", new StandardSQLFunction( "upper" ) );
 		registerFunction( "lcase", new StandardSQLFunction( "lcase" ) );
 		registerFunction( "ucase", new StandardSQLFunction( "ucase" ) );
 		registerFunction( "soundex", new StandardSQLFunction( "soundex", StandardBasicTypes.STRING ) );
 		registerFunction( "ltrim", new StandardSQLFunction( "ltrim" ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim" ) );
 		registerFunction( "reverse", new StandardSQLFunction( "reverse" ) );
 		registerFunction( "space", new StandardSQLFunction( "space", StandardBasicTypes.STRING ) );
 		registerFunction( "str", new SQLFunctionTemplate( StandardBasicTypes.STRING, "cast(?1 as varchar(256))" ) );
 		registerFunction( "to_char", new StandardSQLFunction( "to_char", StandardBasicTypes.STRING ) );
 		registerFunction( "rawtohex", new StandardSQLFunction( "rawtohex" ) );
 		registerFunction( "hextoraw", new StandardSQLFunction( "hextoraw" ) );
 
 		// system functions
 		registerFunction( "user", new NoArgSQLFunction( "user", StandardBasicTypes.STRING ) );
 		registerFunction( "database", new NoArgSQLFunction( "database", StandardBasicTypes.STRING ) );
 
 		// datetime functions
 		if ( hsqldbVersion < 20 ) {
 			registerFunction( "sysdate", new NoArgSQLFunction( "sysdate", StandardBasicTypes.DATE, false ) );
 		}
 		else {
 			registerFunction( "sysdate", new NoArgSQLFunction( "sysdate", StandardBasicTypes.TIMESTAMP, false ) );
 		}
 		registerFunction( "current_date", new NoArgSQLFunction( "current_date", StandardBasicTypes.DATE, false ) );
 		registerFunction( "curdate", new NoArgSQLFunction( "curdate", StandardBasicTypes.DATE ) );
 		registerFunction(
 				"current_timestamp", new NoArgSQLFunction( "current_timestamp", StandardBasicTypes.TIMESTAMP, false )
 		);
 		registerFunction( "now", new NoArgSQLFunction( "now", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "current_time", new NoArgSQLFunction( "current_time", StandardBasicTypes.TIME, false ) );
 		registerFunction( "curtime", new NoArgSQLFunction( "curtime", StandardBasicTypes.TIME ) );
 		registerFunction( "day", new StandardSQLFunction( "day", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofweek", new StandardSQLFunction( "dayofweek", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofyear", new StandardSQLFunction( "dayofyear", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofmonth", new StandardSQLFunction( "dayofmonth", StandardBasicTypes.INTEGER ) );
 		registerFunction( "month", new StandardSQLFunction( "month", StandardBasicTypes.INTEGER ) );
 		registerFunction( "year", new StandardSQLFunction( "year", StandardBasicTypes.INTEGER ) );
 		registerFunction( "week", new StandardSQLFunction( "week", StandardBasicTypes.INTEGER ) );
 		registerFunction( "quarter", new StandardSQLFunction( "quarter", StandardBasicTypes.INTEGER ) );
 		registerFunction( "hour", new StandardSQLFunction( "hour", StandardBasicTypes.INTEGER ) );
 		registerFunction( "minute", new StandardSQLFunction( "minute", StandardBasicTypes.INTEGER ) );
 		registerFunction( "second", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "cast(second(?1) as int)" ) );
 		registerFunction( "dayname", new StandardSQLFunction( "dayname", StandardBasicTypes.STRING ) );
 		registerFunction( "monthname", new StandardSQLFunction( "monthname", StandardBasicTypes.STRING ) );
 
 		// numeric functions
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "sign", new StandardSQLFunction( "sign", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "acos", new StandardSQLFunction( "acos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "asin", new StandardSQLFunction( "asin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan", new StandardSQLFunction( "atan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cos", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cot", new StandardSQLFunction( "cot", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "exp", new StandardSQLFunction( "exp", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log", new StandardSQLFunction( "log", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log10", new StandardSQLFunction( "log10", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sin", new StandardSQLFunction( "sin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sqrt", new StandardSQLFunction( "sqrt", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tan", new StandardSQLFunction( "tan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "pi", new NoArgSQLFunction( "pi", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "rand", new StandardSQLFunction( "rand", StandardBasicTypes.FLOAT ) );
 
 		registerFunction( "radians", new StandardSQLFunction( "radians", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "degrees", new StandardSQLFunction( "degrees", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "round", new StandardSQLFunction( "round" ) );
 		registerFunction( "roundmagic", new StandardSQLFunction( "roundmagic" ) );
 		registerFunction( "truncate", new StandardSQLFunction( "truncate" ) );
 
 		registerFunction( "ceiling", new StandardSQLFunction( "ceiling" ) );
 		registerFunction( "floor", new StandardSQLFunction( "floor" ) );
 
 		// special functions
 		// from v. 2.2.0 ROWNUM() is supported in all modes as the equivalent of Oracle ROWNUM
 		if ( hsqldbVersion > 21 ) {
 			registerFunction( "rownum", new NoArgSQLFunction( "rownum", StandardBasicTypes.INTEGER ) );
 		}
 
 		// function templates
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(", "||", ")" ) );
 
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 
 		limitHandler = new HSQLLimitHandler();
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add column";
 	}
 
 	@Override
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	@Override
 	public String getIdentityColumnString() {
 		//not null is implicit
 		return "generated by default as identity (start with 1)";
 	}
 
 	@Override
 	public String getIdentitySelectString() {
 		return "call identity()";
 	}
 
 	@Override
 	public String getIdentityInsertString() {
 		return hsqldbVersion < 20 ? "null" : "default";
 	}
 
 	@Override
 	public boolean supportsLockTimeouts() {
 		return false;
 	}
 
 	@Override
 	public String getForUpdateString() {
 		if ( hsqldbVersion >= 20 ) {
 			return " for update";
 		}
 		else {
 			return "";
 		}
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return limitHandler;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 		if ( hsqldbVersion < 20 ) {
 			return new StringBuilder( sql.length() + 10 )
 					.append( sql )
 					.insert(
-							sql.toLowerCase().indexOf( "select" ) + 6,
+							sql.toLowerCase(Locale.ROOT).indexOf( "select" ) + 6,
 							hasOffset ? " limit ? ?" : " top ?"
 					)
 					.toString();
 		}
 		else {
 			return sql + (hasOffset ? " offset ? limit ?" : " limit ?");
 		}
 	}
 
 	@Override
 	public boolean bindLimitParametersFirst() {
 		return hsqldbVersion < 20;
 	}
 
 	@Override
 	public boolean supportsIfExistsAfterTableName() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsColumnCheck() {
 		return hsqldbVersion >= 20;
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	/**
 	 * HSQL will start with 0, by default.  In order for Hibernate to know that this not transient,
 	 * manually start with 1.
 	 */
 	@Override
 	protected String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName + " start with 1";
 	}
 	
 	/**
 	 * Because of the overridden {@link #getCreateSequenceString(String)}, we must also override
 	 * {@link #getCreateSequenceString(String, int, int)} to prevent 2 instances of "start with".
 	 */
 	@Override
 	protected String getCreateSequenceString(String sequenceName, int initialValue, int incrementSize) throws MappingException {
 		if ( supportsPooledSequences() ) {
 			return "create sequence " + sequenceName + " start with " + initialValue + " increment by " + incrementSize;
 		}
 		throw new MappingException( getClass().getName() + " does not support pooled sequences" );
 	}
 
 	@Override
 	protected String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return "next value for " + sequenceName;
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "call next value for " + sequenceName;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		// this assumes schema support, which is present in 1.8.0 and later...
 		return "select sequence_name from information_schema.system_sequences";
 	}
 
 	@Override
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return hsqldbVersion < 20 ? EXTRACTER_18 : EXTRACTER_20;
 	}
 
 	private static final ViolatedConstraintNameExtracter EXTRACTER_18 = new TemplatedViolatedConstraintNameExtracter() {
 		@Override
 		public String extractConstraintName(SQLException sqle) {
 			String constraintName = null;
 
 			final int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 
 			if ( errorCode == -8 ) {
 				constraintName = extractUsingTemplate(
 						"Integrity constraint violation ", " table:", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -9 ) {
 				constraintName = extractUsingTemplate(
 						"Violation of unique index: ", " in statement [", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -104 ) {
 				constraintName = extractUsingTemplate(
 						"Unique constraint violation: ", " in statement [", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -177 ) {
 				constraintName = extractUsingTemplate(
 						"Integrity constraint violation - no parent ", " table:",
 						sqle.getMessage()
 				);
 			}
 			return constraintName;
 		}
 
 	};
 
 	/**
 	 * HSQLDB 2.0 messages have changed
 	 * messages may be localized - therefore use the common, non-locale element " table: "
 	 */
 	private static final ViolatedConstraintNameExtracter EXTRACTER_20 = new TemplatedViolatedConstraintNameExtracter() {
 		@Override
 		public String extractConstraintName(SQLException sqle) {
 			String constraintName = null;
 
 			final int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 
 			if ( errorCode == -8 ) {
 				constraintName = extractUsingTemplate(
 						"; ", " table: ", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -9 ) {
 				constraintName = extractUsingTemplate(
 						"; ", " table: ", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -104 ) {
 				constraintName = extractUsingTemplate(
 						"; ", " table: ", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -177 ) {
 				constraintName = extractUsingTemplate(
 						"; ", " table: ", sqle.getMessage()
 				);
 			}
 			return constraintName;
 		}
 	};
 
 	@Override
 	public String getSelectClauseNullString(int sqlType) {
 		String literal;
 		switch ( sqlType ) {
 			case Types.LONGVARCHAR:
 			case Types.VARCHAR:
 			case Types.CHAR:
 				literal = "cast(null as varchar(100))";
 				break;
 			case Types.LONGVARBINARY:
 			case Types.VARBINARY:
 			case Types.BINARY:
 				literal = "cast(null as varbinary(100))";
 				break;
 			case Types.CLOB:
 				literal = "cast(null as clob)";
 				break;
 			case Types.BLOB:
 				literal = "cast(null as blob)";
 				break;
 			case Types.DATE:
 				literal = "cast(null as date)";
 				break;
 			case Types.TIMESTAMP:
 				literal = "cast(null as timestamp)";
 				break;
 			case Types.BOOLEAN:
 				literal = "cast(null as boolean)";
 				break;
 			case Types.BIT:
 				literal = "cast(null as bit)";
 				break;
 			case Types.TIME:
 				literal = "cast(null as time)";
 				break;
 			default:
 				literal = "cast(null as int)";
 		}
 		return literal;
 	}
 
 	@Override
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 	// temporary table support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	// Hibernate uses this information for temporary tables that it uses for its own operations
 	// therefore the appropriate strategy is taken with different versions of HSQLDB
 
 	// All versions of HSQLDB support GLOBAL TEMPORARY tables where the table
 	// definition is shared by all users but data is private to the session
 	// HSQLDB 2.0 also supports session-based LOCAL TEMPORARY tables where
 	// the definition and data is private to the session and table declaration
 	// can happen in the middle of a transaction
 
 	@Override
 	public boolean supportsTemporaryTables() {
 		return true;
 	}
 
 	@Override
 	public String generateTemporaryTableName(String baseTableName) {
 		if ( hsqldbVersion < 20 ) {
 			return "HT_" + baseTableName;
 		}
 		else {
 			// With HSQLDB 2.0, the table name is qualified with MODULE to assist the drop
 			// statement (in-case there is a global name beginning with HT_)
 			return "MODULE.HT_" + baseTableName;
 		}
 	}
 
 	@Override
 	public String getCreateTemporaryTableString() {
 		if ( hsqldbVersion < 20 ) {
 			return "create global temporary table";
 		}
 		else {
 			return "declare local temporary table";
 		}
 	}
 
 	@Override
 	public String getCreateTemporaryTablePostfix() {
 		return "";
 	}
 
 	@Override
 	public String getDropTemporaryTableString() {
 		return "drop table";
 	}
 
 	@Override
 	public Boolean performTemporaryTableDDLInIsolation() {
 		// Different behavior for GLOBAL TEMPORARY (1.8) and LOCAL TEMPORARY (2.0)
 		if ( hsqldbVersion < 20 ) {
 			return Boolean.TRUE;
 		}
 		else {
 			return Boolean.FALSE;
 		}
 	}
 
 	@Override
 	public boolean dropTemporaryTableAfterUse() {
 		// Version 1.8 GLOBAL TEMPORARY table definitions persist beyond the end
 		// of the session (by default, data is cleared at commit).<p>
 		//
 		// Version 2.x LOCAL TEMPORARY table definitions do not persist beyond
 		// the end of the session (by default, data is cleared at commit).
 		return true;
 	}
 
 	// current timestamp support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * HSQLDB 1.8.x requires CALL CURRENT_TIMESTAMP but this should not
 	 * be treated as a callable statement. It is equivalent to
 	 * "select current_timestamp from dual" in some databases.
 	 * HSQLDB 2.0 also supports VALUES CURRENT_TIMESTAMP
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "call current_timestamp";
 	}
 
 	@Override
 	public String getCurrentTimestampSQLFunctionName() {
 		// the standard SQL function name is current_timestamp...
 		return "current_timestamp";
 	}
 
 	/**
 	 * For HSQLDB 2.0, this is a copy of the base class implementation.
 	 * For HSQLDB 1.8, only READ_UNCOMMITTED is supported.
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public LockingStrategy getLockingStrategy(Lockable lockable, LockMode lockMode) {
 		if ( lockMode == LockMode.PESSIMISTIC_FORCE_INCREMENT ) {
 			return new PessimisticForceIncrementLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_WRITE ) {
 			return new PessimisticWriteSelectLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_READ ) {
 			return new PessimisticReadSelectLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC ) {
 			return new OptimisticLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC_FORCE_INCREMENT ) {
 			return new OptimisticForceIncrementLockingStrategy( lockable, lockMode );
 		}
 
 		if ( hsqldbVersion < 20 ) {
 			return new ReadUncommittedLockingStrategy( lockable, lockMode );
 		}
 		else {
 			return new SelectLockingStrategy( lockable, lockMode );
 		}
 	}
 
 	private static class ReadUncommittedLockingStrategy extends SelectLockingStrategy {
 		public ReadUncommittedLockingStrategy(Lockable lockable, LockMode lockMode) {
 			super( lockable, lockMode );
 		}
 
 		public void lock(Serializable id, Object version, Object object, int timeout, SessionImplementor session)
 				throws StaleObjectStateException, JDBCException {
 			if ( getLockMode().greaterThan( LockMode.READ ) ) {
 				LOG.hsqldbSupportsOnlyReadCommittedIsolation();
 			}
 			super.lock( id, version, object, timeout, session );
 		}
 	}
 
 	@Override
 	public boolean supportsCommentOn() {
 		return hsqldbVersion >= 20;
 	}
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	@Override
 	public boolean requiresCastingOfParametersInSelectClause() {
 		return true;
 	}
 
 	@Override
 	public boolean doesReadCommittedCauseWritersToBlockReaders() {
 		return hsqldbVersion >= 20;
 	}
 
 	@Override
 	public boolean doesRepeatableReadCauseReadersToBlockWriters() {
 		return hsqldbVersion >= 20;
 	}
 
 	@Override
 	public boolean supportsLobValueChangePropogation() {
 		return false;
 	}
 
 	@Override
 	public String toBooleanValueString(boolean bool) {
 		return String.valueOf( bool );
 	}
 
 	@Override
 	public boolean supportsTupleDistinctCounts() {
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/InformixDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/InformixDialect.java
index 1f7519b2a1..614d7dc8c2 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/InformixDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/InformixDialect.java
@@ -1,307 +1,308 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.SQLException;
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.MappingException;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.pagination.FirstLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.unique.InformixUniqueDelegate;
 import org.hibernate.dialect.unique.UniqueDelegate;
 import org.hibernate.exception.spi.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * Informix dialect.<br>
  * <br>
  * Seems to work with Informix Dynamic Server Version 7.31.UD3,  Informix JDBC driver version 2.21JC3.
  *
  * @author Steve Molitor
  */
 public class InformixDialect extends Dialect {
 	
 	private final UniqueDelegate uniqueDelegate;
 
 	/**
 	 * Creates new <code>InformixDialect</code> instance. Sets up the JDBC /
 	 * Informix type mappings.
 	 */
 	public InformixDialect() {
 		super();
 
 		registerColumnType( Types.BIGINT, "int8" );
 		registerColumnType( Types.BINARY, "byte" );
 		// Informix doesn't have a bit type
 		registerColumnType( Types.BIT, "smallint" );
 		registerColumnType( Types.CHAR, "char($l)" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.DECIMAL, "decimal" );
 		registerColumnType( Types.DOUBLE, "float" );
 		registerColumnType( Types.FLOAT, "smallfloat" );
 		registerColumnType( Types.INTEGER, "integer" );
 		// or BYTE
 		registerColumnType( Types.LONGVARBINARY, "blob" );
 		// or TEXT?
 		registerColumnType( Types.LONGVARCHAR, "clob" );
 		// or MONEY
 		registerColumnType( Types.NUMERIC, "decimal" );
 		registerColumnType( Types.REAL, "smallfloat" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.TIMESTAMP, "datetime year to fraction(5)" );
 		registerColumnType( Types.TIME, "datetime hour to second" );
 		registerColumnType( Types.TINYINT, "smallint" );
 		registerColumnType( Types.VARBINARY, "byte" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.VARCHAR, 255, "varchar($l)" );
 		registerColumnType( Types.VARCHAR, 32739, "lvarchar($l)" );
 
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(", "||", ")" ) );
 		
 		uniqueDelegate = new InformixUniqueDelegate( this );
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	@Override
 	public String getIdentitySelectString(String table, String column, int type)
 			throws MappingException {
 		return type == Types.BIGINT
 				? "select dbinfo('serial8') from informix.systables where tabid=1"
 				: "select dbinfo('sqlca.sqlerrd1') from informix.systables where tabid=1";
 	}
 
 	@Override
 	public String getIdentityColumnString(int type) throws MappingException {
 		return type == Types.BIGINT ?
 				"serial8 not null" :
 				"serial not null";
 	}
 
 	@Override
 	public boolean hasDataTypeInIdentityColumn() {
 		return false;
 	}
 
 	/**
 	 * Informix constraint name must be at the end.
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public String getAddForeignKeyConstraintString(
 			String constraintName,
 			String[] foreignKey,
 			String referencedTable,
 			String[] primaryKey,
 			boolean referencesPrimaryKey) {
 		final StringBuilder result = new StringBuilder( 30 )
 				.append( " add constraint " )
 				.append( " foreign key (" )
 				.append( StringHelper.join( ", ", foreignKey ) )
 				.append( ") references " )
 				.append( referencedTable );
 
 		if ( !referencesPrimaryKey ) {
 			result.append( " (" )
 					.append( StringHelper.join( ", ", primaryKey ) )
 					.append( ')' );
 		}
 
 		result.append( " constraint " ).append( constraintName );
 
 		return result.toString();
 	}
 
 	/**
 	 * Informix constraint name must be at the end.
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public String getAddPrimaryKeyConstraintString(String constraintName) {
 		return " add constraint primary key constraint " + constraintName + " ";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName + " restrict";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from informix.systables where tabid=1";
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select tabname from informix.systables where tabtype='Q'";
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return FirstLimitHandler.INSTANCE;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimitOffset() {
 		return false;
 	}
 
 	@Override
 	public String getLimitString(String querySelect, int offset, int limit) {
 		if ( offset > 0 ) {
 			throw new UnsupportedOperationException( "query result offset is not supported" );
 		}
 		return new StringBuilder( querySelect.length() + 8 )
 				.append( querySelect )
-				.insert( querySelect.toLowerCase().indexOf( "select" ) + 6, " first " + limit )
+				.insert( querySelect.toLowerCase(Locale.ROOT).indexOf( "select" ) + 6, " first " + limit )
 				.toString();
 	}
 
 	@Override
 	public boolean supportsVariableLimit() {
 		return false;
 	}
 
 	@Override
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 	private static final ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 		@Override
 		public String extractConstraintName(SQLException sqle) {
 			String constraintName = null;
 			final int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 
 			if ( errorCode == -268 ) {
 				constraintName = extractUsingTemplate( "Unique constraint (", ") violated.", sqle.getMessage() );
 			}
 			else if ( errorCode == -691 ) {
 				constraintName = extractUsingTemplate(
 						"Missing key in referenced table for referential constraint (",
 						").",
 						sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -692 ) {
 				constraintName = extractUsingTemplate(
 						"Key value for constraint (",
 						") is still being referenced.",
 						sqle.getMessage()
 				);
 			}
 
 			if ( constraintName != null ) {
 				// strip table-owner because Informix always returns constraint names as "<table-owner>.<constraint-name>"
 				final int i = constraintName.indexOf( '.' );
 				if ( i != -1 ) {
 					constraintName = constraintName.substring( i + 1 );
 				}
 			}
 
 			return constraintName;
 		}
 
 	};
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select distinct current timestamp from informix.systables";
 	}
 
 	@Override
 	public boolean supportsTemporaryTables() {
 		return true;
 	}
 
 	@Override
 	public String getCreateTemporaryTableString() {
 		return "create temp table";
 	}
 
 	@Override
 	public String getCreateTemporaryTablePostfix() {
 		return "with no log";
 	}
 	
 	@Override
 	public UniqueDelegate getUniqueDelegate() {
 		return uniqueDelegate;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/InterbaseDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/InterbaseDialect.java
index 071c13cef7..3cf4fe5cc1 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/InterbaseDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/InterbaseDialect.java
@@ -1,169 +1,170 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * An SQL dialect for Interbase.
  *
  * @author Gavin King
  */
 @SuppressWarnings("deprecation")
 public class InterbaseDialect extends Dialect {
 
 	private static final AbstractLimitHandler LIMIT_HANDLER = new AbstractLimitHandler() {
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final boolean hasOffset = LimitHelper.hasFirstRow( selection );
 			return hasOffset ? sql + " rows ? to ?" : sql + " rows ?";
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return true;
 		}
 	};
 
 	/**
 	 * Constructs a InterbaseDialect
 	 */
 	public InterbaseDialect() {
 		super();
 		registerColumnType( Types.BIT, "smallint" );
 		registerColumnType( Types.BIGINT, "numeric(18,0)" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.TINYINT, "smallint" );
 		registerColumnType( Types.INTEGER, "integer" );
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.DOUBLE, "double precision" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.VARBINARY, "blob" );
 		registerColumnType( Types.NUMERIC, "numeric($p,$s)" );
 		registerColumnType( Types.BLOB, "blob" );
 		registerColumnType( Types.CLOB, "blob sub_type 1" );
 		registerColumnType( Types.BOOLEAN, "smallint" );
 		
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(","||",")" ) );
 		registerFunction( "current_date", new NoArgSQLFunction( "current_date", StandardBasicTypes.DATE, false ) );
 
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, NO_BATCH );
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from RDB$DATABASE";
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return "gen_id( " + sequenceName + ", 1 )";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		return "create generator " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
-		return "delete from RDB$GENERATORS where RDB$GENERATOR_NAME = '" + sequenceName.toUpperCase() + "'";
+		return "delete from RDB$GENERATORS where RDB$GENERATOR_NAME = '" + sequenceName.toUpperCase(Locale.ROOT) + "'";
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select RDB$GENERATOR_NAME from RDB$GENERATORS";
 	}
 
 	@Override
 	public String getForUpdateString() {
 		return " with lock";
 	}
 
 	@Override
 	public String getForUpdateString(String aliases) {
 		return " for update of " + aliases + " with lock";
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return LIMIT_HANDLER;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 		return hasOffset ? sql + " rows ? to ?" : sql + " rows ?";
 	}
 
 	@Override
 	public boolean bindLimitParametersFirst() {
 		return false;
 	}
 
 	@Override
 	public boolean bindLimitParametersInReverseOrder() {
 		return false;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		// TODO : not sure which (either?) is correct, could not find docs on how to do this.
 		// did find various blogs and forums mentioning that select CURRENT_TIMESTAMP
 		// does not work...
 		return "{?= call CURRENT_TIMESTAMP }";
 //		return "select CURRENT_TIMESTAMP from RDB$DATABASE";
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return true;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle8iDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle8iDialect.java
index 636d163cf2..bd5112e908 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle8iDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle8iDialect.java
@@ -1,682 +1,684 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.CallableStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.List;
+import java.util.Locale;
 
 import org.hibernate.JDBCException;
 import org.hibernate.QueryTimeoutException;
 import org.hibernate.annotations.common.util.StringHelper;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.NvlFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.exception.ConstraintViolationException;
 import org.hibernate.exception.LockAcquisitionException;
 import org.hibernate.exception.LockTimeoutException;
 import org.hibernate.exception.spi.SQLExceptionConversionDelegate;
 import org.hibernate.exception.spi.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.procedure.internal.StandardCallableStatementSupport;
 import org.hibernate.procedure.spi.CallableStatementSupport;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.DecodeCaseFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.OracleJoinFragment;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.descriptor.sql.BitTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 /**
  * A dialect for Oracle 8i.
  *
  * @author Steve Ebersole
  */
 @SuppressWarnings("deprecation")
 public class Oracle8iDialect extends Dialect {
 
 	private static final AbstractLimitHandler LIMIT_HANDLER = new AbstractLimitHandler() {
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final boolean hasOffset = LimitHelper.hasFirstRow( selection );
 			sql = sql.trim();
 			boolean isForUpdate = false;
-			if (sql.toLowerCase().endsWith( " for update" )) {
+			if (sql.toLowerCase(Locale.ROOT
+                        ).endsWith( " for update" )) {
 				sql = sql.substring( 0, sql.length() - 11 );
 				isForUpdate = true;
 			}
 
 			final StringBuilder pagingSelect = new StringBuilder( sql.length() + 100 );
 			if (hasOffset) {
 				pagingSelect.append( "select * from ( select row_.*, rownum rownum_ from ( " );
 			}
 			else {
 				pagingSelect.append( "select * from ( " );
 			}
 			pagingSelect.append( sql );
 			if (hasOffset) {
 				pagingSelect.append( " ) row_ ) where rownum_ <= ? and rownum_ > ?" );
 			}
 			else {
 				pagingSelect.append( " ) where rownum <= ?" );
 			}
 
 			if (isForUpdate) {
 				pagingSelect.append( " for update" );
 			}
 
 			return pagingSelect.toString();
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return true;
 		}
 
 		@Override
 		public boolean bindLimitParametersInReverseOrder() {
 			return true;
 		}
 
 		@Override
 		public boolean useMaxForLimit() {
 			return true;
 		}
 	};
 
 	private static final int PARAM_LIST_SIZE_LIMIT = 1000;
 
 	/**
 	 * Constructs a Oracle8iDialect
 	 */
 	public Oracle8iDialect() {
 		super();
 		registerCharacterTypeMappings();
 		registerNumericTypeMappings();
 		registerDateTimeTypeMappings();
 		registerLargeObjectTypeMappings();
 		registerReverseHibernateTypeMappings();
 		registerFunctions();
 		registerDefaultProperties();
 	}
 
 	protected void registerCharacterTypeMappings() {
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.VARCHAR, 4000, "varchar2($l)" );
 		registerColumnType( Types.VARCHAR, "long" );
 	}
 
 	protected void registerNumericTypeMappings() {
 		registerColumnType( Types.BIT, "number(1,0)" );
 		registerColumnType( Types.BIGINT, "number(19,0)" );
 		registerColumnType( Types.SMALLINT, "number(5,0)" );
 		registerColumnType( Types.TINYINT, "number(3,0)" );
 		registerColumnType( Types.INTEGER, "number(10,0)" );
 
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.DOUBLE, "double precision" );
 		registerColumnType( Types.NUMERIC, "number($p,$s)" );
 		registerColumnType( Types.DECIMAL, "number($p,$s)" );
 
 		registerColumnType( Types.BOOLEAN, "number(1,0)" );
 	}
 
 	protected void registerDateTimeTypeMappings() {
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "date" );
 		registerColumnType( Types.TIMESTAMP, "date" );
 	}
 
 	protected void registerLargeObjectTypeMappings() {
 		registerColumnType( Types.BINARY, 2000, "raw($l)" );
 		registerColumnType( Types.BINARY, "long raw" );
 
 		registerColumnType( Types.VARBINARY, 2000, "raw($l)" );
 		registerColumnType( Types.VARBINARY, "long raw" );
 
 		registerColumnType( Types.BLOB, "blob" );
 		registerColumnType( Types.CLOB, "clob" );
 
 		registerColumnType( Types.LONGVARCHAR, "long" );
 		registerColumnType( Types.LONGVARBINARY, "long raw" );
 	}
 
 	protected void registerReverseHibernateTypeMappings() {
 	}
 
 	protected void registerFunctions() {
 		registerFunction( "abs", new StandardSQLFunction("abs") );
 		registerFunction( "sign", new StandardSQLFunction("sign", StandardBasicTypes.INTEGER) );
 
 		registerFunction( "acos", new StandardSQLFunction("acos", StandardBasicTypes.DOUBLE) );
 		registerFunction( "asin", new StandardSQLFunction("asin", StandardBasicTypes.DOUBLE) );
 		registerFunction( "atan", new StandardSQLFunction("atan", StandardBasicTypes.DOUBLE) );
 		registerFunction( "bitand", new StandardSQLFunction("bitand") );
 		registerFunction( "cos", new StandardSQLFunction("cos", StandardBasicTypes.DOUBLE) );
 		registerFunction( "cosh", new StandardSQLFunction("cosh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "exp", new StandardSQLFunction("exp", StandardBasicTypes.DOUBLE) );
 		registerFunction( "ln", new StandardSQLFunction("ln", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sin", new StandardSQLFunction("sin", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sinh", new StandardSQLFunction("sinh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "stddev", new StandardSQLFunction("stddev", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sqrt", new StandardSQLFunction("sqrt", StandardBasicTypes.DOUBLE) );
 		registerFunction( "tan", new StandardSQLFunction("tan", StandardBasicTypes.DOUBLE) );
 		registerFunction( "tanh", new StandardSQLFunction("tanh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "variance", new StandardSQLFunction("variance", StandardBasicTypes.DOUBLE) );
 
 		registerFunction( "round", new StandardSQLFunction("round") );
 		registerFunction( "trunc", new StandardSQLFunction("trunc") );
 		registerFunction( "ceil", new StandardSQLFunction("ceil") );
 		registerFunction( "floor", new StandardSQLFunction("floor") );
 
 		registerFunction( "chr", new StandardSQLFunction("chr", StandardBasicTypes.CHARACTER) );
 		registerFunction( "initcap", new StandardSQLFunction("initcap") );
 		registerFunction( "lower", new StandardSQLFunction("lower") );
 		registerFunction( "ltrim", new StandardSQLFunction("ltrim") );
 		registerFunction( "rtrim", new StandardSQLFunction("rtrim") );
 		registerFunction( "soundex", new StandardSQLFunction("soundex") );
 		registerFunction( "upper", new StandardSQLFunction("upper") );
 		registerFunction( "ascii", new StandardSQLFunction("ascii", StandardBasicTypes.INTEGER) );
 
 		registerFunction( "to_char", new StandardSQLFunction("to_char", StandardBasicTypes.STRING) );
 		registerFunction( "to_date", new StandardSQLFunction("to_date", StandardBasicTypes.TIMESTAMP) );
 
 		registerFunction( "current_date", new NoArgSQLFunction("current_date", StandardBasicTypes.DATE, false) );
 		registerFunction( "current_time", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIME, false) );
 		registerFunction( "current_timestamp", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIMESTAMP, false) );
 
 		registerFunction( "last_day", new StandardSQLFunction("last_day", StandardBasicTypes.DATE) );
 		registerFunction( "sysdate", new NoArgSQLFunction("sysdate", StandardBasicTypes.DATE, false) );
 		registerFunction( "systimestamp", new NoArgSQLFunction("systimestamp", StandardBasicTypes.TIMESTAMP, false) );
 		registerFunction( "uid", new NoArgSQLFunction("uid", StandardBasicTypes.INTEGER, false) );
 		registerFunction( "user", new NoArgSQLFunction("user", StandardBasicTypes.STRING, false) );
 
 		registerFunction( "rowid", new NoArgSQLFunction("rowid", StandardBasicTypes.LONG, false) );
 		registerFunction( "rownum", new NoArgSQLFunction("rownum", StandardBasicTypes.LONG, false) );
 
 		// Multi-param string dialect functions...
 		registerFunction( "concat", new VarArgsSQLFunction(StandardBasicTypes.STRING, "", "||", "") );
 		registerFunction( "instr", new StandardSQLFunction("instr", StandardBasicTypes.INTEGER) );
 		registerFunction( "instrb", new StandardSQLFunction("instrb", StandardBasicTypes.INTEGER) );
 		registerFunction( "lpad", new StandardSQLFunction("lpad", StandardBasicTypes.STRING) );
 		registerFunction( "replace", new StandardSQLFunction("replace", StandardBasicTypes.STRING) );
 		registerFunction( "rpad", new StandardSQLFunction("rpad", StandardBasicTypes.STRING) );
 		registerFunction( "substr", new StandardSQLFunction("substr", StandardBasicTypes.STRING) );
 		registerFunction( "substrb", new StandardSQLFunction("substrb", StandardBasicTypes.STRING) );
 		registerFunction( "translate", new StandardSQLFunction("translate", StandardBasicTypes.STRING) );
 
 		registerFunction( "substring", new StandardSQLFunction( "substr", StandardBasicTypes.STRING ) );
 		registerFunction( "locate", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "instr(?2,?1)" ) );
 		registerFunction( "bit_length", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "vsize(?1)*8" ) );
 		registerFunction( "coalesce", new NvlFunction() );
 
 		// Multi-param numeric dialect functions...
 		registerFunction( "atan2", new StandardSQLFunction("atan2", StandardBasicTypes.FLOAT) );
 		registerFunction( "log", new StandardSQLFunction("log", StandardBasicTypes.INTEGER) );
 		registerFunction( "mod", new StandardSQLFunction("mod", StandardBasicTypes.INTEGER) );
 		registerFunction( "nvl", new StandardSQLFunction("nvl") );
 		registerFunction( "nvl2", new StandardSQLFunction("nvl2") );
 		registerFunction( "power", new StandardSQLFunction("power", StandardBasicTypes.FLOAT) );
 
 		// Multi-param date dialect functions...
 		registerFunction( "add_months", new StandardSQLFunction("add_months", StandardBasicTypes.DATE) );
 		registerFunction( "months_between", new StandardSQLFunction("months_between", StandardBasicTypes.FLOAT) );
 		registerFunction( "next_day", new StandardSQLFunction("next_day", StandardBasicTypes.DATE) );
 
 		registerFunction( "str", new StandardSQLFunction("to_char", StandardBasicTypes.STRING) );
 	}
 
 	protected void registerDefaultProperties() {
 		getDefaultProperties().setProperty( Environment.USE_STREAMS_FOR_BINARY, "true" );
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 		// Oracle driver reports to support getGeneratedKeys(), but they only
 		// support the version taking an array of the names of the columns to
 		// be returned (via its RETURNING clause).  No other driver seems to
 		// support this overloaded version.
 		getDefaultProperties().setProperty( Environment.USE_GET_GENERATED_KEYS, "false" );
 	}
 
 	@Override
 	protected SqlTypeDescriptor getSqlTypeDescriptorOverride(int sqlCode) {
 		return sqlCode == Types.BOOLEAN ? BitTypeDescriptor.INSTANCE : super.getSqlTypeDescriptorOverride( sqlCode );
 	}
 
 
 	// features which change between 8i, 9i, and 10g ~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public JoinFragment createOuterJoinFragment() {
 		return new OracleJoinFragment();
 	}
 
 	@Override
 	public String getCrossJoinSeparator() {
 		return ", ";
 	}
 
 	/**
 	 * Map case support to the Oracle DECODE function.  Oracle did not
 	 * add support for CASE until 9i.
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public CaseFragment createCaseFragment() {
 		return new DecodeCaseFragment();
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return LIMIT_HANDLER;
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 		sql = sql.trim();
 		boolean isForUpdate = false;
-		if ( sql.toLowerCase().endsWith( " for update" ) ) {
+		if ( sql.toLowerCase(Locale.ROOT).endsWith( " for update" ) ) {
 			sql = sql.substring( 0, sql.length()-11 );
 			isForUpdate = true;
 		}
 
 		final StringBuilder pagingSelect = new StringBuilder( sql.length()+100 );
 		if (hasOffset) {
 			pagingSelect.append( "select * from ( select row_.*, rownum rownum_ from ( " );
 		}
 		else {
 			pagingSelect.append( "select * from ( " );
 		}
 		pagingSelect.append( sql );
 		if (hasOffset) {
 			pagingSelect.append( " ) row_ ) where rownum_ <= ? and rownum_ > ?" );
 		}
 		else {
 			pagingSelect.append( " ) where rownum <= ?" );
 		}
 
 		if ( isForUpdate ) {
 			pagingSelect.append( " for update" );
 		}
 
 		return pagingSelect.toString();
 	}
 
 	/**
 	 * Allows access to the basic {@link Dialect#getSelectClauseNullString}
 	 * implementation...
 	 *
 	 * @param sqlType The {@link java.sql.Types} mapping type code
 	 * @return The appropriate select cluse fragment
 	 */
 	public String getBasicSelectClauseNullString(int sqlType) {
 		return super.getSelectClauseNullString( sqlType );
 	}
 
 	@Override
 	public String getSelectClauseNullString(int sqlType) {
 		switch(sqlType) {
 			case Types.VARCHAR:
 			case Types.CHAR:
 				return "to_char(null)";
 			case Types.DATE:
 			case Types.TIMESTAMP:
 			case Types.TIME:
 				return "to_date(null)";
 			default:
 				return "to_number(null)";
 		}
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select sysdate from dual";
 	}
 
 	@Override
 	public String getCurrentTimestampSQLFunctionName() {
 		return "sysdate";
 	}
 
 
 	// features which remain constant across 8i, 9i, and 10g ~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from dual";
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		//starts with 1, implicitly
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getCascadeConstraintsString() {
 		return " cascade constraints";
 	}
 
 	@Override
 	public boolean dropConstraints() {
 		return false;
 	}
 
 	@Override
 	public String getForUpdateNowaitString() {
 		return " for update nowait";
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public String getForUpdateString(String aliases) {
 		return getForUpdateString() + " of " + aliases;
 	}
 
 	@Override
 	public String getForUpdateNowaitString(String aliases) {
 		return getForUpdateString() + " of " + aliases + " nowait";
 	}
 
 	@Override
 	public boolean bindLimitParametersInReverseOrder() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean forUpdateOfColumns() {
 		return true;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return    " select sequence_name from all_sequences"
 				+ "  union"
 				+ " select synonym_name"
 				+ "   from all_synonyms us, all_sequences asq"
 				+ "  where asq.sequence_name = us.table_name"
 				+ "    and asq.sequence_owner = us.table_owner";
 	}
 
 	@Override
 	public String getSelectGUIDString() {
 		return "select rawtohex(sys_guid()) from dual";
 	}
 
 	@Override
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 	private static final ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 
 		/**
 		 * Extract the name of the violated constraint from the given SQLException.
 		 *
 		 * @param sqle The exception that was the result of the constraint violation.
 		 * @return The extracted constraint name.
 		 */
 		public String extractConstraintName(SQLException sqle) {
 			final int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 			if ( errorCode == 1 || errorCode == 2291 || errorCode == 2292 ) {
 				return extractUsingTemplate( "(", ")", sqle.getMessage() );
 			}
 			else if ( errorCode == 1400 ) {
 				// simple nullability constraint
 				return null;
 			}
 			else {
 				return null;
 			}
 		}
 
 	};
 
 	@Override
 	public SQLExceptionConversionDelegate buildSQLExceptionConversionDelegate() {
 		return new SQLExceptionConversionDelegate() {
 			@Override
 			public JDBCException convert(SQLException sqlException, String message, String sql) {
 				// interpreting Oracle exceptions is much much more precise based on their specific vendor codes.
 
 				final int errorCode = JdbcExceptionHelper.extractErrorCode( sqlException );
 
 
 				// lock timeouts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 				if ( errorCode == 30006 ) {
 					// ORA-30006: resource busy; acquire with WAIT timeout expired
 					throw new LockTimeoutException( message, sqlException, sql );
 				}
 				else if ( errorCode == 54 ) {
 					// ORA-00054: resource busy and acquire with NOWAIT specified or timeout expired
 					throw new LockTimeoutException( message, sqlException, sql );
 				}
 				else if ( 4021 == errorCode ) {
 					// ORA-04021 timeout occurred while waiting to lock object
 					throw new LockTimeoutException( message, sqlException, sql );
 				}
 
 
 				// deadlocks ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 				if ( 60 == errorCode ) {
 					// ORA-00060: deadlock detected while waiting for resource
 					return new LockAcquisitionException( message, sqlException, sql );
 				}
 				else if ( 4020 == errorCode ) {
 					// ORA-04020 deadlock detected while trying to lock object
 					return new LockAcquisitionException( message, sqlException, sql );
 				}
 
 
 				// query cancelled ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 				if ( 1013 == errorCode ) {
 					// ORA-01013: user requested cancel of current operation
 					throw new QueryTimeoutException(  message, sqlException, sql );
 				}
 
 
 				// data integrity violation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 				if ( 1407 == errorCode ) {
 					// ORA-01407: cannot update column to NULL
 					final String constraintName = getViolatedConstraintNameExtracter().extractConstraintName( sqlException );
 					return new ConstraintViolationException( message, sqlException, sql, constraintName );
 				}
 
 				return null;
 			}
 		};
 	}
 
 	@Override
 	public int registerResultSetOutParameter(CallableStatement statement, int col) throws SQLException {
 		//	register the type of the out param - an Oracle specific type
 		statement.registerOutParameter( col, OracleTypesHelper.INSTANCE.getOracleCursorTypeSqlType() );
 		col++;
 		return col;
 	}
 
 	@Override
 	public ResultSet getResultSet(CallableStatement ps) throws SQLException {
 		ps.execute();
 		return (ResultSet) ps.getObject( 1 );
 	}
 
 	@Override
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsCommentOn() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsTemporaryTables() {
 		return true;
 	}
 
 	@Override
 	public String generateTemporaryTableName(String baseTableName) {
 		final String name = super.generateTemporaryTableName( baseTableName );
 		return name.length() > 30 ? name.substring( 0, 30 ) : name;
 	}
 
 	@Override
 	public String getCreateTemporaryTableString() {
 		return "create global temporary table";
 	}
 
 	@Override
 	public String getCreateTemporaryTablePostfix() {
 		return "on commit delete rows";
 	}
 
 	@Override
 	public boolean dropTemporaryTableAfterUse() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 	
 	@Override
 	public boolean supportsExistsInSelect() {
 		return false;
 	}
 
 	@Override
 	public int getInExpressionCountLimit() {
 		return PARAM_LIST_SIZE_LIMIT;
 	}
 	
 	@Override
 	public boolean forceLobAsLastValue() {
 		return true;
 	}
 
 	@Override
 	public boolean useFollowOnLocking() {
 		return true;
 	}
 	
 	@Override
 	public String getNotExpression( String expression ) {
 		return "not (" + expression + ")";
 	}
 	
 	@Override
 	public String getQueryHintString(String sql, List<String> hints) {
 		final String hint = StringHelper.join( ", ", hints.iterator() );
 		
 		if ( StringHelper.isEmpty( hint ) ) {
 			return sql;
 		}
 
 		final int pos = sql.indexOf( "select" );
 		if ( pos > -1 ) {
 			final StringBuilder buffer = new StringBuilder( sql.length() + hint.length() + 8 );
 			if ( pos > 0 ) {
 				buffer.append( sql.substring( 0, pos ) );
 			}
 			buffer.append( "select /*+ " ).append( hint ).append( " */" )
 					.append( sql.substring( pos + "select".length() ) );
 			sql = buffer.toString();
 		}
 
 		return sql;
 	}
 	
 	@Override
 	public int getMaxAliasLength() {
 		// Oracle's max identifier length is 30, but Hibernate needs to add "uniqueing info" so we account for that,
 		return 20;
 	}
 
 	@Override
 	public CallableStatementSupport getCallableStatementSupport() {
 		// Oracle supports returning cursors
 		return StandardCallableStatementSupport.REF_CURSOR_INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9Dialect.java
index cf04dbadb2..fdc9f843a7 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9Dialect.java
@@ -1,413 +1,414 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.CallableStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.NvlFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.exception.spi.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.type.StandardBasicTypes;
 
 import org.jboss.logging.Logger;
 
 /**
  * An SQL dialect for Oracle 9 (uses ANSI-style syntax where possible).
  *
  * @author Gavin King
  * @author David Channon
  *
  * @deprecated Use either Oracle9iDialect or Oracle10gDialect instead
  */
 @SuppressWarnings("deprecation")
 @Deprecated
 public class Oracle9Dialect extends Dialect {
 
 	private static final int PARAM_LIST_SIZE_LIMIT = 1000;
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			Oracle9Dialect.class.getName()
 	);
 
 	/**
 	 * Constructs a Oracle9Dialect
 	 */
 	public Oracle9Dialect() {
 		super();
 		LOG.deprecatedOracle9Dialect();
 		registerColumnType( Types.BIT, "number(1,0)" );
 		registerColumnType( Types.BIGINT, "number(19,0)" );
 		registerColumnType( Types.SMALLINT, "number(5,0)" );
 		registerColumnType( Types.TINYINT, "number(3,0)" );
 		registerColumnType( Types.INTEGER, "number(10,0)" );
 		registerColumnType( Types.CHAR, "char(1 char)" );
 		registerColumnType( Types.VARCHAR, 4000, "varchar2($l char)" );
 		registerColumnType( Types.VARCHAR, "long" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.DOUBLE, "double precision" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "date" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.VARBINARY, 2000, "raw($l)" );
 		registerColumnType( Types.VARBINARY, "long raw" );
 		registerColumnType( Types.NUMERIC, "number($p,$s)" );
 		registerColumnType( Types.DECIMAL, "number($p,$s)" );
 		registerColumnType( Types.BLOB, "blob" );
 		registerColumnType( Types.CLOB, "clob" );
 
 		// Oracle driver reports to support getGeneratedKeys(), but they only
 		// support the version taking an array of the names of the columns to
 		// be returned (via its RETURNING clause).  No other driver seems to
 		// support this overloaded version.
 		getDefaultProperties().setProperty( Environment.USE_GET_GENERATED_KEYS, "false" );
 		getDefaultProperties().setProperty( Environment.USE_STREAMS_FOR_BINARY, "true" );
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "sign", new StandardSQLFunction( "sign", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "acos", new StandardSQLFunction( "acos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "asin", new StandardSQLFunction( "asin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan", new StandardSQLFunction( "atan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cos", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cosh", new StandardSQLFunction( "cosh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "exp", new StandardSQLFunction( "exp", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "ln", new StandardSQLFunction( "ln", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sin", new StandardSQLFunction( "sin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sinh", new StandardSQLFunction( "sinh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "stddev", new StandardSQLFunction( "stddev", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sqrt", new StandardSQLFunction( "sqrt", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tan", new StandardSQLFunction( "tan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tanh", new StandardSQLFunction( "tanh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "variance", new StandardSQLFunction( "variance", StandardBasicTypes.DOUBLE ) );
 
 		registerFunction( "round", new StandardSQLFunction( "round" ) );
 		registerFunction( "trunc", new StandardSQLFunction( "trunc" ) );
 		registerFunction( "ceil", new StandardSQLFunction( "ceil" ) );
 		registerFunction( "floor", new StandardSQLFunction( "floor" ) );
 
 		registerFunction( "chr", new StandardSQLFunction( "chr", StandardBasicTypes.CHARACTER ) );
 		registerFunction( "initcap", new StandardSQLFunction( "initcap" ) );
 		registerFunction( "lower", new StandardSQLFunction( "lower" ) );
 		registerFunction( "ltrim", new StandardSQLFunction( "ltrim" ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim" ) );
 		registerFunction( "soundex", new StandardSQLFunction( "soundex" ) );
 		registerFunction( "upper", new StandardSQLFunction( "upper" ) );
 		registerFunction( "ascii", new StandardSQLFunction( "ascii", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "to_char", new StandardSQLFunction( "to_char", StandardBasicTypes.STRING ) );
 		registerFunction( "to_date", new StandardSQLFunction( "to_date", StandardBasicTypes.TIMESTAMP ) );
 
 		registerFunction( "current_date", new NoArgSQLFunction( "current_date", StandardBasicTypes.DATE, false ) );
 		registerFunction( "current_time", new NoArgSQLFunction( "current_timestamp", StandardBasicTypes.TIME, false ) );
 		registerFunction(
 				"current_timestamp", new NoArgSQLFunction(
 				"current_timestamp",
 				StandardBasicTypes.TIMESTAMP,
 				false
 		)
 		);
 
 		registerFunction( "last_day", new StandardSQLFunction( "last_day", StandardBasicTypes.DATE ) );
 		registerFunction( "sysdate", new NoArgSQLFunction( "sysdate", StandardBasicTypes.DATE, false ) );
 		registerFunction( "systimestamp", new NoArgSQLFunction( "systimestamp", StandardBasicTypes.TIMESTAMP, false ) );
 		registerFunction( "uid", new NoArgSQLFunction( "uid", StandardBasicTypes.INTEGER, false ) );
 		registerFunction( "user", new NoArgSQLFunction( "user", StandardBasicTypes.STRING, false ) );
 
 		registerFunction( "rowid", new NoArgSQLFunction( "rowid", StandardBasicTypes.LONG, false ) );
 		registerFunction( "rownum", new NoArgSQLFunction( "rownum", StandardBasicTypes.LONG, false ) );
 
 		// Multi-param string dialect functions...
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "", "||", "" ) );
 		registerFunction( "instr", new StandardSQLFunction( "instr", StandardBasicTypes.INTEGER ) );
 		registerFunction( "instrb", new StandardSQLFunction( "instrb", StandardBasicTypes.INTEGER ) );
 		registerFunction( "lpad", new StandardSQLFunction( "lpad", StandardBasicTypes.STRING ) );
 		registerFunction( "replace", new StandardSQLFunction( "replace", StandardBasicTypes.STRING ) );
 		registerFunction( "rpad", new StandardSQLFunction( "rpad", StandardBasicTypes.STRING ) );
 		registerFunction( "substr", new StandardSQLFunction( "substr", StandardBasicTypes.STRING ) );
 		registerFunction( "substrb", new StandardSQLFunction( "substrb", StandardBasicTypes.STRING ) );
 		registerFunction( "translate", new StandardSQLFunction( "translate", StandardBasicTypes.STRING ) );
 
 		registerFunction( "substring", new StandardSQLFunction( "substr", StandardBasicTypes.STRING ) );
 		registerFunction( "locate", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "instr(?2,?1)" ) );
 		registerFunction( "bit_length", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "vsize(?1)*8" ) );
 		registerFunction( "coalesce", new NvlFunction() );
 
 		// Multi-param numeric dialect functions...
 		registerFunction( "atan2", new StandardSQLFunction( "atan2", StandardBasicTypes.FLOAT ) );
 		registerFunction( "log", new StandardSQLFunction( "log", StandardBasicTypes.INTEGER ) );
 		registerFunction( "mod", new StandardSQLFunction( "mod", StandardBasicTypes.INTEGER ) );
 		registerFunction( "nvl", new StandardSQLFunction( "nvl" ) );
 		registerFunction( "nvl2", new StandardSQLFunction( "nvl2" ) );
 		registerFunction( "power", new StandardSQLFunction( "power", StandardBasicTypes.FLOAT ) );
 
 		// Multi-param date dialect functions...
 		registerFunction( "add_months", new StandardSQLFunction( "add_months", StandardBasicTypes.DATE ) );
 		registerFunction( "months_between", new StandardSQLFunction( "months_between", StandardBasicTypes.FLOAT ) );
 		registerFunction( "next_day", new StandardSQLFunction( "next_day", StandardBasicTypes.DATE ) );
 
 		registerFunction( "str", new StandardSQLFunction( "to_char", StandardBasicTypes.STRING ) );
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from dual";
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		//starts with 1, implicitly
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getCascadeConstraintsString() {
 		return " cascade constraints";
 	}
 
 	@Override
 	public boolean dropConstraints() {
 		return false;
 	}
 
 	@Override
 	public String getForUpdateNowaitString() {
 		return " for update nowait";
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 
 		sql = sql.trim();
 		boolean isForUpdate = false;
-		if ( sql.toLowerCase().endsWith( " for update" ) ) {
+		if ( sql.toLowerCase(Locale.ROOT).endsWith( " for update" ) ) {
 			sql = sql.substring( 0, sql.length() - 11 );
 			isForUpdate = true;
 		}
 
 		final StringBuilder pagingSelect = new StringBuilder( sql.length() + 100 );
 		if ( hasOffset ) {
 			pagingSelect.append( "select * from ( select row_.*, rownum rownum_ from ( " );
 		}
 		else {
 			pagingSelect.append( "select * from ( " );
 		}
 		pagingSelect.append( sql );
 		if ( hasOffset ) {
 			pagingSelect.append( " ) row_ where rownum <= ?) where rownum_ > ?" );
 		}
 		else {
 			pagingSelect.append( " ) where rownum <= ?" );
 		}
 
 		if ( isForUpdate ) {
 			pagingSelect.append( " for update" );
 		}
 
 		return pagingSelect.toString();
 	}
 
 	@Override
 	public String getForUpdateString(String aliases) {
 		return getForUpdateString() + " of " + aliases;
 	}
 
 	@Override
 	public String getForUpdateNowaitString(String aliases) {
 		return getForUpdateString() + " of " + aliases + " nowait";
 	}
 
 	@Override
 	public boolean bindLimitParametersInReverseOrder() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean forUpdateOfColumns() {
 		return true;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select sequence_name from user_sequences";
 	}
 
 	@Override
 	public String getSelectGUIDString() {
 		return "select rawtohex(sys_guid()) from dual";
 	}
 
 	@Override
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 	private static final ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 		@Override
 		public String extractConstraintName(SQLException sqle) {
 			final int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 			if ( errorCode == 1 || errorCode == 2291 || errorCode == 2292 ) {
 				return extractUsingTemplate( "constraint (", ") violated", sqle.getMessage() );
 			}
 			else if ( errorCode == 1400 ) {
 				// simple nullability constraint
 				return null;
 			}
 			else {
 				return null;
 			}
 		}
 	};
 
 	@Override
 	public int registerResultSetOutParameter(java.sql.CallableStatement statement, int col) throws SQLException {
 		//	register the type of the out param - an Oracle specific type
 		statement.registerOutParameter( col, OracleTypesHelper.INSTANCE.getOracleCursorTypeSqlType() );
 		col++;
 		return col;
 	}
 
 	@Override
 	public ResultSet getResultSet(CallableStatement ps) throws SQLException {
 		ps.execute();
 		return (ResultSet) ps.getObject( 1 );
 	}
 
 	@Override
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsCommentOn() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsTemporaryTables() {
 		return true;
 	}
 
 	@Override
 	public String generateTemporaryTableName(String baseTableName) {
 		final String name = super.generateTemporaryTableName( baseTableName );
 		return name.length() > 30 ? name.substring( 1, 30 ) : name;
 	}
 
 	@Override
 	public String getCreateTemporaryTableString() {
 		return "create global temporary table";
 	}
 
 	@Override
 	public String getCreateTemporaryTablePostfix() {
 		return "on commit delete rows";
 	}
 
 	@Override
 	public boolean dropTemporaryTableAfterUse() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select systimestamp from dual";
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsExistsInSelect() {
 		return false;
 	}
 
 	@Override
 	public int getInExpressionCountLimit() {
 		return PARAM_LIST_SIZE_LIMIT;
 	}
 
 	@Override
 	public String getNotExpression(String expression) {
 		return "not (" + expression + ")";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9iDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9iDialect.java
index 6fe8cb271d..8890ff76cb 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9iDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9iDialect.java
@@ -1,217 +1,218 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.LockOptions;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.sql.ANSICaseFragment;
 import org.hibernate.sql.CaseFragment;
 
 /**
  * A dialect for Oracle 9i databases.
  * <p/>
  * Specifies to not use "ANSI join syntax" because 9i does not seem to properly handle it in all cases.
  *
  * @author Steve Ebersole
  */
 public class Oracle9iDialect extends Oracle8iDialect {
 
 	private static final AbstractLimitHandler LIMIT_HANDLER = new AbstractLimitHandler() {
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final boolean hasOffset = LimitHelper.hasFirstRow( selection );
 			sql = sql.trim();
 			String forUpdateClause = null;
 			boolean isForUpdate = false;
-			final int forUpdateIndex = sql.toLowerCase().lastIndexOf( "for update" );
+			final int forUpdateIndex = sql.toLowerCase(Locale.ROOT).lastIndexOf( "for update" );
 			if (forUpdateIndex > -1) {
 				// save 'for update ...' and then remove it
 				forUpdateClause = sql.substring( forUpdateIndex );
 				sql = sql.substring( 0, forUpdateIndex - 1 );
 				isForUpdate = true;
 			}
 
 			final StringBuilder pagingSelect = new StringBuilder( sql.length() + 100 );
 			if (hasOffset) {
 				pagingSelect.append( "select * from ( select row_.*, rownum rownum_ from ( " );
 			}
 			else {
 				pagingSelect.append( "select * from ( " );
 			}
 			pagingSelect.append( sql );
 			if (hasOffset) {
 				pagingSelect.append( " ) row_ where rownum <= ?) where rownum_ > ?" );
 			}
 			else {
 				pagingSelect.append( " ) where rownum <= ?" );
 			}
 
 			if (isForUpdate) {
 				pagingSelect.append( " " );
 				pagingSelect.append( forUpdateClause );
 			}
 
 			return pagingSelect.toString();
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return true;
 		}
 
 		@Override
 		public boolean bindLimitParametersInReverseOrder() {
 			return true;
 		}
 
 		@Override
 		public boolean useMaxForLimit() {
 			return true;
 		}
 	};
 
 	@Override
 	protected void registerCharacterTypeMappings() {
 		registerColumnType( Types.CHAR, "char(1 char)" );
 		registerColumnType( Types.VARCHAR, 4000, "varchar2($l char)" );
 		registerColumnType( Types.VARCHAR, "long" );
 	}
 
 	@Override
 	protected void registerDateTimeTypeMappings() {
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "date" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 	}
 
 	@Override
 	public CaseFragment createCaseFragment() {
 		// Oracle did add support for ANSI CASE statements in 9i
 		return new ANSICaseFragment();
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return LIMIT_HANDLER;
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 		sql = sql.trim();
 		String forUpdateClause = null;
 		boolean isForUpdate = false;
-		final int forUpdateIndex = sql.toLowerCase().lastIndexOf( "for update") ;
+		final int forUpdateIndex = sql.toLowerCase(Locale.ROOT).lastIndexOf( "for update") ;
 		if ( forUpdateIndex > -1 ) {
 			// save 'for update ...' and then remove it
 			forUpdateClause = sql.substring( forUpdateIndex );
 			sql = sql.substring( 0, forUpdateIndex-1 );
 			isForUpdate = true;
 		}
 
 		final StringBuilder pagingSelect = new StringBuilder( sql.length() + 100 );
 		if (hasOffset) {
 			pagingSelect.append( "select * from ( select row_.*, rownum rownum_ from ( " );
 		}
 		else {
 			pagingSelect.append( "select * from ( " );
 		}
 		pagingSelect.append( sql );
 		if (hasOffset) {
 			pagingSelect.append( " ) row_ where rownum <= ?) where rownum_ > ?" );
 		}
 		else {
 			pagingSelect.append( " ) where rownum <= ?" );
 		}
 
 		if ( isForUpdate ) {
 			pagingSelect.append( " " );
 			pagingSelect.append( forUpdateClause );
 		}
 
 		return pagingSelect.toString();
 	}
 
 	@Override
 	public String getSelectClauseNullString(int sqlType) {
 		return getBasicSelectClauseNullString( sqlType );
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select systimestamp from dual";
 	}
 
 	@Override
 	public String getCurrentTimestampSQLFunctionName() {
 		// the standard SQL function name is current_timestamp...
 		return "current_timestamp";
 	}
 
 	@Override
 	public String getForUpdateString() {
 		return " for update";
 	}
 
 	@Override
 	public String getWriteLockString(int timeout) {
 		if ( timeout == LockOptions.NO_WAIT ) {
 			return " for update nowait";
 		}
 		else if ( timeout > 0 ) {
 			// convert from milliseconds to seconds
 			final float seconds = timeout / 1000.0f;
 			timeout = Math.round( seconds );
 			return " for update wait " + timeout;
 		}
 		else {
 			return " for update";
 		}
 	}
 
 	@Override
 	public String getReadLockString(int timeout) {
 		return getWriteLockString( timeout );
 	}
 
 	/**
 	 * HHH-4907, I don't know if oracle 8 supports this syntax, so I'd think it is better add this 
 	 * method here. Reopen this issue if you found/know 8 supports it.
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public boolean supportsRowValueConstructorSyntaxInInList() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsTupleDistinctCounts() {
 		return false;
 	}	
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/OracleDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/OracleDialect.java
index 639febfaf1..16779c4513 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/OracleDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/OracleDialect.java
@@ -1,129 +1,130 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.DecodeCaseFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.OracleJoinFragment;
 
 import org.jboss.logging.Logger;
 
 /**
  * An SQL dialect for Oracle, compatible with Oracle 8.
  *
  * @deprecated Use Oracle8iDialect instead.
  * @author Gavin King
  */
 @SuppressWarnings("deprecation")
 @Deprecated
 public class OracleDialect extends Oracle9Dialect {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			OracleDialect.class.getName()
 	);
 
 	/**
 	 * Constructs a (DEPRECATED) Oracle9Dialect
 	 */
 	public OracleDialect() {
 		super();
 		LOG.deprecatedOracleDialect();
 		// Oracle8 and previous define only a "DATE" type which
 		//      is used to represent all aspects of date/time
 		registerColumnType( Types.TIMESTAMP, "date" );
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.VARCHAR, 4000, "varchar2($l)" );
 	}
 
 	@Override
 	public JoinFragment createOuterJoinFragment() {
 		return new OracleJoinFragment();
 	}
 
 	@Override
 	public CaseFragment createCaseFragment() {
 		return new DecodeCaseFragment();
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 
 		sql = sql.trim();
 		boolean isForUpdate = false;
-		if ( sql.toLowerCase().endsWith( " for update" ) ) {
+		if ( sql.toLowerCase(Locale.ROOT).endsWith( " for update" ) ) {
 			sql = sql.substring( 0, sql.length()-11 );
 			isForUpdate = true;
 		}
 
 		final StringBuilder pagingSelect = new StringBuilder( sql.length()+100 );
 		if (hasOffset) {
 			pagingSelect.append( "select * from ( select row_.*, rownum rownum_ from ( " );
 		}
 		else {
 			pagingSelect.append( "select * from ( " );
 		}
 		pagingSelect.append( sql );
 		if (hasOffset) {
 			pagingSelect.append( " ) row_ ) where rownum_ <= ? and rownum_ > ?" );
 		}
 		else {
 			pagingSelect.append( " ) where rownum <= ?" );
 		}
 
 		if ( isForUpdate ) {
 			pagingSelect.append( " for update" );
 		}
 
 		return pagingSelect.toString();
 	}
 
 	@Override
 	public String getSelectClauseNullString(int sqlType) {
 		switch(sqlType) {
 			case Types.VARCHAR:
 			case Types.CHAR:
 				return "to_char(null)";
 			case Types.DATE:
 			case Types.TIMESTAMP:
 			case Types.TIME:
 				return "to_date(null)";
 			default:
 				return "to_number(null)";
 		}
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select sysdate from dual";
 	}
 
 	@Override
 	public String getCurrentTimestampSQLFunctionName() {
 		return "sysdate";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/SQLServerDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/SQLServerDialect.java
index 864055149e..d0d8a0eee5 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/SQLServerDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/SQLServerDialect.java
@@ -1,223 +1,224 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.Types;
+import java.util.Locale;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.dialect.function.AnsiTrimEmulationFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.TopLimitHandler;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.descriptor.sql.SmallIntTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 /**
  * A dialect for Microsoft SQL Server 2000
  *
  * @author Gavin King
  */
 @SuppressWarnings("deprecation")
 public class SQLServerDialect extends AbstractTransactSQLDialect {
 	private static final int PARAM_LIST_SIZE_LIMIT = 2100;
 
 	private final LimitHandler limitHandler;
 
 	/**
 	 * Constructs a SQLServerDialect
 	 */
 	public SQLServerDialect() {
 		registerColumnType( Types.VARBINARY, "image" );
 		registerColumnType( Types.VARBINARY, 8000, "varbinary($l)" );
 		registerColumnType( Types.LONGVARBINARY, "image" );
 		registerColumnType( Types.LONGVARCHAR, "text" );
 		registerColumnType( Types.BOOLEAN, "bit" );
 
 		registerFunction( "second", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "datepart(second, ?1)" ) );
 		registerFunction( "minute", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "datepart(minute, ?1)" ) );
 		registerFunction( "hour", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "datepart(hour, ?1)" ) );
 		registerFunction( "locate", new StandardSQLFunction( "charindex", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "extract", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "datepart(?1, ?3)" ) );
 		registerFunction( "mod", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "?1 % ?2" ) );
 		registerFunction( "bit_length", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "datalength(?1) * 8" ) );
 
 		registerFunction( "trim", new AnsiTrimEmulationFunction() );
 
 		registerKeyword( "top" );
 
 		this.limitHandler = new TopLimitHandler( false, false );
 	}
 
 	@Override
 	public String getNoColumnsInsertString() {
 		return "default values";
 	}
 
 	static int getAfterSelectInsertPoint(String sql) {
-		final int selectIndex = sql.toLowerCase().indexOf( "select" );
-		final int selectDistinctIndex = sql.toLowerCase().indexOf( "select distinct" );
+		final int selectIndex = sql.toLowerCase(Locale.ROOT).indexOf( "select" );
+		final int selectDistinctIndex = sql.toLowerCase(Locale.ROOT).indexOf( "select distinct" );
 		return selectIndex + (selectDistinctIndex == selectIndex ? 15 : 6);
 	}
 
 	@Override
 	public String getLimitString(String querySelect, int offset, int limit) {
 		if ( offset > 0 ) {
 			throw new UnsupportedOperationException( "query result offset is not supported" );
 		}
 		return new StringBuilder( querySelect.length() + 8 )
 				.append( querySelect )
 				.insert( getAfterSelectInsertPoint( querySelect ), " top " + limit )
 				.toString();
 	}
 
 	/**
 	 * Use <tt>insert table(...) values(...) select SCOPE_IDENTITY()</tt>
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public String appendIdentitySelectToInsert(String insertSQL) {
 		return insertSQL + " select scope_identity()";
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return limitHandler;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimitOffset() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsVariableLimit() {
 		return false;
 	}
 
 	@Override
 	public char closeQuote() {
 		return ']';
 	}
 
 	@Override
 	public char openQuote() {
 		return '[';
 	}
 
 	@Override
 	public String appendLockHint(LockOptions lockOptions, String tableName) {
 		final LockMode mode = lockOptions.getLockMode();
 		switch ( mode ) {
 			case UPGRADE:
 			case UPGRADE_NOWAIT:
 			case PESSIMISTIC_WRITE:
 			case WRITE:
 				return tableName + " with (updlock, rowlock)";
 			case PESSIMISTIC_READ:
 				return tableName + " with (holdlock, rowlock)";
 			case UPGRADE_SKIPLOCKED:
 				return tableName + " with (updlock, rowlock, readpast)";
 			default:
 				return tableName;
 		}
 	}
 
 
 	/**
 	 * The current_timestamp is more accurate, but only known to be supported in SQL Server 7.0 and later and
 	 * Sybase not known to support it at all
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select current_timestamp";
 	}
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean areStringComparisonsCaseInsensitive() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsResultSetPositionQueryMethodsOnForwardOnlyCursor() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsCircularCascadeDeleteConstraints() {
 		// SQL Server (at least up through 2005) does not support defining
 		// cascade delete constraints which can circle back to the mutating
 		// table
 		return false;
 	}
 
 	@Override
 	public boolean supportsLobValueChangePropogation() {
 		// note: at least my local SQL Server 2005 Express shows this not working...
 		return false;
 	}
 
 	@Override
 	public boolean doesReadCommittedCauseWritersToBlockReaders() {
 		// here assume SQLServer2005 using snapshot isolation, which does not have this problem
 		return false;
 	}
 
 	@Override
 	public boolean doesRepeatableReadCauseReadersToBlockWriters() {
 		// here assume SQLServer2005 using snapshot isolation, which does not have this problem
 		return false;
 	}
 
 	@Override
 	protected SqlTypeDescriptor getSqlTypeDescriptorOverride(int sqlCode) {
 		return sqlCode == Types.TINYINT ?
 				SmallIntTypeDescriptor.INSTANCE :
 				super.getSqlTypeDescriptorOverride( sqlCode );
 	}
 
 	@Override
 	public int getInExpressionCountLimit() {
 		return PARAM_LIST_SIZE_LIMIT;
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/function/SQLFunctionRegistry.java b/hibernate-core/src/main/java/org/hibernate/dialect/function/SQLFunctionRegistry.java
index 8040427a18..134a36865d 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/function/SQLFunctionRegistry.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/function/SQLFunctionRegistry.java
@@ -1,82 +1,83 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.function;
 
 import java.util.HashMap;
+import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.dialect.Dialect;
 
 /**
  * Defines a registry for SQLFunction instances
  *
  * @author Steve Ebersole
  */
 public class SQLFunctionRegistry {
 	private final Dialect dialect;
 	private final Map<String, SQLFunction> userFunctions;
 
 	/**
 	 * Constructs a SQLFunctionRegistry
 	 *
 	 * @param dialect The dialect
 	 * @param userFunctions Any application-supplied function definitions
 	 */
 	public SQLFunctionRegistry(Dialect dialect, Map<String, SQLFunction> userFunctions) {
 		this.dialect = dialect;
 		this.userFunctions = new HashMap<String, SQLFunction>();
 		if ( userFunctions != null ) {
 			this.userFunctions.putAll( userFunctions );
 		}
 	}
 
 	/**
 	 * Find a SQLFunction by name
 	 *
 	 * @param functionName The name of the function to locate
 	 *
 	 * @return The located function, maye return {@code null}
 	 */
 	public SQLFunction findSQLFunction(String functionName) {
-		final String name = functionName.toLowerCase();
+		final String name = functionName.toLowerCase(Locale.ROOT);
 		final SQLFunction userFunction = userFunctions.get( name );
 		return userFunction != null
 				? userFunction
 				: dialect.getFunctions().get( name );
 	}
 
 	/**
 	 * Does this registry contain the named function
 	 *
 	 * @param functionName The name of the function to attempt to locate
 	 *
 	 * @return {@code true} if the registry contained that function
 	 */
 	@SuppressWarnings("UnusedDeclaration")
 	public boolean hasFunction(String functionName) {
-		final String name = functionName.toLowerCase();
+		final String name = functionName.toLowerCase(Locale.ROOT);
 		return userFunctions.containsKey( name ) || dialect.getFunctions().containsKey( name );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/pagination/FirstLimitHandler.java b/hibernate-core/src/main/java/org/hibernate/dialect/pagination/FirstLimitHandler.java
index 86ae606025..5d0d11081a 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/pagination/FirstLimitHandler.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/pagination/FirstLimitHandler.java
@@ -1,68 +1,69 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2014 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.dialect.pagination;
 
+import java.util.Locale;
 import org.hibernate.engine.spi.RowSelection;
 
 
 /**
  * @author Brett Meyer
  */
 public class FirstLimitHandler extends AbstractLimitHandler {
 
 	public static final FirstLimitHandler INSTANCE = new FirstLimitHandler();
 
 	private FirstLimitHandler() {
 		// NOP
 	}
 	
 	@Override
 	public String processSql(String sql, RowSelection selection) {
 		final boolean hasOffset = LimitHelper.hasFirstRow( selection );
 		if ( hasOffset ) {
 			throw new UnsupportedOperationException( "query result offset is not supported" );
 		}
 		return new StringBuilder( sql.length() + 16 )
 				.append( sql )
-				.insert( sql.toLowerCase().indexOf( "select" ) + 6, " first ?" )
+				.insert( sql.toLowerCase(Locale.ROOT).indexOf( "select" ) + 6, " first ?" )
 				.toString();
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimitOffset() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsVariableLimit() {
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/pagination/SQLServer2005LimitHandler.java b/hibernate-core/src/main/java/org/hibernate/dialect/pagination/SQLServer2005LimitHandler.java
index bfd05e9c81..9c31059119 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/pagination/SQLServer2005LimitHandler.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/pagination/SQLServer2005LimitHandler.java
@@ -1,322 +1,323 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.pagination;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Locale;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * LIMIT clause handler compatible with SQL Server 2005 and later.
  *
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class SQLServer2005LimitHandler extends AbstractLimitHandler {
 	private static final String SELECT = "select";
 	private static final String SELECT_WITH_SPACE = SELECT + ' ';
 	private static final String FROM = "from";
 	private static final String DISTINCT = "distinct";
 	private static final String ORDER_BY = "order by";
 
 	private static final Pattern ALIAS_PATTERN = Pattern.compile( "(?i)\\sas\\s(.)+$" );
 
 	// Flag indicating whether TOP(?) expression has been added to the original query.
 	private boolean topAdded;
 
 	/**
 	 * Constructs a SQLServer2005LimitHandler
 	 */
 	public SQLServer2005LimitHandler() {
 		// NOP
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimitOffset() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsVariableLimit() {
 		return true;
 	}
 
 	@Override
 	public int convertToFirstRowValue(int zeroBasedFirstResult) {
 		// Our dialect paginated results aren't zero based. The first row should get the number 1 and so on
 		return zeroBasedFirstResult + 1;
 	}
 
 	/**
 	 * Add a LIMIT clause to the given SQL SELECT (HHH-2655: ROW_NUMBER for Paging)
 	 *
 	 * The LIMIT SQL will look like:
 	 *
 	 * <pre>
 	 * WITH query AS (
 	 *   SELECT inner_query.*
 	 *        , ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__
 	 *     FROM ( original_query_with_top_if_order_by_present_and_all_aliased_columns ) inner_query
 	 * )
 	 * SELECT alias_list FROM query WHERE __hibernate_row_nr__ >= offset AND __hibernate_row_nr__ < offset + last
 	 * </pre>
 	 *
 	 * When offset equals {@literal 0}, only <code>TOP(?)</code> expression is added to the original query.
 	 *
 	 * @return A new SQL statement with the LIMIT clause applied.
 	 */
 	@Override
 	public String processSql(String sql, RowSelection selection) {
 		final StringBuilder sb = new StringBuilder( sql );
 		if ( sb.charAt( sb.length() - 1 ) == ';' ) {
 			sb.setLength( sb.length() - 1 );
 		}
 
 		if ( LimitHelper.hasFirstRow( selection ) ) {
 			final String selectClause = fillAliasInSelectClause( sb );
 
 			final int orderByIndex = shallowIndexOfWord( sb, ORDER_BY, 0 );
 			if ( orderByIndex > 0 ) {
 				// ORDER BY requires using TOP.
 				addTopExpression( sb );
 			}
 
 			encloseWithOuterQuery( sb );
 
 			// Wrap the query within a with statement:
 			sb.insert( 0, "WITH query AS (" ).append( ") SELECT " ).append( selectClause ).append( " FROM query " );
 			sb.append( "WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?" );
 		}
 		else {
 			addTopExpression( sb );
 		}
 
 		return sb.toString();
 	}
 
 	@Override
 	public int bindLimitParametersAtStartOfQuery(RowSelection selection, PreparedStatement statement, int index) throws SQLException {
 		if ( topAdded ) {
 			// Binding TOP(?)
 			statement.setInt( index, getMaxOrLimit( selection ) - 1 );
 			return 1;
 		}
 		return 0;
 	}
 
 	@Override
 	public int bindLimitParametersAtEndOfQuery(RowSelection selection, PreparedStatement statement, int index) throws SQLException {
 		return LimitHelper.hasFirstRow( selection ) ? super.bindLimitParametersAtEndOfQuery( selection, statement, index ) : 0;
 	}
 
 	/**
 	 * Adds missing aliases in provided SELECT clause and returns coma-separated list of them.
 	 * If query takes advantage of expressions like {@literal *} or {@literal {table}.*} inside SELECT clause,
 	 * method returns {@literal *}.
 	 *
 	 * @param sb SQL query.
 	 *
 	 * @return List of aliases separated with comas or {@literal *}.
 	 */
 	protected String fillAliasInSelectClause(StringBuilder sb) {
 		final List<String> aliases = new LinkedList<String>();
 		final int startPos = shallowIndexOf( sb, SELECT_WITH_SPACE, 0 );
 		int endPos = shallowIndexOfWord( sb, FROM, startPos );
 		int nextComa = startPos;
 		int prevComa = startPos;
 		int unique = 0;
 		boolean selectsMultipleColumns = false;
 
 		while ( nextComa != -1 ) {
 			prevComa = nextComa;
 			nextComa = shallowIndexOf( sb, ",", nextComa );
 			if ( nextComa > endPos ) {
 				break;
 			}
 			if ( nextComa != -1 ) {
 				final String expression = sb.substring( prevComa, nextComa );
 				if ( selectsMultipleColumns( expression ) ) {
 					selectsMultipleColumns = true;
 				}
 				else {
 					String alias = getAlias( expression );
 					if ( alias == null ) {
 						// Inserting alias. It is unlikely that we would have to add alias, but just in case.
 						alias = StringHelper.generateAlias( "page", unique );
 						sb.insert( nextComa, " as " + alias );
 						final int aliasExprLength = ( " as " + alias ).length();
 						++unique;
 						nextComa += aliasExprLength;
 						endPos += aliasExprLength;
 					}
 					aliases.add( alias );
 				}
 				++nextComa;
 			}
 		}
 		// Processing last column.
 		// Refreshing end position, because we might have inserted new alias.
 		endPos = shallowIndexOfWord( sb, FROM, startPos );
 		final String expression = sb.substring( prevComa, endPos );
 		if ( selectsMultipleColumns( expression ) ) {
 			selectsMultipleColumns = true;
 		}
 		else {
 			String alias = getAlias( expression );
 			if ( alias == null ) {
 				// Inserting alias. It is unlikely that we would have to add alias, but just in case.
 				alias = StringHelper.generateAlias( "page", unique );
 				sb.insert( endPos - 1, " as " + alias );
 			}
 			aliases.add( alias );
 		}
 
 		// In case of '*' or '{table}.*' expressions adding an alias breaks SQL syntax, returning '*'.
 		return selectsMultipleColumns ? "*" : StringHelper.join( ", ", aliases.iterator() );
 	}
 
 	/**
 	 * @param expression Select expression.
 	 *
 	 * @return {@code true} when expression selects multiple columns, {@code false} otherwise.
 	 */
 	private boolean selectsMultipleColumns(String expression) {
 		final String lastExpr = expression.trim().replaceFirst( "(?i)(.)*\\s", "" );
 		return "*".equals( lastExpr ) || lastExpr.endsWith( ".*" );
 	}
 
 	/**
 	 * Returns alias of provided single column selection or {@code null} if not found.
 	 * Alias should be preceded with {@code AS} keyword.
 	 *
 	 * @param expression Single column select expression.
 	 *
 	 * @return Column alias.
 	 */
 	private String getAlias(String expression) {
 		final Matcher matcher = ALIAS_PATTERN.matcher( expression );
 		if ( matcher.find() ) {
 			// Taking advantage of Java regular expressions greedy behavior while extracting the last AS keyword.
 			// Note that AS keyword can appear in CAST operator, e.g. 'cast(tab1.col1 as varchar(255)) as col1'.
 			return matcher.group( 0 ).replaceFirst( "(?i)(.)*\\sas\\s", "" ).trim();
 		}
 		return null;
 	}
 
 	/**
 	 * Encloses original SQL statement with outer query that provides {@literal __hibernate_row_nr__} column.
 	 *
 	 * @param sql SQL query.
 	 */
 	protected void encloseWithOuterQuery(StringBuilder sql) {
 		sql.insert( 0, "SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " );
 		sql.append( " ) inner_query " );
 	}
 
 	/**
 	 * Adds {@code TOP} expression. Parameter value is bind in
 	 * {@link #bindLimitParametersAtStartOfQuery(RowSelection, PreparedStatement, int)} method.
 	 *
 	 * @param sql SQL query.
 	 */
 	protected void addTopExpression(StringBuilder sql) {
 		final int distinctStartPos = shallowIndexOfWord( sql, DISTINCT, 0 );
 		if ( distinctStartPos > 0 ) {
 			// Place TOP after DISTINCT.
 			sql.insert( distinctStartPos + DISTINCT.length(), " TOP(?)" );
 		}
 		else {
 			final int selectStartPos = shallowIndexOf( sql, SELECT_WITH_SPACE, 0 );
 			// Place TOP after SELECT.
 			sql.insert( selectStartPos + SELECT.length(), " TOP(?)" );
 		}
 		topAdded = true;
 	}
 
 	/**
 	 * Returns index of the first case-insensitive match of search term surrounded by spaces
 	 * that is not enclosed in parentheses.
 	 *
 	 * @param sb String to search.
 	 * @param search Search term.
 	 * @param fromIndex The index from which to start the search.
 	 *
 	 * @return Position of the first match, or {@literal -1} if not found.
 	 */
 	private static int shallowIndexOfWord(final StringBuilder sb, final String search, int fromIndex) {
 		final int index = shallowIndexOf( sb, ' ' + search + ' ', fromIndex );
 		// In case of match adding one because of space placed in front of search term.
 		return index != -1 ? ( index + 1 ) : -1;
 	}
 
 	/**
 	 * Returns index of the first case-insensitive match of search term that is not enclosed in parentheses.
 	 *
 	 * @param sb String to search.
 	 * @param search Search term.
 	 * @param fromIndex The index from which to start the search.
 	 *
 	 * @return Position of the first match, or {@literal -1} if not found.
 	 */
 	private static int shallowIndexOf(StringBuilder sb, String search, int fromIndex) {
 		// case-insensitive match
-		final String lowercase = sb.toString().toLowerCase();
+		final String lowercase = sb.toString().toLowerCase(Locale.ROOT);
 		final int len = lowercase.length();
 		final int searchlen = search.length();
 		int pos = -1;
 		int depth = 0;
 		int cur = fromIndex;
 		do {
 			pos = lowercase.indexOf( search, cur );
 			if ( pos != -1 ) {
 				for ( int iter = cur; iter < pos; iter++ ) {
 					final char c = sb.charAt( iter );
 					if ( c == '(' ) {
 						depth = depth + 1;
 					}
 					else if ( c == ')' ) {
 						depth = depth - 1;
 					}
 				}
 				cur = pos + searchlen;
 			}
 		} while ( cur < len && depth != 0 && pos != -1 );
 		return depth == 0 ? pos : -1;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/pagination/TopLimitHandler.java b/hibernate-core/src/main/java/org/hibernate/dialect/pagination/TopLimitHandler.java
index c63ed9de31..c28a6f9c04 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/pagination/TopLimitHandler.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/pagination/TopLimitHandler.java
@@ -1,74 +1,75 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2014 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.dialect.pagination;
 
+import java.util.Locale;
 import org.hibernate.engine.spi.RowSelection;
 
 
 /**
  * @author Brett Meyer
  */
 public class TopLimitHandler extends AbstractLimitHandler {
 	
 	private final boolean supportsVariableLimit;
 	
 	private final boolean bindLimitParametersFirst;
 
 	public TopLimitHandler(boolean supportsVariableLimit, boolean bindLimitParametersFirst) {
 		this.supportsVariableLimit = supportsVariableLimit;
 		this.bindLimitParametersFirst = bindLimitParametersFirst;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 	
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimitOffset() {
 		return supportsVariableLimit;
 	}
 	
 	public boolean bindLimitParametersFirst() {
 		return bindLimitParametersFirst;
 	}
 
 	@Override
 	public String processSql(String sql, RowSelection selection) {
 		if (LimitHelper.hasFirstRow( selection )) {
 			throw new UnsupportedOperationException( "query result offset is not supported" );
 		}
 
-		final int selectIndex = sql.toLowerCase().indexOf( "select" );
-		final int selectDistinctIndex = sql.toLowerCase().indexOf( "select distinct" );
+		final int selectIndex = sql.toLowerCase(Locale.ROOT).indexOf( "select" );
+		final int selectDistinctIndex = sql.toLowerCase(Locale.ROOT).indexOf( "select distinct" );
 		final int insertionPoint = selectIndex + (selectDistinctIndex == selectIndex ? 15 : 6);
 
 		return new StringBuilder( sql.length() + 8 )
 				.append( sql )
 				.insert( insertionPoint, " TOP ? " )
 				.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/ExtractedDatabaseMetaDataImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/ExtractedDatabaseMetaDataImpl.java
index 04a9294906..d91c0bd50d 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/ExtractedDatabaseMetaDataImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/ExtractedDatabaseMetaDataImpl.java
@@ -1,332 +1,333 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.env.internal;
 
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.LinkedHashSet;
+import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.engine.jdbc.cursor.internal.StandardRefCursorSupport;
 import org.hibernate.engine.jdbc.env.spi.ExtractedDatabaseMetaData;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.env.spi.SQLStateType;
 import org.hibernate.engine.jdbc.spi.TypeInfo;
 
 /**
  * Standard implementation of ExtractedDatabaseMetaData
  *
  * @author Steve Ebersole
  */
 public class ExtractedDatabaseMetaDataImpl implements ExtractedDatabaseMetaData {
 	private final JdbcEnvironment jdbcEnvironment;
 
 	private final String connectionCatalogName;
 	private final String connectionSchemaName;
 
 	private final boolean supportsRefCursors;
 	private final boolean supportsNamedParameters;
 	private final boolean supportsScrollableResults;
 	private final boolean supportsGetGeneratedKeys;
 	private final boolean supportsBatchUpdates;
 	private final boolean supportsDataDefinitionInTransaction;
 	private final boolean doesDataDefinitionCauseTransactionCommit;
 	private final SQLStateType sqlStateType;
 	private final boolean lobLocatorUpdateCopy;
 
 	private final Set<String> extraKeywords;
 	private final LinkedHashSet<TypeInfo> typeInfoSet;
 
 	private ExtractedDatabaseMetaDataImpl(
 			JdbcEnvironment jdbcEnvironment,
 			String connectionCatalogName,
 			String connectionSchemaName,
 			Set<String> extraKeywords,
 			LinkedHashSet<TypeInfo> typeInfoSet,
 			boolean supportsRefCursors,
 			boolean supportsNamedParameters,
 			boolean supportsScrollableResults,
 			boolean supportsGetGeneratedKeys,
 			boolean supportsBatchUpdates,
 			boolean supportsDataDefinitionInTransaction,
 			boolean doesDataDefinitionCauseTransactionCommit,
 			SQLStateType sqlStateType,
 			boolean lobLocatorUpdateCopy) {
 		this.jdbcEnvironment = jdbcEnvironment;
 
 		this.connectionCatalogName = connectionCatalogName;
 		this.connectionSchemaName = connectionSchemaName;
 
 		this.extraKeywords = extraKeywords != null
 				? extraKeywords
 				: Collections.<String>emptySet();
 		this.typeInfoSet = typeInfoSet != null
 				? typeInfoSet
 				: new LinkedHashSet<TypeInfo>();
 
 		this.supportsRefCursors = supportsRefCursors;
 		this.supportsNamedParameters = supportsNamedParameters;
 		this.supportsScrollableResults = supportsScrollableResults;
 		this.supportsGetGeneratedKeys = supportsGetGeneratedKeys;
 		this.supportsBatchUpdates = supportsBatchUpdates;
 		this.supportsDataDefinitionInTransaction = supportsDataDefinitionInTransaction;
 		this.doesDataDefinitionCauseTransactionCommit = doesDataDefinitionCauseTransactionCommit;
 		this.sqlStateType = sqlStateType;
 		this.lobLocatorUpdateCopy = lobLocatorUpdateCopy;
 	}
 
 	@Override
 	public boolean supportsRefCursors() {
 		return supportsRefCursors;
 	}
 
 	@Override
 	public JdbcEnvironment getJdbcEnvironment() {
 		return jdbcEnvironment;
 	}
 
 	@Override
 	public boolean supportsNamedParameters() {
 		return supportsNamedParameters;
 	}
 
 	@Override
 	public boolean supportsScrollableResults() {
 		return supportsScrollableResults;
 	}
 
 	@Override
 	public boolean supportsGetGeneratedKeys() {
 		return supportsGetGeneratedKeys;
 	}
 
 	@Override
 	public boolean supportsBatchUpdates() {
 		return supportsBatchUpdates;
 	}
 
 	@Override
 	public boolean supportsDataDefinitionInTransaction() {
 		return supportsDataDefinitionInTransaction;
 	}
 
 	@Override
 	public boolean doesDataDefinitionCauseTransactionCommit() {
 		return doesDataDefinitionCauseTransactionCommit;
 	}
 
 	@Override
 	public Set<String> getExtraKeywords() {
 		return extraKeywords;
 	}
 
 	@Override
 	public SQLStateType getSqlStateType() {
 		return sqlStateType;
 	}
 
 	@Override
 	public boolean doesLobLocatorUpdateCopy() {
 		return lobLocatorUpdateCopy;
 	}
 
 	@Override
 	public String getConnectionCatalogName() {
 		return connectionCatalogName;
 	}
 
 	@Override
 	public String getConnectionSchemaName() {
 		return connectionSchemaName;
 	}
 
 	@Override
 	public LinkedHashSet<TypeInfo> getTypeInfoSet() {
 		return typeInfoSet;
 	}
 
 	public static class Builder {
 		private final JdbcEnvironment jdbcEnvironment;
 
 		private String connectionSchemaName;
 		private String connectionCatalogName;
 
 		private Set<String> extraKeywords;
 		private LinkedHashSet<TypeInfo> typeInfoSet;
 
 		private boolean supportsRefCursors;
 		private boolean supportsNamedParameters;
 		private boolean supportsScrollableResults;
 		private boolean supportsGetGeneratedKeys;
 		private boolean supportsBatchUpdates;
 		private boolean supportsDataDefinitionInTransaction;
 		private boolean doesDataDefinitionCauseTransactionCommit;
 		private SQLStateType sqlStateType;
 		private boolean lobLocatorUpdateCopy;
 
 		public Builder(JdbcEnvironment jdbcEnvironment) {
 			this.jdbcEnvironment = jdbcEnvironment;
 		}
 
 		public Builder apply(DatabaseMetaData databaseMetaData) throws SQLException {
 			connectionCatalogName = databaseMetaData.getConnection().getCatalog();
 			// NOTE : databaseMetaData.getConnection().getSchema() would require java 1.7 as baseline
 			supportsRefCursors = StandardRefCursorSupport.supportsRefCursors( databaseMetaData );
 			supportsNamedParameters = databaseMetaData.supportsNamedParameters();
 			supportsScrollableResults = databaseMetaData.supportsResultSetType( ResultSet.TYPE_SCROLL_INSENSITIVE );
 			supportsGetGeneratedKeys = databaseMetaData.supportsGetGeneratedKeys();
 			supportsBatchUpdates = databaseMetaData.supportsBatchUpdates();
 			supportsDataDefinitionInTransaction = !databaseMetaData.dataDefinitionIgnoredInTransactions();
 			doesDataDefinitionCauseTransactionCommit = databaseMetaData.dataDefinitionCausesTransactionCommit();
 			extraKeywords = parseKeywords( databaseMetaData.getSQLKeywords() );
 			sqlStateType = SQLStateType.interpretReportedSQLStateType( databaseMetaData.getSQLStateType() );
 			lobLocatorUpdateCopy = databaseMetaData.locatorsUpdateCopy();
 			typeInfoSet = new LinkedHashSet<TypeInfo>();
 			typeInfoSet.addAll( TypeInfo.extractTypeInfo( databaseMetaData ) );
 
 			return this;
 		}
 
 		private Set<String> parseKeywords(String extraKeywordsString) {
 			final Set<String> keywordSet = new HashSet<String>();
 			for ( String keyword : extraKeywordsString.split( "," ) ) {
-				keywordSet.add( keyword.toUpperCase() );
+				keywordSet.add( keyword.toUpperCase(Locale.ROOT) );
 			}
 			return keywordSet;
 		}
 
 		public Builder setConnectionSchemaName(String connectionSchemaName) {
 			this.connectionSchemaName = connectionSchemaName;
 			return this;
 		}
 
 		public Builder setConnectionCatalogName(String connectionCatalogName) {
 			this.connectionCatalogName = connectionCatalogName;
 			return this;
 		}
 
 		public Builder setExtraKeywords(Set<String> extraKeywords) {
 			if ( this.extraKeywords == null ) {
 				this.extraKeywords = extraKeywords;
 			}
 			else {
 				this.extraKeywords.addAll( extraKeywords );
 			}
 			return this;
 		}
 
 		public Builder addExtraKeyword(String keyword) {
 			if ( this.extraKeywords == null ) {
 				this.extraKeywords = new HashSet<String>();
 			}
 			this.extraKeywords.add( keyword );
 			return this;
 		}
 
 		public Builder setTypeInfoSet(LinkedHashSet<TypeInfo> typeInfoSet) {
 			if ( this.typeInfoSet == null ) {
 				this.typeInfoSet = typeInfoSet;
 			}
 			else {
 				this.typeInfoSet.addAll( typeInfoSet );
 			}
 			return this;
 		}
 
 		public Builder addTypeInfo(TypeInfo typeInfo) {
 			if ( this.typeInfoSet == null ) {
 				this.typeInfoSet = new LinkedHashSet<TypeInfo>();
 			}
 			typeInfoSet.add( typeInfo );
 			return this;
 		}
 
 		public Builder setSupportsRefCursors(boolean supportsRefCursors) {
 			this.supportsRefCursors = supportsRefCursors;
 			return this;
 		}
 
 		public Builder setSupportsNamedParameters(boolean supportsNamedParameters) {
 			this.supportsNamedParameters = supportsNamedParameters;
 			return this;
 		}
 
 		public Builder setSupportsScrollableResults(boolean supportsScrollableResults) {
 			this.supportsScrollableResults = supportsScrollableResults;
 			return this;
 		}
 
 		public Builder setSupportsGetGeneratedKeys(boolean supportsGetGeneratedKeys) {
 			this.supportsGetGeneratedKeys = supportsGetGeneratedKeys;
 			return this;
 		}
 
 		public Builder setSupportsBatchUpdates(boolean supportsBatchUpdates) {
 			this.supportsBatchUpdates = supportsBatchUpdates;
 			return this;
 		}
 
 		public Builder setSupportsDataDefinitionInTransaction(boolean supportsDataDefinitionInTransaction) {
 			this.supportsDataDefinitionInTransaction = supportsDataDefinitionInTransaction;
 			return this;
 		}
 
 		public Builder setDoesDataDefinitionCauseTransactionCommit(boolean doesDataDefinitionCauseTransactionCommit) {
 			this.doesDataDefinitionCauseTransactionCommit = doesDataDefinitionCauseTransactionCommit;
 			return this;
 		}
 
 		public Builder setSqlStateType(SQLStateType sqlStateType) {
 			this.sqlStateType = sqlStateType;
 			return this;
 		}
 
 		public Builder setLobLocatorUpdateCopy(boolean lobLocatorUpdateCopy) {
 			this.lobLocatorUpdateCopy = lobLocatorUpdateCopy;
 			return this;
 		}
 
 		public ExtractedDatabaseMetaDataImpl build() {
 			return new ExtractedDatabaseMetaDataImpl(
 					jdbcEnvironment,
 					connectionCatalogName,
 					connectionSchemaName,
 					extraKeywords,
 					typeInfoSet,
 					supportsRefCursors,
 					supportsNamedParameters,
 					supportsScrollableResults,
 					supportsGetGeneratedKeys,
 					supportsBatchUpdates,
 					supportsDataDefinitionInTransaction,
 					doesDataDefinitionCauseTransactionCommit,
 					sqlStateType,
 					lobLocatorUpdateCopy
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/JdbcEnvironmentImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/JdbcEnvironmentImpl.java
index 7d559a7097..79ae059ea6 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/JdbcEnvironmentImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/JdbcEnvironmentImpl.java
@@ -1,360 +1,361 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.env.internal;
 
 import java.sql.DatabaseMetaData;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.LinkedHashSet;
+import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.config.spi.StandardConverters;
 import org.hibernate.engine.jdbc.env.spi.ExtractedDatabaseMetaData;
 import org.hibernate.engine.jdbc.env.spi.IdentifierHelper;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.env.spi.LobCreatorBuilder;
 import org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;
 import org.hibernate.engine.jdbc.env.spi.QualifiedObjectNameFormatter;
 import org.hibernate.engine.jdbc.env.spi.SchemaNameResolver;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.TypeInfo;
 import org.hibernate.exception.internal.SQLExceptionTypeDelegate;
 import org.hibernate.exception.internal.SQLStateConversionDelegate;
 import org.hibernate.exception.internal.StandardSQLExceptionConverter;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 
 /**
  * @author Steve Ebersole
  */
 public class JdbcEnvironmentImpl implements JdbcEnvironment {
 	private final Dialect dialect;
 
 	private final SqlExceptionHelper sqlExceptionHelper;
 	private final ExtractedDatabaseMetaData extractedMetaDataSupport;
 	private final Identifier currentCatalog;
 	private final Identifier currentSchema;
 	private final IdentifierHelper identifierHelper;
 	private final QualifiedObjectNameFormatter qualifiedObjectNameFormatter;
 	private final LobCreatorBuilderImpl lobCreatorBuilder;
 
 	private final LinkedHashSet<TypeInfo> typeInfoSet = new LinkedHashSet<TypeInfo>();
 	// todo : should really maintain a standard list of know ANSI-SQL defined keywords somewhere (currently rely on Dialect)
 	private final Set<String> reservedWords = new HashSet<String>();
 
 	/**
 	 * Constructor form used when the JDBC {@link java.sql.DatabaseMetaData} is not available.
 	 *
 	 * @param serviceRegistry The service registry
 	 * @param dialect The resolved dialect.
 	 */
 	public JdbcEnvironmentImpl(ServiceRegistryImplementor serviceRegistry, Dialect dialect) {
 		this.dialect = dialect;
 
 		NameQualifierSupport nameQualifierSupport = dialect.getNameQualifierSupport();
 		if ( nameQualifierSupport == null ) {
 			// assume both catalogs and schemas are supported
 			nameQualifierSupport = NameQualifierSupport.BOTH;
 		}
 
 		this.sqlExceptionHelper = buildSqlExceptionHelper( dialect );
 		this.extractedMetaDataSupport = new ExtractedDatabaseMetaDataImpl.Builder( this ).build();
 
 		for ( String keyword : dialect.getKeywords() ) {
-			reservedWords.add( keyword.toUpperCase() );
+			reservedWords.add( keyword.toUpperCase(Locale.ROOT) );
 		}
 
 		final boolean globallyQuoteIdentifiers = serviceRegistry.getService( ConfigurationService.class )
 				.getSetting( AvailableSettings.GLOBALLY_QUOTED_IDENTIFIERS, StandardConverters.BOOLEAN, false );
 
 		// a simple impl that works on H2
 		this.identifierHelper = new NormalizingIdentifierHelperImpl(
 				this,
 				nameQualifierSupport,
 				globallyQuoteIdentifiers,
 				true,	// storesMixedCaseQuotedIdentifiers
 				false,	// storesLowerCaseQuotedIdentifiers
 				false, 	// storesUpperCaseQuotedIdentifiers
 				false,  // storesMixedCaseIdentifiers
 				true,	// storesUpperCaseIdentifiers
 				false	// storesLowerCaseIdentifiers
 		);
 
 		this.currentCatalog = identifierHelper.toIdentifier(
 				serviceRegistry.getService( ConfigurationService.class )
 						.getSetting( AvailableSettings.DEFAULT_CATALOG, StandardConverters.STRING )
 		);
 		this.currentSchema = Identifier.toIdentifier(
 				serviceRegistry.getService( ConfigurationService.class )
 						.getSetting( AvailableSettings.DEFAULT_SCHEMA, StandardConverters.STRING )
 		);
 
 		// again, a simple impl that works on H2
 		this.qualifiedObjectNameFormatter = new QualifiedObjectNameFormatterStandardImpl( nameQualifierSupport );
 
 		this.lobCreatorBuilder = LobCreatorBuilderImpl.makeLobCreatorBuilder();
 	}
 
 	/**
 	 * Constructor form used from testing
 	 *
 	 * @param dialect The dialect
 	 */
 	public JdbcEnvironmentImpl(DatabaseMetaData databaseMetaData, Dialect dialect) throws SQLException {
 		this.dialect = dialect;
 
 		this.sqlExceptionHelper = buildSqlExceptionHelper( dialect );
 
 		this.extractedMetaDataSupport = new ExtractedDatabaseMetaDataImpl.Builder( this )
 				.apply( databaseMetaData )
 				.build();
 
 		NameQualifierSupport nameQualifierSupport = dialect.getNameQualifierSupport();
 		if ( nameQualifierSupport == null ) {
 			nameQualifierSupport = determineNameQualifierSupport( databaseMetaData );
 		}
 
 		for ( String keyword : dialect.getKeywords() ) {
-			reservedWords.add( keyword.toUpperCase() );
+			reservedWords.add( keyword.toUpperCase(Locale.ROOT) );
 		}
 		// ExtractedMetaDataSupport already capitalizes them
 		reservedWords.addAll( extractedMetaDataSupport.getExtraKeywords() );
 
 		final boolean globallyQuoteIdentifiers = false;
 
 		// a simple impl that works on H2
 		this.identifierHelper = new NormalizingIdentifierHelperImpl(
 				this,
 				nameQualifierSupport,
 				globallyQuoteIdentifiers,
 				true,	// storesMixedCaseQuotedIdentifiers
 				false,	// storesLowerCaseQuotedIdentifiers
 				false, 	// storesUpperCaseQuotedIdentifiers
 				false,  // storesMixedCaseIdentifiers
 				true,	// storesUpperCaseIdentifiers
 				false	// storesLowerCaseIdentifiers
 		);
 
 		this.currentCatalog = null;
 		this.currentSchema = null;
 
 		this.qualifiedObjectNameFormatter = new QualifiedObjectNameFormatterStandardImpl(
 				nameQualifierSupport,
 				databaseMetaData
 		);
 
 		this.lobCreatorBuilder = LobCreatorBuilderImpl.makeLobCreatorBuilder();
 	}
 
 	private NameQualifierSupport determineNameQualifierSupport(DatabaseMetaData databaseMetaData) throws SQLException {
 		final boolean supportsCatalogs = databaseMetaData.supportsCatalogsInTableDefinitions();
 		final boolean supportsSchemas = databaseMetaData.supportsSchemasInTableDefinitions();
 
 		if ( supportsCatalogs && supportsSchemas ) {
 			return NameQualifierSupport.BOTH;
 		}
 		else if ( supportsCatalogs ) {
 			return NameQualifierSupport.CATALOG;
 		}
 		else if ( supportsSchemas ) {
 			return NameQualifierSupport.SCHEMA;
 		}
 		else {
 			return NameQualifierSupport.NONE;
 		}
 	}
 
 	/**
 	 * The main constructor form.  Builds a JdbcEnvironment using the available DatabaseMetaData
 	 *
 	 * @param serviceRegistry The service registry
 	 * @param dialect The resolved dialect
 	 * @param databaseMetaData The available DatabaseMetaData
 	 *
 	 * @throws SQLException
 	 */
 	public JdbcEnvironmentImpl(
 			ServiceRegistryImplementor serviceRegistry,
 			Dialect dialect,
 			DatabaseMetaData databaseMetaData) throws SQLException {
 		this.dialect = dialect;
 
 		this.sqlExceptionHelper = buildSqlExceptionHelper( dialect );
 
 		this.extractedMetaDataSupport = new ExtractedDatabaseMetaDataImpl.Builder( this )
 				.apply( databaseMetaData )
 				.setConnectionSchemaName( determineCurrentSchemaName( databaseMetaData, serviceRegistry, dialect ) )
 				.build();
 
 		NameQualifierSupport nameQualifierSupport = dialect.getNameQualifierSupport();
 		if ( nameQualifierSupport == null ) {
 			nameQualifierSupport = determineNameQualifierSupport( databaseMetaData );
 		}
 
 		for ( String keyword : dialect.getKeywords() ) {
-			reservedWords.add( keyword.toUpperCase() );
+			reservedWords.add( keyword.toUpperCase(Locale.ROOT) );
 		}
 		// ExtractedMetaDataSupport already capitalizes them
 		reservedWords.addAll( extractedMetaDataSupport.getExtraKeywords() );
 
 		final boolean globallyQuoteIdentifiers = serviceRegistry.getService( ConfigurationService.class )
 				.getSetting( AvailableSettings.GLOBALLY_QUOTED_IDENTIFIERS, StandardConverters.BOOLEAN, false );
 
 		this.identifierHelper = new NormalizingIdentifierHelperImpl(
 				this,
 				nameQualifierSupport,
 				globallyQuoteIdentifiers,
 				databaseMetaData.storesMixedCaseQuotedIdentifiers(),
 				databaseMetaData.storesLowerCaseQuotedIdentifiers(),
 				databaseMetaData.storesUpperCaseQuotedIdentifiers(),
 				databaseMetaData.storesMixedCaseIdentifiers(),
 				databaseMetaData.storesUpperCaseIdentifiers(),
 				databaseMetaData.storesLowerCaseIdentifiers()
 		);
 
 		// and that current-catalog and current-schema happen after it
 		this.currentCatalog = identifierHelper.toIdentifier( extractedMetaDataSupport.getConnectionCatalogName() );
 		this.currentSchema = identifierHelper.toIdentifier( extractedMetaDataSupport.getConnectionSchemaName() );
 
 		this.qualifiedObjectNameFormatter = new QualifiedObjectNameFormatterStandardImpl(
 				nameQualifierSupport,
 				databaseMetaData
 		);
 
 		this.typeInfoSet.addAll( TypeInfo.extractTypeInfo( databaseMetaData ) );
 
 		this.lobCreatorBuilder = LobCreatorBuilderImpl.makeLobCreatorBuilder(
 				serviceRegistry.getService( ConfigurationService.class ).getSettings(),
 				databaseMetaData.getConnection()
 		);
 	}
 
 	public static final String SCHEMA_NAME_RESOLVER = "hibernate.schema_name_resolver";
 
 	private String determineCurrentSchemaName(
 			DatabaseMetaData databaseMetaData,
 			ServiceRegistry serviceRegistry,
 			Dialect dialect) throws SQLException {
 		final SchemaNameResolver schemaNameResolver;
 
 		final Object setting = serviceRegistry.getService( ConfigurationService.class ).getSettings().get( SCHEMA_NAME_RESOLVER );
 		if ( setting == null ) {
 			schemaNameResolver = dialect.getSchemaNameResolver();
 		}
 		else {
 			schemaNameResolver = serviceRegistry.getService( StrategySelector.class ).resolveDefaultableStrategy(
 					SchemaNameResolver.class,
 					setting,
 					dialect.getSchemaNameResolver()
 			);
 		}
 
 		try {
 			return schemaNameResolver.resolveSchemaName( databaseMetaData.getConnection(), dialect );
 		}
 		catch (Exception e) {
 			// for now, just ignore the exception.
 			return null;
 		}
 	}
 
 	@SuppressWarnings("deprecation")
 	private SqlExceptionHelper buildSqlExceptionHelper(Dialect dialect) {
 		final StandardSQLExceptionConverter sqlExceptionConverter = new StandardSQLExceptionConverter();
 		sqlExceptionConverter.addDelegate( dialect.buildSQLExceptionConversionDelegate() );
 		sqlExceptionConverter.addDelegate( new SQLExceptionTypeDelegate( dialect ) );
 		// todo : vary this based on extractedMetaDataSupport.getSqlStateType()
 		sqlExceptionConverter.addDelegate( new SQLStateConversionDelegate( dialect ) );
 		return new SqlExceptionHelper( sqlExceptionConverter );
 	}
 
 	private Set<String> buildMergedReservedWords(Dialect dialect, DatabaseMetaData dbmd) throws SQLException {
 		Set<String> reservedWords = new HashSet<String>();
 		reservedWords.addAll( dialect.getKeywords() );
 		// todo : do we need to explicitly handle SQL:2003 keywords?
 		reservedWords.addAll( Arrays.asList( dbmd.getSQLKeywords().split( "," ) ) );
 		return reservedWords;
 	}
 
 	@Override
 	public Dialect getDialect() {
 		return dialect;
 	}
 
 	@Override
 	public ExtractedDatabaseMetaData getExtractedDatabaseMetaData() {
 		return extractedMetaDataSupport;
 	}
 
 	@Override
 	public Identifier getCurrentCatalog() {
 		return currentCatalog;
 	}
 
 	@Override
 	public Identifier getCurrentSchema() {
 		return currentSchema;
 	}
 
 	@Override
 	public QualifiedObjectNameFormatter getQualifiedObjectNameFormatter() {
 		return qualifiedObjectNameFormatter;
 	}
 
 	@Override
 	public IdentifierHelper getIdentifierHelper() {
 		return identifierHelper;
 	}
 
 	@Override
 	public boolean isReservedWord(String word) {
-		return reservedWords.contains( word.toUpperCase() );
+		return reservedWords.contains( word.toUpperCase(Locale.ROOT) );
 	}
 
 	@Override
 	public SqlExceptionHelper getSqlExceptionHelper() {
 		return sqlExceptionHelper;
 	}
 
 	@Override
 	public LobCreatorBuilder getLobCreatorBuilder() {
 		return lobCreatorBuilder;
 	}
 
 	@Override
 	public TypeInfo getTypeInfoForJdbcCode(int jdbcTypeCode) {
 		for ( TypeInfo typeInfo : typeInfoSet ) {
 			if ( typeInfo.getJdbcTypeCode() == jdbcTypeCode ) {
 				return typeInfo;
 			}
 		}
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/NormalizingIdentifierHelperImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/NormalizingIdentifierHelperImpl.java
index 1cbf8722cb..51c85fb8e5 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/NormalizingIdentifierHelperImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/NormalizingIdentifierHelperImpl.java
@@ -1,277 +1,277 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.env.internal;
 
 import java.util.Locale;
 
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.engine.jdbc.env.spi.IdentifierHelper;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.env.spi.NameQualifierSupport;
 
 import org.jboss.logging.Logger;
 
 /**
 * @author Steve Ebersole
 */
 public class NormalizingIdentifierHelperImpl implements IdentifierHelper {
 	private static final Logger log = Logger.getLogger( NormalizingIdentifierHelperImpl.class );
 
 	private final JdbcEnvironment jdbcEnvironment;
 
 	private final NameQualifierSupport nameQualifierSupport;
 	private final boolean globallyQuoteIdentifiers;
 
 	private final boolean storesMixedCaseQuotedIdentifiers;
 	private final boolean storesLowerCaseQuotedIdentifiers;
 	private final boolean storesUpperCaseQuotedIdentifiers;
 	private final boolean storesMixedCaseIdentifiers;
 	private final boolean storesUpperCaseIdentifiers;
 	private final boolean storesLowerCaseIdentifiers;
 
 	public NormalizingIdentifierHelperImpl(
 			JdbcEnvironment jdbcEnvironment,
 			NameQualifierSupport nameQualifierSupport,
 			boolean globallyQuoteIdentifiers,
 			boolean storesMixedCaseQuotedIdentifiers,
 			boolean storesLowerCaseQuotedIdentifiers,
 			boolean storesUpperCaseQuotedIdentifiers,
 			boolean storesMixedCaseIdentifiers,
 			boolean storesUpperCaseIdentifiers,
 			boolean storesLowerCaseIdentifiers) {
 		this.jdbcEnvironment = jdbcEnvironment;
 		this.nameQualifierSupport = nameQualifierSupport;
 		this.globallyQuoteIdentifiers = globallyQuoteIdentifiers;
 		this.storesMixedCaseQuotedIdentifiers = storesMixedCaseQuotedIdentifiers;
 		this.storesLowerCaseQuotedIdentifiers = storesLowerCaseQuotedIdentifiers;
 		this.storesUpperCaseQuotedIdentifiers = storesUpperCaseQuotedIdentifiers;
 		this.storesMixedCaseIdentifiers = storesMixedCaseIdentifiers;
 		this.storesUpperCaseIdentifiers = storesUpperCaseIdentifiers;
 		this.storesLowerCaseIdentifiers = storesLowerCaseIdentifiers;
 
 		if ( storesMixedCaseQuotedIdentifiers && storesLowerCaseQuotedIdentifiers && storesUpperCaseQuotedIdentifiers ) {
 			log.warn( "JDBC Driver reports it stores quoted identifiers in mixed, upper and lower case" );
 		}
 		else if ( storesMixedCaseQuotedIdentifiers && storesUpperCaseQuotedIdentifiers ) {
 			log.warn( "JDBC Driver reports it stores quoted identifiers in both mixed and upper case" );
 		}
 		else if ( storesMixedCaseQuotedIdentifiers && storesLowerCaseQuotedIdentifiers ) {
 			log.warn( "JDBC Driver reports it stores quoted identifiers in both mixed and lower case" );
 		}
 
 		if ( storesUpperCaseIdentifiers && storesLowerCaseIdentifiers ) {
 			log.warn( "JDBC Driver reports it stores non-quoted identifiers in both upper and lower case" );
 		}
 
 		if ( storesUpperCaseIdentifiers && storesUpperCaseQuotedIdentifiers ) {
 			log.warn( "JDBC Driver reports it stores both quoted and non-quoted identifiers in upper case" );
 		}
 
 		if ( storesLowerCaseIdentifiers && storesLowerCaseQuotedIdentifiers ) {
 			log.warn( "JDBC Driver reports it stores both quoted and non-quoted identifiers in lower case" );
 		}
 	}
 
 	@Override
 	public Identifier normalizeQuoting(Identifier identifier) {
 		if ( identifier == null ) {
 			return null;
 		}
 
 		if ( identifier.isQuoted() ) {
 			return identifier;
 		}
 
 		if ( globallyQuoteIdentifiers ) {
 			return Identifier.toIdentifier( identifier.getText(), true );
 		}
 
 		if ( jdbcEnvironment.isReservedWord( identifier.getText() ) ) {
 			return Identifier.toIdentifier( identifier.getText(), true );
 		}
 
 		return identifier;
 	}
 
 	@Override
 	public Identifier toIdentifier(String text) {
 		return normalizeQuoting( Identifier.toIdentifier( text ) );
 	}
 
 	@Override
 	public Identifier toIdentifier(String text, boolean quoted) {
 		return normalizeQuoting( Identifier.toIdentifier( text, quoted ) );
 	}
 
 	// In the DatabaseMetaData method params for catalog and schema name have the following meaning:
 	//		1) <""> means to match things "without a catalog/schema"
 	//		2) <null> means to not limit results based on this field
 	//
 	// todo : not sure how "without a catalog/schema" is interpreted.  Current?
 
 	@Override
 	public String toMetaDataCatalogName(Identifier identifier) {
 		if ( !nameQualifierSupport.supportsCatalogs() ) {
 			// null is used to tell DBMD to not limit results based on catalog.
 			return null;
 		}
 
 		if ( identifier == null ) {
 			if ( jdbcEnvironment.getCurrentCatalog() == null ) {
 				return "";
 			}
 			identifier = jdbcEnvironment.getCurrentCatalog();
 		}
 
 		return toMetaDataText( identifier );
 	}
 
 	private String toMetaDataText(Identifier identifier) {
 		if ( identifier == null ) {
 			throw new IllegalArgumentException( "Identifier cannot be null; bad usage" );
 		}
 
 		if ( identifier.isQuoted() ) {
 			if ( storesMixedCaseQuotedIdentifiers ) {
 				return identifier.getText();
 			}
 			else if ( storesUpperCaseQuotedIdentifiers ) {
 				return identifier.getText().toUpperCase( Locale.ENGLISH );
 			}
 			else if ( storesLowerCaseQuotedIdentifiers ) {
 				return identifier.getText().toLowerCase( Locale.ENGLISH );
 			}
 			else {
 				return identifier.getText();
 			}
 		}
 		else {
 			if ( storesMixedCaseIdentifiers ) {
 				return identifier.getText();
 			}
 			else if ( storesUpperCaseIdentifiers ) {
 				return identifier.getText().toUpperCase( Locale.ENGLISH );
 			}
 			else if ( storesLowerCaseIdentifiers ) {
 				return identifier.getText().toLowerCase( Locale.ENGLISH );
 			}
 			else {
 				return identifier.getText();
 			}
 		}
 	}
 
 	@Override
 	public String toMetaDataSchemaName(Identifier identifier) {
 		if ( !nameQualifierSupport.supportsSchemas() ) {
 			// null is used to tell DBMD to not limit results based on schema.
 			return null;
 		}
 
 		if ( identifier == null ) {
 			if ( jdbcEnvironment.getCurrentSchema() == null ) {
 				return "";
 			}
 			identifier = jdbcEnvironment.getCurrentSchema();
 		}
 
 		return toMetaDataText( identifier );
 	}
 
 	@Override
 	public String toMetaDataObjectName(Identifier identifier) {
 		if ( identifier == null ) {
 			// if this method was called, the value is needed
 			throw new IllegalArgumentException( "null was passed as an object name" );
 		}
 		return toMetaDataText( identifier );
 	}
 
 	@Override
 	public Identifier fromMetaDataCatalogName(String catalogName) {
 		if ( catalogName == null || !nameQualifierSupport.supportsCatalogs() ) {
 			return null;
 		}
 
 //		if ( jdbcEnvironment.getCurrentCatalog() == null
 //				|| catalogName.equals( jdbcEnvironment.getCurrentCatalog().getText() ) ) {
 //			return null;
 //		}
 
 		return toIdentifierFromMetaData( catalogName );
 	}
 
 	public Identifier toIdentifierFromMetaData(String text) {
 		if ( globallyQuoteIdentifiers ) {
 			return Identifier.toIdentifier( text, true );
 		}
 
 		// lovely decipher of whether the incoming value represents a quoted identifier...
-		final boolean isUpperCase = text.toUpperCase().equals( text );
-		final boolean isLowerCase = text.toLowerCase().equals( text );
+		final boolean isUpperCase = text.toUpperCase(Locale.ROOT).equals( text );
+		final boolean isLowerCase = text.toLowerCase(Locale.ROOT).equals( text );
 		final boolean isMixedCase = ! isLowerCase && ! isUpperCase;
 
 		if ( jdbcEnvironment.isReservedWord( text ) ) {
 			// unequivocally it needs to be quoted...
 			return Identifier.toIdentifier( text, true );
 		}
 
 		if ( storesMixedCaseQuotedIdentifiers && isMixedCase ) {
 			return Identifier.toIdentifier( text, true );
 		}
 
 		if ( storesLowerCaseQuotedIdentifiers && isLowerCase ) {
 			return Identifier.toIdentifier( text, true );
 		}
 
 		if ( storesUpperCaseQuotedIdentifiers && isUpperCase ) {
 			return Identifier.toIdentifier( text, true );
 		}
 
 		return Identifier.toIdentifier( text );
 	}
 
 	@Override
 	public Identifier fromMetaDataSchemaName(String schemaName) {
 		if ( schemaName == null || !nameQualifierSupport.supportsSchemas() ) {
 			return null;
 		}
 
 //		if ( jdbcEnvironment.getCurrentSchema() == null
 //				|| schemaName.equals( jdbcEnvironment.getCurrentSchema().getText() ) ) {
 //			return null;
 //		}
 
 		return toIdentifier( schemaName );
 	}
 
 	@Override
 	public Identifier fromMetaDataObjectName(String objectName) {
 		if ( objectName == null ) {
 			return null;
 		}
 
 		return toIdentifier( objectName );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/BasicFormatterImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/BasicFormatterImpl.java
index 7ac399ef11..b753b9b1f9 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/BasicFormatterImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/BasicFormatterImpl.java
@@ -1,398 +1,399 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.util.HashSet;
 import java.util.LinkedList;
+import java.util.Locale;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * Performs formatting of basic SQL statements (DML + query).
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class BasicFormatterImpl implements Formatter {
 
 	private static final Set<String> BEGIN_CLAUSES = new HashSet<String>();
 	private static final Set<String> END_CLAUSES = new HashSet<String>();
 	private static final Set<String> LOGICAL = new HashSet<String>();
 	private static final Set<String> QUANTIFIERS = new HashSet<String>();
 	private static final Set<String> DML = new HashSet<String>();
 	private static final Set<String> MISC = new HashSet<String>();
 
 	static {
 		BEGIN_CLAUSES.add( "left" );
 		BEGIN_CLAUSES.add( "right" );
 		BEGIN_CLAUSES.add( "inner" );
 		BEGIN_CLAUSES.add( "outer" );
 		BEGIN_CLAUSES.add( "group" );
 		BEGIN_CLAUSES.add( "order" );
 
 		END_CLAUSES.add( "where" );
 		END_CLAUSES.add( "set" );
 		END_CLAUSES.add( "having" );
 		END_CLAUSES.add( "join" );
 		END_CLAUSES.add( "from" );
 		END_CLAUSES.add( "by" );
 		END_CLAUSES.add( "join" );
 		END_CLAUSES.add( "into" );
 		END_CLAUSES.add( "union" );
 
 		LOGICAL.add( "and" );
 		LOGICAL.add( "or" );
 		LOGICAL.add( "when" );
 		LOGICAL.add( "else" );
 		LOGICAL.add( "end" );
 
 		QUANTIFIERS.add( "in" );
 		QUANTIFIERS.add( "all" );
 		QUANTIFIERS.add( "exists" );
 		QUANTIFIERS.add( "some" );
 		QUANTIFIERS.add( "any" );
 
 		DML.add( "insert" );
 		DML.add( "update" );
 		DML.add( "delete" );
 
 		MISC.add( "select" );
 		MISC.add( "on" );
 	}
 
 	private static final String INDENT_STRING = "    ";
 	private static final String INITIAL = "\n    ";
 
 	@Override
 	public String format(String source) {
 		return new FormatProcess( source ).perform();
 	}
 
 	private static class FormatProcess {
 		boolean beginLine = true;
 		boolean afterBeginBeforeEnd;
 		boolean afterByOrSetOrFromOrSelect;
 		boolean afterValues;
 		boolean afterOn;
 		boolean afterBetween;
 		boolean afterInsert;
 		int inFunction;
 		int parensSinceSelect;
 		private LinkedList<Integer> parenCounts = new LinkedList<Integer>();
 		private LinkedList<Boolean> afterByOrFromOrSelects = new LinkedList<Boolean>();
 
 		int indent = 1;
 
 		StringBuilder result = new StringBuilder();
 		StringTokenizer tokens;
 		String lastToken;
 		String token;
 		String lcToken;
 
 		public FormatProcess(String sql) {
 			tokens = new StringTokenizer(
 					sql,
 					"()+*/-=<>'`\"[]," + StringHelper.WHITESPACE,
 					true
 			);
 		}
 
 		public String perform() {
 
 			result.append( INITIAL );
 
 			while ( tokens.hasMoreTokens() ) {
 				token = tokens.nextToken();
-				lcToken = token.toLowerCase();
+				lcToken = token.toLowerCase(Locale.ROOT);
 
 				if ( "'".equals( token ) ) {
 					String t;
 					do {
 						t = tokens.nextToken();
 						token += t;
 					}
 					// cannot handle single quotes
 					while ( !"'".equals( t ) && tokens.hasMoreTokens() );
 				}
 				else if ( "\"".equals( token ) ) {
 					String t;
 					do {
 						t = tokens.nextToken();
 						token += t;
 					}
 					while ( !"\"".equals( t ) );
 				}
 
 				if ( afterByOrSetOrFromOrSelect && ",".equals( token ) ) {
 					commaAfterByOrFromOrSelect();
 				}
 				else if ( afterOn && ",".equals( token ) ) {
 					commaAfterOn();
 				}
 
 				else if ( "(".equals( token ) ) {
 					openParen();
 				}
 				else if ( ")".equals( token ) ) {
 					closeParen();
 				}
 
 				else if ( BEGIN_CLAUSES.contains( lcToken ) ) {
 					beginNewClause();
 				}
 
 				else if ( END_CLAUSES.contains( lcToken ) ) {
 					endNewClause();
 				}
 
 				else if ( "select".equals( lcToken ) ) {
 					select();
 				}
 
 				else if ( DML.contains( lcToken ) ) {
 					updateOrInsertOrDelete();
 				}
 
 				else if ( "values".equals( lcToken ) ) {
 					values();
 				}
 
 				else if ( "on".equals( lcToken ) ) {
 					on();
 				}
 
 				else if ( afterBetween && lcToken.equals( "and" ) ) {
 					misc();
 					afterBetween = false;
 				}
 
 				else if ( LOGICAL.contains( lcToken ) ) {
 					logical();
 				}
 
 				else if ( isWhitespace( token ) ) {
 					white();
 				}
 
 				else {
 					misc();
 				}
 
 				if ( !isWhitespace( token ) ) {
 					lastToken = lcToken;
 				}
 
 			}
 			return result.toString();
 		}
 
 		private void commaAfterOn() {
 			out();
 			indent--;
 			newline();
 			afterOn = false;
 			afterByOrSetOrFromOrSelect = true;
 		}
 
 		private void commaAfterByOrFromOrSelect() {
 			out();
 			newline();
 		}
 
 		private void logical() {
 			if ( "end".equals( lcToken ) ) {
 				indent--;
 			}
 			newline();
 			out();
 			beginLine = false;
 		}
 
 		private void on() {
 			indent++;
 			afterOn = true;
 			newline();
 			out();
 			beginLine = false;
 		}
 
 		private void misc() {
 			out();
 			if ( "between".equals( lcToken ) ) {
 				afterBetween = true;
 			}
 			if ( afterInsert ) {
 				newline();
 				afterInsert = false;
 			}
 			else {
 				beginLine = false;
 				if ( "case".equals( lcToken ) ) {
 					indent++;
 				}
 			}
 		}
 
 		private void white() {
 			if ( !beginLine ) {
 				result.append( " " );
 			}
 		}
 
 		private void updateOrInsertOrDelete() {
 			out();
 			indent++;
 			beginLine = false;
 			if ( "update".equals( lcToken ) ) {
 				newline();
 			}
 			if ( "insert".equals( lcToken ) ) {
 				afterInsert = true;
 			}
 		}
 
 		private void select() {
 			out();
 			indent++;
 			newline();
 			parenCounts.addLast( parensSinceSelect );
 			afterByOrFromOrSelects.addLast( afterByOrSetOrFromOrSelect );
 			parensSinceSelect = 0;
 			afterByOrSetOrFromOrSelect = true;
 		}
 
 		private void out() {
 			result.append( token );
 		}
 
 		private void endNewClause() {
 			if ( !afterBeginBeforeEnd ) {
 				indent--;
 				if ( afterOn ) {
 					indent--;
 					afterOn = false;
 				}
 				newline();
 			}
 			out();
 			if ( !"union".equals( lcToken ) ) {
 				indent++;
 			}
 			newline();
 			afterBeginBeforeEnd = false;
 			afterByOrSetOrFromOrSelect = "by".equals( lcToken )
 					|| "set".equals( lcToken )
 					|| "from".equals( lcToken );
 		}
 
 		private void beginNewClause() {
 			if ( !afterBeginBeforeEnd ) {
 				if ( afterOn ) {
 					indent--;
 					afterOn = false;
 				}
 				indent--;
 				newline();
 			}
 			out();
 			beginLine = false;
 			afterBeginBeforeEnd = true;
 		}
 
 		private void values() {
 			indent--;
 			newline();
 			out();
 			indent++;
 			newline();
 			afterValues = true;
 		}
 
 		private void closeParen() {
 			parensSinceSelect--;
 			if ( parensSinceSelect < 0 ) {
 				indent--;
 				parensSinceSelect = parenCounts.removeLast();
 				afterByOrSetOrFromOrSelect = afterByOrFromOrSelects.removeLast();
 			}
 			if ( inFunction > 0 ) {
 				inFunction--;
 				out();
 			}
 			else {
 				if ( !afterByOrSetOrFromOrSelect ) {
 					indent--;
 					newline();
 				}
 				out();
 			}
 			beginLine = false;
 		}
 
 		private void openParen() {
 			if ( isFunctionName( lastToken ) || inFunction > 0 ) {
 				inFunction++;
 			}
 			beginLine = false;
 			if ( inFunction > 0 ) {
 				out();
 			}
 			else {
 				out();
 				if ( !afterByOrSetOrFromOrSelect ) {
 					indent++;
 					newline();
 					beginLine = true;
 				}
 			}
 			parensSinceSelect++;
 		}
 
 		private static boolean isFunctionName(String tok) {
 			final char begin = tok.charAt( 0 );
 			final boolean isIdentifier = Character.isJavaIdentifierStart( begin ) || '"' == begin;
 			return isIdentifier &&
 					!LOGICAL.contains( tok ) &&
 					!END_CLAUSES.contains( tok ) &&
 					!QUANTIFIERS.contains( tok ) &&
 					!DML.contains( tok ) &&
 					!MISC.contains( tok );
 		}
 
 		private static boolean isWhitespace(String token) {
 			return StringHelper.WHITESPACE.contains( token );
 		}
 
 		private void newline() {
 			result.append( "\n" );
 			for ( int i = 0; i < indent; i++ ) {
 				result.append( INDENT_STRING );
 			}
 			beginLine = true;
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/DDLFormatterImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/DDLFormatterImpl.java
index 4a923559d9..a47677f298 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/DDLFormatterImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/DDLFormatterImpl.java
@@ -1,157 +1,158 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
+import java.util.Locale;
 import java.util.StringTokenizer;
 
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * Performs formatting of DDL SQL statements.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class DDLFormatterImpl implements Formatter {
 	/**
 	 * Singleton access
 	 */
 	public static final DDLFormatterImpl INSTANCE = new DDLFormatterImpl();
 
 	@Override
 	public String format(String sql) {
 		if ( StringHelper.isEmpty( sql ) ) {
 			return sql;
 		}
-		if ( sql.toLowerCase().startsWith( "create table" ) ) {
+		if ( sql.toLowerCase(Locale.ROOT).startsWith( "create table" ) ) {
 			return formatCreateTable( sql );
 		}
-		else if ( sql.toLowerCase().startsWith( "alter table" ) ) {
+		else if ( sql.toLowerCase(Locale.ROOT).startsWith( "alter table" ) ) {
 			return formatAlterTable( sql );
 		}
-		else if ( sql.toLowerCase().startsWith( "comment on" ) ) {
+		else if ( sql.toLowerCase(Locale.ROOT).startsWith( "comment on" ) ) {
 			return formatCommentOn( sql );
 		}
 		else {
 			return "\n    " + sql;
 		}
 	}
 
 	private String formatCommentOn(String sql) {
 		final StringBuilder result = new StringBuilder( 60 ).append( "\n    " );
 		final StringTokenizer tokens = new StringTokenizer( sql, " '[]\"", true );
 
 		boolean quoted = false;
 		while ( tokens.hasMoreTokens() ) {
 			final String token = tokens.nextToken();
 			result.append( token );
 			if ( isQuote( token ) ) {
 				quoted = !quoted;
 			}
 			else if ( !quoted ) {
 				if ( "is".equals( token ) ) {
 					result.append( "\n       " );
 				}
 			}
 		}
 
 		return result.toString();
 	}
 
 	private String formatAlterTable(String sql) {
 		final StringBuilder result = new StringBuilder( 60 ).append( "\n    " );
 		final StringTokenizer tokens = new StringTokenizer( sql, " (,)'[]\"", true );
 
 		boolean quoted = false;
 		while ( tokens.hasMoreTokens() ) {
 			final String token = tokens.nextToken();
 			if ( isQuote( token ) ) {
 				quoted = !quoted;
 			}
 			else if ( !quoted ) {
 				if ( isBreak( token ) ) {
 					result.append( "\n        " );
 				}
 			}
 			result.append( token );
 		}
 
 		return result.toString();
 	}
 
 	private String formatCreateTable(String sql) {
 		final StringBuilder result = new StringBuilder( 60 ).append( "\n    " );
 		final StringTokenizer tokens = new StringTokenizer( sql, "(,)'[]\"", true );
 
 		int depth = 0;
 		boolean quoted = false;
 		while ( tokens.hasMoreTokens() ) {
 			final String token = tokens.nextToken();
 			if ( isQuote( token ) ) {
 				quoted = !quoted;
 				result.append( token );
 			}
 			else if ( quoted ) {
 				result.append( token );
 			}
 			else {
 				if ( ")".equals( token ) ) {
 					depth--;
 					if ( depth == 0 ) {
 						result.append( "\n    " );
 					}
 				}
 				result.append( token );
 				if ( ",".equals( token ) && depth == 1 ) {
 					result.append( "\n       " );
 				}
 				if ( "(".equals( token ) ) {
 					depth++;
 					if ( depth == 1 ) {
 						result.append( "\n        " );
 					}
 				}
 			}
 		}
 
 		return result.toString();
 	}
 
 	private static boolean isBreak(String token) {
 		return "drop".equals( token ) ||
 				"add".equals( token ) ||
 				"references".equals( token ) ||
 				"foreign".equals( token ) ||
 				"on".equals( token );
 	}
 
 	private static boolean isQuote(String tok) {
 		return "\"".equals( tok ) ||
 				"`".equals( tok ) ||
 				"]".equals( tok ) ||
 				"[".equals( tok ) ||
 				"'".equals( tok );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/CollectionProperties.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/CollectionProperties.java
index 0d6f043034..551b9e1607 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/CollectionProperties.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/CollectionProperties.java
@@ -1,76 +1,77 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal;
 
 import java.util.HashMap;
+import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.persister.collection.CollectionPropertyNames;
 
 /**
  * Provides a map of collection function names to the corresponding property names.
  *
  * @author josh
  */
 public final class CollectionProperties {
 	public static final Map HQL_COLLECTION_PROPERTIES;
 
-	private static final String COLLECTION_INDEX_LOWER = CollectionPropertyNames.COLLECTION_INDEX.toLowerCase();
+	private static final String COLLECTION_INDEX_LOWER = CollectionPropertyNames.COLLECTION_INDEX.toLowerCase(Locale.ROOT);
 
 	static {
 		HQL_COLLECTION_PROPERTIES = new HashMap();
-		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_ELEMENTS.toLowerCase(), CollectionPropertyNames.COLLECTION_ELEMENTS );
-		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_INDICES.toLowerCase(), CollectionPropertyNames.COLLECTION_INDICES );
-		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_SIZE.toLowerCase(), CollectionPropertyNames.COLLECTION_SIZE );
-		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_MAX_INDEX.toLowerCase(), CollectionPropertyNames.COLLECTION_MAX_INDEX );
-		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_MIN_INDEX.toLowerCase(), CollectionPropertyNames.COLLECTION_MIN_INDEX );
-		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_MAX_ELEMENT.toLowerCase(), CollectionPropertyNames.COLLECTION_MAX_ELEMENT );
-		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_MIN_ELEMENT.toLowerCase(), CollectionPropertyNames.COLLECTION_MIN_ELEMENT );
+		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_ELEMENTS.toLowerCase(Locale.ROOT), CollectionPropertyNames.COLLECTION_ELEMENTS );
+		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_INDICES.toLowerCase(Locale.ROOT), CollectionPropertyNames.COLLECTION_INDICES );
+		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_SIZE.toLowerCase(Locale.ROOT), CollectionPropertyNames.COLLECTION_SIZE );
+		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_MAX_INDEX.toLowerCase(Locale.ROOT), CollectionPropertyNames.COLLECTION_MAX_INDEX );
+		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_MIN_INDEX.toLowerCase(Locale.ROOT), CollectionPropertyNames.COLLECTION_MIN_INDEX );
+		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_MAX_ELEMENT.toLowerCase(Locale.ROOT), CollectionPropertyNames.COLLECTION_MAX_ELEMENT );
+		HQL_COLLECTION_PROPERTIES.put( CollectionPropertyNames.COLLECTION_MIN_ELEMENT.toLowerCase(Locale.ROOT), CollectionPropertyNames.COLLECTION_MIN_ELEMENT );
 		HQL_COLLECTION_PROPERTIES.put( COLLECTION_INDEX_LOWER, CollectionPropertyNames.COLLECTION_INDEX );
 	}
 
 	private CollectionProperties() {
 	}
 
 	@SuppressWarnings("SimplifiableIfStatement")
 	public static boolean isCollectionProperty(String name) {
-		final String key = name.toLowerCase();
+		final String key = name.toLowerCase(Locale.ROOT);
 		// CollectionPropertyMapping processes everything except 'index'.
 		if ( COLLECTION_INDEX_LOWER.equals( key ) ) {
 			return false;
 		}
 		else {
 			return HQL_COLLECTION_PROPERTIES.containsKey( key );
 		}
 	}
 
 	public static String getNormalizedPropertyName(String name) {
 		return (String) HQL_COLLECTION_PROPERTIES.get( name );
 	}
 
 	public static boolean isAnyCollectionProperty(String name) {
-		final String key = name.toLowerCase();
+		final String key = name.toLowerCase(Locale.ROOT);
 		return HQL_COLLECTION_PROPERTIES.containsKey( key );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/QuerySplitter.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/QuerySplitter.java
index 4c4c66c624..72fdfed136 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/QuerySplitter.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/QuerySplitter.java
@@ -1,173 +1,174 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal;
 
 import java.util.ArrayList;
 import java.util.HashSet;
+import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.hql.internal.classic.ParserHelper;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * Provides query splitting methods, which were originally in QueryTranslator.
  *
  * @author josh
  */
 public final class QuerySplitter {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( QuerySplitter.class );
 
 	private static final Set<String> BEFORE_CLASS_TOKENS = new HashSet<String>();
 	private static final Set<String> NOT_AFTER_CLASS_TOKENS = new HashSet<String>();
 
 	static {
 		BEFORE_CLASS_TOKENS.add( "from" );
 		BEFORE_CLASS_TOKENS.add( "delete" );
 		BEFORE_CLASS_TOKENS.add( "update" );
 		//beforeClassTokens.add("new"); DEFINITELY DON'T HAVE THIS!!
 		BEFORE_CLASS_TOKENS.add( "," );
 		NOT_AFTER_CLASS_TOKENS.add( "in" );
 		//notAfterClassTokens.add(",");
 		NOT_AFTER_CLASS_TOKENS.add( "from" );
 		NOT_AFTER_CLASS_TOKENS.add( ")" );
 	}
 
 	/**
 	 * Private empty constructor.
 	 * (or else checkstyle says: 'warning: Utility classes should not have a public or default constructor.')
 	 */
 	private QuerySplitter() {
 	}
 
 	/**
 	 * Handle Hibernate "implicit" polymorphism, by translating the query string into
 	 * several "concrete" queries against mapped classes.
 	 */
 	public static String[] concreteQueries(String query, SessionFactoryImplementor factory) throws MappingException {
 
 		//scan the query string for class names appearing in the from clause and replace
 		//with all persistent implementors of the class/interface, returning multiple
 		//query strings (make sure we don't pick up a class in the select clause!)
 
 		//TODO: this is one of the ugliest and most fragile pieces of code in Hibernate....
 
 		String[] tokens = StringHelper.split( StringHelper.WHITESPACE + "(),", query, true );
 		if ( tokens.length == 0 ) {
 			// just especially for the trivial collection filter
 			return new String[] { query };
 		}
 		ArrayList<String> placeholders = new ArrayList<String>();
 		ArrayList<String[]> replacements = new ArrayList<String[]>();
 		StringBuilder templateQuery = new StringBuilder( 40 );
 
 		int start = getStartingPositionFor( tokens, templateQuery );
 		int count = 0;
 		String next;
-		String last = tokens[start - 1].toLowerCase();
+		String last = tokens[start - 1].toLowerCase(Locale.ROOT);
 
 		for ( int i = start; i < tokens.length; i++ ) {
 
 			String token = tokens[i];
 
 			if ( ParserHelper.isWhitespace( token ) ) {
 				templateQuery.append( token );
 				continue;
 			}
 
-			next = nextNonWhite( tokens, i ).toLowerCase();
+			next = nextNonWhite( tokens, i ).toLowerCase(Locale.ROOT);
 
 			boolean process = isJavaIdentifier( token ) &&
 					isPossiblyClassName( last, next );
 
-			last = token.toLowerCase();
+			last = token.toLowerCase(Locale.ROOT);
 
 			if ( process ) {
 				String importedClassName = getImportedClass( token, factory );
 				if ( importedClassName != null ) {
 					String[] implementors = factory.getImplementors( importedClassName );
 					token = "$clazz" + count++ + "$";
 					if ( implementors != null ) {
 						placeholders.add( token );
 						replacements.add( implementors );
 					}
 				}
 			}
 
 			templateQuery.append( token );
 
 		}
 		String[] results = StringHelper.multiply(
 				templateQuery.toString(),
 				placeholders.iterator(),
 				replacements.iterator()
 		);
 		if ( results.length == 0 ) {
 			LOG.noPersistentClassesFound( query );
 		}
 		return results;
 	}
 
 	private static String nextNonWhite(String[] tokens, int start) {
 		for ( int i = start + 1; i < tokens.length; i++ ) {
 			if ( !ParserHelper.isWhitespace( tokens[i] ) ) {
 				return tokens[i];
 			}
 		}
 		return tokens[tokens.length - 1];
 	}
 
 	private static int getStartingPositionFor(String[] tokens, StringBuilder templateQuery) {
 		templateQuery.append( tokens[0] );
-		if ( !"select".equals( tokens[0].toLowerCase() ) ) {
+		if ( !"select".equals( tokens[0].toLowerCase(Locale.ROOT) ) ) {
 			return 1;
 		}
 
 		// select-range is terminated by declaration of "from"
 		for ( int i = 1; i < tokens.length; i++ ) {
-			if ( "from".equals( tokens[i].toLowerCase() ) ) {
+			if ( "from".equals( tokens[i].toLowerCase(Locale.ROOT) ) ) {
 				return i;
 			}
 			templateQuery.append( tokens[i] );
 		}
 		return tokens.length;
 	}
 
 	private static boolean isPossiblyClassName(String last, String next) {
 		return "class".equals( last )
 				|| ( BEFORE_CLASS_TOKENS.contains( last ) && !NOT_AFTER_CLASS_TOKENS.contains( next ) );
 	}
 
 	private static boolean isJavaIdentifier(String token) {
 		return Character.isJavaIdentifierStart( token.charAt( 0 ) );
 	}
 
 	public static String getImportedClass(String name, SessionFactoryImplementor factory) {
 		return factory.getImportedClassName( name );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ConstructorNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ConstructorNode.java
index 80bde63e1c..76885d6bad 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ConstructorNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ConstructorNode.java
@@ -1,255 +1,256 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.lang.reflect.Constructor;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.hql.internal.ast.DetailedSemanticException;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.transform.AliasToBeanConstructorResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.transform.Transformers;
 import org.hibernate.type.PrimitiveType;
 import org.hibernate.type.Type;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
+import java.util.Locale;
 
 /**
  * Represents a constructor (new) in a SELECT.
  *
  * @author josh
  */
 public class ConstructorNode extends SelectExpressionList implements AggregatedSelectExpression {
 	private Class resultType;
 	private Constructor constructor;
 	private Type[] constructorArgumentTypes;
 	private boolean isMap;
 	private boolean isList;
 
 	@Override
 	public ResultTransformer getResultTransformer() {
 		if ( constructor != null ) {
 			return new AliasToBeanConstructorResultTransformer( constructor );
 		}
 		else if ( isMap ) {
 			return Transformers.ALIAS_TO_ENTITY_MAP;
 		}
 		else if ( isList ) {
 			return Transformers.TO_LIST;
 		}
 		throw new QueryException( "Unable to determine proper dynamic-instantiation tranformer to use." );
 	}
 
 	private String[] aggregatedAliases;
 
 	@Override
 	public String[] getAggregatedAliases() {
 		if ( aggregatedAliases == null ) {
 			aggregatedAliases = buildAggregatedAliases();
 		}
 		return aggregatedAliases;
 	}
 
 	private String[] buildAggregatedAliases() {
 		SelectExpression[] selectExpressions = collectSelectExpressions();
 		String[] aliases = new String[selectExpressions.length];
 		for ( int i = 0; i < selectExpressions.length; i++ ) {
 			String alias = selectExpressions[i].getAlias();
 			aliases[i] = alias == null ? Integer.toString( i ) : alias;
 		}
 		return aliases;
 	}
 
 	@Override
 	public void setScalarColumn(int i) throws SemanticException {
 		SelectExpression[] selectExpressions = collectSelectExpressions();
 		// Invoke setScalarColumnText on each constructor argument.
 		for ( int j = 0; j < selectExpressions.length; j++ ) {
 			SelectExpression selectExpression = selectExpressions[j];
 			selectExpression.setScalarColumn( j );
 		}
 	}
 
 	@Override
 	public int getScalarColumnIndex() {
 		return -1;
 	}
 
 	@Override
 	public void setScalarColumnText(int i) throws SemanticException {
 		SelectExpression[] selectExpressions = collectSelectExpressions();
 		// Invoke setScalarColumnText on each constructor argument.
 		for ( int j = 0; j < selectExpressions.length; j++ ) {
 			SelectExpression selectExpression = selectExpressions[j];
 			selectExpression.setScalarColumnText( j );
 		}
 	}
 
 	@Override
 	protected AST getFirstSelectExpression() {
 		// Collect the select expressions, skip the first child because it is the class name.
 		return getFirstChild().getNextSibling();
 	}
 
 	@Override
 	public Class getAggregationResultType() {
 		return resultType;
 	}
 
 	/**
 	 * @deprecated (tell clover to ignore this method)
 	 */
 	@Deprecated
 	@Override
 	public Type getDataType() {
 /*
 		// Return the type of the object created by the constructor.
 		AST firstChild = getFirstChild();
 		String text = firstChild.getText();
 		if ( firstChild.getType() == SqlTokenTypes.DOT ) {
 			DotNode dot = ( DotNode ) firstChild;
 			text = dot.getPath();
 		}
 		return getSessionFactoryHelper().requireEntityType( text );
 */
 		throw new UnsupportedOperationException( "getDataType() is not supported by ConstructorNode!" );
 	}
 
 	public void prepare() throws SemanticException {
 		constructorArgumentTypes = resolveConstructorArgumentTypes();
 		String path = ( (PathNode) getFirstChild() ).getPath();
-		if ( "map".equals( path.toLowerCase() ) ) {
+		if ( "map".equals( path.toLowerCase(Locale.ROOT) ) ) {
 			isMap = true;
 			resultType = Map.class;
 		}
-		else if ( "list".equals( path.toLowerCase() ) ) {
+		else if ( "list".equals( path.toLowerCase(Locale.ROOT) ) ) {
 			isList = true;
 			resultType = List.class;
 		}
 		else {
 			constructor = resolveConstructor( path );
 			resultType = constructor.getDeclaringClass();
 		}
 	}
 
 	private Type[] resolveConstructorArgumentTypes() throws SemanticException {
 		SelectExpression[] argumentExpressions = collectSelectExpressions();
 		if ( argumentExpressions == null ) {
 			// return an empty Type array
 			return new Type[] {};
 		}
 
 		Type[] types = new Type[argumentExpressions.length];
 		for ( int x = 0; x < argumentExpressions.length; x++ ) {
 			types[x] = argumentExpressions[x].getDataType();
 		}
 		return types;
 	}
 
 	private Constructor resolveConstructor(String path) throws SemanticException {
 		String importedClassName = getSessionFactoryHelper().getImportedClassName( path );
 		String className = StringHelper.isEmpty( importedClassName ) ? path : importedClassName;
 		if ( className == null ) {
 			throw new SemanticException( "Unable to locate class [" + path + "]" );
 		}
 		try {
 			Class holderClass = ReflectHelper.classForName( className );
 			return ReflectHelper.getConstructor( holderClass, constructorArgumentTypes );
 		}
 		catch (ClassNotFoundException e) {
 			throw new DetailedSemanticException( "Unable to locate class [" + className + "]", e );
 		}
 		catch (PropertyNotFoundException e) {
 			// this is the exception returned by ReflectHelper.getConstructor() if it cannot
 			// locate an appropriate constructor
 			throw new DetailedSemanticException( formatMissingContructorExceptionMessage( className ), e );
 		}
 	}
 
 	// HHH-8068 -- provide a more helpful message
 	private String formatMissingContructorExceptionMessage(String className) {
 		String[] params = new String[constructorArgumentTypes.length];
 		for ( int j = 0; j < constructorArgumentTypes.length; j++ ) {
 			params[j] = constructorArgumentTypes[j] instanceof PrimitiveType
 					? ( (PrimitiveType) constructorArgumentTypes[j] ).getPrimitiveClass().getName()
 					: constructorArgumentTypes[j].getReturnedClass().getName();
 		}
 		String formattedList = params.length == 0 ? "no arguments constructor" : StringHelper.join( ", ", params );
 		return String.format(
 				"Unable to locate appropriate constructor on class [%s]. Expected arguments are: %s",
 				className, formattedList
 		);
 	}
 
 	public Constructor getConstructor() {
 		return constructor;
 	}
 
 	public List getConstructorArgumentTypeList() {
 		return Arrays.asList( constructorArgumentTypes );
 	}
 
 	@Override
 	public List getAggregatedSelectionTypeList() {
 		return getConstructorArgumentTypeList();
 	}
 
 	@Override
 	public FromElement getFromElement() {
 		return null;
 	}
 
 	@Override
 	public boolean isConstructor() {
 		return true;
 	}
 
 	@Override
 	public boolean isReturnableEntity() throws SemanticException {
 		return false;
 	}
 
 	@Override
 	public boolean isScalar() {
 		// Constructors are always considered scalar results.
 		return true;
 	}
 
 	@Override
 	public void setAlias(String alias) {
 		throw new UnsupportedOperationException( "constructor may not be aliased" );
 	}
 
 	@Override
 	public String getAlias() {
 		throw new UnsupportedOperationException( "constructor may not be aliased" );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/MethodNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/MethodNode.java
index e2d6df5b3b..a62a48566e 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/MethodNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/MethodNode.java
@@ -1,245 +1,246 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.Arrays;
 
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.TypeDiscriminatorMetadata;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.hql.internal.ast.util.ColumnHelper;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.persister.collection.CollectionPropertyNames;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
+import java.util.Locale;
 
 /**
  * Represents a method call.
  *
  * @author josh
  */
 public class MethodNode extends AbstractSelectExpression implements FunctionNode {
 	private static final Logger LOG = CoreLogging.logger( MethodNode.class );
 
 	private String methodName;
 	private FromElement fromElement;
 	private String[] selectColumns;
 	private SQLFunction function;
 	private boolean inSelect;
 
 	@Override
 	public boolean isScalar() throws SemanticException {
 		// Method expressions in a SELECT should always be considered scalar.
 		return true;
 	}
 
 	@Override
 	public SQLFunction getSQLFunction() {
 		return function;
 	}
 
 	@Override
 	public Type getFirstArgumentType() {
 		AST argument = getFirstChild();
 		while ( argument != null ) {
 			if ( argument instanceof SqlNode ) {
 				final Type type = ( (SqlNode) argument ).getDataType();
 				if ( type != null ) {
 					return type;
 				}
 				argument = argument.getNextSibling();
 			}
 		}
 		return null;
 	}
 
 	public void resolve(boolean inSelect) throws SemanticException {
 		// Get the function name node.
 		AST nameNode = getFirstChild();
 		AST exprListNode = nameNode.getNextSibling();
 
 		initializeMethodNode( nameNode, inSelect );
 
 		// If the expression list has exactly one expression, and the type of the expression is a collection
 		// then this might be a collection function, such as index(c) or size(c).
 		if ( ASTUtil.hasExactlyOneChild( exprListNode ) ) {
 			if ( "type".equals( methodName ) ) {
 				typeDiscriminator( exprListNode.getFirstChild() );
 				return;
 			}
 			if ( isCollectionPropertyMethod() ) {
 				collectionProperty( exprListNode.getFirstChild(), nameNode );
 				return;
 			}
 		}
 
 		dialectFunction( exprListNode );
 	}
 
 	public void initializeMethodNode(AST name, boolean inSelect) {
 		name.setType( SqlTokenTypes.METHOD_NAME );
 		String text = name.getText();
 		// Use the lower case function name.
-		methodName = text.toLowerCase();
+		methodName = text.toLowerCase(Locale.ROOT);
 		// Remember whether we're in a SELECT clause or not.
 		this.inSelect = inSelect;
 	}
 
 	private void typeDiscriminator(AST path) throws SemanticException {
 		if ( path == null ) {
 			throw new SemanticException( "type() discriminator reference has no path!" );
 		}
 
 		FromReferenceNode pathAsFromReferenceNode = (FromReferenceNode) path;
 		FromElement fromElement = pathAsFromReferenceNode.getFromElement();
 		TypeDiscriminatorMetadata typeDiscriminatorMetadata = fromElement.getTypeDiscriminatorMetadata();
 
 		setDataType( typeDiscriminatorMetadata.getResolutionType() );
 		setText( typeDiscriminatorMetadata.getSqlFragment() );
 		setType( SqlTokenTypes.SQL_TOKEN );
 	}
 
 	private void dialectFunction(AST exprList) {
 		function = getSessionFactoryHelper().findSQLFunction( methodName );
 		if ( function != null ) {
 			AST firstChild = exprList != null ? exprList.getFirstChild() : null;
 			Type functionReturnType = getSessionFactoryHelper()
 					.findFunctionReturnType( methodName, function, firstChild );
 			setDataType( functionReturnType );
 		}
 	}
 
 	public boolean isCollectionPropertyMethod() {
 		return CollectionProperties.isAnyCollectionProperty( methodName );
 	}
 
 	private void collectionProperty(AST path, AST name) throws SemanticException {
 		if ( path == null ) {
 			throw new SemanticException( "Collection function " + name.getText() + " has no path!" );
 		}
 
 		SqlNode expr = (SqlNode) path;
 		Type type = expr.getDataType();
 		LOG.debugf( "collectionProperty() :  name=%s type=%s", name, type );
 
 		resolveCollectionProperty( expr );
 	}
 
 	protected void resolveCollectionProperty(AST expr) throws SemanticException {
 		String propertyName = CollectionProperties.getNormalizedPropertyName( methodName );
 		if ( expr instanceof FromReferenceNode ) {
 			FromReferenceNode collectionNode = (FromReferenceNode) expr;
 			// If this is 'elements' then create a new FROM element.
 			if ( CollectionPropertyNames.COLLECTION_ELEMENTS.equals( propertyName ) ) {
 				handleElements( collectionNode, propertyName );
 			}
 			else {
 				// Not elements(x)
 				fromElement = collectionNode.getFromElement();
 				setDataType( fromElement.getPropertyType( propertyName, propertyName ) );
 				selectColumns = fromElement.toColumns( fromElement.getTableAlias(), propertyName, inSelect );
 			}
 			if ( collectionNode instanceof DotNode ) {
 				prepareAnyImplicitJoins( (DotNode) collectionNode );
 			}
 			if ( !inSelect ) {
 				fromElement.setText( "" );
 				fromElement.setUseWhereFragment( false );
 			}
 			prepareSelectColumns( selectColumns );
 			setText( selectColumns[0] );
 			setType( SqlTokenTypes.SQL_TOKEN );
 		}
 		else {
 			throw new SemanticException(
 					"Unexpected expression " + expr +
 							" found for collection function " + propertyName
 			);
 		}
 	}
 
 	private void prepareAnyImplicitJoins(DotNode dotNode) throws SemanticException {
 		if ( dotNode.getLhs() instanceof DotNode ) {
 			DotNode lhs = (DotNode) dotNode.getLhs();
 			FromElement lhsOrigin = lhs.getFromElement();
 			if ( lhsOrigin != null && "".equals( lhsOrigin.getText() ) ) {
 				String lhsOriginText = lhsOrigin.getQueryable().getTableName() +
 						" " + lhsOrigin.getTableAlias();
 				lhsOrigin.setText( lhsOriginText );
 			}
 			prepareAnyImplicitJoins( lhs );
 		}
 	}
 
 	private void handleElements(FromReferenceNode collectionNode, String propertyName) {
 		FromElement collectionFromElement = collectionNode.getFromElement();
 		QueryableCollection queryableCollection = collectionFromElement.getQueryableCollection();
 
 		String path = collectionNode.getPath() + "[]." + propertyName;
 		LOG.debugf( "Creating elements for %s", path );
 
 		fromElement = collectionFromElement;
 		if ( !collectionFromElement.isCollectionOfValuesOrComponents() ) {
 			getWalker().addQuerySpaces( queryableCollection.getElementPersister().getQuerySpaces() );
 		}
 
 		setDataType( queryableCollection.getElementType() );
 		selectColumns = collectionFromElement.toColumns( fromElement.getTableAlias(), propertyName, inSelect );
 	}
 
 	@Override
 	public void setScalarColumnText(int i) throws SemanticException {
 		if ( selectColumns == null ) {    // Dialect function
 			ColumnHelper.generateSingleScalarColumn( this, i );
 		}
 		else {    // Collection 'property function'
 			ColumnHelper.generateScalarColumns( this, selectColumns, i );
 		}
 	}
 
 	protected void prepareSelectColumns(String[] columns) {
 	}
 
 	@Override
 	public FromElement getFromElement() {
 		return fromElement;
 	}
 
 	public String getDisplayText() {
 		return "{" +
 				"method=" + methodName +
 				",selectColumns=" + ( selectColumns == null ?
 				null : Arrays.asList( selectColumns ) ) +
 				",fromElement=" + fromElement.getTableAlias() +
 				"}";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/LiteralProcessor.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/LiteralProcessor.java
index 669403495b..ef00b2c0d0 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/LiteralProcessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/LiteralProcessor.java
@@ -1,365 +1,366 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.util;
 
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.text.DecimalFormat;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.HqlSqlWalker;
 import org.hibernate.hql.internal.ast.InvalidPathException;
 import org.hibernate.hql.internal.ast.tree.DotNode;
 import org.hibernate.hql.internal.ast.tree.FromClause;
 import org.hibernate.hql.internal.ast.tree.IdentNode;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.InFragment;
 import org.hibernate.type.LiteralType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
+import java.util.Locale;
 
 /**
  * A delegate that handles literals and constants for HqlSqlWalker, performing the token replacement functions and
  * classifying literals.
  *
  * @author josh
  */
 public class LiteralProcessor implements HqlSqlTokenTypes {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			LiteralProcessor.class.getName()
 	);
 
 	/**
 	 * In what format should Float and Double literal values be sent to the database?
 	 */
 	public static DecimalLiteralFormat DECIMAL_LITERAL_FORMAT = DecimalLiteralFormat.EXACT;
 
 	private HqlSqlWalker walker;
 
 	public LiteralProcessor(HqlSqlWalker hqlSqlWalker) {
 		this.walker = hqlSqlWalker;
 	}
 
 	public boolean isAlias(String alias) {
 		FromClause from = walker.getCurrentFromClause();
 		while ( from.isSubQuery() ) {
 			if ( from.containsClassAlias( alias ) ) {
 				return true;
 			}
 			from = from.getParentFromClause();
 		}
 		return from.containsClassAlias( alias );
 	}
 
 	public void processConstant(AST constant, boolean resolveIdent) throws SemanticException {
 		// If the constant is an IDENT, figure out what it means...
 		boolean isIdent = ( constant.getType() == IDENT || constant.getType() == WEIRD_IDENT );
 		if ( resolveIdent && isIdent && isAlias( constant.getText() ) ) {
 			// IDENT is a class alias in the FROM.
 			IdentNode ident = (IdentNode) constant;
 			// Resolve to an identity column.
 			ident.resolve( false, true );
 		}
 		else {
 			// IDENT might be the name of a class.
 			Queryable queryable = walker.getSessionFactoryHelper().findQueryableUsingImports( constant.getText() );
 			if ( isIdent && queryable != null ) {
 				constant.setText( queryable.getDiscriminatorSQLValue() );
 			}
 			// Otherwise, it's a literal.
 			else {
 				processLiteral( constant );
 			}
 		}
 	}
 
 	public void lookupConstant(DotNode node) throws SemanticException {
 		String text = ASTUtil.getPathText( node );
 		Queryable persister = walker.getSessionFactoryHelper().findQueryableUsingImports( text );
 		if ( persister != null ) {
 			// the name of an entity class
 			final String discrim = persister.getDiscriminatorSQLValue();
 			node.setDataType( persister.getDiscriminatorType() );
 			if ( InFragment.NULL.equals( discrim ) || InFragment.NOT_NULL.equals( discrim ) ) {
 				throw new InvalidPathException(
 						"subclass test not allowed for null or not null discriminator: '" + text + "'"
 				);
 			}
 			// the class discriminator value
 			setSQLValue( node, text, discrim );
 		}
 		else {
 			Object value = ReflectHelper.getConstantValue( text );
 			if ( value == null ) {
 				throw new InvalidPathException( "Invalid path: '" + text + "'" );
 			}
 			setConstantValue( node, text, value );
 		}
 	}
 
 	private void setSQLValue(DotNode node, String text, String value) {
 		LOG.debugf( "setSQLValue() %s -> %s", text, value );
 		// Chop off the rest of the tree.
 		node.setFirstChild( null );
 		node.setType( SqlTokenTypes.SQL_TOKEN );
 		node.setText( value );
 		node.setResolvedConstant( text );
 	}
 
 	private void setConstantValue(DotNode node, String text, Object value) {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "setConstantValue() %s -> %s %s", text, value, value.getClass().getName() );
 		}
 		// Chop off the rest of the tree.
 		node.setFirstChild( null );
 		if ( value instanceof String ) {
 			node.setType( SqlTokenTypes.QUOTED_STRING );
 		}
 		else if ( value instanceof Character ) {
 			node.setType( SqlTokenTypes.QUOTED_STRING );
 		}
 		else if ( value instanceof Byte ) {
 			node.setType( SqlTokenTypes.NUM_INT );
 		}
 		else if ( value instanceof Short ) {
 			node.setType( SqlTokenTypes.NUM_INT );
 		}
 		else if ( value instanceof Integer ) {
 			node.setType( SqlTokenTypes.NUM_INT );
 		}
 		else if ( value instanceof Long ) {
 			node.setType( SqlTokenTypes.NUM_LONG );
 		}
 		else if ( value instanceof Double ) {
 			node.setType( SqlTokenTypes.NUM_DOUBLE );
 		}
 		else if ( value instanceof Float ) {
 			node.setType( SqlTokenTypes.NUM_FLOAT );
 		}
 		else {
 			node.setType( SqlTokenTypes.CONSTANT );
 		}
 		Type type;
 		try {
 			type = walker.getSessionFactoryHelper().getFactory().getTypeResolver().heuristicType(
 					value.getClass().getName()
 			);
 		}
 		catch (MappingException me) {
 			throw new QueryException( me );
 		}
 		if ( type == null ) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_DETERMINE_TYPE + node.getText() );
 		}
 		try {
 			LiteralType literalType = (LiteralType) type;
 			Dialect dialect = walker.getSessionFactoryHelper().getFactory().getDialect();
 			//noinspection unchecked
 			node.setText( literalType.objectToSQLString( value, dialect ) );
 		}
 		catch (Exception e) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_FORMAT_LITERAL + node.getText(), e );
 		}
 		node.setDataType( type );
 		node.setResolvedConstant( text );
 	}
 
 	public void processBoolean(AST constant) {
 		// TODO: something much better - look at the type of the other expression!
 		// TODO: Have comparisonExpression and/or arithmeticExpression rules complete the resolution of boolean nodes.
 		String replacement = (String) walker.getTokenReplacements().get( constant.getText() );
 		if ( replacement != null ) {
 			constant.setText( replacement );
 		}
 		else {
-			boolean bool = "true".equals( constant.getText().toLowerCase() );
+			boolean bool = "true".equals( constant.getText().toLowerCase(Locale.ROOT) );
 			Dialect dialect = walker.getSessionFactoryHelper().getFactory().getDialect();
 			constant.setText( dialect.toBooleanValueString( bool ) );
 		}
 	}
 
 	private void processLiteral(AST constant) {
 		String replacement = (String) walker.getTokenReplacements().get( constant.getText() );
 		if ( replacement != null ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "processConstant() : Replacing '%s' with '%s'", constant.getText(), replacement );
 			}
 			constant.setText( replacement );
 		}
 	}
 
 	public void processNumeric(AST literal) {
 		if ( literal.getType() == NUM_INT
 				|| literal.getType() == NUM_LONG
 				|| literal.getType() == NUM_BIG_INTEGER ) {
 			literal.setText( determineIntegerRepresentation( literal.getText(), literal.getType() ) );
 		}
 		else if ( literal.getType() == NUM_FLOAT
 				|| literal.getType() == NUM_DOUBLE
 				|| literal.getType() == NUM_BIG_DECIMAL ) {
 			literal.setText( determineDecimalRepresentation( literal.getText(), literal.getType() ) );
 		}
 		else {
 			LOG.unexpectedLiteralTokenType( literal.getType() );
 		}
 	}
 
 	private String determineIntegerRepresentation(String text, int type) {
 		try {
 			if ( type == NUM_BIG_INTEGER ) {
 				String literalValue = text;
 				if ( literalValue.endsWith( "bi" ) || literalValue.endsWith( "BI" ) ) {
 					literalValue = literalValue.substring( 0, literalValue.length() - 2 );
 				}
 				return new BigInteger( literalValue ).toString();
 			}
 			if ( type == NUM_INT ) {
 				try {
 					return Integer.valueOf( text ).toString();
 				}
 				catch (NumberFormatException e) {
 					LOG.tracev(
 							"Could not format incoming text [{0}] as a NUM_INT; assuming numeric overflow and attempting as NUM_LONG",
 							text
 					);
 				}
 			}
 			String literalValue = text;
 			if ( literalValue.endsWith( "l" ) || literalValue.endsWith( "L" ) ) {
 				literalValue = literalValue.substring( 0, literalValue.length() - 1 );
 			}
 			return Long.valueOf( literalValue ).toString();
 		}
 		catch (Throwable t) {
 			throw new HibernateException( "Could not parse literal [" + text + "] as integer", t );
 		}
 	}
 
 	public String determineDecimalRepresentation(String text, int type) {
 		String literalValue = text;
 		if ( type == NUM_FLOAT ) {
 			if ( literalValue.endsWith( "f" ) || literalValue.endsWith( "F" ) ) {
 				literalValue = literalValue.substring( 0, literalValue.length() - 1 );
 			}
 		}
 		else if ( type == NUM_DOUBLE ) {
 			if ( literalValue.endsWith( "d" ) || literalValue.endsWith( "D" ) ) {
 				literalValue = literalValue.substring( 0, literalValue.length() - 1 );
 			}
 		}
 		else if ( type == NUM_BIG_DECIMAL ) {
 			if ( literalValue.endsWith( "bd" ) || literalValue.endsWith( "BD" ) ) {
 				literalValue = literalValue.substring( 0, literalValue.length() - 2 );
 			}
 		}
 
 		final BigDecimal number;
 		try {
 			number = new BigDecimal( literalValue );
 		}
 		catch (Throwable t) {
 			throw new HibernateException( "Could not parse literal [" + text + "] as big-decimal", t );
 		}
 
 		return DECIMAL_LITERAL_FORMAT.getFormatter().format( number );
 	}
 
 
 	private static interface DecimalFormatter {
 		String format(BigDecimal number);
 	}
 
 	private static class ExactDecimalFormatter implements DecimalFormatter {
 		public static final ExactDecimalFormatter INSTANCE = new ExactDecimalFormatter();
 
 		public String format(BigDecimal number) {
 			return number.toString();
 		}
 	}
 
 	private static class ApproximateDecimalFormatter implements DecimalFormatter {
 		public static final ApproximateDecimalFormatter INSTANCE = new ApproximateDecimalFormatter();
 
 		private static final String FORMAT_STRING = "#0.0E0";
 
 		public String format(BigDecimal number) {
 			try {
 				// TODO : what amount of significant digits need to be supported here?
 				//      - from the DecimalFormat docs:
 				//          [significant digits] = [minimum integer digits] + [maximum fraction digits]
 				DecimalFormat jdkFormatter = new DecimalFormat( FORMAT_STRING );
 				jdkFormatter.setMinimumIntegerDigits( 1 );
 				jdkFormatter.setMaximumFractionDigits( Integer.MAX_VALUE );
 				return jdkFormatter.format( number );
 			}
 			catch (Throwable t) {
 				throw new HibernateException(
 						"Unable to format decimal literal in approximate format [" + number.toString() + "]",
 						t
 				);
 			}
 		}
 	}
 
 	public static enum DecimalLiteralFormat {
 		/**
 		 * Indicates that Float and Double literal values should
 		 * be treated using the SQL "exact" format (i.e., '.001')
 		 */
 		EXACT {
 			@Override
 			public DecimalFormatter getFormatter() {
 				return ExactDecimalFormatter.INSTANCE;
 			}
 		},
 		/**
 		 * Indicates that Float and Double literal values should
 		 * be treated using the SQL "approximate" format (i.e., '1E-3')
 		 */
 		@SuppressWarnings({"UnusedDeclaration"})
 		APPROXIMATE {
 			@Override
 			public DecimalFormatter getFormatter() {
 				return ApproximateDecimalFormatter.INSTANCE;
 			}
 		};
 
 		public abstract DecimalFormatter getFormatter();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
index de3319fa8c..8f692dce1b 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
@@ -1,144 +1,145 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.ArrayList;
 import java.util.List;
+import java.util.Locale;
 
 import org.hibernate.QueryException;
 
 /**
  * Parses the Hibernate query into its constituent clauses.
  */
 public class ClauseParser implements Parser {
 	private Parser child;
 	private List<String> selectTokens;
 	private boolean cacheSelectTokens;
 	private boolean byExpected;
 	private int parenCount;
 
 	@Override
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
-		String lcToken = token.toLowerCase();
+		String lcToken = token.toLowerCase(Locale.ROOT);
 
 		if ( "(".equals( token ) ) {
 			parenCount++;
 		}
 		else if ( ")".equals( token ) ) {
 			parenCount--;
 		}
 
 		if ( byExpected && !lcToken.equals( "by" ) ) {
 			throw new QueryException( "BY expected after GROUP or ORDER: " + token );
 		}
 
 		boolean isClauseStart = parenCount == 0; //ignore subselect keywords
 
 		if ( isClauseStart ) {
 			if ( lcToken.equals( "select" ) ) {
 				selectTokens = new ArrayList<String>();
 				cacheSelectTokens = true;
 			}
 			else if ( lcToken.equals( "from" ) ) {
 				child = new FromParser();
 				child.start( q );
 				cacheSelectTokens = false;
 			}
 			else if ( lcToken.equals( "where" ) ) {
 				endChild( q );
 				child = new WhereParser();
 				child.start( q );
 			}
 			else if ( lcToken.equals( "order" ) ) {
 				endChild( q );
 				child = new OrderByParser();
 				byExpected = true;
 			}
 			else if ( lcToken.equals( "having" ) ) {
 				endChild( q );
 				child = new HavingParser();
 				child.start( q );
 			}
 			else if ( lcToken.equals( "group" ) ) {
 				endChild( q );
 				child = new GroupByParser();
 				byExpected = true;
 			}
 			else if ( lcToken.equals( "by" ) ) {
 				if ( !byExpected ) throw new QueryException( "GROUP or ORDER expected before BY" );
 				child.start( q );
 				byExpected = false;
 			}
 			else {
 				isClauseStart = false;
 			}
 		}
 
 		if ( !isClauseStart ) {
 			if ( cacheSelectTokens ) {
 				selectTokens.add( token );
 			}
 			else {
 				if ( child == null ) {
 					throw new QueryException( "query must begin with SELECT or FROM: " + token );
 				}
 				else {
 					child.token( token, q );
 				}
 			}
 		}
 
 	}
 
 	private void endChild(QueryTranslatorImpl q) throws QueryException {
 		if ( child == null ) {
 			//null child could occur for no from clause in a filter
 			cacheSelectTokens = false;
 		}
 		else {
 			child.end( q );
 		}
 	}
 
 	@Override
 	public void start(QueryTranslatorImpl q) {
 	}
 
 	@Override
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		endChild( q );
 		if ( selectTokens != null ) {
 			child = new SelectParser();
 			child.start( q );
 			for ( String selectToken : selectTokens ) {
 				token( selectToken, q );
 			}
 			child.end( q );
 		}
 		byExpected = false;
 		parenCount = 0;
 		cacheSelectTokens = false;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
index ae7a3b1744..bc736eb265 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
@@ -1,302 +1,303 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 import java.util.HashMap;
+import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.QueryException;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 
 /**
  * Parses the from clause of a hibernate query, looking for tables and
  * aliases for the SQL query.
  */
 
 public class FromParser implements Parser {
 
 	private final PathExpressionParser peParser = new FromPathExpressionParser();
 	private String entityName;
 	private String alias;
 	private boolean afterIn;
 	private boolean afterAs;
 	private boolean afterClass;
 	private boolean expectingJoin;
 	private boolean expectingIn;
 	private boolean expectingAs;
 	private boolean afterJoinType;
 	private JoinType joinType = JoinType.INNER_JOIN;
 	private boolean afterFetch;
 	
 	//support collection member declarations
 	//e.g. "from Customer c, in(c.orders) as o"
 	private boolean memberDeclarations;
 	private boolean expectingPathExpression;
 	private boolean afterMemberDeclarations;
 	private String collectionName;
 
 	private static final Map<String,JoinType> JOIN_TYPES = new HashMap<String,JoinType>();
 
 	static {
 		JOIN_TYPES.put( "left", JoinType.LEFT_OUTER_JOIN );
 		JOIN_TYPES.put( "right", JoinType.RIGHT_OUTER_JOIN );
 		JOIN_TYPES.put( "full", JoinType.FULL_JOIN );
 		JOIN_TYPES.put( "inner", JoinType.INNER_JOIN );
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
 		// start by looking for HQL keywords...
-		String lcToken = token.toLowerCase();
+		String lcToken = token.toLowerCase(Locale.ROOT);
 		if ( lcToken.equals( "," ) ) {
 			if ( !( expectingJoin | expectingAs ) ) throw new QueryException( "unexpected token: ," );
 			expectingJoin = false;
 			expectingAs = false;
 		}
 		else if ( lcToken.equals( "join" ) ) {
 			if ( !afterJoinType ) {
 				if ( !( expectingJoin | expectingAs ) ) throw new QueryException( "unexpected token: join" );
 				// inner joins can be abbreviated to 'join'
 				joinType = JoinType.INNER_JOIN;
 				expectingJoin = false;
 				expectingAs = false;
 			}
 			else {
 				afterJoinType = false;
 			}
 		}
 		else if ( lcToken.equals( "fetch" ) ) {
 			if ( q.isShallowQuery() ) throw new QueryException( QueryTranslator.ERROR_CANNOT_FETCH_WITH_ITERATE );
 			if ( joinType == JoinType.NONE ) throw new QueryException( "unexpected token: fetch" );
 			if ( joinType == JoinType.FULL_JOIN || joinType == JoinType.RIGHT_OUTER_JOIN ) {
 				throw new QueryException( "fetch may only be used with inner join or left outer join" );
 			}
 			afterFetch = true;
 		}
 		else if ( lcToken.equals( "outer" ) ) {
 			// 'outer' is optional and is ignored
 			if ( !afterJoinType ||
 					( joinType != JoinType.LEFT_OUTER_JOIN && joinType != JoinType.RIGHT_OUTER_JOIN )
 			) {
 				throw new QueryException( "unexpected token: outer" );
 			}
 		}
 		else if ( JOIN_TYPES.containsKey( lcToken ) ) {
 			if ( !( expectingJoin | expectingAs ) ) throw new QueryException( "unexpected token: " + token );
 			joinType = JOIN_TYPES.get( lcToken );
 			afterJoinType = true;
 			expectingJoin = false;
 			expectingAs = false;
 		}
 		else if ( lcToken.equals( "class" ) ) {
 			if ( !afterIn ) throw new QueryException( "unexpected token: class" );
 			if ( joinType != JoinType.NONE ) throw new QueryException( "outer or full join must be followed by path expression" );
 			afterClass = true;
 		}
 		else if ( lcToken.equals( "in" ) ) {
 			if (alias == null ){
 				memberDeclarations = true;
 				afterMemberDeclarations = false;
 			}
 			else if ( !expectingIn ) {
 				throw new QueryException( "unexpected token: in" );
 			} else {
 				afterIn = true;
 				expectingIn = false;
 			}
 		}
 		else if ( lcToken.equals( "as" ) ) {
 			if ( !expectingAs ) throw new QueryException( "unexpected token: as" );
 			afterAs = true;
 			expectingAs = false;
 		}
 		else if ( "(".equals( token ) ){
 			if( !memberDeclarations ) throw new QueryException( "unexpected token: (" );
 			//TODO alias should be null here
 			expectingPathExpression = true;
 			
 		}
 		else if ( ")".equals( token ) ){
 //			memberDeclarations = false;
 //			expectingPathExpression = false;
 			afterMemberDeclarations = true;
 		}
 		else {
 
 			if ( afterJoinType ) throw new QueryException( "join expected: " + token );
 			if ( expectingJoin ) throw new QueryException( "unexpected token: " + token );
 			if ( expectingIn ) throw new QueryException( "in expected: " + token );
 
 			// now anything that is not a HQL keyword
 
 			if ( afterAs || expectingAs ) {
 
 				// (AS is always optional, for consistency with SQL/OQL)
 
 				// process the "new" HQL style where aliases are assigned
 				// _after_ the class name or path expression ie. using
 				// the AS construction
 
 				if ( entityName != null ) {
 					q.setAliasName( token, entityName );
 				}
 				else if ( collectionName != null ) {
 					q.setAliasName( token, collectionName );
 				}
 				else {
 					throw new QueryException( "unexpected: as " + token );
 				}
 				afterAs = false;
 				expectingJoin = true;
 				expectingAs = false;
 				entityName = null;
 				collectionName = null;
 				memberDeclarations = false;
 				expectingPathExpression = false;
 				afterMemberDeclarations = false;
 
 			}
 			else if ( afterIn ) {
 
 				// process the "old" HQL style where aliases appear _first_
 				// ie. using the IN or IN CLASS constructions
 
 				if ( alias == null ) throw new QueryException( "alias not specified for: " + token );
 
 				if ( joinType != JoinType.NONE ) throw new QueryException( "outer or full join must be followed by path expression" );
 
 				if ( afterClass ) {
 					// treat it as a classname
 					Queryable p = q.getEntityPersisterUsingImports( token );
 					if ( p == null ) throw new QueryException( "persister not found: " + token );
 					q.addFromClass( alias, p );
 				}
 				else {
 					// treat it as a path expression
 					peParser.setJoinType( JoinType.INNER_JOIN );
 					peParser.setUseThetaStyleJoin( true );
 					ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 					if ( !peParser.isCollectionValued() ) throw new QueryException( "path expression did not resolve to collection: " + token );
 					String nm = peParser.addFromCollection( q );
 					q.setAliasName( alias, nm );
 				}
 
 				alias = null;
 				afterIn = false;
 				afterClass = false;
 				expectingJoin = true;
 			}
 			else if( memberDeclarations && expectingPathExpression ){
 				expectingAs = true;
 				peParser.setJoinType( JoinType.INNER_JOIN );
 				peParser.setUseThetaStyleJoin( false );
 				ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 				if ( !peParser.isCollectionValued() ) throw new QueryException( "path expression did not resolve to collection: " + token );
 				collectionName = peParser.addFromCollection( q );
 				expectingPathExpression = false;
 				memberDeclarations = false;
 			}
 			else {
 
 				// handle a path expression or class name that
 				// appears at the start, in the "new" HQL
 				// style or an alias that appears at the start
 				// in the "old" HQL style
 
 				Queryable p = q.getEntityPersisterUsingImports( token );
 				if ( p != null ) {
 					// starts with the name of a mapped class (new style)
 					if ( joinType != JoinType.NONE ) throw new QueryException( "outer or full join must be followed by path expression" );
 					entityName = q.createNameFor( p.getEntityName() );
 					q.addFromClass( entityName, p );
 					expectingAs = true;
 				}
 				else if ( token.indexOf( '.' ) < 0 ) {
 					// starts with an alias (old style)
 					// semi-bad thing about this: can't re-alias another alias.....
 					alias = token;
 					expectingIn = true;
 				}
 				else {
 
 					// starts with a path expression (new style)
 
 					// force HQL style: from Person p inner join p.cars c
 					//if (joinType==NONE) throw new QueryException("path expression must be preceded by full, left, right or inner join");
 
 					//allow ODMG OQL style: from Person p, p.cars c
 					if ( joinType != JoinType.NONE ) {
 						peParser.setJoinType( joinType );
 					}
 					else {
 						peParser.setJoinType( JoinType.INNER_JOIN );
 					}
 					peParser.setUseThetaStyleJoin( q.isSubquery() );
 
 					ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 					entityName = peParser.addFromAssociation( q );
 
 					joinType = JoinType.NONE;
 					peParser.setJoinType( JoinType.INNER_JOIN );
 
 					if ( afterFetch ) {
 						peParser.fetch( q, entityName );
 						afterFetch = false;
 					}
 
 					expectingAs = true;
 
 				}
 			}
 		}
 
 	}
 
 	public void start(QueryTranslatorImpl q) {
 		entityName = null;
 		collectionName = null;
 		alias = null;
 		afterIn = false;
 		afterAs = false;
 		afterClass = false;
 		expectingJoin = false;
 		expectingIn = false;
 		expectingAs = false;
 		memberDeclarations = false;
 		expectingPathExpression = false;
 		afterMemberDeclarations = false;
 		joinType = JoinType.NONE;
 	}
 
 	public void end(QueryTranslatorImpl q) {
 		if( afterMemberDeclarations ){
 			//The exception throwned by the AST query translator contains the error token location, respensent by line and colum, 
 			//but it hard to get that info here.
 			throw new QueryException("alias not specified for IN");
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
index 9a73da7f1f..9dc99864d3 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
@@ -1,156 +1,157 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashSet;
+import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  *
  */
 public class PreprocessingParser implements Parser {
 
 	private static final Set HQL_OPERATORS;
 
 	static {
 		HQL_OPERATORS = new HashSet();
 		HQL_OPERATORS.add( "<=" );
 		HQL_OPERATORS.add( ">=" );
 		HQL_OPERATORS.add( "=>" );
 		HQL_OPERATORS.add( "=<" );
 		HQL_OPERATORS.add( "!=" );
 		HQL_OPERATORS.add( "<>" );
 		HQL_OPERATORS.add( "!#" );
 		HQL_OPERATORS.add( "!~" );
 		HQL_OPERATORS.add( "!<" );
 		HQL_OPERATORS.add( "!>" );
 		HQL_OPERATORS.add( "is not" );
 		HQL_OPERATORS.add( "not like" );
 		HQL_OPERATORS.add( "not in" );
 		HQL_OPERATORS.add( "not between" );
 		HQL_OPERATORS.add( "not exists" );
 	}
 
 	private Map replacements;
 	private boolean quoted;
 	private StringBuilder quotedString;
 	private ClauseParser parser = new ClauseParser();
 	private String lastToken;
 	private String currentCollectionProp;
 
 	public PreprocessingParser(Map replacements) {
 		this.replacements = replacements;
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
 		//handle quoted strings
 		if ( quoted ) {
 			quotedString.append( token );
 		}
 		if ( "'".equals( token ) ) {
 			if ( quoted ) {
 				token = quotedString.toString();
 			}
 			else {
 				quotedString = new StringBuilder( 20 ).append( token );
 			}
 			quoted = !quoted;
 		}
 		if ( quoted ) return;
 
 		//ignore whitespace
 		if ( ParserHelper.isWhitespace( token ) ) return;
 
 		//do replacements
 		String substoken = ( String ) replacements.get( token );
 		token = ( substoken == null ) ? token : substoken;
 
 		//handle HQL2 collection syntax
 		if ( currentCollectionProp != null ) {
 			if ( "(".equals( token ) ) {
 				return;
 			}
 			else if ( ")".equals( token ) ) {
 				currentCollectionProp = null;
 				return;
 			}
 			else {
 				token = StringHelper.qualify( token, currentCollectionProp );
 			}
 		}
 		else {
-			String prop = CollectionProperties.getNormalizedPropertyName( token.toLowerCase() );
+			String prop = CollectionProperties.getNormalizedPropertyName( token.toLowerCase(Locale.ROOT) );
 			if ( prop != null ) {
 				currentCollectionProp = prop;
 				return;
 			}
 		}
 
 
 		//handle <=, >=, !=, is not, not between, not in
 		if ( lastToken == null ) {
 			lastToken = token;
 		}
 		else {
 			String doubleToken = ( token.length() > 1 ) ?
 					lastToken + ' ' + token :
 					lastToken + token;
-			if ( HQL_OPERATORS.contains( doubleToken.toLowerCase() ) ) {
+			if ( HQL_OPERATORS.contains( doubleToken.toLowerCase(Locale.ROOT) ) ) {
 				parser.token( doubleToken, q );
 				lastToken = null;
 			}
 			else {
 				parser.token( lastToken, q );
 				lastToken = token;
 			}
 		}
 
 	}
 
 	public void start(QueryTranslatorImpl q) throws QueryException {
 		quoted = false;
 		parser.start( q );
 	}
 
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		if ( lastToken != null ) parser.token( lastToken, q );
 		parser.end( q );
 		lastToken = null;
 		currentCollectionProp = null;
 	}
 
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
index ab47f4c1f6..a4002548a3 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
@@ -1,1246 +1,1247 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.io.Serializable;
 import java.lang.reflect.Constructor;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
+import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.hql.internal.NameGenerator;
 import org.hibernate.hql.spi.FilterTranslator;
 import org.hibernate.hql.spi.ParameterTranslations;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.IteratorImpl;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.sql.QuerySelect;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * An instance of <tt>QueryTranslator</tt> translates a Hibernate
  * query string to SQL.
  */
 public class QueryTranslatorImpl extends BasicLoader implements FilterTranslator {
     private static final CoreMessageLogger LOG = CoreLogging.messageLogger( QueryTranslatorImpl.class );
 
 	private static final String[] NO_RETURN_ALIASES = new String[] {};
 
 	private final String queryIdentifier;
 	private final String queryString;
 
 	private final Map typeMap = new LinkedHashMap();
 	private final Map collections = new LinkedHashMap();
 	private List returnedTypes = new ArrayList();
 	private final List fromTypes = new ArrayList();
 	private final List scalarTypes = new ArrayList();
 	private final Map namedParameters = new HashMap();
 	private final Map aliasNames = new HashMap();
 	private final Map oneToOneOwnerNames = new HashMap();
 	private final Map uniqueKeyOwnerReferences = new HashMap();
 	private final Map decoratedPropertyMappings = new HashMap();
 
 	private final List scalarSelectTokens = new ArrayList();
 	private final List whereTokens = new ArrayList();
 	private final List havingTokens = new ArrayList();
 	private final Map joins = new LinkedHashMap();
 	private final List orderByTokens = new ArrayList();
 	private final List groupByTokens = new ArrayList();
 	private final Set<Serializable> querySpaces = new HashSet<Serializable>();
 	private final Set entitiesToFetch = new HashSet();
 
 	private final Map pathAliases = new HashMap();
 	private final Map pathJoins = new HashMap();
 
 	private Queryable[] persisters;
 	private int[] owners;
 	private EntityType[] ownerAssociationTypes;
 	private String[] names;
 	private boolean[] includeInSelect;
 	private int selectLength;
 	private Type[] returnTypes;
 	private Type[] actualReturnTypes;
 	private String[][] scalarColumnNames;
 	private Map tokenReplacements;
 	private int nameCount;
 	private int parameterCount;
 	private boolean distinct;
 	private boolean compiled;
 	private String sqlString;
 	private Class holderClass;
 	private Constructor holderConstructor;
 	private boolean hasScalars;
 	private boolean shallowQuery;
 	private QueryTranslatorImpl superQuery;
 
 	private QueryableCollection collectionPersister;
 	private int collectionOwnerColumn = -1;
 	private String collectionOwnerName;
 	private String fetchName;
 
 	private String[] suffixes;
 
 	private Map enabledFilters;
 
 	/**
 	 * Construct a query translator
 	 *
 	 * @param queryIdentifier A unique identifier for the query of which this
 	 * translation is part; typically this is the original, user-supplied query string.
 	 * @param queryString The "preprocessed" query string; at the very least
 	 * already processed by {@link org.hibernate.hql.internal.QuerySplitter}.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 			String queryIdentifier,
 	        String queryString,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		super( factory );
 		this.queryIdentifier = queryIdentifier;
 		this.queryString = queryString;
 		this.enabledFilters = enabledFilters;
 	}
 
 	/**
 	 * Construct a query translator; this form used internally.
 	 *
 	 * @param queryString The query string to process.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 	        String queryString,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		this( queryString, queryString, enabledFilters, factory );
 	}
 
 	/**
 	 * Compile a subquery.
 	 *
 	 * @param superquery The containing query of the query to be compiled.
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	void compile(QueryTranslatorImpl superquery) throws QueryException, MappingException {
 		this.tokenReplacements = superquery.tokenReplacements;
 		this.superQuery = superquery;
 		this.shallowQuery = true;
 		this.enabledFilters = superquery.getEnabledFilters();
 		compile();
 	}
 
 
 	/**
 	 * Compile a "normal" query. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 		if ( !compiled ) {
 			this.tokenReplacements = replacements;
 			this.shallowQuery = scalar;
 			compile();
 		}
 	}
 
 	/**
 	 * Compile a filter. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			String collectionRole,
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 
 		if ( !isCompiled() ) {
 			addFromAssociation( "this", collectionRole );
 			compile( replacements, scalar );
 		}
 	}
 
 	/**
 	 * Compile the query (generate the SQL).
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	private void compile() throws QueryException, MappingException {
 		LOG.trace( "Compiling query" );
 		try {
 			ParserHelper.parse( new PreprocessingParser( tokenReplacements ),
 					queryString,
 					ParserHelper.HQL_SEPARATORS,
 					this );
 			renderSQL();
 		}
 		catch ( QueryException qe ) {
 			if ( qe.getQueryString() == null ) {
 				throw qe.wrapWithQueryString( queryString );
 			}
 			else {
 				throw qe;
 			}
 		}
 		catch ( MappingException me ) {
 			throw me;
 		}
 		catch ( Exception e ) {
 			LOG.debug( "Unexpected query compilation problem", e );
 			e.printStackTrace();
 			throw new QueryException( "Incorrect query syntax", queryString, e );
 		}
 
 		postInstantiate();
 
 		compiled = true;
 
 	}
 
 	@Override
     public String getSQLString() {
 		return sqlString;
 	}
 
 	public List<String> collectSqlStrings() {
 		return ArrayHelper.toList( new String[] { sqlString } );
 	}
 
 	public String getQueryString() {
 		return queryString;
 	}
 
 	/**
 	 * Persisters for the return values of a <tt>find()</tt> style query.
 	 *
 	 * @return an array of <tt>EntityPersister</tt>s.
 	 */
 	@Override
     protected Loadable[] getEntityPersisters() {
 		return persisters;
 	}
 
 	/**
 	 * Types of the return values of an <tt>iterate()</tt> style query.
 	 *
 	 * @return an array of <tt>Type</tt>s.
 	 */
 	public Type[] getReturnTypes() {
 		return actualReturnTypes;
 	}
 
 	public String[] getReturnAliases() {
 		// return aliases not supported in classic translator!
 		return NO_RETURN_ALIASES;
 	}
 
 	public String[][] getColumnNames() {
 		return scalarColumnNames;
 	}
 
 	private static void logQuery(String hql, String sql) {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "HQL: %s", hql );
 			LOG.debugf( "SQL: %s", sql );
 		}
 	}
 
 	void setAliasName(String alias, String name) {
 		aliasNames.put( alias, name );
 	}
 
 	public String getAliasName(String alias) {
 		String name = ( String ) aliasNames.get( alias );
 		if ( name == null ) {
 			if ( superQuery != null ) {
 				name = superQuery.getAliasName( alias );
 			}
 			else {
 				name = alias;
 			}
 		}
 		return name;
 	}
 
 	String unalias(String path) {
 		String alias = StringHelper.root( path );
 		String name = getAliasName( alias );
         if (name != null) return name + path.substring(alias.length());
         return path;
 	}
 
 	void addEntityToFetch(String name, String oneToOneOwnerName, AssociationType ownerAssociationType) {
 		addEntityToFetch( name );
 		if ( oneToOneOwnerName != null ) oneToOneOwnerNames.put( name, oneToOneOwnerName );
 		if ( ownerAssociationType != null ) uniqueKeyOwnerReferences.put( name, ownerAssociationType );
 	}
 
 	private void addEntityToFetch(String name) {
 		entitiesToFetch.add( name );
 	}
 
 	private int nextCount() {
 		return ( superQuery == null ) ? nameCount++ : superQuery.nameCount++;
 	}
 
 	String createNameFor(String type) {
 		return StringHelper.generateAlias( type, nextCount() );
 	}
 
 	String createNameForCollection(String role) {
 		return StringHelper.generateAlias( role, nextCount() );
 	}
 
 	private String getType(String name) {
 		String type = ( String ) typeMap.get( name );
 		if ( type == null && superQuery != null ) {
 			type = superQuery.getType( name );
 		}
 		return type;
 	}
 
 	private String getRole(String name) {
 		String role = ( String ) collections.get( name );
 		if ( role == null && superQuery != null ) {
 			role = superQuery.getRole( name );
 		}
 		return role;
 	}
 
 	boolean isName(String name) {
 		return aliasNames.containsKey( name ) ||
 				typeMap.containsKey( name ) ||
 				collections.containsKey( name ) || (
 				superQuery != null && superQuery.isName( name )
 				);
 	}
 
 	PropertyMapping getPropertyMapping(String name) throws QueryException {
 		PropertyMapping decorator = getDecoratedPropertyMapping( name );
 		if ( decorator != null ) return decorator;
 
 		String type = getType( name );
 		if ( type == null ) {
 			String role = getRole( name );
 			if ( role == null ) {
 				throw new QueryException( "alias not found: " + name );
 			}
 			return getCollectionPersister( role ); //.getElementPropertyMapping();
 		}
 		else {
 			Queryable persister = getEntityPersister( type );
 			if ( persister == null ) throw new QueryException( "persistent class not found: " + type );
 			return persister;
 		}
 	}
 
 	private PropertyMapping getDecoratedPropertyMapping(String name) {
 		return ( PropertyMapping ) decoratedPropertyMappings.get( name );
 	}
 
 	void decoratePropertyMapping(String name, PropertyMapping mapping) {
 		decoratedPropertyMappings.put( name, mapping );
 	}
 
 	private Queryable getEntityPersisterForName(String name) throws QueryException {
 		String type = getType( name );
 		Queryable persister = getEntityPersister( type );
 		if ( persister == null ) throw new QueryException( "persistent class not found: " + type );
 		return persister;
 	}
 
 	Queryable getEntityPersisterUsingImports(String className) {
 		final String importedClassName = getFactory().getImportedClassName( className );
 		if ( importedClassName == null ) {
 			return null;
 		}
 		try {
 			return ( Queryable ) getFactory().getEntityPersister( importedClassName );
 		}
 		catch ( MappingException me ) {
 			return null;
 		}
 	}
 
 	Queryable getEntityPersister(String entityName) throws QueryException {
 		try {
 			return ( Queryable ) getFactory().getEntityPersister( entityName );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( "persistent class not found: " + entityName );
 		}
 	}
 
 	QueryableCollection getCollectionPersister(String role) throws QueryException {
 		try {
 			return ( QueryableCollection ) getFactory().getCollectionPersister( role );
 		}
 		catch ( ClassCastException cce ) {
 			throw new QueryException( "collection role is not queryable: " + role );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( "collection role not found: " + role );
 		}
 	}
 
 	void addType(String name, String type) {
 		typeMap.put( name, type );
 	}
 
 	void addCollection(String name, String role) {
 		collections.put( name, role );
 	}
 
 	void addFrom(String name, String type, JoinSequence joinSequence)
 			throws QueryException {
 		addType( name, type );
 		addFrom( name, joinSequence );
 	}
 
 	void addFromCollection(String name, String collectionRole, JoinSequence joinSequence)
 			throws QueryException {
 		//register collection role
 		addCollection( name, collectionRole );
 		addJoin( name, joinSequence );
 	}
 
 	void addFrom(String name, JoinSequence joinSequence)
 			throws QueryException {
 		fromTypes.add( name );
 		addJoin( name, joinSequence );
 	}
 
 	void addFromClass(String name, Queryable classPersister)
 			throws QueryException {
 		JoinSequence joinSequence = new JoinSequence( getFactory() )
 				.setRoot( classPersister, name );
 		//crossJoins.add(name);
 		addFrom( name, classPersister.getEntityName(), joinSequence );
 	}
 
 	void addSelectClass(String name) {
 		returnedTypes.add( name );
 	}
 
 	void addSelectScalar(Type type) {
 		scalarTypes.add( type );
 	}
 
 	void appendWhereToken(String token) {
 		whereTokens.add( token );
 	}
 
 	void appendHavingToken(String token) {
 		havingTokens.add( token );
 	}
 
 	void appendOrderByToken(String token) {
 		orderByTokens.add( token );
 	}
 
 	void appendGroupByToken(String token) {
 		groupByTokens.add( token );
 	}
 
 	void appendScalarSelectToken(String token) {
 		scalarSelectTokens.add( token );
 	}
 
 	void appendScalarSelectTokens(String[] tokens) {
 		scalarSelectTokens.add( tokens );
 	}
 
 	void addFromJoinOnly(String name, JoinSequence joinSequence) throws QueryException {
 		addJoin( name, joinSequence.getFromPart() );
 	}
 
 	void addJoin(String name, JoinSequence joinSequence) throws QueryException {
 		if ( !joins.containsKey( name ) ) joins.put( name, joinSequence );
 	}
 
 	void addNamedParameter(String name) {
 		if ( superQuery != null ) superQuery.addNamedParameter( name );
 		Integer loc = parameterCount++;
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
 			( ( ArrayList ) o ).add( loc );
 		}
 	}
 
 	@Override
     public int[] getNamedParameterLocs(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			throw new QueryException( ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name, queryString );
 		}
 		if ( o instanceof Integer ) return new int[] { (Integer) o };
 		else {
 			return ArrayHelper.toIntArray( ( ArrayList ) o );
 		}
 	}
 
 	private void renderSQL() throws QueryException, MappingException {
 
 		final int rtsize;
 		if ( returnedTypes.size() == 0 && scalarTypes.size() == 0 ) {
 			//ie no select clause in HQL
 			returnedTypes = fromTypes;
 			rtsize = returnedTypes.size();
 		}
 		else {
 			rtsize = returnedTypes.size();
 			Iterator iter = entitiesToFetch.iterator();
 			while ( iter.hasNext() ) {
 				returnedTypes.add( iter.next() );
 			}
 		}
 		int size = returnedTypes.size();
 		persisters = new Queryable[size];
 		names = new String[size];
 		owners = new int[size];
 		ownerAssociationTypes = new EntityType[size];
 		suffixes = new String[size];
 		includeInSelect = new boolean[size];
 		for ( int i = 0; i < size; i++ ) {
 			String name = ( String ) returnedTypes.get( i );
 			//if ( !isName(name) ) throw new QueryException("unknown type: " + name);
 			persisters[i] = getEntityPersisterForName( name );
 			// TODO: cannot use generateSuffixes() - it handles the initial suffix differently.
 			suffixes[i] = ( size == 1 ) ? "" : Integer.toString( i ) + '_';
 			names[i] = name;
 			includeInSelect[i] = !entitiesToFetch.contains( name );
 			if ( includeInSelect[i] ) selectLength++;
 			if ( name.equals( collectionOwnerName ) ) collectionOwnerColumn = i;
 			String oneToOneOwner = ( String ) oneToOneOwnerNames.get( name );
 			owners[i] = ( oneToOneOwner == null ) ? -1 : returnedTypes.indexOf( oneToOneOwner );
 			ownerAssociationTypes[i] = (EntityType) uniqueKeyOwnerReferences.get( name );
 		}
 
 		if ( ArrayHelper.isAllNegative( owners ) ) owners = null;
 
 		String scalarSelect = renderScalarSelect(); //Must be done here because of side-effect! yuck...
 
 		int scalarSize = scalarTypes.size();
 		hasScalars = scalarTypes.size() != rtsize;
 
 		returnTypes = new Type[scalarSize];
 		for ( int i = 0; i < scalarSize; i++ ) {
 			returnTypes[i] = ( Type ) scalarTypes.get( i );
 		}
 
 		QuerySelect sql = new QuerySelect( getFactory().getDialect() );
 		sql.setDistinct( distinct );
 
 		if ( !shallowQuery ) {
 			renderIdentifierSelect( sql );
 			renderPropertiesSelect( sql );
 		}
 
 		if ( collectionPersister != null ) {
 			sql.addSelectFragmentString( collectionPersister.selectFragment( fetchName, "__" ) );
 		}
 
 		if ( hasScalars || shallowQuery ) sql.addSelectFragmentString( scalarSelect );
 
 		//TODO: for some dialects it would be appropriate to add the renderOrderByPropertiesSelect() to other select strings
 		mergeJoins( sql.getJoinFragment() );
 
 		sql.setWhereTokens( whereTokens.iterator() );
 
 		sql.setGroupByTokens( groupByTokens.iterator() );
 		sql.setHavingTokens( havingTokens.iterator() );
 		sql.setOrderByTokens( orderByTokens.iterator() );
 
 		if ( collectionPersister != null && collectionPersister.hasOrdering() ) {
 			sql.addOrderBy( collectionPersister.getSQLOrderByString( fetchName ) );
 		}
 
 		scalarColumnNames = NameGenerator.generateColumnNames( returnTypes, getFactory() );
 
 		// initialize the Set of queried identifier spaces (ie. tables)
 		Iterator iter = collections.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = getCollectionPersister( ( String ) iter.next() );
 			addQuerySpaces( p.getCollectionSpaces() );
 		}
 		iter = typeMap.keySet().iterator();
 		while ( iter.hasNext() ) {
 			Queryable p = getEntityPersisterForName( ( String ) iter.next() );
 			addQuerySpaces( p.getQuerySpaces() );
 		}
 
 		sqlString = sql.toQueryString();
 
 		if ( holderClass != null ) holderConstructor = ReflectHelper.getConstructor( holderClass, returnTypes );
 
 		if ( hasScalars ) {
 			actualReturnTypes = returnTypes;
 		}
 		else {
 			actualReturnTypes = new Type[selectLength];
 			int j = 0;
 			for ( int i = 0; i < persisters.length; i++ ) {
 				if ( includeInSelect[i] ) {
 					actualReturnTypes[j++] = getFactory().getTypeResolver()
 							.getTypeFactory()
 							.manyToOne( persisters[i].getEntityName(), shallowQuery );
 				}
 			}
 		}
 
 	}
 
 	private void renderIdentifierSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 
 		for ( int k = 0; k < size; k++ ) {
 			String name = ( String ) returnedTypes.get( k );
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			sql.addSelectFragmentString( persisters[k].identifierSelectFragment( name, suffix ) );
 		}
 
 	}
 
 	/*private String renderOrderByPropertiesSelect() {
 		StringBuffer buf = new StringBuffer(10);
 
 		//add the columns we are ordering by to the select ID select clause
 		Iterator iter = orderByTokens.iterator();
 		while ( iter.hasNext() ) {
 			String token = (String) iter.next();
 			if ( token.lastIndexOf(".") > 0 ) {
 				//ie. it is of form "foo.bar", not of form "asc" or "desc"
 				buf.append(StringHelper.COMMA_SPACE).append(token);
 			}
 		}
 
 		return buf.toString();
 	}*/
 
 	private void renderPropertiesSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 		for ( int k = 0; k < size; k++ ) {
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			String name = ( String ) returnedTypes.get( k );
 			sql.addSelectFragmentString( persisters[k].propertySelectFragment( name, suffix, false ) );
 		}
 	}
 
 	/**
 	 * WARNING: side-effecty
 	 */
 	private String renderScalarSelect() {
 
 		boolean isSubselect = superQuery != null;
 
 		StringBuilder buf = new StringBuilder( 20 );
 
 		if ( scalarTypes.size() == 0 ) {
 			//ie. no select clause
 			int size = returnedTypes.size();
 			for ( int k = 0; k < size; k++ ) {
 
 				scalarTypes.add(
 						getFactory().getTypeResolver().getTypeFactory().manyToOne( persisters[k].getEntityName(), shallowQuery )
 				);
 
 				String[] idColumnNames = persisters[k].getIdentifierColumnNames();
 				for ( int i = 0; i < idColumnNames.length; i++ ) {
 					buf.append( returnedTypes.get( k ) ).append( '.' ).append( idColumnNames[i] );
 					if ( !isSubselect ) buf.append( " as " ).append( NameGenerator.scalarName( k, i ) );
 					if ( i != idColumnNames.length - 1 || k != size - 1 ) buf.append( ", " );
 				}
 
 			}
 
 		}
 		else {
 			//there _was_ a select clause
 			Iterator iter = scalarSelectTokens.iterator();
 			int c = 0;
 			boolean nolast = false; //real hacky...
 			int parenCount = 0; // used to count the nesting of parentheses
 			while ( iter.hasNext() ) {
 				Object next = iter.next();
 				if ( next instanceof String ) {
 					String token = ( String ) next;
 
 					if ( "(".equals( token ) ) {
 						parenCount++;
 					}
 					else if ( ")".equals( token ) ) {
 						parenCount--;
 					}
 
-					String lc = token.toLowerCase();
+					String lc = token.toLowerCase(Locale.ROOT);
 					if ( lc.equals( ", " ) ) {
 						if ( nolast ) {
 							nolast = false;
 						}
 						else {
 							if ( !isSubselect && parenCount == 0 ) {
 								int x = c++;
 								buf.append( " as " )
 										.append( NameGenerator.scalarName( x, 0 ) );
 							}
 						}
 					}
 					buf.append( token );
 					if ( lc.equals( "distinct" ) || lc.equals( "all" ) ) {
 						buf.append( ' ' );
 					}
 				}
 				else {
 					nolast = true;
 					String[] tokens = ( String[] ) next;
 					for ( int i = 0; i < tokens.length; i++ ) {
 						buf.append( tokens[i] );
 						if ( !isSubselect ) {
 							buf.append( " as " )
 									.append( NameGenerator.scalarName( c, i ) );
 						}
 						if ( i != tokens.length - 1 ) buf.append( ", " );
 					}
 					c++;
 				}
 			}
 			if ( !isSubselect && !nolast ) {
 				int x = c++;
 				buf.append( " as " )
 						.append( NameGenerator.scalarName( x, 0 ) );
 			}
 
 		}
 
 		return buf.toString();
 	}
 
 	private void mergeJoins(JoinFragment ojf) throws MappingException, QueryException {
 
 		Iterator iter = joins.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = ( Map.Entry ) iter.next();
 			String name = ( String ) me.getKey();
 			JoinSequence join = ( JoinSequence ) me.getValue();
 			join.setSelector( new JoinSequence.Selector() {
 				public boolean includeSubclasses(String alias) {
 					boolean include = returnedTypes.contains( alias ) && !isShallowQuery();
 					return include;
 				}
 			} );
 
 			if ( typeMap.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 			else if ( collections.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 			else {
 				//name from a super query (a bit inelegant that it shows up here)
 			}
 
 		}
 
 	}
 
 	public final Set<Serializable> getQuerySpaces() {
 		return querySpaces;
 	}
 
 	/**
 	 * Is this query called by scroll() or iterate()?
 	 *
 	 * @return true if it is, false if it is called by find() or list()
 	 */
 	boolean isShallowQuery() {
 		return shallowQuery;
 	}
 
 	void addQuerySpaces(Serializable[] spaces) {
 		Collections.addAll( querySpaces, spaces );
 		if ( superQuery != null ) superQuery.addQuerySpaces( spaces );
 	}
 
 	void setDistinct(boolean distinct) {
 		this.distinct = distinct;
 	}
 
 	boolean isSubquery() {
 		return superQuery != null;
 	}
 
 	/**
 	 * Overrides method from Loader
 	 */
 	@Override
     public CollectionPersister[] getCollectionPersisters() {
 		return collectionPersister == null ? null : new CollectionPersister[] { collectionPersister };
 	}
 
 	@Override
     protected String[] getCollectionSuffixes() {
 		return collectionPersister == null ? null : new String[] { "__" };
 	}
 
 	void setCollectionToFetch(String role, String name, String ownerName, String entityName)
 			throws QueryException {
 		fetchName = name;
 		collectionPersister = getCollectionPersister( role );
 		collectionOwnerName = ownerName;
 		if ( collectionPersister.getElementType().isEntityType() ) {
 			addEntityToFetch( entityName );
 		}
 	}
 
 	@Override
     protected String[] getSuffixes() {
 		return suffixes;
 	}
 
 	@Override
     protected String[] getAliases() {
 		return names;
 	}
 
 	/**
 	 * Used for collection filters
 	 */
 	private void addFromAssociation(final String elementName, final String collectionRole)
 			throws QueryException {
 		//q.addCollection(collectionName, collectionRole);
 		QueryableCollection persister = getCollectionPersister( collectionRole );
 		Type collectionElementType = persister.getElementType();
 		if ( !collectionElementType.isEntityType() ) {
 			throw new QueryException( "collection of values in filter: " + elementName );
 		}
 
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		//if (keyColumnNames.length!=1) throw new QueryException("composite-key collection in filter: " + collectionRole);
 
 		String collectionName;
 		JoinSequence join = new JoinSequence( getFactory() );
 		collectionName = persister.isOneToMany() ?
 				elementName :
 				createNameForCollection( collectionRole );
 		join.setRoot( persister, collectionName );
 		if ( !persister.isOneToMany() ) {
 			//many-to-many
 			addCollection( collectionName, collectionRole );
 			try {
 				join.addJoin( ( AssociationType ) persister.getElementType(),
 						elementName,
 						JoinType.INNER_JOIN,
 						persister.getElementColumnNames(collectionName) );
 			}
 			catch ( MappingException me ) {
 				throw new QueryException( me );
 			}
 		}
 		join.addCondition( collectionName, keyColumnNames, " = ?" );
 		//if ( persister.hasWhere() ) join.addCondition( persister.getSQLWhereString(collectionName) );
 		EntityType elemType = ( EntityType ) collectionElementType;
 		addFrom( elementName, elemType.getAssociatedEntityName(), join );
 
 	}
 
 	String getPathAlias(String path) {
 		return ( String ) pathAliases.get( path );
 	}
 
 	JoinSequence getPathJoin(String path) {
 		return ( JoinSequence ) pathJoins.get( path );
 	}
 
 	void addPathAliasAndJoin(String path, String alias, JoinSequence joinSequence) {
 		pathAliases.put( path, alias );
 		pathJoins.put( path, joinSequence );
 	}
 
 	@Override
 	public List list(SessionImplementor session, QueryParameters queryParameters)
 			throws HibernateException {
 		return list( session, queryParameters, getQuerySpaces(), actualReturnTypes );
 	}
 
 	/**
 	 * Return the query results as an iterator
 	 */
 	@Override
 	public Iterator iterate(QueryParameters queryParameters, EventSource session)
 			throws HibernateException {
 
 		boolean stats = session.getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) startTime = System.nanoTime();
 
 		try {
 			final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
 			HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(holderConstructor, queryParameters.getResultTransformer());
 			Iterator result = new IteratorImpl( rs, st, session, queryParameters.isReadOnly( session ), returnTypes, getColumnNames(), hi );
 
 			if ( stats ) {
 				final long endTime = System.nanoTime();
 				final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 				session.getFactory().getStatisticsImplementor().queryExecuted(
 						"HQL: " + queryString,
 						0,
 						milliseconds
 					);
 			}
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using iterate",
 					getSQLString()
 				);
 		}
 
 	}
 
 	public int executeUpdate(QueryParameters queryParameters, SessionImplementor session) throws HibernateException {
 		throw new UnsupportedOperationException( "Not supported!  Use the AST translator...");
 	}
 
 	@Override
     protected boolean[] includeInResultRow() {
 		boolean[] isResultReturned = includeInSelect;
 		if ( hasScalars ) {
 			isResultReturned = new boolean[ returnedTypes.size() ];
 			Arrays.fill( isResultReturned, true );
 		}
 		return isResultReturned;
 	}
 
 
 	@Override
     protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return HolderInstantiator.resolveClassicResultTransformer(
 				holderConstructor,
 				resultTransformer
 		);
 	}
 
 	@Override
     protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow = getResultRow( row, rs, session );
 		return ( holderClass == null && resultRow.length == 1 ?
 				resultRow[ 0 ] :
 				resultRow
 		);
 	}
 
 	@Override
     protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow;
 		if ( hasScalars ) {
 			String[][] scalarColumns = getColumnNames();
 			int queryCols = returnTypes.length;
 			resultRow = new Object[queryCols];
 			for ( int i = 0; i < queryCols; i++ ) {
 				resultRow[i] = returnTypes[i].nullSafeGet( rs, scalarColumns[i], session, null );
 			}
 		}
 		else {
 			resultRow = toResultRow( row );
 		}
 		return resultRow;
 	}
 
 	@Override
     protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		if ( holderClass != null ) {
 			for ( int i = 0; i < results.size(); i++ ) {
 				Object[] row = ( Object[] ) results.get( i );
 				try {
 					results.set( i, holderConstructor.newInstance( row ) );
 				}
 				catch ( Exception e ) {
 					throw new QueryException( "could not instantiate: " + holderClass, e );
 				}
 			}
 		}
 		return results;
 	}
 
 	private Object[] toResultRow(Object[] row) {
 		if ( selectLength == row.length ) {
 			return row;
 		}
 		else {
 			Object[] result = new Object[selectLength];
 			int j = 0;
 			for ( int i = 0; i < row.length; i++ ) {
 				if ( includeInSelect[i] ) result[j++] = row[i];
 			}
 			return result;
 		}
 	}
 
 	void setHolderClass(Class clazz) {
 		holderClass = clazz;
 	}
 
 	@Override
     protected LockMode[] getLockModes(LockOptions lockOptions) {
 
 		// unfortunately this stuff can't be cached because
 		// it is per-invocation, not constant for the
 		// QueryTranslator instance
 		HashMap nameLockOptions = new HashMap();
 		if ( lockOptions == null) {
 			lockOptions = LockOptions.NONE;
 		}
 
 		if ( lockOptions.getAliasLockCount() > 0 ) {
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
 				Map.Entry me = ( Map.Entry ) iter.next();
 				nameLockOptions.put( getAliasName( ( String ) me.getKey() ),
 						me.getValue() );
 			}
 		}
 		LockMode[] lockModesArray = new LockMode[names.length];
 		for ( int i = 0; i < names.length; i++ ) {
 			LockMode lm = ( LockMode ) nameLockOptions.get( names[i] );
 			//if ( lm == null ) lm = LockOptions.NONE;
 			if ( lm == null ) lm = lockOptions.getLockMode();
 			lockModesArray[i] = lm;
 		}
 		return lockModesArray;
 	}
 
 	@Override
     protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws QueryException {
 		// can't cache this stuff either (per-invocation)
 		final LockOptions lockOptions = parameters.getLockOptions();
 		final String result;
 		if ( lockOptions == null ||
 			( lockOptions.getLockMode() == LockMode.NONE && lockOptions.getAliasLockCount() == 0 ) ) {
 			return sql;
 		}
 		else {
 			LockOptions locks = new LockOptions();
 			locks.setLockMode(lockOptions.getLockMode());
 			locks.setTimeOut(lockOptions.getTimeOut());
 			locks.setScope(lockOptions.getScope());
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
 				Map.Entry me = ( Map.Entry ) iter.next();
 				locks.setAliasSpecificLockMode( getAliasName( ( String ) me.getKey() ), (LockMode) me.getValue() );
 			}
 			Map keyColumnNames = null;
 			if ( dialect.forUpdateOfColumns() ) {
 				keyColumnNames = new HashMap();
 				for ( int i = 0; i < names.length; i++ ) {
 					keyColumnNames.put( names[i], persisters[i].getIdentifierColumnNames() );
 				}
 			}
 			result = dialect.applyLocksToSql( sql, locks, keyColumnNames );
 		}
 		logQuery( queryString, result );
 		return result;
 	}
 
 	@Override
     protected boolean upgradeLocks() {
 		return true;
 	}
 
 	@Override
     protected int[] getCollectionOwners() {
 		return new int[] { collectionOwnerColumn };
 	}
 
 	protected boolean isCompiled() {
 		return compiled;
 	}
 
 	@Override
     public String toString() {
 		return queryString;
 	}
 
 	@Override
     protected int[] getOwners() {
 		return owners;
 	}
 
 	@Override
     protected EntityType[] getOwnerAssociationTypes() {
 		return ownerAssociationTypes;
 	}
 
 	public Class getHolderClass() {
 		return holderClass;
 	}
 
 	public Map getEnabledFilters() {
 		return enabledFilters;
 	}
 
 	public ScrollableResults scroll(final QueryParameters queryParameters,
 									final SessionImplementor session)
 			throws HibernateException {
 		HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(
 				holderConstructor, queryParameters.getResultTransformer()
 		);
 		return scroll( queryParameters, returnTypes, hi, session );
 	}
 
 	@Override
     public String getQueryIdentifier() {
 		return queryIdentifier;
 	}
 
 	@Override
     protected boolean isSubselectLoadingEnabled() {
 		return hasSubselectLoadableCollections();
 	}
 
 	public void validateScrollability() throws HibernateException {
 		// This is the legacy behaviour for HQL queries...
 		if ( getCollectionPersisters() != null ) {
 			throw new HibernateException( "Cannot scroll queries which initialize collections" );
 		}
 	}
 
 	public boolean containsCollectionFetches() {
 		return false;
 	}
 
 	public boolean isManipulationStatement() {
 		// classic parser does not support bulk manipulation statements
 		return false;
 	}
 
 	@Override
 	public Class getDynamicInstantiationResultType() {
 		return holderClass;
 	}
 
 	public ParameterTranslations getParameterTranslations() {
 		return new ParameterTranslations() {
 
 			public boolean supportsOrdinalParameterMetadata() {
 				// classic translator does not support collection of ordinal
 				// param metadata
 				return false;
 			}
 
 			public int getOrdinalParameterCount() {
 				return 0; // not known!
 			}
 
 			public int getOrdinalParameterSqlLocation(int ordinalPosition) {
 				return 0; // not known!
 			}
 
 			public Type getOrdinalParameterExpectedType(int ordinalPosition) {
 				return null; // not known!
 			}
 
 			public Set getNamedParameterNames() {
 				return namedParameters.keySet();
 			}
 
 			public int[] getNamedParameterSqlLocations(String name) {
 				return getNamedParameterLocs( name );
 			}
 
 			public Type getNamedParameterExpectedType(String name) {
 				return null; // not known!
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
index f5819addc7..b475830709 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
@@ -1,255 +1,256 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.internal.QuerySplitter;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * Parsers the select clause of a Hibernate query.
  *
  * @author Gavin King, David Channon
  */
 public class SelectParser implements Parser {
 
 	//TODO: arithmetic expressions, multiple new Foo(...)
 
 	private static final Set COUNT_MODIFIERS = new HashSet();
 
 	static {
 		COUNT_MODIFIERS.add( "distinct" );
 		COUNT_MODIFIERS.add( "all" );
 		COUNT_MODIFIERS.add( "*" );
 	}
 
 	private LinkedList aggregateFuncTokenList = new LinkedList();
 
 	private boolean ready;
 	private boolean aggregate;
 	private boolean first;
 	private boolean afterNew;
 	private boolean insideNew;
 	private boolean aggregateAddSelectScalar;
 	private Class holderClass;
 
 	private final SelectPathExpressionParser pathExpressionParser;
 	private final PathExpressionParser aggregatePathExpressionParser;
 
 	{
 		pathExpressionParser = new SelectPathExpressionParser();
 		aggregatePathExpressionParser = new PathExpressionParser();
 		//TODO: would be nice to use false, but issues with MS SQL
 		pathExpressionParser.setUseThetaStyleJoin( true );
 		aggregatePathExpressionParser.setUseThetaStyleJoin( true );
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
-		String lctoken = token.toLowerCase();
+		String lctoken = token.toLowerCase(Locale.ROOT);
 
 		if ( first ) {
 			first = false;
 			if ( "distinct".equals( lctoken ) ) {
 				q.setDistinct( true );
 				return;
 			}
 			else if ( "all".equals( lctoken ) ) {
 				q.setDistinct( false );
 				return;
 			}
 		}
 
 		if ( afterNew ) {
 			afterNew = false;
 			try {
 				holderClass = ReflectHelper.classForName( QuerySplitter.getImportedClass( token, q.getFactory() ) );
 			}
 			catch ( ClassNotFoundException cnfe ) {
 				throw new QueryException( cnfe );
 			}
 			if ( holderClass == null ) throw new QueryException( "class not found: " + token );
 			q.setHolderClass( holderClass );
 			insideNew = true;
 		}
 		else if ( token.equals( "," ) ) {
 			if ( !aggregate && ready ) throw new QueryException( "alias or expression expected in SELECT" );
 			q.appendScalarSelectToken( ", " );
 			ready = true;
 		}
 		else if ( "new".equals( lctoken ) ) {
 			afterNew = true;
 			ready = false;
 		}
 		else if ( "(".equals( token ) ) {
 			if ( insideNew && !aggregate && !ready ) {
 				//opening paren in new Foo ( ... )
 				ready = true;
 			}
 			else if ( aggregate ) {
 				q.appendScalarSelectToken( token );
 			}
 			else {
 				throw new QueryException( "aggregate function expected before ( in SELECT" );
 			}
 			ready = true;
 		}
 		else if ( ")".equals( token ) ) {
 			if ( insideNew && !aggregate && !ready ) {
 				//if we are inside a new Result(), but not inside a nested function
 				insideNew = false;
 			}
 			else if ( aggregate && ready ) {
 				q.appendScalarSelectToken( token );
 				aggregateFuncTokenList.removeLast();
 				if ( aggregateFuncTokenList.size() < 1 ) {
 					aggregate = false;
 					ready = false;
 				}
 			}
 			else {
 				throw new QueryException( "( expected before ) in select" );
 			}
 		}
 		else if ( COUNT_MODIFIERS.contains( lctoken ) ) {
 			if ( !ready || !aggregate ) {
 				throw new QueryException( token + " only allowed inside aggregate function in SELECT" );
 			}
 			q.appendScalarSelectToken( token );
 			if ( "*".equals( token ) ) {
 				// special case
 				q.addSelectScalar( getFunction( "count", q ).getReturnType( StandardBasicTypes.LONG, q.getFactory() ) );
 			}
 		}
 		else if ( getFunction( lctoken, q ) != null && token.equals( q.unalias( token ) ) ) {
 			// the name of an SQL function
 			if ( !ready ) throw new QueryException( ", expected before aggregate function in SELECT: " + token );
 			aggregate = true;
 			aggregateAddSelectScalar = true;
 			aggregateFuncTokenList.add( lctoken );
 			ready = false;
 			q.appendScalarSelectToken( token );
 			if ( !aggregateHasArgs( lctoken, q ) ) {
 				q.addSelectScalar( aggregateType( aggregateFuncTokenList, null, q ) );
 				if ( !aggregateFuncNoArgsHasParenthesis( lctoken, q ) ) {
 					aggregateFuncTokenList.removeLast();
 					if ( aggregateFuncTokenList.size() < 1 ) {
 						aggregate = false;
 						ready = false;
 					}
 					else {
 						ready = true;
 					}
 				}
 			}
 		}
 		else if ( aggregate ) {
 			boolean constantToken = false;
 			if ( !ready ) throw new QueryException( "( expected after aggregate function in SELECT" );
 			try {
 				ParserHelper.parse( aggregatePathExpressionParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 			}
 			catch ( QueryException qex ) {
 				constantToken = true;
 			}
 
 			if ( constantToken ) {
 				q.appendScalarSelectToken( token );
 			}
 			else {
 				if ( aggregatePathExpressionParser.isCollectionValued() ) {
 					q.addCollection( aggregatePathExpressionParser.getCollectionName(),
 							aggregatePathExpressionParser.getCollectionRole() );
 				}
 				q.appendScalarSelectToken( aggregatePathExpressionParser.getWhereColumn() );
 				if ( aggregateAddSelectScalar ) {
 					q.addSelectScalar( aggregateType( aggregateFuncTokenList, aggregatePathExpressionParser.getWhereColumnType(), q ) );
 					aggregateAddSelectScalar = false;
 				}
 				aggregatePathExpressionParser.addAssociation( q );
 			}
 		}
 		else {
 			if ( !ready ) throw new QueryException( ", expected in SELECT" );
 			ParserHelper.parse( pathExpressionParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 			if ( pathExpressionParser.isCollectionValued() ) {
 				q.addCollection( pathExpressionParser.getCollectionName(),
 						pathExpressionParser.getCollectionRole() );
 			}
 			else if ( pathExpressionParser.getWhereColumnType().isEntityType() ) {
 				q.addSelectClass( pathExpressionParser.getSelectName() );
 			}
 			q.appendScalarSelectTokens( pathExpressionParser.getWhereColumns() );
 			q.addSelectScalar( pathExpressionParser.getWhereColumnType() );
 			pathExpressionParser.addAssociation( q );
 
 			ready = false;
 		}
 	}
 
 	public boolean aggregateHasArgs(String funcToken, QueryTranslatorImpl q) {
 		return getFunction( funcToken, q ).hasArguments();
 	}
 
 	public boolean aggregateFuncNoArgsHasParenthesis(String funcToken, QueryTranslatorImpl q) {
 		return getFunction( funcToken, q ).hasParenthesesIfNoArguments();
 	}
 
 	public Type aggregateType(List funcTokenList, Type type, QueryTranslatorImpl q) throws QueryException {
 		Type retType = type;
 		Type argType;
 		for ( int i = funcTokenList.size() - 1; i >= 0; i-- ) {
 			argType = retType;
 			String funcToken = ( String ) funcTokenList.get( i );
 			retType = getFunction( funcToken, q ).getReturnType( argType, q.getFactory() );
 		}
 		return retType;
 	}
 
 	private SQLFunction getFunction(String name, QueryTranslatorImpl q) {
 		return q.getFactory().getSqlFunctionRegistry().findSQLFunction( name );
 	}
 
 	public void start(QueryTranslatorImpl q) {
 		ready = true;
 		first = true;
 		aggregate = false;
 		afterNew = false;
 		insideNew = false;
 		holderClass = null;
 		aggregateFuncTokenList.clear();
 	}
 
 	public void end(QueryTranslatorImpl q) {
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
index 6f557529d6..16c90faf79 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
@@ -1,515 +1,516 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedList;
+import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPropertyNames;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.InFragment;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.LiteralType;
 import org.hibernate.type.Type;
 
 /**
  * Parses the where clause of a hibernate query and translates it to an
  * SQL where clause.
  */
 
 // We should reengineer this class so that, rather than the current ad -
 // hoc linear approach to processing a stream of tokens, we instead
 // build up a tree of expressions.
 
 // We would probably refactor to have LogicParser (builds a tree of simple
 // expressions connected by and, or, not), ExpressionParser (translates
 // from OO terms like foo, foo.Bar, foo.Bar.Baz to SQL terms like
 // FOOS.ID, FOOS.BAR_ID, etc) and PathExpressionParser (which does much
 // the same thing it does now)
 
 public class WhereParser implements Parser {
 
 	private final PathExpressionParser pathExpressionParser;
 
 	{
 		pathExpressionParser = new PathExpressionParser();
 		pathExpressionParser.setUseThetaStyleJoin( true ); //Need this, since join condition can appear inside parens!
 	}
 
 	private static final Set EXPRESSION_TERMINATORS = new HashSet();   //tokens that close a sub expression
 	private static final Set EXPRESSION_OPENERS = new HashSet();       //tokens that open a sub expression
 	private static final Set BOOLEAN_OPERATORS = new HashSet();        //tokens that would indicate a sub expression is a boolean expression
 	private static final Map NEGATIONS = new HashMap();
 
 	static {
 		EXPRESSION_TERMINATORS.add( "and" );
 		EXPRESSION_TERMINATORS.add( "or" );
 		EXPRESSION_TERMINATORS.add( ")" );
 		//expressionTerminators.add(","); // deliberately excluded
 
 		EXPRESSION_OPENERS.add( "and" );
 		EXPRESSION_OPENERS.add( "or" );
 		EXPRESSION_OPENERS.add( "(" );
 		//expressionOpeners.add(","); // deliberately excluded
 
 		BOOLEAN_OPERATORS.add( "<" );
 		BOOLEAN_OPERATORS.add( "=" );
 		BOOLEAN_OPERATORS.add( ">" );
 		BOOLEAN_OPERATORS.add( "#" );
 		BOOLEAN_OPERATORS.add( "~" );
 		BOOLEAN_OPERATORS.add( "like" );
 		BOOLEAN_OPERATORS.add( "ilike" );
 		BOOLEAN_OPERATORS.add( "regexp" );
 		BOOLEAN_OPERATORS.add( "rlike" );
 		BOOLEAN_OPERATORS.add( "is" );
 		BOOLEAN_OPERATORS.add( "in" );
 		BOOLEAN_OPERATORS.add( "any" );
 		BOOLEAN_OPERATORS.add( "some" );
 		BOOLEAN_OPERATORS.add( "all" );
 		BOOLEAN_OPERATORS.add( "exists" );
 		BOOLEAN_OPERATORS.add( "between" );
 		BOOLEAN_OPERATORS.add( "<=" );
 		BOOLEAN_OPERATORS.add( ">=" );
 		BOOLEAN_OPERATORS.add( "=>" );
 		BOOLEAN_OPERATORS.add( "=<" );
 		BOOLEAN_OPERATORS.add( "!=" );
 		BOOLEAN_OPERATORS.add( "<>" );
 		BOOLEAN_OPERATORS.add( "!#" );
 		BOOLEAN_OPERATORS.add( "!~" );
 		BOOLEAN_OPERATORS.add( "!<" );
 		BOOLEAN_OPERATORS.add( "!>" );
 		BOOLEAN_OPERATORS.add( "is not" );
 		BOOLEAN_OPERATORS.add( "not like" );
 		BOOLEAN_OPERATORS.add( "not ilike" );
 		BOOLEAN_OPERATORS.add( "not regexp" );
 		BOOLEAN_OPERATORS.add( "not rlike" );
 		BOOLEAN_OPERATORS.add( "not in" );
 		BOOLEAN_OPERATORS.add( "not between" );
 		BOOLEAN_OPERATORS.add( "not exists" );
 
 		NEGATIONS.put( "and", "or" );
 		NEGATIONS.put( "or", "and" );
 		NEGATIONS.put( "<", ">=" );
 		NEGATIONS.put( "=", "<>" );
 		NEGATIONS.put( ">", "<=" );
 		NEGATIONS.put( "#", "!#" );
 		NEGATIONS.put( "~", "!~" );
 		NEGATIONS.put( "like", "not like" );
 		NEGATIONS.put( "ilike", "not ilike" );
 		NEGATIONS.put( "regexp", "not regexp" );
 		NEGATIONS.put( "rlike", "not rlike" );
 		NEGATIONS.put( "is", "is not" );
 		NEGATIONS.put( "in", "not in" );
 		NEGATIONS.put( "exists", "not exists" );
 		NEGATIONS.put( "between", "not between" );
 		NEGATIONS.put( "<=", ">" );
 		NEGATIONS.put( ">=", "<" );
 		NEGATIONS.put( "=>", "<" );
 		NEGATIONS.put( "=<", ">" );
 		NEGATIONS.put( "!=", "=" );
 		NEGATIONS.put( "<>", "=" );
 		NEGATIONS.put( "!#", "#" );
 		NEGATIONS.put( "!~", "~" );
 		NEGATIONS.put( "!<", "<" );
 		NEGATIONS.put( "!>", ">" );
 		NEGATIONS.put( "is not", "is" );
 		NEGATIONS.put( "not like", "like" );
 		NEGATIONS.put( "not ilike", "ilike" );
 		NEGATIONS.put( "not regexp", "regexp" );
 		NEGATIONS.put( "not rlike", "rlike" );
 		NEGATIONS.put( "not in", "in" );
 		NEGATIONS.put( "not between", "between" );
 		NEGATIONS.put( "not exists", "exists" );
 
 	}
 	// Handles things like:
 	// a and b or c
 	// a and ( b or c )
 	// not a and not b
 	// not ( a and b )
 	// x between y and z            (overloaded "and")
 	// x in ( a, b, c )             (overloaded brackets)
 	// not not a
 	// a is not null                (overloaded "not")
 	// etc......
 	// and expressions like
 	// foo = bar                    (maps to: foo.id = bar.id)
 	// foo.Bar = 'foo'              (maps to: foo.bar = 'foo')
 	// foo.Bar.Baz = 1.0            (maps to: foo.bar = bar.id and bar.baz = 1.0)
 	// 1.0 = foo.Bar.Baz            (maps to: bar.baz = 1.0 and foo.Bar = bar.id)
 	// foo.Bar.Baz = a.B.C          (maps to: bar.Baz = b.C and foo.Bar = bar.id and a.B = b.id)
 	// foo.Bar.Baz + a.B.C          (maps to: bar.Baz + b.C and foo.Bar = bar.id and a.B = b.id)
 	// ( foo.Bar.Baz + 1.0 ) < 2.0  (maps to: ( bar.Baz + 1.0 ) < 2.0 and foo.Bar = bar.id)
 
 	private boolean betweenSpecialCase;       //Inside a BETWEEN ... AND ... expression
 	private boolean negated;
 
 	private boolean inSubselect;
 	private int bracketsSinceSelect;
 	private StringBuilder subselect;
 
 	private boolean expectingPathContinuation;
 	private int expectingIndex;
 
 	// The following variables are stacks that keep information about each subexpression
 	// in the list of nested subexpressions we are currently processing.
 
 	private LinkedList<Boolean> nots = new LinkedList<Boolean>();           //were an odd or even number of NOTs encountered
 	private LinkedList joins = new LinkedList();          //the join string built up by compound paths inside this expression
 	private LinkedList<Boolean> booleanTests = new LinkedList<Boolean>();   //a flag indicating if the subexpression is known to be boolean
 
 	private String getElementName(PathExpressionParser.CollectionElement element, QueryTranslatorImpl q) throws QueryException {
 		String name;
 		if ( element.isOneToMany ) {
 			name = element.alias;
 		}
 		else {
 			Type type = element.elementType;
 			if ( type.isEntityType() ) { //ie. a many-to-many
 				String entityName = ( ( EntityType ) type ).getAssociatedEntityName();
 				name = pathExpressionParser.continueFromManyToMany( entityName, element.elementColumns, q );
 			}
 			else {
 				throw new QueryException( "illegally dereferenced collection element" );
 			}
 		}
 		return name;
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
-		String lcToken = token.toLowerCase();
+		String lcToken = token.toLowerCase(Locale.ROOT);
 
 		//Cope with [,]
 		if ( token.equals( "[" ) && !expectingPathContinuation ) {
 			expectingPathContinuation = false;
 			if ( expectingIndex == 0 ) throw new QueryException( "unexpected [" );
 			return;
 		}
 		else if ( token.equals( "]" ) ) {
 			expectingIndex--;
 			expectingPathContinuation = true;
 			return;
 		}
 
 		//Cope with a continued path expression (ie. ].baz)
 		if ( expectingPathContinuation ) {
 			boolean pathExpressionContinuesFurther = continuePathExpression( token, q );
 			if ( pathExpressionContinuesFurther ) return; //NOTE: early return
 		}
 
 		//Cope with a subselect
 		if ( !inSubselect && ( lcToken.equals( "select" ) || lcToken.equals( "from" ) ) ) {
 			inSubselect = true;
 			subselect = new StringBuilder( 20 );
 		}
 		if ( inSubselect && token.equals( ")" ) ) {
 			bracketsSinceSelect--;
 
 			if ( bracketsSinceSelect == -1 ) {
 				QueryTranslatorImpl subq = new QueryTranslatorImpl(
 				        subselect.toString(),
 						q.getEnabledFilters(),
 						q.getFactory()
 				);
 				try {
 					subq.compile( q );
 				}
 				catch ( MappingException me ) {
 					throw new QueryException( "MappingException occurred compiling subquery", me );
 				}
 				appendToken( q, subq.getSQLString() );
 				inSubselect = false;
 				bracketsSinceSelect = 0;
 			}
 		}
 		if ( inSubselect ) {
 			if ( token.equals( "(" ) ) bracketsSinceSelect++;
 			subselect.append( token ).append( ' ' );
 			return;
 		}
 
 		//Cope with special cases of AND, NOT, ()
 		specialCasesBefore( lcToken );
 
 		//Close extra brackets we opened
 		if ( !betweenSpecialCase && EXPRESSION_TERMINATORS.contains( lcToken ) ) {
 			closeExpression( q, lcToken );
 		}
 
 		//take note when this is a boolean expression
 		if ( BOOLEAN_OPERATORS.contains( lcToken ) ) {
 			booleanTests.removeLast();
 			booleanTests.addLast( Boolean.TRUE );
 		}
 
 		if ( lcToken.equals( "not" ) ) {
 			nots.addLast(  !(  nots.removeLast() ) );
 			negated = !negated;
 			return; //NOTE: early return
 		}
 
 		//process a token, mapping OO path expressions to SQL expressions
 		doToken( token, q );
 
 		//Open any extra brackets we might need.
 		if ( !betweenSpecialCase && EXPRESSION_OPENERS.contains( lcToken ) ) {
 			openExpression( q, lcToken );
 		}
 
 		//Cope with special cases of AND, NOT, )
 		specialCasesAfter( lcToken );
 
 	}
 
 	public void start(QueryTranslatorImpl q) throws QueryException {
 		token( "(", q );
 	}
 
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		if ( expectingPathContinuation ) {
 			expectingPathContinuation = false;
 			PathExpressionParser.CollectionElement element = pathExpressionParser.lastCollectionElement();
 			if ( element.elementColumns.length != 1 ) throw new QueryException( "path expression ended in composite collection element" );
 			appendToken( q, element.elementColumns[0] );
 			addToCurrentJoin( element );
 		}
 		token( ")", q );
 	}
 
 	private void closeExpression(QueryTranslatorImpl q, String lcToken) {
 		if ( booleanTests.removeLast() ) { //it was a boolean expression
 
 			if ( booleanTests.size() > 0 ) {
 				// the next one up must also be
 				booleanTests.removeLast();
 				booleanTests.addLast( Boolean.TRUE );
 			}
 
 			// Add any joins
 			appendToken( q, ( joins.removeLast() ).toString() );
 
 		}
 		else {
 			StringBuilder join = ( StringBuilder ) joins.removeLast();
 			( ( StringBuilder ) joins.getLast() ).append( join.toString() );
 		}
 
 		if ( nots.removeLast() ) negated = !negated;
 
 		if ( !")".equals( lcToken ) ) appendToken( q, ")" );
 	}
 
 	private void openExpression(QueryTranslatorImpl q, String lcToken) {
 		nots.addLast( Boolean.FALSE );
 		booleanTests.addLast( Boolean.FALSE );
 		joins.addLast( new StringBuilder() );
 		if ( !"(".equals( lcToken ) ) appendToken( q, "(" );
 	}
 
 	private void preprocess(String token, QueryTranslatorImpl q) throws QueryException {
 		// ugly hack for cases like "elements(foo.bar.collection)"
 		// (multi-part path expression ending in elements or indices)
 		String[] tokens = StringHelper.split( ".", token, true );
 		if (
 				tokens.length > 5 &&
 				( CollectionPropertyNames.COLLECTION_ELEMENTS.equals( tokens[tokens.length - 1] )
 				|| CollectionPropertyNames.COLLECTION_INDICES.equals( tokens[tokens.length - 1] ) )
 		) {
 			pathExpressionParser.start( q );
 			for ( int i = 0; i < tokens.length - 3; i++ ) {
 				pathExpressionParser.token( tokens[i], q );
 			}
 			pathExpressionParser.token( null, q );
 			pathExpressionParser.end( q );
 			addJoin( pathExpressionParser.getWhereJoin(), q );
 			pathExpressionParser.ignoreInitialJoin();
 		}
 	}
 
 	private void doPathExpression(String token, QueryTranslatorImpl q) throws QueryException {
 
 		preprocess( token, q );
 
 		StringTokenizer tokens = new StringTokenizer( token, ".", true );
 		pathExpressionParser.start( q );
 		while ( tokens.hasMoreTokens() ) {
 			pathExpressionParser.token( tokens.nextToken(), q );
 		}
 		pathExpressionParser.end( q );
 		if ( pathExpressionParser.isCollectionValued() ) {
 			openExpression( q, "" );
 			appendToken( q, pathExpressionParser.getCollectionSubquery( q.getEnabledFilters() ) );
 			closeExpression( q, "" );
 			// this is ugly here, but needed because its a subquery
 			q.addQuerySpaces( q.getCollectionPersister( pathExpressionParser.getCollectionRole() ).getCollectionSpaces() );
 		}
 		else {
 			if ( pathExpressionParser.isExpectingCollectionIndex() ) {
 				expectingIndex++;
 			}
 			else {
 				addJoin( pathExpressionParser.getWhereJoin(), q );
 				appendToken( q, pathExpressionParser.getWhereColumn() );
 			}
 		}
 	}
 
 	private void addJoin(JoinSequence joinSequence, QueryTranslatorImpl q) throws QueryException {
 		//JoinFragment fromClause = q.createJoinFragment(true);
 		//fromClause.addJoins( join.toJoinFragment().toFromFragmentString(), StringHelper.EMPTY_STRING );
 		q.addFromJoinOnly( pathExpressionParser.getName(), joinSequence );
 		try {
 			addToCurrentJoin( joinSequence.toJoinFragment( q.getEnabledFilters(), true ).toWhereFragmentString() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void doToken(String token, QueryTranslatorImpl q) throws QueryException {
 		if ( q.isName( StringHelper.root( token ) ) ) { //path expression
 			doPathExpression( q.unalias( token ), q );
 		}
 		else if ( token.startsWith( ParserHelper.HQL_VARIABLE_PREFIX ) ) { //named query parameter
 			q.addNamedParameter( token.substring( 1 ) );
 			appendToken( q, "?" );
 		}
 		else {
 			Queryable persister = q.getEntityPersisterUsingImports( token );
 			if ( persister != null ) { // the name of a class
 				final String discrim = persister.getDiscriminatorSQLValue();
 				if ( InFragment.NULL.equals(discrim) || InFragment.NOT_NULL.equals(discrim) ) {
 					throw new QueryException( "subclass test not allowed for null or not null discriminator" );
 				}
 				else {
 					appendToken( q, discrim );
 				}
 			}
 			else {
 				Object constant;
 				if (
 						token.indexOf( '.' ) > -1 &&
 						( constant = ReflectHelper.getConstantValue( token ) ) != null
 				) {
 					Type type;
 					try {
 						type = q.getFactory().getTypeResolver().heuristicType( constant.getClass().getName() );
 					}
 					catch ( MappingException me ) {
 						throw new QueryException( me );
 					}
 					if ( type == null ) throw new QueryException( QueryTranslator.ERROR_CANNOT_DETERMINE_TYPE + token );
 					try {
 						appendToken( q, ( ( LiteralType ) type ).objectToSQLString( constant, q.getFactory().getDialect() ) );
 					}
 					catch ( Exception e ) {
 						throw new QueryException( QueryTranslator.ERROR_CANNOT_FORMAT_LITERAL + token, e );
 					}
 				}
 				else { //anything else
 
-					String negatedToken = negated ? ( String ) NEGATIONS.get( token.toLowerCase() ) : null;
+					String negatedToken = negated ? ( String ) NEGATIONS.get( token.toLowerCase(Locale.ROOT) ) : null;
 					if ( negatedToken != null && ( !betweenSpecialCase || !"or".equals( negatedToken ) ) ) {
 						appendToken( q, negatedToken );
 					}
 					else {
 						appendToken( q, token );
 					}
 				}
 			}
 		}
 	}
 
 	private void addToCurrentJoin(String sql) {
 		( ( StringBuilder ) joins.getLast() ).append( sql );
 	}
 
 	private void addToCurrentJoin(PathExpressionParser.CollectionElement ce)
 			throws QueryException {
 		try {
 			addToCurrentJoin( ce.joinSequence.toJoinFragment().toWhereFragmentString() + ce.indexValue.toString() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void specialCasesBefore(String lcToken) {
 		if ( lcToken.equals( "between" ) || lcToken.equals( "not between" ) ) {
 			betweenSpecialCase = true;
 		}
 	}
 
 	private void specialCasesAfter(String lcToken) {
 		if ( betweenSpecialCase && lcToken.equals( "and" ) ) {
 			betweenSpecialCase = false;
 		}
 	}
 
 	void appendToken(QueryTranslatorImpl q, String token) {
 		if ( expectingIndex > 0 ) {
 			pathExpressionParser.setLastCollectionElementIndexValue( token );
 		}
 		else {
 			q.appendWhereToken( token );
 		}
 	}
 
 	private boolean continuePathExpression(String token, QueryTranslatorImpl q) throws QueryException {
 
 		expectingPathContinuation = false;
 
 		PathExpressionParser.CollectionElement element = pathExpressionParser.lastCollectionElement();
 
 		if ( token.startsWith( "." ) ) { // the path expression continues after a ]
 
 			doPathExpression( getElementName( element, q ) + token, q ); // careful with this!
 
 			addToCurrentJoin( element );
 			return true; //NOTE: EARLY EXIT!
 
 		}
 
 		else { // the path expression ends at the ]
 			if ( element.elementColumns.length != 1 ) {
 				throw new QueryException( "path expression ended in composite collection element" );
 			}
 			appendToken( q, element.elementColumns[0] );
 			addToCurrentJoin( element );
 			return false;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
index 471758fa8e..25afd412e8 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
@@ -1,794 +1,794 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.BitSet;
 import java.util.Iterator;
 import java.util.Locale;
 import java.util.StringTokenizer;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 public final class StringHelper {
 
 	private static final int ALIAS_TRUNCATE_LENGTH = 10;
 	public static final String WHITESPACE = " \n\r\f\t";
 	public static final String[] EMPTY_STRINGS = new String[0];
 
 	private StringHelper() { /* static methods only - hide constructor */
 	}
 	
 	/*public static boolean containsDigits(String string) {
 		for ( int i=0; i<string.length(); i++ ) {
 			if ( Character.isDigit( string.charAt(i) ) ) return true;
 		}
 		return false;
 	}*/
 
 	public static int lastIndexOfLetter(String string) {
 		for ( int i=0; i<string.length(); i++ ) {
 			char character = string.charAt(i);
 			// Include "_".  See HHH-8073
 			if ( !Character.isLetter(character) && !('_'==character) ) return i-1;
 		}
 		return string.length()-1;
 	}
 
 	public static String join(String seperator, String[] strings) {
 		int length = strings.length;
 		if ( length == 0 ) return "";
 		StringBuilder buf = new StringBuilder( length * strings[0].length() )
 				.append( strings[0] );
 		for ( int i = 1; i < length; i++ ) {
 			buf.append( seperator ).append( strings[i] );
 		}
 		return buf.toString();
 	}
 
 	public static String joinWithQualifier(String[] values, String qualifier, String deliminator) {
 		int length = values.length;
 		if ( length == 0 ) return "";
 		StringBuilder buf = new StringBuilder( length * values[0].length() )
 				.append( qualify( qualifier, values[0] ) );
 		for ( int i = 1; i < length; i++ ) {
 			buf.append( deliminator ).append( qualify( qualifier, values[i] ) );
 		}
 		return buf.toString();
 	}
 
 	public static String join(String seperator, Iterator objects) {
 		StringBuilder buf = new StringBuilder();
 		if ( objects.hasNext() ) buf.append( objects.next() );
 		while ( objects.hasNext() ) {
 			buf.append( seperator ).append( objects.next() );
 		}
 		return buf.toString();
 	}
 
 	public static String join(String separator, Iterable objects) {
 		return join( separator, objects.iterator() );
 	}
 
 	public static String[] add(String[] x, String sep, String[] y) {
 		final String[] result = new String[x.length];
 		for ( int i = 0; i < x.length; i++ ) {
 			result[i] = x[i] + sep + y[i];
 		}
 		return result;
 	}
 
 	public static String repeat(String string, int times) {
 		StringBuilder buf = new StringBuilder( string.length() * times );
 		for ( int i = 0; i < times; i++ ) buf.append( string );
 		return buf.toString();
 	}
 
 	public static String repeat(String string, int times, String deliminator) {
 		StringBuilder buf = new StringBuilder(  ( string.length() * times ) + ( deliminator.length() * (times-1) ) )
 				.append( string );
 		for ( int i = 1; i < times; i++ ) {
 			buf.append( deliminator ).append( string );
 		}
 		return buf.toString();
 	}
 
 	public static String repeat(char character, int times) {
 		char[] buffer = new char[times];
 		Arrays.fill( buffer, character );
 		return new String( buffer );
 	}
 
 
 	public static String replace(String template, String placeholder, String replacement) {
 		return replace( template, placeholder, replacement, false );
 	}
 
 	public static String[] replace(String[] templates, String placeholder, String replacement) {
 		String[] result = new String[templates.length];
 		for ( int i =0; i<templates.length; i++ ) {
 			result[i] = replace( templates[i], placeholder, replacement );
 		}
 		return result;
 	}
 
 	public static String replace(String template, String placeholder, String replacement, boolean wholeWords) {
 		return replace( template, placeholder, replacement, wholeWords, false );
 	}
 
 	public static String replace(String template,
 								 String placeholder,
 								 String replacement,
 								 boolean wholeWords,
 								 boolean encloseInParensIfNecessary) {
 		if ( template == null ) {
 			return template;
 		}
 		int loc = template.indexOf( placeholder );
 		if ( loc < 0 ) {
 			return template;
 		}
 		else {
 			String beforePlaceholder = template.substring( 0, loc );
 			String afterPlaceholder = template.substring( loc + placeholder.length() );
 			return replace( beforePlaceholder, afterPlaceholder, placeholder, replacement, wholeWords, encloseInParensIfNecessary );
 		}
 	}
 
 
 	public static String replace(String beforePlaceholder,
 								 String afterPlaceholder,
 								 String placeholder,
 								 String replacement,
 								 boolean wholeWords,
 								 boolean encloseInParensIfNecessary) {
 		final boolean actuallyReplace =
 				! wholeWords ||
 				afterPlaceholder.length() == 0 ||
 				! Character.isJavaIdentifierPart( afterPlaceholder.charAt( 0 ) );
 		boolean encloseInParens =
 				actuallyReplace &&
 				encloseInParensIfNecessary &&
 				! ( getLastNonWhitespaceCharacter( beforePlaceholder ) == '(' ) &&
 				! ( getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')' );		
 		StringBuilder buf = new StringBuilder( beforePlaceholder );
 		if ( encloseInParens ) {
 			buf.append( '(' );
 		}
 		buf.append( actuallyReplace ? replacement : placeholder );
 		if ( encloseInParens ) {
 			buf.append( ')' );
 		}
 		buf.append(
 				replace(
 						afterPlaceholder,
 						placeholder,
 						replacement,
 						wholeWords,
 						encloseInParensIfNecessary
 				)
 		);
 		return buf.toString();
 	}
 
 	public static char getLastNonWhitespaceCharacter(String str) {
 		if ( str != null && str.length() > 0 ) {
 			for ( int i = str.length() - 1 ; i >= 0 ; i-- ) {
 				char ch = str.charAt( i );
 				if ( ! Character.isWhitespace( ch ) ) {
 					return ch;
 				}
 			}
 		}
 		return '\0';
 	}
 
 	public static char getFirstNonWhitespaceCharacter(String str) {
 		if ( str != null && str.length() > 0 ) {
 			for ( int i = 0 ; i < str.length() ; i++ ) {
 				char ch = str.charAt( i );
 				if ( ! Character.isWhitespace( ch ) ) {
 					return ch;
 				}
 			}
 		}
 		return '\0';
 	}
 
 	public static String replaceOnce(String template, String placeholder, String replacement) {
 		if ( template == null ) {
 			return template; // returnign null!
 		}
         int loc = template.indexOf( placeholder );
 		if ( loc < 0 ) {
 			return template;
 		}
 		else {
 			return new StringBuilder( template.substring( 0, loc ) )
 					.append( replacement )
 					.append( template.substring( loc + placeholder.length() ) )
 					.toString();
 		}
 	}
 
 
 	public static String[] split(String seperators, String list) {
 		return split( seperators, list, false );
 	}
 
 	public static String[] split(String seperators, String list, boolean include) {
 		StringTokenizer tokens = new StringTokenizer( list, seperators, include );
 		String[] result = new String[ tokens.countTokens() ];
 		int i = 0;
 		while ( tokens.hasMoreTokens() ) {
 			result[i++] = tokens.nextToken();
 		}
 		return result;
 	}
 
 	public static String unqualify(String qualifiedName) {
 		int loc = qualifiedName.lastIndexOf(".");
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc + 1 );
 	}
 
 	public static String qualifier(String qualifiedName) {
 		int loc = qualifiedName.lastIndexOf(".");
 		return ( loc < 0 ) ? "" : qualifiedName.substring( 0, loc );
 	}
 
 	/**
 	 * Collapses a name.  Mainly intended for use with classnames, where an example might serve best to explain.
 	 * Imagine you have a class named <samp>'org.hibernate.internal.util.StringHelper'</samp>; calling collapse on that
 	 * classname will result in <samp>'o.h.u.StringHelper'<samp>.
 	 *
 	 * @param name The name to collapse.
 	 * @return The collapsed name.
 	 */
 	public static String collapse(String name) {
 		if ( name == null ) {
 			return null;
 		}
 		int breakPoint = name.lastIndexOf( '.' );
 		if ( breakPoint < 0 ) {
 			return name;
 		}
 		return collapseQualifier( name.substring( 0, breakPoint ), true ) + name.substring( breakPoint ); // includes last '.'
 	}
 
 	/**
 	 * Given a qualifier, collapse it.
 	 *
 	 * @param qualifier The qualifier to collapse.
 	 * @param includeDots Should we include the dots in the collapsed form?
 	 *
 	 * @return The collapsed form.
 	 */
 	public static String collapseQualifier(String qualifier, boolean includeDots) {
 		StringTokenizer tokenizer = new StringTokenizer( qualifier, "." );
 		String collapsed = Character.toString( tokenizer.nextToken().charAt( 0 ) );
 		while ( tokenizer.hasMoreTokens() ) {
 			if ( includeDots ) {
 				collapsed += '.';
 			}
 			collapsed += tokenizer.nextToken().charAt( 0 );
 		}
 		return collapsed;
 	}
 
 	/**
 	 * Partially unqualifies a qualified name.  For example, with a base of 'org.hibernate' the name
 	 * 'org.hibernate.internal.util.StringHelper' would become 'util.StringHelper'.
 	 *
 	 * @param name The (potentially) qualified name.
 	 * @param qualifierBase The qualifier base.
 	 *
 	 * @return The name itself, or the partially unqualified form if it begins with the qualifier base.
 	 */
 	public static String partiallyUnqualify(String name, String qualifierBase) {
 		if ( name == null || ! name.startsWith( qualifierBase ) ) {
 			return name;
 		}
 		return name.substring( qualifierBase.length() + 1 ); // +1 to start after the following '.'
 	}
 
 	/**
 	 * Cross between {@link #collapse} and {@link #partiallyUnqualify}.  Functions much like {@link #collapse}
 	 * except that only the qualifierBase is collapsed.  For example, with a base of 'org.hibernate' the name
 	 * 'org.hibernate.internal.util.StringHelper' would become 'o.h.util.StringHelper'.
 	 *
 	 * @param name The (potentially) qualified name.
 	 * @param qualifierBase The qualifier base.
 	 *
 	 * @return The name itself if it does not begin with the qualifierBase, or the properly collapsed form otherwise.
 	 */
 	public static String collapseQualifierBase(String name, String qualifierBase) {
 		if ( name == null || ! name.startsWith( qualifierBase ) ) {
 			return collapse( name );
 		}
 		return collapseQualifier( qualifierBase, true ) + name.substring( qualifierBase.length() );
 	}
 
 	public static String[] suffix(String[] columns, String suffix) {
 		if ( suffix == null ) return columns;
 		String[] qualified = new String[columns.length];
 		for ( int i = 0; i < columns.length; i++ ) {
 			qualified[i] = suffix( columns[i], suffix );
 		}
 		return qualified;
 	}
 
 	private static String suffix(String name, String suffix) {
 		return ( suffix == null ) ? name : name + suffix;
 	}
 
 	public static String root(String qualifiedName) {
 		int loc = qualifiedName.indexOf( "." );
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( 0, loc );
 	}
 
 	public static String unroot(String qualifiedName) {
 		int loc = qualifiedName.indexOf( "." );
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc+1, qualifiedName.length() );
 	}
 
 	public static boolean booleanValue(String tfString) {
-		String trimmed = tfString.trim().toLowerCase();
+		String trimmed = tfString.trim().toLowerCase(Locale.ROOT);
 		return trimmed.equals( "true" ) || trimmed.equals( "t" );
 	}
 
 	public static String toString(Object[] array) {
 		int len = array.length;
 		if ( len == 0 ) return "";
 		StringBuilder buf = new StringBuilder( len * 12 );
 		for ( int i = 0; i < len - 1; i++ ) {
 			buf.append( array[i] ).append(", ");
 		}
 		return buf.append( array[len - 1] ).toString();
 	}
 
 	public static String[] multiply(String string, Iterator placeholders, Iterator replacements) {
 		String[] result = new String[]{string};
 		while ( placeholders.hasNext() ) {
 			result = multiply( result, ( String ) placeholders.next(), ( String[] ) replacements.next() );
 		}
 		return result;
 	}
 
 	private static String[] multiply(String[] strings, String placeholder, String[] replacements) {
 		String[] results = new String[replacements.length * strings.length];
 		int n = 0;
 		for ( int i = 0; i < replacements.length; i++ ) {
 			for ( int j = 0; j < strings.length; j++ ) {
 				results[n++] = replaceOnce( strings[j], placeholder, replacements[i] );
 			}
 		}
 		return results;
 	}
 
 	public static int countUnquoted(String string, char character) {
 		if ( '\'' == character ) {
 			throw new IllegalArgumentException( "Unquoted count of quotes is invalid" );
 		}
 		if (string == null)
 			return 0;
 		// Impl note: takes advantage of the fact that an escpaed single quote
 		// embedded within a quote-block can really be handled as two seperate
 		// quote-blocks for the purposes of this method...
 		int count = 0;
 		int stringLength = string.length();
 		boolean inQuote = false;
 		for ( int indx = 0; indx < stringLength; indx++ ) {
 			char c = string.charAt( indx );
 			if ( inQuote ) {
 				if ( '\'' == c ) {
 					inQuote = false;
 				}
 			}
 			else if ( '\'' == c ) {
 				inQuote = true;
 			}
 			else if ( c == character ) {
 				count++;
 			}
 		}
 		return count;
 	}
 
 	public static int[] locateUnquoted(String string, char character) {
 		if ( '\'' == character ) {
 			throw new IllegalArgumentException( "Unquoted count of quotes is invalid" );
 		}
 		if (string == null) {
 			return new int[0];
 		}
 
 		ArrayList locations = new ArrayList( 20 );
 
 		// Impl note: takes advantage of the fact that an escpaed single quote
 		// embedded within a quote-block can really be handled as two seperate
 		// quote-blocks for the purposes of this method...
 		int stringLength = string.length();
 		boolean inQuote = false;
 		for ( int indx = 0; indx < stringLength; indx++ ) {
 			char c = string.charAt( indx );
 			if ( inQuote ) {
 				if ( '\'' == c ) {
 					inQuote = false;
 				}
 			}
 			else if ( '\'' == c ) {
 				inQuote = true;
 			}
 			else if ( c == character ) {
 				locations.add( indx );
 			}
 		}
 		return ArrayHelper.toIntArray( locations );
 	}
 
 	public static boolean isNotEmpty(String string) {
 		return string != null && string.length() > 0;
 	}
 
 	public static boolean isEmpty(String string) {
 		return string == null || string.length() == 0;
 	}
 
 	public static boolean isEmptyOrWhiteSpace(String string){
 		return isEmpty( string ) || isEmpty( string.trim() );
 	}
 
 	public static String qualify(String prefix, String name) {
 		if ( name == null || prefix == null ) {
 			throw new NullPointerException( "prefix or name were null attempting to build qualified name" );
 		}
 		return prefix + '.' + name;
 	}
 
 	public static String[] qualify(String prefix, String[] names) {
 		if ( prefix == null ) {
 			return names;
 		}
 		int len = names.length;
 		String[] qualified = new String[len];
 		for ( int i = 0; i < len; i++ ) {
 			qualified[i] = qualify( prefix, names[i] );
 		}
 		return qualified;
 	}
 
 	public static String[] qualifyIfNot(String prefix, String[] names) {
 		if ( prefix == null ) {
 			return names;
 		}
 		int len = names.length;
 		String[] qualified = new String[len];
 		for ( int i = 0; i < len; i++ ) {
 			if ( names[i].indexOf( '.' ) < 0 ) {
 				qualified[i] = qualify( prefix, names[i] );
 			}
 			else {
 				qualified[i] = names[i];
 			}
 		}
 		return qualified;
 	}
 
 	public static int firstIndexOfChar(String sqlString, BitSet keys, int startindex) {
 		for ( int i = startindex, size = sqlString.length(); i < size; i++ ) {
 			if ( keys.get( sqlString.charAt( i ) ) ) {
 				return i;
 			}
 		}
 		return -1;
 
 	}
 
 	public static int firstIndexOfChar(String sqlString, String string, int startindex) {
 		BitSet keys = new BitSet();
 		for ( int i = 0, size = string.length(); i < size; i++ ) {
 			keys.set( string.charAt( i ) );
 		}
 		return firstIndexOfChar( sqlString, keys, startindex );
 
 	}
 
 	public static String truncate(String string, int length) {
 		if ( string.length() <= length ) {
 			return string;
 		}
 		else {
 			return string.substring( 0, length );
 		}
 	}
 
 	public static String generateAlias(String description) {
 		return generateAliasRoot(description) + '_';
 	}
 
 	/**
 	 * Generate a nice alias for the given class name or collection role name and unique integer. Subclasses of
 	 * Loader do <em>not</em> have to use aliases of this form.
 	 *
 	 * @param description The base name (usually an entity-name or collection-role)
 	 * @param unique A uniquing value
 	 *
 	 * @return an alias of the form <samp>foo1_</samp>
 	 */
 	public static String generateAlias(String description, int unique) {
 		return generateAliasRoot(description) +
 			Integer.toString(unique) +
 			'_';
 	}
 
 	/**
 	 * Generates a root alias by truncating the "root name" defined by
 	 * the incoming decription and removing/modifying any non-valid
 	 * alias characters.
 	 *
 	 * @param description The root name from which to generate a root alias.
 	 * @return The generated root alias.
 	 */
 	private static String generateAliasRoot(String description) {
 		String result = truncate( unqualifyEntityName(description), ALIAS_TRUNCATE_LENGTH )
 				// Important to use Locale.ENGLISH.  See HHH-8579.  #toLowerCase() uses the default Locale.  Certain DBs
 				// do not like non-ascii characters in aliases, etc., so ensure consistency/portability here.
-				.toLowerCase(Locale.ENGLISH)
+				.toLowerCase(Locale.ROOT)
 		        .replace( '/', '_' ) // entityNames may now include slashes for the representations
 				.replace( '$', '_' ); //classname may be an inner class
 		result = cleanAlias( result );
 		if ( Character.isDigit( result.charAt(result.length()-1) ) ) {
 			return result + "x"; //ick!
 		}
 		else {
 			return result;
 		}
 	}
 
 	/**
 	 * Clean the generated alias by removing any non-alpha characters from the
 	 * beginning.
 	 *
 	 * @param alias The generated alias to be cleaned.
 	 * @return The cleaned alias, stripped of any leading non-alpha characters.
 	 */
 	private static String cleanAlias(String alias) {
 		char[] chars = alias.toCharArray();
 		// short cut check...
 		if ( !Character.isLetter( chars[0] ) ) {
 			for ( int i = 1; i < chars.length; i++ ) {
 				// as soon as we encounter our first letter, return the substring
 				// from that position
 				if ( Character.isLetter( chars[i] ) ) {
 					return alias.substring( i );
 				}
 			}
 		}
 		return alias;
 	}
 
 	public static String unqualifyEntityName(String entityName) {
 		String result = unqualify(entityName);
 		int slashPos = result.indexOf( '/' );
 		if ( slashPos > 0 ) {
 			result = result.substring( 0, slashPos - 1 );
 		}
 		return result;
 	}
 	
 	public static String toUpperCase(String str) {
-		return str==null ? null : str.toUpperCase();
+		return str==null ? null : str.toUpperCase(Locale.ROOT);
 	}
 	
 	public static String toLowerCase(String str) {
 		// Important to use Locale.ENGLISH.  See HHH-8579.  #toLowerCase() uses the default Locale.  Certain DBs do not
 		// like non-ascii characters in aliases, etc., so ensure consistency/portability here.
-		return str == null ? null : str.toLowerCase(Locale.ENGLISH);
+		return str == null ? null : str.toLowerCase(Locale.ROOT);
 	}
 
 	public static String moveAndToBeginning(String filter) {
 		if ( filter.trim().length()>0 ){
 			filter += " and ";
 			if ( filter.startsWith(" and ") ) filter = filter.substring(4);
 		}
 		return filter;
 	}
 
 	/**
 	 * Determine if the given string is quoted (wrapped by '`' characters at beginning and end).
 	 *
 	 * @param name The name to check.
 	 * @return True if the given string starts and ends with '`'; false otherwise.
 	 */
 	public static boolean isQuoted(String name) {
 		return name != null && name.length() != 0 
 				&& ( ( name.charAt( 0 ) == '`' && name.charAt( name.length() - 1 ) == '`' )
 						|| ( name.charAt( 0 ) == '"' && name.charAt( name.length() - 1 ) == '"' ) );
 	}
 
 	/**
 	 * Return a representation of the given name ensuring quoting (wrapped with '`' characters).  If already wrapped
 	 * return name.
 	 *
 	 * @param name The name to quote.
 	 * @return The quoted version.
 	 */
 	public static String quote(String name) {
 		if ( isEmpty( name ) || isQuoted( name ) ) {
 			return name;
 		}
 		// Convert the JPA2 specific quoting character (double quote) to Hibernate's (back tick)
         else if ( name.startsWith( "\"" ) && name.endsWith( "\"" ) ) {
             name = name.substring( 1, name.length() - 1 );
         }
 
 		return new StringBuilder( name.length() + 2 ).append('`').append( name ).append( '`' ).toString();
 	}
 
 	/**
 	 * Return the unquoted version of name (stripping the start and end '`' characters if present).
 	 *
 	 * @param name The name to be unquoted.
 	 * @return The unquoted version.
 	 */
 	public static String unquote(String name) {
 		return isQuoted( name ) ? name.substring( 1, name.length() - 1 ) : name;
 	}
 
 	/**
 	 * Determine if the given name is quoted.  It is considered quoted if either:
 	 * <ol>
 	 * <li>starts AND ends with backticks (`)</li>
 	 * <li>starts with dialect-specified {@link org.hibernate.dialect.Dialect#openQuote() open-quote}
 	 * 		AND ends with dialect-specified {@link org.hibernate.dialect.Dialect#closeQuote() close-quote}</li>
 	 * </ol>
 	 *
 	 * @param name The name to check
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return True if quoted, false otherwise
 	 */
 	public static boolean isQuoted(String name, Dialect dialect) {
 		return name != null && name.length() != 0 
 				&& ( ( name.charAt( 0 ) == '`' && name.charAt( name.length() - 1 ) == '`' )
 						|| ( name.charAt( 0 ) == '"' && name.charAt( name.length() - 1 ) == '"' )
 						|| ( name.charAt( 0 ) == dialect.openQuote()
 								&& name.charAt( name.length() - 1 ) == dialect.closeQuote() ) );
 	}
 
 	/**
 	 * Return the unquoted version of name stripping the start and end quote characters.
 	 *
 	 * @param name The name to be unquoted.
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return The unquoted version.
 	 */
 	public static String unquote(String name, Dialect dialect) {
 		return isQuoted( name, dialect ) ? name.substring( 1, name.length() - 1 ) : name;
 	}
 
 	/**
 	 * Return the unquoted version of name stripping the start and end quote characters.
 	 *
 	 * @param names The names to be unquoted.
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return The unquoted versions.
 	 */
 	public static String[] unquote(String[] names, Dialect dialect) {
 		if ( names == null ) {
 			return null;
 		}
 		String[] unquoted = new String[ names.length ];
 		for ( int i = 0; i < names.length; i++ ) {
 			unquoted[i] = unquote( names[i], dialect );
 		}
 		return unquoted;
 	}
 
 
 	public static final String BATCH_ID_PLACEHOLDER = "$$BATCH_ID_PLACEHOLDER$$";
 
 	public static StringBuilder buildBatchFetchRestrictionFragment(
 			String alias,
 			String[] columnNames,
 			Dialect dialect) {
 		// the general idea here is to just insert a placeholder that we can easily find later...
 		if ( columnNames.length == 1 ) {
 			// non-composite key
 			return new StringBuilder( StringHelper.qualify( alias, columnNames[0] ) )
 					.append( " in (" ).append( BATCH_ID_PLACEHOLDER ).append( ")" );
 		}
 		else {
 			// composite key - the form to use here depends on what the dialect supports.
 			if ( dialect.supportsRowValueConstructorSyntaxInInList() ) {
 				// use : (col1, col2) in ( (?,?), (?,?), ... )
 				StringBuilder builder = new StringBuilder();
 				builder.append( "(" );
 				boolean firstPass = true;
 				String deliminator = "";
 				for ( String columnName : columnNames ) {
 					builder.append( deliminator ).append( StringHelper.qualify( alias, columnName ) );
 					if ( firstPass ) {
 						firstPass = false;
 						deliminator = ",";
 					}
 				}
 				builder.append( ") in (" );
 				builder.append( BATCH_ID_PLACEHOLDER );
 				builder.append( ")" );
 				return builder;
 			}
 			else {
 				// use : ( (col1 = ? and col2 = ?) or (col1 = ? and col2 = ?) or ... )
 				//		unfortunately most of this building needs to be held off until we know
 				//		the exact number of ids :(
 				return new StringBuilder( "(" ).append( BATCH_ID_PLACEHOLDER ).append( ")" );
 			}
 		}
 	}
 
 	public static String expandBatchIdPlaceholder(
 			String sql,
 			Serializable[] ids,
 			String alias,
 			String[] keyColumnNames,
 			Dialect dialect) {
 		if ( keyColumnNames.length == 1 ) {
 			// non-composite
 			return StringHelper.replace( sql, BATCH_ID_PLACEHOLDER, repeat( "?", ids.length, "," ) );
 		}
 		else {
 			// composite
 			if ( dialect.supportsRowValueConstructorSyntaxInInList() ) {
 				final String tuple = "(" + StringHelper.repeat( "?", keyColumnNames.length, "," );
 				return StringHelper.replace( sql, BATCH_ID_PLACEHOLDER, repeat( tuple, ids.length, "," ) );
 			}
 			else {
 				final String keyCheck = joinWithQualifier( keyColumnNames, alias, " and " );
 				return replace( sql, BATCH_ID_PLACEHOLDER, repeat( keyCheck, ids.length, " or " ) );
 			}
 		}
 	}
 	
 	/**
 	 * Takes a String s and returns a new String[1] with s as the only element.
 	 * If s is null or "", return String[0].
 	 * 
 	 * @param s
 	 * @return String[]
 	 */
 	public static String[] toArrayElement(String s) {
 		return ( s == null || s.length() == 0 ) ? new String[0] : new String[] { s };
 	}
 
 	public static String nullIfEmpty(String value) {
 		return isEmpty( value ) ? null : value;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/BatchFetchStyle.java b/hibernate-core/src/main/java/org/hibernate/loader/BatchFetchStyle.java
index a429408cec..a892d0725b 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/BatchFetchStyle.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/BatchFetchStyle.java
@@ -1,90 +1,91 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
+import java.util.Locale;
 import org.jboss.logging.Logger;
 
 /**
  * Defines the style that should be used to perform batch loading.  Which style to use is declared using
  * the "{@value org.hibernate.cfg.AvailableSettings#BATCH_FETCH_STYLE}"
  * ({@link org.hibernate.cfg.AvailableSettings#BATCH_FETCH_STYLE}) setting
  *
  * @author Steve Ebersole
  */
 public enum BatchFetchStyle {
 	/**
 	 * The legacy algorithm where we keep a set of pre-built batch sizes based on
 	 * {@link org.hibernate.internal.util.collections.ArrayHelper#getBatchSizes}.  Batches are performed
 	 * using the next-smaller pre-built batch size from the number of existing batchable identifiers.
 	 * <p/>
 	 * For example, with a batch-size setting of 32 the pre-built batch sizes would be [32, 16, 10, 9, 8, 7, .., 1].
 	 * An attempt to batch load 31 identifiers would result in batches of 16, 10, and 5.
 	 */
 	LEGACY,
 	/**
 	 * Still keeps the concept of pre-built batch sizes, but uses the next-bigger batch size and pads the extra
 	 * identifier placeholders.
 	 * <p/>
 	 * Using the same example of a batch-size setting of 32 the pre-built batch sizes would be the same.  However, the
 	 * attempt to batch load 31 identifiers would result just a single batch of size 32.  The identifiers to load would
 	 * be "padded" (aka, repeated) to make up the difference.
 	 */
 	PADDED,
 	/**
 	 * Dynamically builds its SQL based on the actual number of available ids.  Does still limit to the batch-size
 	 * defined on the entity/collection
 	 */
 	DYNAMIC;
 
 	private static final Logger log = Logger.getLogger( BatchFetchStyle.class );
 
 	public static BatchFetchStyle byName(String name) {
-		return valueOf( name.toUpperCase() );
+		return valueOf( name.toUpperCase(Locale.ROOT) );
 	}
 
 	public static BatchFetchStyle interpret(Object setting) {
 		log.tracef( "Interpreting BatchFetchStyle from setting : %s", setting );
 
 		if ( setting == null ) {
 			return LEGACY; // as default
 		}
 
 		if ( BatchFetchStyle.class.isInstance( setting ) ) {
 			return (BatchFetchStyle) setting;
 		}
 
 		try {
 			final BatchFetchStyle byName = byName( setting.toString() );
 			if ( byName != null ) {
 				return byName;
 			}
 		}
 		catch (Exception ignore) {
 		}
 
 		log.debugf( "Unable to interpret given setting [%s] as BatchFetchStyle", setting );
 
 		return LEGACY; // again as default.
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Column.java b/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
index 6ef249f91d..539f8feb3f 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
@@ -1,376 +1,377 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 import java.io.Serializable;
+import java.util.Locale;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.Template;
 
 /**
  * A column of a relational database table
  * @author Gavin King
  */
 public class Column implements Selectable, Serializable, Cloneable {
 
 	public static final int DEFAULT_LENGTH = 255;
 	public static final int DEFAULT_PRECISION = 19;
 	public static final int DEFAULT_SCALE = 2;
 
 	private int length=DEFAULT_LENGTH;
 	private int precision=DEFAULT_PRECISION;
 	private int scale=DEFAULT_SCALE;
 	private Value value;
 	private int typeIndex;
 	private String name;
 	private boolean nullable=true;
 	private boolean unique;
 	private String sqlType;
 	private Integer sqlTypeCode;
 	private boolean quoted;
 	int uniqueInteger;
 	private String checkConstraint;
 	private String comment;
 	private String defaultValue;
 	private String customWrite;
 	private String customRead;
 
 	public Column() {
 	}
 
 	public Column(String columnName) {
 		setName(columnName);
 	}
 
 	public int getLength() {
 		return length;
 	}
 	public void setLength(int length) {
 		this.length = length;
 	}
 	public Value getValue() {
 		return value;
 	}
 	public void setValue(Value value) {
 		this.value= value;
 	}
 	public String getName() {
 		return name;
 	}
 	public void setName(String name) {
 		if (
 			StringHelper.isNotEmpty( name ) &&
 			Dialect.QUOTE.indexOf( name.charAt(0) ) > -1 //TODO: deprecated, remove eventually
 		) {
 			quoted=true;
 			this.name=name.substring( 1, name.length()-1 );
 		}
 		else {
 			this.name = name;
 		}
 	}
 
 	/** returns quoted name as it would be in the mapping file. */
 	public String getQuotedName() {
 		return quoted ?
 				"`" + name + "`" :
 				name;
 	}
 
 	public String getQuotedName(Dialect d) {
 		return quoted ?
 			d.openQuote() + name + d.closeQuote() :
 			name;
 	}
 	
 	@Override
 	public String getAlias(Dialect dialect) {
 		final int lastLetter = StringHelper.lastIndexOfLetter( name );
 		final String suffix = Integer.toString(uniqueInteger) + '_';
 
 		String alias = name;
 		if ( lastLetter == -1 ) {
 			alias = "column";
 		}
 		else if ( name.length() > lastLetter + 1 ) {
 			alias = name.substring( 0, lastLetter + 1 );
 		}
 
 		boolean useRawName = name.length() + suffix.length() <= dialect.getMaxAliasLength()
-				&& !quoted && !name.toLowerCase().equals( "rowid" );
+				&& !quoted && !name.toLowerCase(Locale.ROOT).equals( "rowid" );
 		if ( !useRawName ) {
 			if ( suffix.length() >= dialect.getMaxAliasLength() ) {
 				throw new MappingException( String.format(
 						"Unique suffix [%s] length must be less than maximum [%d]",
 						suffix, dialect.getMaxAliasLength() ) );
 			}
 			if ( alias.length() + suffix.length() > dialect.getMaxAliasLength() ) {
 				alias = alias.substring( 0, dialect.getMaxAliasLength() - suffix.length() );
 			}
 		}
 		return alias + suffix;
 	}
 	
 	/**
 	 * Generate a column alias that is unique across multiple tables
 	 */
 	@Override
 	public String getAlias(Dialect dialect, Table table) {
 		return getAlias(dialect) + table.getUniqueInteger() + '_';
 	}
 
 	public boolean isNullable() {
 		return nullable;
 	}
 
 	public void setNullable(boolean nullable) {
 		this.nullable=nullable;
 	}
 
 	public int getTypeIndex() {
 		return typeIndex;
 	}
 	public void setTypeIndex(int typeIndex) {
 		this.typeIndex = typeIndex;
 	}
 
 	public boolean isUnique() {
 		return unique;
 	}
 
 	@Override
 	public int hashCode() {
 		//used also for generation of FK names!
 		return isQuoted() ?
 			name.hashCode() :
-			name.toLowerCase().hashCode();
+			name.toLowerCase(Locale.ROOT).hashCode();
 	}
 
 	@Override
 	public boolean equals(Object object) {
 		return object instanceof Column && equals( (Column) object );
 	}
 
 	public boolean equals(Column column) {
 		if (null == column) return false;
 		if (this == column) return true;
 
 		return isQuoted() ? 
 			name.equals(column.name) :
 			name.equalsIgnoreCase(column.name);
 	}
 
     public int getSqlTypeCode(Mapping mapping) throws MappingException {
         org.hibernate.type.Type type = getValue().getType();
         try {
             int sqlTypeCode = type.sqlTypes( mapping )[getTypeIndex()];
             if ( getSqlTypeCode() != null && getSqlTypeCode() != sqlTypeCode ) {
                 throw new MappingException( "SQLType code's does not match. mapped as " + sqlTypeCode + " but is " + getSqlTypeCode() );
             }
             return sqlTypeCode;
         }
         catch ( Exception e ) {
             throw new MappingException(
                     "Could not determine type for column " +
                             name +
                             " of type " +
                             type.getClass().getName() +
                             ": " +
                             e.getClass().getName(),
                     e
             );
         }
     }
 
     /**
      * Returns the underlying columns sqltypecode.
      * If null, it is because the sqltype code is unknown.
      *
      * Use #getSqlTypeCode(Mapping) to retreive the sqltypecode used
      * for the columns associated Value/Type.
      *
      * @return sqlTypeCode if it is set, otherwise null.
      */
     public Integer getSqlTypeCode() {
         return sqlTypeCode;
     }
 
     public void setSqlTypeCode(Integer typeCode) {
         sqlTypeCode=typeCode;
     }
 
     public String getSqlType(Dialect dialect, Mapping mapping) throws HibernateException {
         if ( sqlType == null ) {
             sqlType = dialect.getTypeName( getSqlTypeCode( mapping ), getLength(), getPrecision(), getScale() );
         }
         return sqlType;
     }
 
 	public String getSqlType() {
 		return sqlType;
 	}
 
 	public void setSqlType(String sqlType) {
 		this.sqlType = sqlType;
 	}
 
 	public void setUnique(boolean unique) {
 		this.unique = unique;
 	}
 
 	public boolean isQuoted() {
 		return quoted;
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getName() + ')';
 	}
 
 	public String getCheckConstraint() {
 		return checkConstraint;
 	}
 
 	public void setCheckConstraint(String checkConstraint) {
 		this.checkConstraint = checkConstraint;
 	}
 
 	public boolean hasCheckConstraint() {
 		return checkConstraint!=null;
 	}
 
 	@Override
 	public String getTemplate(Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return hasCustomRead()
 				? Template.renderWhereStringTemplate( customRead, dialect, functionRegistry )
 				: Template.TEMPLATE + '.' + getQuotedName( dialect );
 	}
 
 	public boolean hasCustomRead() {
 		return ( customRead != null && customRead.length() > 0 );
 	}
 
 	public String getReadExpr(Dialect dialect) {
 		return hasCustomRead() ? customRead : getQuotedName( dialect );
 	}
 	
 	public String getWriteExpr() {
 		return ( customWrite != null && customWrite.length() > 0 ) ? customWrite : "?";
 	}
 
 	@Override
 	public boolean isFormula() {
 		return false;
 	}
 
 	@Override
 	public String getText(Dialect d) {
 		return getQuotedName(d);
 	}
 
 	@Override
 	public String getText() {
 		return getName();
 	}
 	
 	public int getPrecision() {
 		return precision;
 	}
 	public void setPrecision(int scale) {
 		this.precision = scale;
 	}
 
 	public int getScale() {
 		return scale;
 	}
 	public void setScale(int scale) {
 		this.scale = scale;
 	}
 
 	public String getComment() {
 		return comment;
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public String getDefaultValue() {
 		return defaultValue;
 	}
 
 	public void setDefaultValue(String defaultValue) {
 		this.defaultValue = defaultValue;
 	}
 
 	public String getCustomWrite() {
 		return customWrite;
 	}
 
 	public void setCustomWrite(String customWrite) {
 		this.customWrite = customWrite;
 	}
 
 	public String getCustomRead() {
 		return customRead;
 	}
 
 	public void setCustomRead(String customRead) {
 		this.customRead = customRead;
 	}
 
 	public String getCanonicalName() {
-		return quoted ? name : name.toLowerCase();
+		return quoted ? name : name.toLowerCase(Locale.ROOT);
 	}
 
 	/**
 	 * Shallow copy, the value is not copied
 	 */
 	@Override
 	public Column clone() {
 		Column copy = new Column();
 		copy.setLength( length );
 		copy.setScale( scale );
 		copy.setValue( value );
 		copy.setTypeIndex( typeIndex );
 		copy.setName( getQuotedName() );
 		copy.setNullable( nullable );
 		copy.setPrecision( precision );
 		copy.setUnique( unique );
 		copy.setSqlType( sqlType );
 		copy.setSqlTypeCode( sqlTypeCode );
 		copy.uniqueInteger = uniqueInteger; //usually useless
 		copy.setCheckConstraint( checkConstraint );
 		copy.setComment( comment );
 		copy.setDefaultValue( defaultValue );
 		copy.setCustomRead( customRead );
 		copy.setCustomWrite( customWrite );
 		return copy;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Table.java b/hibernate-core/src/main/java/org/hibernate/mapping/Table.java
index 8fd8974a71..93d3b4a1f9 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Table.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Table.java
@@ -1,896 +1,897 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
+import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.model.relational.Exportable;
 import org.hibernate.boot.model.relational.QualifiedTableName;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.tool.hbm2ddl.ColumnMetadata;
 import org.hibernate.tool.hbm2ddl.TableMetadata;
 import org.hibernate.tool.schema.extract.spi.ColumnInformation;
 import org.hibernate.tool.schema.extract.spi.TableInformation;
 
 /**
  * A relational table
  *
  * @author Gavin King
  */
 @SuppressWarnings("unchecked")
 public class Table implements RelationalModel, Serializable, Exportable {
 
 	private Identifier catalog;
 	private Identifier schema;
 	private Identifier name;
 
 	/**
 	 * contains all columns, including the primary key
 	 */
 	private Map columns = new LinkedHashMap();
 	private KeyValue idValue;
 	private PrimaryKey primaryKey;
 	private Map<ForeignKeyKey, ForeignKey> foreignKeys = new LinkedHashMap<ForeignKeyKey, ForeignKey>();
 	private Map<String, Index> indexes = new LinkedHashMap<String, Index>();
 	private Map<String,UniqueKey> uniqueKeys = new LinkedHashMap<String,UniqueKey>();
 	private int uniqueInteger;
 	private List<String> checkConstraints = new ArrayList<String>();
 	private String rowId;
 	private String subselect;
 	private boolean isAbstract;
 	private boolean hasDenormalizedTables;
 	private String comment;
 
 	public Table() {
 	}
 
 	public Table(String name) {
 		setName( name );
 	}
 
 	public Table(
 			Schema schema,
 			Identifier physicalTableName,
 			boolean isAbstract) {
 		this.catalog = schema.getPhysicalName().getCatalog();
 		this.schema = schema.getPhysicalName().getSchema();
 		this.name = physicalTableName;
 		this.isAbstract = isAbstract;
 	}
 
 	public Table(
 			Identifier catalog,
 			Identifier schema,
 			Identifier physicalTableName,
 			boolean isAbstract) {
 		this.catalog = catalog;
 		this.schema = schema;
 		this.name = physicalTableName;
 		this.isAbstract = isAbstract;
 	}
 
 	public Table(Schema schema, Identifier physicalTableName, String subselect, boolean isAbstract) {
 		this.catalog = schema.getPhysicalName().getCatalog();
 		this.schema = schema.getPhysicalName().getSchema();
 		this.name = physicalTableName;
 		this.subselect = subselect;
 		this.isAbstract = isAbstract;
 	}
 
 	public Table(Schema schema, String subselect, boolean isAbstract) {
 		this.catalog = schema.getPhysicalName().getCatalog();
 		this.schema = schema.getPhysicalName().getSchema();
 		this.subselect = subselect;
 		this.isAbstract = isAbstract;
 	}
 
 	public String getQualifiedName(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		if ( subselect != null ) {
 			return "( " + subselect + " )";
 		}
 		String quotedName = getQuotedName( dialect );
 		String usedSchema = schema == null ?
 				defaultSchema :
 				getQuotedSchema( dialect );
 		String usedCatalog = catalog == null ?
 				defaultCatalog :
 				getQuotedCatalog( dialect );
 		return qualify( usedCatalog, usedSchema, quotedName );
 	}
 
 	public static String qualify(String catalog, String schema, String table) {
 		StringBuilder qualifiedName = new StringBuilder();
 		if ( catalog != null ) {
 			qualifiedName.append( catalog ).append( '.' );
 		}
 		if ( schema != null ) {
 			qualifiedName.append( schema ).append( '.' );
 		}
 		return qualifiedName.append( table ).toString();
 	}
 
 	public void setName(String name) {
 		this.name = Identifier.toIdentifier( name );
 	}
 
 	public String getName() {
 		return name == null ? null : name.getText();
 	}
 
 	public Identifier getNameIdentifier() {
 		return name;
 	}
 
 	public String getQuotedName() {
 		return name == null ? null : name.toString();
 	}
 
 	public String getQuotedName(Dialect dialect) {
 		return name == null ? null : name.render( dialect );
 	}
 
 	public QualifiedTableName getQualifiedTableName() {
 		return name == null ? null : new QualifiedTableName( catalog, schema, name );
 	}
 
 	public boolean isQuoted() {
 		return name.isQuoted();
 	}
 
 	public void setQuoted(boolean quoted) {
 		if ( quoted == name.isQuoted() ) {
 			return;
 		}
 		this.name = new Identifier( name.getText(), quoted );
 	}
 
 	public void setSchema(String schema) {
 		this.schema = Identifier.toIdentifier( schema );
 	}
 
 	public String getSchema() {
 		return schema == null ? null : schema.getText();
 	}
 
 	public String getQuotedSchema() {
 		return schema == null ? null : schema.toString();
 	}
 
 	public String getQuotedSchema(Dialect dialect) {
 		return schema == null ? null : schema.render( dialect );
 	}
 
 	public boolean isSchemaQuoted() {
 		return schema != null && schema.isQuoted();
 	}
 
 	public void setCatalog(String catalog) {
 		this.catalog = Identifier.toIdentifier( catalog );
 	}
 
 	public String getCatalog() {
 		return catalog == null ? null : catalog.getText();
 	}
 
 	public String getQuotedCatalog() {
 		return catalog == null ? null : catalog.render();
 	}
 
 	public String getQuotedCatalog(Dialect dialect) {
 		return catalog == null ? null : catalog.render( dialect );
 	}
 
 	public boolean isCatalogQuoted() {
 		return catalog != null && catalog.isQuoted();
 	}
 
 	/**
 	 * Return the column which is identified by column provided as argument.
 	 *
 	 * @param column column with atleast a name.
 	 * @return the underlying column or null if not inside this table. Note: the instance *can* be different than the input parameter, but the name will be the same.
 	 */
 	public Column getColumn(Column column) {
 		if ( column == null ) {
 			return null;
 		}
 
 		Column myColumn = (Column) columns.get( column.getCanonicalName() );
 
 		return column.equals( myColumn ) ?
 				myColumn :
 				null;
 	}
 
 	public Column getColumn(Identifier name) {
 		if ( name == null ) {
 			return null;
 		}
 
 		return (Column) columns.get( name.getCanonicalName() );
 	}
 
 	public Column getColumn(int n) {
 		Iterator iter = columns.values().iterator();
 		for ( int i = 0; i < n - 1; i++ ) {
 			iter.next();
 		}
 		return (Column) iter.next();
 	}
 
 	public void addColumn(Column column) {
 		Column old = getColumn( column );
 		if ( old == null ) {
 			columns.put( column.getCanonicalName(), column );
 			column.uniqueInteger = columns.size();
 		}
 		else {
 			column.uniqueInteger = old.uniqueInteger;
 		}
 	}
 
 	public int getColumnSpan() {
 		return columns.size();
 	}
 
 	public Iterator getColumnIterator() {
 		return columns.values().iterator();
 	}
 
 	public Iterator<Index> getIndexIterator() {
 		return indexes.values().iterator();
 	}
 
 	public Iterator getForeignKeyIterator() {
 		return foreignKeys.values().iterator();
 	}
 
 	public Map<ForeignKeyKey, ForeignKey> getForeignKeys() {
 		return Collections.unmodifiableMap( foreignKeys );
 	}
 
 	public Iterator<UniqueKey> getUniqueKeyIterator() {
 		return getUniqueKeys().values().iterator();
 	}
 
 	Map<String, UniqueKey> getUniqueKeys() {
 		cleanseUniqueKeyMapIfNeeded();
 		return uniqueKeys;
 	}
 
 	private int sizeOfUniqueKeyMapOnLastCleanse;
 
 	private void cleanseUniqueKeyMapIfNeeded() {
 		if ( uniqueKeys.size() == sizeOfUniqueKeyMapOnLastCleanse ) {
 			// nothing to do
 			return;
 		}
 		cleanseUniqueKeyMap();
 		sizeOfUniqueKeyMapOnLastCleanse = uniqueKeys.size();
 	}
 
 	private void cleanseUniqueKeyMap() {
 		// We need to account for a few conditions here...
 		// 	1) If there are multiple unique keys contained in the uniqueKeys Map, we need to deduplicate
 		// 		any sharing the same columns as other defined unique keys; this is needed for the annotation
 		// 		processor since it creates unique constraints automagically for the user
 		//	2) Remove any unique keys that share the same columns as the primary key; again, this is
 		//		needed for the annotation processor to handle @Id @OneToOne cases.  In such cases the
 		//		unique key is unnecessary because a primary key is already unique by definition.  We handle
 		//		this case specifically because some databases fail if you try to apply a unique key to
 		//		the primary key columns which causes schema export to fail in these cases.
 		if ( uniqueKeys.isEmpty() ) {
 			// nothing to do
 			return;
 		}
 		else if ( uniqueKeys.size() == 1 ) {
 			// we have to worry about condition 2 above, but not condition 1
 			final Map.Entry<String,UniqueKey> uniqueKeyEntry = uniqueKeys.entrySet().iterator().next();
 			if ( isSameAsPrimaryKeyColumns( uniqueKeyEntry.getValue() ) ) {
 				uniqueKeys.remove( uniqueKeyEntry.getKey() );
 			}
 		}
 		else {
 			// we have to check both conditions 1 and 2
 			final Iterator<Map.Entry<String,UniqueKey>> uniqueKeyEntries = uniqueKeys.entrySet().iterator();
 			while ( uniqueKeyEntries.hasNext() ) {
 				final Map.Entry<String,UniqueKey> uniqueKeyEntry = uniqueKeyEntries.next();
 				final UniqueKey uniqueKey = uniqueKeyEntry.getValue();
 				boolean removeIt = false;
 
 				// condition 1 : check against other unique keys
 				for ( UniqueKey otherUniqueKey : uniqueKeys.values() ) {
 					// make sure its not the same unique key
 					if ( uniqueKeyEntry.getValue() == otherUniqueKey ) {
 						continue;
 					}
 					if ( otherUniqueKey.getColumns().containsAll( uniqueKey.getColumns() )
 							&& uniqueKey.getColumns().containsAll( otherUniqueKey.getColumns() ) ) {
 						removeIt = true;
 						break;
 					}
 				}
 
 				// condition 2 : check against pk
 				if ( isSameAsPrimaryKeyColumns( uniqueKeyEntry.getValue() ) ) {
 					removeIt = true;
 				}
 
 				if ( removeIt ) {
 					//uniqueKeys.remove( uniqueKeyEntry.getKey() );
 					uniqueKeyEntries.remove();
 				}
 			}
 
 		}
 	}
 
 	private boolean isSameAsPrimaryKeyColumns(UniqueKey uniqueKey) {
 		if ( primaryKey == null || ! primaryKey.columnIterator().hasNext() ) {
 			// happens for many-to-many tables
 			return false;
 		}
 		return primaryKey.getColumns().containsAll( uniqueKey.getColumns() )
 				&& uniqueKey.getColumns().containsAll( primaryKey.getColumns() );
 	}
 
 	@Override
 	public int hashCode() {
 		final int prime = 31;
 		int result = 1;
 		result = prime * result + ((catalog == null) ? 0 : catalog.hashCode());
 		result = prime * result + ((name == null) ? 0 : name.hashCode());
 		result = prime * result + ((schema == null) ? 0 : schema.hashCode());
 		return result;
 	}
 
 	@Override
 	public boolean equals(Object object) {
 		return object instanceof Table && equals((Table) object);
 	}
 
 	public boolean equals(Table table) {
 		if (null == table) {
 			return false;
 		}
 		if (this == table) {
 			return true;
 		}
 
 		return Identifier.areEqual( name, table.name )
 				&& Identifier.areEqual( schema, table.schema )
 				&& Identifier.areEqual( catalog, table.catalog );
 	}
 	
 	public void validateColumns(Dialect dialect, Mapping mapping, TableMetadata tableInfo) {
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			Column col = (Column) iter.next();
 
 			ColumnMetadata columnInfo = tableInfo.getColumnMetadata( col.getName() );
 
 			if ( columnInfo == null ) {
 				throw new HibernateException( "Missing column: " + col.getName() + " in " + Table.qualify( tableInfo.getCatalog(), tableInfo.getSchema(), tableInfo.getName()));
 			}
 			else {
-				final boolean typesMatch = col.getSqlType( dialect, mapping ).toLowerCase()
-						.startsWith( columnInfo.getTypeName().toLowerCase() )
+				final boolean typesMatch = col.getSqlType( dialect, mapping ).toLowerCase(Locale.ROOT)
+						.startsWith( columnInfo.getTypeName().toLowerCase(Locale.ROOT) )
 						|| columnInfo.getTypeCode() == col.getSqlTypeCode( mapping );
 				if ( !typesMatch ) {
 					throw new HibernateException(
 							"Wrong column type in " +
 							Table.qualify( tableInfo.getCatalog(), tableInfo.getSchema(), tableInfo.getName()) +
 							" for column " + col.getName() +
-							". Found: " + columnInfo.getTypeName().toLowerCase() +
+							". Found: " + columnInfo.getTypeName().toLowerCase(Locale.ROOT) +
 							", expected: " + col.getSqlType( dialect, mapping )
 					);
 				}
 			}
 		}
 
 	}
 
 	public Iterator sqlAlterStrings(
 			Dialect dialect,
 			Mapping p,
 			TableInformation tableInfo,
 			String defaultCatalog,
 			String defaultSchema) throws HibernateException {
 
 		StringBuilder root = new StringBuilder( "alter table " )
 				.append( getQualifiedName( dialect, defaultCatalog, defaultSchema ) )
 				.append( ' ' )
 				.append( dialect.getAddColumnString() );
 
 		Iterator iter = getColumnIterator();
 		List results = new ArrayList();
 		
 		while ( iter.hasNext() ) {
 			final Column column = (Column) iter.next();
 			final ColumnInformation columnInfo = tableInfo.getColumn( Identifier.toIdentifier( column.getName() ) );
 
 			if ( columnInfo == null ) {
 				// the column doesnt exist at all.
 				StringBuilder alter = new StringBuilder( root.toString() )
 						.append( ' ' )
 						.append( column.getQuotedName( dialect ) )
 						.append( ' ' )
 						.append( column.getSqlType( dialect, p ) );
 
 				String defaultValue = column.getDefaultValue();
 				if ( defaultValue != null ) {
 					alter.append( " default " ).append( defaultValue );
 				}
 
 				if ( column.isNullable() ) {
 					alter.append( dialect.getNullColumnString() );
 				}
 				else {
 					alter.append( " not null" );
 				}
 
 				if ( column.isUnique() ) {
 					String keyName = Constraint.generateName( "UK_", this, column );
 					UniqueKey uk = getOrCreateUniqueKey( keyName );
 					uk.addColumn( column );
 					alter.append( dialect.getUniqueDelegate()
 							.getColumnDefinitionUniquenessFragment( column ) );
 				}
 
 				if ( column.hasCheckConstraint() && dialect.supportsColumnCheck() ) {
 					alter.append( " check(" )
 							.append( column.getCheckConstraint() )
 							.append( ")" );
 				}
 
 				String columnComment = column.getComment();
 				if ( columnComment != null ) {
 					alter.append( dialect.getColumnComment( columnComment ) );
 				}
 
 				alter.append( dialect.getAddColumnSuffixString() );
 
 				results.add( alter.toString() );
 			}
 
 		}
 
 		return results.iterator();
 	}
 
 	public boolean hasPrimaryKey() {
 		return getPrimaryKey() != null;
 	}
 
 	public String sqlTemporaryTableCreateString(Dialect dialect, Mapping mapping) throws HibernateException {
 		StringBuilder buffer = new StringBuilder( dialect.getCreateTemporaryTableString() )
 				.append( ' ' )
 				.append( name )
 				.append( " (" );
 		Iterator itr = getColumnIterator();
 		while ( itr.hasNext() ) {
 			final Column column = (Column) itr.next();
 			buffer.append( column.getQuotedName( dialect ) ).append( ' ' );
 			buffer.append( column.getSqlType( dialect, mapping ) );
 			if ( column.isNullable() ) {
 				buffer.append( dialect.getNullColumnString() );
 			}
 			else {
 				buffer.append( " not null" );
 			}
 			if ( itr.hasNext() ) {
 				buffer.append( ", " );
 			}
 		}
 		buffer.append( ") " );
 		buffer.append( dialect.getCreateTemporaryTablePostfix() );
 		return buffer.toString();
 	}
 
 	public String sqlCreateString(Dialect dialect, Mapping p, String defaultCatalog, String defaultSchema) {
 		StringBuilder buf = new StringBuilder( hasPrimaryKey() ? dialect.getCreateTableString() : dialect.getCreateMultisetTableString() )
 				.append( ' ' )
 				.append( getQualifiedName( dialect, defaultCatalog, defaultSchema ) )
 				.append( " (" );
 
 		boolean identityColumn = idValue != null && idValue.isIdentityColumn( p.getIdentifierGeneratorFactory(), dialect );
 
 		// Try to find out the name of the primary key to create it as identity if the IdentityGenerator is used
 		String pkname = null;
 		if ( hasPrimaryKey() && identityColumn ) {
 			pkname = ( (Column) getPrimaryKey().getColumnIterator().next() ).getQuotedName( dialect );
 		}
 
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			Column col = (Column) iter.next();
 
 			buf.append( col.getQuotedName( dialect ) )
 					.append( ' ' );
 
 			if ( identityColumn && col.getQuotedName( dialect ).equals( pkname ) ) {
 				// to support dialects that have their own identity data type
 				if ( dialect.hasDataTypeInIdentityColumn() ) {
 					buf.append( col.getSqlType( dialect, p ) );
 				}
 				buf.append( ' ' )
 						.append( dialect.getIdentityColumnString( col.getSqlTypeCode( p ) ) );
 			}
 			else {
 
 				buf.append( col.getSqlType( dialect, p ) );
 
 				String defaultValue = col.getDefaultValue();
 				if ( defaultValue != null ) {
 					buf.append( " default " ).append( defaultValue );
 				}
 
 				if ( col.isNullable() ) {
 					buf.append( dialect.getNullColumnString() );
 				}
 				else {
 					buf.append( " not null" );
 				}
 
 			}
 			
 			if ( col.isUnique() ) {
 				String keyName = Constraint.generateName( "UK_", this, col );
 				UniqueKey uk = getOrCreateUniqueKey( keyName );
 				uk.addColumn( col );
 				buf.append( dialect.getUniqueDelegate()
 						.getColumnDefinitionUniquenessFragment( col ) );
 			}
 				
 			if ( col.hasCheckConstraint() && dialect.supportsColumnCheck() ) {
 				buf.append( " check (" )
 						.append( col.getCheckConstraint() )
 						.append( ")" );
 			}
 
 			String columnComment = col.getComment();
 			if ( columnComment != null ) {
 				buf.append( dialect.getColumnComment( columnComment ) );
 			}
 
 			if ( iter.hasNext() ) {
 				buf.append( ", " );
 			}
 
 		}
 		if ( hasPrimaryKey() ) {
 			buf.append( ", " )
 					.append( getPrimaryKey().sqlConstraintString( dialect ) );
 		}
 
 		buf.append( dialect.getUniqueDelegate().getTableCreationUniqueConstraintsFragment( this ) );
 
 		if ( dialect.supportsTableCheck() ) {
 			for ( String checkConstraint : checkConstraints ) {
 				buf.append( ", check (" )
 						.append( checkConstraint )
 						.append( ')' );
 			}
 		}
 
 		buf.append( ')' );
 
 		if ( comment != null ) {
 			buf.append( dialect.getTableComment( comment ) );
 		}
 
 		return buf.append( dialect.getTableTypeString() ).toString();
 	}
 
 	public String sqlDropString(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		return dialect.getDropTableString( getQualifiedName( dialect, defaultCatalog, defaultSchema ) );
 	}
 
 	public PrimaryKey getPrimaryKey() {
 		return primaryKey;
 	}
 
 	public void setPrimaryKey(PrimaryKey primaryKey) {
 		this.primaryKey = primaryKey;
 	}
 
 	public Index getOrCreateIndex(String indexName) {
 
 		Index index =  indexes.get( indexName );
 
 		if ( index == null ) {
 			index = new Index();
 			index.setName( indexName );
 			index.setTable( this );
 			indexes.put( indexName, index );
 		}
 
 		return index;
 	}
 
 	public Index getIndex(String indexName) {
 		return  indexes.get( indexName );
 	}
 
 	public Index addIndex(Index index) {
 		Index current =  indexes.get( index.getName() );
 		if ( current != null ) {
 			throw new MappingException( "Index " + index.getName() + " already exists!" );
 		}
 		indexes.put( index.getName(), index );
 		return index;
 	}
 
 	public UniqueKey addUniqueKey(UniqueKey uniqueKey) {
 		UniqueKey current = uniqueKeys.get( uniqueKey.getName() );
 		if ( current != null ) {
 			throw new MappingException( "UniqueKey " + uniqueKey.getName() + " already exists!" );
 		}
 		uniqueKeys.put( uniqueKey.getName(), uniqueKey );
 		return uniqueKey;
 	}
 
 	public UniqueKey createUniqueKey(List keyColumns) {
 		String keyName = Constraint.generateName( "UK_", this, keyColumns );
 		UniqueKey uk = getOrCreateUniqueKey( keyName );
 		uk.addColumns( keyColumns.iterator() );
 		return uk;
 	}
 
 	public UniqueKey getUniqueKey(String keyName) {
 		return uniqueKeys.get( keyName );
 	}
 
 	public UniqueKey getOrCreateUniqueKey(String keyName) {
 		UniqueKey uk = uniqueKeys.get( keyName );
 
 		if ( uk == null ) {
 			uk = new UniqueKey();
 			uk.setName( keyName );
 			uk.setTable( this );
 			uniqueKeys.put( keyName, uk );
 		}
 		return uk;
 	}
 
 	public void createForeignKeys() {
 	}
 
 	public ForeignKey createForeignKey(String keyName, List keyColumns, String referencedEntityName) {
 		return createForeignKey( keyName, keyColumns, referencedEntityName, null );
 	}
 
 	public ForeignKey createForeignKey(
 			String keyName,
 			List keyColumns,
 			String referencedEntityName,
 			List referencedColumns) {
 		final ForeignKeyKey key = new ForeignKeyKey( keyColumns, referencedEntityName, referencedColumns );
 
 		ForeignKey fk = foreignKeys.get( key );
 		if ( fk == null ) {
 			fk = new ForeignKey();
 			fk.setTable( this );
 			fk.setReferencedEntityName( referencedEntityName );
 			fk.addColumns( keyColumns.iterator() );
 			if ( referencedColumns != null ) {
 				fk.addReferencedColumns( referencedColumns.iterator() );
 			}
 
 			// NOTE : if the name is null, we will generate an implicit name during second pass processing
 			// after we know the referenced table name (which might not be resolved yet).
 			fk.setName( keyName );
 
 			foreignKeys.put( key, fk );
 		}
 
 		if ( keyName != null ) {
 			fk.setName( keyName );
 		}
 
 		return fk;
 	}
 
 
 	// This must be done outside of Table, rather than statically, to ensure
 	// deterministic alias names.  See HHH-2448.
 	public void setUniqueInteger( int uniqueInteger ) {
 		this.uniqueInteger = uniqueInteger;
 	}
 
 	public int getUniqueInteger() {
 		return uniqueInteger;
 	}
 
 	public void setIdentifierValue(KeyValue idValue) {
 		this.idValue = idValue;
 	}
 
 	public KeyValue getIdentifierValue() {
 		return idValue;
 	}
 
 	public void addCheckConstraint(String constraint) {
 		checkConstraints.add( constraint );
 	}
 
 	public boolean containsColumn(Column column) {
 		return columns.containsValue( column );
 	}
 
 	public String getRowId() {
 		return rowId;
 	}
 
 	public void setRowId(String rowId) {
 		this.rowId = rowId;
 	}
 
 	public String toString() {
 		StringBuilder buf = new StringBuilder().append( getClass().getName() )
 				.append( '(' );
 		if ( getCatalog() != null ) {
 			buf.append( getCatalog() ).append( "." );
 		}
 		if ( getSchema() != null ) {
 			buf.append( getSchema() ).append( "." );
 		}
 		buf.append( getName() ).append( ')' );
 		return buf.toString();
 	}
 
 	public String getSubselect() {
 		return subselect;
 	}
 
 	public void setSubselect(String subselect) {
 		this.subselect = subselect;
 	}
 
 	public boolean isSubselect() {
 		return subselect != null;
 	}
 
 	public boolean isAbstractUnionTable() {
 		return hasDenormalizedTables() && isAbstract;
 	}
 
 	public boolean hasDenormalizedTables() {
 		return hasDenormalizedTables;
 	}
 
 	void setHasDenormalizedTables() {
 		hasDenormalizedTables = true;
 	}
 
 	public void setAbstract(boolean isAbstract) {
 		this.isAbstract = isAbstract;
 	}
 
 	public boolean isAbstract() {
 		return isAbstract;
 	}
 
 	public boolean isPhysicalTable() {
 		return !isSubselect() && !isAbstractUnionTable();
 	}
 
 	public String getComment() {
 		return comment;
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public Iterator<String> getCheckConstraintsIterator() {
 		return checkConstraints.iterator();
 	}
 
 	public Iterator sqlCommentStrings(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		List comments = new ArrayList();
 		if ( dialect.supportsCommentOn() ) {
 			String tableName = getQualifiedName( dialect, defaultCatalog, defaultSchema );
 			if ( comment != null ) {
 				comments.add( "comment on table " + tableName + " is '" + comment + "'" );
 			}
 			Iterator iter = getColumnIterator();
 			while ( iter.hasNext() ) {
 				Column column = (Column) iter.next();
 				String columnComment = column.getComment();
 				if ( columnComment != null ) {
 					comments.add( "comment on column " + tableName + '.' + column.getQuotedName( dialect ) + " is '" + columnComment + "'" );
 				}
 			}
 		}
 		return comments.iterator();
 	}
 
 	@Override
 	public String getExportIdentifier() {
 		return Table.qualify(
 				render( catalog ),
 				render( schema ),
 				name.render()
 		);
 	}
 
 	private String render(Identifier identifier) {
 		return identifier == null ? null : identifier.render();
 	}
 
 
 	public static class ForeignKeyKey implements Serializable {
 		String referencedClassName;
 		List columns;
 		List referencedColumns;
 
 		ForeignKeyKey(List columns, String referencedClassName, List referencedColumns) {
 			this.referencedClassName = referencedClassName;
 			this.columns = new ArrayList();
 			this.columns.addAll( columns );
 			if ( referencedColumns != null ) {
 				this.referencedColumns = new ArrayList();
 				this.referencedColumns.addAll( referencedColumns );
 			}
 			else {
 				this.referencedColumns = Collections.EMPTY_LIST;
 			}
 		}
 
 		public int hashCode() {
 			return columns.hashCode() + referencedColumns.hashCode();
 		}
 
 		public boolean equals(Object other) {
 			ForeignKeyKey fkk = (ForeignKeyKey) other;
 			return fkk.columns.equals( columns ) &&
 					fkk.referencedClassName.equals( referencedClassName ) && fkk.referencedColumns
 					.equals( referencedColumns );
 		}
 
 		@Override
 		public String toString() {
 			return "ForeignKeyKey{" +
 					"columns=" + StringHelper.join( ",", columns ) +
 					", referencedClassName='" + referencedClassName + '\'' +
 					", referencedColumns=" + StringHelper.join( ",", referencedColumns ) +
 					'}';
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/Template.java b/hibernate-core/src/main/java/org/hibernate/sql/Template.java
index baca2b2fee..060c72f0e2 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/Template.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/Template.java
@@ -1,766 +1,767 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
+import java.util.Locale;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.ordering.antlr.ColumnMapper;
 import org.hibernate.sql.ordering.antlr.OrderByAliasResolver;
 import org.hibernate.sql.ordering.antlr.OrderByFragmentTranslator;
 import org.hibernate.sql.ordering.antlr.OrderByTranslation;
 import org.hibernate.sql.ordering.antlr.SqlValueReference;
 import org.hibernate.sql.ordering.antlr.TranslationContext;
 
 /**
  * Parses SQL fragments specified in mapping documents
  *
  * @author Gavin King
  */
 public final class Template {
 
 	private static final Set<String> KEYWORDS = new HashSet<String>();
 	private static final Set<String> BEFORE_TABLE_KEYWORDS = new HashSet<String>();
 	private static final Set<String> FUNCTION_KEYWORDS = new HashSet<String>();
 	static {
 		KEYWORDS.add("and");
 		KEYWORDS.add("or");
 		KEYWORDS.add("not");
 		KEYWORDS.add("like");
 		KEYWORDS.add("escape");
 		KEYWORDS.add("is");
 		KEYWORDS.add("in");
 		KEYWORDS.add("between");
 		KEYWORDS.add("null");
 		KEYWORDS.add("select");
 		KEYWORDS.add("distinct");
 		KEYWORDS.add("from");
 		KEYWORDS.add("join");
 		KEYWORDS.add("inner");
 		KEYWORDS.add("outer");
 		KEYWORDS.add("left");
 		KEYWORDS.add("right");
 		KEYWORDS.add("on");
 		KEYWORDS.add("where");
 		KEYWORDS.add("having");
 		KEYWORDS.add("group");
 		KEYWORDS.add("order");
 		KEYWORDS.add("by");
 		KEYWORDS.add("desc");
 		KEYWORDS.add("asc");
 		KEYWORDS.add("limit");
 		KEYWORDS.add("any");
 		KEYWORDS.add("some");
 		KEYWORDS.add("exists");
 		KEYWORDS.add("all");
 		KEYWORDS.add("union");
 		KEYWORDS.add("minus");
 
 		BEFORE_TABLE_KEYWORDS.add("from");
 		BEFORE_TABLE_KEYWORDS.add("join");
 
 		FUNCTION_KEYWORDS.add("as");
 		FUNCTION_KEYWORDS.add("leading");
 		FUNCTION_KEYWORDS.add("trailing");
 		FUNCTION_KEYWORDS.add("from");
 		FUNCTION_KEYWORDS.add("case");
 		FUNCTION_KEYWORDS.add("when");
 		FUNCTION_KEYWORDS.add("then");
 		FUNCTION_KEYWORDS.add("else");
 		FUNCTION_KEYWORDS.add("end");
 	}
 
 	public static final String TEMPLATE = "$PlaceHolder$";
 
 	private Template() {}
 
 	public static String renderWhereStringTemplate(String sqlWhereString, Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return renderWhereStringTemplate(sqlWhereString, TEMPLATE, dialect, functionRegistry);
 	}
 
 	/**
 	 * Same functionality as {@link #renderWhereStringTemplate(String, String, Dialect, SQLFunctionRegistry)},
 	 * except that a SQLFunctionRegistry is not provided (i.e., only the dialect-defined functions are
 	 * considered).  This is only intended for use by the annotations project until the
 	 * many-to-many/map-key-from-target-table feature is pulled into core.
 	 *
 	 * @deprecated Only intended for annotations usage; use {@link #renderWhereStringTemplate(String, String, Dialect, SQLFunctionRegistry)} instead
 	 */
 	@Deprecated
     @SuppressWarnings({ "JavaDoc" })
 	public static String renderWhereStringTemplate(String sqlWhereString, String placeholder, Dialect dialect) {
 		return renderWhereStringTemplate(
 				sqlWhereString,
 				placeholder,
 				dialect,
 				new SQLFunctionRegistry( dialect, java.util.Collections.<String, SQLFunction>emptyMap() )
 		);
 	}
 
 	/**
 	 * Takes the where condition provided in the mapping attribute and interpolates the alias.
 	 * Handles sub-selects, quoted identifiers, quoted strings, expressions, SQL functions,
 	 * named parameters.
 	 *
 	 * @param sqlWhereString The string into which to interpolate the placeholder value
 	 * @param placeholder The value to be interpolated into the the sqlWhereString
 	 * @param dialect The dialect to apply
 	 * @param functionRegistry The registry of all sql functions
 	 * @return The rendered sql fragment
 	 */
 	public static String renderWhereStringTemplate(String sqlWhereString, String placeholder, Dialect dialect, SQLFunctionRegistry functionRegistry ) {
 
 		// IMPL NOTE : The basic process here is to tokenize the incoming string and to iterate over each token
 		//		in turn.  As we process each token, we set a series of flags used to indicate the type of context in
 		// 		which the tokens occur.  Depending on the state of those flags we decide whether we need to qualify
 		//		identifier references.
 
 		String symbols = new StringBuilder()
 				.append( "=><!+-*/()',|&`" )
 				.append( StringHelper.WHITESPACE )
 				.append( dialect.openQuote() )
 				.append( dialect.closeQuote() )
 				.toString();
 		StringTokenizer tokens = new StringTokenizer( sqlWhereString, symbols, true );
 		StringBuilder result = new StringBuilder();
 
 		boolean quoted = false;
 		boolean quotedIdentifier = false;
 		boolean beforeTable = false;
 		boolean inFromClause = false;
 		boolean afterFromTable = false;
 
 		boolean hasMore = tokens.hasMoreTokens();
 		String nextToken = hasMore ? tokens.nextToken() : null;
 		while ( hasMore ) {
 			String token = nextToken;
-			String lcToken = token.toLowerCase();
+			String lcToken = token.toLowerCase(Locale.ROOT);
 			hasMore = tokens.hasMoreTokens();
 			nextToken = hasMore ? tokens.nextToken() : null;
 
 			boolean isQuoteCharacter = false;
 
 			if ( !quotedIdentifier && "'".equals(token) ) {
 				quoted = !quoted;
 				isQuoteCharacter = true;
 			}
 
 			if ( !quoted ) {
 				boolean isOpenQuote;
 				if ( "`".equals(token) ) {
 					isOpenQuote = !quotedIdentifier;
 					token = lcToken = isOpenQuote
 							? Character.toString( dialect.openQuote() )
 							: Character.toString( dialect.closeQuote() );
 					quotedIdentifier = isOpenQuote;
 					isQuoteCharacter = true;
 				}
 				else if ( !quotedIdentifier && ( dialect.openQuote()==token.charAt(0) ) ) {
 					isOpenQuote = true;
 					quotedIdentifier = true;
 					isQuoteCharacter = true;
 				}
 				else if ( quotedIdentifier && ( dialect.closeQuote()==token.charAt(0) ) ) {
 					quotedIdentifier = false;
 					isQuoteCharacter = true;
 					isOpenQuote = false;
 				}
 				else {
 					isOpenQuote = false;
 				}
 
 				if ( isOpenQuote ) {
 					result.append( placeholder ).append( '.' );
 				}
 			}
 
 			// Special processing for ANSI SQL EXTRACT function
 			if ( "extract".equals( lcToken ) && "(".equals( nextToken ) ) {
 				final String field = extractUntil( tokens, "from" );
 				final String source = renderWhereStringTemplate(
 						extractUntil( tokens, ")" ),
 						placeholder,
 						dialect,
 						functionRegistry
 				);
 				result.append( "extract(" ).append( field ).append( " from " ).append( source ).append( ')' );
 
 				hasMore = tokens.hasMoreTokens();
 				nextToken = hasMore ? tokens.nextToken() : null;
 
 				continue;
 			}
 
 			// Special processing for ANSI SQL TRIM function
 			if ( "trim".equals( lcToken ) && "(".equals( nextToken ) ) {
 				List<String> operands = new ArrayList<String>();
 				StringBuilder builder = new StringBuilder();
 
 				boolean hasMoreOperands = true;
 				String operandToken = tokens.nextToken();
 				boolean quotedOperand = false;
 				while ( hasMoreOperands ) {
 					final boolean isQuote = "'".equals( operandToken );
 					if ( isQuote ) {
 						quotedOperand = !quotedOperand;
 						if ( !quotedOperand ) {
 							operands.add( builder.append( '\'' ).toString() );
 							builder.setLength( 0 );
 						}
 						else {
 							builder.append( '\'' );
 						}
 					}
 					else if ( quotedOperand ) {
 						builder.append( operandToken );
 					}
 					else if ( operandToken.length() == 1 && Character.isWhitespace( operandToken.charAt( 0 ) ) ) {
 						// do nothing
 					}
 					else {
 						operands.add( operandToken );
 					}
 					operandToken = tokens.nextToken();
 					hasMoreOperands = tokens.hasMoreTokens() && ! ")".equals( operandToken );
 				}
 
 				TrimOperands trimOperands = new TrimOperands( operands );
 				result.append( "trim(" );
 				if ( trimOperands.trimSpec != null ) {
 					result.append( trimOperands.trimSpec ).append( ' ' );
 				}
 				if ( trimOperands.trimChar != null ) {
 					if ( trimOperands.trimChar.startsWith( "'" ) && trimOperands.trimChar.endsWith( "'" ) ) {
 						result.append( trimOperands.trimChar );
 					}
 					else {
 						result.append(
 								renderWhereStringTemplate( trimOperands.trimSpec, placeholder, dialect, functionRegistry )
 						);
 					}
 					result.append( ' ' );
 				}
 				if ( trimOperands.from != null ) {
 					result.append( trimOperands.from ).append( ' ' );
 				}
 				else if ( trimOperands.trimSpec != null || trimOperands.trimChar != null ) {
 					// I think ANSI SQL says that the 'from' is not optional if either trim-spec or trim-char are specified
 					result.append( "from " );
 				}
 
 				result.append( renderWhereStringTemplate( trimOperands.trimSource, placeholder, dialect, functionRegistry ) )
 						.append( ')' );
 
 				hasMore = tokens.hasMoreTokens();
 				nextToken = hasMore ? tokens.nextToken() : null;
 
 				continue;
 			}
 
 			boolean quotedOrWhitespace = quoted || quotedIdentifier || isQuoteCharacter
 					|| Character.isWhitespace( token.charAt(0) );
 
 			if ( quotedOrWhitespace ) {
 				result.append( token );
 			}
 			else if ( beforeTable ) {
 				result.append( token );
 				beforeTable = false;
 				afterFromTable = true;
 			}
 			else if ( afterFromTable ) {
 				if ( !"as".equals(lcToken) ) {
 					afterFromTable = false;
 				}
 				result.append(token);
 			}
 			else if ( isNamedParameter(token) ) {
 				result.append(token);
 			}
 			else if ( isIdentifier(token)
 					&& !isFunctionOrKeyword(lcToken, nextToken, dialect , functionRegistry) ) {
 				result.append(placeholder)
 						.append('.')
 						.append( dialect.quote(token) );
 			}
 			else {
 				if ( BEFORE_TABLE_KEYWORDS.contains(lcToken) ) {
 					beforeTable = true;
 					inFromClause = true;
 				}
 				else if ( inFromClause && ",".equals(lcToken) ) {
 					beforeTable = true;
 				}
 				result.append(token);
 			}
 
 			//Yuck:
 			if ( inFromClause
 					&& KEYWORDS.contains( lcToken ) //"as" is not in KEYWORDS
 					&& !BEFORE_TABLE_KEYWORDS.contains( lcToken ) ) {
 				inFromClause = false;
 			}
 		}
 
 		return result.toString();
 	}
 
 //	/**
 //	 * Takes the where condition provided in the mapping attribute and interpolates the alias.
 //	 * Handles sub-selects, quoted identifiers, quoted strings, expressions, SQL functions,
 //	 * named parameters.
 //	 *
 //	 * @param sqlWhereString The string into which to interpolate the placeholder value
 //	 * @param placeholder The value to be interpolated into the the sqlWhereString
 //	 * @param dialect The dialect to apply
 //	 * @param functionRegistry The registry of all sql functions
 //	 *
 //	 * @return The rendered sql fragment
 //	 */
 //	public static String renderWhereStringTemplate(
 //			String sqlWhereString,
 //			String placeholder,
 //			Dialect dialect,
 //			SQLFunctionRegistry functionRegistry) {
 //
 //		// IMPL NOTE : The basic process here is to tokenize the incoming string and to iterate over each token
 //		//		in turn.  As we process each token, we set a series of flags used to indicate the type of context in
 //		// 		which the tokens occur.  Depending on the state of those flags we decide whether we need to qualify
 //		//		identifier references.
 //
 //		final String dialectOpenQuote = Character.toString( dialect.openQuote() );
 //		final String dialectCloseQuote = Character.toString( dialect.closeQuote() );
 //
 //		String symbols = new StringBuilder()
 //				.append( "=><!+-*/()',|&`" )
 //				.append( StringHelper.WHITESPACE )
 //				.append( dialect.openQuote() )
 //				.append( dialect.closeQuote() )
 //				.toString();
 //		StringTokenizer tokens = new StringTokenizer( sqlWhereString, symbols, true );
 //		ProcessingState state = new ProcessingState();
 //
 //		StringBuilder quotedBuffer = new StringBuilder();
 //		StringBuilder result = new StringBuilder();
 //
 //		boolean hasMore = tokens.hasMoreTokens();
 //		String nextToken = hasMore ? tokens.nextToken() : null;
 //		while ( hasMore ) {
 //			String token = nextToken;
-//			String lcToken = token.toLowerCase();
+//			String lcToken = token.toLowerCase(Locale.ROOT);
 //			hasMore = tokens.hasMoreTokens();
 //			nextToken = hasMore ? tokens.nextToken() : null;
 //
 //			// First, determine quoting which might be based on either:
 //			// 		1) back-tick
 //			// 		2) single quote (ANSI SQL standard)
 //			// 		3) or dialect defined quote character(s)
 //			QuotingCharacterDisposition quotingCharacterDisposition = QuotingCharacterDisposition.NONE;
 //			if ( "`".equals( token ) ) {
 //				state.quoted = !state.quoted;
 //				quotingCharacterDisposition = state.quoted
 //						? QuotingCharacterDisposition.OPEN
 //						: QuotingCharacterDisposition.CLOSE;
 //				// replace token with the appropriate dialect quoting char
 //				token = lcToken = ( quotingCharacterDisposition == QuotingCharacterDisposition.OPEN )
 //						? dialectOpenQuote
 //						: dialectCloseQuote;
 //			}
 //			else if ( "'".equals( token ) ) {
 //				state.quoted = !state.quoted;
 //				quotingCharacterDisposition = state.quoted
 //						? QuotingCharacterDisposition.OPEN
 //						: QuotingCharacterDisposition.CLOSE;
 //			}
 //			else if ( !state.quoted && dialectOpenQuote.equals( token ) ) {
 //				state.quoted = true;
 //				quotingCharacterDisposition = QuotingCharacterDisposition.OPEN;
 //			}
 //			else if ( state.quoted && dialectCloseQuote.equals( token ) ) {
 //				state.quoted = false;
 //				quotingCharacterDisposition = QuotingCharacterDisposition.CLOSE;
 //			}
 //
 //			if ( state.quoted ) {
 //				quotedBuffer.append( token );
 //				continue;
 //			}
 //
 //			// if we were previously processing quoted state and just encountered the close quote, then handle that
 //			// quoted text
 //			if ( quotingCharacterDisposition == QuotingCharacterDisposition.CLOSE ) {
 //				token = quotedBuffer.toString();
 //				quotedBuffer.setLength( 0 );
 //				result.append( placeholder ).append( '.' )
 //						.append( dialectOpenQuote ).append( token ).append( dialectCloseQuote );
 //				continue;
 //			}
 //
 //			// Special processing for ANSI SQL EXTRACT function
 //			if ( "extract".equals( lcToken ) && "(".equals( nextToken ) ) {
 //				final String field = extractUntil( tokens, "from" );
 //				final String source = renderWhereStringTemplate(
 //						extractUntil( tokens, ")" ),
 //						placeholder,
 //						dialect,
 //						functionRegistry
 //				);
 //				result.append( "extract(" ).append( field ).append( " from " ).append( source ).append( ')' );
 //
 //				hasMore = tokens.hasMoreTokens();
 //				nextToken = hasMore ? tokens.nextToken() : null;
 //
 //				continue;
 //			}
 //
 //			// Special processing for ANSI SQL TRIM function
 //			if ( "trim".equals( lcToken ) && "(".equals( nextToken ) ) {
 //				List<String> operands = new ArrayList<String>();
 //				StringBuilder builder = new StringBuilder();
 //
 //				boolean hasMoreOperands = true;
 //				String operandToken = tokens.nextToken();
 //				boolean quoted = false;
 //				while ( hasMoreOperands ) {
 //					final boolean isQuote = "'".equals( operandToken );
 //					if ( isQuote ) {
 //						quoted = !quoted;
 //						if ( !quoted ) {
 //							operands.add( builder.append( '\'' ).toString() );
 //							builder.setLength( 0 );
 //						}
 //						else {
 //							builder.append( '\'' );
 //						}
 //					}
 //					else if ( quoted ) {
 //						builder.append( operandToken );
 //					}
 //					else if ( operandToken.length() == 1 && Character.isWhitespace( operandToken.charAt( 0 ) ) ) {
 //						// do nothing
 //					}
 //					else {
 //						operands.add( operandToken );
 //					}
 //					operandToken = tokens.nextToken();
 //					hasMoreOperands = tokens.hasMoreTokens() && ! ")".equals( operandToken );
 //				}
 //
 //				TrimOperands trimOperands = new TrimOperands( operands );
 //				result.append( "trim(" );
 //				if ( trimOperands.trimSpec != null ) {
 //					result.append( trimOperands.trimSpec ).append( ' ' );
 //				}
 //				if ( trimOperands.trimChar != null ) {
 //					if ( trimOperands.trimChar.startsWith( "'" ) && trimOperands.trimChar.endsWith( "'" ) ) {
 //						result.append( trimOperands.trimChar );
 //					}
 //					else {
 //						result.append(
 //								renderWhereStringTemplate( trimOperands.trimSpec, placeholder, dialect, functionRegistry )
 //						);
 //					}
 //					result.append( ' ' );
 //				}
 //				if ( trimOperands.from != null ) {
 //					result.append( trimOperands.from ).append( ' ' );
 //				}
 //				else if ( trimOperands.trimSpec != null || trimOperands.trimChar != null ) {
 //					// I think ANSI SQL says that the 'from' is not optional if either trim-spec or trim-char are specified
 //					result.append( "from " );
 //				}
 //
 //				result.append( renderWhereStringTemplate( trimOperands.trimSource, placeholder, dialect, functionRegistry ) )
 //						.append( ')' );
 //
 //				hasMore = tokens.hasMoreTokens();
 //				nextToken = hasMore ? tokens.nextToken() : null;
 //
 //				continue;
 //			}
 //
 //
 //			// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 //
 //			if ( Character.isWhitespace( token.charAt( 0 ) ) ) {
 //				result.append( token );
 //			}
 //			else if ( state.beforeTable ) {
 //				result.append( token );
 //				state.beforeTable = false;
 //				state.afterFromTable = true;
 //			}
 //			else if ( state.afterFromTable ) {
 //				if ( !"as".equals(lcToken) ) {
 //					state.afterFromTable = false;
 //				}
 //				result.append(token);
 //			}
 //			else if ( isNamedParameter(token) ) {
 //				result.append(token);
 //			}
 //			else if ( isIdentifier(token, dialect)
 //					&& !isFunctionOrKeyword(lcToken, nextToken, dialect , functionRegistry) ) {
 //				result.append(placeholder)
 //						.append('.')
 //						.append( dialect.quote(token) );
 //			}
 //			else {
 //				if ( BEFORE_TABLE_KEYWORDS.contains(lcToken) ) {
 //					state.beforeTable = true;
 //					state.inFromClause = true;
 //				}
 //				else if ( state.inFromClause && ",".equals(lcToken) ) {
 //					state.beforeTable = true;
 //				}
 //				result.append(token);
 //			}
 //
 //			//Yuck:
 //			if ( state.inFromClause
 //					&& KEYWORDS.contains( lcToken ) //"as" is not in KEYWORDS
 //					&& !BEFORE_TABLE_KEYWORDS.contains( lcToken ) ) {
 //				state.inFromClause = false;
 //			}
 //		}
 //
 //		return result.toString();
 //	}
 //
 //	private static class ProcessingState {
 //		boolean quoted = false;
 //		boolean quotedIdentifier = false;
 //		boolean beforeTable = false;
 //		boolean inFromClause = false;
 //		boolean afterFromTable = false;
 //	}
 //
 //	private static enum QuotingCharacterDisposition { NONE, OPEN, CLOSE }
 
 	private static class TrimOperands {
 		private final String trimSpec;
 		private final String trimChar;
 		private final String from;
 		private final String trimSource;
 
 		private TrimOperands(List<String> operands) {
 			final int size = operands.size();
 			if ( size == 1 ) {
 				trimSpec = null;
 				trimChar = null;
 				from = null;
 				trimSource = operands.get(0);
 			}
 			else if ( size == 4 ) {
 				trimSpec = operands.get(0);
 				trimChar = operands.get(1);
 				from = operands.get(2);
 				trimSource = operands.get(3);
 			}
 			else {
 				if ( size < 1 || size > 4 ) {
 					throw new HibernateException( "Unexpected number of trim function operands : " + size );
 				}
 
 				// trim-source will always be the last operand
 				trimSource = operands.get( size - 1 );
 
 				// ANSI SQL says that more than one operand means that the FROM is required
 				if ( ! "from".equals( operands.get( size - 2 ) ) ) {
 					throw new HibernateException( "Expecting FROM, found : " + operands.get( size - 2 ) );
 				}
 				from = operands.get( size - 2 );
 
 				// trim-spec, if there is one will always be the first operand
 				if ( "leading".equalsIgnoreCase( operands.get(0) )
 						|| "trailing".equalsIgnoreCase( operands.get(0) )
 						|| "both".equalsIgnoreCase( operands.get(0) ) ) {
 					trimSpec = operands.get(0);
 					trimChar = null;
 				}
 				else {
 					trimSpec = null;
 					if ( size - 2 == 0 ) {
 						trimChar = null;
 					}
 					else {
 						trimChar = operands.get( 0 );
 					}
 				}
 			}
 		}
 	}
 
 	private static String extractUntil(StringTokenizer tokens, String delimiter) {
 		StringBuilder valueBuilder = new StringBuilder();
 		String token = tokens.nextToken();
 		while ( ! delimiter.equalsIgnoreCase( token ) ) {
 			valueBuilder.append( token );
 			token = tokens.nextToken();
 		}
 		return valueBuilder.toString().trim();
 	}
 
 	public static class NoOpColumnMapper implements ColumnMapper {
 		public static final NoOpColumnMapper INSTANCE = new NoOpColumnMapper();
 		public SqlValueReference[] map(String reference) {
 //			return new String[] { reference };
 			return null;
 		}
 	}
 
 	/**
 	 * Performs order-by template rendering without {@link ColumnMapper column mapping}.  An <tt>ORDER BY</tt> template
 	 * has all column references "qualified" with a placeholder identified by {@link Template#TEMPLATE}
 	 *
 	 * @param orderByFragment The order-by fragment to render.
 	 * @param dialect The SQL dialect being used.
 	 * @param functionRegistry The SQL function registry
 	 *
 	 * @return The rendered <tt>ORDER BY</tt> template.
 	 *
 	 * @deprecated Use {@link #translateOrderBy} instead
 	 */
 	@Deprecated
     public static String renderOrderByStringTemplate(
 			String orderByFragment,
 			Dialect dialect,
 			SQLFunctionRegistry functionRegistry) {
 		return renderOrderByStringTemplate(
 				orderByFragment,
 				NoOpColumnMapper.INSTANCE,
 				null,
 				dialect,
 				functionRegistry
 		);
 	}
 
 	public static String renderOrderByStringTemplate(
 			String orderByFragment,
 			final ColumnMapper columnMapper,
 			final SessionFactoryImplementor sessionFactory,
 			final Dialect dialect,
 			final SQLFunctionRegistry functionRegistry) {
 		return translateOrderBy(
 				orderByFragment,
 				columnMapper,
 				sessionFactory,
 				dialect,
 				functionRegistry
 		).injectAliases( LEGACY_ORDER_BY_ALIAS_RESOLVER );
 	}
 
 	public static OrderByAliasResolver LEGACY_ORDER_BY_ALIAS_RESOLVER = new OrderByAliasResolver() {
 		@Override
 		public String resolveTableAlias(String columnReference) {
 			return TEMPLATE;
 		}
 	};
 
 	/**
 	 * Performs order-by template rendering allowing {@link ColumnMapper column mapping}.  An <tt>ORDER BY</tt> template
 	 * has all column references "qualified" with a placeholder identified by {@link Template#TEMPLATE} which can later
 	 * be used to easily inject the SQL alias.
 	 *
 	 * @param orderByFragment The order-by fragment to render.
 	 * @param columnMapper The column mapping strategy to use.
 	 * @param sessionFactory The session factory.
 	 * @param dialect The SQL dialect being used.
 	 * @param functionRegistry The SQL function registry
 	 *
 	 * @return The rendered <tt>ORDER BY</tt> template.
 	 */
 	public static OrderByTranslation translateOrderBy(
 			String orderByFragment,
 			final ColumnMapper columnMapper,
 			final SessionFactoryImplementor sessionFactory,
 			final Dialect dialect,
 			final SQLFunctionRegistry functionRegistry) {
 		TranslationContext context = new TranslationContext() {
 			public SessionFactoryImplementor getSessionFactory() {
 				return sessionFactory;
 			}
 
 			public Dialect getDialect() {
 				return dialect;
 			}
 
 			public SQLFunctionRegistry getSqlFunctionRegistry() {
 				return functionRegistry;
 			}
 
 			public ColumnMapper getColumnMapper() {
 				return columnMapper;
 			}
 		};
 
 		return OrderByFragmentTranslator.translate( context, orderByFragment );
 	}
 
 	private static boolean isNamedParameter(String token) {
 		return token.startsWith(":");
 	}
 
 	private static boolean isFunctionOrKeyword(String lcToken, String nextToken, Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return "(".equals(nextToken) ||
 			KEYWORDS.contains(lcToken) ||
 			isFunction(lcToken, nextToken, functionRegistry ) ||
 			dialect.getKeywords().contains(lcToken) ||
 			FUNCTION_KEYWORDS.contains(lcToken);
 	}
 
 	private static boolean isFunction(String lcToken, String nextToken, SQLFunctionRegistry functionRegistry) {
 		// checking for "(" is currently redundant because it is checked before getting here;
 		// doing the check anyhow, in case that earlier check goes away;
 		if ( "(".equals( nextToken ) ) {
 			return true;
 		}
 		SQLFunction function = functionRegistry.findSQLFunction(lcToken);
 		if ( function == null ) {
 			// lcToken does not refer to a function
 			return false;
 		}
 		// if function.hasParenthesesIfNoArguments() is true, then assume
 		// lcToken is not a function (since it is not followed by '(')
 		return ! function.hasParenthesesIfNoArguments();
 	}
 
 	private static boolean isIdentifier(String token) {
 		return token.charAt(0)=='`' || ( //allow any identifier quoted with backtick
 			Character.isLetter( token.charAt(0) ) && //only recognizes identifiers beginning with a letter
 			token.indexOf('.') < 0
 		);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/UniqueConstraintSchemaUpdateStrategy.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/UniqueConstraintSchemaUpdateStrategy.java
index 2e861780a3..0737ab412b 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/UniqueConstraintSchemaUpdateStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/UniqueConstraintSchemaUpdateStrategy.java
@@ -1,88 +1,89 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.tool.hbm2ddl;
 
+import java.util.Locale;
 import org.jboss.logging.Logger;
 
 /**
  * Unique columns and unique keys both use unique constraints in most dialects.
  * SchemaUpdate needs to create these constraints, but DB's
  * support for finding existing constraints is extremely inconsistent. Further,
  * non-explicitly-named unique constraints use randomly generated characters.
  * 
  * @author Brett Meyer
  */
 public enum UniqueConstraintSchemaUpdateStrategy {
 	
 	/**
 	 * Attempt to drop, then (re-)create each unique constraint.  Ignore any
 	 * exceptions thrown.  Note that this will require unique keys/constraints
 	 * to be explicitly named.  If Hibernate generates the names (randomly),
 	 * the drop will not work.
 	 * 
 	 * DEFAULT
 	 */
 	DROP_RECREATE_QUIETLY,
 	
 	/**
 	 * Attempt to (re-)create unique constraints, ignoring exceptions thrown
 	 * (e.g., if the constraint already existed)
 	 */
 	RECREATE_QUIETLY,
 
 	/**
 	 * Do not attempt to create unique constraints on a schema update
 	 */
 	SKIP;
 
 	private static final Logger log = Logger.getLogger( UniqueConstraintSchemaUpdateStrategy.class );
 
 	public static UniqueConstraintSchemaUpdateStrategy byName(String name) {
-		return valueOf( name.toUpperCase() );
+		return valueOf( name.toUpperCase(Locale.ROOT) );
 	}
 
 	public static UniqueConstraintSchemaUpdateStrategy interpret(Object setting) {
 		log.tracef( "Interpreting UniqueConstraintSchemaUpdateStrategy from setting : %s", setting );
 
 		if ( setting == null ) {
 			// default
 			return DROP_RECREATE_QUIETLY;
 		}
 
 		if ( UniqueConstraintSchemaUpdateStrategy.class.isInstance( setting ) ) {
 			return (UniqueConstraintSchemaUpdateStrategy) setting;
 		}
 
 		try {
 			final UniqueConstraintSchemaUpdateStrategy byName = byName( setting.toString() );
 			if ( byName != null ) {
 				return byName;
 			}
 		}
 		catch ( Exception ignore ) {
 		}
 
 		log.debugf( "Unable to interpret given setting [%s] as UniqueConstraintSchemaUpdateStrategy", setting );
 
 		// default
 		return DROP_RECREATE_QUIETLY;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/schema/internal/SchemaValidatorImpl.java b/hibernate-core/src/main/java/org/hibernate/tool/schema/internal/SchemaValidatorImpl.java
index c0a32c41cc..894829fb27 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/schema/internal/SchemaValidatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/schema/internal/SchemaValidatorImpl.java
@@ -1,162 +1,163 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.schema.internal;
 
 import java.util.Iterator;
+import java.util.Locale;
 
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.boot.model.relational.Sequence;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Table;
 import org.hibernate.tool.schema.extract.spi.ColumnInformation;
 import org.hibernate.tool.schema.extract.spi.DatabaseInformation;
 import org.hibernate.tool.schema.extract.spi.SequenceInformation;
 import org.hibernate.tool.schema.extract.spi.TableInformation;
 import org.hibernate.tool.schema.spi.SchemaManagementException;
 import org.hibernate.tool.schema.spi.SchemaValidator;
 import org.hibernate.type.descriptor.JdbcTypeNameMapper;
 
 /**
  * @author Steve Ebersole
  */
 public class SchemaValidatorImpl implements SchemaValidator {
 	
 	private final Dialect dialect;
 	
 	public SchemaValidatorImpl(Dialect dialect) {
 		this.dialect = dialect;
 	}
 	
 	@Override
 	public void doValidation(Metadata metadata, DatabaseInformation databaseInformation) {
 		for ( Schema schema : metadata.getDatabase().getSchemas() ) {
 			for ( Table table : schema.getTables() ) {
 				if ( !table.isPhysicalTable() ) {
 					continue;
 				}
 
 				final TableInformation tableInformation = databaseInformation.getTableInformation(
 						table.getQualifiedTableName()
 				);
 				validateTable( table, tableInformation, metadata );
 			}
 		}
 
 		for ( Schema schema : metadata.getDatabase().getSchemas() ) {
 			for ( Sequence sequence : schema.getSequences() ) {
 				final SequenceInformation sequenceInformation = databaseInformation.getSequenceInformation(
 						sequence.getName()
 				);
 				validateSequence( sequence, sequenceInformation );
 			}
 		}
 	}
 
 	protected void validateTable(Table table, TableInformation tableInformation, Metadata metadata) {
 		if ( tableInformation == null ) {
 			throw new SchemaManagementException(
 					String.format(
 							"Schema-validation: missing table [%s]",
 							table.getName()
 					)
 			);
 		}
 
 		final Iterator selectableItr = table.getColumnIterator();
 		while ( selectableItr.hasNext() ) {
 			final Selectable selectable = (Selectable) selectableItr.next();
 			if ( !Column.class.isInstance( selectable ) ) {
 				continue;
 			}
 
 			final Column column = (Column) selectable;
 			final ColumnInformation existingColumn = tableInformation.getColumn( Identifier.toIdentifier( column.getQuotedName() ) );
 			if ( existingColumn == null ) {
 				throw new SchemaManagementException(
 						String.format(
 								"Schema-validation: missing column [%s] in table [%s]",
 								column.getName(),
 								table.getName()
 						)
 				);
 			}
 			validateColumnType( table, column, existingColumn, metadata );
 		}
 	}
 
 	protected void validateColumnType(
 			Table table,
 			Column column,
 			ColumnInformation columnInformation,
 			Metadata metadata) {
 		boolean typesMatch = column.getSqlTypeCode( metadata ) == columnInformation.getTypeCode()
-				|| column.getSqlType( dialect, metadata ).toLowerCase().startsWith( columnInformation.getTypeName().toLowerCase() );
+				|| column.getSqlType( dialect, metadata ).toLowerCase(Locale.ROOT).startsWith( columnInformation.getTypeName().toLowerCase(Locale.ROOT) );
 		if ( !typesMatch ) {
 			throw new SchemaManagementException(
 					String.format(
 							"Schema-validation: wrong column type encountered in column [%s] in " +
 									"table [%s]; found [%s (Types#%s)], but expecting [%s (Types#%s)]",
 							column.getName(),
 							table.getName(),
-							columnInformation.getTypeName().toLowerCase(),
+							columnInformation.getTypeName().toLowerCase(Locale.ROOT),
 							JdbcTypeNameMapper.getTypeName( columnInformation.getTypeCode() ),
-							column.getSqlType().toLowerCase(),
+							column.getSqlType().toLowerCase(Locale.ROOT),
 							JdbcTypeNameMapper.getTypeName( column.getSqlTypeCode( metadata ) )
 					)
 			);
 		}
 
 		// this is the old Hibernate check...
 		//
 		// but I think a better check involves checks against type code and then the type code family, not
 		// just the type name.
 		//
 		// See org.hibernate.type.descriptor.sql.JdbcTypeFamilyInformation
 		// todo : this ^^
 	}
 
 	protected void validateSequence(Sequence sequence, SequenceInformation sequenceInformation) {
 		if ( sequenceInformation == null ) {
 			throw new SchemaManagementException(
 					String.format( "Schema-validation: missing sequence [%s]", sequence.getName() )
 			);
 		}
 
 		if ( sequenceInformation.getIncrementSize() > 0
 				&& sequence.getIncrementSize() != sequenceInformation.getIncrementSize() ) {
 			throw new SchemaManagementException(
 					String.format(
 							"Schema-validation: sequence [%s] defined inconsistent increment-size; found [%s] but expecting [%s]",
 							sequence.getName(),
 							sequenceInformation.getIncrementSize(),
 							sequence.getIncrementSize()
 					)
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/dialect/SQLServer2005DialectTestCase.java b/hibernate-core/src/test/java/org/hibernate/dialect/SQLServer2005DialectTestCase.java
index 5dbc6cfc49..fbc2cf0fc2 100644
--- a/hibernate-core/src/test/java/org/hibernate/dialect/SQLServer2005DialectTestCase.java
+++ b/hibernate-core/src/test/java/org/hibernate/dialect/SQLServer2005DialectTestCase.java
@@ -1,215 +1,216 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
+import java.util.Locale;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 
 import static org.junit.Assert.assertEquals;
 
 /**
  * Unit test of the behavior of the SQLServerDialect utility methods
  *
  * @author Valotasion Yoryos
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class SQLServer2005DialectTestCase extends BaseUnitTestCase {
 	private SQLServer2005Dialect dialect;
 
 	@Before
 	public void setup() {
 		dialect = new SQLServer2005Dialect();
 	}
 
 	@After
 	public void tearDown() {
 		dialect = null;
 	}
 
 	@Test
 	public void testGetLimitString() {
 		String input = "select distinct f1 as f53245 from table849752 order by f234, f67 desc";
 
 		assertEquals(
 			"with query as (select inner_query.*, row_number() over (order by current_timestamp) as __hibernate_row_nr__ from ( " +
 				"select distinct top(?) f1 as f53245 from table849752 order by f234, f67 desc ) inner_query )" +
 				" select f53245 from query where __hibernate_row_nr__ >= ? and __hibernate_row_nr__ < ?",
-			dialect.getLimitHandler().processSql( input, toRowSelection( 10, 15 ) ).toLowerCase() );
+			dialect.getLimitHandler().processSql( input, toRowSelection( 10, 15 ) ).toLowerCase(Locale.ROOT) );
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-6950")
 	public void testGetLimitStringWithFromColumnName() {
 		final String fromColumnNameSQL = "select persistent0_.rid as rid1688_, " +
 				"persistent0_.deviationfromtarget as deviati16_1688_, " + // "from" character sequence as a part of the column name
 				"persistent0_.sortindex as sortindex1688_ " +
 				"from m_evalstate persistent0_ " +
 				"where persistent0_.customerid=?";
 
 		assertEquals(
 				"WITH query AS (SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " +
 						fromColumnNameSQL + " ) inner_query ) " +
 						"SELECT rid1688_, deviati16_1688_, sortindex1688_ FROM query WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?",
 				dialect.getLimitHandler().processSql( fromColumnNameSQL, toRowSelection( 1, 10 ) )
 		);
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-8301")
 	public void testGetLimitStringAliasGeneration() {
 		final String notAliasedSQL = "select column1, column2, column3, column4 from table1";
 
 		assertEquals(
 				"WITH query AS (SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " +
 						"select column1 as page0_, column2 as page1_, column3 as page2_, column4 as page3_ from table1 ) inner_query ) " +
 						"SELECT page0_, page1_, page2_, page3_ FROM query WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?",
 				dialect.getLimitHandler().processSql( notAliasedSQL, toRowSelection( 3, 5 ) )
 		);
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7019")
 	public void testGetLimitStringWithSubselect() {
 		final String subselectInSelectClauseSQL = "select persistent0_.id as col_0_0_, " +
 				"(select max(persistent1_.acceptancedate) " +
 				"from av_advisoryvariant persistent1_ " +
 				"where persistent1_.clientid=persistent0_.id) as col_1_0_ " +
 				"from c_customer persistent0_ " +
 				"where persistent0_.type='v'";
 
 		assertEquals(
 				"WITH query AS (SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " +
 						subselectInSelectClauseSQL + " ) inner_query ) " +
 						"SELECT col_0_0_, col_1_0_ FROM query WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?",
 				dialect.getLimitHandler().processSql( subselectInSelectClauseSQL, toRowSelection( 2, 5 ) )
 		);
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-6728")
 	public void testGetLimitStringCaseSensitive() {
 		final String caseSensitiveSQL = "select persistent0_.id, persistent0_.uid AS tmp1, " +
 				"(select case when persistent0_.name = 'Smith' then 'Neo' else persistent0_.id end) " +
 				"from C_Customer persistent0_ " +
 				"where persistent0_.type='Va' " +
 				"order by persistent0_.Order";
 
 		assertEquals(
 				"WITH query AS (SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " +
 						"select TOP(?) persistent0_.id as page0_, persistent0_.uid AS tmp1, " +
 						"(select case when persistent0_.name = 'Smith' then 'Neo' else persistent0_.id end) as page1_ " +
 						"from C_Customer persistent0_ where persistent0_.type='Va' order by persistent0_.Order ) " +
 						"inner_query ) SELECT page0_, tmp1, page1_ FROM query WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?",
 				dialect.getLimitHandler().processSql( caseSensitiveSQL, toRowSelection( 1, 2 ) )
 		);
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-6310")
 	public void testGetLimitStringDistinctWithinAggregation() {
 		final String distinctInAggregateSQL = "select aggregate_function(distinct p.n) as f1 from table849752 p order by f1";
 
 		assertEquals(
 				"WITH query AS (SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " +
 						"select TOP(?) aggregate_function(distinct p.n) as f1 from table849752 p order by f1 ) inner_query ) " +
 						"SELECT f1 FROM query WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?",
 				dialect.getLimitHandler().processSql( distinctInAggregateSQL, toRowSelection( 2, 5 ) )
 		);
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7370")
 	public void testGetLimitStringWithMaxOnly() {
 		final String query = "select product2x0_.id as id0_, product2x0_.description as descript2_0_ " +
 				"from Product2 product2x0_ order by product2x0_.id";
 
 		assertEquals(
 				"select TOP(?) product2x0_.id as id0_, product2x0_.description as descript2_0_ " +
 						"from Product2 product2x0_ order by product2x0_.id",
 				dialect.getLimitHandler().processSql( query, toRowSelection( 0, 1 ) )
 		);
 
 		final String distinctQuery = "select distinct product2x0_.id as id0_, product2x0_.description as descript2_0_ " +
 				"from Product2 product2x0_ order by product2x0_.id";
 
 		assertEquals(
 				"select distinct TOP(?) product2x0_.id as id0_, product2x0_.description as descript2_0_ " +
 						"from Product2 product2x0_ order by product2x0_.id",
 				dialect.getLimitHandler().processSql( distinctQuery, toRowSelection( 0, 5 ) )
 		);
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7781")
 	public void testGetLimitStringWithCastOperator() {
 		final String query = "select cast(lc302_doku6_.redniBrojStavke as varchar(255)) as col_0_0_, lc302_doku6_.dokumentiID as col_1_0_ " +
 				"from LC302_Dokumenti lc302_doku6_ order by lc302_doku6_.dokumentiID DESC";
 
 		assertEquals(
 				"WITH query AS (SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " +
 					"select TOP(?) cast(lc302_doku6_.redniBrojStavke as varchar(255)) as col_0_0_, lc302_doku6_.dokumentiID as col_1_0_ " +
 					"from LC302_Dokumenti lc302_doku6_ order by lc302_doku6_.dokumentiID DESC ) inner_query ) " +
 					"SELECT col_0_0_, col_1_0_ FROM query WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?",
 				dialect.getLimitHandler().processSql( query, toRowSelection( 1, 3 ) )
 		);
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-8007")
 	public void testGetLimitStringSelectingMultipleColumnsFromSeveralTables() {
 		final String query = "select t1.*, t2.* from tab1 t1, tab2 t2 where t1.ref = t2.ref order by t1.id desc";
 
 		assertEquals(
 				"WITH query AS (SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " +
 						"select TOP(?) t1.*, t2.* from tab1 t1, tab2 t2 where t1.ref = t2.ref order by t1.id desc ) inner_query ) " +
 						"SELECT * FROM query WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?",
 				dialect.getLimitHandler().processSql( query, toRowSelection( 1, 3 ) )
 		);
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-8007")
 	public void testGetLimitStringSelectingAllColumns() {
 		final String query = "select * from tab1 t1, tab2 t2 where t1.ref = t2.ref order by t1.id desc";
 
 		assertEquals(
 				"WITH query AS (SELECT inner_query.*, ROW_NUMBER() OVER (ORDER BY CURRENT_TIMESTAMP) as __hibernate_row_nr__ FROM ( " +
 						"select TOP(?) * from tab1 t1, tab2 t2 where t1.ref = t2.ref order by t1.id desc ) inner_query ) " +
 						"SELECT * FROM query WHERE __hibernate_row_nr__ >= ? AND __hibernate_row_nr__ < ?",
 				dialect.getLimitHandler().processSql( query, toRowSelection( 1, 3 ) )
 		);
 	}
 
 	private RowSelection toRowSelection(int firstRow, int maxRows) {
 		RowSelection selection = new RowSelection();
 		selection.setFirstRow( firstRow );
 		selection.setMaxRows( maxRows );
 		return selection;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/dataTypes/BasicOperationsTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/dataTypes/BasicOperationsTest.java
index 990bcd8728..ae871bddc7 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/dataTypes/BasicOperationsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/dataTypes/BasicOperationsTest.java
@@ -1,176 +1,177 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.dataTypes;
 
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.Date;
+import java.util.Locale;
 
 import org.junit.Test;
 
 import org.hibernate.Session;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.testing.DialectCheck;
 import org.hibernate.testing.DialectChecks;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.type.descriptor.JdbcTypeNameMapper;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Steve Ebersole
  */
 @RequiresDialectFeature(value = {DialectChecks.SupportsExpectedLobUsagePattern.class, BasicOperationsTest.OracleDialectChecker.class}, jiraKey = "HHH-6834")
 public class BasicOperationsTest extends BaseCoreFunctionalTestCase {
 
 	private static final String SOME_ENTITY_TABLE_NAME = "SOMEENTITY";
 	private static final String SOME_OTHER_ENTITY_TABLE_NAME = "SOMEOTHERENTITY";
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { SomeEntity.class, SomeOtherEntity.class };
 	}
 	public static class OracleDialectChecker implements DialectCheck{
 		@Override
 		public boolean isMatch(Dialect dialect) {
 			return ! (dialect instanceof Oracle8iDialect);
 		}
 	}
 
 	@Test
 	public void testCreateAndDelete() {
 		Date now = new Date();
 
 		Session s = openSession();
 
 		s.doWork( new ValidateSomeEntityColumns( (SessionImplementor) s ) );
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_ENTITY_TABLE_NAME, 0 ) );
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_OTHER_ENTITY_TABLE_NAME, 0 ) );
 
 		s.beginTransaction();
 		SomeEntity someEntity = new SomeEntity( now );
 		SomeOtherEntity someOtherEntity = new SomeOtherEntity( 1 );
 		s.save( someEntity );
 		s.save( someOtherEntity );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_ENTITY_TABLE_NAME, 1 ) );
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_OTHER_ENTITY_TABLE_NAME, 1 ) );
 
 		s.beginTransaction();
 		s.delete( someEntity );
 		s.delete( someOtherEntity );
 		s.getTransaction().commit();
 
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_ENTITY_TABLE_NAME, 0 ) );
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_OTHER_ENTITY_TABLE_NAME, 0 ) );
 
 		s.close();
 	}
 
 	// verify all the expected columns are created
 	class ValidateSomeEntityColumns implements Work {
 		private SessionImplementor s;
 		
 		public ValidateSomeEntityColumns( SessionImplementor s ) {
 			this.s = s;
 		}
 		
 		public void execute(Connection connection) throws SQLException {
 			// id -> java.util.Date (DATE - becase of explicit TemporalType)
 			validateColumn( connection, "ID", java.sql.Types.DATE );
 
 			// timeData -> java.sql.Time (TIME)
 			validateColumn( connection, "TIMEDATA", java.sql.Types.TIME );
 
 			// tsData -> java.sql.Timestamp (TIMESTAMP)
 			validateColumn( connection, "TSDATA", java.sql.Types.TIMESTAMP );
 		}
 
 		private void validateColumn(Connection connection, String columnName, int expectedJdbcTypeCode)
 				throws SQLException {
 			DatabaseMetaData meta = connection.getMetaData();
 
 			// DBs treat the meta information differently, in particular case sensitivity.
 			// We need to use the meta information to find out how to treat names
 			String tableNamePattern = generateFinalNamePattern( meta, SOME_ENTITY_TABLE_NAME );
 			String columnNamePattern = generateFinalNamePattern( meta, columnName );
 
 			ResultSet columnInfo = meta.getColumns( null, null, tableNamePattern, columnNamePattern );
 			s.getTransactionCoordinator().getJdbcCoordinator().register(columnInfo, columnInfo.getStatement());
 			assertTrue( columnInfo.next() );
 			int dataType = columnInfo.getInt( "DATA_TYPE" );
 			s.getTransactionCoordinator().getJdbcCoordinator().release( columnInfo, columnInfo.getStatement() );
 			assertEquals(
 					columnName,
 					JdbcTypeNameMapper.getTypeName( expectedJdbcTypeCode ),
 					JdbcTypeNameMapper.getTypeName( dataType )
 			);
 		}
 
 		private String generateFinalNamePattern(DatabaseMetaData meta, String name) throws SQLException {
 			if ( meta.storesLowerCaseIdentifiers() ) {
-				return name.toLowerCase();
+				return name.toLowerCase(Locale.ROOT);
 			}
 			else {
 				return name;
 			}
 		}
 	}
 
 	// verify we have the right amount of columns
 	class ValidateRowCount implements Work {
 		private final int expectedRowCount;
 		private final String table;
 
 		private SessionImplementor s;
 		
 		public ValidateRowCount(SessionImplementor s, String table, int count) {
 			this.s = s;
 			this.expectedRowCount = count;
 			this.table = table;
 		}
 
 		public void execute(Connection connection) throws SQLException {
 			Statement st = s.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
 			s.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st, "SELECT COUNT(*) FROM " + table );
 			ResultSet result = s.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st, "SELECT COUNT(*) FROM " + table );
 			result.next();
 			int rowCount = result.getInt( 1 );
 			assertEquals( "Unexpected row count", expectedRowCount, rowCount );
 		}
 	}
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/BasicHibernateAnnotationsTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/BasicHibernateAnnotationsTest.java
index 8fbbafc922..d39ed298a3 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/BasicHibernateAnnotationsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/BasicHibernateAnnotationsTest.java
@@ -1,741 +1,742 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat, Inc. and/or its affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.entity;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNotSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 import java.math.BigDecimal;
 import java.util.Currency;
 import java.util.Date;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.Locale;
 import java.util.Set;
 import org.hibernate.dialect.TeradataDialect;
 import org.hibernate.testing.SkipForDialect;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.Query;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.testing.DialectChecks;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.ServiceRegistryBuilder;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 /**
  * @author Emmanuel Bernard
  */
 public class BasicHibernateAnnotationsTest extends BaseCoreFunctionalTestCase {
 	@Override
 	protected boolean isCleanupTestDataRequired() {
 		return true;
 	}
 	@Test
 	@RequiresDialectFeature( DialectChecks.SupportsExpectedLobUsagePattern.class )
 	public void testEntity() throws Exception {
 		Forest forest = new Forest();
 		forest.setName( "Fontainebleau" );
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( forest );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		forest = (Forest) s.get( Forest.class, forest.getId() );
 		assertNotNull( forest );
 		forest.setName( "Fontainebleau" );
 		//should not execute SQL update
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		forest = (Forest) s.get( Forest.class, forest.getId() );
 		assertNotNull( forest );
 		forest.setLength( 23 );
 		//should execute dynamic SQL update
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete( s.get( Forest.class, forest.getId() ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	@RequiresDialectFeature( DialectChecks.SupportsExpectedLobUsagePattern.class )
 	@SkipForDialect(value = TeradataDialect.class , comment = "One transaction hangs the other")
 	public void testVersioning() throws Exception {
 		Forest forest = new Forest();
 		forest.setName( "Fontainebleau" );
 		forest.setLength( 33 );
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( forest );
 		tx.commit();
 		s.close();
 
 		Session parallelSession = openSession();
 		Transaction parallelTx = parallelSession.beginTransaction();
 		s = openSession();
 		tx = s.beginTransaction();
 
 		forest = (Forest) parallelSession.get( Forest.class, forest.getId() );
 		Forest reloadedForest = (Forest) s.get( Forest.class, forest.getId() );
 		reloadedForest.setLength( 11 );
 		assertNotSame( forest, reloadedForest );
 		tx.commit();
 		s.close();
 
 		forest.setLength( 22 );
 		try {
 			parallelTx.commit();
 			fail( "All optimistic locking should have make it fail" );
 		}
 		catch (HibernateException e) {
 			if ( parallelTx != null ) parallelTx.rollback();
 		}
 		finally {
 			parallelSession.close();
 		}
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete( s.get( Forest.class, forest.getId() ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	@RequiresDialectFeature( DialectChecks.SupportsExpectedLobUsagePattern.class )
 	public void testPolymorphism() throws Exception {
 		Forest forest = new Forest();
 		forest.setName( "Fontainebleau" );
 		forest.setLength( 33 );
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( forest );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Query query = s.createQuery( "from java.lang.Object" );
 		assertEquals( 0, query.list().size() );
 		query = s.createQuery( "from Forest" );
 		assertTrue( 0 < query.list().size() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	@RequiresDialectFeature( DialectChecks.SupportsExpectedLobUsagePattern.class )
 	public void testType() throws Exception {
 		Forest f = new Forest();
 		f.setName( "Broceliande" );
 		String description = "C'est une enorme foret enchantee ou vivais Merlin et toute la clique";
 		f.setLongDescription( description );
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( f );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		f = (Forest) s.get( Forest.class, f.getId() );
 		assertNotNull( f );
 		assertEquals( description, f.getLongDescription() );
 		s.delete( f );
 		tx.commit();
 		s.close();
 
 	}
 
 	/*
 	 * Test import of TypeDefs from MappedSuperclass and 
 	 * Embedded classes.
 	 * The classes 'Name' and 'FormalLastName' both embed the same 
 	 * component 'LastName'. This is to verify that processing the 
 	 * typedef defined in the component TWICE does not create any 
 	 * issues.  
 	 */
 	@Test
 	public void testImportTypeDefinitions() throws Exception {
 		LastName lastName = new LastName();
 		lastName.setName("reddy");
 				
 		Name name = new Name();
 		name.setFirstName("SHARATH");
 		name.setLastName(lastName);
 		
 		FormalLastName formalName = new FormalLastName();
 		formalName.setLastName(lastName);
 		formalName.setDesignation("Mr");
 				
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist(name);
 		s.persist(formalName);
 		tx.commit();
 		s.close();
 		 
 		s = openSession();
 		tx = s.beginTransaction();
 		name = (Name) s.get( Name.class, name.getId() );
 		assertNotNull( name );
 		assertEquals( "sharath", name.getFirstName() );
 		assertEquals( "REDDY", name.getLastName().getName() );
 		
 		formalName = (FormalLastName) s.get(FormalLastName.class, formalName.getId());
 		assertEquals( "REDDY", formalName.getLastName().getName() );
 		
 		s.delete(name);
 		s.delete(formalName);
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testNonLazy() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Forest f = new Forest();
 		Tree t = new Tree();
 		t.setName( "Basic one" );
 		s.persist( f );
 		s.persist( t );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		f = (Forest) s.load( Forest.class, f.getId() );
 		t = (Tree) s.load( Tree.class, t.getId() );
 		assertFalse( "Default should be lazy", Hibernate.isInitialized( f ) );
 		assertTrue( "Tree is not lazy", Hibernate.isInitialized( t ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCache() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		ZipCode zc = new ZipCode();
 		zc.code = "92400";
 		s.persist( zc );
 		tx.commit();
 		s.close();
 		sessionFactory().getStatistics().clear();
 		sessionFactory().getStatistics().setStatisticsEnabled( true );
 		sessionFactory().evict( ZipCode.class );
 		s = openSession();
 		tx = s.beginTransaction();
 		s.get( ZipCode.class, zc.code );
 		assertEquals( 1, sessionFactory().getStatistics().getSecondLevelCachePutCount() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.get( ZipCode.class, zc.code );
 		assertEquals( 1, sessionFactory().getStatistics().getSecondLevelCacheHitCount() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testFilterOnCollection() {
 		
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		
 		Topic topic = new Topic();
 		Narrative n1 = new Narrative();
 		n1.setState("published");
 		topic.addNarrative(n1);
 		
 		Narrative n2 = new Narrative();
 		n2.setState("draft");
 		topic.addNarrative(n2);
 		
 		s.persist(topic);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		topic = (Topic) s.load( Topic.class, topic.getId() );
 		
 		s.enableFilter("byState").setParameter("state", "published");
 		topic = (Topic) s.load( Topic.class, topic.getId() );
 		assertNotNull(topic); 
 		assertTrue(topic.getNarratives().size() == 1); 
 		assertEquals("published", topic.getNarratives().iterator().next().getState());
 		tx.commit();
 		s.close();
 		
 		s = openSession();
 		tx = s.beginTransaction();
 		s.createQuery( "delete from " + Narrative.class.getSimpleName() ).executeUpdate();
 		tx.commit();
 		s.close();
 	} 
 
 	@Test
 	public void testCascadedDeleteOfChildEntitiesBug2() {
 		// Relationship is one SoccerTeam to many Players.
 		// Create a SoccerTeam (parent) and three Players (child).
 		// Verify that the count of Players is correct.
 		// Clear the SoccerTeam reference Players.
 		// The orphanRemoval should remove the Players automatically.
 		// @OneToMany(mappedBy="name", orphanRemoval=true)
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 
 		SoccerTeam team = new SoccerTeam();
 		int teamid = team.getId();
 		Player player1 = new Player();
 		player1.setName("Shalrie Joseph");
 		team.addPlayer(player1);
 
 		Player player2 = new Player();
 		player2.setName("Taylor Twellman");
 		team.addPlayer(player2);
 
 		Player player3 = new Player();
 		player3.setName("Steve Ralston");
 		team.addPlayer(player3);
 		s.persist(team);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		team = (SoccerTeam)s.merge(team);
 		int count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 		assertEquals("expected count of 3 but got = " + count, count, 3);
 
 		// clear references to players, this should orphan the players which should
 		// in turn trigger orphanRemoval logic.
 		team.getPlayers().clear();
 //		count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 //		assertEquals("expected count of 0 but got = " + count, count, 0);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 		assertEquals("expected count of 0 but got = " + count, count, 0);
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCascadedDeleteOfChildOneToOne() {
 		// create two single player teams (for one versus one match of soccer)
 		// and associate teams with players via the special OneVOne methods.
 		// Clear the Team reference to players, which should orphan the teams.
 		// Orphaning the team should delete the team. 
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 
 		SoccerTeam team = new SoccerTeam();
 		team.setName("Shalrie's team");
 		Player player1 = new Player();
 		player1.setName("Shalrie Joseph");
 		team.setOneVonePlayer(player1);
 		player1.setOneVoneTeam(team);
 
 		s.persist(team);
 
 		SoccerTeam team2 = new SoccerTeam();
 		team2.setName("Taylor's team");
 		Player player2 = new Player();
 		player2.setName("Taylor Twellman");
 		team2.setOneVonePlayer(player2);
 		player2.setOneVoneTeam(team2);
 		s.persist(team2);
 		tx.commit();
 
 		tx = s.beginTransaction();
 		s.clear();
 		team2 = (SoccerTeam)s.load(team2.getClass(), team2.getId());
 		team = (SoccerTeam)s.load(team.getClass(), team.getId());
 		int count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 		assertEquals("expected count of 2 but got = " + count, count, 2);
 
 		// clear references to players, this should orphan the players which should
 		// in turn trigger orphanRemoval logic.
 		team.setOneVonePlayer(null);
 		team2.setOneVonePlayer(null);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 		assertEquals("expected count of 0 but got = " + count, count, 0);
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testFilter() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.createQuery( "delete Forest" ).executeUpdate();
 		Forest f1 = new Forest();
 		f1.setLength( 2 );
 		s.persist( f1 );
 		Forest f2 = new Forest();
 		f2.setLength( 20 );
 		s.persist( f2 );
 		Forest f3 = new Forest();
 		f3.setLength( 200 );
 		s.persist( f3 );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		s.enableFilter( "betweenLength" ).setParameter( "minLength", 5 ).setParameter( "maxLength", 50 );
 		long count = ( (Long) s.createQuery( "select count(*) from Forest" ).iterate().next() ).intValue();
 		assertEquals( 1, count );
 		s.disableFilter( "betweenLength" );
 		s.enableFilter( "minLength" ).setParameter( "minLength", 5 );
 		count = ( (Long) s.createQuery( "select count(*) from Forest" ).iterate().next() ).longValue();
 		assertEquals( 2l, count );
 		s.disableFilter( "minLength" );
 		tx.rollback();
 		s.close();
 	}
 	  
 	/**
 	 * Tests the functionality of inheriting @Filter and @FilterDef annotations
 	 * defined on a parent MappedSuperclass(s)
 	 */
 	@Test
 	public void testInheritFiltersFromMappedSuperclass() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.createQuery( "delete Drill" ).executeUpdate();
 		Drill d1 = new PowerDrill();
 		d1.setName("HomeDrill1");
 		d1.setCategory("HomeImprovment");
 		s.persist( d1 );
 		Drill d2 = new PowerDrill();
 		d2.setName("HomeDrill2");
 		d2.setCategory("HomeImprovement");
 		s.persist(d2);
 		Drill d3 = new PowerDrill();
 		d3.setName("HighPowerDrill");
 		d3.setCategory("Industrial");
 		s.persist( d3 );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		 
 		//We test every filter with 2 queries, the first on the base class of the 
 		//inheritance hierarchy (Drill), and the second on a subclass (PowerDrill)
 		s.enableFilter( "byName" ).setParameter( "name", "HomeDrill1");
 		long count = ( (Long) s.createQuery( "select count(*) from Drill" ).iterate().next() ).intValue();
 		assertEquals( 1, count );
 		count = ( (Long) s.createQuery( "select count(*) from PowerDrill" ).iterate().next() ).intValue();
 		assertEquals( 1, count );
 		s.disableFilter( "byName" );
 		
 		s.enableFilter( "byCategory" ).setParameter( "category", "Industrial" );
 		count = ( (Long) s.createQuery( "select count(*) from Drill" ).iterate().next() ).longValue();
 		assertEquals( 1, count );
 		count = ( (Long) s.createQuery( "select count(*) from PowerDrill" ).iterate().next() ).longValue();
 		assertEquals( 1, count );
 		s.disableFilter( "byCategory" );
 		
 		tx.rollback();
 		s.close();
 	}
 	
 	@Test
 	@RequiresDialectFeature( DialectChecks.SupportsExpectedLobUsagePattern.class )
 	public void testParameterizedType() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Forest f = new Forest();
 		f.setSmallText( "ThisIsASmallText" );
 		f.setBigText( "ThisIsABigText" );
 		s.persist( f );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		Forest f2 = (Forest) s.get( Forest.class, f.getId() );
-		assertEquals( f.getSmallText().toLowerCase(), f2.getSmallText() );
-		assertEquals( f.getBigText().toUpperCase(), f2.getBigText() );
+		assertEquals( f.getSmallText().toLowerCase(Locale.ROOT), f2.getSmallText() );
+		assertEquals( f.getBigText().toUpperCase(Locale.ROOT), f2.getBigText() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	@RequiresDialectFeature( DialectChecks.SupportsExpectedLobUsagePattern.class )
 	public void testSerialized() throws Exception {
 		Forest forest = new Forest();
 		forest.setName( "Shire" );
 		Country country = new Country();
 		country.setName( "Middle Earth" );
 		forest.setCountry( country );
 		Set<Country> near = new HashSet<Country>();
 		country = new Country();
 		country.setName("Mordor");
 		near.add(country);
 		country = new Country();
 		country.setName("Gondor");
 		near.add(country);
 		country = new Country();
 		country.setName("Eriador");
 		near.add(country);
 		forest.setNear(near);
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( forest );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		forest = (Forest) s.get( Forest.class, forest.getId() );
 		assertNotNull( forest );
 		country = forest.getCountry();
 		assertNotNull( country );
 		assertEquals( country.getName(), forest.getCountry().getName() );
 		near = forest.getNear();
 		assertTrue("correct number of nearby countries", near.size() == 3);
 		for (Iterator iter = near.iterator(); iter.hasNext();) {
 			country = (Country)iter.next();
 			String name = country.getName();
 			assertTrue("found expected nearby country " + name,
 				(name.equals("Mordor") || name.equals("Gondor") || name.equals("Eriador")));
 		}
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCompositeType() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Ransom r = new Ransom();
 		r.setKidnapperName( "Se7en" );
 		r.setDate( new Date() );
 		MonetaryAmount amount = new MonetaryAmount(
 				new BigDecimal( 100000 ),
 				Currency.getInstance( "EUR" )
 		);
 		r.setAmount( amount );
 		s.persist( r );
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		r = (Ransom) s.get( Ransom.class, r.getId() );
 		assertNotNull( r );
 		assertNotNull( r.getAmount() );
 		assertTrue( 0 == new BigDecimal( 100000 ).compareTo( r.getAmount().getAmount() ) );
 		assertEquals( Currency.getInstance( "EUR" ), r.getAmount().getCurrency() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testFormula() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		org.hibernate.test.annotations.entity.Flight airFrance = new Flight();
 		airFrance.setId( new Long( 747 ) );
 		airFrance.setMaxAltitude( 10000 );
 		s.persist( airFrance );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		airFrance = (Flight) s.get( Flight.class, airFrance.getId() );
 		assertNotNull( airFrance );
 		assertEquals( 10000000, airFrance.getMaxAltitudeInMilimeter() );
 		s.delete( airFrance );
 		tx.commit();
 		s.close();
 	}
 		
 	@Test
 	public void testTypeDefNameAndDefaultForTypeAttributes() {
 		ContactDetails contactDetails = new ContactDetails();
 		contactDetails.setLocalPhoneNumber(new PhoneNumber("999999"));
 		contactDetails.setOverseasPhoneNumber(
 				new OverseasPhoneNumber("041", "111111"));
 		
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist(contactDetails);
 		tx.commit();
 		s.close();
 		
 		s = openSession();
 		tx = s.beginTransaction();
 		contactDetails = 
 			(ContactDetails) s.get( ContactDetails.class, contactDetails.getId() );
 		assertNotNull( contactDetails );
 		assertEquals( "999999", contactDetails.getLocalPhoneNumber().getNumber() );
 		assertEquals( "041111111", contactDetails.getOverseasPhoneNumber().getNumber() );
 		s.delete(contactDetails);
 		tx.commit();
 		s.close();
 	
 	}
 	
 	@Test
 	public void testTypeDefWithoutNameAndDefaultForTypeAttributes() {
 		SessionFactory sf=null;
 		try {
 			Configuration config = new Configuration();
 			config.addAnnotatedClass(LocalContactDetails.class);
 			sf = config.buildSessionFactory( ServiceRegistryBuilder.buildServiceRegistry( config.getProperties() ) );
 			fail("Did not throw expected exception");
 		}
 		catch( AnnotationException ex ) {
 			assertEquals(
 					"Either name or defaultForType (or both) attribute should be set in TypeDef having typeClass org.hibernate.test.annotations.entity.PhoneNumberType", 
 					ex.getMessage());
 		} finally {
 			if( sf != null){
 				sf.close();
 			}
 		}
 	}
 
 	
 	/**
 	 * A custom type is used in the base class, but defined in the derived class. 
 	 * This would have caused an exception, because the base class is processed 
 	 * BEFORE the derived class, and the custom type is not yet defined. However, 
 	 * it works now because we are setting the typeName for SimpleValue in the second 
 	 * pass. 
 	 * 
 	 * 
 	 * @throws Exception
 	 */
 	@Test
 	public void testSetSimpleValueTypeNameInSecondPass() throws Exception {
 		Peugot derived = new Peugot();
 		derived.setName("sharath");
 		
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist(derived);
 		tx.commit();
 		s.close();
 		
 		s = openSession();
 		tx = s.beginTransaction();
 		derived = (Peugot) s.get( Peugot.class, derived.getId() );
 		assertNotNull( derived );
 		assertEquals( "SHARATH", derived.getName() );
 		s.delete(derived);
 		tx.commit();
 		s.close();
 	}
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[]{
 				Forest.class,
 				Tree.class,
 				Ransom.class,
 				ZipCode.class,
 				Flight.class,
 				Name.class,
 				FormalLastName.class,
 				Car.class,
 				Peugot.class,
 				ContactDetails.class,
 				Topic.class,
 				Narrative.class,
 				Drill.class,
 				PowerDrill.class,
 				SoccerTeam.class,
 				Player.class
 		};
 	}
 
 	@Override
 	protected String[] getAnnotatedPackages() {
 		return new String[]{
 				"org.hibernate.test.annotations.entity"
 		};
 	}
 
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/CasterStringType.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/CasterStringType.java
index 37f32503f3..d2fe9942d2 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/CasterStringType.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/CasterStringType.java
@@ -1,90 +1,91 @@
 //$Id$
 package org.hibernate.test.annotations.entity;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
+import java.util.Locale;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.usertype.ParameterizedType;
 import org.hibernate.usertype.UserType;
 
 /**
  * Sample of parameter type
  *
  * @author Emmanuel Bernard
  */
 public class CasterStringType implements UserType, ParameterizedType {
 	private static final String CAST = "cast";
 	private Properties parameters;
 
 	public int[] sqlTypes() {
 		return new int[]{Types.VARCHAR};
 	}
 
 	public Class returnedClass() {
 		return String.class;
 	}
 
 	public boolean equals(Object x, Object y) throws HibernateException {
 		return ( x == y ) || ( x != null && x.equals( y ) );
 	}
 
 	public int hashCode(Object x) throws HibernateException {
 		return x.hashCode();
 	}
 
 	public Object nullSafeGet(ResultSet rs, String[] names, SessionImplementor session, Object owner) throws HibernateException, SQLException {
 		String result = rs.getString( names[0] );
 		if ( rs.wasNull() ) return null;
 		if ( parameters.getProperty( CAST ).equals( "lower" ) ) {
-			return result.toLowerCase();
+			return result.toLowerCase(Locale.ROOT);
 		}
 		else {
-			return result.toUpperCase();
+			return result.toUpperCase(Locale.ROOT);
 		}
 	}
 
 	public void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session) throws HibernateException, SQLException {
 		if ( value == null ) {
 			st.setNull( index, sqlTypes()[0] );
 		}
 		else {
 			String string = (String) value;
 			if ( parameters.getProperty( CAST ).equals( "lower" ) ) {
-				string = string.toLowerCase();
+				string = string.toLowerCase(Locale.ROOT);
 			}
 			else {
-				string = string.toUpperCase();
+				string = string.toUpperCase(Locale.ROOT);
 			}
 			st.setString( index, string );
 		}
 	}
 
 	public Object deepCopy(Object value) throws HibernateException {
 		return value;
 	}
 
 	public boolean isMutable() {
 		return false;
 	}
 
 	public Serializable disassemble(Object value) throws HibernateException {
 		return (Serializable) value;
 	}
 
 	public Object assemble(Serializable cached, Object owner) throws HibernateException {
 		return cached;
 	}
 
 	public Object replace(Object original, Object target, Object owner) throws HibernateException {
 		return original;
 	}
 
 	public void setParameterValues(Properties parameters) {
 		this.parameters = parameters;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/join/JoinTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/join/JoinTest.java
index 8643bc0a93..30e17baae2 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/join/JoinTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/join/JoinTest.java
@@ -1,265 +1,266 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.join;
 
 import java.util.ArrayList;
 import java.util.Date;
+import java.util.Locale;
 
 import org.hibernate.Criteria;
 import org.hibernate.HibernateException;
 import org.hibernate.Query;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.mapping.Join;
 
 import org.hibernate.testing.junit4.BaseNonConfigCoreFunctionalTestCase;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  */
 public class JoinTest extends BaseNonConfigCoreFunctionalTestCase {
 	@Test
 	public void testDefaultValue() throws Exception {
 		Join join = (Join) metadata().getEntityBinding( Life.class.getName() ).getJoinClosureIterator().next();
 		assertEquals( "ExtendedLife", join.getTable().getName() );
 		org.hibernate.mapping.Column owner = new org.hibernate.mapping.Column();
 		owner.setName( "LIFE_ID" );
 		assertTrue( join.getTable().getPrimaryKey().containsColumn( owner ) );
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Life life = new Life();
 		life.duration = 15;
 		life.fullDescription = "Long long description";
 		s.persist( life );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Query q = s.createQuery( "from " + Life.class.getName() );
 		life = (Life) q.uniqueResult();
 		assertEquals( "Long long description", life.fullDescription );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCompositePK() throws Exception {
 		Join join = (Join) metadata().getEntityBinding( Dog.class.getName() ).getJoinClosureIterator().next();
 		assertEquals( "DogThoroughbred", join.getTable().getName() );
 		org.hibernate.mapping.Column owner = new org.hibernate.mapping.Column();
 		owner.setName( "OWNER_NAME" );
 		assertTrue( join.getTable().getPrimaryKey().containsColumn( owner ) );
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Dog dog = new Dog();
 		DogPk id = new DogPk();
 		id.name = "Thalie";
 		id.ownerName = "Martine";
 		dog.id = id;
 		dog.weight = 30;
 		dog.thoroughbredName = "Colley";
 		s.persist( dog );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Query q = s.createQuery( "from Dog" );
 		dog = (Dog) q.uniqueResult();
 		assertEquals( "Colley", dog.thoroughbredName );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testExplicitValue() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Death death = new Death();
 		death.date = new Date();
 		death.howDoesItHappen = "Well, haven't seen it";
 		s.persist( death );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Query q = s.createQuery( "from " + Death.class.getName() );
 		death = (Death) q.uniqueResult();
 		assertEquals( "Well, haven't seen it", death.howDoesItHappen );
 		s.delete( death );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testManyToOne() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Life life = new Life();
 		Cat cat = new Cat();
 		cat.setName( "kitty" );
 		cat.setStoryPart2( "and the story continues" );
 		life.duration = 15;
 		life.fullDescription = "Long long description";
 		life.owner = cat;
 		s.persist( life );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Criteria crit = s.createCriteria( Life.class );
 		crit.createCriteria( "owner" ).add( Restrictions.eq( "name", "kitty" ) );
 		life = (Life) crit.uniqueResult();
 		assertEquals( "Long long description", life.fullDescription );
 		s.delete( life.owner );
 		s.delete( life );
 		tx.commit();
 		s.close();
 	}
 	
 	@Test
 	public void testReferenceColumnWithBacktics() throws Exception {
 		Session s=openSession();
 		s.beginTransaction();
 		SysGroupsOrm g=new SysGroupsOrm();
 		SysUserOrm u=new SysUserOrm();
 		u.setGroups( new ArrayList<SysGroupsOrm>() );
 		u.getGroups().add( g );
 		s.save( g );
 		s.save( u );
 		s.getTransaction().commit();
 		s.close();
 	}
 	
 	@Test
 	public void testUniqueConstaintOnSecondaryTable() throws Exception {
 		Cat cat = new Cat();
 		cat.setStoryPart2( "My long story" );
 		Cat cat2 = new Cat();
 		cat2.setStoryPart2( "My long story" );
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		try {
 			s.persist( cat );
 			s.persist( cat2 );
 			tx.commit();
 			fail( "unique constraints violation on secondary table" );
 		}
 		catch (HibernateException e) {
 			//success
 			tx.rollback();
 		}
 		finally {
 			s.close();
 		}
 	}
 
 	@Test
 	public void testFetchModeOnSecondaryTable() throws Exception {
 		Cat cat = new Cat();
 		cat.setStoryPart2( "My long story" );
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 
 		s.persist( cat );
 		s.flush();
 		s.clear();
 		
 		s.get( Cat.class, cat.getId() );
 		//Find a way to test it, I need to define the secondary table on a subclass
 
 		tx.rollback();
 		s.close();
 	}
 
 	@Test
 	public void testCustomSQL() throws Exception {
 		Cat cat = new Cat();
 		String storyPart2 = "My long story";
 		cat.setStoryPart2( storyPart2 );
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 
 		s.persist( cat );
 		s.flush();
 		s.clear();
 
 		Cat c = (Cat) s.get( Cat.class, cat.getId() );
-		assertEquals( storyPart2.toUpperCase(), c.getStoryPart2() );
+		assertEquals( storyPart2.toUpperCase(Locale.ROOT), c.getStoryPart2() );
 
 		tx.rollback();
 		s.close();
 	}
 
 	@Test
 	public void testMappedSuperclassAndSecondaryTable() throws Exception {
 		Session s = openSession( );
 		s.getTransaction().begin();
 		C c = new C();
 		c.setAge( 12 );
 		c.setCreateDate( new Date() );
 		c.setName( "Bob" );
 		s.persist( c );
 		s.flush();
 		s.clear();
 		c= (C) s.get( C.class, c.getId() );
 		assertNotNull( c.getCreateDate() );
 		assertNotNull( c.getName() );
 		s.getTransaction().rollback();
 		s.close();
 	}
 
 	@Override
 	protected void configureMetadataBuilder(MetadataBuilder metadataBuilder) {
 		super.configureMetadataBuilder( metadataBuilder );
 		metadataBuilder.applyImplicitNamingStrategy( ImplicitNamingStrategyLegacyJpaImpl.INSTANCE );
 	}
 
 	@Override
 	protected Class[] getAnnotatedClasses() {
 		return new Class[]{
 				Life.class,
 				Death.class,
 				Cat.class,
 				Dog.class,
 				A.class,
 				B.class,
 				C.class,
 				SysGroupsOrm.class,
 				SysUserOrm.class
 		};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
index 2a578e7af1..805298b650 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
@@ -1,76 +1,77 @@
 // $Id$
 package org.hibernate.test.annotations.namingstrategy;
 
+import java.util.Locale;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyJpaCompliantImpl;
 import org.hibernate.cfg.Environment;
 import org.hibernate.mapping.Collection;
 import org.hibernate.service.ServiceRegistry;
 
 import org.hibernate.testing.ServiceRegistryBuilder;
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import org.jboss.logging.Logger;
 
 import static org.junit.Assert.assertEquals;
 
 /**
  * Test harness for ANN-716.
  *
  * @author Hardy Ferentschik
  */
 public class NamingStrategyTest extends BaseUnitTestCase {
 	private static final Logger log = Logger.getLogger( NamingStrategyTest.class );
 
 	private ServiceRegistry serviceRegistry;
 
 	@Before
     public void setUp() {
 		serviceRegistry = ServiceRegistryBuilder.buildServiceRegistry( Environment.getProperties() );
 	}
 
 	@After
     public void tearDown() {
         if ( serviceRegistry != null ) {
 			ServiceRegistryBuilder.destroy( serviceRegistry );
 		}
 	}
     @Test
 	public void testWithCustomNamingStrategy() throws Exception {
 		new MetadataSources( serviceRegistry )
 				.addAnnotatedClass(Address.class)
 				.addAnnotatedClass(Person.class)
 				.getMetadataBuilder()
 				.applyPhysicalNamingStrategy( new DummyNamingStrategy() )
 				.build();
 	}
 
     @Test
 	public void testWithJpaCompliantNamingStrategy() throws Exception {
 		Metadata metadata = new MetadataSources( serviceRegistry )
 				.addAnnotatedClass( A.class )
 				.addAnnotatedClass( AddressEntry.class )
 				.getMetadataBuilder()
 				.applyImplicitNamingStrategy( ImplicitNamingStrategyJpaCompliantImpl.INSTANCE )
 				.build();
 
 		Collection collectionBinding = metadata.getCollectionBinding( A.class.getName() + ".address" );
 		assertEquals(
 				"Expecting A#address collection table name (implicit) to be [A_address] per JPA spec (section 11.1.8)",
 				"A_ADDRESS",
-				collectionBinding.getCollectionTable().getQuotedName().toUpperCase()
+				collectionBinding.getCollectionTable().getQuotedName().toUpperCase(Locale.ROOT)
 		);
 	}
 
     @Test
 	public void testWithoutCustomNamingStrategy() throws Exception {
 		new MetadataSources( serviceRegistry )
 				.addAnnotatedClass( Address.class )
 				.addAnnotatedClass( Person.class )
 				.buildMetadata();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/query/QueryAndSQLTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/query/QueryAndSQLTest.java
index 9d64452304..af41af1f66 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/query/QueryAndSQLTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/query/QueryAndSQLTest.java
@@ -1,500 +1,501 @@
 //$Id$
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat, Inc. and/or its affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.query;
 
 import java.util.Calendar;
 import java.util.Date;
 import java.util.GregorianCalendar;
 import java.util.List;
+import java.util.Locale;
 
 import org.hibernate.MappingException;
 import org.hibernate.Query;
 import org.hibernate.SQLQuery;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.dialect.PostgreSQL81Dialect;
 import org.hibernate.dialect.PostgreSQLDialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.stat.Statistics;
 
 import org.hibernate.testing.FailureExpected;
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.annotations.A320;
 import org.hibernate.test.annotations.A320b;
 import org.hibernate.test.annotations.Plane;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * Test named queries
  *
  * @author Emmanuel Bernard
  */
 public class QueryAndSQLTest extends BaseCoreFunctionalTestCase {
 	@Override
 	protected boolean isCleanupTestDataRequired() {
 		return true;
 	}
 	@Test
 	public void testNativeQueryWithFormulaAttribute() {
 		SQLFunction dateFunction = getDialect().getFunctions().get( "current_date" );
 		String dateFunctionRendered = dateFunction.render(
 				null,
 				java.util.Collections.EMPTY_LIST,
 				sessionFactory()
 		);
 
 		String sql = String.format(
 				"select t.table_name as {t.tableName}, %s as {t.daysOld} from ALL_TABLES t  where t.table_name = 'AUDIT_ACTIONS' ",
 				dateFunctionRendered
 		);
 		String sql2 = String.format(
 				"select table_name as t_name, %s as t_time from ALL_TABLES   where table_name = 'AUDIT_ACTIONS' ",
 				dateFunctionRendered
 		);
 
 
 		Session s = openSession();
 		s.beginTransaction();
 		s.createSQLQuery( sql ).addEntity( "t", AllTables.class ).list();
 		s.createSQLQuery( sql2 ).setResultSetMapping( "all" ).list();
 		SQLQuery q = s.createSQLQuery( sql2 );
 		q.addRoot( "t", AllTables.class ).addProperty( "tableName", "t_name" ).addProperty( "daysOld", "t_time" );
 		q.list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@FailureExpected(jiraKey = "HHH-2225")
 	public void testNativeQueryWithFormulaAttributeWithoutAlias() {
 		String sql = "select table_name , sysdate() from all_tables  where table_name = 'AUDIT_ACTIONS' ";
 		Session s = openSession();
 		s.beginTransaction();
 		s.createSQLQuery( sql ).addEntity( "t", AllTables.class ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPackageQueries() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Plane p = new Plane();
 		s.persist( p );
 		Query q = s.getNamedQuery( "plane.getAll" );
 		assertEquals( 1, q.list().size() );
 		s.delete( q.list().get( 0 ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testClassQueries() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Night n = new Night();
 		Calendar c = new GregorianCalendar();
 		c.set( 2000, 2, 2 );
 		Date now = c.getTime();
 		c.add( Calendar.MONTH, -1 );
 		Date aMonthAgo = c.getTime();
 		c.add( Calendar.MONTH, 2 );
 		Date inAMonth = c.getTime();
 		n.setDate( now );
 		n.setDuration( 14 );
 		s.persist( n );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		Query q = s.getNamedQuery( "night.moreRecentThan" );
 		q.setDate( "date", aMonthAgo );
 		assertEquals( 1, q.list().size() );
 		q = s.getNamedQuery( "night.moreRecentThan" );
 		q.setDate( "date", inAMonth );
 		assertEquals( 0, q.list().size() );
 		Statistics stats = sessionFactory().getStatistics();
 		stats.setStatisticsEnabled( true );
 		stats.clear();
 		q = s.getNamedQuery( "night.duration" );
 		q.setParameter( "duration", 14l );
 		assertEquals( 1, q.list().size() );
 		assertEquals( 1, stats.getQueryCachePutCount() );
 		q = s.getNamedQuery( "night.duration" );
 		q.setParameter( "duration", 14l );
 		s.delete( q.list().get( 0 ) );
 		assertEquals( 1, stats.getQueryCacheHitCount() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testSQLQuery() {
 		Night n = new Night();
 		Calendar c = new GregorianCalendar();
 		c.set( 2000, 2, 2 );
 		Date now = c.getTime();
 		c.add( Calendar.MONTH, -1 );
 		Date aMonthAgo = c.getTime();
 		c.add( Calendar.MONTH, 2 );
 		Date inAMonth = c.getTime();
 		n.setDate( now );
 		n.setDuration( 9999 );
 		Area area = new Area();
 		area.setName( "Monceau" );
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist( n );
 		s.persist( area );
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		Query q = s.getNamedQuery( "night.getAll.bySQL" );
 		q.setParameter( 0, 9990 );
 		List result = q.list();
 		assertEquals( 1, result.size() );
 		Night n2 = (Night) result.get( 0 );
 		assertEquals( n2.getDuration(), n.getDuration() );
 		List areas = s.getNamedQuery( "getAreaByNative" ).list();
 		assertTrue( 1 == areas.size() );
 		assertEquals( area.getName(), ( (Area) areas.get( 0 ) ).getName() );
 		s.delete( areas.get( 0 ) );
 		s.delete( n2 );
 		tx.commit();
 		s.close();
 	}
 
 
 	/**
 	 * We are testing 2 things here:
 	 * 1. The query 'night.olderThan' is defined in a MappedSuperClass - Darkness.
 	 * We are verifying that queries defined in a MappedSuperClass are processed.
 	 * 2. There are 2 Entity classes that extend from Darkness - Night and Twilight.
 	 * We are verifying that this does not cause any issues.eg. Double processing of the
 	 * MappedSuperClass
 	 */
 	@Test
 	public void testImportQueryFromMappedSuperclass() {
 		Session s = openSession();
 		try {
 			s.getNamedQuery( "night.olderThan" );
 		}
 		catch ( MappingException ex ) {
 			fail( "Query imported from MappedSuperclass" );
 		}
 		s.close();
 	}
 
 	@Test
 	public void testSQLQueryWithManyToOne() {
 		cleanupCache();
 		Night n = new Night();
 		Calendar c = new GregorianCalendar();
 		c.set( 2000, 2, 2 );
 		Date now = c.getTime();
 		c.add( Calendar.MONTH, -1 );
 		Date aMonthAgo = c.getTime();
 		c.add( Calendar.MONTH, 2 );
 		Date inAMonth = c.getTime();
 		n.setDate( now );
 		n.setDuration( 9999 );
 		Area a = new Area();
 		a.setName( "Paris" );
 		n.setArea( a );
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist( a );
 		s.persist( n );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		Statistics stats = sessionFactory().getStatistics();
 		stats.setStatisticsEnabled( true );
 		stats.clear();
 		Query q = s.getNamedQuery( "night&areaCached" );
 		q.setCacheable( true );
 		List result = q.list();
 		assertEquals( 1, result.size() );
 		assertEquals( 1, stats.getQueryCachePutCount() );
 		q.setCacheable( true );
 		q.list();
 		assertEquals( 1, stats.getQueryCacheHitCount() );
 		Night n2 = (Night) ( (Object[]) result.get( 0 ) )[0];
 		assertEquals( n2.getDuration(), n.getDuration() );
 		s.delete( n2.getArea() );
 		s.delete( n2 );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testImplicitNativeQuery() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		SpaceShip ship = new SpaceShip();
 		ship.setModel( "X-Wing" );
 		ship.setName( "YuBlue" );
 		ship.setSpeed( 2000 );
 		ship.setDimensions( new Dimensions() );
 		s.persist( ship );
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		Query q = s.getNamedQuery( "implicitSample" );
 		List result = q.list();
 		assertEquals( 1, result.size() );
 		assertEquals( ship.getModel(), ( (SpaceShip) result.get( 0 ) ).getModel() );
 		s.delete( result.get( 0 ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testNativeQueryAndCompositePKAndComponents() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		SpaceShip ship = new SpaceShip();
 		ship.setModel( "X-Wing" );
 		ship.setName( "YuBlue" );
 		ship.setSpeed( 2000 );
 		ship.setDimensions( new Dimensions() );
 		ship.getDimensions().setLength( 10 );
 		ship.getDimensions().setWidth( 5 );
 		Captain captain = new Captain();
 		captain.setFirstname( "Luke" );
 		captain.setLastname( "Skywalker" );
 		ship.setCaptain( captain );
 		s.persist( captain );
 		s.persist( ship );
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		Query q = s.getNamedQuery( "compositekey" );
 		List result = q.list();
 		assertEquals( 1, result.size() );
 		Object[] row = (Object[]) result.get( 0 );
 		SpaceShip spaceShip = (SpaceShip) row[0];
 		assertEquals( ship.getModel(), spaceShip.getModel() );
 		assertNotNull( spaceShip.getDimensions() );
 		assertEquals( ship.getDimensions().getWidth(), spaceShip.getDimensions().getWidth() );
 		assertEquals( ship.getDimensions().getLength(), spaceShip.getDimensions().getLength() );
 		assertEquals( ship.getCaptain().getFirstname(), ship.getCaptain().getFirstname() );
 		assertEquals( ship.getCaptain().getLastname(), ship.getCaptain().getLastname() );
 		//FIXME vary depending on databases
 		assertTrue( row[1].toString().startsWith( "50" ) );
 		assertTrue( row[2].toString().startsWith( "500" ) );
 		s.delete( spaceShip.getCaptain() );
 		s.delete( spaceShip );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDiscriminator() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Dictionary dic = new Dictionary();
 		dic.setName( "Anglais-Francais" );
 		dic.setEditor( "Harrap's" );
 		SynonymousDictionary syn = new SynonymousDictionary();
 		syn.setName( "Synonymes de tous les temps" );
 		syn.setEditor( "Imagination edition" );
 		s.persist( dic );
 		s.persist( syn );
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		List results = s.getNamedQuery( "all.dictionaries" ).list();
 		assertEquals( 2, results.size() );
 		assertTrue(
 				results.get( 0 ) instanceof SynonymousDictionary
 						|| results.get( 1 ) instanceof SynonymousDictionary
 		);
 		s.delete( results.get( 0 ) );
 		s.delete( results.get( 1 ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	@SkipForDialect(value = { PostgreSQL81Dialect.class, PostgreSQLDialect.class },
 			comment = "postgresql jdbc driver does not implement the setQueryTimeout method")
 	public void testCache() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Plane plane = new Plane();
 		plane.setNbrOfSeats( 5 );
 		s.persist( plane );
 		tx.commit();
 		s.close();
 		sessionFactory().getStatistics().clear();
 		sessionFactory().getStatistics().setStatisticsEnabled( true );
 		s = openSession();
 		tx = s.beginTransaction();
 		Query query = s.getNamedQuery( "plane.byId" ).setParameter( "id", plane.getId() );
 		plane = (Plane) query.uniqueResult();
 		assertEquals( 1, sessionFactory().getStatistics().getQueryCachePutCount() );
 		plane = (Plane) s.getNamedQuery( "plane.byId" ).setParameter( "id", plane.getId() ).uniqueResult();
 		assertEquals( 1, sessionFactory().getStatistics().getQueryCacheHitCount() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete( s.get( Plane.class, plane.getId() ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testEntitySQLOverriding() {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Chaos chaos = new Chaos();
 		chaos.setSize( 123l );
 		chaos.setId( 1l );
 
 		String lowerName = "hello";
-		String upperName = lowerName.toUpperCase();
+		String upperName = lowerName.toUpperCase(Locale.ROOT);
 		assertFalse( lowerName.equals( upperName ) );
 
 		chaos.setName( "hello" );
 		chaos.setNickname( "NickName" );
 		s.persist( chaos );
 		s.flush();
 		s.clear();
 		s.getSessionFactory().evict( Chaos.class );
 
 		Chaos resultChaos = (Chaos) s.load( Chaos.class, chaos.getId() );
 		assertEquals( upperName, resultChaos.getName() );
 		assertEquals( "nickname", resultChaos.getNickname() );
 
 		tx.rollback();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionSQLOverriding() {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Chaos chaos = new Chaos();
 		chaos.setSize( 123l );
 		chaos.setId( 1l );
 
 		chaos.setName( "hello" );
 		s.persist( chaos );
 		CasimirParticle p = new CasimirParticle();
 		p.setId( 1l );
 		s.persist( p );
 		chaos.getParticles().add( p );
 		p = new CasimirParticle();
 		p.setId( 2l );
 		s.persist( p );
 		chaos.getParticles().add( p );
 		s.flush();
 		s.clear();
 		s.getSessionFactory().evict( Chaos.class );
 
 		Chaos resultChaos = (Chaos) s.load( Chaos.class, chaos.getId() );
 		assertEquals( 2, resultChaos.getParticles().size() );
 		resultChaos.getParticles().remove( resultChaos.getParticles().iterator().next() );
 		resultChaos.getParticles().remove( resultChaos.getParticles().iterator().next() );
 		s.flush();
 
 		s.clear();
 		resultChaos = (Chaos) s.load( Chaos.class, chaos.getId() );
 		assertEquals( 0, resultChaos.getParticles().size() );
 
 		tx.rollback();
 		s.close();
 	}
 
 	@Override
 	protected Class[] getAnnotatedClasses() {
 		return new Class[] {
 				Darkness.class,
 				Plane.class,
 				A320.class,
 				A320b.class,
 				Night.class,
 				Twilight.class,
 				Area.class,
 				SpaceShip.class,
 				Dictionary.class,
 				SynonymousDictionary.class,
 				Captain.class,
 				Chaos.class,
 				CasimirParticle.class,
 				AllTables.class,
 				Attrset.class,
 				Attrvalue.class,
 				Employee.class,
 				Employeegroup.class
 		};
 	}
 
 	@Override
 	protected String[] getAnnotatedPackages() {
 		return new String[] {
 				"org.hibernate.test.annotations.query"
 		};
 	}
 
 	@Override
 	protected String[] getXmlFiles() {
 		return new String[] {
 				"org/hibernate/test/annotations/query/orm.xml"
 		};
 	}
 
 	@Override
 	protected void configure(Configuration cfg) {
 		cfg.setProperty( "hibernate.cache.use_query_cache", "true" );
 		cfg.setImplicitNamingStrategy( ImplicitNamingStrategyLegacyJpaImpl.INSTANCE );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/interceptor/InterceptorTest.java b/hibernate-core/src/test/java/org/hibernate/test/interceptor/InterceptorTest.java
index 590691265b..7eadae1682 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/interceptor/InterceptorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/interceptor/InterceptorTest.java
@@ -1,352 +1,353 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2006-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.interceptor;
 import java.io.Serializable;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Locale;
 import java.util.Queue;
 
 import org.junit.Test;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.TransactionException;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.type.Type;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Gavin King
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class InterceptorTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String[] getMappings() {
 		return new String[] { "interceptor/User.hbm.xml", "interceptor/Image.hbm.xml" };
 	}
 
 	@Test
 	public void testCollectionIntercept() {
 		Session s = openSession( new CollectionInterceptor() );
 		Transaction t = s.beginTransaction();
 		User u = new User("Gavin", "nivag");
 		s.persist(u);
 		u.setPassword("vagni");
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		u = (User) s.get(User.class, "Gavin");
 		assertEquals( 2, u.getActions().size() );
 		s.delete(u);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testPropertyIntercept() {
 		Session s = openSession( new PropertyInterceptor() );
 		Transaction t = s.beginTransaction();
 		User u = new User("Gavin", "nivag");
 		s.persist(u);
 		u.setPassword("vagni");
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		u = (User) s.get(User.class, "Gavin");
 		assertNotNull( u.getCreated() );
 		assertNotNull( u.getLastUpdated() );
 		s.delete(u);
 		t.commit();
 		s.close();
 	}
 
 	/**
 	 * Test case from HHH-1921.  Here the interceptor resets the
 	 * current-state to the same thing as the current db state; this
 	 * causes EntityPersister.findDirty() to return no dirty properties.
 	 */
 	@Test
 	@TestForIssue( jiraKey = "HHH-1921" )
 	public void testPropertyIntercept2() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		User u = new User("Josh", "test");
 		s.persist( u );
 		t.commit();
 		s.close();
 
 		s = openSession(
 				new EmptyInterceptor() {
 					public boolean onFlushDirty(Object entity, Serializable id, Object[] currentState, Object[] previousState, String[] propertyNames, Type[] types) {
 						currentState[0] = "test";
 						return true;
 					}
 				}
 		);
 		t = s.beginTransaction();
 		u = ( User ) s.get( User.class, u.getName() );
 		u.setPassword( "nottest" );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		u = (User) s.get(User.class, "Josh");
 		assertEquals("test", u.getPassword());
 		s.delete(u);
 		t.commit();
 		s.close();
 
 	}
 
 	/**
 	 * Test that setting a transaction timeout will cause an Exception to occur
 	 * if the transaction timeout is exceeded.
 	 */
 	@Test
 	public void testTimeout() throws Exception {
 		final int TIMEOUT = 2;
 		final int WAIT = TIMEOUT + 1;
 		Session s = openSession();
 		// Get the transaction and set the timeout BEFORE calling begin()
 		Transaction t = s.getTransaction();
 		t.setTimeout( TIMEOUT );
 		t.begin();
 		// Sleep for an amount of time that exceeds the transaction timeout
 		Thread.sleep( WAIT * 1000 );
         try {
         	// Do something with the transaction and try to commit it
         	s.persist( new User( "john", "test" ) );
         	t.commit();
             fail( "Transaction should have timed out" );
         } 
         catch ( TransactionException e ) {
         	// Insure that the Exception is "transaction timeout expired"
         	String exceptionActual = e.toString();
 			String exceptionExpected = "org.hibernate.TransactionException: transaction timeout expired";
 			if ( !exceptionActual.contains( exceptionExpected ) ) {
         		String msg = String.format( "Transaction failed for the wrong reason.  Expected [%s] but received [%s]",
         				exceptionExpected, exceptionActual );
         		fail( msg );
         				
         	}
         } 
 	}
 
 	@Test
 	public void testComponentInterceptor() {
 		final int checkPerm = 500;
 		final String checkComment = "generated from interceptor";
 
 		Session s = openSession(
 				new EmptyInterceptor() {
 					public boolean onSave(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) {
 						if ( state[0] == null ) {
 							Image.Details detail = new Image.Details();
 							detail.setPerm1( checkPerm );
 							detail.setComment( checkComment );
 							state[0] = detail;
 						}
 						return true;
 					}
 				}
 		);
 		s.beginTransaction();
 		Image i = new Image();
 		i.setName( "compincomp" );
 		i = ( Image ) s.merge( i );
 		assertNotNull( i.getDetails() );
 		assertEquals( checkPerm, i.getDetails().getPerm1() );
 		assertEquals( checkComment, i.getDetails().getComment() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		i = ( Image ) s.get( Image.class, i.getId() );
 		assertNotNull( i.getDetails() );
 		assertEquals( checkPerm, i.getDetails().getPerm1() );
 		assertEquals( checkComment, i.getDetails().getComment() );
 		s.delete( i );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testStatefulIntercept() {
 		final StatefulInterceptor statefulInterceptor = new StatefulInterceptor();
 		Session s = openSession( statefulInterceptor );
 		statefulInterceptor.setSession(s);
 
 		Transaction t = s.beginTransaction();
 		User u = new User("Gavin", "nivag");
 		s.persist(u);
 		u.setPassword("vagni");
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List logs = s.createCriteria(Log.class).list();
 		assertEquals( 2, logs.size() );
 		s.delete(u);
 		s.createQuery( "delete from Log" ).executeUpdate();
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testInitiateIntercept() {
 		final String injectedString = "******";
 		final InstantiateInterceptor initiateInterceptor = new InstantiateInterceptor( injectedString );
 		Session s = openSession( initiateInterceptor );
 
 		Transaction t = s.beginTransaction();
 		User u = new User( "Gavin", "nivag" );
 		s.persist( u );
 		t.commit();
 		s.close();
 
 		assertNull( u.getInjectedString() );
 		u.setPassword( "blah" );
 
 		s = openSession( initiateInterceptor );
 		t = s.beginTransaction();
 
 		User merged = ( User ) s.merge( u );
 		assertEquals( injectedString, merged.getInjectedString() );
 		assertEquals( u.getName(), merged.getName() );
 		assertEquals( u.getPassword(), merged.getPassword() );
 
 		merged.setInjectedString( null );
 
 		User loaded = ( User ) s.load(User.class, merged.getName());
 		// the session-bound instance was not instantiated by the interceptor, load simply returns it
 		assertSame( merged, loaded );
 		assertNull( merged.getInjectedString() );
 
 		// flush the session and evict the merged instance from session to force an actual load
 		s.flush();
 		s.evict( merged );
 
 		User reloaded = ( User ) s.load( User.class, merged.getName() );
 		// Interceptor IS called for instantiating the persistent instance associated to the session when using load
 		assertEquals( injectedString, reloaded.getInjectedString() );
 		assertEquals( u.getName(), reloaded.getName() );
 		assertEquals( u.getPassword(), reloaded.getPassword() );
 
 		s.delete( reloaded );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-6594" )
 	public void testPrepareStatementIntercept() {
 		final Queue<String> expectedSQLs = new LinkedList<String>();
 		// Transaction 1
 		expectedSQLs.add( "insert" );
 		// Transaction 2
 		expectedSQLs.add( "select" );
 		expectedSQLs.add( "select" );
 		// Transaction 3
 		expectedSQLs.add( "select" );
 		expectedSQLs.add( "select" );
 		expectedSQLs.add( "update" );
 		// Transaction 4
 		expectedSQLs.add( "select" );
 		expectedSQLs.add( "delete" );
 
 		final Interceptor interceptor = new EmptyInterceptor() {
 			@Override
 			public String onPrepareStatement(String sql) {
 				assertNotNull( sql );
-				String expectedSql = expectedSQLs.poll().toLowerCase();
-				assertTrue("sql:\n " + sql.toLowerCase() +"\n doesn't start with \n"+expectedSql+"\n", sql.toLowerCase().startsWith( expectedSql ) );
+				String expectedSql = expectedSQLs.poll().toLowerCase(Locale.ROOT);
+				assertTrue("sql:\n " + sql.toLowerCase(Locale.ROOT) +"\n doesn't start with \n"+expectedSql+"\n", sql.toLowerCase(Locale.ROOT).startsWith( expectedSql ) );
 				return sql;
 			}
 		};
 
 		Session s = openSession(interceptor);
 		Transaction t = s.beginTransaction();
 		User u = new User( "Lukasz", "Antoniak" );
 		s.persist( u );
 		t.commit();
 		s.close();
 
 		s = openSession(interceptor);
 		t = s.beginTransaction();
 		s.get( User.class, "Lukasz" );
 		s.createQuery( "from User u" ).list();
 		t.commit();
 		s.close();
 
 		u.setPassword( "Kinga" );
 		s = openSession(interceptor);
 		t = s.beginTransaction();
 		s.merge( u );
 		t.commit();
 		s.close();
 
 		s = openSession(interceptor);
 		t = s.beginTransaction();
 		s.delete( u );
 		t.commit();
 		s.close();
 
 		assertTrue( expectedSQLs.isEmpty() );
 	}
 
 	@Test(expected = AssertionFailure.class)
 	public void testPrepareStatementFaultIntercept() {
 		final Interceptor interceptor = new EmptyInterceptor() {
 			@Override
 			public String onPrepareStatement(String sql) {
 				return null;
 			}
 		};
 
 		Session s = openSession(interceptor);
 		Transaction t = s.beginTransaction();
 		User u = new User( "Kinga", "Mroz" );
 		s.persist( u );
 		t.commit();
 		s.close();
 	}
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/lazycache/Document.java b/hibernate-core/src/test/java/org/hibernate/test/lazycache/Document.java
index 8910391b13..9bb20c6ac6 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/lazycache/Document.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/lazycache/Document.java
@@ -1,99 +1,100 @@
 //$Id: Document.java 7772 2005-08-05 23:03:46Z oneovthafew $
 package org.hibernate.test.lazycache;
 import java.util.Date;
+import java.util.Locale;
 
 /**
  * @author Gavin King
  */
 public class Document {
 	
 	private Long id;
 	private String name;
 	private String upperCaseName;
 	private String summary;
 	private String text;
 	private Date lastTextModification;
 	
 	public Document(String name, String summary, String text) {
 		lastTextModification = new Date();
 		this.name = name;
-		upperCaseName = name.toUpperCase();
+		upperCaseName = name.toUpperCase(Locale.ROOT);
 		this.summary = summary;
 		this.text = text;
 	}
 	
 	Document() {}
 	
 	public Date getLastTextModification() {
 		return lastTextModification;
 	}
 
 	/**
 	 * @return Returns the id.
 	 */
 	public Long getId() {
 		return id;
 	}
 	/**
 	 * @param id The id to set.
 	 */
 	public void setId(Long id) {
 		this.id = id;
 	}
 	/**
 	 * @return Returns the name.
 	 */
 	public String getName() {
 		return name;
 	}
 	/**
 	 * @param name The name to set.
 	 */
 	public void setName(String name) {
 		this.name = name;
 	}
 	/**
 	 * @return Returns the summary.
 	 */
 	public String getSummary() {
 		return summary;
 	}
 	/**
 	 * @param summary The summary to set.
 	 */
 	public void setSummary(String summary) {
 		this.summary = summary;
 	}
 	/**
 	 * @return Returns the text.
 	 */
 	public String getText() {
 		return text;
 	}
 	/**
 	 * @param text The text to set.
 	 */
 	private void setText(String text) {
 		this.text = text;
 	}
 	/**
 	 * @return Returns the upperCaseName.
 	 */
 	public String getUpperCaseName() {
 		return upperCaseName;
 	}
 	/**
 	 * @param upperCaseName The upperCaseName to set.
 	 */
 	public void setUpperCaseName(String upperCaseName) {
 		this.upperCaseName = upperCaseName;
 	}
 	
 	public void updateText(String newText) {
 		if ( !newText.equals(text) ) {
 			this.text = newText;
 			lastTextModification = new Date();
 		}
 	}
 	
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
index 842d76a320..c49c2c1c52 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
@@ -954,2001 +954,2001 @@ public class FooBarTest extends LegacyTestCase {
 	}
 
 	@Test
 	public void testReuseDeletedCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.flush();
 		s.delete(baz);
 		Baz baz2 = new Baz();
 		baz2.setStringArray( new String[] {"x-y-z"} );
 		s.save(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		baz2.setStringSet( baz.getStringSet() );
 		baz2.setStringArray( baz.getStringArray() );
 		baz2.setFooArray( baz.getFooArray() );
 
 		s = openSession();
 		s.beginTransaction();
 		s.update(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		assertTrue( baz2.getStringArray().length==3 );
 		assertTrue( baz2.getStringSet().size()==3 );
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPropertyRef() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Holder h = new Holder();
 		h.setName("foo");
 		Holder h2 = new Holder();
 		h2.setName("bar");
 		h.setOtherHolder(h2);
 		Serializable hid = s.save(h);
 		Qux q = new Qux();
 		q.setHolder(h2);
 		Serializable qid = s.save(q);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		h = (Holder) s.load(Holder.class, hid);
 		assertEquals( h.getName(), "foo");
 		assertEquals( h.getOtherHolder().getName(), "bar");
 		Object[] res = (Object[]) s.createQuery( "from Holder h join h.otherHolder oh where h.otherHolder.name = 'bar'" )
 				.list()
 				.get(0);
 		assertTrue( res[0]==h );
 		q = (Qux) s.get(Qux.class, qid);
 		assertTrue( q.getHolder() == h.getOtherHolder() );
 		s.delete(h);
 		s.delete(q);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testQueryCollectionOfValues() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		Glarch g = new Glarch();
 		Serializable gid = s.save(g);
 
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) /*&& !(dialect instanceof MckoiDialect)*/ && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) && !(getDialect() instanceof TimesTenDialect) ) {
 			s.createFilter( baz.getFooArray(), "where size(this.bytes) > 0" ).list();
 			s.createFilter( baz.getFooArray(), "where 0 in elements(this.bytes)" ).list();
 		}
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Baz baz join baz.fooSet foo join foo.foo.foo foo2 where foo2.string = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.fooArray foo join foo.foo.foo foo2 where foo2.string = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.stringDateMap date where index(date) = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.topGlarchez g where index(g) = 'A'" ).list();
 		s.createQuery( "select index(g) from Baz baz join baz.topGlarchez g" ).list();
 
 		assertTrue( s.createQuery( "from Baz baz left join baz.stringSet" ).list().size()==3 );
 		baz = (Baz) s.createQuery( "from Baz baz join baz.stringSet str where str='foo'" ).list().get(0);
 		assertTrue( !Hibernate.isInitialized( baz.getStringSet() ) );
 		baz = (Baz) s.createQuery( "from Baz baz left join fetch baz.stringSet" ).list().get(0);
 		assertTrue( Hibernate.isInitialized( baz.getStringSet() ) );
 		assertTrue( s.createQuery( "from Baz baz join baz.stringSet string where string='foo'" ).list().size()==1 );
 		assertTrue( s.createQuery( "from Baz baz inner join baz.components comp where comp.name='foo'" ).list().size()==1 );
 		//List bss = s.find("select baz, ss from Baz baz inner join baz.stringSet ss");
 		s.createQuery( "from Glarch g inner join g.fooComponents comp where comp.fee is not null" ).list();
 		s.createQuery( "from Glarch g inner join g.fooComponents comp join comp.fee fee where fee.count > 0" ).list();
 		s.createQuery( "from Glarch g inner join g.fooComponents comp where comp.fee.count is not null" ).list();
 
 		s.delete(baz);
 		s.delete( s.get(Glarch.class, gid) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testBatchLoad() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		SortedSet stringSet = new TreeSet();
 		stringSet.add("foo");
 		stringSet.add("bar");
 		Set fooSet = new HashSet();
 		for (int i=0; i<3; i++) {
 			Foo foo = new Foo();
 			s.save(foo);
 			fooSet.add(foo);
 		}
 		baz.setFooSet(fooSet);
 		baz.setStringSet(stringSet);
 		s.save(baz);
 		Baz baz2 = new Baz();
 		fooSet = new HashSet();
 		for (int i=0; i<2; i++) {
 			Foo foo = new Foo();
 			s.save(foo);
 			fooSet.add(foo);
 		}
 		baz2.setFooSet(fooSet);
 		s.save(baz2);
 		Baz baz3 = new Baz();
 		stringSet = new TreeSet();
 		stringSet.add("foo");
 		stringSet.add("baz");
 		baz3.setStringSet(stringSet);
 		s.save(baz3);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz3 = (Baz) s.load( Baz.class, baz3.getCode() );
 		assertFalse( Hibernate.isInitialized(baz.getFooSet()) || Hibernate.isInitialized(baz2.getFooSet()) || Hibernate.isInitialized(baz3.getFooSet()) );
 		assertFalse( Hibernate.isInitialized(baz.getStringSet()) || Hibernate.isInitialized(baz2.getStringSet()) || Hibernate.isInitialized(baz3.getStringSet()) );
 		assertTrue( baz.getFooSet().size()==3 );
 		assertTrue( Hibernate.isInitialized(baz.getFooSet()) && Hibernate.isInitialized(baz2.getFooSet()) && Hibernate.isInitialized(baz3.getFooSet()));
 		assertTrue( baz2.getFooSet().size()==2 );
 		assertTrue( baz3.getStringSet().contains("baz") );
 		assertTrue( Hibernate.isInitialized(baz.getStringSet()) && Hibernate.isInitialized(baz2.getStringSet()) && Hibernate.isInitialized(baz3.getStringSet()));
 		assertTrue( baz.getStringSet().size()==2 && baz2.getStringSet().size()==0 );
 		s.delete(baz);
 		s.delete(baz2);
 		s.delete(baz3);
 		Iterator iter = new JoinedIterator( new Iterator[] { baz.getFooSet().iterator(), baz2.getFooSet().iterator() } );
 		while ( iter.hasNext() ) s.delete( iter.next() );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testFetchInitializedCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Collection fooBag = new ArrayList();
 		fooBag.add( new Foo() );
 		fooBag.add( new Foo() );
 		baz.setFooBag( fooBag );
 		s.save(baz);
 		s.flush();
 		fooBag = baz.getFooBag();
 		s.createQuery( "from Baz baz left join fetch baz.fooBag" ).list();
 		assertTrue( fooBag == baz.getFooBag() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		Object bag = baz.getFooBag();
 		assertFalse( Hibernate.isInitialized( bag ) );
 		s.createQuery( "from Baz baz left join fetch baz.fooBag" ).list();
 		assertTrue( bag==baz.getFooBag() );
 		assertTrue( baz.getFooBag().size() == 2 );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testLateCollectionAdd() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		List l = new ArrayList();
 		baz.setStringList(l);
 		l.add( "foo" );
 		Serializable id = s.save(baz);
 		l.add("bar");
 		s.flush();
 		l.add( "baz" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, id);
 		assertTrue( baz.getStringList().size() == 3 && baz.getStringList().contains( "bar" ) );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testUpdate() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save( foo );
 		s.getTransaction().commit();
 		s.close();
 
 		foo = (Foo) SerializationHelper.deserialize( SerializationHelper.serialize(foo) );
 
 		s = openSession();
 		s.beginTransaction();
 		FooProxy foo2 = (FooProxy) s.load( Foo.class, foo.getKey() );
 		foo2.setString("dirty");
 		foo2.setBoolean( new Boolean( false ) );
 		foo2.setBytes( new byte[] {1, 2, 3} );
 		foo2.setDate( null );
 		foo2.setShort( new Short( "69" ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo2.setString( "dirty again" );
 		s.update(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo2.setString( "dirty again 2" );
 		s.update( foo2 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo3 = new Foo();
 		s.load( foo3, foo.getKey() );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "update", foo2.equalsFoo(foo3) );
 		s.delete( foo3 );
 		doDelete( s, "from Glarch" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testListRemove() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz b = new Baz();
 		List stringList = new ArrayList();
 		List feeList = new ArrayList();
 		b.setFees(feeList);
 		b.setStringList(stringList);
 		feeList.add( new Fee() );
 		feeList.add( new Fee() );
 		feeList.add( new Fee() );
 		feeList.add( new Fee() );
 		stringList.add("foo");
 		stringList.add("bar");
 		stringList.add("baz");
 		stringList.add("glarch");
 		s.save(b);
 		s.flush();
 		stringList.remove(1);
 		feeList.remove(1);
 		s.flush();
 		s.evict(b);
 		s.refresh(b);
 		assertTrue( b.getFees().size()==3 );
 		stringList = b.getStringList();
 		assertTrue(
 			stringList.size()==3 &&
 			"baz".equals( stringList.get(1) ) &&
 			"foo".equals( stringList.get(0) )
 		);
 		s.delete(b);
 		doDelete( s, "from Fee" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testFetchInitializedCollectionDupe() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Collection fooBag = new ArrayList();
 		fooBag.add( new Foo() );
 		fooBag.add( new Foo() );
 		baz.setFooBag(fooBag);
 		s.save( baz );
 		s.flush();
 		fooBag = baz.getFooBag();
 		s.createQuery( "from Baz baz left join fetch baz.fooBag" ).list();
 		assertTrue( Hibernate.isInitialized( fooBag ) );
 		assertTrue( fooBag == baz.getFooBag() );
 		assertTrue( baz.getFooBag().size() == 2 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		Object bag = baz.getFooBag();
 		assertFalse( Hibernate.isInitialized(bag) );
 		s.createQuery( "from Baz baz left join fetch baz.fooBag" ).list();
 		assertTrue( Hibernate.isInitialized( bag ) );
 		assertTrue( bag==baz.getFooBag() );
 		assertTrue( baz.getFooBag().size()==2 );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testSortables() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz b = new Baz();
 		b.setName("name");
 		SortedSet ss = new TreeSet();
 		ss.add( new Sortable("foo") );
 		ss.add( new Sortable("bar") );
 		ss.add( new Sortable("baz") );
 		b.setSortablez(ss);
 		s.save(b);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Criteria cr = s.createCriteria(Baz.class);
 		cr.setFetchMode( "topGlarchez", FetchMode.SELECT );
 		List result = cr
 			.addOrder( Order.asc("name") )
 			.list();
 		assertTrue( result.size()==1 );
 		b = (Baz) result.get(0);
 		assertTrue( b.getSortablez().size()==3 );
 		assertEquals( ( (Sortable) b.getSortablez().iterator().next() ).getName(), "bar" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		result = s.createQuery("from Baz baz left join fetch baz.sortablez order by baz.name asc")
 			.list();
 		b = (Baz) result.get(0);
 		assertTrue( b.getSortablez().size()==3 );
 		assertEquals( ( (Sortable) b.getSortablez().iterator().next() ).getName(), "bar" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		result = s.createQuery("from Baz baz order by baz.name asc")
 			.list();
 		b = (Baz) result.get(0);
 		assertTrue( b.getSortablez().size()==3 );
 		assertEquals( ( (Sortable) b.getSortablez().iterator().next() ).getName(), "bar" );
 		s.delete(b);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testFetchList() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		s.save(baz);
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo2 = new Foo();
 		s.save(foo2);
 		s.flush();
 		List list = new ArrayList();
 		for ( int i=0; i<5; i++ ) {
 			Fee fee = new Fee();
 			list.add(fee);
 		}
 		baz.setFees(list);
 		list = s.createQuery( "from Foo foo, Baz baz left join fetch baz.fees" ).list();
 		assertTrue( Hibernate.isInitialized( ( (Baz) ( (Object[]) list.get(0) )[1] ).getFees() ) );
 		s.delete(foo);
 		s.delete(foo2);
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testBagOneToMany() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		List list = new ArrayList();
 		baz.setBazez(list);
 		list.add( new Baz() );
 		s.save(baz);
 		s.flush();
 		list.add( new Baz() );
 		s.flush();
 		list.add( 0, new Baz() );
 		s.flush();
 		s.delete( list.remove(1) );
 		s.flush();
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testQueryLockMode() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Bar bar = new Bar();
 		s.save(bar);
 		s.flush();
 		bar.setString("changed");
 		Baz baz = new Baz();
 		baz.setFoo(bar);
 		s.save(baz);
 		Query q = s.createQuery("from Foo foo, Bar bar");
 		if ( supportsLockingNullableSideOfJoin( getDialect() ) ) {
 			q.setLockMode("bar", LockMode.UPGRADE);
 		}
 		Object[] result = (Object[]) q.uniqueResult();
 		Object b = result[0];
 		assertTrue( s.getCurrentLockMode(b)==LockMode.WRITE && s.getCurrentLockMode( result[1] )==LockMode.WRITE );
 		tx.commit();
 
 		tx = s.beginTransaction();
 		assertTrue( s.getCurrentLockMode( b ) == LockMode.NONE );
 		s.createQuery( "from Foo foo" ).list();
 		assertTrue( s.getCurrentLockMode(b)==LockMode.NONE );
 		q = s.createQuery("from Foo foo");
 		q.setLockMode( "foo", LockMode.READ );
 		q.list();
 		assertTrue( s.getCurrentLockMode( b ) == LockMode.READ );
 		s.evict( baz );
 		tx.commit();
 
 		tx = s.beginTransaction();
 		assertTrue( s.getCurrentLockMode(b)==LockMode.NONE );
 		s.delete( s.load( Baz.class, baz.getCode() ) );
 		assertTrue( s.getCurrentLockMode(b)==LockMode.NONE );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		q = s.createQuery("from Foo foo, Bar bar, Bar bar2");
 		if ( supportsLockingNullableSideOfJoin( getDialect() ) ) {
 			q.setLockMode("bar", LockMode.UPGRADE);
 		}
 		q.setLockMode("bar2", LockMode.READ);
 		result = (Object[]) q.list().get(0);
 		if ( supportsLockingNullableSideOfJoin( getDialect() ) ) {
 			assertTrue( s.getCurrentLockMode( result[0] )==LockMode.UPGRADE && s.getCurrentLockMode( result[1] )==LockMode.UPGRADE );
 		}
 		s.delete( result[0] );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testManyToManyBag() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Serializable id = s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, id);
 		baz.getFooBag().add( new Foo() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, id);
 		assertTrue( !Hibernate.isInitialized( baz.getFooBag() ) );
 		assertTrue( baz.getFooBag().size()==1 );
 		if ( !(getDialect() instanceof HSQLDialect) ) assertTrue( Hibernate.isInitialized( baz.getFooBag().iterator().next() ) );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testIdBag() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		s.save(baz);
 		List l = new ArrayList();
 		List l2 = new ArrayList();
 		baz.setIdFooBag(l);
 		baz.setByteBag(l2);
 		l.add( new Foo() );
 		l.add( new Bar() );
 		byte[] bytes = "ffo".getBytes();
 		l2.add(bytes);
 		l2.add( "foo".getBytes() );
 		s.flush();
 		l.add( new Foo() );
 		l.add( new Bar() );
 		l2.add( "bar".getBytes() );
 		s.flush();
 		s.delete( l.remove(3) );
 		bytes[1]='o';
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getIdFooBag().size()==3 );
 		assertTrue( baz.getByteBag().size()==3 );
 		bytes = "foobar".getBytes();
 		Iterator iter = baz.getIdFooBag().iterator();
 		while ( iter.hasNext() ) s.delete( iter.next() );
 		baz.setIdFooBag(null);
 		baz.getByteBag().add(bytes);
 		baz.getByteBag().add(bytes);
 		assertTrue( baz.getByteBag().size()==5 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getIdFooBag().size()==0 );
 		assertTrue( baz.getByteBag().size()==5 );
 		baz.getIdFooBag().add( new Foo() );
 		iter = baz.getByteBag().iterator();
 		iter.next();
 		iter.remove();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getIdFooBag().size()==1 );
 		assertTrue( baz.getByteBag().size()==4 );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	private boolean isOuterJoinFetchingDisabled() {
 		return new Integer(0).equals( sessionFactory().getSettings().getMaximumFetchDepth() );
 	}
 
 	@Test
 	public void testForceOuterJoin() throws Exception {
 		if ( isOuterJoinFetchingDisabled() ) {
 			return;
 		}
 
 		Session s = openSession();
 		s.beginTransaction();
 		Glarch g = new Glarch();
 		FooComponent fc = new FooComponent();
 		fc.setGlarch(g);
 		FooProxy f = new Foo();
 		FooProxy f2 = new Foo();
 		f.setComponent(fc);
 		f.setFoo(f2);
 		s.save(f2);
 		Serializable id = s.save(f);
 		Serializable gid = s.getIdentifier( f.getComponent().getGlarch() );
 		s.getTransaction().commit();
 		s.close();
 
 		sessionFactory().evict(Foo.class);
 
 		s = openSession();
 		s.beginTransaction();
 		f = (FooProxy) s.load(Foo.class, id);
 		assertFalse( Hibernate.isInitialized(f) );
 		assertTrue( Hibernate.isInitialized( f.getComponent().getGlarch() ) ); //outer-join="true"
 		assertFalse( Hibernate.isInitialized( f.getFoo() ) ); //outer-join="auto"
 		assertEquals( s.getIdentifier( f.getComponent().getGlarch() ), gid );
 		s.delete(f);
 		s.delete( f.getFoo() );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testEmptyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Serializable id = s.save( new Baz() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Baz baz = (Baz) s.load(Baz.class, id);
 		Set foos = baz.getFooSet();
 		assertTrue( foos.size() == 0 );
 		Foo foo = new Foo();
 		foos.add( foo );
 		s.save(foo);
 		s.flush();
 		s.delete(foo);
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testOneToOneGenerator() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		X x = new X();
 		Y y = new Y();
 		x.setY(y);
 		y.setTheX(x);
 		x.getXxs().add( new X.XX(x) );
 		x.getXxs().add( new X.XX(x) );
 		Serializable id = s.save(y);
 		assertEquals( id, s.save(x) );
 		s.flush();
 		assertTrue( s.contains(y) && s.contains(x) );
 		s.getTransaction().commit();
 		s.close();
 		assertEquals( new Long(x.getId()), y.getId() );
 
 		s = openSession();
 		s.beginTransaction();
 		x = new X();
 		y = new Y();
 		x.setY(y);
 		y.setTheX(x);
 		x.getXxs().add( new X.XX(x) );
 		s.save(y);
 		s.flush();
 		assertTrue( s.contains(y) && s.contains(x) );
 		s.getTransaction().commit();
 		s.close();
 		assertEquals( new Long(x.getId()), y.getId() );
 
 		s = openSession();
 		s.beginTransaction();
 		x = new X();
 		y = new Y();
 		x.setY(y);
 		y.setTheX(x);
 		x.getXxs().add( new X.XX(x) );
 		x.getXxs().add( new X.XX(x) );
 		id = s.save(x);
 		assertEquals( id, y.getId() );
 		assertEquals( id, new Long( x.getId() ) );
 		s.flush();
 		assertTrue( s.contains(y) && s.contains(x) );
 		doDelete( s, "from X x" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testLimit() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		for ( int i=0; i<10; i++ ) s.save( new Foo() );
 		Iterator iter = s.createQuery("from Foo foo")
 			.setMaxResults(4)
 			.setFirstResult(2)
 			.iterate();
 		int count=0;
 		while ( iter.hasNext() ) {
 		    iter.next();
 			count++;
 		}
 		assertEquals(4, count);
 		iter = s.createQuery("select distinct foo from Foo foo")
 			.setMaxResults(2)
 			.setFirstResult(2)
 			.list()
 			.iterator();
 		count=0;
 		while ( iter.hasNext() ) {
 			iter.next();
 			count++;
 		}
 		assertTrue(count==2);
 		iter = s.createQuery("select distinct foo from Foo foo")
 		.setMaxResults(3)
 		.list()
 		.iterator();
 		count=0;
 		while ( iter.hasNext() ) {
 			iter.next();
 			count++;
 		}
 		assertTrue(count==3);
 		assertEquals( 10, doDelete( s, "from Foo foo" ) );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCustom() throws Exception {
 		GlarchProxy g = new Glarch();
 		Multiplicity m = new Multiplicity();
 		m.count = 12;
 		m.glarch = g;
 		g.setMultiple(m);
 
 		Session s = openSession();
 		s.beginTransaction();
 		Serializable gid = s.save(g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		//g = (Glarch) s.createQuery( "from Glarch g where g.multiple.count=12" ).list().get(0);
 		s.createQuery( "from Glarch g where g.multiple.count=12" ).list().get( 0 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (Glarch) s.createQuery( "from Glarch g where g.multiple.glarch=g and g.multiple.count=12" ).list().get(0);
 		assertTrue( g.getMultiple()!=null );
 		assertEquals( g.getMultiple().count, 12 );
 		assertSame(g.getMultiple().glarch, g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getMultiple() != null );
 		assertEquals( g.getMultiple().count, 12 );
 		assertSame( g.getMultiple().glarch, g );
 		s.delete(g);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testSaveAddDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Set bars = new HashSet();
 		baz.setCascadingBars( bars );
 		s.save( baz );
 		s.flush();
 		baz.getCascadingBars().add( new Bar() );
 		s.delete(baz);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNamedParams() throws Exception {
 		Bar bar = new Bar();
 		Bar bar2 = new Bar();
 		bar.setName("Bar");
 		bar2.setName("Bar Two");
 		bar.setX( 10 );
 		bar2.setX( 1000 );Baz baz = new Baz();
 		baz.setCascadingBars( new HashSet() );
 		baz.getCascadingBars().add(bar);
 		bar.setBaz(baz);
 
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		s.save( baz );
 		s.save( bar2 );
 
 		List list = s.createQuery(
 				"from Bar bar left join bar.baz baz left join baz.cascadingBars b where bar.name like 'Bar %'"
 		).list();
 		Object row = list.iterator().next();
 		assertTrue( row instanceof Object[] && ( (Object[]) row ).length==3 );
 
 		Query q = s.createQuery("select bar, b from Bar bar left join bar.baz baz left join baz.cascadingBars b where bar.name like 'Bar%'");
 		list = q.list();
 		if ( !(getDialect() instanceof SAPDBDialect) ) assertTrue( list.size()==2 );
 
 		q = s.createQuery("select bar, b from Bar bar left join bar.baz baz left join baz.cascadingBars b where ( bar.name in (:nameList) or bar.name in (:nameList) ) and bar.string = :stringVal");
 		HashSet nameList = new HashSet();
 		nameList.add( "bar" );
 		nameList.add( "Bar" );
 		nameList.add( "Bar Two" );
 		q.setParameterList( "nameList", nameList );
 		q.setParameter( "stringVal", "a string" );
 		list = q.list();
 		if ( !(getDialect() instanceof SAPDBDialect) ) assertTrue( list.size()==2 );
 
 		try {
 			q.setParameterList("nameList", (Collection)null);
 			fail("Should throw an queryexception when passing a null!");
 		} catch (QueryException qe) {
 			//should happen
 		}
 
 		q = s.createQuery("select bar, b from Bar bar inner join bar.baz baz inner join baz.cascadingBars b where bar.name like 'Bar%'");
 		Object result = q.uniqueResult();
 		assertTrue( result != null );
 		q = s.createQuery("select bar, b from Bar bar left join bar.baz baz left join baz.cascadingBars b where bar.name like :name and b.name like :name");
 		q.setString( "name", "Bar%" );
 		list = q.list();
 		assertTrue( list.size()==1 );
 
 
 		// This test added for issue HB-297 - there is an named parameter in the Order By clause
 		q = s.createQuery("select bar from Bar bar order by ((bar.x - :valueX)*(bar.x - :valueX))");
 		q.setInteger( "valueX", bar.getX() + 1 );
 		list = q.list();
 		assertTrue( ((Bar) list.get( 0 )).getX() == bar.getX() );
 		q.setInteger( "valueX", bar2.getX() + 1 );
 		list = q.list();
 		assertTrue( ((Bar)list.get(0)).getX() == bar2.getX());
 
 		s.delete(baz);
 		s.delete(bar2);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	@RequiresDialectFeature(
 			value = DialectChecks.SupportsEmptyInListCheck.class,
 			comment = "Dialect does not support SQL empty in list [x in ()]"
 	)
 	public void testEmptyInListQuery() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		Query q = s.createQuery( "select bar from Bar as bar where bar.name in (:nameList)" );
 		q.setParameterList( "nameList", Collections.EMPTY_LIST );
 		assertEquals( 0, q.list().size() );
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testParameterCheck() throws HibernateException {
 		Session s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.x > :myX");
 			q.list();
 			fail("Should throw QueryException for missing myX");
 		}
 		catch (QueryException iae) {
 			// should happen
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.x > ?");
 			q.list();
 			fail("Should throw QueryException for missing ?");
 		}
 		catch (QueryException iae) {
 			// should happen
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.x > ? or bar.short = 1 or bar.string = 'ff ? bb'");
 			q.setInteger(0, 1);
 			q.list();
 		}
 		catch (QueryException iae) {
 			fail("Should not throw QueryException for missing ?");
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.string = ' ? ' or bar.string = '?'");
 			q.list();
 		}
 		catch (QueryException iae) {
 			fail("Should not throw QueryException for ? in quotes");
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.string = ? or bar.string = ? or bar.string = ?");
 			q.setParameter(0, "bull");
 			q.setParameter(2, "shit");
 			q.list();
 			fail("should throw exception telling me i have not set parameter 1");
 		}
 		catch (QueryException iae) {
 			// should happen!
 		}
 		finally {
 			s.close();
 		}
 	}
 
 	@Test
 	public void testDyna() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		g.setName("G");
 		Serializable id = s.save(g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getName().equals("G") );
 		assertTrue( g.getDynaBean().get("foo").equals("foo") && g.getDynaBean().get("bar").equals( new Integer(66) ) );
 		assertTrue( ! (g instanceof Glarch) );
 		g.getDynaBean().put("foo", "bar");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getDynaBean().get("foo").equals("bar") && g.getDynaBean().get("bar").equals( new Integer(66) ) );
 		g.setDynaBean(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getDynaBean()==null );
 		s.delete(g);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testFindByCriteria() throws Exception {
 		if ( getDialect() instanceof DB2Dialect ) {
 			return;
 		}
 
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo f = new Foo();
 		s.save( f );
 		s.flush();
 
 		List list = s.createCriteria(Foo.class)
 			.add( Restrictions.eq( "integer", f.getInteger() ) )
 			.add( Restrictions.eqProperty("integer", "integer") )
-			.add( Restrictions.like( "string", f.getString().toUpperCase() ).ignoreCase() )
+			.add( Restrictions.like( "string", f.getString().toUpperCase(Locale.ROOT) ).ignoreCase() )
 			.add( Restrictions.in( "boolean", new Boolean[] { f.getBoolean(), f.getBoolean() } ) )
 			.setFetchMode("foo", FetchMode.JOIN)
 			.setFetchMode("baz", FetchMode.SELECT)
 			.setFetchMode("abstracts", FetchMode.JOIN)
 			.list();
 		assertTrue( list.size() == 1 && list.get( 0 ) == f );
 
 		list = s.createCriteria(Foo.class).add(
 				Restrictions.disjunction()
 					.add( Restrictions.eq( "integer", f.getInteger() ) )
 					.add( Restrictions.like( "string", f.getString() ) )
 					.add( Restrictions.eq( "boolean", f.getBoolean() ) )
 			)
 			.add( Restrictions.isNotNull("boolean") )
 			.list();
 		assertTrue( list.size() == 1 && list.get( 0 ) == f );
 
 		Foo example = new Foo();
 		example.setString("a STRing");
 		list = s.createCriteria(Foo.class).add(
 			Example.create(example)
 				.excludeZeroes()
 				.ignoreCase()
 				.excludeProperty("bool")
 				.excludeProperty("char")
 				.excludeProperty("yesno")
 			)
 			.list();
 		assertTrue(
 				"Example API without like did not work correctly, size was " + list.size(),
 				list.size() == 1 && list.get( 0 ) == f
 		);
 		example.setString("rin");
 
 		list = s.createCriteria(Foo.class).add(
 			Example.create(example)
 				.excludeZeroes()
 				.enableLike(MatchMode.ANYWHERE)
 				.excludeProperty("bool")
 				.excludeProperty("char")
 				.excludeProperty("yesno")
 			)
 			.list();
 		assertTrue( "Example API without like did not work correctly, size was " + list.size(), list.size()==1 && list.get(0)==f );
 
 		list = s.createCriteria(Foo.class)
 			.add( Restrictions.or(
 					Restrictions.and(
 					Restrictions.eq( "integer", f.getInteger() ),
 					Restrictions.like( "string", f.getString() )
 				),
 				Restrictions.eq( "boolean", f.getBoolean() )
 			) )
 			.list();
 		assertTrue( list.size()==1 && list.get(0)==f );
 		list = s.createCriteria(Foo.class)
 			.setMaxResults(5)
 			.addOrder( Order.asc("date") )
 			.list();
 		assertTrue( list.size()==1 && list.get(0)==f );
 		list = s.createCriteria(Foo.class)
 			.setFirstResult(1)
 			.addOrder( Order.asc("date") )
 			.addOrder( Order.desc("string") )
 			.list();
 		assertTrue( list.size() == 0 );
 		list = s.createCriteria(Foo.class)
 			.setFetchMode( "component.importantDates", FetchMode.JOIN )
 			.list();
 		assertTrue( list.size() == 3 );
 
 		list = s.createCriteria(Foo.class)
 			.setFetchMode( "component.importantDates", FetchMode.JOIN )
 			.setResultTransformer(Criteria.DISTINCT_ROOT_ENTITY)
 			.list();
 		assertTrue( list.size()==1 );
 
 		f.setFoo( new Foo() );
 		s.save( f.getFoo() );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createCriteria(Foo.class)
 			.add( Restrictions.eq( "integer", f.getInteger() ) )
 			.add( Restrictions.like( "string", f.getString() ) )
 			.add( Restrictions.in( "boolean", new Boolean[] { f.getBoolean(), f.getBoolean() } ) )
 			.add( Restrictions.isNotNull("foo") )
 			.setFetchMode( "foo", FetchMode.JOIN )
 			.setFetchMode( "baz", FetchMode.SELECT )
 			.setFetchMode( "component.glarch", FetchMode.SELECT )
 			.setFetchMode( "foo.baz", FetchMode.SELECT )
 			.setFetchMode( "foo.component.glarch", FetchMode.SELECT )
 			.list();
 		f = (Foo) list.get(0);
 		assertTrue( Hibernate.isInitialized( f.getFoo() ) );
 		assertTrue( !Hibernate.isInitialized( f.getComponent().getGlarch() ) );
 
 		s.save( new Bar() );
 		list = s.createCriteria(Bar.class)
 			.list();
 		assertTrue( list.size() == 1 );
 		assertTrue( s.createCriteria(Foo.class).list().size()==3 );
 		s.delete( list.get( 0 ) );
 
 		s.delete( f.getFoo() );
 		s.delete(f);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testAfterDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		s.flush();
 		s.delete(foo);
 		s.save(foo);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionWhere() throws Exception {
 		Foo foo1 = new Foo();
 		Foo foo2 = new Foo();
 		Baz baz = new Baz();
 		Foo[] arr = new Foo[10];
 		arr[0] = foo1;
 		arr[9] = foo2;
 
 		Session s = openSession();
 		s.beginTransaction();
 		s.save( foo1 );
 		s.save(foo2);
 		baz.setFooArray( arr );
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		final Session s2 = openSession();
 		s2.beginTransaction();
 		baz = (Baz) s2.load( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooArray().length == 1 );
 		assertTrue( s2.createQuery( "from Baz baz join baz.fooArray foo" ).list().size()==1 );
 		assertTrue( s2.createQuery( "from Foo foo" ).list().size()==2 );
 		assertTrue( s2.createFilter( baz.getFooArray(), "" ).list().size() == 1 );
 		//assertTrue( s.delete("from java.lang.Object o")==9 );
 		doDelete( s2, "from Foo foo" );
 		final String bazid = baz.getCode();
 		s2.delete( baz );
 		int rows = s2.doReturningWork(
 				new AbstractReturningWork<Integer>() {
 					@Override
 					public Integer execute(Connection connection) throws SQLException {
 						Statement st = connection.createStatement();
 						return st.executeUpdate( "delete from FOO_ARRAY where id_='" + bazid + "' and i>=8" );
 					}
 				}
 		);
 		assertTrue( rows == 1 );
 		s2.getTransaction().commit();
 		s2.close();
 	}
 
 	@Test
 	public void testComponentParent() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		BarProxy bar = new Bar();
 		bar.setBarComponent( new FooComponent() );
 		Baz baz = new Baz();
 		baz.setComponents( new FooComponent[] { new FooComponent(), new FooComponent() } );
 		s.save(bar);
 		s.save(baz);
 		t.commit();
 		s.close();
 		s = openSession();
 		t = s.beginTransaction();
 		bar = (BarProxy) s.load(Bar.class, bar.getKey());
 		s.load(baz, baz.getCode());
 		assertTrue( bar.getBarComponent().getParent()==bar );
 		assertTrue( baz.getComponents()[0].getBaz()==baz && baz.getComponents()[1].getBaz()==baz );
 		s.delete(baz);
 		s.delete(bar);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionCache() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( Baz.class, baz.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void ntestAssociationId() throws Exception {
 		// IMPL NOTE : previously not being run due to the name
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Bar bar = new Bar();
 		String id = (String) s.save(bar);
 		MoreStuff more = new MoreStuff();
 		more.setName("More Stuff");
 		more.setIntId(12);
 		more.setStringId("id");
 		Stuff stuf = new Stuff();
 		stuf.setMoreStuff(more);
 		more.setStuffs( new ArrayList() );
 		more.getStuffs().add(stuf);
 		stuf.setFoo(bar);
 		stuf.setId(1234);
 		stuf.setProperty( TimeZone.getDefault() );
 		s.save(more);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List results = s.createQuery(
 				"from Stuff as s where s.foo.id = ? and s.id.id = ? and s.moreStuff.id.intId = ? and s.moreStuff.id.stringId = ?"
 		)
 				.setParameter( 0, bar, s.getTypeHelper().entity(Foo.class) )
 				.setParameter( 1, new Long(1234), StandardBasicTypes.LONG )
 				.setParameter( 2, new Integer(12), StandardBasicTypes.INTEGER )
 				.setParameter( 3, "id", StandardBasicTypes.STRING )
 				.list();
 		assertEquals( 1, results.size() );
 		results = s.createQuery( "from Stuff as s where s.foo.id = ? and s.id.id = ? and s.moreStuff.name = ?" )
 				.setParameter( 0, bar, s.getTypeHelper().entity(Foo.class) )
 				.setParameter( 1, new Long(1234), StandardBasicTypes.LONG )
 				.setParameter( 2, "More Stuff", StandardBasicTypes.STRING )
 				.list();
 		assertEquals( 1, results.size() );
 		s.createQuery( "from Stuff as s where s.foo.string is not null" ).list();
 		assertTrue(
 				s.createQuery( "from Stuff as s where s.foo > '0' order by s.foo" ).list().size()==1
 		);
 		//s.createCriteria(Stuff.class).createCriteria("id.foo").add( Expression.isNull("foo") ).list();
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		FooProxy foo = (FooProxy) s.load(Foo.class, id);
 		s.load(more, more);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Stuff stuff = new Stuff();
 		stuff.setFoo(foo);
 		stuff.setId(1234);
 		stuff.setMoreStuff(more);
 		s.load(stuff, stuff);
 		assertTrue( stuff.getProperty().equals( TimeZone.getDefault() ) );
 		assertTrue( stuff.getMoreStuff().getName().equals("More Stuff") );
 		doDelete( s, "from MoreStuff" );
 		doDelete( s, "from Foo foo" );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCascadeSave() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		List list = new ArrayList();
 		list.add( new Fee() );
 		list.add( new Fee() );
 		baz.setFees( list );
 		s.save(baz);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		assertTrue( baz.getFees().size() == 2 );
 		s.delete(baz);
 		assertTrue( !s.createQuery( "from Fee fee" ).iterate().hasNext() );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionsInSelect() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Foo[] foos = new Foo[] { null, new Foo() };
 		s.save( foos[1] );
 		Baz baz = new Baz();
 		baz.setDefaults();
 		baz.setFooArray(foos);
 		s.save(baz);
 		Baz baz2 = new Baz();
 		baz2.setDefaults();
 		s.save(baz2);
 
 		Bar bar = new Bar();
 		bar.setBaz(baz);
 		s.save(bar);
 
 		List list = s.createQuery( "select new Result(foo.string, foo.long, foo.integer) from Foo foo" ).list();
 		assertTrue( list.size()==2 && ( list.get(0) instanceof Result ) && ( list.get(1) instanceof Result ) );
 		/*list = s.find("select new Result( baz.name, foo.long, count(elements(baz.fooArray)) ) from Baz baz join baz.fooArray foo group by baz.name, foo.long");
 		assertTrue( list.size()==1 && ( list.get(0) instanceof Result ) );
 		Result r = ((Result) list.get(0) );
 		assertEquals( r.getName(), baz.getName() );
 		assertEquals( r.getCount(), 1 );
 		assertEquals( r.getAmount(), foos[1].getLong().longValue() );*/
 		list = s.createQuery(
 				"select new Result( baz.name, max(foo.long), count(foo) ) from Baz baz join baz.fooArray foo group by baz.name"
 		).list();
 		assertTrue( list.size()==1 && ( list.get(0) instanceof Result ) );
 		Result r = ((Result) list.get(0) );
 		assertEquals( r.getName(), baz.getName() );
 		assertEquals( r.getCount(), 1 );
 		assertTrue( r.getAmount() > 696969696969696000l );
 
 
 		//s.find("select max( elements(bar.baz.fooArray) ) from Bar as bar");
 		//The following test is disabled for databases with no subselects...also for Interbase (not sure why).
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) /*&& !(dialect instanceof MckoiDialect)*/ && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			s.createQuery( "select count(*) from Baz as baz where 1 in indices(baz.fooArray)" ).list();
 			s.createQuery( "select count(*) from Bar as bar where 'abc' in elements(bar.baz.fooArray)" ).list();
 			s.createQuery( "select count(*) from Bar as bar where 1 in indices(bar.baz.fooArray)" ).list();
 			if ( !(getDialect() instanceof DB2Dialect) &&  !(getDialect() instanceof Oracle8iDialect ) && !( getDialect() instanceof SybaseDialect ) && !( getDialect() instanceof Sybase11Dialect ) && !( getDialect() instanceof SybaseASE15Dialect ) && !( getDialect() instanceof PostgreSQLDialect ) && !(getDialect() instanceof PostgreSQL81Dialect) && !(getDialect() instanceof AbstractHANADialect)) {
 				// SybaseAnywhereDialect supports implicit conversions from strings to ints
 				s.createQuery(
 						"select count(*) from Bar as bar, bar.component.glarch.proxyArray as g where g.id in indices(bar.baz.fooArray)"
 				).list();
 				s.createQuery(
 						"select max( elements(bar.baz.fooArray) ) from Bar as bar, bar.component.glarch.proxyArray as g where g.id in indices(bar.baz.fooArray)"
 				).list();
 			}
 			s.createQuery(
 					"select count(*) from Bar as bar where '1' in (from bar.component.glarch.proxyArray g where g.name='foo')"
 			).list();
 			s.createQuery(
 					"select count(*) from Bar as bar where '1' in (from bar.component.glarch.proxyArray g where g.name='foo')"
 			).list();
 			s.createQuery(
 					"select count(*) from Bar as bar left outer join bar.component.glarch.proxyArray as pg where '1' in (from bar.component.glarch.proxyArray)"
 			).list();
 		}
 
 		list = s.createQuery(
 				"from Baz baz left join baz.fooToGlarch join fetch baz.fooArray foo left join fetch foo.foo"
 		).list();
 		assertTrue( list.size()==1 && ( (Object[]) list.get(0) ).length==2 );
 
 		s.createQuery(
 				"select baz.name from Bar bar inner join bar.baz baz inner join baz.fooSet foo where baz.name = bar.string"
 		).list();
 		s.createQuery(
 				"SELECT baz.name FROM Bar AS bar INNER JOIN bar.baz AS baz INNER JOIN baz.fooSet AS foo WHERE baz.name = bar.string"
 		).list();
 
 		if ( !( getDialect() instanceof HSQLDialect ) ) s.createQuery(
 				"select baz.name from Bar bar join bar.baz baz left outer join baz.fooSet foo where baz.name = bar.string"
 		).list();
 
 		s.createQuery( "select baz.name from Bar bar join bar.baz baz join baz.fooSet foo where baz.name = bar.string" )
 				.list();
 		s.createQuery(
 				"SELECT baz.name FROM Bar AS bar JOIN bar.baz AS baz JOIN baz.fooSet AS foo WHERE baz.name = bar.string"
 		).list();
 
 		if ( !( getDialect() instanceof HSQLDialect ) ) {
 			s.createQuery(
 					"select baz.name from Bar bar left join bar.baz baz left join baz.fooSet foo where baz.name = bar.string"
 			).list();
 			s.createQuery( "select foo.string from Bar bar left join bar.baz.fooSet foo where bar.string = foo.string" )
 					.list();
 		}
 
 		s.createQuery(
 				"select baz.name from Bar bar left join bar.baz baz left join baz.fooArray foo where baz.name = bar.string"
 		).list();
 		s.createQuery( "select foo.string from Bar bar left join bar.baz.fooArray foo where bar.string = foo.string" )
 				.list();
 
 		s.createQuery(
 				"select bar.string, foo.string from Bar bar inner join bar.baz as baz inner join baz.fooSet as foo where baz.name = 'name'"
 		).list();
 		s.createQuery( "select foo from Bar bar inner join bar.baz as baz inner join baz.fooSet as foo" ).list();
 		s.createQuery( "select foo from Bar bar inner join bar.baz.fooSet as foo" ).list();
 
 		s.createQuery(
 				"select bar.string, foo.string from Bar bar join bar.baz as baz join baz.fooSet as foo where baz.name = 'name'"
 		).list();
 		s.createQuery( "select foo from Bar bar join bar.baz as baz join baz.fooSet as foo" ).list();
 		s.createQuery( "select foo from Bar bar join bar.baz.fooSet as foo" ).list();
 
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooArray foo" ).list().size()==1 );
 
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooSet foo" ).list().size()==0 );
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooArray foo" ).list().size()==1 );
 
 		s.delete(bar);
 
 		if ( getDialect() instanceof DB2Dialect || getDialect() instanceof PostgreSQLDialect || getDialect() instanceof PostgreSQL81Dialect ) {
 			s.createQuery( "select one from One one join one.manies many group by one order by count(many)" ).iterate();
 			s.createQuery( "select one from One one join one.manies many group by one having count(many) < 5" )
 					.iterate();
 		}
 
 		s.createQuery( "from One one join one.manies many where one.id = 1 and many.id = 1" ).list();
 		s.createQuery( "select one.id, elements(one.manies) from One one" ).iterate();
 		s.createQuery( "select max( elements(one.manies) ) from One one" ).iterate();
 		s.createQuery( "select one, elements(one.manies) from One one" ).list();
 		Iterator iter = s.createQuery( "select elements(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), StandardBasicTypes.STRING )
 				.iterate();
 		assertTrue( iter.next()==foos[1] && !iter.hasNext() );
 		list = s.createQuery( "select elements(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), StandardBasicTypes.STRING )
 				.list();
 		assertEquals( 1, list.size() );
 		iter = s.createQuery( "select indices(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), StandardBasicTypes.STRING )
 				.iterate();
 		assertTrue( iter.next().equals( new Integer(1) ) && !iter.hasNext() );
 
 		iter = s.createQuery( "select size(baz.stringSet) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), StandardBasicTypes.STRING )
 				.iterate();
 		assertEquals( new Integer(3), iter.next() );
 
 		s.createQuery( "from Foo foo where foo.component.glarch.id is not null" ).list();
 
 		iter = s.createQuery(
 				"select baz, size(baz.stringSet), count( distinct elements(baz.stringSet) ), max( elements(baz.stringSet) ) from Baz baz group by baz"
 		).iterate();
 		while ( iter.hasNext() ) {
 			Object[] arr = (Object[]) iter.next();
             log.info(arr[0] + " " + arr[1] + " " + arr[2] + " " + arr[3]);
 		}
 
 		s.delete(baz);
 		s.delete(baz2);
 		s.delete( foos[1] );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testNewFlushing() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.flush();
 		baz.getStringArray()[0] = "a new value";
 		Iterator iter = s.createQuery( "from Baz baz" ).iterate();//no flush
 		assertTrue( iter.next()==baz );
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		boolean found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("a new value") ) found = true;
 		}
 		assertTrue( found );
 		baz.setStringArray( null );
 		s.createQuery( "from Baz baz" ).iterate(); //no flush
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		assertTrue( !iter.hasNext() );
 		baz.getStringList().add( "1E1" );
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		assertTrue( !iter.hasNext() );
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("1E1") ) found = true;
 		}
 		assertTrue( found );
 		baz.getStringList().remove( "1E1" );
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate(); //no flush
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("1E1") ) found = true;
 		}
 		assertTrue(!found);
 
 		List newList = new ArrayList();
 		newList.add("value");
 		baz.setStringList( newList );
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		baz.setStringList( null );
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		assertTrue( !iter.hasNext() );
 
 		baz.setStringList(newList);
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		assertTrue( iter.hasNext() );
 
 		s.delete( baz );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testPersistCollections() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		assertEquals( 0l, s.createQuery( "select count(*) from Bar" ).iterate().next() );
 		assertEquals( 0l, s.createQuery( "select count(*) from Bar b" ).iterate().next() );
 		assertFalse( s.createQuery( "from Glarch g" ).iterate().hasNext() );
 
 		Baz baz = new Baz();
 		s.save(baz);
 		baz.setDefaults();
 		baz.setStringArray( new String[] { "stuff" } );
 		Set bars = new HashSet();
 		bars.add( new Bar() );
 		baz.setCascadingBars(bars);
 		HashMap sgm = new HashMap();
 		sgm.put( "a", new Glarch() );
 		sgm.put( "b", new Glarch() );
 		baz.setStringGlarchMap(sgm);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1L, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) ( (Object[]) s.createQuery( "select baz, baz from Baz baz" ).list().get(0) )[1];
 		assertTrue( baz.getCascadingBars().size()==1 );
 		//System.out.println( s.print(baz) );
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo2 = new Foo() ;
 		s.save(foo2);
 		baz.setFooArray( new Foo[] { foo, foo, null, foo2 } );
 		baz.getFooSet().add(foo);
 		baz.getCustoms().add( new String[] { "new", "custom" } );
 		baz.setStringArray(null);
 		baz.getStringList().set(0, "new value");
 		baz.setStringSet( new TreeSet() );
 		Time time = new java.sql.Time(12345);
 		baz.getTimeArray()[2] = time;
 		//System.out.println(time);
 
 		assertTrue( baz.getStringGlarchMap().size()==1 );
 
 		//The following test is disabled databases with no subselects
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			List list = s.createQuery(
 					"select foo from Foo foo, Baz baz where foo in elements(baz.fooArray) and 3 = some elements(baz.intArray) and 4 > all indices(baz.intArray)"
 			).list();
 			assertTrue( "collection.elements find", list.size()==2 );
 		}
 		if (!(getDialect() instanceof SAPDBDialect) ) { // SAPDB doesn't like distinct with binary type
 			List list = s.createQuery( "select distinct foo from Baz baz join baz.fooArray foo" ).list();
 			assertTrue( "collection.elements find", list.size()==2 );
 		}
 
 		List list = s.createQuery( "select foo from Baz baz join baz.fooSet foo" ).list();
 		assertTrue( "association.elements find", list.size()==1 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( "collection of custom types - added element", baz.getCustoms().size()==4 && baz.getCustoms().get(0)!=null );
 		assertTrue ( "component of component in collection", baz.getComponents()[1].getSubcomponent()!=null );
 		assertTrue( baz.getComponents()[1].getBaz()==baz );
 		assertTrue( "set of objects", ( (FooProxy) baz.getFooSet().iterator().next() ).getKey().equals( foo.getKey() ));
 		assertTrue( "collection removed", baz.getStringArray().length==0 );
 		assertTrue( "changed element", baz.getStringList().get(0).equals("new value"));
 		assertTrue( "replaced set", baz.getStringSet().size()==0 );
 		assertTrue( "array element change", baz.getTimeArray()[2]!=null );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		//System.out.println( s.print(baz) );
 		baz.getStringSet().add("two");
 		baz.getStringSet().add("one");
 		baz.getBag().add("three");
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getStringSet().size()==2 );
 		assertTrue( baz.getStringSet().first().equals("one") );
 		assertTrue( baz.getStringSet().last().equals("two") );
 		assertTrue( baz.getBag().size()==5 );
 		baz.getStringSet().remove("two");
 		baz.getBag().remove("duplicate");
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getCascadingBars().size()==1 );
 		Bar bar = new Bar();
 		Bar bar2 = new Bar();
 		s.save(bar); s.save(bar2);
 		baz.setTopFoos( new HashSet() );
 		baz.getTopFoos().add(bar);
 		baz.getTopFoos().add(bar2);
 		assertTrue( baz.getCascadingBars().size()==1 );
 		baz.setTopGlarchez( new TreeMap() );
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		baz.getTopGlarchez().put( 'G', g );
 		HashMap map = new HashMap();
 		map.put(bar, g);
 		map.put(bar2, g);
 		baz.setFooToGlarch(map);
 		map = new HashMap();
 		map.put( new FooComponent("name", 123, null, null), bar );
 		map.put( new FooComponent("nameName", 12, null, null), bar );
 		baz.setFooComponentToFoo(map);
 		map = new HashMap();
 		map.put(bar, g);
 		baz.setGlarchToFoo(map);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getCascadingBars().size()==1 );
 
 		Session s2 = openSession();
 		Transaction txn2 = s2.beginTransaction();
 		assertEquals( 3, ((Long) s2.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		Baz baz2 = (Baz) s2.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		Object o = baz2.getFooComponentToFoo().get( new FooComponent("name", 123, null, null) );
 		assertTrue(
 			o==baz2.getFooComponentToFoo().get( new FooComponent("nameName", 12, null, null) ) && o!=null
 		);
 		txn2.commit();
 		s2.close();
 
 		assertTrue( Hibernate.isInitialized( baz.getFooToGlarch() ) );
 		assertTrue( baz.getTopFoos().size()==2 );
 		assertTrue( baz.getTopGlarchez().size()==1 );
 		assertTrue( baz.getTopFoos().iterator().next()!=null );
 		assertTrue( baz.getStringSet().size()==1 );
 		assertTrue( baz.getBag().size()==4 );
 		assertTrue( baz.getFooToGlarch().size()==2 );
 		assertTrue( baz.getFooComponentToFoo().size()==2 );
 		assertTrue( baz.getGlarchToFoo().size()==1 );
 		Iterator iter = baz.getFooToGlarch().keySet().iterator();
 		for (int i=0; i<2; i++ ) assertTrue( iter.next() instanceof BarProxy );
 		FooComponent fooComp = (FooComponent) baz.getFooComponentToFoo().keySet().iterator().next();
 		assertTrue(
 			( (fooComp.getCount()==123 && fooComp.getName().equals("name"))
 			|| (fooComp.getCount()==12 && fooComp.getName().equals("nameName")) )
 			&& ( baz.getFooComponentToFoo().get(fooComp) instanceof BarProxy )
 		);
 		Glarch g2 = new Glarch();
 		s.save(g2);
 		g = (GlarchProxy) baz.getTopGlarchez().get( 'G' );
 		baz.getTopGlarchez().put( 'H', g );
 		baz.getTopGlarchez().put( 'G', g2 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getTopGlarchez().size()==2 );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 3, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getTopGlarchez().size()==2 );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		txn.commit();
 
 		final Session s3 = (Session) SerializationHelper.deserialize( SerializationHelper.serialize(s) );
 		s.close();
 
 		txn2 = s3.beginTransaction();
 		baz = (Baz) s3.load(Baz.class, baz.getCode());
 		assertEquals( 3, ((Long) s3.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		s3.delete(baz);
 		s3.delete( baz.getTopGlarchez().get( 'G' ) );
 		s3.delete( baz.getTopGlarchez().get( 'H' ) );
 		int rows = s3.doReturningWork(
 				new AbstractReturningWork<Integer>() {
 					@Override
 					public Integer execute(Connection connection) throws SQLException {
 						final String sql = "update " + getDialect().openQuote() + "glarchez" + getDialect().closeQuote() + " set baz_map_id=null where baz_map_index='a'";
 						Statement st = connection.createStatement();
 						return st.executeUpdate( sql );
 					}
 				}
 		);
 		assertTrue(rows==1);
 		assertEquals( 2, doDelete( s3, "from Bar bar" ) );
 		FooProxy[] arr = baz.getFooArray();
 		assertTrue( "new array of objects", arr.length==4 && arr[1].getKey().equals( foo.getKey() ) );
 		for ( int i=1; i<arr.length; i++ ) {
 			if ( arr[i]!=null) s3.delete(arr[i]);
 		}
 
 		s3.load( Qux.class, new Long(666) ); //nonexistent
 
 		assertEquals( 1, doDelete( s3, "from Glarch g" ) );
 		txn2.commit();
 
 		s3.disconnect();
 
 		Session s4 = (Session) SerializationHelper.deserialize( SerializationHelper.serialize( s3 ) );
 		s3.close();
 		//s3.reconnect();
 		assertTrue( s4.load( Qux.class, new Long(666) )!=null ); //nonexistent
 		//s3.disconnect();
 		s4.close();
 	}
 
 	@Test
 	public void testSaveFlush() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee = new Fee();
 		s.save( fee );
 		fee.setFi( "blah" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee = (Fee) s.load( Fee.class, fee.getKey() );
 		assertTrue( "blah".equals( fee.getFi() ) );
 		s.delete(fee);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCreateUpdate() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		foo.setString("dirty");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		s.load( foo2, foo.getKey() );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create-update", foo.equalsFoo(foo2) );
 		//System.out.println( s.print(foo2) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = new Foo();
 		s.save(foo);
 		foo.setString("dirty");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load(foo2, foo.getKey());
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create-update", foo.equalsFoo(foo2) );
 		//System.out.println( s.print(foo2) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testUpdateCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Holder baz = new Holder();
 		baz.setName("123");
 		Foo f1 = new Foo();
 		Foo f2 = new Foo();
 		Foo f3 = new Foo();
 		One o = new One();
 		baz.setOnes( new ArrayList() );
 		baz.getOnes().add(o);
 		Foo[] foos = new Foo[] { f1, null, f2 };
 		baz.setFooArray(foos);
 		baz.setFoos( new HashSet() );
 		baz.getFoos().add(f1);
 		s.save(f1);
 		s.save(f2);
 		s.save(f3);
 		s.save(o);
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		baz.getOnes().set(0, null);
 		baz.getOnes().add(o);
 		baz.getFoos().add(f2);
 		foos[0] = f3;
 		foos[1] = f1;
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Holder h = (Holder) s.load(Holder.class, baz.getId());
 		assertTrue( h.getOnes().get(0)==null );
 		assertTrue( h.getOnes().get(1)!=null );
 		assertTrue( h.getFooArray()[0]!=null);
 		assertTrue( h.getFooArray()[1]!=null);
 		assertTrue( h.getFooArray()[2]!=null);
 		assertTrue( h.getFoos().size()==2 );
 		s.getTransaction().commit();
 		s.close();
 
 		baz.getFoos().remove(f1);
 		baz.getFoos().remove(f2);
 		baz.getFooArray()[0]=null;
 		baz.getFooArray()[0]=null;
 		baz.getFooArray()[0]=null;
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(baz);
 		doDelete( s, "from Foo" );
 		baz.getOnes().remove(o);
 		doDelete( s, "from One" );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCreate() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		s.load( foo2, foo.getKey() );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create", foo.equalsFoo( foo2 ) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void loadFoo() {
 		Session s = openSession();
 		s.beginTransaction();
 		FooProxy foo = new Foo();
 		s.save( foo );
 		s.getTransaction().commit();
 		s.close();
 
 		final String id = ( (Foo) foo ).key;
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (FooProxy) s.load( Foo.class, id );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( foo );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCallback() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux("0");
 		s.save(q);
 		q.setChild( new Qux( "1" ) );
 		s.save( q.getChild() );
 		Qux q2 = new Qux("2");
 		q2.setChild( q.getChild() );
 		Qux q3 = new Qux("3");
 		q.getChild().setChild(q3);
 		s.save( q3 );
 		Qux q4 = new Qux("4");
 		q4.setChild( q3 );
 		s.save(q4);
 		s.save( q2 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List l = s.createQuery( "from Qux" ).list();
 		assertTrue( "", l.size() == 5 );
 		s.delete( l.get( 0 ) );
 		s.delete( l.get( 1 ) );
 		s.delete( l.get( 2 ) );
 		s.delete( l.get(3) );
 		s.delete( l.get(4) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPolymorphism() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		s.save(bar);
 		bar.setBarString("bar bar");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		FooProxy foo = (FooProxy) s.load( Foo.class, bar.getKey() );
 		assertTrue( "polymorphic", foo instanceof BarProxy );
 		assertTrue( "subclass property", ( (BarProxy) foo ).getBarString().equals( bar.getBarString() ) );
 		//System.out.println( s.print(foo) );
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRemoveContains() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save( baz );
 		s.flush();
 		assertTrue( s.contains(baz) );
 		s.evict( baz );
 		assertFalse( s.contains(baz) );
 		Baz baz2 = (Baz) s.load( Baz.class, baz.getCode() );
 		assertFalse( baz == baz2 );
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testCollectionOfSelf() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		s.save(bar);
 		bar.setAbstracts( new HashSet() );
 		bar.getAbstracts().add( bar );
 		Bar bar2 = new Bar();
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/StringComparator.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/StringComparator.java
index 960de0cb72..405a8c84e3 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/StringComparator.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/StringComparator.java
@@ -1,11 +1,12 @@
 package org.hibernate.test.legacy;
 import java.io.Serializable;
 import java.util.Comparator;
+import java.util.Locale;
 
 public class StringComparator implements Comparator, Serializable {
 
 	public int compare(Object o1, Object o2) {
-		return ( (String) o1 ).toLowerCase().compareTo( ( (String) o2 ).toLowerCase() );
+		return ( (String) o1 ).toLowerCase(Locale.ROOT).compareTo( ( (String) o2 ).toLowerCase(Locale.ROOT) );
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/manytomany/batchload/BatchedManyToManyTest.java b/hibernate-core/src/test/java/org/hibernate/test/manytomany/batchload/BatchedManyToManyTest.java
index 5ee397b82b..811a8f9726 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/manytomany/batchload/BatchedManyToManyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/manytomany/batchload/BatchedManyToManyTest.java
@@ -1,162 +1,163 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.manytomany.batchload;
 
 import java.util.List;
+import java.util.Locale;
 
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.Hibernate;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.batch.internal.BatchBuilderImpl;
 import org.hibernate.engine.jdbc.batch.internal.NonBatchingBatch;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.stat.CollectionStatistics;
 
 import org.junit.Test;
 import junit.framework.Assert;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Tests loading of many-to-many collection which should trigger
  * a batch load.
  *
  * @author Steve Ebersole
  */
 public class BatchedManyToManyTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String[] getMappings() {
 		return new String[] { "manytomany/batchload/UserGroupBatchLoad.hbm.xml" };
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		cfg.setProperty( Environment.USE_SECOND_LEVEL_CACHE, "false" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.BATCH_STRATEGY, TestingBatchBuilder.class.getName() );
 	}
 
 	public static class TestingBatchBuilder extends BatchBuilderImpl {
 		@Override
 		public Batch buildBatch(BatchKey key, JdbcCoordinator jdbcCoordinator) {
 			return new TestingBatch( key, jdbcCoordinator );
 		}
 	}
 
 	public static class TestingBatch extends NonBatchingBatch {
 		public TestingBatch(BatchKey key, JdbcCoordinator jdbcCoordinator) {
 			super( key, jdbcCoordinator );
 		}
 	}
 
 	@Test
 	public void testLoadingNonInverseSide() {
 		prepareTestData();
 
 		sessionFactory().getStatistics().clear();
 		CollectionStatistics userGroupStats = sessionFactory().getStatistics()
 				.getCollectionStatistics( User.class.getName() + ".groups" );
 		CollectionStatistics groupUserStats = sessionFactory().getStatistics()
 				.getCollectionStatistics( Group.class.getName() + ".users" );
 
 		Interceptor testingInterceptor = new EmptyInterceptor() {
 			@Override
             public String onPrepareStatement(String sql) {
 				// ugh, this is the best way I could come up with to assert this.
 				// unfortunately, this is highly dependent on the dialect and its
 				// outer join fragment.  But at least this wil fail on the majority
 				// of dialects...
 				Assert.assertFalse(
 						"batch load of many-to-many should use inner join",
-						sql.toLowerCase().contains( "left outer join" )
+						sql.toLowerCase(Locale.ROOT).contains( "left outer join" )
 				);
 				return super.onPrepareStatement( sql );
 			}
 		};
 
 		Session s = openSession( testingInterceptor );
 		s.beginTransaction();
 		List users = s.createQuery( "from User u" ).list();
 		User user = ( User ) users.get( 0 );
 		assertTrue( Hibernate.isInitialized( user ) );
 		assertTrue( Hibernate.isInitialized( user.getGroups() ) );
 		user = ( User ) users.get( 1 );
 		assertTrue( Hibernate.isInitialized( user ) );
 		assertTrue( Hibernate.isInitialized( user.getGroups() ) );
 		assertEquals( 1, userGroupStats.getFetchCount() ); // should have been just one fetch (the batch fetch)
 		assertEquals( 1, groupUserStats.getFetchCount() ); // should have been just one fetch (the batch fetch)
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	protected void prepareTestData() {
 		// set up the test data
 		User me = new User( "steve" );
 		User you = new User( "not steve" );
 		Group developers = new Group( "developers" );
 		Group translators = new Group( "translators" );
 		Group contributors = new Group( "contributors" );
 		me.getGroups().add( developers );
 		developers.getUsers().add( me );
 		you.getGroups().add( translators );
 		translators.getUsers().add( you );
 		you.getGroups().add( contributors );
 		contributors.getUsers().add( you );
 		Session s = openSession();
 		s.beginTransaction();
 		s.save( me );
 		s.save( you );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	protected void cleanupTestData() {
 		// clean up the test data
 		Session s = openSession();
 		s.beginTransaction();
 		// User is the non-inverse side...
 		List<User> users = s.createQuery( "from User" ).list();
 		for ( User user : users ) {
 			s.delete( user );
 		}
 		s.flush();
 		s.createQuery( "delete Group" ).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Override
 	protected boolean isCleanupTestDataRequired() {
 		return true;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/sql/hand/query/NativeSQLQueriesTest.java b/hibernate-core/src/test/java/org/hibernate/test/sql/hand/query/NativeSQLQueriesTest.java
index 62a7d4cd58..7baa44651a 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/sql/hand/query/NativeSQLQueriesTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/sql/hand/query/NativeSQLQueriesTest.java
@@ -1,915 +1,916 @@
 package org.hibernate.test.sql.hand.query;
 
 import java.io.Serializable;
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.SQLQuery;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.AbstractHANADialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.dialect.MySQL5Dialect;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.spi.NamedSQLQueryDefinitionBuilder;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.transform.BasicTransformerAdapter;
 import org.hibernate.transform.DistinctRootEntityResultTransformer;
 import org.hibernate.transform.Transformers;
 import org.hibernate.type.FloatType;
 import org.hibernate.type.LongType;
 import org.hibernate.type.StringType;
 import org.hibernate.type.TimestampType;
 
 import org.hibernate.testing.FailureExpected;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.sql.hand.Dimension;
 import org.hibernate.test.sql.hand.Employment;
 import org.hibernate.test.sql.hand.Group;
 import org.hibernate.test.sql.hand.ImageHolder;
 import org.hibernate.test.sql.hand.Order;
 import org.hibernate.test.sql.hand.Organization;
 import org.hibernate.test.sql.hand.Person;
 import org.hibernate.test.sql.hand.Product;
 import org.hibernate.test.sql.hand.SpaceShip;
 import org.hibernate.test.sql.hand.Speech;
 import org.hibernate.test.sql.hand.TextHolder;
 import org.junit.Test;
 
 import static org.hibernate.testing.junit4.ExtraAssertions.assertClassAssignability;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * Tests of various features of native SQL queries.
  *
  * @author Steve Ebersole
  */
 public class NativeSQLQueriesTest extends BaseCoreFunctionalTestCase {
 	public String[] getMappings() {
 		return new String[] { "sql/hand/query/NativeSQLQueries.hbm.xml" };
 	}
 
 	@Override
     public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 	}
 
 	protected String getOrganizationFetchJoinEmploymentSQL() {
 		return "SELECT org.ORGID as {org.id}, " +
 		       "        org.NAME as {org.name}, " +
 		       "        emp.EMPLOYER as {emp.key}, " +
 		       "        emp.EMPID as {emp.element}, " +
 		       "        {emp.element.*}  " +
 		       "FROM ORGANIZATION org " +
 		       "    LEFT OUTER JOIN EMPLOYMENT emp ON org.ORGID = emp.EMPLOYER";
 	}
 
 	protected String getOrganizationJoinEmploymentSQL() {
 		return "SELECT org.ORGID as {org.id}, " +
 		       "        org.NAME as {org.name}, " +
 		       "        {emp.*}  " +
 		       "FROM ORGANIZATION org " +
 		       "    LEFT OUTER JOIN EMPLOYMENT emp ON org.ORGID = emp.EMPLOYER";
 	}
 
 	protected String getEmploymentSQL() {
 		return "SELECT * FROM EMPLOYMENT";
 	}
 
 	protected String getEmploymentSQLMixedScalarEntity() {
 		return "SELECT e.*, e.employer as employerid  FROM EMPLOYMENT e" ;
 	}
 
 	protected String getOrgEmpRegionSQL() {
 		return "select {org.*}, {emp.*}, emp.REGIONCODE " +
 		       "from ORGANIZATION org " +
 		       "     left outer join EMPLOYMENT emp on org.ORGID = emp.EMPLOYER";
 	}
 
 	protected String getOrgEmpPersonSQL() {
 		return "select {org.*}, {emp.*}, {pers.*} " +
 		       "from ORGANIZATION org " +
 		       "    join EMPLOYMENT emp on org.ORGID = emp.EMPLOYER " +
 		       "    join PERSON pers on pers.PERID = emp.EMPLOYEE ";
 	}
 
 	protected String getDescriptionsSQL() {
 		return "select DESCRIPTION from TEXT_HOLDER";
 	}
 
 	protected String getPhotosSQL() {
 		return "select PHOTO from IMAGE_HOLDER";
 	}
 
 	@Test
     @SkipForDialect( H2Dialect.class )
 	public void testFailOnNoAddEntityOrScalar() {
 		// Note: this passes, but for the wrong reason.
 		//      there is actually an exception thrown, but it is the database
 		//      throwing a sql exception because the SQL gets passed
 		//      "un-processed"...
 		//
 		// Oddly, H2 accepts this query.
 		Session s = openSession();
 		s.beginTransaction();
 		try {
 			String sql = "select {org.*} " +
 			             "from organization org";
 			s.createSQLQuery( sql ).list();
 			fail( "Should throw an exception since no addEntity nor addScalar has been performed." );
 		}
 		catch( HibernateException he) {
 			// expected behavior
 		}
 		finally {
 			s.getTransaction().rollback();
 			s.close();
 		}
 	}
 	
 	@Test
 	public void testRegisteredNamedSQLQueryWithScalar()
 	{
 		final NamedSQLQueryDefinitionBuilder builder = new NamedSQLQueryDefinitionBuilder();
 		builder.setName("namedQuery");
 		builder.setQuery("select count(*) AS c from organization");
 		builder.setQueryReturns(new NativeSQLQueryReturn[1]);
 		
 		sessionFactory().registerNamedSQLQueryDefinition("namedQuery", builder.createNamedQueryDefinition());
 
 		final Session s = openSession();
 		s.beginTransaction();
 		final SQLQuery query = (SQLQuery) s.getNamedQuery("namedQuery");
 		query.addScalar("c");
 		final Number result = (Number) query.uniqueResult();
  		s.getTransaction().commit();
 		s.close();
 		
 		assertNotNull(result);
 		assertTrue(0 == result.intValue());
 	}
 
 	@Test
 	public void testManualSynchronization() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		sessionFactory().getStatistics().clear();
 
 		// create an Organization...
 		Organization jboss = new Organization( "JBoss" );
 		s.persist( jboss );
 
 		// now query on Employment, this should not cause an auto-flush
 		s.createSQLQuery( getEmploymentSQL() ).list();
 		assertEquals( 0, sessionFactory().getStatistics().getEntityInsertCount() );
 
 		// now try to query on Employment but this time add Organization as a synchronized query space...
 		s.createSQLQuery( getEmploymentSQL() ).addSynchronizedEntityClass( Organization.class ).list();
 		assertEquals( 1, sessionFactory().getStatistics().getEntityInsertCount() );
 
 		// clean up
 		s.delete( jboss );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testSQLQueryInterface() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Organization ifa = new Organization("IFA");
 		Organization jboss = new Organization("JBoss");
 		Person gavin = new Person("Gavin");
 		Employment emp = new Employment(gavin, jboss, "AU");
 
 		s.persist(ifa);
 		s.persist(jboss);
 		s.persist(gavin);
 		s.persist(emp);
 
 		List l = s.createSQLQuery( getOrgEmpRegionSQL() )
 				.addEntity("org", Organization.class)
 				.addJoin("emp", "org.employments")
 				.addScalar("regionCode", StringType.INSTANCE)
 				.list();
 		assertEquals( 2, l.size() );
 
 		l = s.createSQLQuery( getOrgEmpPersonSQL() )
 				.addEntity("org", Organization.class)
 				.addJoin("emp", "org.employments")
 				.addJoin("pers", "emp.employee")
 				.list();
 		assertEquals( l.size(), 1 );
 
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 
 		l = s.createSQLQuery( "select {org.*}, {emp.*} " +
 			       "from ORGANIZATION org " +
 			       "     left outer join EMPLOYMENT emp on org.ORGID = emp.EMPLOYER, ORGANIZATION org2" )
 		.addEntity("org", Organization.class)
 		.addJoin("emp", "org.employments")
 		.setResultTransformer( DistinctRootEntityResultTransformer.INSTANCE )
 		.list();
 		assertEquals( l.size(), 2 );
 
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 
 		s.delete(emp);
 		s.delete(gavin);
 		s.delete(ifa);
 		s.delete(jboss);
 
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testResultSetMappingDefinition() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Organization ifa = new Organization("IFA");
 		Organization jboss = new Organization("JBoss");
 		Person gavin = new Person("Gavin");
 		Employment emp = new Employment(gavin, jboss, "AU");
 
 		s.persist(ifa);
 		s.persist(jboss);
 		s.persist(gavin);
 		s.persist(emp);
 
 		List l = s.createSQLQuery( getOrgEmpRegionSQL() )
 				.setResultSetMapping( "org-emp-regionCode" )
 				.list();
 		assertEquals( l.size(), 2 );
 
 		l = s.createSQLQuery( getOrgEmpPersonSQL() )
 				.setResultSetMapping( "org-emp-person" )
 				.list();
 		assertEquals( l.size(), 1 );
 
 		s.delete(emp);
 		s.delete(gavin);
 		s.delete(ifa);
 		s.delete(jboss);
 
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testScalarValues() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 
 		Organization ifa = new Organization( "IFA" );
 		Organization jboss = new Organization( "JBoss" );
 
 		Serializable idIfa = s.save( ifa );
 		Serializable idJBoss = s.save( jboss );
 
 		s.flush();
 
 		List result = s.getNamedQuery( "orgNamesOnly" ).list();
 		assertTrue( result.contains( "IFA" ) );
 		assertTrue( result.contains( "JBoss" ) );
 
 		result = s.getNamedQuery( "orgNamesOnly" ).setResultTransformer(Transformers.ALIAS_TO_ENTITY_MAP).list();
 		Map m = (Map) result.get(0);
 		assertEquals( 2, result.size() );
 		assertEquals( 1, m.size() );
 		assertTrue( m.containsKey("NAME") );
 
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 
 		Iterator iter = s.getNamedQuery( "orgNamesAndOrgs" ).list().iterator();
 		Object[] o = ( Object[] ) iter.next();
 		assertEquals( "expecting 2 values", 2, o.length );
 		assertEquals( o[0], "IFA" );
 		assertEquals( ( ( Organization ) o[1] ).getName(), "IFA" );
 		o = ( Object[] ) iter.next();
 		assertEquals( o[0], "JBoss" );
 		assertEquals( ( ( Organization ) o[1] ).getName(), "JBoss" );
 
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 
 		// test that the ordering of the results is truly based on the order in which they were defined
 		iter = s.getNamedQuery( "orgsAndOrgNames" ).list().iterator();
 		Object[] row = ( Object[] ) iter.next();
 		assertEquals( "expecting 2 values", 2, row.length );
 		assertEquals( "expecting non-scalar result first", Organization.class, row[0].getClass() );
 		assertEquals( "expecting scalar result second", String.class, row[1].getClass() );
 		assertEquals( ( ( Organization ) row[0] ).getName(), "IFA" );
 		assertEquals( row[1], "IFA" );
 		row = ( Object[] ) iter.next();
 		assertEquals( "expecting non-scalar result first", Organization.class, row[0].getClass() );
 		assertEquals( "expecting scalar result second", String.class, row[1].getClass() );
 		assertEquals( ( ( Organization ) row[0] ).getName(), "JBoss" );
 		assertEquals( row[1], "JBoss" );
 		assertFalse( iter.hasNext() );
 
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 
 		iter = s.getNamedQuery( "orgIdsAndOrgNames" ).list().iterator();
 		o = ( Object[] ) iter.next();
 		assertEquals( o[1], "IFA" );
 		assertEquals( o[0], idIfa );
 		o = ( Object[] ) iter.next();
 		assertEquals( o[1], "JBoss" );
 		assertEquals( o[0], idJBoss );
 
 		s.delete( ifa );
 		s.delete( jboss );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"deprecation", "UnusedDeclaration"})
 	public void testMappedAliasStrategy() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Organization ifa = new Organization("IFA");
 		Organization jboss = new Organization("JBoss");
 		Person gavin = new Person("Gavin");
 		Employment emp = new Employment(gavin, jboss, "AU");
 		Serializable orgId = s.save(jboss);
 		Serializable orgId2 = s.save(ifa);
 		s.save(gavin);
 		s.save(emp);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query namedQuery = s.getNamedQuery("AllEmploymentAsMapped");
 		List list = namedQuery.list();
 		assertEquals(1,list.size());
 		Employment emp2 = (Employment) list.get(0);
 		assertEquals(emp2.getEmploymentId(), emp.getEmploymentId() );
 		assertEquals(emp2.getStartDate().getDate(), emp.getStartDate().getDate() );
 		assertEquals(emp2.getEndDate(), emp.getEndDate() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query sqlQuery = s.getNamedQuery("EmploymentAndPerson");
 		sqlQuery.setResultTransformer(Transformers.ALIAS_TO_ENTITY_MAP);
 		list = sqlQuery.list();
 		assertEquals(1,list.size() );
 		Object res = list.get(0);
 		assertClassAssignability( Map.class, res.getClass() );
 		Map m = (Map) res;
 		assertEquals(2,m.size());
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		sqlQuery = s.getNamedQuery( "organizationreturnproperty" );
 		sqlQuery.setResultTransformer( Transformers.ALIAS_TO_ENTITY_MAP );
 		list = sqlQuery.list();
 		assertEquals( 2,list.size() );
 		m = (Map) list.get(0);
 		assertEquals( 2, m.size() );
 		assertTrue( m.containsKey("org") );
 		assertTrue( m.containsKey("emp") );
 		assertClassAssignability( m.get("org").getClass(), Organization.class );
 		if ( jboss.getId() == ( (Organization) m.get("org") ).getId() ) {
 			assertClassAssignability( m.get("emp").getClass(), Employment.class );
 		}
 		Map m2 = (Map) list.get(1);
 		assertEquals( 2, m.size() );
 		assertTrue( m2.containsKey("org") );
 		assertTrue( m2.containsKey("emp") );
 		assertClassAssignability( m2.get("org").getClass(), Organization.class );
 		if ( jboss.getId() == ( (Organization) m2.get("org") ).getId() ) {
 			assertClassAssignability( m2.get("emp").getClass(), Employment.class );
 		}
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		namedQuery = s.getNamedQuery("EmploymentAndPerson");
 		list = namedQuery.list();
 		assertEquals(1,list.size() );
 		Object[] objs = (Object[]) list.get(0);
 		assertEquals(2, objs.length);
 		emp2 = (Employment) objs[0];
 		gavin = (Person) objs[1];
 		s.delete(emp2);
 		s.delete(jboss);
 		s.delete(gavin);
 		s.delete(ifa);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	@FailureExpected( jiraKey = "unknown" )
 	public void testCompositeIdJoins() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Person person = new Person();
 		person.setName( "Noob" );
 
 		Product product = new Product();
 		product.setProductId( new Product.ProductId() );
 		product.getProductId().setOrgid( "x" );
 		product.getProductId().setProductnumber( "1234" );
 		product.setName( "Hibernate 3" );
 
 		Order order = new Order();
 		order.setOrderId( new Order.OrderId() );
 		order.getOrderId().setOrdernumber( "1" );
 		order.getOrderId().setOrgid( "y" );
 
 		product.getOrders().add( order );
 		order.setProduct( product );
 		order.setPerson( person );
 
 		s.save( product );
 		s.save( order);
 		s.save( person );
 
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Product p = (Product) s.createQuery( "from Product p join fetch p.orders" ).list().get(0);
 		assertTrue(Hibernate.isInitialized( p.getOrders()));
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Object[] o =  (Object[]) s.createSQLQuery( "select\r\n" +
 				"        product.orgid as {product.id.orgid}," +
 				"        product.productnumber as {product.id.productnumber}," +
 				"        {prod_orders}.orgid as orgid3_1_,\r\n" +
 				"        {prod_orders}.ordernumber as ordernum2_3_1_,\r\n" +
 				"        product.name as {product.name}," +
 				"        {prod_orders.element.*}" +
 				/*"        orders.PROD_NO as PROD4_3_1_,\r\n" +
 				"        orders.person as person3_1_,\r\n" +
 				"        orders.PROD_ORGID as PROD3_0__,\r\n" +
 				"        orders.PROD_NO as PROD4_0__,\r\n" +
 				"        orders.orgid as orgid0__,\r\n" +
 				"        orders.ordernumber as ordernum2_0__ \r\n" +*/
 				"    from\r\n" +
 				"        Product product \r\n" +
 				"    inner join\r\n" +
 				"        TBL_ORDER {prod_orders} \r\n" +
 				"            on product.orgid={prod_orders}.PROD_ORGID \r\n" +
 				"            and product.productnumber={prod_orders}.PROD_NO" )
 				.addEntity( "product", Product.class )
 				.addJoin( "prod_orders", "product.orders" )
 				.list().get(0);
 
 		p = (Product) o[0];
 		assertTrue(Hibernate.isInitialized( p.getOrders() ));
 		assertNotNull(p.getOrders().iterator().next());
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"UnusedDeclaration", "deprecation", "UnusedAssignment"})
 	public void testAutoDetectAliasing() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Organization ifa = new Organization("IFA");
 		Organization jboss = new Organization("JBoss");
 		Person gavin = new Person("Gavin");
 		Employment emp = new Employment(gavin, jboss, "AU");
 		Serializable orgId = s.save(jboss);
 		Serializable orgId2 = s.save(ifa);
 		s.save(gavin);
 		s.save(emp);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List list = s.createSQLQuery( getEmploymentSQL() )
 				.addEntity( Employment.class.getName() )
 				.list();
 		assertEquals( 1,list.size() );
 
 		Employment emp2 = (Employment) list.get(0);
 		assertEquals(emp2.getEmploymentId(), emp.getEmploymentId() );
 		assertEquals(emp2.getStartDate().getDate(), emp.getStartDate().getDate() );
 		assertEquals(emp2.getEndDate(), emp.getEndDate() );
 
 		s.clear();
 
 		list = s.createSQLQuery( getEmploymentSQL() )
 		.addEntity( Employment.class.getName() )
 		.setResultTransformer(Transformers.ALIAS_TO_ENTITY_MAP)
 		.list();
 		assertEquals( 1,list.size() );
 		Map m = (Map) list.get(0);
 		assertTrue(m.containsKey("Employment"));
 		assertEquals(1,m.size());
 
 		list = s.createSQLQuery(getEmploymentSQL()).list();
 		assertEquals(1, list.size());
 		Object[] o = (Object[]) list.get(0);
 		assertEquals(8, o.length);
 
 		list = s.createSQLQuery( getEmploymentSQL() ).setResultTransformer( new UpperCasedAliasToEntityMapResultTransformer() ).list();
 		assertEquals(1, list.size());
 		m = (Map) list.get(0);
 		assertTrue(m.containsKey("EMPID"));
 		assertTrue(m.containsKey("AMOUNT"));
 		assertTrue(m.containsKey("ENDDATE"));
 		assertEquals(8, m.size());
 
 		list = s.createSQLQuery( getEmploymentSQLMixedScalarEntity() ).addScalar( "employerid" ).addEntity( Employment.class ).list();
 		assertEquals(1, list.size());
 		o = (Object[]) list.get(0);
 		assertEquals(2, o.length);
 		assertClassAssignability( Number.class, o[0].getClass() );
 		assertClassAssignability( Employment.class, o[1].getClass() );
 
 
 
 		Query queryWithCollection = s.getNamedQuery("organizationEmploymentsExplicitAliases");
 		queryWithCollection.setLong("id",  jboss.getId() );
 		list = queryWithCollection.list();
 		assertEquals(list.size(),1);
 
 		s.clear();
 
 		list = s.createSQLQuery( getOrganizationJoinEmploymentSQL() )
 				.addEntity( "org", Organization.class )
 				.addJoin( "emp", "org.employments" )
 				.list();
 		assertEquals( 2,list.size() );
 
 		s.clear();
 
 		list = s.createSQLQuery( getOrganizationFetchJoinEmploymentSQL() )
 				.addEntity( "org", Organization.class )
 				.addJoin( "emp", "org.employments" )
 				.list();
 		assertEquals( 2,list.size() );
 
 		s.clear();
 
 		// TODO : why twice?
 		s.getNamedQuery( "organizationreturnproperty" ).list();
 		list = s.getNamedQuery( "organizationreturnproperty" ).list();
 		assertEquals( 2,list.size() );
 
 		s.clear();
 
 		list = s.getNamedQuery( "organizationautodetect" ).list();
 		assertEquals( 2,list.size() );
 
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.delete(emp2);
 
 		s.delete(jboss);
 		s.delete(gavin);
 		s.delete(ifa);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Dimension dim = new Dimension( 3, Integer.MAX_VALUE );
 		s.save( dim );
 		list = s.createSQLQuery( "select d_len * d_width as surface, d_len * d_width * 10 as volume from Dimension" ).list();
 		s.delete( dim );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		SpaceShip enterprise = new SpaceShip();
 		enterprise.setModel( "USS" );
 		enterprise.setName( "Entreprise" );
 		enterprise.setSpeed( 50d );
 		Dimension d = new Dimension(45, 10);
 		enterprise.setDimensions( d );
 		s.save( enterprise );
 		Object[] result = (Object[]) s.getNamedQuery( "spaceship" ).uniqueResult();
 		assertEquals( "expecting 3 result values", 3, result.length );
 		enterprise = ( SpaceShip ) result[0];
 		assertTrue(50d == enterprise.getSpeed() );
 		assertTrue( 450d == extractDoubleValue( result[1] ) );
 		assertTrue( 4500d == extractDoubleValue( result[2] ) );
 		s.delete( enterprise );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void testExplicitReturnAPI() {
 		Session s = openSession();
 		s.beginTransaction();
 		Organization jboss = new Organization( "JBoss" );
 		Person me = new Person( "Steve" );
 		Employment emp = new Employment( me, jboss, "US" );
 		Serializable jbossId = s.save( jboss );
 		s.save( me );
 		s.save( emp );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 
 		String sql =
 				"SELECT org.ORGID 		as orgid," +
 				"       org.NAME 		as name," +
 				"       emp.EMPLOYER 	as employer," +
 				"       emp.EMPID 		as empid," +
 				"       emp.EMPLOYEE 	as employee," +
 				"       emp.EMPLOYER 	as employer," +
 				"       emp.STARTDATE 	as startDate," +
 				"       emp.ENDDATE 	as endDate," +
 				"       emp.REGIONCODE 	as regionCode," +
 				"       emp.AMOUNT 		as AMOUNT," +
 				"       emp.CURRENCY 	as CURRENCY" +
 				" FROM 	ORGANIZATION org" +
 				"    LEFT OUTER JOIN EMPLOYMENT emp ON org.ORGID = emp.EMPLOYER";
 
 		// as a control, lets apply an existing rs mapping
 		SQLQuery sqlQuery = s.createSQLQuery( sql );
 		sqlQuery.setResultSetMapping( "org-description" );
 		sqlQuery.list();
 
 		// next try a partial mapping def
 		sqlQuery.addRoot( "org", Organization.class );
 		sqlQuery.addFetch( "emp", "org", "employments" );
 		sqlQuery.list();
 
 		// now try full explicit mappings
 		sqlQuery.addRoot( "org", Organization.class )
 				.addProperty( "id", "orgid" )
 				.addProperty( "name" ).addColumnAlias( "name" );
 		sqlQuery.addFetch( "emp", "org", "employments" )
 				.addProperty( "key", "employer" )
 				.addProperty( "element", "empid" )
 				.addProperty( "element.employee", "employee" )
 				.addProperty( "element.employer", "employer" )
 				.addProperty( "element.startDate", "startDate" )
 				.addProperty( "element.endDate", "endDate" )
 				.addProperty( "element.regionCode", "regionCode" )
 				.addProperty( "element.employmentId", "empId" )
 				.addProperty( "element.salary" ).addColumnAlias( "AMOUNT" ).addColumnAlias( "CURRENCY" );
 		sqlQuery.list();
 
 		// lets try a totally different approach now and pull back scalars, first with explicit types
 		sqlQuery.addScalar( "orgid", LongType.INSTANCE )
 				.addScalar( "name", StringType.INSTANCE )
 				.addScalar( "empid", LongType.INSTANCE )
 				.addScalar( "employee", LongType.INSTANCE )
 				.addScalar( "startDate", TimestampType.INSTANCE )
 				.addScalar( "endDate", TimestampType.INSTANCE )
 				.addScalar( "regionCode", StringType.INSTANCE )
 				.addScalar( "empId", LongType.INSTANCE )
 				.addScalar( "AMOUNT", FloatType.INSTANCE )
 				.addScalar( "CURRENCY", StringType.INSTANCE );
 
 
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( emp );
 		s.delete( jboss );
 		s.delete( me );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testMixAndMatchEntityScalar() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Speech speech = new Speech();
 		speech.setLength( new Double( 23d ) );
 		speech.setName( "Mine" );
 		s.persist( speech );
 		s.flush();
 		s.clear();
 
 		List l = s.createSQLQuery( "select name, id, flength, name as scalarName from Speech" )
 				.setResultSetMapping( "speech" )
 				.list();
 		assertEquals( l.size(), 1 );
 
 		t.rollback();
 		s.close();
 	}
 
 	private double extractDoubleValue(Object value) {
 		if ( value instanceof BigInteger ) {
 			return ( ( BigInteger ) value ).doubleValue();
 		}
 		else if ( value instanceof BigDecimal ) {
 			return ( ( BigDecimal ) value ).doubleValue();
 		}
 		else {
 			return Double.valueOf( value.toString() ).doubleValue();
 		}
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked", "UnusedDeclaration"})
 	public void testAddJoinForManyToMany() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Person gavin = new Person( "Gavin" );
 		Person max = new Person( "Max" );
 		Person pete = new Person( "Pete" );
 
 		Group hibernate = new Group( "Hibernate" );
 		Group seam = new Group( "Seam" );
 
 		s.persist( gavin );
 		s.persist( max );
 		s.persist( pete );
 		s.persist( seam );
 		s.persist( hibernate );
 
 		hibernate.getPersons().add( gavin );
 		hibernate.getPersons().add( max );
 		seam.getPersons().add( gavin );
 		seam.getPersons().add( pete );
 
 		s.flush();
 		s.clear();
 
 		// todo : see http://opensource.atlassian.com/projects/hibernate/browse/HHH-3908
 //		String sqlStr = "SELECT {groupp.*} , {gp.*} " +
 //				"FROM GROUPP groupp, GROUP_PERSON gp, PERSON person WHERE groupp.ID = gp.GROUP_ID and person.PERID = gp.PERSON_ID";
 //
 //		List l = s.createSQLQuery( sqlStr )
 //				.addEntity("groupp", Group.class)
 //				.addJoin("gp","groupp.persons")
 //				.list();
 		List l = s.getNamedQuery( "manyToManyFetch" ).list();
 		//assertEquals( 2, l.size() );
 
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 
 		seam.getPersons().remove( gavin );
 		seam.getPersons().remove( pete );
 
 		hibernate.getPersons().remove( gavin );
 		hibernate.getPersons().remove( max );
 
 		s.delete( seam );
 		s.delete( hibernate );
 		s.delete( gavin );
 		s.delete( max );
 		s.delete( pete );
 
 		t.commit();
 		s.close();
 	}
 
 	@SkipForDialect(value = AbstractHANADialect.class, comment = "On HANA, this returns an clob for the text column which doesn't get mapped to a String")
 	@Test
 	public void testTextTypeInSQLQuery() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		String description = buildLongString( 15000, 'a' );
 		TextHolder holder = new TextHolder( description );
 		s.persist( holder );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		String descriptionRead = ( String ) s.createSQLQuery( getDescriptionsSQL() )
 				.uniqueResult();
 		assertEquals( description, descriptionRead );
 		s.delete( holder );
 		t.commit();
 		s.close();
 	}
 
 	@SkipForDialect(value = AbstractHANADialect.class, comment = "On HANA, this returns a blob for the image column which doesn't get mapped to a byte[]")
 	@Test
 	public void testImageTypeInSQLQuery() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		byte[] photo = buildLongByteArray( 15000, true );
 		ImageHolder holder = new ImageHolder( photo );
 		s.persist( holder );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		byte[] photoRead = ( byte[] ) s.createSQLQuery( getPhotosSQL() )
 				.uniqueResult();
 		assertTrue( ArrayHelper.isEquals( photo, photoRead ) );
 		s.delete( holder );
 		t.commit();
 		s.close();
 	}
 	@Test
 	@RequiresDialect(MySQL5Dialect.class)
 	public void testEscapeColonInSQL() throws QueryException {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		SQLQuery query = s.createSQLQuery( "SELECT @row \\:= 1" );
 		List list = query.list();
 		assertTrue( list.get( 0 ).toString().equals( "1" ) );
 		t.commit();
 		s.close();
 	}
 
 	private String buildLongString(int size, char baseChar) {
 		StringBuilder buff = new StringBuilder();
 		for( int i = 0; i < size; i++ ) {
 			buff.append( baseChar );
 		}
 		return buff.toString();
 	}
 
 	private byte[] buildLongByteArray(int size, boolean on) {
 		byte[] data = new byte[size];
 		data[0] = mask( on );
 		for ( int i = 0; i < size; i++ ) {
 			data[i] = mask( on );
 			on = !on;
 		}
 		return data;
 	}
 
 	private byte mask(boolean on) {
 		return on ? ( byte ) 1 : ( byte ) 0;
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	private static class UpperCasedAliasToEntityMapResultTransformer extends BasicTransformerAdapter implements Serializable {
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			Map result = new HashMap( tuple.length );
 			for ( int i = 0; i < tuple.length; i++ ) {
 				String alias = aliases[i];
 				if ( alias != null ) {
-					result.put( alias.toUpperCase(), tuple[i] );
+					result.put( alias.toUpperCase(Locale.ROOT), tuple[i] );
 				}
 			}
 			return result;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/stateless/fetching/StatelessSessionFetchingTest.java b/hibernate-core/src/test/java/org/hibernate/test/stateless/fetching/StatelessSessionFetchingTest.java
index ac9ff39d75..95706f0e30 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/stateless/fetching/StatelessSessionFetchingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/stateless/fetching/StatelessSessionFetchingTest.java
@@ -1,120 +1,121 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.stateless.fetching;
 
 import java.util.Date;
+import java.util.Locale;
 
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.StatelessSession;
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.internal.util.StringHelper;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 import org.jboss.logging.Logger;
 
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Steve Ebersole
  */
 public class StatelessSessionFetchingTest extends BaseCoreFunctionalTestCase {
 	private static final Logger log = Logger.getLogger( StatelessSessionFetchingTest.class );
 
 	@Override
 	public String[] getMappings() {
 		return new String[] { "stateless/fetching/Mappings.hbm.xml" };
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setPhysicalNamingStrategy( new TestingNamingStrategy() );
 	}
 
 	private class TestingNamingStrategy extends PhysicalNamingStrategyStandardImpl {
 		private final String prefix = determineUniquePrefix();
 
 		protected String applyPrefix(String baseTableName) {
 			String prefixed = prefix + '_' + baseTableName;
             log.debug("prefixed table name : " + baseTableName + " -> " + prefixed);
 			return prefixed;
 		}
 
 		@Override
 		public Identifier toPhysicalTableName(Identifier name, JdbcEnvironment jdbcEnvironment) {
 			return jdbcEnvironment.getIdentifierHelper().toIdentifier( applyPrefix( name.getText() ) );
 		}
 
 		private String determineUniquePrefix() {
-			return StringHelper.collapseQualifier( getClass().getName(), false ).toUpperCase();
+			return StringHelper.collapseQualifier( getClass().getName(), false ).toUpperCase(Locale.ROOT);
 		}
 	}
 
 	@Test
 	public void testDynamicFetch() {
 		Session s = openSession();
 		s.beginTransaction();
 		Date now = new Date();
 		User me = new User( "me" );
 		User you = new User( "you" );
 		Resource yourClock = new Resource( "clock", you );
 		Task task = new Task( me, "clean", yourClock, now ); // :)
 		s.save( me );
 		s.save( you );
 		s.save( yourClock );
 		s.save( task );
 		s.getTransaction().commit();
 		s.close();
 
 		StatelessSession ss = sessionFactory().openStatelessSession();
 		ss.beginTransaction();
 		Task taskRef = ( Task ) ss.createQuery( "from Task t join fetch t.resource join fetch t.user" ).uniqueResult();
 		assertTrue( taskRef != null );
 		assertTrue( Hibernate.isInitialized( taskRef ) );
 		assertTrue( Hibernate.isInitialized( taskRef.getUser() ) );
 		assertTrue( Hibernate.isInitialized( taskRef.getResource() ) );
 		assertFalse( Hibernate.isInitialized( taskRef.getResource().getOwner() ) );
 		ss.getTransaction().commit();
 		ss.close();
 
 		cleanup();
 	}
 
 	private void cleanup() {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "delete Task" ).executeUpdate();
 		s.createQuery( "delete Resource" ).executeUpdate();
 		s.createQuery( "delete User" ).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/ParameterizedFunctionExpression.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/ParameterizedFunctionExpression.java
index 2027a3cdb9..138d325fc2 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/ParameterizedFunctionExpression.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/ParameterizedFunctionExpression.java
@@ -1,135 +1,136 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.expression.function;
 
 import java.util.Arrays;
 import java.util.List;
+import java.util.Locale;
 import javax.persistence.criteria.Expression;
 
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.ParameterContainer;
 import org.hibernate.jpa.criteria.ParameterRegistry;
 import org.hibernate.jpa.criteria.Renderable;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 
 /**
  * Support for functions with parameters.
  *
  * @author Steve Ebersole
  */
 public class ParameterizedFunctionExpression<X>
 		extends BasicFunctionExpression<X>
 		implements FunctionExpression<X> {
 
 	public static List<String> STANDARD_JPA_FUNCTION_NAMES = Arrays.asList(
 			// 4.6.17.2.1
 			"CONCAT",
 			"SUBSTRING",
 			"TRIM",
 			"UPPER",
 			"LOWER",
 			"LOCATE",
 			"LENGTH",
 			//4.6.17.2.2
 			"ABS",
 			"SQRT",
 			"MOD",
 			"SIZE",
 			"INDEX",
 			// 4.6.17.2.3
 			"CURRENT_DATE",
 			"CURRENT_TIME",
 			"CURRENT_TIMESTAMP"
 	);
 
 	private final List<Expression<?>> argumentExpressions;
 	private final boolean isStandardJpaFunction;
 
 	public ParameterizedFunctionExpression(
 			CriteriaBuilderImpl criteriaBuilder,
 			Class<X> javaType,
 			String functionName,
 			List<Expression<?>> argumentExpressions) {
 		super( criteriaBuilder, javaType, functionName );
 		this.argumentExpressions = argumentExpressions;
-		this.isStandardJpaFunction = STANDARD_JPA_FUNCTION_NAMES.contains( functionName.toUpperCase() );
+		this.isStandardJpaFunction = STANDARD_JPA_FUNCTION_NAMES.contains( functionName.toUpperCase(Locale.ROOT) );
 	}
 
 	public ParameterizedFunctionExpression(
 			CriteriaBuilderImpl criteriaBuilder,
 			Class<X> javaType,
 			String functionName,
 			Expression<?>... argumentExpressions) {
 		super( criteriaBuilder, javaType, functionName );
 		this.argumentExpressions = Arrays.asList( argumentExpressions );
-		this.isStandardJpaFunction = STANDARD_JPA_FUNCTION_NAMES.contains( functionName.toUpperCase() );
+		this.isStandardJpaFunction = STANDARD_JPA_FUNCTION_NAMES.contains( functionName.toUpperCase(Locale.ROOT) );
 	}
 
 	protected boolean isStandardJpaFunction() {
 		return isStandardJpaFunction;
 	}
 
 	protected  static int properSize(int number) {
 		return number + (int)( number*.75 ) + 1;
 	}
 
 	public List<Expression<?>> getArgumentExpressions() {
 		return argumentExpressions;
 	}
 
 	@Override
 	public void registerParameters(ParameterRegistry registry) {
 		for ( Expression argument : getArgumentExpressions() ) {
 			if ( ParameterContainer.class.isInstance( argument ) ) {
 				( (ParameterContainer) argument ).registerParameters(registry);
 			}
 		}
 	}
 
 	@Override
 	public String render(RenderingContext renderingContext) {
 		StringBuilder buffer = new StringBuilder();
 		if ( isStandardJpaFunction() ) {
 			buffer.append( getFunctionName() )
 					.append( "(" );
 		}
 		else {
 			buffer.append( "function('" )
 					.append( getFunctionName() )
 					.append( "', " );
 		}
 		renderArguments( buffer, renderingContext );
 		buffer.append( ')' );
 		return buffer.toString();
 	}
 
 	protected void renderArguments(StringBuilder buffer, RenderingContext renderingContext) {
 		String sep = "";
 		for ( Expression argument : argumentExpressions ) {
 			buffer.append( sep ).append( ( (Renderable) argument ).render( renderingContext ) );
 			sep = ", ";
 		}
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/ConfigurationHelper.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/ConfigurationHelper.java
index c8050625e8..be4f5b9902 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/ConfigurationHelper.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/ConfigurationHelper.java
@@ -1,109 +1,110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.util;
 
+import java.util.Locale;
 import java.util.Map;
 import java.util.Properties;
 import javax.persistence.FlushModeType;
 import javax.persistence.PersistenceException;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 
 /**
  * @author Emmanuel Bernard
  */
 public abstract class ConfigurationHelper {
 	public static void overrideProperties(Properties properties, Map<?,?> overrides) {
 		for ( Map.Entry entry : overrides.entrySet() ) {
 			if ( entry.getKey() != null && entry.getValue() != null ) {
 				properties.put( entry.getKey(), entry.getValue() );
 			}
 		}
 	}
 
 	public static FlushMode getFlushMode(Object value) {
 		FlushMode flushMode = null;
 		if (value instanceof FlushMode) {
 			flushMode = (FlushMode) value;
 		}
 		else if (value instanceof javax.persistence.FlushModeType) {
 			flushMode = ConfigurationHelper.getFlushMode( (javax.persistence.FlushModeType) value);
 		}
 		else if (value instanceof String) {
 			flushMode = ConfigurationHelper.getFlushMode( (String) value);
 		}
 		if (flushMode == null) {
 			throw new PersistenceException("Unable to parse org.hibernate.flushMode: " + value);
 		}
 		return flushMode;
 	}
 
 	private static FlushMode getFlushMode(String flushMode)  {
 		if (flushMode == null) {
 			return null;
 		}
-		flushMode = flushMode.toUpperCase();
+		flushMode = flushMode.toUpperCase(Locale.ROOT);
 		return FlushMode.valueOf( flushMode );
 	}
 
 	private static FlushMode getFlushMode(FlushModeType flushMode)  {
 		switch(flushMode) {
 			case AUTO:
 				return FlushMode.AUTO;
 			case COMMIT:
 				return FlushMode.COMMIT;
 			default:
 				throw new AssertionFailure("Unknown FlushModeType: " + flushMode);
 		}
 	}
 
 	public static Integer getInteger(Object value) {
 		if ( value instanceof Integer ) {
 			return (Integer) value;
 		}
 		else {
 			return Integer.valueOf( (String) value );
 		}
 	}
 
 	public static Boolean getBoolean(Object value) {
 		if ( value instanceof Boolean ) {
 			return (Boolean) value;
 		}
 		else {
 			return Boolean.valueOf( (String) value );
 		}
 	}
 
 	public static CacheMode getCacheMode(Object value) {
 		if ( value instanceof CacheMode ) {
 			return (CacheMode) value;
 		}
 		else {
 			return CacheMode.valueOf( (String) value );
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/XmlHelper.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/XmlHelper.java
index ad3a481389..af6046cd8d 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/XmlHelper.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/XmlHelper.java
@@ -1,202 +1,203 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.util;
 
 import java.util.ArrayList;
 import java.util.Iterator;
+import java.util.Locale;
 
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
 /**
  * A utility class to cover up the rough bits of xml parsing
  *
  * @author <a href="mailto:chris@kimptoc.net">Chris Kimpton</a>
  */
 public final class XmlHelper {
 	private XmlHelper() {
 	}
 
 	/**
 	 * Returns an iterator over the children of the given element with
 	 * the given tag name.
 	 *
 	 * @param element The parent element
 	 * @param tagName The name of the desired child
 	 * @return An interator of children or null if element is null.
 	 */
 	public static Iterator getChildrenByTagName(
 			Element element,
 			String tagName) {
 		if ( element == null ) return null;
 		// getElementsByTagName gives the corresponding elements in the whole
 		// descendance. We want only children
 
 		NodeList children = element.getChildNodes();
 		ArrayList goodChildren = new ArrayList();
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			Node currentChild = children.item( i );
 			if ( currentChild.getNodeType() == Node.ELEMENT_NODE &&
 					( (Element) currentChild ).getTagName().equals( tagName ) ) {
 				goodChildren.add( currentChild );
 			}
 		}
 		return goodChildren.iterator();
 	}
 
 	/**
 	 * Gets the child of the specified element having the specified unique
 	 * name.  If there are more than one children elements with the same name
 	 * and exception is thrown.
 	 *
 	 * @param element The parent element
 	 * @param tagName The name of the desired child
 	 * @return The named child.
 	 * @throws Exception Child was not found or was not unique.
 	 */
 	public static Element getUniqueChild(Element element, String tagName) throws Exception {
 		final Iterator goodChildren = getChildrenByTagName( element, tagName );
 
 		if ( goodChildren != null && goodChildren.hasNext() ) {
 			final Element child = (Element) goodChildren.next();
 			if ( goodChildren.hasNext() ) {
 				throw new Exception( "expected only one " + tagName + " tag" );
 			}
 			return child;
 		}
 		else {
 			throw new Exception( "expected one " + tagName + " tag" );
 		}
 	}
 
 	/**
 	 * Gets the child of the specified element having the
 	 * specified name. If the child with this name doesn't exist
 	 * then null is returned instead.
 	 *
 	 * @param element the parent element
 	 * @param tagName the name of the desired child
 	 * @return either the named child or null
 	 */
 	public static Element getOptionalChild(Element element, String tagName) throws Exception {
 		return getOptionalChild( element, tagName, null );
 	}
 
 	/**
 	 * Gets the child of the specified element having the
 	 * specified name. If the child with this name doesn't exist
 	 * then the supplied default element is returned instead.
 	 *
 	 * @param element		the parent element
 	 * @param tagName		the name of the desired child
 	 * @param defaultElement the element to return if the child
 	 *                       doesn't exist
 	 * @return either the named child or the supplied default
 	 */
 	public static Element getOptionalChild(
 			Element element,
 			String tagName,
 			Element defaultElement) throws Exception {
 		final Iterator goodChildren = getChildrenByTagName( element, tagName );
 
 		if ( goodChildren != null && goodChildren.hasNext() ) {
 			final Element child = (Element) goodChildren.next();
 			if ( goodChildren.hasNext() ) {
 				throw new Exception( "expected only one " + tagName + " tag" );
 			}
 			return child;
 		}
 		else {
 			return defaultElement;
 		}
 	}
 
 	/**
 	 * Get the content of the given element.
 	 *
 	 * @param element The element to get the content for.
 	 * @return The content of the element or null.
 	 */
 	public static String getElementContent(final Element element) throws Exception {
 		return getElementContent( element, null );
 	}
 
 	/**
 	 * Get the content of the given element.
 	 *
 	 * @param element	The element to get the content for.
 	 * @param defaultStr The default to return when there is no content.
 	 * @return The content of the element or the default.
 	 */
 	public static String getElementContent(Element element, String defaultStr) throws Exception {
 		if ( element == null ) {
 			return defaultStr;
 		}
 
 		final NodeList children = element.getChildNodes();
 		final StringBuilder result = new StringBuilder("");
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			if ( children.item( i ).getNodeType() == Node.TEXT_NODE
 					|| children.item( i ).getNodeType() == Node.CDATA_SECTION_NODE ) {
 				result.append( children.item( i ).getNodeValue() );
 			}
 //			else if ( children.item( i ).getNodeType() == Node.COMMENT_NODE ) {
 //				// Ignore comment nodes
 //			}
 		}
 		return result.toString().trim();
 	}
 
 	/**
 	 * Macro to get the content of a unique child element.
 	 *
 	 * @param element The parent element.
 	 * @param tagName The name of the desired child.
 	 * @return The element content or null.
 	 */
 	public static String getUniqueChildContent(Element element, String tagName) throws Exception {
 		return getElementContent( getUniqueChild( element, tagName ) );
 	}
 
 	/**
 	 * Macro to get the content of an optional child element.
 	 *
 	 * @param element The parent element.
 	 * @param tagName The name of the desired child.
 	 * @return The element content or null.
 	 */
 	public static String getOptionalChildContent(Element element, String tagName) throws Exception {
 		return getElementContent( getOptionalChild( element, tagName ) );
 	}
 
 	public static boolean getOptionalChildBooleanContent(Element element, String name) throws Exception {
 		Element child = getOptionalChild( element, name );
 		if ( child != null ) {
-			String value = getElementContent( child ).toLowerCase();
+			String value = getElementContent( child ).toLowerCase(Locale.ROOT);
 			return value.equals( "true" ) || value.equals( "yes" );
 		}
 
 		return false;
 	}
 
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/metadata/MetadataTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/metadata/MetadataTest.java
index 1aa2523bcc..1e2e3d58ea 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/metadata/MetadataTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/metadata/MetadataTest.java
@@ -1,463 +1,464 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.test.metadata;
 
 import java.util.Collections;
+import java.util.Locale;
 import java.util.Set;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.Bindable;
 import javax.persistence.metamodel.EmbeddableType;
 import javax.persistence.metamodel.EntityType;
 import javax.persistence.metamodel.IdentifiableType;
 import javax.persistence.metamodel.ListAttribute;
 import javax.persistence.metamodel.ManagedType;
 import javax.persistence.metamodel.MapAttribute;
 import javax.persistence.metamodel.MappedSuperclassType;
 import javax.persistence.metamodel.PluralAttribute;
 import javax.persistence.metamodel.SetAttribute;
 import javax.persistence.metamodel.SingularAttribute;
 import javax.persistence.metamodel.Type;
 
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.jpa.internal.metamodel.MetamodelImpl;
 import org.hibernate.jpa.test.BaseEntityManagerFunctionalTestCase;
 import org.hibernate.mapping.MappedSuperclass;
 
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  */
 public class MetadataTest extends BaseEntityManagerFunctionalTestCase {
 	@Test
 	public void testBaseOfService() throws Exception {
 		EntityManagerFactory emf = entityManagerFactory();
 		assertNotNull( emf.getMetamodel() );
 		final EntityType<Fridge> entityType = emf.getMetamodel().entity( Fridge.class );
 		assertNotNull( entityType );
 	}
 
 	@Test
 	public void testInvalidAttributeCausesIllegalArgumentException() {
 		// should not matter the exact subclass of ManagedType since this is implemented on the base class but
 		// check each anyway..
 
 		// entity
 		checkNonExistentAttributeAccess( entityManagerFactory().getMetamodel().entity( Fridge.class ) );
 
 		// embeddable
 		checkNonExistentAttributeAccess( entityManagerFactory().getMetamodel().embeddable( Address.class ) );
 	}
 
 	private void checkNonExistentAttributeAccess(ManagedType managedType) {
 		final String NAME = "NO_SUCH_ATTRIBUTE";
 		try {
 			managedType.getAttribute( NAME );
 			fail( "Lookup of non-existent attribute (getAttribute) should have caused IAE : " + managedType );
 		}
 		catch (IllegalArgumentException expected) {
 		}
 		try {
 			managedType.getSingularAttribute( NAME );
 			fail( "Lookup of non-existent attribute (getSingularAttribute) should have caused IAE : " + managedType );
 		}
 		catch (IllegalArgumentException expected) {
 		}
 		try {
 			managedType.getCollection( NAME );
 			fail( "Lookup of non-existent attribute (getCollection) should have caused IAE : " + managedType );
 		}
 		catch (IllegalArgumentException expected) {
 		}
 	}
 
 	@Test
 	@SuppressWarnings({ "unchecked" })
 	public void testBuildingMetamodelWithParameterizedCollection() {
 		Metadata metadata = new MetadataSources()
 				.addAnnotatedClass( WithGenericCollection.class )
 				.buildMetadata();
 		SessionFactoryImplementor sfi = (SessionFactoryImplementor) metadata.buildSessionFactory();
 		MetamodelImpl.buildMetamodel(
 				metadata.getEntityBindings().iterator(),
 				Collections.<MappedSuperclass>emptySet(),
 				sfi,
 				true
 		);
 		sfi.close();
 	}
 
 	@Test
 	public void testLogicalManyToOne() throws Exception {
 		final EntityType<JoinedManyToOneOwner> entityType = entityManagerFactory().getMetamodel().entity( JoinedManyToOneOwner.class );
 		final SingularAttribute attr = entityType.getDeclaredSingularAttribute( "house" );
 		assertEquals( Attribute.PersistentAttributeType.MANY_TO_ONE, attr.getPersistentAttributeType() );
 		assertEquals( House.class, attr.getBindableJavaType() );
 		final EntityType<House> houseType = entityManagerFactory().getMetamodel().entity( House.class );
 		assertEquals( houseType.getBindableJavaType(), attr.getBindableJavaType() );
 	}
 
 	@Test
 	public void testEntity() throws Exception {
 		final EntityType<Fridge> fridgeType = entityManagerFactory().getMetamodel().entity( Fridge.class );
 		assertEquals( Fridge.class, fridgeType.getBindableJavaType() );
 		assertEquals( Bindable.BindableType.ENTITY_TYPE, fridgeType.getBindableType() );
 		SingularAttribute<Fridge,Integer> wrapped = fridgeType.getDeclaredSingularAttribute( "temperature", Integer.class );
 		assertNotNull( wrapped );
 		SingularAttribute<Fridge,Integer> primitive = fridgeType.getDeclaredSingularAttribute( "temperature", int.class );
 		assertNotNull( primitive );
 		assertNotNull( fridgeType.getDeclaredSingularAttribute( "temperature" ) );
 		assertNotNull( fridgeType.getDeclaredAttribute( "temperature" ) );
 		final SingularAttribute<Fridge, Long> id = fridgeType.getDeclaredId( Long.class );
 		assertNotNull( id );
 		assertTrue( id.isId() );
 		try {
 			fridgeType.getDeclaredId( java.util.Date.class );
 			fail( "expecting failure" );
 		}
 		catch ( IllegalArgumentException ignore ) {
 			// expected result
 		}
 		final SingularAttribute<? super Fridge, Long> id2 = fridgeType.getId( Long.class );
 		assertNotNull( id2 );
 
 		assertEquals( "Fridge", fridgeType.getName() );
 		assertEquals( Long.class, fridgeType.getIdType().getJavaType() );
 		assertTrue( fridgeType.hasSingleIdAttribute() );
 		assertFalse( fridgeType.hasVersionAttribute() );
 		assertEquals( Type.PersistenceType.ENTITY, fridgeType.getPersistenceType() );
 
 		assertEquals( 3, fridgeType.getDeclaredAttributes().size() );
 
 		final EntityType<House> houseType = entityManagerFactory().getMetamodel().entity( House.class );
 		assertEquals( "House", houseType.getName() );
 		assertTrue( houseType.hasSingleIdAttribute() );
 		final SingularAttribute<House, House.Key> houseId = houseType.getDeclaredId( House.Key.class );
 		assertNotNull( houseId );
 		assertTrue( houseId.isId() );
 		assertEquals( Attribute.PersistentAttributeType.EMBEDDED, houseId.getPersistentAttributeType() );
 		
 		final EntityType<Person> personType = entityManagerFactory().getMetamodel().entity( Person.class );
 		assertEquals( "Homo", personType.getName() );
 		assertFalse( personType.hasSingleIdAttribute() );
 		final Set<SingularAttribute<? super Person,?>> ids = personType.getIdClassAttributes();
 		assertNotNull( ids );
 		assertEquals( 2, ids.size() );
 		for (SingularAttribute<? super Person,?> localId : ids) {
 			assertTrue( localId.isId() );
 			assertSame( personType, localId.getDeclaringType() );
 			assertSame( localId, personType.getDeclaredAttribute( localId.getName() ) );
 			assertSame( localId, personType.getDeclaredSingularAttribute( localId.getName() ) );
 			assertSame( localId, personType.getAttribute( localId.getName() ) );
 			assertSame( localId, personType.getSingularAttribute( localId.getName() ) );
 			assertTrue( personType.getAttributes().contains( localId ) );
 		}
 
 		final EntityType<Giant> giantType = entityManagerFactory().getMetamodel().entity( Giant.class );
 		assertEquals( "HomoGigantus", giantType.getName() );
 		assertFalse( giantType.hasSingleIdAttribute() );
 		final Set<SingularAttribute<? super Giant,?>> giantIds = giantType.getIdClassAttributes();
 		assertNotNull( giantIds );
 		assertEquals( 2, giantIds.size() );
 		assertEquals( personType.getIdClassAttributes(), giantIds );
 		for (SingularAttribute<? super Giant,?> localGiantId : giantIds) {
 			assertTrue( localGiantId.isId() );
 			try {
 				giantType.getDeclaredAttribute( localGiantId.getName() );
 				fail( localGiantId.getName() + " is a declared attribute, but shouldn't be");
 			}
 			catch ( IllegalArgumentException ex) {
 				// expected
 			}
 			try {
 				giantType.getDeclaredSingularAttribute( localGiantId.getName() );
 				fail( localGiantId.getName() + " is a declared singular attribute, but shouldn't be");
 			}
 			catch ( IllegalArgumentException ex) {
 				// expected
 			}
 			assertSame( localGiantId, giantType.getAttribute( localGiantId.getName() ) );
 			assertTrue( giantType.getAttributes().contains( localGiantId ) );
 		}
 
 		final EntityType<FoodItem> foodType = entityManagerFactory().getMetamodel().entity( FoodItem.class );
 		assertTrue( foodType.hasVersionAttribute() );
 		final SingularAttribute<? super FoodItem, Long> version = foodType.getVersion( Long.class );
 		assertNotNull( version );
 		assertTrue( version.isVersion() );
 		assertEquals( 3, foodType.getDeclaredAttributes().size() );
 
 	}
 
 	@Test
 	public void testBasic() throws Exception {
 		final EntityType<Fridge> entityType = entityManagerFactory().getMetamodel().entity( Fridge.class );
 		final SingularAttribute<? super Fridge,Integer> singularAttribute = entityType.getDeclaredSingularAttribute(
 				"temperature",
 				Integer.class
 		);
 //		assertEquals( Integer.class, singularAttribute.getBindableJavaType() );
 //		assertEquals( Integer.class, singularAttribute.getType().getJavaType() );
 		assertEquals( int.class, singularAttribute.getBindableJavaType() );
 		assertEquals( int.class, singularAttribute.getType().getJavaType() );
 		assertEquals( Bindable.BindableType.SINGULAR_ATTRIBUTE, singularAttribute.getBindableType() );
 		assertFalse( singularAttribute.isId() );
 		assertFalse( singularAttribute.isOptional() );
 		assertFalse( entityType.getDeclaredSingularAttribute( "brand", String.class ).isOptional() );
 		assertEquals( Type.PersistenceType.BASIC, singularAttribute.getType().getPersistenceType() );
 		final Attribute<? super Fridge, ?> attribute = entityType.getDeclaredAttribute( "temperature" );
 		assertNotNull( attribute );
 		assertEquals( "temperature", attribute.getName() );
 		assertEquals( Fridge.class, attribute.getDeclaringType().getJavaType() );
 		assertEquals( Attribute.PersistentAttributeType.BASIC, attribute.getPersistentAttributeType() );
 //		assertEquals( Integer.class, attribute.getJavaType() );
 		assertEquals( int.class, attribute.getJavaType() );
 		assertFalse( attribute.isAssociation() );
 		assertFalse( attribute.isCollection() );
 
 		boolean found = false;
 		for (Attribute<Fridge, ?> attr : entityType.getDeclaredAttributes() ) {
 			if ("temperature".equals( attr.getName() ) ) {
 				found = true;
 				break;
 			}
 		}
 		assertTrue( found );
 	}
 
 	@Test
 	public void testEmbeddable() throws Exception {
 		final EntityType<House> entityType = entityManagerFactory().getMetamodel().entity( House.class );
 		final SingularAttribute<? super House,Address> address = entityType.getDeclaredSingularAttribute(
 				"address",
 				Address.class
 		);
 		assertNotNull( address );
 		assertEquals( Attribute.PersistentAttributeType.EMBEDDED, address.getPersistentAttributeType() );
 		assertFalse( address.isCollection() );
 		assertFalse( address.isAssociation() );
 		final EmbeddableType<Address> addressType = (EmbeddableType<Address>) address.getType();
 		assertEquals( Type.PersistenceType.EMBEDDABLE, addressType.getPersistenceType() );
 		assertEquals( 3, addressType.getDeclaredAttributes().size() );
 		assertTrue( addressType.getDeclaredSingularAttribute( "address1" ).isOptional() );
 		assertFalse( addressType.getDeclaredSingularAttribute( "address2" ).isOptional() );
 
 		final EmbeddableType<Address> directType = entityManagerFactory().getMetamodel().embeddable( Address.class );
 		assertNotNull( directType );
 		assertEquals( Type.PersistenceType.EMBEDDABLE, directType.getPersistenceType() );
 	}
 
 	@Test
 	public void testCollection() throws Exception {
 		final EntityType<Garden> entiytype = entityManagerFactory().getMetamodel().entity( Garden.class );
 		final Set<PluralAttribute<? super Garden, ?, ?>> attributes = entiytype.getPluralAttributes();
 		assertEquals( 1, attributes.size() );
 		PluralAttribute<? super Garden, ?, ?> flowers = attributes.iterator().next();
 		assertTrue( flowers instanceof ListAttribute );
 	}
 
 	@Test
 	public void testElementCollection() throws Exception {
 		final EntityType<House> entityType = entityManagerFactory().getMetamodel().entity( House.class );
 		final SetAttribute<House,Room> rooms = entityType.getDeclaredSet( "rooms", Room.class );
 		assertNotNull( rooms );
 		assertTrue( rooms.isAssociation() );
 		assertTrue( rooms.isCollection() );
 		assertEquals( Attribute.PersistentAttributeType.ELEMENT_COLLECTION, rooms.getPersistentAttributeType() );
 		assertEquals( Room.class, rooms.getBindableJavaType() );
 		assertEquals( Bindable.BindableType.PLURAL_ATTRIBUTE, rooms.getBindableType() );
 		assertEquals( Set.class, rooms.getJavaType() );
 		assertEquals( PluralAttribute.CollectionType.SET, rooms.getCollectionType() );
 		assertEquals( 3, entityType.getDeclaredPluralAttributes().size() );
 		assertEquals( Type.PersistenceType.EMBEDDABLE, rooms.getElementType().getPersistenceType() );
 
 		final MapAttribute<House,String,Room> roomsByName = entityType.getDeclaredMap(
 				"roomsByName", String.class, Room.class
 		);
 		assertNotNull( roomsByName );
 		assertEquals( String.class, roomsByName.getKeyJavaType() );
 		assertEquals( Type.PersistenceType.BASIC, roomsByName.getKeyType().getPersistenceType() );
 		assertEquals( PluralAttribute.CollectionType.MAP, roomsByName.getCollectionType() );
 
 		final ListAttribute<House,Room> roomsBySize = entityType.getDeclaredList( "roomsBySize", Room.class );
 		assertNotNull( roomsBySize );
 		assertEquals( Type.PersistenceType.EMBEDDABLE, roomsBySize.getElementType().getPersistenceType() );
 		assertEquals( PluralAttribute.CollectionType.LIST, roomsBySize.getCollectionType() );
 	}
 
 	@Test
 	public void testHierarchy() {
 		final EntityType<Cat> cat = entityManagerFactory().getMetamodel().entity( Cat.class );
 		assertNotNull( cat );
 		assertEquals( 7, cat.getAttributes().size() );
 		assertEquals( 1, cat.getDeclaredAttributes().size() );
 		ensureProperMember(cat.getDeclaredAttributes());
 
 		assertTrue( cat.hasVersionAttribute() );
 		assertEquals( "version", cat.getVersion(Long.class).getName() );
 		verifyDeclaredVersionNotPresent( cat );
 		verifyDeclaredIdNotPresentAndIdPresent(cat);
 
 		assertEquals( Type.PersistenceType.MAPPED_SUPERCLASS, cat.getSupertype().getPersistenceType() );
 		MappedSuperclassType<Cattish> cattish = (MappedSuperclassType<Cattish>) cat.getSupertype();
 		assertEquals( 6, cattish.getAttributes().size() );
 		assertEquals( 1, cattish.getDeclaredAttributes().size() );
 		ensureProperMember(cattish.getDeclaredAttributes());
 
 		assertTrue( cattish.hasVersionAttribute() );
 		assertEquals( "version", cattish.getVersion(Long.class).getName() );
 		verifyDeclaredVersionNotPresent( cattish );
 		verifyDeclaredIdNotPresentAndIdPresent(cattish);
 
 		assertEquals( Type.PersistenceType.ENTITY, cattish.getSupertype().getPersistenceType() );
 		EntityType<Feline> feline = (EntityType<Feline>) cattish.getSupertype();
 		assertEquals( 5, feline.getAttributes().size() );
 		assertEquals( 1, feline.getDeclaredAttributes().size() );
 		ensureProperMember(feline.getDeclaredAttributes());
 
 		assertTrue( feline.hasVersionAttribute() );
 		assertEquals( "version", feline.getVersion(Long.class).getName() );
 		verifyDeclaredVersionNotPresent( feline );
 		verifyDeclaredIdNotPresentAndIdPresent(feline);
 
 		assertEquals( Type.PersistenceType.MAPPED_SUPERCLASS, feline.getSupertype().getPersistenceType() );
 		MappedSuperclassType<Animal> animal = (MappedSuperclassType<Animal>) feline.getSupertype();
 		assertEquals( 4, animal.getAttributes().size() );
 		assertEquals( 2, animal.getDeclaredAttributes().size() );
 		ensureProperMember(animal.getDeclaredAttributes());
 
 		assertTrue( animal.hasVersionAttribute() );
 		assertEquals( "version", animal.getVersion(Long.class).getName() );
 		verifyDeclaredVersionNotPresent( animal );
 		assertEquals( "id", animal.getId(Long.class).getName() );
 		final SingularAttribute<Animal, Long> id = animal.getDeclaredId( Long.class );
 		assertEquals( "id", id.getName() );
 		assertNotNull( id.getJavaMember() );
 
 		assertEquals( Type.PersistenceType.MAPPED_SUPERCLASS, animal.getSupertype().getPersistenceType() );
 		MappedSuperclassType<Thing> thing = (MappedSuperclassType<Thing>) animal.getSupertype();
 		assertEquals( 2, thing.getAttributes().size() );
 		assertEquals( 2, thing.getDeclaredAttributes().size() );
 		ensureProperMember(thing.getDeclaredAttributes());
 		final SingularAttribute<Thing, Double> weight = thing.getDeclaredSingularAttribute( "weight", Double.class );
 		assertEquals( Double.class, weight.getJavaType() );
 
 		assertEquals( "version", thing.getVersion(Long.class).getName() );
 		final SingularAttribute<Thing, Long> version = thing.getDeclaredVersion( Long.class );
 		assertEquals( "version", version.getName() );
 		assertNotNull( version.getJavaMember() );
 		assertNull( thing.getId( Long.class ) );
 
 		assertNull( thing.getSupertype() );
 	}
 
 	@Test
 	public void testBackrefAndGenerics() throws Exception {
 		final EntityType<Parent> parent = entityManagerFactory().getMetamodel().entity( Parent.class );
 		assertNotNull( parent );
 		final SetAttribute<? super Parent, ?> children = parent.getSet( "children" );
 		assertNotNull( children );
 		assertEquals( 1, parent.getPluralAttributes().size() );
 		assertEquals( 4, parent.getAttributes().size() );
 		final EntityType<Child> child = entityManagerFactory().getMetamodel().entity( Child.class );
 		assertNotNull( child );
 		assertEquals( 2, child.getAttributes().size() );
 		final SingularAttribute<? super Parent, Parent.Relatives> attribute = parent.getSingularAttribute(
 				"siblings", Parent.Relatives.class
 		);
 		final EmbeddableType<Parent.Relatives> siblings = (EmbeddableType<Parent.Relatives>) attribute.getType();
 		assertNotNull(siblings);
 		final SetAttribute<? super Parent.Relatives, ?> siblingsCollection = siblings.getSet( "siblings" );
 		assertNotNull( siblingsCollection );
 		final Type<?> collectionElement = siblingsCollection.getElementType();
 		assertNotNull( collectionElement );
 		assertEquals( collectionElement, child );
 	}
 
 	private void ensureProperMember(Set<?> attributes) {
 		//we do not update the set so we are safe
 		@SuppressWarnings( "unchecked" )
 		final Set<Attribute<?, ?>> safeAttributes = ( Set<Attribute<?, ?>> ) attributes;
 		for (Attribute<?,?> attribute : safeAttributes ) {
 			final String name = attribute.getJavaMember().getName();
 			assertNotNull( attribute.getJavaMember() );
-			assertTrue( name.toLowerCase().endsWith( attribute.getName().toLowerCase() ) );
+			assertTrue( name.toLowerCase(Locale.ROOT).endsWith( attribute.getName().toLowerCase(Locale.ROOT) ) );
 		}
 	}
 
 	private void verifyDeclaredIdNotPresentAndIdPresent(IdentifiableType<?> type) {
 		assertEquals( "id", type.getId(Long.class).getName() );
 		try {
 			type.getDeclaredId(Long.class);
 			fail("Should not have a declared id");
 		}
 		catch (IllegalArgumentException e) {
 			//success
 		}
 	}
 
 	private void verifyDeclaredVersionNotPresent(IdentifiableType<?> type) {
 		try {
 			type.getDeclaredVersion(Long.class);
 			fail("Should not have a declared version");
 		}
 		catch (IllegalArgumentException e) {
 			//success
 		}
 	}
 
 	//todo test plural
 
 	@Override
 	public Class[] getAnnotatedClasses() {
 		return new Class[]{
 				Fridge.class,
 				FoodItem.class,
 				Person.class,
 				Giant.class,
 				House.class,
 				Dog.class,
 				Cat.class,
 				Cattish.class,
 				Feline.class,
 				Garden.class,
 				Flower.class,
 				JoinedManyToOneOwner.class,
 				Parent.class,
 				Child.class
 		};
 	}
 
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/IlikeAuditExpression.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/IlikeAuditExpression.java
index a188e1f14b..0583d185fa 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/IlikeAuditExpression.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/IlikeAuditExpression.java
@@ -1,36 +1,37 @@
 package org.hibernate.envers.query.criteria.internal;
 
+import java.util.Locale;
 import org.hibernate.envers.boot.internal.EnversService;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.envers.query.criteria.AuditCriterion;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 
 public class IlikeAuditExpression implements AuditCriterion {
 
 	private PropertyNameGetter propertyNameGetter;
 	private String value;
 
 	public IlikeAuditExpression(PropertyNameGetter propertyNameGetter, String value) {
 		this.propertyNameGetter = propertyNameGetter;
 		this.value = value;
 	}
 
 	public void addToQuery(
 			EnversService enversService,
 			AuditReaderImplementor versionsReader, String entityName,
 			QueryBuilder qb, Parameters parameters) {
 
 		String propertyName = CriteriaTools.determinePropertyName(
 				enversService,
 				versionsReader,
 				entityName,
 				propertyNameGetter
 		);
 		CriteriaTools.checkPropertyNotARelation( enversService, entityName, propertyName );
 
-		parameters.addWhereWithFunction( propertyName, " lower ", " like ", value.toLowerCase() );
+		parameters.addWhereWithFunction( propertyName, " lower ", " like ", value.toLowerCase(Locale.ROOT) );
 	}
 
 }
diff --git a/tooling/metamodel-generator/src/main/java/org/hibernate/jpamodelgen/util/StringUtil.java b/tooling/metamodel-generator/src/main/java/org/hibernate/jpamodelgen/util/StringUtil.java
index 6eaaf2c586..dad3f40c15 100644
--- a/tooling/metamodel-generator/src/main/java/org/hibernate/jpamodelgen/util/StringUtil.java
+++ b/tooling/metamodel-generator/src/main/java/org/hibernate/jpamodelgen/util/StringUtil.java
@@ -1,118 +1,120 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat, Inc. and/or its affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpamodelgen.util;
 
+import java.util.Locale;
+
 /**
  * @author Hardy Ferentschik
  */
 public final class StringUtil {
 	private static final String NAME_SEPARATOR = ".";
 	private static final String PROPERTY_PREFIX_GET = "get";
 	private static final String PROPERTY_PREFIX_IS = "is";
 	private static final String PROPERTY_PREFIX_HAS = "has";
 
 	private StringUtil() {
 	}
 
 	public static String determineFullyQualifiedClassName(String defaultPackage, String name) {
 		if ( isFullyQualified( name ) ) {
 			return name;
 		}
 		else {
 			return defaultPackage + NAME_SEPARATOR + name;
 		}
 	}
 
 	public static boolean isFullyQualified(String name) {
 		return name.contains( NAME_SEPARATOR );
 	}
 
 	public static String packageNameFromFqcn(String fqcn) {
 		return fqcn.substring( 0, fqcn.lastIndexOf( NAME_SEPARATOR ) );
 	}
 
 	public static String classNameFromFqcn(String fqcn) {
 		return fqcn.substring( fqcn.lastIndexOf( NAME_SEPARATOR ) + 1 );
 	}
 
 	public static boolean isProperty(String methodName, String returnTypeAsString) {
 		if ( methodName == null || "void".equals( returnTypeAsString ) ) {
 			return false;
 		}
 
 		if ( isValidPropertyName( methodName, PROPERTY_PREFIX_GET ) ) {
 			return true;
 		}
 
 		if ( isValidPropertyName( methodName, PROPERTY_PREFIX_IS ) || isValidPropertyName( methodName, PROPERTY_PREFIX_HAS ) ) {
 			return isBooleanGetter( returnTypeAsString );
 		}
 
 		return false;
 	}
 
 	private static boolean isBooleanGetter(String type) {
 		return "Boolean".equals( type ) || "java.lang.Boolean".equals( type );
 	}
 
 	private static boolean isValidPropertyName(String name, String prefix) {
 		if ( !name.startsWith( prefix ) ) {
 			return false;
 		}
 
 		// the name has to start with the prefix and have at least one more character
 		return name.length() >= prefix.length() + 1;
 	}
 
 	public static String getPropertyName(String name) {
 		String tmp = name;
 		if ( name.startsWith( PROPERTY_PREFIX_GET ) ) {
 			tmp = name.replaceFirst( PROPERTY_PREFIX_GET, "" );
 		}
 		else if ( name.startsWith( PROPERTY_PREFIX_IS ) ) {
 			tmp = name.replaceFirst( PROPERTY_PREFIX_IS, "" );
 		}
 		else if ( name.startsWith( PROPERTY_PREFIX_HAS ) ) {
 			tmp = name.replaceFirst( PROPERTY_PREFIX_HAS, "" );
 		}
 		return decapitalize( tmp );
 	}
 
 	public static String decapitalize(String string) {
 		if ( string == null || string.isEmpty() || startsWithSeveralUpperCaseLetters( string ) ) {
 			return string;
 		}
 		else {
-			return string.substring( 0, 1 ).toLowerCase() + string.substring( 1 );
+			return string.substring( 0, 1 ).toLowerCase(Locale.ROOT) + string.substring( 1 );
 		}
 	}
 
 	private static boolean startsWithSeveralUpperCaseLetters(String string) {
 		return string.length() > 1 &&
 				Character.isUpperCase( string.charAt( 0 ) ) &&
 				Character.isUpperCase( string.charAt( 1 ) );
 	}
 }
 
 
