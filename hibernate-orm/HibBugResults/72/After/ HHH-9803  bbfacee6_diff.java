diff --git a/hibernate-core/src/main/java/org/hibernate/Interceptor.java b/hibernate-core/src/main/java/org/hibernate/Interceptor.java
index 864fb91e5c..8a227bd2ed 100644
--- a/hibernate-core/src/main/java/org/hibernate/Interceptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/Interceptor.java
@@ -1,282 +1,293 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
 import java.io.Serializable;
 import java.util.Iterator;
 
-import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.type.Type;
 
 /**
  * Allows user code to inspect and/or change property values.
  *
  * Inspection occurs before property values are written and after they are read
  * from the database.
  *
  * There might be a single instance of <tt>Interceptor</tt> for a <tt>SessionFactory</tt>, or a new instance
  * might be specified for each <tt>Session</tt>. Whichever approach is used, the interceptor must be
  * serializable if the <tt>Session</tt> is to be serializable. This means that <tt>SessionFactory</tt>-scoped
  * interceptors should implement <tt>readResolve()</tt>.
  *
  * The <tt>Session</tt> may not be invoked from a callback (nor may a callback cause a collection or proxy to
  * be lazily initialized).
  *
  * Instead of implementing this interface directly, it is usually better to extend <tt>EmptyInterceptor</tt>
  * and override only the callback methods of interest.
  *
  * @see SessionBuilder#interceptor(Interceptor)
  * @see SharedSessionBuilder#interceptor()
  * @see org.hibernate.cfg.Configuration#setInterceptor(Interceptor)
  * @see EmptyInterceptor
  *
  * @author Gavin King
  */
 public interface Interceptor {
 	/**
 	 * Called just before an object is initialized. The interceptor may change the <tt>state</tt>, which will
 	 * be propagated to the persistent object. Note that when this method is called, <tt>entity</tt> will be
 	 * an empty uninitialized instance of the class.
 	 * <p/>
 	 * NOTE: The indexes across the <tt>state</tt>, <tt>propertyNames</tt> and <tt>types</tt> arrays match.
 	 *
 	 * @param entity The entity instance being loaded
 	 * @param id The identifier value being loaded
 	 * @param state The entity state (which will be pushed into the entity instance)
 	 * @param propertyNames The names of the entity properties, corresponding to the <tt>state</tt>.
 	 * @param types The types of the entity properties, corresponding to the <tt>state</tt>.
 	 *
 	 * @return {@code true} if the user modified the <tt>state</tt> in any way.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public boolean onLoad(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
+	boolean onLoad(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
 
 	/**
 	 * Called when an object is detected to be dirty, during a flush. The interceptor may modify the detected
 	 * <tt>currentState</tt>, which will be propagated to both the database and the persistent object.
 	 * Note that not all flushes end in actual synchronization with the database, in which case the
 	 * new <tt>currentState</tt> will be propagated to the object, but not necessarily (immediately) to
 	 * the database. It is strongly recommended that the interceptor <b>not</b> modify the <tt>previousState</tt>.
 	 * <p/>
 	 * NOTE: The indexes across the <tt>currentState</tt>, <tt>previousState</tt>, <tt>propertyNames</tt> and
 	 * <tt>types</tt> arrays match.
 	 *
 	 * @param entity The entity instance detected as being dirty and being flushed
 	 * @param id The identifier of the entity
 	 * @param currentState The entity's current state
 	 * @param previousState The entity's previous (load time) state.
 	 * @param propertyNames The names of the entity properties
 	 * @param types The types of the entity properties
 	 *
 	 * @return {@code true} if the user modified the <tt>currentState</tt> in any way.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public boolean onFlushDirty(Object entity, Serializable id, Object[] currentState, Object[] previousState, String[] propertyNames, Type[] types) throws CallbackException;
+	boolean onFlushDirty(
+			Object entity,
+			Serializable id,
+			Object[] currentState,
+			Object[] previousState,
+			String[] propertyNames,
+			Type[] types) throws CallbackException;
 
 	/**
 	 * Called before an object is saved. The interceptor may modify the <tt>state</tt>, which will be used for
 	 * the SQL <tt>INSERT</tt> and propagated to the persistent object.
 	 *
 	 * @param entity The entity instance whose state is being inserted
 	 * @param id The identifier of the entity
 	 * @param state The state of the entity which will be inserted
 	 * @param propertyNames The names of the entity properties.
 	 * @param types The types of the entity properties
 	 *
 	 * @return <tt>true</tt> if the user modified the <tt>state</tt> in any way.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public boolean onSave(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
+	boolean onSave(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
 
 	/**
 	 *  Called before an object is deleted. It is not recommended that the interceptor modify the <tt>state</tt>.
 	 *
 	 * @param entity The entity instance being deleted
 	 * @param id The identifier of the entity
 	 * @param state The state of the entity
 	 * @param propertyNames The names of the entity properties.
 	 * @param types The types of the entity properties
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public void onDelete(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
+	void onDelete(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
 
 	/**
 	 * Called before a collection is (re)created.
 	 *
 	 * @param collection The collection instance.
 	 * @param key The collection key value.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public void onCollectionRecreate(Object collection, Serializable key) throws CallbackException;
+	void onCollectionRecreate(Object collection, Serializable key) throws CallbackException;
 
 	/**
 	 * Called before a collection is deleted.
 	 *
 	 * @param collection The collection instance.
 	 * @param key The collection key value.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public void onCollectionRemove(Object collection, Serializable key) throws CallbackException;
+	void onCollectionRemove(Object collection, Serializable key) throws CallbackException;
 
 	/**
 	 * Called before a collection is updated.
 	 *
 	 * @param collection The collection instance.
 	 * @param key The collection key value.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public void onCollectionUpdate(Object collection, Serializable key) throws CallbackException;
+	void onCollectionUpdate(Object collection, Serializable key) throws CallbackException;
 
 	/**
 	 * Called before a flush.
 	 *
 	 * @param entities The entities to be flushed.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public void preFlush(Iterator entities) throws CallbackException;
+	void preFlush(Iterator entities) throws CallbackException;
 
 	/**
 	 * Called after a flush that actually ends in execution of the SQL statements required to synchronize
 	 * in-memory state with the database.
 	 *
 	 * @param entities The entities that were flushed.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public void postFlush(Iterator entities) throws CallbackException;
+	void postFlush(Iterator entities) throws CallbackException;
 
 	/**
 	 * Called to distinguish between transient and detached entities. The return value determines the
 	 * state of the entity with respect to the current session.
 	 * <ul>
 	 * <li><tt>Boolean.TRUE</tt> - the entity is transient
 	 * <li><tt>Boolean.FALSE</tt> - the entity is detached
 	 * <li><tt>null</tt> - Hibernate uses the <tt>unsaved-value</tt> mapping and other heuristics to 
 	 * determine if the object is unsaved
 	 * </ul>
 	 * @param entity a transient or detached entity
 	 * @return Boolean or <tt>null</tt> to choose default behaviour
 	 */
-	public Boolean isTransient(Object entity);
+	Boolean isTransient(Object entity);
 
 	/**
 	 * Called from <tt>flush()</tt>. The return value determines whether the entity is updated
 	 * <ul>
 	 * <li>an array of property indices - the entity is dirty
 	 * <li>an empty array - the entity is not dirty
 	 * <li><tt>null</tt> - use Hibernate's default dirty-checking algorithm
 	 * </ul>
 	 *
 	 * @param entity The entity for which to find dirty properties.
 	 * @param id The identifier of the entity
 	 * @param currentState The current entity state as taken from the entity instance
 	 * @param previousState The state of the entity when it was last synchronized (generally when it was loaded)
 	 * @param propertyNames The names of the entity properties.
 	 * @param types The types of the entity properties
 	 *
 	 * @return array of dirty property indices or {@code null} to indicate Hibernate should perform default behaviour
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public int[] findDirty(Object entity, Serializable id, Object[] currentState, Object[] previousState, String[] propertyNames, Type[] types);
+	int[] findDirty(
+			Object entity,
+			Serializable id,
+			Object[] currentState,
+			Object[] previousState,
+			String[] propertyNames,
+			Type[] types);
 	/**
 	 * Instantiate the entity class. Return <tt>null</tt> to indicate that Hibernate should use
 	 * the default constructor of the class. The identifier property of the returned instance
 	 * should be initialized with the given identifier.
 	 *
 	 * @param entityName the name of the entity
 	 * @param entityMode The type of entity instance to be returned.
 	 * @param id the identifier of the new instance
 	 *
 	 * @return an instance of the class, or <tt>null</tt> to choose default behaviour
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public Object instantiate(String entityName, EntityMode entityMode, Serializable id) throws CallbackException;
+	Object instantiate(String entityName, EntityMode entityMode, Serializable id) throws CallbackException;
 
 	/**
 	 * Get the entity name for a persistent or transient instance.
 	 *
 	 * @param object an entity instance
 	 *
 	 * @return the name of the entity
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public String getEntityName(Object object) throws CallbackException;
+	String getEntityName(Object object) throws CallbackException;
 
 	/**
 	 * Get a fully loaded entity instance that is cached externally.
 	 *
 	 * @param entityName the name of the entity
 	 * @param id the instance identifier
 	 *
 	 * @return a fully initialized entity
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
-	public Object getEntity(String entityName, Serializable id) throws CallbackException;
+	Object getEntity(String entityName, Serializable id) throws CallbackException;
 	
 	/**
 	 * Called when a Hibernate transaction is begun via the Hibernate <tt>Transaction</tt> 
 	 * API. Will not be called if transactions are being controlled via some other 
 	 * mechanism (CMT, for example).
 	 *
 	 * @param tx The Hibernate transaction facade object
 	 */
-	public void afterTransactionBegin(Transaction tx);
+	void afterTransactionBegin(Transaction tx);
 
 	/**
 	 * Called before a transaction is committed (but not before rollback).
 	 *
 	 * @param tx The Hibernate transaction facade object
 	 */
-	public void beforeTransactionCompletion(Transaction tx);
+	void beforeTransactionCompletion(Transaction tx);
 
 	/**
 	 * Called after a transaction is committed or rolled back.
 	 *
 	 * @param tx The Hibernate transaction facade object
 	 */
-	public void afterTransactionCompletion(Transaction tx);
+	void afterTransactionCompletion(Transaction tx);
 
 	/**
 	 * Called when sql string is being prepared. 
 	 * @param sql sql to be prepared
 	 * @return original or modified sql
 	 *
 	 * @deprecated Supply a {@link org.hibernate.resource.jdbc.spi.StatementInspector} instead, if you wish
 	 * to inspect and alter SQL statements.
 	 */
 	@Deprecated
-	public String onPrepareStatement(String sql);
+	String onPrepareStatement(String sql);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/Transaction.java b/hibernate-core/src/main/java/org/hibernate/Transaction.java
index c01a80b9b4..a072189682 100644
--- a/hibernate-core/src/main/java/org/hibernate/Transaction.java
+++ b/hibernate-core/src/main/java/org/hibernate/Transaction.java
@@ -1,122 +1,120 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
 import javax.transaction.Synchronization;
 
-import org.hibernate.engine.transaction.spi.IsolationDelegate;
-import org.hibernate.engine.transaction.spi.LocalStatus;
 import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 /**
  * Defines the contract for abstracting applications from the configured underlying means of transaction management.
  * Allows the application to define units of work, while maintaining abstraction from the underlying transaction
  * implementation (eg. JTA, JDBC).
  * <p/>
  * A transaction is associated with a {@link Session} and is usually initiated by a call to
  * {@link org.hibernate.Session#beginTransaction()}.  A single session might span multiple transactions since
  * the notion of a session (a conversation between the application and the datastore) is of coarser granularity than
  * the notion of a transaction.  However, it is intended that there be at most one uncommitted transaction associated
  * with a particular {@link Session} at any time.
  * <p/>
  * Implementers are not intended to be thread-safe.
  *
  * @author Anton van Straaten
  * @author Steve Ebersole
  */
 public interface Transaction {
 
 	/**
 	 * Begin this transaction.  No-op if the transaction has already been begun.  Note that this is not necessarily
 	 * symmetrical since usually multiple calls to {@link #commit} or {@link #rollback} will error.
 	 *
 	 * @throws HibernateException Indicates a problem beginning the transaction.
 	 */
-	public void begin();
+	void begin();
 
 	/**
 	 * Commit this transaction.  This might entail a number of things depending on the context:<ul>
 	 *     <li>
-	 *         If this transaction is the {@link #isInitiator initiator}, {@link Session#flush} the {@link Session}
-	 *         with which it is associated (unless {@link Session} is in {@link FlushMode#MANUAL}).
+	 *         If the underlying transaction was initiated from this Transaction the Session will be flushed,
+	 *         unless the Session is in {@link FlushMode#MANUAL} FlushMode.
 	 *     </li>
 	 *     <li>
-	 *         If this transaction is the {@link #isInitiator initiator}, commit the underlying transaction.
+	 *         If the underlying transaction was initiated from this Transaction, commit the underlying transaction.
 	 *     </li>
 	 *     <li>
 	 *         Coordinate various callbacks
 	 *     </li>
 	 * </ul>
 	 *
 	 * @throws HibernateException Indicates a problem committing the transaction.
 	 */
-	public void commit();
+	void commit();
 
 	/**
 	 * Rollback this transaction.  Either rolls back the underlying transaction or ensures it cannot later commit
 	 * (depending on the actual underlying strategy).
 	 *
 	 * @throws HibernateException Indicates a problem rolling back the transaction.
 	 */
-	public void rollback();
+	void rollback();
 
 	/**
 	 * Get the current local status of this transaction.
 	 * <p/>
 	 * This only accounts for the local view of the transaction status.  In other words it does not check the status
 	 * of the actual underlying transaction.
 	 *
 	 * @return The current local status.
 	 */
-	public TransactionStatus getStatus();
+	TransactionStatus getStatus();
 
 	/**
 	 * Register a user synchronization callback for this transaction.
 	 *
 	 * @param synchronization The Synchronization callback to register.
 	 *
 	 * @throws HibernateException Indicates a problem registering the synchronization.
 	 */
-	public void registerSynchronization(Synchronization synchronization) throws HibernateException;
+	void registerSynchronization(Synchronization synchronization) throws HibernateException;
 
 	/**
 	 * Set the transaction timeout for any transaction started by a subsequent call to {@link #begin} on this instance.
 	 *
 	 * @param seconds The number of seconds before a timeout.
 	 */
-	public void setTimeout(int seconds);
+	void setTimeout(int seconds);
 
 	/**
 	 * Retrieve the transaction timeout set for this transaction.  A negative indicates no timeout has been set.
 	 *
 	 * @return The timeout, in seconds.
 	 */
-	public int getTimeout();
+	int getTimeout();
 
 	/**
 	 * Make a best effort to mark the underlying transaction for rollback only.
 	 */
-	public void markRollbackOnly();
+	void markRollbackOnly();
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/SchemaAutoTooling.java b/hibernate-core/src/main/java/org/hibernate/boot/SchemaAutoTooling.java
index b5a5d10844..fd715748e7 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/SchemaAutoTooling.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/SchemaAutoTooling.java
@@ -1,77 +1,82 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot;
 
-import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * Defines the possible values for "hbm2ddl_auto"
  *
  * @author Steve Ebersole
  */
 public enum SchemaAutoTooling {
 	/**
 	 * Drop the schema and recreate it on SessionFactory startup.
 	 */
-	CREATE,
+	CREATE( "create" ),
 	/**
 	 * Drop the schema and recreate it on SessionFactory startup.  Additionally, drop the
 	 * schema on SessionFactory shutdown.
 	 */
-	CREATE_DROP,
+	CREATE_DROP( "create-drop" ),
 	/**
 	 * Update (alter) the schema on SessionFactory startup.
 	 */
-	UPDATE,
+	UPDATE( "update" ),
 	/**
 	 * Validate the schema on SessionFactory startup.
 	 */
-	VALIDATE;
+	VALIDATE( "validate" );
+
+	private final String externalForm;
+
+	SchemaAutoTooling(String externalForm) {
+		this.externalForm = externalForm;
+	}
 
 	public static SchemaAutoTooling interpret(String configurationValue) {
 		if ( StringHelper.isEmpty( configurationValue ) ) {
 			return null;
 		}
-		else if ( "validate".equals( configurationValue ) ) {
+		else if ( VALIDATE.externalForm.equals( configurationValue ) ) {
 			return VALIDATE;
 		}
-		else if ( "update".equals( configurationValue ) ) {
+		else if ( UPDATE.externalForm.equals( configurationValue ) ) {
 			return UPDATE;
 		}
-		else if ( "create".equals( configurationValue ) ) {
+		else if ( CREATE.externalForm.equals( configurationValue ) ) {
 			return CREATE;
 		}
-		else if ( "create-drop".equals( configurationValue ) ) {
+		else if ( CREATE_DROP.externalForm.equals( configurationValue ) ) {
 			return CREATE_DROP;
 		}
 		else {
 			throw new HibernateException(
 					"Unrecognized hbm2ddl_auto value : " + configurationValue
 							+ ".  Supported values include create, create-drop, update, and validate."
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/archive/scan/internal/ScanResultCollector.java b/hibernate-core/src/main/java/org/hibernate/boot/archive/scan/internal/ScanResultCollector.java
index 733be9f054..7b8b071589 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/archive/scan/internal/ScanResultCollector.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/archive/scan/internal/ScanResultCollector.java
@@ -1,171 +1,170 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.archive.scan.internal;
 
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
 
 import org.hibernate.boot.archive.scan.spi.ClassDescriptor;
 import org.hibernate.boot.archive.scan.spi.MappingFileDescriptor;
 import org.hibernate.boot.archive.scan.spi.PackageDescriptor;
 import org.hibernate.boot.archive.scan.spi.ScanEnvironment;
 import org.hibernate.boot.archive.scan.spi.ScanOptions;
 import org.hibernate.boot.archive.scan.spi.ScanParameters;
 import org.hibernate.boot.archive.scan.spi.ScanResult;
 
-import org.jboss.jandex.ClassInfo;
 import org.jboss.logging.Logger;
 
 /**
  * @author Steve Ebersole
  */
 public class ScanResultCollector {
 	private static final Logger log = Logger.getLogger( ScanResultCollector.class );
 
 	private final ScanEnvironment environment;
 	private final ScanOptions options;
 
 	private final ScanParameters scanParameters;
 
 	private final Set<ClassDescriptor> discoveredClasses;
 	private final Set<PackageDescriptor> discoveredPackages;
 	private final Set<MappingFileDescriptor> discoveredMappingFiles;
 
 	public ScanResultCollector(ScanEnvironment environment, ScanOptions options, ScanParameters parameters) {
 		this.environment = environment;
 		this.options = options;
 
 		this.scanParameters = parameters;
 
 		if ( environment.getExplicitlyListedClassNames() == null ) {
 			throw new IllegalArgumentException( "ScanEnvironment#getExplicitlyListedClassNames should not return null" );
 		}
 
 		if ( environment.getExplicitlyListedMappingFiles() == null ) {
 			throw new IllegalArgumentException( "ScanEnvironment#getExplicitlyListedMappingFiles should not return null" );
 		}
 
 		this.discoveredPackages = new HashSet<PackageDescriptor>();
 		this.discoveredClasses = new HashSet<ClassDescriptor>();
 		this.discoveredMappingFiles = new HashSet<MappingFileDescriptor>();
 	}
 
 	public void handleClass(ClassDescriptor classDescriptor, boolean rootUrl) {
 		// see if "discovery" of this entry is allowed
 
 //		final ClassInfo classInfo = scanParameters.getJandexInitializer().handle( classDescriptor );
 //
 // 		if ( !isListedOrDetectable( classInfo.name().toString(), rootUrl ) ) {
 //			return;
 //		}
 //
 //		if ( !containsClassAnnotationsOfInterest( classInfo ) ) {
 //			// not strictly needed, but helps cut down on the size of discoveredClasses
 //			return;
 //		}
 
 		if ( !isListedOrDetectable( classDescriptor.getName(), rootUrl ) ) {
 			return;
 		}
 
 		discoveredClasses.add( classDescriptor );
 	}
 
 	@SuppressWarnings("SimplifiableIfStatement")
 	protected boolean isListedOrDetectable(String name, boolean rootUrl) {
 		// IMPL NOTE : protect the calls to getExplicitlyListedClassNames unless needed,
 		// since it can take time with lots of listed classes.
 		if ( rootUrl ) {
 			// The entry comes from the root url.  Allow it if either:
 			//		1) we are allowed to discover classes/packages in the root url
 			//		2) the entry was explicitly listed
 			return options.canDetectUnlistedClassesInRoot()
 					|| environment.getExplicitlyListedClassNames().contains( name );
 		}
 		else {
 			// The entry comes from a non-root url.  Allow it if either:
 			//		1) we are allowed to discover classes/packages in non-root urls
 			//		2) the entry was explicitly listed
 			return options.canDetectUnlistedClassesInNonRoot()
 					|| environment.getExplicitlyListedClassNames().contains( name );
 		}
 	}
 
 //	@SuppressWarnings("SimplifiableIfStatement")
 //	private boolean containsClassAnnotationsOfInterest(ClassInfo classInfo) {
 //		if ( classInfo.annotations() == null ) {
 //			return false;
 //		}
 //
 //		return classInfo.annotations().containsKey( JPADotNames.ENTITY )
 //				|| classInfo.annotations().containsKey( JPADotNames.MAPPED_SUPERCLASS )
 //				|| classInfo.annotations().containsKey( JPADotNames.EMBEDDABLE )
 //				|| classInfo.annotations().containsKey( JPADotNames.CONVERTER );
 //	}
 
 	public void handlePackage(PackageDescriptor packageDescriptor, boolean rootUrl) {
 //		final ClassInfo classInfo = scanParameters.getJandexInitializer().handle( packageDescriptor );
 
 		if ( !isListedOrDetectable( packageDescriptor.getName(), rootUrl ) ) {
 			// not strictly needed, but helps cut down on the size of discoveredPackages
 			return;
 		}
 
 		discoveredPackages.add( packageDescriptor );
 	}
 
 	public void handleMappingFile(MappingFileDescriptor mappingFileDescriptor, boolean rootUrl) {
 		if ( acceptAsMappingFile( mappingFileDescriptor, rootUrl ) ) {
 			discoveredMappingFiles.add( mappingFileDescriptor );
 		}
 	}
 
 	@SuppressWarnings("SimplifiableIfStatement")
 	private boolean acceptAsMappingFile(MappingFileDescriptor mappingFileDescriptor, boolean rootUrl) {
 		if ( mappingFileDescriptor.getName().endsWith( "hbm.xml" ) ) {
 			return options.canDetectHibernateMappingFiles();
 		}
 
 		if ( mappingFileDescriptor.getName().endsWith( "META-INF/orm.xml" ) ) {
 			if ( environment.getExplicitlyListedMappingFiles().contains( "META-INF/orm.xml" ) ) {
 				// if the user explicitly listed META-INF/orm.xml, only except the root one
 				//
 				// not sure why exactly, but this is what the old code does
 				return rootUrl;
 			}
 			return true;
 		}
 
 		return environment.getExplicitlyListedMappingFiles().contains( mappingFileDescriptor.getName() );
 	}
 
 	public ScanResult toScanResult() {
 		return new ScanResultImpl(
 				Collections.unmodifiableSet( discoveredPackages ),
 				Collections.unmodifiableSet( discoveredClasses ),
 				Collections.unmodifiableSet( discoveredMappingFiles )
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/internal/MetadataBuildingProcess.java b/hibernate-core/src/main/java/org/hibernate/boot/internal/MetadataBuildingProcess.java
index 55767f5cd6..d95cd07aab 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/internal/MetadataBuildingProcess.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/internal/MetadataBuildingProcess.java
@@ -1,530 +1,529 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.internal;
 
 import java.lang.reflect.Constructor;
 import java.util.Collection;
 import java.util.HashSet;
-import java.util.LinkedHashSet;
 import java.util.Set;
 import javax.persistence.Converter;
 
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.archive.internal.StandardArchiveDescriptorFactory;
 import org.hibernate.boot.archive.scan.internal.StandardScanner;
 import org.hibernate.boot.archive.scan.spi.ClassDescriptor;
 import org.hibernate.boot.archive.scan.spi.JandexInitializer;
 import org.hibernate.boot.archive.scan.spi.MappingFileDescriptor;
 import org.hibernate.boot.archive.scan.spi.PackageDescriptor;
 import org.hibernate.boot.archive.scan.spi.ScanParameters;
 import org.hibernate.boot.archive.scan.spi.ScanResult;
 import org.hibernate.boot.archive.scan.spi.Scanner;
 import org.hibernate.boot.archive.spi.ArchiveDescriptorFactory;
 import org.hibernate.boot.internal.DeploymentResourcesInterpreter.DeploymentResources;
 import org.hibernate.boot.internal.MetadataBuilderImpl.MetadataBuildingOptionsImpl;
 import org.hibernate.boot.jaxb.internal.MappingBinder;
 import org.hibernate.boot.model.TypeContributions;
 import org.hibernate.boot.model.TypeContributor;
 import org.hibernate.boot.model.source.internal.annotations.AnnotationMetadataSourceProcessorImpl;
 import org.hibernate.boot.model.source.internal.hbm.EntityHierarchyBuilder;
 import org.hibernate.boot.model.source.internal.hbm.EntityHierarchySourceImpl;
 import org.hibernate.boot.model.source.internal.hbm.HbmMetadataSourceProcessorImpl;
 import org.hibernate.boot.model.source.internal.hbm.MappingDocument;
 import org.hibernate.boot.model.source.internal.hbm.ModelBinder;
 import org.hibernate.boot.model.source.spi.MetadataSourceProcessor;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.boot.spi.AdditionalJaxbMappingProducer;
 import org.hibernate.boot.spi.ClassLoaderAccess;
 import org.hibernate.boot.spi.MetadataBuildingOptions;
 import org.hibernate.boot.spi.MetadataContributor;
 import org.hibernate.cfg.AttributeConverterDefinition;
 import org.hibernate.cfg.MetadataSourceType;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.type.BasicTypeRegistry;
 import org.hibernate.type.TypeFactory;
 import org.hibernate.type.TypeResolver;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
 
 import org.jboss.jandex.IndexView;
 import org.jboss.logging.Logger;
 
 /**
  * Represents the process of building a Metadata object.  The main entry point is the
  * static {@link #build}
  *
  * @author Steve Ebersole
  */
 public class MetadataBuildingProcess {
 	private static final Logger log = Logger.getLogger( MetadataBuildingProcess.class );
 
 	public static MetadataImpl build(
 			final MetadataSources sources,
 			final MetadataBuildingOptionsImpl options) {
 		final ClassLoaderService classLoaderService = options.getServiceRegistry().getService( ClassLoaderService.class );
 
 		final ClassLoaderAccess classLoaderAccess = new ClassLoaderAccessImpl(
 				options.getTempClassLoader(),
 				classLoaderService
 		);
 
 //		final JandexInitManager jandexInitializer = buildJandexInitializer( options, classLoaderAccess );
 		
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// scanning - Jandex initialization and source discovery
 		if ( options.getScanEnvironment() != null ) {
 			final Scanner scanner = buildScanner( options, classLoaderAccess );
 			final ScanResult scanResult = scanner.scan(
 					options.getScanEnvironment(),
 					options.getScanOptions(),
 					new ScanParameters() {
 						@Override
 						public JandexInitializer getJandexInitializer() {
 //							return jandexInitializer;
 							return null;
 						}
 					}
 			);
 
 			// Add to the MetadataSources any classes/packages/mappings discovered during scanning
 			addScanResultsToSources( sources, options, scanResult );
 		}
 
 //		// todo : add options.getScanEnvironment().getExplicitlyListedClassNames() to jandex?
 //		//		^^ - another option is to make sure that they are added to sources
 //
 //		if ( !jandexInitializer.wasIndexSupplied() ) {
 //			// If the Jandex Index(View) was supplied, we consider that supplied
 //			// one "complete".
 //			// Here though we were NOT supplied an index; in this case we want to
 //			// additionally ensure that any-and-all "known" classes are added to
 //			// the index we are building
 //			sources.indexKnownClasses( jandexInitializer );
 //		}
 		
 		// It's necessary to delay the binding of XML resources until now.  ClassLoaderAccess is needed for
 		// reflection, etc.
 //		sources.buildBindResults( classLoaderAccess );
 
 //		final IndexView jandexView = augmentJandexFromMappings( jandexInitializer.buildIndex(), sources, options );
 		final IndexView jandexView = options.getJandexView();
 
 		final BasicTypeRegistry basicTypeRegistry = handleTypes( options );
 
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// prep to start handling binding in earnest
 
 //		final JandexAccessImpl jandexAccess = new JandexAccessImpl(
 //				jandexView,
 //				classLoaderAccess
 //
 //		);
 		final InFlightMetadataCollectorImpl metadataCollector = new InFlightMetadataCollectorImpl(
 				options,
 				sources,
 				new TypeResolver( basicTypeRegistry, new TypeFactory() )
 		);
 
 		final MetadataBuildingContextRootImpl rootMetadataBuildingContext = new MetadataBuildingContextRootImpl(
 				options,
 				classLoaderAccess,
 				metadataCollector
 		);
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Set up the processors and start binding
 		//		NOTE : this becomes even more simplified after we move purely
 		// 		to unified model
 
 		final MetadataSourceProcessor processor = new MetadataSourceProcessor() {
 			private final HbmMetadataSourceProcessorImpl hbmProcessor = new HbmMetadataSourceProcessorImpl(
 					sources,
 					rootMetadataBuildingContext
 			);
 
 			private final AnnotationMetadataSourceProcessorImpl annotationProcessor = new AnnotationMetadataSourceProcessorImpl(
 					sources,
 					rootMetadataBuildingContext,
 					jandexView
 			);
 
 			@Override
 			public void prepare() {
 				hbmProcessor.prepare();
 				annotationProcessor.prepare();
 			}
 
 			@Override
 			public void processTypeDefinitions() {
 				hbmProcessor.processTypeDefinitions();
 				annotationProcessor.processTypeDefinitions();
 			}
 
 			@Override
 			public void processQueryRenames() {
 				hbmProcessor.processQueryRenames();
 				annotationProcessor.processQueryRenames();
 			}
 
 			@Override
 			public void processNamedQueries() {
 				hbmProcessor.processNamedQueries();
 				annotationProcessor.processNamedQueries();
 			}
 
 			@Override
 			public void processAuxiliaryDatabaseObjectDefinitions() {
 				hbmProcessor.processAuxiliaryDatabaseObjectDefinitions();
 				annotationProcessor.processAuxiliaryDatabaseObjectDefinitions();
 			}
 
 			@Override
 			public void processIdentifierGenerators() {
 				hbmProcessor.processIdentifierGenerators();
 				annotationProcessor.processIdentifierGenerators();
 			}
 
 			@Override
 			public void processFilterDefinitions() {
 				hbmProcessor.processFilterDefinitions();
 				annotationProcessor.processFilterDefinitions();
 			}
 
 			@Override
 			public void processFetchProfiles() {
 				hbmProcessor.processFetchProfiles();
 				annotationProcessor.processFetchProfiles();
 			}
 
 			@Override
 			public void prepareForEntityHierarchyProcessing() {
 				for ( MetadataSourceType metadataSourceType : options.getSourceProcessOrdering() ) {
 					if ( metadataSourceType == MetadataSourceType.HBM ) {
 						hbmProcessor.prepareForEntityHierarchyProcessing();
 					}
 
 					if ( metadataSourceType == MetadataSourceType.CLASS ) {
 						annotationProcessor.prepareForEntityHierarchyProcessing();
 					}
 				}
 			}
 
 			@Override
 			public void processEntityHierarchies(Set<String> processedEntityNames) {
 				for ( MetadataSourceType metadataSourceType : options.getSourceProcessOrdering() ) {
 					if ( metadataSourceType == MetadataSourceType.HBM ) {
 						hbmProcessor.processEntityHierarchies( processedEntityNames );
 					}
 
 					if ( metadataSourceType == MetadataSourceType.CLASS ) {
 						annotationProcessor.processEntityHierarchies( processedEntityNames );
 					}
 				}
 			}
 
 			@Override
 			public void postProcessEntityHierarchies() {
 				for ( MetadataSourceType metadataSourceType : options.getSourceProcessOrdering() ) {
 					if ( metadataSourceType == MetadataSourceType.HBM ) {
 						hbmProcessor.postProcessEntityHierarchies();
 					}
 
 					if ( metadataSourceType == MetadataSourceType.CLASS ) {
 						annotationProcessor.postProcessEntityHierarchies();
 					}
 				}
 			}
 
 			@Override
 			public void processResultSetMappings() {
 				hbmProcessor.processResultSetMappings();
 				annotationProcessor.processResultSetMappings();
 			}
 
 			@Override
 			public void finishUp() {
 				hbmProcessor.finishUp();
 				annotationProcessor.finishUp();
 			}
 		};
 
 		processor.prepare();
 
 		processor.processTypeDefinitions();
 		processor.processQueryRenames();
 		processor.processAuxiliaryDatabaseObjectDefinitions();
 
 		processor.processIdentifierGenerators();
 		processor.processFilterDefinitions();
 		processor.processFetchProfiles();
 
 		final Set<String> processedEntityNames = new HashSet<String>();
 		processor.prepareForEntityHierarchyProcessing();
 		processor.processEntityHierarchies( processedEntityNames );
 		processor.postProcessEntityHierarchies();
 
 		processor.processResultSetMappings();
 		processor.processNamedQueries();
 
 		processor.finishUp();
 
 		for ( MetadataContributor contributor : classLoaderService.loadJavaServices( MetadataContributor.class ) ) {
 			log.tracef( "Calling MetadataContributor : %s", contributor );
 			contributor.contribute( metadataCollector, jandexView );
 		}
 
 		metadataCollector.processSecondPasses( rootMetadataBuildingContext );
 
 		Iterable<AdditionalJaxbMappingProducer> producers = classLoaderService.loadJavaServices( AdditionalJaxbMappingProducer.class );
 		if ( producers != null ) {
 			final EntityHierarchyBuilder hierarchyBuilder = new EntityHierarchyBuilder();
 //			final MappingBinder mappingBinder = new MappingBinder( true );
 			// We need to disable validation here.  It seems Envers is not producing valid (according to schema) XML
 			final MappingBinder mappingBinder = new MappingBinder( false );
 			for ( AdditionalJaxbMappingProducer producer : producers ) {
 				log.tracef( "Calling AdditionalJaxbMappingProducer : %s", producer );
 				Collection<MappingDocument> additionalMappings = producer.produceAdditionalMappings(
 						metadataCollector,
 						jandexView,
 						mappingBinder,
 						rootMetadataBuildingContext
 				);
 				for ( MappingDocument mappingDocument : additionalMappings ) {
 					hierarchyBuilder.indexMappingDocument( mappingDocument );
 				}
 			}
 
 			ModelBinder binder = ModelBinder.prepare( rootMetadataBuildingContext );
 			for ( EntityHierarchySourceImpl entityHierarchySource : hierarchyBuilder.buildHierarchies() ) {
 				binder.bindEntityHierarchy( entityHierarchySource );
 			}
 		}
 
 		return metadataCollector.buildMetadataInstance( rootMetadataBuildingContext );
 	}
 
 //	private static JandexInitManager buildJandexInitializer(
 //			MetadataBuildingOptions options,
 //			ClassLoaderAccess classLoaderAccess) {
 //		final boolean autoIndexMembers = ConfigurationHelper.getBoolean(
 //				org.hibernate.cfg.AvailableSettings.ENABLE_AUTO_INDEX_MEMBER_TYPES,
 //				options.getServiceRegistry().getService( ConfigurationService.class ).getSettings(),
 //				false
 //		);
 //
 //		return new JandexInitManager( options.getJandexView(), classLoaderAccess, autoIndexMembers );
 //	}
 
 	private static final Class[] SINGLE_ARG = new Class[] { ArchiveDescriptorFactory.class };
 
 	private static Scanner buildScanner(MetadataBuildingOptions options, ClassLoaderAccess classLoaderAccess) {
 		final Object scannerSetting = options.getScanner();
 		final ArchiveDescriptorFactory archiveDescriptorFactory = options.getArchiveDescriptorFactory();
 
 		if ( scannerSetting == null ) {
 			// No custom Scanner specified, use the StandardScanner
 			if ( archiveDescriptorFactory == null ) {
 				return new StandardScanner();
 			}
 			else {
 				return new StandardScanner( archiveDescriptorFactory );
 			}
 		}
 		else {
 			if ( Scanner.class.isInstance( scannerSetting ) ) {
 				if ( archiveDescriptorFactory != null ) {
 					throw new IllegalStateException(
 							"A Scanner instance and an ArchiveDescriptorFactory were both specified; please " +
 									"specify one or the other, or if you need to supply both, Scanner class to use " +
 									"(assuming it has a constructor accepting a ArchiveDescriptorFactory).  " +
 									"Alternatively, just pass the ArchiveDescriptorFactory during your own " +
 									"Scanner constructor assuming it is statically known."
 					);
 				}
 				return (Scanner) scannerSetting;
 			}
 
 			final Class<? extends  Scanner> scannerImplClass;
 			if ( Class.class.isInstance( scannerSetting ) ) {
 				scannerImplClass = (Class<? extends Scanner>) scannerSetting;
 			}
 			else {
 				scannerImplClass = classLoaderAccess.classForName( scannerSetting.toString() );
 			}
 
 
 			if ( archiveDescriptorFactory != null ) {
 				// find the single-arg constructor - its an error if none exists
 				try {
 					final Constructor<? extends Scanner> constructor = scannerImplClass.getConstructor( SINGLE_ARG );
 					try {
 						return constructor.newInstance( archiveDescriptorFactory );
 					}
 					catch (Exception e) {
 						throw new IllegalStateException(
 								"Error trying to instantiate custom specified Scanner [" +
 										scannerImplClass.getName() + "]",
 								e
 						);
 					}
 				}
 				catch (NoSuchMethodException e) {
 					throw new IllegalArgumentException(
 							"Configuration named a custom Scanner and a custom ArchiveDescriptorFactory, but " +
 									"Scanner impl did not define a constructor accepting ArchiveDescriptorFactory"
 					);
 				}
 			}
 			else {
 				// could be either ctor form...
 				// find the single-arg constructor - its an error if none exists
 				try {
 					final Constructor<? extends Scanner> constructor = scannerImplClass.getConstructor( SINGLE_ARG );
 					try {
 						return constructor.newInstance( StandardArchiveDescriptorFactory.INSTANCE );
 					}
 					catch (Exception e) {
 						throw new IllegalStateException(
 								"Error trying to instantiate custom specified Scanner [" +
 										scannerImplClass.getName() + "]",
 								e
 						);
 					}
 				}
 				catch (NoSuchMethodException e) {
 					try {
 						final Constructor<? extends Scanner> constructor = scannerImplClass.getConstructor();
 						try {
 							return constructor.newInstance();
 						}
 						catch (Exception e2) {
 							throw new IllegalStateException(
 									"Error trying to instantiate custom specified Scanner [" +
 											scannerImplClass.getName() + "]",
 									e2
 							);
 						}
 					}
 					catch (NoSuchMethodException ignore) {
 						throw new IllegalArgumentException(
 								"Configuration named a custom Scanner, but we were unable to locate " +
 										"an appropriate constructor"
 						);
 					}
 				}
 			}
 		}
 	}
 
 	private static void addScanResultsToSources(
 			MetadataSources sources,
 			MetadataBuildingOptionsImpl options,
 			ScanResult scanResult) {
 		final ClassLoaderService cls = options.getServiceRegistry().getService( ClassLoaderService.class );
 
 		DeploymentResources deploymentResources = DeploymentResourcesInterpreter.INSTANCE.buildDeploymentResources(
 				options.getScanEnvironment(),
 				scanResult,
 				options.getServiceRegistry()
 		);
 
 		for ( ClassDescriptor classDescriptor : deploymentResources.getClassDescriptors() ) {
 			final String className = classDescriptor.getName();
 
 			// todo : leverage Jandex calls after we fully integrate Jandex...
 			try {
 				final Class classRef = cls.classForName( className );
 
 				// logic here assumes an entity is not also a converter...
 				final Converter converter = (Converter) classRef.getAnnotation( Converter.class );
 				if ( converter != null ) {
 					//noinspection unchecked
 					options.addAttributeConverterDefinition(
 							AttributeConverterDefinition.from( classRef, converter.autoApply() )
 					);
 				}
 				else {
 					sources.addAnnotatedClass( classRef );
 				}
 			}
 			catch (ClassLoadingException e) {
 				// Not really sure what this means...
 				sources.addAnnotatedClassName( className );
 			}
 		}
 
 		for ( PackageDescriptor packageDescriptor : deploymentResources.getPackageDescriptors() ) {
 			sources.addPackage( packageDescriptor.getName() );
 		}
 
 		for ( MappingFileDescriptor mappingFileDescriptor : deploymentResources.getMappingFileDescriptors() ) {
 			sources.addInputStream( mappingFileDescriptor.getStreamAccess() );
 		}
 	}
 
 
 	private static BasicTypeRegistry handleTypes(MetadataBuildingOptions options) {
 		final ClassLoaderService classLoaderService = options.getServiceRegistry().getService( ClassLoaderService.class );
 
 		// ultimately this needs to change a little bit to account for HHH-7792
 		final BasicTypeRegistry basicTypeRegistry = new BasicTypeRegistry();
 
 		final TypeContributions typeContributions = new TypeContributions() {
 			@Override
 			public void contributeType(org.hibernate.type.BasicType type) {
 				basicTypeRegistry.register( type );
 			}
 
 			@Override
 			public void contributeType(UserType type, String[] keys) {
 				basicTypeRegistry.register( type, keys );
 			}
 
 			@Override
 			public void contributeType(CompositeUserType type, String[] keys) {
 				basicTypeRegistry.register( type, keys );
 			}
 		};
 
 		// add Dialect contributed types
 		final Dialect dialect = options.getServiceRegistry().getService( JdbcServices.class ).getDialect();
 		dialect.contributeTypes( typeContributions, options.getServiceRegistry() );
 
 		// add TypeContributor contributed types.
 		for ( TypeContributor contributor : classLoaderService.loadJavaServices( TypeContributor.class ) ) {
 			contributor.contribute( typeContributions, options.getServiceRegistry() );
 		}
 
 		// add explicit application registered types
 		for ( org.hibernate.type.BasicType basicType : options.getBasicTypeRegistrations() ) {
 			basicTypeRegistry.register( basicType );
 		}
 
 		return basicTypeRegistry;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/EntityInfo.java b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/EntityInfo.java
index 7d24820594..22fbe163d0 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/EntityInfo.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/EntityInfo.java
@@ -1,63 +1,75 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.jaxb.hbm.spi;
 
 import java.util.List;
 
 /**
  * Common interface for all entity mappings (root entity and sub-entity mappings).
  *
  * @author Steve Ebersole
  */
 public interface EntityInfo extends ToolingHintContainer {
-	public String getName();
-	public String getEntityName();
+	String getName();
 
-    public Boolean isAbstract();
-    public Boolean isLazy();
-    public String getProxy();
-    public int getBatchSize();
-    public boolean isDynamicInsert();
-    public boolean isDynamicUpdate();
-    public boolean isSelectBeforeUpdate();
+	String getEntityName();
 
-	public List<JaxbHbmTuplizerType> getTuplizer();
-    public String getPersister();
+	Boolean isAbstract();
 
-	public JaxbHbmLoaderType getLoader();
-	public JaxbHbmCustomSqlDmlType getSqlInsert();
-	public JaxbHbmCustomSqlDmlType getSqlUpdate();
-	public JaxbHbmCustomSqlDmlType getSqlDelete();
+	Boolean isLazy();
 
-	public List<JaxbHbmSynchronizeType> getSynchronize();
+	String getProxy();
 
-	public List<JaxbHbmFetchProfileType> getFetchProfile();
+	int getBatchSize();
 
-    public List<JaxbHbmResultSetMappingType> getResultset();
+	boolean isDynamicInsert();
 
-	public List<JaxbHbmNamedNativeQueryType> getSqlQuery();
-	public List<JaxbHbmNamedQueryType> getQuery();
+	boolean isDynamicUpdate();
 
-	public List getAttributes();
+	boolean isSelectBeforeUpdate();
+
+	List<JaxbHbmTuplizerType> getTuplizer();
+
+	String getPersister();
+
+	JaxbHbmLoaderType getLoader();
+
+	JaxbHbmCustomSqlDmlType getSqlInsert();
+
+	JaxbHbmCustomSqlDmlType getSqlUpdate();
+
+	JaxbHbmCustomSqlDmlType getSqlDelete();
+
+	List<JaxbHbmSynchronizeType> getSynchronize();
+
+	List<JaxbHbmFetchProfileType> getFetchProfile();
+
+	List<JaxbHbmResultSetMappingType> getResultset();
+
+	List<JaxbHbmNamedNativeQueryType> getSqlQuery();
+
+	List<JaxbHbmNamedQueryType> getQuery();
+
+	List getAttributes();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/PluralAttributeInfo.java b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/PluralAttributeInfo.java
index fd73fff664..8f0877c8ae 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/PluralAttributeInfo.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/PluralAttributeInfo.java
@@ -1,73 +1,91 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.jaxb.hbm.spi;
 
 import java.util.List;
 
 /**
  * Commonality between the various forms of plural attribute (collection) mappings: {@code <bag/>}, {@code <set/>}, etc.
  *
  * @author Steve Ebersole
  */
 public interface PluralAttributeInfo extends AttributeMapping, TableInformationContainer, ToolingHintContainer {
-	public JaxbHbmKeyType getKey();
+	JaxbHbmKeyType getKey();
 
-	public JaxbHbmBasicCollectionElementType getElement();
-	public JaxbHbmCompositeCollectionElementType getCompositeElement();
-	public JaxbHbmOneToManyCollectionElementType getOneToMany();
-	public JaxbHbmManyToManyCollectionElementType getManyToMany();
-    public JaxbHbmManyToAnyCollectionElementType getManyToAny();
+	JaxbHbmBasicCollectionElementType getElement();
 
-	public String getComment();
-	public String getCheck();
-	public String getWhere();
+	JaxbHbmCompositeCollectionElementType getCompositeElement();
 
-	public JaxbHbmLoaderType getLoader();
-	public JaxbHbmCustomSqlDmlType getSqlInsert();
-    public JaxbHbmCustomSqlDmlType getSqlUpdate();
-    public JaxbHbmCustomSqlDmlType getSqlDelete();
-    public JaxbHbmCustomSqlDmlType getSqlDeleteAll();
+	JaxbHbmOneToManyCollectionElementType getOneToMany();
 
-	public List<JaxbHbmSynchronizeType> getSynchronize();
+	JaxbHbmManyToManyCollectionElementType getManyToMany();
 
-	public JaxbHbmCacheType getCache();
-	public List<JaxbHbmFilterType> getFilter();
+	JaxbHbmManyToAnyCollectionElementType getManyToAny();
 
-	public String getCascade();
-	public JaxbHbmFetchStyleWithSubselectEnum getFetch();
-	public JaxbHbmLazyWithExtraEnum getLazy();
-	public JaxbHbmOuterJoinEnum getOuterJoin();
+	String getComment();
 
-	public int getBatchSize();
-	public boolean isInverse();
-    public boolean isMutable();
-	public boolean isOptimisticLock();
+	String getCheck();
 
-	public String getCollectionType();
-    public String getPersister();
+	String getWhere();
+
+	JaxbHbmLoaderType getLoader();
+
+	JaxbHbmCustomSqlDmlType getSqlInsert();
+
+	JaxbHbmCustomSqlDmlType getSqlUpdate();
+
+	JaxbHbmCustomSqlDmlType getSqlDelete();
+
+	JaxbHbmCustomSqlDmlType getSqlDeleteAll();
+
+	List<JaxbHbmSynchronizeType> getSynchronize();
+
+	JaxbHbmCacheType getCache();
+
+	List<JaxbHbmFilterType> getFilter();
+
+	String getCascade();
+
+	JaxbHbmFetchStyleWithSubselectEnum getFetch();
+
+	JaxbHbmLazyWithExtraEnum getLazy();
+
+	JaxbHbmOuterJoinEnum getOuterJoin();
+
+	int getBatchSize();
+
+	boolean isInverse();
+
+	boolean isMutable();
+
+	boolean isOptimisticLock();
+
+	String getCollectionType();
+
+	String getPersister();
 
 // todo : not available on all.  do we need a specific interface for these?
 //	public String getSort();
 //	public String getOrderBy();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/SubEntityInfo.java b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/SubEntityInfo.java
index f60a7efb17..b62772101c 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/SubEntityInfo.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/SubEntityInfo.java
@@ -1,33 +1,33 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.jaxb.hbm.spi;
 
 /**
  * Common interface for all sub-entity mappings.
  *
  * @author Steve Ebersole
  */
 public interface SubEntityInfo extends EntityInfo {
-    public String getExtends();
+    String getExtends();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/TypeDefinition.java b/hibernate-core/src/main/java/org/hibernate/boot/model/TypeDefinition.java
index fb815dddb3..42a7c138be 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/TypeDefinition.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/TypeDefinition.java
@@ -1,154 +1,154 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model;
 
 import java.io.Serializable;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Properties;
 
 import org.hibernate.internal.util.compare.EqualsHelper;
 
 /**
  * Models the information pertaining to a custom type definition supplied by the user.  Used
  * to delay instantiation of the actual {@link org.hibernate.type.Type} instance.
  *
  * Generally speaking this information would come from annotations
  * ({@link org.hibernate.annotations.TypeDef}) or XML mappings.  An alternative form of
  * supplying custom types is programatically via one of:<ul>
  *     <li>{@link org.hibernate.boot.MetadataBuilder#applyBasicType(org.hibernate.type.BasicType)}</li>
  *     <li>{@link org.hibernate.boot.MetadataBuilder#applyBasicType(org.hibernate.usertype.UserType, String[])}</li>
  *     <li>{@link org.hibernate.boot.MetadataBuilder#applyTypes(TypeContributor)}</li>
  * </ul>
  *
  * @author Steve Ebersole
  * @author John Verhaeg
  */
 public class TypeDefinition implements Serializable {
 	private final String name;
-    private final Class typeImplementorClass;
+	private final Class typeImplementorClass;
 	private final String[] registrationKeys;
-    private final Map<String, String> parameters;
+	private final Map<String, String> parameters;
 
 	public TypeDefinition(
 			String name,
 			Class typeImplementorClass,
 			String[] registrationKeys,
 			Map<String, String> parameters) {
 		this.name = name;
 		this.typeImplementorClass = typeImplementorClass;
 		this.registrationKeys= registrationKeys;
 		this.parameters = parameters == null
 				? Collections.<String, String>emptyMap()
 				: Collections.unmodifiableMap( parameters );
 	}
 
 	public TypeDefinition(
 			String name,
 			Class typeImplementorClass,
 			String[] registrationKeys,
 			Properties parameters) {
 		this.name = name;
 		this.typeImplementorClass = typeImplementorClass;
 		this.registrationKeys= registrationKeys;
 		this.parameters = parameters == null
 				? Collections.<String, String>emptyMap()
 				: extractStrings( parameters );
 	}
 
 	private Map<String, String> extractStrings(Properties properties) {
 		final Map<String, String> parameters = new HashMap<String, String>();
 
 		for ( Map.Entry entry : properties.entrySet() ) {
 			if ( String.class.isInstance( entry.getKey() )
 					&& String.class.isInstance( entry.getValue() ) ) {
 				parameters.put(
 						(String) entry.getKey(),
 						(String) entry.getValue()
 				);
 			}
 		}
 
 		return parameters;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public Class getTypeImplementorClass() {
 		return typeImplementorClass;
 	}
 
 	public String[] getRegistrationKeys() {
 		return registrationKeys;
 	}
 
 	public Map<String, String> getParameters() {
-        return parameters;
-    }
+		return parameters;
+	}
 
 	public Properties getParametersAsProperties() {
 		Properties properties = new Properties();
 		properties.putAll( parameters );
 		return properties;
 	}
 
 	@Override
 	public boolean equals(Object o) {
 		if ( this == o ) {
 			return true;
 		}
 		if ( !( o instanceof TypeDefinition ) ) {
 			return false;
 		}
 
 		final TypeDefinition that = (TypeDefinition) o;
 		return EqualsHelper.equals( this.name, that.name )
 				&& EqualsHelper.equals( this.typeImplementorClass, that.typeImplementorClass )
 				&& Arrays.equals( this.registrationKeys, that.registrationKeys )
 				&& EqualsHelper.equals( this.parameters, that.parameters );
 	}
 
 	@Override
 	public int hashCode() {
 		int result = name != null ? name.hashCode() : 0;
 		result = 31 * result + ( typeImplementorClass != null ? typeImplementorClass.hashCode() : 0 );
 		result = 31 * result + ( registrationKeys != null ? Arrays.hashCode( registrationKeys ) : 0 );
 		result = 31 * result + ( parameters != null ? parameters.hashCode() : 0 );
 		return result;
 	}
 
 	@Override
 	public String toString() {
 		return "TypeDefinition{" +
 				"name='" + name + '\'' +
 				", typeImplementorClass=" + typeImplementorClass +
 				", registrationKeys=" + Arrays.toString( registrationKeys ) +
 				", parameters=" + parameters +
 				'}';
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/AbstractEntitySourceImpl.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/AbstractEntitySourceImpl.java
index 72a160c2f9..fa8a72c13e 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/AbstractEntitySourceImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/AbstractEntitySourceImpl.java
@@ -1,554 +1,552 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.internal.hbm;
 
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.boot.MappingException;
 import org.hibernate.boot.jaxb.Origin;
 import org.hibernate.boot.jaxb.hbm.spi.EntityInfo;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmEntityBaseDefinition;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmFetchProfileType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmFilterType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmNamedNativeQueryType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmNamedQueryType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmRootEntityType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmSecondaryTableType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmTuplizerType;
 import org.hibernate.boot.jaxb.hbm.spi.SecondaryTableContainer;
 import org.hibernate.boot.model.CustomSql;
 import org.hibernate.boot.model.TruthValue;
 import org.hibernate.boot.model.source.spi.AttributePath;
 import org.hibernate.boot.model.source.spi.AttributeRole;
 import org.hibernate.boot.model.source.spi.AttributeSource;
 import org.hibernate.boot.model.source.spi.AttributeSourceContainer;
 import org.hibernate.boot.model.source.spi.ConstraintSource;
 import org.hibernate.boot.model.source.spi.EntityHierarchySource;
 import org.hibernate.boot.model.source.spi.EntityNamingSource;
 import org.hibernate.boot.model.source.spi.EntitySource;
 import org.hibernate.boot.model.source.spi.FilterSource;
 import org.hibernate.boot.model.source.spi.IdentifiableTypeSource;
 import org.hibernate.boot.model.source.spi.JpaCallbackSource;
 import org.hibernate.boot.model.source.spi.LocalMetadataBuildingContext;
 import org.hibernate.boot.model.source.spi.NaturalIdMutability;
 import org.hibernate.boot.model.source.spi.SecondaryTableSource;
 import org.hibernate.boot.model.source.spi.SubclassEntitySource;
 import org.hibernate.boot.model.source.spi.ToolingHintContext;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.compare.EqualsHelper;
 
-
 /**
  * @author Steve Ebersole
  * @author Hardy Ferentschik
  * @author Brett Meyer
  */
 public abstract class AbstractEntitySourceImpl
 		extends AbstractHbmSourceNode
 		implements EntitySource, Helper.InLineViewNameInferrer {
 
 	private static final FilterSource[] NO_FILTER_SOURCES = new FilterSource[0];
 
 	private final JaxbHbmEntityBaseDefinition jaxbEntityMapping;
 	private final EntityNamingSource entityNamingSource;
 
 	private final AttributeRole attributeRoleBase;
 	private final AttributePath attributePathBase;
 
 	private List<IdentifiableTypeSource> subclassEntitySources = new ArrayList<IdentifiableTypeSource>();
 
 	private int inLineViewCount = 0;
 
 	// logically final, but built during 'afterInstantiation' callback
 	private List<AttributeSource> attributeSources;
 	private Map<String,SecondaryTableSource> secondaryTableMap;
 	private final FilterSource[] filterSources;
 
 	private final Map<EntityMode, String> tuplizerClassMap;
 
 	private final ToolingHintContext toolingHintContext;
 
 	private Map<String, ConstraintSource> constraintMap = new HashMap<String, ConstraintSource>();
 
 
 	protected AbstractEntitySourceImpl(MappingDocument sourceMappingDocument, JaxbHbmEntityBaseDefinition jaxbEntityMapping) {
 		super( sourceMappingDocument );
 		this.jaxbEntityMapping = jaxbEntityMapping;
 
 		this.entityNamingSource = extractEntityNamingSource( sourceMappingDocument, jaxbEntityMapping );
 
 		this.attributePathBase = new AttributePath();
 		this.attributeRoleBase = new AttributeRole( entityNamingSource.getEntityName() );
 
 		this.tuplizerClassMap = extractTuplizers( jaxbEntityMapping );
 
 		this.filterSources = buildFilterSources();
 
 		for ( JaxbHbmFetchProfileType jaxbFetchProfile : jaxbEntityMapping.getFetchProfile() ) {
 			FetchProfileBinder.processFetchProfile(
 					sourceMappingDocument,
 					jaxbFetchProfile,
 					entityNamingSource.getClassName() != null
 							? entityNamingSource.getClassName()
 							: entityNamingSource.getEntityName()
 			);
 		}
 
 		this.toolingHintContext = Helper.collectToolingHints(
 				sourceMappingDocument.getToolingHintContext(),
 				jaxbEntityMapping
 		);
 	}
 
 	public static EntityNamingSourceImpl extractEntityNamingSource(
 			MappingDocument sourceMappingDocument,
 			EntityInfo jaxbEntityMapping) {
 		final String className = sourceMappingDocument.qualifyClassName( jaxbEntityMapping.getName() );
 		final String entityName;
 		final String jpaEntityName;
 		if ( StringHelper.isNotEmpty( jaxbEntityMapping.getEntityName() ) ) {
 			entityName = jaxbEntityMapping.getEntityName();
 			jpaEntityName = jaxbEntityMapping.getEntityName();
 		}
 		else {
 			entityName = className;
 			jpaEntityName = StringHelper.unqualify( className );
 		}
 		return new EntityNamingSourceImpl( entityName, className, jpaEntityName );
 	}
 
 	private static Map<EntityMode, String> extractTuplizers(JaxbHbmEntityBaseDefinition entityElement) {
 		if ( entityElement.getTuplizer() == null ) {
 			return Collections.emptyMap();
 		}
 
 		final Map<EntityMode, String> tuplizers = new HashMap<EntityMode, String>();
 		for ( JaxbHbmTuplizerType tuplizerElement : entityElement.getTuplizer() ) {
 			tuplizers.put(
 					tuplizerElement.getEntityMode(),
 					tuplizerElement.getClazz()
 			);
 		}
 		return tuplizers;
 	}
 
 	private FilterSource[] buildFilterSources() {
 		//todo for now, i think all EntityElement should support this.
 		if ( JaxbHbmRootEntityType.class.isInstance( jaxbEntityMapping() ) ) {
 			final JaxbHbmRootEntityType jaxbClassElement = (JaxbHbmRootEntityType) jaxbEntityMapping();
 			final int size = jaxbClassElement.getFilter().size();
 			if ( size == 0 ) {
 				return NO_FILTER_SOURCES;
 			}
 
 			FilterSource[] results = new FilterSource[size];
 			for ( int i = 0; i < size; i++ ) {
 				JaxbHbmFilterType element = jaxbClassElement.getFilter().get( i );
 				results[i] = new FilterSourceImpl( sourceMappingDocument(), element );
 			}
 			return results;
 		}
 		else {
 			return NO_FILTER_SOURCES;
 		}
 
 	}
 
 	@Override
 	public String getXmlNodeName() {
 		return jaxbEntityMapping.getNode();
 	}
 
 	@Override
 	public LocalMetadataBuildingContext getLocalMetadataBuildingContext() {
 		return super.metadataBuildingContext();
 	}
 
 	@Override
 	public String getTypeName() {
 		return entityNamingSource.getTypeName();
 	}
 
 	@Override
 	public AttributePath getAttributePathBase() {
 		return attributePathBase;
 	}
 
 	@Override
 	public AttributeRole getAttributeRoleBase() {
 		return attributeRoleBase;
 	}
 
 	@Override
 	public Collection<IdentifiableTypeSource> getSubTypes() {
 		return subclassEntitySources;
 	}
 
 	@Override
 	public FilterSource[] getFilterSources() {
 		return filterSources;
 	}
 
 	@Override
 	public String inferInLineViewName() {
 		return entityNamingSource.getEntityName() + '#' + (++inLineViewCount);
 	}
 
 	protected void afterInstantiation() {
 		this.attributeSources = buildAttributeSources();
 		this.secondaryTableMap = buildSecondaryTableMap();
 	}
 
 	protected List<AttributeSource> buildAttributeSources() {
 		final List<AttributeSource> attributeSources = new ArrayList<AttributeSource>();
 
 		AttributesHelper.Callback attributeBuildingCallback = new AttributesHelper.Callback() {
 			@Override
 			public AttributeSourceContainer getAttributeSourceContainer() {
 				return AbstractEntitySourceImpl.this;
 			}
 
 			@Override
 			public void addAttributeSource(AttributeSource attributeSource) {
 				attributeSources.add( attributeSource );
 			}
 
 			@Override
 			public void registerIndexColumn(String constraintName, String logicalTableName, String columnName) {
 				registerIndexConstraintColumn( constraintName, logicalTableName, columnName );
 			}
 
 			@Override
 			public void registerUniqueKeyColumn(String constraintName, String logicalTableName, String columnName) {
 				registerUniqueKeyConstraintColumn( constraintName, logicalTableName, columnName );
 			}
 		};
 		buildAttributeSources( attributeBuildingCallback );
 
 		return attributeSources;
 	}
 
 	private void registerIndexConstraintColumn(String constraintName, String logicalTableName, String columnName) {
 		getOrCreateIndexConstraintSource( constraintName, logicalTableName ).addColumnName( columnName );
 	}
 
 	private IndexConstraintSourceImpl getOrCreateIndexConstraintSource(String constraintName, String logicalTableName) {
 		IndexConstraintSourceImpl constraintSource = (IndexConstraintSourceImpl) constraintMap.get( constraintName );
 		if ( constraintSource == null ) {
 			constraintSource = new IndexConstraintSourceImpl( constraintName, logicalTableName );
 			constraintMap.put( constraintName, constraintSource );
 		}
 		else {
 			// make sure we have the same table name...
 			if ( !EqualsHelper.equals( constraintSource.getTableName(), logicalTableName ) ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Named relational index [%s] referenced more than one table [%s, %s]",
 								constraintName,
 								constraintSource.getTableName() == null
 										? "null(implicit)"
 										: constraintSource.getTableName(),
 								logicalTableName == null
 										? "null(implicit)"
 										: logicalTableName
 						),
 						origin()
 				);
 			}
 		}
 		return constraintSource;
 	}
 
 	private void registerUniqueKeyConstraintColumn(String constraintName, String logicalTableName, String columnName) {
 		getOrCreateUniqueKeyConstraintSource( constraintName, logicalTableName ).addColumnName( columnName );
 	}
 
 	private UniqueKeyConstraintSourceImpl getOrCreateUniqueKeyConstraintSource(String constraintName, String logicalTableName) {
 		UniqueKeyConstraintSourceImpl constraintSource = (UniqueKeyConstraintSourceImpl) constraintMap.get( constraintName );
 		if ( constraintSource == null ) {
 			constraintSource = new UniqueKeyConstraintSourceImpl( constraintName, logicalTableName );
 			constraintMap.put( constraintName, constraintSource );
 		}
 		else {
 			// make sure we have the same table name...
 			if ( !EqualsHelper.equals( constraintSource.getTableName(), logicalTableName ) ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Named relational unique-key [%s] referenced more than one table [%s, %s]",
 								constraintName,
 								constraintSource.getTableName() == null
 										? "null(implicit)"
 										: constraintSource.getTableName(),
 								logicalTableName == null
 										? "null(implicit)"
 										: logicalTableName
 						),
 						origin()
 				);
 			}
 		}
 		return constraintSource;
 	}
 
 	protected void buildAttributeSources(AttributesHelper.Callback attributeBuildingCallback) {
 		AttributesHelper.processAttributes(
 				sourceMappingDocument(),
 				attributeBuildingCallback,
 				jaxbEntityMapping.getAttributes(),
 				null,
 				NaturalIdMutability.NOT_NATURAL_ID
 		);
 	}
 
 	private Map<String,SecondaryTableSource> buildSecondaryTableMap() {
 		if ( !SecondaryTableContainer.class.isInstance( jaxbEntityMapping ) ) {
 			return Collections.emptyMap();
 		}
 
 		final HashMap<String,SecondaryTableSource> secondaryTableSourcesMap =
 				new HashMap<String, SecondaryTableSource>();
 
 		for ( final JaxbHbmSecondaryTableType joinElement :  ( (SecondaryTableContainer) jaxbEntityMapping ).getJoin() ) {
 			final SecondaryTableSourceImpl secondaryTableSource = new SecondaryTableSourceImpl(
 					sourceMappingDocument(),
 					joinElement,
 					getEntityNamingSource(),
 					this
 			);
 
 			final String logicalTableName = secondaryTableSource.getLogicalTableNameForContainedColumns();
 			secondaryTableSourcesMap.put( logicalTableName, secondaryTableSource );
 
 			AttributesHelper.processAttributes(
 					sourceMappingDocument(),
 					new AttributesHelper.Callback() {
 						@Override
 						public AttributeSourceContainer getAttributeSourceContainer() {
 							return AbstractEntitySourceImpl.this;
 						}
 
 						@Override
 						public void addAttributeSource(AttributeSource attributeSource) {
 							attributeSources.add( attributeSource );
 						}
 
 						@Override
 						public void registerIndexColumn(
 								String constraintName,
 								String logicalTableName,
 								String columnName) {
 							registerIndexConstraintColumn( constraintName, logicalTableName, columnName );
 						}
 
 						@Override
 						public void registerUniqueKeyColumn(
 								String constraintName,
 								String logicalTableName,
 								String columnName) {
 							registerUniqueKeyConstraintColumn( constraintName, logicalTableName, columnName );
 						}
 					},
 					joinElement.getAttributes(),
 					logicalTableName,
 					NaturalIdMutability.NOT_NATURAL_ID
 			);
 		}
 		return secondaryTableSourcesMap;
 	}
 
 	protected JaxbHbmEntityBaseDefinition jaxbEntityMapping() {
 		return jaxbEntityMapping;
 	}
 
 	@Override
 	public Origin getOrigin() {
 		return origin();
 	}
 
 	@Override
 	public EntityNamingSource getEntityNamingSource() {
 		return entityNamingSource;
 	}
 
 	@Override
 	public Boolean isAbstract() {
 		return jaxbEntityMapping().isAbstract();
 	}
 
 	@Override
 	public boolean isLazy() {
 		if ( jaxbEntityMapping.isLazy() == null ) {
 			return metadataBuildingContext().getMappingDefaults().areEntitiesImplicitlyLazy();
 		}
 		return jaxbEntityMapping().isLazy();
 	}
 
 	@Override
 	public String getProxy() {
 		return jaxbEntityMapping.getProxy();
 	}
 
 	@Override
 	public int getBatchSize() {
 		return jaxbEntityMapping.getBatchSize();
 	}
 
 	@Override
 	public boolean isDynamicInsert() {
 		return jaxbEntityMapping.isDynamicInsert();
 	}
 
 	@Override
 	public boolean isDynamicUpdate() {
 		return jaxbEntityMapping.isDynamicUpdate();
 	}
 
 	@Override
 	public boolean isSelectBeforeUpdate() {
 		return jaxbEntityMapping.isSelectBeforeUpdate();
 	}
 
 	protected EntityMode determineEntityMode() {
 		return StringHelper.isNotEmpty( entityNamingSource.getClassName() ) ? EntityMode.POJO : EntityMode.MAP;
 	}
 
 	@Override
 	public Map<EntityMode, String> getTuplizerClassMap() {
 		return tuplizerClassMap;
 	}
 
 	@Override
 	public String getCustomPersisterClassName() {
 		return metadataBuildingContext().qualifyClassName( jaxbEntityMapping.getPersister() );
 	}
 
 	@Override
 	public String getCustomLoaderName() {
 		return jaxbEntityMapping.getLoader() != null ? jaxbEntityMapping.getLoader().getQueryRef() : null;
 	}
 
 	@Override
 	public CustomSql getCustomSqlInsert() {
 		return Helper.buildCustomSql( jaxbEntityMapping.getSqlInsert() );
 	}
 
 	@Override
 	public CustomSql getCustomSqlUpdate() {
 		return Helper.buildCustomSql( jaxbEntityMapping.getSqlUpdate() );
 	}
 
 	@Override
 	public CustomSql getCustomSqlDelete() {
 		return Helper.buildCustomSql( jaxbEntityMapping.getSqlDelete() );
 	}
 
 	@Override
 	public String[] getSynchronizedTableNames() {
 		if ( CollectionHelper.isEmpty( jaxbEntityMapping.getSynchronize() ) ) {
 			return StringHelper.EMPTY_STRINGS;
 		}
 		else {
 			final int size = jaxbEntityMapping.getSynchronize().size();
 			final String[] synchronizedTableNames = new String[size];
 			for ( int i = 0; i < size; i++ ) {
 				synchronizedTableNames[i] = jaxbEntityMapping.getSynchronize().get( i ).getTable();
 			}
 			return synchronizedTableNames;
 		}
 	}
 
 	@Override
 	public ToolingHintContext getToolingHintContext() {
 		return toolingHintContext;
 	}
 
 	@Override
 	public List<AttributeSource> attributeSources() {
 		return attributeSources;
 	}
 
 	private EntityHierarchySourceImpl entityHierarchy;
 
 	public void injectHierarchy(EntityHierarchySourceImpl entityHierarchy) {
 		this.entityHierarchy = entityHierarchy;
 	}
 
 	@Override
 	public EntityHierarchySource getHierarchy() {
 		return entityHierarchy;
 	}
 
 	void add(SubclassEntitySource subclassEntitySource) {
 		add( (SubclassEntitySourceImpl) subclassEntitySource );
 	}
 
 	void add(SubclassEntitySourceImpl subclassEntitySource) {
 		subclassEntitySource.injectHierarchy( entityHierarchy );
 		entityHierarchy.processSubclass( subclassEntitySource );
 		subclassEntitySources.add( subclassEntitySource );
 	}
 
 	@Override
 	public Collection<ConstraintSource> getConstraints() {
 		return constraintMap.values();
 	}
 
 	@Override
 	public Map<String,SecondaryTableSource> getSecondaryTableMap() {
 		return secondaryTableMap;
 	}
 
 	@Override
-	@SuppressWarnings( {"unchecked"})
 	public List<JpaCallbackSource> getJpaCallbackClasses() {
-	    return Collections.EMPTY_LIST;
+		return Collections.emptyList();
 	}
 
 	@Override
 	public List<JaxbHbmNamedQueryType> getNamedQueries() {
 		return jaxbEntityMapping.getQuery();
 	}
 
 	@Override
 	public List<JaxbHbmNamedNativeQueryType> getNamedNativeQueries() {
 		return jaxbEntityMapping.getSqlQuery();
 	}
 
 	@Override
 	public TruthValue quoteIdentifiersLocalToEntity() {
 		// HBM does not allow for this
 		return TruthValue.UNKNOWN;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ColumnAttributeSourceImpl.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ColumnAttributeSourceImpl.java
index 7803fe5f30..5ec8104c1d 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ColumnAttributeSourceImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ColumnAttributeSourceImpl.java
@@ -1,126 +1,126 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.internal.hbm;
 
 import org.hibernate.boot.model.TruthValue;
 import org.hibernate.boot.model.source.spi.ColumnSource;
 import org.hibernate.boot.model.source.spi.JdbcDataType;
 import org.hibernate.boot.model.source.spi.SizeSource;
 
 /**
  * Implementation of a {@link ColumnSource} when the column is declared as just the name via the column XML
  * attribute.  For example, {@code <property name="socialSecurityNumber" column="ssn"/>}.
  *
  * @author Steve Ebersole
  */
 class ColumnAttributeSourceImpl
 		extends AbstractHbmSourceNode
 		implements ColumnSource {
 
 	private final String tableName;
 	private final String columnName;
 	private final SizeSource sizeSource;
-    private final TruthValue nullable;
-    private final TruthValue unique;
+	private final TruthValue nullable;
+	private final TruthValue unique;
 
-    ColumnAttributeSourceImpl(
+	ColumnAttributeSourceImpl(
 			MappingDocument mappingDocument,
 			String tableName,
 			String columnName,
 			SizeSource sizeSource,
-            TruthValue nullable,
+			TruthValue nullable,
 			TruthValue unique) {
 		super( mappingDocument );
 		this.tableName = tableName;
 		this.columnName = columnName;
 		this.sizeSource = sizeSource;
-        this.nullable = nullable;
+		this.nullable = nullable;
 		this.unique = unique;
 	}
 
 	@Override
 	public Nature getNature() {
 		return Nature.COLUMN;
 	}
 
 	@Override
 	public String getContainingTableName() {
 		return tableName;
 	}
 
 	@Override
 	public String getName() {
 		return columnName;
 	}
 
 	@Override
 	public TruthValue isNullable() {
 		return nullable;
 	}
 
 	@Override
 	public String getDefaultValue() {
 		return null;
 	}
 
 	@Override
 	public String getSqlType() {
 		return null;
 	}
 
 	@Override
 	public JdbcDataType getDatatype() {
 		return null;
 	}
 
 	@Override
 	public SizeSource getSizeSource() {
 		return sizeSource;
 	}
 
 	@Override
 	public String getReadFragment() {
 		return null;
 	}
 
 	@Override
 	public String getWriteFragment() {
 		return null;
 	}
 
 	@Override
 	public boolean isUnique() {
 		return unique == TruthValue.TRUE;
 	}
 
 	@Override
 	public String getCheckCondition() {
 		return null;
 	}
 
 	@Override
 	public String getComment() {
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ColumnSourceImpl.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ColumnSourceImpl.java
index a04df63246..685de80283 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ColumnSourceImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ColumnSourceImpl.java
@@ -1,145 +1,145 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.internal.hbm;
 
 
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmColumnType;
 import org.hibernate.boot.model.TruthValue;
 import org.hibernate.boot.model.source.spi.ColumnSource;
 import org.hibernate.boot.model.source.spi.JdbcDataType;
 import org.hibernate.boot.model.source.spi.SizeSource;
 
 /**
  * @author Steve Ebersole
  */
 class ColumnSourceImpl
 		extends AbstractHbmSourceNode
 		implements ColumnSource {
 	private final String tableName;
 	private final JaxbHbmColumnType columnElement;
 	private final TruthValue nullable;
 
 	ColumnSourceImpl(
 			MappingDocument mappingDocument,
 			String tableName,
 			JaxbHbmColumnType columnElement) {
 		this(
 				mappingDocument,
 				tableName,
 				columnElement,
 				interpretNotNullToNullability( columnElement.isNotNull() )
 		);
 	}
 
 	private static TruthValue interpretNotNullToNullability(Boolean notNull) {
 		if ( notNull == null ) {
 			return TruthValue.UNKNOWN;
 		}
 		else {
 			// not-null == nullable, so the booleans are reversed
 			return notNull ? TruthValue.FALSE : TruthValue.TRUE;
 		}
 	}
 
 	ColumnSourceImpl(
 			MappingDocument mappingDocument,
-            String tableName,
+			String tableName,
 			JaxbHbmColumnType columnElement,
-            TruthValue nullable) {
+			TruthValue nullable) {
 		super( mappingDocument );
-        this.tableName = tableName;
-        this.columnElement = columnElement;
-        this.nullable = nullable;
+		this.tableName = tableName;
+		this.columnElement = columnElement;
+		this.nullable = nullable;
 	}
 
 	@Override
 	public Nature getNature() {
 		return Nature.COLUMN;
 	}
 
 	@Override
 	public String getName() {
 		return columnElement.getName();
 	}
 
 	@Override
 	public TruthValue isNullable() {
 		return nullable;
 	}
 
 	@Override
 	public String getDefaultValue() {
 		return columnElement.getDefault();
 	}
 
 	@Override
 	public String getSqlType() {
 		return columnElement.getSqlType();
 	}
 
 	@Override
 	public JdbcDataType getDatatype() {
 		return null;
 	}
 
 	@Override
 	public SizeSource getSizeSource() {
 		return Helper.interpretSizeSource(
 				columnElement.getLength(),
 				columnElement.getScale(),
 				columnElement.getPrecision()
 		);
 	}
 
 	@Override
 	public String getReadFragment() {
 		return columnElement.getRead();
 	}
 
 	@Override
 	public String getWriteFragment() {
 		return columnElement.getWrite();
 	}
 
 	@Override
 	public boolean isUnique() {
 		// TODO: should TruthValue be returned instead of boolean?
 		return columnElement.isUnique() != null && columnElement.isUnique().booleanValue();
 	}
 
 	@Override
 	public String getCheckCondition() {
 		return columnElement.getCheck();
 	}
 
 	@Override
 	public String getComment() {
 		return columnElement.getComment();
 	}
 
 	@Override
 	public String getContainingTableName() {
 		return tableName;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/Helper.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/Helper.java
index 6a2e29fdf5..e646e64b62 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/Helper.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/Helper.java
@@ -1,305 +1,305 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.internal.hbm;
 
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmCacheType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmConfigParameterType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmCustomSqlDmlType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmDiscriminatorSubclassEntityType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmEntityBaseDefinition;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmJoinedSubclassEntityType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmNaturalIdCacheType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmToolingHintType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmUnionSubclassEntityType;
 import org.hibernate.boot.jaxb.hbm.spi.TableInformationContainer;
 import org.hibernate.boot.jaxb.hbm.spi.ToolingHintContainer;
 import org.hibernate.boot.model.Caching;
 import org.hibernate.boot.model.CustomSql;
 import org.hibernate.boot.model.TruthValue;
 import org.hibernate.boot.model.source.spi.InheritanceType;
 import org.hibernate.boot.model.source.spi.SizeSource;
 import org.hibernate.boot.model.source.spi.TableSpecificationSource;
 import org.hibernate.boot.model.source.spi.ToolingHint;
 import org.hibernate.boot.model.source.spi.ToolingHintContext;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public class Helper {
 	public static InheritanceType interpretInheritanceType(JaxbHbmEntityBaseDefinition entityElement) {
 		if ( JaxbHbmDiscriminatorSubclassEntityType.class.isInstance( entityElement ) ) {
 			return InheritanceType.DISCRIMINATED;
 		}
 		else if ( JaxbHbmJoinedSubclassEntityType.class.isInstance( entityElement ) ) {
 			return InheritanceType.JOINED;
 		}
 		else if ( JaxbHbmUnionSubclassEntityType.class.isInstance( entityElement ) ) {
 			return InheritanceType.UNION;
 		}
 		else {
 			return InheritanceType.NO_INHERITANCE;
 		}
 	}
 
 	/**
 	 * Given a user-specified description of how to perform custom SQL, build the {@link CustomSql} representation.
 	 *
 	 * @param customSqlElement User-specified description of how to perform custom SQL
 	 *
 	 * @return The {@link CustomSql} representation
 	 */
 	public static CustomSql buildCustomSql(JaxbHbmCustomSqlDmlType customSqlElement) {
 		if ( customSqlElement == null ) {
 			return null;
 		}
 		final ExecuteUpdateResultCheckStyle checkStyle = customSqlElement.getCheck() == null
 				? customSqlElement.isCallable()
 						? ExecuteUpdateResultCheckStyle.NONE
 						: ExecuteUpdateResultCheckStyle.COUNT
 				: customSqlElement.getCheck();
 		return new CustomSql( customSqlElement.getValue(), customSqlElement.isCallable(), checkStyle );
 	}
 
 	public static Caching createCaching(JaxbHbmCacheType cacheElement) {
 		if ( cacheElement == null ) {
 			// I'd really rather this be UNKNOWN, but the annotation version resolves this to TRUE/FALSE
 			return new Caching( TruthValue.FALSE );
 		}
 
- 		final boolean cacheLazyProps = cacheElement.getInclude() == null
+		final boolean cacheLazyProps = cacheElement.getInclude() == null
 				|| !"non-lazy".equals( cacheElement.getInclude().value() );
 
 		return new Caching(
 				cacheElement.getRegion(),
 				cacheElement.getUsage(),
 				cacheLazyProps,
 				TruthValue.TRUE
 		);
 	}
 
 	public static Caching createNaturalIdCaching(JaxbHbmNaturalIdCacheType cacheElement) {
 		if ( cacheElement == null ) {
 			return new Caching( TruthValue.UNKNOWN );
 		}
 
 		return new Caching(
 				StringHelper.nullIfEmpty( cacheElement.getRegion() ),
 				null,
 				false,
 				TruthValue.TRUE
 		);
 	}
 
 	public static String getPropertyAccessorName(String access, boolean isEmbedded, String defaultAccess) {
 		return getValue( access, isEmbedded ? "embedded" : defaultAccess );
 	}
 
 	public static <T> T getValue(T value, T defaultValue){
 		return value == null ? defaultValue : value;
 	}
 
 	public static Map<String, String> extractParameters(List<JaxbHbmConfigParameterType> xmlParamElements) {
 		if ( xmlParamElements == null || xmlParamElements.isEmpty() ) {
 			return Collections.emptyMap();
 		}
 		final HashMap<String,String> params = new HashMap<String, String>();
 		for ( JaxbHbmConfigParameterType paramElement : xmlParamElements ) {
 			params.put( paramElement.getName(), paramElement.getValue() );
 		}
 		return params;
 	}
 
 	/**
 	 * Operates like SQL coalesce expression, except empty strings are treated as null.  Return the first non-empty value
 	 *
 	 * @param values The list of values.
 	 * @param <T> Generic type of values to coalesce
 	 *
 	 * @return The first non-empty value, or null if all values were empty
 	 */
 	public static <T> T coalesce(T... values) {
 		if ( values == null ) {
 			return null;
 		}
 		for ( T value : values ) {
 			if ( value != null ) {
 				if ( String.class.isInstance( value ) ) {
 					if ( StringHelper.isNotEmpty( (String) value ) ) {
 						return value;
 					}
 				}
 				else {
 					return value;
 				}
 			}
 		}
 		return null;
 	}
 
 	static ToolingHintContext collectToolingHints(
 			ToolingHintContext baseline,
 			ToolingHintContainer toolingHintContainer) {
 		return collectToolingHints( baseline, toolingHintContainer, false );
 	}
 
 	private static ToolingHintContext collectToolingHints(
 			ToolingHintContext baseline,
 			ToolingHintContainer toolingHintContainer,
 			boolean onlyInheritable) {
 		final ToolingHintContext localToolingHints = new ToolingHintContext( baseline );
 
 		if ( toolingHintContainer != null && toolingHintContainer.getToolingHints() != null ) {
 			for ( JaxbHbmToolingHintType toolingHintJaxbBinding : toolingHintContainer.getToolingHints() ) {
 				if ( onlyInheritable && !toolingHintJaxbBinding.isInheritable() ) {
 					continue;
 				}
 
 				final String hintName = toolingHintJaxbBinding.getName();
 				ToolingHint toolingHint = localToolingHints.getToolingHint( hintName );
 
 				if ( toolingHint == null ) {
 					toolingHint = new ToolingHint( hintName, toolingHintJaxbBinding.isInheritable() );
 					localToolingHints.add( toolingHint );
 				}
 				else {
 					if ( baseline != null ) {
 						final ToolingHint inherited = baseline.getToolingHint( hintName );
 						if ( toolingHint == inherited ) {
 							// overriding inherited meta attribute. HBX-621 & HBX-793
 							toolingHint = new ToolingHint( hintName, toolingHintJaxbBinding.isInheritable() );
 							localToolingHints.add( toolingHint );
 						}
 					}
 				}
 
 				toolingHint.addValue( toolingHintJaxbBinding.getValue() );
 			}
 		}
 
 		return localToolingHints;
 	}
 
 	public static TableSpecificationSource createTableSource(
 			MappingDocument mappingDocument,
 			TableInformationContainer entityElement,
 			InLineViewNameInferrer inLineViewNameInferrer) {
 		return createTableSource( mappingDocument, entityElement, inLineViewNameInferrer, null, null, null );
 	}
 
 	public static interface InLineViewNameInferrer {
 		public String inferInLineViewName();
 	}
 
 	public static TableSpecificationSource createTableSource(
 			MappingDocument mappingDocument,
 			TableInformationContainer tableInformationContainer,
 			InLineViewNameInferrer inLineViewNameInferrer,
 			String rowId,
 			String comment,
 			String checkConstraint) {
 		if ( StringHelper.isEmpty( tableInformationContainer.getSubselectAttribute() )
 				&& StringHelper.isEmpty( tableInformationContainer.getSubselect() ) ) {
 			return new TableSourceImpl(
 					mappingDocument,
 					tableInformationContainer.getSchema(),
 					tableInformationContainer.getCatalog(),
 					tableInformationContainer.getTable(),
 					rowId,
 					comment,
 					checkConstraint
 			);
 		}
 		else {
 			return new InLineViewSourceImpl(
 					mappingDocument,
 					tableInformationContainer.getSchema(),
 					tableInformationContainer.getCatalog(),
 					tableInformationContainer.getSubselectAttribute() != null
 							? tableInformationContainer.getSubselectAttribute()
 							: tableInformationContainer.getSubselect(),
 					tableInformationContainer.getTable() == null
 							? inLineViewNameInferrer.inferInLineViewName()
 							: tableInformationContainer.getTable()
 			);
 		}
 	}
 
 	public static SizeSource interpretSizeSource(Integer length, Integer scale, Integer precision) {
 		if ( length != null || precision != null || scale != null ) {
 			return new SizeSourceImpl( length, scale, precision );
 		}
 		return null;
 	}
 
 	public static SizeSource interpretSizeSource(Integer length, String scale, String precision) {
 		return interpretSizeSource(
 				length,
 				scale == null ? null : Integer.parseInt( scale ),
 				precision == null ? null : Integer.parseInt( precision )
 		);
 	}
 
 	public static Class reflectedPropertyClass(
 			MetadataBuildingContext buildingContext,
 			String attributeOwnerClassName,
 			String attributeName) {
 		final Class attributeOwnerClass = buildingContext.getClassLoaderAccess().classForName( attributeOwnerClassName );
 		return reflectedPropertyClass(
 				buildingContext,
 				attributeOwnerClass,
 				attributeName
 		);
 	}
 
 	public static Class reflectedPropertyClass(
 			MetadataBuildingContext buildingContext,
 			Class attributeOwnerClass,
 			final String attributeName) {
 //		return BeanInfoHelper.visitBeanInfo(
 //				attributeOwnerClass,
 //				new BeanInfoHelper.ReturningBeanInfoDelegate<Class>() {
 //					@Override
 //					public Class processBeanInfo(BeanInfo beanInfo) throws Exception {
 //						for ( PropertyDescriptor propertyDescriptor : beanInfo.getPropertyDescriptors() ) {
 //							if ( propertyDescriptor.getName().equals( attributeName ) ) {
 //								return propertyDescriptor.getPropertyType();
 //							}
 //						}
 //						return null;
 //					}
 //				}
 //		);
 		return ReflectHelper.reflectedPropertyClass( attributeOwnerClass, attributeName );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/SubclassEntitySourceImpl.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/SubclassEntitySourceImpl.java
index 18b8ee051b..54d78c2c9e 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/SubclassEntitySourceImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/SubclassEntitySourceImpl.java
@@ -1,71 +1,71 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.internal.hbm;
 
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmDiscriminatorSubclassEntityType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmEntityBaseDefinition;
 import org.hibernate.boot.jaxb.hbm.spi.TableInformationContainer;
 import org.hibernate.boot.model.source.spi.EntitySource;
 import org.hibernate.boot.model.source.spi.IdentifiableTypeSource;
 import org.hibernate.boot.model.source.spi.SubclassEntitySource;
 import org.hibernate.boot.model.source.spi.TableSpecificationSource;
 
 /**
  * @author Steve Ebersole
  */
 public class SubclassEntitySourceImpl extends AbstractEntitySourceImpl implements SubclassEntitySource {
-    private final EntitySource container;
+	private final EntitySource container;
 	private final TableSpecificationSource primaryTable;
 
 	protected SubclassEntitySourceImpl(
 			MappingDocument sourceMappingDocument,
 			JaxbHbmEntityBaseDefinition entityElement,
 			EntitySource container) {
 		super( sourceMappingDocument, entityElement );
 		this.container = container;
 
 		this.primaryTable = TableInformationContainer.class.isInstance( entityElement )
 				? Helper.createTableSource( sourceMappingDocument(), (TableInformationContainer) entityElement, this )
 				: null;
 
 		afterInstantiation();
 	}
 
 	@Override
 	public TableSpecificationSource getPrimaryTable() {
 		return primaryTable;
 	}
 
 	@Override
 	public String getDiscriminatorMatchValue() {
 		return JaxbHbmDiscriminatorSubclassEntityType.class.isInstance( jaxbEntityMapping() )
 				? ( (JaxbHbmDiscriminatorSubclassEntityType) jaxbEntityMapping() ).getDiscriminatorValue()
 				: null;
 	}
 
 	@Override
 	public IdentifiableTypeSource getSuperType() {
 		return container;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/spi/CompositeIdentifierSource.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/spi/CompositeIdentifierSource.java
index ca92fd66d3..70d1bb496a 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/spi/CompositeIdentifierSource.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/spi/CompositeIdentifierSource.java
@@ -1,45 +1,45 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.spi;
 
 import org.hibernate.boot.model.IdentifierGeneratorDefinition;
 
 /**
  * Common contract for composite identifiers.  Specific sub-types include aggregated
  * (think {@link javax.persistence.EmbeddedId}) and non-aggregated (think
  * {@link javax.persistence.IdClass}).
  *
  * @author Steve Ebersole
  */
 public interface CompositeIdentifierSource extends IdentifierSource, EmbeddableSourceContributor {
 	/**
 	 * Handle silly SpecJ reading of the JPA spec.  They believe composite identifiers should have "partial generation"
 	 * capabilities.
 	 *
 	 * @param identifierAttributeName The name of the individual attribute within the composite identifier.
 	 *
 	 * @return The generator for the named attribute (within the composite).
 	 */
-	public IdentifierGeneratorDefinition getIndividualAttributeIdGenerator(String identifierAttributeName);
-}
\ No newline at end of file
+	IdentifierGeneratorDefinition getIndividualAttributeIdGenerator(String identifierAttributeName);
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/spi/VersionAttributeSource.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/spi/VersionAttributeSource.java
index 28c669cd02..6da6e3d63c 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/spi/VersionAttributeSource.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/spi/VersionAttributeSource.java
@@ -1,34 +1,34 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.spi;
 
 import org.hibernate.boot.model.naming.ImplicitBasicColumnNameSource;
 
 /**
  * @author Steve Ebersole
  */
 public interface VersionAttributeSource
 		extends SingularAttributeSource, RelationalValueSourceContainer, ImplicitBasicColumnNameSource {
-	public String getUnsavedValue();
-}
\ No newline at end of file
+	String getUnsavedValue();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/AbstractHANADialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/AbstractHANADialect.java
index 24c185c8b7..a2938865e7 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/AbstractHANADialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/AbstractHANADialect.java
@@ -1,709 +1,707 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.io.FilterReader;
 import java.io.Reader;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.ScrollMode;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.dialect.function.AnsiTrimFunction;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.jdbc.CharacterStream;
 import org.hibernate.engine.jdbc.ClobImplementer;
 import org.hibernate.engine.jdbc.NClobImplementer;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.exception.ConstraintViolationException;
 import org.hibernate.exception.LockAcquisitionException;
 import org.hibernate.exception.LockTimeoutException;
 import org.hibernate.exception.SQLGrammarException;
 import org.hibernate.exception.spi.SQLExceptionConversionDelegate;
-import org.hibernate.hql.spi.id.IdTableSupport;
 import org.hibernate.hql.spi.id.IdTableSupportStandardImpl;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.global.GlobalTemporaryTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.AfterUseAction;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 import org.hibernate.type.descriptor.sql.BasicBinder;
 import org.hibernate.type.descriptor.sql.BitTypeDescriptor;
 import org.hibernate.type.descriptor.sql.ClobTypeDescriptor;
 import org.hibernate.type.descriptor.sql.NClobTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SmallIntTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 /**
  * An abstract base class for HANA dialects. <br/>
  * <a href="http://help.sap.com/hana/html/sqlmain.html">SAP HANA Reference</a> <br/>
  *
  * NOTE: This dialect is currently configured to create foreign keys with
  * <code>on update cascade</code>.
  *
  * @author Andrew Clemons <andrew.clemons@sap.com>
  */
 public abstract class AbstractHANADialect extends Dialect {
 
 	private static final AbstractLimitHandler LIMIT_HANDLER = new AbstractLimitHandler() {
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final boolean hasOffset = LimitHelper.hasFirstRow( selection );
-			return new StringBuilder( sql.length() + 20 ).append( sql )
-					.append( hasOffset ? " limit ? offset ?" : " limit ?" ).toString();
+			return sql + ( hasOffset ? " limit ? offset ?" : " limit ?" );
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return true;
 		}
 
 		@Override
 		public boolean bindLimitParametersInReverseOrder() {
 			return true;
 		}
 	};
 
 	private static class CloseSuppressingReader extends FilterReader {
 		protected CloseSuppressingReader(final Reader in) {
 			super( in );
 		}
 
 		@Override
 		public void close() {
 			// do not close
 		}
 	}
 
 	// the ClobTypeDescriptor and NClobTypeDescriptor for HANA are slightly
 	// changed from the standard ones. The HANA JDBC driver currently closes any
 	// stream passed in via
 	// PreparedStatement.setCharacterStream(int,Reader,long)
 	// after the stream has been processed. this causes problems later if we are
 	// using non-contexual lob creation and HANA then closes our StringReader.
 	// see test case LobLocatorTest
 
 	private static final ClobTypeDescriptor HANA_CLOB_STREAM_BINDING = new ClobTypeDescriptor() {
 		/** serial version uid. */
 		private static final long serialVersionUID = -379042275442752102L;
 
 		@Override
 		public <X> BasicBinder<X> getClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
 				protected void doBind(final PreparedStatement st, final X value, final int index,
 						final WrapperOptions options) throws SQLException {
 					final CharacterStream characterStream = javaTypeDescriptor.unwrap( value, CharacterStream.class,
 							options );
 
 					if ( value instanceof ClobImplementer ) {
 						st.setCharacterStream( index, new CloseSuppressingReader( characterStream.asReader() ),
 								characterStream.getLength() );
 					}
 					else {
 						st.setCharacterStream( index, characterStream.asReader(), characterStream.getLength() );
 					}
 
 				}
 			};
 		}
 	};
 
 	private static final NClobTypeDescriptor HANA_NCLOB_STREAM_BINDING = new NClobTypeDescriptor() {
 		/** serial version uid. */
 		private static final long serialVersionUID = 5651116091681647859L;
 
 		@Override
 		public <X> BasicBinder<X> getNClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
 				protected void doBind(final PreparedStatement st, final X value, final int index,
 						final WrapperOptions options) throws SQLException {
 					final CharacterStream characterStream = javaTypeDescriptor.unwrap( value, CharacterStream.class,
 							options );
 
 					if ( value instanceof NClobImplementer ) {
 						st.setCharacterStream( index, new CloseSuppressingReader( characterStream.asReader() ),
 								characterStream.getLength() );
 					}
 					else {
 						st.setCharacterStream( index, characterStream.asReader(), characterStream.getLength() );
 					}
 
 				}
 			};
 		}
 	};
 
 	public AbstractHANADialect() {
 		super();
 
 		registerColumnType( Types.DECIMAL, "decimal($p, $s)" );
 		registerColumnType( Types.DOUBLE, "double" );
 
 		// varbinary max length 5000
 		registerColumnType( Types.BINARY, 5000, "varbinary($l)" );
 		registerColumnType( Types.VARBINARY, 5000, "varbinary($l)" );
 		registerColumnType( Types.LONGVARBINARY, 5000, "varbinary($l)" );
 
 		// for longer values, map to blob
 		registerColumnType( Types.BINARY, "blob" );
 		registerColumnType( Types.VARBINARY, "blob" );
 		registerColumnType( Types.LONGVARBINARY, "blob" );
 
 		registerColumnType( Types.CHAR, "varchar(1)" );
 		registerColumnType( Types.VARCHAR, 5000, "varchar($l)" );
 		registerColumnType( Types.LONGVARCHAR, 5000, "varchar($l)" );
 		registerColumnType( Types.NVARCHAR, 5000, "nvarchar($l)" );
 
 		// for longer values map to clob/nclob
 		registerColumnType( Types.LONGVARCHAR, "clob" );
 		registerColumnType( Types.VARCHAR, "clob" );
 		registerColumnType( Types.NVARCHAR, "nclob" );
 		registerColumnType( Types.CLOB, "clob" );
 
 		registerColumnType( Types.BOOLEAN, "tinyint" );
 
 		// map bit/tinyint to smallint since tinyint is unsigned on HANA
 		registerColumnType( Types.BIT, "smallint" );
 		registerColumnType( Types.TINYINT, "smallint" );
 
 		registerHibernateType( Types.NCLOB, StandardBasicTypes.NCLOB.getName() );
 		registerHibernateType( Types.NVARCHAR, StandardBasicTypes.STRING.getName() );
 
 		registerFunction( "to_date", new StandardSQLFunction( "to_date", StandardBasicTypes.DATE ) );
 		registerFunction( "to_seconddate", new StandardSQLFunction( "to_seconddate", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "to_time", new StandardSQLFunction( "to_time", StandardBasicTypes.TIME ) );
 		registerFunction( "to_timestamp", new StandardSQLFunction( "to_timestamp", StandardBasicTypes.TIMESTAMP ) );
 
 		registerFunction( "current_date", new NoArgSQLFunction( "current_date", StandardBasicTypes.DATE, false ) );
 		registerFunction( "current_time", new NoArgSQLFunction( "current_time", StandardBasicTypes.TIME, false ) );
 		registerFunction( "current_timestamp", new NoArgSQLFunction( "current_timestamp", StandardBasicTypes.TIMESTAMP,
 				false ) );
 		registerFunction( "current_utcdate", new NoArgSQLFunction( "current_utcdate", StandardBasicTypes.DATE, false ) );
 		registerFunction( "current_utctime", new NoArgSQLFunction( "current_utctime", StandardBasicTypes.TIME, false ) );
 		registerFunction( "current_utctimestamp", new NoArgSQLFunction( "current_utctimestamp",
 				StandardBasicTypes.TIMESTAMP, false ) );
 
 		registerFunction( "add_days", new StandardSQLFunction( "add_days" ) );
 		registerFunction( "add_months", new StandardSQLFunction( "add_months" ) );
 		registerFunction( "add_seconds", new StandardSQLFunction( "add_seconds" ) );
 		registerFunction( "add_years", new StandardSQLFunction( "add_years" ) );
 		registerFunction( "dayname", new StandardSQLFunction( "dayname", StandardBasicTypes.STRING ) );
 		registerFunction( "dayofmonth", new StandardSQLFunction( "dayofmonth", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofyear", new StandardSQLFunction( "dayofyear", StandardBasicTypes.INTEGER ) );
 		registerFunction( "days_between", new StandardSQLFunction( "days_between", StandardBasicTypes.INTEGER ) );
 		registerFunction( "hour", new StandardSQLFunction( "hour", StandardBasicTypes.INTEGER ) );
 		registerFunction( "isoweek", new StandardSQLFunction( "isoweek", StandardBasicTypes.STRING ) );
 		registerFunction( "last_day", new StandardSQLFunction( "last_day", StandardBasicTypes.DATE ) );
 		registerFunction( "localtoutc", new StandardSQLFunction( "localtoutc", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "minute", new StandardSQLFunction( "minute", StandardBasicTypes.INTEGER ) );
 		registerFunction( "month", new StandardSQLFunction( "month", StandardBasicTypes.INTEGER ) );
 		registerFunction( "monthname", new StandardSQLFunction( "monthname", StandardBasicTypes.STRING ) );
 		registerFunction( "next_day", new StandardSQLFunction( "next_day", StandardBasicTypes.DATE ) );
 		registerFunction( "now", new NoArgSQLFunction( "now", StandardBasicTypes.TIMESTAMP, true ) );
 		registerFunction( "quarter", new StandardSQLFunction( "quarter", StandardBasicTypes.STRING ) );
 		registerFunction( "second", new StandardSQLFunction( "second", StandardBasicTypes.INTEGER ) );
 		registerFunction( "seconds_between", new StandardSQLFunction( "seconds_between", StandardBasicTypes.LONG ) );
 		registerFunction( "week", new StandardSQLFunction( "week", StandardBasicTypes.INTEGER ) );
 		registerFunction( "weekday", new StandardSQLFunction( "weekday", StandardBasicTypes.INTEGER ) );
 		registerFunction( "year", new StandardSQLFunction( "year", StandardBasicTypes.INTEGER ) );
 		registerFunction( "utctolocal", new StandardSQLFunction( "utctolocal", StandardBasicTypes.TIMESTAMP ) );
 
 		registerFunction( "to_bigint", new StandardSQLFunction( "to_bigint", StandardBasicTypes.LONG ) );
 		registerFunction( "to_binary", new StandardSQLFunction( "to_binary", StandardBasicTypes.BINARY ) );
 		registerFunction( "to_decimal", new StandardSQLFunction( "to_decimal", StandardBasicTypes.BIG_DECIMAL ) );
 		registerFunction( "to_double", new StandardSQLFunction( "to_double", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "to_int", new StandardSQLFunction( "to_int", StandardBasicTypes.INTEGER ) );
 		registerFunction( "to_integer", new StandardSQLFunction( "to_integer", StandardBasicTypes.INTEGER ) );
 		registerFunction( "to_real", new StandardSQLFunction( "to_real", StandardBasicTypes.FLOAT ) );
 		registerFunction( "to_smalldecimal",
 				new StandardSQLFunction( "to_smalldecimal", StandardBasicTypes.BIG_DECIMAL ) );
 		registerFunction( "to_smallint", new StandardSQLFunction( "to_smallint", StandardBasicTypes.SHORT ) );
 		registerFunction( "to_tinyint", new StandardSQLFunction( "to_tinyint", StandardBasicTypes.BYTE ) );
 
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "acos", new StandardSQLFunction( "acos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "asin", new StandardSQLFunction( "asin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan2", new StandardSQLFunction( "atan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "bin2hex", new StandardSQLFunction( "bin2hex", StandardBasicTypes.STRING ) );
 		registerFunction( "bitand", new StandardSQLFunction( "bitand", StandardBasicTypes.LONG ) );
 		registerFunction( "ceil", new StandardSQLFunction( "ceil" ) );
 		registerFunction( "cos", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cosh", new StandardSQLFunction( "cosh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cot", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "exp", new StandardSQLFunction( "exp", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "floor", new StandardSQLFunction( "floor" ) );
 		registerFunction( "greatest", new StandardSQLFunction( "greatest" ) );
 		registerFunction( "hex2bin", new StandardSQLFunction( "hex2bin", StandardBasicTypes.BINARY ) );
 		registerFunction( "least", new StandardSQLFunction( "least" ) );
 		registerFunction( "ln", new StandardSQLFunction( "ln", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log", new StandardSQLFunction( "ln", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "power", new StandardSQLFunction( "power" ) );
 		registerFunction( "round", new StandardSQLFunction( "round" ) );
 		registerFunction( "mod", new StandardSQLFunction( "mod", StandardBasicTypes.INTEGER ) );
 		registerFunction( "sign", new StandardSQLFunction( "sign", StandardBasicTypes.INTEGER ) );
 		registerFunction( "sin", new StandardSQLFunction( "sin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sinh", new StandardSQLFunction( "sinh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sqrt", new StandardSQLFunction( "sqrt", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tan", new StandardSQLFunction( "tan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tanh", new StandardSQLFunction( "tanh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "uminus", new StandardSQLFunction( "uminus" ) );
 
 		registerFunction( "to_alphanum", new StandardSQLFunction( "to_alphanum", StandardBasicTypes.STRING ) );
 		registerFunction( "to_nvarchar", new StandardSQLFunction( "to_nvarchar", StandardBasicTypes.STRING ) );
 		registerFunction( "to_varchar", new StandardSQLFunction( "to_varchar", StandardBasicTypes.STRING ) );
 
 		registerFunction( "ascii", new StandardSQLFunction( "ascii", StandardBasicTypes.INTEGER ) );
 		registerFunction( "char", new StandardSQLFunction( "char", StandardBasicTypes.CHARACTER ) );
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(", "||", ")" ) );
 		registerFunction( "lcase", new StandardSQLFunction( "lcase", StandardBasicTypes.STRING ) );
 		registerFunction( "left", new StandardSQLFunction( "left", StandardBasicTypes.STRING ) );
 		registerFunction( "length", new StandardSQLFunction( "length", StandardBasicTypes.LONG ) );
 		registerFunction( "locate", new StandardSQLFunction( "locate", StandardBasicTypes.INTEGER ) );
 		registerFunction( "lpad", new StandardSQLFunction( "lpad", StandardBasicTypes.STRING ) );
 		registerFunction( "ltrim", new StandardSQLFunction( "ltrim", StandardBasicTypes.STRING ) );
 		registerFunction( "nchar", new StandardSQLFunction( "nchar", StandardBasicTypes.STRING ) );
 		registerFunction( "replace", new StandardSQLFunction( "replace", StandardBasicTypes.STRING ) );
 		registerFunction( "right", new StandardSQLFunction( "right", StandardBasicTypes.STRING ) );
 		registerFunction( "rpad", new StandardSQLFunction( "rpad", StandardBasicTypes.STRING ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim", StandardBasicTypes.STRING ) );
 		registerFunction( "substr_after", new StandardSQLFunction( "substr_after", StandardBasicTypes.STRING ) );
 		registerFunction( "substr_before", new StandardSQLFunction( "substr_before", StandardBasicTypes.STRING ) );
 		registerFunction( "substring", new StandardSQLFunction( "substring", StandardBasicTypes.STRING ) );
 		registerFunction( "trim", new AnsiTrimFunction() );
 		registerFunction( "ucase", new StandardSQLFunction( "ucase", StandardBasicTypes.STRING ) );
 		registerFunction( "unicode", new StandardSQLFunction( "unicode", StandardBasicTypes.INTEGER ) );
 		registerFunction( "bit_length", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "length(to_binary(?1))*8" ) );
 
 		registerFunction( "to_blob", new StandardSQLFunction( "to_blob", StandardBasicTypes.BLOB ) );
 		registerFunction( "to_clob", new StandardSQLFunction( "to_clob", StandardBasicTypes.CLOB ) );
 		registerFunction( "to_nclob", new StandardSQLFunction( "to_nclob", StandardBasicTypes.NCLOB ) );
 
 		registerFunction( "coalesce", new StandardSQLFunction( "coalesce" ) );
 		registerFunction( "current_connection", new NoArgSQLFunction( "current_connection", StandardBasicTypes.INTEGER,
 				false ) );
 		registerFunction( "current_schema", new NoArgSQLFunction( "current_schema", StandardBasicTypes.STRING, false ) );
 		registerFunction( "current_user", new NoArgSQLFunction( "current_user", StandardBasicTypes.STRING, false ) );
 		registerFunction( "grouping_id", new VarArgsSQLFunction( StandardBasicTypes.INTEGER, "(", ",", ")" ) );
 		registerFunction( "ifnull", new StandardSQLFunction( "ifnull" ) );
 		registerFunction( "map", new StandardSQLFunction( "map" ) );
 		registerFunction( "nullif", new StandardSQLFunction( "nullif" ) );
 		registerFunction( "session_context", new StandardSQLFunction( "session_context" ) );
 		registerFunction( "session_user", new NoArgSQLFunction( "session_user", StandardBasicTypes.STRING, false ) );
 		registerFunction( "sysuuid", new NoArgSQLFunction( "sysuuid", StandardBasicTypes.STRING, false ) );
 
 		registerHanaKeywords();
 
 		// createBlob() and createClob() are not supported by the HANA JDBC driver
 		getDefaultProperties().setProperty( AvailableSettings.NON_CONTEXTUAL_LOB_CREATION, "true" );
 	}
 
 	@Override
 	public boolean bindLimitParametersInReverseOrder() {
 		return true;
 	}
 
 	@Override
 	public SQLExceptionConversionDelegate buildSQLExceptionConversionDelegate() {
 		return new SQLExceptionConversionDelegate() {
 			@Override
 			public JDBCException convert(final SQLException sqlException, final String message, final String sql) {
 
 				final int errorCode = JdbcExceptionHelper.extractErrorCode( sqlException );
 
 				if ( errorCode == 131 ) {
 					// 131 - Transaction rolled back by lock wait timeout
 					return new LockTimeoutException( message, sqlException, sql );
 				}
 
 				if ( errorCode == 146 ) {
 					// 146 - Resource busy and acquire with NOWAIT specified
 					return new LockTimeoutException( message, sqlException, sql );
 				}
 
 				if ( errorCode == 132 ) {
 					// 132 - Transaction rolled back due to unavailable resource
 					return new LockAcquisitionException( message, sqlException, sql );
 				}
 
 				if ( errorCode == 133 ) {
 					// 133 - Transaction rolled back by detected deadlock
 					return new LockAcquisitionException( message, sqlException, sql );
 				}
 
 				// 259 - Invalid table name
 				// 260 - Invalid column name
 				// 261 - Invalid index name
 				// 262 - Invalid query name
 				// 263 - Invalid alias name
 				if ( errorCode == 257 || ( errorCode >= 259 && errorCode <= 263 ) ) {
 					throw new SQLGrammarException( message, sqlException, sql );
 				}
 
 				// 257 - Cannot insert NULL or update to NULL
 				// 301 - Unique constraint violated
 				// 461 - foreign key constraint violation
 				// 462 - failed on update or delete by foreign key constraint violation
 				if ( errorCode == 287 || errorCode == 301 || errorCode == 461 || errorCode == 462 ) {
 					final String constraintName = getViolatedConstraintNameExtracter().extractConstraintName(
 							sqlException );
 
 					return new ConstraintViolationException( message, sqlException, sql, constraintName );
 				}
 
 				return null;
 			}
 		};
 	}
 
 	@Override
 	public boolean forUpdateOfColumns() {
 		return true;
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add (";
 	}
 
 	@Override
 	public String getAddColumnSuffixString() {
 		return ")";
 	}
 
 	@Override
 	public String getCascadeConstraintsString() {
 		return " cascade";
 	}
 
 	@Override
 	public String getCreateSequenceString(final String sequenceName) {
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getDefaultMultiTableBulkIdStrategy() {
 		return new GlobalTemporaryTableBulkIdStrategy(
 				new IdTableSupportStandardImpl() {
 					@Override
 					public String getCreateIdTableCommand() {
 						return "create global temporary table";
 					}
 				},
 				AfterUseAction.CLEAN
 		);
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select current_timestamp from dummy";
 	}
 
 	@Override
 	public String getDropSequenceString(final String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getForUpdateString(final String aliases) {
 		return getForUpdateString() + " of " + aliases;
 	}
 
 	@Override
 	public String getForUpdateString(final String aliases, final LockOptions lockOptions) {
 		LockMode lockMode = lockOptions.getLockMode();
 		final Iterator<Map.Entry<String, LockMode>> itr = lockOptions.getAliasLockIterator();
 		while ( itr.hasNext() ) {
 			// seek the highest lock mode
 			final Map.Entry<String, LockMode> entry = itr.next();
 			final LockMode lm = entry.getValue();
 			if ( lm.greaterThan( lockMode ) ) {
 				lockMode = lm;
 			}
 		}
 
 		// not sure why this is sometimes empty
 		if ( aliases == null || "".equals( aliases ) ) {
 			return getForUpdateString( lockMode );
 		}
 
 		return getForUpdateString( lockMode ) + " of " + aliases;
 	}
 
 	@Override
 	public String getLimitString(final String sql, final boolean hasOffset) {
 		return new StringBuilder( sql.length() + 20 ).append( sql )
 				.append( hasOffset ? " limit ? offset ?" : " limit ?" ).toString();
 	}
 
 	@Override
 	public String getNotExpression(final String expression) {
 		return "not (" + expression + ")";
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select sequence_name from sys.sequences";
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(final String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	@Override
 	public String getSequenceNextValString(final String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from dummy";
 	}
 
 	@Override
 	protected SqlTypeDescriptor getSqlTypeDescriptorOverride(final int sqlCode) {
 		switch ( sqlCode ) {
 		case Types.BOOLEAN:
 			return BitTypeDescriptor.INSTANCE;
 		case Types.CLOB:
 			return HANA_CLOB_STREAM_BINDING;
 		case Types.NCLOB:
 			return HANA_NCLOB_STREAM_BINDING;
 		case Types.TINYINT:
 			// tinyint is unsigned on HANA
 			return SmallIntTypeDescriptor.INSTANCE;
 		default:
 			return super.getSqlTypeDescriptorOverride( sqlCode );
 		}
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	protected void registerHanaKeywords() {
 		registerKeyword( "all" );
 		registerKeyword( "alter" );
 		registerKeyword( "as" );
 		registerKeyword( "before" );
 		registerKeyword( "begin" );
 		registerKeyword( "both" );
 		registerKeyword( "case" );
 		registerKeyword( "char" );
 		registerKeyword( "condition" );
 		registerKeyword( "connect" );
 		registerKeyword( "cross" );
 		registerKeyword( "cube" );
 		registerKeyword( "current_connection" );
 		registerKeyword( "current_date" );
 		registerKeyword( "current_schema" );
 		registerKeyword( "current_time" );
 		registerKeyword( "current_timestamp" );
 		registerKeyword( "current_user" );
 		registerKeyword( "current_utcdate" );
 		registerKeyword( "current_utctime" );
 		registerKeyword( "current_utctimestamp" );
 		registerKeyword( "currval" );
 		registerKeyword( "cursor" );
 		registerKeyword( "declare" );
 		registerKeyword( "distinct" );
 		registerKeyword( "else" );
 		registerKeyword( "elseif" );
 		registerKeyword( "elsif" );
 		registerKeyword( "end" );
 		registerKeyword( "except" );
 		registerKeyword( "exception" );
 		registerKeyword( "exec" );
 		registerKeyword( "for" );
 		registerKeyword( "from" );
 		registerKeyword( "full" );
 		registerKeyword( "group" );
 		registerKeyword( "having" );
 		registerKeyword( "if" );
 		registerKeyword( "in" );
 		registerKeyword( "inner" );
 		registerKeyword( "inout" );
 		registerKeyword( "intersect" );
 		registerKeyword( "into" );
 		registerKeyword( "is" );
 		registerKeyword( "join" );
 		registerKeyword( "leading" );
 		registerKeyword( "left" );
 		registerKeyword( "limit" );
 		registerKeyword( "loop" );
 		registerKeyword( "minus" );
 		registerKeyword( "natural" );
 		registerKeyword( "nextval" );
 		registerKeyword( "null" );
 		registerKeyword( "on" );
 		registerKeyword( "order" );
 		registerKeyword( "out" );
 		registerKeyword( "prior" );
 		registerKeyword( "return" );
 		registerKeyword( "returns" );
 		registerKeyword( "reverse" );
 		registerKeyword( "right" );
 		registerKeyword( "rollup" );
 		registerKeyword( "rowid" );
 		registerKeyword( "select" );
 		registerKeyword( "set" );
 		registerKeyword( "sql" );
 		registerKeyword( "start" );
 		registerKeyword( "sysdate" );
 		registerKeyword( "systime" );
 		registerKeyword( "systimestamp" );
 		registerKeyword( "sysuuid" );
 		registerKeyword( "top" );
 		registerKeyword( "trailing" );
 		registerKeyword( "union" );
 		registerKeyword( "using" );
 		registerKeyword( "utcdate" );
 		registerKeyword( "utctime" );
 		registerKeyword( "utctimestamp" );
 		registerKeyword( "values" );
 		registerKeyword( "when" );
 		registerKeyword( "where" );
 		registerKeyword( "while" );
 		registerKeyword( "with" );
 	}
 
 	@Override
 	public boolean supportsCircularCascadeDeleteConstraints() {
 		// HANA does not support circular constraints
 		return false;
 	}
 
 	@Override
 	public ScrollMode defaultScrollMode() {
 		return ScrollMode.FORWARD_ONLY;
 	}
 
 	/**
 	 * HANA currently does not support check constraints.
 	 */
 	@Override
 	public boolean supportsColumnCheck() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsExistsInSelect() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsExpectedLobUsagePattern() {
 		// http://scn.sap.com/thread/3221812
 		return false;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsTableCheck() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsTupleDistinctCounts() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 	@Override
 	public boolean dropConstraints() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsRowValueConstructorSyntax() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsRowValueConstructorSyntaxInInList() {
 		return true;
 	}
 
 	@Override
 	public int getMaxAliasLength() {
 		return 128;
 	}
 
 	/**
 	 * The default behaviour for 'on update restrict' on HANA is currently
 	 * to not allow any updates to any column of a row if the row has a 
 	 * foreign key. Make the default for foreign keys have 'on update cascade'
 	 * to work around the issue.
 	 */
 	@Override
 	public String getAddForeignKeyConstraintString(final String constraintName, final String[] foreignKey,
 			final String referencedTable, final String[] primaryKey, final boolean referencesPrimaryKey) {
 		return super.getAddForeignKeyConstraintString(constraintName, foreignKey, referencedTable, primaryKey, referencesPrimaryKey) + " on update cascade";
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return LIMIT_HANDLER;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/CUBRIDDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/CUBRIDDialect.java
index e3bfd242bd..007041ccef 100755
--- a/hibernate-core/src/main/java/org/hibernate/dialect/CUBRIDDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/CUBRIDDialect.java
@@ -1,381 +1,380 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.Types;
 
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.pagination.CUBRIDLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
-import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * An SQL dialect for CUBRID (8.3.x and later).
  *
  * @author Seok Jeong Il
  */
 public class CUBRIDDialect extends Dialect {
 	/**
 	 * Constructs a CUBRIDDialect
 	 */
 	public CUBRIDDialect() {
 		super();
 
 		registerColumnType( Types.BIGINT, "bigint" );
 		registerColumnType( Types.BIT, "bit(8)" );
 		registerColumnType( Types.BLOB, "bit varying(65535)" );
 		registerColumnType( Types.BOOLEAN, "bit(8)" );
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.CLOB, "string" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.DECIMAL, "decimal" );
 		registerColumnType( Types.DOUBLE, "double" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.INTEGER, "int" );
 		registerColumnType( Types.NUMERIC, "numeric($p,$s)" );
 		registerColumnType( Types.REAL, "double" );
 		registerColumnType( Types.SMALLINT, "short" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.TINYINT, "short" );
 		registerColumnType( Types.VARBINARY, 2000, "bit varying($l)" );
 		registerColumnType( Types.VARCHAR, "string" );
 		registerColumnType( Types.VARCHAR, 2000, "varchar($l)" );
 		registerColumnType( Types.VARCHAR, 255, "varchar($l)" );
 
 		getDefaultProperties().setProperty( Environment.USE_STREAMS_FOR_BINARY, "true" );
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 
 		registerFunction( "ascii", new StandardSQLFunction( "ascii", StandardBasicTypes.INTEGER ) );
 		registerFunction( "bin", new StandardSQLFunction( "bin", StandardBasicTypes.STRING ) );
 		registerFunction( "char_length", new StandardSQLFunction( "char_length", StandardBasicTypes.LONG ) );
 		registerFunction( "character_length", new StandardSQLFunction( "character_length", StandardBasicTypes.LONG ) );
 		registerFunction( "lengthb", new StandardSQLFunction( "lengthb", StandardBasicTypes.LONG ) );
 		registerFunction( "lengthh", new StandardSQLFunction( "lengthh", StandardBasicTypes.LONG ) );
 		registerFunction( "lcase", new StandardSQLFunction( "lcase" ) );
 		registerFunction( "lower", new StandardSQLFunction( "lower" ) );
 		registerFunction( "ltrim", new StandardSQLFunction( "ltrim" ) );
 		registerFunction( "reverse", new StandardSQLFunction( "reverse" ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim" ) );
 		registerFunction( "trim", new StandardSQLFunction( "trim" ) );
 		registerFunction( "space", new StandardSQLFunction( "space", StandardBasicTypes.STRING ) );
 		registerFunction( "ucase", new StandardSQLFunction( "ucase" ) );
 		registerFunction( "upper", new StandardSQLFunction( "upper" ) );
 
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "sign", new StandardSQLFunction( "sign", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "acos", new StandardSQLFunction( "acos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "asin", new StandardSQLFunction( "asin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan", new StandardSQLFunction( "atan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cos", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cot", new StandardSQLFunction( "cot", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "exp", new StandardSQLFunction( "exp", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "ln", new StandardSQLFunction( "ln", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log2", new StandardSQLFunction( "log2", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log10", new StandardSQLFunction( "log10", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "pi", new NoArgSQLFunction( "pi", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "rand", new NoArgSQLFunction( "rand", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "random", new NoArgSQLFunction( "random", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sin", new StandardSQLFunction( "sin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sqrt", new StandardSQLFunction( "sqrt", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tan", new StandardSQLFunction( "tan", StandardBasicTypes.DOUBLE ) );
 
 		registerFunction( "radians", new StandardSQLFunction( "radians", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "degrees", new StandardSQLFunction( "degrees", StandardBasicTypes.DOUBLE ) );
 
 		registerFunction( "ceil", new StandardSQLFunction( "ceil", StandardBasicTypes.INTEGER ) );
 		registerFunction( "floor", new StandardSQLFunction( "floor", StandardBasicTypes.INTEGER ) );
 		registerFunction( "round", new StandardSQLFunction( "round" ) );
 
 		registerFunction( "datediff", new StandardSQLFunction( "datediff", StandardBasicTypes.INTEGER ) );
 		registerFunction( "timediff", new StandardSQLFunction( "timediff", StandardBasicTypes.TIME ) );
 
 		registerFunction( "date", new StandardSQLFunction( "date", StandardBasicTypes.DATE ) );
 		registerFunction( "curdate", new NoArgSQLFunction( "curdate", StandardBasicTypes.DATE ) );
 		registerFunction( "current_date", new NoArgSQLFunction( "current_date", StandardBasicTypes.DATE, false ) );
 		registerFunction( "sys_date", new NoArgSQLFunction( "sys_date", StandardBasicTypes.DATE, false ) );
 		registerFunction( "sysdate", new NoArgSQLFunction( "sysdate", StandardBasicTypes.DATE, false ) );
 
 		registerFunction( "time", new StandardSQLFunction( "time", StandardBasicTypes.TIME ) );
 		registerFunction( "curtime", new NoArgSQLFunction( "curtime", StandardBasicTypes.TIME ) );
 		registerFunction( "current_time", new NoArgSQLFunction( "current_time", StandardBasicTypes.TIME, false ) );
 		registerFunction( "sys_time", new NoArgSQLFunction( "sys_time", StandardBasicTypes.TIME, false ) );
 		registerFunction( "systime", new NoArgSQLFunction( "systime", StandardBasicTypes.TIME, false ) );
 
 		registerFunction( "timestamp", new StandardSQLFunction( "timestamp", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction(
 				"current_timestamp", new NoArgSQLFunction(
 				"current_timestamp",
 				StandardBasicTypes.TIMESTAMP,
 				false
 		)
 		);
 		registerFunction(
 				"sys_timestamp", new NoArgSQLFunction(
 				"sys_timestamp",
 				StandardBasicTypes.TIMESTAMP,
 				false
 		)
 		);
 		registerFunction( "systimestamp", new NoArgSQLFunction( "systimestamp", StandardBasicTypes.TIMESTAMP, false ) );
 		registerFunction( "localtime", new NoArgSQLFunction( "localtime", StandardBasicTypes.TIMESTAMP, false ) );
 		registerFunction(
 				"localtimestamp", new NoArgSQLFunction(
 				"localtimestamp",
 				StandardBasicTypes.TIMESTAMP,
 				false
 		)
 		);
 
 		registerFunction( "day", new StandardSQLFunction( "day", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofmonth", new StandardSQLFunction( "dayofmonth", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofweek", new StandardSQLFunction( "dayofweek", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofyear", new StandardSQLFunction( "dayofyear", StandardBasicTypes.INTEGER ) );
 		registerFunction( "from_days", new StandardSQLFunction( "from_days", StandardBasicTypes.DATE ) );
 		registerFunction( "from_unixtime", new StandardSQLFunction( "from_unixtime", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "last_day", new StandardSQLFunction( "last_day", StandardBasicTypes.DATE ) );
 		registerFunction( "minute", new StandardSQLFunction( "minute", StandardBasicTypes.INTEGER ) );
 		registerFunction( "month", new StandardSQLFunction( "month", StandardBasicTypes.INTEGER ) );
 		registerFunction( "months_between", new StandardSQLFunction( "months_between", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "now", new NoArgSQLFunction( "now", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "quarter", new StandardSQLFunction( "quarter", StandardBasicTypes.INTEGER ) );
 		registerFunction( "second", new StandardSQLFunction( "second", StandardBasicTypes.INTEGER ) );
 		registerFunction( "sec_to_time", new StandardSQLFunction( "sec_to_time", StandardBasicTypes.TIME ) );
 		registerFunction( "time_to_sec", new StandardSQLFunction( "time_to_sec", StandardBasicTypes.INTEGER ) );
 		registerFunction( "to_days", new StandardSQLFunction( "to_days", StandardBasicTypes.LONG ) );
 		registerFunction( "unix_timestamp", new StandardSQLFunction( "unix_timestamp", StandardBasicTypes.LONG ) );
 		registerFunction( "utc_date", new NoArgSQLFunction( "utc_date", StandardBasicTypes.STRING ) );
 		registerFunction( "utc_time", new NoArgSQLFunction( "utc_time", StandardBasicTypes.STRING ) );
 		registerFunction( "week", new StandardSQLFunction( "week", StandardBasicTypes.INTEGER ) );
 		registerFunction( "weekday", new StandardSQLFunction( "weekday", StandardBasicTypes.INTEGER ) );
 		registerFunction( "year", new StandardSQLFunction( "year", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "hex", new StandardSQLFunction( "hex", StandardBasicTypes.STRING ) );
 
 		registerFunction( "octet_length", new StandardSQLFunction( "octet_length", StandardBasicTypes.LONG ) );
 		registerFunction( "bit_length", new StandardSQLFunction( "bit_length", StandardBasicTypes.LONG ) );
 
 		registerFunction( "bit_count", new StandardSQLFunction( "bit_count", StandardBasicTypes.LONG ) );
 		registerFunction( "md5", new StandardSQLFunction( "md5", StandardBasicTypes.STRING ) );
 
 		registerFunction( "concat", new StandardSQLFunction( "concat", StandardBasicTypes.STRING ) );
 
 		registerFunction( "substring", new StandardSQLFunction( "substring", StandardBasicTypes.STRING ) );
 		registerFunction( "substr", new StandardSQLFunction( "substr", StandardBasicTypes.STRING ) );
 
 		registerFunction( "length", new StandardSQLFunction( "length", StandardBasicTypes.INTEGER ) );
 		registerFunction( "bit_length", new StandardSQLFunction( "bit_length", StandardBasicTypes.INTEGER ) );
 		registerFunction( "coalesce", new StandardSQLFunction( "coalesce" ) );
 		registerFunction( "nullif", new StandardSQLFunction( "nullif" ) );
 		registerFunction( "mod", new StandardSQLFunction( "mod" ) );
 
 		registerFunction( "power", new StandardSQLFunction( "power" ) );
 		registerFunction( "stddev", new StandardSQLFunction( "stddev" ) );
 		registerFunction( "variance", new StandardSQLFunction( "variance" ) );
 		registerFunction( "trunc", new StandardSQLFunction( "trunc" ) );
 		registerFunction( "nvl", new StandardSQLFunction( "nvl" ) );
 		registerFunction( "nvl2", new StandardSQLFunction( "nvl2" ) );
 		registerFunction( "chr", new StandardSQLFunction( "chr", StandardBasicTypes.CHARACTER ) );
 		registerFunction( "to_char", new StandardSQLFunction( "to_char", StandardBasicTypes.STRING ) );
 		registerFunction( "to_date", new StandardSQLFunction( "to_date", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "instr", new StandardSQLFunction( "instr", StandardBasicTypes.INTEGER ) );
 		registerFunction( "instrb", new StandardSQLFunction( "instrb", StandardBasicTypes.INTEGER ) );
 		registerFunction( "lpad", new StandardSQLFunction( "lpad", StandardBasicTypes.STRING ) );
 		registerFunction( "replace", new StandardSQLFunction( "replace", StandardBasicTypes.STRING ) );
 		registerFunction( "rpad", new StandardSQLFunction( "rpad", StandardBasicTypes.STRING ) );
 		registerFunction( "translate", new StandardSQLFunction( "translate", StandardBasicTypes.STRING ) );
 
 		registerFunction( "add_months", new StandardSQLFunction( "add_months", StandardBasicTypes.DATE ) );
 		registerFunction( "user", new NoArgSQLFunction( "user", StandardBasicTypes.STRING, false ) );
 		registerFunction( "rownum", new NoArgSQLFunction( "rownum", StandardBasicTypes.LONG, false ) );
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "", "||", "" ) );
 
 		registerKeyword( "TYPE" );
 		registerKeyword( "YEAR" );
 		registerKeyword( "MONTH" );
 		registerKeyword( "ALIAS" );
 		registerKeyword( "VALUE" );
 		registerKeyword( "FIRST" );
 		registerKeyword( "ROLE" );
 		registerKeyword( "CLASS" );
 		registerKeyword( "BIT" );
 		registerKeyword( "TIME" );
 		registerKeyword( "QUERY" );
 		registerKeyword( "DATE" );
 		registerKeyword( "USER" );
 		registerKeyword( "ACTION" );
 		registerKeyword( "SYS_USER" );
 		registerKeyword( "ZONE" );
 		registerKeyword( "LANGUAGE" );
 		registerKeyword( "DICTIONARY" );
 		registerKeyword( "DATA" );
 		registerKeyword( "TEST" );
 		registerKeyword( "SUPERCLASS" );
 		registerKeyword( "SECTION" );
 		registerKeyword( "LOWER" );
 		registerKeyword( "LIST" );
 		registerKeyword( "OID" );
 		registerKeyword( "DAY" );
 		registerKeyword( "IF" );
 		registerKeyword( "ATTRIBUTE" );
 		registerKeyword( "STRING" );
 		registerKeyword( "SEARCH" );
 	}
 
 	@Override
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	@Override
 	public String getIdentityInsertString() {
 		return "NULL";
 	}
 
 	@Override
 	public boolean supportsColumnCheck() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	@Override
 	public String getIdentitySelectString() {
 		return "select last_insert_id()";
 	}
 
 	@Override
 	protected String getIdentityColumnString() {
 		//starts with 1, implicitly
 		return "not null auto_increment";
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + sequenceName + ".next_value from table({1}) as T(X)";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		return "create serial " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop serial " + sequenceName;
 	}
 
 	@Override
 	public String getDropForeignKeyString() {
 		return " drop foreign key ";
 	}
 
 	@Override
 	public boolean qualifyIndexName() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsExistsInSelect() {
 		return false;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select name from db_serial";
 	}
 
 	@Override
 	public char openQuote() {
 		return '[';
 	}
 
 	@Override
 	public char closeQuote() {
 		return ']';
 	}
 
 	@Override
 	public String getForUpdateString() {
 		return " ";
 	}
 
 	@Override
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select now()";
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsIfExistsBeforeTableName() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsTupleDistinctCounts() {
 		return false;
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return CUBRIDLimitHandler.INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/InformixDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/InformixDialect.java
index 12bcae35a4..eac63cc4c6 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/InformixDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/InformixDialect.java
@@ -1,317 +1,316 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Locale;
 
 import org.hibernate.MappingException;
-import org.hibernate.boot.TempTableDdlTransactionHandling;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.pagination.FirstLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.unique.InformixUniqueDelegate;
 import org.hibernate.dialect.unique.UniqueDelegate;
 import org.hibernate.exception.spi.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.hql.spi.id.IdTableSupportStandardImpl;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.AfterUseAction;
 import org.hibernate.hql.spi.id.local.LocalTemporaryTableBulkIdStrategy;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * Informix dialect.<br>
  * <br>
  * Seems to work with Informix Dynamic Server Version 7.31.UD3,  Informix JDBC driver version 2.21JC3.
  *
  * @author Steve Molitor
  */
 public class InformixDialect extends Dialect {
 	
 	private final UniqueDelegate uniqueDelegate;
 
 	/**
 	 * Creates new <code>InformixDialect</code> instance. Sets up the JDBC /
 	 * Informix type mappings.
 	 */
 	public InformixDialect() {
 		super();
 
 		registerColumnType( Types.BIGINT, "int8" );
 		registerColumnType( Types.BINARY, "byte" );
 		// Informix doesn't have a bit type
 		registerColumnType( Types.BIT, "smallint" );
 		registerColumnType( Types.CHAR, "char($l)" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.DECIMAL, "decimal" );
 		registerColumnType( Types.DOUBLE, "float" );
 		registerColumnType( Types.FLOAT, "smallfloat" );
 		registerColumnType( Types.INTEGER, "integer" );
 		// or BYTE
 		registerColumnType( Types.LONGVARBINARY, "blob" );
 		// or TEXT?
 		registerColumnType( Types.LONGVARCHAR, "clob" );
 		// or MONEY
 		registerColumnType( Types.NUMERIC, "decimal" );
 		registerColumnType( Types.REAL, "smallfloat" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.TIMESTAMP, "datetime year to fraction(5)" );
 		registerColumnType( Types.TIME, "datetime hour to second" );
 		registerColumnType( Types.TINYINT, "smallint" );
 		registerColumnType( Types.VARBINARY, "byte" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.VARCHAR, 255, "varchar($l)" );
 		registerColumnType( Types.VARCHAR, 32739, "lvarchar($l)" );
 
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(", "||", ")" ) );
 		
 		uniqueDelegate = new InformixUniqueDelegate( this );
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	@Override
 	public String getIdentitySelectString(String table, String column, int type)
 			throws MappingException {
 		return type == Types.BIGINT
 				? "select dbinfo('serial8') from informix.systables where tabid=1"
 				: "select dbinfo('sqlca.sqlerrd1') from informix.systables where tabid=1";
 	}
 
 	@Override
 	public String getIdentityColumnString(int type) throws MappingException {
 		return type == Types.BIGINT ?
 				"serial8 not null" :
 				"serial not null";
 	}
 
 	@Override
 	public boolean hasDataTypeInIdentityColumn() {
 		return false;
 	}
 
 	/**
 	 * Informix constraint name must be at the end.
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public String getAddForeignKeyConstraintString(
 			String constraintName,
 			String[] foreignKey,
 			String referencedTable,
 			String[] primaryKey,
 			boolean referencesPrimaryKey) {
 		final StringBuilder result = new StringBuilder( 30 )
 				.append( " add constraint " )
 				.append( " foreign key (" )
 				.append( StringHelper.join( ", ", foreignKey ) )
 				.append( ") references " )
 				.append( referencedTable );
 
 		if ( !referencesPrimaryKey ) {
 			result.append( " (" )
 					.append( StringHelper.join( ", ", primaryKey ) )
 					.append( ')' );
 		}
 
 		result.append( " constraint " ).append( constraintName );
 
 		return result.toString();
 	}
 
 	/**
 	 * Informix constraint name must be at the end.
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public String getAddPrimaryKeyConstraintString(String constraintName) {
 		return " add constraint primary key constraint " + constraintName + " ";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName + " restrict";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from informix.systables where tabid=1";
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select tabname from informix.systables where tabtype='Q'";
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return FirstLimitHandler.INSTANCE;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimitOffset() {
 		return false;
 	}
 
 	@Override
 	public String getLimitString(String querySelect, int offset, int limit) {
 		if ( offset > 0 ) {
 			throw new UnsupportedOperationException( "query result offset is not supported" );
 		}
 		return new StringBuilder( querySelect.length() + 8 )
 				.append( querySelect )
 				.insert( querySelect.toLowerCase(Locale.ROOT).indexOf( "select" ) + 6, " first " + limit )
 				.toString();
 	}
 
 	@Override
 	public boolean supportsVariableLimit() {
 		return false;
 	}
 
 	@Override
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 	private static final ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 		@Override
 		public String extractConstraintName(SQLException sqle) {
 			String constraintName = null;
 			final int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 
 			if ( errorCode == -268 ) {
 				constraintName = extractUsingTemplate( "Unique constraint (", ") violated.", sqle.getMessage() );
 			}
 			else if ( errorCode == -691 ) {
 				constraintName = extractUsingTemplate(
 						"Missing key in referenced table for referential constraint (",
 						").",
 						sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -692 ) {
 				constraintName = extractUsingTemplate(
 						"Key value for constraint (",
 						") is still being referenced.",
 						sqle.getMessage()
 				);
 			}
 
 			if ( constraintName != null ) {
 				// strip table-owner because Informix always returns constraint names as "<table-owner>.<constraint-name>"
 				final int i = constraintName.indexOf( '.' );
 				if ( i != -1 ) {
 					constraintName = constraintName.substring( i + 1 );
 				}
 			}
 
 			return constraintName;
 		}
 
 	};
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select distinct current timestamp from informix.systables";
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getDefaultMultiTableBulkIdStrategy() {
 		return new LocalTemporaryTableBulkIdStrategy(
 				new IdTableSupportStandardImpl() {
 					@Override
 					public String getCreateIdTableCommand() {
 						return "create temp table";
 					}
 
 					@Override
 					public String getCreateIdTableStatementOptions() {
 						return "with no log";
 					}
 				},
 				AfterUseAction.CLEAN,
 				null
 		);
 	}
 	
 	@Override
 	public UniqueDelegate getUniqueDelegate() {
 		return uniqueDelegate;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/MySQLDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/MySQLDialect.java
index 2798700906..3075531b89 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/MySQLDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/MySQLDialect.java
@@ -1,488 +1,487 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.CallableStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.hibernate.JDBCException;
 import org.hibernate.NullPrecedence;
 import org.hibernate.boot.TempTableDdlTransactionHandling;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.exception.LockAcquisitionException;
 import org.hibernate.exception.LockTimeoutException;
 import org.hibernate.exception.spi.SQLExceptionConversionDelegate;
-import org.hibernate.hql.spi.id.IdTableSupport;
 import org.hibernate.hql.spi.id.IdTableSupportStandardImpl;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.AfterUseAction;
 import org.hibernate.hql.spi.id.local.LocalTemporaryTableBulkIdStrategy;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * An SQL dialect for MySQL (prior to 5.x).
  *
  * @author Gavin King
  */
 @SuppressWarnings("deprecation")
 public class MySQLDialect extends Dialect {
 
 	private static final LimitHandler LIMIT_HANDLER = new AbstractLimitHandler() {
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final boolean hasOffset = LimitHelper.hasFirstRow( selection );
 			return sql + (hasOffset ? " limit ?, ?" : " limit ?");
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return true;
 		}
 	};
 
 	/**
 	 * Constructs a MySQLDialect
 	 */
 	public MySQLDialect() {
 		super();
 		registerColumnType( Types.BIT, "bit" );
 		registerColumnType( Types.BIGINT, "bigint" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.TINYINT, "tinyint" );
 		registerColumnType( Types.INTEGER, "integer" );
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.DOUBLE, "double precision" );
 		registerColumnType( Types.BOOLEAN, "bit" ); // HHH-6935
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "datetime" );
 		registerColumnType( Types.VARBINARY, "longblob" );
 		registerColumnType( Types.VARBINARY, 16777215, "mediumblob" );
 		registerColumnType( Types.VARBINARY, 65535, "blob" );
 		registerColumnType( Types.VARBINARY, 255, "tinyblob" );
 		registerColumnType( Types.BINARY, "binary($l)" );
 		registerColumnType( Types.LONGVARBINARY, "longblob" );
 		registerColumnType( Types.LONGVARBINARY, 16777215, "mediumblob" );
 		registerColumnType( Types.NUMERIC, "decimal($p,$s)" );
 		registerColumnType( Types.BLOB, "longblob" );
 //		registerColumnType( Types.BLOB, 16777215, "mediumblob" );
 //		registerColumnType( Types.BLOB, 65535, "blob" );
 		registerColumnType( Types.CLOB, "longtext" );
 //		registerColumnType( Types.CLOB, 16777215, "mediumtext" );
 //		registerColumnType( Types.CLOB, 65535, "text" );
 		registerVarcharTypes();
 
 		registerFunction( "ascii", new StandardSQLFunction( "ascii", StandardBasicTypes.INTEGER ) );
 		registerFunction( "bin", new StandardSQLFunction( "bin", StandardBasicTypes.STRING ) );
 		registerFunction( "char_length", new StandardSQLFunction( "char_length", StandardBasicTypes.LONG ) );
 		registerFunction( "character_length", new StandardSQLFunction( "character_length", StandardBasicTypes.LONG ) );
 		registerFunction( "lcase", new StandardSQLFunction( "lcase" ) );
 		registerFunction( "lower", new StandardSQLFunction( "lower" ) );
 		registerFunction( "ltrim", new StandardSQLFunction( "ltrim" ) );
 		registerFunction( "ord", new StandardSQLFunction( "ord", StandardBasicTypes.INTEGER ) );
 		registerFunction( "quote", new StandardSQLFunction( "quote" ) );
 		registerFunction( "reverse", new StandardSQLFunction( "reverse" ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim" ) );
 		registerFunction( "soundex", new StandardSQLFunction( "soundex" ) );
 		registerFunction( "space", new StandardSQLFunction( "space", StandardBasicTypes.STRING ) );
 		registerFunction( "ucase", new StandardSQLFunction( "ucase" ) );
 		registerFunction( "upper", new StandardSQLFunction( "upper" ) );
 		registerFunction( "unhex", new StandardSQLFunction( "unhex", StandardBasicTypes.STRING ) );
 
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "sign", new StandardSQLFunction( "sign", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "acos", new StandardSQLFunction( "acos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "asin", new StandardSQLFunction( "asin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan", new StandardSQLFunction( "atan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cos", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cot", new StandardSQLFunction( "cot", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "crc32", new StandardSQLFunction( "crc32", StandardBasicTypes.LONG ) );
 		registerFunction( "exp", new StandardSQLFunction( "exp", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "ln", new StandardSQLFunction( "ln", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log", new StandardSQLFunction( "log", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log2", new StandardSQLFunction( "log2", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log10", new StandardSQLFunction( "log10", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "pi", new NoArgSQLFunction( "pi", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "rand", new NoArgSQLFunction( "rand", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sin", new StandardSQLFunction( "sin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sqrt", new StandardSQLFunction( "sqrt", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "stddev", new StandardSQLFunction("std", StandardBasicTypes.DOUBLE) );
 		registerFunction( "tan", new StandardSQLFunction( "tan", StandardBasicTypes.DOUBLE ) );
 
 		registerFunction( "radians", new StandardSQLFunction( "radians", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "degrees", new StandardSQLFunction( "degrees", StandardBasicTypes.DOUBLE ) );
 
 		registerFunction( "ceiling", new StandardSQLFunction( "ceiling", StandardBasicTypes.INTEGER ) );
 		registerFunction( "ceil", new StandardSQLFunction( "ceil", StandardBasicTypes.INTEGER ) );
 		registerFunction( "floor", new StandardSQLFunction( "floor", StandardBasicTypes.INTEGER ) );
 		registerFunction( "round", new StandardSQLFunction( "round" ) );
 
 		registerFunction( "datediff", new StandardSQLFunction( "datediff", StandardBasicTypes.INTEGER ) );
 		registerFunction( "timediff", new StandardSQLFunction( "timediff", StandardBasicTypes.TIME ) );
 		registerFunction( "date_format", new StandardSQLFunction( "date_format", StandardBasicTypes.STRING ) );
 
 		registerFunction( "curdate", new NoArgSQLFunction( "curdate", StandardBasicTypes.DATE ) );
 		registerFunction( "curtime", new NoArgSQLFunction( "curtime", StandardBasicTypes.TIME ) );
 		registerFunction( "current_date", new NoArgSQLFunction( "current_date", StandardBasicTypes.DATE, false ) );
 		registerFunction( "current_time", new NoArgSQLFunction( "current_time", StandardBasicTypes.TIME, false ) );
 		registerFunction( "current_timestamp", new NoArgSQLFunction( "current_timestamp", StandardBasicTypes.TIMESTAMP, false ) );
 		registerFunction( "date", new StandardSQLFunction( "date", StandardBasicTypes.DATE ) );
 		registerFunction( "day", new StandardSQLFunction( "day", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofmonth", new StandardSQLFunction( "dayofmonth", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayname", new StandardSQLFunction( "dayname", StandardBasicTypes.STRING ) );
 		registerFunction( "dayofweek", new StandardSQLFunction( "dayofweek", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofyear", new StandardSQLFunction( "dayofyear", StandardBasicTypes.INTEGER ) );
 		registerFunction( "from_days", new StandardSQLFunction( "from_days", StandardBasicTypes.DATE ) );
 		registerFunction( "from_unixtime", new StandardSQLFunction( "from_unixtime", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "hour", new StandardSQLFunction( "hour", StandardBasicTypes.INTEGER ) );
 		registerFunction( "last_day", new StandardSQLFunction( "last_day", StandardBasicTypes.DATE ) );
 		registerFunction( "localtime", new NoArgSQLFunction( "localtime", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "localtimestamp", new NoArgSQLFunction( "localtimestamp", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "microseconds", new StandardSQLFunction( "microseconds", StandardBasicTypes.INTEGER ) );
 		registerFunction( "minute", new StandardSQLFunction( "minute", StandardBasicTypes.INTEGER ) );
 		registerFunction( "month", new StandardSQLFunction( "month", StandardBasicTypes.INTEGER ) );
 		registerFunction( "monthname", new StandardSQLFunction( "monthname", StandardBasicTypes.STRING ) );
 		registerFunction( "now", new NoArgSQLFunction( "now", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "quarter", new StandardSQLFunction( "quarter", StandardBasicTypes.INTEGER ) );
 		registerFunction( "second", new StandardSQLFunction( "second", StandardBasicTypes.INTEGER ) );
 		registerFunction( "sec_to_time", new StandardSQLFunction( "sec_to_time", StandardBasicTypes.TIME ) );
 		registerFunction( "sysdate", new NoArgSQLFunction( "sysdate", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "time", new StandardSQLFunction( "time", StandardBasicTypes.TIME ) );
 		registerFunction( "timestamp", new StandardSQLFunction( "timestamp", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "time_to_sec", new StandardSQLFunction( "time_to_sec", StandardBasicTypes.INTEGER ) );
 		registerFunction( "to_days", new StandardSQLFunction( "to_days", StandardBasicTypes.LONG ) );
 		registerFunction( "unix_timestamp", new StandardSQLFunction( "unix_timestamp", StandardBasicTypes.LONG ) );
 		registerFunction( "utc_date", new NoArgSQLFunction( "utc_date", StandardBasicTypes.STRING ) );
 		registerFunction( "utc_time", new NoArgSQLFunction( "utc_time", StandardBasicTypes.STRING ) );
 		registerFunction( "utc_timestamp", new NoArgSQLFunction( "utc_timestamp", StandardBasicTypes.STRING ) );
 		registerFunction( "week", new StandardSQLFunction( "week", StandardBasicTypes.INTEGER ) );
 		registerFunction( "weekday", new StandardSQLFunction( "weekday", StandardBasicTypes.INTEGER ) );
 		registerFunction( "weekofyear", new StandardSQLFunction( "weekofyear", StandardBasicTypes.INTEGER ) );
 		registerFunction( "year", new StandardSQLFunction( "year", StandardBasicTypes.INTEGER ) );
 		registerFunction( "yearweek", new StandardSQLFunction( "yearweek", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "hex", new StandardSQLFunction( "hex", StandardBasicTypes.STRING ) );
 		registerFunction( "oct", new StandardSQLFunction( "oct", StandardBasicTypes.STRING ) );
 
 		registerFunction( "octet_length", new StandardSQLFunction( "octet_length", StandardBasicTypes.LONG ) );
 		registerFunction( "bit_length", new StandardSQLFunction( "bit_length", StandardBasicTypes.LONG ) );
 
 		registerFunction( "bit_count", new StandardSQLFunction( "bit_count", StandardBasicTypes.LONG ) );
 		registerFunction( "encrypt", new StandardSQLFunction( "encrypt", StandardBasicTypes.STRING ) );
 		registerFunction( "md5", new StandardSQLFunction( "md5", StandardBasicTypes.STRING ) );
 		registerFunction( "sha1", new StandardSQLFunction( "sha1", StandardBasicTypes.STRING ) );
 		registerFunction( "sha", new StandardSQLFunction( "sha", StandardBasicTypes.STRING ) );
 
 		registerFunction( "concat", new StandardSQLFunction( "concat", StandardBasicTypes.STRING ) );
 
 		getDefaultProperties().setProperty( Environment.MAX_FETCH_DEPTH, "2" );
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 	}
 
 	protected void registerVarcharTypes() {
 		registerColumnType( Types.VARCHAR, "longtext" );
 //		registerColumnType( Types.VARCHAR, 16777215, "mediumtext" );
 //		registerColumnType( Types.VARCHAR, 65535, "text" );
 		registerColumnType( Types.VARCHAR, 255, "varchar($l)" );
 		registerColumnType( Types.LONGVARCHAR, "longtext" );
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add column";
 	}
 
 	@Override
 	public boolean qualifyIndexName() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	@Override
 	public String getIdentitySelectString() {
 		return "select last_insert_id()";
 	}
 
 	@Override
 	public String getIdentityColumnString() {
 		//starts with 1, implicitly
 		return "not null auto_increment";
 	}
 
 	@Override
 	public String getAddForeignKeyConstraintString(
 			String constraintName,
 			String[] foreignKey,
 			String referencedTable,
 			String[] primaryKey,
 			boolean referencesPrimaryKey) {
 		final String cols = StringHelper.join( ", ", foreignKey );
 		final String referencedCols = StringHelper.join( ", ", primaryKey );
 		return String.format(
 				" add constraint %s foreign key (%s) references %s (%s)",
 				constraintName,
 				cols,
 				referencedTable,
 				referencedCols
 		);
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public String getDropForeignKeyString() {
 		return " drop foreign key ";
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return LIMIT_HANDLER;
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 		return sql + (hasOffset ? " limit ?, ?" : " limit ?");
 	}
 
 	@Override
 	public char closeQuote() {
 		return '`';
 	}
 
 	@Override
 	public char openQuote() {
 		return '`';
 	}
 
 	@Override
 	public boolean supportsIfExistsBeforeTableName() {
 		return true;
 	}
 
 	@Override
 	public String getSelectGUIDString() {
 		return "select uuid()";
 	}
 
 	@Override
 	public boolean supportsCascadeDelete() {
 		return false;
 	}
 
 	@Override
 	public String getTableComment(String comment) {
 		return " comment='" + comment + "'";
 	}
 
 	@Override
 	public String getColumnComment(String comment) {
 		return " comment '" + comment + "'";
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getDefaultMultiTableBulkIdStrategy() {
 		return new LocalTemporaryTableBulkIdStrategy(
 				new IdTableSupportStandardImpl() {
 					@Override
 					public String getCreateIdTableCommand() {
 						return "create temporary table if not exists";
 					}
 
 					@Override
 					public String getDropIdTableCommand() {
 						return "drop temporary table";
 					}
 				},
 				AfterUseAction.DROP,
 				TempTableDdlTransactionHandling.NONE
 		);
 	}
 
 	@Override
 	public String getCastTypeName(int code) {
 		switch ( code ) {
 			case Types.INTEGER:
 			case Types.BIGINT:
 			case Types.SMALLINT:
 				return "signed";
 			case Types.FLOAT:
 			case Types.NUMERIC:
 			case Types.REAL:
 				return "decimal";
 			case Types.VARCHAR:
 				return "char";
 			case Types.VARBINARY:
 				return "binary";
 			default:
 				return super.getCastTypeName( code );
 		}
 	}
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select now()";
 	}
 
 	@Override
 	public int registerResultSetOutParameter(CallableStatement statement, int col) throws SQLException {
 		return col;
 	}
 
 	@Override
 	public ResultSet getResultSet(CallableStatement ps) throws SQLException {
 		boolean isResultSet = ps.execute();
 		while ( !isResultSet && ps.getUpdateCount() != -1 ) {
 			isResultSet = ps.getMoreResults();
 		}
 		return ps.getResultSet();
 	}
 
 	@Override
 	public boolean supportsRowValueConstructorSyntax() {
 		return true;
 	}
 
 	@Override
 	public String renderOrderByElement(String expression, String collation, String order, NullPrecedence nulls) {
 		final StringBuilder orderByElement = new StringBuilder();
 		if ( nulls != NullPrecedence.NONE ) {
 			// Workaround for NULLS FIRST / LAST support.
 			orderByElement.append( "case when " ).append( expression ).append( " is null then " );
 			if ( nulls == NullPrecedence.FIRST ) {
 				orderByElement.append( "0 else 1" );
 			}
 			else {
 				orderByElement.append( "1 else 0" );
 			}
 			orderByElement.append( " end, " );
 		}
 		// Nulls precedence has already been handled so passing NONE value.
 		orderByElement.append( super.renderOrderByElement( expression, collation, order, NullPrecedence.NONE ) );
 		return orderByElement.toString();
 	}
 
 	// locking support
 
 	@Override
 	public String getForUpdateString() {
 		return " for update";
 	}
 
 	@Override
 	public String getWriteLockString(int timeout) {
 		return " for update";
 	}
 
 	@Override
 	public String getReadLockString(int timeout) {
 		return " lock in share mode";
 	}
 
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	@Override
 	public boolean areStringComparisonsCaseInsensitive() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLobValueChangePropogation() {
 		// note: at least my local MySQL 5.1 install shows this not working...
 		return false;
 	}
 
 	@Override
 	public boolean supportsSubqueryOnMutatingTable() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsLockTimeouts() {
 		// yes, we do handle "lock timeout" conditions in the exception conversion delegate,
 		// but that's a hardcoded lock timeout period across the whole entire MySQL database.
 		// MySQL does not support specifying lock timeouts as part of the SQL statement, which is really
 		// what this meta method is asking.
 		return false;
 	}
 
 	@Override
 	public SQLExceptionConversionDelegate buildSQLExceptionConversionDelegate() {
 		return new SQLExceptionConversionDelegate() {
 			@Override
 			public JDBCException convert(SQLException sqlException, String message, String sql) {
 				final String sqlState = JdbcExceptionHelper.extractSqlState( sqlException );
 
 				if ( "41000".equals( sqlState ) ) {
 					return new LockTimeoutException( message, sqlException, sql );
 				}
 
 				if ( "40001".equals( sqlState ) ) {
 					return new LockAcquisitionException( message, sqlException, sql );
 				}
 
 				return null;
 			}
 		};
 	}
 
 	@Override
 	public String getNotExpression(String expression) {
 		return "not (" + expression + ")";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle12cDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle12cDialect.java
index 2551dc4fe2..562817f991 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle12cDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle12cDialect.java
@@ -1,68 +1,66 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.SQL2008StandardLimitHandler;
-import org.hibernate.engine.spi.RowSelection;
 
 /**
  * An SQL dialect for Oracle 12c.
- * 
+ *
  * @author zhouyanming (zhouyanming@gmail.com)
  */
 public class Oracle12cDialect extends Oracle10gDialect {
+	public Oracle12cDialect() {
+		super();
+	}
+
+	@Override
+	protected void registerDefaultProperties() {
+		super.registerDefaultProperties();
+		getDefaultProperties().setProperty( Environment.USE_GET_GENERATED_KEYS, "true" );
+	}
 
-        public Oracle12cDialect() {
-                super();
-        }
-        
-        @Override
-    	protected void registerDefaultProperties() {
-    		super.registerDefaultProperties();
-    		getDefaultProperties().setProperty( Environment.USE_GET_GENERATED_KEYS, "true" );
-    	}
-        
-        @Override
-    	public boolean supportsIdentityColumns() {
-    		return true;
-    	}
+	@Override
+	public boolean supportsIdentityColumns() {
+		return true;
+	}
 
-    	@Override
-    	public boolean supportsInsertSelectIdentity() {
-    		return true;
-    	}
+	@Override
+	public boolean supportsInsertSelectIdentity() {
+		return true;
+	}
 
-    	@Override
-    	public String getIdentityColumnString() {
-    		return "generated as identity";
-    	}
+	@Override
+	public String getIdentityColumnString() {
+		return "generated as identity";
+	}
 
-		@Override
-		public LimitHandler getLimitHandler() {
-			return SQL2008StandardLimitHandler.INSTANCE;
-		}
+	@Override
+	public LimitHandler getLimitHandler() {
+		return SQL2008StandardLimitHandler.INSTANCE;
+	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/PostgreSQL81Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/PostgreSQL81Dialect.java
index f4c8e9c43a..dfe5b709aa 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/PostgreSQL81Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/PostgreSQL81Dialect.java
@@ -1,581 +1,580 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.CallableStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.hibernate.JDBCException;
 import org.hibernate.LockOptions;
 import org.hibernate.PessimisticLockException;
-import org.hibernate.boot.TempTableDdlTransactionHandling;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.PositionSubstringFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.exception.LockAcquisitionException;
 import org.hibernate.exception.spi.SQLExceptionConversionDelegate;
 import org.hibernate.exception.spi.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.hql.spi.id.IdTableSupportStandardImpl;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.AfterUseAction;
 import org.hibernate.hql.spi.id.local.LocalTemporaryTableBulkIdStrategy;
 import org.hibernate.id.SequenceGenerator;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.procedure.internal.PostgresCallableStatementSupport;
 import org.hibernate.procedure.spi.CallableStatementSupport;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.descriptor.sql.BlobTypeDescriptor;
 import org.hibernate.type.descriptor.sql.ClobTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 /**
  * An SQL dialect for Postgres
  * <p/>
  * For discussion of BLOB support in Postgres, as of 8.4, have a peek at
  * <a href="http://jdbc.postgresql.org/documentation/84/binary-data.html">http://jdbc.postgresql.org/documentation/84/binary-data.html</a>.
  * For the effects in regards to Hibernate see <a href="http://in.relation.to/15492.lace">http://in.relation.to/15492.lace</a>
  *
  * @author Gavin King
  */
 @SuppressWarnings("deprecation")
 public class PostgreSQL81Dialect extends Dialect {
 
 	private static final AbstractLimitHandler LIMIT_HANDLER = new AbstractLimitHandler() {
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final boolean hasOffset = LimitHelper.hasFirstRow( selection );
 			return sql + (hasOffset ? " limit ? offset ?" : " limit ?");
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return true;
 		}
 
 		@Override
 		public boolean bindLimitParametersInReverseOrder() {
 			return true;
 		}
 	};
 
 	/**
 	 * Constructs a PostgreSQL81Dialect
 	 */
 	public PostgreSQL81Dialect() {
 		super();
 		registerColumnType( Types.BIT, "bool" );
 		registerColumnType( Types.BIGINT, "int8" );
 		registerColumnType( Types.SMALLINT, "int2" );
 		registerColumnType( Types.TINYINT, "int2" );
 		registerColumnType( Types.INTEGER, "int4" );
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.FLOAT, "float4" );
 		registerColumnType( Types.DOUBLE, "float8" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.VARBINARY, "bytea" );
 		registerColumnType( Types.BINARY, "bytea" );
 		registerColumnType( Types.LONGVARCHAR, "text" );
 		registerColumnType( Types.LONGVARBINARY, "bytea" );
 		registerColumnType( Types.CLOB, "text" );
 		registerColumnType( Types.BLOB, "oid" );
 		registerColumnType( Types.NUMERIC, "numeric($p, $s)" );
 		registerColumnType( Types.OTHER, "uuid" );
 
 		registerFunction( "abs", new StandardSQLFunction("abs") );
 		registerFunction( "sign", new StandardSQLFunction("sign", StandardBasicTypes.INTEGER) );
 
 		registerFunction( "acos", new StandardSQLFunction("acos", StandardBasicTypes.DOUBLE) );
 		registerFunction( "asin", new StandardSQLFunction("asin", StandardBasicTypes.DOUBLE) );
 		registerFunction( "atan", new StandardSQLFunction("atan", StandardBasicTypes.DOUBLE) );
 		registerFunction( "cos", new StandardSQLFunction("cos", StandardBasicTypes.DOUBLE) );
 		registerFunction( "cot", new StandardSQLFunction("cot", StandardBasicTypes.DOUBLE) );
 		registerFunction( "exp", new StandardSQLFunction("exp", StandardBasicTypes.DOUBLE) );
 		registerFunction( "ln", new StandardSQLFunction("ln", StandardBasicTypes.DOUBLE) );
 		registerFunction( "log", new StandardSQLFunction("log", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sin", new StandardSQLFunction("sin", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sqrt", new StandardSQLFunction("sqrt", StandardBasicTypes.DOUBLE) );
 		registerFunction( "cbrt", new StandardSQLFunction("cbrt", StandardBasicTypes.DOUBLE) );
 		registerFunction( "tan", new StandardSQLFunction("tan", StandardBasicTypes.DOUBLE) );
 		registerFunction( "radians", new StandardSQLFunction("radians", StandardBasicTypes.DOUBLE) );
 		registerFunction( "degrees", new StandardSQLFunction("degrees", StandardBasicTypes.DOUBLE) );
 
 		registerFunction( "stddev", new StandardSQLFunction("stddev", StandardBasicTypes.DOUBLE) );
 		registerFunction( "variance", new StandardSQLFunction("variance", StandardBasicTypes.DOUBLE) );
 
 		registerFunction( "random", new NoArgSQLFunction("random", StandardBasicTypes.DOUBLE) );
 		registerFunction( "rand", new NoArgSQLFunction("random", StandardBasicTypes.DOUBLE) );
 
 		registerFunction( "round", new StandardSQLFunction("round") );
 		registerFunction( "trunc", new StandardSQLFunction("trunc") );
 		registerFunction( "ceil", new StandardSQLFunction("ceil") );
 		registerFunction( "floor", new StandardSQLFunction("floor") );
 
 		registerFunction( "chr", new StandardSQLFunction("chr", StandardBasicTypes.CHARACTER) );
 		registerFunction( "lower", new StandardSQLFunction("lower") );
 		registerFunction( "upper", new StandardSQLFunction("upper") );
 		registerFunction( "substr", new StandardSQLFunction("substr", StandardBasicTypes.STRING) );
 		registerFunction( "initcap", new StandardSQLFunction("initcap") );
 		registerFunction( "to_ascii", new StandardSQLFunction("to_ascii") );
 		registerFunction( "quote_ident", new StandardSQLFunction("quote_ident", StandardBasicTypes.STRING) );
 		registerFunction( "quote_literal", new StandardSQLFunction("quote_literal", StandardBasicTypes.STRING) );
 		registerFunction( "md5", new StandardSQLFunction("md5", StandardBasicTypes.STRING) );
 		registerFunction( "ascii", new StandardSQLFunction("ascii", StandardBasicTypes.INTEGER) );
 		registerFunction( "char_length", new StandardSQLFunction("char_length", StandardBasicTypes.LONG) );
 		registerFunction( "bit_length", new StandardSQLFunction("bit_length", StandardBasicTypes.LONG) );
 		registerFunction( "octet_length", new StandardSQLFunction("octet_length", StandardBasicTypes.LONG) );
 
 		registerFunction( "age", new StandardSQLFunction("age") );
 		registerFunction( "current_date", new NoArgSQLFunction("current_date", StandardBasicTypes.DATE, false) );
 		registerFunction( "current_time", new NoArgSQLFunction("current_time", StandardBasicTypes.TIME, false) );
 		registerFunction( "current_timestamp", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIMESTAMP, false) );
 		registerFunction( "date_trunc", new StandardSQLFunction( "date_trunc", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "localtime", new NoArgSQLFunction("localtime", StandardBasicTypes.TIME, false) );
 		registerFunction( "localtimestamp", new NoArgSQLFunction("localtimestamp", StandardBasicTypes.TIMESTAMP, false) );
 		registerFunction( "now", new NoArgSQLFunction("now", StandardBasicTypes.TIMESTAMP) );
 		registerFunction( "timeofday", new NoArgSQLFunction("timeofday", StandardBasicTypes.STRING) );
 
 		registerFunction( "current_user", new NoArgSQLFunction("current_user", StandardBasicTypes.STRING, false) );
 		registerFunction( "session_user", new NoArgSQLFunction("session_user", StandardBasicTypes.STRING, false) );
 		registerFunction( "user", new NoArgSQLFunction("user", StandardBasicTypes.STRING, false) );
 		registerFunction( "current_database", new NoArgSQLFunction("current_database", StandardBasicTypes.STRING, true) );
 		registerFunction( "current_schema", new NoArgSQLFunction("current_schema", StandardBasicTypes.STRING, true) );
 		
 		registerFunction( "to_char", new StandardSQLFunction("to_char", StandardBasicTypes.STRING) );
 		registerFunction( "to_date", new StandardSQLFunction("to_date", StandardBasicTypes.DATE) );
 		registerFunction( "to_timestamp", new StandardSQLFunction("to_timestamp", StandardBasicTypes.TIMESTAMP) );
 		registerFunction( "to_number", new StandardSQLFunction("to_number", StandardBasicTypes.BIG_DECIMAL) );
 
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(","||",")" ) );
 
 		registerFunction( "locate", new PositionSubstringFunction() );
 
 		registerFunction( "str", new SQLFunctionTemplate(StandardBasicTypes.STRING, "cast(?1 as varchar)") );
 
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 		getDefaultProperties().setProperty( Environment.NON_CONTEXTUAL_LOB_CREATION, "true" );
 	}
 
 	@Override
 	public SqlTypeDescriptor getSqlTypeDescriptorOverride(int sqlCode) {
 		SqlTypeDescriptor descriptor;
 		switch ( sqlCode ) {
 			case Types.BLOB: {
 				// Force BLOB binding.  Otherwise, byte[] fields annotated
 				// with @Lob will attempt to use
 				// BlobTypeDescriptor.PRIMITIVE_ARRAY_BINDING.  Since the
 				// dialect uses oid for Blobs, byte arrays cannot be used.
 				descriptor = BlobTypeDescriptor.BLOB_BINDING;
 				break;
 			}
 			case Types.CLOB: {
 				descriptor = ClobTypeDescriptor.CLOB_BINDING;
 				break;
 			}
 			default: {
 				descriptor = super.getSqlTypeDescriptorOverride( sqlCode );
 				break;
 			}
 		}
 		return descriptor;
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add column";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName );
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return "nextval ('" + sequenceName + "')";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		//starts with 1, implicitly
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getCascadeConstraintsString() {
 		return " cascade";
 	}
 
 	@Override
 	public boolean dropConstraints() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select relname from pg_class where relkind='S'";
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return LIMIT_HANDLER;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 		return sql + (hasOffset ? " limit ? offset ?" : " limit ?");
 	}
 
 	@Override
 	public boolean bindLimitParametersInReverseOrder() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	@Override
 	public String getForUpdateString(String aliases) {
 		return getForUpdateString() + " of " + aliases;
 	}
 	
 	@Override
 	public String getForUpdateString(String aliases, LockOptions lockOptions) {
 		/*
 		 * Parent's implementation for (aliases, lockOptions) ignores aliases.
 		 */
 		return getForUpdateString(aliases);
 	}
 
 	@Override
 	public String getIdentitySelectString(String table, String column, int type) {
 		return "select currval('" + table + '_' + column + "_seq')";
 	}
 
 	@Override
 	public String getIdentityColumnString(int type) {
 		return type==Types.BIGINT ?
 			"bigserial not null" :
 			"serial not null";
 	}
 
 	@Override
 	public boolean hasDataTypeInIdentityColumn() {
 		return false;
 	}
 
 	@Override
 	public String getNoColumnsInsertString() {
 		return "default values";
 	}
 
 	@Override
 	public String getCaseInsensitiveLike(){
 		return "ilike";
 	}
 
 	@Override
 	public boolean supportsCaseInsensitiveLike() {
 		return true;
 	}
 
 	@Override
 	public Class getNativeIdentifierGeneratorClass() {
 		return SequenceGenerator.class;
 	}
 
 	@Override
 	public boolean supportsOuterJoinForUpdate() {
 		return false;
 	}
 
 	@Override
 	public boolean useInputStreamToInsertBlob() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 	/**
 	 * Workaround for postgres bug #1453
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public String getSelectClauseNullString(int sqlType) {
 		String typeName = getTypeName( sqlType, 1, 1, 0 );
 		//trim off the length/precision/scale
 		final int loc = typeName.indexOf( '(' );
 		if ( loc > -1 ) {
 			typeName = typeName.substring( 0, loc );
 		}
 		return "null::" + typeName;
 	}
 
 	@Override
 	public boolean supportsCommentOn() {
 		return true;
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getDefaultMultiTableBulkIdStrategy() {
 		return new LocalTemporaryTableBulkIdStrategy(
 				new IdTableSupportStandardImpl() {
 					@Override
 					public String getCreateIdTableCommand() {
 						return "create temporary table";
 					}
 
 					@Override
 					public String getCreateIdTableStatementOptions() {
 						return "on commit drop";
 					}
 				},
 				AfterUseAction.CLEAN,
 				null
 		);
 	}
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select now()";
 	}
 
 	@Override
 	public boolean requiresParensForTupleDistinctCounts() {
 		return true;
 	}
 
 	@Override
 	public String toBooleanValueString(boolean bool) {
 		return bool ? "true" : "false";
 	}
 
 	@Override
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 	/**
 	 * Constraint-name extractor for Postgres constraint violation exceptions.
 	 * Orginally contributed by Denny Bartelt.
 	 */
 	private static final ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 		public String extractConstraintName(SQLException sqle) {
 			try {
 				final int sqlState = Integer.valueOf( JdbcExceptionHelper.extractSqlState( sqle ) );
 				switch (sqlState) {
 					// CHECK VIOLATION
 					case 23514: return extractUsingTemplate( "violates check constraint \"","\"", sqle.getMessage() );
 					// UNIQUE VIOLATION
 					case 23505: return extractUsingTemplate( "violates unique constraint \"","\"", sqle.getMessage() );
 					// FOREIGN KEY VIOLATION
 					case 23503: return extractUsingTemplate( "violates foreign key constraint \"","\"", sqle.getMessage() );
 					// NOT NULL VIOLATION
 					case 23502: return extractUsingTemplate( "null value in column \"","\" violates not-null constraint", sqle.getMessage() );
 					// TODO: RESTRICT VIOLATION
 					case 23001: return null;
 					// ALL OTHER
 					default: return null;
 				}
 			}
 			catch (NumberFormatException nfe) {
 				return null;
 			}
 		}
 	};
 	
 	@Override
 	public SQLExceptionConversionDelegate buildSQLExceptionConversionDelegate() {
 		return new SQLExceptionConversionDelegate() {
 			@Override
 			public JDBCException convert(SQLException sqlException, String message, String sql) {
 				final String sqlState = JdbcExceptionHelper.extractSqlState( sqlException );
 
 				if ( "40P01".equals( sqlState ) ) {
 					// DEADLOCK DETECTED
 					return new LockAcquisitionException( message, sqlException, sql );
 				}
 
 				if ( "55P03".equals( sqlState ) ) {
 					// LOCK NOT AVAILABLE
 					return new PessimisticLockException( message, sqlException, sql );
 				}
 
 				// returning null allows other delegates to operate
 				return null;
 			}
 		};
 	}
 
 	@Override
 	public int registerResultSetOutParameter(CallableStatement statement, int col) throws SQLException {
 		// Register the type of the out param - PostgreSQL uses Types.OTHER
 		statement.registerOutParameter( col++, Types.OTHER );
 		return col;
 	}
 
 	@Override
 	public ResultSet getResultSet(CallableStatement ps) throws SQLException {
 		ps.execute();
 		return (ResultSet) ps.getObject( 1 );
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	/**
 	 * only necessary for postgre < 7.4  See http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/doc/src/sgml/ref/create_sequence.sgml
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	protected String getCreateSequenceString(String sequenceName, int initialValue, int incrementSize) {
 		return getCreateSequenceString( sequenceName ) + " start " + initialValue + " increment " + incrementSize;
 	}
 	
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsExpectedLobUsagePattern() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLobValueChangePropogation() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsUnboundedLobLocatorMaterialization() {
 		return false;
 	}
 
 	@Override
 	public String getForUpdateString() {
 		return " for update";
 	}
 
 	@Override
 	public String getWriteLockString(int timeout) {
 		if ( timeout == LockOptions.NO_WAIT ) {
 			return " for update nowait";
 		}
 		else {
 			return " for update";
 		}
 	}
 
 	@Override
 	public String getReadLockString(int timeout) {
 		if ( timeout == LockOptions.NO_WAIT ) {
 			return " for share nowait";
 		}
 		else {
 			return " for share";
 		}
 	}
 
 	@Override
 	public boolean supportsRowValueConstructorSyntax() {
 		return true;
 	}
 	
 	@Override
 	public String getForUpdateNowaitString() {
 		return getForUpdateString() + " nowait ";
 	}
 	
 	@Override
 	public String getForUpdateNowaitString(String aliases) {
 		return getForUpdateString( aliases ) + " nowait ";
 	}
 
 	@Override
 	public CallableStatementSupport getCallableStatementSupport() {
 		return PostgresCallableStatementSupport.INSTANCE;
 	}
 
 	@Override
 	public ResultSet getResultSet(CallableStatement statement, int position) throws SQLException {
 		if ( position != 1 ) {
 			throw new UnsupportedOperationException( "PostgreSQL only supports REF_CURSOR parameters as the first parameter" );
 		}
 		return (ResultSet) statement.getObject( 1 );
 	}
 
 	@Override
 	public ResultSet getResultSet(CallableStatement statement, String name) throws SQLException {
 		throw new UnsupportedOperationException( "PostgreSQL only supports accessing REF_CURSOR parameters by name" );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/SAPDBDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/SAPDBDialect.java
index faa67d3a60..1f094c244a 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/SAPDBDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/SAPDBDialect.java
@@ -1,245 +1,244 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.Types;
 
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.hql.spi.id.IdTableSupportStandardImpl;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
-import org.hibernate.hql.spi.id.global.GlobalTemporaryTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.AfterUseAction;
 import org.hibernate.hql.spi.id.local.LocalTemporaryTableBulkIdStrategy;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.DecodeCaseFragment;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * An SQL dialect compatible with SAP DB.
  *
  * @author Brad Clow
  */
 public class SAPDBDialect extends Dialect {
 	/**
 	 * Constructs a SAPDBDialect
 	 */
 	public SAPDBDialect() {
 		super();
 		registerColumnType( Types.BIT, "boolean" );
 		registerColumnType( Types.BIGINT, "fixed(19,0)" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.TINYINT, "fixed(3,0)" );
 		registerColumnType( Types.INTEGER, "int" );
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.DOUBLE, "double precision" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.VARBINARY, "long byte" );
 		registerColumnType( Types.NUMERIC, "fixed($p,$s)" );
 		registerColumnType( Types.CLOB, "long varchar" );
 		registerColumnType( Types.BLOB, "long byte" );
 
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "sign", new StandardSQLFunction( "sign", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "exp", new StandardSQLFunction( "exp", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "ln", new StandardSQLFunction( "ln", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log", new StandardSQLFunction( "ln", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "pi", new NoArgSQLFunction( "pi", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "power", new StandardSQLFunction( "power" ) );
 		registerFunction( "acos", new StandardSQLFunction( "acos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "asin", new StandardSQLFunction( "asin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan", new StandardSQLFunction( "atan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cos", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cosh", new StandardSQLFunction( "cosh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cot", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sin", new StandardSQLFunction( "sin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sinh", new StandardSQLFunction( "sinh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tan", new StandardSQLFunction( "tan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tanh", new StandardSQLFunction( "tanh", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "radians", new StandardSQLFunction( "radians", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "degrees", new StandardSQLFunction( "degrees", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan2", new StandardSQLFunction( "atan2", StandardBasicTypes.DOUBLE ) );
 
 		registerFunction( "round", new StandardSQLFunction( "round" ) );
 		registerFunction( "trunc", new StandardSQLFunction( "trunc" ) );
 		registerFunction( "ceil", new StandardSQLFunction( "ceil" ) );
 		registerFunction( "floor", new StandardSQLFunction( "floor" ) );
 		registerFunction( "greatest", new StandardSQLFunction( "greatest" ) );
 		registerFunction( "least", new StandardSQLFunction( "least" ) );
 
 		registerFunction( "time", new StandardSQLFunction( "time", StandardBasicTypes.TIME ) );
 		registerFunction( "timestamp", new StandardSQLFunction( "timestamp", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "date", new StandardSQLFunction( "date", StandardBasicTypes.DATE ) );
 		registerFunction( "microsecond", new StandardSQLFunction( "microsecond", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "second", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "second(?1)" ) );
 		registerFunction( "minute", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "minute(?1)" ) );
 		registerFunction( "hour", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "hour(?1)" ) );
 		registerFunction( "day", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "day(?1)" ) );
 		registerFunction( "month", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "month(?1)" ) );
 		registerFunction( "year", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "year(?1)" ) );
 
 		registerFunction( "extract", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "?1(?3)" ) );
 
 		registerFunction( "dayname", new StandardSQLFunction( "dayname", StandardBasicTypes.STRING ) );
 		registerFunction( "monthname", new StandardSQLFunction( "monthname", StandardBasicTypes.STRING ) );
 		registerFunction( "dayofmonth", new StandardSQLFunction( "dayofmonth", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofweek", new StandardSQLFunction( "dayofweek", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofyear", new StandardSQLFunction( "dayofyear", StandardBasicTypes.INTEGER ) );
 		registerFunction( "weekofyear", new StandardSQLFunction( "weekofyear", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "replace", new StandardSQLFunction( "replace", StandardBasicTypes.STRING ) );
 		registerFunction( "translate", new StandardSQLFunction( "translate", StandardBasicTypes.STRING ) );
 		registerFunction( "lpad", new StandardSQLFunction( "lpad", StandardBasicTypes.STRING ) );
 		registerFunction( "rpad", new StandardSQLFunction( "rpad", StandardBasicTypes.STRING ) );
 		registerFunction( "substr", new StandardSQLFunction( "substr", StandardBasicTypes.STRING ) );
 		registerFunction( "initcap", new StandardSQLFunction( "initcap", StandardBasicTypes.STRING ) );
 		registerFunction( "lower", new StandardSQLFunction( "lower", StandardBasicTypes.STRING ) );
 		registerFunction( "ltrim", new StandardSQLFunction( "ltrim", StandardBasicTypes.STRING ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim", StandardBasicTypes.STRING ) );
 		registerFunction( "lfill", new StandardSQLFunction( "ltrim", StandardBasicTypes.STRING ) );
 		registerFunction( "rfill", new StandardSQLFunction( "rtrim", StandardBasicTypes.STRING ) );
 		registerFunction( "soundex", new StandardSQLFunction( "soundex", StandardBasicTypes.STRING ) );
 		registerFunction( "upper", new StandardSQLFunction( "upper", StandardBasicTypes.STRING ) );
 		registerFunction( "ascii", new StandardSQLFunction( "ascii", StandardBasicTypes.STRING ) );
 		registerFunction( "index", new StandardSQLFunction( "index", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "value", new StandardSQLFunction( "value" ) );
 
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(", "||", ")" ) );
 		registerFunction( "substring", new StandardSQLFunction( "substr", StandardBasicTypes.STRING ) );
 		registerFunction( "locate", new StandardSQLFunction( "index", StandardBasicTypes.INTEGER ) );
 		registerFunction( "coalesce", new StandardSQLFunction( "value" ) );
 
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 
 	}
 
 	@Override
 	public boolean dropConstraints() {
 		return false;
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public String getAddForeignKeyConstraintString(
 			String constraintName,
 			String[] foreignKey,
 			String referencedTable,
 			String[] primaryKey,
 			boolean referencesPrimaryKey) {
 		final StringBuilder res = new StringBuilder( 30 )
 				.append( " foreign key " )
 				.append( constraintName )
 				.append( " (" )
 				.append( StringHelper.join( ", ", foreignKey ) )
 				.append( ") references " )
 				.append( referencedTable );
 
 		if ( !referencesPrimaryKey ) {
 			res.append( " (" )
 					.append( StringHelper.join( ", ", primaryKey ) )
 					.append( ')' );
 		}
 
 		return res.toString();
 	}
 
 	@Override
 	public String getAddPrimaryKeyConstraintString(String constraintName) {
 		return " primary key ";
 	}
 
 	@Override
 	public String getNullColumnString() {
 		return " null";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from dual";
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select sequence_name from domain.sequences";
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public CaseFragment createCaseFragment() {
 		return new DecodeCaseFragment();
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getDefaultMultiTableBulkIdStrategy() {
 		return new LocalTemporaryTableBulkIdStrategy(
 				new IdTableSupportStandardImpl() {
 					@Override
 					public String generateIdTableName(String baseName) {
 						return "temp." + super.generateIdTableName( baseName );
 					}
 
 					@Override
 					public String getCreateIdTableStatementOptions() {
 						return "ignore rollback";
 					}
 				},
 				AfterUseAction.DROP,
 				null
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/SQLServer2005Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/SQLServer2005Dialect.java
index 4aa7db7854..7eaf086b1a 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/SQLServer2005Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/SQLServer2005Dialect.java
@@ -1,122 +1,122 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryTimeoutException;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.SQLServer2005LimitHandler;
-import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.exception.LockTimeoutException;
 import org.hibernate.exception.spi.SQLExceptionConversionDelegate;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * A dialect for Microsoft SQL 2005. (HHH-3936 fix)
  *
  * @author Yoryos Valotasios
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 @SuppressWarnings("deprecation")
 public class SQLServer2005Dialect extends SQLServerDialect {
 	private static final int MAX_LENGTH = 8000;
 
 	/**
 	 * Constructs a SQLServer2005Dialect
 	 */
 	public SQLServer2005Dialect() {
 		// HHH-3965 fix
 		// As per http://www.sql-server-helper.com/faq/sql-server-2005-varchar-max-p01.aspx
 		// use varchar(max) and varbinary(max) instead of TEXT and IMAGE types
 		registerColumnType( Types.BLOB, "varbinary(MAX)" );
 		registerColumnType( Types.VARBINARY, "varbinary(MAX)" );
 		registerColumnType( Types.VARBINARY, MAX_LENGTH, "varbinary($l)" );
 		registerColumnType( Types.LONGVARBINARY, "varbinary(MAX)" );
 
 		registerColumnType( Types.CLOB, "varchar(MAX)" );
 		registerColumnType( Types.LONGVARCHAR, "varchar(MAX)" );
 		registerColumnType( Types.VARCHAR, "varchar(MAX)" );
 		registerColumnType( Types.VARCHAR, MAX_LENGTH, "varchar($l)" );
 
 		registerColumnType( Types.BIGINT, "bigint" );
 		registerColumnType( Types.BIT, "bit" );
 
 
 		registerFunction( "row_number", new NoArgSQLFunction( "row_number", StandardBasicTypes.INTEGER, true ) );
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return new SQLServer2005LimitHandler();
 	}
 
 	@Override
 	public String appendLockHint(LockOptions lockOptions, String tableName) {
 		// NOTE : since SQLServer2005 the nowait hint is supported
 		if ( lockOptions.getLockMode() == LockMode.UPGRADE_NOWAIT ) {
 			return tableName + " with (updlock, rowlock, nowait)";
 		}
 
 		final LockMode mode = lockOptions.getLockMode();
 		final boolean isNoWait = lockOptions.getTimeOut() == LockOptions.NO_WAIT;
 		final String noWaitStr = isNoWait ? ", nowait" : "";
 		switch ( mode ) {
-			case UPGRADE_NOWAIT:
-				return tableName + " with (updlock, rowlock, nowait)";
 			case UPGRADE:
 			case PESSIMISTIC_WRITE:
-			case WRITE:
+			case WRITE: {
 				return tableName + " with (updlock, rowlock" + noWaitStr + " )";
-			case PESSIMISTIC_READ:
+			}
+			case PESSIMISTIC_READ: {
 				return tableName + " with (holdlock, rowlock" + noWaitStr + " )";
-			default:
+			}
+			default: {
 				return tableName;
+			}
 		}
 	}
 
 	@Override
 	public SQLExceptionConversionDelegate buildSQLExceptionConversionDelegate() {
 		return new SQLExceptionConversionDelegate() {
 			@Override
 			public JDBCException convert(SQLException sqlException, String message, String sql) {
 				final String sqlState = JdbcExceptionHelper.extractSqlState( sqlException );
 				final int errorCode = JdbcExceptionHelper.extractErrorCode( sqlException );
 				if ( "HY008".equals( sqlState ) ) {
 					throw new QueryTimeoutException( message, sqlException, sql );
 				}
 				if (1222 == errorCode ) {
 					throw new LockTimeoutException( message, sqlException, sql );
 				}
 				return null;
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/SQLServer2012Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/SQLServer2012Dialect.java
index e25b004a03..71332dcb02 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/SQLServer2012Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/SQLServer2012Dialect.java
@@ -1,96 +1,99 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
-import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.internal.util.StringHelper;
+
 /**
  * Microsoft SQL Server 2012 Dialect
  *
  * @author Brett Meyer
  */
 public class SQLServer2012Dialect extends SQLServer2008Dialect {
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return "next value for " + sequenceName;
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName );
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select name from sys.sequences";
 	}
-	
+
 	@Override
 	public String getQueryHintString(String sql, List<String> hints) {
-		final String hint = StringHelper.join(", ", hints.iterator());
+		final String hint = StringHelper.join( ", ", hints.iterator() );
 
-		if (StringHelper.isEmpty(hint)) {
+		if ( StringHelper.isEmpty( hint ) ) {
 			return sql;
 		}
 
-		final StringBuilder buffer = new StringBuilder(sql.length()
-				+ hint.length() + 12);
-		final int pos = sql.indexOf(";");
-		if (pos > -1) {
-			buffer.append(sql.substring(0, pos));
-		} else {
-			buffer.append(sql);
+		final StringBuilder buffer = new StringBuilder(
+				sql.length()
+						+ hint.length() + 12
+		);
+		final int pos = sql.indexOf( ";" );
+		if ( pos > -1 ) {
+			buffer.append( sql.substring( 0, pos ) );
+		}
+		else {
+			buffer.append( sql );
 		}
-		buffer.append(" OPTION (").append(hint).append(")");
-		if (pos > -1) {
-			buffer.append(";");
+		buffer.append( " OPTION (" ).append( hint ).append( ")" );
+		if ( pos > -1 ) {
+			buffer.append( ";" );
 		}
 		sql = buffer.toString();
 
 		return sql;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Teradata14Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Teradata14Dialect.java
index 54918fdcfc..89791847db 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Teradata14Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Teradata14Dialect.java
@@ -1,218 +1,221 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
+
 import org.hibernate.HibernateException;
 import org.hibernate.LockOptions;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.exception.spi.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.sql.ForUpdateFragment;
 import org.hibernate.type.StandardBasicTypes;
 
 import java.sql.CallableStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Map;
+
 /**
  * A dialect for the Teradata database
- *
  */
 public class Teradata14Dialect extends TeradataDialect {
 	/**
 	 * Constructor
 	 */
 	public Teradata14Dialect() {
 		super();
 		//registerColumnType data types
 		registerColumnType( Types.BIGINT, "BIGINT" );
 		registerColumnType( Types.BINARY, "VARBYTE(100)" );
 		registerColumnType( Types.LONGVARBINARY, "VARBYTE(32000)" );
 		registerColumnType( Types.LONGVARCHAR, "VARCHAR(32000)" );
 
 		getDefaultProperties().setProperty( Environment.USE_STREAMS_FOR_BINARY, "true" );
-		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE,DEFAULT_BATCH_SIZE );
+		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 
 		registerFunction( "current_time", new SQLFunctionTemplate( StandardBasicTypes.TIME, "current_time" ) );
 		registerFunction( "current_date", new SQLFunctionTemplate( StandardBasicTypes.DATE, "current_date" ) );
 	}
 
 	@Override
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "Add";
 	}
 
 	/**
 	 * Get the name of the database type associated with the given
 	 * <tt>java.sql.Types</tt> typecode.
 	 *
 	 * @param code <tt>java.sql.Types</tt> typecode
 	 * @param length the length or precision of the column
 	 * @param precision the precision of the column
 	 * @param scale the scale of the column
 	 *
 	 * @return the database type name
 	 *
 	 * @throws HibernateException
 	 */
-	 public String getTypeName(int code, int length, int precision, int scale) throws HibernateException {
+	public String getTypeName(int code, int length, int precision, int scale) throws HibernateException {
 		/*
 		 * We might want a special case for 19,2. This is very common for money types
 		 * and here it is converted to 18,1
 		 */
-		float f = precision > 0 ? ( float ) scale / ( float ) precision : 0;
+		float f = precision > 0 ? (float) scale / (float) precision : 0;
 		int p = ( precision > 38 ? 38 : precision );
-		int s = ( precision > 38 ? ( int ) ( 38.0 * f ) : ( scale > 38 ? 38 : scale ) );
+		int s = ( precision > 38 ? (int) ( 38.0 * f ) : ( scale > 38 ? 38 : scale ) );
 		return super.getTypeName( code, length, p, s );
 	}
 
 	@Override
 	public boolean areStringComparisonsCaseInsensitive() {
 		return false;
 	}
 
 	@Override
 	public String getIdentityColumnString() {
 		return "generated by default as identity not null";
 	}
 
 	@Override
 	public String getIdentityInsertString() {
 		return "null";
 	}
 
 	@Override
 	public boolean supportsExpectedLobUsagePattern() {
 		return true;
 	}
 
 	@Override
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 
 	@Override
 	public boolean supportsTupleDistinctCounts() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsExistsInSelect() {
 		return false;
 	}
 
 
 	@Override
 	public boolean supportsUnboundedLobLocatorMaterialization() {
 		return false;
 	}
 
 
 	@Override
 	public int registerResultSetOutParameter(CallableStatement statement, int col) throws SQLException {
-		statement.registerOutParameter(col, Types.REF);
+		statement.registerOutParameter( col, Types.REF );
 		col++;
 		return col;
 	}
 
 	@Override
 	public ResultSet getResultSet(CallableStatement cs) throws SQLException {
 		boolean isResultSet = cs.execute();
-		while (!isResultSet && cs.getUpdateCount() != -1) {
+		while ( !isResultSet && cs.getUpdateCount() != -1 ) {
 			isResultSet = cs.getMoreResults();
 		}
 		return cs.getResultSet();
 	}
 
 	private static ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 		/**
 		 * Extract the name of the violated constraint from the given SQLException.
 		 *
 		 * @param sqle The exception that was the result of the constraint violation.
 		 * @return The extracted constraint name.
 		 */
 		@Override
 		public String extractConstraintName(SQLException sqle) {
 			String constraintName = null;
 
 			int errorCode = sqle.getErrorCode();
-			if (errorCode == 27003) {
-				constraintName = extractUsingTemplate("Unique constraint (", ") violated.", sqle.getMessage());
-			} else if (errorCode == 2700) {
-				constraintName = extractUsingTemplate("Referential constraint", "violation:", sqle.getMessage());
-			} else if (errorCode == 5317) {
-				constraintName = extractUsingTemplate("Check constraint (", ") violated.", sqle.getMessage());
+			if ( errorCode == 27003 ) {
+				constraintName = extractUsingTemplate( "Unique constraint (", ") violated.", sqle.getMessage() );
+			}
+			else if ( errorCode == 2700 ) {
+				constraintName = extractUsingTemplate( "Referential constraint", "violation:", sqle.getMessage() );
+			}
+			else if ( errorCode == 5317 ) {
+				constraintName = extractUsingTemplate( "Check constraint (", ") violated.", sqle.getMessage() );
 			}
 
-			if (constraintName != null) {
-				int i = constraintName.indexOf('.');
-				if (i != -1) {
-					constraintName = constraintName.substring(i + 1);
+			if ( constraintName != null ) {
+				int i = constraintName.indexOf( '.' );
+				if ( i != -1 ) {
+					constraintName = constraintName.substring( i + 1 );
 				}
 			}
 			return constraintName;
 		}
 	};
 
 	@Override
 	public String getWriteLockString(int timeout) {
 		String sMsg = " Locking row for write ";
 		if ( timeout == LockOptions.NO_WAIT ) {
 			return sMsg + " nowait ";
 		}
 		return sMsg;
 	}
 
 	@Override
 	public String getReadLockString(int timeout) {
 		String sMsg = " Locking row for read  ";
 		if ( timeout == LockOptions.NO_WAIT ) {
 			return sMsg + " nowait ";
 		}
 		return sMsg;
 	}
 
 	@Override
 	public String applyLocksToSql(String sql, LockOptions aliasedLockOptions, Map keyColumnNames) {
 		return new ForUpdateFragment( this, aliasedLockOptions, keyColumnNames ).toFragmentString() + " " + sql;
 	}
 
 	@Override
 	public boolean useFollowOnLocking() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLockTimeouts() {
 		return false;
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/TeradataDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/TeradataDialect.java
index f9f4b80867..413b64c48e 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/TeradataDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/TeradataDialect.java
@@ -1,279 +1,279 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 import java.sql.Types;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.hql.spi.id.IdTableSupport;
 import org.hibernate.hql.spi.id.IdTableSupportStandardImpl;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.global.GlobalTemporaryTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.AfterUseAction;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * A dialect for the Teradata database created by MCR as part of the
  * dialect certification process.
  *
  * @author Jay Nance
  */
 public class TeradataDialect extends Dialect implements IdTableSupport {
 	
 	private static final int PARAM_LIST_SIZE_LIMIT = 1024;
 
 	/**
 	 * Constructor
 	 */
 	public TeradataDialect() {
 		super();
 		//registerColumnType data types
 		registerColumnType( Types.NUMERIC, "NUMERIC($p,$s)" );
 		registerColumnType( Types.DOUBLE, "DOUBLE PRECISION" );
 		registerColumnType( Types.BIGINT, "NUMERIC(18,0)" );
 		registerColumnType( Types.BIT, "BYTEINT" );
 		registerColumnType( Types.TINYINT, "BYTEINT" );
 		registerColumnType( Types.VARBINARY, "VARBYTE($l)" );
 		registerColumnType( Types.BINARY, "BYTEINT" );
 		registerColumnType( Types.LONGVARCHAR, "LONG VARCHAR" );
 		registerColumnType( Types.CHAR, "CHAR(1)" );
 		registerColumnType( Types.DECIMAL, "DECIMAL" );
 		registerColumnType( Types.INTEGER, "INTEGER" );
 		registerColumnType( Types.SMALLINT, "SMALLINT" );
 		registerColumnType( Types.FLOAT, "FLOAT" );
 		registerColumnType( Types.VARCHAR, "VARCHAR($l)" );
 		registerColumnType( Types.DATE, "DATE" );
 		registerColumnType( Types.TIME, "TIME" );
 		registerColumnType( Types.TIMESTAMP, "TIMESTAMP" );
 		registerColumnType( Types.BOOLEAN, "BYTEINT" );  // hibernate seems to ignore this type...
 		registerColumnType( Types.BLOB, "BLOB" );
 		registerColumnType( Types.CLOB, "CLOB" );
 
 		registerFunction( "year", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "extract(year from ?1)" ) );
 		registerFunction( "length", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "character_length(?1)" ) );
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(", "||", ")" ) );
 		registerFunction( "substring", new SQLFunctionTemplate( StandardBasicTypes.STRING, "substring(?1 from ?2 for ?3)" ) );
 		registerFunction( "locate", new SQLFunctionTemplate( StandardBasicTypes.STRING, "position(?1 in ?2)" ) );
 		registerFunction( "mod", new SQLFunctionTemplate( StandardBasicTypes.STRING, "?1 mod ?2" ) );
 		registerFunction( "str", new SQLFunctionTemplate( StandardBasicTypes.STRING, "cast(?1 as varchar(255))" ) );
 
 		// bit_length feels a bit broken to me. We have to cast to char in order to
 		// pass when a numeric value is supplied. But of course the answers given will
 		// be wildly different for these two datatypes. 1234.5678 will be 9 bytes as
 		// a char string but will be 8 or 16 bytes as a true numeric.
 		// Jay Nance 2006-09-22
 		registerFunction(
 				"bit_length", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "octet_length(cast(?1 as char))*4" )
 		);
 
 		// The preference here would be
 		//   SQLFunctionTemplate( StandardBasicTypes.TIMESTAMP, "current_timestamp(?1)", false)
 		// but this appears not to work.
 		// Jay Nance 2006-09-22
 		registerFunction( "current_timestamp", new SQLFunctionTemplate( StandardBasicTypes.TIMESTAMP, "current_timestamp" ) );
 		registerFunction( "current_time", new SQLFunctionTemplate( StandardBasicTypes.TIMESTAMP, "current_time" ) );
 		registerFunction( "current_date", new SQLFunctionTemplate( StandardBasicTypes.TIMESTAMP, "current_date" ) );
 		// IBID for current_time and current_date
 
 		registerKeyword( "password" );
 		registerKeyword( "type" );
 		registerKeyword( "title" );
 		registerKeyword( "year" );
 		registerKeyword( "month" );
 		registerKeyword( "summary" );
 		registerKeyword( "alias" );
 		registerKeyword( "value" );
 		registerKeyword( "first" );
 		registerKeyword( "role" );
 		registerKeyword( "account" );
 		registerKeyword( "class" );
 
 		// Tell hibernate to use getBytes instead of getBinaryStream
 		getDefaultProperties().setProperty( Environment.USE_STREAMS_FOR_BINARY, "false" );
 		// No batch statements
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, NO_BATCH );
 	}
 
 	/**
 	 * Does this dialect support the <tt>FOR UPDATE</tt> syntax?
 	 *
 	 * @return empty string ... Teradata does not support <tt>FOR UPDATE<tt> syntax
 	 */
 	public String getForUpdateString() {
 		return "";
 	}
 
 	public boolean supportsIdentityColumns() {
 		return false;
 	}
 
 	public boolean supportsSequences() {
 		return false;
 	}
 
 	public String getAddColumnString() {
 		return "Add Column";
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getDefaultMultiTableBulkIdStrategy() {
 		return new GlobalTemporaryTableBulkIdStrategy( this, AfterUseAction.CLEAN );
 	}
 
 	@Override
 	public String generateIdTableName(String baseName) {
 		return IdTableSupportStandardImpl.INSTANCE.generateIdTableName( baseName );
 	}
 
 	@Override
 	public String getCreateIdTableCommand() {
 		return "create global temporary table";
 	}
 
 	@Override
 	public String getCreateIdTableStatementOptions() {
 		return " on commit preserve rows";
 	}
 
 	@Override
 	public String getDropIdTableCommand() {
 		return "drop table";
 	}
 
 	/**
 	 * Get the name of the database type associated with the given
 	 * <tt>java.sql.Types</tt> typecode.
 	 *
 	 * @param code <tt>java.sql.Types</tt> typecode
 	 * @param length the length or precision of the column
 	 * @param precision the precision of the column
 	 * @param scale the scale of the column
 	 *
 	 * @return the database type name
 	 *
 	 * @throws HibernateException
 	 */
 	public String getTypeName(int code, int length, int precision, int scale) throws HibernateException {
 		/*
 		 * We might want a special case for 19,2. This is very common for money types
 		 * and here it is converted to 18,1
 		 */
 		float f = precision > 0 ? ( float ) scale / ( float ) precision : 0;
 		int p = ( precision > 18 ? 18 : precision );
 		int s = ( precision > 18 ? ( int ) ( 18.0 * f ) : ( scale > 18 ? 18 : scale ) );
 
 		return super.getTypeName( code, length, p, s );
 	}
 
 	public boolean supportsCascadeDelete() {
 		return false;
 	}
 
 	public boolean supportsCircularCascadeDeleteConstraints() {
 		return false;
 	}
 
 	public boolean areStringComparisonsCaseInsensitive() {
 		return true;
 	}
 
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	public String getSelectClauseNullString(int sqlType) {
 		String v = "null";
 
 		switch ( sqlType ) {
 			case Types.BIT:
 			case Types.TINYINT:
 			case Types.SMALLINT:
 			case Types.INTEGER:
 			case Types.BIGINT:
 			case Types.FLOAT:
 			case Types.REAL:
 			case Types.DOUBLE:
 			case Types.NUMERIC:
 			case Types.DECIMAL:
 				v = "cast(null as decimal)";
 				break;
 			case Types.CHAR:
 			case Types.VARCHAR:
 			case Types.LONGVARCHAR:
 				v = "cast(null as varchar(255))";
 				break;
 			case Types.DATE:
 			case Types.TIME:
 			case Types.TIMESTAMP:
 				v = "cast(null as timestamp)";
 				break;
 			case Types.BINARY:
 			case Types.VARBINARY:
 			case Types.LONGVARBINARY:
 			case Types.NULL:
 			case Types.OTHER:
 			case Types.JAVA_OBJECT:
 			case Types.DISTINCT:
 			case Types.STRUCT:
 			case Types.ARRAY:
 			case Types.BLOB:
 			case Types.CLOB:
 			case Types.REF:
 			case Types.DATALINK:
 			case Types.BOOLEAN:
 				break;
 		}
 		return v;
 	}
 
 	public String getCreateMultisetTableString() {
 		return "create multiset table ";
 	}
 
 	public boolean supportsLobValueChangePropogation() {
 		return false;
 	}
 
 	public boolean doesReadCommittedCauseWritersToBlockReaders() {
 		return true;
 	}
 
 	public boolean doesRepeatableReadCauseReadersToBlockWriters() {
 		return true;
 	}
 
 	public boolean supportsBindAsCallableArgument() {
 		return false;
 	}
 
 	/* (non-Javadoc)
 		 * @see org.hibernate.dialect.Dialect#getInExpressionCountLimit()
 		 */
 	@Override
 	public int getInExpressionCountLimit() {
 		return PARAM_LIST_SIZE_LIMIT;
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/TimesTenDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/TimesTenDialect.java
index 808305385f..bad922aa91 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/TimesTenDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/TimesTenDialect.java
@@ -1,285 +1,284 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.Types;
 
 import org.hibernate.LockMode;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.dialect.lock.OptimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.OptimisticLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticReadUpdateLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticWriteUpdateLockingStrategy;
 import org.hibernate.dialect.lock.SelectLockingStrategy;
 import org.hibernate.dialect.lock.UpdateLockingStrategy;
 import org.hibernate.dialect.pagination.FirstLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.hql.spi.id.IdTableSupportStandardImpl;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.global.GlobalTemporaryTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.AfterUseAction;
-import org.hibernate.hql.spi.id.local.LocalTemporaryTableBulkIdStrategy;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.OracleJoinFragment;
 import org.hibernate.type.StandardBasicTypes;
 
 /**
  * A SQL dialect for TimesTen 5.1.
  * <p/>
  * Known limitations:
  * joined-subclass support because of no CASE support in TimesTen
  * No support for subqueries that includes aggregation
  * - size() in HQL not supported
  * - user queries that does subqueries with aggregation
  * No CLOB/BLOB support
  * No cascade delete support.
  * No Calendar support
  * No support for updating primary keys.
  *
  * @author Sherry Listgarten and Max Andersen
  */
 @SuppressWarnings("deprecation")
 public class TimesTenDialect extends Dialect {
 	/**
 	 * Constructs a TimesTenDialect
 	 */
 	public TimesTenDialect() {
 		super();
 		registerColumnType( Types.BIT, "TINYINT" );
 		registerColumnType( Types.BIGINT, "BIGINT" );
 		registerColumnType( Types.SMALLINT, "SMALLINT" );
 		registerColumnType( Types.TINYINT, "TINYINT" );
 		registerColumnType( Types.INTEGER, "INTEGER" );
 		registerColumnType( Types.CHAR, "CHAR(1)" );
 		registerColumnType( Types.VARCHAR, "VARCHAR($l)" );
 		registerColumnType( Types.FLOAT, "FLOAT" );
 		registerColumnType( Types.DOUBLE, "DOUBLE" );
 		registerColumnType( Types.DATE, "DATE" );
 		registerColumnType( Types.TIME, "TIME" );
 		registerColumnType( Types.TIMESTAMP, "TIMESTAMP" );
 		registerColumnType( Types.VARBINARY, "VARBINARY($l)" );
 		registerColumnType( Types.NUMERIC, "DECIMAL($p, $s)" );
 		// TimesTen has no BLOB/CLOB support, but these types may be suitable 
 		// for some applications. The length is limited to 4 million bytes.
 		registerColumnType( Types.BLOB, "VARBINARY(4000000)" );
 		registerColumnType( Types.CLOB, "VARCHAR(4000000)" );
 
 		getDefaultProperties().setProperty( Environment.USE_STREAMS_FOR_BINARY, "true" );
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 		registerFunction( "lower", new StandardSQLFunction( "lower" ) );
 		registerFunction( "upper", new StandardSQLFunction( "upper" ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim" ) );
 		registerFunction( "concat", new StandardSQLFunction( "concat", StandardBasicTypes.STRING ) );
 		registerFunction( "mod", new StandardSQLFunction( "mod" ) );
 		registerFunction( "to_char", new StandardSQLFunction( "to_char", StandardBasicTypes.STRING ) );
 		registerFunction( "to_date", new StandardSQLFunction( "to_date", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "sysdate", new NoArgSQLFunction( "sysdate", StandardBasicTypes.TIMESTAMP, false ) );
 		registerFunction( "getdate", new NoArgSQLFunction( "getdate", StandardBasicTypes.TIMESTAMP, false ) );
 		registerFunction( "nvl", new StandardSQLFunction( "nvl" ) );
 
 	}
 
 	@Override
 	public boolean dropConstraints() {
 		return true;
 	}
 
 	@Override
 	public boolean qualifyIndexName() {
 		return false;
 	}
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select first 1 " + sequenceName + ".nextval from sys.tables";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return "select NAME from sys.sequences";
 	}
 
 	@Override
 	public JoinFragment createOuterJoinFragment() {
 		return new OracleJoinFragment();
 	}
 
 	@Override
 	public String getCrossJoinSeparator() {
 		return ", ";
 	}
 
 	@Override
 	public String getForUpdateString() {
 		return "";
 	}
 
 	@Override
 	public boolean supportsColumnCheck() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsTableCheck() {
 		return false;
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return FirstLimitHandler.INSTANCE;
 	}
 
 	@Override
 	public boolean supportsLimitOffset() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsVariableLimit() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public String getLimitString(String querySelect, int offset, int limit) {
 		if ( offset > 0 ) {
 			throw new UnsupportedOperationException( "query result offset is not supported" );
 		}
 		return new StringBuilder( querySelect.length() + 8 )
 				.append( querySelect )
 				.insert( 6, " first " + limit )
 				.toString();
 	}
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select first 1 sysdate from sys.tables";
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getDefaultMultiTableBulkIdStrategy() {
 		return new GlobalTemporaryTableBulkIdStrategy(
 				new IdTableSupportStandardImpl() {
 					@Override
 					public String generateIdTableName(String baseName) {
 						final String name = super.generateIdTableName( baseName );
 						return name.length() > 30 ? name.substring( 1, 30 ) : name;
 					}
 
 					@Override
 					public String getCreateIdTableCommand() {
 						return "create global temporary table";
 					}
 
 					@Override
 					public String getCreateIdTableStatementOptions() {
 						return "on commit delete rows";
 					}
 				},
 				AfterUseAction.CLEAN
 		);
 	}
 
 	@Override
 	public LockingStrategy getLockingStrategy(Lockable lockable, LockMode lockMode) {
 		// TimesTen has no known variation of a "SELECT ... FOR UPDATE" syntax...
 		if ( lockMode == LockMode.PESSIMISTIC_FORCE_INCREMENT ) {
 			return new PessimisticForceIncrementLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_WRITE ) {
 			return new PessimisticWriteUpdateLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_READ ) {
 			return new PessimisticReadUpdateLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC ) {
 			return new OptimisticLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC_FORCE_INCREMENT ) {
 			return new OptimisticForceIncrementLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode.greaterThan( LockMode.READ ) ) {
 			return new UpdateLockingStrategy( lockable, lockMode );
 		}
 		else {
 			return new SelectLockingStrategy( lockable, lockMode );
 		}
 	}
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
index 56cd8b5d35..557931a97e 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
@@ -1,158 +1,158 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.batch.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * A {@link org.hibernate.engine.jdbc.batch.spi.Batch} implementation which does bathing based on a given size.  Once
  * the batch size is reached for a statement in the batch, the entire batch is implicitly executed.
  *
  * @author Steve Ebersole
  */
 public class BatchingBatch extends AbstractBatchImpl {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			BatchingBatch.class.getName()
 	);
 
 	// IMPL NOTE : Until HHH-5797 is fixed, there will only be 1 statement in a batch
 
 	private final int batchSize;
 	private int batchPosition;
 	private boolean batchExecuted;
 	private int statementPosition;
 
 	/**
 	 * Constructs a BatchingBatch
 	 *
 	 * @param key The batch key
 	 * @param jdbcCoordinator The JDBC jdbcCoordinator
 	 * @param batchSize The batch size.
 	 */
 	public BatchingBatch(
 			BatchKey key,
 			JdbcCoordinator jdbcCoordinator,
 			int batchSize) {
 		super( key, jdbcCoordinator );
 		if ( ! key.getExpectation().canBeBatched() ) {
 			throw new HibernateException( "attempting to batch an operation which cannot be batched" );
 		}
 		this.batchSize = batchSize;
 	}
 
 	private String currentStatementSql;
 	private PreparedStatement currentStatement;
 
 	@Override
 	public PreparedStatement getBatchStatement(String sql, boolean callable) {
 		currentStatementSql = sql;
 		currentStatement = super.getBatchStatement( sql, callable );
 		return currentStatement;
 	}
 
 	@Override
 	public void addToBatch() {
 		try {
 			currentStatement.addBatch();
 		}
 		catch ( SQLException e ) {
 			LOG.debugf( "SQLException escaped proxy", e );
 			throw sqlExceptionHelper().convert( e, "could not perform addBatch", currentStatementSql );
 		}
 		statementPosition++;
 		if ( statementPosition >= getKey().getBatchedStatementCount() ) {
 			batchPosition++;
 			if ( batchPosition == batchSize ) {
 				notifyObserversImplicitExecution();
 				performExecution();
 				batchPosition = 0;
-                batchExecuted = true;
+				batchExecuted = true;
 			}
 			statementPosition = 0;
 		}
 	}
 
 	@Override
 	protected void doExecuteBatch() {
 		if (batchPosition == 0 ) {
 			if(! batchExecuted) {
 				LOG.debug( "No batched statements to execute" );
 			}
 		}
 		else {
 			performExecution();
 		}
 	}
 
 	private void performExecution() {
 		LOG.debugf( "Executing batch size: %s", batchPosition );
 		try {
 			for ( Map.Entry<String,PreparedStatement> entry : getStatements().entrySet() ) {
 				try {
 					final PreparedStatement statement = entry.getValue();
 					final int[] rowCounts;
 					try {
 						getJdbcCoordinator().getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcExecuteBatchStart();
 						rowCounts = statement.executeBatch();
 					}
 					finally {
 						getJdbcCoordinator().getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcExecuteBatchEnd();
 					}
 					checkRowCounts( rowCounts, statement );
 				}
 				catch ( SQLException e ) {
 					abortBatch();
 					throw sqlExceptionHelper().convert( e, "could not execute batch", entry.getKey() );
 				}
 			}
 		}
 		catch ( RuntimeException re ) {
 			LOG.unableToExecuteBatch( re.getMessage() );
 			throw re;
 		}
 		finally {
 			batchPosition = 0;
 		}
 	}
 
 	private void checkRowCounts(int[] rowCounts, PreparedStatement ps) throws SQLException, HibernateException {
 		final int numberOfRowCounts = rowCounts.length;
 		if ( numberOfRowCounts != batchPosition ) {
 			LOG.unexpectedRowCounts();
 		}
 		for ( int i = 0; i < numberOfRowCounts; i++ ) {
 			getKey().getExpectation().verifyOutcome( rowCounts[i], ps, i );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
index fa402300a3..263568f36d 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
@@ -1,309 +1,311 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.connections.internal;
 
 import java.sql.Connection;
 import java.sql.Driver;
 import java.sql.SQLException;
 import java.util.Map;
 import java.util.Properties;
 import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.Executors;
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.UnknownUnwrapTypeException;
 import org.hibernate.service.spi.Configurable;
 import org.hibernate.service.spi.ServiceException;
 import org.hibernate.service.spi.ServiceRegistryAwareService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.Stoppable;
 
 /**
  * A connection provider that uses the {@link java.sql.DriverManager} directly to open connections and provides
  * a very rudimentary connection pool.
  * <p/>
  * IMPL NOTE : not intended for production use!
  * <p/>
  * Thanks to Oleg Varaksin and his article on object pooling using the {@link java.util.concurrent} package, from
  * which much of the pooling code here is derived.  See http://ovaraksin.blogspot.com/2013/08/simple-and-lightweight-pool.html
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class DriverManagerConnectionProviderImpl
 		implements ConnectionProvider, Configurable, Stoppable, ServiceRegistryAwareService {
 
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( DriverManagerConnectionProviderImpl.class );
 
 	public static final String MIN_SIZE = "hibernate.connection.min_pool_size";
 	public static final String INITIAL_SIZE = "hibernate.connection.initial_pool_size";
 	// in TimeUnit.SECONDS
 	public static final String VALIDATION_INTERVAL = "hibernate.connection.pool_validation_interval";
 
 	private boolean active = true;
 
 	private ConcurrentLinkedQueue<Connection> connections = new ConcurrentLinkedQueue<Connection>();
 	private ConnectionCreator connectionCreator;
 	private ScheduledExecutorService executorService;
 
 
 
 	// create the pool ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private ServiceRegistryImplementor serviceRegistry;
 
 	@Override
 	public void injectServices(ServiceRegistryImplementor serviceRegistry) {
 		this.serviceRegistry = serviceRegistry;
 	}
 
 	@Override
 	public void configure(Map configurationValues) {
 		log.usingHibernateBuiltInConnectionPool();
 
 		connectionCreator = buildCreator( configurationValues );
 
 		final int minSize = ConfigurationHelper.getInt( MIN_SIZE, configurationValues, 1 );
 		final int maxSize = ConfigurationHelper.getInt( AvailableSettings.POOL_SIZE, configurationValues, 20 );
 		final int initialSize = ConfigurationHelper.getInt( INITIAL_SIZE, configurationValues, minSize );
 		final long validationInterval = ConfigurationHelper.getLong( VALIDATION_INTERVAL, configurationValues, 30 );
 
 		log.hibernateConnectionPoolSize( maxSize, minSize );
 
 		log.debugf( "Initializing Connection pool with %s Connections", initialSize );
 		for ( int i = 0; i < initialSize; i++ ) {
 			connections.add( connectionCreator.createConnection() );
 		}
 
 		executorService = Executors.newSingleThreadScheduledExecutor();
 		executorService.scheduleWithFixedDelay(
 				new Runnable() {
 					private boolean primed;
 					@Override
 					public void run() {
 						int size = connections.size();
 
 						if ( !primed && size >= minSize ) {
 							// IMPL NOTE : the purpose of primed is to allow the pool to lazily reach its
 							// defined min-size.
 							log.debug( "Connection pool now considered primed; min-size will be maintained" );
 							primed = true;
 						}
 
 						if ( size < minSize && primed ) {
 							int numberToBeAdded = minSize - size;
 							log.debugf( "Adding %s Connections to the pool", numberToBeAdded );
 							for (int i = 0; i < numberToBeAdded; i++) {
 								connections.add( connectionCreator.createConnection() );
 							}
 						}
 						else if ( size > maxSize ) {
 							int numberToBeRemoved = size - maxSize;
 							log.debugf( "Removing %s Connections from the pool", numberToBeRemoved );
 							for ( int i = 0; i < numberToBeRemoved; i++ ) {
 								Connection connection = connections.poll();
 								try {
 									connection.close();
 								}
 								catch (SQLException e) {
 									log.unableToCloseConnection( e );
 								}
 							}
 						}
 					}
 				},
 				validationInterval,
 				validationInterval,
 				TimeUnit.SECONDS
 		);
 	}
 
 	private ConnectionCreator buildCreator(Map configurationValues) {
 		final ConnectionCreatorBuilder connectionCreatorBuilder = new ConnectionCreatorBuilder( serviceRegistry );
 
 		final String driverClassName = (String) configurationValues.get( AvailableSettings.DRIVER );
 		connectionCreatorBuilder.setDriver( loadDriverIfPossible( driverClassName ) );
 
 		final String url = (String) configurationValues.get( AvailableSettings.URL );
 		if ( url == null ) {
 			final String msg = log.jdbcUrlNotSpecified( AvailableSettings.URL );
 			log.error( msg );
 			throw new HibernateException( msg );
 		}
 		connectionCreatorBuilder.setUrl( url );
 
 		log.usingDriver( driverClassName, url );
 
 		final Properties connectionProps = ConnectionProviderInitiator.getConnectionProperties( configurationValues );
 
 		// if debug level is enabled, then log the password, otherwise mask it
 		if ( log.isDebugEnabled() ) {
 			log.connectionProperties( connectionProps );
 		}
 		else {
 			log.connectionProperties( ConfigurationHelper.maskOut( connectionProps, "password" ) );
 		}
 		connectionCreatorBuilder.setConnectionProps( connectionProps );
 
 		final boolean autoCommit = ConfigurationHelper.getBoolean( AvailableSettings.AUTOCOMMIT, configurationValues, false );
 		log.autoCommitMode( autoCommit );
 		connectionCreatorBuilder.setAutoCommit( autoCommit );
 
 		final Integer isolation = ConfigurationHelper.getInteger( AvailableSettings.ISOLATION, configurationValues );
 		if ( isolation != null ) {
 			log.jdbcIsolationLevel( Environment.isolationLevelToString( isolation ) );
 		}
 		connectionCreatorBuilder.setIsolation( isolation );
 
 		return connectionCreatorBuilder.build();
 	}
 
 	private Driver loadDriverIfPossible(String driverClassName) {
 		if ( driverClassName == null ) {
 			log.debug( "No driver class specified" );
 			return null;
 		}
 
 		if ( serviceRegistry != null ) {
 			final ClassLoaderService classLoaderService = serviceRegistry.getService( ClassLoaderService.class );
 			final Class<Driver> driverClass = classLoaderService.classForName( driverClassName );
 			try {
 				return driverClass.newInstance();
 			}
 			catch ( Exception e ) {
 				throw new ServiceException( "Specified JDBC Driver " + driverClassName + " could not be loaded", e );
 			}
 		}
 
 		try {
 			return (Driver) Class.forName( driverClassName ).newInstance();
 		}
 		catch ( Exception e1 ) {
 			try{
 				return (Driver) ReflectHelper.classForName( driverClassName ).newInstance();
 			}
 			catch ( Exception e2 ) {
 				throw new ServiceException( "Specified JDBC Driver " + driverClassName + " could not be loaded", e2 );
 			}
 		}
 	}
 
 
 	// use the pool ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Connection getConnection() throws SQLException {
 		if ( !active ) {
 			throw new HibernateException( "Connection pool is no longer active" );
 		}
 
 		Connection connection;
 		if ( (connection = connections.poll()) == null ) {
 			connection = connectionCreator.createConnection();
 		}
 
 		return connection;
 	}
 
 	@Override
 	public void closeConnection(Connection conn) throws SQLException {
 		if (conn == null) {
 			return;
 		}
 
 		this.connections.offer( conn );
 	}
 
 
 	@Override
 	public boolean supportsAggressiveRelease() {
 		return false;
 	}
 
 	@Override
 	public boolean isUnwrappableAs(Class unwrapType) {
 		return ConnectionProvider.class.equals( unwrapType ) ||
 				DriverManagerConnectionProviderImpl.class.isAssignableFrom( unwrapType );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public <T> T unwrap(Class<T> unwrapType) {
 		if ( ConnectionProvider.class.equals( unwrapType ) ||
 				DriverManagerConnectionProviderImpl.class.isAssignableFrom( unwrapType ) ) {
 			return (T) this;
 		}
 		else {
 			throw new UnknownUnwrapTypeException( unwrapType );
 		}
 	}
 
 
 	// destroy the pool ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void stop() {
 		if ( !active ) {
 			return;
 		}
 
 		log.cleaningUpConnectionPool( connectionCreator.getUrl() );
 
 		active = false;
 
 		if ( executorService != null ) {
 			executorService.shutdown();
 		}
 		executorService = null;
 
 		for ( Connection connection : connections ) {
 			try {
 				connection.close();
 			}
 			catch (SQLException e) {
 				log.unableToClosePooledConnection( e );
 			}
 		}
 	}
 
 
+	//CHECKSTYLE:START_ALLOW_FINALIZER
 	@Override
 	protected void finalize() throws Throwable {
 		if ( active ) {
 			stop();
 		}
 		super.finalize();
 	}
+	//CHECKSTYLE:END_ALLOW_FINALIZER
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/ExtractedDatabaseMetaDataImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/ExtractedDatabaseMetaDataImpl.java
index 841f0c1875..63c82e1f17 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/ExtractedDatabaseMetaDataImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/env/internal/ExtractedDatabaseMetaDataImpl.java
@@ -1,338 +1,336 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.env.internal;
 
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.LinkedHashSet;
-import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.engine.jdbc.cursor.internal.StandardRefCursorSupport;
 import org.hibernate.engine.jdbc.env.spi.ExtractedDatabaseMetaData;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.env.spi.SQLStateType;
 import org.hibernate.engine.jdbc.spi.TypeInfo;
 import org.hibernate.internal.util.StringHelper;
-import org.hibernate.mapping.Collection;
 
 /**
  * Standard implementation of ExtractedDatabaseMetaData
  *
  * @author Steve Ebersole
  */
 public class ExtractedDatabaseMetaDataImpl implements ExtractedDatabaseMetaData {
 	private final JdbcEnvironment jdbcEnvironment;
 
 	private final String connectionCatalogName;
 	private final String connectionSchemaName;
 
 	private final boolean supportsRefCursors;
 	private final boolean supportsNamedParameters;
 	private final boolean supportsScrollableResults;
 	private final boolean supportsGetGeneratedKeys;
 	private final boolean supportsBatchUpdates;
 	private final boolean supportsDataDefinitionInTransaction;
 	private final boolean doesDataDefinitionCauseTransactionCommit;
 	private final SQLStateType sqlStateType;
 	private final boolean lobLocatorUpdateCopy;
 
 	private final Set<String> extraKeywords;
 	private final LinkedHashSet<TypeInfo> typeInfoSet;
 
 	private ExtractedDatabaseMetaDataImpl(
 			JdbcEnvironment jdbcEnvironment,
 			String connectionCatalogName,
 			String connectionSchemaName,
 			Set<String> extraKeywords,
 			LinkedHashSet<TypeInfo> typeInfoSet,
 			boolean supportsRefCursors,
 			boolean supportsNamedParameters,
 			boolean supportsScrollableResults,
 			boolean supportsGetGeneratedKeys,
 			boolean supportsBatchUpdates,
 			boolean supportsDataDefinitionInTransaction,
 			boolean doesDataDefinitionCauseTransactionCommit,
 			SQLStateType sqlStateType,
 			boolean lobLocatorUpdateCopy) {
 		this.jdbcEnvironment = jdbcEnvironment;
 
 		this.connectionCatalogName = connectionCatalogName;
 		this.connectionSchemaName = connectionSchemaName;
 
 		this.extraKeywords = extraKeywords != null
 				? extraKeywords
 				: Collections.<String>emptySet();
 		this.typeInfoSet = typeInfoSet != null
 				? typeInfoSet
 				: new LinkedHashSet<TypeInfo>();
 
 		this.supportsRefCursors = supportsRefCursors;
 		this.supportsNamedParameters = supportsNamedParameters;
 		this.supportsScrollableResults = supportsScrollableResults;
 		this.supportsGetGeneratedKeys = supportsGetGeneratedKeys;
 		this.supportsBatchUpdates = supportsBatchUpdates;
 		this.supportsDataDefinitionInTransaction = supportsDataDefinitionInTransaction;
 		this.doesDataDefinitionCauseTransactionCommit = doesDataDefinitionCauseTransactionCommit;
 		this.sqlStateType = sqlStateType;
 		this.lobLocatorUpdateCopy = lobLocatorUpdateCopy;
 	}
 
 	@Override
 	public boolean supportsRefCursors() {
 		return supportsRefCursors;
 	}
 
 	@Override
 	public JdbcEnvironment getJdbcEnvironment() {
 		return jdbcEnvironment;
 	}
 
 	@Override
 	public boolean supportsNamedParameters() {
 		return supportsNamedParameters;
 	}
 
 	@Override
 	public boolean supportsScrollableResults() {
 		return supportsScrollableResults;
 	}
 
 	@Override
 	public boolean supportsGetGeneratedKeys() {
 		return supportsGetGeneratedKeys;
 	}
 
 	@Override
 	public boolean supportsBatchUpdates() {
 		return supportsBatchUpdates;
 	}
 
 	@Override
 	public boolean supportsDataDefinitionInTransaction() {
 		return supportsDataDefinitionInTransaction;
 	}
 
 	@Override
 	public boolean doesDataDefinitionCauseTransactionCommit() {
 		return doesDataDefinitionCauseTransactionCommit;
 	}
 
 	@Override
 	public Set<String> getExtraKeywords() {
 		return extraKeywords;
 	}
 
 	@Override
 	public SQLStateType getSqlStateType() {
 		return sqlStateType;
 	}
 
 	@Override
 	public boolean doesLobLocatorUpdateCopy() {
 		return lobLocatorUpdateCopy;
 	}
 
 	@Override
 	public String getConnectionCatalogName() {
 		return connectionCatalogName;
 	}
 
 	@Override
 	public String getConnectionSchemaName() {
 		return connectionSchemaName;
 	}
 
 	@Override
 	public LinkedHashSet<TypeInfo> getTypeInfoSet() {
 		return typeInfoSet;
 	}
 
 	public static class Builder {
 		private final JdbcEnvironment jdbcEnvironment;
 
 		private String connectionSchemaName;
 		private String connectionCatalogName;
 
 		private Set<String> extraKeywords;
 		private LinkedHashSet<TypeInfo> typeInfoSet;
 
 		private boolean supportsRefCursors;
 		private boolean supportsNamedParameters;
 		private boolean supportsScrollableResults;
 		private boolean supportsGetGeneratedKeys;
 		private boolean supportsBatchUpdates;
 		private boolean supportsDataDefinitionInTransaction;
 		private boolean doesDataDefinitionCauseTransactionCommit;
 		private SQLStateType sqlStateType;
 		private boolean lobLocatorUpdateCopy;
 
 		public Builder(JdbcEnvironment jdbcEnvironment) {
 			this.jdbcEnvironment = jdbcEnvironment;
 		}
 
 		public Builder apply(DatabaseMetaData databaseMetaData) throws SQLException {
 			connectionCatalogName = databaseMetaData.getConnection().getCatalog();
 			// NOTE : databaseMetaData.getConnection().getSchema() would require java 1.7 as baseline
 			supportsRefCursors = StandardRefCursorSupport.supportsRefCursors( databaseMetaData );
 			supportsNamedParameters = databaseMetaData.supportsNamedParameters();
 			supportsScrollableResults = databaseMetaData.supportsResultSetType( ResultSet.TYPE_SCROLL_INSENSITIVE );
 			supportsGetGeneratedKeys = databaseMetaData.supportsGetGeneratedKeys();
 			supportsBatchUpdates = databaseMetaData.supportsBatchUpdates();
 			supportsDataDefinitionInTransaction = !databaseMetaData.dataDefinitionIgnoredInTransactions();
 			doesDataDefinitionCauseTransactionCommit = databaseMetaData.dataDefinitionCausesTransactionCommit();
 			extraKeywords = parseKeywords( databaseMetaData.getSQLKeywords() );
 			sqlStateType = SQLStateType.interpretReportedSQLStateType( databaseMetaData.getSQLStateType() );
 			lobLocatorUpdateCopy = databaseMetaData.locatorsUpdateCopy();
 			typeInfoSet = new LinkedHashSet<TypeInfo>();
 			typeInfoSet.addAll( TypeInfo.extractTypeInfo( databaseMetaData ) );
 
 			return this;
 		}
 
 		private Set<String> parseKeywords(String extraKeywordsString) {
 			if ( StringHelper.isEmpty(  extraKeywordsString ) ) {
 				return Collections.emptySet();
 			}
 
 			final Set<String> keywordSet = new HashSet<String>();
 			keywordSet.addAll( Arrays.asList( extraKeywordsString.split( "\\s*,\\s*" ) ) );
 			return keywordSet;
 		}
 
 		public Builder setConnectionSchemaName(String connectionSchemaName) {
 			this.connectionSchemaName = connectionSchemaName;
 			return this;
 		}
 
 		public Builder setConnectionCatalogName(String connectionCatalogName) {
 			this.connectionCatalogName = connectionCatalogName;
 			return this;
 		}
 
 		public Builder setExtraKeywords(Set<String> extraKeywords) {
 			if ( this.extraKeywords == null ) {
 				this.extraKeywords = extraKeywords;
 			}
 			else {
 				this.extraKeywords.addAll( extraKeywords );
 			}
 			return this;
 		}
 
 		public Builder addExtraKeyword(String keyword) {
 			if ( this.extraKeywords == null ) {
 				this.extraKeywords = new HashSet<String>();
 			}
 			this.extraKeywords.add( keyword );
 			return this;
 		}
 
 		public Builder setTypeInfoSet(LinkedHashSet<TypeInfo> typeInfoSet) {
 			if ( this.typeInfoSet == null ) {
 				this.typeInfoSet = typeInfoSet;
 			}
 			else {
 				this.typeInfoSet.addAll( typeInfoSet );
 			}
 			return this;
 		}
 
 		public Builder addTypeInfo(TypeInfo typeInfo) {
 			if ( this.typeInfoSet == null ) {
 				this.typeInfoSet = new LinkedHashSet<TypeInfo>();
 			}
 			typeInfoSet.add( typeInfo );
 			return this;
 		}
 
 		public Builder setSupportsRefCursors(boolean supportsRefCursors) {
 			this.supportsRefCursors = supportsRefCursors;
 			return this;
 		}
 
 		public Builder setSupportsNamedParameters(boolean supportsNamedParameters) {
 			this.supportsNamedParameters = supportsNamedParameters;
 			return this;
 		}
 
 		public Builder setSupportsScrollableResults(boolean supportsScrollableResults) {
 			this.supportsScrollableResults = supportsScrollableResults;
 			return this;
 		}
 
 		public Builder setSupportsGetGeneratedKeys(boolean supportsGetGeneratedKeys) {
 			this.supportsGetGeneratedKeys = supportsGetGeneratedKeys;
 			return this;
 		}
 
 		public Builder setSupportsBatchUpdates(boolean supportsBatchUpdates) {
 			this.supportsBatchUpdates = supportsBatchUpdates;
 			return this;
 		}
 
 		public Builder setSupportsDataDefinitionInTransaction(boolean supportsDataDefinitionInTransaction) {
 			this.supportsDataDefinitionInTransaction = supportsDataDefinitionInTransaction;
 			return this;
 		}
 
 		public Builder setDoesDataDefinitionCauseTransactionCommit(boolean doesDataDefinitionCauseTransactionCommit) {
 			this.doesDataDefinitionCauseTransactionCommit = doesDataDefinitionCauseTransactionCommit;
 			return this;
 		}
 
 		public Builder setSqlStateType(SQLStateType sqlStateType) {
 			this.sqlStateType = sqlStateType;
 			return this;
 		}
 
 		public Builder setLobLocatorUpdateCopy(boolean lobLocatorUpdateCopy) {
 			this.lobLocatorUpdateCopy = lobLocatorUpdateCopy;
 			return this;
 		}
 
 		public ExtractedDatabaseMetaDataImpl build() {
 			return new ExtractedDatabaseMetaDataImpl(
 					jdbcEnvironment,
 					connectionCatalogName,
 					connectionSchemaName,
 					extraKeywords,
 					typeInfoSet,
 					supportsRefCursors,
 					supportsNamedParameters,
 					supportsScrollableResults,
 					supportsGetGeneratedKeys,
 					supportsBatchUpdates,
 					supportsDataDefinitionInTransaction,
 					doesDataDefinitionCauseTransactionCommit,
 					sqlStateType,
 					lobLocatorUpdateCopy
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/ResultSetReturnImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/ResultSetReturnImpl.java
index 92403f6ee3..6ba702885c 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/ResultSetReturnImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/ResultSetReturnImpl.java
@@ -1,249 +1,249 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.ResultSetReturn;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 
 /**
  * Standard implementation of the ResultSetReturn contract
  *
  * @author Brett Meyer
  */
 public class ResultSetReturnImpl implements ResultSetReturn {
 	private final JdbcCoordinator jdbcCoordinator;
 
 	private final Dialect dialect;
 	private final SqlStatementLogger sqlStatementLogger;
 	private final SqlExceptionHelper sqlExceptionHelper;
-	
+
 	private boolean isJdbc4 = true;
 
 	/**
 	 * Constructs a ResultSetReturnImpl
 	 *
 	 * @param jdbcCoordinator The JdbcCoordinator
 	 */
 	public ResultSetReturnImpl(JdbcCoordinator jdbcCoordinator) {
 		this.jdbcCoordinator = jdbcCoordinator;
 
 		final JdbcServices jdbcServices = jdbcCoordinator.getJdbcSessionOwner()
 				.getJdbcSessionContext()
 				.getServiceRegistry()
 				.getService( JdbcServices.class );
 
 		this.dialect = jdbcServices.getDialect();
 
 		this.sqlStatementLogger = jdbcServices.getSqlStatementLogger();
 		this.sqlExceptionHelper = jdbcServices.getSqlExceptionHelper();
 	}
 
 	@Override
 	public ResultSet extract(PreparedStatement statement) {
 		// IMPL NOTE : SQL logged by caller
-		if (isTypeOf(statement, CallableStatement.class)) {
+		if ( isTypeOf( statement, CallableStatement.class ) ) {
 			// We actually need to extract from Callable statement.  Although
 			// this seems needless, Oracle can return an
 			// OracleCallableStatementWrapper that finds its way to this method,
 			// rather than extract(CallableStatement).  See HHH-8022.
 			final CallableStatement callableStatement = (CallableStatement) statement;
 			return extract( callableStatement );
 		}
 		try {
 			final ResultSet rs;
 			try {
 				jdbcExecuteStatementStart();
 				rs = statement.executeQuery();
 			}
 			finally {
 				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, statement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not extract ResultSet" );
 		}
 	}
 
 	private void jdbcExecuteStatementEnd() {
 		jdbcCoordinator.getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcExecuteStatementEnd();
 	}
 
 	private void jdbcExecuteStatementStart() {
 		jdbcCoordinator.getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcExecuteStatementStart();
 	}
 
 	private boolean isTypeOf(final Statement statement, final Class<? extends Statement> type) {
-        if (isJdbc4) {
-            try {
-                // This is "more correct" than #isInstance, but not always supported.
-                return statement.isWrapperFor( type );
-            }
-            catch (SQLException e) {
-                // No operation
-            }
-            catch (Throwable e) {
-                // No operation. Note that this catches more than just SQLException to
-                // cover edge cases where a driver might throw an UnsupportedOperationException, AbstractMethodError,
-                // etc.  If so, skip permanently.
-                isJdbc4 = false;
-            }
-        }
-        return type.isInstance( statement );
-    }
+		if ( isJdbc4 ) {
+			try {
+				// This is "more correct" than #isInstance, but not always supported.
+				return statement.isWrapperFor( type );
+			}
+			catch (SQLException e) {
+				// No operation
+			}
+			catch (Throwable e) {
+				// No operation. Note that this catches more than just SQLException to
+				// cover edge cases where a driver might throw an UnsupportedOperationException, AbstractMethodError,
+				// etc.  If so, skip permanently.
+				isJdbc4 = false;
+			}
+		}
+		return type.isInstance( statement );
+	}
 
 	@Override
 	public ResultSet extract(CallableStatement callableStatement) {
 		// IMPL NOTE : SQL logged by caller
 		try {
 			final ResultSet rs;
 			try {
 				jdbcExecuteStatementStart();
 				rs = dialect.getResultSet( callableStatement );
 			}
 			finally {
 				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, callableStatement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not extract ResultSet" );
 		}
 	}
 
 	@Override
 	public ResultSet extract(Statement statement, String sql) {
 		sqlStatementLogger.logStatement( sql );
 		try {
 			final ResultSet rs;
 			try {
 				jdbcExecuteStatementStart();
 				rs = statement.executeQuery( sql );
 			}
 			finally {
 				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, statement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not extract ResultSet" );
 		}
 	}
 
 	@Override
 	public ResultSet execute(PreparedStatement statement) {
 		// sql logged by StatementPreparerImpl
 		try {
 			final ResultSet rs;
 			try {
 				jdbcExecuteStatementStart();
 				if ( !statement.execute() ) {
 					while ( !statement.getMoreResults() && statement.getUpdateCount() != -1 ) {
 						// do nothing until we hit the resultset
 					}
 				}
 				rs = statement.getResultSet();
 			}
 			finally {
 				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, statement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not execute statement" );
 		}
 	}
 
 	@Override
 	public ResultSet execute(Statement statement, String sql) {
 		sqlStatementLogger.logStatement( sql );
 		try {
 			final ResultSet rs;
 			try {
 				jdbcExecuteStatementStart();
 				if ( !statement.execute( sql ) ) {
 					while ( !statement.getMoreResults() && statement.getUpdateCount() != -1 ) {
 						// do nothing until we hit the resultset
 					}
 				}
 				rs = statement.getResultSet();
 			}
 			finally {
 				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, statement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not execute statement" );
 		}
 	}
-	
+
 	@Override
 	public int executeUpdate(PreparedStatement statement) {
 		try {
 			jdbcExecuteStatementStart();
 			return statement.executeUpdate();
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not execute statement" );
 		}
 		finally {
 			jdbcExecuteStatementEnd();
 		}
 	}
-	
+
 	@Override
 	public int executeUpdate(Statement statement, String sql) {
 		sqlStatementLogger.logStatement( sql );
 		try {
 			jdbcExecuteStatementStart();
 			return statement.executeUpdate( sql );
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not execute statement" );
 		}
 		finally {
 			jdbcExecuteStatementEnd();
 		}
 	}
 
 	private void postExtract(ResultSet rs, Statement st) {
 		if ( rs != null ) {
 			jdbcCoordinator.getResourceRegistry().register( rs, st );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlExceptionHelper.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlExceptionHelper.java
index 8a27415b48..c4eba020f4 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlExceptionHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlExceptionHelper.java
@@ -1,335 +1,337 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.spi;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
 import java.sql.Statement;
 
 import org.hibernate.JDBCException;
 import org.hibernate.exception.internal.SQLStateConverter;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 
 import org.jboss.logging.Logger;
 import org.jboss.logging.Logger.Level;
 
 /**
  * Helper for handling SQLExceptions in various manners.
  *
  * @author Steve Ebersole
  */
 public class SqlExceptionHelper {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			SqlExceptionHelper.class.getName()
 	);
 
 	private static final String DEFAULT_EXCEPTION_MSG = "SQL Exception";
 	private static final String DEFAULT_WARNING_MSG = "SQL Warning";
 
 	private static final SQLExceptionConverter DEFAULT_CONVERTER = new SQLStateConverter(
 			new ViolatedConstraintNameExtracter() {
 				public String extractConstraintName(SQLException e) {
 					return null;
 				}
 			}
 	);
 
 	private SQLExceptionConverter sqlExceptionConverter;
 
 	/**
 	 * Create an exception helper with a default exception converter.
 	 */
 	public SqlExceptionHelper() {
 		sqlExceptionConverter = DEFAULT_CONVERTER;
 	}
 
 	/**
 	 * Create an exception helper with a specific exception converter.
 	 *
 	 * @param sqlExceptionConverter The exception converter to use.
 	 */
 	public SqlExceptionHelper(SQLExceptionConverter sqlExceptionConverter) {
 		this.sqlExceptionConverter = sqlExceptionConverter;
 	}
 
 	/**
 	 * Access the current exception converter being used internally.
 	 *
 	 * @return The current exception converter.
 	 */
 	public SQLExceptionConverter getSqlExceptionConverter() {
 		return sqlExceptionConverter;
 	}
 
 	/**
 	 * Inject the exception converter to use.
 	 * <p/>
 	 * NOTE : <tt>null</tt> is allowed and signifies to use the default.
 	 *
 	 * @param sqlExceptionConverter The converter to use.
 	 */
 	public void setSqlExceptionConverter(SQLExceptionConverter sqlExceptionConverter) {
-		this.sqlExceptionConverter = (sqlExceptionConverter == null ? DEFAULT_CONVERTER : sqlExceptionConverter);
+		this.sqlExceptionConverter = ( sqlExceptionConverter == null ? DEFAULT_CONVERTER : sqlExceptionConverter );
 	}
 
 	// SQLException ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Convert an SQLException using the current converter, doing some logging first.
 	 *
 	 * @param sqlException The exception to convert
 	 * @param message An error message.
 	 *
 	 * @return The converted exception
 	 */
 	public JDBCException convert(SQLException sqlException, String message) {
 		return convert( sqlException, message, "n/a" );
 	}
 
 	/**
 	 * Convert an SQLException using the current converter, doing some logging first.
 	 *
 	 * @param sqlException The exception to convert
 	 * @param message An error message.
 	 * @param sql The SQL being executed when the exception occurred
 	 *
 	 * @return The converted exception
 	 */
 	public JDBCException convert(SQLException sqlException, String message, String sql) {
 		logExceptions( sqlException, message + " [" + sql + "]" );
 		return sqlExceptionConverter.convert( sqlException, message, sql );
 	}
 
 	/**
 	 * Log the given (and any nested) exception.
 	 *
 	 * @param sqlException The exception to log
 	 * @param message The message text to use as a preamble.
 	 */
 	public void logExceptions(SQLException sqlException, String message) {
 		if ( LOG.isEnabled( Level.ERROR ) ) {
 			if ( LOG.isDebugEnabled() ) {
 				message = StringHelper.isNotEmpty( message ) ? message : DEFAULT_EXCEPTION_MSG;
 				LOG.debug( message, sqlException );
 			}
 			final boolean warnEnabled = LOG.isEnabled( Level.WARN );
 			while ( sqlException != null ) {
 				if ( warnEnabled ) {
 					LOG.warn( "SQL Error: " + sqlException.getErrorCode() + ", SQLState: " + sqlException.getSQLState() );
 				}
 				LOG.error( sqlException.getMessage() );
 				sqlException = sqlException.getNextException();
 			}
 		}
 	}
 
 	// SQLWarning ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Contract for handling {@link SQLWarning warnings}
 	 */
-	public static interface WarningHandler {
+	public interface WarningHandler {
 		/**
 		 * Should processing be done? Allows short-circuiting if not.
 		 *
 		 * @return True to process warnings, false otherwise.
 		 */
-		public boolean doProcess();
+		boolean doProcess();
 
 		/**
 		 * Prepare for processing of a {@link SQLWarning warning} stack.
 		 * <p/>
 		 * Note that the warning here is also the first passed to {@link #handleWarning}
 		 *
 		 * @param warning The first warning in the stack.
 		 */
-		public void prepare(SQLWarning warning);
+		void prepare(SQLWarning warning);
 
 		/**
 		 * Handle an individual warning in the stack.
 		 *
 		 * @param warning The warning to handle.
 		 */
-		public void handleWarning(SQLWarning warning);
+		void handleWarning(SQLWarning warning);
 	}
 
 	/**
 	 * Basic support for {@link WarningHandler} implementations which handle {@link SQLWarning warnings}
 	 */
 	public abstract static class WarningHandlerLoggingSupport implements WarningHandler {
 		@Override
 		public final void handleWarning(SQLWarning warning) {
 			logWarning(
 					"SQL Warning Code: " + warning.getErrorCode() + ", SQLState: " + warning.getSQLState(),
 					warning.getMessage()
 			);
 		}
 
 		/**
 		 * Delegate to log common details of a {@link SQLWarning warning}
 		 *
 		 * @param description A description of the warning
 		 * @param message The warning message
 		 */
 		protected abstract void logWarning(String description, String message);
 	}
 
 	/**
 	 * Standard SQLWarning handler for logging warnings
 	 */
 	public static class StandardWarningHandler extends WarningHandlerLoggingSupport {
 		private final String introMessage;
 
 		/**
 		 * Creates a StandardWarningHandler
 		 *
 		 * @param introMessage The introduction message for the hierarchy
 		 */
 		public StandardWarningHandler(String introMessage) {
 			this.introMessage = introMessage;
 		}
 
 		@Override
 		public boolean doProcess() {
 			return LOG.isEnabled( Level.WARN );
 		}
 
 		@Override
 		public void prepare(SQLWarning warning) {
 			LOG.debug( introMessage, warning );
 		}
 
 		@Override
 		protected void logWarning(
 				String description,
 				String message) {
 			LOG.warn( description );
 			LOG.warn( message );
 		}
 	}
 
 	/**
 	 * Static access to the standard handler for logging warnings
 	 */
-	public static final StandardWarningHandler STANDARD_WARNING_HANDLER = new StandardWarningHandler( DEFAULT_WARNING_MSG );
+	public static final StandardWarningHandler STANDARD_WARNING_HANDLER = new StandardWarningHandler(
+			DEFAULT_WARNING_MSG
+	);
 
 	/**
 	 * Generic algorithm to walk the hierarchy of SQLWarnings
 	 *
 	 * @param warning The warning to walk
 	 * @param handler The handler
 	 */
 	public void walkWarnings(
 			SQLWarning warning,
 			WarningHandler handler) {
 		if ( warning == null || !handler.doProcess() ) {
 			return;
 		}
 		handler.prepare( warning );
 		while ( warning != null ) {
 			handler.handleWarning( warning );
 			warning = warning.getNextWarning();
 		}
 	}
 
 	/**
 	 * Standard (legacy) behavior for logging warnings associated with a JDBC {@link Connection} and clearing them.
 	 * <p/>
 	 * Calls {@link #handleAndClearWarnings(Connection, WarningHandler)} using {@link #STANDARD_WARNING_HANDLER}
 	 *
 	 * @param connection The JDBC connection potentially containing warnings
 	 */
 	public void logAndClearWarnings(Connection connection) {
 		handleAndClearWarnings( connection, STANDARD_WARNING_HANDLER );
 	}
-	
+
 	public void logAndClearWarnings(Statement statement) {
 		handleAndClearWarnings( statement, STANDARD_WARNING_HANDLER );
 	}
 
 	/**
 	 * General purpose handling of warnings associated with a JDBC {@link Connection}.
 	 *
 	 * @param connection The JDBC connection potentially containing warnings
 	 * @param handler The handler for each individual warning in the stack.
 	 *
 	 * @see #walkWarnings
 	 */
 	@SuppressWarnings({"ThrowableResultOfMethodCallIgnored"})
 	public void handleAndClearWarnings(
 			Connection connection,
 			WarningHandler handler) {
 		try {
 			walkWarnings( connection.getWarnings(), handler );
 		}
 		catch (SQLException sqle) {
 			// workaround for WebLogic
 			LOG.debug( "could not log warnings", sqle );
 		}
 		try {
 			// Sybase fail if we don't do that, sigh...
 			connection.clearWarnings();
 		}
 		catch (SQLException sqle) {
 			LOG.debug( "could not clear warnings", sqle );
 		}
 	}
 
 	/**
 	 * General purpose handling of warnings associated with a JDBC {@link Statement}.
 	 *
 	 * @param statement The JDBC statement potentially containing warnings
 	 * @param handler The handler for each individual warning in the stack.
 	 *
 	 * @see #walkWarnings
 	 */
 	@SuppressWarnings({"ThrowableResultOfMethodCallIgnored"})
 	public void handleAndClearWarnings(
 			Statement statement,
 			WarningHandler handler) {
 		// See HHH-9174.  Statement#getWarnings can be an expensive call for many JDBC libs.  Don't do it unless
-    	// the log level would actually allow a warning to be logged.
-    	if (LOG.isEnabled(Level.WARN)) {
-    		try {
+		// the log level would actually allow a warning to be logged.
+		if ( LOG.isEnabled( Level.WARN ) ) {
+			try {
 				walkWarnings( statement.getWarnings(), handler );
 			}
 			catch (SQLException sqlException) {
 				// workaround for WebLogic
 				LOG.debug( "could not log warnings", sqlException );
 			}
-    	}
+		}
 		try {
 			// Sybase fail if we don't do that, sigh...
 			statement.clearWarnings();
 		}
 		catch (SQLException sqle) {
 			LOG.debug( "could not clear warnings", sqle );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/query/spi/EntityGraphQueryHint.java b/hibernate-core/src/main/java/org/hibernate/engine/query/spi/EntityGraphQueryHint.java
index 4356100302..7f703c3b10 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/query/spi/EntityGraphQueryHint.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/query/spi/EntityGraphQueryHint.java
@@ -1,170 +1,171 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.engine.query.spi;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import javax.persistence.AttributeNode;
 import javax.persistence.EntityGraph;
 import javax.persistence.Subgraph;
 
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.internal.ast.HqlSqlWalker;
 import org.hibernate.hql.internal.ast.tree.FromClause;
 import org.hibernate.hql.internal.ast.tree.FromElement;
 import org.hibernate.hql.internal.ast.tree.FromElementFactory;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Encapsulates a JPA EntityGraph provided through a JPQL query hint.  Converts the fetches into a list of AST
  * FromElements.  The logic is kept here as much as possible in order to make it easy to remove this in the future,
  * once our AST is improved and this "hack" is no longer needed.
  *
  * @author Brett Meyer
  */
 public class EntityGraphQueryHint {
 	private final EntityGraph<?> originEntityGraph;
 
 	public EntityGraphQueryHint(EntityGraph<?> originEntityGraph) {
 		this.originEntityGraph = originEntityGraph;
 	}
 
 	public List<FromElement> toFromElements(FromClause fromClause, HqlSqlWalker walker) {
 		// If a role already has an explicit fetch in the query, skip it in the graph.
 		Map<String, FromElement> explicitFetches = new HashMap<String, FromElement>();
 		for ( Object o : fromClause.getFromElements() ) {
 			final FromElement fromElement = (FromElement) o;
 			if ( fromElement.getRole() != null ) {
 				explicitFetches.put( fromElement.getRole(), fromElement );
 			}
 		}
 
 		return getFromElements(
 				originEntityGraph.getAttributeNodes(),
 				fromClause.getFromElement(),
 				fromClause,
 				walker,
 				explicitFetches
 		);
 	}
 
 	private List<FromElement> getFromElements(
 			List attributeNodes,
 			FromElement origin,
 			FromClause fromClause,
 			HqlSqlWalker walker,
 			Map<String, FromElement> explicitFetches) {
 		final List<FromElement> fromElements = new ArrayList<FromElement>();
 
 		for ( Object obj : attributeNodes ) {
 			final AttributeNode<?> attributeNode = (AttributeNode<?>) obj;
 
 			final String attributeName = attributeNode.getAttributeName();
 			final String className = origin.getClassName();
 			// TODO: This is ignored by collection types and probably wrong for entity types.  Presumably it screws
 			// with inheritance.
 			final String role = className + "." + attributeName;
 			final String classAlias = origin.getClassAlias();
 			final String originTableAlias = origin.getTableAlias();
 			final Type propertyType = origin.getPropertyType( attributeName, attributeName );
 
 			try {
 				FromElement fromElement = explicitFetches.get( role );
 				boolean explicitFromElement = false;
 				if ( fromElement == null ) {
 					if ( propertyType.isEntityType() ) {
 						final EntityType entityType = (EntityType) propertyType;
 
 						final String[] columns = origin.toColumns( originTableAlias, attributeName, false );
 						final String tableAlias = walker.getAliasGenerator().createName(
 								entityType.getAssociatedEntityName()
 						);
 
 						final FromElementFactory fromElementFactory = new FromElementFactory(
 								fromClause, origin,
 								attributeName, classAlias, columns, false
 						);
 						final JoinSequence joinSequence = walker.getSessionFactoryHelper().createJoinSequence(
 								false, entityType, tableAlias, JoinType.LEFT_OUTER_JOIN, columns
 						);
 						fromElement = fromElementFactory.createEntityJoin(
 								entityType.getAssociatedEntityName(),
 								tableAlias,
 								joinSequence,
 								true,
 								walker.isInFrom(),
 								entityType,
 								role,
 								null
 						);
 					}
 					else if ( propertyType.isCollectionType() ) {
 						CollectionType collectionType = (CollectionType) propertyType;
 						final String[] columns = origin.toColumns( originTableAlias, attributeName, false );
 
 						final FromElementFactory fromElementFactory = new FromElementFactory(
 								fromClause, origin,
 								attributeName, classAlias, columns, false
 						);
 						final QueryableCollection queryableCollection = walker.getSessionFactoryHelper()
 								.requireQueryableCollection( collectionType.getRole() );
 						fromElement = fromElementFactory.createCollection(
 								queryableCollection, collectionType.getRole(), JoinType.LEFT_OUTER_JOIN, true, false
 						);
 					}
-				} else {
+				}
+				else {
 					explicitFromElement = true;
 					fromElement.setInProjectionList( true );
 					fromElement.setFetch( true );
 				}
 
 				if ( fromElement != null ) {
 					if( !explicitFromElement ){
 						fromElements.add( fromElement );
 					}
 
 					// recurse into subgraphs
 					for ( Subgraph<?> subgraph : attributeNode.getSubgraphs().values() ) {
 						fromElements.addAll(
 								getFromElements(
 										subgraph.getAttributeNodes(), fromElement,
 										fromClause, walker, explicitFetches
 								)
 						);
 					}
 				}
 			}
 			catch (Exception e) {
 				throw new QueryException( "Could not apply the EntityGraph to the Query!", e );
 			}
 		}
 
 		return fromElements;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/query/spi/QueryPlanCache.java b/hibernate-core/src/main/java/org/hibernate/engine/query/spi/QueryPlanCache.java
index 5f7eebf196..21dfb40ffe 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/query/spi/QueryPlanCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/query/spi/QueryPlanCache.java
@@ -1,403 +1,404 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.query.spi;
 
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.Filter;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterImpl;
 import org.hibernate.internal.util.collections.BoundedConcurrentHashMap;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 
 /**
  * Acts as a cache for compiled query plans, as well as query-parameter metadata.
  *
  * @see Environment#QUERY_PLAN_CACHE_PARAMETER_METADATA_MAX_SIZE
  * @see Environment#QUERY_PLAN_CACHE_MAX_SIZE
  *
  * @author Steve Ebersole
  */
 public class QueryPlanCache implements Serializable {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( QueryPlanCache.class );
 
 	/**
 	 * The default strong reference count.
 	 */
 	public static final int DEFAULT_PARAMETER_METADATA_MAX_COUNT = 128;
 	/**
 	 * The default soft reference count.
 	 */
 	public static final int DEFAULT_QUERY_PLAN_MAX_COUNT = 2048;
 
 	private final SessionFactoryImplementor factory;
 
 	/**
 	 * the cache of the actual plans...
 	 */
 	private final BoundedConcurrentHashMap queryPlanCache;
 
 	/**
 	 * simple cache of param metadata based on query string.  Ideally, the original "user-supplied query"
 	 * string should be used to obtain this metadata (i.e., not the para-list-expanded query string) to avoid
 	 * unnecessary cache entries.
 	 * <p></p>
 	 * Used solely for caching param metadata for native-sql queries, see {@link #getSQLParameterMetadata} for a
 	 * discussion as to why...
 	 */
 	private final BoundedConcurrentHashMap<String,ParameterMetadata> parameterMetadataCache;
 
 
 	private NativeQueryInterpreter nativeQueryInterpreterService;
 
 	/**
 	 * Constructs the QueryPlanCache to be used by the given SessionFactory
 	 *
 	 * @param factory The SessionFactory
 	 */
 	@SuppressWarnings("deprecation")
 	public QueryPlanCache(final SessionFactoryImplementor factory) {
 		this.factory = factory;
 
 		Integer maxParameterMetadataCount = ConfigurationHelper.getInteger(
 				Environment.QUERY_PLAN_CACHE_PARAMETER_METADATA_MAX_SIZE,
 				factory.getProperties()
 		);
 		if ( maxParameterMetadataCount == null ) {
 			maxParameterMetadataCount = ConfigurationHelper.getInt(
 					Environment.QUERY_PLAN_CACHE_MAX_STRONG_REFERENCES,
 					factory.getProperties(),
 					DEFAULT_PARAMETER_METADATA_MAX_COUNT
 			);
 		}
 		Integer maxQueryPlanCount = ConfigurationHelper.getInteger(
 				Environment.QUERY_PLAN_CACHE_MAX_SIZE,
 				factory.getProperties()
 		);
 		if ( maxQueryPlanCount == null ) {
 			maxQueryPlanCount = ConfigurationHelper.getInt(
 					Environment.QUERY_PLAN_CACHE_MAX_SOFT_REFERENCES,
 					factory.getProperties(),
 					DEFAULT_QUERY_PLAN_MAX_COUNT
 			);
 		}
 
 		queryPlanCache = new BoundedConcurrentHashMap( maxQueryPlanCount, 20, BoundedConcurrentHashMap.Eviction.LIRS );
 		parameterMetadataCache = new BoundedConcurrentHashMap<String, ParameterMetadata>(
 				maxParameterMetadataCount,
 				20,
 				BoundedConcurrentHashMap.Eviction.LIRS
 		);
 
 		nativeQueryInterpreterService = factory.getServiceRegistry().getService( NativeQueryInterpreter.class );
 	}
 
 	/**
 	 * Obtain the parameter metadata for given native-sql query.
 	 * <p/>
 	 * for native-sql queries, the param metadata is determined outside any relation to a query plan, because
 	 * query plan creation and/or retrieval for a native-sql query depends on all of the return types having been
 	 * set, which might not be the case up-front when param metadata would be most useful
 	 *
 	 * @param query The query
 	 * @return The parameter metadata
 	 */
 	public ParameterMetadata getSQLParameterMetadata(final String query)  {
 		ParameterMetadata value = parameterMetadataCache.get( query );
 		if ( value == null ) {
 			value = nativeQueryInterpreterService.getParameterMetadata( query );
 			parameterMetadataCache.putIfAbsent( query, value );
 		}
 		return value;
 	}
 
 	/**
 	 * Get the query plan for the given HQL query, creating it and caching it if not already cached
 	 *
 	 * @param queryString The HQL query string
 	 * @param shallow Whether the execution will be shallow
 	 * @param enabledFilters The filters enabled on the Session
 	 *
 	 * @return The query plan
 	 *
 	 * @throws QueryException Indicates a problem translating the query
 	 * @throws MappingException Indicates a problem translating the query
 	 */
 	@SuppressWarnings("unchecked")
 	public HQLQueryPlan getHQLQueryPlan(String queryString, boolean shallow, Map<String,Filter> enabledFilters)
 			throws QueryException, MappingException {
 		final HQLQueryPlanKey key = new HQLQueryPlanKey( queryString, shallow, enabledFilters );
 		HQLQueryPlan value = (HQLQueryPlan) queryPlanCache.get( key );
 		if ( value == null ) {
 			LOG.tracev( "Unable to locate HQL query plan in cache; generating ({0})", queryString );
 			value = new HQLQueryPlan( queryString, shallow, enabledFilters, factory );
 			queryPlanCache.putIfAbsent( key, value );
-		} else {
+		}
+		else {
 			LOG.tracev( "Located HQL query plan in cache ({0})", queryString );
 		}
 		return value;
 	}
 
 	/**
 	 * Get the query plan for the given collection HQL filter fragment, creating it and caching it if not already cached
 	 *
 	 * @param filterString The HQL filter fragment
 	 * @param collectionRole The collection being filtered
 	 * @param shallow Whether the execution will be shallow
 	 * @param enabledFilters The filters enabled on the Session
 	 *
 	 * @return The query plan
 	 *
 	 * @throws QueryException Indicates a problem translating the query
 	 * @throws MappingException Indicates a problem translating the query
 	 */
 	@SuppressWarnings("unchecked")
 	public FilterQueryPlan getFilterQueryPlan(
 			String filterString,
 			String collectionRole,
 			boolean shallow,
 			Map<String,Filter> enabledFilters) throws QueryException, MappingException {
 		final FilterQueryPlanKey key =  new FilterQueryPlanKey( filterString, collectionRole, shallow, enabledFilters );
 		FilterQueryPlan value = (FilterQueryPlan) queryPlanCache.get( key );
 		if ( value == null ) {
 			LOG.tracev(
 					"Unable to locate collection-filter query plan in cache; generating ({0} : {1} )",
 					collectionRole,
 					filterString
 			);
 			value = new FilterQueryPlan( filterString, collectionRole, shallow, enabledFilters,factory );
 			queryPlanCache.putIfAbsent( key, value );
 		}
 		else {
 			LOG.tracev( "Located collection-filter query plan in cache ({0} : {1})", collectionRole, filterString );
 		}
 		return value;
 	}
 
 	/**
 	 * Get the query plan for a native SQL query, creating it and caching it if not already cached
 	 *
 	 * @param spec The native SQL query specification
 	 *
 	 * @return The query plan
 	 *
 	 * @throws QueryException Indicates a problem translating the query
 	 * @throws MappingException Indicates a problem translating the query
 	 */
 	@SuppressWarnings("unchecked")
 	public NativeSQLQueryPlan getNativeSQLQueryPlan(final NativeSQLQuerySpecification spec) {
 		NativeSQLQueryPlan value = (NativeSQLQueryPlan) queryPlanCache.get( spec );
 		if ( value == null ) {
 			LOG.tracev( "Unable to locate native-sql query plan in cache; generating ({0})", spec.getQueryString() );
 			value = nativeQueryInterpreterService.createQueryPlan( spec, factory );
 			queryPlanCache.putIfAbsent( spec, value );
 		}
 		else {
 			LOG.tracev( "Located native-sql query plan in cache ({0})", spec.getQueryString() );
 		}
 		return value;
 	}
 
 	/**
 	 * clean up QueryPlanCache when SessionFactory is closed
 	 */
 	public void cleanup() {
 		LOG.trace( "Cleaning QueryPlan Cache" );
 		queryPlanCache.clear();
 		parameterMetadataCache.clear();
 	}
 
 	private static class HQLQueryPlanKey implements Serializable {
 		private final String query;
 		private final boolean shallow;
 		private final Set<DynamicFilterKey> filterKeys;
 		private final int hashCode;
 
 		public HQLQueryPlanKey(String query, boolean shallow, Map enabledFilters) {
 			this.query = query;
 			this.shallow = shallow;
 			if ( CollectionHelper.isEmpty( enabledFilters ) ) {
 				filterKeys = Collections.emptySet();
 			}
 			else {
 				final Set<DynamicFilterKey> tmp = new HashSet<DynamicFilterKey>(
 						CollectionHelper.determineProperSizing( enabledFilters ),
 						CollectionHelper.LOAD_FACTOR
 				);
 				for ( Object o : enabledFilters.values() ) {
 					tmp.add( new DynamicFilterKey( (FilterImpl) o ) );
 				}
 				this.filterKeys = Collections.unmodifiableSet( tmp );
 			}
 
 			int hash = query.hashCode();
 			hash = 29 * hash + ( shallow ? 1 : 0 );
 			hash = 29 * hash + filterKeys.hashCode();
 			this.hashCode = hash;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			final HQLQueryPlanKey that = (HQLQueryPlanKey) o;
 
 			return shallow == that.shallow
 					&& filterKeys.equals( that.filterKeys )
 					&& query.equals( that.query );
 
 		}
 
 		@Override
 		public int hashCode() {
 			return hashCode;
 		}
 	}
 
 	private static class DynamicFilterKey implements Serializable {
 		private final String filterName;
 		private final Map<String,Integer> parameterMetadata;
 		private final int hashCode;
 
 		private DynamicFilterKey(FilterImpl filter) {
 			this.filterName = filter.getName();
 			if ( filter.getParameters().isEmpty() ) {
 				parameterMetadata = Collections.emptyMap();
 			}
 			else {
 				parameterMetadata = new HashMap<String,Integer>(
 						CollectionHelper.determineProperSizing( filter.getParameters() ),
 						CollectionHelper.LOAD_FACTOR
 				);
 				for ( Object o : filter.getParameters().entrySet() ) {
 					final Map.Entry entry = (Map.Entry) o;
 					final String key = (String) entry.getKey();
 					final Integer valueCount;
 					if ( Collection.class.isInstance( entry.getValue() ) ) {
 						valueCount = ( (Collection) entry.getValue() ).size();
 					}
 					else {
 						valueCount = 1;
 					}
 					parameterMetadata.put( key, valueCount );
 				}
 			}
 
 			int hash = filterName.hashCode();
 			hash = 31 * hash + parameterMetadata.hashCode();
 			this.hashCode = hash;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			final DynamicFilterKey that = (DynamicFilterKey) o;
 			return filterName.equals( that.filterName )
 					&& parameterMetadata.equals( that.parameterMetadata );
 
 		}
 
 		@Override
 		public int hashCode() {
 			return hashCode;
 		}
 	}
 
 	private static class FilterQueryPlanKey implements Serializable {
 		private final String query;
 		private final String collectionRole;
 		private final boolean shallow;
 		private final Set<String> filterNames;
 		private final int hashCode;
 
 		@SuppressWarnings({ "unchecked" })
 		public FilterQueryPlanKey(String query, String collectionRole, boolean shallow, Map enabledFilters) {
 			this.query = query;
 			this.collectionRole = collectionRole;
 			this.shallow = shallow;
 
 			if ( CollectionHelper.isEmpty( enabledFilters ) ) {
 				this.filterNames = Collections.emptySet();
 			}
 			else {
 				final Set<String> tmp = new HashSet<String>();
 				tmp.addAll( enabledFilters.keySet() );
 				this.filterNames = Collections.unmodifiableSet( tmp );
 
 			}
 
 			int hash = query.hashCode();
 			hash = 29 * hash + collectionRole.hashCode();
 			hash = 29 * hash + ( shallow ? 1 : 0 );
 			hash = 29 * hash + filterNames.hashCode();
 			this.hashCode = hash;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			final FilterQueryPlanKey that = (FilterQueryPlanKey) o;
 			return shallow == that.shallow
 					&& filterNames.equals( that.filterNames )
 					&& query.equals( that.query )
 					&& collectionRole.equals( that.collectionRole );
 
 		}
 
 		@Override
 		public int hashCode() {
 			return hashCode;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/ActionQueue.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/ActionQueue.java
index a3793f3087..ebb6092caa 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/ActionQueue.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/ActionQueue.java
@@ -1,913 +1,914 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
-import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
 import java.util.Queue;
 import java.util.Set;
 import java.util.concurrent.ConcurrentLinkedQueue;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.PropertyValueException;
 import org.hibernate.action.internal.AbstractEntityInsertAction;
 import org.hibernate.action.internal.BulkOperationCleanupAction;
 import org.hibernate.action.internal.CollectionRecreateAction;
 import org.hibernate.action.internal.CollectionRemoveAction;
 import org.hibernate.action.internal.CollectionUpdateAction;
 import org.hibernate.action.internal.EntityDeleteAction;
 import org.hibernate.action.internal.EntityIdentityInsertAction;
 import org.hibernate.action.internal.EntityInsertAction;
 import org.hibernate.action.internal.EntityUpdateAction;
 import org.hibernate.action.internal.OrphanRemovalAction;
 import org.hibernate.action.internal.QueuedOperationCollectionAction;
 import org.hibernate.action.internal.UnresolvedEntityInsertActions;
 import org.hibernate.action.spi.AfterTransactionCompletionProcess;
 import org.hibernate.action.spi.BeforeTransactionCompletionProcess;
 import org.hibernate.action.spi.Executable;
 import org.hibernate.cache.CacheException;
 import org.hibernate.engine.internal.NonNullableTransientDependencies;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.type.Type;
 
 /**
  * Responsible for maintaining the queue of actions related to events.
  *
  * The ActionQueue holds the DML operations queued as part of a session's transactional-write-behind semantics. The
  * DML operations are queued here until a flush forces them to be executed against the database.
  * 
  * @author Steve Ebersole
  * @author Gail Badner
  * @author Anton Marsden
  */
 public class ActionQueue {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( ActionQueue.class );
 
 	private SessionImplementor session;
 
 	private UnresolvedEntityInsertActions unresolvedInsertions;
 
 	// Object insertions, updates, and deletions have list semantics because
 	// they must happen in the right order so as to respect referential
 	// integrity
 	private final ExecutableList<AbstractEntityInsertAction> insertions;
 	private final ExecutableList<EntityDeleteAction> deletions;
 	private final ExecutableList<EntityUpdateAction> updates;
 
 	// Actually the semantics of the next three are really "Bag"
 	// Note that, unlike objects, collection insertions, updates,
 	// deletions are not really remembered between flushes. We
 	// just re-use the same Lists for convenience.
 	private final ExecutableList<CollectionRecreateAction> collectionCreations;
 	private final ExecutableList<CollectionUpdateAction> collectionUpdates;
 	private final ExecutableList<QueuedOperationCollectionAction> collectionQueuedOps;
 	private final ExecutableList<CollectionRemoveAction> collectionRemovals;
 	
 	// TODO: The removeOrphan concept is a temporary "hack" for HHH-6484.  This should be removed once action/task
 	// ordering is improved.
 	private final ExecutableList<OrphanRemovalAction> orphanRemovals;
 
 	// an immutable array holding all 7 ExecutionLists in execution order
 	private final List<ExecutableList<?>> executableLists;
 
 	private transient boolean isTransactionCoordinatorShared;
 	private AfterTransactionCompletionProcessQueue afterTransactionProcesses;
 	private BeforeTransactionCompletionProcessQueue beforeTransactionProcesses;
 
 	/**
 	 * Constructs an action queue bound to the given session.
 	 * 
 	 * @param session The session "owning" this queue.
 	 */
 	public ActionQueue(SessionImplementor session) {
 		this.session = session;
 
 		unresolvedInsertions = new UnresolvedEntityInsertActions();
 
 		insertions = new ExecutableList<AbstractEntityInsertAction>( new InsertActionSorter() );
 		deletions = new ExecutableList<EntityDeleteAction>();
 		updates = new ExecutableList<EntityUpdateAction>();
 
 		collectionCreations = new ExecutableList<CollectionRecreateAction>();
 		collectionRemovals = new ExecutableList<CollectionRemoveAction>();
 		collectionUpdates = new ExecutableList<CollectionUpdateAction>();
 		collectionQueuedOps = new ExecutableList<QueuedOperationCollectionAction>();
 		
 		orphanRemovals = new ExecutableList<OrphanRemovalAction>();
 
 		// Important: these lists are in execution order
 		List<ExecutableList<?>> tmp = Arrays.<ExecutableList<?>>asList(
 				orphanRemovals,
 				insertions,
 				updates,
 				// do before actions are handled in the other collection queues
 				collectionQueuedOps,
 				collectionRemovals,
 				collectionUpdates,
 				collectionCreations,
 				deletions
 		);
 
 		executableLists = Collections.unmodifiableList( tmp );
 
 		isTransactionCoordinatorShared = false;
 		afterTransactionProcesses = new AfterTransactionCompletionProcessQueue( session );
 		beforeTransactionProcesses = new BeforeTransactionCompletionProcessQueue( session );
 
 	}
 
 	public void clear() {
 		for ( ExecutableList<?> l : executableLists ) {
 			l.clear();
 		}
 		unresolvedInsertions.clear();
 	}
 
 	/**
 	 * Adds an entity insert action
 	 *
 	 * @param action The action representing the entity insertion
 	 */
 	public void addAction(EntityInsertAction action) {
 		LOG.tracev( "Adding an EntityInsertAction for [{0}] object", action.getEntityName() );
 		addInsertAction( action );
 	}
 
 	private void addInsertAction(AbstractEntityInsertAction insert) {
 		if ( insert.isEarlyInsert() ) {
 			// For early inserts, must execute inserts before finding non-nullable transient entities.
 			// TODO: find out why this is necessary
 			LOG.tracev( "Executing inserts before finding non-nullable transient entities for early insert: [{0}]", insert );
 			executeInserts();
 		}
 		NonNullableTransientDependencies nonNullableTransientDependencies = insert.findNonNullableTransientEntities();
 		if ( nonNullableTransientDependencies == null ) {
 			LOG.tracev( "Adding insert with no non-nullable, transient entities: [{0}]", insert );
 			addResolvedEntityInsertAction( insert );
 		}
 		else {
 			if ( LOG.isTraceEnabled() ) {
 				LOG.tracev( "Adding insert with non-nullable, transient entities; insert=[{0}], dependencies=[{1}]", insert,
 							nonNullableTransientDependencies.toLoggableString( insert.getSession() ) );
 			}
 			unresolvedInsertions.addUnresolvedEntityInsertAction( insert, nonNullableTransientDependencies );
 		}
 	}
 
 	private void addResolvedEntityInsertAction(AbstractEntityInsertAction insert) {
 		if ( insert.isEarlyInsert() ) {
 			LOG.trace( "Executing insertions before resolved early-insert" );
 			executeInserts();
 			LOG.debug( "Executing identity-insert immediately" );
 			execute( insert );
 		}
 		else {
 			LOG.trace( "Adding resolved non-early insert action." );
 			insertions.add( insert );
 		}
 		insert.makeEntityManaged();
 		for ( AbstractEntityInsertAction resolvedAction : unresolvedInsertions.resolveDependentActions( insert.getInstance(), session ) ) {
 			addResolvedEntityInsertAction( resolvedAction );
 		}
 	}
 
 	/**
 	 * Adds an entity (IDENTITY) insert action
 	 *
 	 * @param action The action representing the entity insertion
 	 */
 	public void addAction(EntityIdentityInsertAction action) {
 		LOG.tracev( "Adding an EntityIdentityInsertAction for [{0}] object", action.getEntityName() );
 		addInsertAction( action );
 	}
 
 	/**
 	 * Adds an entity delete action
 	 *
 	 * @param action The action representing the entity deletion
 	 */
 	public void addAction(EntityDeleteAction action) {
 		deletions.add( action );
 	}
 
 	/**
 	 * Adds an orphan removal action
 	 *
 	 * @param action The action representing the orphan removal
 	 */
 	public void addAction(OrphanRemovalAction action) {
 		orphanRemovals.add( action );
 	}
 
 	/**
 	 * Adds an entity update action
 	 *
 	 * @param action The action representing the entity update
 	 */
 	public void addAction(EntityUpdateAction action) {
 		updates.add( action );
 	}
 
 	/**
 	 * Adds a collection (re)create action
 	 *
 	 * @param action The action representing the (re)creation of a collection
 	 */
 	public void addAction(CollectionRecreateAction action) {
 		collectionCreations.add( action );
 	}
 
 	/**
 	 * Adds a collection remove action
 	 *
 	 * @param action The action representing the removal of a collection
 	 */
 	public void addAction(CollectionRemoveAction action) {
 		collectionRemovals.add( action );
 	}
 
 	/**
 	 * Adds a collection update action
 	 *
 	 * @param action The action representing the update of a collection
 	 */
 	public void addAction(CollectionUpdateAction action) {
 		collectionUpdates.add( action );
 	}
 
 	/**
 	 * Adds an action relating to a collection queued operation (extra lazy).
 	 *
 	 * @param action The action representing the queued operation
 	 */
 	public void addAction(QueuedOperationCollectionAction action) {
 		collectionQueuedOps.add( action );
 	}
 
 	/**
 	 * Adds an action defining a cleanup relating to a bulk operation (HQL/JPQL or Criteria based update/delete)
 	 *
 	 * @param action The action representing the queued operation
 	 */
 	public void addAction(BulkOperationCleanupAction action) {
 		registerCleanupActions( action );
 	}
 
 	private void registerCleanupActions(Executable executable) {
 		beforeTransactionProcesses.register( executable.getBeforeTransactionCompletionProcess() );
-		if ( session.getFactory().getSettings().isQueryCacheEnabled() ) {
+		if ( session.getFactory().getSessionFactoryOptions().isQueryCacheEnabled() ) {
 			invalidateSpaces( executable.getPropertySpaces() );
 		}
 		afterTransactionProcesses.register( executable.getAfterTransactionCompletionProcess() );
 	}
 
 	/**
 	 * Are there unresolved entity insert actions that depend on non-nullable associations with a transient entity?
 	 * 
 	 * @return true, if there are unresolved entity insert actions that depend on non-nullable associations with a
 	 * transient entity; false, otherwise
 	 */
 	public boolean hasUnresolvedEntityInsertActions() {
 		return !unresolvedInsertions.isEmpty();
 	}
 
 	/**
 	 * Throws {@link org.hibernate.PropertyValueException} if there are any unresolved entity insert actions that depend
 	 * on non-nullable associations with a transient entity. This method should be called on completion of an operation
 	 * (after all cascades are completed) that saves an entity.
 	 * 
 	 * @throws org.hibernate.PropertyValueException if there are any unresolved entity insert actions;
 	 * {@link org.hibernate.PropertyValueException#getEntityName()} and
 	 * {@link org.hibernate.PropertyValueException#getPropertyName()} will return the entity name and property value for
 	 * the first unresolved entity insert action.
 	 */
 	public void checkNoUnresolvedActionsAfterOperation() throws PropertyValueException {
 		unresolvedInsertions.checkNoUnresolvedActionsAfterOperation();
 	}
 
 	public void registerProcess(AfterTransactionCompletionProcess process) {
 		afterTransactionProcesses.register( process );
 	}
 
 	public void registerProcess(BeforeTransactionCompletionProcess process) {
 		beforeTransactionProcesses.register( process );
 	}
 
 	/**
 	 * Perform all currently queued entity-insertion actions.
 	 * 
 	 * @throws HibernateException error executing queued insertion actions.
 	 */
 	public void executeInserts() throws HibernateException {
 		executeActions( insertions );
 	}
 
 	/**
 	 * Perform all currently queued actions.
 	 * 
 	 * @throws HibernateException error executing queued actions.
 	 */
 	public void executeActions() throws HibernateException {
 		if ( !unresolvedInsertions.isEmpty() ) {
 			throw new IllegalStateException( "About to execute actions, but there are unresolved entity insert actions." );
 		}
 
 		for ( ExecutableList<?> l : executableLists ) {
 			executeActions( l );
 		}
 	}
 
 	/**
 	 * Prepares the internal action queues for execution.
 	 * 
 	 * @throws HibernateException error preparing actions.
 	 */
 	public void prepareActions() throws HibernateException {
 		prepareActions( collectionRemovals );
 		prepareActions( collectionUpdates );
 		prepareActions( collectionCreations );
 		prepareActions( collectionQueuedOps );
 	}
 
 	private void prepareActions(ExecutableList<?> queue) throws HibernateException {
 		for ( Executable executable : queue ) {
 			executable.beforeExecutions();
 		}
 	}
 
 	/**
 	 * Performs cleanup of any held cache softlocks.
 	 * 
 	 * @param success Was the transaction successful.
 	 */
 	public void afterTransactionCompletion(boolean success) {
 		if ( !isTransactionCoordinatorShared ) {
 			// Execute completion actions only in transaction owner (aka parent session).
 			afterTransactionProcesses.afterTransactionCompletion( success );
 		}
 	}
 
 	/**
 	 * Execute any registered {@link org.hibernate.action.spi.BeforeTransactionCompletionProcess}
 	 */
 	public void beforeTransactionCompletion() {
 		if ( !isTransactionCoordinatorShared ) {
 			// Execute completion actions only in transaction owner (aka parent session).
 			beforeTransactionProcesses.beforeTransactionCompletion();
 		}
 	}
 
 	/**
 	 * Check whether any insertion or deletion actions are currently queued.
 	 *
 	 * @return {@code true} if insertions or deletions are currently queued; {@code false} otherwise.
 	 */
 	public boolean areInsertionsOrDeletionsQueued() {
 		return !insertions.isEmpty() || !unresolvedInsertions.isEmpty() || !deletions.isEmpty() || !orphanRemovals.isEmpty();
 	}
 
 	/**
 	 * Check whether the given tables/query-spaces are to be executed against given the currently queued actions.
 	 * 
 	 * @param tables The table/query-spaces to check.
 	 *
 	 * @return {@code true} if we contain pending actions against any of the given tables; {@code false} otherwise.
 	 */
 	public boolean areTablesToBeUpdated(@SuppressWarnings("rawtypes") Set tables) {
 		if ( tables.isEmpty() ) {
 			return false;
 		}
 		for ( ExecutableList<?> l : executableLists ) {
 			if ( areTablesToBeUpdated( l, tables ) ) {
 				return true;
 			}
 		}
 		return areTablesToBeUpdated( unresolvedInsertions, tables );
 	}
 
 	private static boolean areTablesToBeUpdated(ExecutableList<?> actions, @SuppressWarnings("rawtypes") Set tableSpaces) {
 		if ( actions.isEmpty() ) {
 			return false;
 		}
 
 		for ( Serializable actionSpace : actions.getQuerySpaces() ) {
 			if ( tableSpaces.contains( actionSpace ) ) {
 				LOG.debugf( "Changes must be flushed to space: %s", actionSpace );
 				return true;
 			}
 		}
 
 		return false;
 	}
 
 	private static boolean areTablesToBeUpdated(UnresolvedEntityInsertActions actions, @SuppressWarnings("rawtypes") Set tableSpaces) {
 		for ( Executable action : actions.getDependentEntityInsertActions() ) {
 			final Serializable[] spaces = action.getPropertySpaces();
 			for ( Serializable space : spaces ) {
 				if ( tableSpaces.contains( space ) ) {
 					LOG.debugf( "Changes must be flushed to space: %s", space );
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	/**
 	 * Perform {@link org.hibernate.action.spi.Executable#execute()} on each element of the list
 	 * 
 	 * @param list The list of Executable elements to be performed
 	 *
 	 * @throws HibernateException
 	 */
 	private <E extends Executable & Comparable<?> & Serializable> void executeActions(ExecutableList<E> list) throws HibernateException {
 		// todo : consider ways to improve the double iteration of Executables here:
 		//		1) we explicitly iterate list here to perform Executable#execute()
 		//		2) ExecutableList#getQuerySpaces also iterates the Executables to collect query spaces.
 		try {
 			for ( E e : list ) {
 				try {
 					e.execute();
 				}
 				finally {
 					beforeTransactionProcesses.register( e.getBeforeTransactionCompletionProcess() );
 					afterTransactionProcesses.register( e.getAfterTransactionCompletionProcess() );
 				}
 			}
 		}
 		finally {
-			if ( session.getFactory().getSettings().isQueryCacheEnabled() ) {
+			if ( session.getFactory().getSessionFactoryOptions().isQueryCacheEnabled() ) {
 				// Strictly speaking, only a subset of the list may have been processed if a RuntimeException occurs.
 				// We still invalidate all spaces. I don't see this as a big deal - after all, RuntimeExceptions are
 				// unexpected.
 				Set<Serializable> propertySpaces = list.getQuerySpaces();
 				invalidateSpaces( propertySpaces.toArray( new Serializable[propertySpaces.size()] ) );
 			}
 		}
 
 		list.clear();
 		session.getJdbcCoordinator().executeBatch();
 	}
 
 	/**
 	 * @param executable The action to execute
 	 */
 	public <E extends Executable & Comparable<?>> void execute(E executable) {
 		try {
 			executable.execute();
 		}
 		finally {
 			registerCleanupActions( executable );
 		}
 	}
 
 	/**
 	 * This method is now called once per execution of an ExecutableList or once for execution of an Execution.
 	 * 
 	 * @param spaces The spaces to invalidate
 	 */
 	private void invalidateSpaces(Serializable... spaces) {
 		if ( spaces != null && spaces.length > 0 ) {
 			for ( Serializable s : spaces ) {
 				afterTransactionProcesses.addSpaceToInvalidate( (String) s );
 			}
 			// Performance win: If we are processing an ExecutableList, this will only be called once
 			session.getFactory().getUpdateTimestampsCache().preInvalidate( spaces, session );
 		}
 	}
 
 	/**
 	 * Returns a string representation of the object.
 	 * 
 	 * @return a string representation of the object.
 	 */
 	@Override
 	public String toString() {
 		return "ActionQueue[insertions=" + insertions
 				+ " updates=" + updates
 				+ " deletions=" + deletions
 				+ " orphanRemovals=" + orphanRemovals
 				+ " collectionCreations=" + collectionCreations
 				+ " collectionRemovals=" + collectionRemovals
 				+ " collectionUpdates=" + collectionUpdates
 				+ " collectionQueuedOps=" + collectionQueuedOps
 				+ " unresolvedInsertDependencies=" + unresolvedInsertions
 				+ "]";
 	}
 
 	public int numberOfCollectionRemovals() {
 		return collectionRemovals.size();
 	}
 
 	public int numberOfCollectionUpdates() {
 		return collectionUpdates.size();
 	}
 
 	public int numberOfCollectionCreations() {
 		return collectionCreations.size();
 	}
 
 	public int numberOfDeletions() {
 		return deletions.size() + orphanRemovals.size();
 	}
 
 	public int numberOfUpdates() {
 		return updates.size();
 	}
 
 	public int numberOfInsertions() {
 		return insertions.size();
 	}
 
 	public TransactionCompletionProcesses getTransactionCompletionProcesses() {
 		return new TransactionCompletionProcesses( beforeTransactionProcesses, afterTransactionProcesses );
 	}
 
 	/**
 	 * Bind transaction completion processes to make them shared between primary and secondary session.
 	 * Transaction completion processes are always executed by transaction owner (primary session),
 	 * but can be registered using secondary session too.
 	 *
 	 * @param processes Transaction completion processes.
 	 * @param isTransactionCoordinatorShared Flag indicating shared transaction context.
 	 */
 	public void setTransactionCompletionProcesses(TransactionCompletionProcesses processes, boolean isTransactionCoordinatorShared) {
 		this.isTransactionCoordinatorShared = isTransactionCoordinatorShared;
 		this.beforeTransactionProcesses = processes.beforeTransactionCompletionProcesses;
 		this.afterTransactionProcesses = processes.afterTransactionCompletionProcesses;
 	}
 
 	public void sortCollectionActions() {
-		if ( session.getFactory().getSettings().isOrderUpdatesEnabled() ) {
+		if ( session.getFactory().getSessionFactoryOptions().isOrderUpdatesEnabled() ) {
 			// sort the updates by fk
 			collectionCreations.sort();
 			collectionUpdates.sort();
 			collectionQueuedOps.sort();
 			collectionRemovals.sort();
 		}
 	}
 
 	public void sortActions() {
-		if ( session.getFactory().getSettings().isOrderUpdatesEnabled() ) {
+		if ( session.getFactory().getSessionFactoryOptions().isOrderUpdatesEnabled() ) {
 			// sort the updates by pk
 			updates.sort();
 		}
-		if ( session.getFactory().getSettings().isOrderInsertsEnabled() ) {
+		if ( session.getFactory().getSessionFactoryOptions().isOrderInsertsEnabled() ) {
 			insertions.sort();
 		}
 	}
 
 	public void clearFromFlushNeededCheck(int previousCollectionRemovalSize) {
 		collectionCreations.clear();
 		collectionUpdates.clear();
 		collectionQueuedOps.clear();
 		updates.clear();
 		// collection deletions are a special case since update() can add
 		// deletions of collections not loaded by the session.
 		if ( collectionRemovals.size() > previousCollectionRemovalSize ) {
 			collectionRemovals.removeLastN( collectionRemovals.size() - previousCollectionRemovalSize );
 		}
 	}
 
+	@SuppressWarnings("SimplifiableConditionalExpression")
 	public boolean hasAfterTransactionActions() {
 		return isTransactionCoordinatorShared ? false : afterTransactionProcesses.hasActions();
 	}
 
+	@SuppressWarnings("SimplifiableConditionalExpression")
 	public boolean hasBeforeTransactionActions() {
 		return isTransactionCoordinatorShared ? false : beforeTransactionProcesses.hasActions();
 	}
 
 	public boolean hasAnyQueuedActions() {
 		return !updates.isEmpty() || !insertions.isEmpty() || !unresolvedInsertions.isEmpty() || !deletions.isEmpty() || !collectionUpdates.isEmpty()
 				|| !collectionQueuedOps.isEmpty() || !collectionRemovals.isEmpty() || !collectionCreations.isEmpty();
 	}
 
 	public void unScheduleDeletion(EntityEntry entry, Object rescuedEntity) {
 		if ( rescuedEntity instanceof HibernateProxy ) {
 			LazyInitializer initializer = ( ( HibernateProxy ) rescuedEntity ).getHibernateLazyInitializer();
 			if ( !initializer.isUninitialized() ) {
 				rescuedEntity = initializer.getImplementation( session );
 			}
 		}
 		for ( int i = 0; i < deletions.size(); i++ ) {
 			EntityDeleteAction action = deletions.get( i );
 			if ( action.getInstance() == rescuedEntity ) {
 				deletions.remove( i );
 				return;
 			}
 		}
 		for ( int i = 0; i < orphanRemovals.size(); i++ ) {
 			EntityDeleteAction action = orphanRemovals.get( i );
 			if ( action.getInstance() == rescuedEntity ) {
 				orphanRemovals.remove( i );
 				return;
 			}
 		}
 		throw new AssertionFailure( "Unable to perform un-delete for instance " + entry.getEntityName() );
 	}
 
 	/**
 	 * Used by the owning session to explicitly control serialization of the action queue
 	 * 
 	 * @param oos The stream to which the action queue should get written
 	 * @throws IOException Indicates an error writing to the stream
 	 */
 	public void serialize(ObjectOutputStream oos) throws IOException {
 		LOG.trace( "Serializing action-queue" );
 
 		unresolvedInsertions.serialize( oos );
 
 		for ( ExecutableList<?> l : executableLists ) {
 			l.writeExternal( oos );
 		}
 	}
 
 	/**
 	 * Used by the owning session to explicitly control deserialization of the action queue.
 	 * 
 	 * @param ois The stream from which to read the action queue
 	 * @param session The session to which the action queue belongs
 	 * @return The deserialized action queue
 	 * @throws IOException indicates a problem reading from the stream
 	 * @throws ClassNotFoundException Generally means we were unable to locate user classes.
 	 */
 	public static ActionQueue deserialize(ObjectInputStream ois, SessionImplementor session) throws IOException, ClassNotFoundException {
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		if ( traceEnabled ) {
 			LOG.trace( "Deserializing action-queue" );
 		}
 		ActionQueue rtn = new ActionQueue( session );
 
 		rtn.unresolvedInsertions = UnresolvedEntityInsertActions.deserialize( ois, session );
 
 		for ( ExecutableList<?> l : rtn.executableLists ) {
 			l.readExternal( ois );
 			if ( traceEnabled ) {
 				LOG.tracev( "Deserialized [{0}] entries", l.size() );
 			}
 			l.afterDeserialize( session );
 		}
 
 		return rtn;
 	}
 
 	private static abstract class AbstractTransactionCompletionProcessQueue<T> {
 		protected SessionImplementor session;
 		// Concurrency handling required when transaction completion process is dynamically registered
 		// inside event listener (HHH-7478).
 		protected Queue<T> processes = new ConcurrentLinkedQueue<T>();
 
 		private AbstractTransactionCompletionProcessQueue(SessionImplementor session) {
 			this.session = session;
 		}
 
 		public void register(T process) {
 			if ( process == null ) {
 				return;
 			}
 			processes.add( process );
 		}
 
 		public boolean hasActions() {
 			return !processes.isEmpty();
 		}
 	}
 
 	/**
 	 * Encapsulates behavior needed for before transaction processing
 	 */
 	private static class BeforeTransactionCompletionProcessQueue extends AbstractTransactionCompletionProcessQueue<BeforeTransactionCompletionProcess> {
 		private BeforeTransactionCompletionProcessQueue(SessionImplementor session) {
 			super( session );
 		}
 
 		public void beforeTransactionCompletion() {
 			while ( !processes.isEmpty() ) {
 				try {
 					processes.poll().doBeforeTransactionCompletion( session );
 				}
 				catch (HibernateException he) {
 					throw he;
 				}
 				catch (Exception e) {
 					throw new AssertionFailure( "Unable to perform beforeTransactionCompletion callback", e );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Encapsulates behavior needed for after transaction processing
 	 */
 	private static class AfterTransactionCompletionProcessQueue extends AbstractTransactionCompletionProcessQueue<AfterTransactionCompletionProcess> {
 		private Set<String> querySpacesToInvalidate = new HashSet<String>();
 
 		private AfterTransactionCompletionProcessQueue(SessionImplementor session) {
 			super( session );
 		}
 
 		public void addSpaceToInvalidate(String space) {
 			querySpacesToInvalidate.add( space );
 		}
 
 		public void afterTransactionCompletion(boolean success) {
 			while ( !processes.isEmpty() ) {
 				try {
 					processes.poll().doAfterTransactionCompletion( success, session );
 				}
 				catch (CacheException ce) {
 					LOG.unableToReleaseCacheLock( ce );
 					// continue loop
 				}
 				catch (Exception e) {
 					throw new AssertionFailure( "Exception releasing cache locks", e );
 				}
 			}
 
-			if ( session.getFactory().getSettings().isQueryCacheEnabled() ) {
+			if ( session.getFactory().getSessionFactoryOptions().isQueryCacheEnabled() ) {
 				session.getFactory().getUpdateTimestampsCache().invalidate(
 						querySpacesToInvalidate.toArray( new String[querySpacesToInvalidate.size()] ),
 						session
 				);
 			}
 			querySpacesToInvalidate.clear();
 		}
 	}
 
 	/**
 	 * Wrapper class allowing to bind the same transaction completion process queues in different sessions.
 	 */
 	public static class TransactionCompletionProcesses {
 		private final BeforeTransactionCompletionProcessQueue beforeTransactionCompletionProcesses;
 		private final AfterTransactionCompletionProcessQueue afterTransactionCompletionProcesses;
 
 		private TransactionCompletionProcesses(
 				BeforeTransactionCompletionProcessQueue beforeTransactionCompletionProcessQueue,
 				AfterTransactionCompletionProcessQueue afterTransactionCompletionProcessQueue) {
 			this.beforeTransactionCompletionProcesses = beforeTransactionCompletionProcessQueue;
 			this.afterTransactionCompletionProcesses = afterTransactionCompletionProcessQueue;
 		}
 	}
 
 	/**
 	 * Order the {@link #insertions} queue such that we group inserts against the same entity together (without
 	 * violating constraints). The original order is generated by cascade order, which in turn is based on the
 	 * directionality of foreign-keys. So even though we will be changing the ordering here, we need to make absolutely
 	 * certain that we do not circumvent this FK ordering to the extent of causing constraint violations.
 	 * <p>
 	 * Sorts the insert actions using more hashes.
 	 * </p>
 	 * NOTE: this class is not thread-safe.
 	 * 
 	 * @author Jay Erb
 	 */
 	private static class InsertActionSorter implements ExecutableList.Sorter<AbstractEntityInsertAction> {
 		/**
 		 * Singleton access
 		 */
 		public static final InsertActionSorter INSTANCE = new InsertActionSorter();
 
 		// the mapping of entity names to their latest batch numbers.
 		private Map<String, Integer> latestBatches;
 		private Map<Object, Integer> entityBatchNumber;
 
 		// the map of batch numbers to EntityInsertAction lists
 		private Map<Integer, List<AbstractEntityInsertAction>> actionBatches;
 
 		public InsertActionSorter() {
 		}
 
 		/**
 		 * Sort the insert actions.
 		 */
 		public void sort(List<AbstractEntityInsertAction> insertions) {
 			// optimize the hash size to eliminate a rehash.
 			this.latestBatches = new HashMap<String, Integer>();
 			this.entityBatchNumber = new HashMap<Object, Integer>( insertions.size() + 1, 1.0f );
 			this.actionBatches = new HashMap<Integer, List<AbstractEntityInsertAction>>();
 
 			// the list of entity names that indicate the batch number
 			for ( AbstractEntityInsertAction action : insertions ) {
 				// remove the current element from insertions. It will be added back later.
 				String entityName = action.getEntityName();
 
 				// the entity associated with the current action.
 				Object currentEntity = action.getInstance();
 
 				Integer batchNumber;
 				if ( latestBatches.containsKey( entityName ) ) {
 					// There is already an existing batch for this type of entity.
 					// Check to see if the latest batch is acceptable.
 					batchNumber = findBatchNumber( action, entityName );
 				}
 				else {
 					// add an entry for this type of entity.
 					// we can be assured that all referenced entities have already
 					// been processed,
 					// so specify that this entity is with the latest batch.
 					// doing the batch number before adding the name to the list is
 					// a faster way to get an accurate number.
 
 					batchNumber = actionBatches.size();
 					latestBatches.put( entityName, batchNumber );
 				}
 				entityBatchNumber.put( currentEntity, batchNumber );
 				addToBatch( batchNumber, action );
 			}
 			insertions.clear();
 
 			// now rebuild the insertions list. There is a batch for each entry in the name list.
 			for ( int i = 0; i < actionBatches.size(); i++ ) {
 				List<AbstractEntityInsertAction> batch = actionBatches.get( i );
 				insertions.addAll( batch );
 			}
 		}
 
 		/**
 		 * Finds an acceptable batch for this entity to be a member as part of the {@link InsertActionSorter}
 		 * 
 		 * @param action The action being sorted
 		 * @param entityName The name of the entity affected by the action
 		 * @return An appropriate batch number; todo document this process better
 		 */
 		private Integer findBatchNumber(AbstractEntityInsertAction action, String entityName) {
 			// loop through all the associated entities and make sure they have been
 			// processed before the latest
 			// batch associated with this entity type.
 
 			// the current batch number is the latest batch for this entity type.
 			Integer latestBatchNumberForType = latestBatches.get( entityName );
 
 			// loop through all the associations of the current entity and make sure that they are processed
 			// before the current batch number
 			Object[] propertyValues = action.getState();
 			Type[] propertyTypes = action.getPersister().getClassMetadata().getPropertyTypes();
 
 			for ( int i = 0; i < propertyValues.length; i++ ) {
 				Object value = propertyValues[i];
 				Type type = propertyTypes[i];
 				if ( type.isEntityType() && value != null ) {
 					// find the batch number associated with the current association, if any.
 					Integer associationBatchNumber = entityBatchNumber.get( value );
 					if ( associationBatchNumber != null && associationBatchNumber.compareTo( latestBatchNumberForType ) > 0 ) {
 						// create a new batch for this type. The batch number is the number of current batches.
 						latestBatchNumberForType = actionBatches.size();
 						latestBatches.put( entityName, latestBatchNumberForType );
 						// since this entity will now be processed in the latest possible batch,
 						// we can be assured that it will come after all other associations,
 						// there's not need to continue checking.
 						break;
 					}
 				}
 			}
 			return latestBatchNumberForType;
 		}
 
 		private void addToBatch(Integer batchNumber, AbstractEntityInsertAction action) {
 			List<AbstractEntityInsertAction> actions = actionBatches.get( batchNumber );
 
 			if ( actions == null ) {
 				actions = new LinkedList<AbstractEntityInsertAction>();
 				actionBatches.put( batchNumber, actions );
 			}
 			actions.add( action );
 		}
 
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/EntityEntry.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/EntityEntry.java
index 1ecdf10311..643b525a47 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/EntityEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/EntityEntry.java
@@ -1,163 +1,162 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.io.IOException;
-import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 
 import org.hibernate.LockMode;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * We need an entry to tell us all about the current state of an object with respect to its persistent state
  *
  * Implementation Warning: Hibernate needs to instantiate a high amount of instances of this class,
  * therefore we need to take care of its impact on memory consumption.
  *
  * @author Gavin King
  * @author Emmanuel Bernard <emmanuel@hibernate.org>
  * @author Gunnar Morling
  * @author Sanne Grinovero  <sanne@hibernate.org>
  */
 public interface EntityEntry {
 	LockMode getLockMode();
 
 	void setLockMode(LockMode lockMode);
 
 	Status getStatus();
 
 	void setStatus(Status status);
 
 	Serializable getId();
 
 	Object[] getLoadedState();
 
 	Object[] getDeletedState();
 
 	void setDeletedState(Object[] deletedState);
 
 	boolean isExistsInDatabase();
 
 	Object getVersion();
 
 	EntityPersister getPersister();
 
 	/**
 	 * Get the EntityKey based on this EntityEntry.
 	 * @return the EntityKey
 	 * @throws  IllegalStateException if getId() is null
 	 */
 	EntityKey getEntityKey();
 
 	String getEntityName();
 
 	boolean isBeingReplicated();
 
 	Object getRowId();
 
 	/**
 	 * Handle updating the internal state of the entry after actually performing
 	 * the database update.  Specifically we update the snapshot information and
 	 * escalate the lock mode
 	 *
 	 * @param entity The entity instance
 	 * @param updatedState The state calculated after the update (becomes the
 	 * new {@link #getLoadedState() loaded state}.
 	 * @param nextVersion The new version.
 	 */
 	void postUpdate(Object entity, Object[] updatedState, Object nextVersion);
 
 	/**
 	 * After actually deleting a row, record the fact that the instance no longer
 	 * exists in the database
 	 */
 	void postDelete();
 
 	/**
 	 * After actually inserting a row, record the fact that the instance exists on the
 	 * database (needed for identity-column key generation)
 	 */
 	void postInsert(Object[] insertedState);
 
 	boolean isNullifiable(boolean earlyInsert, SessionImplementor session);
 
 	Object getLoadedValue(String propertyName);
 
 	/**
 	 * Not sure this is the best method name, but the general idea here is to return {@code true} if the entity can
 	 * possibly be dirty.  This can only be the case if it is in a modifiable state (not read-only/deleted) and it
 	 * either has mutable properties or field-interception is not telling us it is dirty.  Clear as mud? :/
 	 *
 	 * A name like canPossiblyBeDirty might be better
 	 *
 	 * @param entity The entity to test
 	 *
 	 * @return {@code true} indicates that the entity could possibly be dirty and that dirty check
 	 * should happen; {@code false} indicates there is no way the entity can be dirty
 	 */
 	boolean requiresDirtyCheck(Object entity);
 
 	/**
 	 * Can the entity be modified?
 	 *
 	 * The entity is modifiable if all of the following are true:
 	 * <ul>
 	 * <li>the entity class is mutable</li>
 	 * <li>the entity is not read-only</li>
 	 * <li>if the current status is Status.DELETED, then the entity was not read-only when it was deleted</li>
 	 * </ul>
 	 * @return true, if the entity is modifiable; false, otherwise,
 	 */
 	boolean isModifiableEntity();
 
 	void forceLocked(Object entity, Object nextVersion);
 
 	boolean isReadOnly();
 
 	void setReadOnly(boolean readOnly, Object entity);
 
 	@Override
 	String toString();
 
 	boolean isLoadedWithLazyPropertiesUnfetched();
 
 	/**
 	 * Custom serialization routine used during serialization of a
 	 * Session/PersistenceContext for increased performance.
 	 *
 	 * @param oos The stream to which we should write the serial data.
 	 *
 	 * @throws java.io.IOException If a stream error occurs
 	 */
 	void serialize(ObjectOutputStream oos) throws IOException;
 
 	//the following methods are handling extraState contracts.
 	//they are not shared by a common superclass to avoid alignment padding
 	//we are trading off duplication for padding efficiency
 	void addExtraState(EntityEntryExtraState extraState);
 
 	<T extends EntityEntryExtraState> T getExtraState(Class<T> extraStateType);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionImplementor.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionImplementor.java
index b456700f69..7d89247023 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionImplementor.java
@@ -1,373 +1,371 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Iterator;
 import java.util.List;
-import java.util.Map;
 
 import org.hibernate.CacheMode;
 import org.hibernate.Criteria;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Query;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
-import org.hibernate.Transaction;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.type.Type;
 
 /**
  * Defines the internal contract between {@link org.hibernate.Session} / {@link org.hibernate.StatelessSession} and
  * other parts of Hibernate such as {@link Type}, {@link EntityPersister} and
  * {@link org.hibernate.persister.collection.CollectionPersister} implementors
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public interface SessionImplementor extends Serializable, LobCreationContext {
 	/**
 	 * Match te method on {@link org.hibernate.Session} and {@link org.hibernate.StatelessSession}
 	 *
 	 * @return The tenant identifier of this session
 	 */
 	String getTenantIdentifier();
 
 	/**
 	 * Provides access to JDBC connections
 	 *
 	 * @return The contract for accessing JDBC connections.
 	 */
 	JdbcConnectionAccess getJdbcConnectionAccess();
 
 	/**
 	 * Hide the changing requirements of entity key creation
 	 *
 	 * @param id The entity id
 	 * @param persister The entity persister
 	 *
 	 * @return The entity key
 	 */
 	EntityKey generateEntityKey(Serializable id, EntityPersister persister);
 
 	/**
 	 * Hide the changing requirements of cache key creation.
 	 *
 	 * @param id The entity identifier or collection key.
 	 * @param type The type
 	 * @param entityOrRoleName The entity name or collection role.
 	 *
 	 * @return The cache key
 	 */
 	CacheKey generateCacheKey(Serializable id, final Type type, final String entityOrRoleName);
 
 	/**
 	 * Retrieves the interceptor currently in use by this event source.
 	 *
 	 * @return The interceptor.
 	 */
 	Interceptor getInterceptor();
 
 	/**
 	 * Enable/disable automatic cache clearing from after transaction
 	 * completion (for EJB3)
 	 */
 	void setAutoClear(boolean enabled);
 
 	/**
 	 * Disable automatic transaction joining.  The really only has any effect for CMT transactions.  The default
 	 * Hibernate behavior is to auto join any active JTA transaction (register {@link javax.transaction.Synchronization}).
 	 * JPA however defines an explicit join transaction operation.
 	 * <p/>
 	 * See javax.persistence.EntityManager#joinTransaction
 	 */
 	void disableTransactionAutoJoin();
 
 	/**
 	 * Does this <tt>Session</tt> have an active Hibernate transaction
 	 * or is there a JTA transaction in progress?
 	 */
 	boolean isTransactionInProgress();
 
 	/**
 	 * Initialize the collection (if not already initialized)
 	 */
 	void initializeCollection(PersistentCollection collection, boolean writing)
 			throws HibernateException;
 
 	/**
 	 * Load an instance without checking if it was deleted.
 	 * <p/>
 	 * When <tt>nullable</tt> is disabled this method may create a new proxy or
 	 * return an existing proxy; if it does not exist, throw an exception.
 	 * <p/>
 	 * When <tt>nullable</tt> is enabled, the method does not create new proxies
 	 * (but might return an existing proxy); if it does not exist, return
 	 * <tt>null</tt>.
 	 * <p/>
 	 * When <tt>eager</tt> is enabled, the object is eagerly fetched
 	 */
 	Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable)
 			throws HibernateException;
 
 	/**
 	 * Load an instance immediately. This method is only called when lazily initializing a proxy.
 	 * Do not return the proxy.
 	 */
 	Object immediateLoad(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * System time before the start of the transaction
 	 */
 	long getTimestamp();
 
 	/**
 	 * Get the creating <tt>SessionFactoryImplementor</tt>
 	 */
 	SessionFactoryImplementor getFactory();
 
 	/**
 	 * Execute a <tt>find()</tt> query
 	 */
 	List list(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute an <tt>iterate()</tt> query
 	 */
 	Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute a <tt>scroll()</tt> query
 	 */
 	ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute a criteria query
 	 */
 	ScrollableResults scroll(Criteria criteria, ScrollMode scrollMode);
 
 	/**
 	 * Execute a criteria query
 	 */
 	List list(Criteria criteria);
 
 	/**
 	 * Execute a filter
 	 */
 	List listFilter(Object collection, String filter, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Iterate a filter
 	 */
 	Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Get the <tt>EntityPersister</tt> for any instance
 	 *
 	 * @param entityName optional entity name
 	 * @param object the entity instance
 	 */
 	EntityPersister getEntityPersister(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Get the entity instance associated with the given <tt>Key</tt>,
 	 * calling the Interceptor if necessary
 	 */
 	Object getEntityUsingInterceptor(EntityKey key) throws HibernateException;
 
 	/**
 	 * Return the identifier of the persistent object, or null if
 	 * not associated with the session
 	 */
 	Serializable getContextEntityIdentifier(Object object);
 
 	/**
 	 * The best guess entity name for an entity not in an association
 	 */
 	String bestGuessEntityName(Object object);
 
 	/**
 	 * The guessed entity name for an entity not in an association
 	 */
 	String guessEntityName(Object entity) throws HibernateException;
 
 	/**
 	 * Instantiate the entity class, initializing with the given identifier
 	 */
 	Object instantiate(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * Execute an SQL Query
 	 */
 	List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Execute an SQL Query
 	 */
 	ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Execute a native SQL query, and return the results as a fully built list.
 	 *
 	 * @param spec The specification of the native SQL query to execute.
 	 * @param queryParameters The parameters by which to perform the execution.
 	 *
 	 * @return The result list.
 	 *
 	 * @throws HibernateException
 	 */
 	List list(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Execute a native SQL query, and return the results as a scrollable result.
 	 *
 	 * @param spec The specification of the native SQL query to execute.
 	 * @param queryParameters The parameters by which to perform the execution.
 	 *
 	 * @return The resulting scrollable result.
 	 *
 	 * @throws HibernateException
 	 */
 	ScrollableResults scroll(NativeSQLQuerySpecification spec, QueryParameters queryParameters);
 
 	int getDontFlushFromFind();
 
 	//TODO: temporary
 
 	/**
 	 * Get the persistence context for this session
 	 */
 	PersistenceContext getPersistenceContext();
 
 	/**
 	 * Execute a HQL update or delete query
 	 */
 	int executeUpdate(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute a native SQL update or delete query
 	 */
 	int executeNativeUpdate(NativeSQLQuerySpecification specification, QueryParameters queryParameters)
 			throws HibernateException;
 
 
 	// copied from Session:
 
 	CacheMode getCacheMode();
 
 	void setCacheMode(CacheMode cm);
 
 	boolean isOpen();
 
 	boolean isConnected();
 
 	FlushMode getFlushMode();
 
 	void setFlushMode(FlushMode fm);
 
 	Connection connection();
 
 	void flush();
 
 	/**
 	 * Get a Query instance for a named query or named native SQL query
 	 */
 	Query getNamedQuery(String name);
 
 	/**
 	 * Get a Query instance for a named native SQL query
 	 */
 	Query getNamedSQLQuery(String name);
 
 	boolean isEventSource();
 
 	void afterScrollOperation();
 
 	/**
 	 * Retrieve access to the session's transaction coordinator.
 	 *
 	 * @return The transaction coordinator.
 	 */
 	TransactionCoordinator getTransactionCoordinator();
 
 	JdbcCoordinator getJdbcCoordinator();
 
 	/**
 	 * Determine whether the session is closed.  Provided separately from
 	 * {@link #isOpen()} as this method does not attempt any JTA synchronization
 	 * registration, where as {@link #isOpen()} does; which makes this one
 	 * nicer to use for most internal purposes.
 	 *
 	 * @return True if the session is closed; false otherwise.
 	 */
 	boolean isClosed();
 
 	boolean shouldAutoClose();
 
 	boolean isAutoCloseSessionEnabled();
 
 	/**
 	 * Get the load query influencers associated with this session.
 	 *
 	 * @return the load query influencers associated with this session;
 	 *         should never be null.
 	 */
 	LoadQueryInfluencers getLoadQueryInfluencers();
 
 	/**
 	 * Used from EntityManager
 	 *
 	 * @param namedQueryDefinition The named query definition
 	 *
 	 * @return The basic HQL/JPQL query (without saved settings applied)
 	 */
 	Query createQuery(NamedQueryDefinition namedQueryDefinition);
 
 	/**
 	 * Used from EntityManager
 	 *
 	 * @param namedQueryDefinition The named query definition
 	 *
 	 * @return The basic SQL query (without saved settings applied)
 	 */
 	SQLQuery createSQLQuery(NamedSQLQueryDefinition namedQueryDefinition);
 
 	SessionEventListenerManager getEventListenerManager();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/LocalStatus.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/LocalStatus.java
deleted file mode 100644
index ef9343c825..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/LocalStatus.java
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.spi;
-
-/**
- * Enumeration of statuses in which a local transaction facade ({@link org.hibernate.Transaction}) might be.
- *
- * @author Steve Ebersole
- */
-public enum LocalStatus {
-	/**
-	 * The local transaction has not yet been begun
-	 */
-	NOT_ACTIVE,
-	/**
-	 * The local transaction has been begun, but not yet completed.
-	 */
-	ACTIVE,
-	/**
-	 * The local transaction has been competed successfully.
-	 */
-	COMMITTED,
-	/**
-	 * The local transaction has been rolled back.
-	 */
-	ROLLED_BACK,
-	/**
-	 * The local transaction attempted to commit, but failed.
-	 */
-	FAILED_COMMIT
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractFlushingEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractFlushingEventListener.java
index c99a3bb827..39d97df4b3 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractFlushingEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractFlushingEventListener.java
@@ -1,404 +1,406 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import java.io.Serializable;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.action.internal.CollectionRecreateAction;
 import org.hibernate.action.internal.CollectionRemoveAction;
 import org.hibernate.action.internal.CollectionUpdateAction;
 import org.hibernate.action.internal.QueuedOperationCollectionAction;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.internal.Cascade;
 import org.hibernate.engine.internal.CascadePoint;
 import org.hibernate.engine.internal.Collections;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CascadingAction;
 import org.hibernate.engine.spi.CascadingActions;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.CollectionKey;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.event.spi.FlushEntityEvent;
 import org.hibernate.event.spi.FlushEntityEventListener;
 import org.hibernate.event.spi.FlushEvent;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.EntityPrinter;
 import org.hibernate.internal.util.collections.IdentityMap;
 import org.hibernate.internal.util.collections.LazyIterator;
 import org.hibernate.persister.entity.EntityPersister;
 
 import org.jboss.logging.Logger;
 
 /**
  * A convenience base class for listeners whose functionality results in flushing.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractFlushingEventListener implements Serializable {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, AbstractFlushingEventListener.class.getName() );
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Pre-flushing section
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Coordinates the processing necessary to get things ready for executions
 	 * as db calls by preping the session caches and moving the appropriate
 	 * entities and collections to their respective execution queues.
 	 *
 	 * @param event The flush event.
 	 * @throws HibernateException Error flushing caches to execution queues.
 	 */
 	protected void flushEverythingToExecutions(FlushEvent event) throws HibernateException {
 
 		LOG.trace( "Flushing session" );
 
 		EventSource session = event.getSession();
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		session.getInterceptor().preFlush( new LazyIterator( persistenceContext.getEntitiesByKey() ) );
 
 		prepareEntityFlushes( session, persistenceContext );
 		// we could move this inside if we wanted to
 		// tolerate collection initializations during
 		// collection dirty checking:
 		prepareCollectionFlushes( persistenceContext );
 		// now, any collections that are initialized
 		// inside this block do not get updated - they
 		// are ignored until the next flush
 
 		persistenceContext.setFlushing( true );
 		try {
 			int entityCount = flushEntities( event, persistenceContext );
 			int collectionCount = flushCollections( session, persistenceContext );
 
 			event.setNumberOfEntitiesProcessed( entityCount );
 			event.setNumberOfCollectionsProcessed( collectionCount );
 		}
 		finally {
 			persistenceContext.setFlushing(false);
 		}
 
 		//some statistics
 		logFlushResults( event );
 	}
 
 	@SuppressWarnings( value = {"unchecked"} )
 	private void logFlushResults(FlushEvent event) {
 		if ( !LOG.isDebugEnabled() ) {
 			return;
 		}
 		final EventSource session = event.getSession();
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		LOG.debugf(
 				"Flushed: %s insertions, %s updates, %s deletions to %s objects",
 				session.getActionQueue().numberOfInsertions(),
 				session.getActionQueue().numberOfUpdates(),
 				session.getActionQueue().numberOfDeletions(),
 				persistenceContext.getNumberOfManagedEntities()
 		);
 		LOG.debugf(
 				"Flushed: %s (re)creations, %s updates, %s removals to %s collections",
 				session.getActionQueue().numberOfCollectionCreations(),
 				session.getActionQueue().numberOfCollectionUpdates(),
 				session.getActionQueue().numberOfCollectionRemovals(),
 				persistenceContext.getCollectionEntries().size()
 		);
 		new EntityPrinter( session.getFactory() ).toString(
 				persistenceContext.getEntitiesByKey().entrySet()
 		);
 	}
 
 	/**
 	 * process cascade save/update at the start of a flush to discover
 	 * any newly referenced entity that must be passed to saveOrUpdate(),
 	 * and also apply orphan delete
 	 */
 	private void prepareEntityFlushes(EventSource session, PersistenceContext persistenceContext) throws HibernateException {
 
 		LOG.debug( "Processing flush-time cascades" );
 
 		final Object anything = getAnything();
 		//safe from concurrent modification because of how concurrentEntries() is implemented on IdentityMap
 		for ( Map.Entry<Object,EntityEntry> me : persistenceContext.reentrantSafeEntityEntries() ) {
 //		for ( Map.Entry me : IdentityMap.concurrentEntries( persistenceContext.getEntityEntries() ) ) {
 			EntityEntry entry = (EntityEntry) me.getValue();
 			Status status = entry.getStatus();
 			if ( status == Status.MANAGED || status == Status.SAVING || status == Status.READ_ONLY ) {
 				cascadeOnFlush( session, entry.getPersister(), me.getKey(), anything );
 			}
 		}
 	}
 
 	private void cascadeOnFlush(EventSource session, EntityPersister persister, Object object, Object anything)
 	throws HibernateException {
 		session.getPersistenceContext().incrementCascadeLevel();
 		try {
 			Cascade.cascade( getCascadingAction(), CascadePoint.BEFORE_FLUSH, session, persister, object, anything );
 		}
 		finally {
 			session.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
-	protected Object getAnything() { return null; }
+	protected Object getAnything() {
+		return null;
+	}
 
 	protected CascadingAction getCascadingAction() {
 		return CascadingActions.SAVE_UPDATE;
 	}
 
 	/**
 	 * Initialize the flags of the CollectionEntry, including the
 	 * dirty check.
 	 */
 	private void prepareCollectionFlushes(PersistenceContext persistenceContext) throws HibernateException {
 
 		// Initialize dirty flags for arrays + collections with composite elements
 		// and reset reached, doupdate, etc.
 
 		LOG.debug( "Dirty checking collections" );
 
 		for ( Map.Entry<PersistentCollection,CollectionEntry> entry :
 				IdentityMap.concurrentEntries( (Map<PersistentCollection,CollectionEntry>) persistenceContext.getCollectionEntries() )) {
 			entry.getValue().preFlush( entry.getKey() );
 		}
 	}
 
 	/**
 	 * 1. detect any dirty entities
 	 * 2. schedule any entity updates
 	 * 3. search out any reachable collections
 	 */
 	private int flushEntities(final FlushEvent event, final PersistenceContext persistenceContext) throws HibernateException {
 
 		LOG.trace( "Flushing entities and processing referenced collections" );
 
 		final EventSource source = event.getSession();
 		final Iterable<FlushEntityEventListener> flushListeners = source.getFactory().getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( EventType.FLUSH_ENTITY )
 				.listeners();
 
 		// Among other things, updateReachables() will recursively load all
 		// collections that are moving roles. This might cause entities to
 		// be loaded.
 
 		// So this needs to be safe from concurrent modification problems.
 
 		final Map.Entry<Object,EntityEntry>[] entityEntries = persistenceContext.reentrantSafeEntityEntries();
 		final int count = entityEntries.length;
 
 		for ( Map.Entry<Object,EntityEntry> me : entityEntries ) {
 
 			// Update the status of the object and if necessary, schedule an update
 
 			EntityEntry entry = me.getValue();
 			Status status = entry.getStatus();
 
 			if ( status != Status.LOADING && status != Status.GONE ) {
 				final FlushEntityEvent entityEvent = new FlushEntityEvent( source, me.getKey(), entry );
 				for ( FlushEntityEventListener listener : flushListeners ) {
 					listener.onFlushEntity( entityEvent );
 				}
 			}
 		}
 
 		source.getActionQueue().sortActions();
 
 		return count;
 	}
 
 	/**
 	 * process any unreferenced collections and then inspect all known collections,
 	 * scheduling creates/removes/updates
 	 */
 	@SuppressWarnings("unchecked")
 	private int flushCollections(final EventSource session, final PersistenceContext persistenceContext) throws HibernateException {
 		LOG.trace( "Processing unreferenced collections" );
 
 		final Map.Entry<PersistentCollection,CollectionEntry>[] entries = IdentityMap.concurrentEntries(
 				(Map<PersistentCollection,CollectionEntry>) persistenceContext.getCollectionEntries()
 		);
 
 		final int count = entries.length;
 
 		for ( Map.Entry<PersistentCollection,CollectionEntry> me : entries ) {
 			CollectionEntry ce = me.getValue();
 			if ( !ce.isReached() && !ce.isIgnore() ) {
 				Collections.processUnreachableCollection( me.getKey(), session );
 			}
 		}
 
 		// Schedule updates to collections:
 
 		LOG.trace( "Scheduling collection removes/(re)creates/updates" );
 
 		ActionQueue actionQueue = session.getActionQueue();
 		for ( Map.Entry<PersistentCollection,CollectionEntry> me :
 			IdentityMap.concurrentEntries( (Map<PersistentCollection,CollectionEntry>) persistenceContext.getCollectionEntries() )) {
 			PersistentCollection coll = me.getKey();
 			CollectionEntry ce = me.getValue();
 
 			if ( ce.isDorecreate() ) {
 				session.getInterceptor().onCollectionRecreate( coll, ce.getCurrentKey() );
 				actionQueue.addAction(
 						new CollectionRecreateAction(
 								coll,
 								ce.getCurrentPersister(),
 								ce.getCurrentKey(),
 								session
 							)
 					);
 			}
 			if ( ce.isDoremove() ) {
 				session.getInterceptor().onCollectionRemove( coll, ce.getLoadedKey() );
 				actionQueue.addAction(
 						new CollectionRemoveAction(
 								coll,
 								ce.getLoadedPersister(),
 								ce.getLoadedKey(),
 								ce.isSnapshotEmpty(coll),
 								session
 							)
 					);
 			}
 			if ( ce.isDoupdate() ) {
 				session.getInterceptor().onCollectionUpdate( coll, ce.getLoadedKey() );
 				actionQueue.addAction(
 						new CollectionUpdateAction(
 								coll,
 								ce.getLoadedPersister(),
 								ce.getLoadedKey(),
 								ce.isSnapshotEmpty(coll),
 								session
 							)
 					);
 			}
 			if ( !coll.wasInitialized() && coll.hasQueuedOperations() ) {
 				actionQueue.addAction(
 						new QueuedOperationCollectionAction(
 								coll,
 								ce.getLoadedPersister(),
 								ce.getLoadedKey(),
 								session
 							)
 					);
 			}
 
 		}
 
 		actionQueue.sortCollectionActions();
 
 		return count;
 	}
 
 	/**
 	 * Execute all SQL (and second-level cache updates) in a special order so that foreign-key constraints cannot
 	 * be violated: <ol>
 	 * <li> Inserts, in the order they were performed
 	 * <li> Updates
 	 * <li> Deletion of collection elements
 	 * <li> Insertion of collection elements
 	 * <li> Deletes, in the order they were performed
 	 * </ol>
 	 *
 	 * @param session The session being flushed
 	 */
 	protected void performExecutions(EventSource session) {
 		LOG.trace( "Executing flush" );
 
 		// IMPL NOTE : here we alter the flushing flag of the persistence context to allow
 		//		during-flush callbacks more leniency in regards to initializing proxies and
 		//		lazy collections during their processing.
 		// For more information, see HHH-2763
 		try {
 			session.getJdbcCoordinator().flushBeginning();
 			session.getPersistenceContext().setFlushing( true );
 			// we need to lock the collection caches before executing entity inserts/updates in order to
 			// account for bi-directional associations
 			session.getActionQueue().prepareActions();
 			session.getActionQueue().executeActions();
 		}
 		finally {
 			session.getPersistenceContext().setFlushing( false );
 			session.getJdbcCoordinator().flushEnding();
 		}
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Post-flushing section
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * 1. Recreate the collection key -> collection map
 	 * 2. rebuild the collection entries
 	 * 3. call Interceptor.postFlush()
 	 */
 	protected void postFlush(SessionImplementor session) throws HibernateException {
 
 		LOG.trace( "Post flush" );
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		persistenceContext.getCollectionsByKey().clear();
 		
 		// the database has changed now, so the subselect results need to be invalidated
 		// the batch fetching queues should also be cleared - especially the collection batch fetching one
 		persistenceContext.getBatchFetchQueue().clear();
 
 		for ( Map.Entry<PersistentCollection, CollectionEntry> me : IdentityMap.concurrentEntries( persistenceContext.getCollectionEntries() ) ) {
 			CollectionEntry collectionEntry = me.getValue();
 			PersistentCollection persistentCollection = me.getKey();
 			collectionEntry.postFlush(persistentCollection);
 			if ( collectionEntry.getLoadedPersister() == null ) {
 				//if the collection is dereferenced, remove from the session cache
 				//iter.remove(); //does not work, since the entrySet is not backed by the set
 				persistenceContext.getCollectionEntries()
 						.remove(persistentCollection);
 			}
 			else {
 				//otherwise recreate the mapping between the collection and its key
 				CollectionKey collectionKey = new CollectionKey(
 						collectionEntry.getLoadedPersister(),
 						collectionEntry.getLoadedKey()
 				);
 				persistenceContext.getCollectionsByKey().put(collectionKey, persistentCollection);
 			}
 		}
 
 	}
 
 	protected void postPostFlush(SessionImplementor session) {
 		session.getInterceptor().postFlush( new LazyIterator( session.getPersistenceContext().getEntitiesByKey() ) );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/EvictVisitor.java b/hibernate-core/src/main/java/org/hibernate/event/internal/EvictVisitor.java
index ba995c97bb..11d185fae2 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/EvictVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/EvictVisitor.java
@@ -1,98 +1,96 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import org.hibernate.HibernateException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.CollectionKey;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.CollectionType;
 
-import org.jboss.logging.Logger;
-
 /**
  * Evict any collections referenced by the object from the session cache.
  * This will NOT pick up any collections that were dereferenced, so they
  * will be deleted (suboptimal but not exactly incorrect).
  *
  * @author Gavin King
  */
 public class EvictVisitor extends AbstractVisitor {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( EvictVisitor.class );
 
 	EvictVisitor(EventSource session) {
 		super(session);
 	}
 
 	@Override
 	Object processCollection(Object collection, CollectionType type) throws HibernateException {
 		if (collection != null) {
 			evictCollection(collection, type);
 		}
 
 		return null;
 	}
 	public void evictCollection(Object value, CollectionType type) {
 		final Object pc;
 		if ( type.hasHolder() ) {
 			pc = getSession().getPersistenceContext().removeCollectionHolder(value);
 		}
 		else if ( value instanceof PersistentCollection ) {
 			pc = value;
 		}
 		else {
 			return; //EARLY EXIT!
 		}
 
 		PersistentCollection collection = (PersistentCollection) pc;
 		if ( collection.unsetSession( getSession() ) ) {
 			evictCollection(collection);
 		}
 	}
 
 	private void evictCollection(PersistentCollection collection) {
 		CollectionEntry ce = (CollectionEntry) getSession().getPersistenceContext().getCollectionEntries().remove(collection);
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Evicting collection: %s",
 					MessageHelper.collectionInfoString( ce.getLoadedPersister(),
 							collection,
 							ce.getLoadedKey(),
 							getSession() ) );
 		}
 		if (ce.getLoadedPersister() != null && ce.getLoadedPersister().getBatchSize() > 1) {
 			getSession().getPersistenceContext().getBatchFetchQueue().removeBatchLoadableCollection(ce);
 		}
 		if ( ce.getLoadedPersister() != null && ce.getLoadedKey() != null ) {
 			//TODO: is this 100% correct?
 			getSession().getPersistenceContext().getCollectionsByKey().remove(
 					new CollectionKey( ce.getLoadedPersister(), ce.getLoadedKey() )
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/spi/EntityCopyObserver.java b/hibernate-core/src/main/java/org/hibernate/event/spi/EntityCopyObserver.java
index a1286fdb7b..3f0d8f93b0 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/spi/EntityCopyObserver.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/spi/EntityCopyObserver.java
@@ -1,56 +1,54 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.spi;
 
-import org.hibernate.event.spi.EventSource;
-
 /**
  * An observer for detection of multiple entity representations for a persistent entity being merged.
  *
  * @author Gail Badner
  */
 public interface EntityCopyObserver {
 
 	/**
 	 * Called when more than one representation of the same persistent entity is being merged.
 	 *
 	 * @param managedEntity The managed entity in the persistence context (the merge result).
 	 * @param mergeEntity1 A managed or detached entity being merged; must be non-null.
 	 * @param mergeEntity2 A different managed or detached entity being merged; must be non-null.
 	 * @param session The session.
 	 */
 	void entityCopyDetected(Object managedEntity, Object mergeEntity1, Object mergeEntity2, EventSource session);
 
 	/**
 	 * Called when the top-level merge operation is complete.
 	 *
 	 * @param session The session
 	 */
 	void topLevelMergeComplete(EventSource session);
 
 	/**
 	 * Called to clear any data stored in this EntityCopyObserver.
 	 */
 	void clear();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/HolderInstantiator.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/HolderInstantiator.java
index afa96d782a..846656f24a 100755
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/HolderInstantiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/HolderInstantiator.java
@@ -1,107 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal;
 import java.lang.reflect.Constructor;
 
 import org.hibernate.transform.AliasToBeanConstructorResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.transform.Transformers;
 
 /**
  * @author Gavin King
  */
 public final class HolderInstantiator {
 		
 	public static final HolderInstantiator NOOP_INSTANTIATOR = new HolderInstantiator(null,null);
 	
 	private final ResultTransformer transformer;
 	private final String[] queryReturnAliases;
 	
 	public static HolderInstantiator getHolderInstantiator(ResultTransformer selectNewTransformer, ResultTransformer customTransformer, String[] queryReturnAliases) {
 		return new HolderInstantiator(
 				resolveResultTransformer( selectNewTransformer, customTransformer ),
 				queryReturnAliases
 		);
 	}
 
 	public static ResultTransformer resolveResultTransformer(ResultTransformer selectNewTransformer, ResultTransformer customTransformer) {
 		return selectNewTransformer != null ? selectNewTransformer : customTransformer;
 	}	
 
 	public static ResultTransformer createSelectNewTransformer(Constructor constructor, boolean returnMaps, boolean returnLists) {
 		if ( constructor != null ) {
 			return new AliasToBeanConstructorResultTransformer(constructor);
 		}
 		else if ( returnMaps ) {
 			return Transformers.ALIAS_TO_ENTITY_MAP;			
 		}
 		else if ( returnLists ) {
 			return Transformers.TO_LIST;
 		}		
 		else {
 			return null;
 		}
 	}
 	
 	static public HolderInstantiator createClassicHolderInstantiator(Constructor constructor, 
 			ResultTransformer transformer) {
 		return new HolderInstantiator( resolveClassicResultTransformer( constructor, transformer ), null );
 	}
 
 	static public ResultTransformer resolveClassicResultTransformer(
 			Constructor constructor,
 			ResultTransformer transformer) {
 		return constructor != null ? new AliasToBeanConstructorResultTransformer( constructor ) : transformer;
 	}	
 
-	public HolderInstantiator( 
-			ResultTransformer transformer,
-			String[] queryReturnAliases
-	) {
+	public HolderInstantiator(ResultTransformer transformer, String[] queryReturnAliases) {
 		this.transformer = transformer;		
 		this.queryReturnAliases = queryReturnAliases;
 	}
 	
 	public boolean isRequired() {
 		return transformer!=null;
 	}
 	
 	public Object instantiate(Object[] row) {
-		if(transformer==null) {
+		if (transformer==null) {
 			return row;
-		} else {
+		}
+		else {
 			return transformer.transformTuple(row, queryReturnAliases);
 		}
 	}	
 	
 	public String[] getQueryReturnAliases() {
 		return queryReturnAliases;
 	}
 
 	public ResultTransformer getResultTransformer() {
 		return transformer;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/QueryTranslatorFactoryInitiator.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/QueryTranslatorFactoryInitiator.java
index c8144e32d4..b91c93d2ee 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/QueryTranslatorFactoryInitiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/QueryTranslatorFactoryInitiator.java
@@ -1,78 +1,74 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal;
 
 import java.util.Map;
 
-import org.hibernate.HibernateException;
 import org.hibernate.boot.registry.StandardServiceInitiator;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.hql.internal.ast.ASTQueryTranslatorFactory;
 import org.hibernate.hql.spi.QueryTranslatorFactory;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 
-import org.jboss.logging.Logger;
-
 import static org.hibernate.cfg.AvailableSettings.QUERY_TRANSLATOR;
 
 /**
  * Initiator for the QueryTranslatorFactory service
  *
  * @author Steve Ebersole
  */
 public class QueryTranslatorFactoryInitiator implements StandardServiceInitiator<QueryTranslatorFactory> {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( QueryTranslatorFactoryInitiator.class );
 
 	/**
 	 * Singleton access
 	 */
 	public static final QueryTranslatorFactoryInitiator INSTANCE = new QueryTranslatorFactoryInitiator();
 
 	@Override
 	public QueryTranslatorFactory initiateService(
 			Map configurationValues,
 			ServiceRegistryImplementor registry) {
 		final StrategySelector strategySelector = registry.getService( StrategySelector.class );
 		final QueryTranslatorFactory factory = strategySelector.resolveDefaultableStrategy(
 				QueryTranslatorFactory.class,
 				configurationValues.get( QUERY_TRANSLATOR ),
 				ASTQueryTranslatorFactory.INSTANCE
 		);
 
 		log.debugf( "QueryTranslatorFactory : %s", factory );
 		if ( factory instanceof ASTQueryTranslatorFactory ) {
 			log.usingAstQueryTranslatorFactory();
 		}
 
 		return factory;
 	}
 
 	@Override
 	public Class<QueryTranslatorFactory> getServiceInitiated() {
 		return QueryTranslatorFactory.class;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromClause.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromClause.java
index 4978690fce..73625b1791 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromClause.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromClause.java
@@ -1,412 +1,411 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.HashMap;
 import java.util.HashSet;
-import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ASTIterator;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents the 'FROM' part of a query or subquery, containing all mapped class references.
  *
  * @author josh
  */
 public class FromClause extends HqlSqlWalkerNode implements HqlSqlTokenTypes, DisplayableNode {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( FromClause.class );
 
 	public static final int ROOT_LEVEL = 1;
 
 	private int level = ROOT_LEVEL;
 	private Set<FromElement> fromElements = new HashSet<FromElement>();
 	private Map<String,FromElement> fromElementByClassAlias = new HashMap<String,FromElement>();
 	private Map<String,FromElement> fromElementByTableAlias = new HashMap<String,FromElement>();
 	private Map<String,FromElement> fromElementsByPath = new HashMap<String,FromElement>();
 
 	/**
 	 * All of the implicit FROM xxx JOIN yyy elements that are the destination of a collection.  These are created from
 	 * index operators on collection property references.
 	 */
 	private Map collectionJoinFromElementsByPath = new HashMap();
 	/**
 	 * Pointer to the parent FROM clause, if there is one.
 	 */
 	private FromClause parentFromClause;
 	/**
 	 * Collection of FROM clauses of which this is the parent.
 	 */
 	private Set<FromClause> childFromClauses;
 	/**
 	 * Counts the from elements as they are added.
 	 */
 	private int fromElementCounter;
 	/**
 	 * Implied FROM elements to add onto the end of the FROM clause.
 	 */
 	private List impliedElements = new LinkedList();
 
 	/**
 	 * Adds a new from element to the from node.
 	 *
 	 * @param path The reference to the class.
 	 * @param alias The alias AST.
 	 *
 	 * @return FromElement - The new FROM element.
 	 */
 	public FromElement addFromElement(String path, AST alias) throws SemanticException {
 		// The path may be a reference to an alias defined in the parent query.
 		String classAlias = ( alias == null ) ? null : alias.getText();
 		checkForDuplicateClassAlias( classAlias );
 		FromElementFactory factory = new FromElementFactory( this, null, path, classAlias, null, false );
 		return factory.addFromElement();
 	}
 
 	void registerFromElement(FromElement element) {
 		fromElements.add( element );
 		String classAlias = element.getClassAlias();
 		if ( classAlias != null ) {
 			// The HQL class alias refers to the class name.
 			fromElementByClassAlias.put( classAlias, element );
 		}
 		// Associate the table alias with the element.
 		String tableAlias = element.getTableAlias();
 		if ( tableAlias != null ) {
 			fromElementByTableAlias.put( tableAlias, element );
 		}
 	}
 
 	void addDuplicateAlias(String alias, FromElement element) {
 		if ( alias != null ) {
 			fromElementByClassAlias.put( alias, element );
 		}
 	}
 
 	private void checkForDuplicateClassAlias(String classAlias) throws SemanticException {
 		if ( classAlias != null && fromElementByClassAlias.containsKey( classAlias ) ) {
 			throw new SemanticException( "Duplicate definition of alias '" + classAlias + "'" );
 		}
 	}
 
 	/**
 	 * Retreives the from-element represented by the given alias.
 	 *
 	 * @param aliasOrClassName The alias by which to locate the from-element.
 	 *
 	 * @return The from-element assigned the given alias, or null if none.
 	 */
 	public FromElement getFromElement(String aliasOrClassName) {
 		FromElement fromElement = fromElementByClassAlias.get( aliasOrClassName );
 		if ( fromElement == null && getSessionFactoryHelper().isStrictJPAQLComplianceEnabled() ) {
 			fromElement = findIntendedAliasedFromElementBasedOnCrazyJPARequirements( aliasOrClassName );
 		}
 		if ( fromElement == null && parentFromClause != null ) {
 			fromElement = parentFromClause.getFromElement( aliasOrClassName );
 		}
 		return fromElement;
 	}
 
 	public FromElement findFromElementBySqlAlias(String sqlAlias) {
 		FromElement fromElement = fromElementByTableAlias.get( sqlAlias );
 		if ( fromElement == null && parentFromClause != null ) {
 			fromElement = parentFromClause.getFromElement( sqlAlias );
 		}
 		return fromElement;
 	}
 
 	public FromElement findFromElementByUserOrSqlAlias(String userAlias, String sqlAlias) {
 		FromElement fromElement = null;
 		if ( userAlias != null ) {
 			fromElement = getFromElement( userAlias );
 		}
 
 		if ( fromElement == null ) {
 			fromElement = findFromElementBySqlAlias( sqlAlias );
 		}
 
 		return fromElement;
 	}
 
 	private FromElement findIntendedAliasedFromElementBasedOnCrazyJPARequirements(String specifiedAlias) {
 		for ( Map.Entry<String, FromElement> entry : fromElementByClassAlias.entrySet() ) {
 			final String alias = entry.getKey();
 			if ( alias.equalsIgnoreCase( specifiedAlias ) ) {
 				return entry.getValue();
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Convenience method to check whether a given token represents a from-element alias.
 	 *
 	 * @param possibleAlias The potential from-element alias to check.
 	 *
 	 * @return True if the possibleAlias is an alias to a from-element visible
 	 *         from this point in the query graph.
 	 */
 	public boolean isFromElementAlias(String possibleAlias) {
 		boolean isAlias = containsClassAlias( possibleAlias );
 		if ( !isAlias && parentFromClause != null ) {
 			// try the parent FromClause...
 			isAlias = parentFromClause.isFromElementAlias( possibleAlias );
 		}
 		return isAlias;
 	}
 
 	/**
 	 * Returns the list of from elements in order.
 	 *
 	 * @return the list of from elements (instances of FromElement).
 	 */
 	public List getFromElements() {
 		return ASTUtil.collectChildren( this, fromElementPredicate );
 	}
 
 	public FromElement getFromElement() {
 		// TODO: not sure about this one
 //		List fromElements = getFromElements();
 //		if ( fromElements == null || fromElements.isEmpty() ) {
 //			throw new QueryException( "Unable to locate from element" );
 //		}
 		return (FromElement) getFromElements().get( 0 );
 	}
 
 	/**
 	 * Returns the list of from elements that will be part of the result set.
 	 *
 	 * @return the list of from elements that will be part of the result set.
 	 */
 	public List getProjectionList() {
 		return ASTUtil.collectChildren( this, projectionListPredicate );
 	}
 
 	public List getCollectionFetches() {
 		return ASTUtil.collectChildren( this, collectionFetchPredicate );
 	}
 
 	public boolean hasCollectionFecthes() {
 		return getCollectionFetches().size() > 0;
 	}
 
 	public List getExplicitFromElements() {
 		return ASTUtil.collectChildren( this, explicitFromPredicate );
 	}
 
 	private static ASTUtil.FilterPredicate fromElementPredicate = new ASTUtil.IncludePredicate() {
 		@Override
 		public boolean include(AST node) {
 			FromElement fromElement = (FromElement) node;
 			return fromElement.isFromOrJoinFragment();
 		}
 	};
 
 	private static ASTUtil.FilterPredicate projectionListPredicate = new ASTUtil.IncludePredicate() {
 		@Override
 		public boolean include(AST node) {
 			FromElement fromElement = (FromElement) node;
 			return fromElement.inProjectionList();
 		}
 	};
 
 	private static ASTUtil.FilterPredicate collectionFetchPredicate = new ASTUtil.IncludePredicate() {
 		@Override
 		public boolean include(AST node) {
 			FromElement fromElement = (FromElement) node;
 			return fromElement.isFetch() && fromElement.getQueryableCollection() != null;
 		}
 	};
 
 	private static ASTUtil.FilterPredicate explicitFromPredicate = new ASTUtil.IncludePredicate() {
 		@Override
 		public boolean include(AST node) {
 			final FromElement fromElement = (FromElement) node;
 			return !fromElement.isImplied();
 		}
 	};
 
 	FromElement findCollectionJoin(String path) {
 		return (FromElement) collectionJoinFromElementsByPath.get( path );
 	}
 
 	/**
 	 * Look for an existing implicit or explicit join by the
 	 * given path.
 	 */
 	FromElement findJoinByPath(String path) {
 		FromElement elem = findJoinByPathLocal( path );
 		if ( elem == null && parentFromClause != null ) {
 			elem = parentFromClause.findJoinByPath( path );
 		}
 		return elem;
 	}
 
 	FromElement findJoinByPathLocal(String path) {
 		Map joinsByPath = fromElementsByPath;
 		return (FromElement) joinsByPath.get( path );
 	}
 
 	void addJoinByPathMap(String path, FromElement destination) {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "addJoinByPathMap() : %s -> %s", path, destination.getDisplayText() );
 		}
 		fromElementsByPath.put( path, destination );
 	}
 
 	/**
 	 * Returns true if the from node contains the class alias name.
 	 *
 	 * @param alias The HQL class alias name.
 	 *
 	 * @return true if the from node contains the class alias name.
 	 */
 	public boolean containsClassAlias(String alias) {
 		boolean isAlias = fromElementByClassAlias.containsKey( alias );
 		if ( !isAlias && getSessionFactoryHelper().isStrictJPAQLComplianceEnabled() ) {
 			isAlias = findIntendedAliasedFromElementBasedOnCrazyJPARequirements( alias ) != null;
 		}
 		return isAlias;
 	}
 
 	/**
 	 * Returns true if the from node contains the table alias name.
 	 *
 	 * @param alias The SQL table alias name.
 	 *
 	 * @return true if the from node contains the table alias name.
 	 */
 	public boolean containsTableAlias(String alias) {
 		return fromElementByTableAlias.keySet().contains( alias );
 	}
 
 	public String getDisplayText() {
 		return "FromClause{" +
 				"level=" + level +
 				", fromElementCounter=" + fromElementCounter +
 				", fromElements=" + fromElements.size() +
 				", fromElementByClassAlias=" + fromElementByClassAlias.keySet() +
 				", fromElementByTableAlias=" + fromElementByTableAlias.keySet() +
 				", fromElementsByPath=" + fromElementsByPath.keySet() +
 				", collectionJoinFromElementsByPath=" + collectionJoinFromElementsByPath.keySet() +
 				", impliedElements=" + impliedElements +
 				"}";
 	}
 
 	public void setParentFromClause(FromClause parentFromClause) {
 		this.parentFromClause = parentFromClause;
 		if ( parentFromClause != null ) {
 			level = parentFromClause.getLevel() + 1;
 			parentFromClause.addChild( this );
 		}
 	}
 
 	private void addChild(FromClause fromClause) {
 		if ( childFromClauses == null ) {
 			childFromClauses = new HashSet<FromClause>();
 		}
 		childFromClauses.add( fromClause );
 	}
 
 	public FromClause locateChildFromClauseWithJoinByPath(String path) {
 		if ( childFromClauses != null && !childFromClauses.isEmpty() ) {
 			for ( FromClause child : childFromClauses ) {
 				if ( child.findJoinByPathLocal( path ) != null ) {
 					return child;
 				}
 			}
 		}
 		return null;
 	}
 
 	public void promoteJoin(FromElement elem) {
 		LOG.debugf( "Promoting [%s] to [%s]", elem, this );
 		//TODO: implement functionality
 		//  this might be painful to do here, as the "join post processing" for
 		//  the subquery has already been performed (meaning that for
 		//  theta-join dialects, the join conditions have already been moved
 		//  over to the where clause).  A "simple" solution here might to
 		//  doAfterTransactionCompletion "join post processing" once for the entire query (including
 		//  any subqueries) at one fell swoop
 	}
 
 	public boolean isSubQuery() {
 		// TODO : this is broke for subqueries in statements other than selects...
 		return parentFromClause != null;
 	}
 
 	void addCollectionJoinFromElementByPath(String path, FromElement destination) {
 		LOG.debugf( "addCollectionJoinFromElementByPath() : %s -> %s", path, destination );
 		collectionJoinFromElementsByPath.put(
 				path,
 				destination
 		);    // Add the new node to the map so that we don't create it twice.
 	}
 
 	public FromClause getParentFromClause() {
 		return parentFromClause;
 	}
 
 	public int getLevel() {
 		return level;
 	}
 
 	public int nextFromElementCounter() {
 		return fromElementCounter++;
 	}
 
 	public void resolve() {
 		// Make sure that all from elements registered with this FROM clause are actually in the AST.
 		ASTIterator iter = new ASTIterator( this.getFirstChild() );
 		Set childrenInTree = new HashSet();
 		while ( iter.hasNext() ) {
 			childrenInTree.add( iter.next() );
 		}
 		for ( FromElement fromElement : fromElements ) {
 			if ( !childrenInTree.contains( fromElement ) ) {
 				throw new IllegalStateException( "Element not in AST: " + fromElement );
 			}
 		}
 	}
 
 	public void addImpliedFromElement(FromElement element) {
 		impliedElements.add( element );
 	}
 
 	@Override
 	public String toString() {
 		return "FromClause{level=" + level + "}";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
index eb96909c44..316a8f0670 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
@@ -1,706 +1,711 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.TypeDiscriminatorMetadata;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.DiscriminatorMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Represents a single mapped class mentioned in an HQL FROM clause.  Each
  * class reference will have the following symbols:
  * <ul>
  * <li>A class name - This is the name of the Java class that is mapped by Hibernate.</li>
  * <li>[optional] an HQL alias for the mapped class.</li>
  * <li>A table name - The name of the table that is mapped to the Java class.</li>
  * <li>A table alias - The alias for the table that will be used in the resulting SQL.</li>
  * </ul>
  *
  * @author josh
  */
 public class FromElement extends HqlSqlWalkerNode implements DisplayableNode, ParameterContainer {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( FromElement.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( FromElement.class );
 
 	private String className;
 	private String classAlias;
 	private String tableAlias;
 	private String collectionTableAlias;
 	private FromClause fromClause;
 	private boolean includeSubclasses = true;
 	private boolean collectionJoin;
 	private FromElement origin;
 	private String[] columns;
 	private String role;
 	private boolean fetch;
 	private boolean isAllPropertyFetch;
 	private boolean filter;
 	private int sequence = -1;
 	private boolean useFromFragment;
 	private boolean initialized;
 	private FromElementType elementType;
 	private boolean useWhereFragment = true;
 	private List destinations = new LinkedList();
 	private boolean manyToMany;
 	private String withClauseFragment;
 	private String withClauseJoinAlias;
 	private boolean dereferencedBySuperclassProperty;
 	private boolean dereferencedBySubclassProperty;
 
 	public FromElement() {
 	}
 
 	/**
 	 * Constructor form used to initialize {@link ComponentJoin}
 	 *
 	 * @param fromClause The FROM clause to which this element belongs
 	 * @param origin The origin (LHS) of this element
 	 * @param alias The alias applied to this element
 	 */
 	protected FromElement(
 			FromClause fromClause,
 			FromElement origin,
 			String alias) {
 		this.fromClause = fromClause;
 		this.origin = origin;
 		this.classAlias = alias;
 		this.tableAlias = origin.getTableAlias();
 		super.initialize( fromClause.getWalker() );
 
 	}
 
 	protected void initializeComponentJoin(FromElementType elementType) {
 		fromClause.registerFromElement( this );
 		elementType.applyTreatAsDeclarations( getWalker().getTreatAsDeclarationsByPath( classAlias ) );
 		this.elementType = elementType;
 		initialized = true;
 	}
 
 	public String getCollectionSuffix() {
 		return elementType.getCollectionSuffix();
 	}
 
 	public void setCollectionSuffix(String suffix) {
 		elementType.setCollectionSuffix(suffix);
 	}
 
 	public void initializeCollection(FromClause fromClause, String classAlias, String tableAlias) {
 		doInitialize( fromClause, tableAlias, null, classAlias, null, null );
 		initialized = true;
 	}
 
 	public void initializeEntity(
-	        FromClause fromClause,
-	        String className,
-	        EntityPersister persister,
-	        EntityType type,
-	        String classAlias,
-	        String tableAlias) {
+			FromClause fromClause,
+			String className,
+			EntityPersister persister,
+			EntityType type,
+			String classAlias,
+			String tableAlias) {
 		doInitialize( fromClause, tableAlias, className, classAlias, persister, type );
 		this.sequence = fromClause.nextFromElementCounter();
 		initialized = true;
 	}
 
-	private void doInitialize(FromClause fromClause, String tableAlias, String className, String classAlias,
-							  EntityPersister persister, EntityType type) {
+	private void doInitialize(
+			FromClause fromClause,
+			String tableAlias,
+			String className,
+			String classAlias,
+			EntityPersister persister,
+			EntityType type) {
 		if ( initialized ) {
 			throw new IllegalStateException( "Already initialized!!" );
 		}
 		this.fromClause = fromClause;
 		this.tableAlias = tableAlias;
 		this.className = className;
 		this.classAlias = classAlias;
 		this.elementType = new FromElementType( this, persister, type );
 		// Register the FromElement with the FROM clause, now that we have the names and aliases.
 		fromClause.registerFromElement( this );
 		LOG.debugf( "%s : %s (%s) -> %s", fromClause, className, classAlias == null ? "<no alias>" : classAlias, tableAlias );
 	}
 
 	public EntityPersister getEntityPersister() {
 		return elementType.getEntityPersister();
 	}
 
 	@Override
-    public Type getDataType() {
+	public Type getDataType() {
 		return elementType.getDataType();
 	}
 
 	public Type getSelectType() {
 		return elementType.getSelectType();
 	}
 
 	public Queryable getQueryable() {
 		return elementType.getQueryable();
 	}
 
 	public String getClassName() {
 		return className;
 	}
 
 	public String getClassAlias() {
 		return classAlias;
 		//return classAlias == null ? className : classAlias;
 	}
 
 	private String getTableName() {
 		Queryable queryable = getQueryable();
 		return ( queryable != null ) ? queryable.getTableName() : "{none}";
 	}
 
 	public String getTableAlias() {
 		return tableAlias;
 	}
 
 	/**
 	 * Render the identifier select, but in a 'scalar' context (i.e. generate the column alias).
 	 *
 	 * @param i the sequence of the returned type
 	 * @return the identifier select with the column alias.
 	 */
 	String renderScalarIdentifierSelect(int i) {
 		return elementType.renderScalarIdentifierSelect( i );
 	}
 
 	void checkInitialized() {
 		if ( !initialized ) {
 			throw new IllegalStateException( "FromElement has not been initialized!" );
 		}
 	}
 
 	/**
 	 * Returns the identifier select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the identifier select SQL fragment.
 	 */
 	String renderIdentifierSelect(int size, int k) {
 		return elementType.renderIdentifierSelect( size, k );
 	}
 
 	/**
 	 * Returns the property select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the property select SQL fragment.
 	 */
 	String renderPropertySelect(int size, int k) {
 		return elementType.renderPropertySelect( size, k, isAllPropertyFetch );
 	}
 
 	String renderCollectionSelectFragment(int size, int k) {
 		return elementType.renderCollectionSelectFragment( size, k );
 	}
 
 	String renderValueCollectionSelectFragment(int size, int k) {
 		return elementType.renderValueCollectionSelectFragment( size, k );
 	}
 
 	public FromClause getFromClause() {
 		return fromClause;
 	}
 
 	/**
 	 * Returns true if this FromElement was implied by a path, or false if this FROM element is explicitly declared in
 	 * the FROM clause.
 	 *
 	 * @return true if this FromElement was implied by a path, or false if this FROM element is explicitly declared
 	 */
 	public boolean isImplied() {
 		return false;	// This is an explicit FROM element.
 	}
 
 	/**
 	 * Returns additional display text for the AST node.
 	 *
 	 * @return String - The additional display text.
 	 */
 	public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 		buf.append( "FromElement{" );
 		appendDisplayText( buf );
 		buf.append( "}" );
 		return buf.toString();
 	}
 
 	protected void appendDisplayText(StringBuilder buf) {
 		buf.append( isImplied() ? (
 				isImpliedInFromClause() ? "implied in FROM clause" : "implied" )
 				: "explicit" );
 		buf.append( "," ).append( isCollectionJoin() ? "collection join" : "not a collection join" );
 		buf.append( "," ).append( fetch ? "fetch join" : "not a fetch join" );
 		buf.append( "," ).append( isAllPropertyFetch ? "fetch all properties" : "fetch non-lazy properties" );
 		buf.append( ",classAlias=" ).append( getClassAlias() );
 		buf.append( ",role=" ).append( role );
 		buf.append( ",tableName=" ).append( getTableName() );
 		buf.append( ",tableAlias=" ).append( getTableAlias() );
 		FromElement origin = getRealOrigin();
 		buf.append( ",origin=" ).append( origin == null ? "null" : origin.getText() );
 		buf.append( ",columns={" );
 		if ( columns != null ) {
 			for ( int i = 0; i < columns.length; i++ ) {
 				buf.append( columns[i] );
 				if ( i < columns.length ) {
 					buf.append( " " );
 				}
 			}
 		}
 		buf.append( ",className=" ).append( className );
 		buf.append( "}" );
 	}
 
 	@Override
-    public int hashCode() {
+	public int hashCode() {
 		return super.hashCode();
 	}
 
 	@Override
-    public boolean equals(Object obj) {
+	public boolean equals(Object obj) {
 		return super.equals( obj );
 	}
 
 
 	public void setJoinSequence(JoinSequence joinSequence) {
 		elementType.setJoinSequence( joinSequence );
 	}
 
 	public JoinSequence getJoinSequence() {
 		return elementType.getJoinSequence();
 	}
 
 	public void setIncludeSubclasses(boolean includeSubclasses) {
 		if ( !includeSubclasses && isDereferencedBySuperclassOrSubclassProperty() && LOG.isTraceEnabled() ) {
 			LOG.trace( "Attempt to disable subclass-inclusions : ", new Exception( "Stack-trace source" ) );
 		}
 		this.includeSubclasses = includeSubclasses;
 	}
 
 	public boolean isIncludeSubclasses() {
 		return includeSubclasses;
 	}
 
 	public boolean isDereferencedBySuperclassOrSubclassProperty() {
 		return dereferencedBySubclassProperty || dereferencedBySuperclassProperty;
 	}
 
 	public String getIdentityColumn() {
 		final String[] cols = getIdentityColumns();
 		if ( cols.length == 1 ) {
 			return cols[0];
 		}
 		else {
 			return "(" + StringHelper.join( ", ", cols ) + ")";
 		}
 	}
 
 	public String[] getIdentityColumns() {
 		checkInitialized();
 		final String table = getTableAlias();
 		if ( table == null ) {
 			throw new IllegalStateException( "No table alias for node " + this );
 		}
 
 		final String propertyName;
 		if ( getEntityPersister() != null && getEntityPersister().getEntityMetamodel() != null
 				&& getEntityPersister().getEntityMetamodel().hasNonIdentifierPropertyNamedId() ) {
 			propertyName = getEntityPersister().getIdentifierPropertyName();
 		}
 		else {
 			propertyName = EntityPersister.ENTITY_ID;
 		}
 
 		if ( getWalker().getStatementType() == HqlSqlTokenTypes.SELECT ) {
 			return getPropertyMapping( propertyName ).toColumns( table, propertyName );
 		}
 		else {
 			return getPropertyMapping( propertyName ).toColumns( propertyName );
 		}
 	}
 
 	public void setCollectionJoin(boolean collectionJoin) {
 		this.collectionJoin = collectionJoin;
 	}
 
 	public boolean isCollectionJoin() {
 		return collectionJoin;
 	}
 
 	public void setRole(String role) {
 		this.role = role;
 		applyTreatAsDeclarations( getWalker().getTreatAsDeclarationsByPath( role ) );
 	}
 
 	public void applyTreatAsDeclarations(Set<String> treatAsDeclarationsByPath) {
 		elementType.applyTreatAsDeclarations( treatAsDeclarationsByPath );
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public void setQueryableCollection(QueryableCollection queryableCollection) {
 		elementType.setQueryableCollection( queryableCollection );
 	}
 
 	public QueryableCollection getQueryableCollection() {
 		return elementType.getQueryableCollection();
 	}
 
 	public void setColumns(String[] columns) {
 		this.columns = columns;
 	}
 
 	public void setOrigin(FromElement origin, boolean manyToMany) {
 		this.origin = origin;
 		this.manyToMany = manyToMany;
 		origin.addDestination( this );
 		if ( origin.getFromClause() == this.getFromClause() ) {
 			// TODO: Figure out a better way to get the FROM elements in a proper tree structure.
 			// If this is not the destination of a many-to-many, add it as a child of the origin.
 			if ( manyToMany ) {
 				ASTUtil.appendSibling( origin, this );
 			}
 			else {
 				if ( !getWalker().isInFrom() && !getWalker().isInSelect() && !getWalker().isInEntityGraph()) {
 					getFromClause().addChild( this );
 				}
 				else {
 					origin.addChild( this );
 				}
 			}
 		}
 		else if ( !getWalker().isInFrom() ) {
 			// HHH-276 : implied joins in a subselect where clause - The destination needs to be added
 			// to the destination's from clause.
 			getFromClause().addChild( this );	// Not sure if this is will fix everything, but it works.
 		}
 		else {
 			// Otherwise, the destination node was implied by the FROM clause and the FROM clause processor
 			// will automatically add it in the right place.
 		}
 	}
 
 	public boolean isManyToMany() {
 		return manyToMany;
 	}
 
 	private void addDestination(FromElement fromElement) {
 		destinations.add( fromElement );
 	}
 
 	public List getDestinations() {
 		return destinations;
 	}
 
 	public FromElement getOrigin() {
 		return origin;
 	}
 
 	public FromElement getRealOrigin() {
 		if ( origin == null ) {
 			return null;
 		}
 		if ( origin.getText() == null || "".equals( origin.getText() ) ) {
 			return origin.getRealOrigin();
 		}
 		return origin;
 	}
 
 	public static final String DISCRIMINATOR_PROPERTY_NAME = "class";
 	private TypeDiscriminatorMetadata typeDiscriminatorMetadata;
 
 	private static class TypeDiscriminatorMetadataImpl implements TypeDiscriminatorMetadata {
 		private final DiscriminatorMetadata persisterDiscriminatorMetadata;
 		private final String alias;
 
 		private TypeDiscriminatorMetadataImpl(
 				DiscriminatorMetadata persisterDiscriminatorMetadata,
 				String alias) {
 			this.persisterDiscriminatorMetadata = persisterDiscriminatorMetadata;
 			this.alias = alias;
 		}
 
 		@Override
 		public String getSqlFragment() {
 			return persisterDiscriminatorMetadata.getSqlFragment( alias );
 		}
 
 		@Override
 		public Type getResolutionType() {
 			return persisterDiscriminatorMetadata.getResolutionType();
 		}
 	}
 
 	public TypeDiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( typeDiscriminatorMetadata == null ) {
 			typeDiscriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return typeDiscriminatorMetadata;
 	}
 
 	private TypeDiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		final String aliasToUse = getTableAlias();
 		Queryable queryable = getQueryable();
 		if ( queryable == null ) {
 			QueryableCollection collection = getQueryableCollection();
 			if ( ! collection.getElementType().isEntityType() ) {
 				throw new QueryException( "type discrimination cannot be applied to value collection [" + collection.getRole() + "]" );
 			}
 			queryable = (Queryable) collection.getElementPersister();
 		}
 
 		handlePropertyBeingDereferenced( getDataType(), DISCRIMINATOR_PROPERTY_NAME );
 
 		return new TypeDiscriminatorMetadataImpl( queryable.getTypeDiscriminatorMetadata(), aliasToUse );
 	}
 
 	public Type getPropertyType(String propertyName, String propertyPath) {
 		return elementType.getPropertyType( propertyName, propertyPath );
 	}
 
 	public String[] toColumns(String tableAlias, String path, boolean inSelect) {
 		return elementType.toColumns( tableAlias, path, inSelect );
 	}
 
 	public String[] toColumns(String tableAlias, String path, boolean inSelect, boolean forceAlias) {
 		return elementType.toColumns( tableAlias, path, inSelect, forceAlias );
 	}
 
 	public PropertyMapping getPropertyMapping(String propertyName) {
 		return elementType.getPropertyMapping( propertyName );
 	}
 
 	public void setFetch(boolean fetch) {
 		this.fetch = fetch;
 		// Fetch can't be used with scroll() or iterate().
 		if ( fetch && getWalker().isShallowQuery() ) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_FETCH_WITH_ITERATE );
 		}
 	}
 
 	public boolean isFetch() {
 		return fetch;
 	}
 
 	public int getSequence() {
 		return sequence;
 	}
 
 	public void setFilter(boolean b) {
 		filter = b;
 	}
 
 	public boolean isFilter() {
 		return filter;
 	}
 
 	public boolean useFromFragment() {
 		checkInitialized();
 		// If it's not implied or it is implied and it's a many to many join where the target wasn't found.
 		return !isImplied() || this.useFromFragment;
 	}
 
 	public void setUseFromFragment(boolean useFromFragment) {
 		this.useFromFragment = useFromFragment;
 	}
 
 	public boolean useWhereFragment() {
 		return useWhereFragment;
 	}
 
 	public void setUseWhereFragment(boolean b) {
 		useWhereFragment = b;
 	}
 
 
 	public void setCollectionTableAlias(String collectionTableAlias) {
 		this.collectionTableAlias = collectionTableAlias;
 	}
 
 	public String getCollectionTableAlias() {
 		return collectionTableAlias;
 	}
 
 	public boolean isCollectionOfValuesOrComponents() {
 		return elementType.isCollectionOfValuesOrComponents();
 	}
 
 	public boolean isEntity() {
 		return elementType.isEntity();
 	}
 
 	public void setImpliedInFromClause(boolean flag) {
 		throw new UnsupportedOperationException( "Explicit FROM elements can't be implied in the FROM clause!" );
 	}
 
 	public boolean isImpliedInFromClause() {
 		return false;	// Since this is an explicit FROM element, it can't be implied in the FROM clause.
 	}
 
 	public void setInProjectionList(boolean inProjectionList) {
 		// Do nothing, eplicit from elements are *always* in the projection list.
 	}
 
 	public boolean inProjectionList() {
 		return !isImplied() && isFromOrJoinFragment();
 	}
 
 	public boolean isFromOrJoinFragment() {
 		return getType() == SqlTokenTypes.FROM_FRAGMENT || getType() == SqlTokenTypes.JOIN_FRAGMENT;
 	}
 
 	public boolean isAllPropertyFetch() {
 		return isAllPropertyFetch;
 	}
 
 	public void setAllPropertyFetch(boolean fetch) {
 		isAllPropertyFetch = fetch;
 	}
 
 	public String getWithClauseFragment() {
 		return withClauseFragment;
 	}
 
 	public String getWithClauseJoinAlias() {
 		return withClauseJoinAlias;
 	}
 
 	public void setWithClauseFragment(String withClauseJoinAlias, String withClauseFragment) {
 		this.withClauseJoinAlias = withClauseJoinAlias;
 		this.withClauseFragment = withClauseFragment;
 	}
 
 	public boolean hasCacheablePersister() {
 		if ( getQueryableCollection() != null ) {
 			return getQueryableCollection().hasCache();
 		}
 		else {
 			return getQueryable().hasCache();
 		}
 	}
 
 	public void handlePropertyBeingDereferenced(Type propertySource, String propertyName) {
 		if ( getQueryableCollection() != null && CollectionProperties.isCollectionProperty( propertyName ) ) {
 			// propertyName refers to something like collection.size...
 			return;
 		}
 		if ( propertySource.isComponentType() ) {
 			// property name is a sub-path of a component...
 			return;
 		}
 
 		Queryable persister = getQueryable();
 		if ( persister != null ) {
 			try {
 				Queryable.Declarer propertyDeclarer = persister.getSubclassPropertyDeclarer( propertyName );
 				if ( LOG.isTraceEnabled() ) {
 					LOG.tracev( "Handling property dereference [{0} ({1}) -> {2} ({3})]",
 							persister.getEntityName(), getClassAlias(), propertyName, propertyDeclarer );
 				}
 				if ( propertyDeclarer == Queryable.Declarer.SUBCLASS ) {
 					dereferencedBySubclassProperty = true;
 					includeSubclasses = true;
 				}
 				else if ( propertyDeclarer == Queryable.Declarer.SUPERCLASS ) {
 					dereferencedBySuperclassProperty = true;
 				}
 			}
 			catch( QueryException ignore ) {
 				// ignore it; the incoming property could not be found so we
 				// cannot be sure what to do here.  At the very least, the
 				// safest is to simply not apply any dereference toggling...
 
 			}
 		}
 	}
 
 	public boolean isDereferencedBySuperclassProperty() {
 		return dereferencedBySuperclassProperty;
 	}
 
 	public boolean isDereferencedBySubclassProperty() {
 		return dereferencedBySubclassProperty;
 	}
 
 
 	// ParameterContainer impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private List<ParameterSpecification> embeddedParameters;
 
 	@Override
 	public void addEmbeddedParameter(ParameterSpecification specification) {
 		if ( embeddedParameters == null ) {
 			embeddedParameters = new ArrayList<ParameterSpecification>();
 		}
 		embeddedParameters.add( specification );
 	}
 
 	@Override
 	public boolean hasEmbeddedParameters() {
 		return embeddedParameters != null && ! embeddedParameters.isEmpty();
 	}
 
 	@Override
 	public ParameterSpecification[] getEmbeddedParameters() {
 		return embeddedParameters.toArray( new ParameterSpecification[ embeddedParameters.size() ] );
 	}
 
 	public ParameterSpecification getIndexCollectionSelectorParamSpec() {
 		return elementType.getIndexCollectionSelectorParamSpec();
 	}
 
 	public void setIndexCollectionSelectorParamSpec(ParameterSpecification indexCollectionSelectorParamSpec) {
 		if ( indexCollectionSelectorParamSpec == null ) {
 			if ( elementType.getIndexCollectionSelectorParamSpec() != null ) {
 				embeddedParameters.remove( elementType.getIndexCollectionSelectorParamSpec() );
 				elementType.setIndexCollectionSelectorParamSpec( null );
 			}
 		}
 		else {
 			elementType.setIndexCollectionSelectorParamSpec( indexCollectionSelectorParamSpec );
 			addEmbeddedParameter( indexCollectionSelectorParamSpec );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IdentNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IdentNode.java
index 3acabfcef6..657167bba5 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IdentNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IdentNode.java
@@ -1,388 +1,388 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.List;
 
 import org.hibernate.QueryException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ColumnHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.Type;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents an identifier all by itself, which may be a function name,
  * a class alias, or a form of naked property-ref depending on the
  * context.
  *
  * @author josh
  */
 public class IdentNode extends FromReferenceNode implements SelectExpression {
 	private static enum DereferenceType {
 		UNKNOWN,
 		PROPERTY_REF,
 		COMPONENT_REF
 	}
 
 	private boolean nakedPropertyRef;
 
 	public void resolveIndex(AST parent) throws SemanticException {
 		// An ident node can represent an index expression if the ident
 		// represents a naked property ref
 		//      *Note: this makes the assumption (which is currently the case
 		//      in the hql-sql grammar) that the ident is first resolved
 		//      itself (addrExpr -> resolve()).  The other option, if that
 		//      changes, is to call resolve from here; but it is
 		//      currently un-needed overhead.
 		if (!(isResolved() && nakedPropertyRef)) {
 			throw new UnsupportedOperationException();
 		}
 
 		String propertyName = getOriginalText();
 		if (!getDataType().isCollectionType()) {
 			throw new SemanticException("Collection expected; [" + propertyName + "] does not refer to a collection property");
 		}
 
 		// TODO : most of below was taken verbatim from DotNode; should either delegate this logic or super-type it
 		CollectionType type = (CollectionType) getDataType();
 		String role = type.getRole();
 		QueryableCollection queryableCollection = getSessionFactoryHelper().requireQueryableCollection(role);
 
 		String alias = null;  // DotNode uses null here...
 		String columnTableAlias = getFromElement().getTableAlias();
 		JoinType joinType = JoinType.INNER_JOIN;
 		boolean fetch = false;
 
 		FromElementFactory factory = new FromElementFactory(
 				getWalker().getCurrentFromClause(),
 				getFromElement(),
 				propertyName,
 				alias,
 				getFromElement().toColumns(columnTableAlias, propertyName, false),
 				true
 		);
 		FromElement elem = factory.createCollection(queryableCollection, role, joinType, fetch, true);
 		setFromElement(elem);
 		getWalker().addQuerySpaces(queryableCollection.getCollectionSpaces());	// Always add the collection's query spaces.
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin, String classAlias, AST parent) {
 		if (!isResolved()) {
 			if (getWalker().getCurrentFromClause().isFromElementAlias(getText())) {
 				if (resolveAsAlias()) {
 					setResolved();
 					// We represent a from-clause alias
 				}
 			}
 			else if (parent != null && parent.getType() == SqlTokenTypes.DOT) {
 				DotNode dot = (DotNode) parent;
 				if (parent.getFirstChild() == this) {
 					if (resolveAsNakedComponentPropertyRefLHS(dot)) {
 						// we are the LHS of the DOT representing a naked comp-prop-ref
 						setResolved();
 					}
 				}
 				else {
 					if (resolveAsNakedComponentPropertyRefRHS(dot)) {
 						// we are the RHS of the DOT representing a naked comp-prop-ref
 						setResolved();
 					}
 				}
 			}
 			else {
 				DereferenceType result = resolveAsNakedPropertyRef();
 				if (result == DereferenceType.PROPERTY_REF) {
 					// we represent a naked (simple) prop-ref
 					setResolved();
 				}
 				else if (result == DereferenceType.COMPONENT_REF) {
 					// EARLY EXIT!!!  return so the resolve call explicitly coming from DotNode can
 					// resolve this...
 					return;
 				}
 			}
 
 			// if we are still not resolved, we might represent a constant.
 			//      needed to add this here because the allowance of
 			//      naked-prop-refs in the grammar collides with the
 			//      definition of literals/constants ("nondeterminism").
 			//      TODO: cleanup the grammar so that "processConstants" is always just handled from here
 			if (!isResolved()) {
 				try {
 					getWalker().getLiteralProcessor().processConstant(this, false);
 				}
 				catch (Throwable ignore) {
 					// just ignore it for now, it'll get resolved later...
 				}
 			}
 		}
 	}
 
 	private boolean resolveAsAlias() {
 		final String alias = getText();
 
 		// This is not actually a constant, but a reference to FROM element.
 		final FromElement element = getWalker().getCurrentFromClause().getFromElement( alias );
 		if ( element == null ) {
 			return false;
 		}
 
 		element.applyTreatAsDeclarations( getWalker().getTreatAsDeclarationsByPath( alias ) );
 
 		setType( SqlTokenTypes.ALIAS_REF );
 		setFromElement( element );
 
 		String[] columnExpressions = element.getIdentityColumns();
 
 		// determine whether to apply qualification (table alias) to the column(s)...
 		if ( ! isFromElementUpdateOrDeleteRoot( element ) ) {
 			if ( StringHelper.isNotEmpty( element.getTableAlias() ) ) {
 				// apparently we also need to check that they are not already qualified.  Ugh!
 				columnExpressions = StringHelper.qualifyIfNot( element.getTableAlias(), columnExpressions );
 			}
 		}
 
 		final Dialect dialect = getWalker().getSessionFactoryHelper().getFactory().getDialect();
 		final boolean isInCount = getWalker().isInCount();
 		final boolean isInDistinctCount = isInCount && getWalker().isInCountDistinct();
 		final boolean isInNonDistinctCount = isInCount && ! getWalker().isInCountDistinct();
 		final boolean isCompositeValue = columnExpressions.length > 1;
 		if ( isCompositeValue ) {
 			if ( isInNonDistinctCount && ! dialect.supportsTupleCounts() ) {
 				// TODO: #supportsTupleCounts currently false for all Dialects -- could this be cleaned up?
 				setText( columnExpressions[0] );
 			}
 			else {
 				String joinedFragment = StringHelper.join( ", ", columnExpressions );
 				// avoid wrapping in parenthesis (explicit tuple treatment) if possible due to varied support for
 				// tuple syntax across databases..
 				final boolean shouldSkipWrappingInParenthesis =
 						(isInDistinctCount && ! dialect.requiresParensForTupleDistinctCounts())
 						|| isInNonDistinctCount
 						|| getWalker().getCurrentTopLevelClauseType() == HqlSqlTokenTypes.ORDER
 						|| getWalker().getCurrentTopLevelClauseType() == HqlSqlTokenTypes.GROUP;
 				if ( ! shouldSkipWrappingInParenthesis ) {
 					joinedFragment = "(" + joinedFragment + ")";
 				}
 				setText( joinedFragment );
 			}
 			return true;
 		}
 		else if ( columnExpressions.length > 0 ) {
 			setText( columnExpressions[0] );
 			return true;
 		}
 
 		return false;
 	}
 
 	private Type getNakedPropertyType(FromElement fromElement) {
 		if (fromElement == null) {
 			return null;
 		}
 		String property = getOriginalText();
 		Type propertyType = null;
 		try {
 			propertyType = fromElement.getPropertyType(property, property);
 		}
 		catch (Throwable ignore) {
 		}
 		return propertyType;
 	}
 
 	private DereferenceType resolveAsNakedPropertyRef() {
 		FromElement fromElement = locateSingleFromElement();
 		if (fromElement == null) {
 			return DereferenceType.UNKNOWN;
 		}
 		Queryable persister = fromElement.getQueryable();
 		if (persister == null) {
 			return DereferenceType.UNKNOWN;
 		}
 		Type propertyType = getNakedPropertyType(fromElement);
 		if (propertyType == null) {
 			// assume this ident's text does *not* refer to a property on the given persister
 			return DereferenceType.UNKNOWN;
 		}
 
 		if ((propertyType.isComponentType() || propertyType.isAssociationType() )) {
 			return DereferenceType.COMPONENT_REF;
 		}
 
 		setFromElement(fromElement);
 		String property = getText();
 		String[] columns = getWalker().isSelectStatement()
 				? persister.toColumns(fromElement.getTableAlias(), property)
 				: persister.toColumns(property);
 		String text = StringHelper.join(", ", columns);
 		setText(columns.length == 1 ? text : "(" + text + ")");
 		setType(SqlTokenTypes.SQL_TOKEN);
 
 		// these pieces are needed for usage in select clause
 		super.setDataType(propertyType);
 		nakedPropertyRef = true;
 
 		return DereferenceType.PROPERTY_REF;
 	}
 
 	private boolean resolveAsNakedComponentPropertyRefLHS(DotNode parent) {
 		FromElement fromElement = locateSingleFromElement();
 		if (fromElement == null) {
 			return false;
 		}
 
 		Type componentType = getNakedPropertyType(fromElement);
 		if ( componentType == null ) {
 			throw new QueryException( "Unable to resolve path [" + parent.getPath() + "], unexpected token [" + getOriginalText() + "]" );
 		}
 		if (!componentType.isComponentType()) {
 			throw new QueryException("Property '" + getOriginalText() + "' is not a component.  Use an alias to reference associations or collections.");
 		}
 
 		Type propertyType;
 		String propertyPath = getText() + "." + getNextSibling().getText();
 		try {
 			// check to see if our "propPath" actually
 			// represents a property on the persister
 			propertyType = fromElement.getPropertyType(getText(), propertyPath);
 		}
 		catch (Throwable t) {
 			// assume we do *not* refer to a property on the given persister
 			return false;
 		}
 
 		setFromElement(fromElement);
 		parent.setPropertyPath(propertyPath);
 		parent.setDataType(propertyType);
 
 		return true;
 	}
 
 	private boolean resolveAsNakedComponentPropertyRefRHS(DotNode parent) {
 		FromElement fromElement = locateSingleFromElement();
 		if (fromElement == null) {
 			return false;
 		}
 
 		Type propertyType;
 		String propertyPath = parent.getLhs().getText() + "." + getText();
 		try {
 			// check to see if our "propPath" actually
 			// represents a property on the persister
 			propertyType = fromElement.getPropertyType(getText(), propertyPath);
 		}
 		catch (Throwable t) {
 			// assume we do *not* refer to a property on the given persister
 			return false;
 		}
 
 		setFromElement(fromElement);
 		// this piece is needed for usage in select clause
 		super.setDataType(propertyType);
 		nakedPropertyRef = true;
 
 		return true;
 	}
 
 	private FromElement locateSingleFromElement() {
 		List fromElements = getWalker().getCurrentFromClause().getFromElements();
 		if (fromElements == null || fromElements.size() != 1) {
 			// TODO : should this be an error?
 			return null;
 		}
 		FromElement element = (FromElement) fromElements.get(0);
 		if (element.getClassAlias() != null) {
 			// naked property-refs cannot be used with an aliased from element
 			return null;
 		}
 		return element;
 	}
 
 	@Override
-    public Type getDataType() {
+	public Type getDataType() {
 		Type type = super.getDataType();
 		if ( type != null ) {
 			return type;
 		}
 		FromElement fe = getFromElement();
 		if ( fe != null ) {
 			return fe.getDataType();
 		}
 		SQLFunction sf = getWalker().getSessionFactoryHelper().findSQLFunction( getText() );
 		if ( sf != null ) {
 			return sf.getReturnType( null, getWalker().getSessionFactoryHelper().getFactory() );
 		}
 		return null;
 	}
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		if (nakedPropertyRef) {
 			// do *not* over-write the column text, as that has already been
 			// "rendered" during resolve
 			ColumnHelper.generateSingleScalarColumn(this, i);
 		}
 		else {
 			FromElement fe = getFromElement();
 			if (fe != null) {
 				setText(fe.renderScalarIdentifierSelect(i));
 			}
 			else {
 				ColumnHelper.generateSingleScalarColumn(this, i);
 			}
 		}
 	}
 
 	@Override
-    public String getDisplayText() {
+	public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 
 		if (getType() == SqlTokenTypes.ALIAS_REF) {
 			buf.append("{alias=").append(getOriginalText());
 			if (getFromElement() == null) {
 				buf.append(", no from element");
 			}
 			else {
 				buf.append(", className=").append(getFromElement().getClassName());
 				buf.append(", tableAlias=").append(getFromElement().getTableAlias());
 			}
 			buf.append("}");
 		}
 		else {
 			buf.append( "{originalText=" ).append( getOriginalText() ).append( "}" );
 		}
 		return buf.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IntoClause.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IntoClause.java
index 34b79dccde..5303b5495b 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IntoClause.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IntoClause.java
@@ -1,283 +1,283 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.sql.Types;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.Type;
 
 import antlr.collections.AST;
 
 /**
  * Represents an entity referenced in the INTO clause of an HQL
  * INSERT statement.
  *
  * @author Steve Ebersole
  */
 public class IntoClause extends HqlSqlWalkerNode implements DisplayableNode {
 
 	private Queryable persister;
 	private String columnSpec = "";
 	private Type[] types;
 
 	private boolean discriminated;
 	private boolean explicitIdInsertion;
 	private boolean explicitVersionInsertion;
 
 	private Set componentIds;
 	private List explicitComponentIds;
 
 	public void initialize(Queryable persister) {
 		if ( persister.isAbstract() ) {
 			throw new QueryException( "cannot insert into abstract class (no table)" );
 		}
 		this.persister = persister;
 		initializeColumns();
 
 		if ( getWalker().getSessionFactoryHelper().hasPhysicalDiscriminatorColumn( persister ) ) {
 			discriminated = true;
 			columnSpec += ", " + persister.getDiscriminatorColumnName();
 		}
 
 		resetText();
 	}
 
 	private void resetText() {
 		setText( "into " + getTableName() + " ( " + columnSpec + " )" );
 	}
 
 	public String getTableName() {
 		return persister.getSubclassTableName( 0 );
 	}
 
 	public Queryable getQueryable() {
 		return persister;
 	}
 
 	public String getEntityName() {
 		return persister.getEntityName();
 	}
 
 	public Type[] getInsertionTypes() {
 		return types;
 	}
 
 	public boolean isDiscriminated() {
 		return discriminated;
 	}
 
 	public boolean isExplicitIdInsertion() {
 		return explicitIdInsertion;
 	}
 
 	public boolean isExplicitVersionInsertion() {
 		return explicitVersionInsertion;
 	}
 
 	public void prependIdColumnSpec() {
 		columnSpec = persister.getIdentifierColumnNames()[0] + ", " + columnSpec;
 		resetText();
 	}
 
 	public void prependVersionColumnSpec() {
 		columnSpec = persister.getPropertyColumnNames( persister.getVersionProperty() )[0] + ", " + columnSpec;
 		resetText();
 	}
 
 	public void validateTypes(SelectClause selectClause) throws QueryException {
 		Type[] selectTypes = selectClause.getQueryReturnTypes();
 		if ( selectTypes.length + selectClause.getTotalParameterCount() != types.length ) {
 			throw new QueryException( "number of select types did not match those for insert" );
 		}
 
-		int parameterCount = 0; 
+		int parameterCount = 0;
 		for ( int i = 0; i < types.length; i++ ) {
-			if( selectClause.getParameterPositions().contains(i) ) {
+			if ( selectClause.getParameterPositions().contains( i ) ) {
 				parameterCount++;
 			}
 			else if ( !areCompatible( types[i], selectTypes[i - parameterCount] ) ) {
 				throw new QueryException(
-				        "insertion type [" + types[i] + "] and selection type [" +
-				        selectTypes[i - parameterCount] + "] at position " + i + " are not compatible"
+						"insertion type [" + types[i] + "] and selection type [" +
+								selectTypes[i - parameterCount] + "] at position " + i + " are not compatible"
 				);
 			}
 		}
 
 		// otherwise, everything ok.
 	}
 
 	/**
 	 * Returns additional display text for the AST node.
 	 *
 	 * @return String - The additional display text.
 	 */
 	public String getDisplayText() {
-		StringBuilder buf = new StringBuilder();
-		buf.append( "IntoClause{" );
-		buf.append( "entityName=" ).append( getEntityName() );
-		buf.append( ",tableName=" ).append( getTableName() );
-		buf.append( ",columns={" ).append( columnSpec ).append( "}" );
-		buf.append( "}" );
-		return buf.toString();
+		return "IntoClause{"
+				+ "entityName=" + getEntityName()
+				+ ",tableName=" + getTableName()
+				+ ",columns={" + columnSpec + "}"
+				+ "}";
 	}
 
 	private void initializeColumns() {
 		AST propertySpec = getFirstChild();
 		List types = new ArrayList();
 		visitPropertySpecNodes( propertySpec.getFirstChild(), types );
 		this.types = ArrayHelper.toTypeArray( types );
 		columnSpec = columnSpec.substring( 0, columnSpec.length() - 2 );
 	}
 
 	private void visitPropertySpecNodes(AST propertyNode, List types) {
 		if ( propertyNode == null ) {
 			return;
 		}
 		// TODO : we really need to be able to deal with component paths here also;
 		// this is difficult because the hql-sql grammar expects all those node types
 		// to be FromReferenceNodes.  One potential fix here would be to convert the
 		// IntoClause to just use a FromClause/FromElement combo (as a child of the
 		// InsertStatement) and move all this logic into the InsertStatement.  That's
 		// probably the easiest approach (read: least amount of changes to the grammar
 		// and code), but just doesn't feel right as then an insert would contain
 		// 2 from-clauses
 		String name = propertyNode.getText();
 		if ( isSuperclassProperty( name ) ) {
 			throw new QueryException( "INSERT statements cannot refer to superclass/joined properties [" + name + "]" );
 		}
 
 		if ( !explicitIdInsertion ) {
 			if ( persister.getIdentifierType() instanceof ComponentType ) {
 				if ( componentIds == null ) {
 					String[] propertyNames = ( (ComponentType) persister.getIdentifierType() ).getPropertyNames();
 					componentIds = new HashSet();
 					for ( int i = 0; i < propertyNames.length; i++ ) {
 						componentIds.add( propertyNames[i] );
 					}
 				}
-				if ( componentIds.contains(name) ) {
+				if ( componentIds.contains( name ) ) {
 					if ( explicitComponentIds == null ) {
 						explicitComponentIds = new ArrayList( componentIds.size() );
 					}
 					explicitComponentIds.add( name );
 					explicitIdInsertion = explicitComponentIds.size() == componentIds.size();
 				}
-			} else if ( name.equals( persister.getIdentifierPropertyName() ) ) {
+			}
+			else if ( name.equals( persister.getIdentifierPropertyName() ) ) {
 				explicitIdInsertion = true;
 			}
 		}
-			
+
 		if ( persister.isVersioned() ) {
-			if ( name.equals( persister.getPropertyNames()[ persister.getVersionProperty() ] ) ) {
+			if ( name.equals( persister.getPropertyNames()[persister.getVersionProperty()] ) ) {
 				explicitVersionInsertion = true;
 			}
 		}
 
 		String[] columnNames = persister.toColumns( name );
 		renderColumns( columnNames );
 		types.add( persister.toType( name ) );
 
 		// visit width-first, then depth
 		visitPropertySpecNodes( propertyNode.getNextSibling(), types );
 		visitPropertySpecNodes( propertyNode.getFirstChild(), types );
 	}
 
 	private void renderColumns(String[] columnNames) {
 		for ( int i = 0; i < columnNames.length; i++ ) {
 			columnSpec += columnNames[i] + ", ";
 		}
 	}
 
 	private boolean isSuperclassProperty(String propertyName) {
 		// really there are two situations where it should be ok to allow the insertion
 		// into properties defined on a superclass:
 		//      1) union-subclass with an abstract root entity
 		//      2) discrim-subclass
 		//
 		// #1 is handled already because of the fact that
 		// UnionSubclassPersister alreay always returns 0
 		// for this call...
 		//
 		// we may want to disallow it for discrim-subclass just for
 		// consistency-sake (currently does not work anyway)...
 		return persister.getSubclassPropertyTableNumber( propertyName ) != 0;
 	}
 
 	/**
 	 * Determine whether the two types are "assignment compatible".
 	 *
 	 * @param target The type defined in the into-clause.
 	 * @param source The type defined in the select clause.
+	 *
 	 * @return True if they are assignment compatible.
 	 */
 	private boolean areCompatible(Type target, Type source) {
 		if ( target.equals( source ) ) {
 			// if the types report logical equivalence, return true...
 			return true;
 		}
 
 		// otherwise, doAfterTransactionCompletion a "deep equivalence" check...
 
 		if ( !target.getReturnedClass().isAssignableFrom( source.getReturnedClass() ) ) {
 			return false;
 		}
 
 		int[] targetDatatypes = target.sqlTypes( getSessionFactoryHelper().getFactory() );
 		int[] sourceDatatypes = source.sqlTypes( getSessionFactoryHelper().getFactory() );
 
 		if ( targetDatatypes.length != sourceDatatypes.length ) {
 			return false;
 		}
 
 		for ( int i = 0; i < targetDatatypes.length; i++ ) {
 			if ( !areSqlTypesCompatible( targetDatatypes[i], sourceDatatypes[i] ) ) {
 				return false;
 			}
 		}
 
 		return true;
 	}
 
 	private boolean areSqlTypesCompatible(int target, int source) {
 		switch ( target ) {
 			case Types.TIMESTAMP:
 				return source == Types.DATE || source == Types.TIME || source == Types.TIMESTAMP;
 			case Types.DATE:
 				return source == Types.DATE || source == Types.TIMESTAMP;
 			case Types.TIME:
 				return source == Types.TIME || source == Types.TIMESTAMP;
 			default:
 				return target == source;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/JavaConstantNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/JavaConstantNode.java
index fee5f51717..f426b5c1b4 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/JavaConstantNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/JavaConstantNode.java
@@ -1,133 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.Locale;
 
 import org.hibernate.QueryException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.type.LiteralType;
-import org.hibernate.type.StringRepresentableType;
 import org.hibernate.type.Type;
 import org.hibernate.type.descriptor.converter.AttributeConverterTypeAdapter;
 
 /**
  * A node representing a static Java constant.
  *
  * @author Steve Ebersole
  */
 public class JavaConstantNode extends Node implements ExpectedTypeAwareNode, SessionFactoryAwareNode {
 	private SessionFactoryImplementor factory;
 
 	private String constantExpression;
 	private Object constantValue;
 	private Type heuristicType;
 
 	private Type expectedType;
 
 	@Override
 	public void setText(String s) {
 		// for some reason the antlr.CommonAST initialization routines force
 		// this method to get called twice.  The first time with an empty string
 		if ( StringHelper.isNotEmpty( s ) ) {
 			constantExpression = s;
 			constantValue = ReflectHelper.getConstantValue( s );
 			heuristicType = factory.getTypeResolver().heuristicType( constantValue.getClass().getName() );
 			super.setText( s );
 		}
 	}
 
 	@Override
 	public void setExpectedType(Type expectedType) {
 		this.expectedType = expectedType;
 	}
 
 	@Override
 	public Type getExpectedType() {
 		return expectedType;
 	}
 
 	@Override
 	public void setSessionFactory(SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public String getRenderText(SessionFactoryImplementor sessionFactory) {
 		final Type type = expectedType == null
 				? heuristicType
 				: Number.class.isAssignableFrom( heuristicType.getReturnedClass() )
 				? heuristicType
 				: expectedType;
 		try {
 			if ( LiteralType.class.isInstance( type ) ) {
 				final LiteralType literalType = (LiteralType) type;
 				final Dialect dialect = factory.getDialect();
 				return literalType.objectToSQLString( constantValue, dialect );
 			}
 			else if ( AttributeConverterTypeAdapter.class.isInstance( type ) ) {
 				final AttributeConverterTypeAdapter converterType = (AttributeConverterTypeAdapter) type;
 				if ( !converterType.getModelType().isInstance( constantValue ) ) {
 					throw new QueryException(
 							String.format(
 									Locale.ENGLISH,
 									"Recognized query constant expression [%s] was not resolved to type [%s] expected by defined AttributeConverter [%s]",
 									constantExpression,
 									constantValue.getClass().getName(),
 									converterType.getModelType().getName()
 							)
 					);
 				}
 				final Object value = converterType.getAttributeConverter().convertToDatabaseColumn( constantValue );
 				if ( String.class.equals( converterType.getJdbcType() ) ) {
 					return "'" + value + "'";
 				}
 				else {
 					return value.toString();
 				}
 			}
 			else {
 				throw new QueryException(
 						String.format(
 								Locale.ENGLISH,
 								"Unrecognized Hibernate Type for handling query constant (%s); expecting LiteralType implementation or AttributeConverter",
 								constantExpression
 						)
 				);
 			}
 		}
 		catch (QueryException e) {
 			throw e;
 		}
 		catch (Exception t) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_FORMAT_LITERAL + constantExpression, t );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/Node.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/Node.java
index 1b5e451c87..9e59d700be 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/Node.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/Node.java
@@ -1,103 +1,103 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 
 import antlr.Token;
 import antlr.collections.AST;
 
 /**
  * Base node class for use by Hibernate within its AST trees.
  *
  * @author Joshua Davis
  * @author Steve Ebersole
  */
 public class Node extends antlr.CommonAST {
 	private String filename;
 	private int line;
 	private int column;
 	private int textLength;
 
 	public Node() {
 		super();
 	}
 
 	public Node(Token tok) {
 		super(tok);  // This will call initialize(tok)!
 	}
 
 	/**
 	 * Retrieve the text to be used for rendering this particular node.
 	 *
 	 * @param sessionFactory The session factory
 	 * @return The text to use for rendering
 	 */
 	public String getRenderText(SessionFactoryImplementor sessionFactory) {
 		// The basic implementation is to simply use the node's text
 		return getText();
 	}
 
 	@Override
-    public void initialize(Token tok) {
+	public void initialize(Token tok) {
 		super.initialize(tok);
 		filename = tok.getFilename();
 		line = tok.getLine();
 		column = tok.getColumn();
 		String text = tok.getText();
 		textLength = StringHelper.isEmpty(text) ? 0 : text.length();
 	}
 
 	@Override
-    public void initialize(AST t) {
+	public void initialize(AST t) {
 		super.initialize( t );
 		if ( t instanceof Node ) {
 			Node n = (Node)t;
 			filename = n.filename;
 			line = n.line;
 			column = n.column;
 			textLength = n.textLength;
 		}
 	}
 
 	public String getFilename() {
 		return filename;
 	}
 
 	@Override
-    public int getLine() {
+	public int getLine() {
 		return line;
 	}
 
 	@Override
-    public int getColumn() {
+	public int getColumn() {
 		return column;
 	}
 
 	public int getTextLength() {
 		return textLength;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/OrderByClause.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/OrderByClause.java
index c4bc307022..1701c76180 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/OrderByClause.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/OrderByClause.java
@@ -1,49 +1,48 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 
 import antlr.collections.AST;
 
 /**
  * Implementation of OrderByClause.
  *
  * @author Steve Ebersole
  */
 public class OrderByClause extends HqlSqlWalkerNode implements HqlSqlTokenTypes {
-
 	public void addOrderFragment(String orderByFragment) {
 		AST fragment = ASTUtil.create( getASTFactory(), SQL_TOKEN, orderByFragment );
 		if ( getFirstChild() == null ) {
-            setFirstChild( fragment );
+			setFirstChild( fragment );
 		}
 		else {
 			addChild( fragment );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ResultVariableRefNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ResultVariableRefNode.java
index 1e1efcad05..c76f47ac95 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ResultVariableRefNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ResultVariableRefNode.java
@@ -1,94 +1,91 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 
 import antlr.SemanticException;
 
 /**
  * Represents a reference to a result_variable as defined in the JPA 2 spec.
  * For example:
  * <code>
  * select v as value from tab1 order by value
  * </code>
  * <p/>
  * "value" used in the order by clause is a reference to the
  * result_variable, "value", defined in the select clause.
  *
  * @author Gail Badner
  */
 public class ResultVariableRefNode extends HqlSqlWalkerNode {
 	private SelectExpression selectExpression;
 
 	/**
 	 * Set the select expression that defines the result variable.
 	 *
 	 * @param selectExpression the select expression;
 	 *        selectExpression.getAlias() must be non-null
 	 * @throws SemanticException if selectExpression or
 	 *         selectExpression.getAlias() is null.
 	 */
 	public void setSelectExpression(SelectExpression selectExpression) throws SemanticException {
 		if ( selectExpression == null || selectExpression.getAlias() == null ) {
 			throw new SemanticException( "A ResultVariableRefNode must refer to a non-null alias." );
 		}
 		this.selectExpression = selectExpression;
 	}
 
-	/**
-	 *  {@inheritDoc}
-	 */
 	@Override
-    public String getRenderText(SessionFactoryImplementor sessionFactory) {
+	public String getRenderText(SessionFactoryImplementor sessionFactory) {
 		int scalarColumnIndex = selectExpression.getScalarColumnIndex();
 		if ( scalarColumnIndex < 0 ) {
 			throw new IllegalStateException(
 					"selectExpression.getScalarColumnIndex() must be >= 0; actual = " + scalarColumnIndex
 			);
 		}
 		return sessionFactory.getDialect().replaceResultVariableInOrderByClauseWithPosition() ?
 			getColumnPositionsString( scalarColumnIndex ) :
 			getColumnNamesString( scalarColumnIndex );
 
 	}
 
 	private String getColumnPositionsString(int scalarColumnIndex ) {
 		int startPosition = getWalker().getSelectClause().getColumnNamesStartPosition( scalarColumnIndex );
 		StringBuilder buf = new StringBuilder();
 		int nColumns = getWalker().getSelectClause().getColumnNames()[ scalarColumnIndex ].length;
 		for ( int i = startPosition; i < startPosition + nColumns; i++ ) {
 			if ( i > startPosition ) {
 				buf.append( ", " );
 			}
 			buf.append( i );
 		}
 		return buf.toString();
 	}
 
 	private String getColumnNamesString(int scalarColumnIndex) {
 		return StringHelper.join( ", ", getWalker().getSelectClause().getColumnNames()[scalarColumnIndex] );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/UpdateStatement.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/UpdateStatement.java
index eabb8f3ca5..1d70d9f373 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/UpdateStatement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/UpdateStatement.java
@@ -1,72 +1,66 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
-import org.jboss.logging.Logger;
-
 import antlr.collections.AST;
 
 /**
  * Defines a top-level AST node representing an HQL update statement.
  *
  * @author Steve Ebersole
  */
 public class UpdateStatement extends AbstractRestrictableStatement {
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( UpdateStatement.class );
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, UpdateStatement.class.getName());
-
-	/**
-	 * @see org.hibernate.hql.internal.ast.tree.Statement#getStatementType()
-	 */
+	@Override
 	public int getStatementType() {
 		return SqlTokenTypes.UPDATE;
 	}
 
-	/**
-	 * @see org.hibernate.hql.internal.ast.tree.Statement#needsExecutor()
-	 */
+	@Override
 	public boolean needsExecutor() {
 		return true;
 	}
 
 	@Override
-    protected int getWhereClauseParentTokenType() {
+	protected int getWhereClauseParentTokenType() {
 		return SqlTokenTypes.SET;
 	}
 
 	@Override
-    protected CoreMessageLogger getLog() {
-        return LOG;
+	protected CoreMessageLogger getLog() {
+		return LOG;
 	}
 
 	public AST getSetClause() {
 		return ASTUtil.findTypeInChildren( this, HqlSqlTokenTypes.SET );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClassicQueryTranslatorFactory.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClassicQueryTranslatorFactory.java
index e400fb2868..6daec30f65 100755
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClassicQueryTranslatorFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClassicQueryTranslatorFactory.java
@@ -1,69 +1,65 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
+
 import java.util.Map;
 
 import org.hibernate.QueryException;
 import org.hibernate.engine.query.spi.EntityGraphQueryHint;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.hql.spi.FilterTranslator;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.hql.spi.QueryTranslatorFactory;
 
 /**
  * Generates translators which uses the older hand-written parser to perform
  * the translation.
  *
  * @author Gavin King
  */
 public class ClassicQueryTranslatorFactory implements QueryTranslatorFactory {
-
-	/**
-	 * @see QueryTranslatorFactory#createQueryTranslator
-	 */
+	@Override
 	public QueryTranslator createQueryTranslator(
 			String queryIdentifier,
-	        String queryString,
-	        Map filters,
-	        SessionFactoryImplementor factory,
-	        EntityGraphQueryHint entityGraphQueryHint) {
-		if (entityGraphQueryHint != null) {
+			String queryString,
+			Map filters,
+			SessionFactoryImplementor factory,
+			EntityGraphQueryHint entityGraphQueryHint) {
+		if ( entityGraphQueryHint != null ) {
 			throw new QueryException( "EntityGraphs cannot be applied queries using the classic QueryTranslator!" );
 		}
 		return new QueryTranslatorImpl( queryIdentifier, queryString, filters, factory );
 	}
 
-	/**
-	 * @see org.hibernate.hql.spi.QueryTranslatorFactory#createFilterTranslator
-	 */
+	@Override
 	public FilterTranslator createFilterTranslator(
 			String queryIdentifier,
 			String queryString,
-	        Map filters,
-	        SessionFactoryImplementor factory) {
+			Map filters,
+			SessionFactoryImplementor factory) {
 		return new QueryTranslatorImpl( queryIdentifier, queryString, filters, factory );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
index 9bf9bcc3fb..0ed2339bf0 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
@@ -1,333 +1,342 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
+
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.QueryException;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 
 /**
  * Parses the from clause of a hibernate query, looking for tables and
  * aliases for the SQL query.
  */
 
 public class FromParser implements Parser {
 
 	private final PathExpressionParser peParser = new FromPathExpressionParser();
 	private String entityName;
 	private String alias;
 	private boolean afterIn;
 	private boolean afterAs;
 	private boolean afterClass;
 	private boolean expectingJoin;
 	private boolean expectingIn;
 	private boolean expectingAs;
 	private boolean afterJoinType;
 	private JoinType joinType = JoinType.INNER_JOIN;
 	private boolean afterFetch;
-	
+
 	//support collection member declarations
 	//e.g. "from Customer c, in(c.orders) as o"
 	private boolean memberDeclarations;
 	private boolean expectingPathExpression;
 	private boolean afterMemberDeclarations;
 	private String collectionName;
 
-	private static final Map<String,JoinType> JOIN_TYPES = new HashMap<String,JoinType>();
+	private static final Map<String, JoinType> JOIN_TYPES = new HashMap<String, JoinType>();
 
 	static {
 		JOIN_TYPES.put( "left", JoinType.LEFT_OUTER_JOIN );
 		JOIN_TYPES.put( "right", JoinType.RIGHT_OUTER_JOIN );
 		JOIN_TYPES.put( "full", JoinType.FULL_JOIN );
 		JOIN_TYPES.put( "inner", JoinType.INNER_JOIN );
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
 		// start by looking for HQL keywords...
-		String lcToken = token.toLowerCase(Locale.ROOT);
+		String lcToken = token.toLowerCase( Locale.ROOT );
 		if ( lcToken.equals( "," ) ) {
 			if ( !( expectingJoin | expectingAs ) ) {
 				throw new QueryException( "unexpected token: ," );
 			}
 			expectingJoin = false;
 			expectingAs = false;
 		}
 		else if ( lcToken.equals( "join" ) ) {
 			if ( !afterJoinType ) {
-				if ( !( expectingJoin | expectingAs ) ) throw new QueryException( "unexpected token: join" );
+				if ( !( expectingJoin | expectingAs ) ) {
+					throw new QueryException( "unexpected token: join" );
+				}
 				// inner joins can be abbreviated to 'join'
 				joinType = JoinType.INNER_JOIN;
 				expectingJoin = false;
 				expectingAs = false;
 			}
 			else {
 				afterJoinType = false;
 			}
 		}
 		else if ( lcToken.equals( "fetch" ) ) {
 			if ( q.isShallowQuery() ) {
 				throw new QueryException( QueryTranslator.ERROR_CANNOT_FETCH_WITH_ITERATE );
 			}
 			if ( joinType == JoinType.NONE ) {
 				throw new QueryException( "unexpected token: fetch" );
 			}
 			if ( joinType == JoinType.FULL_JOIN || joinType == JoinType.RIGHT_OUTER_JOIN ) {
 				throw new QueryException( "fetch may only be used with inner join or left outer join" );
 			}
 			afterFetch = true;
 		}
 		else if ( lcToken.equals( "outer" ) ) {
 			// 'outer' is optional and is ignored
 			if ( !afterJoinType ||
 					( joinType != JoinType.LEFT_OUTER_JOIN && joinType != JoinType.RIGHT_OUTER_JOIN )
-			) {
+					) {
 				throw new QueryException( "unexpected token: outer" );
 			}
 		}
 		else if ( JOIN_TYPES.containsKey( lcToken ) ) {
 			if ( !( expectingJoin | expectingAs ) ) {
 				throw new QueryException( "unexpected token: " + token );
 			}
 			joinType = JOIN_TYPES.get( lcToken );
 			afterJoinType = true;
 			expectingJoin = false;
 			expectingAs = false;
 		}
 		else if ( lcToken.equals( "class" ) ) {
 			if ( !afterIn ) {
 				throw new QueryException( "unexpected token: class" );
 			}
 			if ( joinType != JoinType.NONE ) {
 				throw new QueryException( "outer or full join must be followed by path expression" );
 			}
 			afterClass = true;
 		}
 		else if ( lcToken.equals( "in" ) ) {
-			if (alias == null ){
+			if ( alias == null ) {
 				memberDeclarations = true;
 				afterMemberDeclarations = false;
 			}
 			else if ( !expectingIn ) {
 				throw new QueryException( "unexpected token: in" );
 			}
 			else {
 				afterIn = true;
 				expectingIn = false;
 			}
 		}
 		else if ( lcToken.equals( "as" ) ) {
 			if ( !expectingAs ) {
 				throw new QueryException( "unexpected token: as" );
 			}
 			afterAs = true;
 			expectingAs = false;
 		}
-		else if ( "(".equals( token ) ){
-			if( !memberDeclarations ) {
+		else if ( "(".equals( token ) ) {
+			if ( !memberDeclarations ) {
 				throw new QueryException( "unexpected token: (" );
 			}
 			//TODO alias should be null here
 			expectingPathExpression = true;
-			
+
 		}
-		else if ( ")".equals( token ) ){
+		else if ( ")".equals( token ) ) {
 //			memberDeclarations = false;
 //			expectingPathExpression = false;
 			afterMemberDeclarations = true;
 		}
 		else {
 			if ( afterJoinType ) {
 				throw new QueryException( "join expected: " + token );
 			}
 			if ( expectingJoin ) {
 				throw new QueryException( "unexpected token: " + token );
 			}
 			if ( expectingIn ) {
 				throw new QueryException( "in expected: " + token );
 			}
 
 			// now anything that is not a HQL keyword
 
 			if ( afterAs || expectingAs ) {
 
 				// (AS is always optional, for consistency with SQL/OQL)
 
 				// process the "new" HQL style where aliases are assigned
 				// _after_ the class name or path expression ie. using
 				// the AS construction
 
 				if ( entityName != null ) {
 					q.setAliasName( token, entityName );
 				}
 				else if ( collectionName != null ) {
 					q.setAliasName( token, collectionName );
 				}
 				else {
 					throw new QueryException( "unexpected: as " + token );
 				}
 				afterAs = false;
 				expectingJoin = true;
 				expectingAs = false;
 				entityName = null;
 				collectionName = null;
 				memberDeclarations = false;
 				expectingPathExpression = false;
 				afterMemberDeclarations = false;
 
 			}
 			else if ( afterIn ) {
 
 				// process the "old" HQL style where aliases appear _first_
 				// ie. using the IN or IN CLASS constructions
 
 				if ( alias == null ) {
 					throw new QueryException( "alias not specified for: " + token );
 				}
 
 				if ( joinType != JoinType.NONE ) {
 					throw new QueryException( "outer or full join must be followed by path expression" );
 				}
 
 				if ( afterClass ) {
 					// treat it as a classname
 					Queryable p = q.getEntityPersisterUsingImports( token );
-					if ( p == null ) throw new QueryException( "persister not found: " + token );
+					if ( p == null ) {
+						throw new QueryException( "persister not found: " + token );
+					}
 					q.addFromClass( alias, p );
 				}
 				else {
 					// treat it as a path expression
 					peParser.setJoinType( JoinType.INNER_JOIN );
 					peParser.setUseThetaStyleJoin( true );
 					ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
-					if ( !peParser.isCollectionValued() ) throw new QueryException( "path expression did not resolve to collection: " + token );
+					if ( !peParser.isCollectionValued() ) {
+						throw new QueryException(
+								"path expression did not resolve to collection: " + token
+						);
+					}
 					String nm = peParser.addFromCollection( q );
 					q.setAliasName( alias, nm );
 				}
 
 				alias = null;
 				afterIn = false;
 				afterClass = false;
 				expectingJoin = true;
 			}
-			else if( memberDeclarations && expectingPathExpression ){
+			else if ( memberDeclarations && expectingPathExpression ) {
 				expectingAs = true;
 				peParser.setJoinType( JoinType.INNER_JOIN );
 				peParser.setUseThetaStyleJoin( false );
 				ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 				if ( !peParser.isCollectionValued() ) {
 					throw new QueryException( "path expression did not resolve to collection: " + token );
 				}
 				collectionName = peParser.addFromCollection( q );
 				expectingPathExpression = false;
 				memberDeclarations = false;
 			}
 			else {
 
 				// handle a path expression or class name that
 				// appears at the start, in the "new" HQL
 				// style or an alias that appears at the start
 				// in the "old" HQL style
 
 				Queryable p = q.getEntityPersisterUsingImports( token );
 				if ( p != null ) {
 					// starts with the name of a mapped class (new style)
 					if ( joinType != JoinType.NONE ) {
 						throw new QueryException( "outer or full join must be followed by path expression" );
 					}
 					entityName = q.createNameFor( p.getEntityName() );
 					q.addFromClass( entityName, p );
 					expectingAs = true;
 				}
 				else if ( token.indexOf( '.' ) < 0 ) {
 					// starts with an alias (old style)
 					// semi-bad thing about this: can't re-alias another alias.....
 					alias = token;
 					expectingIn = true;
 				}
 				else {
 
 					// starts with a path expression (new style)
 
 					// force HQL style: from Person p inner join p.cars c
 					//if (joinType==NONE) throw new QueryException("path expression must be preceded by full, left, right or inner join");
 
 					//allow ODMG OQL style: from Person p, p.cars c
 					if ( joinType != JoinType.NONE ) {
 						peParser.setJoinType( joinType );
 					}
 					else {
 						peParser.setJoinType( JoinType.INNER_JOIN );
 					}
 					peParser.setUseThetaStyleJoin( q.isSubquery() );
 
 					ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 					entityName = peParser.addFromAssociation( q );
 
 					joinType = JoinType.NONE;
 					peParser.setJoinType( JoinType.INNER_JOIN );
 
 					if ( afterFetch ) {
 						peParser.fetch( q, entityName );
 						afterFetch = false;
 					}
 
 					expectingAs = true;
 
 				}
 			}
 		}
 
 	}
 
 	public void start(QueryTranslatorImpl q) {
 		entityName = null;
 		collectionName = null;
 		alias = null;
 		afterIn = false;
 		afterAs = false;
 		afterClass = false;
 		expectingJoin = false;
 		expectingIn = false;
 		expectingAs = false;
 		memberDeclarations = false;
 		expectingPathExpression = false;
 		afterMemberDeclarations = false;
 		joinType = JoinType.NONE;
 	}
 
 	public void end(QueryTranslatorImpl q) {
-		if( afterMemberDeclarations ) {
+		if ( afterMemberDeclarations ) {
 			//The exception throwned by the AST query translator contains the error token location, respensent by line and colum, 
 			//but it hard to get that info here.
-			throw new QueryException("alias not specified for IN");
+			throw new QueryException( "alias not specified for IN" );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
index 9dc99864d3..a8210ab430 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
@@ -1,157 +1,156 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashSet;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  *
  */
 public class PreprocessingParser implements Parser {
 
-	private static final Set HQL_OPERATORS;
+	private static final Set<String> HQL_OPERATORS;
 
 	static {
-		HQL_OPERATORS = new HashSet();
+		HQL_OPERATORS = new HashSet<String>();
 		HQL_OPERATORS.add( "<=" );
 		HQL_OPERATORS.add( ">=" );
 		HQL_OPERATORS.add( "=>" );
 		HQL_OPERATORS.add( "=<" );
 		HQL_OPERATORS.add( "!=" );
 		HQL_OPERATORS.add( "<>" );
 		HQL_OPERATORS.add( "!#" );
 		HQL_OPERATORS.add( "!~" );
 		HQL_OPERATORS.add( "!<" );
 		HQL_OPERATORS.add( "!>" );
 		HQL_OPERATORS.add( "is not" );
 		HQL_OPERATORS.add( "not like" );
 		HQL_OPERATORS.add( "not in" );
 		HQL_OPERATORS.add( "not between" );
 		HQL_OPERATORS.add( "not exists" );
 	}
 
 	private Map replacements;
 	private boolean quoted;
 	private StringBuilder quotedString;
 	private ClauseParser parser = new ClauseParser();
 	private String lastToken;
 	private String currentCollectionProp;
 
 	public PreprocessingParser(Map replacements) {
 		this.replacements = replacements;
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
 		//handle quoted strings
 		if ( quoted ) {
 			quotedString.append( token );
 		}
 		if ( "'".equals( token ) ) {
 			if ( quoted ) {
 				token = quotedString.toString();
 			}
 			else {
 				quotedString = new StringBuilder( 20 ).append( token );
 			}
 			quoted = !quoted;
 		}
-		if ( quoted ) return;
+		if ( quoted ) {
+			return;
+		}
 
 		//ignore whitespace
 		if ( ParserHelper.isWhitespace( token ) ) return;
 
 		//do replacements
 		String substoken = ( String ) replacements.get( token );
 		token = ( substoken == null ) ? token : substoken;
 
 		//handle HQL2 collection syntax
 		if ( currentCollectionProp != null ) {
 			if ( "(".equals( token ) ) {
 				return;
 			}
 			else if ( ")".equals( token ) ) {
 				currentCollectionProp = null;
 				return;
 			}
 			else {
 				token = StringHelper.qualify( token, currentCollectionProp );
 			}
 		}
 		else {
 			String prop = CollectionProperties.getNormalizedPropertyName( token.toLowerCase(Locale.ROOT) );
 			if ( prop != null ) {
 				currentCollectionProp = prop;
 				return;
 			}
 		}
 
 
 		//handle <=, >=, !=, is not, not between, not in
 		if ( lastToken == null ) {
 			lastToken = token;
 		}
 		else {
 			String doubleToken = ( token.length() > 1 ) ?
 					lastToken + ' ' + token :
 					lastToken + token;
 			if ( HQL_OPERATORS.contains( doubleToken.toLowerCase(Locale.ROOT) ) ) {
 				parser.token( doubleToken, q );
 				lastToken = null;
 			}
 			else {
 				parser.token( lastToken, q );
 				lastToken = token;
 			}
 		}
 
 	}
 
 	public void start(QueryTranslatorImpl q) throws QueryException {
 		quoted = false;
 		parser.start( q );
 	}
 
 	public void end(QueryTranslatorImpl q) throws QueryException {
-		if ( lastToken != null ) parser.token( lastToken, q );
+		if ( lastToken != null ) {
+			parser.token( lastToken, q );
+		}
 		parser.end( q );
 		lastToken = null;
 		currentCollectionProp = null;
 	}
 
 }
 
-
-
-
-
-
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
index 9b45d71d9c..03181d319c 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
@@ -1,1278 +1,1310 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.io.Serializable;
 import java.lang.reflect.Constructor;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.hql.internal.NameGenerator;
 import org.hibernate.hql.spi.FilterTranslator;
 import org.hibernate.hql.spi.ParameterTranslations;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.IteratorImpl;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.sql.QuerySelect;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * An instance of <tt>QueryTranslator</tt> translates a Hibernate
  * query string to SQL.
  */
 public class QueryTranslatorImpl extends BasicLoader implements FilterTranslator {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( QueryTranslatorImpl.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( QueryTranslatorImpl.class );
 
 	private static final String[] NO_RETURN_ALIASES = new String[] {};
 
 	private final String queryIdentifier;
 	private final String queryString;
 
 	private final Map typeMap = new LinkedHashMap();
 	private final Map collections = new LinkedHashMap();
 	private List returnedTypes = new ArrayList();
 	private final List fromTypes = new ArrayList();
 	private final List scalarTypes = new ArrayList();
 	private final Map namedParameters = new HashMap();
 	private final Map aliasNames = new HashMap();
 	private final Map oneToOneOwnerNames = new HashMap();
 	private final Map uniqueKeyOwnerReferences = new HashMap();
 	private final Map decoratedPropertyMappings = new HashMap();
 
 	private final List scalarSelectTokens = new ArrayList();
 	private final List whereTokens = new ArrayList();
 	private final List havingTokens = new ArrayList();
 	private final Map joins = new LinkedHashMap();
 	private final List orderByTokens = new ArrayList();
 	private final List groupByTokens = new ArrayList();
 	private final Set<Serializable> querySpaces = new HashSet<Serializable>();
 	private final Set entitiesToFetch = new HashSet();
 
 	private final Map pathAliases = new HashMap();
 	private final Map pathJoins = new HashMap();
 
 	private Queryable[] persisters;
 	private int[] owners;
 	private EntityType[] ownerAssociationTypes;
 	private String[] names;
 	private boolean[] includeInSelect;
 	private int selectLength;
 	private Type[] returnTypes;
 	private Type[] actualReturnTypes;
 	private String[][] scalarColumnNames;
 	private Map tokenReplacements;
 	private int nameCount;
 	private int parameterCount;
 	private boolean distinct;
 	private boolean compiled;
 	private String sqlString;
 	private Class holderClass;
 	private Constructor holderConstructor;
 	private boolean hasScalars;
 	private boolean shallowQuery;
 	private QueryTranslatorImpl superQuery;
 
 	private QueryableCollection collectionPersister;
 	private int collectionOwnerColumn = -1;
 	private String collectionOwnerName;
 	private String fetchName;
 
 	private String[] suffixes;
 
 	private Map enabledFilters;
 
 	/**
 	 * Construct a query translator
 	 *
 	 * @param queryIdentifier A unique identifier for the query of which this
 	 * translation is part; typically this is the original, user-supplied query string.
 	 * @param queryString The "preprocessed" query string; at the very least
 	 * already processed by {@link org.hibernate.hql.internal.QuerySplitter}.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 			String queryIdentifier,
-	        String queryString,
-	        Map enabledFilters,
-	        SessionFactoryImplementor factory) {
+			String queryString,
+			Map enabledFilters,
+			SessionFactoryImplementor factory) {
 		super( factory );
 		this.queryIdentifier = queryIdentifier;
 		this.queryString = queryString;
 		this.enabledFilters = enabledFilters;
 	}
 
 	/**
 	 * Construct a query translator; this form used internally.
 	 *
 	 * @param queryString The query string to process.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
-	        String queryString,
-	        Map enabledFilters,
-	        SessionFactoryImplementor factory) {
+			String queryString,
+			Map enabledFilters,
+			SessionFactoryImplementor factory) {
 		this( queryString, queryString, enabledFilters, factory );
 	}
 
 	/**
 	 * Compile a subquery.
 	 *
 	 * @param superquery The containing query of the query to be compiled.
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	void compile(QueryTranslatorImpl superquery) throws QueryException, MappingException {
 		this.tokenReplacements = superquery.tokenReplacements;
 		this.superQuery = superquery;
 		this.shallowQuery = true;
 		this.enabledFilters = superquery.getEnabledFilters();
 		compile();
 	}
 
 
 	/**
 	 * Compile a "normal" query. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 		if ( !compiled ) {
 			this.tokenReplacements = replacements;
 			this.shallowQuery = scalar;
 			compile();
 		}
 	}
 
 	/**
 	 * Compile a filter. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			String collectionRole,
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 
 		if ( !isCompiled() ) {
 			addFromAssociation( "this", collectionRole );
 			compile( replacements, scalar );
 		}
 	}
 
 	/**
 	 * Compile the query (generate the SQL).
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	private void compile() throws QueryException, MappingException {
 		LOG.trace( "Compiling query" );
 		try {
-			ParserHelper.parse( new PreprocessingParser( tokenReplacements ),
+			ParserHelper.parse(
+					new PreprocessingParser( tokenReplacements ),
 					queryString,
 					ParserHelper.HQL_SEPARATORS,
-					this );
+					this
+			);
 			renderSQL();
 		}
-		catch ( QueryException qe ) {
+		catch (QueryException qe) {
 			if ( qe.getQueryString() == null ) {
 				throw qe.wrapWithQueryString( queryString );
 			}
 			else {
 				throw qe;
 			}
 		}
-		catch ( MappingException me ) {
+		catch (MappingException me) {
 			throw me;
 		}
-		catch ( Exception e ) {
+		catch (Exception e) {
 			LOG.debug( "Unexpected query compilation problem", e );
 			e.printStackTrace();
 			throw new QueryException( "Incorrect query syntax", queryString, e );
 		}
 
 		postInstantiate();
 
 		compiled = true;
 
 	}
 
 	@Override
-    public String getSQLString() {
+	public String getSQLString() {
 		return sqlString;
 	}
 
 	public List<String> collectSqlStrings() {
-		return ArrayHelper.toList( new String[] { sqlString } );
+		return ArrayHelper.toList( new String[] {sqlString} );
 	}
 
 	public String getQueryString() {
 		return queryString;
 	}
 
 	/**
 	 * Persisters for the return values of a <tt>find()</tt> style query.
 	 *
 	 * @return an array of <tt>EntityPersister</tt>s.
 	 */
 	@Override
-    protected Loadable[] getEntityPersisters() {
+	protected Loadable[] getEntityPersisters() {
 		return persisters;
 	}
 
 	/**
 	 * Types of the return values of an <tt>iterate()</tt> style query.
 	 *
 	 * @return an array of <tt>Type</tt>s.
 	 */
 	public Type[] getReturnTypes() {
 		return actualReturnTypes;
 	}
 
 	public String[] getReturnAliases() {
 		// return aliases not supported in classic translator!
 		return NO_RETURN_ALIASES;
 	}
 
 	public String[][] getColumnNames() {
 		return scalarColumnNames;
 	}
 
 	private static void logQuery(String hql, String sql) {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "HQL: %s", hql );
 			LOG.debugf( "SQL: %s", sql );
 		}
 	}
 
 	void setAliasName(String alias, String name) {
 		aliasNames.put( alias, name );
 	}
 
 	public String getAliasName(String alias) {
-		String name = ( String ) aliasNames.get( alias );
+		String name = (String) aliasNames.get( alias );
 		if ( name == null ) {
 			if ( superQuery != null ) {
 				name = superQuery.getAliasName( alias );
 			}
 			else {
 				name = alias;
 			}
 		}
 		return name;
 	}
 
 	String unalias(String path) {
 		String alias = StringHelper.root( path );
 		String name = getAliasName( alias );
-        if (name != null) {
-			return name + path.substring(alias.length());
+		if ( name != null ) {
+			return name + path.substring( alias.length() );
 		}
-        return path;
+		return path;
 	}
 
 	void addEntityToFetch(String name, String oneToOneOwnerName, AssociationType ownerAssociationType) {
 		addEntityToFetch( name );
 		if ( oneToOneOwnerName != null ) {
 			oneToOneOwnerNames.put( name, oneToOneOwnerName );
 		}
 		if ( ownerAssociationType != null ) {
 			uniqueKeyOwnerReferences.put( name, ownerAssociationType );
 		}
 	}
 
 	private void addEntityToFetch(String name) {
 		entitiesToFetch.add( name );
 	}
 
 	private int nextCount() {
 		return ( superQuery == null ) ? nameCount++ : superQuery.nameCount++;
 	}
 
 	String createNameFor(String type) {
 		return StringHelper.generateAlias( type, nextCount() );
 	}
 
 	String createNameForCollection(String role) {
 		return StringHelper.generateAlias( role, nextCount() );
 	}
 
 	private String getType(String name) {
-		String type = ( String ) typeMap.get( name );
+		String type = (String) typeMap.get( name );
 		if ( type == null && superQuery != null ) {
 			type = superQuery.getType( name );
 		}
 		return type;
 	}
 
 	private String getRole(String name) {
-		String role = ( String ) collections.get( name );
+		String role = (String) collections.get( name );
 		if ( role == null && superQuery != null ) {
 			role = superQuery.getRole( name );
 		}
 		return role;
 	}
 
 	boolean isName(String name) {
 		return aliasNames.containsKey( name ) ||
 				typeMap.containsKey( name ) ||
 				collections.containsKey( name ) || (
 				superQuery != null && superQuery.isName( name )
-				);
+		);
 	}
 
 	PropertyMapping getPropertyMapping(String name) throws QueryException {
 		PropertyMapping decorator = getDecoratedPropertyMapping( name );
 		if ( decorator != null ) {
 			return decorator;
 		}
 
 		String type = getType( name );
 		if ( type == null ) {
 			String role = getRole( name );
 			if ( role == null ) {
 				throw new QueryException( "alias not found: " + name );
 			}
 			return getCollectionPersister( role ); //.getElementPropertyMapping();
 		}
 		else {
 			Queryable persister = getEntityPersister( type );
 			if ( persister == null ) {
 				throw new QueryException( "persistent class not found: " + type );
 			}
 			return persister;
 		}
 	}
 
 	private PropertyMapping getDecoratedPropertyMapping(String name) {
-		return ( PropertyMapping ) decoratedPropertyMappings.get( name );
+		return (PropertyMapping) decoratedPropertyMappings.get( name );
 	}
 
 	void decoratePropertyMapping(String name, PropertyMapping mapping) {
 		decoratedPropertyMappings.put( name, mapping );
 	}
 
 	private Queryable getEntityPersisterForName(String name) throws QueryException {
 		String type = getType( name );
 		Queryable persister = getEntityPersister( type );
 		if ( persister == null ) {
 			throw new QueryException( "persistent class not found: " + type );
 		}
 		return persister;
 	}
 
 	Queryable getEntityPersisterUsingImports(String className) {
 		final String importedClassName = getFactory().getImportedClassName( className );
 		if ( importedClassName == null ) {
 			return null;
 		}
 		try {
-			return ( Queryable ) getFactory().getEntityPersister( importedClassName );
+			return (Queryable) getFactory().getEntityPersister( importedClassName );
 		}
-		catch ( MappingException me ) {
+		catch (MappingException me) {
 			return null;
 		}
 	}
 
 	Queryable getEntityPersister(String entityName) throws QueryException {
 		try {
-			return ( Queryable ) getFactory().getEntityPersister( entityName );
+			return (Queryable) getFactory().getEntityPersister( entityName );
 		}
-		catch ( Exception e ) {
+		catch (Exception e) {
 			throw new QueryException( "persistent class not found: " + entityName );
 		}
 	}
 
 	QueryableCollection getCollectionPersister(String role) throws QueryException {
 		try {
-			return ( QueryableCollection ) getFactory().getCollectionPersister( role );
+			return (QueryableCollection) getFactory().getCollectionPersister( role );
 		}
-		catch ( ClassCastException cce ) {
+		catch (ClassCastException cce) {
 			throw new QueryException( "collection role is not queryable: " + role );
 		}
-		catch ( Exception e ) {
+		catch (Exception e) {
 			throw new QueryException( "collection role not found: " + role );
 		}
 	}
 
 	void addType(String name, String type) {
 		typeMap.put( name, type );
 	}
 
 	void addCollection(String name, String role) {
 		collections.put( name, role );
 	}
 
 	void addFrom(String name, String type, JoinSequence joinSequence)
 			throws QueryException {
 		addType( name, type );
 		addFrom( name, joinSequence );
 	}
 
 	void addFromCollection(String name, String collectionRole, JoinSequence joinSequence)
 			throws QueryException {
 		//register collection role
 		addCollection( name, collectionRole );
 		addJoin( name, joinSequence );
 	}
 
 	void addFrom(String name, JoinSequence joinSequence)
 			throws QueryException {
 		fromTypes.add( name );
 		addJoin( name, joinSequence );
 	}
 
 	void addFromClass(String name, Queryable classPersister)
 			throws QueryException {
 		JoinSequence joinSequence = new JoinSequence( getFactory() )
 				.setRoot( classPersister, name );
 		//crossJoins.add(name);
 		addFrom( name, classPersister.getEntityName(), joinSequence );
 	}
 
 	void addSelectClass(String name) {
 		returnedTypes.add( name );
 	}
 
 	void addSelectScalar(Type type) {
 		scalarTypes.add( type );
 	}
 
 	void appendWhereToken(String token) {
 		whereTokens.add( token );
 	}
 
 	void appendHavingToken(String token) {
 		havingTokens.add( token );
 	}
 
 	void appendOrderByToken(String token) {
 		orderByTokens.add( token );
 	}
 
 	void appendGroupByToken(String token) {
 		groupByTokens.add( token );
 	}
 
 	void appendScalarSelectToken(String token) {
 		scalarSelectTokens.add( token );
 	}
 
 	void appendScalarSelectTokens(String[] tokens) {
 		scalarSelectTokens.add( tokens );
 	}
 
 	void addFromJoinOnly(String name, JoinSequence joinSequence) throws QueryException {
 		addJoin( name, joinSequence.getFromPart() );
 	}
 
 	void addJoin(String name, JoinSequence joinSequence) throws QueryException {
 		if ( !joins.containsKey( name ) ) {
 			joins.put( name, joinSequence );
 		}
 	}
 
 	void addNamedParameter(String name) {
 		if ( superQuery != null ) {
 			superQuery.addNamedParameter( name );
 		}
 		Integer loc = parameterCount++;
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
-			( ( ArrayList ) o ).add( loc );
+			( (ArrayList) o ).add( loc );
 		}
 	}
 
 	@Override
-    public int[] getNamedParameterLocs(String name) throws QueryException {
+	public int[] getNamedParameterLocs(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			throw new QueryException( ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name, queryString );
 		}
 		if ( o instanceof Integer ) {
-			return new int[] { (Integer) o };
+			return new int[] {(Integer) o};
 		}
 		else {
-			return ArrayHelper.toIntArray( ( ArrayList ) o );
+			return ArrayHelper.toIntArray( (ArrayList) o );
 		}
 	}
 
 	private void renderSQL() throws QueryException, MappingException {
 
 		final int rtsize;
 		if ( returnedTypes.size() == 0 && scalarTypes.size() == 0 ) {
 			//ie no select clause in HQL
 			returnedTypes = fromTypes;
 			rtsize = returnedTypes.size();
 		}
 		else {
 			rtsize = returnedTypes.size();
 			Iterator iter = entitiesToFetch.iterator();
 			while ( iter.hasNext() ) {
 				returnedTypes.add( iter.next() );
 			}
 		}
 		int size = returnedTypes.size();
 		persisters = new Queryable[size];
 		names = new String[size];
 		owners = new int[size];
 		ownerAssociationTypes = new EntityType[size];
 		suffixes = new String[size];
 		includeInSelect = new boolean[size];
 		for ( int i = 0; i < size; i++ ) {
-			String name = ( String ) returnedTypes.get( i );
+			String name = (String) returnedTypes.get( i );
 			//if ( !isName(name) ) throw new QueryException("unknown type: " + name);
 			persisters[i] = getEntityPersisterForName( name );
 			// TODO: cannot use generateSuffixes() - it handles the initial suffix differently.
 			suffixes[i] = ( size == 1 ) ? "" : Integer.toString( i ) + '_';
 			names[i] = name;
 			includeInSelect[i] = !entitiesToFetch.contains( name );
 			if ( includeInSelect[i] ) {
 				selectLength++;
 			}
 			if ( name.equals( collectionOwnerName ) ) {
 				collectionOwnerColumn = i;
 			}
-			String oneToOneOwner = ( String ) oneToOneOwnerNames.get( name );
+			String oneToOneOwner = (String) oneToOneOwnerNames.get( name );
 			owners[i] = ( oneToOneOwner == null ) ? -1 : returnedTypes.indexOf( oneToOneOwner );
 			ownerAssociationTypes[i] = (EntityType) uniqueKeyOwnerReferences.get( name );
 		}
 
 		if ( ArrayHelper.isAllNegative( owners ) ) {
 			owners = null;
 		}
 
 		String scalarSelect = renderScalarSelect(); //Must be done here because of side-effect! yuck...
 
 		int scalarSize = scalarTypes.size();
 		hasScalars = scalarTypes.size() != rtsize;
 
 		returnTypes = new Type[scalarSize];
 		for ( int i = 0; i < scalarSize; i++ ) {
-			returnTypes[i] = ( Type ) scalarTypes.get( i );
+			returnTypes[i] = (Type) scalarTypes.get( i );
 		}
 
 		QuerySelect sql = new QuerySelect( getFactory().getDialect() );
 		sql.setDistinct( distinct );
 
 		if ( !shallowQuery ) {
 			renderIdentifierSelect( sql );
 			renderPropertiesSelect( sql );
 		}
 
 		if ( collectionPersister != null ) {
 			sql.addSelectFragmentString( collectionPersister.selectFragment( fetchName, "__" ) );
 		}
 
 		if ( hasScalars || shallowQuery ) {
 			sql.addSelectFragmentString( scalarSelect );
 		}
 
 		//TODO: for some dialects it would be appropriate to add the renderOrderByPropertiesSelect() to other select strings
 		mergeJoins( sql.getJoinFragment() );
 
 		sql.setWhereTokens( whereTokens.iterator() );
 
 		sql.setGroupByTokens( groupByTokens.iterator() );
 		sql.setHavingTokens( havingTokens.iterator() );
 		sql.setOrderByTokens( orderByTokens.iterator() );
 
 		if ( collectionPersister != null && collectionPersister.hasOrdering() ) {
 			sql.addOrderBy( collectionPersister.getSQLOrderByString( fetchName ) );
 		}
 
 		scalarColumnNames = NameGenerator.generateColumnNames( returnTypes, getFactory() );
 
 		// initialize the Set of queried identifier spaces (ie. tables)
 		Iterator iter = collections.values().iterator();
 		while ( iter.hasNext() ) {
-			CollectionPersister p = getCollectionPersister( ( String ) iter.next() );
+			CollectionPersister p = getCollectionPersister( (String) iter.next() );
 			addQuerySpaces( p.getCollectionSpaces() );
 		}
 		iter = typeMap.keySet().iterator();
 		while ( iter.hasNext() ) {
-			Queryable p = getEntityPersisterForName( ( String ) iter.next() );
+			Queryable p = getEntityPersisterForName( (String) iter.next() );
 			addQuerySpaces( p.getQuerySpaces() );
 		}
 
 		sqlString = sql.toQueryString();
 
 		if ( holderClass != null ) {
 			holderConstructor = ReflectHelper.getConstructor( holderClass, returnTypes );
 		}
 
 		if ( hasScalars ) {
 			actualReturnTypes = returnTypes;
 		}
 		else {
 			actualReturnTypes = new Type[selectLength];
 			int j = 0;
 			for ( int i = 0; i < persisters.length; i++ ) {
 				if ( includeInSelect[i] ) {
 					actualReturnTypes[j++] = getFactory().getTypeResolver()
 							.getTypeFactory()
 							.manyToOne( persisters[i].getEntityName(), shallowQuery );
 				}
 			}
 		}
 
 	}
 
 	private void renderIdentifierSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 
 		for ( int k = 0; k < size; k++ ) {
-			String name = ( String ) returnedTypes.get( k );
+			String name = (String) returnedTypes.get( k );
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			sql.addSelectFragmentString( persisters[k].identifierSelectFragment( name, suffix ) );
 		}
 
 	}
 
 	/*private String renderOrderByPropertiesSelect() {
 		StringBuffer buf = new StringBuffer(10);
 
 		//add the columns we are ordering by to the select ID select clause
 		Iterator iter = orderByTokens.iterator();
 		while ( iter.hasNext() ) {
 			String token = (String) iter.next();
 			if ( token.lastIndexOf(".") > 0 ) {
 				//ie. it is of form "foo.bar", not of form "asc" or "desc"
 				buf.append(StringHelper.COMMA_SPACE).append(token);
 			}
 		}
 
 		return buf.toString();
 	}*/
 
 	private void renderPropertiesSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 		for ( int k = 0; k < size; k++ ) {
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
-			String name = ( String ) returnedTypes.get( k );
+			String name = (String) returnedTypes.get( k );
 			sql.addSelectFragmentString( persisters[k].propertySelectFragment( name, suffix, false ) );
 		}
 	}
 
 	/**
 	 * WARNING: side-effecty
 	 */
 	private String renderScalarSelect() {
 
 		boolean isSubselect = superQuery != null;
 
 		StringBuilder buf = new StringBuilder( 20 );
 
 		if ( scalarTypes.size() == 0 ) {
 			//ie. no select clause
 			int size = returnedTypes.size();
 			for ( int k = 0; k < size; k++ ) {
 
 				scalarTypes.add(
-						getFactory().getTypeResolver().getTypeFactory().manyToOne( persisters[k].getEntityName(), shallowQuery )
+						getFactory().getTypeResolver().getTypeFactory().manyToOne(
+								persisters[k].getEntityName(),
+								shallowQuery
+						)
 				);
 
 				String[] idColumnNames = persisters[k].getIdentifierColumnNames();
 				for ( int i = 0; i < idColumnNames.length; i++ ) {
 					buf.append( returnedTypes.get( k ) ).append( '.' ).append( idColumnNames[i] );
 					if ( !isSubselect ) {
 						buf.append( " as " ).append( NameGenerator.scalarName( k, i ) );
 					}
 					if ( i != idColumnNames.length - 1 || k != size - 1 ) {
 						buf.append( ", " );
 					}
 				}
 
 			}
 
 		}
 		else {
 			//there _was_ a select clause
 			Iterator iter = scalarSelectTokens.iterator();
 			int c = 0;
 			boolean nolast = false; //real hacky...
 			int parenCount = 0; // used to count the nesting of parentheses
 			while ( iter.hasNext() ) {
 				Object next = iter.next();
 				if ( next instanceof String ) {
-					String token = ( String ) next;
+					String token = (String) next;
 
 					if ( "(".equals( token ) ) {
 						parenCount++;
 					}
 					else if ( ")".equals( token ) ) {
 						parenCount--;
 					}
 
-					String lc = token.toLowerCase(Locale.ROOT);
+					String lc = token.toLowerCase( Locale.ROOT );
 					if ( lc.equals( ", " ) ) {
 						if ( nolast ) {
 							nolast = false;
 						}
 						else {
 							if ( !isSubselect && parenCount == 0 ) {
 								int x = c++;
 								buf.append( " as " ).append( NameGenerator.scalarName( x, 0 ) );
 							}
 						}
 					}
 					buf.append( token );
 					if ( lc.equals( "distinct" ) || lc.equals( "all" ) ) {
 						buf.append( ' ' );
 					}
 				}
 				else {
 					nolast = true;
-					String[] tokens = ( String[] ) next;
+					String[] tokens = (String[]) next;
 					for ( int i = 0; i < tokens.length; i++ ) {
 						buf.append( tokens[i] );
 						if ( !isSubselect ) {
 							buf.append( " as " ).append( NameGenerator.scalarName( c, i ) );
 						}
 						if ( i != tokens.length - 1 ) {
 							buf.append( ", " );
 						}
 					}
 					c++;
 				}
 			}
 			if ( !isSubselect && !nolast ) {
 				int x = c++;
 				buf.append( " as " ).append( NameGenerator.scalarName( x, 0 ) );
 			}
 
 		}
 
 		return buf.toString();
 	}
 
 	private void mergeJoins(JoinFragment ojf) throws MappingException, QueryException {
 
 		Iterator iter = joins.entrySet().iterator();
 		while ( iter.hasNext() ) {
-			Map.Entry me = ( Map.Entry ) iter.next();
-			String name = ( String ) me.getKey();
-			JoinSequence join = ( JoinSequence ) me.getValue();
-			join.setSelector( new JoinSequence.Selector() {
-				public boolean includeSubclasses(String alias) {
-					return returnedTypes.contains( alias ) && !isShallowQuery();
-				}
-			} );
+			Map.Entry me = (Map.Entry) iter.next();
+			String name = (String) me.getKey();
+			JoinSequence join = (JoinSequence) me.getValue();
+			join.setSelector(
+					new JoinSequence.Selector() {
+						public boolean includeSubclasses(String alias) {
+							return returnedTypes.contains( alias ) && !isShallowQuery();
+						}
+					}
+			);
 
 			if ( typeMap.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 			else if ( collections.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 		}
 
 	}
 
 	public final Set<Serializable> getQuerySpaces() {
 		return querySpaces;
 	}
 
 	/**
 	 * Is this query called by scroll() or iterate()?
 	 *
 	 * @return true if it is, false if it is called by find() or list()
 	 */
 	boolean isShallowQuery() {
 		return shallowQuery;
 	}
 
 	void addQuerySpaces(Serializable[] spaces) {
 		Collections.addAll( querySpaces, spaces );
-		if ( superQuery != null ) superQuery.addQuerySpaces( spaces );
+		if ( superQuery != null ) {
+			superQuery.addQuerySpaces( spaces );
+		}
 	}
 
 	void setDistinct(boolean distinct) {
 		this.distinct = distinct;
 	}
 
 	boolean isSubquery() {
 		return superQuery != null;
 	}
 
-	/**
-	 * Overrides method from Loader
-	 */
 	@Override
-    public CollectionPersister[] getCollectionPersisters() {
-		return collectionPersister == null ? null : new CollectionPersister[] { collectionPersister };
+	public CollectionPersister[] getCollectionPersisters() {
+		return collectionPersister == null ? null : new CollectionPersister[] {collectionPersister};
 	}
 
 	@Override
-    protected String[] getCollectionSuffixes() {
-		return collectionPersister == null ? null : new String[] { "__" };
+	protected String[] getCollectionSuffixes() {
+		return collectionPersister == null ? null : new String[] {"__"};
 	}
 
 	void setCollectionToFetch(String role, String name, String ownerName, String entityName)
 			throws QueryException {
 		fetchName = name;
 		collectionPersister = getCollectionPersister( role );
 		collectionOwnerName = ownerName;
 		if ( collectionPersister.getElementType().isEntityType() ) {
 			addEntityToFetch( entityName );
 		}
 	}
 
 	@Override
-    protected String[] getSuffixes() {
+	protected String[] getSuffixes() {
 		return suffixes;
 	}
 
 	@Override
-    protected String[] getAliases() {
+	protected String[] getAliases() {
 		return names;
 	}
 
 	/**
 	 * Used for collection filters
 	 */
 	private void addFromAssociation(final String elementName, final String collectionRole)
 			throws QueryException {
 		//q.addCollection(collectionName, collectionRole);
 		QueryableCollection persister = getCollectionPersister( collectionRole );
 		Type collectionElementType = persister.getElementType();
 		if ( !collectionElementType.isEntityType() ) {
 			throw new QueryException( "collection of values in filter: " + elementName );
 		}
 
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		//if (keyColumnNames.length!=1) throw new QueryException("composite-key collection in filter: " + collectionRole);
 
 		String collectionName;
 		JoinSequence join = new JoinSequence( getFactory() );
 		collectionName = persister.isOneToMany() ?
 				elementName :
 				createNameForCollection( collectionRole );
 		join.setRoot( persister, collectionName );
 		if ( !persister.isOneToMany() ) {
 			//many-to-many
 			addCollection( collectionName, collectionRole );
 			try {
-				join.addJoin( ( AssociationType ) persister.getElementType(),
+				join.addJoin(
+						(AssociationType) persister.getElementType(),
 						elementName,
 						JoinType.INNER_JOIN,
-						persister.getElementColumnNames(collectionName) );
+						persister.getElementColumnNames( collectionName )
+				);
 			}
-			catch ( MappingException me ) {
+			catch (MappingException me) {
 				throw new QueryException( me );
 			}
 		}
 		join.addCondition( collectionName, keyColumnNames, " = ?" );
 		//if ( persister.hasWhere() ) join.addCondition( persister.getSQLWhereString(collectionName) );
-		EntityType elemType = ( EntityType ) collectionElementType;
+		EntityType elemType = (EntityType) collectionElementType;
 		addFrom( elementName, elemType.getAssociatedEntityName(), join );
 
 	}
 
 	String getPathAlias(String path) {
-		return ( String ) pathAliases.get( path );
+		return (String) pathAliases.get( path );
 	}
 
 	JoinSequence getPathJoin(String path) {
-		return ( JoinSequence ) pathJoins.get( path );
+		return (JoinSequence) pathJoins.get( path );
 	}
 
 	void addPathAliasAndJoin(String path, String alias, JoinSequence joinSequence) {
 		pathAliases.put( path, alias );
 		pathJoins.put( path, joinSequence );
 	}
 
 	@Override
 	public List list(SessionImplementor session, QueryParameters queryParameters)
 			throws HibernateException {
 		return list( session, queryParameters, getQuerySpaces(), actualReturnTypes );
 	}
 
 	/**
 	 * Return the query results as an iterator
 	 */
 	@Override
 	public Iterator iterate(QueryParameters queryParameters, EventSource session)
 			throws HibernateException {
 
 		boolean stats = session.getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) {
 			startTime = System.nanoTime();
 		}
 
 		try {
 			final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
-			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
+			final SqlStatementWrapper wrapper = executeQueryStatement(
+					queryParameters,
+					false,
+					afterLoadActions,
+					session
+			);
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
-			HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(holderConstructor, queryParameters.getResultTransformer());
-			Iterator result = new IteratorImpl( rs, st, session, queryParameters.isReadOnly( session ), returnTypes, getColumnNames(), hi );
+			HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(
+					holderConstructor,
+					queryParameters.getResultTransformer()
+			);
+			Iterator result = new IteratorImpl(
+					rs,
+					st,
+					session,
+					queryParameters.isReadOnly( session ),
+					returnTypes,
+					getColumnNames(),
+					hi
+			);
 
 			if ( stats ) {
 				final long endTime = System.nanoTime();
 				final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 				session.getFactory().getStatisticsImplementor().queryExecuted(
 						"HQL: " + queryString,
 						0,
 						milliseconds
-					);
+				);
 			}
 
 			return result;
 
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using iterate",
 					getSQLString()
-				);
+			);
 		}
 
 	}
 
 	public int executeUpdate(QueryParameters queryParameters, SessionImplementor session) throws HibernateException {
-		throw new UnsupportedOperationException( "Not supported!  Use the AST translator...");
+		throw new UnsupportedOperationException( "Not supported!  Use the AST translator..." );
 	}
 
 	@Override
-    protected boolean[] includeInResultRow() {
+	protected boolean[] includeInResultRow() {
 		boolean[] isResultReturned = includeInSelect;
 		if ( hasScalars ) {
-			isResultReturned = new boolean[ returnedTypes.size() ];
+			isResultReturned = new boolean[returnedTypes.size()];
 			Arrays.fill( isResultReturned, true );
 		}
 		return isResultReturned;
 	}
 
 
 	@Override
-    protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
+	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return HolderInstantiator.resolveClassicResultTransformer(
 				holderConstructor,
 				resultTransformer
 		);
 	}
 
 	@Override
-    protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
+	protected Object getResultColumnOrRow(
+			Object[] row,
+			ResultTransformer transformer,
+			ResultSet rs,
+			SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow = getResultRow( row, rs, session );
 		return ( holderClass == null && resultRow.length == 1 ?
-				resultRow[ 0 ] :
+				resultRow[0] :
 				resultRow
 		);
 	}
 
 	@Override
-    protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
+	protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow;
 		if ( hasScalars ) {
 			String[][] scalarColumns = getColumnNames();
 			int queryCols = returnTypes.length;
 			resultRow = new Object[queryCols];
 			for ( int i = 0; i < queryCols; i++ ) {
 				resultRow[i] = returnTypes[i].nullSafeGet( rs, scalarColumns[i], session, null );
 			}
 		}
 		else {
 			resultRow = toResultRow( row );
 		}
 		return resultRow;
 	}
 
 	@Override
-    protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
+	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		if ( holderClass != null ) {
 			for ( int i = 0; i < results.size(); i++ ) {
-				Object[] row = ( Object[] ) results.get( i );
+				Object[] row = (Object[]) results.get( i );
 				try {
 					results.set( i, holderConstructor.newInstance( row ) );
 				}
-				catch ( Exception e ) {
+				catch (Exception e) {
 					throw new QueryException( "could not instantiate: " + holderClass, e );
 				}
 			}
 		}
 		return results;
 	}
 
 	private Object[] toResultRow(Object[] row) {
 		if ( selectLength == row.length ) {
 			return row;
 		}
 		else {
 			Object[] result = new Object[selectLength];
 			int j = 0;
 			for ( int i = 0; i < row.length; i++ ) {
-				if ( includeInSelect[i] ) result[j++] = row[i];
+				if ( includeInSelect[i] ) {
+					result[j++] = row[i];
+				}
 			}
 			return result;
 		}
 	}
 
 	void setHolderClass(Class clazz) {
 		holderClass = clazz;
 	}
 
 	@Override
-    protected LockMode[] getLockModes(LockOptions lockOptions) {
+	protected LockMode[] getLockModes(LockOptions lockOptions) {
 
 		// unfortunately this stuff can't be cached because
 		// it is per-invocation, not constant for the
 		// QueryTranslator instance
 		HashMap nameLockOptions = new HashMap();
-		if ( lockOptions == null) {
+		if ( lockOptions == null ) {
 			lockOptions = LockOptions.NONE;
 		}
 
 		if ( lockOptions.getAliasLockCount() > 0 ) {
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
-				Map.Entry me = ( Map.Entry ) iter.next();
-				nameLockOptions.put( getAliasName( ( String ) me.getKey() ),
-						me.getValue() );
+				Map.Entry me = (Map.Entry) iter.next();
+				nameLockOptions.put(
+						getAliasName( (String) me.getKey() ),
+						me.getValue()
+				);
 			}
 		}
 		LockMode[] lockModesArray = new LockMode[names.length];
 		for ( int i = 0; i < names.length; i++ ) {
-			LockMode lm = ( LockMode ) nameLockOptions.get( names[i] );
+			LockMode lm = (LockMode) nameLockOptions.get( names[i] );
 			//if ( lm == null ) lm = LockOptions.NONE;
 			if ( lm == null ) {
 				lm = lockOptions.getLockMode();
 			}
 			lockModesArray[i] = lm;
 		}
 		return lockModesArray;
 	}
 
 	@Override
-    protected String applyLocks(
+	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws QueryException {
 		// can't cache this stuff either (per-invocation)
 		final LockOptions lockOptions = parameters.getLockOptions();
 		final String result;
 		if ( lockOptions == null ||
-			( lockOptions.getLockMode() == LockMode.NONE && lockOptions.getAliasLockCount() == 0 ) ) {
+				( lockOptions.getLockMode() == LockMode.NONE && lockOptions.getAliasLockCount() == 0 ) ) {
 			return sql;
 		}
 		else {
 			LockOptions locks = new LockOptions();
-			locks.setLockMode(lockOptions.getLockMode());
-			locks.setTimeOut(lockOptions.getTimeOut());
-			locks.setScope(lockOptions.getScope());
+			locks.setLockMode( lockOptions.getLockMode() );
+			locks.setTimeOut( lockOptions.getTimeOut() );
+			locks.setScope( lockOptions.getScope() );
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
-				Map.Entry me = ( Map.Entry ) iter.next();
-				locks.setAliasSpecificLockMode( getAliasName( ( String ) me.getKey() ), (LockMode) me.getValue() );
+				Map.Entry me = (Map.Entry) iter.next();
+				locks.setAliasSpecificLockMode( getAliasName( (String) me.getKey() ), (LockMode) me.getValue() );
 			}
 			Map keyColumnNames = null;
 			if ( dialect.forUpdateOfColumns() ) {
 				keyColumnNames = new HashMap();
 				for ( int i = 0; i < names.length; i++ ) {
 					keyColumnNames.put( names[i], persisters[i].getIdentifierColumnNames() );
 				}
 			}
 			result = dialect.applyLocksToSql( sql, locks, keyColumnNames );
 		}
 		logQuery( queryString, result );
 		return result;
 	}
 
 	@Override
-    protected boolean upgradeLocks() {
+	protected boolean upgradeLocks() {
 		return true;
 	}
 
 	@Override
-    protected int[] getCollectionOwners() {
-		return new int[] { collectionOwnerColumn };
+	protected int[] getCollectionOwners() {
+		return new int[] {collectionOwnerColumn};
 	}
 
 	protected boolean isCompiled() {
 		return compiled;
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return queryString;
 	}
 
 	@Override
-    protected int[] getOwners() {
+	protected int[] getOwners() {
 		return owners;
 	}
 
 	@Override
-    protected EntityType[] getOwnerAssociationTypes() {
+	protected EntityType[] getOwnerAssociationTypes() {
 		return ownerAssociationTypes;
 	}
 
 	public Class getHolderClass() {
 		return holderClass;
 	}
 
 	public Map getEnabledFilters() {
 		return enabledFilters;
 	}
 
 	public ScrollableResults scroll(
 			final QueryParameters queryParameters,
 			final SessionImplementor session) throws HibernateException {
 		HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(
 				holderConstructor,
 				queryParameters.getResultTransformer()
 		);
 		return scroll( queryParameters, returnTypes, hi, session );
 	}
 
 	@Override
-    public String getQueryIdentifier() {
+	public String getQueryIdentifier() {
 		return queryIdentifier;
 	}
 
 	@Override
-    protected boolean isSubselectLoadingEnabled() {
+	protected boolean isSubselectLoadingEnabled() {
 		return hasSubselectLoadableCollections();
 	}
 
 	public void validateScrollability() throws HibernateException {
 		// This is the legacy behaviour for HQL queries...
 		if ( getCollectionPersisters() != null ) {
 			throw new HibernateException( "Cannot scroll queries which initialize collections" );
 		}
 	}
 
 	public boolean containsCollectionFetches() {
 		return false;
 	}
 
 	public boolean isManipulationStatement() {
 		// classic parser does not support bulk manipulation statements
 		return false;
 	}
 
 	@Override
 	public Class getDynamicInstantiationResultType() {
 		return holderClass;
 	}
 
 	public ParameterTranslations getParameterTranslations() {
 		return new ParameterTranslations() {
 
 			public boolean supportsOrdinalParameterMetadata() {
 				// classic translator does not support collection of ordinal
 				// param metadata
 				return false;
 			}
 
 			public int getOrdinalParameterCount() {
 				return 0; // not known!
 			}
 
 			public int getOrdinalParameterSqlLocation(int ordinalPosition) {
 				return 0; // not known!
 			}
 
 			public Type getOrdinalParameterExpectedType(int ordinalPosition) {
 				return null; // not known!
 			}
 
 			public Set getNamedParameterNames() {
 				return namedParameters.keySet();
 			}
 
 			public int[] getNamedParameterSqlLocations(String name) {
 				return getNamedParameterLocs( name );
 			}
 
 			public Type getNamedParameterExpectedType(String name) {
 				return null; // not known!
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
index bc8ad8a880..e1194de29c 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
@@ -1,263 +1,265 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.internal.QuerySplitter;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * Parsers the select clause of a Hibernate query.
  *
  * @author Gavin King, David Channon
  */
 public class SelectParser implements Parser {
 
 	//TODO: arithmetic expressions, multiple new Foo(...)
 
 	private static final Set<String> COUNT_MODIFIERS = new HashSet<String>();
 
 	static {
 		COUNT_MODIFIERS.add( "distinct" );
 		COUNT_MODIFIERS.add( "all" );
 		COUNT_MODIFIERS.add( "*" );
 	}
 
 	private LinkedList<String> aggregateFuncTokenList = new LinkedList<String>();
 
 	private boolean ready;
 	private boolean aggregate;
 	private boolean first;
 	private boolean afterNew;
 	private boolean insideNew;
 	private boolean aggregateAddSelectScalar;
 	private Class holderClass;
 
 	private final SelectPathExpressionParser pathExpressionParser;
 	private final PathExpressionParser aggregatePathExpressionParser;
 
 	{
 		pathExpressionParser = new SelectPathExpressionParser();
 		aggregatePathExpressionParser = new PathExpressionParser();
 		//TODO: would be nice to use false, but issues with MS SQL
 		pathExpressionParser.setUseThetaStyleJoin( true );
 		aggregatePathExpressionParser.setUseThetaStyleJoin( true );
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 		String lctoken = token.toLowerCase(Locale.ROOT);
 
 		if ( first ) {
 			first = false;
 			if ( "distinct".equals( lctoken ) ) {
 				q.setDistinct( true );
 				return;
 			}
 			else if ( "all".equals( lctoken ) ) {
 				q.setDistinct( false );
 				return;
 			}
 		}
 
 		if ( afterNew ) {
 			afterNew = false;
 			try {
 				holderClass = ReflectHelper.classForName( QuerySplitter.getImportedClass( token, q.getFactory() ) );
 			}
 			catch ( ClassNotFoundException cnfe ) {
 				throw new QueryException( cnfe );
 			}
 			if ( holderClass == null ) {
 				throw new QueryException( "class not found: " + token );
 			}
 			q.setHolderClass( holderClass );
 			insideNew = true;
 		}
 		else if ( token.equals( "," ) ) {
 			if ( !aggregate && ready ) {
 				throw new QueryException( "alias or expression expected in SELECT" );
 			}
 			q.appendScalarSelectToken( ", " );
 			ready = true;
 		}
 		else if ( "new".equals( lctoken ) ) {
 			afterNew = true;
 			ready = false;
 		}
 		else if ( "(".equals( token ) ) {
 			if ( insideNew && !aggregate && !ready ) {
 				//opening paren in new Foo ( ... )
 				ready = true;
 			}
 			else if ( aggregate ) {
 				q.appendScalarSelectToken( token );
 			}
 			else {
 				throw new QueryException( "aggregate function expected before ( in SELECT" );
 			}
 			ready = true;
 		}
 		else if ( ")".equals( token ) ) {
 			if ( insideNew && !aggregate && !ready ) {
 				//if we are inside a new Result(), but not inside a nested function
 				insideNew = false;
 			}
 			else if ( aggregate && ready ) {
 				q.appendScalarSelectToken( token );
 				aggregateFuncTokenList.removeLast();
 				if ( aggregateFuncTokenList.size() < 1 ) {
 					aggregate = false;
 					ready = false;
 				}
 			}
 			else {
 				throw new QueryException( "( expected before ) in select" );
 			}
 		}
 		else if ( COUNT_MODIFIERS.contains( lctoken ) ) {
 			if ( !ready || !aggregate ) {
 				throw new QueryException( token + " only allowed inside aggregate function in SELECT" );
 			}
 			q.appendScalarSelectToken( token );
 			if ( "*".equals( token ) ) {
 				// special case
 				q.addSelectScalar( getFunction( "count", q ).getReturnType( StandardBasicTypes.LONG, q.getFactory() ) );
 			}
 		}
 		else if ( getFunction( lctoken, q ) != null && token.equals( q.unalias( token ) ) ) {
 			// the name of an SQL function
-			if ( !ready ) throw new QueryException( ", expected before aggregate function in SELECT: " + token );
+			if ( !ready ) {
+				throw new QueryException( ", expected before aggregate function in SELECT: " + token );
+			}
 			aggregate = true;
 			aggregateAddSelectScalar = true;
 			aggregateFuncTokenList.add( lctoken );
 			ready = false;
 			q.appendScalarSelectToken( token );
 			if ( !aggregateHasArgs( lctoken, q ) ) {
 				q.addSelectScalar( aggregateType( aggregateFuncTokenList, null, q ) );
 				if ( !aggregateFuncNoArgsHasParenthesis( lctoken, q ) ) {
 					aggregateFuncTokenList.removeLast();
 					if ( aggregateFuncTokenList.size() < 1 ) {
 						aggregate = false;
 						ready = false;
 					}
 					else {
 						ready = true;
 					}
 				}
 			}
 		}
 		else if ( aggregate ) {
 			boolean constantToken = false;
 			if ( !ready ) {
 				throw new QueryException( "( expected after aggregate function in SELECT" );
 			}
 			try {
 				ParserHelper.parse( aggregatePathExpressionParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 			}
 			catch ( QueryException qex ) {
 				constantToken = true;
 			}
 
 			if ( constantToken ) {
 				q.appendScalarSelectToken( token );
 			}
 			else {
 				if ( aggregatePathExpressionParser.isCollectionValued() ) {
 					q.addCollection( aggregatePathExpressionParser.getCollectionName(),
 							aggregatePathExpressionParser.getCollectionRole() );
 				}
 				q.appendScalarSelectToken( aggregatePathExpressionParser.getWhereColumn() );
 				if ( aggregateAddSelectScalar ) {
 					q.addSelectScalar( aggregateType( aggregateFuncTokenList, aggregatePathExpressionParser.getWhereColumnType(), q ) );
 					aggregateAddSelectScalar = false;
 				}
 				aggregatePathExpressionParser.addAssociation( q );
 			}
 		}
 		else {
 			if ( !ready ) {
 				throw new QueryException( ", expected in SELECT" );
 			}
 			ParserHelper.parse( pathExpressionParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 			if ( pathExpressionParser.isCollectionValued() ) {
 				q.addCollection( pathExpressionParser.getCollectionName(),
 						pathExpressionParser.getCollectionRole() );
 			}
 			else if ( pathExpressionParser.getWhereColumnType().isEntityType() ) {
 				q.addSelectClass( pathExpressionParser.getSelectName() );
 			}
 			q.appendScalarSelectTokens( pathExpressionParser.getWhereColumns() );
 			q.addSelectScalar( pathExpressionParser.getWhereColumnType() );
 			pathExpressionParser.addAssociation( q );
 
 			ready = false;
 		}
 	}
 
 	public boolean aggregateHasArgs(String funcToken, QueryTranslatorImpl q) {
 		return getFunction( funcToken, q ).hasArguments();
 	}
 
 	public boolean aggregateFuncNoArgsHasParenthesis(String funcToken, QueryTranslatorImpl q) {
 		return getFunction( funcToken, q ).hasParenthesesIfNoArguments();
 	}
 
 	public Type aggregateType(List funcTokenList, Type type, QueryTranslatorImpl q) throws QueryException {
 		Type retType = type;
 		Type argType;
 		for ( int i = funcTokenList.size() - 1; i >= 0; i-- ) {
 			argType = retType;
 			String funcToken = ( String ) funcTokenList.get( i );
 			retType = getFunction( funcToken, q ).getReturnType( argType, q.getFactory() );
 		}
 		return retType;
 	}
 
 	private SQLFunction getFunction(String name, QueryTranslatorImpl q) {
 		return q.getFactory().getSqlFunctionRegistry().findSQLFunction( name );
 	}
 
 	public void start(QueryTranslatorImpl q) {
 		ready = true;
 		first = true;
 		aggregate = false;
 		afterNew = false;
 		insideNew = false;
 		holderClass = null;
 		aggregateFuncTokenList.clear();
 	}
 
 	public void end(QueryTranslatorImpl q) {
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
index 3c7d56ae49..ff21adbaf2 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
@@ -1,530 +1,532 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPropertyNames;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.InFragment;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.LiteralType;
 import org.hibernate.type.Type;
 
 /**
  * Parses the where clause of a hibernate query and translates it to an
  * SQL where clause.
  */
 
 // We should reengineer this class so that, rather than the current ad -
 // hoc linear approach to processing a stream of tokens, we instead
 // build up a tree of expressions.
 
 // We would probably refactor to have LogicParser (builds a tree of simple
 // expressions connected by and, or, not), ExpressionParser (translates
 // from OO terms like foo, foo.Bar, foo.Bar.Baz to SQL terms like
 // FOOS.ID, FOOS.BAR_ID, etc) and PathExpressionParser (which does much
 // the same thing it does now)
 
 public class WhereParser implements Parser {
 
 	private final PathExpressionParser pathExpressionParser;
 
 	{
 		pathExpressionParser = new PathExpressionParser();
 		pathExpressionParser.setUseThetaStyleJoin( true ); //Need this, since join condition can appear inside parens!
 	}
 
 	private static final Set<String> EXPRESSION_TERMINATORS = new HashSet<String>();   //tokens that close a sub expression
 	private static final Set<String> EXPRESSION_OPENERS = new HashSet<String>();       //tokens that open a sub expression
 	private static final Set<String> BOOLEAN_OPERATORS = new HashSet<String>();        //tokens that would indicate a sub expression is a boolean expression
 	private static final Map<String,String> NEGATIONS = new HashMap<String,String>();
 
 	static {
 		EXPRESSION_TERMINATORS.add( "and" );
 		EXPRESSION_TERMINATORS.add( "or" );
 		EXPRESSION_TERMINATORS.add( ")" );
 		//expressionTerminators.add(","); // deliberately excluded
 
 		EXPRESSION_OPENERS.add( "and" );
 		EXPRESSION_OPENERS.add( "or" );
 		EXPRESSION_OPENERS.add( "(" );
 		//expressionOpeners.add(","); // deliberately excluded
 
 		BOOLEAN_OPERATORS.add( "<" );
 		BOOLEAN_OPERATORS.add( "=" );
 		BOOLEAN_OPERATORS.add( ">" );
 		BOOLEAN_OPERATORS.add( "#" );
 		BOOLEAN_OPERATORS.add( "~" );
 		BOOLEAN_OPERATORS.add( "like" );
 		BOOLEAN_OPERATORS.add( "ilike" );
 		BOOLEAN_OPERATORS.add( "regexp" );
 		BOOLEAN_OPERATORS.add( "rlike" );
 		BOOLEAN_OPERATORS.add( "is" );
 		BOOLEAN_OPERATORS.add( "in" );
 		BOOLEAN_OPERATORS.add( "any" );
 		BOOLEAN_OPERATORS.add( "some" );
 		BOOLEAN_OPERATORS.add( "all" );
 		BOOLEAN_OPERATORS.add( "exists" );
 		BOOLEAN_OPERATORS.add( "between" );
 		BOOLEAN_OPERATORS.add( "<=" );
 		BOOLEAN_OPERATORS.add( ">=" );
 		BOOLEAN_OPERATORS.add( "=>" );
 		BOOLEAN_OPERATORS.add( "=<" );
 		BOOLEAN_OPERATORS.add( "!=" );
 		BOOLEAN_OPERATORS.add( "<>" );
 		BOOLEAN_OPERATORS.add( "!#" );
 		BOOLEAN_OPERATORS.add( "!~" );
 		BOOLEAN_OPERATORS.add( "!<" );
 		BOOLEAN_OPERATORS.add( "!>" );
 		BOOLEAN_OPERATORS.add( "is not" );
 		BOOLEAN_OPERATORS.add( "not like" );
 		BOOLEAN_OPERATORS.add( "not ilike" );
 		BOOLEAN_OPERATORS.add( "not regexp" );
 		BOOLEAN_OPERATORS.add( "not rlike" );
 		BOOLEAN_OPERATORS.add( "not in" );
 		BOOLEAN_OPERATORS.add( "not between" );
 		BOOLEAN_OPERATORS.add( "not exists" );
 
 		NEGATIONS.put( "and", "or" );
 		NEGATIONS.put( "or", "and" );
 		NEGATIONS.put( "<", ">=" );
 		NEGATIONS.put( "=", "<>" );
 		NEGATIONS.put( ">", "<=" );
 		NEGATIONS.put( "#", "!#" );
 		NEGATIONS.put( "~", "!~" );
 		NEGATIONS.put( "like", "not like" );
 		NEGATIONS.put( "ilike", "not ilike" );
 		NEGATIONS.put( "regexp", "not regexp" );
 		NEGATIONS.put( "rlike", "not rlike" );
 		NEGATIONS.put( "is", "is not" );
 		NEGATIONS.put( "in", "not in" );
 		NEGATIONS.put( "exists", "not exists" );
 		NEGATIONS.put( "between", "not between" );
 		NEGATIONS.put( "<=", ">" );
 		NEGATIONS.put( ">=", "<" );
 		NEGATIONS.put( "=>", "<" );
 		NEGATIONS.put( "=<", ">" );
 		NEGATIONS.put( "!=", "=" );
 		NEGATIONS.put( "<>", "=" );
 		NEGATIONS.put( "!#", "#" );
 		NEGATIONS.put( "!~", "~" );
 		NEGATIONS.put( "!<", "<" );
 		NEGATIONS.put( "!>", ">" );
 		NEGATIONS.put( "is not", "is" );
 		NEGATIONS.put( "not like", "like" );
 		NEGATIONS.put( "not ilike", "ilike" );
 		NEGATIONS.put( "not regexp", "regexp" );
 		NEGATIONS.put( "not rlike", "rlike" );
 		NEGATIONS.put( "not in", "in" );
 		NEGATIONS.put( "not between", "between" );
 		NEGATIONS.put( "not exists", "exists" );
 
 	}
 	// Handles things like:
 	// a and b or c
 	// a and ( b or c )
 	// not a and not b
 	// not ( a and b )
 	// x between y and z            (overloaded "and")
 	// x in ( a, b, c )             (overloaded brackets)
 	// not not a
 	// a is not null                (overloaded "not")
 	// etc......
 	// and expressions like
 	// foo = bar                    (maps to: foo.id = bar.id)
 	// foo.Bar = 'foo'              (maps to: foo.bar = 'foo')
 	// foo.Bar.Baz = 1.0            (maps to: foo.bar = bar.id and bar.baz = 1.0)
 	// 1.0 = foo.Bar.Baz            (maps to: bar.baz = 1.0 and foo.Bar = bar.id)
 	// foo.Bar.Baz = a.B.C          (maps to: bar.Baz = b.C and foo.Bar = bar.id and a.B = b.id)
 	// foo.Bar.Baz + a.B.C          (maps to: bar.Baz + b.C and foo.Bar = bar.id and a.B = b.id)
 	// ( foo.Bar.Baz + 1.0 ) < 2.0  (maps to: ( bar.Baz + 1.0 ) < 2.0 and foo.Bar = bar.id)
 
 	private boolean betweenSpecialCase;       //Inside a BETWEEN ... AND ... expression
 	private boolean negated;
 
 	private boolean inSubselect;
 	private int bracketsSinceSelect;
 	private StringBuilder subselect;
 
 	private boolean expectingPathContinuation;
 	private int expectingIndex;
 
 	// The following variables are stacks that keep information about each subexpression
 	// in the list of nested subexpressions we are currently processing.
 
 	private LinkedList<Boolean> nots = new LinkedList<Boolean>();           //were an odd or even number of NOTs encountered
 	private LinkedList<StringBuilder> joins = new LinkedList<StringBuilder>();          //the join string built up by compound paths inside this expression
 	private LinkedList<Boolean> booleanTests = new LinkedList<Boolean>();   //a flag indicating if the subexpression is known to be boolean
 
 	private String getElementName(PathExpressionParser.CollectionElement element, QueryTranslatorImpl q) throws QueryException {
 		String name;
 		if ( element.isOneToMany ) {
 			name = element.alias;
 		}
 		else {
 			Type type = element.elementType;
 			if ( type.isEntityType() ) { //ie. a many-to-many
 				String entityName = ( ( EntityType ) type ).getAssociatedEntityName();
 				name = pathExpressionParser.continueFromManyToMany( entityName, element.elementColumns, q );
 			}
 			else {
 				throw new QueryException( "illegally dereferenced collection element" );
 			}
 		}
 		return name;
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 		String lcToken = token.toLowerCase(Locale.ROOT);
 
 		//Cope with [,]
 		if ( token.equals( "[" ) && !expectingPathContinuation ) {
 			expectingPathContinuation = false;
 			if ( expectingIndex == 0 ) {
 				throw new QueryException( "unexpected [" );
 			}
 			return;
 		}
 		else if ( token.equals( "]" ) ) {
 			expectingIndex--;
 			expectingPathContinuation = true;
 			return;
 		}
 
 		//Cope with a continued path expression (ie. ].baz)
 		if ( expectingPathContinuation ) {
 			boolean pathExpressionContinuesFurther = continuePathExpression( token, q );
 			if ( pathExpressionContinuesFurther ) {
 				return; //NOTE: early return
 			}
 		}
 
 		//Cope with a subselect
 		if ( !inSubselect && ( lcToken.equals( "select" ) || lcToken.equals( "from" ) ) ) {
 			inSubselect = true;
 			subselect = new StringBuilder( 20 );
 		}
 		if ( inSubselect && token.equals( ")" ) ) {
 			bracketsSinceSelect--;
 
 			if ( bracketsSinceSelect == -1 ) {
 				QueryTranslatorImpl subq = new QueryTranslatorImpl(
-				        subselect.toString(),
+						subselect.toString(),
 						q.getEnabledFilters(),
 						q.getFactory()
 				);
 				try {
 					subq.compile( q );
 				}
 				catch ( MappingException me ) {
 					throw new QueryException( "MappingException occurred compiling subquery", me );
 				}
 				appendToken( q, subq.getSQLString() );
 				inSubselect = false;
 				bracketsSinceSelect = 0;
 			}
 		}
 		if ( inSubselect ) {
 			if ( token.equals( "(" ) ) {
 				bracketsSinceSelect++;
 			}
 			subselect.append( token ).append( ' ' );
 			return;
 		}
 
 		//Cope with special cases of AND, NOT, ()
 		specialCasesBefore( lcToken );
 
 		//Close extra brackets we opened
 		if ( !betweenSpecialCase && EXPRESSION_TERMINATORS.contains( lcToken ) ) {
 			closeExpression( q, lcToken );
 		}
 
 		//take note when this is a boolean expression
 		if ( BOOLEAN_OPERATORS.contains( lcToken ) ) {
 			booleanTests.removeLast();
 			booleanTests.addLast( Boolean.TRUE );
 		}
 
 		if ( lcToken.equals( "not" ) ) {
 			nots.addLast(  !(  nots.removeLast() ) );
 			negated = !negated;
 			return; //NOTE: early return
 		}
 
 		//process a token, mapping OO path expressions to SQL expressions
 		doToken( token, q );
 
 		//Open any extra brackets we might need.
 		if ( !betweenSpecialCase && EXPRESSION_OPENERS.contains( lcToken ) ) {
 			openExpression( q, lcToken );
 		}
 
 		//Cope with special cases of AND, NOT, )
 		specialCasesAfter( lcToken );
 
 	}
 
 	public void start(QueryTranslatorImpl q) throws QueryException {
 		token( "(", q );
 	}
 
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		if ( expectingPathContinuation ) {
 			expectingPathContinuation = false;
 			PathExpressionParser.CollectionElement element = pathExpressionParser.lastCollectionElement();
 			if ( element.elementColumns.length != 1 ) {
 				throw new QueryException( "path expression ended in composite collection element" );
 			}
 			appendToken( q, element.elementColumns[0] );
 			addToCurrentJoin( element );
 		}
 		token( ")", q );
 	}
 
 	private void closeExpression(QueryTranslatorImpl q, String lcToken) {
 		if ( booleanTests.removeLast() ) { //it was a boolean expression
 
 			if ( booleanTests.size() > 0 ) {
 				// the next one up must also be
 				booleanTests.removeLast();
 				booleanTests.addLast( Boolean.TRUE );
 			}
 
 			// Add any joins
 			appendToken( q, ( joins.removeLast() ).toString() );
 
 		}
 		else {
 			StringBuilder join = joins.removeLast();
 			joins.getLast().append( join.toString() );
 		}
 
 		if ( nots.removeLast() ) {
 			negated = !negated;
 		}
 
 		if ( !")".equals( lcToken ) ) {
 			appendToken( q, ")" );
 		}
 	}
 
 	private void openExpression(QueryTranslatorImpl q, String lcToken) {
 		nots.addLast( Boolean.FALSE );
 		booleanTests.addLast( Boolean.FALSE );
 		joins.addLast( new StringBuilder() );
 		if ( !"(".equals( lcToken ) ) {
 			appendToken( q, "(" );
 		}
 	}
 
 	private void preprocess(String token, QueryTranslatorImpl q) throws QueryException {
 		// ugly hack for cases like "elements(foo.bar.collection)"
 		// (multi-part path expression ending in elements or indices)
 		String[] tokens = StringHelper.split( ".", token, true );
 		if (
 				tokens.length > 5 &&
 				( CollectionPropertyNames.COLLECTION_ELEMENTS.equals( tokens[tokens.length - 1] )
 				|| CollectionPropertyNames.COLLECTION_INDICES.equals( tokens[tokens.length - 1] ) )
 		) {
 			pathExpressionParser.start( q );
 			for ( int i = 0; i < tokens.length - 3; i++ ) {
 				pathExpressionParser.token( tokens[i], q );
 			}
 			pathExpressionParser.token( null, q );
 			pathExpressionParser.end( q );
 			addJoin( pathExpressionParser.getWhereJoin(), q );
 			pathExpressionParser.ignoreInitialJoin();
 		}
 	}
 
 	private void doPathExpression(String token, QueryTranslatorImpl q) throws QueryException {
 
 		preprocess( token, q );
 
 		StringTokenizer tokens = new StringTokenizer( token, ".", true );
 		pathExpressionParser.start( q );
 		while ( tokens.hasMoreTokens() ) {
 			pathExpressionParser.token( tokens.nextToken(), q );
 		}
 		pathExpressionParser.end( q );
 		if ( pathExpressionParser.isCollectionValued() ) {
 			openExpression( q, "" );
 			appendToken( q, pathExpressionParser.getCollectionSubquery( q.getEnabledFilters() ) );
 			closeExpression( q, "" );
 			// this is ugly here, but needed because its a subquery
 			q.addQuerySpaces( q.getCollectionPersister( pathExpressionParser.getCollectionRole() ).getCollectionSpaces() );
 		}
 		else {
 			if ( pathExpressionParser.isExpectingCollectionIndex() ) {
 				expectingIndex++;
 			}
 			else {
 				addJoin( pathExpressionParser.getWhereJoin(), q );
 				appendToken( q, pathExpressionParser.getWhereColumn() );
 			}
 		}
 	}
 
 	private void addJoin(JoinSequence joinSequence, QueryTranslatorImpl q) throws QueryException {
 		//JoinFragment fromClause = q.createJoinFragment(true);
 		//fromClause.addJoins( join.toJoinFragment().toFromFragmentString(), StringHelper.EMPTY_STRING );
 		q.addFromJoinOnly( pathExpressionParser.getName(), joinSequence );
 		try {
 			addToCurrentJoin( joinSequence.toJoinFragment( q.getEnabledFilters(), true ).toWhereFragmentString() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void doToken(String token, QueryTranslatorImpl q) throws QueryException {
 		if ( q.isName( StringHelper.root( token ) ) ) { //path expression
 			doPathExpression( q.unalias( token ), q );
 		}
 		else if ( token.startsWith( ParserHelper.HQL_VARIABLE_PREFIX ) ) { //named query parameter
 			q.addNamedParameter( token.substring( 1 ) );
 			appendToken( q, "?" );
 		}
 		else {
 			Queryable persister = q.getEntityPersisterUsingImports( token );
 			if ( persister != null ) { // the name of a class
 				final String discrim = persister.getDiscriminatorSQLValue();
 				if ( InFragment.NULL.equals(discrim) || InFragment.NOT_NULL.equals(discrim) ) {
 					throw new QueryException( "subclass test not allowed for null or not null discriminator" );
 				}
 				else {
 					appendToken( q, discrim );
 				}
 			}
 			else {
 				Object constant;
 				if (
 						token.indexOf( '.' ) > -1 &&
 						( constant = ReflectHelper.getConstantValue( token ) ) != null
 				) {
 					Type type;
 					try {
 						type = q.getFactory().getTypeResolver().heuristicType( constant.getClass().getName() );
 					}
 					catch ( MappingException me ) {
 						throw new QueryException( me );
 					}
-					if ( type == null ) throw new QueryException( QueryTranslator.ERROR_CANNOT_DETERMINE_TYPE + token );
+					if ( type == null ) {
+						throw new QueryException( QueryTranslator.ERROR_CANNOT_DETERMINE_TYPE + token );
+					}
 					try {
 						//noinspection unchecked
 						appendToken( q, ( ( LiteralType ) type ).objectToSQLString( constant, q.getFactory().getDialect() ) );
 					}
 					catch ( Exception e ) {
 						throw new QueryException( QueryTranslator.ERROR_CANNOT_FORMAT_LITERAL + token, e );
 					}
 				}
 				else { //anything else
 
 					String negatedToken = negated ? NEGATIONS.get( token.toLowerCase(Locale.ROOT) ) : null;
 					if ( negatedToken != null && ( !betweenSpecialCase || !"or".equals( negatedToken ) ) ) {
 						appendToken( q, negatedToken );
 					}
 					else {
 						appendToken( q, token );
 					}
 				}
 			}
 		}
 	}
 
 	private void addToCurrentJoin(String sql) {
 		joins.getLast().append( sql );
 	}
 
 	private void addToCurrentJoin(PathExpressionParser.CollectionElement ce)
 			throws QueryException {
 		try {
 			addToCurrentJoin( ce.joinSequence.toJoinFragment().toWhereFragmentString() + ce.indexValue.toString() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void specialCasesBefore(String lcToken) {
 		if ( lcToken.equals( "between" ) || lcToken.equals( "not between" ) ) {
 			betweenSpecialCase = true;
 		}
 	}
 
 	private void specialCasesAfter(String lcToken) {
 		if ( betweenSpecialCase && lcToken.equals( "and" ) ) {
 			betweenSpecialCase = false;
 		}
 	}
 
 	void appendToken(QueryTranslatorImpl q, String token) {
 		if ( expectingIndex > 0 ) {
 			pathExpressionParser.setLastCollectionElementIndexValue( token );
 		}
 		else {
 			q.appendWhereToken( token );
 		}
 	}
 
 	private boolean continuePathExpression(String token, QueryTranslatorImpl q) throws QueryException {
 
 		expectingPathContinuation = false;
 
 		PathExpressionParser.CollectionElement element = pathExpressionParser.lastCollectionElement();
 
 		if ( token.startsWith( "." ) ) { // the path expression continues after a ]
 
 			doPathExpression( getElementName( element, q ) + token, q ); // careful with this!
 
 			addToCurrentJoin( element );
 			return true; //NOTE: EARLY EXIT!
 
 		}
 
 		else { // the path expression ends at the ]
 			if ( element.elementColumns.length != 1 ) {
 				throw new QueryException( "path expression ended in composite collection element" );
 			}
 			appendToken( q, element.elementColumns[0] );
 			addToCurrentJoin( element );
 			return false;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/spi/QueryTranslator.java b/hibernate-core/src/main/java/org/hibernate/hql/spi/QueryTranslator.java
index 7de8ef02cb..5109187206 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/spi/QueryTranslator.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/spi/QueryTranslator.java
@@ -1,192 +1,190 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.spi;
 
 import java.io.Serializable;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.type.Type;
 
 /**
  * Defines the contract of an HQL->SQL translator.
  *
  * @author josh
  */
 public interface QueryTranslator {
-
-	// Error message constants.
-	public static final String ERROR_CANNOT_FETCH_WITH_ITERATE = "fetch may not be used with scroll() or iterate()";
-	public static final String ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR = "Named parameter does not appear in Query: ";
-    public static final String ERROR_CANNOT_DETERMINE_TYPE = "Could not determine type of: ";
-	public static final String ERROR_CANNOT_FORMAT_LITERAL =  "Could not format constant value to SQL literal: ";
+	String ERROR_CANNOT_FETCH_WITH_ITERATE = "fetch may not be used with scroll() or iterate()";
+	String ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR = "Named parameter does not appear in Query: ";
+	String ERROR_CANNOT_DETERMINE_TYPE = "Could not determine type of: ";
+	String ERROR_CANNOT_FORMAT_LITERAL =  "Could not format constant value to SQL literal: ";
 
 	/**
 	 * Compile a "normal" query. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 *
 	 * @param replacements Defined query substitutions.
 	 * @param shallow      Does this represent a shallow (scalar or entity-id) select?
 	 * @throws QueryException   There was a problem parsing the query string.
 	 * @throws MappingException There was a problem querying defined mappings.
 	 */
 	void compile(Map replacements, boolean shallow) throws QueryException, MappingException;
 
 	/**
 	 * Perform a list operation given the underlying query definition.
 	 *
 	 * @param session         The session owning this query.
 	 * @param queryParameters The query bind parameters.
 	 * @return The query list results.
 	 * @throws HibernateException
 	 */
 	List list(SessionImplementor session, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Perform an iterate operation given the underlying query definition.
 	 *
 	 * @param queryParameters The query bind parameters.
 	 * @param session         The session owning this query.
 	 * @return An iterator over the query results.
 	 * @throws HibernateException
 	 */
 	Iterator iterate(QueryParameters queryParameters, EventSource session)
 			throws HibernateException;
 
 	/**
 	 * Perform a scroll operation given the underlying query definition.
 	 *
 	 * @param queryParameters The query bind parameters.
 	 * @param session         The session owning this query.
 	 * @return The ScrollableResults wrapper around the query results.
 	 * @throws HibernateException
 	 */
 	ScrollableResults scroll(QueryParameters queryParameters, SessionImplementor session)
 			throws HibernateException;
 
 	/**
 	 * Perform a bulk update/delete operation given the underlying query definition.
 	 *
 	 * @param queryParameters The query bind parameters.
 	 * @param session         The session owning this query.
 	 * @return The number of entities updated or deleted.
 	 * @throws HibernateException
 	 */
 	int executeUpdate(QueryParameters queryParameters, SessionImplementor session)
 			throws HibernateException;
 
 	/**
 	 * Returns the set of query spaces (table names) that the query refers to.
 	 *
 	 * @return A set of query spaces (table names).
 	 */
 	Set<Serializable> getQuerySpaces();
 
 	/**
 	 * Retrieve the query identifier for this translator.  The query identifier is
 	 * used in states collection.
 	 *
 	 * @return the identifier
 	 */
 	String getQueryIdentifier();
 
 	/**
 	 * Returns the SQL string generated by the translator.
 	 *
 	 * @return the SQL string generated by the translator.
 	 */
 	String getSQLString();
 
 	List<String> collectSqlStrings();
 
 	/**
 	 * Returns the HQL string processed by the translator.
 	 *
 	 * @return the HQL string processed by the translator.
 	 */
 	String getQueryString();
 
 	/**
 	 * Returns the filters enabled for this query translator.
 	 *
 	 * @return Filters enabled for this query execution.
 	 */
 	Map getEnabledFilters();
 
 	/**
 	 * Returns an array of Types represented in the query result.
 	 *
 	 * @return Query return types.
 	 */
 	Type[] getReturnTypes();
 	
 	/**
 	 * Returns an array of HQL aliases
 	 */
 	String[] getReturnAliases();
 
 	/**
 	 * Returns the column names in the generated SQL.
 	 *
 	 * @return the column names in the generated SQL.
 	 */
 	String[][] getColumnNames();
 
 	/**
 	 * Return information about any parameters encountered during
 	 * translation.
 	 *
 	 * @return The parameter information.
 	 */
 	ParameterTranslations getParameterTranslations();
 
 	/**
 	 * Validate the scrollability of the translated query.
 	 *
 	 * @throws HibernateException
 	 */
 	void validateScrollability() throws HibernateException;
 
 	/**
 	 * Does the translated query contain collection fetches?
 	 *
 	 * @return true if the query does contain collection fetched;
 	 * false otherwise.
 	 */
 	boolean containsCollectionFetches();
 
 	boolean isManipulationStatement();
 
-	public Class getDynamicInstantiationResultType();
+	Class getDynamicInstantiationResultType();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/AbstractMultiTableBulkIdStrategyImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/AbstractMultiTableBulkIdStrategyImpl.java
index ad06120d7c..de92a1589b 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/AbstractMultiTableBulkIdStrategyImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/AbstractMultiTableBulkIdStrategyImpl.java
@@ -1,213 +1,211 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.spi.id;
 
-import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
-import java.util.List;
 import java.util.Map;
 
 import org.hibernate.QueryException;
 import org.hibernate.boot.model.relational.QualifiedTableName;
 import org.hibernate.boot.spi.MetadataBuildingOptions;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Table;
 import org.hibernate.persister.entity.Queryable;
 
 /**
  * Convenience base class for MultiTableBulkIdStrategy implementations.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractMultiTableBulkIdStrategyImpl<TT extends IdTableInfo, CT extends AbstractMultiTableBulkIdStrategyImpl.PreparationContext>
 		implements MultiTableBulkIdStrategy {
 
 	private final IdTableSupport idTableSupport;
 	private Map<String,TT> idTableInfoMap = new HashMap<String, TT>();
 
 	public AbstractMultiTableBulkIdStrategyImpl(IdTableSupport idTableSupport) {
 		this.idTableSupport = idTableSupport;
 	}
 
 	public IdTableSupport getIdTableSupport() {
 		return idTableSupport;
 	}
 
 	@Override
 	public final void prepare(
 			JdbcServices jdbcServices,
 			JdbcConnectionAccess connectionAccess,
 			MetadataImplementor metadata,
 			SessionFactoryOptions sessionFactoryOptions) {
 		// build/get Table representation of the bulk-id tables - subclasses need hooks
 		// for each:
 		// 		handle DDL
 		// 		build insert-select
 		//		build id-subselect
 
 		final CT context =  buildPreparationContext();
 
 		initialize( metadata.getMetadataBuildingOptions(), sessionFactoryOptions );
 
 		final JdbcEnvironment jdbcEnvironment = jdbcServices.getJdbcEnvironment();
 
 		for ( PersistentClass entityBinding : metadata.getEntityBindings() ) {
 			if ( !IdTableHelper.INSTANCE.needsIdTable( entityBinding ) ) {
 				continue;
 			}
 
 			final String idTableName = jdbcEnvironment.getQualifiedObjectNameFormatter().format(
 					determineIdTableName( jdbcEnvironment, entityBinding ),
 					jdbcEnvironment.getDialect()
 			);
 			final Table idTable = new Table();
 			idTable.setName( idTableName );
 			idTable.setComment( "Used to hold id values for the " + entityBinding.getEntityName() + " entity" );
 
 			Iterator itr = entityBinding.getTable().getPrimaryKey().getColumnIterator();
 			while( itr.hasNext() ) {
 				Column column = (Column) itr.next();
 				idTable.addColumn( column.clone()  );
 			}
 			augmentIdTableDefinition( idTable );
 
 			final TT idTableInfo = buildIdTableInfo( entityBinding, idTable, jdbcServices, metadata, context );
 			idTableInfoMap.put( entityBinding.getEntityName(), idTableInfo );
 		}
 
 		finishPreparation( jdbcServices, connectionAccess, metadata, context );
 	}
 
 	protected CT buildPreparationContext() {
 		return null;
 	}
 
 
 	/**
 	 * Configure ourselves.  By default, nothing to do; here totally for subclass hook-in
 	 *
 	 * @param buildingOptions Access to user-defined Metadata building options
 	 * @param sessionFactoryOptions
 	 */
 	protected void initialize(MetadataBuildingOptions buildingOptions, SessionFactoryOptions sessionFactoryOptions) {
 		// by default nothing to do
 	}
 
 	protected QualifiedTableName determineIdTableName(JdbcEnvironment jdbcEnvironment, PersistentClass entityBinding) {
 		final String entityPrimaryTableName = entityBinding.getTable().getName();
 		final String idTableName = getIdTableSupport().generateIdTableName( entityPrimaryTableName );
 
 		// by default no explicit catalog/schema
 		return new QualifiedTableName(
 				null,
 				null,
 				jdbcEnvironment.getIdentifierHelper().toIdentifier( idTableName )
 		);
 
 	}
 
 	protected void augmentIdTableDefinition(Table idTable) {
 		// by default nothing to do
 	}
 
 	protected abstract TT buildIdTableInfo(
 			PersistentClass entityBinding,
 			Table idTable,
 			JdbcServices jdbcServices,
 			MetadataImplementor metadata,
 			CT context);
 
 
 	protected String buildIdTableCreateStatement(Table idTable, JdbcServices jdbcServices, MetadataImplementor metadata) {
 		final JdbcEnvironment jdbcEnvironment = jdbcServices.getJdbcEnvironment();
 		final Dialect dialect = jdbcEnvironment.getDialect();
 
 		StringBuilder buffer = new StringBuilder( getIdTableSupport().getCreateIdTableCommand() )
 				.append( ' ' )
 				.append( jdbcEnvironment.getQualifiedObjectNameFormatter().format( idTable.getQualifiedTableName(), dialect ) )
 				.append( " (" );
 
 		Iterator itr = idTable.getColumnIterator();
 		while ( itr.hasNext() ) {
 			final Column column = (Column) itr.next();
 			buffer.append( column.getQuotedName( dialect ) ).append( ' ' );
 			buffer.append( column.getSqlType( dialect, metadata ) );
 			if ( column.isNullable() ) {
 				buffer.append( dialect.getNullColumnString() );
 			}
 			else {
 				buffer.append( " not null" );
 			}
 			if ( itr.hasNext() ) {
 				buffer.append( ", " );
 			}
 		}
 
 		buffer.append( ") " );
 		if ( getIdTableSupport().getCreateIdTableStatementOptions() != null ) {
 			buffer.append( getIdTableSupport().getCreateIdTableStatementOptions() );
 		}
 
 		return buffer.toString();
 	}
 
 	protected String buildIdTableDropStatement(Table idTable, JdbcServices jdbcServices) {
 		final JdbcEnvironment jdbcEnvironment = jdbcServices.getJdbcEnvironment();
 		final Dialect dialect = jdbcEnvironment.getDialect();
 
 		return getIdTableSupport().getDropIdTableCommand() + " "
 				+ jdbcEnvironment.getQualifiedObjectNameFormatter().format( idTable.getQualifiedTableName(), dialect );
 	}
 
 	protected void finishPreparation(
 			JdbcServices jdbcServices,
 			JdbcConnectionAccess connectionAccess,
 			MetadataImplementor metadata,
 			CT context) {
 	}
 
 	protected TT getIdTableInfo(Queryable targetedPersister) {
 		return getIdTableInfo( targetedPersister.getEntityName() );
 	}
 
 	protected TT getIdTableInfo(String entityName) {
 		TT tableInfo = idTableInfoMap.get( entityName );
 		if ( tableInfo == null ) {
 			throw new QueryException( "Entity does not have an id table for multi-table handling : " + entityName );
 		}
 		return tableInfo;
 	}
 
 	public static interface PreparationContext {
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/IdTableSupport.java b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/IdTableSupport.java
index 4ebd8bc3b8..130715db41 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/IdTableSupport.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/IdTableSupport.java
@@ -1,36 +1,34 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.spi.id;
 
-import org.hibernate.hql.spi.id.local.AfterUseAction;
-
 /**
  * @author Steve Ebersole
  */
 public interface IdTableSupport {
-	public String generateIdTableName(String baseName);
-	public String getCreateIdTableCommand();
-	public String getCreateIdTableStatementOptions();
-	public String getDropIdTableCommand();
+	String generateIdTableName(String baseName);
+	String getCreateIdTableCommand();
+	String getCreateIdTableStatementOptions();
+	String getDropIdTableCommand();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
index a072bd3ea8..02950141ff 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
@@ -1,85 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
 /**
  * Generates <tt>string</tt> values using the SQL Server NEWID() function.
  *
  * @author Joseph Fifield
  */
 public class GUIDGenerator implements IdentifierGenerator {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( GUIDGenerator.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( GUIDGenerator.class );
 
 	private static boolean WARNED;
 
 	public GUIDGenerator() {
 		if ( !WARNED ) {
 			WARNED = true;
-            LOG.deprecatedUuidGenerator( UUIDGenerator.class.getName(), UUIDGenerationStrategy.class.getName() );
+			LOG.deprecatedUuidGenerator( UUIDGenerator.class.getName(), UUIDGenerationStrategy.class.getName() );
 		}
 	}
 
 	public Serializable generate(SessionImplementor session, Object obj) throws HibernateException {
 		final String sql = session.getFactory().getDialect().getSelectGUIDString();
 		try {
 			PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				final String result;
 				try {
 					if ( !rs.next() ) {
 						throw new HibernateException( "The database returned no GUID identity value" );
 					}
-					result = rs.getString(1);
+					result = rs.getString( 1 );
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
-                LOG.guidGenerated(result);
+				LOG.guidGenerated( result );
 				return result;
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve GUID",
 					sql
-				);
+			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/IdentifierGeneratorHelper.java b/hibernate-core/src/main/java/org/hibernate/id/IdentifierGeneratorHelper.java
index 10e442e306..d42f998c4b 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/IdentifierGeneratorHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/IdentifierGeneratorHelper.java
@@ -1,727 +1,725 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.CustomType;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * Factory and helper methods for {@link IdentifierGenerator} framework.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public final class IdentifierGeneratorHelper {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
-                                                                       IdentifierGeneratorHelper.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( IdentifierGeneratorHelper.class );
 
 	/**
 	 * Marker object returned from {@link IdentifierGenerator#generate} to indicate that we should short-circuit any
 	 * continued generated id checking.  Currently this is only used in the case of the
 	 * {@link org.hibernate.id.ForeignGenerator foreign} generator as a way to signal that we should use the associated
 	 * entity's id value.
 	 */
 	public static final Serializable SHORT_CIRCUIT_INDICATOR = new Serializable() {
 		@Override
 		public String toString() {
 			return "SHORT_CIRCUIT_INDICATOR";
 		}
 	};
 
 	/**
 	 * Marker object returned from {@link IdentifierGenerator#generate} to indicate that the entity's identifier will
 	 * be generated as part of the datbase insertion.
 	 */
 	public static final Serializable POST_INSERT_INDICATOR = new Serializable() {
 		@Override
 		public String toString() {
 			return "POST_INSERT_INDICATOR";
 		}
 	};
 
 
 	/**
 	 * Get the generated identifier when using identity columns
 	 *
 	 * @param rs The result set from which to extract the the generated identity.
 	 * @param identifier The name of the identifier column
 	 * @param type The expected type mapping for the identity value.
 	 *
 	 * @return The generated identity value
 	 *
 	 * @throws SQLException Can be thrown while accessing the result set
 	 * @throws HibernateException Indicates a problem reading back a generated identity value.
 	 */
-	public static Serializable getGeneratedIdentity(ResultSet rs, String identifier, Type type) throws SQLException, HibernateException {
+	public static Serializable getGeneratedIdentity(ResultSet rs, String identifier, Type type)
+			throws SQLException, HibernateException {
 		if ( !rs.next() ) {
 			throw new HibernateException( "The database returned no natively generated identity value" );
 		}
 		final Serializable id = get( rs, identifier, type );
 		LOG.debugf( "Natively generated identity: %s", id );
 		return id;
 	}
 
 	/**
 	 * Extract the value from the result set (which is assumed to already have been positioned to the apopriate row)
 	 * and wrp it in the appropriate Java numeric type.
 	 *
 	 * @param rs The result set from which to extract the value.
 	 * @param identifier The name of the identifier column
 	 * @param type The expected type of the value.
 	 *
 	 * @return The extracted value.
 	 *
 	 * @throws SQLException Indicates problems access the result set
 	 * @throws IdentifierGenerationException Indicates an unknown type.
 	 */
-	public static Serializable get(ResultSet rs, String identifier, Type type) throws SQLException, IdentifierGenerationException {
+	public static Serializable get(ResultSet rs, String identifier, Type type)
+			throws SQLException, IdentifierGenerationException {
 		if ( ResultSetIdentifierConsumer.class.isInstance( type ) ) {
-			return ( ( ResultSetIdentifierConsumer ) type ).consumeIdentifier( rs );
+			return ( (ResultSetIdentifierConsumer) type ).consumeIdentifier( rs );
 		}
 		if ( CustomType.class.isInstance( type ) ) {
 			final CustomType customType = (CustomType) type;
 			if ( ResultSetIdentifierConsumer.class.isInstance( customType.getUserType() ) ) {
 				return ( (ResultSetIdentifierConsumer) customType.getUserType() ).consumeIdentifier( rs );
 			}
 		}
 		int columnCount = 1;
 		try {
 			columnCount = rs.getMetaData().getColumnCount();
 		}
-		catch(Exception e){
+		catch (Exception e) {
 			//Oracle driver will throw NPE
 		}
 
 		Class clazz = type.getReturnedClass();
-		if (columnCount == 1) {
+		if ( columnCount == 1 ) {
 			if ( clazz == Long.class ) {
 				return rs.getLong( 1 );
 			}
 			else if ( clazz == Integer.class ) {
 				return rs.getInt( 1 );
 			}
 			else if ( clazz == Short.class ) {
 				return rs.getShort( 1 );
 			}
 			else if ( clazz == String.class ) {
 				return rs.getString( 1 );
 			}
 			else if ( clazz == BigInteger.class ) {
 				return rs.getBigDecimal( 1 ).setScale( 0, BigDecimal.ROUND_UNNECESSARY ).toBigInteger();
 			}
 			else if ( clazz == BigDecimal.class ) {
 				return rs.getBigDecimal( 1 ).setScale( 0, BigDecimal.ROUND_UNNECESSARY );
 			}
 			else {
 				throw new IdentifierGenerationException(
 						"unrecognized id type : " + type.getName() + " -> " + clazz.getName()
 				);
 			}
 		}
 		else {
 			if ( clazz == Long.class ) {
-				return rs.getLong(identifier);
+				return rs.getLong( identifier );
 			}
 			else if ( clazz == Integer.class ) {
-				return rs.getInt(identifier);
+				return rs.getInt( identifier );
 			}
 			else if ( clazz == Short.class ) {
-				return rs.getShort(identifier);
+				return rs.getShort( identifier );
 			}
 			else if ( clazz == String.class ) {
-				return rs.getString(identifier);
+				return rs.getString( identifier );
 			}
 			else if ( clazz == BigInteger.class ) {
-				return rs.getBigDecimal(identifier).setScale( 0, BigDecimal.ROUND_UNNECESSARY ).toBigInteger();
+				return rs.getBigDecimal( identifier ).setScale( 0, BigDecimal.ROUND_UNNECESSARY ).toBigInteger();
 			}
 			else if ( clazz == BigDecimal.class ) {
-				return rs.getBigDecimal(identifier).setScale( 0, BigDecimal.ROUND_UNNECESSARY );
+				return rs.getBigDecimal( identifier ).setScale( 0, BigDecimal.ROUND_UNNECESSARY );
 			}
 			else {
 				throw new IdentifierGenerationException(
 						"unrecognized id type : " + type.getName() + " -> " + clazz.getName()
 				);
 			}
 		}
 	}
 
 	/**
 	 * Wrap the given value in the given Java numeric class.
 	 *
 	 * @param value The primitive value to wrap.
 	 * @param clazz The Java numeric type in which to wrap the value.
 	 *
 	 * @return The wrapped type.
 	 *
 	 * @throws IdentifierGenerationException Indicates an unhandled 'clazz'.
-	 *
 	 * @deprecated Use the {@link #getIntegralDataTypeHolder holders} instead.
 	 */
 	@Deprecated
-    public static Number createNumber(long value, Class clazz) throws IdentifierGenerationException {
+	public static Number createNumber(long value, Class clazz) throws IdentifierGenerationException {
 		if ( clazz == Long.class ) {
 			return value;
 		}
 		else if ( clazz == Integer.class ) {
-			return ( int ) value;
+			return (int) value;
 		}
 		else if ( clazz == Short.class ) {
-			return ( short ) value;
+			return (short) value;
 		}
 		else {
 			throw new IdentifierGenerationException( "unrecognized id type : " + clazz.getName() );
 		}
 	}
 
 	public static IntegralDataTypeHolder getIntegralDataTypeHolder(Class integralType) {
 		if ( integralType == Long.class
 				|| integralType == Integer.class
 				|| integralType == Short.class ) {
 			return new BasicHolder( integralType );
 		}
 		else if ( integralType == BigInteger.class ) {
 			return new BigIntegerHolder();
 		}
 		else if ( integralType == BigDecimal.class ) {
 			return new BigDecimalHolder();
 		}
 		else {
 			throw new IdentifierGenerationException(
 					"Unknown integral data type for ids : " + integralType.getName()
 			);
 		}
 	}
 
 	public static long extractLong(IntegralDataTypeHolder holder) {
 		if ( holder.getClass() == BasicHolder.class ) {
 			( (BasicHolder) holder ).checkInitialized();
 			return ( (BasicHolder) holder ).value;
 		}
 		else if ( holder.getClass() == BigIntegerHolder.class ) {
 			( (BigIntegerHolder) holder ).checkInitialized();
 			return ( (BigIntegerHolder) holder ).value.longValue();
 		}
 		else if ( holder.getClass() == BigDecimalHolder.class ) {
 			( (BigDecimalHolder) holder ).checkInitialized();
 			return ( (BigDecimalHolder) holder ).value.longValue();
 		}
 		throw new IdentifierGenerationException( "Unknown IntegralDataTypeHolder impl [" + holder + "]" );
 	}
 
 	public static BigInteger extractBigInteger(IntegralDataTypeHolder holder) {
 		if ( holder.getClass() == BasicHolder.class ) {
 			( (BasicHolder) holder ).checkInitialized();
 			return BigInteger.valueOf( ( (BasicHolder) holder ).value );
 		}
 		else if ( holder.getClass() == BigIntegerHolder.class ) {
 			( (BigIntegerHolder) holder ).checkInitialized();
 			return ( (BigIntegerHolder) holder ).value;
 		}
 		else if ( holder.getClass() == BigDecimalHolder.class ) {
 			( (BigDecimalHolder) holder ).checkInitialized();
 			// scale should already be set...
 			return ( (BigDecimalHolder) holder ).value.toBigInteger();
 		}
 		throw new IdentifierGenerationException( "Unknown IntegralDataTypeHolder impl [" + holder + "]" );
 	}
 
 	public static BigDecimal extractBigDecimal(IntegralDataTypeHolder holder) {
 		if ( holder.getClass() == BasicHolder.class ) {
 			( (BasicHolder) holder ).checkInitialized();
 			return BigDecimal.valueOf( ( (BasicHolder) holder ).value );
 		}
 		else if ( holder.getClass() == BigIntegerHolder.class ) {
 			( (BigIntegerHolder) holder ).checkInitialized();
 			return new BigDecimal( ( (BigIntegerHolder) holder ).value );
 		}
 		else if ( holder.getClass() == BigDecimalHolder.class ) {
 			( (BigDecimalHolder) holder ).checkInitialized();
 			// scale should already be set...
 			return ( (BigDecimalHolder) holder ).value;
 		}
 		throw new IdentifierGenerationException( "Unknown IntegralDataTypeHolder impl [" + holder + "]" );
 	}
 
 	public static class BasicHolder implements IntegralDataTypeHolder {
 		private final Class exactType;
 		private long value = Long.MIN_VALUE;
 
 		public BasicHolder(Class exactType) {
 			this.exactType = exactType;
 			if ( exactType != Long.class && exactType != Integer.class && exactType != Short.class ) {
 				throw new IdentifierGenerationException( "Invalid type for basic integral holder : " + exactType );
 			}
 		}
 
 		public long getActualLongValue() {
 			return value;
 		}
 
 		public IntegralDataTypeHolder initialize(long value) {
 			this.value = value;
 			return this;
 		}
 
 		public IntegralDataTypeHolder initialize(ResultSet resultSet, long defaultValue) throws SQLException {
 			long value = resultSet.getLong( 1 );
 			if ( resultSet.wasNull() ) {
 				value = defaultValue;
 			}
 			return initialize( value );
 		}
 
 		public void bind(PreparedStatement preparedStatement, int position) throws SQLException {
 			// TODO : bind it as 'exact type'?  Not sure if that gains us anything...
 			preparedStatement.setLong( position, value );
 		}
 
 		public IntegralDataTypeHolder increment() {
 			checkInitialized();
 			value++;
 			return this;
 		}
 
 		private void checkInitialized() {
 			if ( value == Long.MIN_VALUE ) {
 				throw new IdentifierGenerationException( "integral holder was not initialized" );
 			}
 		}
 
 		public IntegralDataTypeHolder add(long addend) {
 			checkInitialized();
 			value += addend;
 			return this;
 		}
 
 		public IntegralDataTypeHolder decrement() {
 			checkInitialized();
 			value--;
 			return this;
 		}
 
 		public IntegralDataTypeHolder subtract(long subtrahend) {
 			checkInitialized();
 			value -= subtrahend;
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(IntegralDataTypeHolder factor) {
 			return multiplyBy( extractLong( factor ) );
 		}
 
 		public IntegralDataTypeHolder multiplyBy(long factor) {
 			checkInitialized();
 			value *= factor;
 			return this;
 		}
 
 		public boolean eq(IntegralDataTypeHolder other) {
 			return eq( extractLong( other ) );
 		}
 
 		public boolean eq(long value) {
 			checkInitialized();
 			return this.value == value;
 		}
 
 		public boolean lt(IntegralDataTypeHolder other) {
 			return lt( extractLong( other ) );
 		}
 
 		public boolean lt(long value) {
 			checkInitialized();
 			return this.value < value;
 		}
 
 		public boolean gt(IntegralDataTypeHolder other) {
 			return gt( extractLong( other ) );
 		}
 
 		public boolean gt(long value) {
 			checkInitialized();
 			return this.value > value;
 		}
 
 		public IntegralDataTypeHolder copy() {
 			BasicHolder copy = new BasicHolder( exactType );
 			copy.value = value;
 			return copy;
 		}
 
 		public Number makeValue() {
 			// TODO : should we check for truncation?
 			checkInitialized();
 			if ( exactType == Long.class ) {
 				return value;
 			}
 			else if ( exactType == Integer.class ) {
-				return ( int ) value;
+				return (int) value;
 			}
 			else {
-				return ( short ) value;
+				return (short) value;
 			}
 		}
 
 		public Number makeValueThenIncrement() {
 			final Number result = makeValue();
 			value++;
 			return result;
 		}
 
 		public Number makeValueThenAdd(long addend) {
 			final Number result = makeValue();
 			value += addend;
 			return result;
 		}
 
 		@Override
-        public String toString() {
+		public String toString() {
 			return "BasicHolder[" + exactType.getName() + "[" + value + "]]";
 		}
 
 		@Override
-        public boolean equals(Object o) {
+		public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			BasicHolder that = (BasicHolder) o;
 
 			return value == that.value;
 		}
 
 		@Override
-        public int hashCode() {
+		public int hashCode() {
 			return (int) ( value ^ ( value >>> 32 ) );
 		}
 	}
 
 	public static class BigIntegerHolder implements IntegralDataTypeHolder {
 		private BigInteger value;
 
 		public IntegralDataTypeHolder initialize(long value) {
 			this.value = BigInteger.valueOf( value );
 			return this;
 		}
 
 		public IntegralDataTypeHolder initialize(ResultSet resultSet, long defaultValue) throws SQLException {
 			final BigDecimal rsValue = resultSet.getBigDecimal( 1 );
 			if ( resultSet.wasNull() ) {
 				return initialize( defaultValue );
 			}
 			this.value = rsValue.setScale( 0, BigDecimal.ROUND_UNNECESSARY ).toBigInteger();
 			return this;
 		}
 
 		public void bind(PreparedStatement preparedStatement, int position) throws SQLException {
 			preparedStatement.setBigDecimal( position, new BigDecimal( value ) );
 		}
 
 		public IntegralDataTypeHolder increment() {
 			checkInitialized();
 			value = value.add( BigInteger.ONE );
 			return this;
 		}
 
 		private void checkInitialized() {
 			if ( value == null ) {
 				throw new IdentifierGenerationException( "integral holder was not initialized" );
 			}
 		}
 
 		public IntegralDataTypeHolder add(long increment) {
 			checkInitialized();
 			value = value.add( BigInteger.valueOf( increment ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder decrement() {
 			checkInitialized();
 			value = value.subtract( BigInteger.ONE );
 			return this;
 		}
 
 		public IntegralDataTypeHolder subtract(long subtrahend) {
 			checkInitialized();
 			value = value.subtract( BigInteger.valueOf( subtrahend ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(IntegralDataTypeHolder factor) {
 			checkInitialized();
 			value = value.multiply( extractBigInteger( factor ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(long factor) {
 			checkInitialized();
 			value = value.multiply( BigInteger.valueOf( factor ) );
 			return this;
 		}
 
 		public boolean eq(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigInteger( other ) ) == 0;
 		}
 
 		public boolean eq(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigInteger.valueOf( value ) ) == 0;
 		}
 
 		public boolean lt(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigInteger( other ) ) < 0;
 		}
 
 		public boolean lt(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigInteger.valueOf( value ) ) < 0;
 		}
 
 		public boolean gt(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigInteger( other ) ) > 0;
 		}
 
 		public boolean gt(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigInteger.valueOf( value ) ) > 0;
 		}
 
 		public IntegralDataTypeHolder copy() {
 			BigIntegerHolder copy = new BigIntegerHolder();
 			copy.value = value;
 			return copy;
 		}
 
 		public Number makeValue() {
 			checkInitialized();
 			return value;
 		}
 
 		public Number makeValueThenIncrement() {
 			final Number result = makeValue();
 			value = value.add( BigInteger.ONE );
 			return result;
 		}
 
 		public Number makeValueThenAdd(long addend) {
 			final Number result = makeValue();
 			value = value.add( BigInteger.valueOf( addend ) );
 			return result;
 		}
 
 		@Override
-        public String toString() {
+		public String toString() {
 			return "BigIntegerHolder[" + value + "]";
 		}
 
 		@Override
-        public boolean equals(Object o) {
+		public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			BigIntegerHolder that = (BigIntegerHolder) o;
 
 			return this.value == null
 					? that.value == null
 					: value.equals( that.value );
 		}
 
 		@Override
-        public int hashCode() {
+		public int hashCode() {
 			return value != null ? value.hashCode() : 0;
 		}
 	}
 
 	public static class BigDecimalHolder implements IntegralDataTypeHolder {
 		private BigDecimal value;
 
 		public IntegralDataTypeHolder initialize(long value) {
 			this.value = BigDecimal.valueOf( value );
 			return this;
 		}
 
 		public IntegralDataTypeHolder initialize(ResultSet resultSet, long defaultValue) throws SQLException {
 			final BigDecimal rsValue = resultSet.getBigDecimal( 1 );
 			if ( resultSet.wasNull() ) {
 				return initialize( defaultValue );
 			}
 			this.value = rsValue.setScale( 0, BigDecimal.ROUND_UNNECESSARY );
 			return this;
 		}
 
 		public void bind(PreparedStatement preparedStatement, int position) throws SQLException {
 			preparedStatement.setBigDecimal( position, value );
 		}
 
 		public IntegralDataTypeHolder increment() {
 			checkInitialized();
 			value = value.add( BigDecimal.ONE );
 			return this;
 		}
 
 		private void checkInitialized() {
 			if ( value == null ) {
 				throw new IdentifierGenerationException( "integral holder was not initialized" );
 			}
 		}
 
 		public IntegralDataTypeHolder add(long increment) {
 			checkInitialized();
 			value = value.add( BigDecimal.valueOf( increment ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder decrement() {
 			checkInitialized();
 			value = value.subtract( BigDecimal.ONE );
 			return this;
 		}
 
 		public IntegralDataTypeHolder subtract(long subtrahend) {
 			checkInitialized();
 			value = value.subtract( BigDecimal.valueOf( subtrahend ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(IntegralDataTypeHolder factor) {
 			checkInitialized();
 			value = value.multiply( extractBigDecimal( factor ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(long factor) {
 			checkInitialized();
 			value = value.multiply( BigDecimal.valueOf( factor ) );
 			return this;
 		}
 
 		public boolean eq(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigDecimal( other ) ) == 0;
 		}
 
 		public boolean eq(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigDecimal.valueOf( value ) ) == 0;
 		}
 
 		public boolean lt(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigDecimal( other ) ) < 0;
 		}
 
 		public boolean lt(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigDecimal.valueOf( value ) ) < 0;
 		}
 
 		public boolean gt(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigDecimal( other ) ) > 0;
 		}
 
 		public boolean gt(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigDecimal.valueOf( value ) ) > 0;
 		}
 
 		public IntegralDataTypeHolder copy() {
 			BigDecimalHolder copy = new BigDecimalHolder();
 			copy.value = value;
 			return copy;
 		}
 
 		public Number makeValue() {
 			checkInitialized();
 			return value;
 		}
 
 		public Number makeValueThenIncrement() {
 			final Number result = makeValue();
 			value = value.add( BigDecimal.ONE );
 			return result;
 		}
 
 		public Number makeValueThenAdd(long addend) {
 			final Number result = makeValue();
 			value = value.add( BigDecimal.valueOf( addend ) );
 			return result;
 		}
 
 		@Override
-        public String toString() {
+		public String toString() {
 			return "BigDecimalHolder[" + value + "]";
 		}
 
 		@Override
-        public boolean equals(Object o) {
+		public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			BigDecimalHolder that = (BigDecimalHolder) o;
 
 			return this.value == null
 					? that.value == null
 					: this.value.equals( that.value );
 		}
 
 		@Override
-        public int hashCode() {
+		public int hashCode() {
 			return value != null ? value.hashCode() : 0;
 		}
 	}
 
 	/**
 	 * Disallow instantiation of IdentifierGeneratorHelper.
 	 */
 	private IdentifierGeneratorHelper() {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/IdentityGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/IdentityGenerator.java
index b47085a50d..0f263e7e32 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/IdentityGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/IdentityGenerator.java
@@ -1,196 +1,213 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.id;
+
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.insert.AbstractReturningDelegate;
 import org.hibernate.id.insert.AbstractSelectingDelegate;
 import org.hibernate.id.insert.IdentifierGeneratingInsert;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.id.insert.InsertSelectIdentityInsert;
 
 /**
  * A generator for use with ANSI-SQL IDENTITY columns used as the primary key.
  * The IdentityGenerator for autoincrement/identity key generation.
  * <br><br>
  * Indicates to the <tt>Session</tt> that identity (ie. identity/autoincrement
  * column) key generation should be used.
  *
  * @author Christoph Sturm
  */
 public class IdentityGenerator extends AbstractPostInsertGenerator {
 
+	@Override
 	public InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
 			PostInsertIdentityPersister persister,
-	        Dialect dialect,
-	        boolean isGetGeneratedKeysEnabled) throws HibernateException {
+			Dialect dialect,
+			boolean isGetGeneratedKeysEnabled) throws HibernateException {
 		if ( isGetGeneratedKeysEnabled ) {
 			return new GetGeneratedKeysDelegate( persister, dialect );
 		}
 		else if ( dialect.supportsInsertSelectIdentity() ) {
 			return new InsertSelectDelegate( persister, dialect );
 		}
 		else {
 			return new BasicDelegate( persister, dialect );
 		}
 	}
 
 	/**
 	 * Delegate for dealing with IDENTITY columns using JDBC3 getGeneratedKeys
 	 */
 	public static class GetGeneratedKeysDelegate
 			extends AbstractReturningDelegate
 			implements InsertGeneratedIdentifierDelegate {
 		private final PostInsertIdentityPersister persister;
 		private final Dialect dialect;
 
 		public GetGeneratedKeysDelegate(PostInsertIdentityPersister persister, Dialect dialect) {
 			super( persister );
 			this.persister = persister;
 			this.dialect = dialect;
 		}
 
+		@Override
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			IdentifierGeneratingInsert insert = new IdentifierGeneratingInsert( dialect );
 			insert.addIdentityColumn( persister.getRootTableKeyColumnNames()[0] );
 			return insert;
 		}
 
+		@Override
 		protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
 			return session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( insertSQL, PreparedStatement.RETURN_GENERATED_KEYS );
 		}
 
-		public Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session) throws SQLException {
+		@Override
+		public Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session)
+				throws SQLException {
 			session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
 			ResultSet rs = null;
 			try {
 				rs = insert.getGeneratedKeys();
 				return IdentifierGeneratorHelper.getGeneratedIdentity(
 						rs,
 						persister.getRootTableKeyColumnNames()[0],
 						persister.getIdentifierType()
 				);
 			}
 			finally {
 				if ( rs != null ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, insert );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Delegate for dealing with IDENTITY columns where the dialect supports returning
 	 * the generated IDENTITY value directly from the insert statement.
 	 */
 	public static class InsertSelectDelegate
 			extends AbstractReturningDelegate
 			implements InsertGeneratedIdentifierDelegate {
 		private final PostInsertIdentityPersister persister;
 		private final Dialect dialect;
 
 		public InsertSelectDelegate(PostInsertIdentityPersister persister, Dialect dialect) {
 			super( persister );
 			this.persister = persister;
 			this.dialect = dialect;
 		}
 
+		@Override
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			InsertSelectIdentityInsert insert = new InsertSelectIdentityInsert( dialect );
 			insert.addIdentityColumn( persister.getRootTableKeyColumnNames()[0] );
 			return insert;
 		}
 
+		@Override
 		protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
 			return session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( insertSQL, PreparedStatement.NO_GENERATED_KEYS );
 		}
 
-		public Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session) throws SQLException {
+		@Override
+		public Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session)
+				throws SQLException {
 			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().execute( insert );
 			try {
 				return IdentifierGeneratorHelper.getGeneratedIdentity(
 						rs,
 						persister.getRootTableKeyColumnNames()[0],
 						persister.getIdentifierType()
 				);
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( rs, insert );
 			}
 		}
 
 		public Serializable determineGeneratedIdentifier(SessionImplementor session, Object entity) {
 			throw new AssertionFailure( "insert statement returns generated value" );
 		}
 	}
 
 	/**
 	 * Delegate for dealing with IDENTITY columns where the dialect requires an
 	 * additional command execution to retrieve the generated IDENTITY value
 	 */
 	public static class BasicDelegate
 			extends AbstractSelectingDelegate
 			implements InsertGeneratedIdentifierDelegate {
 		private final PostInsertIdentityPersister persister;
 		private final Dialect dialect;
 
 		public BasicDelegate(PostInsertIdentityPersister persister, Dialect dialect) {
 			super( persister );
 			this.persister = persister;
 			this.dialect = dialect;
 		}
 
+		@Override
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			IdentifierGeneratingInsert insert = new IdentifierGeneratingInsert( dialect );
 			insert.addIdentityColumn( persister.getRootTableKeyColumnNames()[0] );
 			return insert;
 		}
 
+		@Override
 		protected String getSelectSQL() {
 			return persister.getIdentitySelectString();
 		}
 
+		@Override
 		protected Serializable getResult(
 				SessionImplementor session,
-		        ResultSet rs,
-		        Object object) throws SQLException {
-			return IdentifierGeneratorHelper.getGeneratedIdentity( rs, persister.getRootTableKeyColumnNames()[0], persister.getIdentifierType() );
+				ResultSet rs,
+				Object object) throws SQLException {
+			return IdentifierGeneratorHelper.getGeneratedIdentity(
+					rs,
+					persister.getRootTableKeyColumnNames()[0],
+					persister.getIdentifierType()
+			);
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
index f1683e2200..bc0397ad5a 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
@@ -1,157 +1,158 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 
 /**
  * <b>increment</b><br>
  * <br>
  * An <tt>IdentifierGenerator</tt> that returns a <tt>long</tt>, constructed by
  * counting from the maximum primary key value at startup. Not safe for use in a
  * cluster!<br>
  * <br>
  * Mapping parameters supported, but not usually needed: tables, column.
  * (The tables parameter specified a comma-separated list of table names.)
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public class IncrementGenerator implements IdentifierGenerator, Configurable {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( IncrementGenerator.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( IncrementGenerator.class );
 
 	private Class returnClass;
 	private String sql;
 
 	private IntegralDataTypeHolder previousValueHolder;
 
+	@Override
 	public synchronized Serializable generate(SessionImplementor session, Object object) throws HibernateException {
 		if ( sql != null ) {
 			initializePreviousValueHolder( session );
 		}
 		return previousValueHolder.makeValueThenIncrement();
 	}
 
 	@Override
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		returnClass = type.getReturnedClass();
 
 		ObjectNameNormalizer normalizer =
-				( ObjectNameNormalizer ) params.get( PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER );
+				(ObjectNameNormalizer) params.get( PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER );
 
 		String column = params.getProperty( "column" );
 		if ( column == null ) {
 			column = params.getProperty( PersistentIdentifierGenerator.PK );
 		}
 		column = normalizer.normalizeIdentifierQuoting( column ).render( jdbcEnv.getDialect() );
 
 		String tableList = params.getProperty( "tables" );
 		if ( tableList == null ) {
 			tableList = params.getProperty( PersistentIdentifierGenerator.TABLES );
 		}
 		String[] tables = StringHelper.split( ", ", tableList );
 
 		final String schema = normalizer.toDatabaseIdentifierText(
 				params.getProperty( PersistentIdentifierGenerator.SCHEMA )
 		);
 		final String catalog = normalizer.toDatabaseIdentifierText(
 				params.getProperty( PersistentIdentifierGenerator.CATALOG )
 		);
 
 		StringBuilder buf = new StringBuilder();
-		for ( int i=0; i < tables.length; i++ ) {
+		for ( int i = 0; i < tables.length; i++ ) {
 			final String tableName = normalizer.toDatabaseIdentifierText( tables[i] );
 			if ( tables.length > 1 ) {
 				buf.append( "select max(" ).append( column ).append( ") as mx from " );
 			}
 			buf.append( Table.qualify( catalog, schema, tableName ) );
-			if ( i < tables.length-1 ) {
+			if ( i < tables.length - 1 ) {
 				buf.append( " union " );
 			}
 		}
 		if ( tables.length > 1 ) {
 			buf.insert( 0, "( " ).append( " ) ids_" );
 			column = "ids_.mx";
 		}
 
 		sql = "select max(" + column + ") from " + buf.toString();
 	}
 
 	private void initializePreviousValueHolder(SessionImplementor session) {
 		previousValueHolder = IdentifierGeneratorHelper.getIntegralDataTypeHolder( returnClass );
 
 		final boolean debugEnabled = LOG.isDebugEnabled();
 		if ( debugEnabled ) {
 			LOG.debugf( "Fetching initial value: %s", sql );
 		}
 		try {
 			PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
-                    if (rs.next()) {
-						previousValueHolder.initialize(rs, 0L).increment();
+					if ( rs.next() ) {
+						previousValueHolder.initialize( rs, 0L ).increment();
 					}
-                    else {
-						previousValueHolder.initialize(1L);
+					else {
+						previousValueHolder.initialize( 1L );
 					}
 					sql = null;
 					if ( debugEnabled ) {
 						LOG.debugf( "First free id: %s", previousValueHolder.makeValue() );
 					}
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not fetch initial value for increment generator",
 					sql
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
index 46922444f4..c661b51a20 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
@@ -1,356 +1,368 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.boot.model.relational.Database;
 import org.hibernate.boot.model.relational.QualifiedName;
 import org.hibernate.boot.model.relational.QualifiedNameParser;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.engine.spi.SessionEventListenerManager;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.enhanced.AccessCallback;
 import org.hibernate.id.enhanced.LegacyHiLoAlgorithmOptimizer;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.PrimaryKey;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.LongType;
 import org.hibernate.type.StringType;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
- *
  * A hilo <tt>IdentifierGenerator</tt> that returns a <tt>Long</tt>, constructed using
  * a hi/lo algorithm. The hi value MUST be fetched in a seperate transaction
  * to the <tt>Session</tt> transaction so the generator must be able to obtain
  * a new connection and commit it. Hence this implementation may not
  * be used  when the user is supplying connections. In this
  * case a <tt>SequenceHiLoGenerator</tt> would be a better choice (where
  * supported).<br>
  * <br>
- *
+ * <p/>
  * A hilo <tt>IdentifierGenerator</tt> that uses a database
  * table to store the last generated values. A table can contains
  * several hi values. They are distinct from each other through a key
  * <p/>
  * <p>This implementation is not compliant with a user connection</p>
  * <p/>
- *
+ * <p/>
  * <p>Allowed parameters (all of them are optional):</p>
  * <ul>
  * <li>table: table name (default <tt>hibernate_sequences</tt>)</li>
  * <li>primary_key_column: key column name (default <tt>sequence_name</tt>)</li>
  * <li>value_column: hi value column name(default <tt>sequence_next_hi_value</tt>)</li>
  * <li>primary_key_value: key value for the current entity (default to the entity's primary table name)</li>
  * <li>primary_key_length: length of the key column in DB represented as a varchar (default to 255)</li>
  * <li>max_lo: max low value before increasing hi (default to Short.MAX_VALUE)</li>
  * </ul>
  *
  * @author Emmanuel Bernard
  * @author <a href="mailto:kr@hbt.de">Klaus Richarz</a>.
  */
 public class MultipleHiLoPerTableGenerator implements PersistentIdentifierGenerator, Configurable {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
-                                                                       MultipleHiLoPerTableGenerator.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( MultipleHiLoPerTableGenerator.class );
 
 	public static final String ID_TABLE = "table";
 	public static final String PK_COLUMN_NAME = "primary_key_column";
 	public static final String PK_VALUE_NAME = "primary_key_value";
 	public static final String VALUE_COLUMN_NAME = "value_column";
 	public static final String PK_LENGTH_NAME = "primary_key_length";
 
 	private static final int DEFAULT_PK_LENGTH = 255;
 	public static final String DEFAULT_TABLE = "hibernate_sequences";
 	private static final String DEFAULT_PK_COLUMN = "sequence_name";
 	private static final String DEFAULT_VALUE_COLUMN = "sequence_next_hi_value";
 
 	private QualifiedName qualifiedTableName;
 	private String tableName;
 	private String pkColumnName;
 	private String valueColumnName;
 	private String query;
 	private String insert;
 	private String update;
 
 	//hilo params
 	public static final String MAX_LO = "max_lo";
 
 	private int maxLo;
 	private LegacyHiLoAlgorithmOptimizer hiloOptimizer;
 
 	private Class returnClass;
 	private int keySize;
 
 	public synchronized Serializable generate(final SessionImplementor session, Object obj) {
 		final SqlStatementLogger statementLogger = session.getFactory().getServiceRegistry()
 				.getService( JdbcServices.class )
 				.getSqlStatementLogger();
 		final SessionEventListenerManager statsCollector = session.getEventListenerManager();
 
 		final WorkExecutorVisitable<IntegralDataTypeHolder> work = new AbstractReturningWork<IntegralDataTypeHolder>() {
 			@Override
 			public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
 				IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( returnClass );
 
 				int rows;
 				do {
-					final PreparedStatement queryPreparedStatement = prepareStatement( connection, query, statementLogger, statsCollector );
+					final PreparedStatement queryPreparedStatement = prepareStatement(
+							connection,
+							query,
+							statementLogger,
+							statsCollector
+					);
 					try {
 						final ResultSet rs = executeQuery( queryPreparedStatement, statsCollector );
 						boolean isInitialized = rs.next();
 						if ( !isInitialized ) {
 							value.initialize( 0 );
-							final PreparedStatement insertPreparedStatement = prepareStatement( connection, insert, statementLogger, statsCollector );
+							final PreparedStatement insertPreparedStatement = prepareStatement(
+									connection,
+									insert,
+									statementLogger,
+									statsCollector
+							);
 							try {
 								value.bind( insertPreparedStatement, 1 );
 								executeUpdate( insertPreparedStatement, statsCollector );
 							}
 							finally {
 								insertPreparedStatement.close();
 							}
 						}
 						else {
 							value.initialize( rs, 0 );
 						}
 						rs.close();
 					}
 					catch (SQLException sqle) {
 						LOG.unableToReadOrInitHiValue( sqle );
 						throw sqle;
 					}
 					finally {
 						queryPreparedStatement.close();
 					}
 
 
-					final PreparedStatement updatePreparedStatement = prepareStatement( connection, update, statementLogger, statsCollector );
+					final PreparedStatement updatePreparedStatement = prepareStatement(
+							connection,
+							update,
+							statementLogger,
+							statsCollector
+					);
 					try {
 						value.copy().increment().bind( updatePreparedStatement, 1 );
 						value.bind( updatePreparedStatement, 2 );
 
 						rows = executeUpdate( updatePreparedStatement, statsCollector );
 					}
 					catch (SQLException sqle) {
 						LOG.error( LOG.unableToUpdateHiValue( tableName ), sqle );
 						throw sqle;
 					}
 					finally {
 						updatePreparedStatement.close();
 					}
-				} while ( rows==0 );
+				} while ( rows == 0 );
 
 				return value;
 			}
 		};
 
 		// maxLo < 1 indicates a hilo generator with no hilo :?
 		if ( maxLo < 1 ) {
 			//keep the behavior consistent even for boundary usages
 			IntegralDataTypeHolder value = null;
 			while ( value == null || value.lt( 1 ) ) {
 				value = session.getTransactionCoordinator().createIsolationDelegate().delegateWork( work, true );
 			}
 			return value.makeValue();
 		}
 
 		return hiloOptimizer.generate(
 				new AccessCallback() {
 					public IntegralDataTypeHolder getNextValue() {
 						return session.getTransactionCoordinator().createIsolationDelegate().delegateWork(
 								work,
 								true
 						);
 					}
 
 					@Override
 					public String getTenantIdentifier() {
 						return session.getTenantIdentifier();
 					}
 				}
 		);
 	}
 
 	private PreparedStatement prepareStatement(
 			Connection connection,
 			String sql,
 			SqlStatementLogger statementLogger,
 			SessionEventListenerManager statsCollector) throws SQLException {
 		statementLogger.logStatement( sql, FormatStyle.BASIC.getFormatter() );
 		try {
 			statsCollector.jdbcPrepareStatementStart();
 			return connection.prepareStatement( sql );
 		}
 		finally {
 			statsCollector.jdbcPrepareStatementEnd();
 		}
 	}
 
 	private int executeUpdate(PreparedStatement ps, SessionEventListenerManager statsCollector) throws SQLException {
 		try {
 			statsCollector.jdbcExecuteStatementStart();
 			return ps.executeUpdate();
 		}
 		finally {
 			statsCollector.jdbcExecuteStatementEnd();
 		}
 
 	}
 
-	private ResultSet executeQuery(PreparedStatement ps, SessionEventListenerManager statsCollector) throws SQLException {
+	private ResultSet executeQuery(PreparedStatement ps, SessionEventListenerManager statsCollector)
+			throws SQLException {
 		try {
 			statsCollector.jdbcExecuteStatementStart();
 			return ps.executeQuery();
 		}
 		finally {
 			statsCollector.jdbcExecuteStatementEnd();
 		}
 	}
 
 	@SuppressWarnings({"StatementWithEmptyBody", "deprecation"})
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
-		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
+		ObjectNameNormalizer normalizer = (ObjectNameNormalizer) params.get( IDENTIFIER_NORMALIZER );
 
 		qualifiedTableName = QualifiedNameParser.INSTANCE.parse(
 				ConfigurationHelper.getString( ID_TABLE, params, DEFAULT_TABLE ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) )
 		);
 
 		tableName = jdbcEnv.getQualifiedObjectNameFormatter().format(
 				qualifiedTableName,
 				jdbcEnv.getDialect()
 		);
 		pkColumnName = normalizer.toDatabaseIdentifierText(
 				ConfigurationHelper.getString( PK_COLUMN_NAME, params, DEFAULT_PK_COLUMN )
 		);
 		valueColumnName = normalizer.toDatabaseIdentifierText(
 				ConfigurationHelper.getString( VALUE_COLUMN_NAME, params, DEFAULT_VALUE_COLUMN )
 		);
 
 		keySize = ConfigurationHelper.getInt( PK_LENGTH_NAME, params, DEFAULT_PK_LENGTH );
 		String keyValue = ConfigurationHelper.getString( PK_VALUE_NAME, params, params.getProperty( TABLE ) );
 
 		query = "select " +
-			valueColumnName +
-			" from " +
-			jdbcEnv.getDialect().appendLockHint( LockMode.PESSIMISTIC_WRITE, tableName ) +
-			" where " + pkColumnName + " = '" + keyValue + "'" +
+				valueColumnName +
+				" from " +
+				jdbcEnv.getDialect().appendLockHint( LockMode.PESSIMISTIC_WRITE, tableName ) +
+				" where " + pkColumnName + " = '" + keyValue + "'" +
 				jdbcEnv.getDialect().getForUpdateString();
 
 		update = "update " +
-			tableName +
-			" set " +
-			valueColumnName +
-			" = ? where " +
-			valueColumnName +
-			" = ? and " +
-			pkColumnName +
-			" = '" +
-			keyValue
-			+ "'";
+				tableName +
+				" set " +
+				valueColumnName +
+				" = ? where " +
+				valueColumnName +
+				" = ? and " +
+				pkColumnName +
+				" = '" +
+				keyValue
+				+ "'";
 
 		insert = "insert into " + tableName +
-			"(" + pkColumnName + ", " +	valueColumnName + ") " +
-			"values('"+ keyValue +"', ?)";
+				"(" + pkColumnName + ", " + valueColumnName + ") " +
+				"values('" + keyValue + "', ?)";
 
 
 		//hilo config
-		maxLo = ConfigurationHelper.getInt(MAX_LO, params, Short.MAX_VALUE);
+		maxLo = ConfigurationHelper.getInt( MAX_LO, params, Short.MAX_VALUE );
 		returnClass = type.getReturnedClass();
 
 		if ( maxLo >= 1 ) {
 			hiloOptimizer = new LegacyHiLoAlgorithmOptimizer( returnClass, maxLo );
 		}
 	}
 
 	@Override
 	public void registerExportables(Database database) {
 		final Schema schema = database.locateSchema(
 				qualifiedTableName.getCatalogName(),
 				qualifiedTableName.getSchemaName()
 		);
 
 		final Table table = schema.createTable( qualifiedTableName.getObjectName(), false );
 		table.setPrimaryKey( new PrimaryKey() );
 
 		final Column pkColumn = new ExportableColumn(
 				database,
 				table,
 				pkColumnName,
 				StringType.INSTANCE,
 				database.getDialect().getTypeName( Types.VARCHAR, keySize, 0, 0 )
 		);
 		table.addColumn( pkColumn );
 		table.getPrimaryKey().addColumn( pkColumn );
 
 		final Column valueColumn = new ExportableColumn(
 				database,
 				table,
 				valueColumnName,
 				LongType.INSTANCE
 		);
 		table.addColumn( valueColumn );
 	}
 
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		return new String[] {
 				dialect.getCreateTableString()
 						+ ' ' + tableName + " ( "
 						+ pkColumnName + ' ' + dialect.getTypeName( Types.VARCHAR, keySize, 0, 0 ) + ",  "
 						+ valueColumnName + ' ' + dialect.getTypeName( Types.INTEGER )
 						+ " )" + dialect.getTableTypeString()
 		};
 	}
 
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
-		return new String[] { dialect.getDropTableString( tableName ) };
+		return new String[] {dialect.getDropTableString( tableName )};
 	}
 
 	public Object generatorKey() {
 		return tableName;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/PersistentIdentifierGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/PersistentIdentifierGenerator.java
index 6b619ec069..a4a544a393 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/PersistentIdentifierGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/PersistentIdentifierGenerator.java
@@ -1,107 +1,110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
+
 import org.hibernate.HibernateException;
 import org.hibernate.boot.model.relational.ExportableProducer;
 import org.hibernate.dialect.Dialect;
 
 /**
  * An <tt>IdentifierGenerator</tt> that requires creation of database objects.
  * <br><br>
  * All <tt>PersistentIdentifierGenerator</tt>s that also implement
  * <tt>Configurable</tt> have access to a special mapping parameter: schema
  *
- * @see IdentifierGenerator
- * @see Configurable
- *
  * @author Gavin King
  * @author Steve Ebersole
+ *
+ * @see IdentifierGenerator
+ * @see Configurable
  */
 public interface PersistentIdentifierGenerator extends IdentifierGenerator, ExportableProducer {
 
 	/**
 	 * The configuration parameter holding the schema name
 	 */
-	public static final String SCHEMA = "schema";
+	String SCHEMA = "schema";
 
 	/**
 	 * The configuration parameter holding the table name for the
 	 * generated id
 	 */
-	public static final String TABLE = "target_table";
+	String TABLE = "target_table";
 
 	/**
 	 * The configuration parameter holding the table names for all
 	 * tables for which the id must be unique
 	 */
-	public static final String TABLES = "identity_tables";
+	String TABLES = "identity_tables";
 
 	/**
 	 * The configuration parameter holding the primary key column
 	 * name of the generated id
 	 */
-	public static final String PK = "target_column";
+	String PK = "target_column";
 
-    /**
-     * The configuration parameter holding the catalog name
-     */
-    public static final String CATALOG = "catalog";
+	/**
+	 * The configuration parameter holding the catalog name
+	 */
+	String CATALOG = "catalog";
 
 	/**
 	 * The key under whcih to find the {@link org.hibernate.boot.model.naming.ObjectNameNormalizer} in the config param map.
 	 */
-	public static final String IDENTIFIER_NORMALIZER = "identifier_normalizer";
+	String IDENTIFIER_NORMALIZER = "identifier_normalizer";
 
 	/**
 	 * The SQL required to create the underlying database objects.
 	 *
 	 * @param dialect The dialect against which to generate the create command(s)
+	 *
 	 * @return The create command(s)
-	 * @throws HibernateException problem creating the create command(s)
 	 *
+	 * @throws HibernateException problem creating the create command(s)
 	 * @deprecated Utilize the ExportableProducer contract instead
 	 */
 	@Deprecated
-	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException;
+	String[] sqlCreateStrings(Dialect dialect) throws HibernateException;
 
 	/**
 	 * The SQL required to remove the underlying database objects.
 	 *
 	 * @param dialect The dialect against which to generate the drop command(s)
+	 *
 	 * @return The drop command(s)
-	 * @throws HibernateException problem creating the drop command(s)
 	 *
+	 * @throws HibernateException problem creating the drop command(s)
 	 * @deprecated Utilize the ExportableProducer contract instead
 	 */
 	@Deprecated
-	public String[] sqlDropStrings(Dialect dialect) throws HibernateException;
+	String[] sqlDropStrings(Dialect dialect) throws HibernateException;
 
 	/**
 	 * Return a key unique to the underlying database objects. Prevents us from
 	 * trying to create/remove them multiple times.
-	 * 
+	 *
 	 * @return Object an identifying key for this generator
 	 */
-	public Object generatorKey();
+	Object generatorKey();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/PostInsertIdentifierGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/PostInsertIdentifierGenerator.java
index e763ef0572..189ae67705 100755
--- a/hibernate-core/src/main/java/org/hibernate/id/PostInsertIdentifierGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/PostInsertIdentifierGenerator.java
@@ -1,38 +1,38 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 
 /**
  * @author Gavin King
  */
 public interface PostInsertIdentifierGenerator extends IdentifierGenerator {
-	public InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
+	InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
 			PostInsertIdentityPersister persister,
-	        Dialect dialect,
-	        boolean isGetGeneratedKeysEnabled) throws HibernateException;
+			Dialect dialect,
+			boolean isGetGeneratedKeysEnabled) throws HibernateException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/SelectGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/SelectGenerator.java
index d9948f896a..20c64826e7 100755
--- a/hibernate-core/src/main/java/org/hibernate/id/SelectGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/SelectGenerator.java
@@ -1,160 +1,160 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.insert.AbstractSelectingDelegate;
 import org.hibernate.id.insert.IdentifierGeneratingInsert;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.type.Type;
 
 /**
  * A generator that selects the just inserted row to determine the identifier
  * value assigned by the database. The correct row is located using a unique
  * key.
  * <p/>
  * One mapping parameter is required: key (unless a natural-id is defined in the mapping).
  *
  * @author Gavin King
  */
 public class SelectGenerator extends AbstractPostInsertGenerator implements Configurable {
 	private String uniqueKeyPropertyName;
 
 	@Override
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnvironment) throws MappingException {
 		uniqueKeyPropertyName = params.getProperty( "key" );
 	}
 
 	public InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
 			PostInsertIdentityPersister persister,
-	        Dialect dialect,
-	        boolean isGetGeneratedKeysEnabled) throws HibernateException {
+			Dialect dialect,
+			boolean isGetGeneratedKeysEnabled) throws HibernateException {
 		return new SelectGeneratorDelegate( persister, dialect, uniqueKeyPropertyName );
 	}
 
 	private static String determineNameOfPropertyToUse(PostInsertIdentityPersister persister, String supplied) {
 		if ( supplied != null ) {
 			return supplied;
 		}
 		int[] naturalIdPropertyIndices = persister.getNaturalIdentifierProperties();
-		if ( naturalIdPropertyIndices == null ){
+		if ( naturalIdPropertyIndices == null ) {
 			throw new IdentifierGenerationException(
 					"no natural-id property defined; need to specify [key] in " +
-					"generator parameters"
+							"generator parameters"
 			);
 		}
 		if ( naturalIdPropertyIndices.length > 1 ) {
 			throw new IdentifierGenerationException(
 					"select generator does not currently support composite " +
-					"natural-id properties; need to specify [key] in generator parameters"
+							"natural-id properties; need to specify [key] in generator parameters"
 			);
 		}
 		if ( persister.getEntityMetamodel().isNaturalIdentifierInsertGenerated() ) {
 			throw new IdentifierGenerationException(
 					"natural-id also defined as insert-generated; need to specify [key] " +
-					"in generator parameters"
+							"in generator parameters"
 			);
 		}
-		return persister.getPropertyNames() [ naturalIdPropertyIndices[0] ];
+		return persister.getPropertyNames()[naturalIdPropertyIndices[0]];
 	}
 
 
 	/**
 	 * The delegate for the select generation strategy.
 	 */
 	public static class SelectGeneratorDelegate
 			extends AbstractSelectingDelegate
 			implements InsertGeneratedIdentifierDelegate {
 		private final PostInsertIdentityPersister persister;
 		private final Dialect dialect;
 
 		private final String uniqueKeyPropertyName;
 		private final Type uniqueKeyType;
 		private final Type idType;
 
 		private final String idSelectString;
 
 		private SelectGeneratorDelegate(
 				PostInsertIdentityPersister persister,
-		        Dialect dialect,
-		        String suppliedUniqueKeyPropertyName) {
+				Dialect dialect,
+				String suppliedUniqueKeyPropertyName) {
 			super( persister );
 			this.persister = persister;
 			this.dialect = dialect;
 			this.uniqueKeyPropertyName = determineNameOfPropertyToUse( persister, suppliedUniqueKeyPropertyName );
 
 			idSelectString = persister.getSelectByUniqueKeyString( uniqueKeyPropertyName );
 			uniqueKeyType = persister.getPropertyType( uniqueKeyPropertyName );
 			idType = persister.getIdentifierType();
 		}
 
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			return new IdentifierGeneratingInsert( dialect );
 		}
 
 
 		// AbstractSelectingDelegate impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		protected String getSelectSQL() {
 			return idSelectString;
 		}
 
 		protected void bindParameters(
 				SessionImplementor session,
-		        PreparedStatement ps,
-		        Object entity) throws SQLException {
+				PreparedStatement ps,
+				Object entity) throws SQLException {
 			Object uniqueKeyValue = persister.getPropertyValue( entity, uniqueKeyPropertyName );
 			uniqueKeyType.nullSafeSet( ps, uniqueKeyValue, 1, session );
 		}
 
 		protected Serializable getResult(
 				SessionImplementor session,
-		        ResultSet rs,
-		        Object entity) throws SQLException {
+				ResultSet rs,
+				Object entity) throws SQLException {
 			if ( !rs.next() ) {
 				throw new IdentifierGenerationException(
 						"the inserted row could not be located by the unique key: " +
-						uniqueKeyPropertyName
+								uniqueKeyPropertyName
 				);
 			}
-			return ( Serializable ) idType.nullSafeGet(
+			return (Serializable) idType.nullSafeGet(
 					rs,
 					persister.getRootTableKeyColumnNames(),
 					session,
 					entity
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
index 77637311d3..1ef6fab784 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
@@ -1,199 +1,199 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Collections;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.boot.model.relational.Database;
 import org.hibernate.boot.model.relational.QualifiedName;
 import org.hibernate.boot.model.relational.QualifiedNameParser;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.boot.model.relational.SimpleAuxiliaryDatabaseObject;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * <b>sequence</b><br>
  * <br>
  * Generates <tt>long</tt> values using an oracle-style sequence. A higher
  * performance algorithm is <tt>SequenceHiLoGenerator</tt>.<br>
  * <br>
  * Mapping parameters supported: sequence, parameters.
  *
  * @see SequenceHiLoGenerator
  * @author Gavin King
  *
  * @deprecated Use {@link org.hibernate.id.enhanced.SequenceStyleGenerator} instead
  */
 @Deprecated
 public class SequenceGenerator
 		implements PersistentIdentifierGenerator, BulkInsertionCapableIdentifierGenerator, Configurable {
 
-    private static final Logger LOG = Logger.getLogger( SequenceGenerator.class.getName() );
+	private static final Logger LOG = Logger.getLogger( SequenceGenerator.class.getName() );
 
 	/**
 	 * The sequence parameter
 	 */
 	public static final String SEQUENCE = "sequence";
 
 	/**
 	 * The parameters parameter, appended to the create sequence DDL.
 	 * For example (Oracle): <tt>INCREMENT BY 1 START WITH 1 MAXVALUE 100 NOCACHE</tt>.
 	 */
 	public static final String PARAMETERS = "parameters";
 
 	private QualifiedName qualifiedSequenceName;
 	private String sequenceName;
 	private String parameters;
 	private Type identifierType;
 	private String sql;
 
 	protected Type getIdentifierType() {
 		return identifierType;
 	}
 
 	public Object generatorKey() {
 		return getSequenceName();
 	}
 
 	public String getSequenceName() {
 		return sequenceName;
 	}
 
 	@Override
 	@SuppressWarnings("StatementWithEmptyBody")
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		identifierType = type;
 		parameters = params.getProperty( PARAMETERS );
 
 		final Dialect dialect = jdbcEnv.getDialect();
 		final ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 		qualifiedSequenceName = QualifiedNameParser.INSTANCE.parse(
 				ConfigurationHelper.getString( SEQUENCE, params, "hibernate_sequence" ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) )
 		);
 		sequenceName = jdbcEnv.getQualifiedObjectNameFormatter().format( qualifiedSequenceName, dialect );
 
 		sql = dialect.getSequenceNextValString( sequenceName );
 	}
 
 	@Override
 	public Serializable generate(SessionImplementor session, Object obj) {
 		return generateHolder( session ).makeValue();
 	}
 
 	protected IntegralDataTypeHolder generateHolder(SessionImplementor session) {
 		try {
 			PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					rs.next();
 					IntegralDataTypeHolder result = buildHolder();
 					result.initialize( rs, 1 );
 					LOG.debugf( "Sequence identifier generated: %s", result );
 					return result;
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not get next sequence value",
 					sql
 			);
 		}
 	}
 
 	protected IntegralDataTypeHolder buildHolder() {
 		return IdentifierGeneratorHelper.getIntegralDataTypeHolder( identifierType.getReturnedClass() );
 	}
 
 	@Override
 	@SuppressWarnings( {"deprecation"})
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		String[] ddl = dialect.getCreateSequenceStrings( sequenceName );
 		if ( parameters != null ) {
 			ddl[ddl.length - 1] += ' ' + parameters;
 		}
 		return ddl;
 	}
 
 	@Override
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		return dialect.getDropSequenceStrings(sequenceName);
 	}
 
 	@Override
 	public boolean supportsBulkInsertionIdentifierGeneration() {
 		return true;
 	}
 
 	@Override
 	public String determineBulkInsertionIdentifierGenerationSelectFragment(Dialect dialect) {
 		return dialect.getSelectSequenceNextValString( getSequenceName() );
 	}
 
 	@Override
 	public void registerExportables(Database database) {
 		// we cannot register a proper Sequence object here because of the free-form
 		//'parameters' as opposed to specific initialValue/increment values
 
 		final Schema schema = database.locateSchema(
 				qualifiedSequenceName.getCatalogName(),
 				qualifiedSequenceName.getSchemaName()
 		);
 
 		database.addAuxiliaryDatabaseObject(
 				new SimpleAuxiliaryDatabaseObject(
 						schema,
 						sqlCreateStrings( database.getDialect() ),
 						sqlDropStrings( database.getDialect() ),
 						Collections.<String>emptySet()
 				)
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
index f6a2508b6d..12b987873c 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
@@ -1,138 +1,138 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.insert.AbstractReturningDelegate;
 import org.hibernate.id.insert.IdentifierGeneratingInsert;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.sql.Insert;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * A generator which combines sequence generation with immediate retrieval
  * through JDBC3 {@link java.sql.Connection#prepareStatement(String, String[]) getGeneratedKeys}.
  * In this respect it works much like ANSI-SQL IDENTITY generation.
  * <p/>
  * This generator only known to work with newer Oracle drivers compiled for
  * JDK 1.4 (JDBC3).
  * <p/>
  * Note: Due to a bug in Oracle drivers, sql comments on these insert statements
  * are completely disabled.
  *
  * @author Steve Ebersole
- *
  * @deprecated See deprecation discussion on {@link SequenceGenerator}
  */
 @Deprecated
 public class SequenceIdentityGenerator
 		extends SequenceGenerator
 		implements PostInsertIdentifierGenerator {
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			SequenceIdentityGenerator.class.getName()
 	);
 
 	@Override
-    public Serializable generate(SessionImplementor s, Object obj) {
+	public Serializable generate(SessionImplementor s, Object obj) {
 		return IdentifierGeneratorHelper.POST_INSERT_INDICATOR;
 	}
 
 	@Override
 	public InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
 			PostInsertIdentityPersister persister,
-	        Dialect dialect,
-	        boolean isGetGeneratedKeysEnabled) throws HibernateException {
+			Dialect dialect,
+			boolean isGetGeneratedKeysEnabled) throws HibernateException {
 		return new Delegate( persister, dialect, getSequenceName() );
 	}
 
 	@Override
-    public void configure(Type type, Properties params, JdbcEnvironment env) throws MappingException {
+	public void configure(Type type, Properties params, JdbcEnvironment env) throws MappingException {
 		super.configure( type, params, env );
 	}
 
 	public static class Delegate extends AbstractReturningDelegate {
 		private final Dialect dialect;
 		private final String sequenceNextValFragment;
 		private final String[] keyColumns;
 
 		public Delegate(PostInsertIdentityPersister persister, Dialect dialect, String sequenceName) {
 			super( persister );
 			this.dialect = dialect;
 			this.sequenceNextValFragment = dialect.getSelectSequenceNextValString( sequenceName );
 			this.keyColumns = getPersister().getRootTableKeyColumnNames();
 			if ( keyColumns.length > 1 ) {
 				throw new HibernateException( "sequence-identity generator cannot be used with with multi-column keys" );
 			}
 		}
 
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			NoCommentsInsert insert = new NoCommentsInsert( dialect );
 			insert.addColumn( getPersister().getRootTableKeyColumnNames()[0], sequenceNextValFragment );
 			return insert;
 		}
 
 		@Override
-        protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
+		protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
 			return session.getJdbcCoordinator().getStatementPreparer().prepareStatement( insertSQL, keyColumns );
 		}
 
 		@Override
-		protected Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session) throws SQLException {
-						session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
+		protected Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session)
+				throws SQLException {
+			session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
 			return IdentifierGeneratorHelper.getGeneratedIdentity(
 					insert.getGeneratedKeys(),
 					getPersister().getRootTableKeyColumnNames()[0],
 					getPersister().getIdentifierType()
 			);
 		}
 	}
 
 	public static class NoCommentsInsert extends IdentifierGeneratingInsert {
 		public NoCommentsInsert(Dialect dialect) {
 			super( dialect );
 		}
 
 		@Override
-        public Insert setComment(String comment) {
+		public Insert setComment(String comment) {
 			// don't allow comments on these insert statements as comments totally
 			// blow up the Oracle getGeneratedKeys "support" :(
 			LOG.disallowingInsertStatementComment();
 			return this;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/UUIDGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/UUIDGenerator.java
index f4c68b867b..c5a9454e0c 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/UUIDGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/UUIDGenerator.java
@@ -1,119 +1,118 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.util.Properties;
 import java.util.UUID;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.uuid.StandardRandomStrategy;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.Type;
 import org.hibernate.type.descriptor.java.UUIDTypeDescriptor;
 
-import org.jboss.logging.Logger;
-
 /**
  * An {@link IdentifierGenerator} which generates {@link UUID} values using a pluggable
  * {@link UUIDGenerationStrategy generation strategy}.  The values this generator can return
  * include {@link UUID}, {@link String} and byte[16]
  * <p/>
  * Supports 2 config parameters:<ul>
  * <li>{@link #UUID_GEN_STRATEGY} - names the {@link UUIDGenerationStrategy} instance to use</li>
  * <li>{@link #UUID_GEN_STRATEGY_CLASS} - names the {@link UUIDGenerationStrategy} class to use</li>
  * </ul>
  * <p/>
  * Currently there are 2 standard implementations of {@link UUIDGenerationStrategy}:<ul>
  * <li>{@link StandardRandomStrategy} (the default, if none specified)</li>
  * <li>{@link org.hibernate.id.uuid.CustomVersionOneStrategy}</li>
  * </ul>
  *
  * @author Steve Ebersole
  */
 public class UUIDGenerator implements IdentifierGenerator, Configurable {
 	public static final String UUID_GEN_STRATEGY = "uuid_gen_strategy";
 	public static final String UUID_GEN_STRATEGY_CLASS = "uuid_gen_strategy_class";
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, UUIDGenerator.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( UUIDGenerator.class );
 
 	private UUIDGenerationStrategy strategy;
 	private UUIDTypeDescriptor.ValueTransformer valueTransformer;
 
 	public static UUIDGenerator buildSessionFactoryUniqueIdentifierGenerator() {
 		final UUIDGenerator generator = new UUIDGenerator();
 		generator.strategy = StandardRandomStrategy.INSTANCE;
 		generator.valueTransformer = UUIDTypeDescriptor.ToStringTransformer.INSTANCE;
 		return generator;
 	}
 
 	@Override
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		// check first for the strategy instance
 		strategy = (UUIDGenerationStrategy) params.get( UUID_GEN_STRATEGY );
 		if ( strategy == null ) {
 			// next check for the strategy class
 			final String strategyClassName = params.getProperty( UUID_GEN_STRATEGY_CLASS );
 			if ( strategyClassName != null ) {
 				try {
 					final Class strategyClass = ReflectHelper.classForName( strategyClassName );
 					try {
 						strategy = (UUIDGenerationStrategy) strategyClass.newInstance();
 					}
 					catch ( Exception ignore ) {
-                        LOG.unableToInstantiateUuidGenerationStrategy(ignore);
+						LOG.unableToInstantiateUuidGenerationStrategy(ignore);
 					}
 				}
 				catch ( ClassNotFoundException ignore ) {
-                    LOG.unableToLocateUuidGenerationStrategy(strategyClassName);
+						LOG.unableToLocateUuidGenerationStrategy(strategyClassName);
 				}
 			}
 		}
 		if ( strategy == null ) {
 			// lastly use the standard random generator
 			strategy = StandardRandomStrategy.INSTANCE;
 		}
 
 		if ( UUID.class.isAssignableFrom( type.getReturnedClass() ) ) {
 			valueTransformer = UUIDTypeDescriptor.PassThroughTransformer.INSTANCE;
 		}
 		else if ( String.class.isAssignableFrom( type.getReturnedClass() ) ) {
 			valueTransformer = UUIDTypeDescriptor.ToStringTransformer.INSTANCE;
 		}
 		else if ( byte[].class.isAssignableFrom( type.getReturnedClass() ) ) {
 			valueTransformer = UUIDTypeDescriptor.ToBytesTransformer.INSTANCE;
 		}
 		else {
 			throw new HibernateException( "Unanticipated return type [" + type.getReturnedClass().getName() + "] for UUID conversion" );
 		}
 	}
 
 	public Serializable generate(SessionImplementor session, Object object) throws HibernateException {
 		return valueTransformer.transform( strategy.generateUUID( session ) );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
index cbaf2e494c..cba8e15955 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
@@ -1,92 +1,91 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.util.Properties;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * <b>uuid</b><br>
  * <br>
  * A <tt>UUIDGenerator</tt> that returns a string of length 32,
  * This string will consist of only hex digits. Optionally,
  * the string may be generated with separators between each
  * component of the UUID.
- *
+ * <p/>
  * Mapping parameters supported: separator.
  *
  * @author Gavin King
  */
 public class UUIDHexGenerator extends AbstractUUIDGenerator implements Configurable {
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, UUIDHexGenerator.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( UUIDHexGenerator.class );
 
 	private static boolean WARNED;
 
 	private String sep = "";
 
 	public UUIDHexGenerator() {
 		if ( !WARNED ) {
 			WARNED = true;
-            LOG.usingUuidHexGenerator( this.getClass().getName(), UUIDGenerator.class.getName() );
+			LOG.usingUuidHexGenerator( this.getClass().getName(), UUIDGenerator.class.getName() );
 		}
 	}
 
 
 	@Override
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		sep = ConfigurationHelper.getString( "separator", params, "" );
 	}
 
 	@Override
 	public Serializable generate(SessionImplementor session, Object obj) {
 		return format( getIP() ) + sep
 				+ format( getJVM() ) + sep
 				+ format( getHiTime() ) + sep
 				+ format( getLoTime() ) + sep
 				+ format( getCount() );
 	}
 
 	protected String format(int intValue) {
 		String formatted = Integer.toHexString( intValue );
 		StringBuilder buf = new StringBuilder( "00000000" );
 		buf.replace( 8 - formatted.length(), 8, formatted );
 		return buf.toString();
 	}
 
 	protected String format(short shortValue) {
 		String formatted = Integer.toHexString( shortValue );
 		StringBuilder buf = new StringBuilder( "0000" );
 		buf.replace( 4 - formatted.length(), 4, formatted );
 		return buf.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/factory/internal/DefaultIdentifierGeneratorFactory.java b/hibernate-core/src/main/java/org/hibernate/id/factory/internal/DefaultIdentifierGeneratorFactory.java
index d7bc7e9755..81ff1e8065 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/factory/internal/DefaultIdentifierGeneratorFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/factory/internal/DefaultIdentifierGeneratorFactory.java
@@ -1,163 +1,163 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id.factory.internal;
 
 import java.io.Serializable;
 import java.util.Properties;
 import java.util.concurrent.ConcurrentHashMap;
 
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.id.Assigned;
 import org.hibernate.id.Configurable;
 import org.hibernate.id.ForeignGenerator;
 import org.hibernate.id.GUIDGenerator;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.id.IncrementGenerator;
 import org.hibernate.id.SelectGenerator;
 import org.hibernate.id.SequenceGenerator;
 import org.hibernate.id.SequenceHiLoGenerator;
 import org.hibernate.id.SequenceIdentityGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.UUIDHexGenerator;
 import org.hibernate.id.enhanced.SequenceStyleGenerator;
 import org.hibernate.id.enhanced.TableGenerator;
 import org.hibernate.id.factory.spi.MutableIdentifierGeneratorFactory;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.service.spi.ServiceRegistryAwareService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.type.Type;
 
 /**
  * Basic <tt>templated</tt> support for {@link org.hibernate.id.factory.IdentifierGeneratorFactory} implementations.
  *
  * @author Steve Ebersole
  */
 public class DefaultIdentifierGeneratorFactory
 		implements MutableIdentifierGeneratorFactory, Serializable, ServiceRegistryAwareService {
 
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( DefaultIdentifierGeneratorFactory.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( DefaultIdentifierGeneratorFactory.class );
 
 	private JdbcEnvironment jdbcEnvironment;
 	private ConcurrentHashMap<String, Class> generatorStrategyToClassNameMap = new ConcurrentHashMap<String, Class>();
 
 	/**
 	 * Constructs a new DefaultIdentifierGeneratorFactory.
 	 */
 	public DefaultIdentifierGeneratorFactory() {
 		register( "uuid2", UUIDGenerator.class );
 		register( "guid", GUIDGenerator.class );			// can be done with UUIDGenerator + strategy
 		register( "uuid", UUIDHexGenerator.class );			// "deprecated" for new use
 		register( "uuid.hex", UUIDHexGenerator.class ); 	// uuid.hex is deprecated
 		register( "assigned", Assigned.class );
 		register( "identity", IdentityGenerator.class );
 		register( "select", SelectGenerator.class );
 		register( "sequence", SequenceGenerator.class );
 		register( "seqhilo", SequenceHiLoGenerator.class );
 		register( "increment", IncrementGenerator.class );
 		register( "foreign", ForeignGenerator.class );
 		register( "sequence-identity", SequenceIdentityGenerator.class );
 		register( "enhanced-sequence", SequenceStyleGenerator.class );
 		register( "enhanced-table", TableGenerator.class );
 	}
 
 	public void register(String strategy, Class generatorClass) {
 		LOG.debugf( "Registering IdentifierGenerator strategy [%s] -> [%s]", strategy, generatorClass.getName() );
 		final Class previous = generatorStrategyToClassNameMap.put( strategy, generatorClass );
 		if ( previous != null ) {
 			LOG.debugf( "    - overriding [%s]", previous.getName() );
 		}
 	}
 
 	@Override
 	public Dialect getDialect() {
 		return jdbcEnvironment.getDialect();
 	}
 
 	@Override
 	public void setDialect(Dialect dialect) {
 //		LOG.debugf( "Setting dialect [%s]", dialect );
 //		this.dialect = dialect;
 //
 //		if ( dialect == jdbcEnvironment.getDialect() ) {
 //			LOG.debugf(
 //					"Call to unsupported method IdentifierGeneratorFactory#setDialect; " +
 //							"ignoring as passed Dialect matches internal Dialect"
 //			);
 //		}
 //		else {
 //			throw new UnsupportedOperationException(
 //					"Call to unsupported method IdentifierGeneratorFactory#setDialect attempting to" +
 //							"set a non-matching Dialect : " + dialect.getClass().getName()
 //			);
 //		}
 	}
 
 	@Override
 	public IdentifierGenerator createIdentifierGenerator(String strategy, Type type, Properties config) {
 		try {
 			Class clazz = getIdentifierGeneratorClass( strategy );
 			IdentifierGenerator identifierGenerator = ( IdentifierGenerator ) clazz.newInstance();
 			if ( identifierGenerator instanceof Configurable ) {
 				( ( Configurable ) identifierGenerator ).configure( type, config, jdbcEnvironment );
 			}
 			return identifierGenerator;
 		}
 		catch ( Exception e ) {
 			final String entityName = config.getProperty( IdentifierGenerator.ENTITY_NAME );
 			throw new MappingException( String.format( "Could not instantiate id generator [entity-name=%s]", entityName ), e );
 		}
 	}
 
 	@Override
 	public Class getIdentifierGeneratorClass(String strategy) {
 		if ( "native".equals( strategy ) ) {
 			return getDialect().getNativeIdentifierGeneratorClass();
 		}
 
 		if ( "hilo".equals( strategy ) ) {
 			throw new UnsupportedOperationException( "Support for 'hilo' generator has been removed" );
 		}
 
 		Class generatorClass = generatorStrategyToClassNameMap.get( strategy );
 		try {
 			if ( generatorClass == null ) {
 				generatorClass = ReflectHelper.classForName( strategy );
 			}
 		}
 		catch ( ClassNotFoundException e ) {
 			throw new MappingException( String.format( "Could not interpret id generator strategy [%s]", strategy ) );
 		}
 		return generatorClass;
 	}
 
 	@Override
 	public void injectServices(ServiceRegistryImplementor serviceRegistry) {
 		this.jdbcEnvironment = serviceRegistry.getService( JdbcEnvironment.class );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractReturningDelegate.java b/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractReturningDelegate.java
index add0184582..870a45f910 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractReturningDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractReturningDelegate.java
@@ -1,85 +1,88 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.id.insert;
+
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * Abstract InsertGeneratedIdentifierDelegate implementation where the
- * underlying strategy causes the enerated identitifer to be returned as an
+ * underlying strategy causes the generated identifier to be returned as an
  * effect of performing the insert statement.  Thus, there is no need for an
- * additional sql statement to determine the generated identitifer.
+ * additional sql statement to determine the generated identifier.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractReturningDelegate implements InsertGeneratedIdentifierDelegate {
 	private final PostInsertIdentityPersister persister;
 
 	public AbstractReturningDelegate(PostInsertIdentityPersister persister) {
 		this.persister = persister;
 	}
 
+	@Override
 	public final Serializable performInsert(
 			String insertSQL,
 			SessionImplementor session,
 			Binder binder) {
 		try {
 			// prepare and execute the insert
 			PreparedStatement insert = prepare( insertSQL, session );
 			try {
 				binder.bindValues( insert );
 				return executeAndExtract( insert, session );
 			}
 			finally {
 				releaseStatement( insert, session );
 			}
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
-			        sqle,
-			        "could not insert: " + MessageHelper.infoString( persister ),
-			        insertSQL
-				);
+					sqle,
+					"could not insert: " + MessageHelper.infoString( persister ),
+					insertSQL
+			);
 		}
 	}
 
 	protected PostInsertIdentityPersister getPersister() {
 		return persister;
 	}
 
 	protected abstract PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException;
 
-	protected abstract Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session) throws SQLException;
+	protected abstract Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session)
+			throws SQLException;
 
 	protected void releaseStatement(PreparedStatement insert, SessionImplementor session) throws SQLException {
 		session.getJdbcCoordinator().getResourceRegistry().release( insert );
 		session.getJdbcCoordinator().afterStatementExecution();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractSelectingDelegate.java b/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractSelectingDelegate.java
index dba353bff2..487eb1a6be 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractSelectingDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractSelectingDelegate.java
@@ -1,144 +1,148 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.id.insert;
+
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * Abstract InsertGeneratedIdentifierDelegate implementation where the
  * underlying strategy requires an subsequent select after the insert
  * to determine the generated identifier.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractSelectingDelegate implements InsertGeneratedIdentifierDelegate {
 	private final PostInsertIdentityPersister persister;
 
 	protected AbstractSelectingDelegate(PostInsertIdentityPersister persister) {
 		this.persister = persister;
 	}
 
+	@Override
 	public final Serializable performInsert(
 			String insertSQL,
 			SessionImplementor session,
 			Binder binder) {
 		try {
 			// prepare and execute the insert
 			PreparedStatement insert = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( insertSQL, PreparedStatement.NO_GENERATED_KEYS );
 			try {
 				binder.bindValues( insert );
 				session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( insert );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
-			        sqle,
-			        "could not insert: " + MessageHelper.infoString( persister ),
-			        insertSQL
-				);
+					sqle,
+					"could not insert: " + MessageHelper.infoString( persister ),
+					insertSQL
+			);
 		}
 
 		final String selectSQL = getSelectSQL();
 
 		try {
 			//fetch the generated id in a separate query
 			PreparedStatement idSelect = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( selectSQL, false );
 			try {
 				bindParameters( session, idSelect, binder.getEntity() );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( idSelect );
 				try {
 					return getResult( session, rs, binder.getEntity() );
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, idSelect );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( idSelect );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
-			        sqle,
-			        "could not retrieve generated id after insert: " + MessageHelper.infoString( persister ),
-			        insertSQL
+					sqle,
+					"could not retrieve generated id after insert: " + MessageHelper.infoString( persister ),
+					insertSQL
 			);
 		}
 	}
 
 	/**
 	 * Get the SQL statement to be used to retrieve generated key values.
 	 *
 	 * @return The SQL command string
 	 */
 	protected abstract String getSelectSQL();
 
 	/**
 	 * Bind any required parameter values into the SQL command {@link #getSelectSQL}.
 	 *
 	 * @param session The session
 	 * @param ps The prepared {@link #getSelectSQL SQL} command
 	 * @param entity The entity being saved.
+	 *
 	 * @throws SQLException
 	 */
 	protected void bindParameters(
 			SessionImplementor session,
-	        PreparedStatement ps,
-	        Object entity) throws SQLException {
+			PreparedStatement ps,
+			Object entity) throws SQLException {
 	}
 
 	/**
 	 * Extract the generated key value from the given result set.
 	 *
 	 * @param session The session
 	 * @param rs The result set containing the generated primay key values.
 	 * @param entity The entity being saved.
+	 *
 	 * @return The generated identifier
+	 *
 	 * @throws SQLException
 	 */
 	protected abstract Serializable getResult(
 			SessionImplementor session,
-	        ResultSet rs,
-	        Object entity) throws SQLException;
+			ResultSet rs,
+			Object entity) throws SQLException;
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/AbstractQueryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/AbstractQueryImpl.java
index 6f7265b282..c4e1e61c38 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/AbstractQueryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/AbstractQueryImpl.java
@@ -1,1047 +1,1048 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Calendar;
 import java.util.Collection;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.NonUniqueResultException;
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.Session;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.hql.internal.classic.ParserHelper;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.property.Getter;
 import org.hibernate.proxy.HibernateProxyHelper;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.SerializableType;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Abstract implementation of the Query interface.
  *
  * @author Gavin King
  * @author Max Andersen
  */
 public abstract class AbstractQueryImpl implements Query {
 	private static final CoreMessageLogger log = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			AbstractQueryImpl.class.getName()
 	);
 
-	private static final Object UNSET_PARAMETER = new MarkerObject("<unset parameter>");
-	private static final Object UNSET_TYPE = new MarkerObject("<unset type>");
+	private static final Object UNSET_PARAMETER = new MarkerObject( "<unset parameter>" );
+	private static final Object UNSET_TYPE = new MarkerObject( "<unset type>" );
 
 	private final String queryString;
 	protected final SessionImplementor session;
 	protected final ParameterMetadata parameterMetadata;
 
 	// parameter bind values...
-	private List values = new ArrayList(4);
-	private List types = new ArrayList(4);
-	private Map<String,TypedValue> namedParameters = new HashMap<String, TypedValue>(4);
-	private Map<String, TypedValue> namedParameterLists = new HashMap<String, TypedValue>(4);
+	private List values = new ArrayList( 4 );
+	private List types = new ArrayList( 4 );
+	private Map<String, TypedValue> namedParameters = new HashMap<String, TypedValue>( 4 );
+	private Map<String, TypedValue> namedParameterLists = new HashMap<String, TypedValue>( 4 );
 
 	private Object optionalObject;
 	private Serializable optionalId;
 	private String optionalEntityName;
 
 	private RowSelection selection;
 	private boolean cacheable;
 	private String cacheRegion;
 	private String comment;
 	private final List<String> queryHints = new ArrayList<String>();
 	private FlushMode flushMode;
 	private CacheMode cacheMode;
 	private FlushMode sessionFlushMode;
 	private CacheMode sessionCacheMode;
 	private Serializable collectionKey;
 	private Boolean readOnly;
 	private ResultTransformer resultTransformer;
-	
+
 	private HQLQueryPlan queryPlan;
 
 	public AbstractQueryImpl(
 			String queryString,
-	        FlushMode flushMode,
-	        SessionImplementor session,
-	        ParameterMetadata parameterMetadata) {
+			FlushMode flushMode,
+			SessionImplementor session,
+			ParameterMetadata parameterMetadata) {
 		this.session = session;
 		this.queryString = queryString;
 		this.selection = new RowSelection();
 		this.flushMode = flushMode;
 		this.cacheMode = null;
 		this.parameterMetadata = parameterMetadata;
 	}
 
 	public ParameterMetadata getParameterMetadata() {
 		return parameterMetadata;
 	}
 
 	@Override
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) + '(' + queryString + ')';
 	}
 
 	@Override
 	public final String getQueryString() {
 		return queryString;
 	}
 
 	@Override
 	public boolean isCacheable() {
 		return cacheable;
 	}
 
 	@Override
 	public Query setCacheable(boolean cacheable) {
 		this.cacheable = cacheable;
 		return this;
 	}
 
 	@Override
 	public String getCacheRegion() {
 		return cacheRegion;
 	}
 
 	@Override
 	public Query setCacheRegion(String cacheRegion) {
-		if (cacheRegion != null) {
+		if ( cacheRegion != null ) {
 			this.cacheRegion = cacheRegion.trim();
 		}
 		return this;
 	}
 
 	@Override
 	public FlushMode getFlushMode() {
 		return flushMode;
 	}
 
 	@Override
 	public Query setFlushMode(FlushMode flushMode) {
 		this.flushMode = flushMode;
 		return this;
 	}
 
 	@Override
 	public CacheMode getCacheMode() {
 		return cacheMode;
 	}
 
 	@Override
 	public Query setCacheMode(CacheMode cacheMode) {
 		this.cacheMode = cacheMode;
 		return this;
 	}
 
 	@Override
 	public String getComment() {
 		return comment;
 	}
 
 	@Override
 	public Query setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
-	  
+
 	@Override
 	public Query addQueryHint(String queryHint) {
 		queryHints.add( queryHint );
 		return this;
-	} 
+	}
 
 	@Override
 	public Integer getFirstResult() {
 		return selection.getFirstRow();
 	}
 
 	@Override
 	public Query setFirstResult(int firstResult) {
-		selection.setFirstRow( firstResult);
+		selection.setFirstRow( firstResult );
 		return this;
 	}
 
 	@Override
 	public Integer getMaxResults() {
 		return selection.getMaxRows();
 	}
 
 	@Override
 	public Query setMaxResults(int maxResults) {
 		if ( maxResults <= 0 ) {
 			// treat zero and negatives specically as meaning no limit...
 			selection.setMaxRows( null );
 		}
 		else {
-			selection.setMaxRows( maxResults);
+			selection.setMaxRows( maxResults );
 		}
 		return this;
 	}
 
 	@Override
 	public Integer getTimeout() {
 		return selection.getTimeout();
 	}
 
 	@Override
 	public Query setTimeout(int timeout) {
-		selection.setTimeout( timeout);
+		selection.setTimeout( timeout );
 		return this;
 	}
 
 	@Override
 	public Integer getFetchSize() {
 		return selection.getFetchSize();
 	}
 
 	@Override
 	public Query setFetchSize(int fetchSize) {
-		selection.setFetchSize( fetchSize);
+		selection.setFetchSize( fetchSize );
 		return this;
 	}
 
 	public Type[] getReturnTypes() throws HibernateException {
 		return session.getFactory().getReturnTypes( queryString );
 	}
 
 	public String[] getReturnAliases() throws HibernateException {
 		return session.getFactory().getReturnAliases( queryString );
 	}
 
 	public Query setCollectionKey(Serializable collectionKey) {
 		this.collectionKey = collectionKey;
 		return this;
 	}
 
 	@Override
 	public boolean isReadOnly() {
 		return ( readOnly == null ?
 				getSession().getPersistenceContext().isDefaultReadOnly() :
 				readOnly
 		);
 	}
 
 	@Override
 	public Query setReadOnly(boolean readOnly) {
 		this.readOnly = readOnly;
 		return this;
 	}
+
 	@Override
 	public Query setResultTransformer(ResultTransformer transformer) {
 		this.resultTransformer = transformer;
 		return this;
 	}
-	
+
 	public void setOptionalEntityName(String optionalEntityName) {
 		this.optionalEntityName = optionalEntityName;
 	}
 
 	public void setOptionalId(Serializable optionalId) {
 		this.optionalId = optionalId;
 	}
 
 	public void setOptionalObject(Object optionalObject) {
 		this.optionalObject = optionalObject;
 	}
 
 	SessionImplementor getSession() {
 		return session;
 	}
+
 	@Override
 	public abstract LockOptions getLockOptions();
 
 
 	// Parameter handling code ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Returns a shallow copy of the named parameter value map.
 	 *
 	 * @return Shallow copy of the named parameter value map
 	 */
 	protected Map<String, TypedValue> getNamedParams() {
 		return new HashMap<String, TypedValue>( namedParameters );
 	}
 
 	/**
 	 * Returns an array representing all named parameter names encountered
 	 * during (intial) parsing of the query.
 	 * <p/>
 	 * Note <i>initial</i> here means different things depending on whether
 	 * this is a native-sql query or an HQL/filter query.  For native-sql, a
 	 * precursory inspection of the query string is performed specifically to
 	 * locate defined parameters.  For HQL/filter queries, this is the
 	 * information returned from the query-translator.  This distinction
 	 * holds true for all parameter metadata exposed here.
 	 *
 	 * @return Array of named parameter names.
+	 *
 	 * @throws HibernateException
 	 */
 	@Override
 	public String[] getNamedParameters() throws HibernateException {
 		return ArrayHelper.toStringArray( parameterMetadata.getNamedParameterNames() );
 	}
 
 	/**
 	 * Does this query contain named parameters?
 	 *
 	 * @return True if the query was found to contain named parameters; false
 	 * otherwise;
 	 */
 	public boolean hasNamedParameters() {
 		return parameterMetadata.getNamedParameterNames().size() > 0;
 	}
 
 	/**
 	 * Retreive the value map for any named parameter lists (i.e., for
 	 * auto-expansion) bound to this query.
 	 *
 	 * @return The parameter list value map.
 	 */
 	protected Map<String, TypedValue> getNamedParameterLists() {
 		return namedParameterLists;
 	}
 
 	/**
 	 * Retreives the list of parameter values bound to this query for
 	 * ordinal parameters.
 	 *
 	 * @return The ordinal parameter values.
 	 */
 	protected List getValues() {
 		return values;
 	}
 
 	/**
 	 * Retreives the list of parameter {@link Type type}s bound to this query for
 	 * ordinal parameters.
 	 *
 	 * @return The ordinal parameter types.
 	 */
 	protected List getTypes() {
 		return types;
 	}
 
 	/**
 	 * Perform parameter validation.  Used prior to executing the encapsulated
 	 * query.
 	 *
 	 * @throws QueryException
 	 */
 	protected void verifyParameters() throws QueryException {
-		verifyParameters(false);
+		verifyParameters( false );
 	}
 
 	/**
 	 * Perform parameter validation.  Used prior to executing the encapsulated
 	 * query.
 	 *
 	 * @param reserveFirstParameter if true, the first ? will not be verified since
 	 * its needed for e.g. callable statements returning a out parameter
+	 *
 	 * @throws HibernateException
 	 */
 	protected void verifyParameters(boolean reserveFirstParameter) throws HibernateException {
-		if ( parameterMetadata.getNamedParameterNames().size() != namedParameters.size() + namedParameterLists.size() ) {
+		if ( parameterMetadata.getNamedParameterNames()
+				.size() != namedParameters.size() + namedParameterLists.size() ) {
 			Set<String> missingParams = new HashSet<String>( parameterMetadata.getNamedParameterNames() );
 			missingParams.removeAll( namedParameterLists.keySet() );
 			missingParams.removeAll( namedParameters.keySet() );
 			throw new QueryException( "Not all named parameters have been set: " + missingParams, getQueryString() );
 		}
 
 		int positionalValueSpan = 0;
 		for ( int i = 0; i < values.size(); i++ ) {
 			Object object = types.get( i );
-			if( values.get( i ) == UNSET_PARAMETER || object == UNSET_TYPE ) {
-				if ( reserveFirstParameter && i==0 ) {
+			if ( values.get( i ) == UNSET_PARAMETER || object == UNSET_TYPE ) {
+				if ( reserveFirstParameter && i == 0 ) {
 					continue;
 				}
 				else {
 					throw new QueryException( "Unset positional parameter at position: " + i, getQueryString() );
 				}
 			}
 			positionalValueSpan += ( (Type) object ).getColumnSpan( session.getFactory() );
 		}
 
 		if ( parameterMetadata.getOrdinalParameterCount() != positionalValueSpan ) {
 			if ( reserveFirstParameter && parameterMetadata.getOrdinalParameterCount() - 1 != positionalValueSpan ) {
 				throw new QueryException(
-				 		"Expected positional parameter count: " +
-				 		(parameterMetadata.getOrdinalParameterCount()-1) +
-				 		", actual parameters: " +
-				 		values,
-				 		getQueryString()
-				 	);
+						"Expected positional parameter count: " +
+								( parameterMetadata.getOrdinalParameterCount() - 1 ) +
+								", actual parameters: " +
+								values,
+						getQueryString()
+				);
 			}
 			else if ( !reserveFirstParameter ) {
 				throw new QueryException(
-				 		"Expected positional parameter count: " +
-				 		parameterMetadata.getOrdinalParameterCount() +
-				 		", actual parameters: " +
-				 		values,
-				 		getQueryString()
-				 	);
+						"Expected positional parameter count: " +
+								parameterMetadata.getOrdinalParameterCount() +
+								", actual parameters: " +
+								values,
+						getQueryString()
+				);
 			}
 		}
 	}
 
 	public Query setParameter(int position, Object val, Type type) {
 		if ( parameterMetadata.getOrdinalParameterCount() == 0 ) {
-			throw new IllegalArgumentException("No positional parameters in query: " + getQueryString() );
+			throw new IllegalArgumentException( "No positional parameters in query: " + getQueryString() );
 		}
 		if ( position < 0 || position > parameterMetadata.getOrdinalParameterCount() - 1 ) {
-			throw new IllegalArgumentException("Positional parameter does not exist: " + position + " in query: " + getQueryString() );
+			throw new IllegalArgumentException( "Positional parameter does not exist: " + position + " in query: " + getQueryString() );
 		}
 		int size = values.size();
 		if ( position < size ) {
 			values.set( position, val );
 			types.set( position, type );
 		}
 		else {
 			// prepend value and type list with null for any positions before the wanted position.
 			for ( int i = 0; i < position - size; i++ ) {
 				values.add( UNSET_PARAMETER );
 				types.add( UNSET_TYPE );
 			}
 			values.add( val );
 			types.add( type );
 		}
 		return this;
 	}
 
 	public Query setParameter(String name, Object val, Type type) {
 		if ( !parameterMetadata.getNamedParameterNames().contains( name ) ) {
-			throw new IllegalArgumentException("Parameter " + name + " does not exist as a named parameter in [" + getQueryString() + "]");
+			throw new IllegalArgumentException( "Parameter " + name + " does not exist as a named parameter in [" + getQueryString() + "]" );
 		}
 		else {
-			 namedParameters.put( name, new TypedValue( type, val  ) );
-			 return this;
+			namedParameters.put( name, new TypedValue( type, val ) );
+			return this;
 		}
 	}
 
 	public Query setParameter(int position, Object val) throws HibernateException {
-		if (val == null) {
+		if ( val == null ) {
 			setParameter( position, val, StandardBasicTypes.SERIALIZABLE );
 		}
 		else {
 			setParameter( position, val, determineType( position, val ) );
 		}
 		return this;
 	}
 
 	public Query setParameter(String name, Object val) throws HibernateException {
-		if (val == null) {
+		if ( val == null ) {
 			Type type = parameterMetadata.getNamedParameterExpectedType( name );
 			if ( type == null ) {
 				type = StandardBasicTypes.SERIALIZABLE;
 			}
 			setParameter( name, val, type );
 		}
 		else {
 			setParameter( name, val, determineType( name, val ) );
 		}
 		return this;
 	}
 
 	protected Type determineType(int paramPosition, Object paramValue, Type defaultType) {
 		Type type = parameterMetadata.getOrdinalParameterExpectedType( paramPosition + 1 );
 		if ( type == null ) {
 			type = defaultType;
 		}
 		return type;
 	}
 
 	protected Type determineType(int paramPosition, Object paramValue) throws HibernateException {
 		Type type = parameterMetadata.getOrdinalParameterExpectedType( paramPosition + 1 );
 		if ( type == null ) {
 			type = guessType( paramValue );
 		}
 		return type;
 	}
 
 	protected Type determineType(String paramName, Object paramValue, Type defaultType) {
 		Type type = parameterMetadata.getNamedParameterExpectedType( paramName );
 		if ( type == null ) {
 			type = defaultType;
 		}
 		return type;
 	}
 
 	protected Type determineType(String paramName, Object paramValue) throws HibernateException {
 		Type type = parameterMetadata.getNamedParameterExpectedType( paramName );
 		if ( type == null ) {
 			type = guessType( paramValue );
 		}
 		return type;
 	}
 
 	protected Type determineType(String paramName, Class clazz) throws HibernateException {
 		Type type = parameterMetadata.getNamedParameterExpectedType( paramName );
 		if ( type == null ) {
 			type = guessType( clazz );
 		}
 		return type;
 	}
 
 	private Type guessType(Object param) throws HibernateException {
 		Class clazz = HibernateProxyHelper.getClassWithoutInitializingProxy( param );
 		return guessType( clazz );
 	}
 
 	private Type guessType(Class clazz) throws HibernateException {
 		String typename = clazz.getName();
-		Type type = session.getFactory().getTypeResolver().heuristicType(typename);
-		boolean serializable = type!=null && type instanceof SerializableType;
-		if (type==null || serializable) {
+		Type type = session.getFactory().getTypeResolver().heuristicType( typename );
+		boolean serializable = type != null && type instanceof SerializableType;
+		if ( type == null || serializable ) {
 			try {
 				session.getFactory().getEntityPersister( clazz.getName() );
 			}
 			catch (MappingException me) {
-				if (serializable) {
+				if ( serializable ) {
 					return type;
 				}
 				else {
-					throw new HibernateException("Could not determine a type for class: " + typename);
+					throw new HibernateException( "Could not determine a type for class: " + typename );
 				}
 			}
 			return ( (Session) session ).getTypeHelper().entity( clazz );
 		}
 		else {
 			return type;
 		}
 	}
 
 	public Query setString(int position, String val) {
-		setParameter(position, val, StandardBasicTypes.STRING);
+		setParameter( position, val, StandardBasicTypes.STRING );
 		return this;
 	}
 
 	public Query setCharacter(int position, char val) {
 		setParameter( position, Character.valueOf( val ), StandardBasicTypes.CHARACTER );
 		return this;
 	}
 
 	public Query setBoolean(int position, boolean val) {
 		Boolean valueToUse = val;
 		Type typeToUse = determineType( position, valueToUse, StandardBasicTypes.BOOLEAN );
 		setParameter( position, valueToUse, typeToUse );
 		return this;
 	}
 
 	public Query setByte(int position, byte val) {
-		setParameter(position, val, StandardBasicTypes.BYTE);
+		setParameter( position, val, StandardBasicTypes.BYTE );
 		return this;
 	}
 
 	public Query setShort(int position, short val) {
-		setParameter(position, val, StandardBasicTypes.SHORT);
+		setParameter( position, val, StandardBasicTypes.SHORT );
 		return this;
 	}
 
 	public Query setInteger(int position, int val) {
-		setParameter(position, val, StandardBasicTypes.INTEGER);
+		setParameter( position, val, StandardBasicTypes.INTEGER );
 		return this;
 	}
 
 	public Query setLong(int position, long val) {
-		setParameter(position, val, StandardBasicTypes.LONG);
+		setParameter( position, val, StandardBasicTypes.LONG );
 		return this;
 	}
 
 	public Query setFloat(int position, float val) {
-		setParameter(position, val, StandardBasicTypes.FLOAT);
+		setParameter( position, val, StandardBasicTypes.FLOAT );
 		return this;
 	}
 
 	public Query setDouble(int position, double val) {
-		setParameter(position, val, StandardBasicTypes.DOUBLE);
+		setParameter( position, val, StandardBasicTypes.DOUBLE );
 		return this;
 	}
 
 	public Query setBinary(int position, byte[] val) {
-		setParameter(position, val, StandardBasicTypes.BINARY);
+		setParameter( position, val, StandardBasicTypes.BINARY );
 		return this;
 	}
 
 	public Query setText(int position, String val) {
-		setParameter(position, val, StandardBasicTypes.TEXT);
+		setParameter( position, val, StandardBasicTypes.TEXT );
 		return this;
 	}
 
 	public Query setSerializable(int position, Serializable val) {
-		setParameter(position, val, StandardBasicTypes.SERIALIZABLE);
+		setParameter( position, val, StandardBasicTypes.SERIALIZABLE );
 		return this;
 	}
 
 	public Query setDate(int position, Date date) {
-		setParameter(position, date, StandardBasicTypes.DATE);
+		setParameter( position, date, StandardBasicTypes.DATE );
 		return this;
 	}
 
 	public Query setTime(int position, Date date) {
-		setParameter(position, date, StandardBasicTypes.TIME);
+		setParameter( position, date, StandardBasicTypes.TIME );
 		return this;
 	}
 
 	public Query setTimestamp(int position, Date date) {
-		setParameter(position, date, StandardBasicTypes.TIMESTAMP);
+		setParameter( position, date, StandardBasicTypes.TIMESTAMP );
 		return this;
 	}
 
 	public Query setEntity(int position, Object val) {
 		setParameter( position, val, ( (Session) session ).getTypeHelper().entity( resolveEntityName( val ) ) );
 		return this;
 	}
 
 	private String resolveEntityName(Object val) {
 		if ( val == null ) {
 			throw new IllegalArgumentException( "entity for parameter binding cannot be null" );
 		}
 		return session.bestGuessEntityName( val );
 	}
 
 	public Query setLocale(int position, Locale locale) {
-		setParameter(position, locale, StandardBasicTypes.LOCALE);
+		setParameter( position, locale, StandardBasicTypes.LOCALE );
 		return this;
 	}
 
 	public Query setCalendar(int position, Calendar calendar) {
-		setParameter(position, calendar, StandardBasicTypes.CALENDAR);
+		setParameter( position, calendar, StandardBasicTypes.CALENDAR );
 		return this;
 	}
 
 	public Query setCalendarDate(int position, Calendar calendar) {
-		setParameter(position, calendar, StandardBasicTypes.CALENDAR_DATE);
+		setParameter( position, calendar, StandardBasicTypes.CALENDAR_DATE );
 		return this;
 	}
 
 	public Query setBinary(String name, byte[] val) {
-		setParameter(name, val, StandardBasicTypes.BINARY);
+		setParameter( name, val, StandardBasicTypes.BINARY );
 		return this;
 	}
 
 	public Query setText(String name, String val) {
-		setParameter(name, val, StandardBasicTypes.TEXT);
+		setParameter( name, val, StandardBasicTypes.TEXT );
 		return this;
 	}
 
 	public Query setBoolean(String name, boolean val) {
 		Boolean valueToUse = val;
 		Type typeToUse = determineType( name, valueToUse, StandardBasicTypes.BOOLEAN );
 		setParameter( name, valueToUse, typeToUse );
 		return this;
 	}
 
 	public Query setByte(String name, byte val) {
-		setParameter(name, val, StandardBasicTypes.BYTE);
+		setParameter( name, val, StandardBasicTypes.BYTE );
 		return this;
 	}
 
 	public Query setCharacter(String name, char val) {
-		setParameter(name, val, StandardBasicTypes.CHARACTER);
+		setParameter( name, val, StandardBasicTypes.CHARACTER );
 		return this;
 	}
 
 	public Query setDate(String name, Date date) {
-		setParameter(name, date, StandardBasicTypes.DATE);
+		setParameter( name, date, StandardBasicTypes.DATE );
 		return this;
 	}
 
 	public Query setDouble(String name, double val) {
-		setParameter(name, val, StandardBasicTypes.DOUBLE);
+		setParameter( name, val, StandardBasicTypes.DOUBLE );
 		return this;
 	}
 
 	public Query setEntity(String name, Object val) {
 		setParameter( name, val, ( (Session) session ).getTypeHelper().entity( resolveEntityName( val ) ) );
 		return this;
 	}
 
 	public Query setFloat(String name, float val) {
-		setParameter(name, val, StandardBasicTypes.FLOAT);
+		setParameter( name, val, StandardBasicTypes.FLOAT );
 		return this;
 	}
 
 	public Query setInteger(String name, int val) {
-		setParameter(name, val, StandardBasicTypes.INTEGER);
+		setParameter( name, val, StandardBasicTypes.INTEGER );
 		return this;
 	}
 
 	public Query setLocale(String name, Locale locale) {
-		setParameter(name, locale, StandardBasicTypes.LOCALE);
+		setParameter( name, locale, StandardBasicTypes.LOCALE );
 		return this;
 	}
 
 	public Query setCalendar(String name, Calendar calendar) {
-		setParameter(name, calendar, StandardBasicTypes.CALENDAR);
+		setParameter( name, calendar, StandardBasicTypes.CALENDAR );
 		return this;
 	}
 
 	public Query setCalendarDate(String name, Calendar calendar) {
-		setParameter(name, calendar, StandardBasicTypes.CALENDAR_DATE);
+		setParameter( name, calendar, StandardBasicTypes.CALENDAR_DATE );
 		return this;
 	}
 
 	public Query setLong(String name, long val) {
-		setParameter(name, val, StandardBasicTypes.LONG);
+		setParameter( name, val, StandardBasicTypes.LONG );
 		return this;
 	}
 
 	public Query setSerializable(String name, Serializable val) {
-		setParameter(name, val, StandardBasicTypes.SERIALIZABLE);
+		setParameter( name, val, StandardBasicTypes.SERIALIZABLE );
 		return this;
 	}
 
 	public Query setShort(String name, short val) {
-		setParameter(name, val, StandardBasicTypes.SHORT);
+		setParameter( name, val, StandardBasicTypes.SHORT );
 		return this;
 	}
 
 	public Query setString(String name, String val) {
-		setParameter(name, val, StandardBasicTypes.STRING);
+		setParameter( name, val, StandardBasicTypes.STRING );
 		return this;
 	}
 
 	public Query setTime(String name, Date date) {
-		setParameter(name, date, StandardBasicTypes.TIME);
+		setParameter( name, date, StandardBasicTypes.TIME );
 		return this;
 	}
 
 	public Query setTimestamp(String name, Date date) {
-		setParameter(name, date, StandardBasicTypes.TIMESTAMP);
+		setParameter( name, date, StandardBasicTypes.TIMESTAMP );
 		return this;
 	}
 
 	public Query setBigDecimal(int position, BigDecimal number) {
-		setParameter(position, number, StandardBasicTypes.BIG_DECIMAL);
+		setParameter( position, number, StandardBasicTypes.BIG_DECIMAL );
 		return this;
 	}
 
 	public Query setBigDecimal(String name, BigDecimal number) {
-		setParameter(name, number, StandardBasicTypes.BIG_DECIMAL);
+		setParameter( name, number, StandardBasicTypes.BIG_DECIMAL );
 		return this;
 	}
 
 	public Query setBigInteger(int position, BigInteger number) {
-		setParameter(position, number, StandardBasicTypes.BIG_INTEGER);
+		setParameter( position, number, StandardBasicTypes.BIG_INTEGER );
 		return this;
 	}
 
 	public Query setBigInteger(String name, BigInteger number) {
-		setParameter(name, number, StandardBasicTypes.BIG_INTEGER);
+		setParameter( name, number, StandardBasicTypes.BIG_INTEGER );
 		return this;
 	}
 
 	@Override
 	public Query setParameterList(String name, Collection vals, Type type) throws HibernateException {
 		if ( !parameterMetadata.getNamedParameterNames().contains( name ) ) {
-			throw new IllegalArgumentException("Parameter " + name + " does not exist as a named parameter in [" + getQueryString() + "]");
+			throw new IllegalArgumentException( "Parameter " + name + " does not exist as a named parameter in [" + getQueryString() + "]" );
 		}
 		namedParameterLists.put( name, new TypedValue( type, vals ) );
 		return this;
 	}
-	
+
 	/**
 	 * Warning: adds new parameters to the argument by side-effect, as well as
 	 * mutating the query string!
 	 */
 	protected String expandParameterLists(Map namedParamsCopy) {
 		String query = this.queryString;
 		for ( Map.Entry<String, TypedValue> stringTypedValueEntry : namedParameterLists.entrySet() ) {
 			Map.Entry me = (Map.Entry) stringTypedValueEntry;
 			query = expandParameterList( query, (String) me.getKey(), (TypedValue) me.getValue(), namedParamsCopy );
 		}
 		return query;
 	}
 
 	/**
 	 * Warning: adds new parameters to the argument by side-effect, as well as
 	 * mutating the query string!
 	 */
 	private String expandParameterList(String query, String name, TypedValue typedList, Map namedParamsCopy) {
 		Collection vals = (Collection) typedList.getValue();
-		
+
 		// HHH-1123
 		// Some DBs limit number of IN expressions.  For now, warn...
 		final Dialect dialect = session.getFactory().getDialect();
 		final int inExprLimit = dialect.getInExpressionCountLimit();
 		if ( inExprLimit > 0 && vals.size() > inExprLimit ) {
 			log.tooManyInExpressions( dialect.getClass().getName(), inExprLimit, name, vals.size() );
 		}
 
 		Type type = typedList.getType();
 
 		boolean isJpaPositionalParam = parameterMetadata.getNamedParameterDescriptor( name ).isJpaStyle();
 		String paramPrefix = isJpaPositionalParam ? "?" : ParserHelper.HQL_VARIABLE_PREFIX;
-		String placeholder =
-				new StringBuilder( paramPrefix.length() + name.length() )
-						.append( paramPrefix ).append(  name )
-						.toString();
+		String placeholder = paramPrefix + name;
 
 		if ( query == null ) {
-			return query;
+			return null;
 		}
 		int loc = query.indexOf( placeholder );
 
 		if ( loc < 0 ) {
 			return query;
 		}
 
 		String beforePlaceholder = query.substring( 0, loc );
-		String afterPlaceholder =  query.substring( loc + placeholder.length() );
+		String afterPlaceholder = query.substring( loc + placeholder.length() );
 
 		// check if placeholder is already immediately enclosed in parentheses
 		// (ignoring whitespace)
 		boolean isEnclosedInParens =
 				StringHelper.getLastNonWhitespaceCharacter( beforePlaceholder ) == '(' &&
-				StringHelper.getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')';
+						StringHelper.getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')';
 
-		if ( vals.size() == 1  && isEnclosedInParens ) {
+		if ( vals.size() == 1 && isEnclosedInParens ) {
 			// short-circuit for performance when only 1 value and the
 			// placeholder is already enclosed in parentheses...
 			namedParamsCopy.put( name, new TypedValue( type, vals.iterator().next() ) );
 			return query;
 		}
 
 		StringBuilder list = new StringBuilder( 16 );
 		Iterator iter = vals.iterator();
 		int i = 0;
 		while ( iter.hasNext() ) {
 			// Variable 'name' can represent a number or contain digit at the end. Surrounding it with
 			// characters to avoid ambiguous definition after concatenating value of 'i' counter.
 			String alias = ( isJpaPositionalParam ? 'x' + name : name ) + '_' + i++ + '_';
 			if ( namedParamsCopy.put( alias, new TypedValue( type, iter.next() ) ) != null ) {
 				throw new HibernateException( "Repeated usage of alias '" + alias + "' while expanding list parameter." );
 			}
 			list.append( ParserHelper.HQL_VARIABLE_PREFIX ).append( alias );
 			if ( iter.hasNext() ) {
 				list.append( ", " );
 			}
 		}
 		return StringHelper.replace(
 				beforePlaceholder,
 				afterPlaceholder,
 				placeholder.toString(),
 				list.toString(),
 				true,
 				true
 		);
 	}
 
 	public Query setParameterList(String name, Collection vals) throws HibernateException {
 		if ( vals == null ) {
 			throw new QueryException( "Collection must be not null!" );
 		}
 
-		if( vals.size() == 0 ) {
+		if ( vals.size() == 0 ) {
 			setParameterList( name, vals, null );
 		}
 		else {
-			setParameterList(name, vals, determineType( name, vals.iterator().next() ) );
+			setParameterList( name, vals, determineType( name, vals.iterator().next() ) );
 		}
 
 		return this;
 	}
 
 	public Query setParameterList(String name, Object[] vals, Type type) throws HibernateException {
-		return setParameterList( name, Arrays.asList(vals), type );
+		return setParameterList( name, Arrays.asList( vals ), type );
 	}
 
 	public Query setParameterList(String name, Object[] values) throws HibernateException {
 		return setParameterList( name, Arrays.asList( values ) );
 	}
 
 	public Query setProperties(Map map) throws HibernateException {
 		String[] params = getNamedParameters();
-		for (int i = 0; i < params.length; i++) {
+		for ( int i = 0; i < params.length; i++ ) {
 			String namedParam = params[i];
-				final Object object = map.get(namedParam);
-				if(object==null) {
-					continue;
-				}
-				Class retType = object.getClass();
-				if ( Collection.class.isAssignableFrom( retType ) ) {
-					setParameterList( namedParam, ( Collection ) object );
-				}
-				else if ( retType.isArray() ) {
-					setParameterList( namedParam, ( Object[] ) object );
-				}
-				else {
-					setParameter( namedParam, object, determineType( namedParam, retType ) );
-				}
+			final Object object = map.get( namedParam );
+			if ( object == null ) {
+				continue;
+			}
+			Class retType = object.getClass();
+			if ( Collection.class.isAssignableFrom( retType ) ) {
+				setParameterList( namedParam, (Collection) object );
+			}
+			else if ( retType.isArray() ) {
+				setParameterList( namedParam, (Object[]) object );
+			}
+			else {
+				setParameter( namedParam, object, determineType( namedParam, retType ) );
+			}
+
 
-			
 		}
-		return this;				
+		return this;
 	}
-	
+
 	public Query setProperties(Object bean) throws HibernateException {
 		Class clazz = bean.getClass();
 		String[] params = getNamedParameters();
-		for (int i = 0; i < params.length; i++) {
-			String namedParam = params[i];
+		for ( String namedParam : params ) {
 			try {
 				Getter getter = ReflectHelper.getGetter( clazz, namedParam );
 				Class retType = getter.getReturnType();
 				final Object object = getter.get( bean );
 				if ( Collection.class.isAssignableFrom( retType ) ) {
-					setParameterList( namedParam, ( Collection ) object );
+					setParameterList( namedParam, (Collection) object );
 				}
 				else if ( retType.isArray() ) {
-				 	setParameterList( namedParam, ( Object[] ) object );
+					setParameterList( namedParam, (Object[]) object );
 				}
 				else {
 					setParameter( namedParam, object, determineType( namedParam, retType ) );
 				}
 			}
 			catch (PropertyNotFoundException pnfe) {
 				// ignore
 			}
 		}
 		return this;
 	}
 
 	public Query setParameters(Object[] values, Type[] types) {
-		this.values = Arrays.asList(values);
-		this.types = Arrays.asList(types);
+		this.values = Arrays.asList( values );
+		this.types = Arrays.asList( types );
 		return this;
 	}
 
 
 	// Execution methods ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Object uniqueResult() throws HibernateException {
 		return uniqueElement( list() );
 	}
 
 	static Object uniqueElement(List list) throws NonUniqueResultException {
 		int size = list.size();
-		if (size==0) {
+		if ( size == 0 ) {
 			return null;
 		}
-		Object first = list.get(0);
-		for ( int i=1; i<size; i++ ) {
-			if ( list.get(i)!=first ) {
+		Object first = list.get( 0 );
+		for ( int i = 1; i < size; i++ ) {
+			if ( list.get( i ) != first ) {
 				throw new NonUniqueResultException( list.size() );
 			}
 		}
 		return first;
 	}
 
 	protected RowSelection getRowSelection() {
 		return selection;
 	}
 
 	public Type[] typeArray() {
 		return ArrayHelper.toTypeArray( getTypes() );
 	}
-	
+
 	public Object[] valueArray() {
 		return getValues().toArray();
 	}
 
 	public QueryParameters getQueryParameters(Map namedParams) {
 		QueryParameters queryParameters = new QueryParameters(
 				typeArray(),
 				valueArray(),
 				namedParams,
 				getLockOptions(),
 				getRowSelection(),
 				true,
 				isReadOnly(),
 				cacheable,
 				cacheRegion,
 				comment,
 				queryHints,
-				collectionKey == null ? null : new Serializable[] { collectionKey },
+				collectionKey == null ? null : new Serializable[] {collectionKey},
 				optionalObject,
 				optionalEntityName,
 				optionalId,
 				resultTransformer
 		);
 		queryParameters.setQueryPlan( queryPlan );
 		return queryParameters;
 	}
-	
+
 	protected void before() {
-		if ( flushMode!=null ) {
+		if ( flushMode != null ) {
 			sessionFlushMode = getSession().getFlushMode();
-			getSession().setFlushMode(flushMode);
+			getSession().setFlushMode( flushMode );
 		}
-		if ( cacheMode!=null ) {
+		if ( cacheMode != null ) {
 			sessionCacheMode = getSession().getCacheMode();
-			getSession().setCacheMode(cacheMode);
+			getSession().setCacheMode( cacheMode );
 		}
 	}
-	
+
 	protected void after() {
-		if (sessionFlushMode!=null) {
-			getSession().setFlushMode(sessionFlushMode);
+		if ( sessionFlushMode != null ) {
+			getSession().setFlushMode( sessionFlushMode );
 			sessionFlushMode = null;
 		}
-		if (sessionCacheMode!=null) {
-			getSession().setCacheMode(sessionCacheMode);
+		if ( sessionCacheMode != null ) {
+			getSession().setCacheMode( sessionCacheMode );
 			sessionCacheMode = null;
 		}
 	}
 
 	public HQLQueryPlan getQueryPlan() {
 		return queryPlan;
 	}
 
 	public void setQueryPlan(HQLQueryPlan queryPlan) {
 		this.queryPlan = queryPlan;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/AbstractScrollableResults.java b/hibernate-core/src/main/java/org/hibernate/internal/AbstractScrollableResults.java
index d77e49c25e..5673397f2f 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/AbstractScrollableResults.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/AbstractScrollableResults.java
@@ -1,301 +1,295 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.Locale;
 import java.util.TimeZone;
 
 import org.hibernate.HibernateException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.loader.Loader;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * Base implementation of the ScrollableResults interface.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractScrollableResults implements ScrollableResults {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class,
-			AbstractScrollableResults.class.getName()
-	);
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( AbstractScrollableResults.class );
 
 	private final ResultSet resultSet;
 	private final PreparedStatement ps;
 	private final SessionImplementor session;
 	private final Loader loader;
 	private final QueryParameters queryParameters;
 	private final Type[] types;
 	private HolderInstantiator holderInstantiator;
 
 	protected AbstractScrollableResults(
-	        ResultSet rs,
-	        PreparedStatement ps,
-	        SessionImplementor sess,
+			ResultSet rs,
+			PreparedStatement ps,
+			SessionImplementor sess,
 			Loader loader,
 			QueryParameters queryParameters,
-	        Type[] types,
-	        HolderInstantiator holderInstantiator) {
-		this.resultSet=rs;
-		this.ps=ps;
+			Type[] types,
+			HolderInstantiator holderInstantiator) {
+		this.resultSet = rs;
+		this.ps = ps;
 		this.session = sess;
 		this.loader = loader;
 		this.queryParameters = queryParameters;
 		this.types = types;
-		this.holderInstantiator = holderInstantiator!=null && holderInstantiator.isRequired()
-		        ? holderInstantiator
-		        : null;
+		this.holderInstantiator = holderInstantiator != null && holderInstantiator.isRequired()
+				? holderInstantiator
+				: null;
 	}
 
 	protected abstract Object[] getCurrentRow();
 
 	protected ResultSet getResultSet() {
 		return resultSet;
 	}
 
 	protected PreparedStatement getPs() {
 		return ps;
 	}
 
 	protected SessionImplementor getSession() {
 		return session;
 	}
 
 	protected Loader getLoader() {
 		return loader;
 	}
 
 	protected QueryParameters getQueryParameters() {
 		return queryParameters;
 	}
 
 	protected Type[] getTypes() {
 		return types;
 	}
 
 	protected HolderInstantiator getHolderInstantiator() {
 		return holderInstantiator;
 	}
 
 	@Override
 	public final void close() {
 		// not absolutely necessary, but does help with aggressive release
 		//session.getJDBCContext().getConnectionManager().closeQueryStatement( ps, resultSet );
 		session.getJdbcCoordinator().getResourceRegistry().release( ps );
 		session.getJdbcCoordinator().afterStatementExecution();
 		try {
 			session.getPersistenceContext().getLoadContexts().cleanup( resultSet );
 		}
-		catch( Throwable ignore ) {
+		catch (Throwable ignore) {
 			// ignore this error for now
 			if ( LOG.isTraceEnabled() ) {
 				LOG.tracev( "Exception trying to cleanup load context : {0}", ignore.getMessage() );
 			}
 		}
 	}
 
 	@Override
 	public final Object[] get() throws HibernateException {
 		return getCurrentRow();
 	}
 
 	@Override
 	public final Object get(int col) throws HibernateException {
 		return getCurrentRow()[col];
 	}
 
 	/**
 	 * Check that the requested type is compatible with the result type, and
 	 * return the column value.  This version makes sure the the classes
 	 * are identical.
 	 *
 	 * @param col the column
 	 * @param returnType a "final" type
 	 */
 	protected final Object getFinal(int col, Type returnType) throws HibernateException {
-		if ( holderInstantiator!=null ) {
-			throw new HibernateException("query specifies a holder class");
+		if ( holderInstantiator != null ) {
+			throw new HibernateException( "query specifies a holder class" );
 		}
 
-		if ( returnType.getReturnedClass()==types[col].getReturnedClass() ) {
-			return get(col);
+		if ( returnType.getReturnedClass() == types[col].getReturnedClass() ) {
+			return get( col );
 		}
 		else {
-			return throwInvalidColumnTypeException(col, types[col], returnType);
+			return throwInvalidColumnTypeException( col, types[col], returnType );
 		}
 	}
 
 	/**
 	 * Check that the requested type is compatible with the result type, and
 	 * return the column value.  This version makes sure the the classes
 	 * are "assignable".
 	 *
 	 * @param col the column
 	 * @param returnType any type
 	 */
 	protected final Object getNonFinal(int col, Type returnType) throws HibernateException {
-		if ( holderInstantiator!=null ) {
-			throw new HibernateException("query specifies a holder class");
+		if ( holderInstantiator != null ) {
+			throw new HibernateException( "query specifies a holder class" );
 		}
 
 		if ( returnType.getReturnedClass().isAssignableFrom( types[col].getReturnedClass() ) ) {
-			return get(col);
+			return get( col );
 		}
 		else {
-			return throwInvalidColumnTypeException(col, types[col], returnType);
+			return throwInvalidColumnTypeException( col, types[col], returnType );
 		}
 	}
 
 	@Override
 	public final BigDecimal getBigDecimal(int col) throws HibernateException {
-		return (BigDecimal) getFinal(col, StandardBasicTypes.BIG_DECIMAL);
+		return (BigDecimal) getFinal( col, StandardBasicTypes.BIG_DECIMAL );
 	}
 
 	@Override
 	public final BigInteger getBigInteger(int col) throws HibernateException {
-		return (BigInteger) getFinal(col, StandardBasicTypes.BIG_INTEGER);
+		return (BigInteger) getFinal( col, StandardBasicTypes.BIG_INTEGER );
 	}
 
 	@Override
 	public final byte[] getBinary(int col) throws HibernateException {
-		return (byte[]) getFinal(col, StandardBasicTypes.BINARY);
+		return (byte[]) getFinal( col, StandardBasicTypes.BINARY );
 	}
 
 	@Override
 	public final String getText(int col) throws HibernateException {
-		return (String) getFinal(col, StandardBasicTypes.TEXT);
+		return (String) getFinal( col, StandardBasicTypes.TEXT );
 	}
 
 	@Override
 	public final Blob getBlob(int col) throws HibernateException {
-		return (Blob) getNonFinal(col, StandardBasicTypes.BLOB);
+		return (Blob) getNonFinal( col, StandardBasicTypes.BLOB );
 	}
 
 	@Override
 	public final Clob getClob(int col) throws HibernateException {
-		return (Clob) getNonFinal(col, StandardBasicTypes.CLOB);
+		return (Clob) getNonFinal( col, StandardBasicTypes.CLOB );
 	}
 
 	@Override
 	public final Boolean getBoolean(int col) throws HibernateException {
-		return (Boolean) getFinal(col, StandardBasicTypes.BOOLEAN);
+		return (Boolean) getFinal( col, StandardBasicTypes.BOOLEAN );
 	}
 
 	@Override
 	public final Byte getByte(int col) throws HibernateException {
-		return (Byte) getFinal(col, StandardBasicTypes.BYTE);
+		return (Byte) getFinal( col, StandardBasicTypes.BYTE );
 	}
 
 	@Override
 	public final Character getCharacter(int col) throws HibernateException {
-		return (Character) getFinal(col, StandardBasicTypes.CHARACTER);
+		return (Character) getFinal( col, StandardBasicTypes.CHARACTER );
 	}
 
 	@Override
 	public final Date getDate(int col) throws HibernateException {
-		return (Date) getNonFinal(col, StandardBasicTypes.TIMESTAMP);
+		return (Date) getNonFinal( col, StandardBasicTypes.TIMESTAMP );
 	}
 
 	@Override
 	public final Calendar getCalendar(int col) throws HibernateException {
-		return (Calendar) getNonFinal(col, StandardBasicTypes.CALENDAR);
+		return (Calendar) getNonFinal( col, StandardBasicTypes.CALENDAR );
 	}
 
 	@Override
 	public final Double getDouble(int col) throws HibernateException {
-		return (Double) getFinal(col, StandardBasicTypes.DOUBLE);
+		return (Double) getFinal( col, StandardBasicTypes.DOUBLE );
 	}
 
 	@Override
 	public final Float getFloat(int col) throws HibernateException {
-		return (Float) getFinal(col, StandardBasicTypes.FLOAT);
+		return (Float) getFinal( col, StandardBasicTypes.FLOAT );
 	}
 
 	@Override
 	public final Integer getInteger(int col) throws HibernateException {
-		return (Integer) getFinal(col, StandardBasicTypes.INTEGER);
+		return (Integer) getFinal( col, StandardBasicTypes.INTEGER );
 	}
 
 	@Override
 	public final Long getLong(int col) throws HibernateException {
-		return (Long) getFinal(col, StandardBasicTypes.LONG);
+		return (Long) getFinal( col, StandardBasicTypes.LONG );
 	}
 
 	@Override
 	public final Short getShort(int col) throws HibernateException {
-		return (Short) getFinal(col, StandardBasicTypes.SHORT);
+		return (Short) getFinal( col, StandardBasicTypes.SHORT );
 	}
 
 	@Override
 	public final String getString(int col) throws HibernateException {
-		return (String) getFinal(col, StandardBasicTypes.STRING);
+		return (String) getFinal( col, StandardBasicTypes.STRING );
 	}
 
 	@Override
 	public final Locale getLocale(int col) throws HibernateException {
-		return (Locale) getFinal(col, StandardBasicTypes.LOCALE);
+		return (Locale) getFinal( col, StandardBasicTypes.LOCALE );
 	}
 
 	@Override
 	public final TimeZone getTimeZone(int col) throws HibernateException {
-		return (TimeZone) getNonFinal(col, StandardBasicTypes.TIMEZONE);
+		return (TimeZone) getNonFinal( col, StandardBasicTypes.TIMEZONE );
 	}
 
 	@Override
 	public final Type getType(int i) {
 		return types[i];
 	}
 
 	private Object throwInvalidColumnTypeException(
-	        int i,
-	        Type type,
-	        Type returnType) throws HibernateException {
+			int i,
+			Type type,
+			Type returnType) throws HibernateException {
 		throw new HibernateException(
 				"incompatible column types: " +
-				type.getName() +
-				", " +
-				returnType.getName()
+						type.getName() +
+						", " +
+						returnType.getName()
 		);
 	}
 
 	protected void afterScrollOperation() {
 		session.afterScrollOperation();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
index 0d96d4800a..e5f6e4894d 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
@@ -1,615 +1,616 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.UUID;
 
 import org.hibernate.ConnectionAcquisitionMode;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.Query;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollableResults;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionException;
 import org.hibernate.SharedSessionContract;
 import org.hibernate.Transaction;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider;
 import org.hibernate.engine.jdbc.spi.ConnectionObserver;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NativeSQLQueryPlan;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.transaction.internal.TransactionImpl;
 import org.hibernate.id.uuid.StandardRandomStrategy;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.procedure.ProcedureCall;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.procedure.internal.ProcedureCallImpl;
 import org.hibernate.resource.jdbc.spi.JdbcObserver;
 import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
 import org.hibernate.resource.jdbc.spi.JdbcSessionOwner;
 import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
 import org.hibernate.resource.transaction.TransactionCoordinatorBuilder.TransactionCoordinatorOptions;
 import org.hibernate.resource.transaction.spi.TransactionStatus;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.type.Type;
 
 /**
  * Functionality common to stateless and stateful sessions
  *
  * @author Gavin King
  */
 public abstract class AbstractSessionImpl
 		implements Serializable, SharedSessionContract, SessionImplementor, JdbcSessionOwner, TransactionCoordinatorOptions {
 	protected transient SessionFactoryImpl factory;
 	private final String tenantIdentifier;
 	private boolean closed;
 
 	protected transient Transaction currentHibernateTransaction;
 
 	protected AbstractSessionImpl(SessionFactoryImpl factory, String tenantIdentifier) {
 		this.factory = factory;
 		this.tenantIdentifier = tenantIdentifier;
 		if ( MultiTenancyStrategy.NONE == factory.getSettings().getMultiTenancyStrategy() ) {
 			if ( tenantIdentifier != null ) {
 				throw new HibernateException( "SessionFactory was not configured for multi-tenancy" );
 			}
 		}
 		else {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "SessionFactory configured for multi-tenancy, but no tenant identifier specified" );
 			}
 		}
 	}
 
+	@Override
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	@Override
 	public abstract boolean shouldAutoJoinTransaction();
 
 	@Override
 	public <T> T execute(final LobCreationContext.Callback<T> callback) {
 		return getJdbcCoordinator().coordinateWork(
 				new WorkExecutorVisitable<T>() {
 					@Override
 					public T accept(WorkExecutor<T> workExecutor, Connection connection) throws SQLException {
 						try {
 							return callback.executeOnConnection( connection );
 						}
 						catch (SQLException e) {
 							throw getFactory().getSQLExceptionHelper().convert(
 									e,
 									"Error creating contextual LOB : " + e.getMessage()
 							);
 						}
 					}
 				}
 		);
 	}
 
 	@Override
 	public boolean isClosed() {
 		return closed || factory.isClosed();
 	}
 
 	protected void setClosed() {
 		closed = true;
 	}
 
 	protected void errorIfClosed() {
 		if ( isClosed() ) {
 			throw new SessionException( "Session is closed!" );
 		}
 	}
 
 	@Override
 	public Query createQuery(NamedQueryDefinition namedQueryDefinition) {
 		String queryString = namedQueryDefinition.getQueryString();
 		final Query query = new QueryImpl(
 				queryString,
 				namedQueryDefinition.getFlushMode(),
 				this,
 				getHQLQueryPlan( queryString, false ).getParameterMetadata()
 		);
 		query.setComment( "named HQL query " + namedQueryDefinition.getName() );
 		if ( namedQueryDefinition.getLockOptions() != null ) {
 			query.setLockOptions( namedQueryDefinition.getLockOptions() );
 		}
 
 		return query;
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(NamedSQLQueryDefinition namedQueryDefinition) {
 		final ParameterMetadata parameterMetadata = factory.getQueryPlanCache().getSQLParameterMetadata(
 				namedQueryDefinition.getQueryString()
 		);
 		final SQLQuery query = new SQLQueryImpl(
 				namedQueryDefinition,
 				this,
 				parameterMetadata
 		);
 		query.setComment( "named native SQL query " + namedQueryDefinition.getName() );
 		return query;
 	}
 
 	@Override
 	public Query getNamedQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		NamedQueryDefinition nqd = factory.getNamedQuery( queryName );
 		final Query query;
 		if ( nqd != null ) {
 			query = createQuery( nqd );
 		}
 		else {
 			NamedSQLQueryDefinition nsqlqd = factory.getNamedSQLQuery( queryName );
 			if ( nsqlqd==null ) {
 				throw new MappingException( "Named query not known: " + queryName );
 			}
 
 			query = createSQLQuery( nsqlqd );
 			nqd = nsqlqd;
 		}
 		initQuery( query, nqd );
 		return query;
 	}
 
 	@Override
 	public Query getNamedSQLQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		NamedSQLQueryDefinition nsqlqd = factory.getNamedSQLQuery( queryName );
 		if ( nsqlqd==null ) {
 			throw new MappingException( "Named SQL query not known: " + queryName );
 		}
 		Query query = new SQLQueryImpl(
 				nsqlqd,
-		        this,
-		        factory.getQueryPlanCache().getSQLParameterMetadata( nsqlqd.getQueryString() )
+				this,
+				factory.getQueryPlanCache().getSQLParameterMetadata( nsqlqd.getQueryString() )
 		);
 		query.setComment( "named native SQL query " + queryName );
 		initQuery( query, nsqlqd );
 		return query;
 	}
 
 	private void initQuery(Query query, NamedQueryDefinition nqd) {
 		// todo : cacheable and readonly should be Boolean rather than boolean...
 		query.setCacheable( nqd.isCacheable() );
 		query.setCacheRegion( nqd.getCacheRegion() );
 		query.setReadOnly( nqd.isReadOnly() );
 
 		if ( nqd.getTimeout() != null ) {
 			query.setTimeout( nqd.getTimeout() );
 		}
 		if ( nqd.getFetchSize() != null ) {
 			query.setFetchSize( nqd.getFetchSize() );
 		}
 		if ( nqd.getCacheMode() != null ) {
 			query.setCacheMode( nqd.getCacheMode() );
 		}
 		if ( nqd.getComment() != null ) {
 			query.setComment( nqd.getComment() );
 		}
 		if ( nqd.getFirstResult() != null ) {
 			query.setFirstResult( nqd.getFirstResult() );
 		}
 		if ( nqd.getMaxResults() != null ) {
 			query.setMaxResults( nqd.getMaxResults() );
 		}
 		if ( nqd.getFlushMode() != null ) {
 			query.setFlushMode( nqd.getFlushMode() );
 		}
 	}
 
 	@Override
 	public Query createQuery(String queryString) {
 		errorIfClosed();
 		final QueryImpl query = new QueryImpl(
 				queryString,
 				this,
 				getHQLQueryPlan( queryString, false ).getParameterMetadata()
 		);
 		query.setComment( queryString );
 		return query;
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(String sql) {
 		errorIfClosed();
 		final SQLQueryImpl query = new SQLQueryImpl(
 				sql,
 				this,
 				factory.getQueryPlanCache().getSQLParameterMetadata( sql )
 		);
 		query.setComment( "dynamic native SQL query" );
 		return query;
 	}
 
 	@Override
 	@SuppressWarnings("UnnecessaryLocalVariable")
 	public ProcedureCall getNamedProcedureCall(String name) {
 		errorIfClosed();
 
 		final ProcedureCallMemento memento = factory.getNamedQueryRepository().getNamedProcedureCallMemento( name );
 		if ( memento == null ) {
 			throw new IllegalArgumentException(
 					"Could not find named stored procedure call with that registration name : " + name
 			);
 		}
 		final ProcedureCall procedureCall = memento.makeProcedureCall( this );
 //		procedureCall.setComment( "Named stored procedure call [" + name + "]" );
 		return procedureCall;
 	}
 
 	@Override
 	@SuppressWarnings("UnnecessaryLocalVariable")
 	public ProcedureCall createStoredProcedureCall(String procedureName) {
 		errorIfClosed();
 		final ProcedureCall procedureCall = new ProcedureCallImpl( this, procedureName );
 //		call.setComment( "Dynamic stored procedure call" );
 		return procedureCall;
 	}
 
 	@Override
 	@SuppressWarnings("UnnecessaryLocalVariable")
 	public ProcedureCall createStoredProcedureCall(String procedureName, Class... resultClasses) {
 		errorIfClosed();
 		final ProcedureCall procedureCall = new ProcedureCallImpl( this, procedureName, resultClasses );
 //		call.setComment( "Dynamic stored procedure call" );
 		return procedureCall;
 	}
 
 	@Override
 	@SuppressWarnings("UnnecessaryLocalVariable")
 	public ProcedureCall createStoredProcedureCall(String procedureName, String... resultSetMappings) {
 		errorIfClosed();
 		final ProcedureCall procedureCall = new ProcedureCallImpl( this, procedureName, resultSetMappings );
 //		call.setComment( "Dynamic stored procedure call" );
 		return procedureCall;
 	}
 
 	protected HQLQueryPlan getHQLQueryPlan(String query, boolean shallow) throws HibernateException {
 		return factory.getQueryPlanCache().getHQLQueryPlan( query, shallow, getLoadQueryInfluencers().getEnabledFilters() );
 	}
 
 	protected NativeSQLQueryPlan getNativeSQLQueryPlan(NativeSQLQuerySpecification spec) throws HibernateException {
 		return factory.getQueryPlanCache().getNativeSQLQueryPlan( spec );
 	}
 
 	@Override
 	public Transaction getTransaction() throws HibernateException {
 		errorIfClosed();
 		if ( this.currentHibernateTransaction == null || this.currentHibernateTransaction.getStatus() != TransactionStatus.ACTIVE ) {
 			this.currentHibernateTransaction = new TransactionImpl( getTransactionCoordinator() );
 		}
 		getTransactionCoordinator().pulse();
 		return currentHibernateTransaction;
 	}
 
 	@Override
 	public List list(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException {
 		return listCustomQuery( getNativeSQLQueryPlan( spec ).getCustomQuery(), queryParameters );
 	}
 
 	@Override
 	public ScrollableResults scroll(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException {
 		return scrollCustomQuery( getNativeSQLQueryPlan( spec ).getCustomQuery(), queryParameters );
 	}
 
 	@Override
 	public String getTenantIdentifier() {
 		return tenantIdentifier;
 	}
 
 	@Override
 	public EntityKey generateEntityKey(Serializable id, EntityPersister persister) {
 		return new EntityKey( id, persister );
 	}
 
 	@Override
 	public CacheKey generateCacheKey(Serializable id, Type type, String entityOrRoleName) {
 		return new CacheKey( id, type, entityOrRoleName, getTenantIdentifier(), getFactory() );
 	}
 
 	private transient JdbcConnectionAccess jdbcConnectionAccess;
 
 	@Override
 	public JdbcConnectionAccess getJdbcConnectionAccess() {
 		if ( jdbcConnectionAccess == null ) {
 			if ( MultiTenancyStrategy.NONE == factory.getSettings().getMultiTenancyStrategy() ) {
 				jdbcConnectionAccess = new NonContextualJdbcConnectionAccess(
 						getEventListenerManager(),
 						factory.getServiceRegistry().getService( ConnectionProvider.class )
 				);
 			}
 			else {
 				jdbcConnectionAccess = new ContextualJdbcConnectionAccess(
 						getEventListenerManager(),
 						factory.getServiceRegistry().getService( MultiTenantConnectionProvider.class )
 				);
 			}
 		}
 		return jdbcConnectionAccess;
 	}
 
 	private UUID sessionIdentifier;
 
 	public UUID getSessionIdentifier() {
 		if ( sessionIdentifier == null ) {
 			sessionIdentifier = StandardRandomStrategy.INSTANCE.generateUUID( this );
 		}
 		return sessionIdentifier;
 	}
 
 	private static class NonContextualJdbcConnectionAccess implements JdbcConnectionAccess, Serializable {
 		private final SessionEventListener listener;
 		private final ConnectionProvider connectionProvider;
 
 		private NonContextualJdbcConnectionAccess(
 				SessionEventListener listener,
 				ConnectionProvider connectionProvider) {
 			this.listener = listener;
 			this.connectionProvider = connectionProvider;
 		}
 
 		@Override
 		public Connection obtainConnection() throws SQLException {
 			try {
 				listener.jdbcConnectionAcquisitionStart();
 				return connectionProvider.getConnection();
 			}
 			finally {
 				listener.jdbcConnectionAcquisitionEnd();
 			}
 		}
 
 		@Override
 		public void releaseConnection(Connection connection) throws SQLException {
 			try {
 				listener.jdbcConnectionReleaseStart();
 				connectionProvider.closeConnection( connection );
 			}
 			finally {
 				listener.jdbcConnectionReleaseEnd();
 			}
 		}
 
 		@Override
 		public boolean supportsAggressiveRelease() {
 			return connectionProvider.supportsAggressiveRelease();
 		}
 	}
 
 	private class ContextualJdbcConnectionAccess implements JdbcConnectionAccess, Serializable {
 		private final SessionEventListener listener;
 		private final MultiTenantConnectionProvider connectionProvider;
 
 		private ContextualJdbcConnectionAccess(
 				SessionEventListener listener,
 				MultiTenantConnectionProvider connectionProvider) {
 			this.listener = listener;
 			this.connectionProvider = connectionProvider;
 		}
 
 		@Override
 		public Connection obtainConnection() throws SQLException {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "Tenant identifier required!" );
 			}
 
 			try {
 				listener.jdbcConnectionAcquisitionStart();
 				return connectionProvider.getConnection( tenantIdentifier );
 			}
 			finally {
 				listener.jdbcConnectionAcquisitionEnd();
 			}
 		}
 
 		@Override
 		public void releaseConnection(Connection connection) throws SQLException {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "Tenant identifier required!" );
 			}
 
 			try {
 				listener.jdbcConnectionReleaseStart();
 				connectionProvider.releaseConnection( tenantIdentifier, connection );
 			}
 			finally {
 				listener.jdbcConnectionReleaseEnd();
 			}
 		}
 
 		@Override
 		public boolean supportsAggressiveRelease() {
 			return connectionProvider.supportsAggressiveRelease();
 		}
 	}
 
 	public class JdbcSessionContextImpl implements JdbcSessionContext {
 		private final SessionFactoryImpl sessionFactory;
 		private final StatementInspector inspector;
 		private final transient ServiceRegistry serviceRegistry;
 		private final transient JdbcObserver jdbcObserver;
 
 		public JdbcSessionContextImpl(SessionFactoryImpl sessionFactory, StatementInspector inspector) {
 			this.sessionFactory = sessionFactory;
 			this.inspector = inspector;
 			this.serviceRegistry = sessionFactory.getServiceRegistry();
 			this.jdbcObserver = new JdbcObserverImpl();
 
 			if ( inspector == null ) {
 				throw new IllegalArgumentException( "StatementInspector cannot be null" );
 			}
 		}
 
 		@Override
 		public boolean isScrollableResultSetsEnabled() {
 			return settings().isScrollableResultSetsEnabled();
 		}
 
 		@Override
 		public boolean isGetGeneratedKeysEnabled() {
 			return settings().isGetGeneratedKeysEnabled();
 		}
 
 		@Override
 		public int getFetchSize() {
 			return settings().getJdbcFetchSize();
 		}
 
 		@Override
 		public ConnectionReleaseMode getConnectionReleaseMode() {
 			return settings().getConnectionReleaseMode();
 		}
 
 		@Override
 		public ConnectionAcquisitionMode getConnectionAcquisitionMode() {
 			return ConnectionAcquisitionMode.DEFAULT;
 		}
 
 		@Override
 		public StatementInspector getStatementInspector() {
 			return inspector;
 		}
 
 		@Override
 		public JdbcObserver getObserver() {
 			return this.jdbcObserver;
 		}
 
 		@Override
 		public SessionFactoryImplementor getSessionFactory() {
 			return this.sessionFactory;
 		}
 
 		@Override
 		public ServiceRegistry getServiceRegistry() {
 			return this.serviceRegistry;
 		}
 
 		private SessionFactoryOptions settings() {
 			return this.sessionFactory.getSessionFactoryOptions();
 		}
 	}
 
 	public class JdbcObserverImpl implements JdbcObserver {
 
 		private final transient List<ConnectionObserver> observers;
 
 		public JdbcObserverImpl() {
 			this.observers = new ArrayList<ConnectionObserver>();
 			this.observers.add( new ConnectionObserverStatsBridge( factory ) );
 		}
 
 		@Override
 		public void jdbcConnectionAcquisitionStart() {
 
 		}
 
 		@Override
 		public void jdbcConnectionAcquisitionEnd(Connection connection) {
 			for ( ConnectionObserver observer : observers ) {
 				observer.physicalConnectionObtained( connection );
 			}
 		}
 
 		@Override
 		public void jdbcConnectionReleaseStart() {
 
 		}
 
 		@Override
 		public void jdbcConnectionReleaseEnd() {
 			for ( ConnectionObserver observer : observers ) {
 				observer.physicalConnectionReleased();
 			}
 		}
 
 		@Override
 		public void jdbcPrepareStatementStart() {
 			getEventListenerManager().jdbcPrepareStatementStart();
 		}
 
 		@Override
 		public void jdbcPrepareStatementEnd() {
 			for ( ConnectionObserver observer : observers ) {
 				observer.statementPrepared();
 			}
 			getEventListenerManager().jdbcPrepareStatementEnd();
 		}
 
 		@Override
 		public void jdbcExecuteStatementStart() {
 			getEventListenerManager().jdbcExecuteStatementStart();
 		}
 
 		@Override
 		public void jdbcExecuteStatementEnd() {
 			getEventListenerManager().jdbcExecuteStatementEnd();
 		}
 
 		@Override
 		public void jdbcExecuteBatchStart() {
 			getEventListenerManager().jdbcExecuteBatchStart();
 		}
 
 		@Override
 		public void jdbcExecuteBatchEnd() {
 			getEventListenerManager().jdbcExecuteBatchEnd();
 		}
 	}
 
 	@Override
 	public TransactionCoordinatorBuilder getTransactionCoordinatorBuilder() {
 		return factory.getServiceRegistry().getService( TransactionCoordinatorBuilder.class );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/CacheImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/CacheImpl.java
index e54da177b2..7dd2ef6375 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/CacheImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/CacheImpl.java
@@ -1,376 +1,370 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.engine.spi.CacheImplementor;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 
-import org.jboss.logging.Logger;
-
 /**
  * @author Strong Liu <stliu@hibernate.org>
  */
 public class CacheImpl implements CacheImplementor {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class,
-			CacheImpl.class.getName()
-	);
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( CacheImpl.class );
+
 	private final SessionFactoryImplementor sessionFactory;
 	private final SessionFactoryOptions settings;
 	private final transient QueryCache queryCache;
 	private final transient RegionFactory regionFactory;
 	private final transient UpdateTimestampsCache updateTimestampsCache;
 	private final transient ConcurrentMap<String, QueryCache> queryCaches;
 	private final transient ConcurrentMap<String, Region> allCacheRegions = new ConcurrentHashMap<String, Region>();
 
 	public CacheImpl(SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 		this.settings = sessionFactory.getSessionFactoryOptions();
 		//todo should get this from service registry
 		this.regionFactory = settings.getServiceRegistry().getService( RegionFactory.class );
 		regionFactory.start( settings, sessionFactory.getProperties() );
 		if ( settings.isQueryCacheEnabled() ) {
 			updateTimestampsCache = new UpdateTimestampsCache(
 					settings,
 					sessionFactory.getProperties(),
 					sessionFactory
 			);
 			queryCache = settings.getQueryCacheFactory()
 					.getQueryCache( null, updateTimestampsCache, settings, sessionFactory.getProperties() );
 			queryCaches = new ConcurrentHashMap<String, QueryCache>();
 			allCacheRegions.put( updateTimestampsCache.getRegion().getName(), updateTimestampsCache.getRegion() );
 			allCacheRegions.put( queryCache.getRegion().getName(), queryCache.getRegion() );
 		}
 		else {
 			updateTimestampsCache = null;
 			queryCache = null;
 			queryCaches = null;
 		}
 	}
 
 	@Override
 	public boolean containsEntity(Class entityClass, Serializable identifier) {
 		return containsEntity( entityClass.getName(), identifier );
 	}
 
 	@Override
 	public boolean containsEntity(String entityName, Serializable identifier) {
 		EntityPersister p = sessionFactory.getEntityPersister( entityName );
 		return p.hasCache() &&
 				p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( identifier, p ) );
 	}
 
 	@Override
 	public void evictEntity(Class entityClass, Serializable identifier) {
 		evictEntity( entityClass.getName(), identifier );
 	}
 
 	@Override
 	public void evictEntity(String entityName, Serializable identifier) {
 		EntityPersister p = sessionFactory.getEntityPersister( entityName );
 		if ( p.hasCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf(
 						"Evicting second-level cache: %s",
 						MessageHelper.infoString( p, identifier, sessionFactory )
 				);
 			}
 			p.getCacheAccessStrategy().evict( buildCacheKey( identifier, p ) );
 		}
 	}
 
 	private CacheKey buildCacheKey(Serializable identifier, EntityPersister p) {
 		return new CacheKey(
 				identifier,
 				p.getIdentifierType(),
 				p.getRootEntityName(),
 				null,                         // have to assume non tenancy
 				sessionFactory
 		);
 	}
 
 	@Override
 	public void evictEntityRegion(Class entityClass) {
 		evictEntityRegion( entityClass.getName() );
 	}
 
 	@Override
 	public void evictEntityRegion(String entityName) {
 		EntityPersister p = sessionFactory.getEntityPersister( entityName );
 		if ( p.hasCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Evicting second-level cache: %s", p.getEntityName() );
 			}
 			p.getCacheAccessStrategy().evictAll();
 		}
 	}
 
 	@Override
 	public void evictEntityRegions() {
 		for ( String s : sessionFactory.getEntityPersisters().keySet() ) {
 			evictEntityRegion( s );
 		}
 	}
 
 	@Override
 	public void evictNaturalIdRegion(Class entityClass) {
 		evictNaturalIdRegion( entityClass.getName() );
 	}
 
 	@Override
 	public void evictNaturalIdRegion(String entityName) {
 		EntityPersister p = sessionFactory.getEntityPersister( entityName );
 		if ( p.hasNaturalIdCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Evicting natural-id cache: %s", p.getEntityName() );
 			}
 			p.getNaturalIdCacheAccessStrategy().evictAll();
 		}
 	}
 
 	@Override
 	public void evictNaturalIdRegions() {
 		for ( String s : sessionFactory.getEntityPersisters().keySet() ) {
 			evictNaturalIdRegion( s );
 		}
 	}
 
 	@Override
 	public boolean containsCollection(String role, Serializable ownerIdentifier) {
 		CollectionPersister p = sessionFactory.getCollectionPersister( role );
 		return p.hasCache() &&
 				p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( ownerIdentifier, p ) );
 	}
 
 	@Override
 	public void evictCollection(String role, Serializable ownerIdentifier) {
 		CollectionPersister p = sessionFactory.getCollectionPersister( role );
 		if ( p.hasCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf(
 						"Evicting second-level cache: %s",
 						MessageHelper.collectionInfoString( p, ownerIdentifier, sessionFactory )
 				);
 			}
 			CacheKey cacheKey = buildCacheKey( ownerIdentifier, p );
 			p.getCacheAccessStrategy().evict( cacheKey );
 		}
 	}
 
 	private CacheKey buildCacheKey(Serializable ownerIdentifier, CollectionPersister p) {
 		return new CacheKey(
 				ownerIdentifier,
 				p.getKeyType(),
 				p.getRole(),
 				null,                        // have to assume non tenancy
 				sessionFactory
 		);
 	}
 
 	@Override
 	public void evictCollectionRegion(String role) {
 		CollectionPersister p = sessionFactory.getCollectionPersister( role );
 		if ( p.hasCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Evicting second-level cache: %s", p.getRole() );
 			}
 			p.getCacheAccessStrategy().evictAll();
 		}
 	}
 
 	@Override
 	public void evictCollectionRegions() {
 		for ( String s : sessionFactory.getCollectionPersisters().keySet() ) {
 			evictCollectionRegion( s );
 		}
 	}
 
 	@Override
 	public boolean containsQuery(String regionName) {
 		return queryCaches.containsKey( regionName );
 	}
 
 	@Override
 	public void evictDefaultQueryRegion() {
-		if ( sessionFactory.getSettings().isQueryCacheEnabled() ) {
-            if ( LOG.isDebugEnabled() ) {
-                LOG.debug( "Evicting default query region cache." );
-            }
+		if ( sessionFactory.getSessionFactoryOptions().isQueryCacheEnabled() ) {
+			if ( LOG.isDebugEnabled() ) {
+				LOG.debug( "Evicting default query region cache." );
+			}
 			sessionFactory.getQueryCache().clear();
 		}
 	}
 
 	@Override
 	public void evictQueryRegion(String regionName) {
 		if ( regionName == null ) {
 			throw new NullPointerException(
 					"Region-name cannot be null (use Cache#evictDefaultQueryRegion to evict the default query cache)"
 			);
 		}
-		if ( sessionFactory.getSettings().isQueryCacheEnabled() ) {
+		if ( sessionFactory.getSessionFactoryOptions().isQueryCacheEnabled() ) {
 			QueryCache namedQueryCache = queryCaches.get( regionName );
 			// TODO : cleanup entries in queryCaches + allCacheRegions ?
 			if ( namedQueryCache != null ) {
-                if ( LOG.isDebugEnabled() ) {
-                    LOG.debugf( "Evicting query cache, region: %s", regionName );
-                }
+				if ( LOG.isDebugEnabled() ) {
+					LOG.debugf( "Evicting query cache, region: %s", regionName );
+				}
 				namedQueryCache.clear();
 			}
 		}
 	}
 
 	@Override
 	public void evictQueryRegions() {
 		evictDefaultQueryRegion();
-		
+
 		if ( CollectionHelper.isEmpty( queryCaches ) ) {
 			return;
 		}
-        if ( LOG.isDebugEnabled() ) {
-            LOG.debug( "Evicting cache of all query regions." );
-        }
+		if ( LOG.isDebugEnabled() ) {
+			LOG.debug( "Evicting cache of all query regions." );
+		}
 		for ( QueryCache queryCache : queryCaches.values() ) {
 			queryCache.clear();
 		}
 	}
 
 	@Override
 	public void close() {
 		if ( settings.isQueryCacheEnabled() ) {
 			queryCache.destroy();
 
-			Iterator iter = queryCaches.values().iterator();
-			while ( iter.hasNext() ) {
-				QueryCache cache = (QueryCache) iter.next();
+			for ( QueryCache cache : queryCaches.values() ) {
 				cache.destroy();
 			}
 			updateTimestampsCache.destroy();
 		}
 
 		regionFactory.stop();
 	}
 
 	@Override
 	public QueryCache getQueryCache() {
 		return queryCache;
 	}
 
 	@Override
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		if ( regionName == null ) {
 			return getQueryCache();
 		}
 
 		if ( !settings.isQueryCacheEnabled() ) {
 			return null;
 		}
 
 		QueryCache currentQueryCache = queryCaches.get( regionName );
 		if ( currentQueryCache == null ) {
-			synchronized ( allCacheRegions ) {
+			synchronized (allCacheRegions) {
 				currentQueryCache = queryCaches.get( regionName );
 				if ( currentQueryCache == null ) {
 					currentQueryCache = settings.getQueryCacheFactory()
 							.getQueryCache(
 									regionName,
 									updateTimestampsCache,
 									settings,
 									sessionFactory.getProperties()
 							);
 					queryCaches.put( regionName, currentQueryCache );
 					allCacheRegions.put( currentQueryCache.getRegion().getName(), currentQueryCache.getRegion() );
 				}
 				else {
 					return currentQueryCache;
 				}
 			}
 		}
 		return currentQueryCache;
 	}
 
 	@Override
 	public void addCacheRegion(String name, Region region) {
 		allCacheRegions.put( name, region );
 	}
 
 	@Override
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return updateTimestampsCache;
 	}
 
 	@Override
 	public void evictQueries() throws HibernateException {
 		if ( settings.isQueryCacheEnabled() ) {
 			queryCache.clear();
 		}
 	}
 
 	@Override
 	public Region getSecondLevelCacheRegion(String regionName) {
 		return allCacheRegions.get( regionName );
 	}
 
 	@Override
 	public Region getNaturalIdCacheRegion(String regionName) {
 		return allCacheRegions.get( regionName );
 	}
 
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	@Override
 	public Map<String, Region> getAllSecondLevelCacheRegions() {
-		return new HashMap<String,Region>( allCacheRegions );
+		return new HashMap<String, Region>( allCacheRegions );
 	}
 
 	@Override
 	public RegionFactory getRegionFactory() {
 		return regionFactory;
 	}
-	
+
 	@Override
 	public void evictAllRegions() {
 		evictCollectionRegions();
 		evictDefaultQueryRegion();
 		evictEntityRegions();
 		evictQueryRegions();
 		evictNaturalIdRegions();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/CollectionFilterImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/CollectionFilterImpl.java
index e035662414..ad9f38ef0e 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/CollectionFilterImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/CollectionFilterImpl.java
@@ -1,107 +1,108 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.internal;
+
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.type.Type;
 
 /**
  * implementation of the <tt>Query</tt> interface for collection filters
+ *
  * @author Gavin King
  */
 public class CollectionFilterImpl extends QueryImpl {
 
 	private Object collection;
 
 	public CollectionFilterImpl(
 			String queryString,
-	        Object collection,
-	        SessionImplementor session,
-	        ParameterMetadata parameterMetadata) {
+			Object collection,
+			SessionImplementor session,
+			ParameterMetadata parameterMetadata) {
 		super( queryString, session, parameterMetadata );
 		this.collection = collection;
 	}
 
 
 	/**
 	 * @see org.hibernate.Query#iterate()
 	 */
 	public Iterator iterate() throws HibernateException {
 		verifyParameters();
 		Map namedParams = getNamedParams();
-		return getSession().iterateFilter( 
-				collection, 
-				expandParameterLists(namedParams),
-				getQueryParameters(namedParams) 
+		return getSession().iterateFilter(
+				collection,
+				expandParameterLists( namedParams ),
+				getQueryParameters( namedParams )
 		);
 	}
 
 	/**
 	 * @see org.hibernate.Query#list()
 	 */
 	public List list() throws HibernateException {
 		verifyParameters();
 		Map namedParams = getNamedParams();
-		return getSession().listFilter( 
-				collection, 
-				expandParameterLists(namedParams),
-				getQueryParameters(namedParams) 
+		return getSession().listFilter(
+				collection,
+				expandParameterLists( namedParams ),
+				getQueryParameters( namedParams )
 		);
 	}
 
 	/**
 	 * @see org.hibernate.Query#scroll()
 	 */
 	public ScrollableResults scroll() throws HibernateException {
-		throw new UnsupportedOperationException("Can't scroll filters");
+		throw new UnsupportedOperationException( "Can't scroll filters" );
 	}
 
 	public Type[] typeArray() {
 		List typeList = getTypes();
 		int size = typeList.size();
-		Type[] result = new Type[size+1];
-		for (int i=0; i<size; i++) {
-			result[i+1] = (Type) typeList.get(i);
+		Type[] result = new Type[size + 1];
+		for ( int i = 0; i < size; i++ ) {
+			result[i + 1] = (Type) typeList.get( i );
 		}
 		return result;
 	}
 
 	public Object[] valueArray() {
 		List valueList = getValues();
 		int size = valueList.size();
-		Object[] result = new Object[size+1];
-		for (int i=0; i<size; i++) {
-			result[i+1] = valueList.get(i);
+		Object[] result = new Object[size + 1];
+		for ( int i = 0; i < size; i++ ) {
+			result[i + 1] = valueList.get( i );
 		}
 		return result;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/CoreMessageLogger.java b/hibernate-core/src/main/java/org/hibernate/internal/CoreMessageLogger.java
index 5d0daef85e..42022c2422 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/CoreMessageLogger.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/CoreMessageLogger.java
@@ -1,1705 +1,1754 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.File;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.lang.reflect.Method;
 import java.net.URL;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
 import java.util.Hashtable;
 import java.util.Properties;
 import java.util.Set;
 import javax.naming.NameNotFoundException;
 import javax.naming.NamingException;
 import javax.transaction.Synchronization;
 import javax.transaction.SystemException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.cache.CacheException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.dialect.spi.DialectResolver;
 import org.hibernate.engine.jndi.JndiException;
 import org.hibernate.engine.jndi.JndiNameException;
 import org.hibernate.engine.loading.internal.CollectionLoadContext;
 import org.hibernate.engine.loading.internal.EntityLoadContext;
 import org.hibernate.engine.spi.CollectionKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.id.IntegralDataTypeHolder;
 import org.hibernate.type.BasicType;
 import org.hibernate.type.SerializationException;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.BasicLogger;
 import org.jboss.logging.annotations.Cause;
 import org.jboss.logging.annotations.LogMessage;
 import org.jboss.logging.annotations.Message;
 import org.jboss.logging.annotations.MessageLogger;
 
 import static org.jboss.logging.Logger.Level.DEBUG;
 import static org.jboss.logging.Logger.Level.ERROR;
 import static org.jboss.logging.Logger.Level.INFO;
 import static org.jboss.logging.Logger.Level.WARN;
 
 /**
  * The jboss-logging {@link MessageLogger} for the hibernate-core module.  It reserves message ids ranging from
  * 00001 to 10000 inclusively.
  * <p/>
  * New messages must be added after the last message defined to ensure message codes are unique.
  */
 @MessageLogger(projectCode = "HHH")
 public interface CoreMessageLogger extends BasicLogger {
 
 	@LogMessage(level = WARN)
 	@Message(value = "Already session bound on call to bind(); make sure you clean up your sessions!", id = 2)
 	void alreadySessionBound();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Autocommit mode: %s", id = 6)
 	void autoCommitMode(boolean autocommit);
 
 	@LogMessage(level = WARN)
 	@Message(value = "JTASessionContext being used with JDBCTransactionFactory; auto-flush will not operate correctly with getCurrentSession()",
 			id = 8)
 	void autoFlushWillNotWork();
 
 	@LogMessage(level = INFO)
 	@Message(value = "On release of batch it still contained JDBC statements", id = 10)
 	void batchContainedStatementsOnRelease();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Bytecode provider name : %s", id = 21)
 	void bytecodeProvider(String provider);
 
 	@LogMessage(level = WARN)
 	@Message(value = "c3p0 properties were encountered, but the %s provider class was not found on the classpath; these properties are going to be ignored.",
 			id = 22)
 	void c3p0ProviderClassNotFound(String c3p0ProviderClassName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "I/O reported cached file could not be found : %s : %s", id = 23)
-	void cachedFileNotFound(String path,
-							FileNotFoundException error);
+	void cachedFileNotFound(String path, FileNotFoundException error);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Cache provider: %s", id = 24)
 	void cacheProvider(String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Calling joinTransaction() on a non JTA EntityManager", id = 27)
 	void callingJoinTransactionOnNonJtaEntityManager();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Cleaning up connection pool [%s]", id = 30)
 	void cleaningUpConnectionPool(String url);
 
 	@LogMessage(level = DEBUG)
 	@Message(value = "Closing", id = 31)
 	void closing();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Collections fetched (minimize this): %s", id = 32)
 	void collectionsFetched(long collectionFetchCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Collections loaded: %s", id = 33)
 	void collectionsLoaded(long collectionLoadCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Collections recreated: %s", id = 34)
 	void collectionsRecreated(long collectionRecreateCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Collections removed: %s", id = 35)
 	void collectionsRemoved(long collectionRemoveCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Collections updated: %s", id = 36)
 	void collectionsUpdated(long collectionUpdateCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Columns: %s", id = 37)
 	void columns(Set keySet);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Composite-id class does not override equals(): %s", id = 38)
 	void compositeIdClassDoesNotOverrideEquals(String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Composite-id class does not override hashCode(): %s", id = 39)
 	void compositeIdClassDoesNotOverrideHashCode(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Configuration resource: %s", id = 40)
 	void configurationResource(String resource);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Configured SessionFactory: %s", id = 41)
 	void configuredSessionFactory(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Configuring from file: %s", id = 42)
 	void configuringFromFile(String file);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Configuring from resource: %s", id = 43)
 	void configuringFromResource(String resource);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Configuring from URL: %s", id = 44)
 	void configuringFromUrl(URL url);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Configuring from XML document", id = 45)
 	void configuringFromXmlDocument();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Connection properties: %s", id = 46)
 	void connectionProperties(Properties connectionProps);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Connections obtained: %s", id = 48)
 	void connectionsObtained(long connectCount);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Container is providing a null PersistenceUnitRootUrl: discovery impossible", id = 50)
 	void containerProvidingNullPersistenceUnitRootUrl();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Ignoring bag join fetch [%s] due to prior collection join fetch", id = 51)
 	void containsJoinFetchedCollection(String role);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Creating subcontext: %s", id = 53)
 	void creatingSubcontextInfo(String intermediateContextName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Defining %s=true ignored in HEM", id = 59)
 	void definingFlushBeforeCompletionIgnoredInHem(String flushBeforeCompletion);
 
 	@LogMessage(level = WARN)
 	@Message(value = "@ForceDiscriminator is deprecated use @DiscriminatorOptions instead.", id = 62)
 	void deprecatedForceDescriminatorAnnotation();
 
 	@LogMessage(level = WARN)
 	@Message(value = "The Oracle9Dialect dialect has been deprecated; use either Oracle9iDialect or Oracle10gDialect instead",
 			id = 63)
 	void deprecatedOracle9Dialect();
 
 	@LogMessage(level = WARN)
 	@Message(value = "The OracleDialect dialect has been deprecated; use Oracle8iDialect instead", id = 64)
 	void deprecatedOracleDialect();
 
 	@LogMessage(level = WARN)
 	@Message(value = "DEPRECATED : use [%s] instead with custom [%s] implementation", id = 65)
-	void deprecatedUuidGenerator(String name,
-								 String name2);
+	void deprecatedUuidGenerator(String name, String name2);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Disallowing insert statement comment for select-identity due to Oracle driver bug", id = 67)
 	void disallowingInsertStatementComment();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Duplicate generator name %s", id = 69)
 	void duplicateGeneratorName(String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Duplicate generator table: %s", id = 70)
 	void duplicateGeneratorTable(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Duplicate import: %s -> %s", id = 71)
-	void duplicateImport(String entityName,
-						 String rename);
+	void duplicateImport(String entityName, String rename);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Duplicate joins for class: %s", id = 72)
 	void duplicateJoins(String entityName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "entity-listener duplication, first event definition will be used: %s", id = 73)
 	void duplicateListener(String className);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Found more than one <persistence-unit-metadata>, subsequent ignored", id = 74)
 	void duplicateMetadata();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Entities deleted: %s", id = 76)
 	void entitiesDeleted(long entityDeleteCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Entities fetched (minimize this): %s", id = 77)
 	void entitiesFetched(long entityFetchCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Entities inserted: %s", id = 78)
 	void entitiesInserted(long entityInsertCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Entities loaded: %s", id = 79)
 	void entitiesLoaded(long entityLoadCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Entities updated: %s", id = 80)
 	void entitiesUpdated(long entityUpdateCount);
 
 	@LogMessage(level = WARN)
 	@Message(value = "@org.hibernate.annotations.Entity used on a non root entity: ignored for %s", id = 81)
 	void entityAnnotationOnNonRoot(String className);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Entity Manager closed by someone else (%s must not be used)", id = 82)
 	void entityManagerClosedBySomeoneElse(String autoCloseSession);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Entity [%s] is abstract-class/interface explicitly mapped as non-abstract; be sure to supply entity-names",
 			id = 84)
 	void entityMappedAsNonAbstract(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "%s %s found", id = 85)
-	void exceptionHeaderFound(String exceptionHeader,
-							  String metaInfOrmXml);
+	void exceptionHeaderFound(String exceptionHeader, String metaInfOrmXml);
 
 	@LogMessage(level = INFO)
 	@Message(value = "%s No %s found", id = 86)
-	void exceptionHeaderNotFound(String exceptionHeader,
-								 String metaInfOrmXml);
+	void exceptionHeaderNotFound(String exceptionHeader, String metaInfOrmXml);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Exception in interceptor afterTransactionCompletion()", id = 87)
 	void exceptionInAfterTransactionCompletionInterceptor(@Cause Throwable e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Exception in interceptor beforeTransactionCompletion()", id = 88)
 	void exceptionInBeforeTransactionCompletionInterceptor(@Cause Throwable e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Sub-resolver threw unexpected exception, continuing to next : %s", id = 89)
 	void exceptionInSubResolver(String message);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Expected type: %s, actual value: %s", id = 91)
 	void expectedType(String name,
-					  String string);
+			String string);
 
 	@LogMessage(level = WARN)
 	@Message(value = "An item was expired by the cache while it was locked (increase your cache timeout): %s", id = 92)
 	void expired(Object key);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Bound factory to JNDI name: %s", id = 94)
 	void factoryBoundToJndiName(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "A factory was renamed from [%s] to [%s] in JNDI", id = 96)
 	void factoryJndiRename(String oldName, String newName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unbound factory from JNDI name: %s", id = 97)
 	void factoryUnboundFromJndiName(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "A factory was unbound from name: %s", id = 98)
 	void factoryUnboundFromName(String name);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "an assertion failure occured" + " (this may indicate a bug in Hibernate, but is more likely due"
 			+ " to unsafe use of the session): %s", id = 99)
 	void failed(Throwable throwable);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Fail-safe cleanup (collections) : %s", id = 100)
 	void failSafeCollectionsCleanup(CollectionLoadContext collectionLoadContext);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Fail-safe cleanup (entities) : %s", id = 101)
 	void failSafeEntitiesCleanup(EntityLoadContext entityLoadContext);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Fetching database metadata", id = 102)
 	void fetchingDatabaseMetadata();
 
 	@LogMessage(level = WARN)
 	@Message(value = "firstResult/maxResults specified with collection fetch; applying in memory!", id = 104)
 	void firstOrMaxResultsSpecifiedWithCollectionFetch();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Flushes: %s", id = 105)
 	void flushes(long flushCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Forcing container resource cleanup on transaction completion", id = 106)
 	void forcingContainerResourceCleanup();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Forcing table use for sequence-style generator due to pooled optimizer selection where db does not support pooled sequences",
 			id = 107)
 	void forcingTableUse();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Foreign keys: %s", id = 108)
 	void foreignKeys(Set keySet);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Found mapping document in jar: %s", id = 109)
 	void foundMappingDocument(String name);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Getters of lazy classes cannot be final: %s.%s", id = 112)
-	void gettersOfLazyClassesCannotBeFinal(String entityName,
-										   String name);
+	void gettersOfLazyClassesCannotBeFinal(
+			String entityName,
+			String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "GUID identifier generated: %s", id = 113)
 	void guidGenerated(String result);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Handling transient entity in delete processing", id = 114)
 	void handlingTransientEntity();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Hibernate connection pool size: %s (min=%s)", id = 115)
 	void hibernateConnectionPoolSize(int poolSize, int minSize);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Config specified explicit optimizer of [%s], but [%s=%s; honoring optimizer setting", id = 116)
-	void honoringOptimizerSetting(String none,
-								  String incrementParam,
-								  int incrementSize);
+	void honoringOptimizerSetting(
+			String none,
+			String incrementParam,
+			int incrementSize);
 
 	@LogMessage(level = DEBUG)
 	@Message(value = "HQL: %s, time: %sms, rows: %s", id = 117)
-	void hql(String hql,
-			 Long valueOf,
-			 Long valueOf2);
+	void hql(
+			String hql,
+			Long valueOf,
+			Long valueOf2);
 
 	@LogMessage(level = WARN)
 	@Message(value = "HSQLDB supports only READ_UNCOMMITTED isolation", id = 118)
 	void hsqldbSupportsOnlyReadCommittedIsolation();
 
 	@LogMessage(level = WARN)
 	@Message(value = "On EntityLoadContext#clear, hydratingEntities contained [%s] entries", id = 119)
 	void hydratingEntitiesCount(int size);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Ignoring unique constraints specified on table generator [%s]", id = 120)
 	void ignoringTableGeneratorConstraints(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Ignoring unrecognized query hint [%s]", id = 121)
 	void ignoringUnrecognizedQueryHint(String hintName);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "IllegalArgumentException in class: %s, getter method of property: %s", id = 122)
-	void illegalPropertyGetterArgument(String name,
-									   String propertyName);
+	void illegalPropertyGetterArgument(
+			String name,
+			String propertyName);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "IllegalArgumentException in class: %s, setter method of property: %s", id = 123)
-	void illegalPropertySetterArgument(String name,
-									   String propertyName);
+	void illegalPropertySetterArgument(
+			String name,
+			String propertyName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "@Immutable used on a non root entity: ignored for %s", id = 124)
 	void immutableAnnotationOnNonRoot(String className);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Mapping metadata cache was not completely processed", id = 125)
 	void incompleteMappingMetadataCacheProcessing();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Indexes: %s", id = 126)
 	void indexes(Set keySet);
 
 	@LogMessage(level = DEBUG)
 	@Message(value = "Could not bind JNDI listener", id = 127)
 	void couldNotBindJndiListener();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Instantiating explicit connection provider: %s", id = 130)
 	void instantiatingExplicitConnectionProvider(String providerClassName);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Array element type error\n%s", id = 132)
 	void invalidArrayElementType(String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Discriminator column has to be defined in the root entity, it will be ignored in subclass: %s",
 			id = 133)
 	void invalidDiscriminatorAnnotation(String className);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Application attempted to edit read only item: %s", id = 134)
 	void invalidEditOfReadOnlyItem(Object key);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Invalid JNDI name: %s", id = 135)
-	void invalidJndiName(String name,
-						 @Cause JndiNameException e);
+	void invalidJndiName(
+			String name,
+			@Cause JndiNameException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Inapropriate use of @OnDelete on entity, annotation ignored: %s", id = 136)
 	void invalidOnDeleteAnnotation(String entityName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Root entity should not hold an PrimaryKeyJoinColum(s), will be ignored", id = 137)
 	void invalidPrimaryKeyJoinColumnAnnotation();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Mixing inheritance strategy in a entity hierarchy is not allowed, ignoring sub strategy in: %s",
 			id = 138)
 	void invalidSubStrategy(String className);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Illegal use of @Table in a subclass of a SINGLE_TABLE hierarchy: %s", id = 139)
 	void invalidTableAnnotation(String className);
 
 	@LogMessage(level = INFO)
 	@Message(value = "JACC contextID: %s", id = 140)
 	void jaccContextId(String contextId);
 
 	@LogMessage(level = INFO)
 	@Message(value = "java.sql.Types mapped the same code [%s] multiple times; was [%s]; now [%s]", id = 141)
-	void JavaSqlTypesMappedSameCodeMultipleTimes(int code,
-												 String old,
-												 String name);
+	void JavaSqlTypesMappedSameCodeMultipleTimes(
+			int code,
+			String old,
+			String name);
 
 	@Message(value = "Javassist Enhancement failed: %s", id = 142)
 	String javassistEnhancementFailed(String entityName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "%s = false breaks the EJB3 specification", id = 144)
 	void jdbcAutoCommitFalseBreaksEjb3Spec(String autocommit);
 
 	@LogMessage(level = WARN)
 	@Message(value = "No JDBC Driver class was specified by property %s", id = 148)
 	void jdbcDriverNotSpecified(String driver);
 
 	@LogMessage(level = INFO)
 	@Message(value = "JDBC isolation level: %s", id = 149)
 	void jdbcIsolationLevel(String isolationLevelToString);
 
 	@Message(value = "JDBC rollback failed", id = 151)
 	String jdbcRollbackFailed();
 
 	@Message(value = "JDBC URL was not specified by property %s", id = 152)
 	String jdbcUrlNotSpecified(String url);
 
 	@LogMessage(level = INFO)
 	@Message(value = "JNDI InitialContext properties:%s", id = 154)
 	void jndiInitialContextProperties(Hashtable hash);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "JNDI name %s does not handle a session factory reference", id = 155)
-	void jndiNameDoesNotHandleSessionFactoryReference(String sfJNDIName,
-													  @Cause ClassCastException e);
+	void jndiNameDoesNotHandleSessionFactoryReference(
+			String sfJNDIName,
+			@Cause ClassCastException e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Lazy property fetching available for: %s", id = 157)
 	void lazyPropertyFetchingAvailable(String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "In CollectionLoadContext#endLoadingCollections, localLoadingCollectionKeys contained [%s], but no LoadingCollectionEntry was found in loadContexts",
 			id = 159)
 	void loadingCollectionKeyNotFound(CollectionKey collectionKey);
 
 	@LogMessage(level = WARN)
 	@Message(value = "On CollectionLoadContext#cleanup, localLoadingCollectionKeys contained [%s] entries", id = 160)
 	void localLoadingCollectionKeysCount(int size);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Logging statistics....", id = 161)
 	void loggingStatistics();
 
 	@LogMessage(level = DEBUG)
 	@Message(value = "*** Logical connection closed ***", id = 162)
 	void logicalConnectionClosed();
 
 	@LogMessage(level = DEBUG)
 	@Message(value = "Logical connection releasing its physical connection", id = 163)
 	void logicalConnectionReleasingPhysicalConnection();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Max query time: %sms", id = 173)
 	void maxQueryTime(long queryExecutionMaxTime);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Function template anticipated %s arguments, but %s arguments encountered", id = 174)
-	void missingArguments(int anticipatedNumberOfArguments,
-						  int numberOfArguments);
+	void missingArguments(
+			int anticipatedNumberOfArguments,
+			int numberOfArguments);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Class annotated @org.hibernate.annotations.Entity but not javax.persistence.Entity (most likely a user error): %s",
 			id = 175)
 	void missingEntityAnnotation(String className);
 
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error in named query: %s", id = 177)
-	void namedQueryError(String queryName,
-						 @Cause HibernateException e);
+	void namedQueryError(
+			String queryName,
+			@Cause HibernateException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Naming exception occurred accessing factory: %s", id = 178)
 	void namingExceptionAccessingFactory(NamingException exception);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Narrowing proxy to %s - this operation breaks ==", id = 179)
 	void narrowingProxy(Class concreteProxyClass);
 
 	@LogMessage(level = WARN)
 	@Message(value = "FirstResult/maxResults specified on polymorphic query; applying in memory!", id = 180)
 	void needsLimit();
 
 	@LogMessage(level = WARN)
 	@Message(value = "No appropriate connection provider encountered, assuming application will be supplying connections",
 			id = 181)
 	void noAppropriateConnectionProvider();
 
 	@LogMessage(level = INFO)
 	@Message(value = "No default (no-argument) constructor for class: %s (class must be instantiated by Interceptor)",
 			id = 182)
 	void noDefaultConstructor(String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "no persistent classes found for query class: %s", id = 183)
 	void noPersistentClassesFound(String query);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "No session factory with JNDI name %s", id = 184)
-	void noSessionFactoryWithJndiName(String sfJNDIName,
-									  @Cause NameNotFoundException e);
+	void noSessionFactoryWithJndiName(
+			String sfJNDIName,
+			@Cause NameNotFoundException e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Optimistic lock failures: %s", id = 187)
 	void optimisticLockFailures(long optimisticFailureCount);
 
 	@LogMessage(level = WARN)
 	@Message(value = "@OrderBy not allowed for an indexed collection, annotation ignored.", id = 189)
 	void orderByAnnotationIndexedCollection();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Overriding %s is dangerous, this might break the EJB3 specification implementation", id = 193)
 	void overridingTransactionStrategyDangerous(String transactionStrategy);
 
 	@LogMessage(level = DEBUG)
 	@Message(value = "Package not found or wo package-info.java: %s", id = 194)
 	void packageNotFound(String packageName);
 
 //	@LogMessage(level = WARN)
 //	@Message(value = "Parameter position [%s] occurred as both JPA and Hibernate positional parameter", id = 195)
 //	void parameterPositionOccurredAsBothJpaAndHibernatePositionalParameter(Integer position);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error parsing XML (%s) : %s", id = 196)
-	void parsingXmlError(int lineNumber,
-						 String message);
+	void parsingXmlError(
+			int lineNumber,
+			String message);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error parsing XML: %s(%s) %s", id = 197)
-	void parsingXmlErrorForFile(String file,
-								int lineNumber,
-								String message);
+	void parsingXmlErrorForFile(
+			String file,
+			int lineNumber,
+			String message);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Warning parsing XML (%s) : %s", id = 198)
-	void parsingXmlWarning(int lineNumber,
-						   String message);
+	void parsingXmlWarning(
+			int lineNumber,
+			String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Warning parsing XML: %s(%s) %s", id = 199)
-	void parsingXmlWarningForFile(String file,
-								  int lineNumber,
-								  String message);
+	void parsingXmlWarningForFile(
+			String file,
+			int lineNumber,
+			String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Persistence provider caller does not implement the EJB3 spec correctly."
 			+ "PersistenceUnitInfo.getNewTempClassLoader() is null.", id = 200)
 	void persistenceProviderCallerDoesNotImplementEjb3SpecCorrectly();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Pooled optimizer source reported [%s] as the initial value; use of 1 or greater highly recommended",
 			id = 201)
 	void pooledOptimizerReportedInitialValue(IntegralDataTypeHolder value);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "PreparedStatement was already in the batch, [%s].", id = 202)
 	void preparedStatementAlreadyInBatch(String sql);
 
 	@LogMessage(level = WARN)
 	@Message(value = "processEqualityExpression() : No expression to process!", id = 203)
 	void processEqualityExpression();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Processing PersistenceUnitInfo [\n\tname: %s\n\t...]", id = 204)
 	void processingPersistenceUnitInfoName(String persistenceUnitName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Loaded properties from resource hibernate.properties: %s", id = 205)
 	void propertiesLoaded(Properties maskOut);
 
 	@LogMessage(level = INFO)
 	@Message(value = "hibernate.properties not found", id = 206)
 	void propertiesNotFound();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Property %s not found in class but described in <mapping-file/> (possible typo error)", id = 207)
 	void propertyNotFound(String property);
 
 	@LogMessage(level = WARN)
 	@Message(value = "%s has been deprecated in favor of %s; that provider will be used instead.", id = 208)
-	void providerClassDeprecated(String providerClassName,
-								 String actualProviderClassName);
+	void providerClassDeprecated(
+			String providerClassName,
+			String actualProviderClassName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "proxool properties were encountered, but the %s provider class was not found on the classpath; these properties are going to be ignored.",
 			id = 209)
 	void proxoolProviderClassNotFound(String proxoolProviderClassName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Queries executed to database: %s", id = 210)
 	void queriesExecuted(long queryExecutionCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Query cache hits: %s", id = 213)
 	void queryCacheHits(long queryCacheHitCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Query cache misses: %s", id = 214)
 	void queryCacheMisses(long queryCacheMissCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Query cache puts: %s", id = 215)
 	void queryCachePuts(long queryCachePutCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "RDMSOS2200Dialect version: 1.0", id = 218)
 	void rdmsOs2200Dialect();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Reading mappings from cache file: %s", id = 219)
 	void readingCachedMappings(File cachedFile);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Reading mappings from file: %s", id = 220)
 	void readingMappingsFromFile(String path);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Reading mappings from resource: %s", id = 221)
 	void readingMappingsFromResource(String resourceName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "read-only cache configured for mutable collection [%s]", id = 222)
 	void readOnlyCacheConfiguredForMutableCollection(String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Recognized obsolete hibernate namespace %s. Use namespace %s instead. Refer to Hibernate 3.6 Migration Guide!",
 			id = 223)
-	void recognizedObsoleteHibernateNamespace(String oldHibernateNamespace,
-											  String hibernateNamespace);
+	void recognizedObsoleteHibernateNamespace(
+			String oldHibernateNamespace,
+			String hibernateNamespace);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Property [%s] has been renamed to [%s]; update your properties appropriately", id = 225)
-	void renamedProperty(Object propertyName,
-						 Object newPropertyName);
+	void renamedProperty(
+			Object propertyName,
+			Object newPropertyName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Required a different provider: %s", id = 226)
 	void requiredDifferentProvider(String provider);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Running hbm2ddl schema export", id = 227)
 	void runningHbm2ddlSchemaExport();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Running hbm2ddl schema update", id = 228)
 	void runningHbm2ddlSchemaUpdate();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Running schema validator", id = 229)
 	void runningSchemaValidator();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Schema export complete", id = 230)
 	void schemaExportComplete();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Schema export unsuccessful", id = 231)
 	void schemaExportUnsuccessful(@Cause Exception e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Schema update complete", id = 232)
 	void schemaUpdateComplete();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Scoping types to session factory %s after already scoped %s", id = 233)
-	void scopingTypesToSessionFactoryAfterAlreadyScoped(SessionFactoryImplementor factory,
-														SessionFactoryImplementor factory2);
+	void scopingTypesToSessionFactoryAfterAlreadyScoped(
+			SessionFactoryImplementor factory,
+			SessionFactoryImplementor factory2);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Searching for mapping documents in jar: %s", id = 235)
 	void searchingForMappingDocuments(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Second level cache hits: %s", id = 237)
 	void secondLevelCacheHits(long secondLevelCacheHitCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Second level cache misses: %s", id = 238)
 	void secondLevelCacheMisses(long secondLevelCacheMissCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Second level cache puts: %s", id = 239)
 	void secondLevelCachePuts(long secondLevelCachePutCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Service properties: %s", id = 240)
 	void serviceProperties(Properties properties);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Sessions closed: %s", id = 241)
 	void sessionsClosed(long sessionCloseCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Sessions opened: %s", id = 242)
 	void sessionsOpened(long sessionOpenCount);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Setters of lazy classes cannot be final: %s.%s", id = 243)
-	void settersOfLazyClassesCannotBeFinal(String entityName,
-										   String name);
+	void settersOfLazyClassesCannotBeFinal(
+			String entityName,
+			String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "@Sort not allowed for an indexed collection, annotation ignored.", id = 244)
 	void sortAnnotationIndexedCollection();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Manipulation query [%s] resulted in [%s] split queries", id = 245)
-	void splitQueries(String sourceQuery,
-					  int length);
+	void splitQueries(
+			String sourceQuery,
+			int length);
 
 //	@LogMessage(level = ERROR)
 //	@Message(value = "SQLException escaped proxy", id = 246)
 //	void sqlExceptionEscapedProxy(@Cause SQLException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "SQL Error: %s, SQLState: %s", id = 247)
-	void sqlWarning(int errorCode,
-					String sqlState);
+	void sqlWarning(
+			int errorCode,
+			String sqlState);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Starting query cache at region: %s", id = 248)
 	void startingQueryCache(String region);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Starting service at JNDI name: %s", id = 249)
 	void startingServiceAtJndiName(String boundName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Starting update timestamps cache at region: %s", id = 250)
 	void startingUpdateTimestampsCache(String region);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Start time: %s", id = 251)
 	void startTime(long startTime);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Statements closed: %s", id = 252)
 	void statementsClosed(long closeStatementCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Statements prepared: %s", id = 253)
 	void statementsPrepared(long prepareStatementCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Stopping service", id = 255)
 	void stoppingService();
 
 	@LogMessage(level = INFO)
 	@Message(value = "sub-resolver threw unexpected exception, continuing to next : %s", id = 257)
 	void subResolverException(String message);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Successful transactions: %s", id = 258)
 	void successfulTransactions(long committedTransactionCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Synchronization [%s] was already registered", id = 259)
 	void synchronizationAlreadyRegistered(Synchronization synchronization);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Exception calling user Synchronization [%s] : %s", id = 260)
-	void synchronizationFailed(Synchronization synchronization,
-							   Throwable t);
+	void synchronizationFailed(
+			Synchronization synchronization,
+			Throwable t);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Table found: %s", id = 261)
 	void tableFound(String string);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Table not found: %s", id = 262)
 	void tableNotFound(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "More than one table found: %s", id = 263)
 	void multipleTablesFound(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Transactions: %s", id = 266)
 	void transactions(long transactionCount);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Transaction started on non-root session", id = 267)
 	void transactionStartedOnNonRootSession();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Transaction strategy: %s", id = 268)
 	void transactionStrategy(String strategyClassName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Type [%s] defined no registration keys; ignoring", id = 269)
 	void typeDefinedNoRegistrationKeys(BasicType type);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Type registration [%s] overrides previous : %s", id = 270)
-	void typeRegistrationOverridesPrevious(String key,
-										   Type old);
+	void typeRegistrationOverridesPrevious(
+			String key,
+			Type old);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Naming exception occurred accessing Ejb3Configuration", id = 271)
 	void unableToAccessEjb3Configuration(@Cause NamingException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error while accessing session factory with JNDI name %s", id = 272)
-	void unableToAccessSessionFactory(String sfJNDIName,
-									  @Cause NamingException e);
+	void unableToAccessSessionFactory(
+			String sfJNDIName,
+			@Cause NamingException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Error accessing type info result set : %s", id = 273)
 	void unableToAccessTypeInfoResultSet(String string);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to apply constraints on DDL for %s", id = 274)
-	void unableToApplyConstraints(String className,
-								  @Cause Exception e);
+	void unableToApplyConstraints(
+			String className,
+			@Cause Exception e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not bind Ejb3Configuration to JNDI", id = 276)
 	void unableToBindEjb3ConfigurationToJndi(@Cause JndiException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not bind factory to JNDI", id = 277)
 	void unableToBindFactoryToJndi(@Cause JndiException e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Could not bind value '%s' to parameter: %s; %s", id = 278)
-	void unableToBindValueToParameter(String nullSafeToString,
-									  int index,
-									  String message);
+	void unableToBindValueToParameter(
+			String nullSafeToString,
+			int index,
+			String message);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unable to build enhancement metamodel for %s", id = 279)
 	void unableToBuildEnhancementMetamodel(String className);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Could not build SessionFactory using the MBean classpath - will try again using client classpath: %s",
 			id = 280)
 	void unableToBuildSessionFactoryUsingMBeanClasspath(String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to clean up callable statement", id = 281)
 	void unableToCleanUpCallableStatement(@Cause SQLException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to clean up prepared statement", id = 282)
 	void unableToCleanUpPreparedStatement(@Cause SQLException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to cleanup temporary id table after use [%s]", id = 283)
 	void unableToCleanupTemporaryIdTable(Throwable t);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error closing connection", id = 284)
 	void unableToCloseConnection(@Cause Exception e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Error closing InitialContext [%s]", id = 285)
 	void unableToCloseInitialContext(String string);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error closing input files: %s", id = 286)
-	void unableToCloseInputFiles(String name,
-								 @Cause IOException e);
+	void unableToCloseInputFiles(
+			String name,
+			@Cause IOException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not close input stream", id = 287)
 	void unableToCloseInputStream(@Cause IOException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not close input stream for %s", id = 288)
-	void unableToCloseInputStreamForResource(String resourceName,
-											 @Cause IOException e);
+	void unableToCloseInputStreamForResource(
+			String resourceName,
+			@Cause IOException e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unable to close iterator", id = 289)
 	void unableToCloseIterator(@Cause SQLException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not close jar: %s", id = 290)
 	void unableToCloseJar(String message);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error closing output file: %s", id = 291)
-	void unableToCloseOutputFile(String outputFile,
-								 @Cause IOException e);
+	void unableToCloseOutputFile(
+			String outputFile,
+			@Cause IOException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "IOException occurred closing output stream", id = 292)
 	void unableToCloseOutputStream(@Cause IOException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Problem closing pooled connection", id = 293)
 	void unableToClosePooledConnection(@Cause SQLException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not close session", id = 294)
 	void unableToCloseSession(@Cause HibernateException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not close session during rollback", id = 295)
 	void unableToCloseSessionDuringRollback(@Cause Exception e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "IOException occurred closing stream", id = 296)
 	void unableToCloseStream(@Cause IOException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not close stream on hibernate.properties: %s", id = 297)
 	void unableToCloseStreamError(IOException error);
 
 	@Message(value = "JTA commit failed", id = 298)
 	String unableToCommitJta();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not complete schema update", id = 299)
 	void unableToCompleteSchemaUpdate(@Cause Exception e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not complete schema validation", id = 300)
 	void unableToCompleteSchemaValidation(@Cause SQLException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to configure SQLExceptionConverter : %s", id = 301)
 	void unableToConfigureSqlExceptionConverter(HibernateException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unable to construct current session context [%s]", id = 302)
-	void unableToConstructCurrentSessionContext(String impl,
-												@Cause Throwable e);
+	void unableToConstructCurrentSessionContext(
+			String impl,
+			@Cause Throwable e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to construct instance of specified SQLExceptionConverter : %s", id = 303)
 	void unableToConstructSqlExceptionConverter(Throwable t);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not copy system properties, system properties will be ignored", id = 304)
 	void unableToCopySystemProperties();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not create proxy factory for:%s", id = 305)
-	void unableToCreateProxyFactory(String entityName,
-									@Cause HibernateException e);
+	void unableToCreateProxyFactory(
+			String entityName,
+			@Cause HibernateException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error creating schema ", id = 306)
 	void unableToCreateSchema(@Cause Exception e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not deserialize cache file: %s : %s", id = 307)
-	void unableToDeserializeCache(String path,
-								  SerializationException error);
+	void unableToDeserializeCache(
+			String path,
+			SerializationException error);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to destroy cache: %s", id = 308)
 	void unableToDestroyCache(String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to destroy query cache: %s: %s", id = 309)
-	void unableToDestroyQueryCache(String region,
-								   String message);
+	void unableToDestroyQueryCache(
+			String region,
+			String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to destroy update timestamps cache: %s: %s", id = 310)
-	void unableToDestroyUpdateTimestampsCache(String region,
-											  String message);
+	void unableToDestroyUpdateTimestampsCache(
+			String region,
+			String message);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unable to determine lock mode value : %s -> %s", id = 311)
-	void unableToDetermineLockModeValue(String hintName,
-										Object value);
+	void unableToDetermineLockModeValue(
+			String hintName,
+			Object value);
 
 	@Message(value = "Could not determine transaction status", id = 312)
 	String unableToDetermineTransactionStatus();
 
 	@Message(value = "Could not determine transaction status after commit", id = 313)
 	String unableToDetermineTransactionStatusAfterCommit();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to drop temporary id table after use [%s]", id = 314)
 	void unableToDropTemporaryIdTable(String message);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Exception executing batch [%s]", id = 315)
 	void unableToExecuteBatch(String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Error executing resolver [%s] : %s", id = 316)
-	void unableToExecuteResolver(DialectResolver abstractDialectResolver,
-								 String message);
+	void unableToExecuteResolver(
+			DialectResolver abstractDialectResolver,
+			String message);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Could not find any META-INF/persistence.xml file in the classpath", id = 318)
 	void unableToFindPersistenceXmlInClasspath();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not get database metadata", id = 319)
 	void unableToGetDatabaseMetadata(@Cause SQLException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to instantiate configured schema name resolver [%s] %s", id = 320)
-	void unableToInstantiateConfiguredSchemaNameResolver(String resolverClassName,
-														 String message);
+	void unableToInstantiateConfiguredSchemaNameResolver(
+			String resolverClassName,
+			String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to interpret specified optimizer [%s], falling back to noop", id = 321)
 	void unableToLocateCustomOptimizerClass(String type);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to instantiate specified optimizer [%s], falling back to noop", id = 322)
 	void unableToInstantiateOptimizer(String type);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to instantiate UUID generation strategy class : %s", id = 325)
 	void unableToInstantiateUuidGenerationStrategy(Exception ignore);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Cannot join transaction: do not override %s", id = 326)
 	void unableToJoinTransaction(String transactionStrategy);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Error performing load command : %s", id = 327)
 	void unableToLoadCommand(HibernateException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to load/access derby driver class sysinfo to check versions : %s", id = 328)
 	void unableToLoadDerbyDriver(String message);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Problem loading properties from hibernate.properties", id = 329)
 	void unableToLoadProperties();
 
 	@Message(value = "Unable to locate config file: %s", id = 330)
 	String unableToLocateConfigFile(String path);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to locate configured schema name resolver class [%s] %s", id = 331)
-	void unableToLocateConfiguredSchemaNameResolver(String resolverClassName,
-													String message);
+	void unableToLocateConfiguredSchemaNameResolver(
+			String resolverClassName,
+			String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to locate MBeanServer on JMX service shutdown", id = 332)
 	void unableToLocateMBeanServer();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to locate requested UUID generation strategy class : %s", id = 334)
 	void unableToLocateUuidGenerationStrategy(String strategyClassName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to log SQLWarnings : %s", id = 335)
 	void unableToLogSqlWarnings(SQLException sqle);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not log warnings", id = 336)
 	void unableToLogWarnings(@Cause SQLException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unable to mark for rollback on PersistenceException: ", id = 337)
 	void unableToMarkForRollbackOnPersistenceException(@Cause Exception e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unable to mark for rollback on TransientObjectException: ", id = 338)
 	void unableToMarkForRollbackOnTransientObjectException(@Cause Exception e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not obtain connection metadata: %s", id = 339)
 	void unableToObjectConnectionMetadata(SQLException error);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not obtain connection to query metadata: %s", id = 340)
 	void unableToObjectConnectionToQueryMetadata(SQLException error);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not obtain connection metadata : %s", id = 341)
 	void unableToObtainConnectionMetadata(String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not obtain connection to query metadata : %s", id = 342)
 	void unableToObtainConnectionToQueryMetadata(String message);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not obtain initial context", id = 343)
 	void unableToObtainInitialContext(@Cause NamingException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not parse the package-level metadata [%s]", id = 344)
 	void unableToParseMetadata(String packageName);
 
 	@Message(value = "JDBC commit failed", id = 345)
 	String unableToPerformJdbcCommit();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error during managed flush [%s]", id = 346)
 	void unableToPerformManagedFlush(String message);
 
 	@Message(value = "Unable to query java.sql.DatabaseMetaData", id = 347)
 	String unableToQueryDatabaseMetadata();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unable to read class: %s", id = 348)
 	void unableToReadClass(String message);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Could not read column value from result set: %s; %s", id = 349)
-	void unableToReadColumnValueFromResultSet(String name,
-											  String message);
+	void unableToReadColumnValueFromResultSet(
+			String name,
+			String message);
 
 	@Message(value = "Could not read a hi value - you need to populate the table: %s", id = 350)
 	String unableToReadHiValue(String tableName);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not read or init a hi value", id = 351)
 	void unableToReadOrInitHiValue(@Cause SQLException e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unable to release batch statement...", id = 352)
 	void unableToReleaseBatchStatement();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not release a cache lock : %s", id = 353)
 	void unableToReleaseCacheLock(CacheException ce);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unable to release initial context: %s", id = 354)
 	void unableToReleaseContext(String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to release created MBeanServer : %s", id = 355)
 	void unableToReleaseCreatedMBeanServer(String string);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unable to release isolated connection [%s]", id = 356)
 	void unableToReleaseIsolatedConnection(Throwable ignore);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to release type info result set", id = 357)
 	void unableToReleaseTypeInfoResultSet();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to erase previously added bag join fetch", id = 358)
 	void unableToRemoveBagJoinFetch();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Could not resolve aggregate function [%s]; using standard definition", id = 359)
 	void unableToResolveAggregateFunction(String name);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unable to resolve mapping file [%s]", id = 360)
 	void unableToResolveMappingFile(String xmlFile);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unable to retreive cache from JNDI [%s]: %s", id = 361)
-	void unableToRetrieveCache(String namespace,
-							   String message);
+	void unableToRetrieveCache(
+			String namespace,
+			String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to retrieve type info result set : %s", id = 362)
 	void unableToRetrieveTypeInfoResultSet(String string);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unable to rollback connection on exception [%s]", id = 363)
 	void unableToRollbackConnection(Exception ignore);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Unable to rollback isolated transaction on error [%s] : [%s]", id = 364)
-	void unableToRollbackIsolatedTransaction(Exception e,
-											 Exception ignore);
+	void unableToRollbackIsolatedTransaction(
+			Exception e,
+			Exception ignore);
 
 	@Message(value = "JTA rollback failed", id = 365)
 	String unableToRollbackJta();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Error running schema update", id = 366)
 	void unableToRunSchemaUpdate(@Cause Exception e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not set transaction to rollback only", id = 367)
 	void unableToSetTransactionToRollbackOnly(@Cause SystemException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Exception while stopping service", id = 368)
 	void unableToStopHibernateService(@Cause Exception e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Error stopping service [%s] : %s", id = 369)
-	void unableToStopService(Class class1,
-							 String string);
+	void unableToStopService(
+			Class class1,
+			String string);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Exception switching from method: [%s] to a method using the column index. Reverting to using: [%<s]",
 			id = 370)
 	void unableToSwitchToMethodUsingColumnIndex(Method method);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not synchronize database state with session: %s", id = 371)
 	void unableToSynchronizeDatabaseStateWithSession(HibernateException he);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not toggle autocommit", id = 372)
 	void unableToToggleAutoCommit(@Cause Exception e);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unable to transform class: %s", id = 373)
 	void unableToTransformClass(String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Could not unbind factory from JNDI", id = 374)
 	void unableToUnbindFactoryFromJndi(@Cause JndiException e);
 
 	@Message(value = "Could not update hi value in: %s", id = 375)
 	Object unableToUpdateHiValue(String tableName);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Could not updateQuery hi value in: %s", id = 376)
-	void unableToUpdateQueryHiValue(String tableName,
-									@Cause SQLException e);
+	void unableToUpdateQueryHiValue(
+			String tableName,
+			@Cause SQLException e);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Error wrapping result set", id = 377)
 	void unableToWrapResultSet(@Cause SQLException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "I/O reported error writing cached file : %s: %s", id = 378)
-	void unableToWriteCachedFile(String path,
-								 String message);
+	void unableToWriteCachedFile(
+			String path,
+			String message);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unexpected literal token type [%s] passed for numeric processing", id = 380)
 	void unexpectedLiteralTokenType(int type);
 
 	@LogMessage(level = WARN)
 	@Message(value = "JDBC driver did not return the expected number of row counts", id = 381)
 	void unexpectedRowCounts();
 
 	@LogMessage(level = WARN)
 	@Message(value = "unrecognized bytecode provider [%s], using javassist by default", id = 382)
 	void unknownBytecodeProvider(String providerName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unknown Ingres major version [%s]; using Ingres 9.2 dialect", id = 383)
 	void unknownIngresVersion(int databaseMajorVersion);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unknown Oracle major version [%s]", id = 384)
 	void unknownOracleVersion(int databaseMajorVersion);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unknown Microsoft SQL Server major version [%s] using SQL Server 2000 dialect", id = 385)
 	void unknownSqlServerVersion(int databaseMajorVersion);
 
 	@LogMessage(level = WARN)
 	@Message(value = "ResultSet had no statement associated with it, but was not yet registered", id = 386)
 	void unregisteredResultSetWithoutStatement();
 
 	// Keep this at DEBUG level, rather than warn.  Numerous connection pool implementations can return a
 	// proxy/wrapper around the JDBC Statement, causing excessive logging here.  See HHH-8210.
 	@LogMessage(level = DEBUG)
 	@Message(value = "ResultSet's statement was not registered", id = 387)
 	void unregisteredStatement();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unsuccessful: %s", id = 388)
 	void unsuccessful(String sql);
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Unsuccessful: %s", id = 389)
 	void unsuccessfulCreate(String string);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Overriding release mode as connection provider does not support 'after_statement'", id = 390)
 	void unsupportedAfterStatement();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Ingres 10 is not yet fully supported; using Ingres 9.3 dialect", id = 391)
 	void unsupportedIngresVersion();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Hibernate does not support SequenceGenerator.initialValue() unless '%s' set", id = 392)
 	void unsupportedInitialValue(String propertyName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "The %s.%s.%s version of H2 implements temporary table creation such that it commits current transaction; multi-table, bulk hql/jpaql will not work properly",
 			id = 393)
-	void unsupportedMultiTableBulkHqlJpaql(int majorVersion,
-										   int minorVersion,
-										   int buildId);
+	void unsupportedMultiTableBulkHqlJpaql(
+			int majorVersion,
+			int minorVersion,
+			int buildId);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Oracle 11g is not yet fully supported; using Oracle 10g dialect", id = 394)
 	void unsupportedOracleVersion();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Usage of obsolete property: %s no longer supported, use: %s", id = 395)
-	void unsupportedProperty(Object propertyName,
-							 Object newPropertyName);
+	void unsupportedProperty(
+			Object propertyName,
+			Object newPropertyName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Updating schema", id = 396)
 	void updatingSchema();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Using ASTQueryTranslatorFactory", id = 397)
 	void usingAstQueryTranslatorFactory();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Explicit segment value for id generator [%s.%s] suggested; using default [%s]", id = 398)
-	void usingDefaultIdGeneratorSegmentValue(String tableName,
-											 String segmentColumnName,
-											 String defaultToUse);
+	void usingDefaultIdGeneratorSegmentValue(
+			String tableName,
+			String segmentColumnName,
+			String defaultToUse);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Using default transaction strategy (direct JDBC transactions)", id = 399)
 	void usingDefaultTransactionStrategy();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Using dialect: %s", id = 400)
 	void usingDialect(Dialect dialect);
 
 	@LogMessage(level = INFO)
 	@Message(value = "using driver [%s] at URL [%s]", id = 401)
-	void usingDriver(String driverClassName,
-					 String url);
+	void usingDriver(
+			String driverClassName,
+			String url);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Using Hibernate built-in connection pool (not for production use!)", id = 402)
 	void usingHibernateBuiltInConnectionPool();
 
 	@LogMessage(level = ERROR)
 	@Message(value = "Don't use old DTDs, read the Hibernate 3.x Migration Guide!", id = 404)
 	void usingOldDtd();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Using bytecode reflection optimizer", id = 406)
 	void usingReflectionOptimizer();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Using java.io streams to persist binary types", id = 407)
 	void usingStreams();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Using workaround for JVM bug in java.sql.Timestamp", id = 408)
 	void usingTimestampWorkaround();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Using %s which does not generate IETF RFC 4122 compliant UUID values; consider using %s instead",
 			id = 409)
-	void usingUuidHexGenerator(String name,
-							   String name2);
+	void usingUuidHexGenerator(
+			String name,
+			String name2);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Hibernate Validator not found: ignoring", id = 410)
 	void validatorNotFound();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Hibernate Core {%s}", id = 412)
 	void version(String versionString);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Warnings creating temp table : %s", id = 413)
 	void warningsCreatingTempTable(SQLWarning warning);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Property hibernate.search.autoregister_listeners is set to false. No attempt will be made to register Hibernate Search event listeners.",
 			id = 414)
 	void willNotRegisterListeners();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Write locks via update not supported for non-versioned entities [%s]", id = 416)
 	void writeLocksNotSupported(String entityName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Writing generated schema to file: %s", id = 417)
 	void writingGeneratedSchemaToFile(String outputFile);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Adding override for %s: %s", id = 418)
-	void addingOverrideFor(String name,
-						   String name2);
+	void addingOverrideFor(
+			String name,
+			String name2);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Resolved SqlTypeDescriptor is for a different SQL code. %s has sqlCode=%s; type override %s has sqlCode=%s",
 			id = 419)
-	void resolvedSqlTypeDescriptorForDifferentSqlCode(String name,
-													  String valueOf,
-													  String name2,
-													  String valueOf2);
+	void resolvedSqlTypeDescriptorForDifferentSqlCode(
+			String name,
+			String valueOf,
+			String name2,
+			String valueOf2);
 
 	@LogMessage(level = DEBUG)
 	@Message(value = "Closing un-released batch", id = 420)
 	void closingUnreleasedBatch();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Disabling contextual LOB creation as %s is true", id = 421)
 	void disablingContextualLOBCreation(String nonContextualLobCreation);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Disabling contextual LOB creation as connection was null", id = 422)
 	void disablingContextualLOBCreationSinceConnectionNull();
 
 	@LogMessage(level = INFO)
 	@Message(value = "Disabling contextual LOB creation as JDBC driver reported JDBC version [%s] less than 4",
 			id = 423)
 	void disablingContextualLOBCreationSinceOldJdbcVersion(int jdbcMajorVersion);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Disabling contextual LOB creation as createClob() method threw error : %s", id = 424)
 	void disablingContextualLOBCreationSinceCreateClobFailed(Throwable t);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Could not close session; swallowing exception[%s] as transaction completed", id = 425)
 	void unableToCloseSessionButSwallowingError(HibernateException e);
 
 	@LogMessage(level = WARN)
 	@Message(value = "You should set hibernate.transaction.jta.platform if cache is enabled", id = 426)
 	void setManagerLookupClass();
 
 //	@LogMessage(level = WARN)
 //	@Message(value = "Using deprecated %s strategy [%s], use newer %s strategy instead [%s]", id = 427)
 //	void deprecatedTransactionManagerStrategy(String name,
 //											  String transactionManagerStrategy,
 //											  String name2,
 //											  String jtaPlatform);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Encountered legacy TransactionManagerLookup specified; convert to newer %s contract specified via %s setting",
 			id = 428)
-	void legacyTransactionManagerStrategy(String name,
-										  String jtaPlatform);
+	void legacyTransactionManagerStrategy(
+			String name,
+			String jtaPlatform);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Setting entity-identifier value binding where one already existed : %s.", id = 429)
 	void entityIdentifierValueBindingExists(String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "The DerbyDialect dialect has been deprecated; use one of the version-specific dialects instead",
 			id = 430)
 	void deprecatedDerbyDialect();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to determine H2 database version, certain features may not work", id = 431)
 	void undeterminedH2Version();
 
 	@LogMessage(level = WARN)
 	@Message(value = "There were not column names specified for index %s on table %s", id = 432)
 	void noColumnsSpecifiedForIndex(String indexName, String tableName);
 
 	@LogMessage(level = INFO)
 	@Message(value = "update timestamps cache puts: %s", id = 433)
 	void timestampCachePuts(long updateTimestampsCachePutCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "update timestamps cache hits: %s", id = 434)
 	void timestampCacheHits(long updateTimestampsCachePutCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "update timestamps cache misses: %s", id = 435)
 	void timestampCacheMisses(long updateTimestampsCachePutCount);
 
 	@LogMessage(level = WARN)
-	@Message(value = "Entity manager factory name (%s) is already registered.  If entity manager will be clustered "+
+	@Message(value = "Entity manager factory name (%s) is already registered.  If entity manager will be clustered " +
 			"or passivated, specify a unique value for property '%s'", id = 436)
 	void entityManagerFactoryAlreadyRegistered(String emfName, String propertyName);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Attempting to save one or more entities that have a non-nullable association with an unsaved transient entity. The unsaved transient entity must be saved in an operation prior to saving these dependent entities.\n" +
-			"\tUnsaved transient entity: (%s)\n\tDependent entities: (%s)\n\tNon-nullable association(s): (%s)" , id = 437)
-	void cannotResolveNonNullableTransientDependencies(String transientEntityString,
-													   Set<String> dependentEntityStrings,
-													   Set<String> nonNullableAssociationPaths);
+			"\tUnsaved transient entity: (%s)\n\tDependent entities: (%s)\n\tNon-nullable association(s): (%s)", id = 437)
+	void cannotResolveNonNullableTransientDependencies(
+			String transientEntityString,
+			Set<String> dependentEntityStrings,
+			Set<String> nonNullableAssociationPaths);
 
 	@LogMessage(level = INFO)
 	@Message(value = "NaturalId cache puts: %s", id = 438)
 	void naturalIdCachePuts(long naturalIdCachePutCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "NaturalId cache hits: %s", id = 439)
 	void naturalIdCacheHits(long naturalIdCacheHitCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "NaturalId cache misses: %s", id = 440)
 	void naturalIdCacheMisses(long naturalIdCacheMissCount);
 
 	@LogMessage(level = INFO)
 	@Message(value = "Max NaturalId query time: %sms", id = 441)
 	void naturalIdMaxQueryTime(long naturalIdQueryExecutionMaxTime);
-	
+
 	@LogMessage(level = INFO)
 	@Message(value = "NaturalId queries executed to database: %s", id = 442)
 	void naturalIdQueriesExecuted(long naturalIdQueriesExecutionCount);
 
 	@LogMessage(level = WARN)
 	@Message(
 			value = "Dialect [%s] limits the number of elements in an IN predicate to %s entries.  " +
 					"However, the given parameter list [%s] contained %s entries, which will likely cause failures " +
 					"to execute the query in the database",
 			id = 443
 	)
 	void tooManyInExpressions(String dialectName, int limit, String paramName, int size);
 
 	@LogMessage(level = WARN)
 	@Message(
 			value = "Encountered request for locking however dialect reports that database prefers locking be done in a " +
 					"separate select (follow-on locking); results will be locked after initial query executes",
 			id = 444
 	)
 	void usingFollowOnLocking();
 
 	@LogMessage(level = WARN)
 	@Message(
 			value = "Alias-specific lock modes requested, which is not currently supported with follow-on locking; " +
 					"all acquired locks will be [%s]",
 			id = 445
 	)
 	void aliasSpecificLockingWithFollowOnLocking(LockMode lockMode);
 
 	/**
 	 * @see org.hibernate.internal.log.DeprecationLogger#logDeprecationOfEmbedXmlSupport()
 	 */
 	@LogMessage(level = WARN)
 	@Message(
 			value = "embed-xml attributes were intended to be used for DOM4J entity mode. Since that entity mode has been " +
 					"removed, embed-xml attributes are no longer supported and should be removed from mappings.",
 			id = 446
 	)
 	void embedXmlAttributesNoLongerSupported();
 
 	@LogMessage(level = WARN)
 	@Message(
 			value = "Explicit use of UPGRADE_SKIPLOCKED in lock() calls is not recommended; use normal UPGRADE locking instead",
 			id = 447
 	)
 	void explicitSkipLockedLockCombo();
 
 	@LogMessage(level = INFO)
-	@Message( value = "'javax.persistence.validation.mode' named multiple values : %s", id = 448 )
+	@Message(value = "'javax.persistence.validation.mode' named multiple values : %s", id = 448)
 	void multipleValidationModes(String modes);
 
 	@LogMessage(level = WARN)
 	@Message(
 			id = 449,
 			value = "@Convert annotation applied to Map attribute [%s] did not explicitly specify attributeName " +
 					"using 'key'/'value' as required by spec; attempting to DoTheRightThing"
 	)
 	void nonCompliantMapConversion(String collectionRole);
 
 	@LogMessage(level = WARN)
 	@Message(
 			id = 450,
 			value = "Encountered request for Service by non-primary service role [%s -> %s]; please update usage"
 	)
 	void alternateServiceRole(String requestedRole, String targetRole);
 
 	@LogMessage(level = WARN)
 	@Message(
 			id = 451,
 			value = "Transaction afterCompletion called by a background thread; " +
 					"delaying afterCompletion processing until the original thread can handle it. [status=%s]"
 	)
 	void rollbackFromBackgroundThread(int status);
-	
+
 	@LogMessage(level = WARN)
 	@Message(value = "Exception while loading a class or resource found during scanning", id = 452)
 	void unableToLoadScannedClassOrResource(@Cause Exception e);
-	
+
 	@LogMessage(level = WARN)
 	@Message(value = "Exception while discovering OSGi service implementations : %s", id = 453)
 	void unableToDiscoverOsgiService(String service, @Cause Exception e);
 
 	/**
 	 * @deprecated Use {@link org.hibernate.internal.log.DeprecationLogger#deprecatedManyToManyOuterJoin} instead
 	 */
 	@Deprecated
 	@LogMessage(level = WARN)
 	@Message(value = "The outer-join attribute on <many-to-many> has been deprecated. Instead of outer-join=\"false\", use lazy=\"extra\" with <map>, <set>, <bag>, <idbag>, or <list>, which will only initialize entities (not as a proxy) as needed.", id = 454)
 	void deprecatedManyToManyOuterJoin();
 
 	/**
 	 * @deprecated Use {@link org.hibernate.internal.log.DeprecationLogger#deprecatedManyToManyFetch} instead
 	 */
 	@Deprecated
 	@LogMessage(level = WARN)
 	@Message(value = "The fetch attribute on <many-to-many> has been deprecated. Instead of fetch=\"select\", use lazy=\"extra\" with <map>, <set>, <bag>, <idbag>, or <list>, which will only initialize entities (not as a proxy) as needed.", id = 455)
 	void deprecatedManyToManyFetch();
 
 	@LogMessage(level = WARN)
 	@Message(value = "Named parameters are used for a callable statement, but database metadata indicates named parameters are not supported.", id = 456)
 	void unsupportedNamedParameters();
 
 	@LogMessage(level = WARN)
 	@Message(
 			id = 457,
 			value = "Joined inheritance hierarchy [%1$s] defined explicit @DiscriminatorColumn.  Legacy Hibernate behavior " +
 					"was to ignore the @DiscriminatorColumn.  However, as part of issue HHH-6911 we now apply the " +
 					"explicit @DiscriminatorColumn.  If you would prefer the legacy behavior, enable the `%2$s` setting " +
 					"(%2$s=true)"
 	)
 	void applyingExplicitDiscriminatorColumnForJoined(String className, String overrideSetting);
-	
+
 	// 458-466 reserved for use by master (ORM 5.0.0)
 
 	@LogMessage(level = DEBUG)
 	@Message(value = "Creating pooled optimizer (lo) with [incrementSize=%s; returnClass=%s]", id = 467)
 	void creatingPooledLoOptimizer(int incrementSize, String name);
 
 	@LogMessage(level = WARN)
 	@Message(value = "Unable to interpret type [%s] as an AttributeConverter due to an exception : %s", id = 468)
 	void logBadHbmAttributeConverterType(String type, String exceptionMessage);
 
 	@Message(value = "The ClassLoaderService can not be reused. This instance was stopped already.", id = 469)
 	HibernateException usingStoppedClassLoaderService();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/CriteriaImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/CriteriaImpl.java
index f872b5c44c..3f5d5bbb13 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/CriteriaImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/CriteriaImpl.java
@@ -1,740 +1,741 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.CacheMode;
 import org.hibernate.Criteria;
 import org.hibernate.FetchMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.criterion.Criterion;
 import org.hibernate.criterion.NaturalIdentifier;
 import org.hibernate.criterion.Order;
 import org.hibernate.criterion.Projection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.JoinType;
 import org.hibernate.transform.ResultTransformer;
 
 /**
  * Implementation of the <tt>Criteria</tt> interface
  * @author Gavin King
  */
 public class CriteriaImpl implements Criteria, Serializable {
 
 	private final String entityOrClassName;
 	private transient SessionImplementor session;
 	private final String rootAlias;
 
 	private List<CriterionEntry> criterionEntries = new ArrayList<CriterionEntry>();
 	private List<OrderEntry> orderEntries = new ArrayList<OrderEntry>();
 	private Projection projection;
 	private Criteria projectionCriteria;
 
 	private List<Subcriteria> subcriteriaList = new ArrayList<Subcriteria>();
 
 	private Map<String, FetchMode> fetchModes = new HashMap<String, FetchMode>();
 	private Map<String, LockMode> lockModes = new HashMap<String, LockMode>();
 
 	private Integer maxResults;
 	private Integer firstResult;
 	private Integer timeout;
 	private Integer fetchSize;
 
 	private boolean cacheable;
 	private String cacheRegion;
 	private String comment;
 	private final List<String> queryHints = new ArrayList<String>();
 
 	private FlushMode flushMode;
 	private CacheMode cacheMode;
 	private FlushMode sessionFlushMode;
 	private CacheMode sessionCacheMode;
 
 	private Boolean readOnly;
 
 	private ResultTransformer resultTransformer = Criteria.ROOT_ENTITY;
 
 
 	// Constructors ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public CriteriaImpl(String entityOrClassName, SessionImplementor session) {
 		this(entityOrClassName, ROOT_ALIAS, session);
 	}
 
 	public CriteriaImpl(String entityOrClassName, String alias, SessionImplementor session) {
 		this.session = session;
 		this.entityOrClassName = entityOrClassName;
 		this.cacheable = false;
 		this.rootAlias = alias;
 	}
 	@Override
 	public String toString() {
 		return "CriteriaImpl(" +
 			entityOrClassName + ":" +
 			(rootAlias==null ? "" : rootAlias) +
 			subcriteriaList.toString() +
 			criterionEntries.toString() +
 			( projection==null ? "" : projection.toString() ) +
 			')';
 	}
 
 
 	// State ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public SessionImplementor getSession() {
 		return session;
 	}
 
 	public void setSession(SessionImplementor session) {
 		this.session = session;
 	}
 
 	public String getEntityOrClassName() {
 		return entityOrClassName;
 	}
 
 	public Map<String, LockMode> getLockModes() {
 		return lockModes;
 	}
 
 	public Criteria getProjectionCriteria() {
 		return projectionCriteria;
 	}
 
 	public Iterator<Subcriteria> iterateSubcriteria() {
 		return subcriteriaList.iterator();
 	}
 
 	public Iterator<CriterionEntry> iterateExpressionEntries() {
 		return criterionEntries.iterator();
 	}
 
 	public Iterator<OrderEntry> iterateOrderings() {
 		return orderEntries.iterator();
 	}
 
 	public Criteria add(Criteria criteriaInst, Criterion expression) {
 		criterionEntries.add( new CriterionEntry(expression, criteriaInst) );
 		return this;
 	}
 
 
 	// Criteria impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	@Override
 	public String getAlias() {
 		return rootAlias;
 	}
 
 	public Projection getProjection() {
 		return projection;
 	}
 	@Override
 	public Criteria setProjection(Projection projection) {
 		this.projection = projection;
 		this.projectionCriteria = this;
 		setResultTransformer( PROJECTION );
 		return this;
 	}
 	@Override
 	public Criteria add(Criterion expression) {
 		add( this, expression );
 		return this;
 	}
 	@Override
 	public Criteria addOrder(Order ordering) {
 		orderEntries.add( new OrderEntry( ordering, this ) );
 		return this;
 	}
 	public FetchMode getFetchMode(String path) {
 		return fetchModes.get(path);
 	}
 	@Override
 	public Criteria setFetchMode(String associationPath, FetchMode mode) {
 		fetchModes.put( associationPath, mode );
 		return this;
 	}
 	@Override
 	public Criteria setLockMode(LockMode lockMode) {
 		return setLockMode( getAlias(), lockMode );
 	}
 	@Override
 	public Criteria setLockMode(String alias, LockMode lockMode) {
 		lockModes.put( alias, lockMode );
 		return this;
 	}
 	@Override
 	public Criteria createAlias(String associationPath, String alias) {
 		return createAlias( associationPath, alias, JoinType.INNER_JOIN );
 	}
 	@Override
 	public Criteria createAlias(String associationPath, String alias, JoinType joinType) {
 		new Subcriteria( this, associationPath, alias, joinType );
 		return this;
 	}
 
 	@Override
 	public Criteria createAlias(String associationPath, String alias, int joinType) throws HibernateException {
 		return createAlias( associationPath, alias, JoinType.parse( joinType ) );
 	}
 	@Override
 	public Criteria createAlias(String associationPath, String alias, JoinType joinType, Criterion withClause) {
 		new Subcriteria( this, associationPath, alias, joinType, withClause );
 		return this;
 	}
 
 	@Override
 	public Criteria createAlias(String associationPath, String alias, int joinType, Criterion withClause)
 			throws HibernateException {
 		return createAlias( associationPath, alias, JoinType.parse( joinType ), withClause );
 	}
 	@Override
 	public Criteria createCriteria(String associationPath) {
 		return createCriteria( associationPath, JoinType.INNER_JOIN );
 	}
 	@Override
 	public Criteria createCriteria(String associationPath, JoinType joinType) {
 		return new Subcriteria( this, associationPath, joinType );
 	}
 
 	@Override
 	public Criteria createCriteria(String associationPath, int joinType) throws HibernateException {
 		return createCriteria(associationPath, JoinType.parse( joinType ));
 	}
 	@Override
 	public Criteria createCriteria(String associationPath, String alias) {
 		return createCriteria( associationPath, alias, JoinType.INNER_JOIN );
 	}
 	@Override
 	public Criteria createCriteria(String associationPath, String alias, JoinType joinType) {
 		return new Subcriteria( this, associationPath, alias, joinType );
 	}
 
 	@Override
 	public Criteria createCriteria(String associationPath, String alias, int joinType) throws HibernateException {
 		return createCriteria( associationPath, alias, JoinType.parse( joinType ) );
 	}
 	@Override
 	public Criteria createCriteria(String associationPath, String alias, JoinType joinType, Criterion withClause) {
 		return new Subcriteria( this, associationPath, alias, joinType, withClause );
 	}
 
 	@Override
 	public Criteria createCriteria(String associationPath, String alias, int joinType, Criterion withClause)
 			throws HibernateException {
 		return createCriteria( associationPath, alias, JoinType.parse( joinType ), withClause );
 	}
 
 	public ResultTransformer getResultTransformer() {
 		return resultTransformer;
 	}
 	@Override
 	public Criteria setResultTransformer(ResultTransformer tupleMapper) {
 		this.resultTransformer = tupleMapper;
 		return this;
 	}
 
 	public Integer getMaxResults() {
 		return maxResults;
 	}
 	@Override
 	public Criteria setMaxResults(int maxResults) {
 		this.maxResults = maxResults;
 		return this;
 	}
 
 	public Integer getFirstResult() {
 		return firstResult;
 	}
 	@Override
 	public Criteria setFirstResult(int firstResult) {
 		this.firstResult = firstResult;
 		return this;
 	}
 
 	public Integer getFetchSize() {
 		return fetchSize;
 	}
 	@Override
 	public Criteria setFetchSize(int fetchSize) {
 		this.fetchSize = fetchSize;
 		return this;
 	}
 
 	public Integer getTimeout() {
 		return timeout;
 	}
-   @Override
+
+	@Override
 	public Criteria setTimeout(int timeout) {
 		this.timeout = timeout;
 		return this;
 	}
 
 	@Override
 	public boolean isReadOnlyInitialized() {
 		return readOnly != null;
 	}
 
 	@Override
 	public boolean isReadOnly() {
 		if ( ! isReadOnlyInitialized() && getSession() == null ) {
 			throw new IllegalStateException(
 					"cannot determine readOnly/modifiable setting when it is not initialized and is not initialized and getSession() == null"
 			);
 		}
 		return ( isReadOnlyInitialized() ?
 				readOnly :
 				getSession().getPersistenceContext().isDefaultReadOnly()
 		);
 	}
 
 	@Override
 	public Criteria setReadOnly(boolean readOnly) {
 		this.readOnly = readOnly;
 		return this;
 	}
 
 	public boolean getCacheable() {
 		return this.cacheable;
 	}
 	@Override
 	public Criteria setCacheable(boolean cacheable) {
 		this.cacheable = cacheable;
 		return this;
 	}
 
 	public String getCacheRegion() {
 		return this.cacheRegion;
 	}
 	@Override
 	public Criteria setCacheRegion(String cacheRegion) {
 		this.cacheRegion = cacheRegion.trim();
 		return this;
 	}
 
 	public String getComment() {
 		return comment;
 	}
 	
 	@Override
 	public Criteria setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
 
 	public List<String> getQueryHints() {
 		return queryHints;
 	}
 
 	@Override
 	public Criteria addQueryHint(String queryHint) {
 		queryHints.add( queryHint );
 		return this;
 	}
 	
 	@Override
 	public Criteria setFlushMode(FlushMode flushMode) {
 		this.flushMode = flushMode;
 		return this;
 	}
 	@Override
 	public Criteria setCacheMode(CacheMode cacheMode) {
 		this.cacheMode = cacheMode;
 		return this;
 	}
 	@Override
 	public List list() throws HibernateException {
 		before();
 		try {
 			return session.list( this );
 		}
 		finally {
 			after();
 		}
 	}
 	@Override
 	public ScrollableResults scroll() {
 		return scroll( session.getFactory().getDialect().defaultScrollMode() );
 	}
 	@Override
 	public ScrollableResults scroll(ScrollMode scrollMode) {
 		before();
 		try {
 			return session.scroll(this, scrollMode);
 		}
 		finally {
 			after();
 		}
 	}
 	@Override
 	public Object uniqueResult() throws HibernateException {
 		return AbstractQueryImpl.uniqueElement( list() );
 	}
 
 	protected void before() {
 		if ( flushMode != null ) {
 			sessionFlushMode = getSession().getFlushMode();
 			getSession().setFlushMode( flushMode );
 		}
 		if ( cacheMode != null ) {
 			sessionCacheMode = getSession().getCacheMode();
 			getSession().setCacheMode( cacheMode );
 		}
 	}
 
 	protected void after() {
 		if ( sessionFlushMode != null ) {
 			getSession().setFlushMode( sessionFlushMode );
 			sessionFlushMode = null;
 		}
 		if ( sessionCacheMode != null ) {
 			getSession().setCacheMode( sessionCacheMode );
 			sessionCacheMode = null;
 		}
 	}
 
 	public boolean isLookupByNaturalKey() {
 		if ( projection != null ) {
 			return false;
 		}
 		if ( subcriteriaList.size() > 0 ) {
 			return false;
 		}
 		if ( criterionEntries.size() != 1 ) {
 			return false;
 		}
 		CriterionEntry ce = criterionEntries.get(0);
 		return ce.getCriterion() instanceof NaturalIdentifier;
 	}
 
 
 	// Inner classes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public final class Subcriteria implements Criteria, Serializable {
 
 		private String alias;
 		private String path;
 		private Criteria parent;
 		private LockMode lockMode;
 		private JoinType joinType = JoinType.INNER_JOIN;
 		private Criterion withClause;
 		private boolean hasRestriction;
 
 		// Constructors ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		private Subcriteria(Criteria parent, String path, String alias, JoinType joinType, Criterion withClause) {
 			this.alias = alias;
 			this.path = path;
 			this.parent = parent;
 			this.joinType = joinType;
 			this.withClause = withClause;
 			this.hasRestriction = withClause != null;
 			CriteriaImpl.this.subcriteriaList.add( this );
 		}
 
 		private Subcriteria(Criteria parent, String path, String alias, JoinType joinType) {
 			this( parent, path, alias, joinType, null );
 		}
 
 		private Subcriteria(Criteria parent, String path, JoinType joinType) {
 			this( parent, path, null, joinType );
 		}
 		@Override
 		public String toString() {
 			return "Subcriteria("
 					+ path + ":"
 					+ (alias==null ? "" : alias)
 					+ ')';
 		}
 
 
 		// State ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		@Override
 		public String getAlias() {
 			return alias;
 		}
 
 		public void setAlias(String alias) {
 			this.alias = alias;
 		}
 
 		public String getPath() {
 			return path;
 		}
 
 		public Criteria getParent() {
 			return parent;
 		}
 
 		public LockMode getLockMode() {
 			return lockMode;
 		}
 		@Override
 		public Criteria setLockMode(LockMode lockMode) {
 			this.lockMode = lockMode;
 			return this;
 		}
 
 		public JoinType getJoinType() {
 			return joinType;
 		}
 
 		public Criterion getWithClause() {
 			return this.withClause;
 		}
 
 		public boolean hasRestriction() {
 			return hasRestriction;
 		}
 
 		// Criteria impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		@Override
 		public Criteria add(Criterion expression) {
 			hasRestriction = true;
 			CriteriaImpl.this.add(this, expression);
 			return this;
 		}
 		@Override
 		public Criteria addOrder(Order order) {
 			CriteriaImpl.this.orderEntries.add( new OrderEntry(order, this) );
 			return this;
 		}
 		@Override
 		public Criteria createAlias(String associationPath, String alias) {
 			return createAlias( associationPath, alias, JoinType.INNER_JOIN );
 		}
 		@Override
 		public Criteria createAlias(String associationPath, String alias, JoinType joinType) throws HibernateException {
 			new Subcriteria( this, associationPath, alias, joinType );
 			return this;
 		}
 
 		@Override
 		public Criteria createAlias(String associationPath, String alias, int joinType) throws HibernateException {
 			return createAlias( associationPath, alias, JoinType.parse( joinType ) );
 		}
 		@Override
 		public Criteria createAlias(String associationPath, String alias, JoinType joinType, Criterion withClause) throws HibernateException {
 			new Subcriteria( this, associationPath, alias, joinType, withClause );
 			return this;
 		}
 
 		@Override
 		public Criteria createAlias(String associationPath, String alias, int joinType, Criterion withClause)
 				throws HibernateException {
 			return createAlias( associationPath, alias, JoinType.parse( joinType ), withClause );
 		}
 		@Override
 		public Criteria createCriteria(String associationPath) {
 			return createCriteria( associationPath, JoinType.INNER_JOIN );
 		}
 		@Override
 		public Criteria createCriteria(String associationPath, JoinType joinType) throws HibernateException {
 			return new Subcriteria( Subcriteria.this, associationPath, joinType );
 		}
 
 		@Override
 		public Criteria createCriteria(String associationPath, int joinType) throws HibernateException {
 			return createCriteria( associationPath, JoinType.parse( joinType ) );
 		}
 		@Override
 		public Criteria createCriteria(String associationPath, String alias) {
 			return createCriteria( associationPath, alias, JoinType.INNER_JOIN );
 		}
 		@Override
 		public Criteria createCriteria(String associationPath, String alias, JoinType joinType) throws HibernateException {
 			return new Subcriteria( Subcriteria.this, associationPath, alias, joinType );
 		}
 
 		@Override
 		public Criteria createCriteria(String associationPath, String alias, int joinType) throws HibernateException {
 			return createCriteria( associationPath, alias, JoinType.parse( joinType ) );
 		}
 		@Override
 		public Criteria createCriteria(String associationPath, String alias, JoinType joinType, Criterion withClause) throws HibernateException {
 			return new Subcriteria( this, associationPath, alias, joinType, withClause );
 		}
 
 		@Override
 		public Criteria createCriteria(String associationPath, String alias, int joinType, Criterion withClause)
 				throws HibernateException {
 			return createCriteria( associationPath, alias, JoinType.parse( joinType ), withClause );
 		}
 		@Override
 		public boolean isReadOnly() {
 			return CriteriaImpl.this.isReadOnly();
 		}
 		@Override
 		public boolean isReadOnlyInitialized() {
 			return CriteriaImpl.this.isReadOnlyInitialized();
 		}
 		@Override
 		public Criteria setReadOnly(boolean readOnly) {
 			CriteriaImpl.this.setReadOnly( readOnly );
 			return this;
 		}
 		@Override
 		public Criteria setCacheable(boolean cacheable) {
 			CriteriaImpl.this.setCacheable(cacheable);
 			return this;
 		}
 		@Override
 		public Criteria setCacheRegion(String cacheRegion) {
 			CriteriaImpl.this.setCacheRegion(cacheRegion);
 			return this;
 		}
 		@Override
 		public List list() throws HibernateException {
 			return CriteriaImpl.this.list();
 		}
 		@Override
 		public ScrollableResults scroll() throws HibernateException {
 			return CriteriaImpl.this.scroll();
 		}
 		@Override
 		public ScrollableResults scroll(ScrollMode scrollMode) throws HibernateException {
 			return CriteriaImpl.this.scroll(scrollMode);
 		}
 		@Override
 		public Object uniqueResult() throws HibernateException {
 			return CriteriaImpl.this.uniqueResult();
 		}
 		@Override
 		public Criteria setFetchMode(String associationPath, FetchMode mode) {
 			CriteriaImpl.this.setFetchMode( StringHelper.qualify(path, associationPath), mode);
 			return this;
 		}
 		@Override
 		public Criteria setFlushMode(FlushMode flushMode) {
 			CriteriaImpl.this.setFlushMode(flushMode);
 			return this;
 		}
 		@Override
 		public Criteria setCacheMode(CacheMode cacheMode) {
 			CriteriaImpl.this.setCacheMode(cacheMode);
 			return this;
 		}
 		@Override
 		public Criteria setFirstResult(int firstResult) {
 			CriteriaImpl.this.setFirstResult(firstResult);
 			return this;
 		}
 		@Override
 		public Criteria setMaxResults(int maxResults) {
 			CriteriaImpl.this.setMaxResults(maxResults);
 			return this;
 		}
 		@Override
 		public Criteria setTimeout(int timeout) {
 			CriteriaImpl.this.setTimeout(timeout);
 			return this;
 		}
 		@Override
 		public Criteria setFetchSize(int fetchSize) {
 			CriteriaImpl.this.setFetchSize(fetchSize);
 			return this;
 		}
 		@Override
 		public Criteria setLockMode(String alias, LockMode lockMode) {
 			CriteriaImpl.this.setLockMode(alias, lockMode);
 			return this;
 		}
 		@Override
 		public Criteria setResultTransformer(ResultTransformer resultProcessor) {
 			CriteriaImpl.this.setResultTransformer(resultProcessor);
 			return this;
 		}
 		@Override
 		public Criteria setComment(String comment) {
 			CriteriaImpl.this.setComment(comment);
 			return this;
 		}   
 		@Override
 		public Criteria addQueryHint(String queryHint) {
 			CriteriaImpl.this.addQueryHint( queryHint );
 			return this;
 		}
 		@Override
 		public Criteria setProjection(Projection projection) {
 			CriteriaImpl.this.projection = projection;
 			CriteriaImpl.this.projectionCriteria = this;
 			setResultTransformer(PROJECTION);
 			return this;
 		}
 	}
 
 	public static final class CriterionEntry implements Serializable {
 		private final Criterion criterion;
 		private final Criteria criteria;
 
 		private CriterionEntry(Criterion criterion, Criteria criteria) {
 			this.criteria = criteria;
 			this.criterion = criterion;
 		}
 
 		public Criterion getCriterion() {
 			return criterion;
 		}
 
 		public Criteria getCriteria() {
 			return criteria;
 		}
 		@Override
 		public String toString() {
 			return criterion.toString();
 		}
 	}
 
 	public static final class OrderEntry implements Serializable {
 		private final Order order;
 		private final Criteria criteria;
 
 		private OrderEntry(Order order, Criteria criteria) {
 			this.criteria = criteria;
 			this.order = order;
 		}
 
 		public Order getOrder() {
 			return order;
 		}
 
 		public Criteria getCriteria() {
 			return criteria;
 		}
 		@Override
 		public String toString() {
 			return order.toString();
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/DynamicFilterAliasGenerator.java b/hibernate-core/src/main/java/org/hibernate/internal/DynamicFilterAliasGenerator.java
index f2bb6dceca..345e55fddd 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/DynamicFilterAliasGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/DynamicFilterAliasGenerator.java
@@ -1,52 +1,53 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import org.hibernate.persister.entity.AbstractEntityPersister;
 
 /**
- * 
  * @author Rob Worsnop
- *
  */
 public class DynamicFilterAliasGenerator implements FilterAliasGenerator {
-	
 	private String[] tables;
 	private String rootAlias;
 
 	public DynamicFilterAliasGenerator(String[] tables, String rootAlias) {
 		this.tables = tables;
 		this.rootAlias = rootAlias;
 	}
 
 	@Override
 	public String getAlias(String table) {
-		if (table == null){
+		if ( table == null ) {
 			return rootAlias;
-		} else{
-			return AbstractEntityPersister.generateTableAlias(rootAlias, AbstractEntityPersister.getTableId(table, tables));
+		}
+		else {
+			return AbstractEntityPersister.generateTableAlias(
+					rootAlias,
+					AbstractEntityPersister.getTableId( table, tables )
+			);
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/FetchingScrollableResultsImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/FetchingScrollableResultsImpl.java
index 5036a7cfb2..b023cb01be 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/FetchingScrollableResultsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/FetchingScrollableResultsImpl.java
@@ -1,287 +1,287 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.loader.Loader;
 import org.hibernate.type.Type;
 
 /**
  * Implementation of ScrollableResults which can handle collection fetches.
  *
  * @author Steve Ebersole
  */
 public class FetchingScrollableResultsImpl extends AbstractScrollableResults {
 	private Object[] currentRow;
 	private int currentPosition;
 	private Integer maxPosition;
 
 	/**
 	 * Constructs a FetchingScrollableResultsImpl.
 	 *
 	 * @param rs The scrollable result set
 	 * @param ps The prepared statement used to obtain the result set
 	 * @param sess The originating session
 	 * @param loader The loader
 	 * @param queryParameters query parameters
 	 * @param types The result types
 	 * @param holderInstantiator Ugh
 	 */
 	public FetchingScrollableResultsImpl(
-	        ResultSet rs,
-	        PreparedStatement ps,
-	        SessionImplementor sess,
-	        Loader loader,
-	        QueryParameters queryParameters,
-	        Type[] types,
-	        HolderInstantiator holderInstantiator) {
+			ResultSet rs,
+			PreparedStatement ps,
+			SessionImplementor sess,
+			Loader loader,
+			QueryParameters queryParameters,
+			Type[] types,
+			HolderInstantiator holderInstantiator) {
 		super( rs, ps, sess, loader, queryParameters, types, holderInstantiator );
 	}
 
 	@Override
-    protected Object[] getCurrentRow() {
+	protected Object[] getCurrentRow() {
 		return currentRow;
 	}
 
 	@Override
 	public boolean next() {
 		if ( maxPosition != null && maxPosition <= currentPosition ) {
 			currentRow = null;
 			currentPosition = maxPosition + 1;
 			return false;
 		}
 
 		if ( isResultSetEmpty() ) {
 			currentRow = null;
 			currentPosition = 0;
 			return false;
 		}
 
 		final Object row = getLoader().loadSequentialRowsForward(
 				getResultSet(),
 				getSession(),
 				getQueryParameters(),
 				false
 		);
 
 
 		final boolean afterLast;
 		try {
 			afterLast = getResultSet().isAfterLast();
 		}
-		catch( SQLException e ) {
+		catch (SQLException e) {
 			throw getSession().getFactory().getSQLExceptionHelper().convert(
-			        e,
-			        "exception calling isAfterLast()"
+					e,
+					"exception calling isAfterLast()"
 			);
 		}
 
 		currentPosition++;
-		currentRow = new Object[] { row };
+		currentRow = new Object[] {row};
 
 		if ( afterLast ) {
 			if ( maxPosition == null ) {
 				// we just hit the last position
 				maxPosition = currentPosition;
 			}
 		}
 
 		afterScrollOperation();
 
 		return true;
 	}
 
 	@Override
 	public boolean previous() {
 		if ( currentPosition <= 1 ) {
 			currentPosition = 0;
 			currentRow = null;
 			return false;
 		}
 
 		final Object loadResult = getLoader().loadSequentialRowsReverse(
 				getResultSet(),
 				getSession(),
 				getQueryParameters(),
 				false,
-		        ( maxPosition != null && currentPosition > maxPosition )
+				( maxPosition != null && currentPosition > maxPosition )
 		);
 
-		currentRow = new Object[] { loadResult };
+		currentRow = new Object[] {loadResult};
 		currentPosition--;
 
 		afterScrollOperation();
 
 		return true;
 	}
 
 	@Override
 	public boolean scroll(int positions) {
 		boolean more = false;
 		if ( positions > 0 ) {
 			// scroll ahead
 			for ( int i = 0; i < positions; i++ ) {
 				more = next();
 				if ( !more ) {
 					break;
 				}
 			}
 		}
 		else if ( positions < 0 ) {
 			// scroll backward
 			for ( int i = 0; i < ( 0 - positions ); i++ ) {
 				more = previous();
 				if ( !more ) {
 					break;
 				}
 			}
 		}
 		else {
 			throw new HibernateException( "scroll(0) not valid" );
 		}
 
 		afterScrollOperation();
 
 		return more;
 	}
 
 	@Override
 	public boolean last() {
 		boolean more = false;
 		if ( maxPosition != null ) {
 			if ( currentPosition > maxPosition ) {
 				more = previous();
 			}
 			for ( int i = currentPosition; i < maxPosition; i++ ) {
 				more = next();
 			}
 		}
 		else {
 			try {
 				if ( isResultSetEmpty() || getResultSet().isAfterLast() ) {
 					// should not be able to reach last without maxPosition being set
 					// unless there are no results
 					return false;
 				}
 
 				while ( !getResultSet().isAfterLast() ) {
 					more = next();
 				}
 			}
-			catch( SQLException e ) {
+			catch (SQLException e) {
 				throw getSession().getFactory().getSQLExceptionHelper().convert(
 						e,
 						"exception calling isAfterLast()"
 				);
 			}
 		}
 
 		afterScrollOperation();
 
 		return more;
 	}
 
 	@Override
 	public boolean first() {
 		beforeFirst();
 		boolean more = next();
 
 		afterScrollOperation();
 
 		return more;
 	}
 
 	@Override
 	public void beforeFirst() {
 		try {
 			getResultSet().beforeFirst();
 		}
-		catch( SQLException e ) {
+		catch (SQLException e) {
 			throw getSession().getFactory().getSQLExceptionHelper().convert(
-			        e,
-			        "exception calling beforeFirst()"
+					e,
+					"exception calling beforeFirst()"
 			);
 		}
 		currentRow = null;
 		currentPosition = 0;
 	}
 
 	@Override
 	public void afterLast() {
 		// TODO : not sure the best way to handle this.
 		// The non-performant way :
 		last();
 		next();
 		afterScrollOperation();
 	}
 
 	@Override
 	public boolean isFirst() {
 		return currentPosition == 1;
 	}
 
 	@Override
 	public boolean isLast() {
 		return maxPosition != null && currentPosition == maxPosition;
 	}
 
 	@Override
 	public int getRowNumber() {
 		return currentPosition;
 	}
 
 	@Override
 	public boolean setRowNumber(int rowNumber) {
 		if ( rowNumber == 1 ) {
 			return first();
 		}
 		else if ( rowNumber == -1 ) {
 			return last();
 		}
 		else if ( maxPosition != null && rowNumber == maxPosition ) {
 			return last();
 		}
 		return scroll( rowNumber - currentPosition );
 	}
 
 	private boolean isResultSetEmpty() {
 		try {
-			return currentPosition == 0 && ! getResultSet().isBeforeFirst() && ! getResultSet().isAfterLast();
+			return currentPosition == 0 && !getResultSet().isBeforeFirst() && !getResultSet().isAfterLast();
 		}
-		catch( SQLException e ) {
+		catch (SQLException e) {
 			throw getSession().getFactory().getSQLExceptionHelper().convert(
-			        e,
-			        "Could not determine if resultset is empty due to exception calling isBeforeFirst or isAfterLast()"
+					e,
+					"Could not determine if resultset is empty due to exception calling isBeforeFirst or isAfterLast()"
 			);
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/FilterConfiguration.java b/hibernate-core/src/main/java/org/hibernate/internal/FilterConfiguration.java
index 7ae640910f..b8f80088b0 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/FilterConfiguration.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/FilterConfiguration.java
@@ -1,94 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.persister.entity.Joinable;
 
 /**
- *
  * @author Rob Worsnop
  */
 public class FilterConfiguration {
 	private final String name;
 	private final String condition;
 	private final boolean autoAliasInjection;
 	private final Map<String, String> aliasTableMap;
 	private final Map<String, String> aliasEntityMap;
 	private final PersistentClass persistentClass;
-	
-	public FilterConfiguration(String name, String condition, boolean autoAliasInjection, Map<String, String> aliasTableMap, Map<String, String> aliasEntityMap, PersistentClass persistentClass) {
+
+	public FilterConfiguration(
+			String name,
+			String condition,
+			boolean autoAliasInjection,
+			Map<String, String> aliasTableMap,
+			Map<String, String> aliasEntityMap,
+			PersistentClass persistentClass) {
 		this.name = name;
 		this.condition = condition;
 		this.autoAliasInjection = autoAliasInjection;
 		this.aliasTableMap = aliasTableMap;
 		this.aliasEntityMap = aliasEntityMap;
 		this.persistentClass = persistentClass;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public String getCondition() {
 		return condition;
 	}
 
 	public boolean useAutoAliasInjection() {
 		return autoAliasInjection;
 	}
 
 	public Map<String, String> getAliasTableMap(SessionFactoryImplementor factory) {
-		Map<String,String> mergedAliasTableMap = mergeAliasMaps(factory);
-		if (!mergedAliasTableMap.isEmpty()){
+		Map<String, String> mergedAliasTableMap = mergeAliasMaps( factory );
+		if ( !mergedAliasTableMap.isEmpty() ) {
 			return mergedAliasTableMap;
-		} else if (persistentClass != null){
-			String table = persistentClass.getTable().getQualifiedName(factory.getDialect(), 
+		}
+		else if ( persistentClass != null ) {
+			String table = persistentClass.getTable().getQualifiedName(
+					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
-					factory.getSettings().getDefaultSchemaName());
-			return Collections.singletonMap(null, table);
-		} else{
+					factory.getSettings().getDefaultSchemaName()
+			);
+			return Collections.singletonMap( null, table );
+		}
+		else {
 			return Collections.emptyMap();
 		}
 	}
-	
-	private Map<String,String> mergeAliasMaps(SessionFactoryImplementor factory){
-		Map<String,String> ret = new HashMap<String, String>();
-		if (aliasTableMap != null){
-			ret.putAll(aliasTableMap);
+
+	private Map<String, String> mergeAliasMaps(SessionFactoryImplementor factory) {
+		Map<String, String> ret = new HashMap<String, String>();
+		if ( aliasTableMap != null ) {
+			ret.putAll( aliasTableMap );
 		}
-		if (aliasEntityMap != null){
-			for (Map.Entry<String, String> entry : aliasEntityMap.entrySet()){
-				ret.put(entry.getKey(), 
-						Joinable.class.cast(factory.getEntityPersister(entry.getValue())).getTableName());
+		if ( aliasEntityMap != null ) {
+			for ( Map.Entry<String, String> entry : aliasEntityMap.entrySet() ) {
+				ret.put(
+						entry.getKey(),
+						Joinable.class.cast( factory.getEntityPersister( entry.getValue() ) ).getTableName()
+				);
 			}
 		}
 		return ret;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/FilterHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/FilterHelper.java
index 53430e878c..e98d71bc0a 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/FilterHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/FilterHelper.java
@@ -1,134 +1,143 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal;
 
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.sql.Template;
 
 /**
  * Implementation of FilterHelper.
  *
  * @author Steve Ebersole
  * @author Rob Worsnop
  */
 public class FilterHelper {
 
 	private final String[] filterNames;
 	private final String[] filterConditions;
 	private final boolean[] filterAutoAliasFlags;
-	private final Map<String,String>[] filterAliasTableMaps;
+	private final Map<String, String>[] filterAliasTableMaps;
 
 	/**
 	 * The map of defined filters.  This is expected to be in format
 	 * where the filter names are the map keys, and the defined
 	 * conditions are the values.
 	 *
 	 * @param filters The map of defined filters.
 	 * @param factory The session factory
 	 */
 	public FilterHelper(List<FilterConfiguration> filters, SessionFactoryImplementor factory) {
 		int filterCount = filters.size();
 		filterNames = new String[filterCount];
 		filterConditions = new String[filterCount];
 		filterAutoAliasFlags = new boolean[filterCount];
 		filterAliasTableMaps = new Map[filterCount];
 		filterCount = 0;
 		for ( final FilterConfiguration filter : filters ) {
 			filterAutoAliasFlags[filterCount] = false;
 			filterNames[filterCount] = filter.getName();
 			filterConditions[filterCount] = filter.getCondition();
 			filterAliasTableMaps[filterCount] = filter.getAliasTableMap( factory );
-			if ( (filterAliasTableMaps[filterCount].isEmpty() || isTableFromPersistentClass( filterAliasTableMaps[filterCount] )) && filter
+			if ( ( filterAliasTableMaps[filterCount].isEmpty() || isTableFromPersistentClass( filterAliasTableMaps[filterCount] ) ) && filter
 					.useAutoAliasInjection() ) {
 				filterConditions[filterCount] = Template.renderWhereStringTemplate(
 						filter.getCondition(),
 						FilterImpl.MARKER,
 						factory.getDialect(),
 						factory.getSqlFunctionRegistry()
 				);
 				filterAutoAliasFlags[filterCount] = true;
 			}
 			filterConditions[filterCount] = StringHelper.replace(
 					filterConditions[filterCount],
 					":",
 					":" + filterNames[filterCount] + "."
 			);
 			filterCount++;
 		}
 	}
-	
-	private static boolean isTableFromPersistentClass(Map<String,String> aliasTableMap){
-		return aliasTableMap.size() == 1 && aliasTableMap.containsKey(null);
+
+	private static boolean isTableFromPersistentClass(Map<String, String> aliasTableMap) {
+		return aliasTableMap.size() == 1 && aliasTableMap.containsKey( null );
 	}
 
 	public boolean isAffectedBy(Map enabledFilters) {
 		for ( String filterName : filterNames ) {
 			if ( enabledFilters.containsKey( filterName ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	public String render(FilterAliasGenerator aliasGenerator, Map enabledFilters) {
 		StringBuilder buffer = new StringBuilder();
 		render( buffer, aliasGenerator, enabledFilters );
 		return buffer.toString();
 	}
 
 	public void render(StringBuilder buffer, FilterAliasGenerator aliasGenerator, Map enabledFilters) {
 		if ( CollectionHelper.isEmpty( filterNames ) ) {
 			return;
 		}
 		for ( int i = 0, max = filterNames.length; i < max; i++ ) {
 			if ( enabledFilters.containsKey( filterNames[i] ) ) {
 				final String condition = filterConditions[i];
 				if ( StringHelper.isNotEmpty( condition ) ) {
 					buffer.append( " and " ).append( render( aliasGenerator, i ) );
 				}
 			}
 		}
 	}
-	
-	private String render(FilterAliasGenerator aliasGenerator, int filterIndex){
-		Map<String,String> aliasTableMap = filterAliasTableMaps[filterIndex];
+
+	private String render(FilterAliasGenerator aliasGenerator, int filterIndex) {
+		Map<String, String> aliasTableMap = filterAliasTableMaps[filterIndex];
 		String condition = filterConditions[filterIndex];
-		if (filterAutoAliasFlags[filterIndex]){
-			return StringHelper.replace(condition, FilterImpl.MARKER, aliasGenerator.getAlias(aliasTableMap.get(null)));
-		} else if (isTableFromPersistentClass(aliasTableMap)){
-			return condition.replace("{alias}", aliasGenerator.getAlias(aliasTableMap.get(null)));
-		} else {
-			for (Map.Entry<String, String> entry : aliasTableMap.entrySet()){
-				condition = condition.replace("{"+entry.getKey()+"}", aliasGenerator.getAlias(entry.getValue()));
+		if ( filterAutoAliasFlags[filterIndex] ) {
+			return StringHelper.replace(
+					condition,
+					FilterImpl.MARKER,
+					aliasGenerator.getAlias( aliasTableMap.get( null ) )
+			);
+		}
+		else if ( isTableFromPersistentClass( aliasTableMap ) ) {
+			return condition.replace( "{alias}", aliasGenerator.getAlias( aliasTableMap.get( null ) ) );
+		}
+		else {
+			for ( Map.Entry<String, String> entry : aliasTableMap.entrySet() ) {
+				condition = condition.replace(
+						"{" + entry.getKey() + "}",
+						aliasGenerator.getAlias( entry.getValue() )
+				);
 			}
 			return condition;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
index 210d6df332..c19b861fbb 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
@@ -1,176 +1,175 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.NoSuchElementException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.engine.HibernateIterator;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * An implementation of <tt>java.util.Iterator</tt> that is
  * returned by <tt>iterate()</tt> query execution methods.
+ *
  * @author Gavin King
  */
 public final class IteratorImpl implements HibernateIterator {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( IteratorImpl.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( IteratorImpl.class );
 
 	private ResultSet rs;
 	private final EventSource session;
 	private boolean readOnly;
 	private final Type[] types;
 	private final boolean single;
 	private Object currentResult;
 	private boolean hasNext;
 	private final String[][] names;
 	private PreparedStatement ps;
 	private HolderInstantiator holderInstantiator;
 
 	public IteratorImpl(
-	        ResultSet rs,
-	        PreparedStatement ps,
-	        EventSource sess,
-	        boolean readOnly,
-	        Type[] types,
-	        String[][] columnNames,
-	        HolderInstantiator holderInstantiator)
-	throws HibernateException, SQLException {
-
-		this.rs=rs;
-		this.ps=ps;
+			ResultSet rs,
+			PreparedStatement ps,
+			EventSource sess,
+			boolean readOnly,
+			Type[] types,
+			String[][] columnNames,
+			HolderInstantiator holderInstantiator) throws HibernateException, SQLException {
+		this.rs = rs;
+		this.ps = ps;
 		this.session = sess;
 		this.readOnly = readOnly;
 		this.types = types;
 		this.names = columnNames;
 		this.holderInstantiator = holderInstantiator;
 
-		single = types.length==1;
+		single = types.length == 1;
 
 		postNext();
 	}
 
 	public void close() throws JDBCException {
-		if (ps!=null) {
+		if ( ps != null ) {
 			LOG.debug( "Closing iterator" );
 			session.getJdbcCoordinator().getResourceRegistry().release( ps );
 			try {
 				session.getPersistenceContext().getLoadContexts().cleanup( rs );
 			}
-			catch( Throwable ignore ) {
+			catch (Throwable ignore) {
 				// ignore this error for now
-                LOG.debugf("Exception trying to cleanup load context : %s", ignore.getMessage());
+				LOG.debugf( "Exception trying to cleanup load context : %s", ignore.getMessage() );
 			}
 			session.getJdbcCoordinator().afterStatementExecution();
 			ps = null;
 			rs = null;
 			hasNext = false;
 		}
 	}
 
 	private void postNext() throws SQLException {
-		LOG.debug("Attempting to retrieve next results");
+		LOG.debug( "Attempting to retrieve next results" );
 		this.hasNext = rs.next();
-		if (!hasNext) {
-			LOG.debug("Exhausted results");
+		if ( !hasNext ) {
+			LOG.debug( "Exhausted results" );
 			close();
 		}
 		else {
-			LOG.debug("Retrieved next results");
+			LOG.debug( "Retrieved next results" );
 		}
 	}
 
 	public boolean hasNext() {
 		return hasNext;
 	}
 
 	public Object next() throws HibernateException {
 		if ( !hasNext ) {
-			throw new NoSuchElementException("No more results");
+			throw new NoSuchElementException( "No more results" );
 		}
 		boolean sessionDefaultReadOnlyOrig = session.isDefaultReadOnly();
 		session.setDefaultReadOnly( readOnly );
 		try {
 			boolean isHolder = holderInstantiator.isRequired();
 
 			LOG.debugf( "Assembling results" );
 			if ( single && !isHolder ) {
 				currentResult = types[0].nullSafeGet( rs, names[0], session, null );
 			}
 			else {
 				Object[] currentResults = new Object[types.length];
-				for (int i=0; i<types.length; i++) {
+				for ( int i = 0; i < types.length; i++ ) {
 					currentResults[i] = types[i].nullSafeGet( rs, names[i], session, null );
 				}
 
-				if (isHolder) {
-					currentResult = holderInstantiator.instantiate(currentResults);
+				if ( isHolder ) {
+					currentResult = holderInstantiator.instantiate( currentResults );
 				}
 				else {
 					currentResult = currentResults;
 				}
 			}
 
 			postNext();
 			LOG.debugf( "Returning current results" );
 			return currentResult;
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not get next iterator result"
-				);
+			);
 		}
 		finally {
 			session.setDefaultReadOnly( sessionDefaultReadOnlyOrig );
 		}
 	}
 
 	public void remove() {
-		if (!single) {
-			throw new UnsupportedOperationException("Not a single column hibernate query result set");
+		if ( !single ) {
+			throw new UnsupportedOperationException( "Not a single column hibernate query result set" );
 		}
-		if (currentResult==null) {
-			throw new IllegalStateException("Called Iterator.remove() before next()");
+		if ( currentResult == null ) {
+			throw new IllegalStateException( "Called Iterator.remove() before next()" );
 		}
 		if ( !( types[0] instanceof EntityType ) ) {
-			throw new UnsupportedOperationException("Not an entity");
+			throw new UnsupportedOperationException( "Not an entity" );
 		}
 
 		session.delete(
 				( (EntityType) types[0] ).getAssociatedEntityName(),
 				currentResult,
 				false,
-		        null
+				null
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/QueryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/QueryImpl.java
index 214be22122..31c702d6a1 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/QueryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/QueryImpl.java
@@ -1,149 +1,150 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.internal;
+
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.Filter;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.Query;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 
 /**
  * default implementation of the <tt>Query</tt> interface,
  * for "ordinary" HQL queries (not collection filters)
- * @see CollectionFilterImpl
+ *
  * @author Gavin King
+ * @see CollectionFilterImpl
  */
 public class QueryImpl extends AbstractQueryImpl {
 
 	private LockOptions lockOptions = new LockOptions();
 
 	public QueryImpl(
 			String queryString,
-	        FlushMode flushMode,
-	        SessionImplementor session,
-	        ParameterMetadata parameterMetadata) {
+			FlushMode flushMode,
+			SessionImplementor session,
+			ParameterMetadata parameterMetadata) {
 		super( queryString, flushMode, session, parameterMetadata );
 	}
 
 	public QueryImpl(String queryString, SessionImplementor session, ParameterMetadata parameterMetadata) {
 		this( queryString, null, session, parameterMetadata );
 	}
 
 	public Iterator iterate() throws HibernateException {
 		verifyParameters();
 		Map namedParams = getNamedParams();
 		before();
 		try {
 			return getSession().iterate(
-					expandParameterLists(namedParams),
-			        getQueryParameters(namedParams)
-				);
+					expandParameterLists( namedParams ),
+					getQueryParameters( namedParams )
+			);
 		}
 		finally {
 			after();
 		}
 	}
 
 	public ScrollableResults scroll() throws HibernateException {
 		return scroll( session.getFactory().getDialect().defaultScrollMode() );
 	}
 
 	public ScrollableResults scroll(ScrollMode scrollMode) throws HibernateException {
 		verifyParameters();
 		Map namedParams = getNamedParams();
 		before();
-		QueryParameters qp = getQueryParameters(namedParams);
-		qp.setScrollMode(scrollMode);
+		QueryParameters qp = getQueryParameters( namedParams );
+		qp.setScrollMode( scrollMode );
 		try {
-			return getSession().scroll( expandParameterLists(namedParams), qp );
+			return getSession().scroll( expandParameterLists( namedParams ), qp );
 		}
 		finally {
 			after();
 		}
 	}
 
 	public List list() throws HibernateException {
 		verifyParameters();
 		Map namedParams = getNamedParams();
 		before();
 		try {
 			return getSession().list(
-					expandParameterLists(namedParams),
-			        getQueryParameters(namedParams)
-				);
+					expandParameterLists( namedParams ),
+					getQueryParameters( namedParams )
+			);
 		}
 		finally {
 			after();
 		}
 	}
 
 	public int executeUpdate() throws HibernateException {
 		verifyParameters();
 		Map namedParams = getNamedParams();
 		before();
 		try {
-            return getSession().executeUpdate(
-                    expandParameterLists( namedParams ),
-                    getQueryParameters( namedParams )
-	            );
+			return getSession().executeUpdate(
+					expandParameterLists( namedParams ),
+					getQueryParameters( namedParams )
+			);
 		}
 		finally {
 			after();
 		}
 	}
 
 	public Query setLockMode(String alias, LockMode lockMode) {
 		lockOptions.setAliasSpecificLockMode( alias, lockMode );
 		return this;
 	}
-	
+
 	public Query setLockOptions(LockOptions lockOption) {
-		this.lockOptions.setLockMode(lockOption.getLockMode());
-		this.lockOptions.setScope(lockOption.getScope());
-		this.lockOptions.setTimeOut(lockOption.getTimeOut());
+		this.lockOptions.setLockMode( lockOption.getLockMode() );
+		this.lockOptions.setScope( lockOption.getScope() );
+		this.lockOptions.setTimeOut( lockOption.getTimeOut() );
 		return this;
 	}
 
 	public LockOptions getLockOptions() {
 		return lockOptions;
 	}
 
 	public boolean isSelect() {
 		return getSession().getFactory().getQueryPlanCache()
 				.getHQLQueryPlan( getQueryString(), false, Collections.<String, Filter>emptyMap() )
 				.isSelect();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SQLQueryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SQLQueryImpl.java
index 6f5bc091e4..26c317ede4 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SQLQueryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SQLQueryImpl.java
@@ -1,502 +1,512 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
+
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryConstructorReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryJoinReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryScalarReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.type.Type;
 
 /**
  * Implementation of the {@link SQLQuery} contract.
  *
  * @author Max Andersen
  * @author Steve Ebersole
  */
 public class SQLQueryImpl extends AbstractQueryImpl implements SQLQuery {
 
 	private List<NativeSQLQueryReturn> queryReturns;
 	private List<ReturnBuilder> queryReturnBuilders;
 	private boolean autoDiscoverTypes;
 
 	private Collection<String> querySpaces;
 
 	private final boolean callable;
 	private final LockOptions lockOptions = new LockOptions();
 
 	/**
 	 * Constructs a SQLQueryImpl given a sql query defined in the mappings.
 	 *
 	 * @param queryDef The representation of the defined <sql-query/>.
 	 * @param session The session to which this SQLQueryImpl belongs.
 	 * @param parameterMetadata Metadata about parameters found in the query.
 	 */
 	SQLQueryImpl(NamedSQLQueryDefinition queryDef, SessionImplementor session, ParameterMetadata parameterMetadata) {
 		super( queryDef.getQueryString(), queryDef.getFlushMode(), session, parameterMetadata );
 		if ( queryDef.getResultSetRef() != null ) {
 			ResultSetMappingDefinition definition = session.getFactory()
 					.getResultSetMapping( queryDef.getResultSetRef() );
-			if (definition == null) {
+			if ( definition == null ) {
 				throw new MappingException(
 						"Unable to find resultset-ref definition: " +
-						queryDef.getResultSetRef()
-					);
+								queryDef.getResultSetRef()
+				);
 			}
-			this.queryReturns = new ArrayList<NativeSQLQueryReturn>(Arrays.asList( definition.getQueryReturns() ));
+			this.queryReturns = new ArrayList<NativeSQLQueryReturn>( Arrays.asList( definition.getQueryReturns() ) );
 		}
 		else if ( queryDef.getQueryReturns() != null && queryDef.getQueryReturns().length > 0 ) {
-			this.queryReturns = new ArrayList<NativeSQLQueryReturn>(Arrays.asList( queryDef.getQueryReturns()));
+			this.queryReturns = new ArrayList<NativeSQLQueryReturn>( Arrays.asList( queryDef.getQueryReturns() ) );
 		}
 		else {
 			this.queryReturns = new ArrayList<NativeSQLQueryReturn>();
 		}
 
 		this.querySpaces = queryDef.getQuerySpaces();
 		this.callable = queryDef.isCallable();
 	}
 
 	SQLQueryImpl(String sql, SessionImplementor session, ParameterMetadata parameterMetadata) {
 		this( sql, false, session, parameterMetadata );
 	}
 
 	SQLQueryImpl(String sql, boolean callable, SessionImplementor session, ParameterMetadata parameterMetadata) {
 		super( sql, null, session, parameterMetadata );
 		this.queryReturns = new ArrayList<NativeSQLQueryReturn>();
 		this.querySpaces = null;
 		this.callable = callable;
 	}
 
 	@Override
-	public List<NativeSQLQueryReturn>  getQueryReturns() {
+	public List<NativeSQLQueryReturn> getQueryReturns() {
 		prepareQueryReturnsIfNecessary();
 		return queryReturns;
 	}
 
 	@Override
 	public Collection<String> getSynchronizedQuerySpaces() {
 		return querySpaces;
 	}
 
 	@Override
 	public boolean isCallable() {
 		return callable;
 	}
 
 	@Override
 	public List list() throws HibernateException {
 		verifyParameters();
 		before();
 
 		Map namedParams = getNamedParams();
 		NativeSQLQuerySpecification spec = generateQuerySpecification( namedParams );
 
 		try {
 			return getSession().list( spec, getQueryParameters( namedParams ) );
 		}
 		finally {
 			after();
 		}
 	}
 
 	private NativeSQLQuerySpecification generateQuerySpecification(Map namedParams) {
 		return new NativeSQLQuerySpecification(
-		        expandParameterLists(namedParams),
+				expandParameterLists( namedParams ),
 				queryReturns.toArray( new NativeSQLQueryReturn[queryReturns.size()] ),
-		        querySpaces
+				querySpaces
 		);
 	}
 
 	public ScrollableResults scroll(ScrollMode scrollMode) throws HibernateException {
 		verifyParameters();
 		before();
 
 		Map namedParams = getNamedParams();
 		NativeSQLQuerySpecification spec = generateQuerySpecification( namedParams );
 
 		QueryParameters qp = getQueryParameters( namedParams );
 		qp.setScrollMode( scrollMode );
 
 		try {
 			return getSession().scroll( spec, qp );
 		}
 		finally {
 			after();
 		}
 	}
 
 	public ScrollableResults scroll() throws HibernateException {
 		return scroll( session.getFactory().getDialect().defaultScrollMode() );
 	}
 
 	public Iterator iterate() throws HibernateException {
-		throw new UnsupportedOperationException("SQL queries do not currently support iteration");
+		throw new UnsupportedOperationException( "SQL queries do not currently support iteration" );
 	}
 
 	@Override
-    public QueryParameters getQueryParameters(Map namedParams) {
-		QueryParameters qp = super.getQueryParameters(namedParams);
-		qp.setCallable(callable);
+	public QueryParameters getQueryParameters(Map namedParams) {
+		QueryParameters qp = super.getQueryParameters( namedParams );
+		qp.setCallable( callable );
 		qp.setAutoDiscoverScalarTypes( autoDiscoverTypes );
 		return qp;
 	}
 
 	@Override
-    protected void verifyParameters() {
+	protected void verifyParameters() {
 		// verifyParameters is called at the start of all execution type methods, so we use that here to perform
 		// some preparation work.
 		prepareQueryReturnsIfNecessary();
 		verifyParameters( callable );
-		boolean noReturns = queryReturns==null || queryReturns.isEmpty();
+		boolean noReturns = queryReturns == null || queryReturns.isEmpty();
 		if ( noReturns ) {
 			this.autoDiscoverTypes = noReturns;
 		}
 		else {
 			for ( NativeSQLQueryReturn queryReturn : queryReturns ) {
 				if ( queryReturn instanceof NativeSQLQueryScalarReturn ) {
 					NativeSQLQueryScalarReturn scalar = (NativeSQLQueryScalarReturn) queryReturn;
 					if ( scalar.getType() == null ) {
 						autoDiscoverTypes = true;
 						break;
 					}
 				}
 				else if ( NativeSQLQueryConstructorReturn.class.isInstance( queryReturn ) ) {
 					autoDiscoverTypes = true;
 					break;
 				}
 			}
 		}
 	}
 
 	private void prepareQueryReturnsIfNecessary() {
 		if ( queryReturnBuilders != null ) {
-			if ( ! queryReturnBuilders.isEmpty() ) {
+			if ( !queryReturnBuilders.isEmpty() ) {
 				if ( queryReturns != null ) {
 					queryReturns.clear();
 					queryReturns = null;
 				}
 				queryReturns = new ArrayList<NativeSQLQueryReturn>();
 				for ( ReturnBuilder builder : queryReturnBuilders ) {
 					queryReturns.add( builder.buildReturn() );
 				}
 				queryReturnBuilders.clear();
 			}
 			queryReturnBuilders = null;
 		}
 	}
 
 	@Override
-    public String[] getReturnAliases() throws HibernateException {
-		throw new UnsupportedOperationException("SQL queries do not currently support returning aliases");
+	public String[] getReturnAliases() throws HibernateException {
+		throw new UnsupportedOperationException( "SQL queries do not currently support returning aliases" );
 	}
 
 	@Override
-    public Type[] getReturnTypes() throws HibernateException {
-		throw new UnsupportedOperationException("not yet implemented for SQL queries");
+	public Type[] getReturnTypes() throws HibernateException {
+		throw new UnsupportedOperationException( "not yet implemented for SQL queries" );
 	}
 
 	public Query setLockMode(String alias, LockMode lockMode) {
-		throw new UnsupportedOperationException("cannot set the lock mode for a native SQL query");
+		throw new UnsupportedOperationException( "cannot set the lock mode for a native SQL query" );
 	}
 
 	public Query setLockOptions(LockOptions lockOptions) {
-		throw new UnsupportedOperationException("cannot set lock options for a native SQL query");
+		throw new UnsupportedOperationException( "cannot set lock options for a native SQL query" );
 	}
 
 	@Override
-    public LockOptions getLockOptions() {
+	public LockOptions getLockOptions() {
 		//we never need to apply locks to the SQL, however the native-sql loader handles this specially
 		return lockOptions;
 	}
 
 	public SQLQuery addScalar(final String columnAlias, final Type type) {
 		if ( queryReturnBuilders == null ) {
 			queryReturnBuilders = new ArrayList<ReturnBuilder>();
 		}
 		queryReturnBuilders.add(
 				new ReturnBuilder() {
 					public NativeSQLQueryReturn buildReturn() {
 						return new NativeSQLQueryScalarReturn( columnAlias, type );
 					}
 				}
 		);
 		return this;
 	}
 
 	public SQLQuery addScalar(String columnAlias) {
 		return addScalar( columnAlias, null );
 	}
 
 	public RootReturn addRoot(String tableAlias, String entityName) {
 		RootReturnBuilder builder = new RootReturnBuilder( tableAlias, entityName );
 		if ( queryReturnBuilders == null ) {
 			queryReturnBuilders = new ArrayList<ReturnBuilder>();
 		}
 		queryReturnBuilders.add( builder );
 		return builder;
 	}
 
 	public RootReturn addRoot(String tableAlias, Class entityType) {
 		return addRoot( tableAlias, entityType.getName() );
 	}
 
 	public SQLQuery addEntity(String entityName) {
 		return addEntity( StringHelper.unqualify( entityName ), entityName );
 	}
 
 	public SQLQuery addEntity(String alias, String entityName) {
 		addRoot( alias, entityName );
 		return this;
 	}
 
 	public SQLQuery addEntity(String alias, String entityName, LockMode lockMode) {
 		addRoot( alias, entityName ).setLockMode( lockMode );
 		return this;
 	}
 
 	public SQLQuery addEntity(Class entityType) {
 		return addEntity( entityType.getName() );
 	}
 
 	public SQLQuery addEntity(String alias, Class entityClass) {
 		return addEntity( alias, entityClass.getName() );
 	}
 
 	public SQLQuery addEntity(String alias, Class entityClass, LockMode lockMode) {
 		return addEntity( alias, entityClass.getName(), lockMode );
 	}
 
 	public FetchReturn addFetch(String tableAlias, String ownerTableAlias, String joinPropertyName) {
 		FetchReturnBuilder builder = new FetchReturnBuilder( tableAlias, ownerTableAlias, joinPropertyName );
 		if ( queryReturnBuilders == null ) {
 			queryReturnBuilders = new ArrayList<ReturnBuilder>();
 		}
 		queryReturnBuilders.add( builder );
 		return builder;
 	}
 
 	public SQLQuery addJoin(String tableAlias, String ownerTableAlias, String joinPropertyName) {
 		addFetch( tableAlias, ownerTableAlias, joinPropertyName );
 		return this;
 	}
 
 	public SQLQuery addJoin(String alias, String path) {
 		createFetchJoin( alias, path );
 		return this;
 	}
 
 	private FetchReturn createFetchJoin(String tableAlias, String path) {
-		int loc = path.indexOf('.');
+		int loc = path.indexOf( '.' );
 		if ( loc < 0 ) {
 			throw new QueryException( "not a property path: " + path );
 		}
 		final String ownerTableAlias = path.substring( 0, loc );
-		final String joinedPropertyName = path.substring( loc+1 );
+		final String joinedPropertyName = path.substring( loc + 1 );
 		return addFetch( tableAlias, ownerTableAlias, joinedPropertyName );
 	}
 
 	public SQLQuery addJoin(String alias, String path, LockMode lockMode) {
 		createFetchJoin( alias, path ).setLockMode( lockMode );
 		return this;
 	}
 
 	public SQLQuery setResultSetMapping(String name) {
 		ResultSetMappingDefinition mapping = session.getFactory().getResultSetMapping( name );
 		if ( mapping == null ) {
 			throw new MappingException( "Unknown SqlResultSetMapping [" + name + "]" );
 		}
 		NativeSQLQueryReturn[] returns = mapping.getQueryReturns();
 		queryReturns.addAll( Arrays.asList( returns ) );
 		return this;
 	}
 
 	public SQLQuery addSynchronizedQuerySpace(String querySpace) {
 		if ( querySpaces == null ) {
 			querySpaces = new ArrayList<String>();
 		}
 		querySpaces.add( querySpace );
 		return this;
 	}
 
 	public SQLQuery addSynchronizedEntityName(String entityName) {
 		return addQuerySpaces( getSession().getFactory().getEntityPersister( entityName ).getQuerySpaces() );
 	}
 
 	public SQLQuery addSynchronizedEntityClass(Class entityClass) {
 		return addQuerySpaces( getSession().getFactory().getEntityPersister( entityClass.getName() ).getQuerySpaces() );
 	}
 
 	private SQLQuery addQuerySpaces(Serializable[] spaces) {
 		if ( spaces != null ) {
 			if ( querySpaces == null ) {
 				querySpaces = new ArrayList<String>();
 			}
 			querySpaces.addAll( Arrays.asList( (String[]) spaces ) );
 		}
 		return this;
 	}
 
 	public int executeUpdate() throws HibernateException {
 		Map namedParams = getNamedParams();
 		before();
 		try {
 			return getSession().executeNativeUpdate(
 					generateQuerySpecification( namedParams ),
 					getQueryParameters( namedParams )
 			);
 		}
 		finally {
 			after();
 		}
 	}
 
 	private class RootReturnBuilder implements RootReturn, ReturnBuilder {
 		private final String alias;
 		private final String entityName;
 		private LockMode lockMode = LockMode.READ;
-		private Map<String,String[]> propertyMappings;
+		private Map<String, String[]> propertyMappings;
 
 		private RootReturnBuilder(String alias, String entityName) {
 			this.alias = alias;
 			this.entityName = entityName;
 		}
 
 		public RootReturn setLockMode(LockMode lockMode) {
 			this.lockMode = lockMode;
 			return this;
 		}
 
 		public RootReturn setDiscriminatorAlias(String alias) {
 			addProperty( "class", alias );
 			return this;
 		}
 
 		public RootReturn addProperty(String propertyName, String columnAlias) {
 			addProperty( propertyName ).addColumnAlias( columnAlias );
 			return this;
 		}
 
 		public ReturnProperty addProperty(final String propertyName) {
 			if ( propertyMappings == null ) {
-				propertyMappings = new HashMap<String,String[]>();
+				propertyMappings = new HashMap<String, String[]>();
 			}
 			return new ReturnProperty() {
 				public ReturnProperty addColumnAlias(String columnAlias) {
 					String[] columnAliases = propertyMappings.get( propertyName );
 					if ( columnAliases == null ) {
-						columnAliases = new String[]{columnAlias};
-					}else{
-						 String[] newColumnAliases = new String[columnAliases.length + 1];
+						columnAliases = new String[] {columnAlias};
+					}
+					else {
+						String[] newColumnAliases = new String[columnAliases.length + 1];
 						System.arraycopy( columnAliases, 0, newColumnAliases, 0, columnAliases.length );
 						newColumnAliases[columnAliases.length] = columnAlias;
 						columnAliases = newColumnAliases;
 					}
-					propertyMappings.put( propertyName,columnAliases );
+					propertyMappings.put( propertyName, columnAliases );
 					return this;
 				}
 			};
 		}
 
 		public NativeSQLQueryReturn buildReturn() {
 			return new NativeSQLQueryRootReturn( alias, entityName, propertyMappings, lockMode );
 		}
 	}
+
 	private class FetchReturnBuilder implements FetchReturn, ReturnBuilder {
 		private final String alias;
 		private String ownerTableAlias;
 		private final String joinedPropertyName;
 		private LockMode lockMode = LockMode.READ;
-		private Map<String,String[]> propertyMappings;
+		private Map<String, String[]> propertyMappings;
 
 		private FetchReturnBuilder(String alias, String ownerTableAlias, String joinedPropertyName) {
 			this.alias = alias;
 			this.ownerTableAlias = ownerTableAlias;
 			this.joinedPropertyName = joinedPropertyName;
 		}
 
 		public FetchReturn setLockMode(LockMode lockMode) {
 			this.lockMode = lockMode;
 			return this;
 		}
 
 		public FetchReturn addProperty(String propertyName, String columnAlias) {
 			addProperty( propertyName ).addColumnAlias( columnAlias );
 			return this;
 		}
 
 		public ReturnProperty addProperty(final String propertyName) {
 			if ( propertyMappings == null ) {
-				propertyMappings = new HashMap<String,String[]>();
+				propertyMappings = new HashMap<String, String[]>();
 			}
 			return new ReturnProperty() {
 				public ReturnProperty addColumnAlias(String columnAlias) {
 					String[] columnAliases = propertyMappings.get( propertyName );
 					if ( columnAliases == null ) {
-						columnAliases = new String[]{columnAlias};
-					}else{
-						 String[] newColumnAliases = new String[columnAliases.length + 1];
+						columnAliases = new String[] {columnAlias};
+					}
+					else {
+						String[] newColumnAliases = new String[columnAliases.length + 1];
 						System.arraycopy( columnAliases, 0, newColumnAliases, 0, columnAliases.length );
 						newColumnAliases[columnAliases.length] = columnAlias;
 						columnAliases = newColumnAliases;
 					}
-					propertyMappings.put( propertyName,columnAliases );
+					propertyMappings.put( propertyName, columnAliases );
 					return this;
 				}
 			};
 		}
 
 		public NativeSQLQueryReturn buildReturn() {
-			return new NativeSQLQueryJoinReturn( alias, ownerTableAlias, joinedPropertyName, propertyMappings, lockMode );
+			return new NativeSQLQueryJoinReturn(
+					alias,
+					ownerTableAlias,
+					joinedPropertyName,
+					propertyMappings,
+					lockMode
+			);
 		}
 	}
 
 	private interface ReturnBuilder {
 		NativeSQLQueryReturn buildReturn();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/ScrollableResultsImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/ScrollableResultsImpl.java
index e6fcb9adaa..adaa9e38bb 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/ScrollableResultsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/ScrollableResultsImpl.java
@@ -1,257 +1,229 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
+import org.hibernate.JDBCException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.loader.Loader;
 import org.hibernate.type.Type;
 
 /**
  * Standard ScrollableResults implementation.
  *
  * @author Gavin King
  */
 public class ScrollableResultsImpl extends AbstractScrollableResults implements ScrollableResults {
 	private Object[] currentRow;
 
 	/**
 	 * Constructs a ScrollableResultsImpl using the specified information.
 	 *
 	 * @param rs The scrollable result set
 	 * @param ps The prepared statement used to obtain the result set
 	 * @param sess The originating session
 	 * @param loader The loader
 	 * @param queryParameters query parameters
 	 * @param types The result types
 	 * @param holderInstantiator Ugh
 	 */
 	public ScrollableResultsImpl(
-	        ResultSet rs,
-	        PreparedStatement ps,
-	        SessionImplementor sess,
-	        Loader loader,
-	        QueryParameters queryParameters,
-	        Type[] types, HolderInstantiator holderInstantiator) {
+			ResultSet rs,
+			PreparedStatement ps,
+			SessionImplementor sess,
+			Loader loader,
+			QueryParameters queryParameters,
+			Type[] types, HolderInstantiator holderInstantiator) {
 		super( rs, ps, sess, loader, queryParameters, types, holderInstantiator );
 	}
 
 	@Override
 	protected Object[] getCurrentRow() {
 		return currentRow;
 	}
 
 	@Override
 	public boolean scroll(int i) {
 		try {
-			final boolean result = getResultSet().relative(i);
-			prepareCurrentRow(result);
+			final boolean result = getResultSet().relative( i );
+			prepareCurrentRow( result );
 			return result;
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"could not advance using scroll()"
-			);
+			throw convert( sqle, "could not advance using scroll()" );
 		}
 	}
 
+	protected JDBCException convert(SQLException sqle, String message) {
+		return getSession().getFactory().getSQLExceptionHelper().convert( sqle, message );
+	}
+
 	@Override
 	public boolean first() {
 		try {
 			final boolean result = getResultSet().first();
-			prepareCurrentRow(result);
+			prepareCurrentRow( result );
 			return result;
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"could not advance using first()"
-			);
+			throw convert( sqle, "could not advance using first()" );
 		}
 	}
 
 	@Override
 	public boolean last() {
 		try {
 			final boolean result = getResultSet().last();
-			prepareCurrentRow(result);
+			prepareCurrentRow( result );
 			return result;
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"could not advance using last()"
-			);
+			throw convert( sqle, "could not advance using last()" );
 		}
 	}
 
 	@Override
 	public boolean next() {
 		try {
 			final boolean result = getResultSet().next();
-			prepareCurrentRow(result);
+			prepareCurrentRow( result );
 			return result;
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"could not advance using next()"
-			);
+			throw convert( sqle, "could not advance using next()" );
 		}
 	}
 
 	@Override
 	public boolean previous() {
 		try {
 			final boolean result = getResultSet().previous();
-			prepareCurrentRow(result);
+			prepareCurrentRow( result );
 			return result;
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"could not advance using previous()"
-			);
+			throw convert( sqle, "could not advance using previous()" );
 		}
 	}
 
 	@Override
 	public void afterLast() {
 		try {
 			getResultSet().afterLast();
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"exception calling afterLast()"
-			);
+			throw convert( sqle, "exception calling afterLast()" );
 		}
 	}
 
 	@Override
 	public void beforeFirst() {
 		try {
 			getResultSet().beforeFirst();
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"exception calling beforeFirst()"
-			);
+			throw convert( sqle, "exception calling beforeFirst()" );
 		}
 	}
 
 	@Override
 	public boolean isFirst() {
 		try {
 			return getResultSet().isFirst();
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"exception calling isFirst()"
-			);
+			throw convert( sqle, "exception calling isFirst()" );
 		}
 	}
 
 	@Override
 	public boolean isLast() {
 		try {
 			return getResultSet().isLast();
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"exception calling isLast()"
-			);
+			throw convert( sqle, "exception calling isLast()" );
 		}
 	}
 
 	@Override
 	public int getRowNumber() throws HibernateException {
 		try {
-			return getResultSet().getRow()-1;
+			return getResultSet().getRow() - 1;
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"exception calling getRow()"
-			);
+			throw convert( sqle, "exception calling getRow()" );
 		}
 	}
 
 	@Override
 	public boolean setRowNumber(int rowNumber) throws HibernateException {
 		if ( rowNumber >= 0 ) {
 			rowNumber++;
 		}
 
 		try {
-			final boolean result = getResultSet().absolute(rowNumber);
-			prepareCurrentRow(result);
+			final boolean result = getResultSet().absolute( rowNumber );
+			prepareCurrentRow( result );
 			return result;
 		}
 		catch (SQLException sqle) {
-			throw getSession().getFactory().getSQLExceptionHelper().convert(
-					sqle,
-					"could not advance using absolute()"
-			);
+			throw convert( sqle, "could not advance using absolute()" );
 		}
 	}
 
 	private void prepareCurrentRow(boolean underlyingScrollSuccessful) {
 		if ( !underlyingScrollSuccessful ) {
 			currentRow = null;
 			return;
 		}
 
 		final Object result = getLoader().loadSingleRow(
 				getResultSet(),
 				getSession(),
 				getQueryParameters(),
 				false
 		);
 		if ( result != null && result.getClass().isArray() ) {
 			currentRow = (Object[]) result;
 		}
 		else {
-			currentRow = new Object[] { result };
+			currentRow = new Object[] {result};
 		}
 
 		if ( getHolderInstantiator() != null ) {
-			currentRow = new Object[] { getHolderInstantiator().instantiate(currentRow) };
+			currentRow = new Object[] {getHolderInstantiator().instantiate( currentRow )};
 		}
 
 		afterScrollOperation();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
index ab3cc2b683..a2f556e8c7 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
@@ -1,1535 +1,1535 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.StatelessSession;
 import org.hibernate.StatelessSessionBuilder;
 import org.hibernate.Transaction;
 import org.hibernate.TypeHelper;
 import org.hibernate.boot.cfgxml.spi.CfgXmlAccessService;
 import org.hibernate.boot.cfgxml.spi.LoadedConfig;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.internal.CacheDataDescriptionImpl;
 import org.hibernate.cache.spi.CollectionRegion;
 import org.hibernate.cache.spi.EntityRegion;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
 import org.hibernate.context.internal.JTASessionContext;
 import org.hibernate.context.internal.ManagedSessionContext;
 import org.hibernate.context.internal.ThreadLocalSessionContext;
 import org.hibernate.context.spi.CurrentSessionContext;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider;
 import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jndi.spi.JndiService;
 import org.hibernate.engine.profile.Association;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.spi.QueryPlanCache;
 import org.hibernate.engine.query.spi.ReturnMetadata;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CacheImplementor;
 import org.hibernate.engine.spi.FilterDefinition;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionBuilderImplementor;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.integrator.spi.IntegratorService;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.config.ConfigurationException;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.persister.spi.PersisterFactory;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.secure.spi.GrantedPermission;
 import org.hibernate.secure.spi.JaccPermissionDeclarations;
 import org.hibernate.secure.spi.JaccService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistryFactory;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.tool.hbm2ddl.ImportSqlCommandExtractor;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 import org.hibernate.tool.hbm2ddl.SchemaValidator;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
 
 /**
  * Concrete implementation of the <tt>SessionFactory</tt> interface. Has the following
  * responsibilities
  * <ul>
  * <li>caches configuration settings (immutably)
  * <li>caches "compiled" mappings ie. <tt>EntityPersister</tt>s and
  *     <tt>CollectionPersister</tt>s (immutable)
  * <li>caches "compiled" queries (memory sensitive cache)
  * <li>manages <tt>PreparedStatement</tt>s
  * <li> delegates JDBC <tt>Connection</tt> management to the <tt>ConnectionProvider</tt>
  * <li>factory for instances of <tt>SessionImpl</tt>
  * </ul>
  * This class must appear immutable to clients, even if it does all kinds of caching
  * and pooling under the covers. It is crucial that the class is not only thread
  * safe, but also highly concurrent. Synchronization must be used extremely sparingly.
  *
  * @see org.hibernate.engine.jdbc.connections.spi.ConnectionProvider
  * @see org.hibernate.Session
  * @see org.hibernate.hql.spi.QueryTranslator
  * @see org.hibernate.persister.entity.EntityPersister
  * @see org.hibernate.persister.collection.CollectionPersister
  * @author Gavin King
  */
 public final class SessionFactoryImpl implements SessionFactoryImplementor {
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SessionFactoryImpl.class );
 
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class,
-			SessionFactoryImpl.class.getName()
-	);
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
 	private final String name;
 	private final String uuid;
 
 	private final transient Map<String,EntityPersister> entityPersisters;
 	private final transient Map<String,ClassMetadata> classMetadata;
 	private final transient Map<Class,String> entityProxyInterfaceMap;
 	private final transient Map<String,CollectionPersister> collectionPersisters;
 	private final transient Map<String,CollectionMetadata> collectionMetadata;
 	private final transient Map<String,Set<String>> collectionRolesByEntityParticipant;
 	private final transient Map<String,IdentifierGenerator> identifierGenerators;
 	private final transient NamedQueryRepository namedQueryRepository;
 	private final transient Map<String, FilterDefinition> filters;
 	private final transient Map<String, FetchProfile> fetchProfiles;
 	private final transient Map<String,String> imports;
 	private final transient SessionFactoryServiceRegistry serviceRegistry;
 	private final transient JdbcServices jdbcServices;
 	private final transient Dialect dialect;
 	private final transient Settings settings;
 	private final transient Properties properties;
 	private transient SchemaExport schemaExport;
 	private final transient CurrentSessionContext currentSessionContext;
 	private final transient SQLFunctionRegistry sqlFunctionRegistry;
 	private final transient SessionFactoryObserverChain observer = new SessionFactoryObserverChain();
 	private final transient ConcurrentMap<EntityNameResolver,Object> entityNameResolvers = new ConcurrentHashMap<EntityNameResolver, Object>();
 	private final transient QueryPlanCache queryPlanCache;
 	private final transient CacheImplementor cacheAccess;
 	private transient boolean isClosed;
 	private final transient TypeResolver typeResolver;
 	private final transient TypeHelper typeHelper;
 	private final transient SessionFactoryOptions sessionFactoryOptions;
 
 	public SessionFactoryImpl(final MetadataImplementor metadata, SessionFactoryOptions options) {
 		LOG.debug( "Building session factory" );
 
 		this.sessionFactoryOptions = options;
 		this.settings = new Settings( options, metadata );
 
 		this.serviceRegistry = options.getServiceRegistry()
 				.getService( SessionFactoryServiceRegistryFactory.class )
 				.buildServiceRegistry( this, options );
 
 		final CfgXmlAccessService cfgXmlAccessService = serviceRegistry.getService( CfgXmlAccessService.class );
 
 		String sfName = settings.getSessionFactoryName();
 		if ( cfgXmlAccessService.getAggregatedConfig() != null ) {
 			if ( sfName == null ) {
 				sfName = cfgXmlAccessService.getAggregatedConfig().getSessionFactoryName();
 			}
 			applyCfgXmlValues( cfgXmlAccessService.getAggregatedConfig(), serviceRegistry );
 		}
 
 		this.name = sfName;
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 
 		this.properties = new Properties();
 		this.properties.putAll( serviceRegistry.getService( ConfigurationService.class ).getSettings() );
 
 		this.jdbcServices = this.serviceRegistry.getService( JdbcServices.class );
 		this.dialect = this.jdbcServices.getDialect();
 		this.cacheAccess = this.serviceRegistry.getService( CacheImplementor.class );
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), options.getCustomSqlFunctionMap() );
 
 		for ( SessionFactoryObserver sessionFactoryObserver : options.getSessionFactoryObservers() ) {
 			this.observer.addObserver( sessionFactoryObserver );
 		}
 
 		this.typeResolver = metadata.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap<String, FilterDefinition>();
 		this.filters.putAll( metadata.getFilterDefinitions() );
 
 		LOG.debugf( "Session factory constructed with filter configurations : %s", filters );
 		LOG.debugf( "Instantiating session factory with properties: %s", properties );
 
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
 				integrators.clear();
 			}
 		}
 		final IntegratorObserver integratorObserver = new IntegratorObserver();
 		this.observer.addObserver( integratorObserver );
 		for ( Integrator integrator : serviceRegistry.getService( IntegratorService.class ).getIntegrators() ) {
 			integrator.integrate( metadata, this, this.serviceRegistry );
 			integratorObserver.integrators.add( integrator );
 		}
 
 		//Generators:
 
 		this.identifierGenerators = new HashMap<String, IdentifierGenerator>();
 		for ( PersistentClass model : metadata.getEntityBindings() ) {
 			if ( !model.isInherited() ) {
 				IdentifierGenerator generator = model.getIdentifier().createIdentifierGenerator(
 						metadata.getIdentifierGeneratorFactory(),
 						getDialect(),
 						settings.getDefaultCatalogName(),
 						settings.getDefaultSchemaName(),
 						(RootClass) model
 				);
 				identifierGenerators.put( model.getEntityName(), generator );
 			}
 		}
 
 		this.imports = new HashMap<String,String>( metadata.getImports() );
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		final PersisterCreationContext persisterCreationContext = new PersisterCreationContext() {
 			@Override
 			public SessionFactoryImplementor getSessionFactory() {
 				return SessionFactoryImpl.this;
 			}
 
 			@Override
 			public MetadataImplementor getMetadata() {
 				return metadata;
 			}
 		};
 
 		final RegionFactory regionFactory = cacheAccess.getRegionFactory();
 		final String cacheRegionPrefix = settings.getCacheRegionPrefix() == null ? "" : settings.getCacheRegionPrefix() + ".";
 		final PersisterFactory persisterFactory = serviceRegistry.getService( PersisterFactory.class );
 
 		// todo : consider removing this silliness and just have EntityPersister directly implement ClassMetadata
 		//		EntityPersister.getClassMetadata() for the internal impls simply "return this";
 		//		collapsing those would allow us to remove this "extra" Map
 		//
 		// todo : similar for CollectionPersister/CollectionMetadata
 
 		this.entityPersisters = new HashMap<String,EntityPersister>();
 		Map cacheAccessStrategiesMap = new HashMap();
 		Map<String,ClassMetadata> inFlightClassMetadataMap = new HashMap<String,ClassMetadata>();
 		this.entityProxyInterfaceMap = CollectionHelper.concurrentMap( metadata.getEntityBindings().size() );
 		for ( final PersistentClass model : metadata.getEntityBindings() ) {
 			final String cacheRegionName = cacheRegionPrefix + model.getRootClass().getCacheRegionName();
 			// cache region is defined by the root-class in the hierarchy...
 			final EntityRegionAccessStrategy accessStrategy = determineEntityRegionAccessStrategy(
 					regionFactory,
 					cacheAccessStrategiesMap,
 					model,
 					cacheRegionName
 			);
 
 			final NaturalIdRegionAccessStrategy naturalIdAccessStrategy = determineNaturalIdRegionAccessStrategy(
 					regionFactory,
 					cacheRegionPrefix,
 					cacheAccessStrategiesMap,
 					model
 			);
 
 			final EntityPersister cp = persisterFactory.createEntityPersister(
 					model,
 					accessStrategy,
 					naturalIdAccessStrategy,
 					persisterCreationContext
 			);
 			entityPersisters.put( model.getEntityName(), cp );
 			inFlightClassMetadataMap.put( model.getEntityName(), cp.getClassMetadata() );
 
 			if ( cp.getConcreteProxyClass() != null
 					&& cp.getConcreteProxyClass().isInterface()
 					&& !Map.class.isAssignableFrom( cp.getConcreteProxyClass() )
 					&& cp.getMappedClass() != cp.getConcreteProxyClass() ) {
 				// IMPL NOTE : we exclude Map based proxy interfaces here because that should
 				//		indicate MAP entity mode.0
 
 				if ( cp.getMappedClass().equals( cp.getConcreteProxyClass() ) ) {
 					// this part handles an odd case in the Hibernate test suite where we map an interface
 					// as the class and the proxy.  I cannot think of a real life use case for that
 					// specific test, but..
 					LOG.debugf( "Entity [%s] mapped same interface [%s] as class and proxy", cp.getEntityName(), cp.getMappedClass() );
 				}
 				else {
 					final String old = entityProxyInterfaceMap.put( cp.getConcreteProxyClass(), cp.getEntityName() );
 					if ( old != null ) {
 						throw new HibernateException(
 								String.format(
 										Locale.ENGLISH,
 										"Multiple entities [%s, %s] named the same interface [%s] as their proxy which is not supported",
 										old,
 										cp.getEntityName(),
 										cp.getConcreteProxyClass().getName()
 								)
 						);
 					}
 				}
 			}
 		}
 		this.classMetadata = Collections.unmodifiableMap( inFlightClassMetadataMap );
 
 		this.collectionPersisters = new HashMap<String,CollectionPersister>();
 		Map<String,Set<String>> inFlightEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		Map<String,CollectionMetadata> tmpCollectionMetadata = new HashMap<String,CollectionMetadata>();
 		for ( final Collection model : metadata.getCollectionBindings() ) {
 			final String cacheRegionName = cacheRegionPrefix + model.getCacheRegionName();
 			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			final CollectionRegionAccessStrategy accessStrategy;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
 				LOG.tracev( "Building shared cache region for collection data [{0}]", model.getRole() );
 				CollectionRegion collectionRegion = regionFactory.buildCollectionRegion(
 						cacheRegionName,
 						properties,
 						CacheDataDescriptionImpl.decode( model )
 				);
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				cacheAccessStrategiesMap.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion( cacheRegionName, collectionRegion );
 			}
 			else {
 				accessStrategy = null;
 			}
 
 			final CollectionPersister persister = persisterFactory.createCollectionPersister(
 					model,
 					accessStrategy,
 					persisterCreationContext
 			);
 			collectionPersisters.put( model.getRole(), persister );
 			tmpCollectionMetadata.put( model.getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set<String> roles = inFlightEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					inFlightEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set<String> roles = inFlightEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					inFlightEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		this.collectionMetadata = Collections.unmodifiableMap( tmpCollectionMetadata );
 
 		for ( Map.Entry<String,Set<String>> entityToCollectionRoleMapEntry : inFlightEntityToCollectionRoleMap.entrySet() ) {
 			entityToCollectionRoleMapEntry.setValue(
 					Collections.unmodifiableSet( entityToCollectionRoleMapEntry.getValue() )
 			);
 		}
 		this.collectionRolesByEntityParticipant = Collections.unmodifiableMap( inFlightEntityToCollectionRoleMap );
 
 		//Named Queries:
 		this.namedQueryRepository = metadata.buildNamedQueryRepository( this );
 
 		// after *all* persisters and named queries are registered
 		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.generateEntityDefinition();
 		}
 
 		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 		}
 		for ( CollectionPersister persister : collectionPersisters.values() ) {
 			persister.postInstantiate();
 		}
 
 		LOG.debug( "Instantiated session factory" );
 
 		settings.getMultiTableBulkIdStrategy().prepare(
 				jdbcServices,
 				buildLocalConnectionAccess(),
 				metadata,
 				sessionFactoryOptions
 		);
 
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( serviceRegistry, metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) )
 					.create( false, true );
 		}
 		if ( settings.isAutoUpdateSchema() ) {
 			new SchemaUpdate( serviceRegistry, metadata ).execute( false, true );
 		}
 		if ( settings.isAutoValidateSchema() ) {
 			new SchemaValidator( serviceRegistry, metadata ).validate();
 		}
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( serviceRegistry, metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			final Map<String,HibernateException> errors = checkNamedQueries();
 			if ( ! errors.isEmpty() ) {
 				StringBuilder failingQueries = new StringBuilder( "Errors in named queries: " );
 				String sep = "";
 				for ( Map.Entry<String,HibernateException> entry : errors.entrySet() ) {
 					LOG.namedQueryError( entry.getKey(), entry.getValue() );
 					failingQueries.append( sep ).append( entry.getKey() );
 					sep = ", ";
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap<String,FetchProfile>();
 		for ( org.hibernate.mapping.FetchProfile mappingProfile : metadata.getFetchProfiles() ) {
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			for ( org.hibernate.mapping.FetchProfile.Fetch mappingFetch : mappingProfile.getFetches() ) {
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = entityName == null
 						? null
 						: entityPersisters.get( entityName );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || !associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				((Loadable) owner).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.observer.sessionFactoryCreated( this );
 
 		SessionFactoryRegistry.INSTANCE.addSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				this,
 				serviceRegistry.getService( JndiService.class )
 		);
 	}
 
 	private void applyCfgXmlValues(LoadedConfig aggregatedConfig, SessionFactoryServiceRegistry serviceRegistry) {
 		final JaccService jaccService = serviceRegistry.getService( JaccService.class );
 		if ( jaccService.getContextId() != null ) {
 			final JaccPermissionDeclarations permissions = aggregatedConfig.getJaccPermissions( jaccService.getContextId() );
 			if ( permissions != null ) {
 				for ( GrantedPermission grantedPermission : permissions.getPermissionDeclarations() ) {
 					jaccService.addPermission( grantedPermission );
 				}
 			}
 		}
 
 		if ( aggregatedConfig.getEventListenerMap() != null ) {
 			final ClassLoaderService cls = serviceRegistry.getService( ClassLoaderService.class );
 			final EventListenerRegistry eventListenerRegistry = serviceRegistry.getService( EventListenerRegistry.class );
 			for ( Map.Entry<EventType, Set<String>> entry : aggregatedConfig.getEventListenerMap().entrySet() ) {
 				final EventListenerGroup group = eventListenerRegistry.getEventListenerGroup( entry.getKey() );
 				for ( String listenerClassName : entry.getValue() ) {
 					try {
 						group.appendListener( cls.classForName( listenerClassName ).newInstance() );
 					}
 					catch (Exception e) {
 						throw new ConfigurationException( "Unable to instantiate event listener class : " + listenerClassName, e );
 					}
 				}
 			}
 		}
 	}
 
 	private NaturalIdRegionAccessStrategy determineNaturalIdRegionAccessStrategy(
 			RegionFactory regionFactory,
 			String cacheRegionPrefix,
 			Map cacheAccessStrategiesMap,
 			PersistentClass model) {
 		NaturalIdRegionAccessStrategy naturalIdAccessStrategy = null;
 		if ( model.hasNaturalId() && model.getNaturalIdCacheRegionName() != null ) {
 			final String naturalIdCacheRegionName = cacheRegionPrefix + model.getNaturalIdCacheRegionName();
 			naturalIdAccessStrategy = ( NaturalIdRegionAccessStrategy ) cacheAccessStrategiesMap.get( naturalIdCacheRegionName );
 
 			if ( naturalIdAccessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 				final CacheDataDescriptionImpl cacheDataDescription = CacheDataDescriptionImpl.decode( model );
 
 				NaturalIdRegion naturalIdRegion = null;
 				try {
 					naturalIdRegion = regionFactory.buildNaturalIdRegion(
 							naturalIdCacheRegionName,
 							properties,
 							cacheDataDescription
 					);
 				}
 				catch ( UnsupportedOperationException e ) {
 					LOG.warnf(
 							"Shared cache region factory [%s] does not support natural id caching; " +
 									"shared NaturalId caching will be disabled for not be enabled for %s",
 							regionFactory.getClass().getName(),
 							model.getEntityName()
 					);
 				}
 
 				if (naturalIdRegion != null) {
 					naturalIdAccessStrategy = naturalIdRegion.buildAccessStrategy( regionFactory.getDefaultAccessType() );
 					cacheAccessStrategiesMap.put( naturalIdCacheRegionName, naturalIdAccessStrategy );
 					cacheAccess.addCacheRegion(  naturalIdCacheRegionName, naturalIdRegion );
 				}
 			}
 		}
 		return naturalIdAccessStrategy;
 	}
 
 	private EntityRegionAccessStrategy determineEntityRegionAccessStrategy(
 			RegionFactory regionFactory,
 			Map cacheAccessStrategiesMap,
 			PersistentClass model,
 			String cacheRegionName) {
 		EntityRegionAccessStrategy accessStrategy = ( EntityRegionAccessStrategy ) cacheAccessStrategiesMap.get( cacheRegionName );
 		if ( accessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			if ( accessType != null ) {
 				LOG.tracef( "Building shared cache region for entity data [%s]", model.getEntityName() );
-				EntityRegion entityRegion = regionFactory.buildEntityRegion( cacheRegionName, properties, CacheDataDescriptionImpl
-																					 .decode( model ) );
+				EntityRegion entityRegion = regionFactory.buildEntityRegion(
+						cacheRegionName,
+						properties,
+						CacheDataDescriptionImpl.decode( model )
+				);
 				accessStrategy = entityRegion.buildAccessStrategy( accessType );
 				cacheAccessStrategiesMap.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion( cacheRegionName, entityRegion );
 			}
 		}
 		return accessStrategy;
 	}
 
 	private JdbcConnectionAccess buildLocalConnectionAccess() {
 		return new JdbcConnectionAccess() {
 			@Override
 			public Connection obtainConnection() throws SQLException {
 				return settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE
 						? serviceRegistry.getService( ConnectionProvider.class ).getConnection()
 						: serviceRegistry.getService( MultiTenantConnectionProvider.class ).getAnyConnection();
 			}
 
 			@Override
 			public void releaseConnection(Connection connection) throws SQLException {
 				if ( settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE ) {
 					serviceRegistry.getService( ConnectionProvider.class ).closeConnection( connection );
 				}
 				else {
 					serviceRegistry.getService( MultiTenantConnectionProvider.class ).releaseAnyConnection( connection );
 				}
 			}
 
 			@Override
 			public boolean supportsAggressiveRelease() {
 				return false;
 			}
 		};
 	}
 
 	@SuppressWarnings( {"unchecked"} )
 	private static Properties createPropertiesFromMap(Map map) {
 		Properties properties = new Properties();
 		properties.putAll( map );
 		return properties;
 	}
 
 	public Session openSession() throws HibernateException {
 		return withOptions().openSession();
 	}
 
 	public Session openTemporarySession() throws HibernateException {
 		return withOptions()
 				.autoClose( false )
 				.flushBeforeCompletion( false )
 				.connectionReleaseMode( ConnectionReleaseMode.AFTER_STATEMENT )
 				.openSession();
 	}
 
 	public Session getCurrentSession() throws HibernateException {
 		if ( currentSessionContext == null ) {
 			throw new HibernateException( "No CurrentSessionContext configured!" );
 		}
 		return currentSessionContext.currentSession();
 	}
 
 	@Override
 	public SessionBuilderImplementor withOptions() {
 		return new SessionBuilderImpl( this );
 	}
 
 	@Override
 	public StatelessSessionBuilder withStatelessOptions() {
 		return new StatelessSessionBuilderImpl( this );
 	}
 
 	public StatelessSession openStatelessSession() {
 		return withStatelessOptions().openStatelessSession();
 	}
 
 	public StatelessSession openStatelessSession(Connection connection) {
 		return withStatelessOptions().connection( connection ).openStatelessSession();
 	}
 
 	@Override
 	public void addObserver(SessionFactoryObserver observer) {
 		this.observer.addObserver( observer );
 	}
 
 	public Properties getProperties() {
 		return properties;
 	}
 
 	public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return null;
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	private void registerEntityNameResolvers(EntityPersister persister) {
 		if ( persister.getEntityMetamodel() == null || persister.getEntityMetamodel().getTuplizer() == null ) {
 			return;
 		}
 		registerEntityNameResolvers( persister.getEntityMetamodel().getTuplizer() );
 	}
 
 	private void registerEntityNameResolvers(EntityTuplizer tuplizer) {
 		EntityNameResolver[] resolvers = tuplizer.getEntityNameResolvers();
 		if ( resolvers == null ) {
 			return;
 		}
 
 		for ( EntityNameResolver resolver : resolvers ) {
 			registerEntityNameResolver( resolver );
 		}
 	}
 
 	private static final Object ENTITY_NAME_RESOLVER_MAP_VALUE = new Object();
 
 	public void registerEntityNameResolver(EntityNameResolver resolver) {
 		entityNameResolvers.put( resolver, ENTITY_NAME_RESOLVER_MAP_VALUE );
 	}
 
 	@Override
 	public Iterable<EntityNameResolver> iterateEntityNameResolvers() {
 		return entityNameResolvers.keySet();
 	}
 
 	public QueryPlanCache getQueryPlanCache() {
 		return queryPlanCache;
 	}
 
 	private Map<String,HibernateException> checkNamedQueries() throws HibernateException {
 		return namedQueryRepository.checkNamedQueries( queryPlanCache );
 	}
 
 	@Override
 	public Map<String, EntityPersister> getEntityPersisters() {
 		return entityPersisters;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister(String entityName) throws MappingException {
 		EntityPersister result = entityPersisters.get( entityName );
 		if ( result == null ) {
 			throw new MappingException( "Unknown entity: " + entityName );
 		}
 		return result;
 	}
 
 	@Override
 	public EntityPersister locateEntityPersister(Class byClass) {
 		EntityPersister entityPersister = entityPersisters.get( byClass.getName() );
 		if ( entityPersister == null ) {
 			String mappedEntityName = entityProxyInterfaceMap.get( byClass );
 			if ( mappedEntityName != null ) {
 				entityPersister = entityPersisters.get( mappedEntityName );
 			}
 		}
 
 		if ( entityPersister == null ) {
 			throw new HibernateException( "Unable to locate persister: " + byClass.getName() );
 		}
 
 		return entityPersister;
 	}
 
 	@Override
 	public EntityPersister locateEntityPersister(String byName) {
 		final EntityPersister entityPersister = entityPersisters.get( byName );
 		if ( entityPersister == null ) {
 			throw new HibernateException( "Unable to locate persister: " + byName );
 		}
 		return entityPersister;
 	}
 
 	@Override
 	public Map<String, CollectionPersister> getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	public CollectionPersister getCollectionPersister(String role) throws MappingException {
 		CollectionPersister result = collectionPersisters.get(role);
 		if ( result == null ) {
 			throw new MappingException( "Unknown collection role: " + role );
 		}
 		return result;
 	}
 
 	@SuppressWarnings("deprecation")
 	public Settings getSettings() {
 		return settings;
 	}
 
 	@Override
 	public SessionFactoryOptions getSessionFactoryOptions() {
 		return sessionFactoryOptions;
 	}
 
 	public JdbcServices getJdbcServices() {
 		return jdbcServices;
 	}
 
 	public Dialect getDialect() {
 		if ( serviceRegistry == null ) {
 			throw new IllegalStateException( "Cannot determine dialect because serviceRegistry is null." );
 		}
 		return dialect;
 	}
 
 	public Interceptor getInterceptor() {
 		return sessionFactoryOptions.getInterceptor();
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	public SqlExceptionHelper getSQLExceptionHelper() {
 		return getJdbcServices().getSqlExceptionHelper();
 	}
 
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName) {
 		return collectionRolesByEntityParticipant.get( entityName );
 	}
 
 	@Override
 	public Reference getReference() {
 		// from javax.naming.Referenceable
-        LOG.debug( "Returning a Reference to the SessionFactory" );
+		LOG.debug( "Returning a Reference to the SessionFactory" );
 		return new Reference(
 				SessionFactoryImpl.class.getName(),
 				new StringRefAddr("uuid", uuid),
 				SessionFactoryRegistry.ObjectFactoryImpl.class.getName(),
 				null
 		);
 	}
 
 	@Override
 	public NamedQueryRepository getNamedQueryRepository() {
 		return namedQueryRepository;
 	}
 
 	public void registerNamedQueryDefinition(String name, NamedQueryDefinition definition) {
 		namedQueryRepository.registerNamedQueryDefinition( name, definition );
 	}
 
 	public NamedQueryDefinition getNamedQuery(String queryName) {
 		return namedQueryRepository.getNamedQueryDefinition( queryName );
 	}
 
 	public void registerNamedSQLQueryDefinition(String name, NamedSQLQueryDefinition definition) {
 		namedQueryRepository.registerNamedSQLQueryDefinition( name, definition );
 	}
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName) {
 		return namedQueryRepository.getNamedSQLQueryDefinition( queryName );
 	}
 
 	public ResultSetMappingDefinition getResultSetMapping(String mappingName) {
 		return namedQueryRepository.getResultSetMappingDefinition( mappingName );
 	}
 
 	public Type getIdentifierType(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierType();
 	}
 	public String getIdentifierPropertyName(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierPropertyName();
 	}
 
 	public Type[] getReturnTypes(String queryString) throws HibernateException {
 		final ReturnMetadata metadata = queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata();
 		return metadata == null ? null : metadata.getReturnTypes();
 	}
 
 	public String[] getReturnAliases(String queryString) throws HibernateException {
 		final ReturnMetadata metadata = queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata();
 		return metadata == null ? null : metadata.getReturnAliases();
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getClassMetadata( persistentClass.getName() );
 	}
 
 	public CollectionMetadata getCollectionMetadata(String roleName) throws HibernateException {
 		return collectionMetadata.get( roleName );
 	}
 
 	public ClassMetadata getClassMetadata(String entityName) throws HibernateException {
 		return classMetadata.get( entityName );
 	}
 
 	/**
 	 * Given the name of an entity class, determine all the class and interface names by which it can be
 	 * referenced in an HQL query.
 	 *
      * @param className The name of the entity class
 	 *
 	 * @return the names of all persistent (mapped) classes that extend or implement the
 	 *     given class or interface, accounting for implicit/explicit polymorphism settings
 	 *     and excluding mapped subclasses/joined-subclasses of other classes in the result.
 	 * @throws MappingException
 	 */
 	public String[] getImplementors(String className) throws MappingException {
 
 		final Class clazz;
 		try {
 			clazz = serviceRegistry.getService( ClassLoaderService.class ).classForName( className );
 		}
 		catch (ClassLoadingException cnfe) {
 			return new String[] { className }; //for a dynamic-class
 		}
 
 		ArrayList<String> results = new ArrayList<String>();
 		for ( EntityPersister checkPersister : entityPersisters.values() ) {
 			if ( ! Queryable.class.isInstance( checkPersister ) ) {
 				continue;
 			}
 			final Queryable checkQueryable = Queryable.class.cast( checkPersister );
 			final String checkQueryableEntityName = checkQueryable.getEntityName();
 			final boolean isMappedClass = className.equals( checkQueryableEntityName );
 			if ( checkQueryable.isExplicitPolymorphism() ) {
 				if ( isMappedClass ) {
 					return new String[] { className }; //NOTE EARLY EXIT
 				}
 			}
 			else {
 				if ( isMappedClass ) {
 					results.add( checkQueryableEntityName );
 				}
 				else {
 					final Class mappedClass = checkQueryable.getMappedClass();
 					if ( mappedClass != null && clazz.isAssignableFrom( mappedClass ) ) {
 						final boolean assignableSuperclass;
 						if ( checkQueryable.isInherited() ) {
 							Class mappedSuperclass = getEntityPersister( checkQueryable.getMappedSuperclass() ).getMappedClass();
 							assignableSuperclass = clazz.isAssignableFrom( mappedSuperclass );
 						}
 						else {
 							assignableSuperclass = false;
 						}
 						if ( !assignableSuperclass ) {
 							results.add( checkQueryableEntityName );
 						}
 					}
 				}
 			}
 		}
 		return results.toArray( new String[results.size()] );
 	}
 
 	@Override
 	public String getImportedClassName(String className) {
 		String result = imports.get( className );
 		if ( result == null ) {
 			try {
 				serviceRegistry.getService( ClassLoaderService.class ).classForName( className );
 				imports.put( className, className );
 				return className;
 			}
 			catch ( ClassLoadingException cnfe ) {
 				return null;
 			}
 		}
 		else {
 			return result;
 		}
 	}
 
 	public Map<String,ClassMetadata> getAllClassMetadata() throws HibernateException {
 		return classMetadata;
 	}
 
 	public Map getAllCollectionMetadata() throws HibernateException {
 		return collectionMetadata;
 	}
 
 	public Type getReferencedPropertyType(String className, String propertyName)
 		throws MappingException {
 		return getEntityPersister( className ).getPropertyType( propertyName );
 	}
 
 	/**
 	 * Closes the session factory, releasing all held resources.
 	 *
 	 * <ol>
 	 * <li>cleans up used cache regions and "stops" the cache provider.
 	 * <li>close the JDBC connection
 	 * <li>remove the JNDI binding
 	 * </ol>
 	 *
 	 * Note: Be aware that the sessionFactory instance still can
 	 * be a "heavy" object memory wise after close() has been called.  Thus
 	 * it is important to not keep referencing the instance to let the garbage
 	 * collector release the memory.
 	 * @throws HibernateException
 	 */
 	public void close() throws HibernateException {
 
 		if ( isClosed ) {
 			LOG.trace( "Already closed" );
 			return;
 		}
 
 		LOG.closing();
 
 		isClosed = true;
 
 		settings.getMultiTableBulkIdStrategy().release( jdbcServices, buildLocalConnectionAccess() );
 
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			EntityPersister p = (EntityPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = (CollectionPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		cacheAccess.close();
 
 		queryPlanCache.cleanup();
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport.drop( false, true );
 		}
 
 		SessionFactoryRegistry.INSTANCE.removeSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				serviceRegistry.getService( JndiService.class )
 		);
 
 		observer.sessionFactoryClosed( this );
 		serviceRegistry.destroy();
 	}
 
 	public Cache getCache() {
 		return cacheAccess;
 	}
 
 	public void evictEntity(String entityName, Serializable id) throws HibernateException {
 		getCache().evictEntity( entityName, id );
 	}
 
 	public void evictEntity(String entityName) throws HibernateException {
 		getCache().evictEntityRegion( entityName );
 	}
 
 	public void evict(Class persistentClass, Serializable id) throws HibernateException {
 		getCache().evictEntity( persistentClass, id );
 	}
 
 	public void evict(Class persistentClass) throws HibernateException {
 		getCache().evictEntityRegion( persistentClass );
 	}
 
 	public void evictCollection(String roleName, Serializable id) throws HibernateException {
 		getCache().evictCollection( roleName, id );
 	}
 
 	public void evictCollection(String roleName) throws HibernateException {
 		getCache().evictCollectionRegion( roleName );
 	}
 
 	public void evictQueries() throws HibernateException {
 		cacheAccess.evictQueries();
 	}
 
 	public void evictQueries(String regionName) throws HibernateException {
 		getCache().evictQueryRegion( regionName );
 	}
 
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return cacheAccess.getUpdateTimestampsCache();
 	}
 
 	public QueryCache getQueryCache() {
 		return cacheAccess.getQueryCache();
 	}
 
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		return cacheAccess.getQueryCache( regionName );
 	}
 
 	public Region getSecondLevelCacheRegion(String regionName) {
 		return cacheAccess.getSecondLevelCacheRegion( regionName );
 	}
 
 	public Region getNaturalIdCacheRegion(String regionName) {
 		return cacheAccess.getNaturalIdCacheRegion( regionName );
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public Map getAllSecondLevelCacheRegions() {
 		return cacheAccess.getAllSecondLevelCacheRegions();
 	}
 
 	public boolean isClosed() {
 		return isClosed;
 	}
 
 	public Statistics getStatistics() {
 		return getStatisticsImplementor();
 	}
 
 	public StatisticsImplementor getStatisticsImplementor() {
 		return serviceRegistry.getService( StatisticsImplementor.class );
 	}
 
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException {
 		FilterDefinition def = filters.get( filterName );
 		if ( def == null ) {
 			throw new HibernateException( "No such filter configured [" + filterName + "]" );
 		}
 		return def;
 	}
 
 	public boolean containsFetchProfileDefinition(String name) {
 		return fetchProfiles.containsKey( name );
 	}
 
 	public Set getDefinedFilterNames() {
 		return filters.keySet();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName) {
 		return identifierGenerators.get(rootEntityName);
 	}
 
 	private boolean canAccessTransactionManager() {
 		try {
 			return serviceRegistry.getService( JtaPlatform.class ).retrieveTransactionManager() != null;
 		}
 		catch (Exception e) {
 			return false;
 		}
 	}
 
 	private CurrentSessionContext buildCurrentSessionContext() {
 		String impl = properties.getProperty( Environment.CURRENT_SESSION_CONTEXT_CLASS );
 		// for backward-compatibility
 		if ( impl == null ) {
 			if ( canAccessTransactionManager() ) {
 				impl = "jta";
 			}
 			else {
 				return null;
 			}
 		}
 
 		if ( "jta".equals( impl ) ) {
 //			if ( ! transactionFactory().compatibleWithJtaSynchronization() ) {
 //				LOG.autoFlushWillNotWork();
 //			}
 			return new JTASessionContext( this );
 		}
 		else if ( "thread".equals( impl ) ) {
 			return new ThreadLocalSessionContext( this );
 		}
 		else if ( "managed".equals( impl ) ) {
 			return new ManagedSessionContext( this );
 		}
 		else {
 			try {
 				Class implClass = serviceRegistry.getService( ClassLoaderService.class ).classForName( impl );
 				return ( CurrentSessionContext ) implClass
 						.getConstructor( new Class[] { SessionFactoryImplementor.class } )
 						.newInstance( this );
 			}
 			catch( Throwable t ) {
 				LOG.unableToConstructCurrentSessionContext( impl, t );
 				return null;
 			}
 		}
 	}
 
 	@Override
 	public ServiceRegistryImplementor getServiceRegistry() {
 		return serviceRegistry;
 	}
 
 	@Override
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return sessionFactoryOptions.getEntityNotFoundDelegate();
 	}
 
 	public SQLFunctionRegistry getSqlFunctionRegistry() {
 		return sqlFunctionRegistry;
 	}
 
 	public FetchProfile getFetchProfile(String name) {
 		return fetchProfiles.get( name );
 	}
 
 	public TypeHelper getTypeHelper() {
 		return typeHelper;
 	}
 
 	static class SessionBuilderImpl implements SessionBuilderImplementor {
 		private static final Logger log = CoreLogging.logger( SessionBuilderImpl.class );
 
 		private final SessionFactoryImpl sessionFactory;
 		private SessionOwner sessionOwner;
 		private Interceptor interceptor;
 		private StatementInspector statementInspector;
 		private Connection connection;
 		private ConnectionReleaseMode connectionReleaseMode;
 		private boolean autoClose;
 		private boolean autoJoinTransactions = true;
 		private boolean flushBeforeCompletion;
 		private String tenantIdentifier;
 		private List<SessionEventListener> listeners;
 
 		SessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 			this.sessionOwner = null;
 			final Settings settings = sessionFactory.settings;
 
 			// set up default builder values...
 			this.interceptor = sessionFactory.getInterceptor();
 			this.statementInspector = sessionFactory.getSessionFactoryOptions().getStatementInspector();
 			this.connectionReleaseMode = settings.getConnectionReleaseMode();
 			this.autoClose = settings.isAutoCloseSessionEnabled();
 			this.flushBeforeCompletion = settings.isFlushBeforeCompletionEnabled();
 
 			if ( sessionFactory.getCurrentTenantIdentifierResolver() != null ) {
 				tenantIdentifier = sessionFactory.getCurrentTenantIdentifierResolver().resolveCurrentTenantIdentifier();
 			}
 
 			listeners = settings.getBaselineSessionEventsListenerBuilder().buildBaselineList();
 		}
 
 		protected TransactionCoordinator getTransactionCoordinator() {
 			return null;
 		}
 
 		protected JdbcCoordinatorImpl getJdbcCoordinator() {
 			return null;
 		}
 
 		protected Transaction getTransaction() {
 			return null;
 		}
 
 		protected ActionQueue.TransactionCompletionProcesses getTransactionCompletionProcesses() {
 			return null;
 		}
 
 		@Override
 		public Session openSession() {
 			log.tracef( "Opening Hibernate Session.  tenant=%s, owner=%s", tenantIdentifier, sessionOwner );
 			final SessionImpl session = new SessionImpl(
 					connection,
 					sessionFactory,
 					sessionOwner,
 					getTransactionCoordinator(),
 					getJdbcCoordinator(),
 					getTransaction(),
 					getTransactionCompletionProcesses(),
 					autoJoinTransactions,
 					sessionFactory.settings.getRegionFactory().nextTimestamp(),
 					interceptor,
 					statementInspector,
 					flushBeforeCompletion,
 					autoClose,
 					connectionReleaseMode,
 					tenantIdentifier
 			);
 
 			for ( SessionEventListener listener : listeners ) {
 				session.getEventListenerManager().addListener( listener );
 			}
 
 			return session;
 		}
 
 		@Override
 		public SessionBuilder owner(SessionOwner sessionOwner) {
 			this.sessionOwner = sessionOwner;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder interceptor(Interceptor interceptor) {
 			this.interceptor = interceptor;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder noInterceptor() {
 			this.interceptor = EmptyInterceptor.INSTANCE;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder statementInspector(StatementInspector statementInspector) {
 			this.statementInspector = statementInspector;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder connection(Connection connection) {
 			this.connection = connection;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder connectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 			this.connectionReleaseMode = connectionReleaseMode;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder autoJoinTransactions(boolean autoJoinTransactions) {
 			this.autoJoinTransactions = autoJoinTransactions;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder autoClose(boolean autoClose) {
 			this.autoClose = autoClose;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder flushBeforeCompletion(boolean flushBeforeCompletion) {
 			this.flushBeforeCompletion = flushBeforeCompletion;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder tenantIdentifier(String tenantIdentifier) {
 			this.tenantIdentifier = tenantIdentifier;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder eventListeners(SessionEventListener... listeners) {
 			Collections.addAll( this.listeners, listeners );
 			return this;
 		}
 
 		@Override
 		public SessionBuilder clearEventListeners() {
 			listeners.clear();
 			return this;
 		}
 	}
 
 	public static class StatelessSessionBuilderImpl implements StatelessSessionBuilder {
 		private final SessionFactoryImpl sessionFactory;
 		private Connection connection;
 		private String tenantIdentifier;
 
 		public StatelessSessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 
 			if ( sessionFactory.getCurrentTenantIdentifierResolver() != null ) {
 				tenantIdentifier = sessionFactory.getCurrentTenantIdentifierResolver().resolveCurrentTenantIdentifier();
 			}
 		}
 
 		@Override
 		public StatelessSession openStatelessSession() {
 			return new StatelessSessionImpl( connection, tenantIdentifier, sessionFactory,
 					sessionFactory.settings.getRegionFactory().nextTimestamp() );
 		}
 
 		@Override
 		public StatelessSessionBuilder connection(Connection connection) {
 			this.connection = connection;
 			return this;
 		}
 
 		@Override
 		public StatelessSessionBuilder tenantIdentifier(String tenantIdentifier) {
 			this.tenantIdentifier = tenantIdentifier;
 			return this;
 		}
 	}
 
 	@Override
 	public CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy() {
 		return getSessionFactoryOptions().getCustomEntityDirtinessStrategy();
 	}
 
 	@Override
 	public CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver() {
 		return getSessionFactoryOptions().getCurrentTenantIdentifierResolver();
 	}
 
 
 	// Serialization handling ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly serialized
 	 *
 	 * @param out The stream into which the object is being serialized.
 	 *
 	 * @throws IOException Can be thrown by the stream
 	 */
 	private void writeObject(ObjectOutputStream out) throws IOException {
 		LOG.debugf( "Serializing: %s", uuid );
 		out.defaultWriteObject();
 		LOG.trace( "Serialized" );
 	}
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly deserialized
 	 *
 	 * @param in The stream from which the object is being deserialized.
 	 *
 	 * @throws IOException Can be thrown by the stream
 	 * @throws ClassNotFoundException Again, can be thrown by the stream
 	 */
 	private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
 		LOG.trace( "Deserializing" );
 		in.defaultReadObject();
 		LOG.debugf( "Deserialized: %s", uuid );
 	}
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly deserialized.
 	 * Here we resolve the uuid/name read from the stream previously to resolve the SessionFactory
 	 * instance to use based on the registrations with the {@link SessionFactoryRegistry}
 	 *
 	 * @return The resolved factory to use.
 	 *
 	 * @throws InvalidObjectException Thrown if we could not resolve the factory by uuid/name.
 	 */
 	private Object readResolve() throws InvalidObjectException {
 		LOG.trace( "Resolving serialized SessionFactory" );
 		return locateSessionFactoryOnDeserialization( uuid, name );
 	}
 
 	private static SessionFactory locateSessionFactoryOnDeserialization(String uuid, String name) throws InvalidObjectException{
 		final SessionFactory uuidResult = SessionFactoryRegistry.INSTANCE.getSessionFactory( uuid );
 		if ( uuidResult != null ) {
 			LOG.debugf( "Resolved SessionFactory by UUID [%s]", uuid );
 			return uuidResult;
 		}
 
 		// in case we were deserialized in a different JVM, look for an instance with the same name
 		// (provided we were given a name)
 		if ( name != null ) {
 			final SessionFactory namedResult = SessionFactoryRegistry.INSTANCE.getNamedSessionFactory( name );
 			if ( namedResult != null ) {
 				LOG.debugf( "Resolved SessionFactory by name [%s]", name );
 				return namedResult;
 			}
 		}
 
 		throw new InvalidObjectException( "Could not find a SessionFactory [uuid=" + uuid + ",name=" + name + "]" );
 	}
 
 	/**
 	 * Custom serialization hook used during Session serialization.
 	 *
 	 * @param oos The stream to which to write the factory
 	 * @throws IOException Indicates problems writing out the serial data stream
 	 */
 	void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeUTF( uuid );
 		oos.writeBoolean( name != null );
 		if ( name != null ) {
 			oos.writeUTF( name );
 		}
 	}
 
 	/**
 	 * Custom deserialization hook used during Session deserialization.
 	 *
 	 * @param ois The stream from which to "read" the factory
 	 * @return The deserialized factory
 	 * @throws IOException indicates problems reading back serial data stream
 	 * @throws ClassNotFoundException indicates problems reading back serial data stream
 	 */
 	static SessionFactoryImpl deserialize(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		LOG.trace( "Deserializing SessionFactory from Session" );
 		final String uuid = ois.readUTF();
 		boolean isNamed = ois.readBoolean();
 		final String name = isNamed ? ois.readUTF() : null;
 		return (SessionFactoryImpl) locateSessionFactoryOnDeserialization( uuid, name );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryRegistry.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryRegistry.java
index d3bcc4a128..f69681a97e 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryRegistry.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryRegistry.java
@@ -1,249 +1,249 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.util.Hashtable;
 import java.util.concurrent.ConcurrentHashMap;
 import javax.naming.Context;
 import javax.naming.Name;
 import javax.naming.Reference;
 import javax.naming.event.NamespaceChangeListener;
 import javax.naming.event.NamingEvent;
 import javax.naming.event.NamingExceptionEvent;
 import javax.naming.spi.ObjectFactory;
 
 import org.hibernate.SessionFactory;
 import org.hibernate.engine.jndi.JndiException;
 import org.hibernate.engine.jndi.JndiNameException;
 import org.hibernate.engine.jndi.spi.JndiService;
 
 /**
  * A registry of all {@link SessionFactory} instances for the same classloader as this class.
- *
+ * <p/>
  * This registry is used for serialization/deserialization as well as JNDI binding.
  *
  * @author Steve Ebersole
  */
 public class SessionFactoryRegistry {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SessionFactoryRegistry.class );
 
 	/**
 	 * Singleton access
 	 */
 	public static final SessionFactoryRegistry INSTANCE = new SessionFactoryRegistry();
 
 	/**
 	 * A map for mapping the UUID of a SessionFactory to the corresponding SessionFactory instance
 	 */
 	private final ConcurrentHashMap<String, SessionFactory> sessionFactoryMap = new ConcurrentHashMap<String, SessionFactory>();
 
 	/**
 	 * A cross-reference for mapping a SessionFactory name to its UUID.  Not all SessionFactories get named,
 	 */
-	private final ConcurrentHashMap<String,String> nameUuidXref = new ConcurrentHashMap<String, String>();
+	private final ConcurrentHashMap<String, String> nameUuidXref = new ConcurrentHashMap<String, String>();
 
 	private SessionFactoryRegistry() {
 		LOG.debugf( "Initializing SessionFactoryRegistry : %s", this );
 	}
 
 	/**
 	 * Adds a SessionFactory to the registry
 	 *
 	 * @param uuid The uuid under which to register the SessionFactory
 	 * @param name The optional name under which to register the SessionFactory
 	 * @param isNameAlsoJndiName Is name, if provided, also a JNDI name?
 	 * @param instance The SessionFactory instance
 	 * @param jndiService The JNDI service, so we can register a listener if name is a JNDI name
 	 */
 	public void addSessionFactory(
 			String uuid,
 			String name,
 			boolean isNameAlsoJndiName,
 			SessionFactory instance,
 			JndiService jndiService) {
 		if ( uuid == null ) {
 			throw new IllegalArgumentException( "SessionFactory UUID cannot be null" );
 		}
 
 		LOG.debugf( "Registering SessionFactory: %s (%s)", uuid, name == null ? "<unnamed>" : name );
 		sessionFactoryMap.put( uuid, instance );
 		if ( name != null ) {
 			nameUuidXref.put( name, uuid );
 		}
 
-		if ( name == null || ! isNameAlsoJndiName ) {
+		if ( name == null || !isNameAlsoJndiName ) {
 			LOG.debug( "Not binding SessionFactory to JNDI, no JNDI name configured" );
 			return;
 		}
 
 		LOG.debugf( "Attempting to bind SessionFactory [%s] to JNDI", name );
 
 		try {
 			jndiService.bind( name, instance );
 			LOG.factoryBoundToJndiName( name );
 			try {
 				jndiService.addListener( name, listener );
 			}
 			catch (Exception e) {
 				LOG.couldNotBindJndiListener();
 			}
 		}
 		catch (JndiNameException e) {
 			LOG.invalidJndiName( name, e );
 		}
 		catch (JndiException e) {
 			LOG.unableToBindFactoryToJndi( e );
 		}
 	}
 
 	/**
 	 * Remove a previously added SessionFactory
 	 *
 	 * @param uuid The uuid
 	 * @param name The optional name
 	 * @param isNameAlsoJndiName Is name, if provided, also a JNDI name?
 	 * @param jndiService The JNDI service
 	 */
 	public void removeSessionFactory(
 			String uuid,
 			String name,
 			boolean isNameAlsoJndiName,
 			JndiService jndiService) {
 		if ( name != null ) {
 			nameUuidXref.remove( name );
 
 			if ( isNameAlsoJndiName ) {
 				try {
 					LOG.tracef( "Unbinding SessionFactory from JNDI : %s", name );
 					jndiService.unbind( name );
 					LOG.factoryUnboundFromJndiName( name );
 				}
-				catch ( JndiNameException e ) {
+				catch (JndiNameException e) {
 					LOG.invalidJndiName( name, e );
 				}
-				catch ( JndiException e ) {
+				catch (JndiException e) {
 					LOG.unableToUnbindFactoryFromJndi( e );
 				}
 			}
 		}
 
 		sessionFactoryMap.remove( uuid );
 	}
 
 	/**
 	 * Get a registered SessionFactory by name
 	 *
 	 * @param name The name
 	 *
 	 * @return The SessionFactory
 	 */
 	public SessionFactory getNamedSessionFactory(String name) {
 		LOG.debugf( "Lookup: name=%s", name );
 		final String uuid = nameUuidXref.get( name );
 		// protect against NPE -- see HHH-8428
 		return uuid == null ? null : getSessionFactory( uuid );
 	}
 
 	public SessionFactory getSessionFactory(String uuid) {
 		LOG.debugf( "Lookup: uid=%s", uuid );
 		final SessionFactory sessionFactory = sessionFactoryMap.get( uuid );
 		if ( sessionFactory == null && LOG.isDebugEnabled() ) {
 			LOG.debugf( "Not found: %s", uuid );
 			LOG.debugf( sessionFactoryMap.toString() );
 		}
 		return sessionFactory;
 	}
 
 	/**
 	 * Does this registry currently contain registrations?
 	 *
 	 * @return true/false
 	 */
 	public boolean hasRegistrations() {
-		return ! sessionFactoryMap.isEmpty();
+		return !sessionFactoryMap.isEmpty();
 	}
 
 	public void clearRegistrations() {
 		nameUuidXref.clear();
 		for ( SessionFactory factory : sessionFactoryMap.values() ) {
 			try {
 				factory.close();
 			}
 			catch (Exception ignore) {
 			}
 		}
 		sessionFactoryMap.clear();
 	}
 
 	/**
 	 * Implementation of {@literal JNDI} {@link javax.naming.event.NamespaceChangeListener} contract to listener for context events
 	 * and react accordingly if necessary
 	 */
 	private final NamespaceChangeListener listener = new NamespaceChangeListener() {
 		@Override
 		public void objectAdded(NamingEvent evt) {
-			LOG.debugf("A factory was successfully bound to name: %s", evt.getNewBinding().getName());
+			LOG.debugf( "A factory was successfully bound to name: %s", evt.getNewBinding().getName() );
 		}
 
 		@Override
 		public void objectRemoved(NamingEvent evt) {
 			final String jndiName = evt.getOldBinding().getName();
-            LOG.factoryUnboundFromName( jndiName );
+			LOG.factoryUnboundFromName( jndiName );
 
 			final String uuid = nameUuidXref.remove( jndiName );
 			if ( uuid == null ) {
 				// serious problem... but not sure what to do yet
 			}
 			sessionFactoryMap.remove( uuid );
 		}
 
 		@Override
 		public void objectRenamed(NamingEvent evt) {
 			final String oldJndiName = evt.getOldBinding().getName();
 			final String newJndiName = evt.getNewBinding().getName();
 
 			LOG.factoryJndiRename( oldJndiName, newJndiName );
 
 			final String uuid = nameUuidXref.remove( oldJndiName );
 			nameUuidXref.put( newJndiName, uuid );
 		}
 
 		@Override
 		public void namingExceptionThrown(NamingExceptionEvent evt) {
 			//noinspection ThrowableResultOfMethodCallIgnored
-            LOG.namingExceptionAccessingFactory(evt.getException());
+			LOG.namingExceptionAccessingFactory( evt.getException() );
 		}
 	};
 
 	public static class ObjectFactoryImpl implements ObjectFactory {
 		@Override
 		public Object getObjectInstance(Object reference, Name name, Context nameCtx, Hashtable<?, ?> environment)
 				throws Exception {
 			LOG.debugf( "JNDI lookup: %s", name );
 			final String uuid = (String) ( (Reference) reference ).get( 0 ).getContent();
 			LOG.tracef( "Resolved to UUID = %s", uuid );
 			return INSTANCE.getSessionFactory( uuid );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
index d92dcc5cfd..82c7987736 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
@@ -1,2941 +1,2966 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2005-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Reader;
 import java.io.Serializable;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.Connection;
 import java.sql.NClob;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.EntityNotFoundException;
 import javax.transaction.SystemException;
 
 import org.hibernate.CacheMode;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.Filter;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.IdentifierLoadAccess;
 import org.hibernate.Interceptor;
 import org.hibernate.LobHelper;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.NaturalIdLoadAccess;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ReplicationMode;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionException;
 import org.hibernate.SharedSessionBuilder;
 import org.hibernate.SimpleNaturalIdLoadAccess;
 import org.hibernate.Transaction;
 import org.hibernate.TransactionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeHelper;
 import org.hibernate.UnknownProfileException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.criterion.NaturalIdentifier;
 import org.hibernate.engine.internal.SessionEventListenerManagerImpl;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.NonContextualLobCreator;
 import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.query.spi.FilterQueryPlan;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NativeSQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.engine.transaction.spi.TransactionObserver;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.AutoFlushEvent;
 import org.hibernate.event.spi.AutoFlushEventListener;
 import org.hibernate.event.spi.ClearEvent;
 import org.hibernate.event.spi.ClearEventListener;
 import org.hibernate.event.spi.DeleteEvent;
 import org.hibernate.event.spi.DeleteEventListener;
 import org.hibernate.event.spi.DirtyCheckEvent;
 import org.hibernate.event.spi.DirtyCheckEventListener;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.event.spi.EvictEvent;
 import org.hibernate.event.spi.EvictEventListener;
 import org.hibernate.event.spi.FlushEvent;
 import org.hibernate.event.spi.FlushEventListener;
 import org.hibernate.event.spi.InitializeCollectionEvent;
 import org.hibernate.event.spi.InitializeCollectionEventListener;
 import org.hibernate.event.spi.LoadEvent;
 import org.hibernate.event.spi.LoadEventListener;
 import org.hibernate.event.spi.LoadEventListener.LoadType;
 import org.hibernate.event.spi.LockEvent;
 import org.hibernate.event.spi.LockEventListener;
 import org.hibernate.event.spi.MergeEvent;
 import org.hibernate.event.spi.MergeEventListener;
 import org.hibernate.event.spi.PersistEvent;
 import org.hibernate.event.spi.PersistEventListener;
 import org.hibernate.event.spi.RefreshEvent;
 import org.hibernate.event.spi.RefreshEventListener;
 import org.hibernate.event.spi.ReplicateEvent;
 import org.hibernate.event.spi.ReplicateEventListener;
 import org.hibernate.event.spi.ResolveNaturalIdEvent;
 import org.hibernate.event.spi.ResolveNaturalIdEventListener;
 import org.hibernate.event.spi.SaveOrUpdateEvent;
 import org.hibernate.event.spi.SaveOrUpdateEventListener;
 import org.hibernate.internal.CriteriaImpl.CriterionEntry;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.jdbc.Work;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.procedure.ProcedureCall;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
 import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.AfterCompletionAction;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.ExceptionMapper;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.ManagedFlushChecker;
 import org.hibernate.resource.transaction.spi.TransactionStatus;
 import org.hibernate.stat.SessionStatistics;
 import org.hibernate.stat.internal.SessionStatisticsImpl;
 
-import org.jboss.logging.Logger;
-
 /**
  * Concrete implementation of a Session.
- *
+ * <p/>
  * Exposes two interfaces:<ul>
- *     <li>{@link Session} to the application</li>
- *     <li>{@link org.hibernate.engine.spi.SessionImplementor} to other Hibernate components (SPI)</li>
+ * <li>{@link Session} to the application</li>
+ * <li>{@link org.hibernate.engine.spi.SessionImplementor} to other Hibernate components (SPI)</li>
  * </ul>
- *
+ * <p/>
  * This class is not thread-safe.
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public final class SessionImpl extends AbstractSessionImpl implements EventSource {
 
 	// todo : need to find a clean way to handle the "event source" role
 	// a separate class responsible for generating/dispatching events just duplicates most of the Session methods...
 	// passing around separate interceptor, factory, actionQueue, and persistentContext is not manageable...
 
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class,
-			SessionImpl.class.getName()
-	);
-
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SessionImpl.class );
 	private static final boolean TRACE_ENABLED = LOG.isTraceEnabled();
 
 	private transient long timestamp;
 
 	private transient SessionOwner sessionOwner;
 
 	private transient ActionQueue actionQueue;
 	private transient StatefulPersistenceContext persistenceContext;
 	private transient TransactionCoordinator transactionCoordinator;
 	private transient JdbcCoordinatorImpl jdbcCoordinator;
 	private transient Interceptor interceptor;
 	private StatementInspector statementInspector;
 	private transient EntityNameResolver entityNameResolver = new CoordinatingEntityNameResolver();
 
 	private transient ConnectionReleaseMode connectionReleaseMode;
 	private transient FlushMode flushMode = FlushMode.AUTO;
 	private transient CacheMode cacheMode = CacheMode.NORMAL;
 
 	private transient boolean autoClear; //for EJB3
 	private transient boolean autoJoinTransactions = true;
 	private transient boolean flushBeforeCompletionEnabled;
 	private transient boolean autoCloseSessionEnabled;
 
 	private transient int dontFlushFromFind;
 
 	private transient LoadQueryInfluencers loadQueryInfluencers;
 
 	private final transient boolean isTransactionCoordinatorShared;
 	private transient TransactionObserver transactionObserver;
 
 	private SessionEventListenerManagerImpl sessionEventsManager = new SessionEventListenerManagerImpl();
 
 	private transient JdbcSessionContext jdbcSessionContext;
 
 	private transient ExceptionMapper exceptionMapper;
 	private transient ManagedFlushChecker managedFlushChecker;
 	private transient AfterCompletionAction afterCompletionAction;
 
 	/**
 	 * Constructor used for openSession(...) processing, as well as construction
 	 * of sessions for getCurrentSession().
 	 *
 	 * @param connection The user-supplied connection to use for this session.
 	 * @param factory The factory from which this session was obtained
 	 * @param transactionCoordinator The transaction coordinator to use, may be null to indicate that a new transaction
 	 * coordinator should get created.
 	 * @param autoJoinTransactions Should the session automatically join JTA transactions?
 	 * @param timestamp The timestamp for this session
 	 * @param interceptor The interceptor to be applied to this session
 	 * @param flushBeforeCompletionEnabled Should we auto flush before completion of transaction
 	 * @param autoCloseSessionEnabled Should we auto close after completion of transaction
 	 * @param connectionReleaseMode The mode by which we should release JDBC connections.
 	 * @param tenantIdentifier The tenant identifier to use.  May be null
 	 */
 	SessionImpl(
 			final Connection connection,
 			final SessionFactoryImpl factory,
 			final SessionOwner sessionOwner,
 			final TransactionCoordinator transactionCoordinator,
 			final JdbcCoordinatorImpl jdbcCoordinator,
 			final Transaction transaction,
 			final ActionQueue.TransactionCompletionProcesses transactionCompletionProcesses,
 			final boolean autoJoinTransactions,
 			final long timestamp,
 			final Interceptor interceptor,
 			final StatementInspector statementInspector,
 			final boolean flushBeforeCompletionEnabled,
 			final boolean autoCloseSessionEnabled,
 			final ConnectionReleaseMode connectionReleaseMode,
 			final String tenantIdentifier) {
 		super( factory, tenantIdentifier );
 		this.timestamp = timestamp;
 		this.sessionOwner = sessionOwner;
 		this.interceptor = interceptor == null ? EmptyInterceptor.INSTANCE : interceptor;
 		this.actionQueue = new ActionQueue( this );
 		this.persistenceContext = new StatefulPersistenceContext( this );
 
 		this.autoCloseSessionEnabled = autoCloseSessionEnabled;
 		this.flushBeforeCompletionEnabled = flushBeforeCompletionEnabled;
 
 		initializeFromSessionOwner( sessionOwner );
 
 		if ( statementInspector == null ) {
 			this.statementInspector = new StatementInspector() {
 				@Override
+				@SuppressWarnings("deprecation")
 				public String inspect(String sql) {
 					return SessionImpl.this.interceptor.onPrepareStatement( sql );
 				}
 			};
 		}
 		else {
 			this.statementInspector = statementInspector;
 		}
 		this.jdbcSessionContext = new JdbcSessionContextImpl( factory, this.statementInspector );
 
 		if ( transactionCoordinator == null ) {
 			this.isTransactionCoordinatorShared = false;
 			this.connectionReleaseMode = connectionReleaseMode;
 			this.autoJoinTransactions = autoJoinTransactions;
 
 			this.jdbcCoordinator = new JdbcCoordinatorImpl( connection, this );
-			this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator( this.jdbcCoordinator, this );
+			this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator(
+					this.jdbcCoordinator,
+					this
+			);
 			this.currentHibernateTransaction = getTransaction();
 		}
 		else {
 			if ( connection != null ) {
 				throw new SessionException( "Cannot simultaneously share transaction context and specify connection" );
 			}
 			this.transactionCoordinator = transactionCoordinator;
 			this.jdbcCoordinator = jdbcCoordinator;
 			this.currentHibernateTransaction = transaction;
 			this.isTransactionCoordinatorShared = true;
 			this.autoJoinTransactions = false;
 			if ( transactionCompletionProcesses != null ) {
 				actionQueue.setTransactionCompletionProcesses( transactionCompletionProcesses, true );
 			}
 			if ( autoJoinTransactions ) {
 				LOG.debug(
 						"Session creation specified 'autoJoinTransactions', which is invalid in conjunction " +
 								"with sharing JDBC connection between sessions; ignoring"
 				);
 			}
 			if ( connectionReleaseMode != this.jdbcCoordinator.getConnectionReleaseMode() ) {
 				LOG.debug(
 						"Session creation specified 'getConnectionReleaseMode', which is invalid in conjunction " +
 								"with sharing JDBC connection between sessions; ignoring"
 				);
 			}
 			this.connectionReleaseMode = this.jdbcCoordinator.getConnectionReleaseMode();
 
 			transactionObserver = new TransactionObserver() {
 				@Override
 				public void afterBegin() {
 				}
 
 				@Override
 				public void beforeCompletion() {
 					if ( isOpen() && flushBeforeCompletionEnabled ) {
 						SessionImpl.this.managedFlush();
 					}
 					actionQueue.beforeTransactionCompletion();
 					try {
-						interceptor.beforeTransactionCompletion( currentHibernateTransaction );
+						SessionImpl.this.interceptor.beforeTransactionCompletion( currentHibernateTransaction );
 					}
 					catch (Throwable t) {
 						LOG.exceptionInBeforeTransactionCompletionInterceptor( t );
 					}
 				}
 
 				@Override
 				public void afterCompletion(boolean successful, boolean delayed) {
 					afterTransactionCompletion( successful, delayed );
 					if ( !isClosed() && autoCloseSessionEnabled ) {
 						managedClose();
 					}
 				}
 			};
 
 			transactionCoordinator.addObserver( transactionObserver );
 		}
 
 		loadQueryInfluencers = new LoadQueryInfluencers( factory );
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().openSession();
 		}
 
 		if ( TRACE_ENABLED ) {
 			LOG.tracef( "Opened session at timestamp: %s", timestamp );
 		}
 
 	}
 
 	private void initializeFromSessionOwner(SessionOwner sessionOwner) {
 		if ( sessionOwner != null ) {
 			if ( sessionOwner.getExceptionMapper() != null ) {
 				exceptionMapper = sessionOwner.getExceptionMapper();
 			}
 			else {
 				exceptionMapper = STANDARD_EXCEPTION_MAPPER;
 			}
 			if ( sessionOwner.getAfterCompletionAction() != null ) {
 				afterCompletionAction = sessionOwner.getAfterCompletionAction();
 			}
 			else {
 				afterCompletionAction = STANDARD_AFTER_COMPLETION_ACTION;
 			}
 			if ( sessionOwner.getManagedFlushChecker() != null ) {
 				managedFlushChecker = sessionOwner.getManagedFlushChecker();
 			}
 			else {
 				managedFlushChecker = STANDARD_MANAGED_FLUSH_CHECKER;
 			}
 		}
 		else {
 			exceptionMapper = STANDARD_EXCEPTION_MAPPER;
 			afterCompletionAction = STANDARD_AFTER_COMPLETION_ACTION;
 			managedFlushChecker = STANDARD_MANAGED_FLUSH_CHECKER;
 		}
 	}
 
 	@Override
 	public SharedSessionBuilder sessionWithOptions() {
 		return new SharedSessionBuilderImpl( this );
 	}
 
 	@Override
 	public void clear() {
 		errorIfClosed();
 		// Do not call checkTransactionSynchStatus() here -- if a delayed
 		// afterCompletion exists, it can cause an infinite loop.
 		pulseTransactionCoordinator();
 		internalClear();
 	}
 
 	private void internalClear() {
 		persistenceContext.clear();
 		actionQueue.clear();
 
 		final ClearEvent event = new ClearEvent( this );
 		for ( ClearEventListener listener : listeners( EventType.CLEAR ) ) {
 			listener.onClear( event );
 		}
 	}
 
 	@Override
 	public long getTimestamp() {
 		checkTransactionSynchStatus();
 		return timestamp;
 	}
 
 	@Override
 	public void close() throws HibernateException {
 		LOG.trace( "Closing session" );
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed" );
 		}
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().closeSession();
 		}
 		getEventListenerManager().end();
 
 		try {
 			if ( !isTransactionCoordinatorShared ) {
 				jdbcCoordinator.close();
 				return;
 			}
 			else {
 				if ( getActionQueue().hasBeforeTransactionActions() || getActionQueue().hasAfterTransactionActions() ) {
 					LOG.warn(
 							"On close, shared Session had before / after transaction actions that have not yet been processed"
 					);
 				}
 				return;
 			}
 		}
 		finally {
 			setClosed();
 			cleanup();
 		}
 	}
 
 	@Override
 	public boolean isAutoCloseSessionEnabled() {
 		return autoCloseSessionEnabled;
 	}
 
 	@Override
 	public boolean shouldAutoJoinTransaction() {
 		return autoJoinTransactions;
 	}
 
 	@Override
 	public boolean isOpen() {
 		checkTransactionSynchStatus();
 		return !isClosed();
 	}
 
 	private boolean isFlushModeNever() {
 		return FlushMode.isManualFlushMode( getFlushMode() );
 	}
 
 	private void managedFlush() {
 		if ( isClosed() ) {
 			LOG.trace( "Skipping auto-flush due to session closed" );
 			return;
 		}
 		LOG.trace( "Automatically flushing session" );
 		flush();
 	}
 
 	@Override
 	public boolean shouldAutoClose() {
 		if ( isClosed() ) {
 			return false;
 		}
 		else if ( sessionOwner != null ) {
 			return sessionOwner.shouldAutoCloseSession();
 		}
 		else {
 			return isAutoCloseSessionEnabled();
 		}
 	}
 
 	private void managedClose() {
 		LOG.trace( "Automatically closing session" );
 		close();
 	}
 
 	@Override
 	public Connection connection() throws HibernateException {
 		errorIfClosed();
 		return this.jdbcCoordinator.getLogicalConnection().getPhysicalConnection();
 	}
 
 	@Override
 	public boolean isConnected() {
 		checkTransactionSynchStatus();
 		return !isClosed() && this.jdbcCoordinator.getLogicalConnection().isOpen();
 	}
 
 	@Override
 	public boolean isTransactionInProgress() {
 		checkTransactionSynchStatus();
 		return !isClosed() && transactionCoordinator.getTransactionDriverControl()
 				.getStatus() == TransactionStatus.ACTIVE && transactionCoordinator.isJoined();
 	}
 
 	@Override
 	public Connection disconnect() throws HibernateException {
 		errorIfClosed();
 		LOG.debug( "Disconnecting session" );
 		return this.jdbcCoordinator.getLogicalConnection().manualDisconnect();
 	}
 
 	@Override
 	public void reconnect(Connection conn) throws HibernateException {
 		errorIfClosed();
 		LOG.debug( "Reconnecting session" );
 		checkTransactionSynchStatus();
 		this.jdbcCoordinator.getLogicalConnection().manualReconnect( conn );
 	}
 
 	@Override
 	public void setAutoClear(boolean enabled) {
 		errorIfClosed();
 		autoClear = enabled;
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		errorIfClosed();
 		autoJoinTransactions = false;
 	}
 
 	/**
 	 * Check if there is a Hibernate or JTA transaction in progress and,
 	 * if there is not, flush if necessary, make sure the connection has
 	 * been committed (if it is not in autocommit mode) and run the after
 	 * completion processing
 	 *
 	 * @param success Was the operation a success
 	 */
 	public void afterOperation(boolean success) {
-		if ( ! isTransactionInProgress() ) {
+		if ( !isTransactionInProgress() ) {
 			jdbcCoordinator.afterTransaction();
 		}
 	}
 
 	@Override
 	public SessionEventListenerManagerImpl getEventListenerManager() {
 		return sessionEventsManager;
 	}
 
 	@Override
 	public void addEventListeners(SessionEventListener... listeners) {
 		getEventListenerManager().addListener( listeners );
 	}
 
 	/**
 	 * clear all the internal collections, just
 	 * to help the garbage collector, does not
 	 * clear anything that is needed during the
 	 * afterTransactionCompletion() phase
 	 */
 	private void cleanup() {
 		persistenceContext.clear();
 	}
 
 	@Override
 	public LockMode getCurrentLockMode(Object object) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object == null ) {
 			throw new NullPointerException( "null object passed to getCurrentLockMode()" );
 		}
 		if ( object instanceof HibernateProxy ) {
-			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation(this);
+			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation( this );
 			if ( object == null ) {
 				return LockMode.NONE;
 			}
 		}
-		EntityEntry e = persistenceContext.getEntry(object);
+		EntityEntry e = persistenceContext.getEntry( object );
 		if ( e == null ) {
 			throw new TransientObjectException( "Given object not associated with the session" );
 		}
 		if ( e.getStatus() != Status.MANAGED ) {
 			throw new ObjectDeletedException(
 					"The given object was deleted",
 					e.getId(),
 					e.getPersister().getEntityName()
-				);
+			);
 		}
 		return e.getLockMode();
 	}
 
 	@Override
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		// todo : should this get moved to PersistentContext?
 		// logically, is PersistentContext the "thing" to which an interceptor gets attached?
-		final Object result = persistenceContext.getEntity(key);
+		final Object result = persistenceContext.getEntity( key );
 		if ( result == null ) {
 			final Object newObject = interceptor.getEntity( key.getEntityName(), key.getIdentifier() );
 			if ( newObject != null ) {
 				lock( newObject, LockMode.NONE );
 			}
 			return newObject;
 		}
 		else {
 			return result;
 		}
 	}
 
 	private void checkNoUnresolvedActionsBeforeOperation() {
 		if ( persistenceContext.getCascadeLevel() == 0 && actionQueue.hasUnresolvedEntityInsertActions() ) {
 			throw new IllegalStateException( "There are delayed insert actions before operation as cascade level 0." );
 		}
 	}
 
 	private void checkNoUnresolvedActionsAfterOperation() {
 		if ( persistenceContext.getCascadeLevel() == 0 ) {
 			actionQueue.checkNoUnresolvedActionsAfterOperation();
 		}
 		delayedAfterCompletion();
 	}
 
 	private void delayedAfterCompletion() {
-		if(transactionCoordinator instanceof JtaTransactionCoordinatorImpl) {
-			((JtaTransactionCoordinatorImpl)transactionCoordinator).getSynchronizationCallbackCoordinator().processAnyDelayedAfterCompletion();
+		if ( transactionCoordinator instanceof JtaTransactionCoordinatorImpl ) {
+			( (JtaTransactionCoordinatorImpl) transactionCoordinator ).getSynchronizationCallbackCoordinator()
+					.processAnyDelayedAfterCompletion();
 		}
 	}
 
 	// saveOrUpdate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void saveOrUpdate(Object object) throws HibernateException {
 		saveOrUpdate( null, object );
 	}
 
 	@Override
 	public void saveOrUpdate(String entityName, Object obj) throws HibernateException {
 		fireSaveOrUpdate( new SaveOrUpdateEvent( entityName, obj, this ) );
 	}
 
 	private void fireSaveOrUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE_UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 	private <T> Iterable<T> listeners(EventType<T> type) {
 		return eventListenerGroup( type ).listeners();
 	}
 
 	private <T> EventListenerGroup<T> eventListenerGroup(EventType<T> type) {
 		return factory.getServiceRegistry().getService( EventListenerRegistry.class ).getEventListenerGroup( type );
 	}
 
 
 	// save() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Serializable save(Object obj) throws HibernateException {
 		return save( null, obj );
 	}
 
 	@Override
 	public Serializable save(String entityName, Object object) throws HibernateException {
 		return fireSave( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private Serializable fireSave(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 		return event.getResultId();
 	}
 
 
 	// update() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void update(Object obj) throws HibernateException {
 		update( null, obj );
 	}
 
 	@Override
 	public void update(String entityName, Object object) throws HibernateException {
 		fireUpdate( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private void fireUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// lock() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void lock(String entityName, Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent( entityName, object, lockMode, this ) );
 	}
 
 	@Override
 	public LockRequest buildLockRequest(LockOptions lockOptions) {
-		return new LockRequestImpl(lockOptions);
+		return new LockRequestImpl( lockOptions );
 	}
 
 	@Override
 	public void lock(Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent( object, lockMode, this ) );
 	}
 
 	private void fireLock(String entityName, Object object, LockOptions options) {
 		fireLock( new LockEvent( entityName, object, options, this ) );
 	}
 
 	private void fireLock(Object object, LockOptions options) {
 		fireLock( new LockEvent( object, options, this ) );
 	}
 
 	private void fireLock(LockEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LockEventListener listener : listeners( EventType.LOCK ) ) {
 			listener.onLock( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// persist() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void persist(String entityName, Object object) throws HibernateException {
 		firePersist( new PersistEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public void persist(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	@Override
 	public void persist(String entityName, Object object, Map copiedAlready) throws HibernateException {
 		firePersist( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersist(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void firePersist(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// persistOnFlush() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void persistOnFlush(String entityName, Object object)
 			throws HibernateException {
 		firePersistOnFlush( new PersistEvent( entityName, object, this ) );
 	}
 
 	public void persistOnFlush(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	@Override
 	public void persistOnFlush(String entityName, Object object, Map copiedAlready)
 			throws HibernateException {
 		firePersistOnFlush( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersistOnFlush(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void firePersistOnFlush(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// merge() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Object merge(String entityName, Object object) throws HibernateException {
 		return fireMerge( new MergeEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public Object merge(Object object) throws HibernateException {
 		return merge( null, object );
 	}
 
 	@Override
 	public void merge(String entityName, Object object, Map copiedAlready) throws HibernateException {
 		fireMerge( copiedAlready, new MergeEvent( entityName, object, this ) );
 	}
 
 	private Object fireMerge(MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 		return event.getResult();
 	}
 
 	private void fireMerge(Map copiedAlready, MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// delete() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void delete(Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( object, this ) );
 	}
 
 	@Override
 	public void delete(String entityName, Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( entityName, object, this ) );
 	}
 
 	@Override
-	public void delete(String entityName, Object object, boolean isCascadeDeleteEnabled, Set transientEntities) throws HibernateException {
+	public void delete(String entityName, Object object, boolean isCascadeDeleteEnabled, Set transientEntities)
+			throws HibernateException {
 		if ( TRACE_ENABLED && persistenceContext.isRemovingOrphanBeforeUpates() ) {
 			logRemoveOrphanBeforeUpdates( "before continuing", entityName, object );
 		}
 		fireDelete(
 				new DeleteEvent(
 						entityName,
 						object,
 						isCascadeDeleteEnabled,
 						persistenceContext.isRemovingOrphanBeforeUpates(),
 						this
 				),
 				transientEntities
 		);
 		if ( TRACE_ENABLED && persistenceContext.isRemovingOrphanBeforeUpates() ) {
 			logRemoveOrphanBeforeUpdates( "after continuing", entityName, object );
 		}
 	}
 
 	@Override
 	public void removeOrphanBeforeUpdates(String entityName, Object child) {
 		// TODO: The removeOrphan concept is a temporary "hack" for HHH-6484.  This should be removed once action/task
 		// ordering is improved.
 		if ( TRACE_ENABLED ) {
 			logRemoveOrphanBeforeUpdates( "begin", entityName, child );
 		}
 		persistenceContext.beginRemoveOrphanBeforeUpdates();
 		try {
 			fireDelete( new DeleteEvent( entityName, child, false, true, this ) );
 		}
 		finally {
 			persistenceContext.endRemoveOrphanBeforeUpdates();
 			if ( TRACE_ENABLED ) {
 				logRemoveOrphanBeforeUpdates( "end", entityName, child );
 			}
 		}
 	}
 
 	private void logRemoveOrphanBeforeUpdates(String timing, String entityName, Object entity) {
 		final EntityEntry entityEntry = persistenceContext.getEntry( entity );
 		LOG.tracef(
 				"%s remove orphan before updates: [%s]",
 				timing,
 				entityEntry == null ? entityName : MessageHelper.infoString( entityName, entityEntry.getId() )
 		);
 	}
 
 	private void fireDelete(DeleteEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireDelete(DeleteEvent event, Set transientEntities) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event, transientEntities );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// load()/get() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void load(Object object, Serializable id) throws HibernateException {
-		LoadEvent event = new LoadEvent(id, object, this);
+		LoadEvent event = new LoadEvent( id, object, this );
 		fireLoad( event, LoadEventListener.RELOAD );
 	}
 
 	@Override
-	public Object load(Class entityClass, Serializable id) throws HibernateException {
+	public <T> T load(Class<T> entityClass, Serializable id) throws HibernateException {
 		return this.byId( entityClass ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id) throws HibernateException {
 		return this.byId( entityName ).getReference( id );
 	}
 
 	@Override
-	public Object get(Class entityClass, Serializable id) throws HibernateException {
+	public <T> T get(Class<T> entityClass, Serializable id) throws HibernateException {
 		return this.byId( entityClass ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id) throws HibernateException {
 		return this.byId( entityName ).load( id );
 	}
 
-	/**	
+	/**
 	 * Load the data for the object with the specified id into a newly created object.
 	 * This is only called when lazily initializing a proxy.
 	 * Do NOT return a proxy.
 	 */
 	@Override
 	public Object immediateLoad(String entityName, Serializable id) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
-			EntityPersister persister = getFactory().getEntityPersister(entityName);
+			EntityPersister persister = getFactory().getEntityPersister( entityName );
 			LOG.debugf( "Initializing proxy: %s", MessageHelper.infoString( persister, id, getFactory() ) );
 		}
 
-		LoadEvent event = new LoadEvent(id, entityName, true, this);
-		fireLoad(event, LoadEventListener.IMMEDIATE_LOAD);
+		LoadEvent event = new LoadEvent( id, entityName, true, this );
+		fireLoad( event, LoadEventListener.IMMEDIATE_LOAD );
 		return event.getResult();
 	}
 
 	@Override
-	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable) throws HibernateException {
+	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable)
+			throws HibernateException {
 		// todo : remove
 		LoadEventListener.LoadType type = nullable
 				? LoadEventListener.INTERNAL_LOAD_NULLABLE
 				: eager
-						? LoadEventListener.INTERNAL_LOAD_EAGER
-						: LoadEventListener.INTERNAL_LOAD_LAZY;
-		LoadEvent event = new LoadEvent(id, entityName, true, this);
+				? LoadEventListener.INTERNAL_LOAD_EAGER
+				: LoadEventListener.INTERNAL_LOAD_LAZY;
+		LoadEvent event = new LoadEvent( id, entityName, true, this );
 		fireLoad( event, type );
 		if ( !nullable ) {
 			UnresolvableObjectException.throwIfNull( event.getResult(), id, entityName );
 		}
 		return event.getResult();
 	}
 
 	@Override
-	public Object load(Class entityClass, Serializable id, LockMode lockMode) throws HibernateException {
+	public <T> T load(Class<T> entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityClass ).with( new LockOptions( lockMode ) ).getReference( id );
 	}
 
 	@Override
-	public Object load(Class entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
+	public <T> T load(Class<T> entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityClass ).with( lockOptions ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityName ).with( new LockOptions( lockMode ) ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityName ).with( lockOptions ).getReference( id );
 	}
 
 	@Override
-	public Object get(Class entityClass, Serializable id, LockMode lockMode) throws HibernateException {
+	public <T> T get(Class<T> entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityClass ).with( new LockOptions( lockMode ) ).load( id );
 	}
 
 	@Override
-	public Object get(Class entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
+	public <T> T get(Class<T> entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityClass ).with( lockOptions ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityName ).with( new LockOptions( lockMode ) ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityName ).with( lockOptions ).load( id );
 	}
-	
+
 	@Override
 	public IdentifierLoadAccessImpl byId(String entityName) {
 		return new IdentifierLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public <T> IdentifierLoadAccessImpl<T> byId(Class<T> entityClass) {
-		return new IdentifierLoadAccessImpl( entityClass );
+		return new IdentifierLoadAccessImpl<T>( entityClass );
 	}
 
 	@Override
 	public NaturalIdLoadAccess byNaturalId(String entityName) {
 		return new NaturalIdLoadAccessImpl( entityName );
 	}
 
 	@Override
-	public NaturalIdLoadAccess byNaturalId(Class entityClass) {
-		return new NaturalIdLoadAccessImpl( entityClass );
+	public <T> NaturalIdLoadAccess<T> byNaturalId(Class<T> entityClass) {
+		return new NaturalIdLoadAccessImpl<T>( entityClass );
 	}
 
 	@Override
 	public SimpleNaturalIdLoadAccess bySimpleNaturalId(String entityName) {
 		return new SimpleNaturalIdLoadAccessImpl( entityName );
 	}
 
 	@Override
-	public SimpleNaturalIdLoadAccess bySimpleNaturalId(Class entityClass) {
-		return new SimpleNaturalIdLoadAccessImpl( entityClass );
+	public <T> SimpleNaturalIdLoadAccess<T> bySimpleNaturalId(Class<T> entityClass) {
+		return new SimpleNaturalIdLoadAccessImpl<T>( entityClass );
 	}
 
 	private void fireLoad(LoadEvent event, LoadType loadType) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LoadEventListener listener : listeners( EventType.LOAD ) ) {
 			listener.onLoad( event, loadType );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireResolveNaturalId(ResolveNaturalIdEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ResolveNaturalIdEventListener listener : listeners( EventType.RESOLVE_NATURAL_ID ) ) {
 			listener.onResolveNaturalId( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// refresh() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void refresh(Object object) throws HibernateException {
 		refresh( null, object );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object) throws HibernateException {
 		fireRefresh( new RefreshEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public void refresh(Object object, LockMode lockMode) throws HibernateException {
 		fireRefresh( new RefreshEvent( object, lockMode, this ) );
 	}
 
 	@Override
 	public void refresh(Object object, LockOptions lockOptions) throws HibernateException {
 		refresh( null, object, lockOptions );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object, LockOptions lockOptions) throws HibernateException {
 		fireRefresh( new RefreshEvent( entityName, object, lockOptions, this ) );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object, Map refreshedAlready) throws HibernateException {
 		fireRefresh( refreshedAlready, new RefreshEvent( entityName, object, this ) );
 	}
 
 	private void fireRefresh(RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireRefresh(Map refreshedAlready, RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event, refreshedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// replicate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void replicate(Object obj, ReplicationMode replicationMode) throws HibernateException {
 		fireReplicate( new ReplicateEvent( obj, replicationMode, this ) );
 	}
 
 	@Override
 	public void replicate(String entityName, Object obj, ReplicationMode replicationMode)
-	throws HibernateException {
+			throws HibernateException {
 		fireReplicate( new ReplicateEvent( entityName, obj, replicationMode, this ) );
 	}
 
 	private void fireReplicate(ReplicateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ReplicateEventListener listener : listeners( EventType.REPLICATE ) ) {
 			listener.onReplicate( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// evict() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * remove any hard references to the entity that are held by the infrastructure
 	 * (references held by application or other persistent instances are okay)
 	 */
 	@Override
 	public void evict(Object object) throws HibernateException {
 		fireEvict( new EvictEvent( object, this ) );
 	}
 
 	private void fireEvict(EvictEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( EvictEventListener listener : listeners( EventType.EVICT ) ) {
 			listener.onEvict( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	/**
 	 * detect in-memory changes, determine if the changes are to tables
 	 * named in the query and, if so, complete execution the flush
 	 */
 	protected boolean autoFlushIfRequired(Set querySpaces) throws HibernateException {
 		errorIfClosed();
-		if ( ! isTransactionInProgress() ) {
+		if ( !isTransactionInProgress() ) {
 			// do not auto-flush while outside a transaction
 			return false;
 		}
 		AutoFlushEvent event = new AutoFlushEvent( querySpaces, this );
 		listeners( EventType.AUTO_FLUSH );
 		for ( AutoFlushEventListener listener : listeners( EventType.AUTO_FLUSH ) ) {
 			listener.onAutoFlush( event );
 		}
 		return event.isFlushRequired();
 	}
 
 	@Override
 	public boolean isDirty() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		LOG.debug( "Checking session dirtiness" );
 		if ( actionQueue.areInsertionsOrDeletionsQueued() ) {
 			LOG.debug( "Session dirty (scheduled updates and insertions)" );
 			return true;
 		}
 		DirtyCheckEvent event = new DirtyCheckEvent( this );
 		for ( DirtyCheckEventListener listener : listeners( EventType.DIRTY_CHECK ) ) {
 			listener.onDirtyCheck( event );
 		}
 		delayedAfterCompletion();
 		return event.isDirty();
 	}
 
 	@Override
 	public void flush() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( persistenceContext.getCascadeLevel() > 0 ) {
-			throw new HibernateException("Flush during cascade is dangerous");
+			throw new HibernateException( "Flush during cascade is dangerous" );
 		}
 		FlushEvent flushEvent = new FlushEvent( this );
 		for ( FlushEventListener listener : listeners( EventType.FLUSH ) ) {
 			listener.onFlush( flushEvent );
 		}
 		delayedAfterCompletion();
 	}
 
 	@Override
 	public void forceFlush(EntityEntry entityEntry) throws HibernateException {
 		errorIfClosed();
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Flushing to force deletion of re-saved object: %s",
-					MessageHelper.infoString( entityEntry.getPersister(), entityEntry.getId(), getFactory() ) );
+					MessageHelper.infoString( entityEntry.getPersister(), entityEntry.getId(), getFactory() )
+			);
 		}
 
 		if ( persistenceContext.getCascadeLevel() > 0 ) {
 			throw new ObjectDeletedException(
-				"deleted object would be re-saved by cascade (remove deleted object from associations)",
-				entityEntry.getId(),
-				entityEntry.getPersister().getEntityName()
+					"deleted object would be re-saved by cascade (remove deleted object from associations)",
+					entityEntry.getId(),
+					entityEntry.getPersister().getEntityName()
 			);
 		}
 
 		flush();
 	}
 
 	@Override
 	public List list(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
-		
+
 		HQLQueryPlan plan = queryParameters.getQueryPlan();
-		if (plan == null) {
+		if ( plan == null ) {
 			plan = getHQLQueryPlan( query, false );
 		}
-		
+
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		List results = Collections.EMPTY_LIST;
 		boolean success = false;
 
 		dontFlushFromFind++;   //stops flush being called multiple times if this method is recursively called
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
 			dontFlushFromFind--;
 			afterOperation( success );
 			delayedAfterCompletion();
 		}
 		return results;
 	}
 
 	@Override
 	public int executeUpdate(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate( queryParameters, this );
 			success = true;
 		}
 		finally {
 			afterOperation( success );
 			delayedAfterCompletion();
 		}
 		return result;
 	}
 
 	@Override
-    public int executeNativeUpdate(NativeSQLQuerySpecification nativeQuerySpecification,
-            QueryParameters queryParameters) throws HibernateException {
-        errorIfClosed();
-        checkTransactionSynchStatus();
-        queryParameters.validateParameters();
-        NativeSQLQueryPlan plan = getNativeSQLQueryPlan( nativeQuerySpecification );
+	public int executeNativeUpdate(
+			NativeSQLQuerySpecification nativeQuerySpecification,
+			QueryParameters queryParameters) throws HibernateException {
+		errorIfClosed();
+		checkTransactionSynchStatus();
+		queryParameters.validateParameters();
+		NativeSQLQueryPlan plan = getNativeSQLQueryPlan( nativeQuerySpecification );
 
 
-        autoFlushIfRequired( plan.getCustomQuery().getQuerySpaces() );
+		autoFlushIfRequired( plan.getCustomQuery().getQuerySpaces() );
 
-        boolean success = false;
-        int result = 0;
-        try {
-            result = plan.performExecuteUpdate(queryParameters, this);
-            success = true;
-        } finally {
-            afterOperation( success );
-    		delayedAfterCompletion();
+		boolean success = false;
+		int result = 0;
+		try {
+			result = plan.performExecuteUpdate( queryParameters, this );
+			success = true;
 		}
-        return result;
-    }
+		finally {
+			afterOperation( success );
+			delayedAfterCompletion();
+		}
+		return result;
+	}
 
 	@Override
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, true );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		dontFlushFromFind++; //stops flush being called multiple times if this method is recursively called
 		try {
 			return plan.performIterate( queryParameters, this );
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	@Override
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 		dontFlushFromFind++;
 		try {
 			return plan.performScroll( queryParameters, this );
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	@Override
 	public Query createFilter(Object collection, String queryString) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		CollectionFilterImpl filter = new CollectionFilterImpl(
 				queryString,
-		        collection,
-		        this,
-		        getFilterQueryPlan( collection, queryString, null, false ).getParameterMetadata()
+				collection,
+				this,
+				getFilterQueryPlan( collection, queryString, null, false ).getParameterMetadata()
 		);
 		filter.setComment( queryString );
 		delayedAfterCompletion();
 		return filter;
 	}
 
 	@Override
 	public Query getNamedQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		Query query = super.getNamedQuery( queryName );
 		delayedAfterCompletion();
 		return query;
 	}
 
 	@Override
 	public Object instantiate(String entityName, Serializable id) throws HibernateException {
 		return instantiate( factory.getEntityPersister( entityName ), id );
 	}
 
 	/**
 	 * give the interceptor an opportunity to override the default instantiation
 	 */
 	@Override
 	public Object instantiate(EntityPersister persister, Serializable id) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
-		Object result = interceptor.instantiate( persister.getEntityName(), persister.getEntityMetamodel().getEntityMode(), id );
+		Object result = interceptor.instantiate(
+				persister.getEntityName(),
+				persister.getEntityMetamodel().getEntityMode(),
+				id
+		);
 		if ( result == null ) {
 			result = persister.instantiate( id, this );
 		}
 		delayedAfterCompletion();
 		return result;
 	}
 
 	@Override
 	public void setFlushMode(FlushMode flushMode) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		LOG.tracev( "Setting flush mode to: {0}", flushMode );
 		this.flushMode = flushMode;
 	}
 
 	@Override
 	public FlushMode getFlushMode() {
 		checkTransactionSynchStatus();
 		return flushMode;
 	}
 
 	@Override
 	public CacheMode getCacheMode() {
 		checkTransactionSynchStatus();
 		return cacheMode;
 	}
 
 	@Override
 	public void setCacheMode(CacheMode cacheMode) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		LOG.tracev( "Setting cache mode to: {0}", cacheMode );
-		this.cacheMode= cacheMode;
+		this.cacheMode = cacheMode;
 	}
 
 	@Override
 	public Transaction beginTransaction() throws HibernateException {
 		errorIfClosed();
 		Transaction result = getTransaction();
 		result.begin();
 		return result;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister(final String entityName, final Object object) {
 		errorIfClosed();
-		if (entityName==null) {
+		if ( entityName == null ) {
 			return factory.getEntityPersister( guessEntityName( object ) );
 		}
 		else {
 			// try block is a hack around fact that currently tuplizers are not
 			// given the opportunity to resolve a subclass entity name.  this
 			// allows the (we assume custom) interceptor the ability to
 			// influence this decision if we were not able to based on the
 			// given entityName
 			try {
 				return factory.getEntityPersister( entityName ).getSubclassEntityPersister( object, getFactory() );
 			}
-			catch( HibernateException e ) {
+			catch (HibernateException e) {
 				try {
 					return getEntityPersister( null, object );
 				}
-				catch( HibernateException e2 ) {
+				catch (HibernateException e2) {
 					throw e;
 				}
 			}
 		}
 	}
 
 	// not for internal use:
 	@Override
 	public Serializable getIdentifier(Object object) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object instanceof HibernateProxy ) {
 			LazyInitializer li = ( (HibernateProxy) object ).getHibernateLazyInitializer();
 			if ( li.getSession() != this ) {
 				throw new TransientObjectException( "The proxy was not associated with this session" );
 			}
 			return li.getIdentifier();
 		}
 		else {
-			EntityEntry entry = persistenceContext.getEntry(object);
+			EntityEntry entry = persistenceContext.getEntry( object );
 			if ( entry == null ) {
 				throw new TransientObjectException( "The instance was not associated with this session" );
 			}
 			return entry.getId();
 		}
 	}
 
 	/**
 	 * Get the id value for an object that is actually associated with the session. This
 	 * is a bit stricter than getEntityIdentifierIfNotUnsaved().
 	 */
 	@Override
 	public Serializable getContextEntityIdentifier(Object object) {
 		errorIfClosed();
 		if ( object instanceof HibernateProxy ) {
 			return getProxyIdentifier( object );
 		}
 		else {
-			EntityEntry entry = persistenceContext.getEntry(object);
+			EntityEntry entry = persistenceContext.getEntry( object );
 			return entry != null ? entry.getId() : null;
 		}
 	}
 
 	private Serializable getProxyIdentifier(Object proxy) {
 		return ( (HibernateProxy) proxy ).getHibernateLazyInitializer().getIdentifier();
 	}
 
 	private FilterQueryPlan getFilterQueryPlan(
 			Object collection,
 			String filter,
 			QueryParameters parameters,
 			boolean shallow) throws HibernateException {
 		if ( collection == null ) {
 			throw new NullPointerException( "null collection passed to filter" );
 		}
 
 		CollectionEntry entry = persistenceContext.getCollectionEntryOrNull( collection );
-		final CollectionPersister roleBeforeFlush = (entry == null) ? null : entry.getLoadedPersister();
+		final CollectionPersister roleBeforeFlush = ( entry == null ) ? null : entry.getLoadedPersister();
 
 		FilterQueryPlan plan = null;
 		if ( roleBeforeFlush == null ) {
 			// if it was previously unreferenced, we need to flush in order to
 			// get its state into the database in order to execute query
 			flush();
 			entry = persistenceContext.getCollectionEntryOrNull( collection );
-			CollectionPersister roleAfterFlush = (entry == null) ? null : entry.getLoadedPersister();
+			CollectionPersister roleAfterFlush = ( entry == null ) ? null : entry.getLoadedPersister();
 			if ( roleAfterFlush == null ) {
 				throw new QueryException( "The collection was unreferenced" );
 			}
 			plan = factory.getQueryPlanCache().getFilterQueryPlan(
 					filter,
 					roleAfterFlush.getRole(),
 					shallow,
 					getLoadQueryInfluencers().getEnabledFilters()
 			);
 		}
 		else {
 			// otherwise, we only need to flush if there are in-memory changes
 			// to the queried tables
 			plan = factory.getQueryPlanCache().getFilterQueryPlan(
 					filter,
 					roleBeforeFlush.getRole(),
 					shallow,
 					getLoadQueryInfluencers().getEnabledFilters()
 			);
 			if ( autoFlushIfRequired( plan.getQuerySpaces() ) ) {
 				// might need to run a different filter entirely after the flush
 				// because the collection role may have changed
 				entry = persistenceContext.getCollectionEntryOrNull( collection );
-				CollectionPersister roleAfterFlush = (entry == null) ? null : entry.getLoadedPersister();
+				CollectionPersister roleAfterFlush = ( entry == null ) ? null : entry.getLoadedPersister();
 				if ( roleBeforeFlush != roleAfterFlush ) {
 					if ( roleAfterFlush == null ) {
 						throw new QueryException( "The collection was dereferenced" );
 					}
 					plan = factory.getQueryPlanCache().getFilterQueryPlan(
 							filter,
 							roleAfterFlush.getRole(),
 							shallow,
 							getLoadQueryInfluencers().getEnabledFilters()
 					);
 				}
 			}
 		}
 
 		if ( parameters != null ) {
 			parameters.getPositionalParameterValues()[0] = entry.getLoadedKey();
 			parameters.getPositionalParameterTypes()[0] = entry.getLoadedPersister().getKeyType();
 		}
 
 		return plan;
 	}
 
 	@Override
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters)
-	throws HibernateException {
+			throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		FilterQueryPlan plan = getFilterQueryPlan( collection, filter, queryParameters, false );
 		List results = Collections.EMPTY_LIST;
 
 		boolean success = false;
 		dontFlushFromFind++;   //stops flush being called multiple times if this method is recursively called
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
 			dontFlushFromFind--;
-			afterOperation(success);
+			afterOperation( success );
 			delayedAfterCompletion();
 		}
 		return results;
 	}
 
 	@Override
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters)
-	throws HibernateException {
+			throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		FilterQueryPlan plan = getFilterQueryPlan( collection, filter, queryParameters, true );
 		Iterator itr = plan.performIterate( queryParameters, this );
 		delayedAfterCompletion();
 		return itr;
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass, String alias) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return new CriteriaImpl( persistentClass.getName(), alias, this );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName, String alias) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
-		return new CriteriaImpl(entityName, alias, this);
+		return new CriteriaImpl( entityName, alias, this );
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return new CriteriaImpl( persistentClass.getName(), this );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
-		return new CriteriaImpl(entityName, this);
+		return new CriteriaImpl( entityName, this );
 	}
 
 	@Override
 	public ScrollableResults scroll(Criteria criteria, ScrollMode scrollMode) {
 		// TODO: Is this guaranteed to always be CriteriaImpl?
 		CriteriaImpl criteriaImpl = (CriteriaImpl) criteria;
-		
+
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		String entityName = criteriaImpl.getEntityOrClassName();
 		CriteriaLoader loader = new CriteriaLoader(
-				getOuterJoinLoadable(entityName),
+				getOuterJoinLoadable( entityName ),
 				factory,
 				criteriaImpl,
 				entityName,
 				getLoadQueryInfluencers()
 		);
 		autoFlushIfRequired( loader.getQuerySpaces() );
 		dontFlushFromFind++;
 		try {
-			return loader.scroll(this, scrollMode);
+			return loader.scroll( this, scrollMode );
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	@Override
 	public List list(Criteria criteria) throws HibernateException {
 		// TODO: Is this guaranteed to always be CriteriaImpl?
 		CriteriaImpl criteriaImpl = (CriteriaImpl) criteria;
-				
+
 		final NaturalIdLoadAccess naturalIdLoadAccess = this.tryNaturalIdLoadAccess( criteriaImpl );
 		if ( naturalIdLoadAccess != null ) {
 			// EARLY EXIT!
 			return Arrays.asList( naturalIdLoadAccess.load() );
 		}
 
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		String[] implementors = factory.getImplementors( criteriaImpl.getEntityOrClassName() );
 		int size = implementors.length;
 
 		CriteriaLoader[] loaders = new CriteriaLoader[size];
 		Set spaces = new HashSet();
-		for( int i=0; i <size; i++ ) {
+		for ( int i = 0; i < size; i++ ) {
 
 			loaders[i] = new CriteriaLoader(
 					getOuterJoinLoadable( implementors[i] ),
 					factory,
 					criteriaImpl,
 					implementors[i],
 					getLoadQueryInfluencers()
-				);
+			);
 
 			spaces.addAll( loaders[i].getQuerySpaces() );
 
 		}
 
-		autoFlushIfRequired(spaces);
+		autoFlushIfRequired( spaces );
 
 		List results = Collections.EMPTY_LIST;
 		dontFlushFromFind++;
 		boolean success = false;
 		try {
-			for( int i=0; i<size; i++ ) {
-				final List currentResults = loaders[i].list(this);
-				currentResults.addAll(results);
+			for ( int i = 0; i < size; i++ ) {
+				final List currentResults = loaders[i].list( this );
+				currentResults.addAll( results );
 				results = currentResults;
 			}
 			success = true;
 		}
 		finally {
 			dontFlushFromFind--;
-			afterOperation(success);
+			afterOperation( success );
 			delayedAfterCompletion();
 		}
 
 		return results;
 	}
 
 	/**
 	 * Checks to see if the CriteriaImpl is a naturalId lookup that can be done via
 	 * NaturalIdLoadAccess
 	 *
 	 * @param criteria The criteria to check as a complete natural identifier lookup.
 	 *
 	 * @return A fully configured NaturalIdLoadAccess or null, if null is returned the standard CriteriaImpl execution
-	 *         should be performed
+	 * should be performed
 	 */
 	private NaturalIdLoadAccess tryNaturalIdLoadAccess(CriteriaImpl criteria) {
 		// See if the criteria lookup is by naturalId
 		if ( !criteria.isLookupByNaturalKey() ) {
 			return null;
 		}
 
 		final String entityName = criteria.getEntityOrClassName();
 		final EntityPersister entityPersister = factory.getEntityPersister( entityName );
 
 		// Verify the entity actually has a natural id, needed for legacy support as NaturalIdentifier criteria
 		// queries did no natural id validation
 		if ( !entityPersister.hasNaturalIdentifier() ) {
 			return null;
 		}
 
 		// Since isLookupByNaturalKey is true there can be only one CriterionEntry and getCriterion() will
 		// return an instanceof NaturalIdentifier
 		final CriterionEntry criterionEntry = (CriterionEntry) criteria.iterateExpressionEntries().next();
 		final NaturalIdentifier naturalIdentifier = (NaturalIdentifier) criterionEntry.getCriterion();
 
 		final Map<String, Object> naturalIdValues = naturalIdentifier.getNaturalIdValues();
 		final int[] naturalIdentifierProperties = entityPersister.getNaturalIdentifierProperties();
 
 		// Verify the NaturalIdentifier criterion includes all naturalId properties, first check that the property counts match
 		if ( naturalIdentifierProperties.length != naturalIdValues.size() ) {
 			return null;
 		}
 
 		final String[] propertyNames = entityPersister.getPropertyNames();
 		final NaturalIdLoadAccess naturalIdLoader = this.byNaturalId( entityName );
 
 		// Build NaturalIdLoadAccess and in the process verify all naturalId properties were specified
-		for ( int i = 0; i < naturalIdentifierProperties.length; i++ ) {
-			final String naturalIdProperty = propertyNames[naturalIdentifierProperties[i]];
+		for ( int naturalIdentifierProperty : naturalIdentifierProperties ) {
+			final String naturalIdProperty = propertyNames[naturalIdentifierProperty];
 			final Object naturalIdValue = naturalIdValues.get( naturalIdProperty );
 
 			if ( naturalIdValue == null ) {
 				// A NaturalId property is missing from the critera query, can't use NaturalIdLoadAccess
 				return null;
 			}
 
 			naturalIdLoader.using( naturalIdProperty, naturalIdValue );
 		}
 
 		// Critera query contains a valid naturalId, use the new API
-		LOG.warn( "Session.byNaturalId(" + entityName
-				+ ") should be used for naturalId queries instead of Restrictions.naturalId() from a Criteria" );
+		LOG.warn(
+				"Session.byNaturalId(" + entityName
+						+ ") should be used for naturalId queries instead of Restrictions.naturalId() from a Criteria"
+		);
 
 		return naturalIdLoader;
 	}
 
 	private OuterJoinLoadable getOuterJoinLoadable(String entityName) throws MappingException {
-		EntityPersister persister = factory.getEntityPersister(entityName);
-		if ( !(persister instanceof OuterJoinLoadable) ) {
+		EntityPersister persister = factory.getEntityPersister( entityName );
+		if ( !( persister instanceof OuterJoinLoadable ) ) {
 			throw new MappingException( "class persister is not OuterJoinLoadable: " + entityName );
 		}
-		return ( OuterJoinLoadable ) persister;
+		return (OuterJoinLoadable) persister;
 	}
 
 	@Override
 	public boolean contains(Object object) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object instanceof HibernateProxy ) {
 			//do not use proxiesByKey, since not all
 			//proxies that point to this session's
 			//instances are in that collection!
 			LazyInitializer li = ( (HibernateProxy) object ).getHibernateLazyInitializer();
 			if ( li.isUninitialized() ) {
 				//if it is an uninitialized proxy, pointing
 				//with this session, then when it is accessed,
 				//the underlying instance will be "contained"
-				return li.getSession()==this;
+				return li.getSession() == this;
 			}
 			else {
 				//if it is initialized, see if the underlying
 				//instance is contained, since we need to
 				//account for the fact that it might have been
 				//evicted
 				object = li.getImplementation();
 			}
 		}
 		// A session is considered to contain an entity only if the entity has
 		// an entry in the session's persistence context and the entry reports
 		// that the entity has not been removed
 		EntityEntry entry = persistenceContext.getEntry( object );
 		delayedAfterCompletion();
 		return entry != null && entry.getStatus() != Status.DELETED && entry.getStatus() != Status.GONE;
 	}
 
 	@Override
 	public Query createQuery(String queryString) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createQuery( queryString );
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(String sql) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createSQLQuery( sql );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createStoredProcedureCall( procedureName );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName, String... resultSetMappings) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createStoredProcedureCall( procedureName, resultSetMappings );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName, Class... resultClasses) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createStoredProcedureCall( procedureName, resultClasses );
 	}
 
 	@Override
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
-	throws HibernateException {
+			throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Scroll SQL query: {0}", customQuery.getSQL() );
 		}
 
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 
 		autoFlushIfRequired( loader.getQuerySpaces() );
 
 		dontFlushFromFind++; //stops flush being called multiple times if this method is recursively called
 		try {
-			return loader.scroll(queryParameters, this);
+			return loader.scroll( queryParameters, this );
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	// basically just an adapted copy of find(CriteriaImpl)
 	@Override
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
-	throws HibernateException {
+			throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "SQL query: {0}", customQuery.getSQL() );
 		}
 
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 
 		autoFlushIfRequired( loader.getQuerySpaces() );
 
 		dontFlushFromFind++;
 		boolean success = false;
 		try {
-			List results = loader.list(this, queryParameters);
+			List results = loader.list( this, queryParameters );
 			success = true;
 			return results;
 		}
 		finally {
 			dontFlushFromFind--;
 			delayedAfterCompletion();
-			afterOperation(success);
+			afterOperation( success );
 		}
 	}
 
 	@Override
 	public SessionFactoryImplementor getSessionFactory() {
 		checkTransactionSynchStatus();
 		return factory;
 	}
 
 	@Override
 	public void initializeCollection(PersistentCollection collection, boolean writing)
-	throws HibernateException {
+			throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		InitializeCollectionEvent event = new InitializeCollectionEvent( collection, this );
 		for ( InitializeCollectionEventListener listener : listeners( EventType.INIT_COLLECTION ) ) {
 			listener.onInitializeCollection( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	@Override
 	public String bestGuessEntityName(Object object) {
-		if (object instanceof HibernateProxy) {
-			LazyInitializer initializer = ( ( HibernateProxy ) object ).getHibernateLazyInitializer();
+		if ( object instanceof HibernateProxy ) {
+			LazyInitializer initializer = ( (HibernateProxy) object ).getHibernateLazyInitializer();
 			// it is possible for this method to be called during flush processing,
 			// so make certain that we do not accidentally initialize an uninitialized proxy
 			if ( initializer.isUninitialized() ) {
 				return initializer.getEntityName();
 			}
 			object = initializer.getImplementation();
 		}
-		EntityEntry entry = persistenceContext.getEntry(object);
-		if (entry==null) {
-			return guessEntityName(object);
+		EntityEntry entry = persistenceContext.getEntry( object );
+		if ( entry == null ) {
+			return guessEntityName( object );
 		}
 		else {
 			return entry.getPersister().getEntityName();
 		}
 	}
 
 	@Override
 	public String getEntityName(Object object) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
-		if (object instanceof HibernateProxy) {
+		if ( object instanceof HibernateProxy ) {
 			if ( !persistenceContext.containsProxy( object ) ) {
-				throw new TransientObjectException("proxy was not associated with the session");
+				throw new TransientObjectException( "proxy was not associated with the session" );
 			}
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation();
 		}
 
-		EntityEntry entry = persistenceContext.getEntry(object);
+		EntityEntry entry = persistenceContext.getEntry( object );
 		if ( entry == null ) {
 			throwTransientObjectException( object );
 		}
 		return entry.getPersister().getEntityName();
 	}
 
 	private void throwTransientObjectException(Object object) throws HibernateException {
 		throw new TransientObjectException(
 				"object references an unsaved transient instance - save the transient instance before flushing: " +
-				guessEntityName(object)
-			);
+						guessEntityName( object )
+		);
 	}
 
 	@Override
 	public String guessEntityName(Object object) throws HibernateException {
 		errorIfClosed();
 		return entityNameResolver.resolveEntityName( object );
 	}
 
 	@Override
 	public void cancelQuery() throws HibernateException {
 		errorIfClosed();
 		this.jdbcCoordinator.cancelLastQuery();
 	}
 
 	@Override
 	public Interceptor getInterceptor() {
 		checkTransactionSynchStatus();
 		return interceptor;
 	}
 
 	@Override
 	public int getDontFlushFromFind() {
 		return dontFlushFromFind;
 	}
 
 	@Override
 	public String toString() {
-		StringBuilder buf = new StringBuilder(500)
-			.append( "SessionImpl(" );
+		StringBuilder buf = new StringBuilder( 500 )
+				.append( "SessionImpl(" );
 		if ( !isClosed() ) {
-			buf.append(persistenceContext)
-				.append(";")
-				.append(actionQueue);
+			buf.append( persistenceContext )
+					.append( ";" )
+					.append( actionQueue );
 		}
 		else {
-			buf.append("<closed>");
+			buf.append( "<closed>" );
 		}
-		return buf.append(')').toString();
+		return buf.append( ')' ).toString();
 	}
 
 	@Override
 	public ActionQueue getActionQueue() {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return actionQueue;
 	}
 
 	@Override
 	public PersistenceContext getPersistenceContext() {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return persistenceContext;
 	}
 
 	@Override
 	public SessionStatistics getStatistics() {
 		checkTransactionSynchStatus();
-		return new SessionStatisticsImpl(this);
+		return new SessionStatisticsImpl( this );
 	}
 
 	@Override
 	public boolean isEventSource() {
 		checkTransactionSynchStatus();
 		return true;
 	}
 
 	@Override
 	public boolean isDefaultReadOnly() {
 		return persistenceContext.isDefaultReadOnly();
 	}
 
 	@Override
 	public void setDefaultReadOnly(boolean defaultReadOnly) {
 		persistenceContext.setDefaultReadOnly( defaultReadOnly );
 	}
 
 	@Override
 	public boolean isReadOnly(Object entityOrProxy) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return persistenceContext.isReadOnly( entityOrProxy );
 	}
 
 	@Override
 	public void setReadOnly(Object entity, boolean readOnly) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		persistenceContext.setReadOnly( entity, readOnly );
 	}
 
 	@Override
 	public void doWork(final Work work) throws HibernateException {
 		WorkExecutorVisitable<Void> realWork = new WorkExecutorVisitable<Void>() {
 			@Override
 			public Void accept(WorkExecutor<Void> workExecutor, Connection connection) throws SQLException {
 				workExecutor.executeWork( work, connection );
 				return null;
 			}
 		};
 		doWork( realWork );
 	}
 
 	@Override
 	public <T> T doReturningWork(final ReturningWork<T> work) throws HibernateException {
 		WorkExecutorVisitable<T> realWork = new WorkExecutorVisitable<T>() {
 			@Override
 			public T accept(WorkExecutor<T> workExecutor, Connection connection) throws SQLException {
 				return workExecutor.executeReturningWork( work, connection );
 			}
 		};
 		return doWork( realWork );
 	}
 
 	private <T> T doWork(WorkExecutorVisitable<T> work) throws HibernateException {
 		return this.jdbcCoordinator.coordinateWork( work );
 	}
 
 	@Override
 	public void afterScrollOperation() {
 		// nothing to do in a stateful session
 	}
 
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		errorIfClosed();
 		return transactionCoordinator;
 	}
 
 	@Override
 	public JdbcCoordinator getJdbcCoordinator() {
 		return this.jdbcCoordinator;
 	}
 
 	@Override
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return loadQueryInfluencers;
 	}
 
 	// filter support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Filter getEnabledFilter(String filterName) {
 		checkTransactionSynchStatus();
 		return loadQueryInfluencers.getEnabledFilter( filterName );
 	}
 
 	@Override
 	public Filter enableFilter(String filterName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return loadQueryInfluencers.enableFilter( filterName );
 	}
 
 	@Override
 	public void disableFilter(String filterName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		loadQueryInfluencers.disableFilter( filterName );
 	}
 
 
 	// fetch profile support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean isFetchProfileEnabled(String name) throws UnknownProfileException {
 		return loadQueryInfluencers.isFetchProfileEnabled( name );
 	}
 
 	@Override
 	public void enableFetchProfile(String name) throws UnknownProfileException {
 		loadQueryInfluencers.enableFetchProfile( name );
 	}
 
 	@Override
 	public void disableFetchProfile(String name) throws UnknownProfileException {
 		loadQueryInfluencers.disableFetchProfile( name );
 	}
 
 	private void checkTransactionSynchStatus() {
 		pulseTransactionCoordinator();
 		delayedAfterCompletion();
 	}
 
 	private void pulseTransactionCoordinator() {
 		if ( !isClosed() ) {
 			transactionCoordinator.pulse();
 		}
 	}
 
 	/**
 	 * Used by JDK serialization...
 	 *
 	 * @param ois The input stream from which we are being read...
+	 *
 	 * @throws IOException Indicates a general IO stream exception
 	 * @throws ClassNotFoundException Indicates a class resolution issue
 	 */
 	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException, SQLException {
 		LOG.trace( "Deserializing session" );
 
 		ois.defaultReadObject();
 
 		entityNameResolver = new CoordinatingEntityNameResolver();
 
 		connectionReleaseMode = ConnectionReleaseMode.parse( (String) ois.readObject() );
 		autoClear = ois.readBoolean();
 		autoJoinTransactions = ois.readBoolean();
 		flushMode = FlushMode.valueOf( (String) ois.readObject() );
 		cacheMode = CacheMode.valueOf( (String) ois.readObject() );
 		flushBeforeCompletionEnabled = ois.readBoolean();
 		autoCloseSessionEnabled = ois.readBoolean();
 		interceptor = (Interceptor) ois.readObject();
 
 		factory = SessionFactoryImpl.deserialize( ois );
 		this.jdbcSessionContext = new JdbcSessionContextImpl( factory, statementInspector );
 		sessionOwner = (SessionOwner) ois.readObject();
 
 		initializeFromSessionOwner( sessionOwner );
 
 		jdbcCoordinator = JdbcCoordinatorImpl.deserialize( ois, this );
 
-		this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator( jdbcCoordinator, this );
+		this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator(
+				jdbcCoordinator,
+				this
+		);
 
 		persistenceContext = StatefulPersistenceContext.deserialize( ois, this );
 		actionQueue = ActionQueue.deserialize( ois, this );
 
 		loadQueryInfluencers = (LoadQueryInfluencers) ois.readObject();
 
 		// LoadQueryInfluencers.getEnabledFilters() tries to validate each enabled
 		// filter, which will fail when called before FilterImpl.afterDeserialize( factory );
 		// Instead lookup the filter by name and then call FilterImpl.afterDeserialize( factory ).
 		for ( String filterName : loadQueryInfluencers.getEnabledFilterNames() ) {
-			((FilterImpl) loadQueryInfluencers.getEnabledFilter( filterName )).afterDeserialize( factory );
+			( (FilterImpl) loadQueryInfluencers.getEnabledFilter( filterName ) ).afterDeserialize( factory );
 		}
 	}
 
 	/**
 	 * Used by JDK serialization...
 	 *
 	 * @param oos The output stream to which we are being written...
+	 *
 	 * @throws IOException Indicates a general IO stream exception
 	 */
 	private void writeObject(ObjectOutputStream oos) throws IOException {
 		if ( !jdbcCoordinator.isReadyForSerialization() ) {
 			throw new IllegalStateException( "Cannot serialize a session while connected" );
 		}
 
 		LOG.trace( "Serializing session" );
 
 		oos.defaultWriteObject();
 
 		oos.writeObject( connectionReleaseMode.toString() );
 		oos.writeBoolean( autoClear );
 		oos.writeBoolean( autoJoinTransactions );
 		oos.writeObject( flushMode.toString() );
 		oos.writeObject( cacheMode.name() );
 		oos.writeBoolean( flushBeforeCompletionEnabled );
 		oos.writeBoolean( autoCloseSessionEnabled );
 		// we need to writeObject() on this since interceptor is user defined
 		oos.writeObject( interceptor );
 
 		factory.serialize( oos );
 		oos.writeObject( sessionOwner );
 
 		jdbcCoordinator.serialize( oos );
 
 		persistenceContext.serialize( oos );
 		actionQueue.serialize( oos );
 
 		// todo : look at optimizing these...
 		oos.writeObject( loadQueryInfluencers );
 	}
 
 	@Override
 	public TypeHelper getTypeHelper() {
 		return getSessionFactory().getTypeHelper();
 	}
 
 	@Override
 	public LobHelper getLobHelper() {
 		if ( lobHelper == null ) {
 			lobHelper = new LobHelperImpl( this );
 		}
 		return lobHelper;
 	}
 
 	private transient LobHelperImpl lobHelper;
 
 	@Override
 	public JdbcSessionContext getJdbcSessionContext() {
 		return this.jdbcSessionContext;
 	}
 
 	@Override
 	public void beforeTransactionCompletion() {
 		LOG.tracef( "SessionImpl#beforeTransactionCompletion()" );
 		flushBeforeTransactionCompletion();
 		actionQueue.beforeTransactionCompletion();
 		try {
 			interceptor.beforeTransactionCompletion( currentHibernateTransaction );
 		}
 		catch (Throwable t) {
 			LOG.exceptionInBeforeTransactionCompletionInterceptor( t );
 		}
 	}
 
 	@Override
 	public void afterTransactionCompletion(boolean successful, boolean delayed) {
 		LOG.tracef( "SessionImpl#afterTransactionCompletion(successful=%s, delayed=%s)", successful, delayed );
 
 		afterCompletionAction.doAction( successful );
 
 		persistenceContext.afterTransactionCompletion();
 		actionQueue.afterTransactionCompletion( successful );
 
 		getEventListenerManager().transactionCompletion( successful );
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().endTransaction( successful );
 		}
 
 		try {
 			interceptor.afterTransactionCompletion( currentHibernateTransaction );
 		}
 		catch (Throwable t) {
 			LOG.exceptionInAfterTransactionCompletionInterceptor( t );
 		}
 
 		if ( !delayed ) {
 			if ( shouldAutoClose() && !isClosed() ) {
 				managedClose();
 			}
 		}
 
 		if ( autoClear ) {
 			internalClear();
 		}
 	}
 
 	private static class LobHelperImpl implements LobHelper {
 		private final SessionImpl session;
 
 		private LobHelperImpl(SessionImpl session) {
 			this.session = session;
 		}
 
 		@Override
 		public Blob createBlob(byte[] bytes) {
 			return lobCreator().createBlob( bytes );
 		}
 
 		private LobCreator lobCreator() {
 			// Always use NonContextualLobCreator.  If ContextualLobCreator is
 			// used both here and in WrapperOptions, 
 			return NonContextualLobCreator.INSTANCE;
 		}
 
 		@Override
 		public Blob createBlob(InputStream stream, long length) {
 			return lobCreator().createBlob( stream, length );
 		}
 
 		@Override
 		public Clob createClob(String string) {
 			return lobCreator().createClob( string );
 		}
 
 		@Override
 		public Clob createClob(Reader reader, long length) {
 			return lobCreator().createClob( reader, length );
 		}
 
 		@Override
 		public NClob createNClob(String string) {
 			return lobCreator().createNClob( string );
 		}
 
 		@Override
 		public NClob createNClob(Reader reader, long length) {
 			return lobCreator().createNClob( reader, length );
 		}
 	}
 
-	private static class SharedSessionBuilderImpl extends SessionFactoryImpl.SessionBuilderImpl implements SharedSessionBuilder {
+	private static class SharedSessionBuilderImpl extends SessionFactoryImpl.SessionBuilderImpl
+			implements SharedSessionBuilder {
 		private final SessionImpl session;
 		private boolean shareTransactionContext;
 
 		private SharedSessionBuilderImpl(SessionImpl session) {
 			super( session.factory );
 			this.session = session;
 			super.owner( session.sessionOwner );
 			super.tenantIdentifier( session.getTenantIdentifier() );
 		}
 
 		@Override
 		public SessionBuilder tenantIdentifier(String tenantIdentifier) {
 			// todo : is this always true?  Or just in the case of sharing JDBC resources?
 			throw new SessionException( "Cannot redefine tenant identifier on child session" );
 		}
 
 		@Override
 		protected TransactionCoordinator getTransactionCoordinator() {
 			return shareTransactionContext ? session.transactionCoordinator : super.getTransactionCoordinator();
 		}
 
 		@Override
 		protected JdbcCoordinatorImpl getJdbcCoordinator() {
 			return shareTransactionContext ? session.jdbcCoordinator : super.getJdbcCoordinator();
 		}
 
 		@Override
 		protected Transaction getTransaction() {
 			return shareTransactionContext ? session.currentHibernateTransaction : super.getTransaction();
 		}
 
 		@Override
 		protected ActionQueue.TransactionCompletionProcesses getTransactionCompletionProcesses() {
 			return shareTransactionContext ?
 					session.getActionQueue().getTransactionCompletionProcesses() :
 					super.getTransactionCompletionProcesses();
 		}
 
 		@Override
 		public SharedSessionBuilder interceptor() {
 			return interceptor( session.interceptor );
 		}
 
 		@Override
 		public SharedSessionBuilder connection() {
 			this.shareTransactionContext = true;
 			return this;
 		}
 
 		@Override
 		public SharedSessionBuilder connectionReleaseMode() {
 			return connectionReleaseMode( session.connectionReleaseMode );
 		}
 
 		@Override
 		public SharedSessionBuilder autoJoinTransactions() {
 			return autoJoinTransactions( session.autoJoinTransactions );
 		}
 
 		@Override
 		public SharedSessionBuilder autoClose() {
 			return autoClose( session.autoCloseSessionEnabled );
 		}
 
 		@Override
 		public SharedSessionBuilder flushBeforeCompletion() {
 			return flushBeforeCompletion( session.flushBeforeCompletionEnabled );
 		}
 
 		/**
 		 * @deprecated Use {@link #connection()} instead
 		 */
 		@Override
 		@Deprecated
 		public SharedSessionBuilder transactionContext() {
 			return connection();
 		}
 
 		@Override
 		public SharedSessionBuilder interceptor(Interceptor interceptor) {
 			return (SharedSessionBuilder) super.interceptor( interceptor );
 		}
 
 		@Override
 		public SharedSessionBuilder noInterceptor() {
 			return (SharedSessionBuilder) super.noInterceptor();
 		}
 
 		@Override
 		public SharedSessionBuilder statementInspector(StatementInspector statementInspector) {
 			return (SharedSessionBuilder) super.statementInspector( statementInspector );
 		}
 
 		@Override
 		public SharedSessionBuilder connection(Connection connection) {
 			return (SharedSessionBuilder) super.connection( connection );
 		}
 
 		@Override
 		public SharedSessionBuilder connectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 			return (SharedSessionBuilder) super.connectionReleaseMode( connectionReleaseMode );
 		}
 
 		@Override
 		public SharedSessionBuilder autoJoinTransactions(boolean autoJoinTransactions) {
 			return (SharedSessionBuilder) super.autoJoinTransactions( autoJoinTransactions );
 		}
 
 		@Override
 		public SharedSessionBuilder autoClose(boolean autoClose) {
 			return (SharedSessionBuilder) super.autoClose( autoClose );
 		}
 
 		@Override
 		public SharedSessionBuilder flushBeforeCompletion(boolean flushBeforeCompletion) {
 			return (SharedSessionBuilder) super.flushBeforeCompletion( flushBeforeCompletion );
 		}
 
 		@Override
 		public SharedSessionBuilder eventListeners(SessionEventListener... listeners) {
 			super.eventListeners( listeners );
 			return this;
 		}
 
 		@Override
 		public SessionBuilder clearEventListeners() {
 			super.clearEventListeners();
 			return this;
 		}
 	}
 
 	private class CoordinatingEntityNameResolver implements EntityNameResolver {
 		@Override
 		public String resolveEntityName(Object entity) {
 			String entityName = interceptor.getEntityName( entity );
 			if ( entityName != null ) {
 				return entityName;
 			}
 
 			for ( EntityNameResolver resolver : factory.iterateEntityNameResolvers() ) {
 				entityName = resolver.resolveEntityName( entity );
 				if ( entityName != null ) {
 					break;
 				}
 			}
 
 			if ( entityName != null ) {
 				return entityName;
 			}
 
 			// the old-time stand-by...
 			return entity.getClass().getName();
 		}
 	}
 
 	private class LockRequestImpl implements LockRequest {
 		private final LockOptions lockOptions;
+
 		private LockRequestImpl(LockOptions lo) {
 			lockOptions = new LockOptions();
-			LockOptions.copy(lo, lockOptions);
+			LockOptions.copy( lo, lockOptions );
 		}
 
 		@Override
 		public LockMode getLockMode() {
 			return lockOptions.getLockMode();
 		}
 
 		@Override
 		public LockRequest setLockMode(LockMode lockMode) {
-			lockOptions.setLockMode(lockMode);
+			lockOptions.setLockMode( lockMode );
 			return this;
 		}
 
 		@Override
 		public int getTimeOut() {
 			return lockOptions.getTimeOut();
 		}
 
 		@Override
 		public LockRequest setTimeOut(int timeout) {
-			lockOptions.setTimeOut(timeout);
+			lockOptions.setTimeOut( timeout );
 			return this;
 		}
 
 		@Override
 		public boolean getScope() {
 			return lockOptions.getScope();
 		}
 
 		@Override
 		public LockRequest setScope(boolean scope) {
-			lockOptions.setScope(scope);
+			lockOptions.setScope( scope );
 			return this;
 		}
 
 		@Override
 		public void lock(String entityName, Object object) throws HibernateException {
 			fireLock( entityName, object, lockOptions );
 		}
 
 		@Override
 		public void lock(Object object) throws HibernateException {
 			fireLock( object, lockOptions );
 		}
 	}
 
 	private class IdentifierLoadAccessImpl<T> implements IdentifierLoadAccess<T> {
 		private final EntityPersister entityPersister;
 		private LockOptions lockOptions;
 
 		private IdentifierLoadAccessImpl(EntityPersister entityPersister) {
 			this.entityPersister = entityPersister;
 		}
 
 		private IdentifierLoadAccessImpl(String entityName) {
 			this( locateEntityPersister( entityName ) );
 		}
 
 		private IdentifierLoadAccessImpl(Class<T> entityClass) {
 			this( locateEntityPersister( entityClass ) );
 		}
 
 		@Override
 		public final IdentifierLoadAccessImpl<T> with(LockOptions lockOptions) {
 			this.lockOptions = lockOptions;
 			return this;
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public final T getReference(Serializable id) {
 			if ( this.lockOptions != null ) {
 				LoadEvent event = new LoadEvent( id, entityPersister.getEntityName(), lockOptions, SessionImpl.this );
 				fireLoad( event, LoadEventListener.LOAD );
 				return (T) event.getResult();
 			}
 
 			LoadEvent event = new LoadEvent( id, entityPersister.getEntityName(), false, SessionImpl.this );
 			boolean success = false;
 			try {
 				fireLoad( event, LoadEventListener.LOAD );
 				if ( event.getResult() == null ) {
-					getFactory().getEntityNotFoundDelegate().handleEntityNotFound( entityPersister.getEntityName(), id );
+					getFactory().getEntityNotFoundDelegate().handleEntityNotFound(
+							entityPersister.getEntityName(),
+							id
+					);
 				}
 				success = true;
 				return (T) event.getResult();
 			}
 			finally {
 				afterOperation( success );
 			}
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public final T load(Serializable id) {
 			if ( this.lockOptions != null ) {
 				LoadEvent event = new LoadEvent( id, entityPersister.getEntityName(), lockOptions, SessionImpl.this );
 				fireLoad( event, LoadEventListener.GET );
 				return (T) event.getResult();
 			}
 
 			LoadEvent event = new LoadEvent( id, entityPersister.getEntityName(), false, SessionImpl.this );
 			boolean success = false;
 			try {
 				fireLoad( event, LoadEventListener.GET );
 				success = true;
 			}
 			catch (ObjectNotFoundException e) {
 				// if session cache contains proxy for non-existing object
 			}
 			finally {
 				afterOperation( success );
 			}
 			return (T) event.getResult();
 		}
 	}
 
 	private EntityPersister locateEntityPersister(Class entityClass) {
 		return factory.locateEntityPersister( entityClass );
 	}
 
 	private EntityPersister locateEntityPersister(String entityName) {
 		return factory.locateEntityPersister( entityName );
 	}
 
-	private abstract class BaseNaturalIdLoadAccessImpl<T>  {
+	private abstract class BaseNaturalIdLoadAccessImpl<T> {
 		private final EntityPersister entityPersister;
 		private LockOptions lockOptions;
 		private boolean synchronizationEnabled = true;
 
 		private BaseNaturalIdLoadAccessImpl(EntityPersister entityPersister) {
 			this.entityPersister = entityPersister;
 
-			if ( ! entityPersister.hasNaturalIdentifier() ) {
+			if ( !entityPersister.hasNaturalIdentifier() ) {
 				throw new HibernateException(
 						String.format( "Entity [%s] did not define a natural id", entityPersister.getEntityName() )
 				);
 			}
 		}
 
 		public BaseNaturalIdLoadAccessImpl<T> with(LockOptions lockOptions) {
 			this.lockOptions = lockOptions;
 			return this;
 		}
 
 		protected void synchronizationEnabled(boolean synchronizationEnabled) {
 			this.synchronizationEnabled = synchronizationEnabled;
 		}
 
 		protected final Serializable resolveNaturalId(Map<String, Object> naturalIdParameters) {
 			performAnyNeededCrossReferenceSynchronizations();
 
 			final ResolveNaturalIdEvent event =
 					new ResolveNaturalIdEvent( naturalIdParameters, entityPersister, SessionImpl.this );
 			fireResolveNaturalId( event );
 
 			if ( event.getEntityId() == PersistenceContext.NaturalIdHelper.INVALID_NATURAL_ID_REFERENCE ) {
 				return null;
 			}
 			else {
 				return event.getEntityId();
 			}
 		}
 
 		protected void performAnyNeededCrossReferenceSynchronizations() {
-			if ( ! synchronizationEnabled ) {
+			if ( !synchronizationEnabled ) {
 				// synchronization (this process) was disabled
 				return;
 			}
 			if ( entityPersister.getEntityMetamodel().hasImmutableNaturalId() ) {
 				// only mutable natural-ids need this processing
 				return;
 			}
-			if ( ! isTransactionInProgress() ) {
+			if ( !isTransactionInProgress() ) {
 				// not in a transaction so skip synchronization
 				return;
 			}
 
 			final boolean debugEnabled = LOG.isDebugEnabled();
-			for ( Serializable pk : getPersistenceContext().getNaturalIdHelper().getCachedPkResolutions( entityPersister ) ) {
+			for ( Serializable pk : getPersistenceContext().getNaturalIdHelper()
+					.getCachedPkResolutions( entityPersister ) ) {
 				final EntityKey entityKey = generateEntityKey( pk, entityPersister );
 				final Object entity = getPersistenceContext().getEntity( entityKey );
 				final EntityEntry entry = getPersistenceContext().getEntry( entity );
 
 				if ( entry == null ) {
 					if ( debugEnabled ) {
 						LOG.debug(
 								"Cached natural-id/pk resolution linked to null EntityEntry in persistence context : "
 										+ MessageHelper.infoString( entityPersister, pk, getFactory() )
 						);
 					}
 					continue;
 				}
 
 				if ( !entry.requiresDirtyCheck( entity ) ) {
 					continue;
 				}
 
 				// MANAGED is the only status we care about here...
 				if ( entry.getStatus() != Status.MANAGED ) {
 					continue;
 				}
 
 				getPersistenceContext().getNaturalIdHelper().handleSynchronization(
 						entityPersister,
 						pk,
 						entity
 				);
 			}
 		}
 
 		protected final IdentifierLoadAccess getIdentifierLoadAccess() {
 			final IdentifierLoadAccessImpl identifierLoadAccess = new IdentifierLoadAccessImpl( entityPersister );
 			if ( this.lockOptions != null ) {
 				identifierLoadAccess.with( lockOptions );
 			}
 			return identifierLoadAccess;
 		}
 
 		protected EntityPersister entityPersister() {
 			return entityPersister;
 		}
 	}
 
 	private class NaturalIdLoadAccessImpl<T> extends BaseNaturalIdLoadAccessImpl<T> implements NaturalIdLoadAccess<T> {
 		private final Map<String, Object> naturalIdParameters = new LinkedHashMap<String, Object>();
 
 		private NaturalIdLoadAccessImpl(EntityPersister entityPersister) {
-			super(entityPersister);
+			super( entityPersister );
 		}
 
 		private NaturalIdLoadAccessImpl(String entityName) {
 			this( locateEntityPersister( entityName ) );
 		}
 
 		private NaturalIdLoadAccessImpl(Class entityClass) {
 			this( locateEntityPersister( entityClass ) );
 		}
-		
+
 		@Override
 		public NaturalIdLoadAccessImpl<T> with(LockOptions lockOptions) {
 			return (NaturalIdLoadAccessImpl<T>) super.with( lockOptions );
 		}
 
 		@Override
 		public NaturalIdLoadAccess<T> using(String attributeName, Object value) {
 			naturalIdParameters.put( attributeName, value );
 			return this;
 		}
 
 		@Override
 		public NaturalIdLoadAccessImpl<T> setSynchronizationEnabled(boolean synchronizationEnabled) {
 			super.synchronizationEnabled( synchronizationEnabled );
 			return this;
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public final T getReference() {
 			final Serializable entityId = resolveNaturalId( this.naturalIdParameters );
 			if ( entityId == null ) {
 				return null;
 			}
 			return (T) this.getIdentifierLoadAccess().getReference( entityId );
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public final T load() {
 			final Serializable entityId = resolveNaturalId( this.naturalIdParameters );
 			if ( entityId == null ) {
 				return null;
 			}
 			try {
 				return (T) this.getIdentifierLoadAccess().load( entityId );
 			}
 			catch (EntityNotFoundException enf) {
 				// OK
 			}
 			catch (ObjectNotFoundException nf) {
 				// OK
 			}
 			return null;
 		}
 	}
 
-	private class SimpleNaturalIdLoadAccessImpl<T> extends BaseNaturalIdLoadAccessImpl<T> implements SimpleNaturalIdLoadAccess<T> {
+	private class SimpleNaturalIdLoadAccessImpl<T> extends BaseNaturalIdLoadAccessImpl<T>
+			implements SimpleNaturalIdLoadAccess<T> {
 		private final String naturalIdAttributeName;
 
 		private SimpleNaturalIdLoadAccessImpl(EntityPersister entityPersister) {
-			super(entityPersister);
+			super( entityPersister );
 
 			if ( entityPersister.getNaturalIdentifierProperties().length != 1 ) {
 				throw new HibernateException(
-						String.format( "Entity [%s] did not define a simple natural id", entityPersister.getEntityName() )
+						String.format(
+								"Entity [%s] did not define a simple natural id",
+								entityPersister.getEntityName()
+						)
 				);
 			}
 
 			final int naturalIdAttributePosition = entityPersister.getNaturalIdentifierProperties()[0];
-			this.naturalIdAttributeName = entityPersister.getPropertyNames()[ naturalIdAttributePosition ];
+			this.naturalIdAttributeName = entityPersister.getPropertyNames()[naturalIdAttributePosition];
 		}
 
 		private SimpleNaturalIdLoadAccessImpl(String entityName) {
 			this( locateEntityPersister( entityName ) );
 		}
 
 		private SimpleNaturalIdLoadAccessImpl(Class entityClass) {
 			this( locateEntityPersister( entityClass ) );
 		}
 
 		@Override
 		public final SimpleNaturalIdLoadAccessImpl<T> with(LockOptions lockOptions) {
 			return (SimpleNaturalIdLoadAccessImpl<T>) super.with( lockOptions );
 		}
-		
+
 		private Map<String, Object> getNaturalIdParameters(Object naturalIdValue) {
 			return Collections.singletonMap( naturalIdAttributeName, naturalIdValue );
 		}
 
 		@Override
 		public SimpleNaturalIdLoadAccessImpl<T> setSynchronizationEnabled(boolean synchronizationEnabled) {
 			super.synchronizationEnabled( synchronizationEnabled );
 			return this;
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public T getReference(Object naturalIdValue) {
 			final Serializable entityId = resolveNaturalId( getNaturalIdParameters( naturalIdValue ) );
 			if ( entityId == null ) {
 				return null;
 			}
 			return (T) this.getIdentifierLoadAccess().getReference( entityId );
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public T load(Object naturalIdValue) {
 			final Serializable entityId = resolveNaturalId( getNaturalIdParameters( naturalIdValue ) );
 			if ( entityId == null ) {
 				return null;
 			}
 			try {
 				return (T) this.getIdentifierLoadAccess().load( entityId );
 			}
 			catch (EntityNotFoundException enf) {
 				// OK
 			}
 			catch (ObjectNotFoundException nf) {
 				// OK
 			}
 			return null;
 		}
 	}
 
 	@Override
 	public void afterTransactionBegin() {
 		errorIfClosed();
 		interceptor.afterTransactionBegin( currentHibernateTransaction );
 	}
 
 	@Override
 	public void flushBeforeTransactionCompletion() {
 		boolean flush = isTransactionFlushable() && managedFlushChecker.shouldDoManagedFlush( this );
 		try {
 			if ( flush ) {
 				managedFlush();
 			}
 		}
 		catch (HibernateException he) {
 			throw exceptionMapper.mapManagedFlushFailure( "error during managed flush", he );
 		}
 		catch (RuntimeException re) {
 			throw exceptionMapper.mapManagedFlushFailure( "error during managed flush", re );
 		}
 	}
 
 	private boolean isTransactionFlushable() {
 		if ( currentHibernateTransaction == null ) {
 			// assume it is flushable - CMT, auto-commit, etc
 			return true;
 		}
 		final TransactionStatus status = currentHibernateTransaction.getStatus();
-		return status == TransactionStatus.ACTIVE || status ==TransactionStatus.COMMITTING;
+		return status == TransactionStatus.ACTIVE || status == TransactionStatus.COMMITTING;
 	}
 
 	private static final ExceptionMapper STANDARD_EXCEPTION_MAPPER = new ExceptionMapper() {
 		@Override
 		public RuntimeException mapStatusCheckFailure(String message, SystemException systemException) {
 			return new TransactionException(
 					"could not determine transaction status in beforeCompletion()",
 					systemException
 			);
 		}
 
 		@Override
 		public RuntimeException mapManagedFlushFailure(String message, RuntimeException failure) {
 			LOG.unableToPerformManagedFlush( failure.getMessage() );
 			return failure;
 		}
 	};
 
 	private static final AfterCompletionAction STANDARD_AFTER_COMPLETION_ACTION = new AfterCompletionAction() {
 		@Override
 		public void doAction(boolean successful) {
 			// nothing to do by default.
 		}
 	};
 
 	private static final ManagedFlushChecker STANDARD_MANAGED_FLUSH_CHECKER = new ManagedFlushChecker() {
 		@Override
 		public boolean shouldDoManagedFlush(SessionImpl session) {
 			boolean isFlushModeNever = session.isFlushModeNever();
-			return (!isFlushModeNever &&
-					!session.flushBeforeCompletionEnabled) ||
+			return ( !isFlushModeNever &&
+					!session.flushBeforeCompletionEnabled ) ||
 					!session.isClosed()
 							&& !isFlushModeNever
 							&& session.flushBeforeCompletionEnabled;
 		}
 	};
 
 	private JtaPlatform getJtaPlatform() {
 		return factory.getServiceRegistry().getService( JtaPlatform.class );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
index 3d44720b0d..47237ffeba 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
@@ -1,790 +1,795 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import javax.transaction.SystemException;
 
 import org.hibernate.CacheMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.SessionException;
 import org.hibernate.StatelessSession;
 import org.hibernate.Transaction;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.internal.SessionEventListenerManagerImpl;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.internal.Versioning;
 import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NativeSQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionEventListenerManager;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
 import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 /**
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class StatelessSessionImpl extends AbstractSessionImpl implements StatelessSession {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( StatelessSessionImpl.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( StatelessSessionImpl.class );
 
 	private TransactionCoordinator transactionCoordinator;
 
 	private transient JdbcCoordinator jdbcCoordinator;
 	private PersistenceContext temporaryPersistenceContext = new StatefulPersistenceContext( this );
 	private long timestamp;
 	private JdbcSessionContext jdbcSessionContext;
 
 	private LoadQueryInfluencers statelessLoadQueryInfluencers = new LoadQueryInfluencers( null ) {
 		@Override
 		public String getInternalFetchProfile() {
 			return null;
 		}
 
 		@Override
 		public void setInternalFetchProfile(String internalFetchProfile) {
 		}
 	};
 
 	StatelessSessionImpl(
 			Connection connection,
 			String tenantIdentifier,
 			SessionFactoryImpl factory) {
 		this( connection, tenantIdentifier, factory, factory.getSettings().getRegionFactory().nextTimestamp() );
 	}
 
 	StatelessSessionImpl(
 			Connection connection,
 			String tenantIdentifier,
 			SessionFactoryImpl factory,
 			long timestamp) {
 		super( factory, tenantIdentifier );
 		this.jdbcSessionContext = new JdbcSessionContextImpl(
 				factory,
 				new StatementInspector() {
 					@Override
 					public String inspect(String sql) {
 						return null;
 					}
 				}
 		);
 		this.jdbcCoordinator = new JdbcCoordinatorImpl( connection, this );
 
-		this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator( jdbcCoordinator, this );
+		this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator(
+				jdbcCoordinator,
+				this
+		);
 		this.currentHibernateTransaction = getTransaction();
 		this.timestamp = timestamp;
 	}
 
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		return transactionCoordinator;
 	}
 
 	@Override
 	public JdbcCoordinator getJdbcCoordinator() {
 		return this.jdbcCoordinator;
 	}
 
 	@Override
 	public boolean shouldAutoJoinTransaction() {
 		return true;
 	}
 
 	// inserts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Serializable insert(Object entity) {
 		errorIfClosed();
-		return insert(null, entity);
+		return insert( null, entity );
 	}
 
 	@Override
 	public Serializable insert(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister( entityName, entity );
 		Serializable id = persister.getIdentifierGenerator().generate( this, entity );
 		Object[] state = persister.getPropertyValues( entity );
 		if ( persister.isVersioned() ) {
 			boolean substitute = Versioning.seedVersion(
 					state, persister.getVersionProperty(), persister.getVersionType(), this
 			);
 			if ( substitute ) {
 				persister.setPropertyValues( entity, state );
 			}
 		}
 		if ( id == IdentifierGeneratorHelper.POST_INSERT_INDICATOR ) {
-			id = persister.insert(state, entity, this);
+			id = persister.insert( state, entity, this );
 		}
 		else {
-			persister.insert(id, state, entity, this);
+			persister.insert( id, state, entity, this );
 		}
 		persister.setIdentifier( entity, id, this );
 		return id;
 	}
 
 
 	// deletes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void delete(Object entity) {
 		errorIfClosed();
 		delete( null, entity );
 	}
 
 	@Override
 	public void delete(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister( entityName, entity );
 		Serializable id = persister.getIdentifier( entity, this );
 		Object version = persister.getVersion( entity );
 		persister.delete( id, version, entity, this );
 	}
 
 
 	// updates ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void update(Object entity) {
 		errorIfClosed();
-		update(null, entity);
+		update( null, entity );
 	}
 
 	@Override
 	public void update(String entityName, Object entity) {
 		errorIfClosed();
-		EntityPersister persister = getEntityPersister(entityName, entity);
+		EntityPersister persister = getEntityPersister( entityName, entity );
 		Serializable id = persister.getIdentifier( entity, this );
 		Object[] state = persister.getPropertyValues( entity );
 		Object oldVersion;
 		if ( persister.isVersioned() ) {
 			oldVersion = persister.getVersion( entity );
 			Object newVersion = Versioning.increment( oldVersion, persister.getVersionType(), this );
-			Versioning.setVersion(state, newVersion, persister);
+			Versioning.setVersion( state, newVersion, persister );
 			persister.setPropertyValues( entity, state );
 		}
 		else {
 			oldVersion = null;
 		}
-		persister.update(id, state, null, false, null, oldVersion, entity, null, this);
+		persister.update( id, state, null, false, null, oldVersion, entity, null, this );
 	}
 
 
 	// loading ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Object get(Class entityClass, Serializable id) {
 		return get( entityClass.getName(), id );
 	}
 
 	@Override
 	public Object get(Class entityClass, Serializable id, LockMode lockMode) {
 		return get( entityClass.getName(), id, lockMode );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id) {
-		return get(entityName, id, LockMode.NONE);
+		return get( entityName, id, LockMode.NONE );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockMode lockMode) {
 		errorIfClosed();
-		Object result = getFactory().getEntityPersister(entityName)
-				.load(id, null, lockMode, this);
+		Object result = getFactory().getEntityPersister( entityName )
+				.load( id, null, lockMode, this );
 		if ( temporaryPersistenceContext.isLoadFinished() ) {
 			temporaryPersistenceContext.clear();
 		}
 		return result;
 	}
 
 	@Override
 	public void refresh(Object entity) {
 		refresh( bestGuessEntityName( entity ), entity, LockMode.NONE );
 	}
 
 	@Override
 	public void refresh(String entityName, Object entity) {
 		refresh( entityName, entity, LockMode.NONE );
 	}
 
 	@Override
 	public void refresh(Object entity, LockMode lockMode) {
 		refresh( bestGuessEntityName( entity ), entity, lockMode );
 	}
 
 	@Override
 	public void refresh(String entityName, Object entity, LockMode lockMode) {
 		final EntityPersister persister = this.getEntityPersister( entityName, entity );
 		final Serializable id = persister.getIdentifier( entity, this );
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Refreshing transient {0}", MessageHelper.infoString( persister, id, this.getFactory() ) );
 		}
 		// TODO : can this ever happen???
 //		EntityKey key = new EntityKey( id, persister, source.getEntityMode() );
 //		if ( source.getPersistenceContext().getEntry( key ) != null ) {
 //			throw new PersistentObjectException(
 //					"attempted to refresh transient instance when persistent " +
 //					"instance was already associated with the Session: " +
 //					MessageHelper.infoString( persister, id, source.getFactory() )
 //			);
 //		}
 
 		if ( persister.hasCache() ) {
 			final CacheKey ck = generateCacheKey( id, persister.getIdentifierType(), persister.getRootEntityName() );
 			persister.getCacheAccessStrategy().evict( ck );
 		}
 		String previousFetchProfile = this.getLoadQueryInfluencers().getInternalFetchProfile();
 		Object result = null;
 		try {
 			this.getLoadQueryInfluencers().setInternalFetchProfile( "refresh" );
 			result = persister.load( id, entity, lockMode, this );
 		}
 		finally {
 			this.getLoadQueryInfluencers().setInternalFetchProfile( previousFetchProfile );
 		}
 		UnresolvableObjectException.throwIfNull( result, id, persister.getEntityName() );
 	}
 
 	@Override
 	public Object immediateLoad(String entityName, Serializable id)
 			throws HibernateException {
-		throw new SessionException("proxies cannot be fetched by a stateless session");
+		throw new SessionException( "proxies cannot be fetched by a stateless session" );
 	}
 
 	@Override
 	public void initializeCollection(
 			PersistentCollection collection,
-	        boolean writing) throws HibernateException {
-		throw new SessionException("collections cannot be fetched by a stateless session");
+			boolean writing) throws HibernateException {
+		throw new SessionException( "collections cannot be fetched by a stateless session" );
 	}
 
 	@Override
 	public Object instantiate(
 			String entityName,
-	        Serializable id) throws HibernateException {
+			Serializable id) throws HibernateException {
 		errorIfClosed();
 		return getFactory().getEntityPersister( entityName ).instantiate( id, this );
 	}
 
 	@Override
 	public Object internalLoad(
 			String entityName,
-	        Serializable id,
-	        boolean eager,
-	        boolean nullable) throws HibernateException {
+			Serializable id,
+			boolean eager,
+			boolean nullable) throws HibernateException {
 		errorIfClosed();
 		EntityPersister persister = getFactory().getEntityPersister( entityName );
 		// first, try to load it from the temp PC associated to this SS
 		Object loaded = temporaryPersistenceContext.getEntity( generateEntityKey( id, persister ) );
 		if ( loaded != null ) {
 			// we found it in the temp PC.  Should indicate we are in the midst of processing a result set
 			// containing eager fetches via join fetch
 			return loaded;
 		}
 		if ( !eager && persister.hasProxy() ) {
 			// if the metadata allowed proxy creation and caller did not request forceful eager loading,
 			// generate a proxy
 			return persister.createProxy( id, this );
 		}
 		// otherwise immediately materialize it
 		return get( entityName, id );
 	}
 
 	@Override
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters)
-	throws HibernateException {
+			throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters)
-	throws HibernateException {
+			throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public boolean isOpen() {
 		return !isClosed();
 	}
 
 	@Override
 	public void close() {
 		managedClose();
 	}
 
 	@Override
 	public boolean isAutoCloseSessionEnabled() {
 		return factory.getSettings().isAutoCloseSessionEnabled();
 	}
 
 	@Override
 	public boolean shouldAutoClose() {
 		return isAutoCloseSessionEnabled() && !isClosed();
 	}
 
 
 	private boolean isFlushModeNever() {
 		return false;
 	}
 
 	private void managedClose() {
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed!" );
 		}
 		jdbcCoordinator.close();
 		setClosed();
 	}
 
 	private void managedFlush() {
 		errorIfClosed();
 		jdbcCoordinator.executeBatch();
 	}
 
 	private SessionEventListenerManagerImpl sessionEventsManager;
 
 	@Override
 	public SessionEventListenerManager getEventListenerManager() {
 		if ( sessionEventsManager == null ) {
 			sessionEventsManager = new SessionEventListenerManagerImpl();
 		}
 		return sessionEventsManager;
 	}
 
 	@Override
 	public String bestGuessEntityName(Object object) {
-		if (object instanceof HibernateProxy) {
+		if ( object instanceof HibernateProxy ) {
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation();
 		}
-		return guessEntityName(object);
+		return guessEntityName( object );
 	}
 
 	@Override
 	public Connection connection() {
 		errorIfClosed();
 		return jdbcCoordinator.getLogicalConnection().getPhysicalConnection();
 	}
 
 	@Override
 	public int executeUpdate(String query, QueryParameters queryParameters)
 			throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate( queryParameters, this );
 			success = true;
 		}
 		finally {
-			afterOperation(success);
+			afterOperation( success );
 		}
 		temporaryPersistenceContext.clear();
 		return result;
 	}
 
 	@Override
 	public CacheMode getCacheMode() {
 		return CacheMode.IGNORE;
 	}
 
 	@Override
 	public int getDontFlushFromFind() {
 		return 0;
 	}
 
 	@Override
 	public Serializable getContextEntityIdentifier(Object object) {
 		errorIfClosed();
 		return null;
 	}
 
 	public EntityMode getEntityMode() {
 		return EntityMode.POJO;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister(String entityName, Object object)
 			throws HibernateException {
 		errorIfClosed();
-		if ( entityName==null ) {
+		if ( entityName == null ) {
 			return factory.getEntityPersister( guessEntityName( object ) );
 		}
 		else {
 			return factory.getEntityPersister( entityName ).getSubclassEntityPersister( object, getFactory() );
 		}
 	}
 
 	@Override
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		return null;
 	}
 
 	@Override
 	public FlushMode getFlushMode() {
 		return FlushMode.COMMIT;
 	}
 
 	@Override
 	public Interceptor getInterceptor() {
 		return EmptyInterceptor.INSTANCE;
 	}
 
 	@Override
 	public PersistenceContext getPersistenceContext() {
 		return temporaryPersistenceContext;
 	}
 
 	@Override
 	public long getTimestamp() {
 		return timestamp;
 	}
 
 	@Override
 	public String guessEntityName(Object entity) throws HibernateException {
 		errorIfClosed();
 		return entity.getClass().getName();
 	}
 
 	@Override
 	public boolean isConnected() {
 		return jdbcCoordinator.getLogicalConnection().isPhysicallyConnected();
 	}
 
 	@Override
 	public boolean isTransactionInProgress() {
 		return !isClosed() && transactionCoordinator.isJoined() && transactionCoordinator.getTransactionDriverControl()
 				.getStatus() == TransactionStatus.ACTIVE;
 	}
 
 	@Override
 	public void setAutoClear(boolean enabled) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public void setCacheMode(CacheMode cm) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public void setFlushMode(FlushMode fm) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public Transaction beginTransaction() throws HibernateException {
 		errorIfClosed();
 		Transaction result = getTransaction();
 		result.begin();
 		return result;
 	}
 
 	@Override
 	public boolean isEventSource() {
 		return false;
 	}
 
 	public boolean isDefaultReadOnly() {
 		return false;
 	}
 
 	public void setDefaultReadOnly(boolean readOnly) throws HibernateException {
 		if ( readOnly ) {
 			throw new UnsupportedOperationException();
 		}
 	}
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////
 
 	//TODO: COPY/PASTE FROM SessionImpl, pull up!
 
 	@Override
 	public List list(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		boolean success = false;
 		List results = Collections.EMPTY_LIST;
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
-			afterOperation(success);
+			afterOperation( success );
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	public void afterOperation(boolean success) {
-		if ( ! isTransactionInProgress() ) {
+		if ( !isTransactionInProgress() ) {
 			jdbcCoordinator.afterTransaction();
 		}
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass, String alias) {
 		errorIfClosed();
 		return new CriteriaImpl( persistentClass.getName(), alias, this );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName, String alias) {
 		errorIfClosed();
-		return new CriteriaImpl(entityName, alias, this);
+		return new CriteriaImpl( entityName, alias, this );
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass) {
 		errorIfClosed();
 		return new CriteriaImpl( persistentClass.getName(), this );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName) {
 		errorIfClosed();
-		return new CriteriaImpl(entityName, this);
+		return new CriteriaImpl( entityName, this );
 	}
 
 	@Override
 	public ScrollableResults scroll(Criteria criteria, ScrollMode scrollMode) {
 		// TODO: Is this guaranteed to always be CriteriaImpl?
 		CriteriaImpl criteriaImpl = (CriteriaImpl) criteria;
-		
+
 		errorIfClosed();
 		String entityName = criteriaImpl.getEntityOrClassName();
 		CriteriaLoader loader = new CriteriaLoader(
 				getOuterJoinLoadable( entityName ),
-		        factory,
-		        criteriaImpl,
-		        entityName,
-		        getLoadQueryInfluencers()
+				factory,
+				criteriaImpl,
+				entityName,
+				getLoadQueryInfluencers()
 		);
-		return loader.scroll(this, scrollMode);
+		return loader.scroll( this, scrollMode );
 	}
 
 	@Override
-	@SuppressWarnings( {"unchecked"})
+	@SuppressWarnings({"unchecked"})
 	public List list(Criteria criteria) throws HibernateException {
 		// TODO: Is this guaranteed to always be CriteriaImpl?
 		CriteriaImpl criteriaImpl = (CriteriaImpl) criteria;
-		
+
 		errorIfClosed();
 		String[] implementors = factory.getImplementors( criteriaImpl.getEntityOrClassName() );
 		int size = implementors.length;
 
 		CriteriaLoader[] loaders = new CriteriaLoader[size];
-		for( int i=0; i <size; i++ ) {
+		for ( int i = 0; i < size; i++ ) {
 			loaders[i] = new CriteriaLoader(
 					getOuterJoinLoadable( implementors[i] ),
-			        factory,
-			        criteriaImpl,
-			        implementors[i],
-			        getLoadQueryInfluencers()
+					factory,
+					criteriaImpl,
+					implementors[i],
+					getLoadQueryInfluencers()
 			);
 		}
 
 
 		List results = Collections.EMPTY_LIST;
 		boolean success = false;
 		try {
-			for( int i=0; i<size; i++ ) {
-				final List currentResults = loaders[i].list(this);
-				currentResults.addAll(results);
+			for ( int i = 0; i < size; i++ ) {
+				final List currentResults = loaders[i].list( this );
+				currentResults.addAll( results );
 				results = currentResults;
 			}
 			success = true;
 		}
 		finally {
-			afterOperation(success);
+			afterOperation( success );
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	private OuterJoinLoadable getOuterJoinLoadable(String entityName) throws MappingException {
-		EntityPersister persister = factory.getEntityPersister(entityName);
-		if ( !(persister instanceof OuterJoinLoadable) ) {
+		EntityPersister persister = factory.getEntityPersister( entityName );
+		if ( !( persister instanceof OuterJoinLoadable ) ) {
 			throw new MappingException( "class persister is not OuterJoinLoadable: " + entityName );
 		}
-		return ( OuterJoinLoadable ) persister;
+		return (OuterJoinLoadable) persister;
 	}
 
 	@Override
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
-	throws HibernateException {
+			throws HibernateException {
 		errorIfClosed();
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 
 		boolean success = false;
 		List results;
 		try {
-			results = loader.list(this, queryParameters);
+			results = loader.list( this, queryParameters );
 			success = true;
 		}
 		finally {
-			afterOperation(success);
+			afterOperation( success );
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	@Override
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
-	throws HibernateException {
+			throws HibernateException {
 		errorIfClosed();
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 		return loader.scroll( queryParameters, this );
 	}
 
 	@Override
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		return plan.performScroll( queryParameters, this );
 	}
 
 	@Override
 	public void afterScrollOperation() {
 		temporaryPersistenceContext.clear();
 	}
 
 	@Override
 	public void flush() {
 	}
 
 	@Override
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return statelessLoadQueryInfluencers;
 	}
 
 	@Override
-	public int executeNativeUpdate(NativeSQLQuerySpecification nativeSQLQuerySpecification,
+	public int executeNativeUpdate(
+			NativeSQLQuerySpecification nativeSQLQuerySpecification,
 			QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
-		NativeSQLQueryPlan plan = getNativeSQLQueryPlan(nativeSQLQuerySpecification);
+		NativeSQLQueryPlan plan = getNativeSQLQueryPlan( nativeSQLQuerySpecification );
 
 		boolean success = false;
 		int result = 0;
 		try {
-			result = plan.performExecuteUpdate(queryParameters, this);
+			result = plan.performExecuteUpdate( queryParameters, this );
 			success = true;
-		} finally {
-			afterOperation(success);
+		}
+		finally {
+			afterOperation( success );
 		}
 		temporaryPersistenceContext.clear();
 		return result;
 	}
 
 	@Override
 	public JdbcSessionContext getJdbcSessionContext() {
 		return this.jdbcSessionContext;
 	}
 
 	@Override
 	public void afterTransactionBegin() {
 
 	}
 
 	@Override
 	public void beforeTransactionCompletion() {
 		flushBeforeTransactionCompletion();
 	}
 
 	@Override
 	public void afterTransactionCompletion(boolean successful, boolean delayed) {
 		if ( shouldAutoClose() && !isClosed() ) {
 			managedClose();
 		}
 	}
 
 	@Override
 	public void flushBeforeTransactionCompletion() {
 		boolean flush = false;
 		try {
 			flush = (
 					!isClosed()
 							&& !isFlushModeNever()
 							&& !JtaStatusHelper.isRollback(
 							getJtaPlatform().getCurrentStatus()
-					));
+					) );
 		}
 		catch (SystemException se) {
 			throw new HibernateException( "could not determine transaction status in beforeCompletion()", se );
 		}
 		if ( flush ) {
 			managedFlush();
 		}
 	}
 
 	private JtaPlatform getJtaPlatform() {
 		return factory.getServiceRegistry().getService( JtaPlatform.class );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/BytesHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/BytesHelper.java
index 392c9e64f3..48ddd0434f 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/BytesHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/BytesHelper.java
@@ -1,143 +1,143 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util;
 
 
 public final class BytesHelper {
 
 	private BytesHelper() {
 	}
 
 	/**
 	 * Custom algorithm used to generate an int from a series of bytes.
 	 * <p/>
 	 * NOTE : this is different than interpreting the incoming bytes as an int value!
 	 *
 	 * @param bytes The bytes to use in generating the int.
 	 *
 	 * @return The generated int.
 	 */
 	public static int toInt(byte[] bytes) {
 		int result = 0;
 		for ( int i = 0; i < 4; i++ ) {
 			result = ( result << 8 ) - Byte.MIN_VALUE + (int) bytes[i];
 		}
 		return result;
 	}
 
 	/**
 	 * Interpret a short as its binary form
 	 *
 	 * @param shortValue The short to interpret to binary
 	 *
 	 * @return The binary
 	 */
 	public static byte[] fromShort(int shortValue) {
 		byte[] bytes = new byte[2];
 		bytes[0] = (byte) ( shortValue >> 8 );
 		bytes[1] = (byte) ( ( shortValue << 8 ) >> 8 );
 		return bytes;
 	}
 
 	/**
 	 * Interpret an int as its binary form
 	 *
 	 * @param intValue The int to interpret to binary
 	 *
 	 * @return The binary
 	 */
 	public static byte[] fromInt(int intValue) {
 		byte[] bytes = new byte[4];
 		bytes[0] = (byte) ( intValue >> 24 );
 		bytes[1] = (byte) ( ( intValue << 8 ) >> 24 );
 		bytes[2] = (byte) ( ( intValue << 16 ) >> 24 );
 		bytes[3] = (byte) ( ( intValue << 24 ) >> 24 );
 		return bytes;
 	}
 
 	/**
 	 * Interpret a long as its binary form
 	 *
 	 * @param longValue The long to interpret to binary
 	 *
 	 * @return The binary
 	 */
 	public static byte[] fromLong(long longValue) {
 		byte[] bytes = new byte[8];
 		bytes[0] = (byte) ( longValue >> 56 );
 		bytes[1] = (byte) ( ( longValue << 8 ) >> 56 );
 		bytes[2] = (byte) ( ( longValue << 16 ) >> 56 );
 		bytes[3] = (byte) ( ( longValue << 24 ) >> 56 );
 		bytes[4] = (byte) ( ( longValue << 32 ) >> 56 );
 		bytes[5] = (byte) ( ( longValue << 40 ) >> 56 );
 		bytes[6] = (byte) ( ( longValue << 48 ) >> 56 );
 		bytes[7] = (byte) ( ( longValue << 56 ) >> 56 );
 		return bytes;
 	}
 
 	/**
 	 * Interpret the binary representation of a long.
 	 *
 	 * @param bytes The bytes to interpret.
 	 *
 	 * @return The long
 	 */
 	public static long asLong(byte[] bytes) {
 		if ( bytes == null ) {
 			return 0;
 		}
 		if ( bytes.length != 8 ) {
 			throw new IllegalArgumentException( "Expecting 8 byte values to construct a long" );
 		}
 		long value = 0;
-        for (int i=0; i<8; i++) {
+		for (int i=0; i<8; i++) {
 			value = (value << 8) | (bytes[i] & 0xff);
 		}
 		return value;
 	}
 
 	public static String toBinaryString(byte value) {
 		String formatted = Integer.toBinaryString( value );
 		if ( formatted.length() > 8 ) {
 			formatted = formatted.substring( formatted.length() - 8 );
 		}
 		StringBuilder buf = new StringBuilder( "00000000" );
 		buf.replace( 8 - formatted.length(), 8, formatted );
 		return buf.toString();
 	}
 
 	public static String toBinaryString(int value) {
 		String formatted = Long.toBinaryString( value );
 		StringBuilder buf = new StringBuilder( StringHelper.repeat( '0', 32 ) );
 		buf.replace( 64 - formatted.length(), 64, formatted );
 		return buf.toString();
 	}
 
 	public static String toBinaryString(long value) {
 		String formatted = Long.toBinaryString( value );
 		StringBuilder buf = new StringBuilder( StringHelper.repeat( '0', 64 ) );
 		buf.replace( 64 - formatted.length(), 64, formatted );
 		return buf.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/Cloneable.java b/hibernate-core/src/main/java/org/hibernate/internal/util/Cloneable.java
index cc02dd80a3..39fbc8d441 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/Cloneable.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/Cloneable.java
@@ -1,162 +1,160 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.internal.util;
 
 import java.beans.BeanInfo;
 import java.beans.IntrospectionException;
 import java.beans.Introspector;
 import java.beans.PropertyDescriptor;
 import java.security.AccessController;
 import java.security.PrivilegedAction;
 
 import org.hibernate.HibernateException;
 
 /**
  * An object that is shallow-coneable
- * 
+ *
  * @author Steve Ebersole
  */
 public class Cloneable {
-	
+
 	private static final Object[] READER_METHOD_ARGS = new Object[0];
 
 	/**
 	 * Essentially performs a shallow copy of this SessionEventListenerConfig
 	 * instance; meaning the SessionEventListenerConfig itself is cloned, but
 	 * the individual listeners are <b>not</b> cloned.
 	 *
 	 * @return The SessionEventListenerConfig shallow copy.
 	 */
 	public Object shallowCopy() {
 		return AccessController.doPrivileged(
-		        new PrivilegedAction() {
-			        public Object run() {
-				        return copyListeners();
-			        }
-		        }
-			);
+				new PrivilegedAction() {
+					@Override
+					public Object run() {
+						return copyListeners();
+					}
+				}
+		);
 	}
 
 	/**
 	 * Checks to ensure the SessionEventListenerConfig is fully
 	 * configured (basically, that none of the listeners is null).
 	 *
 	 * @throws HibernateException If the SessionEventListenerConfig
 	 * is not fully configured.
 	 */
 	public void validate() throws HibernateException {
 		AccessController.doPrivileged(
-		        new PrivilegedAction() {
-			        public Object run() {
-				        checkListeners();
-				        return null;
-			        }
-		        }
-			);
+				new PrivilegedAction() {
+					@Override
+					public Object run() {
+						checkListeners();
+						return null;
+					}
+				}
+		);
 
 	}
 
 	private Object copyListeners() {
 		Object copy = null;
 		BeanInfo beanInfo = null;
 		try {
 			beanInfo = Introspector.getBeanInfo( getClass(), Object.class );
 			internalCheckListeners( beanInfo );
 			copy = getClass().newInstance();
 			PropertyDescriptor[] pds = beanInfo.getPropertyDescriptors();
-			for ( int i = 0, max = pds.length; i < max; i++ ) {
+			for ( PropertyDescriptor pd : pds ) {
 				try {
-					pds[i].getWriteMethod().invoke(
+					pd.getWriteMethod().invoke(
 							copy,
-							new Object[] {
-								pds[i].getReadMethod().invoke( this, READER_METHOD_ARGS )
-							}
-						);
+							pd.getReadMethod().invoke( this, READER_METHOD_ARGS )
+					);
 				}
-				catch( Throwable t ) {
-					throw new HibernateException( "Unable copy copy listener [" + pds[i].getName() + "]" );
+				catch (Throwable t) {
+					throw new HibernateException( "Unable copy copy listener [" + pd.getName() + "]" );
 				}
 			}
 		}
-		catch( Exception t ) {
+		catch (Exception t) {
 			throw new HibernateException( "Unable to copy listeners", t );
 		}
 		finally {
 			if ( beanInfo != null ) {
 				// release the jdk internal caches everytime to ensure this
 				// plays nicely with destroyable class-loaders
 				Introspector.flushFromCaches( getClass() );
 			}
 		}
-		
+
 		return copy;
 	}
 
 	private void checkListeners() {
 		BeanInfo beanInfo = null;
 		try {
 			beanInfo = Introspector.getBeanInfo( getClass(), Object.class );
 			internalCheckListeners( beanInfo );
 		}
-		catch( IntrospectionException t ) {
+		catch (IntrospectionException t) {
 			throw new HibernateException( "Unable to validate listener config", t );
 		}
 		finally {
 			if ( beanInfo != null ) {
 				// release the jdk internal caches everytime to ensure this
 				// plays nicely with destroyable class-loaders
 				Introspector.flushFromCaches( getClass() );
 			}
 		}
 	}
 
 	private void internalCheckListeners(BeanInfo beanInfo) {
 		PropertyDescriptor[] pds = beanInfo.getPropertyDescriptors();
 		try {
-			for ( int i = 0, max = pds.length; i < max; i++ ) {
-				final Object listener = pds[i].getReadMethod().invoke( this, READER_METHOD_ARGS );
+			for ( PropertyDescriptor pd : pds ) {
+				final Object listener = pd.getReadMethod().invoke( this, READER_METHOD_ARGS );
 				if ( listener == null ) {
-					throw new HibernateException( "Listener [" + pds[i].getName() + "] was null" );
+					throw new HibernateException( "Listener [" + pd.getName() + "] was null" );
 				}
 				if ( listener.getClass().isArray() ) {
 					Object[] listenerArray = (Object[]) listener;
-					int length = listenerArray.length;
-					for ( int index = 0 ; index < length ; index++ ) {
-						if ( listenerArray[index] == null ) {
-							throw new HibernateException( "Listener in [" + pds[i].getName() + "] was null" );
+					for ( Object aListenerArray : listenerArray ) {
+						if ( aListenerArray == null ) {
+							throw new HibernateException( "Listener in [" + pd.getName() + "] was null" );
 						}
 					}
 				}
 			}
 		}
-		catch( HibernateException e ) {
+		catch (HibernateException e) {
 			throw e;
 		}
-		catch( Throwable t ) {
+		catch (Throwable t) {
 			throw new HibernateException( "Unable to validate listener config" );
 		}
 	}
-	
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
index f26abfaa9c..f989694c8d 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
@@ -1,208 +1,219 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
 import java.net.MalformedURLException;
 import java.net.URL;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Environment;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
-import org.jboss.logging.Logger;
-
 /**
  * A simple class to centralize logic needed to locate config files on the system.
  *
- * @todo : Update usages to use {@link org.hibernate.boot.registry.classloading.spi.ClassLoaderService}
- *
  * @author Steve Ebersole
+ * @todo : Update usages to use {@link org.hibernate.boot.registry.classloading.spi.ClassLoaderService}
  */
 public final class ConfigHelper {
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ConfigHelper.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( ConfigHelper.class );
 
-	/** Try to locate a local URL representing the incoming path.  The first attempt
+	/**
+	 * Try to locate a local URL representing the incoming path.  The first attempt
 	 * assumes that the incoming path is an actual URL string (file://, etc).  If this
 	 * does not work, then the next attempts try to locate this UURL as a java system
 	 * resource.
 	 *
 	 * @param path The path representing the config location.
+	 *
 	 * @return An appropriate URL or null.
 	 */
 	public static URL locateConfig(final String path) {
 		try {
-			return new URL(path);
+			return new URL( path );
 		}
-		catch(MalformedURLException e) {
-			return findAsResource(path);
+		catch (MalformedURLException e) {
+			return findAsResource( path );
 		}
 	}
 
 	/**
 	 * Try to locate a local URL representing the incoming path.
 	 * This method <b>only</b> attempts to locate this URL as a
 	 * java system resource.
 	 *
 	 * @param path The path representing the config location.
+	 *
 	 * @return An appropriate URL or null.
 	 */
 	public static URL findAsResource(final String path) {
 		URL url = null;
 
 		// First, try to locate this resource through the current
 		// context classloader.
 		ClassLoader contextClassLoader = ClassLoaderHelper.getContextClassLoader();
-		if (contextClassLoader!=null) {
-			url = contextClassLoader.getResource(path);
+		if ( contextClassLoader != null ) {
+			url = contextClassLoader.getResource( path );
 		}
-		if (url != null) {
+		if ( url != null ) {
 			return url;
 		}
 
 		// Next, try to locate this resource through this class's classloader
-		url = ConfigHelper.class.getClassLoader().getResource(path);
-		if (url != null) {
+		url = ConfigHelper.class.getClassLoader().getResource( path );
+		if ( url != null ) {
 			return url;
 		}
 
 		// Next, try to locate this resource through the system classloader
-		url = ClassLoader.getSystemClassLoader().getResource(path);
+		url = ClassLoader.getSystemClassLoader().getResource( path );
 
 		// Anywhere else we should look?
 		return url;
 	}
 
-	/** Open an InputStream to the URL represented by the incoming path.  First makes a call
+	/**
+	 * Open an InputStream to the URL represented by the incoming path.  First makes a call
 	 * to {@link #locateConfig(java.lang.String)} in order to find an appropriate URL.
 	 * {@link java.net.URL#openStream()} is then called to obtain the stream.
 	 *
 	 * @param path The path representing the config location.
+	 *
 	 * @return An input stream to the requested config resource.
+	 *
 	 * @throws HibernateException Unable to open stream to that resource.
 	 */
 	public static InputStream getConfigStream(final String path) throws HibernateException {
-		final URL url = ConfigHelper.locateConfig(path);
+		final URL url = ConfigHelper.locateConfig( path );
 
-		if (url == null) {
-            String msg = LOG.unableToLocateConfigFile(path);
-            LOG.error(msg);
-			throw new HibernateException(msg);
+		if ( url == null ) {
+			String msg = LOG.unableToLocateConfigFile( path );
+			LOG.error( msg );
+			throw new HibernateException( msg );
 		}
 
 		try {
 			return url.openStream();
-        }
-		catch(IOException e) {
-	        throw new HibernateException("Unable to open config file: " + path, e);
-        }
+		}
+		catch (IOException e) {
+			throw new HibernateException( "Unable to open config file: " + path, e );
+		}
 	}
 
-	/** Open an Reader to the URL represented by the incoming path.  First makes a call
+	/**
+	 * Open an Reader to the URL represented by the incoming path.  First makes a call
 	 * to {@link #locateConfig(java.lang.String)} in order to find an appropriate URL.
 	 * {@link java.net.URL#openStream()} is then called to obtain a stream, which is then
 	 * wrapped in a Reader.
 	 *
 	 * @param path The path representing the config location.
+	 *
 	 * @return An input stream to the requested config resource.
+	 *
 	 * @throws HibernateException Unable to open reader to that resource.
 	 */
 	public static Reader getConfigStreamReader(final String path) throws HibernateException {
-		return new InputStreamReader( getConfigStream(path) );
+		return new InputStreamReader( getConfigStream( path ) );
 	}
 
-	/** Loads a properties instance based on the data at the incoming config location.
+	/**
+	 * Loads a properties instance based on the data at the incoming config location.
 	 *
 	 * @param path The path representing the config location.
+	 *
 	 * @return The loaded properties instance.
+	 *
 	 * @throws HibernateException Unable to load properties from that resource.
 	 */
 	public static Properties getConfigProperties(String path) throws HibernateException {
 		try {
 			Properties properties = new Properties();
-			properties.load( getConfigStream(path) );
+			properties.load( getConfigStream( path ) );
 			return properties;
 		}
-		catch(IOException e) {
-			throw new HibernateException("Unable to load properties from specified config file: " + path, e);
+		catch (IOException e) {
+			throw new HibernateException( "Unable to load properties from specified config file: " + path, e );
 		}
 	}
 
-	private ConfigHelper() {}
+	private ConfigHelper() {
+	}
 
 	public static InputStream getResourceAsStream(String resource) {
-		String stripped = resource.startsWith("/")
-				? resource.substring(1)
+		String stripped = resource.startsWith( "/" )
+				? resource.substring( 1 )
 				: resource;
 
 		InputStream stream = null;
 		ClassLoader classLoader = ClassLoaderHelper.getContextClassLoader();
-		if (classLoader!=null) {
+		if ( classLoader != null ) {
 			stream = classLoader.getResourceAsStream( stripped );
 		}
 		if ( stream == null ) {
 			stream = Environment.class.getResourceAsStream( resource );
 		}
 		if ( stream == null ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( stripped );
 		}
 		if ( stream == null ) {
 			throw new HibernateException( resource + " not found" );
 		}
 		return stream;
 	}
 
 
 	public static InputStream getUserResourceAsStream(String resource) {
 		boolean hasLeadingSlash = resource.startsWith( "/" );
-		String stripped = hasLeadingSlash ? resource.substring(1) : resource;
+		String stripped = hasLeadingSlash ? resource.substring( 1 ) : resource;
 
 		InputStream stream = null;
 
 		ClassLoader classLoader = ClassLoaderHelper.getContextClassLoader();
 		if ( classLoader != null ) {
 			stream = classLoader.getResourceAsStream( resource );
 			if ( stream == null && hasLeadingSlash ) {
 				stream = classLoader.getResourceAsStream( stripped );
 			}
 		}
 
 		if ( stream == null ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( resource );
 		}
 		if ( stream == null && hasLeadingSlash ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( stripped );
 		}
 
 		if ( stream == null ) {
 			throw new HibernateException( resource + " not found" );
 		}
 
 		return stream;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/EntityPrinter.java b/hibernate-core/src/main/java/org/hibernate/internal/util/EntityPrinter.java
index 5cfce5f089..2e814c9cda 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/EntityPrinter.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/EntityPrinter.java
@@ -1,129 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.Type;
 
 /**
  * Renders entities and query parameters to a nicely readable string.
+ *
  * @author Gavin King
  */
 public final class EntityPrinter {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( EntityPrinter.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( EntityPrinter.class );
 
-    private SessionFactoryImplementor factory;
+	private SessionFactoryImplementor factory;
 
 	/**
 	 * Renders an entity to a string.
 	 *
 	 * @param entityName the entity name
 	 * @param entity an actual entity object, not a proxy!
+	 *
 	 * @return the entity rendered to a string
 	 */
 	public String toString(String entityName, Object entity) throws HibernateException {
 		EntityPersister entityPersister = factory.getEntityPersister( entityName );
 
 		if ( entityPersister == null ) {
 			return entity.getClass().getName();
 		}
 
-		Map<String,String> result = new HashMap<String,String>();
+		Map<String, String> result = new HashMap<String, String>();
 
 		if ( entityPersister.hasIdentifierProperty() ) {
 			result.put(
-				entityPersister.getIdentifierPropertyName(),
-				entityPersister.getIdentifierType().toLoggableString( entityPersister.getIdentifier( entity ), factory )
+					entityPersister.getIdentifierPropertyName(),
+					entityPersister.getIdentifierType().toLoggableString(
+							entityPersister.getIdentifier( entity ),
+							factory
+					)
 			);
 		}
 
 		Type[] types = entityPersister.getPropertyTypes();
 		String[] names = entityPersister.getPropertyNames();
 		Object[] values = entityPersister.getPropertyValues( entity );
-		for ( int i=0; i<types.length; i++ ) {
-			if ( !names[i].startsWith("_") ) {
-				String strValue = values[i]==LazyPropertyInitializer.UNFETCHED_PROPERTY ?
-					values[i].toString() :
-					types[i].toLoggableString( values[i], factory );
+		for ( int i = 0; i < types.length; i++ ) {
+			if ( !names[i].startsWith( "_" ) ) {
+				String strValue = values[i] == LazyPropertyInitializer.UNFETCHED_PROPERTY ?
+						values[i].toString() :
+						types[i].toLoggableString( values[i], factory );
 				result.put( names[i], strValue );
 			}
 		}
 		return entityName + result.toString();
 	}
 
 	public String toString(Type[] types, Object[] values) throws HibernateException {
 		StringBuilder buffer = new StringBuilder();
-		for ( int i=0; i<types.length; i++ ) {
-			if ( types[i]!=null ) {
+		for ( int i = 0; i < types.length; i++ ) {
+			if ( types[i] != null ) {
 				buffer.append( types[i].toLoggableString( values[i], factory ) ).append( ", " );
 			}
 		}
 		return buffer.toString();
 	}
 
-	public String toString(Map<String,TypedValue> namedTypedValues) throws HibernateException {
-		Map<String,String> result = new HashMap<String,String>();
+	public String toString(Map<String, TypedValue> namedTypedValues) throws HibernateException {
+		Map<String, String> result = new HashMap<String, String>();
 		for ( Map.Entry<String, TypedValue> entry : namedTypedValues.entrySet() ) {
 			result.put(
 					entry.getKey(), entry.getValue().getType().toLoggableString(
 							entry.getValue().getValue(),
 							factory
 					)
 			);
 		}
 		return result.toString();
 	}
 
 	// Cannot use Map as an argument because it clashes with the previous method (due to type erasure)
-	public void toString(Iterable<Map.Entry<EntityKey,Object>> entitiesByEntityKey) throws HibernateException {
-        if ( ! LOG.isDebugEnabled() || ! entitiesByEntityKey.iterator().hasNext() ) {
+	public void toString(Iterable<Map.Entry<EntityKey, Object>> entitiesByEntityKey) throws HibernateException {
+		if ( !LOG.isDebugEnabled() || !entitiesByEntityKey.iterator().hasNext() ) {
 			return;
 		}
 
-        LOG.debug( "Listing entities:" );
-		int i=0;
-		for (  Map.Entry<EntityKey,Object> entityKeyAndEntity : entitiesByEntityKey ) {
-			if (i++>20) {
-                LOG.debug("More......");
+		LOG.debug( "Listing entities:" );
+		int i = 0;
+		for ( Map.Entry<EntityKey, Object> entityKeyAndEntity : entitiesByEntityKey ) {
+			if ( i++ > 20 ) {
+				LOG.debug( "More......" );
 				break;
 			}
-            LOG.debug( toString( entityKeyAndEntity.getKey().getEntityName(), entityKeyAndEntity.getValue() ) );
+			LOG.debug( toString( entityKeyAndEntity.getKey().getEntityName(), entityKeyAndEntity.getValue() ) );
 		}
 	}
 
 	public EntityPrinter(SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/LockModeConverter.java b/hibernate-core/src/main/java/org/hibernate/internal/util/LockModeConverter.java
index d22d4d5be6..3210ccef2f 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/LockModeConverter.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/LockModeConverter.java
@@ -1,109 +1,109 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util;
 
 import javax.persistence.LockModeType;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.LockMode;
 
 /**
  * Helper to deal with conversions (both directions) between {@link org.hibernate.LockMode} and
  * {@link javax.persistence.LockModeType}.
  *
  * @author Steve Ebersole
  */
 public final class LockModeConverter {
 	private LockModeConverter() {
 	}
 
 	/**
 	 * Convert from the Hibernate specific LockMode to the JPA defined LockModeType.
 	 *
 	 * @param lockMode The Hibernate LockMode.
 	 *
 	 * @return The JPA LockModeType
 	 */
 	public static LockModeType convertToLockModeType(LockMode lockMode) {
 		if ( lockMode == LockMode.NONE ) {
 			return LockModeType.NONE;
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC || lockMode == LockMode.READ ) {
 			return LockModeType.OPTIMISTIC;
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC_FORCE_INCREMENT || lockMode == LockMode.WRITE ) {
 			return LockModeType.OPTIMISTIC_FORCE_INCREMENT;
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_READ ) {
 			return LockModeType.PESSIMISTIC_READ;
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_WRITE
 				|| lockMode == LockMode.UPGRADE
 				|| lockMode == LockMode.UPGRADE_NOWAIT
-                || lockMode == LockMode.UPGRADE_SKIPLOCKED) {
+				|| lockMode == LockMode.UPGRADE_SKIPLOCKED) {
 			return LockModeType.PESSIMISTIC_WRITE;
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_FORCE_INCREMENT
 				|| lockMode == LockMode.FORCE ) {
 			return LockModeType.PESSIMISTIC_FORCE_INCREMENT;
 		}
 		throw new AssertionFailure( "unhandled lock mode " + lockMode );
 	}
 
 
 	/**
 	 * Convert from JPA defined LockModeType to Hibernate specific LockMode.
 	 *
 	 * @param lockMode The JPA LockModeType
 	 *
 	 * @return The Hibernate LockMode.
 	 */
 	public static LockMode convertToLockMode(LockModeType lockMode) {
 		switch ( lockMode ) {
 			case READ:
 			case OPTIMISTIC: {
 				return LockMode.OPTIMISTIC;
 			}
 			case OPTIMISTIC_FORCE_INCREMENT:
 			case WRITE: {
 				return LockMode.OPTIMISTIC_FORCE_INCREMENT;
 			}
 			case PESSIMISTIC_READ: {
 				return LockMode.PESSIMISTIC_READ;
 			}
 			case PESSIMISTIC_WRITE: {
 				return LockMode.PESSIMISTIC_WRITE;
 			}
 			case PESSIMISTIC_FORCE_INCREMENT: {
 				return LockMode.PESSIMISTIC_FORCE_INCREMENT;
 			}
 			case NONE: {
 				return LockMode.NONE;
 			}
 			default: {
 				throw new AssertionFailure( "Unknown LockModeType: " + lockMode );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/MarkerObject.java b/hibernate-core/src/main/java/org/hibernate/internal/util/MarkerObject.java
index 86fdae7089..ee8a4845b2 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/MarkerObject.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/MarkerObject.java
@@ -1,42 +1,43 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import java.io.Serializable;
 
 /**
  * @author Gavin King
  */
 public class MarkerObject implements Serializable {
 	private String name;
-	
+
 	public MarkerObject(String name) {
-		this.name=name;
+		this.name = name;
 	}
+
 	@Override
-    public String toString() {
+	public String toString() {
 		return name;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
index d94fbf393c..4095cc1de5 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
@@ -1,380 +1,378 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.ObjectStreamClass;
 import java.io.OutputStream;
 import java.io.Serializable;
 
 import org.hibernate.Hibernate;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.SerializationException;
 
-import org.jboss.logging.Logger;
-
 /**
  * <p>Assists with the serialization process and performs additional functionality based
  * on serialization.</p>
  * <p>
  * <ul>
  * <li>Deep clone using serialization
  * <li>Serialize managing finally and IOException
  * <li>Deserialize managing finally and IOException
  * </ul>
- *
+ * <p/>
  * <p>This class throws exceptions for invalid <code>null</code> inputs.
  * Each method documents its behaviour in more detail.</p>
  *
  * @author <a href="mailto:nissim@nksystems.com">Nissim Karpenstein</a>
  * @author <a href="mailto:janekdb@yahoo.co.uk">Janek Bogucki</a>
  * @author <a href="mailto:dlr@finemaltcoding.com">Daniel Rall</a>
  * @author Stephen Colebourne
  * @author Jeff Varszegi
  * @author Gary Gregory
- * @version $Id: SerializationHelper.java 9180 2006-01-30 23:51:27Z steveebersole $
+ *
  * @since 1.0
  */
 public final class SerializationHelper {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SerializationHelper.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SerializationHelper.class );
 
 	private SerializationHelper() {
 	}
 
 	// Clone
 	//-----------------------------------------------------------------------
 
 	/**
 	 * <p>Deep clone an <code>Object</code> using serialization.</p>
-	 *
+	 * <p/>
 	 * <p>This is many times slower than writing clone methods by hand
 	 * on all objects in your object graph. However, for complex object
 	 * graphs, or for those that don't support deep cloning this can
 	 * be a simple alternative implementation. Of course all the objects
 	 * must be <code>Serializable</code>.</p>
 	 *
 	 * @param object the <code>Serializable</code> object to clone
 	 *
 	 * @return the cloned object
 	 *
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object clone(Serializable object) throws SerializationException {
 		LOG.trace( "Starting clone through serialization" );
 		if ( object == null ) {
 			return null;
 		}
 		return deserialize( serialize( object ), object.getClass().getClassLoader() );
 	}
 
 	// Serialize
 	//-----------------------------------------------------------------------
 
 	/**
 	 * <p>Serializes an <code>Object</code> to the specified stream.</p>
-	 *
+	 * <p/>
 	 * <p>The stream will be closed once the object is written.
 	 * This avoids the need for a finally clause, and maybe also exception
 	 * handling, in the application code.</p>
-	 *
+	 * <p/>
 	 * <p>The stream passed in is not buffered internally within this method.
 	 * This is the responsibility of your application if desired.</p>
 	 *
 	 * @param obj the object to serialize to bytes, may be null
 	 * @param outputStream the stream to write to, must not be null
 	 *
 	 * @throws IllegalArgumentException if <code>outputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static void serialize(Serializable obj, OutputStream outputStream) throws SerializationException {
 		if ( outputStream == null ) {
 			throw new IllegalArgumentException( "The OutputStream must not be null" );
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			if ( Hibernate.isInitialized( obj ) ) {
 				LOG.tracev( "Starting serialization of object [{0}]", obj );
 			}
 			else {
 				LOG.trace( "Starting serialization of [uninitialized proxy]" );
 			}
 		}
 
 		ObjectOutputStream out = null;
 		try {
 			// stream closed in the finally
 			out = new ObjectOutputStream( outputStream );
 			out.writeObject( obj );
 
 		}
-		catch ( IOException ex ) {
+		catch (IOException ex) {
 			throw new SerializationException( "could not serialize", ex );
 		}
 		finally {
 			try {
 				if ( out != null ) {
 					out.close();
 				}
 			}
-			catch ( IOException ignored ) {
+			catch (IOException ignored) {
 			}
 		}
 	}
 
 	/**
 	 * <p>Serializes an <code>Object</code> to a byte array for
 	 * storage/serialization.</p>
 	 *
 	 * @param obj the object to serialize to bytes
 	 *
 	 * @return a byte[] with the converted Serializable
 	 *
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static byte[] serialize(Serializable obj) throws SerializationException {
 		ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream( 512 );
 		serialize( obj, byteArrayOutputStream );
 		return byteArrayOutputStream.toByteArray();
 	}
 
 	// Deserialize
 	//-----------------------------------------------------------------------
 
 	/**
 	 * Deserializes an object from the specified stream using the Thread Context
 	 * ClassLoader (TCCL).
 	 * <p/>
 	 * Delegates to {@link #doDeserialize}
 	 *
 	 * @param inputStream the serialized object input stream, must not be null
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>inputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static <T> T deserialize(InputStream inputStream) throws SerializationException {
 		return doDeserialize( inputStream, defaultClassLoader(), hibernateClassLoader(), null );
 	}
 
 	/**
 	 * Returns the Thread Context ClassLoader (TCCL).
 	 *
 	 * @return The current TCCL
 	 */
 	public static ClassLoader defaultClassLoader() {
 		return ClassLoaderHelper.getContextClassLoader();
 	}
 
 	public static ClassLoader hibernateClassLoader() {
 		return SerializationHelper.class.getClassLoader();
 	}
 
 	/**
 	 * Deserializes an object from the specified stream using the Thread Context
 	 * ClassLoader (TCCL).  If there is no TCCL set, the classloader of the calling
 	 * class is used.
 	 * <p/>
 	 * The stream will be closed once the object is read. This avoids the need
 	 * for a finally clause, and maybe also exception handling, in the application
 	 * code.
 	 * <p/>
 	 * The stream passed in is not buffered internally within this method.  This is
 	 * the responsibility of the caller, if desired.
 	 *
 	 * @param inputStream the serialized object input stream, must not be null
 	 * @param loader The classloader to use
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>inputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(InputStream inputStream, ClassLoader loader) throws SerializationException {
 		return doDeserialize( inputStream, loader, defaultClassLoader(), hibernateClassLoader() );
 	}
 
 	@SuppressWarnings("unchecked")
 	public static <T> T doDeserialize(
 			InputStream inputStream,
 			ClassLoader loader,
 			ClassLoader fallbackLoader1,
 			ClassLoader fallbackLoader2) throws SerializationException {
 		if ( inputStream == null ) {
 			throw new IllegalArgumentException( "The InputStream must not be null" );
 		}
 
 		LOG.trace( "Starting deserialization of object" );
 
 		try {
 			CustomObjectInputStream in = new CustomObjectInputStream(
 					inputStream,
 					loader,
 					fallbackLoader1,
 					fallbackLoader2
 			);
 			try {
 				return (T) in.readObject();
 			}
-			catch ( ClassNotFoundException e ) {
+			catch (ClassNotFoundException e) {
 				throw new SerializationException( "could not deserialize", e );
 			}
-			catch ( IOException e ) {
+			catch (IOException e) {
 				throw new SerializationException( "could not deserialize", e );
 			}
 			finally {
 				try {
 					in.close();
 				}
-				catch ( IOException ignore ) {
+				catch (IOException ignore) {
 					// ignore
 				}
 			}
 		}
-		catch ( IOException e ) {
+		catch (IOException e) {
 			throw new SerializationException( "could not deserialize", e );
 		}
 	}
 
 	/**
 	 * Deserializes an object from an array of bytes using the Thread Context
 	 * ClassLoader (TCCL).  If there is no TCCL set, the classloader of the calling
 	 * class is used.
 	 * <p/>
 	 * Delegates to {@link #deserialize(byte[], ClassLoader)}
 	 *
 	 * @param objectData the serialized object, must not be null
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>objectData</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(byte[] objectData) throws SerializationException {
 		return doDeserialize( wrap( objectData ), defaultClassLoader(), hibernateClassLoader(), null );
 	}
 
 	private static InputStream wrap(byte[] objectData) {
 		if ( objectData == null ) {
 			throw new IllegalArgumentException( "The byte[] must not be null" );
 		}
 		return new ByteArrayInputStream( objectData );
 	}
 
 	/**
 	 * Deserializes an object from an array of bytes.
 	 * <p/>
 	 * Delegates to {@link #deserialize(java.io.InputStream, ClassLoader)} using a
 	 * {@link ByteArrayInputStream} to wrap the array.
 	 *
 	 * @param objectData the serialized object, must not be null
 	 * @param loader The classloader to use
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>objectData</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(byte[] objectData, ClassLoader loader) throws SerializationException {
 		return doDeserialize( wrap( objectData ), loader, defaultClassLoader(), hibernateClassLoader() );
 	}
 
 
 	/**
 	 * By default, to resolve the classes being deserialized JDK serialization uses the
 	 * classes loader which loaded the class which initiated the deserialization call.  Here
 	 * that would be hibernate classes.  However, there are cases where that is not the correct
 	 * class loader to use; mainly here we are worried about deserializing user classes in
 	 * environments (app servers, etc) where Hibernate is on a parent classes loader.  To
 	 * facilitate for that we allow passing in the class loader we should use.
 	 */
 	private static final class CustomObjectInputStream extends ObjectInputStream {
 		private final ClassLoader loader1;
 		private final ClassLoader loader2;
 		private final ClassLoader loader3;
 
 		private CustomObjectInputStream(
 				InputStream in,
 				ClassLoader loader1,
 				ClassLoader loader2,
 				ClassLoader loader3) throws IOException {
 			super( in );
 			this.loader1 = loader1;
 			this.loader2 = loader2;
 			this.loader3 = loader3;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		@Override
 		protected Class resolveClass(ObjectStreamClass v) throws IOException, ClassNotFoundException {
 			final String className = v.getName();
 			LOG.tracev( "Attempting to locate class [{0}]", className );
 
 			try {
 				return Class.forName( className, false, loader1 );
 			}
-			catch ( ClassNotFoundException e ) {
+			catch (ClassNotFoundException e) {
 				LOG.trace( "Unable to locate class using given classloader" );
 			}
 
 			if ( different( loader1, loader2 ) ) {
 				try {
 					return Class.forName( className, false, loader2 );
 				}
-				catch ( ClassNotFoundException e ) {
+				catch (ClassNotFoundException e) {
 					LOG.trace( "Unable to locate class using given classloader" );
 				}
 			}
 
 			if ( different( loader1, loader3 ) && different( loader2, loader3 ) ) {
 				try {
 					return Class.forName( className, false, loader3 );
 				}
-				catch ( ClassNotFoundException e ) {
+				catch (ClassNotFoundException e) {
 					LOG.trace( "Unable to locate class using given classloader" );
 				}
 			}
 
 			// By default delegate to normal JDK deserialization which will use the class loader
 			// of the class which is calling this deserialization.
 			return super.resolveClass( v );
 		}
 
 		private boolean different(ClassLoader one, ClassLoader other) {
-            if (one == null) {
+			if ( one == null ) {
 				return other != null;
 			}
-            return !one.equals(other);
+			return !one.equals( other );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
index 226092c73b..dd57a6ead2 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
@@ -1,788 +1,817 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.BitSet;
 import java.util.Iterator;
 import java.util.Locale;
 import java.util.StringTokenizer;
 
 public final class StringHelper {
 
 	private static final int ALIAS_TRUNCATE_LENGTH = 10;
 	public static final String WHITESPACE = " \n\r\f\t";
 	public static final String[] EMPTY_STRINGS = new String[0];
 
 	private StringHelper() { /* static methods only - hide constructor */
 	}
 
 	public static int lastIndexOfLetter(String string) {
-		for ( int i=0; i<string.length(); i++ ) {
-			char character = string.charAt(i);
+		for ( int i = 0; i < string.length(); i++ ) {
+			char character = string.charAt( i );
 			// Include "_".  See HHH-8073
-			if ( !Character.isLetter(character) && !('_'==character) ) {
-				return i-1;
+			if ( !Character.isLetter( character ) && !( '_' == character ) ) {
+				return i - 1;
 			}
 		}
-		return string.length()-1;
+		return string.length() - 1;
 	}
 
 	public static String join(String seperator, String[] strings) {
 		int length = strings.length;
 		if ( length == 0 ) {
 			return "";
 		}
 		StringBuilder buf = new StringBuilder( length * strings[0].length() )
 				.append( strings[0] );
 		for ( int i = 1; i < length; i++ ) {
 			buf.append( seperator ).append( strings[i] );
 		}
 		return buf.toString();
 	}
 
-	public static String joinWithQualifierAndSuffix(String[] values, String qualifier, String suffix, String deliminator) {
+	public static String joinWithQualifierAndSuffix(
+			String[] values,
+			String qualifier,
+			String suffix,
+			String deliminator) {
 		int length = values.length;
 		if ( length == 0 ) {
 			return "";
 		}
 		StringBuilder buf = new StringBuilder( length * ( values[0].length() + suffix.length() ) )
 				.append( qualify( qualifier, values[0] ) ).append( suffix );
 		for ( int i = 1; i < length; i++ ) {
 			buf.append( deliminator ).append( qualify( qualifier, values[i] ) ).append( suffix );
 		}
 		return buf.toString();
 	}
 
 	public static String join(String seperator, Iterator objects) {
 		StringBuilder buf = new StringBuilder();
 		if ( objects.hasNext() ) {
 			buf.append( objects.next() );
 		}
 		while ( objects.hasNext() ) {
 			buf.append( seperator ).append( objects.next() );
 		}
 		return buf.toString();
 	}
 
 	public static String join(String separator, Iterable objects) {
 		return join( separator, objects.iterator() );
 	}
 
 	public static String[] add(String[] x, String sep, String[] y) {
 		final String[] result = new String[x.length];
 		for ( int i = 0; i < x.length; i++ ) {
 			result[i] = x[i] + sep + y[i];
 		}
 		return result;
 	}
 
 	public static String repeat(String string, int times) {
 		StringBuilder buf = new StringBuilder( string.length() * times );
 		for ( int i = 0; i < times; i++ ) {
 			buf.append( string );
 		}
 		return buf.toString();
 	}
 
 	public static String repeat(String string, int times, String deliminator) {
-		StringBuilder buf = new StringBuilder(  ( string.length() * times ) + ( deliminator.length() * (times-1) ) )
+		StringBuilder buf = new StringBuilder( ( string.length() * times ) + ( deliminator.length() * ( times - 1 ) ) )
 				.append( string );
 		for ( int i = 1; i < times; i++ ) {
 			buf.append( deliminator ).append( string );
 		}
 		return buf.toString();
 	}
 
 	public static String repeat(char character, int times) {
 		char[] buffer = new char[times];
 		Arrays.fill( buffer, character );
 		return new String( buffer );
 	}
 
 
 	public static String replace(String template, String placeholder, String replacement) {
 		return replace( template, placeholder, replacement, false );
 	}
 
 	public static String[] replace(String[] templates, String placeholder, String replacement) {
 		String[] result = new String[templates.length];
-		for ( int i =0; i<templates.length; i++ ) {
+		for ( int i = 0; i < templates.length; i++ ) {
 			result[i] = replace( templates[i], placeholder, replacement );
 		}
 		return result;
 	}
 
 	public static String replace(String template, String placeholder, String replacement, boolean wholeWords) {
 		return replace( template, placeholder, replacement, wholeWords, false );
 	}
 
 	public static String replace(
 			String template,
 			String placeholder,
 			String replacement,
 			boolean wholeWords,
 			boolean encloseInParensIfNecessary) {
 		if ( template == null ) {
 			return null;
 		}
 		int loc = template.indexOf( placeholder );
 		if ( loc < 0 ) {
 			return template;
 		}
 		else {
 			String beforePlaceholder = template.substring( 0, loc );
 			String afterPlaceholder = template.substring( loc + placeholder.length() );
-			return replace( beforePlaceholder, afterPlaceholder, placeholder, replacement, wholeWords, encloseInParensIfNecessary );
+			return replace(
+					beforePlaceholder,
+					afterPlaceholder,
+					placeholder,
+					replacement,
+					wholeWords,
+					encloseInParensIfNecessary
+			);
 		}
 	}
 
 
 	public static String replace(
 			String beforePlaceholder,
 			String afterPlaceholder,
 			String placeholder,
 			String replacement,
 			boolean wholeWords,
 			boolean encloseInParensIfNecessary) {
 		final boolean actuallyReplace =
-				! wholeWords
+				!wholeWords
 						|| afterPlaceholder.length() == 0
-						|| ! Character.isJavaIdentifierPart( afterPlaceholder.charAt( 0 ) );
+						|| !Character.isJavaIdentifierPart( afterPlaceholder.charAt( 0 ) );
 		boolean encloseInParens =
 				actuallyReplace
 						&& encloseInParensIfNecessary
-						&& ! ( getLastNonWhitespaceCharacter( beforePlaceholder ) == '(' )
-						&& ! ( getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')' );
+						&& !( getLastNonWhitespaceCharacter( beforePlaceholder ) == '(' )
+						&& !( getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')' );
 		StringBuilder buf = new StringBuilder( beforePlaceholder );
 		if ( encloseInParens ) {
 			buf.append( '(' );
 		}
 		buf.append( actuallyReplace ? replacement : placeholder );
 		if ( encloseInParens ) {
 			buf.append( ')' );
 		}
 		buf.append(
 				replace(
 						afterPlaceholder,
 						placeholder,
 						replacement,
 						wholeWords,
 						encloseInParensIfNecessary
 				)
 		);
 		return buf.toString();
 	}
 
 	public static char getLastNonWhitespaceCharacter(String str) {
 		if ( str != null && str.length() > 0 ) {
-			for ( int i = str.length() - 1 ; i >= 0 ; i-- ) {
+			for ( int i = str.length() - 1; i >= 0; i-- ) {
 				char ch = str.charAt( i );
-				if ( ! Character.isWhitespace( ch ) ) {
+				if ( !Character.isWhitespace( ch ) ) {
 					return ch;
 				}
 			}
 		}
 		return '\0';
 	}
 
 	public static char getFirstNonWhitespaceCharacter(String str) {
 		if ( str != null && str.length() > 0 ) {
-			for ( int i = 0 ; i < str.length() ; i++ ) {
+			for ( int i = 0; i < str.length(); i++ ) {
 				char ch = str.charAt( i );
-				if ( ! Character.isWhitespace( ch ) ) {
+				if ( !Character.isWhitespace( ch ) ) {
 					return ch;
 				}
 			}
 		}
 		return '\0';
 	}
 
 	public static String replaceOnce(String template, String placeholder, String replacement) {
 		if ( template == null ) {
 			return null;  // returnign null!
 		}
-        int loc = template.indexOf( placeholder );
+		int loc = template.indexOf( placeholder );
 		if ( loc < 0 ) {
 			return template;
 		}
 		else {
 			return template.substring( 0, loc ) + replacement + template.substring( loc + placeholder.length() );
 		}
 	}
 
 
 	public static String[] split(String seperators, String list) {
 		return split( seperators, list, false );
 	}
 
 	public static String[] split(String seperators, String list, boolean include) {
 		StringTokenizer tokens = new StringTokenizer( list, seperators, include );
-		String[] result = new String[ tokens.countTokens() ];
+		String[] result = new String[tokens.countTokens()];
 		int i = 0;
 		while ( tokens.hasMoreTokens() ) {
 			result[i++] = tokens.nextToken();
 		}
 		return result;
 	}
 
 	public static String unqualify(String qualifiedName) {
-		int loc = qualifiedName.lastIndexOf(".");
+		int loc = qualifiedName.lastIndexOf( "." );
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc + 1 );
 	}
 
 	public static String qualifier(String qualifiedName) {
-		int loc = qualifiedName.lastIndexOf(".");
+		int loc = qualifiedName.lastIndexOf( "." );
 		return ( loc < 0 ) ? "" : qualifiedName.substring( 0, loc );
 	}
 
 	/**
 	 * Collapses a name.  Mainly intended for use with classnames, where an example might serve best to explain.
 	 * Imagine you have a class named <samp>'org.hibernate.internal.util.StringHelper'</samp>; calling collapse on that
 	 * classname will result in <samp>'o.h.u.StringHelper'<samp>.
 	 *
 	 * @param name The name to collapse.
+	 *
 	 * @return The collapsed name.
 	 */
 	public static String collapse(String name) {
 		if ( name == null ) {
 			return null;
 		}
 		int breakPoint = name.lastIndexOf( '.' );
 		if ( breakPoint < 0 ) {
 			return name;
 		}
-		return collapseQualifier( name.substring( 0, breakPoint ), true ) + name.substring( breakPoint ); // includes last '.'
+		return collapseQualifier(
+				name.substring( 0, breakPoint ),
+				true
+		) + name.substring( breakPoint ); // includes last '.'
 	}
 
 	/**
 	 * Given a qualifier, collapse it.
 	 *
 	 * @param qualifier The qualifier to collapse.
 	 * @param includeDots Should we include the dots in the collapsed form?
 	 *
 	 * @return The collapsed form.
 	 */
 	public static String collapseQualifier(String qualifier, boolean includeDots) {
 		StringTokenizer tokenizer = new StringTokenizer( qualifier, "." );
 		String collapsed = Character.toString( tokenizer.nextToken().charAt( 0 ) );
 		while ( tokenizer.hasMoreTokens() ) {
 			if ( includeDots ) {
 				collapsed += '.';
 			}
 			collapsed += tokenizer.nextToken().charAt( 0 );
 		}
 		return collapsed;
 	}
 
 	/**
 	 * Partially unqualifies a qualified name.  For example, with a base of 'org.hibernate' the name
 	 * 'org.hibernate.internal.util.StringHelper' would become 'util.StringHelper'.
 	 *
 	 * @param name The (potentially) qualified name.
 	 * @param qualifierBase The qualifier base.
 	 *
 	 * @return The name itself, or the partially unqualified form if it begins with the qualifier base.
 	 */
 	public static String partiallyUnqualify(String name, String qualifierBase) {
-		if ( name == null || ! name.startsWith( qualifierBase ) ) {
+		if ( name == null || !name.startsWith( qualifierBase ) ) {
 			return name;
 		}
 		return name.substring( qualifierBase.length() + 1 ); // +1 to start after the following '.'
 	}
 
 	/**
 	 * Cross between {@link #collapse} and {@link #partiallyUnqualify}.  Functions much like {@link #collapse}
 	 * except that only the qualifierBase is collapsed.  For example, with a base of 'org.hibernate' the name
 	 * 'org.hibernate.internal.util.StringHelper' would become 'o.h.util.StringHelper'.
 	 *
 	 * @param name The (potentially) qualified name.
 	 * @param qualifierBase The qualifier base.
 	 *
 	 * @return The name itself if it does not begin with the qualifierBase, or the properly collapsed form otherwise.
 	 */
 	public static String collapseQualifierBase(String name, String qualifierBase) {
-		if ( name == null || ! name.startsWith( qualifierBase ) ) {
+		if ( name == null || !name.startsWith( qualifierBase ) ) {
 			return collapse( name );
 		}
 		return collapseQualifier( qualifierBase, true ) + name.substring( qualifierBase.length() );
 	}
 
 	public static String[] suffix(String[] columns, String suffix) {
-		if ( suffix == null ) return columns;
+		if ( suffix == null ) {
+			return columns;
+		}
 		String[] qualified = new String[columns.length];
 		for ( int i = 0; i < columns.length; i++ ) {
 			qualified[i] = suffix( columns[i], suffix );
 		}
 		return qualified;
 	}
 
 	private static String suffix(String name, String suffix) {
 		return ( suffix == null ) ? name : name + suffix;
 	}
 
 	public static String root(String qualifiedName) {
 		int loc = qualifiedName.indexOf( "." );
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( 0, loc );
 	}
 
 	public static String unroot(String qualifiedName) {
 		int loc = qualifiedName.indexOf( "." );
-		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc+1, qualifiedName.length() );
+		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc + 1, qualifiedName.length() );
 	}
 
 	public static boolean booleanValue(String tfString) {
 		String trimmed = tfString.trim().toLowerCase( Locale.ROOT );
 		return trimmed.equals( "true" ) || trimmed.equals( "t" );
 	}
 
 	public static String toString(Object[] array) {
 		int len = array.length;
 		if ( len == 0 ) {
 			return "";
 		}
 		StringBuilder buf = new StringBuilder( len * 12 );
 		for ( int i = 0; i < len - 1; i++ ) {
-			buf.append( array[i] ).append(", ");
+			buf.append( array[i] ).append( ", " );
 		}
 		return buf.append( array[len - 1] ).toString();
 	}
 
 	public static String[] multiply(String string, Iterator placeholders, Iterator replacements) {
-		String[] result = new String[]{string};
+		String[] result = new String[] {string};
 		while ( placeholders.hasNext() ) {
-			result = multiply( result, ( String ) placeholders.next(), ( String[] ) replacements.next() );
+			result = multiply( result, (String) placeholders.next(), (String[]) replacements.next() );
 		}
 		return result;
 	}
 
 	private static String[] multiply(String[] strings, String placeholder, String[] replacements) {
 		String[] results = new String[replacements.length * strings.length];
 		int n = 0;
 		for ( String replacement : replacements ) {
 			for ( String string : strings ) {
 				results[n++] = replaceOnce( string, placeholder, replacement );
 			}
 		}
 		return results;
 	}
 
 	public static int countUnquoted(String string, char character) {
 		if ( '\'' == character ) {
 			throw new IllegalArgumentException( "Unquoted count of quotes is invalid" );
 		}
-		if (string == null)
+		if ( string == null ) {
 			return 0;
+		}
 		// Impl note: takes advantage of the fact that an escpaed single quote
 		// embedded within a quote-block can really be handled as two seperate
 		// quote-blocks for the purposes of this method...
 		int count = 0;
 		int stringLength = string.length();
 		boolean inQuote = false;
 		for ( int indx = 0; indx < stringLength; indx++ ) {
 			char c = string.charAt( indx );
 			if ( inQuote ) {
 				if ( '\'' == c ) {
 					inQuote = false;
 				}
 			}
 			else if ( '\'' == c ) {
 				inQuote = true;
 			}
 			else if ( c == character ) {
 				count++;
 			}
 		}
 		return count;
 	}
 
 	public static int[] locateUnquoted(String string, char character) {
 		if ( '\'' == character ) {
 			throw new IllegalArgumentException( "Unquoted count of quotes is invalid" );
 		}
-		if (string == null) {
+		if ( string == null ) {
 			return new int[0];
 		}
 
 		ArrayList locations = new ArrayList( 20 );
 
 		// Impl note: takes advantage of the fact that an escpaed single quote
 		// embedded within a quote-block can really be handled as two seperate
 		// quote-blocks for the purposes of this method...
 		int stringLength = string.length();
 		boolean inQuote = false;
 		for ( int indx = 0; indx < stringLength; indx++ ) {
 			char c = string.charAt( indx );
 			if ( inQuote ) {
 				if ( '\'' == c ) {
 					inQuote = false;
 				}
 			}
 			else if ( '\'' == c ) {
 				inQuote = true;
 			}
 			else if ( c == character ) {
 				locations.add( indx );
 			}
 		}
 		return ArrayHelper.toIntArray( locations );
 	}
 
 	public static boolean isNotEmpty(String string) {
 		return string != null && string.length() > 0;
 	}
 
 	public static boolean isEmpty(String string) {
 		return string == null || string.length() == 0;
 	}
 
-	public static boolean isEmptyOrWhiteSpace(String string){
+	public static boolean isEmptyOrWhiteSpace(String string) {
 		return isEmpty( string ) || isEmpty( string.trim() );
 	}
 
 	public static String qualify(String prefix, String name) {
 		if ( name == null || prefix == null ) {
 			throw new NullPointerException( "prefix or name were null attempting to build qualified name" );
 		}
 		return prefix + '.' + name;
 	}
 
 	public static String[] qualify(String prefix, String[] names) {
 		if ( prefix == null ) {
 			return names;
 		}
 		int len = names.length;
 		String[] qualified = new String[len];
 		for ( int i = 0; i < len; i++ ) {
 			qualified[i] = qualify( prefix, names[i] );
 		}
 		return qualified;
 	}
 
 	public static String[] qualifyIfNot(String prefix, String[] names) {
 		if ( prefix == null ) {
 			return names;
 		}
 		int len = names.length;
 		String[] qualified = new String[len];
 		for ( int i = 0; i < len; i++ ) {
 			if ( names[i].indexOf( '.' ) < 0 ) {
 				qualified[i] = qualify( prefix, names[i] );
 			}
 			else {
 				qualified[i] = names[i];
 			}
 		}
 		return qualified;
 	}
 
 	public static int firstIndexOfChar(String sqlString, BitSet keys, int startindex) {
 		for ( int i = startindex, size = sqlString.length(); i < size; i++ ) {
 			if ( keys.get( sqlString.charAt( i ) ) ) {
 				return i;
 			}
 		}
 		return -1;
 
 	}
 
 	public static int firstIndexOfChar(String sqlString, String string, int startindex) {
 		BitSet keys = new BitSet();
 		for ( int i = 0, size = string.length(); i < size; i++ ) {
 			keys.set( string.charAt( i ) );
 		}
 		return firstIndexOfChar( sqlString, keys, startindex );
 
 	}
 
 	public static String truncate(String string, int length) {
 		if ( string.length() <= length ) {
 			return string;
 		}
 		else {
 			return string.substring( 0, length );
 		}
 	}
 
 	public static String generateAlias(String description) {
-		return generateAliasRoot(description) + '_';
+		return generateAliasRoot( description ) + '_';
 	}
 
 	/**
 	 * Generate a nice alias for the given class name or collection role name and unique integer. Subclasses of
 	 * Loader do <em>not</em> have to use aliases of this form.
 	 *
 	 * @param description The base name (usually an entity-name or collection-role)
 	 * @param unique A uniquing value
 	 *
 	 * @return an alias of the form <samp>foo1_</samp>
 	 */
 	public static String generateAlias(String description, int unique) {
-		return generateAliasRoot(description)
-				+ Integer.toString(unique)
+		return generateAliasRoot( description )
+				+ Integer.toString( unique )
 				+ '_';
 	}
 
 	/**
 	 * Generates a root alias by truncating the "root name" defined by
 	 * the incoming decription and removing/modifying any non-valid
 	 * alias characters.
 	 *
 	 * @param description The root name from which to generate a root alias.
+	 *
 	 * @return The generated root alias.
 	 */
 	private static String generateAliasRoot(String description) {
-		String result = truncate( unqualifyEntityName(description), ALIAS_TRUNCATE_LENGTH )
-				.toLowerCase(Locale.ROOT)
-		        .replace( '/', '_' ) // entityNames may now include slashes for the representations
+		String result = truncate( unqualifyEntityName( description ), ALIAS_TRUNCATE_LENGTH )
+				.toLowerCase( Locale.ROOT )
+				.replace( '/', '_' ) // entityNames may now include slashes for the representations
 				.replace( '$', '_' ); //classname may be an inner class
 		result = cleanAlias( result );
-		if ( Character.isDigit( result.charAt(result.length()-1) ) ) {
+		if ( Character.isDigit( result.charAt( result.length() - 1 ) ) ) {
 			return result + "x"; //ick!
 		}
 		else {
 			return result;
 		}
 	}
 
 	/**
 	 * Clean the generated alias by removing any non-alpha characters from the
 	 * beginning.
 	 *
 	 * @param alias The generated alias to be cleaned.
+	 *
 	 * @return The cleaned alias, stripped of any leading non-alpha characters.
 	 */
 	private static String cleanAlias(String alias) {
 		char[] chars = alias.toCharArray();
 		// short cut check...
 		if ( !Character.isLetter( chars[0] ) ) {
 			for ( int i = 1; i < chars.length; i++ ) {
 				// as soon as we encounter our first letter, return the substring
 				// from that position
 				if ( Character.isLetter( chars[i] ) ) {
 					return alias.substring( i );
 				}
 			}
 		}
 		return alias;
 	}
 
 	public static String unqualifyEntityName(String entityName) {
-		String result = unqualify(entityName);
+		String result = unqualify( entityName );
 		int slashPos = result.indexOf( '/' );
 		if ( slashPos > 0 ) {
 			result = result.substring( 0, slashPos - 1 );
 		}
 		return result;
 	}
 
 	public static String moveAndToBeginning(String filter) {
-		if ( filter.trim().length()>0 ){
+		if ( filter.trim().length() > 0 ) {
 			filter += " and ";
-			if ( filter.startsWith(" and ") ) {
-				filter = filter.substring(4);
+			if ( filter.startsWith( " and " ) ) {
+				filter = filter.substring( 4 );
 			}
 		}
 		return filter;
 	}
 
 	/**
 	 * Determine if the given string is quoted (wrapped by '`' characters at beginning and end).
 	 *
 	 * @param name The name to check.
+	 *
 	 * @return True if the given string starts and ends with '`'; false otherwise.
 	 */
 	public static boolean isQuoted(String name) {
-		return name != null && name.length() != 0 
+		return name != null && name.length() != 0
 				&& ( ( name.charAt( 0 ) == '`' && name.charAt( name.length() - 1 ) == '`' )
-						|| ( name.charAt( 0 ) == '"' && name.charAt( name.length() - 1 ) == '"' ) );
+				|| ( name.charAt( 0 ) == '"' && name.charAt( name.length() - 1 ) == '"' ) );
 	}
 
 	/**
 	 * Return a representation of the given name ensuring quoting (wrapped with '`' characters).  If already wrapped
 	 * return name.
 	 *
 	 * @param name The name to quote.
+	 *
 	 * @return The quoted version.
 	 */
 	public static String quote(String name) {
 		if ( isEmpty( name ) || isQuoted( name ) ) {
 			return name;
 		}
 		// Convert the JPA2 specific quoting character (double quote) to Hibernate's (back tick)
-        else if ( name.startsWith( "\"" ) && name.endsWith( "\"" ) ) {
-            name = name.substring( 1, name.length() - 1 );
-        }
+		else if ( name.startsWith( "\"" ) && name.endsWith( "\"" ) ) {
+			name = name.substring( 1, name.length() - 1 );
+		}
 
 		return "`" + name + '`';
 	}
 
 	/**
 	 * Return the unquoted version of name (stripping the start and end '`' characters if present).
 	 *
 	 * @param name The name to be unquoted.
+	 *
 	 * @return The unquoted version.
 	 */
 	public static String unquote(String name) {
 		return isQuoted( name ) ? name.substring( 1, name.length() - 1 ) : name;
 	}
 
 	/**
 	 * Determine if the given name is quoted.  It is considered quoted if either:
 	 * <ol>
 	 * <li>starts AND ends with backticks (`)</li>
 	 * <li>starts with dialect-specified {@link org.hibernate.dialect.Dialect#openQuote() open-quote}
-	 * 		AND ends with dialect-specified {@link org.hibernate.dialect.Dialect#closeQuote() close-quote}</li>
+	 * AND ends with dialect-specified {@link org.hibernate.dialect.Dialect#closeQuote() close-quote}</li>
 	 * </ol>
 	 *
 	 * @param name The name to check
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return True if quoted, false otherwise
 	 */
 	public static boolean isQuoted(String name, Dialect dialect) {
-		return name != null && name.length() != 0 
+		return name != null && name.length() != 0
 				&& ( ( name.charAt( 0 ) == '`' && name.charAt( name.length() - 1 ) == '`' )
-						|| ( name.charAt( 0 ) == '"' && name.charAt( name.length() - 1 ) == '"' )
-						|| ( name.charAt( 0 ) == dialect.openQuote()
-								&& name.charAt( name.length() - 1 ) == dialect.closeQuote() ) );
+				|| ( name.charAt( 0 ) == '"' && name.charAt( name.length() - 1 ) == '"' )
+				|| ( name.charAt( 0 ) == dialect.openQuote()
+				&& name.charAt( name.length() - 1 ) == dialect.closeQuote() ) );
 	}
 
 	/**
 	 * Return the unquoted version of name stripping the start and end quote characters.
 	 *
 	 * @param name The name to be unquoted.
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return The unquoted version.
 	 */
 	public static String unquote(String name, Dialect dialect) {
 		return isQuoted( name, dialect ) ? name.substring( 1, name.length() - 1 ) : name;
 	}
 
 	/**
 	 * Return the unquoted version of name stripping the start and end quote characters.
 	 *
 	 * @param names The names to be unquoted.
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return The unquoted versions.
 	 */
 	public static String[] unquote(String[] names, Dialect dialect) {
 		if ( names == null ) {
 			return null;
 		}
-		String[] unquoted = new String[ names.length ];
+		String[] unquoted = new String[names.length];
 		for ( int i = 0; i < names.length; i++ ) {
 			unquoted[i] = unquote( names[i], dialect );
 		}
 		return unquoted;
 	}
 
 
 	public static final String BATCH_ID_PLACEHOLDER = "$$BATCH_ID_PLACEHOLDER$$";
 
 	public static StringBuilder buildBatchFetchRestrictionFragment(
 			String alias,
 			String[] columnNames,
 			Dialect dialect) {
 		// the general idea here is to just insert a placeholder that we can easily find later...
 		if ( columnNames.length == 1 ) {
 			// non-composite key
 			return new StringBuilder( StringHelper.qualify( alias, columnNames[0] ) )
 					.append( " in (" ).append( BATCH_ID_PLACEHOLDER ).append( ")" );
 		}
 		else {
 			// composite key - the form to use here depends on what the dialect supports.
 			if ( dialect.supportsRowValueConstructorSyntaxInInList() ) {
 				// use : (col1, col2) in ( (?,?), (?,?), ... )
 				StringBuilder builder = new StringBuilder();
 				builder.append( "(" );
 				boolean firstPass = true;
 				String deliminator = "";
 				for ( String columnName : columnNames ) {
 					builder.append( deliminator ).append( StringHelper.qualify( alias, columnName ) );
 					if ( firstPass ) {
 						firstPass = false;
 						deliminator = ",";
 					}
 				}
 				builder.append( ") in (" );
 				builder.append( BATCH_ID_PLACEHOLDER );
 				builder.append( ")" );
 				return builder;
 			}
 			else {
 				// use : ( (col1 = ? and col2 = ?) or (col1 = ? and col2 = ?) or ... )
 				//		unfortunately most of this building needs to be held off until we know
 				//		the exact number of ids :(
 				return new StringBuilder( "(" ).append( BATCH_ID_PLACEHOLDER ).append( ")" );
 			}
 		}
 	}
 
 	public static String expandBatchIdPlaceholder(
 			String sql,
 			Serializable[] ids,
 			String alias,
 			String[] keyColumnNames,
 			Dialect dialect) {
 		if ( keyColumnNames.length == 1 ) {
 			// non-composite
 			return StringHelper.replace( sql, BATCH_ID_PLACEHOLDER, repeat( "?", ids.length, "," ) );
 		}
 		else {
 			// composite
 			if ( dialect.supportsRowValueConstructorSyntaxInInList() ) {
 				final String tuple = "(" + StringHelper.repeat( "?", keyColumnNames.length, "," ) + ")";
 				return StringHelper.replace( sql, BATCH_ID_PLACEHOLDER, repeat( tuple, ids.length, "," ) );
 			}
 			else {
-				final String keyCheck = "(" +  joinWithQualifierAndSuffix( keyColumnNames, alias, " = ?", " and " ) + ")";
+				final String keyCheck = "(" + joinWithQualifierAndSuffix(
+						keyColumnNames,
+						alias,
+						" = ?",
+						" and "
+				) + ")";
 				return replace( sql, BATCH_ID_PLACEHOLDER, repeat( keyCheck, ids.length, " or " ) );
 			}
 		}
 	}
-	
+
 	/**
 	 * Takes a String s and returns a new String[1] with s as the only element.
 	 * If s is null or "", return String[0].
-	 * 
+	 *
 	 * @param s
+	 *
 	 * @return String[]
 	 */
 	public static String[] toArrayElement(String s) {
-		return ( s == null || s.length() == 0 ) ? new String[0] : new String[] { s };
+		return ( s == null || s.length() == 0 ) ? new String[0] : new String[] {s};
 	}
 
 	public static String nullIfEmpty(String value) {
 		return isEmpty( value ) ? null : value;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/beans/BeanIntrospectionException.java b/hibernate-core/src/main/java/org/hibernate/internal/util/beans/BeanIntrospectionException.java
index 93ae2206ed..a876f76c3b 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/beans/BeanIntrospectionException.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/beans/BeanIntrospectionException.java
@@ -1,42 +1,41 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.beans;
-import java.beans.BeanInfo;
 
 import org.hibernate.HibernateException;
 
 /**
- * Indicates a problem dealing with {@link BeanInfo} via the {@link BeanInfoHelper} delegate.
+ * Indicates a problem dealing with {@link java.beans.BeanInfo} via the {@link BeanInfoHelper} delegate.
  *
  * @author Steve Ebersole
  */
 public class BeanIntrospectionException extends HibernateException {
 	public BeanIntrospectionException(String string, Throwable root) {
 		super( string, root );
 	}
 
 	public BeanIntrospectionException(String s) {
 		super( s );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ArrayHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ArrayHelper.java
index 697743be59..da42dfe82c 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ArrayHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ArrayHelper.java
@@ -1,459 +1,461 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.internal.util.collections;
 
 import java.io.Serializable;
 import java.lang.reflect.Array;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.type.Type;
 
 public final class ArrayHelper {
-	
+
 	public static boolean contains(Object[] array, Object object) {
 		return indexOf( array, object ) > -1;
 	}
-	
+
 	public static int indexOf(Object[] array, Object object) {
 		for ( int i = 0; i < array.length; i++ ) {
 			if ( array[i].equals( object ) ) {
 				return i;
 			}
 		}
 		return -1;
 	}
 	
 	/*public static Object[] clone(Class elementClass, Object[] array) {
 		Object[] result = (Object[]) Array.newInstance( elementClass, array.length );
 		System.arraycopy(array, 0, result, 0, array.length);
 		return result;
 	}*/
 
 	public static String[] toStringArray(Object[] objects) {
-		int length=objects.length;
+		int length = objects.length;
 		String[] result = new String[length];
-		for (int i=0; i<length; i++) {
+		for ( int i = 0; i < length; i++ ) {
 			result[i] = objects[i].toString();
 		}
 		return result;
 	}
 
 	public static String[] fillArray(String value, int length) {
 		String[] result = new String[length];
-		Arrays.fill(result, value);
+		Arrays.fill( result, value );
 		return result;
 	}
 
 	public static int[] fillArray(int value, int length) {
 		int[] result = new int[length];
-		Arrays.fill(result, value);
+		Arrays.fill( result, value );
 		return result;
 	}
 
 	public static LockMode[] fillArray(LockMode lockMode, int length) {
 		LockMode[] array = new LockMode[length];
-		Arrays.fill(array, lockMode);
+		Arrays.fill( array, lockMode );
 		return array;
 	}
 
 	public static LockOptions[] fillArray(LockOptions lockOptions, int length) {
 		LockOptions[] array = new LockOptions[length];
-		Arrays.fill(array, lockOptions);
+		Arrays.fill( array, lockOptions );
 		return array;
 	}
 
 	public static String[] toStringArray(Collection coll) {
 		return (String[]) coll.toArray( new String[coll.size()] );
 	}
-	
+
 	public static String[][] to2DStringArray(Collection coll) {
-		return (String[][]) coll.toArray( new String[ coll.size() ][] );
+		return (String[][]) coll.toArray( new String[coll.size()][] );
 	}
-	
+
 	public static int[][] to2DIntArray(Collection coll) {
-		return (int[][]) coll.toArray( new int[ coll.size() ][] );
+		return (int[][]) coll.toArray( new int[coll.size()][] );
 	}
-	
+
 	public static Type[] toTypeArray(Collection coll) {
 		return (Type[]) coll.toArray( new Type[coll.size()] );
 	}
 
 	public static int[] toIntArray(Collection coll) {
 		Iterator iter = coll.iterator();
-		int[] arr = new int[ coll.size() ];
-		int i=0;
-		while( iter.hasNext() ) {
+		int[] arr = new int[coll.size()];
+		int i = 0;
+		while ( iter.hasNext() ) {
 			arr[i++] = (Integer) iter.next();
 		}
 		return arr;
 	}
 
 	public static boolean[] toBooleanArray(Collection coll) {
 		Iterator iter = coll.iterator();
-		boolean[] arr = new boolean[ coll.size() ];
-		int i=0;
-		while( iter.hasNext() ) {
+		boolean[] arr = new boolean[coll.size()];
+		int i = 0;
+		while ( iter.hasNext() ) {
 			arr[i++] = (Boolean) iter.next();
 		}
 		return arr;
 	}
 
 	public static Object[] typecast(Object[] array, Object[] to) {
-		return java.util.Arrays.asList(array).toArray(to);
+		return java.util.Arrays.asList( array ).toArray( to );
 	}
 
 	//Arrays.asList doesn't do primitive arrays
 	public static List toList(Object array) {
-		if ( array instanceof Object[] ) return Arrays.asList( (Object[]) array ); //faster?
-		int size = Array.getLength(array);
-		ArrayList list = new ArrayList(size);
-		for (int i=0; i<size; i++) {
-			list.add( Array.get(array, i) );
+		if ( array instanceof Object[] ) {
+			return Arrays.asList( (Object[]) array ); //faster?
+		}
+		int size = Array.getLength( array );
+		ArrayList list = new ArrayList( size );
+		for ( int i = 0; i < size; i++ ) {
+			list.add( Array.get( array, i ) );
 		}
 		return list;
 	}
 
 	public static String[] slice(String[] strings, int begin, int length) {
 		String[] result = new String[length];
 		System.arraycopy( strings, begin, result, 0, length );
 		return result;
 	}
 
 	public static Object[] slice(Object[] objects, int begin, int length) {
 		Object[] result = new Object[length];
 		System.arraycopy( objects, begin, result, 0, length );
 		return result;
 	}
 
 	public static List toList(Iterator iter) {
 		List list = new ArrayList();
 		while ( iter.hasNext() ) {
 			list.add( iter.next() );
 		}
 		return list;
 	}
 
 	public static String[] join(String[] x, String[] y) {
-		String[] result = new String[ x.length + y.length ];
+		String[] result = new String[x.length + y.length];
 		System.arraycopy( x, 0, result, 0, x.length );
 		System.arraycopy( y, 0, result, x.length, y.length );
 		return result;
 	}
 
 	public static String[] join(String[] x, String[] y, boolean[] use) {
-		String[] result = new String[ x.length + countTrue(use) ];
+		String[] result = new String[x.length + countTrue( use )];
 		System.arraycopy( x, 0, result, 0, x.length );
 		int k = x.length;
-		for ( int i=0; i<y.length; i++ ) {
+		for ( int i = 0; i < y.length; i++ ) {
 			if ( use[i] ) {
 				result[k++] = y[i];
 			}
 		}
 		return result;
 	}
 
 	public static int[] join(int[] x, int[] y) {
-		int[] result = new int[ x.length + y.length ];
+		int[] result = new int[x.length + y.length];
 		System.arraycopy( x, 0, result, 0, x.length );
 		System.arraycopy( y, 0, result, x.length, y.length );
 		return result;
 	}
 
-	@SuppressWarnings( {"unchecked"})
+	@SuppressWarnings({"unchecked"})
 	public static <T> T[] join(T[] x, T... y) {
 		T[] result = (T[]) Array.newInstance( x.getClass().getComponentType(), x.length + y.length );
 		System.arraycopy( x, 0, result, 0, x.length );
 		System.arraycopy( y, 0, result, x.length, y.length );
 		return result;
 	}
 
-	public static final boolean[] TRUE = { true };
-	public static final boolean[] FALSE = { false };
+	public static final boolean[] TRUE = {true};
+	public static final boolean[] FALSE = {false};
 
-	private ArrayHelper() {}
+	private ArrayHelper() {
+	}
 
-	public static String toString( Object[] array ) {
+	public static String toString(Object[] array) {
 		StringBuilder sb = new StringBuilder();
-		sb.append("[");
-		for (int i = 0; i < array.length; i++) {
+		sb.append( "[" );
+		for ( int i = 0; i < array.length; i++ ) {
 			sb.append( array[i] );
-			if( i<array.length-1 ) {
-				sb.append(",");
+			if ( i < array.length - 1 ) {
+				sb.append( "," );
 			}
 		}
-		sb.append("]");
+		sb.append( "]" );
 		return sb.toString();
 	}
 
 	public static boolean isAllNegative(int[] array) {
 		for ( int anArray : array ) {
 			if ( anArray >= 0 ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public static boolean isAllTrue(boolean[] array) {
 		for ( boolean anArray : array ) {
 			if ( !anArray ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public static int countTrue(boolean[] array) {
-		int result=0;
+		int result = 0;
 		for ( boolean anArray : array ) {
 			if ( anArray ) {
 				result++;
 			}
 		}
 		return result;
 	}
 
 	/*public static int countFalse(boolean[] array) {
 		int result=0;
 		for ( int i=0; i<array.length; i++ ) {
 			if ( !array[i] ) result++;
 		}
 		return result;
 	}*/
 
 	public static boolean isAllFalse(boolean[] array) {
 		for ( boolean anArray : array ) {
 			if ( anArray ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public static <T> void addAll(Collection<T> collection, T[] array) {
 		collection.addAll( Arrays.asList( array ) );
 	}
 
 	public static final String[] EMPTY_STRING_ARRAY = {};
 	public static final int[] EMPTY_INT_ARRAY = {};
 	public static final boolean[] EMPTY_BOOLEAN_ARRAY = {};
 	public static final Class[] EMPTY_CLASS_ARRAY = {};
 	public static final Object[] EMPTY_OBJECT_ARRAY = {};
 	public static final Type[] EMPTY_TYPE_ARRAY = {};
 	public static final byte[] EMPTY_BYTE_ARRAY = {};
-	
+
 	public static int[] getBatchSizes(int maxBatchSize) {
 		int batchSize = maxBatchSize;
-		int n=1;
-		while ( batchSize>1 ) {
-			batchSize = getNextBatchSize(batchSize);
+		int n = 1;
+		while ( batchSize > 1 ) {
+			batchSize = getNextBatchSize( batchSize );
 			n++;
 		}
 		int[] result = new int[n];
 		batchSize = maxBatchSize;
-		for ( int i=0; i<n; i++ ) {
+		for ( int i = 0; i < n; i++ ) {
 			result[i] = batchSize;
-			batchSize = getNextBatchSize(batchSize);
+			batchSize = getNextBatchSize( batchSize );
 		}
 		return result;
 	}
-	
+
 	private static int getNextBatchSize(int batchSize) {
-		if (batchSize<=10) {
-			return batchSize-1; //allow 9,8,7,6,5,4,3,2,1
+		if ( batchSize <= 10 ) {
+			return batchSize - 1; //allow 9,8,7,6,5,4,3,2,1
 		}
-		else if (batchSize/2 < 10) {
+		else if ( batchSize / 2 < 10 ) {
 			return 10;
 		}
 		else {
 			return batchSize / 2;
 		}
 	}
 
 	private static int SEED = 23;
 	private static int PRIME_NUMER = 37;
 
 	/**
 	 * calculate the array hash (only the first level)
 	 */
 	public static int hash(Object[] array) {
 		int length = array.length;
 		int seed = SEED;
 		for ( Object anArray : array ) {
 			seed = hash( seed, anArray == null ? 0 : anArray.hashCode() );
 		}
 		return seed;
 	}
 
 	/**
 	 * calculate the array hash (only the first level)
 	 */
 	public static int hash(char[] array) {
 		int length = array.length;
 		int seed = SEED;
 		for ( char anArray : array ) {
 			seed = hash( seed, anArray );
 		}
 		return seed;
 	}
 
 	/**
 	 * calculate the array hash (only the first level)
 	 */
 	public static int hash(byte[] bytes) {
 		int length = bytes.length;
 		int seed = SEED;
 		for ( byte aByte : bytes ) {
 			seed = hash( seed, aByte );
 		}
 		return seed;
 	}
 
 	private static int hash(int seed, int i) {
 		return PRIME_NUMER * seed + i;
 	}
 
 	/**
 	 * Compare 2 arrays only at the first level
 	 */
 	public static boolean isEquals(Object[] o1, Object[] o2) {
-		if (o1 == o2) {
+		if ( o1 == o2 ) {
 			return true;
 		}
-		if (o1 == null || o2 == null) {
+		if ( o1 == null || o2 == null ) {
 			return false;
 		}
 		int length = o1.length;
-		if (length != o2.length) {
+		if ( length != o2.length ) {
 			return false;
 		}
-		for (int index = 0 ; index < length ; index++) {
-			if ( ! o1[index].equals( o2[index] ) ) {
+		for ( int index = 0; index < length; index++ ) {
+			if ( !o1[index].equals( o2[index] ) ) {
 				return false;
 			}
 		}
-        return true;
+		return true;
 	}
 
 	/**
 	 * Compare 2 arrays only at the first level
 	 */
 	public static boolean isEquals(char[] o1, char[] o2) {
-		if (o1 == o2) {
+		if ( o1 == o2 ) {
 			return true;
 		}
-		if (o1 == null || o2 == null) {
+		if ( o1 == null || o2 == null ) {
 			return false;
 		}
 		int length = o1.length;
-		if (length != o2.length) {
+		if ( length != o2.length ) {
 			return false;
 		}
-		for (int index = 0 ; index < length ; index++) {
-			if ( ! ( o1[index] == o2[index] ) ) {
+		for ( int index = 0; index < length; index++ ) {
+			if ( !( o1[index] == o2[index] ) ) {
 				return false;
 			}
 		}
-        return true;
+		return true;
 	}
 
 	/**
 	 * Compare 2 arrays only at the first level
 	 */
 	public static boolean isEquals(byte[] b1, byte[] b2) {
-		if (b1 == b2) {
+		if ( b1 == b2 ) {
 			return true;
 		}
-		if (b1 == null || b2 == null) {
+		if ( b1 == null || b2 == null ) {
 			return false;
 		}
 		int length = b1.length;
-		if (length != b2.length) {
+		if ( length != b2.length ) {
 			return false;
 		}
-		for (int index = 0 ; index < length ; index++) {
-			if ( ! ( b1[index] == b2[index] ) ) {
+		for ( int index = 0; index < length; index++ ) {
+			if ( !( b1[index] == b2[index] ) ) {
 				return false;
 			}
 		}
-        return true;
+		return true;
 	}
 
 	public static Serializable[] extractNonNull(Serializable[] array) {
 		final int nonNullCount = countNonNull( array );
 		final Serializable[] result = new Serializable[nonNullCount];
 		int i = 0;
 		for ( Serializable element : array ) {
 			if ( element != null ) {
 				result[i++] = element;
 			}
 		}
 		if ( i != nonNullCount ) {
 			throw new HibernateException( "Number of non-null elements varied between iterations" );
 		}
 		return result;
 	}
 
 	public static int countNonNull(Serializable[] array) {
 		int i = 0;
 		for ( Serializable element : array ) {
 			if ( element != null ) {
 				i++;
 			}
 		}
 		return i;
 	}
 
 	public static String[] reverse(String[] source) {
 		final int length = source.length;
 		final String[] destination = new String[length];
 		for ( int i = 0; i < length; i++ ) {
 			final int x = length - i - 1;
 			destination[x] = source[i];
 		}
 		return destination;
 	}
 
 	public static void main(String... args) {
 		int[] batchSizes = ArrayHelper.getBatchSizes( 32 );
 
 		System.out.println( "Forward ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~" );
 		for ( int i = 0; i < batchSizes.length; i++ ) {
 			System.out.println( "[" + i + "] -> " + batchSizes[i] );
 		}
 
 		System.out.println( "Backward ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~" );
-		for ( int i = batchSizes.length-1; i >= 0; i-- ) {
+		for ( int i = batchSizes.length - 1; i >= 0; i-- ) {
 			System.out.println( "[" + i + "] -> " + batchSizes[i] );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
index 5fdc3fc23a..ebadbb78bd 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
@@ -1,2464 +1,2492 @@
 /*
  * JBoss, Home of Professional Open Source
  * Copyright 2010 Red Hat Inc. and/or its affiliates and other
  * contributors as indicated by the @author tags. All rights reserved.
  * See the copyright.txt in the distribution for a full listing of
  * individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 /*
  * Written by Doug Lea with assistance from members of JCP JSR-166
  * Expert Group and released to the public domain, as explained at
  * http://creativecommons.org/licenses/publicdomain
  *
  * Modified for https://jira.jboss.org/jira/browse/ISPN-299
  * Includes ideas described in http://portal.acm.org/citation.cfm?id=1547428
  *
  */
 
 package org.hibernate.internal.util.collections;
 
 import java.io.IOException;
 import java.io.Serializable;
 import java.util.AbstractCollection;
 import java.util.AbstractMap;
 import java.util.AbstractSet;
 import java.util.Collection;
 import java.util.Collections;
-import java.util.ConcurrentModificationException;
 import java.util.Enumeration;
 import java.util.HashMap;
 import java.util.HashSet;
-import java.util.Hashtable;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.Map;
 import java.util.NoSuchElementException;
 import java.util.Set;
 import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.locks.ReentrantLock;
 
 import static java.util.Collections.singletonMap;
 import static java.util.Collections.unmodifiableMap;
 
 
 /**
  * A hash table supporting full concurrency of retrievals and
  * adjustable expected concurrency for updates. This class obeys the
- * same functional specification as {@link Hashtable}, and
+ * same functional specification as {@link java.util.Hashtable}, and
  * includes versions of methods corresponding to each method of
  * <tt>Hashtable</tt>. However, even though all operations are
  * thread-safe, retrieval operations do <em>not</em> entail locking,
  * and there is <em>not</em> any support for locking the entire table
  * in a way that prevents all access.  This class is fully
  * interoperable with <tt>Hashtable</tt> in programs that rely on its
  * thread safety but not on its synchronization details.
- *
+ * <p/>
  * <p> Retrieval operations (including <tt>get</tt>) generally do not
  * block, so may overlap with update operations (including
  * <tt>put</tt> and <tt>remove</tt>). Retrievals reflect the results
  * of the most recently <em>completed</em> update operations holding
  * upon their onset.  For aggregate operations such as <tt>putAll</tt>
  * and <tt>clear</tt>, concurrent retrievals may reflect insertion or
  * removal of only some entries.  Similarly, Iterators and
  * Enumerations return elements reflecting the state of the hash table
  * at some point at or since the creation of the iterator/enumeration.
- * They do <em>not</em> throw {@link ConcurrentModificationException}.
+ * They do <em>not</em> throw {@link java.util.ConcurrentModificationException}.
  * However, iterators are designed to be used by only one thread at a time.
- *
+ * <p/>
  * <p> The allowed concurrency among update operations is guided by
  * the optional <tt>concurrencyLevel</tt> constructor argument
  * (default <tt>16</tt>), which is used as a hint for internal sizing.  The
  * table is internally partitioned to try to permit the indicated
  * number of concurrent updates without contention. Because placement
  * in hash tables is essentially random, the actual concurrency will
  * vary.  Ideally, you should choose a value to accommodate as many
  * threads as will ever concurrently modify the table. Using a
  * significantly higher value than you need can waste space and time,
  * and a significantly lower value can lead to thread contention. But
  * overestimates and underestimates within an order of magnitude do
  * not usually have much noticeable impact. A value of one is
  * appropriate when it is known that only one thread will modify and
  * all others will only read. Also, resizing this or any other kind of
  * hash table is a relatively slow operation, so, when possible, it is
  * a good idea to provide estimates of expected table sizes in
  * constructors.
- *
+ * <p/>
  * <p>This class and its views and iterators implement all of the
  * <em>optional</em> methods of the {@link Map} and {@link Iterator}
  * interfaces.
- *
+ * <p/>
  * <p>This class is copied from Infinispan, and was originally written
  * by Doug Lea with assistance from members of JCP JSR-166 Expert Group and
  * released to the public domain, as explained at
  * http://creativecommons.org/licenses/publicdomain</p>
- *
- *
- * <p> Like {@link Hashtable} but unlike {@link HashMap}, this class
+ * <p/>
+ * <p/>
+ * <p> Like {@link java.util.Hashtable} but unlike {@link HashMap}, this class
  * does <em>not</em> allow <tt>null</tt> to be used as a key or value.
  *
- * @author Doug Lea
  * @param <K> the type of keys maintained by this map
  * @param <V> the type of mapped values
+ *
+ * @author Doug Lea
  */
 public class BoundedConcurrentHashMap<K, V> extends AbstractMap<K, V>
 		implements ConcurrentMap<K, V>, Serializable {
 	private static final long serialVersionUID = 7249069246763182397L;
 
 	/*
 		* The basic strategy is to subdivide the table among Segments,
 		* each of which itself is a concurrently readable hash table.
 		*/
 
 	/* ---------------- Constants -------------- */
 
 	/**
 	 * The default initial capacity for this table,
 	 * used when not otherwise specified in a constructor.
 	 */
 	static final int DEFAULT_MAXIMUM_CAPACITY = 512;
 
 	/**
 	 * The default load factor for this table, used when not
 	 * otherwise specified in a constructor.
 	 */
 	static final float DEFAULT_LOAD_FACTOR = 0.75f;
 
 	/**
 	 * The default concurrency level for this table, used when not
 	 * otherwise specified in a constructor.
 	 */
 	static final int DEFAULT_CONCURRENCY_LEVEL = 16;
 
 	/**
 	 * The maximum capacity, used if a higher value is implicitly
 	 * specified by either of the constructors with arguments.  MUST
 	 * be a power of two <= 1<<30 to ensure that entries are indexable
 	 * using ints.
 	 */
 	static final int MAXIMUM_CAPACITY = 1 << 30;
 
 	/**
 	 * The maximum number of segments to allow; used to bound
 	 * constructor arguments.
 	 */
 	static final int MAX_SEGMENTS = 1 << 16; // slightly conservative
 
 	/**
 	 * Number of unsynchronized retries in size and containsValue
 	 * methods before resorting to locking. This is used to avoid
 	 * unbounded retries if tables undergo continuous modification
 	 * which would make it impossible to obtain an accurate result.
 	 */
 	static final int RETRIES_BEFORE_LOCK = 2;
 
 	/* ---------------- Fields -------------- */
 
 	/**
 	 * Mask value for indexing into segments. The upper bits of a
 	 * key's hash code are used to choose the segment.
 	 */
 	final int segmentMask;
 
 	/**
 	 * Shift value for indexing within segments.
 	 */
 	final int segmentShift;
 
 	/**
 	 * The segments, each of which is a specialized hash table
 	 */
-	final Segment<K,V>[] segments;
+	final Segment<K, V>[] segments;
 
 	transient Set<K> keySet;
-	transient Set<Map.Entry<K,V>> entrySet;
+	transient Set<Map.Entry<K, V>> entrySet;
 	transient Collection<V> values;
 
 	/* ---------------- Small Utilities -------------- */
 
 	/**
 	 * Applies a supplemental hash function to a given hashCode, which
 	 * defends against poor quality hash functions.  This is critical
 	 * because ConcurrentHashMap uses power-of-two length hash tables,
 	 * that otherwise encounter collisions for hashCodes that do not
 	 * differ in lower or upper bits.
 	 */
 	private static int hash(int h) {
 		// Spread bits to regularize both segment and index locations,
 		// using variant of single-word Wang/Jenkins hash.
-		h += h <<  15 ^ 0xffffcd7d;
+		h += h << 15 ^ 0xffffcd7d;
 		h ^= h >>> 10;
-		h += h <<   3;
-		h ^= h >>>  6;
-		h += (h <<   2) + (h << 14);
+		h += h << 3;
+		h ^= h >>> 6;
+		h += ( h << 2 ) + ( h << 14 );
 		return h ^ h >>> 16;
 	}
 
 	/**
 	 * Returns the segment that should be used for key with given hash
+	 *
 	 * @param hash the hash code for the key
+	 *
 	 * @return the segment
 	 */
-	final Segment<K,V> segmentFor(int hash) {
+	final Segment<K, V> segmentFor(int hash) {
 		return segments[hash >>> segmentShift & segmentMask];
 	}
 
 	/* ---------------- Inner Classes -------------- */
 
 	/**
 	 * ConcurrentHashMap list entry. Note that this is never exported
 	 * out as a user-visible Map.Entry.
-	 *
+	 * <p/>
 	 * Because the value field is volatile, not final, it is legal wrt
 	 * the Java Memory Model for an unsynchronized reader to see null
 	 * instead of initial value when read via a data race.  Although a
 	 * reordering leading to this is not likely to ever actually
 	 * occur, the Segment.readValueUnderLock method is used as a
 	 * backup in case a null (pre-initialized) value is ever seen in
 	 * an unsynchronized access method.
 	 */
 	private static class HashEntry<K, V> {
 		final K key;
 		final int hash;
 		volatile V value;
 		final HashEntry<K, V> next;
 
 		HashEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			this.key = key;
 			this.hash = hash;
 			this.next = next;
 			this.value = value;
 		}
 
 		@Override
 		public int hashCode() {
 			int result = 17;
 			result = result * 31 + hash;
 			result = result * 31 + key.hashCode();
 			return result;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			// HashEntry is internal class, never leaks out of CHM, hence slight optimization
-			if (this == o) {
+			if ( this == o ) {
 				return true;
 			}
-			if (o == null) {
+			if ( o == null ) {
 				return false;
 			}
 			HashEntry<?, ?> other = (HashEntry<?, ?>) o;
-			return hash == other.hash && key.equals(other.key);
+			return hash == other.hash && key.equals( other.key );
 		}
 
 		@SuppressWarnings("unchecked")
 		static <K, V> HashEntry<K, V>[] newArray(int i) {
 			return new HashEntry[i];
 		}
 	}
 
 	private enum Recency {
 		HIR_RESIDENT, LIR_RESIDENT, HIR_NONRESIDENT
 	}
 
 	public enum Eviction {
 		NONE {
 			@Override
 			public <K, V> EvictionPolicy<K, V> make(Segment<K, V> s, int capacity, float lf) {
 				return new NullEvictionPolicy<K, V>();
 			}
 		},
 		LRU {
 			@Override
 			public <K, V> EvictionPolicy<K, V> make(Segment<K, V> s, int capacity, float lf) {
-				return new LRU<K, V>(s,capacity,lf,capacity*10,lf);
+				return new LRU<K, V>( s, capacity, lf, capacity * 10, lf );
 			}
 		},
 		LIRS {
 			@Override
 			public <K, V> EvictionPolicy<K, V> make(Segment<K, V> s, int capacity, float lf) {
-				return new LIRS<K,V>(s,capacity,capacity*10,lf);
+				return new LIRS<K, V>( s, capacity, capacity * 10, lf );
 			}
 		};
 
 		abstract <K, V> EvictionPolicy<K, V> make(Segment<K, V> s, int capacity, float lf);
 	}
 
 	public interface EvictionListener<K, V> {
 		void onEntryEviction(Map<K, V> evicted);
+
 		void onEntryChosenForEviction(V internalCacheEntry);
 	}
 
 	static final class NullEvictionListener<K, V> implements EvictionListener<K, V> {
 		@Override
 		public void onEntryEviction(Map<K, V> evicted) {
 			// Do nothing.
 		}
+
 		@Override
 		public void onEntryChosenForEviction(V internalCacheEntry) {
 			// Do nothing.
 		}
 	}
 
 	public interface EvictionPolicy<K, V> {
 
 		public final static int MAX_BATCH_SIZE = 64;
 
 		HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value);
 
 		/**
 		 * Invokes eviction policy algorithm and returns set of evicted entries.
-		 *
-		 * <p>
+		 * <p/>
+		 * <p/>
 		 * Set cannot be null but could possibly be an empty set.
 		 *
 		 * @return set of evicted entries.
 		 */
 		Set<HashEntry<K, V>> execute();
 
 		/**
 		 * Invoked to notify EvictionPolicy implementation that there has been an attempt to access
 		 * an entry in Segment, however that entry was not present in Segment.
 		 *
-		 * @param e
-		 *            accessed entry in Segment
+		 * @param e accessed entry in Segment
 		 *
 		 * @return non null set of evicted entries.
 		 */
 		Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> e);
 
 		/**
 		 * Invoked to notify EvictionPolicy implementation that an entry in Segment has been
 		 * accessed. Returns true if batching threshold has been reached, false otherwise.
-		 * <p>
+		 * <p/>
 		 * Note that this method is potentially invoked without holding a lock on Segment.
 		 *
-		 * @return true if batching threshold has been reached, false otherwise.
+		 * @param e accessed entry in Segment
 		 *
-		 * @param e
-		 *            accessed entry in Segment
+		 * @return true if batching threshold has been reached, false otherwise.
 		 */
 		boolean onEntryHit(HashEntry<K, V> e);
 
 		/**
 		 * Invoked to notify EvictionPolicy implementation that an entry e has been removed from
 		 * Segment.
 		 *
-		 * @param e
-		 *            removed entry in Segment
+		 * @param e removed entry in Segment
 		 */
 		void onEntryRemove(HashEntry<K, V> e);
 
 		/**
 		 * Invoked to notify EvictionPolicy implementation that all Segment entries have been
 		 * cleared.
-		 *
 		 */
 		void clear();
 
 		/**
 		 * Returns type of eviction algorithm (strategy).
 		 *
 		 * @return type of eviction algorithm
 		 */
 		Eviction strategy();
 
 		/**
 		 * Returns true if batching threshold has expired, false otherwise.
-		 * <p>
+		 * <p/>
 		 * Note that this method is potentially invoked without holding a lock on Segment.
 		 *
 		 * @return true if batching threshold has expired, false otherwise.
 		 */
 		boolean thresholdExpired();
 	}
 
 	static class NullEvictionPolicy<K, V> implements EvictionPolicy<K, V> {
 
 		@Override
 		public void clear() {
 			// Do nothing.
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> execute() {
 			return Collections.emptySet();
 		}
 
 		@Override
 		public boolean onEntryHit(HashEntry<K, V> e) {
 			return false;
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> e) {
 			return Collections.emptySet();
 		}
 
 		@Override
 		public void onEntryRemove(HashEntry<K, V> e) {
 			// Do nothing.
 		}
 
 		@Override
 		public boolean thresholdExpired() {
 			return false;
 		}
 
 		@Override
 		public Eviction strategy() {
 			return Eviction.NONE;
 		}
 
 		@Override
 		public HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value) {
-			return new HashEntry<K, V>(key, hash, next, value);
+			return new HashEntry<K, V>( key, hash, next, value );
 		}
 	}
 
-	static final class LRU<K, V> extends LinkedHashMap<HashEntry<K,V>, V> implements EvictionPolicy<K, V> {
+	static final class LRU<K, V> extends LinkedHashMap<HashEntry<K, V>, V> implements EvictionPolicy<K, V> {
 
-		/** The serialVersionUID */
+		/**
+		 * The serialVersionUID
+		 */
 		private static final long serialVersionUID = -7645068174197717838L;
 
 		private final ConcurrentLinkedQueue<HashEntry<K, V>> accessQueue;
-		private final Segment<K,V> segment;
+		private final Segment<K, V> segment;
 		private final int maxBatchQueueSize;
 		private final int trimDownSize;
 		private final float batchThresholdFactor;
 		private final Set<HashEntry<K, V>> evicted;
 
-		public LRU(Segment<K,V> s, int capacity, float lf, int maxBatchSize, float batchThresholdFactor) {
-			super(capacity, lf, true);
+		public LRU(Segment<K, V> s, int capacity, float lf, int maxBatchSize, float batchThresholdFactor) {
+			super( capacity, lf, true );
 			this.segment = s;
 			this.trimDownSize = capacity;
 			this.maxBatchQueueSize = maxBatchSize > MAX_BATCH_SIZE ? MAX_BATCH_SIZE : maxBatchSize;
 			this.batchThresholdFactor = batchThresholdFactor;
 			this.accessQueue = new ConcurrentLinkedQueue<HashEntry<K, V>>();
 			this.evicted = new HashSet<HashEntry<K, V>>();
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> execute() {
 			Set<HashEntry<K, V>> evictedCopy = new HashSet<HashEntry<K, V>>();
-			for (HashEntry<K, V> e : accessQueue) {
-				put(e, e.value);
+			for ( HashEntry<K, V> e : accessQueue ) {
+				put( e, e.value );
 			}
-			evictedCopy.addAll(evicted);
+			evictedCopy.addAll( evicted );
 			accessQueue.clear();
 			evicted.clear();
 			return evictedCopy;
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> e) {
-			put(e, e.value);
-			if (!evicted.isEmpty()) {
+			put( e, e.value );
+			if ( !evicted.isEmpty() ) {
 				Set<HashEntry<K, V>> evictedCopy = new HashSet<HashEntry<K, V>>();
-				evictedCopy.addAll(evicted);
+				evictedCopy.addAll( evicted );
 				evicted.clear();
 				return evictedCopy;
-			} else {
+			}
+			else {
 				return Collections.emptySet();
 			}
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean onEntryHit(HashEntry<K, V> e) {
-			accessQueue.add(e);
+			accessQueue.add( e );
 			return accessQueue.size() >= maxBatchQueueSize * batchThresholdFactor;
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean thresholdExpired() {
 			return accessQueue.size() >= maxBatchQueueSize;
 		}
 
 		@Override
 		public void onEntryRemove(HashEntry<K, V> e) {
-			remove(e);
+			remove( e );
 			// we could have multiple instances of e in accessQueue; remove them all
-			while (accessQueue.remove(e)) {
+			while ( accessQueue.remove( e ) ) {
 				continue;
 			}
 		}
 
 		@Override
 		public void clear() {
 			super.clear();
 			accessQueue.clear();
 		}
 
 		@Override
 		public Eviction strategy() {
 			return Eviction.LRU;
 		}
 
-		protected boolean isAboveThreshold(){
+		protected boolean isAboveThreshold() {
 			return size() > trimDownSize;
 		}
 
-		protected boolean removeEldestEntry(Map.Entry<HashEntry<K,V>,V> eldest){
+		protected boolean removeEldestEntry(Map.Entry<HashEntry<K, V>, V> eldest) {
 			boolean aboveThreshold = isAboveThreshold();
-			if(aboveThreshold){
+			if ( aboveThreshold ) {
 				HashEntry<K, V> evictedEntry = eldest.getKey();
-				segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
-				segment.remove(evictedEntry.key, evictedEntry.hash, null);
-				evicted.add(evictedEntry);
+				segment.evictionListener.onEntryChosenForEviction( evictedEntry.value );
+				segment.remove( evictedEntry.key, evictedEntry.hash, null );
+				evicted.add( evictedEntry );
 			}
 			return aboveThreshold;
 		}
 
 		@Override
 		public HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value) {
-			return new HashEntry<K, V>(key, hash, next, value);
+			return new HashEntry<K, V>( key, hash, next, value );
 		}
 	}
 
 	/**
 	 * Adapted to Infinispan BoundedConcurrentHashMap using LIRS implementation ideas from Charles Fry (fry@google.com)
 	 * See http://code.google.com/p/concurrentlinkedhashmap/source/browse/trunk/src/test/java/com/googlecode/concurrentlinkedhashmap/caches/LirsMap.java
 	 * for original sources
-	 *
 	 */
-	private static final class LIRSHashEntry<K,V> extends HashEntry<K,V> {
+	private static final class LIRSHashEntry<K, V> extends HashEntry<K, V> {
 
 		// LIRS stack S
 		private LIRSHashEntry<K, V> previousInStack;
 		private LIRSHashEntry<K, V> nextInStack;
 
 		// LIRS queue Q
 		private LIRSHashEntry<K, V> previousInQueue;
 		private LIRSHashEntry<K, V> nextInQueue;
 		volatile Recency state;
 
 		LIRS<K, V> owner;
 
 
 		LIRSHashEntry(LIRS<K, V> owner, K key, int hash, HashEntry<K, V> next, V value) {
-			super(key,hash,next,value);
+			super( key, hash, next, value );
 			this.owner = owner;
 			this.state = Recency.HIR_RESIDENT;
 
 			// initially point everything back to self
 			this.previousInStack = this;
 			this.nextInStack = this;
 			this.previousInQueue = this;
 			this.nextInQueue = this;
 		}
 
 		@Override
 		public int hashCode() {
 			int result = 17;
 			result = result * 31 + hash;
 			result = result * 31 + key.hashCode();
 			return result;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			// HashEntry is internal class, never leaks out of CHM, hence slight optimization
-			if (this == o) {
+			if ( this == o ) {
 				return true;
 			}
-			if (o == null) {
+			if ( o == null ) {
 				return false;
 			}
 			HashEntry<?, ?> other = (HashEntry<?, ?>) o;
-			return hash == other.hash && key.equals(other.key);
+			return hash == other.hash && key.equals( other.key );
 		}
 
 		/**
 		 * Returns true if this entry is in the stack, false otherwise.
 		 */
 		public boolean inStack() {
-			return (nextInStack != null);
+			return ( nextInStack != null );
 		}
 
 		/**
 		 * Returns true if this entry is in the queue, false otherwise.
 		 */
 		public boolean inQueue() {
-			return (nextInQueue != null);
+			return ( nextInQueue != null );
 		}
 
 		/**
 		 * Records a cache hit.
 		 */
 		public void hit(Set<HashEntry<K, V>> evicted) {
-			switch (state) {
+			switch ( state ) {
 				case LIR_RESIDENT:
-					hotHit(evicted);
+					hotHit( evicted );
 					break;
 				case HIR_RESIDENT:
-					coldHit(evicted);
+					coldHit( evicted );
 					break;
 				case HIR_NONRESIDENT:
-					throw new IllegalStateException("Can't hit a non-resident entry!");
+					throw new IllegalStateException( "Can't hit a non-resident entry!" );
 				default:
-					throw new AssertionError("Hit with unknown status: " + state);
+					throw new AssertionError( "Hit with unknown status: " + state );
 			}
 		}
 
 		/**
 		 * Records a cache hit on a hot block.
 		 */
 		private void hotHit(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 1:
 			// "Upon accessing an LIR block X:
 			// This access is guaranteed to be a hit in the cache."
 
 			// "We move it to the top of stack S."
-			boolean onBottom = (owner.stackBottom() == this);
+			boolean onBottom = ( owner.stackBottom() == this );
 			moveToStackTop();
 
 			// "If the LIR block is originally located in the bottom of the stack,
 			// we conduct a stack pruning."
-			if (onBottom) {
-				owner.pruneStack(evicted);
+			if ( onBottom ) {
+				owner.pruneStack( evicted );
 			}
 		}
 
 		/**
 		 * Records a cache hit on a cold block.
 		 */
 		private void coldHit(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 2:
 			// "Upon accessing an HIR resident block X:
 			// This is a hit in the cache."
 
 			// "We move it to the top of stack S."
 			boolean inStack = inStack();
 			moveToStackTop();
 
 			// "There are two cases for block X:"
-			if (inStack) {
+			if ( inStack ) {
 				// "(1) If X is in the stack S, we change its status to LIR."
 				hot();
 
 				// "This block is also removed from list Q."
 				removeFromQueue();
 
 				// "The LIR block in the bottom of S is moved to the end of list Q
 				// with its status changed to HIR."
 				owner.stackBottom().migrateToQueue();
 
 				// "A stack pruning is then conducted."
-				owner.pruneStack(evicted);
-			} else {
+				owner.pruneStack( evicted );
+			}
+			else {
 				// "(2) If X is not in stack S, we leave its status in HIR and move
 				// it to the end of list Q."
 				moveToQueueEnd();
 			}
 		}
 
 		/**
 		 * Records a cache miss. This is how new entries join the LIRS stack and
 		 * queue. This is called both when a new entry is first created, and when a
 		 * non-resident entry is re-computed.
 		 */
 		private Set<HashEntry<K, V>> miss() {
 			Set<HashEntry<K, V>> evicted = Collections.emptySet();
-			if (owner.hotSize < owner.maximumHotSize) {
+			if ( owner.hotSize < owner.maximumHotSize ) {
 				warmupMiss();
-			} else {
-				evicted = new HashSet<HashEntry<K,V>>();
-				fullMiss(evicted);
+			}
+			else {
+				evicted = new HashSet<HashEntry<K, V>>();
+				fullMiss( evicted );
 			}
 
 			// now the missed item is in the cache
 			owner.size++;
 			return evicted;
 		}
 
 		/**
 		 * Records a miss when the hot entry set is not full.
 		 */
 		private void warmupMiss() {
 			// See section 3.3:
 			// "When LIR block set is not full, all the referenced blocks are
 			// given an LIR status until its size reaches L_lirs."
 			hot();
 			moveToStackTop();
 		}
 
 		/**
 		 * Records a miss when the hot entry set is full.
 		 */
 		private void fullMiss(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 3:
 			// "Upon accessing an HIR non-resident block X:
 			// This is a miss."
 
 			// This condition is unspecified in the paper, but appears to be
 			// necessary.
-			if (owner.size >= owner.maximumSize) {
+			if ( owner.size >= owner.maximumSize ) {
 				// "We remove the HIR resident block at the front of list Q (it then
 				// becomes a non-resident block), and replace it out of the cache."
 				LIRSHashEntry<K, V> evictedNode = owner.queueFront();
-				evicted.add(evictedNode);
+				evicted.add( evictedNode );
 			}
 
 			// "Then we load the requested block X into the freed buffer and place
 			// it on the top of stack S."
 			boolean inStack = inStack();
 			moveToStackTop();
 
 			// "There are two cases for block X:"
-			if (inStack) {
+			if ( inStack ) {
 				// "(1) If X is in stack S, we change its status to LIR and move the
 				// LIR block in the bottom of stack S to the end of list Q with its
 				// status changed to HIR. A stack pruning is then conducted.
 				hot();
 				owner.stackBottom().migrateToQueue();
-				owner.pruneStack(evicted);
-			} else {
+				owner.pruneStack( evicted );
+			}
+			else {
 				// "(2) If X is not in stack S, we leave its status in HIR and place
 				// it in the end of list Q."
 				cold();
 			}
 		}
 
 		/**
 		 * Marks this entry as hot.
 		 */
 		private void hot() {
-			if (state != Recency.LIR_RESIDENT) {
+			if ( state != Recency.LIR_RESIDENT ) {
 				owner.hotSize++;
 			}
 			state = Recency.LIR_RESIDENT;
 		}
 
 		/**
 		 * Marks this entry as cold.
 		 */
 		private void cold() {
-			if (state == Recency.LIR_RESIDENT) {
+			if ( state == Recency.LIR_RESIDENT ) {
 				owner.hotSize--;
 			}
 			state = Recency.HIR_RESIDENT;
 			moveToQueueEnd();
 		}
 
 		/**
 		 * Marks this entry as non-resident.
 		 */
 		@SuppressWarnings("fallthrough")
 		private void nonResident() {
-			switch (state) {
+			switch ( state ) {
 				case LIR_RESIDENT:
 					owner.hotSize--;
 					// fallthrough
 				case HIR_RESIDENT:
 					owner.size--;
 					break;
 			}
 			state = Recency.HIR_NONRESIDENT;
 		}
 
 		/**
 		 * Returns true if this entry is resident in the cache, false otherwise.
 		 */
 		public boolean isResident() {
-			return (state != Recency.HIR_NONRESIDENT);
+			return ( state != Recency.HIR_NONRESIDENT );
 		}
 
 
 		/**
 		 * Temporarily removes this entry from the stack, fixing up neighbor links.
 		 * This entry's links remain unchanged, meaning that {@link #inStack()} will
 		 * continue to return true. This should only be called if this node's links
 		 * will be subsequently changed.
 		 */
 		private void tempRemoveFromStack() {
-			if (inStack()) {
+			if ( inStack() ) {
 				previousInStack.nextInStack = nextInStack;
 				nextInStack.previousInStack = previousInStack;
 			}
 		}
 
 		/**
 		 * Removes this entry from the stack.
 		 */
 		private void removeFromStack() {
 			tempRemoveFromStack();
 			previousInStack = null;
 			nextInStack = null;
 		}
 
 		/**
 		 * Inserts this entry before the specified existing entry in the stack.
 		 */
-		private void addToStackBefore(LIRSHashEntry<K,V> existingEntry) {
+		private void addToStackBefore(LIRSHashEntry<K, V> existingEntry) {
 			previousInStack = existingEntry.previousInStack;
 			nextInStack = existingEntry;
 			previousInStack.nextInStack = this;
 			nextInStack.previousInStack = this;
 		}
 
 		/**
 		 * Moves this entry to the top of the stack.
 		 */
 		private void moveToStackTop() {
 			tempRemoveFromStack();
-			addToStackBefore(owner.header.nextInStack);
+			addToStackBefore( owner.header.nextInStack );
 		}
 
 		/**
 		 * Moves this entry to the bottom of the stack.
 		 */
 		private void moveToStackBottom() {
 			tempRemoveFromStack();
-			addToStackBefore(owner.header);
+			addToStackBefore( owner.header );
 		}
 
 		/**
 		 * Temporarily removes this entry from the queue, fixing up neighbor links.
 		 * This entry's links remain unchanged. This should only be called if this
 		 * node's links will be subsequently changed.
 		 */
 		private void tempRemoveFromQueue() {
-			if (inQueue()) {
+			if ( inQueue() ) {
 				previousInQueue.nextInQueue = nextInQueue;
 				nextInQueue.previousInQueue = previousInQueue;
 			}
 		}
 
 		/**
 		 * Removes this entry from the queue.
 		 */
 		private void removeFromQueue() {
 			tempRemoveFromQueue();
 			previousInQueue = null;
 			nextInQueue = null;
 		}
 
 		/**
 		 * Inserts this entry before the specified existing entry in the queue.
 		 */
-		private void addToQueueBefore(LIRSHashEntry<K,V> existingEntry) {
+		private void addToQueueBefore(LIRSHashEntry<K, V> existingEntry) {
 			previousInQueue = existingEntry.previousInQueue;
 			nextInQueue = existingEntry;
 			previousInQueue.nextInQueue = this;
 			nextInQueue.previousInQueue = this;
 		}
 
 		/**
 		 * Moves this entry to the end of the queue.
 		 */
 		private void moveToQueueEnd() {
 			tempRemoveFromQueue();
-			addToQueueBefore(owner.header);
+			addToQueueBefore( owner.header );
 		}
 
 
 		/**
 		 * Moves this entry from the stack to the queue, marking it cold
 		 * (as hot entries must remain in the stack). This should only be called
 		 * on resident entries, as non-resident entries should not be made resident.
 		 * The bottom entry on the queue is always hot due to stack pruning.
 		 */
 		private void migrateToQueue() {
 			removeFromStack();
 			cold();
 		}
 
 		/**
 		 * Moves this entry from the queue to the stack, marking it hot (as cold
 		 * resident entries must remain in the queue).
 		 */
 		private void migrateToStack() {
 			removeFromQueue();
-			if (!inStack()) {
+			if ( !inStack() ) {
 				moveToStackBottom();
 			}
 			hot();
 		}
 
 		/**
 		 * Evicts this entry, removing it from the queue and setting its status to
 		 * cold non-resident. If the entry is already absent from the stack, it is
 		 * removed from the backing map; otherwise it remains in order for its
 		 * recency to be maintained.
 		 */
 		private void evict() {
 			removeFromQueue();
 			removeFromStack();
 			nonResident();
 			owner = null;
 		}
 
 		/**
 		 * Removes this entry from the cache. This operation is not specified in
 		 * the paper, which does not account for forced eviction.
 		 */
 		private V remove() {
-			boolean wasHot = (state == Recency.LIR_RESIDENT);
+			boolean wasHot = ( state == Recency.LIR_RESIDENT );
 			V result = value;
-			LIRSHashEntry<K,V> end = owner != null? owner.queueEnd():null;
+			LIRSHashEntry<K, V> end = owner != null ? owner.queueEnd() : null;
 			evict();
 
 			// attempt to maintain a constant number of hot entries
-			if (wasHot) {
-				if (end != null) {
+			if ( wasHot ) {
+				if ( end != null ) {
 					end.migrateToStack();
 				}
 			}
 
 			return result;
 		}
 	}
 
 
 	static final class LIRS<K, V> implements EvictionPolicy<K, V> {
 
 		/**
 		 * The percentage of the cache which is dedicated to hot blocks.
 		 * See section 5.1
 		 */
 		private static final float L_LIRS = 0.95f;
 
-		/** The owning segment */
-		private final Segment<K,V> segment;
+		/**
+		 * The owning segment
+		 */
+		private final Segment<K, V> segment;
 
 		/**
 		 * The accessQueue for reducing lock contention
 		 * See "BP-Wrapper: a system framework making any replacement algorithms
 		 * (almost) lock contention free"
-		 *
+		 * <p/>
 		 * http://www.cse.ohio-state.edu/hpcs/WWW/HTML/publications/abs09-1.html
-		 *
-		 * */
+		 */
 		private final ConcurrentLinkedQueue<LIRSHashEntry<K, V>> accessQueue;
 
 		/**
 		 * The maxBatchQueueSize
-		 *
+		 * <p/>
 		 * See "BP-Wrapper: a system framework making any replacement algorithms (almost) lock
 		 * contention free"
-		 * */
+		 */
 		private final int maxBatchQueueSize;
 
-		/** The number of LIRS entries in a segment */
+		/**
+		 * The number of LIRS entries in a segment
+		 */
 		private int size;
 
 		private final float batchThresholdFactor;
 
 
 		/**
 		 * This header encompasses two data structures:
-		 *
+		 * <p/>
 		 * <ul>
 		 * <li>The LIRS stack, S, which is maintains recency information. All hot
 		 * entries are on the stack. All cold and non-resident entries which are more
 		 * recent than the least recent hot entry are also stored in the stack (the
 		 * stack is always pruned such that the last entry is hot, and all entries
 		 * accessed more recently than the last hot entry are present in the stack).
 		 * The stack is ordered by recency, with its most recently accessed entry
 		 * at the top, and its least recently accessed entry at the bottom.</li>
-		 *
+		 * <p/>
 		 * <li>The LIRS queue, Q, which enqueues all cold entries for eviction. Cold
 		 * entries (by definition in the queue) may be absent from the stack (due to
 		 * pruning of the stack). Cold entries are added to the end of the queue
 		 * and entries are evicted from the front of the queue.</li>
 		 * </ul>
 		 */
-		private final LIRSHashEntry<K,V> header = new LIRSHashEntry<K,V>(null, null,0,null,null);
+		private final LIRSHashEntry<K, V> header = new LIRSHashEntry<K, V>( null, null, 0, null, null );
 
-		/** The maximum number of hot entries (L_lirs in the paper). */
+		/**
+		 * The maximum number of hot entries (L_lirs in the paper).
+		 */
 		private final int maximumHotSize;
 
-		/** The maximum number of resident entries (L in the paper). */
-		private final int maximumSize ;
+		/**
+		 * The maximum number of resident entries (L in the paper).
+		 */
+		private final int maximumSize;
 
-		/** The actual number of hot entries. */
+		/**
+		 * The actual number of hot entries.
+		 */
 		private int hotSize;
 
 
-
-		public LIRS(Segment<K,V> s, int capacity, int maxBatchSize, float batchThresholdFactor) {
+		public LIRS(Segment<K, V> s, int capacity, int maxBatchSize, float batchThresholdFactor) {
 			this.segment = s;
 			this.maximumSize = capacity;
-			this.maximumHotSize = calculateLIRSize(capacity);
+			this.maximumHotSize = calculateLIRSize( capacity );
 			this.maxBatchQueueSize = maxBatchSize > MAX_BATCH_SIZE ? MAX_BATCH_SIZE : maxBatchSize;
 			this.batchThresholdFactor = batchThresholdFactor;
 			this.accessQueue = new ConcurrentLinkedQueue<LIRSHashEntry<K, V>>();
 		}
 
 		private static int calculateLIRSize(int maximumSize) {
-			int result = (int) (L_LIRS * maximumSize);
-			return (result == maximumSize) ? maximumSize - 1 : result;
+			int result = (int) ( L_LIRS * maximumSize );
+			return ( result == maximumSize ) ? maximumSize - 1 : result;
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> execute() {
 			Set<HashEntry<K, V>> evicted = new HashSet<HashEntry<K, V>>();
 			try {
-				for (LIRSHashEntry<K, V> e : accessQueue) {
-					if(e.isResident()){
-						e.hit(evicted);
+				for ( LIRSHashEntry<K, V> e : accessQueue ) {
+					if ( e.isResident() ) {
+						e.hit( evicted );
 					}
 				}
-				removeFromSegment(evicted);
-			} finally {
+				removeFromSegment( evicted );
+			}
+			finally {
 				accessQueue.clear();
 			}
 			return evicted;
 		}
 
 		/**
 		 * Prunes HIR blocks in the bottom of the stack until an HOT block sits in
 		 * the stack bottom. If pruned blocks were resident, then they
 		 * remain in the queue; otherwise they are no longer referenced, and are thus
 		 * removed from the backing map.
 		 */
-		private void pruneStack(Set<HashEntry<K,V>> evicted) {
+		private void pruneStack(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3:
 			// "We define an operation called "stack pruning" on the LIRS
 			// stack S, which removes the HIR blocks in the bottom of
 			// the stack until an LIR block sits in the stack bottom. This
 			// operation serves for two purposes: (1) We ensure the block in
 			// the bottom of the stack always belongs to the LIR block set.
 			// (2) After the LIR block in the bottom is removed, those HIR
 			// blocks contiguously located above it will not have chances to
 			// change their status from HIR to LIR, because their recencies
 			// are larger than the new maximum recency of LIR blocks."
 			LIRSHashEntry<K, V> bottom = stackBottom();
-			while (bottom != null && bottom.state != Recency.LIR_RESIDENT) {
+			while ( bottom != null && bottom.state != Recency.LIR_RESIDENT ) {
 				bottom.removeFromStack();
-				if (bottom.state == Recency.HIR_NONRESIDENT) {
-					evicted.add(bottom);
+				if ( bottom.state == Recency.HIR_NONRESIDENT ) {
+					evicted.add( bottom );
 				}
 				bottom = stackBottom();
 			}
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> en) {
 			LIRSHashEntry<K, V> e = (LIRSHashEntry<K, V>) en;
 			Set<HashEntry<K, V>> evicted = e.miss();
-			removeFromSegment(evicted);
+			removeFromSegment( evicted );
 			return evicted;
 		}
 
 		private void removeFromSegment(Set<HashEntry<K, V>> evicted) {
-			for (HashEntry<K, V> e : evicted) {
-				((LIRSHashEntry<K, V>)e).evict();
-				segment.evictionListener.onEntryChosenForEviction(e.value);
-				segment.remove(e.key, e.hash, null);
+			for ( HashEntry<K, V> e : evicted ) {
+				( (LIRSHashEntry<K, V>) e ).evict();
+				segment.evictionListener.onEntryChosenForEviction( e.value );
+				segment.remove( e.key, e.hash, null );
 			}
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean onEntryHit(HashEntry<K, V> e) {
-			accessQueue.add((LIRSHashEntry<K, V>) e);
+			accessQueue.add( (LIRSHashEntry<K, V>) e );
 			return accessQueue.size() >= maxBatchQueueSize * batchThresholdFactor;
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean thresholdExpired() {
 			return accessQueue.size() >= maxBatchQueueSize;
 		}
 
 		@Override
 		public void onEntryRemove(HashEntry<K, V> e) {
 
-			((LIRSHashEntry<K,V>)e).remove();
+			( (LIRSHashEntry<K, V>) e ).remove();
 			// we could have multiple instances of e in accessQueue; remove them all
-			while (accessQueue.remove(e)) {
+			while ( accessQueue.remove( e ) ) {
 			}
 		}
 
 		@Override
 		public void clear() {
 			accessQueue.clear();
 		}
 
 		@Override
 		public Eviction strategy() {
 			return Eviction.LIRS;
 		}
 
 		/**
 		 * Returns the entry at the bottom of the stack.
 		 */
 		private LIRSHashEntry<K, V> stackBottom() {
 			LIRSHashEntry<K, V> bottom = header.previousInStack;
-			return (bottom == header) ? null : bottom;
+			return ( bottom == header ) ? null : bottom;
 		}
 
 		/**
 		 * Returns the entry at the front of the queue.
 		 */
 		private LIRSHashEntry<K, V> queueFront() {
 			LIRSHashEntry<K, V> front = header.nextInQueue;
-			return (front == header) ? null : front;
+			return ( front == header ) ? null : front;
 		}
 
 		/**
 		 * Returns the entry at the end of the queue.
 		 */
 		private LIRSHashEntry<K, V> queueEnd() {
 			LIRSHashEntry<K, V> end = header.previousInQueue;
-			return (end == header) ? null : end;
+			return ( end == header ) ? null : end;
 		}
 
 
 		@Override
 		public HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value) {
-			return new LIRSHashEntry<K, V>(this,key, hash, next, value);
+			return new LIRSHashEntry<K, V>( this, key, hash, next, value );
 		}
 	}
 
 	/**
 	 * Segments are specialized versions of hash tables.  This
 	 * subclasses from ReentrantLock opportunistically, just to
 	 * simplify some locking and avoid separate construction.
 	 */
-	static final class Segment<K,V> extends ReentrantLock {
+	static final class Segment<K, V> extends ReentrantLock {
 		/*
 			   * Segments maintain a table of entry lists that are ALWAYS
 			   * kept in a consistent state, so can be read without locking.
 			   * Next fields of nodes are immutable (final).  All list
 			   * additions are performed at the front of each bin. This
 			   * makes it easy to check changes, and also fast to traverse.
 			   * When nodes would otherwise be changed, new nodes are
 			   * created to replace them. This works well for hash tables
 			   * since the bin lists tend to be short. (The average length
 			   * is less than two for the default load factor threshold.)
 			   *
 			   * Read operations can thus proceed without locking, but rely
 			   * on selected uses of volatiles to ensure that completed
 			   * write operations performed by other threads are
 			   * noticed. For most purposes, the "count" field, tracking the
 			   * number of elements, serves as that volatile variable
 			   * ensuring visibility.  This is convenient because this field
 			   * needs to be read in many read operations anyway:
 			   *
 			   *   - All (unsynchronized) read operations must first read the
 			   *     "count" field, and should not look at table entries if
 			   *     it is 0.
 			   *
 			   *   - All (synchronized) write operations should write to
 			   *     the "count" field after structurally changing any bin.
 			   *     The operations must not take any action that could even
 			   *     momentarily cause a concurrent read operation to see
 			   *     inconsistent data. This is made easier by the nature of
 			   *     the read operations in Map. For example, no operation
 			   *     can reveal that the table has grown but the threshold
 			   *     has not yet been updated, so there are no atomicity
 			   *     requirements for this with respect to reads.
 			   *
 			   * As a guide, all critical volatile reads and writes to the
 			   * count field are marked in code comments.
 			   */
 
 		private static final long serialVersionUID = 2249069246763182397L;
 
 		/**
 		 * The number of elements in this segment's region.
 		 */
 		transient volatile int count;
 
 		/**
 		 * Number of updates that alter the size of the table. This is
 		 * used during bulk-read methods to make sure they see a
 		 * consistent snapshot: If modCounts change during a traversal
 		 * of segments computing size or checking containsValue, then
 		 * we might have an inconsistent view of state so (usually)
 		 * must retry.
 		 */
 		transient int modCount;
 
 		/**
 		 * The table is rehashed when its size exceeds this threshold.
 		 * (The value of this field is always <tt>(int)(capacity *
 		 * loadFactor)</tt>.)
 		 */
 		transient int threshold;
 
 		/**
 		 * The per-segment table.
 		 */
-		transient volatile HashEntry<K,V>[] table;
+		transient volatile HashEntry<K, V>[] table;
 
 		/**
 		 * The load factor for the hash table.  Even though this value
 		 * is same for all segments, it is replicated to avoid needing
 		 * links to outer object.
+		 *
 		 * @serial
 		 */
 		final float loadFactor;
 
 		final int evictCap;
 
 		transient final EvictionPolicy<K, V> eviction;
 
 		transient final EvictionListener<K, V> evictionListener;
 
 		Segment(int cap, int evictCap, float lf, Eviction es, EvictionListener<K, V> listener) {
 			loadFactor = lf;
 			this.evictCap = evictCap;
-			eviction = es.make(this, evictCap, lf);
+			eviction = es.make( this, evictCap, lf );
 			evictionListener = listener;
-			setTable(HashEntry.<K, V> newArray(cap));
+			setTable( HashEntry.<K, V>newArray( cap ) );
 		}
 
 		@SuppressWarnings("unchecked")
-		static <K,V> Segment<K,V>[] newArray(int i) {
+		static <K, V> Segment<K, V>[] newArray(int i) {
 			return new Segment[i];
 		}
 
 		EvictionListener<K, V> getEvictionListener() {
 			return evictionListener;
 		}
 
 		/**
 		 * Sets table to new HashEntry array.
 		 * Call only while holding lock or in constructor.
 		 */
-		void setTable(HashEntry<K,V>[] newTable) {
-			threshold = (int)(newTable.length * loadFactor);
+		void setTable(HashEntry<K, V>[] newTable) {
+			threshold = (int) ( newTable.length * loadFactor );
 			table = newTable;
 		}
 
 		/**
 		 * Returns properly casted first entry of bin for given hash.
 		 */
-		HashEntry<K,V> getFirst(int hash) {
-			HashEntry<K,V>[] tab = table;
+		HashEntry<K, V> getFirst(int hash) {
+			HashEntry<K, V>[] tab = table;
 			return tab[hash & tab.length - 1];
 		}
 
 		/**
 		 * Reads value field of an entry under lock. Called if value
 		 * field ever appears to be null. This is possible only if a
 		 * compiler happens to reorder a HashEntry initialization with
 		 * its table assignment, which is legal under memory model
 		 * but is not known to ever occur.
 		 */
-		V readValueUnderLock(HashEntry<K,V> e) {
+		V readValueUnderLock(HashEntry<K, V> e) {
 			lock();
 			try {
 				return e.value;
-			} finally {
+			}
+			finally {
 				unlock();
 			}
 		}
 
 		/* Specialized implementations of map methods */
 
 		V get(Object key, int hash) {
 			int c = count;
-			if (c != 0) { // read-volatile
+			if ( c != 0 ) { // read-volatile
 				V result = null;
-				HashEntry<K, V> e = getFirst(hash);
-				while (e != null) {
-					if (e.hash == hash && key.equals(e.key)) {
+				HashEntry<K, V> e = getFirst( hash );
+				while ( e != null ) {
+					if ( e.hash == hash && key.equals( e.key ) ) {
 						V v = e.value;
-						if (v != null) {
+						if ( v != null ) {
 							result = v;
 							break;
-						} else {
-							result = readValueUnderLock(e); // recheck
+						}
+						else {
+							result = readValueUnderLock( e ); // recheck
 							break;
 						}
 					}
 					e = e.next;
 				}
 				// a hit
-				if (result != null) {
-					if (eviction.onEntryHit(e)) {
-						Set<HashEntry<K, V>> evicted = attemptEviction(false);
-						notifyEvictionListener(evicted);
+				if ( result != null ) {
+					if ( eviction.onEntryHit( e ) ) {
+						Set<HashEntry<K, V>> evicted = attemptEviction( false );
+						notifyEvictionListener( evicted );
 					}
 				}
 				return result;
 			}
 			return null;
 		}
 
 		boolean containsKey(Object key, int hash) {
-			if (count != 0) { // read-volatile
-				HashEntry<K,V> e = getFirst(hash);
-				while (e != null) {
-					if (e.hash == hash && key.equals(e.key)) {
+			if ( count != 0 ) { // read-volatile
+				HashEntry<K, V> e = getFirst( hash );
+				while ( e != null ) {
+					if ( e.hash == hash && key.equals( e.key ) ) {
 						return true;
 					}
 					e = e.next;
 				}
 			}
 			return false;
 		}
 
 		boolean containsValue(Object value) {
-			if (count != 0) { // read-volatile
-				HashEntry<K,V>[] tab = table;
+			if ( count != 0 ) { // read-volatile
+				HashEntry<K, V>[] tab = table;
 				int len = tab.length;
-				for (int i = 0 ; i < len; i++) {
-					for (HashEntry<K,V> e = tab[i]; e != null; e = e.next) {
+				for ( int i = 0; i < len; i++ ) {
+					for ( HashEntry<K, V> e = tab[i]; e != null; e = e.next ) {
 						V v = e.value;
-						if (v == null) {
-							v = readValueUnderLock(e);
+						if ( v == null ) {
+							v = readValueUnderLock( e );
 						}
-						if (value.equals(v)) {
+						if ( value.equals( v ) ) {
 							return true;
 						}
 					}
 				}
 			}
 			return false;
 		}
 
 		boolean replace(K key, int hash, V oldValue, V newValue) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
-				HashEntry<K, V> e = getFirst(hash);
-				while (e != null && (e.hash != hash || !key.equals(e.key))) {
+				HashEntry<K, V> e = getFirst( hash );
+				while ( e != null && ( e.hash != hash || !key.equals( e.key ) ) ) {
 					e = e.next;
 				}
 
 				boolean replaced = false;
-				if (e != null && oldValue.equals(e.value)) {
+				if ( e != null && oldValue.equals( e.value ) ) {
 					replaced = true;
 					e.value = newValue;
-					if (eviction.onEntryHit(e)) {
-						evicted = attemptEviction(true);
+					if ( eviction.onEntryHit( e ) ) {
+						evicted = attemptEviction( true );
 					}
 				}
 				return replaced;
-			} finally {
+			}
+			finally {
 				unlock();
-				notifyEvictionListener(evicted);
+				notifyEvictionListener( evicted );
 			}
 		}
 
 		V replace(K key, int hash, V newValue) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
-				HashEntry<K, V> e = getFirst(hash);
-				while (e != null && (e.hash != hash || !key.equals(e.key))) {
+				HashEntry<K, V> e = getFirst( hash );
+				while ( e != null && ( e.hash != hash || !key.equals( e.key ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue = null;
-				if (e != null) {
+				if ( e != null ) {
 					oldValue = e.value;
 					e.value = newValue;
-					if (eviction.onEntryHit(e)) {
-						evicted = attemptEviction(true);
+					if ( eviction.onEntryHit( e ) ) {
+						evicted = attemptEviction( true );
 					}
 				}
 				return oldValue;
-			} finally {
+			}
+			finally {
 				unlock();
-				notifyEvictionListener(evicted);
+				notifyEvictionListener( evicted );
 			}
 		}
 
 		V put(K key, int hash, V value, boolean onlyIfAbsent) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
 				int c = count;
-				if (c++ > threshold && eviction.strategy() == Eviction.NONE) {
+				if ( c++ > threshold && eviction.strategy() == Eviction.NONE ) {
 					rehash();
 				}
 				HashEntry<K, V>[] tab = table;
 				int index = hash & tab.length - 1;
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
-				while (e != null && (e.hash != hash || !key.equals(e.key))) {
+				while ( e != null && ( e.hash != hash || !key.equals( e.key ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue;
-				if (e != null) {
+				if ( e != null ) {
 					oldValue = e.value;
-					if (!onlyIfAbsent) {
+					if ( !onlyIfAbsent ) {
 						e.value = value;
-						eviction.onEntryHit(e);
+						eviction.onEntryHit( e );
 					}
-				} else {
+				}
+				else {
 					oldValue = null;
 					++modCount;
 					count = c; // write-volatile
-					if (eviction.strategy() != Eviction.NONE) {
-						if (c > evictCap) {
+					if ( eviction.strategy() != Eviction.NONE ) {
+						if ( c > evictCap ) {
 							// remove entries;lower count
 							evicted = eviction.execute();
 							// re-read first
 							first = tab[index];
 						}
 						// add a new entry
-						tab[index] = eviction.createNewEntry(key, hash, first, value);
+						tab[index] = eviction.createNewEntry( key, hash, first, value );
 						// notify a miss
-						Set<HashEntry<K, V>> newlyEvicted = eviction.onEntryMiss(tab[index]);
-						if (!newlyEvicted.isEmpty()) {
-							if (evicted != null) {
-								evicted.addAll(newlyEvicted);
-							} else {
+						Set<HashEntry<K, V>> newlyEvicted = eviction.onEntryMiss( tab[index] );
+						if ( !newlyEvicted.isEmpty() ) {
+							if ( evicted != null ) {
+								evicted.addAll( newlyEvicted );
+							}
+							else {
 								evicted = newlyEvicted;
 							}
 						}
-					} else {
-						tab[index] = eviction.createNewEntry(key, hash, first, value);
+					}
+					else {
+						tab[index] = eviction.createNewEntry( key, hash, first, value );
 					}
 				}
 				return oldValue;
-			} finally {
+			}
+			finally {
 				unlock();
-				notifyEvictionListener(evicted);
+				notifyEvictionListener( evicted );
 			}
 		}
 
 		void rehash() {
-			HashEntry<K,V>[] oldTable = table;
+			HashEntry<K, V>[] oldTable = table;
 			int oldCapacity = oldTable.length;
-			if (oldCapacity >= MAXIMUM_CAPACITY) {
+			if ( oldCapacity >= MAXIMUM_CAPACITY ) {
 				return;
 			}
 
 			/*
 					  * Reclassify nodes in each list to new Map.  Because we are
 					  * using power-of-two expansion, the elements from each bin
 					  * must either stay at same index, or move with a power of two
 					  * offset. We eliminate unnecessary node creation by catching
 					  * cases where old nodes can be reused because their next
 					  * fields won't change. Statistically, at the default
 					  * threshold, only about one-sixth of them need cloning when
 					  * a table doubles. The nodes they replace will be garbage
 					  * collectable as soon as they are no longer referenced by any
 					  * reader thread that may be in the midst of traversing table
 					  * right now.
 					  */
 
-			HashEntry<K,V>[] newTable = HashEntry.newArray(oldCapacity<<1);
-			threshold = (int)(newTable.length * loadFactor);
+			HashEntry<K, V>[] newTable = HashEntry.newArray( oldCapacity << 1 );
+			threshold = (int) ( newTable.length * loadFactor );
 			int sizeMask = newTable.length - 1;
-			for (int i = 0; i < oldCapacity ; i++) {
+			for ( int i = 0; i < oldCapacity; i++ ) {
 				// We need to guarantee that any existing reads of old Map can
 				//  proceed. So we cannot yet null out each bin.
-				HashEntry<K,V> e = oldTable[i];
+				HashEntry<K, V> e = oldTable[i];
 
-				if (e != null) {
-					HashEntry<K,V> next = e.next;
+				if ( e != null ) {
+					HashEntry<K, V> next = e.next;
 					int idx = e.hash & sizeMask;
 
 					//  Single node on list
-					if (next == null) {
+					if ( next == null ) {
 						newTable[idx] = e;
-					} else {
+					}
+					else {
 						// Reuse trailing consecutive sequence at same slot
-						HashEntry<K,V> lastRun = e;
+						HashEntry<K, V> lastRun = e;
 						int lastIdx = idx;
-						for (HashEntry<K,V> last = next;
-							 last != null;
-							 last = last.next) {
+						for ( HashEntry<K, V> last = next;
+							  last != null;
+							  last = last.next ) {
 							int k = last.hash & sizeMask;
-							if (k != lastIdx) {
+							if ( k != lastIdx ) {
 								lastIdx = k;
 								lastRun = last;
 							}
 						}
 						newTable[lastIdx] = lastRun;
 
 						// Clone all remaining nodes
-						for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {
+						for ( HashEntry<K, V> p = e; p != lastRun; p = p.next ) {
 							int k = p.hash & sizeMask;
-							HashEntry<K,V> n = newTable[k];
-							newTable[k] = eviction.createNewEntry(p.key, p.hash, n, p.value);
+							HashEntry<K, V> n = newTable[k];
+							newTable[k] = eviction.createNewEntry( p.key, p.hash, n, p.value );
 						}
 					}
 				}
 			}
 			table = newTable;
 		}
 
 		/**
 		 * Remove; match on key only if value null, else match both.
 		 */
 		V remove(Object key, int hash, Object value) {
 			lock();
 			try {
 				int c = count - 1;
 				HashEntry<K, V>[] tab = table;
 				int index = hash & tab.length - 1;
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
-				while (e != null && (e.hash != hash || !key.equals(e.key))) {
+				while ( e != null && ( e.hash != hash || !key.equals( e.key ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue = null;
-				if (e != null) {
+				if ( e != null ) {
 					V v = e.value;
-					if (value == null || value.equals(v)) {
+					if ( value == null || value.equals( v ) ) {
 						oldValue = v;
 						// All entries following removed node can stay
 						// in list, but all preceding ones need to be
 						// cloned.
 						++modCount;
 
 						// e was removed
-						eviction.onEntryRemove(e);
+						eviction.onEntryRemove( e );
 
 						HashEntry<K, V> newFirst = e.next;
-						for (HashEntry<K, V> p = first; p != e; p = p.next) {
+						for ( HashEntry<K, V> p = first; p != e; p = p.next ) {
 							// TODO A remove operation makes the map behave like all the other keys in the bucket were just added???
 							// allow p to be GC-ed
-							eviction.onEntryRemove(p);
-							newFirst = eviction.createNewEntry(p.key, p.hash, newFirst, p.value);
+							eviction.onEntryRemove( p );
+							newFirst = eviction.createNewEntry( p.key, p.hash, newFirst, p.value );
 							// and notify eviction algorithm about new hash entries
-							eviction.onEntryMiss(newFirst);
+							eviction.onEntryMiss( newFirst );
 						}
 
 						tab[index] = newFirst;
 						count = c; // write-volatile
 					}
 				}
 				return oldValue;
-			} finally {
+			}
+			finally {
 				unlock();
 			}
 		}
 
 		void clear() {
-			if (count != 0) {
+			if ( count != 0 ) {
 				lock();
 				try {
 					HashEntry<K, V>[] tab = table;
-					for (int i = 0; i < tab.length; i++) {
+					for ( int i = 0; i < tab.length; i++ ) {
 						tab[i] = null;
 					}
 					++modCount;
 					eviction.clear();
 					count = 0; // write-volatile
-				} finally {
+				}
+				finally {
 					unlock();
 				}
 			}
 		}
 
 		private Set<HashEntry<K, V>> attemptEviction(boolean lockedAlready) {
 			Set<HashEntry<K, V>> evicted = null;
 			boolean obtainedLock = lockedAlready || tryLock();
-			if (!obtainedLock && eviction.thresholdExpired()) {
+			if ( !obtainedLock && eviction.thresholdExpired() ) {
 				lock();
 				obtainedLock = true;
 			}
-			if (obtainedLock) {
+			if ( obtainedLock ) {
 				try {
-					if (eviction.thresholdExpired()) {
+					if ( eviction.thresholdExpired() ) {
 						evicted = eviction.execute();
 					}
-				} finally {
-					if (!lockedAlready) {
+				}
+				finally {
+					if ( !lockedAlready ) {
 						unlock();
 					}
 				}
 			}
 			return evicted;
 		}
 
 		private void notifyEvictionListener(Set<HashEntry<K, V>> evicted) {
 			// piggyback listener invocation on callers thread outside lock
-			if (evicted != null) {
+			if ( evicted != null ) {
 				Map<K, V> evictedCopy;
-				if (evicted.size() == 1) {
+				if ( evicted.size() == 1 ) {
 					HashEntry<K, V> evictedEntry = evicted.iterator().next();
-					evictedCopy = singletonMap(evictedEntry.key, evictedEntry.value);
-				} else {
-					evictedCopy = new HashMap<K, V>(evicted.size());
-					for (HashEntry<K, V> he : evicted) {
-						evictedCopy.put(he.key, he.value);
+					evictedCopy = singletonMap( evictedEntry.key, evictedEntry.value );
+				}
+				else {
+					evictedCopy = new HashMap<K, V>( evicted.size() );
+					for ( HashEntry<K, V> he : evicted ) {
+						evictedCopy.put( he.key, he.value );
 					}
-					evictedCopy = unmodifiableMap(evictedCopy);
+					evictedCopy = unmodifiableMap( evictedCopy );
 				}
-				evictionListener.onEntryEviction(evictedCopy);
+				evictionListener.onEntryEviction( evictedCopy );
 			}
 		}
 	}
 
 
 	/* ---------------- Public operations -------------- */
 
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor and concurrency
 	 * level.
 	 *
-	 * @param capacity
-	 *            is the upper bound capacity for the number of elements in this map
-	 *
-	 * @param concurrencyLevel
-	 *            the estimated number of concurrently updating threads. The implementation performs
-	 *            internal sizing to try to accommodate this many threads.
-	 *
-	 * @param evictionStrategy
-	 *            the algorithm used to evict elements from this map
-	 *
-	 * @param evictionListener
-	 *            the evicton listener callback to be notified about evicted elements
+	 * @param capacity is the upper bound capacity for the number of elements in this map
+	 * @param concurrencyLevel the estimated number of concurrently updating threads. The implementation performs
+	 * internal sizing to try to accommodate this many threads.
+	 * @param evictionStrategy the algorithm used to evict elements from this map
+	 * @param evictionListener the evicton listener callback to be notified about evicted elements
 	 *
-	 * @throws IllegalArgumentException
-	 *             if the initial capacity is negative or the load factor or concurrencyLevel are
-	 *             nonpositive.
+	 * @throws IllegalArgumentException if the initial capacity is negative or the load factor or concurrencyLevel are
+	 * nonpositive.
 	 */
-	public BoundedConcurrentHashMap(int capacity, int concurrencyLevel,
-									Eviction evictionStrategy, EvictionListener<K, V> evictionListener) {
-		if (capacity < 0 || concurrencyLevel <= 0) {
+	public BoundedConcurrentHashMap(
+			int capacity, int concurrencyLevel,
+			Eviction evictionStrategy, EvictionListener<K, V> evictionListener) {
+		if ( capacity < 0 || concurrencyLevel <= 0 ) {
 			throw new IllegalArgumentException();
 		}
 
-		concurrencyLevel = Math.min(capacity / 2, concurrencyLevel); // concurrencyLevel cannot be > capacity/2
-		concurrencyLevel = Math.max(concurrencyLevel, 1); // concurrencyLevel cannot be less than 1
+		concurrencyLevel = Math.min( capacity / 2, concurrencyLevel ); // concurrencyLevel cannot be > capacity/2
+		concurrencyLevel = Math.max( concurrencyLevel, 1 ); // concurrencyLevel cannot be less than 1
 
 		// minimum two elements per segment
-		if (capacity < concurrencyLevel * 2 && capacity != 1) {
-			throw new IllegalArgumentException("Maximum capacity has to be at least twice the concurrencyLevel");
+		if ( capacity < concurrencyLevel * 2 && capacity != 1 ) {
+			throw new IllegalArgumentException( "Maximum capacity has to be at least twice the concurrencyLevel" );
 		}
 
-		if (evictionStrategy == null || evictionListener == null) {
+		if ( evictionStrategy == null || evictionListener == null ) {
 			throw new IllegalArgumentException();
 		}
 
-		if (concurrencyLevel > MAX_SEGMENTS) {
+		if ( concurrencyLevel > MAX_SEGMENTS ) {
 			concurrencyLevel = MAX_SEGMENTS;
 		}
 
 		// Find power-of-two sizes best matching arguments
 		int sshift = 0;
 		int ssize = 1;
-		while (ssize < concurrencyLevel) {
+		while ( ssize < concurrencyLevel ) {
 			++sshift;
 			ssize <<= 1;
 		}
 		segmentShift = 32 - sshift;
 		segmentMask = ssize - 1;
-		this.segments = Segment.newArray(ssize);
+		this.segments = Segment.newArray( ssize );
 
-		if (capacity > MAXIMUM_CAPACITY) {
+		if ( capacity > MAXIMUM_CAPACITY ) {
 			capacity = MAXIMUM_CAPACITY;
 		}
 		int c = capacity / ssize;
 		int cap = 1;
-		while (cap < c) {
+		while ( cap < c ) {
 			cap <<= 1;
 		}
 
-		for (int i = 0; i < this.segments.length; ++i) {
-			this.segments[i] = new Segment<K, V>(cap, c, DEFAULT_LOAD_FACTOR, evictionStrategy, evictionListener);
+		for ( int i = 0; i < this.segments.length; ++i ) {
+			this.segments[i] = new Segment<K, V>( cap, c, DEFAULT_LOAD_FACTOR, evictionStrategy, evictionListener );
 		}
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor, concurrency
 	 * level and LRU eviction policy.
 	 *
-	 * @param capacity
-	 *            is the upper bound capacity for the number of elements in this map
+	 * @param capacity is the upper bound capacity for the number of elements in this map
+	 * @param concurrencyLevel the estimated number of concurrently updating threads. The implementation performs
+	 * internal sizing to try to accommodate this many threads.
 	 *
-	 * @param concurrencyLevel
-	 *            the estimated number of concurrently updating threads. The implementation performs
-	 *            internal sizing to try to accommodate this many threads.
-	 *
-	 * @throws IllegalArgumentException
-	 *             if the initial capacity is negative or the load factor or concurrencyLevel are
-	 *             nonpositive.
+	 * @throws IllegalArgumentException if the initial capacity is negative or the load factor or concurrencyLevel are
+	 * nonpositive.
 	 */
 	public BoundedConcurrentHashMap(int capacity, int concurrencyLevel) {
-		this(capacity, concurrencyLevel, Eviction.LRU);
+		this( capacity, concurrencyLevel, Eviction.LRU );
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor, concurrency
 	 * level and eviction strategy.
 	 *
-	 * @param capacity
-	 *            is the upper bound capacity for the number of elements in this map
-	 *
-	 * @param concurrencyLevel
-	 *            the estimated number of concurrently updating threads. The implementation performs
-	 *            internal sizing to try to accommodate this many threads.
-	 *
-	 * @param evictionStrategy
-	 *            the algorithm used to evict elements from this map
+	 * @param capacity is the upper bound capacity for the number of elements in this map
+	 * @param concurrencyLevel the estimated number of concurrently updating threads. The implementation performs
+	 * internal sizing to try to accommodate this many threads.
+	 * @param evictionStrategy the algorithm used to evict elements from this map
 	 *
-	 * @throws IllegalArgumentException
-	 *             if the initial capacity is negative or the load factor or concurrencyLevel are
-	 *             nonpositive.
+	 * @throws IllegalArgumentException if the initial capacity is negative or the load factor or concurrencyLevel are
+	 * nonpositive.
 	 */
 	public BoundedConcurrentHashMap(int capacity, int concurrencyLevel, Eviction evictionStrategy) {
-		this(capacity, concurrencyLevel, evictionStrategy, new NullEvictionListener<K, V>());
+		this( capacity, concurrencyLevel, evictionStrategy, new NullEvictionListener<K, V>() );
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, default concurrency
 	 * level and LRU eviction policy.
 	 *
-	 *  @param capacity
-	 *            is the upper bound capacity for the number of elements in this map
-	 *
+	 * @param capacity is the upper bound capacity for the number of elements in this map
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative or the load factor is nonpositive
-	 *
 	 * @since 1.6
 	 */
 	public BoundedConcurrentHashMap(int capacity) {
-		this(capacity, DEFAULT_CONCURRENCY_LEVEL);
+		this( capacity, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 	/**
 	 * Creates a new, empty map with the default maximum capacity
 	 */
 	public BoundedConcurrentHashMap() {
-		this(DEFAULT_MAXIMUM_CAPACITY, DEFAULT_CONCURRENCY_LEVEL);
+		this( DEFAULT_MAXIMUM_CAPACITY, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map contains no key-value mappings.
 	 *
 	 * @return <tt>true</tt> if this map contains no key-value mappings
 	 */
 	@Override
 	public boolean isEmpty() {
-		final Segment<K,V>[] segments = this.segments;
+		final Segment<K, V>[] segments = this.segments;
 		/*
 			   * We keep track of per-segment modCounts to avoid ABA
 			   * problems in which an element in one segment was added and
 			   * in another removed during traversal, in which case the
 			   * table was never actually empty at any point. Note the
 			   * similar use of modCounts in the size() and containsValue()
 			   * methods, which are the only other methods also susceptible
 			   * to ABA problems.
 			   */
 		int[] mc = new int[segments.length];
 		int mcsum = 0;
-		for (int i = 0; i < segments.length; ++i) {
-			if (segments[i].count != 0) {
+		for ( int i = 0; i < segments.length; ++i ) {
+			if ( segments[i].count != 0 ) {
 				return false;
-			} else {
+			}
+			else {
 				mcsum += mc[i] = segments[i].modCount;
 			}
 		}
 		// If mcsum happens to be zero, then we know we got a snapshot
 		// before any modifications at all were made.  This is
 		// probably common enough to bother tracking.
-		if (mcsum != 0) {
-			for (int i = 0; i < segments.length; ++i) {
-				if (segments[i].count != 0 || mc[i] != segments[i].modCount) {
+		if ( mcsum != 0 ) {
+			for ( int i = 0; i < segments.length; ++i ) {
+				if ( segments[i].count != 0 || mc[i] != segments[i].modCount ) {
 					return false;
 				}
 			}
 		}
 		return true;
 	}
 
 	/**
 	 * Returns the number of key-value mappings in this map.  If the
 	 * map contains more than <tt>Integer.MAX_VALUE</tt> elements, returns
 	 * <tt>Integer.MAX_VALUE</tt>.
 	 *
 	 * @return the number of key-value mappings in this map
 	 */
 	@Override
 	public int size() {
-		final Segment<K,V>[] segments = this.segments;
+		final Segment<K, V>[] segments = this.segments;
 		long sum = 0;
 		long check = 0;
 		int[] mc = new int[segments.length];
 		// Try a few times to get accurate count. On failure due to
 		// continuous async changes in table, resort to locking.
-		for (int k = 0; k < RETRIES_BEFORE_LOCK; ++ k) {
+		for ( int k = 0; k < RETRIES_BEFORE_LOCK; ++k ) {
 			check = 0;
 			sum = 0;
 			int mcsum = 0;
-			for (int i = 0; i < segments.length; ++ i) {
+			for ( int i = 0; i < segments.length; ++i ) {
 				sum += segments[i].count;
 				mcsum += mc[i] = segments[i].modCount;
 			}
-			if (mcsum != 0) {
-				for (int i = 0; i < segments.length; ++ i) {
+			if ( mcsum != 0 ) {
+				for ( int i = 0; i < segments.length; ++i ) {
 					check += segments[i].count;
-					if (mc[i] != segments[i].modCount) {
+					if ( mc[i] != segments[i].modCount ) {
 						check = -1; // force retry
 						break;
 					}
 				}
 			}
-			if (check == sum) {
+			if ( check == sum ) {
 				break;
 			}
 		}
-		if (check != sum) { // Resort to locking all segments
+		if ( check != sum ) { // Resort to locking all segments
 			sum = 0;
-			for (int i = 0; i < segments.length; ++ i) {
+			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].lock();
 			}
 			try {
-				for (int i = 0; i < segments.length; ++ i) {
+				for ( int i = 0; i < segments.length; ++i ) {
 					sum += segments[i].count;
 				}
-			} finally {
-				for (int i = 0; i < segments.length; ++ i) {
+			}
+			finally {
+				for ( int i = 0; i < segments.length; ++i ) {
 					segments[i].unlock();
 				}
 			}
 		}
-		if (sum > Integer.MAX_VALUE) {
+		if ( sum > Integer.MAX_VALUE ) {
 			return Integer.MAX_VALUE;
-		} else {
+		}
+		else {
 			return (int) sum;
 		}
 	}
 
 	/**
 	 * Returns the value to which the specified key is mapped,
 	 * or {@code null} if this map contains no mapping for the key.
-	 *
+	 * <p/>
 	 * <p>More formally, if this map contains a mapping from a key
 	 * {@code k} to a value {@code v} such that {@code key.equals(k)},
 	 * then this method returns {@code v}; otherwise it returns
 	 * {@code null}.  (There can be at most one such mapping.)
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V get(Object key) {
-		int hash = hash(key.hashCode());
-		return segmentFor(hash).get(key, hash);
+		int hash = hash( key.hashCode() );
+		return segmentFor( hash ).get( key, hash );
 	}
 
 	/**
 	 * Tests if the specified object is a key in this table.
 	 *
-	 * @param  key   possible key
+	 * @param key possible key
+	 *
 	 * @return <tt>true</tt> if and only if the specified object
-	 *         is a key in this table, as determined by the
-	 *         <tt>equals</tt> method; <tt>false</tt> otherwise.
+	 * is a key in this table, as determined by the
+	 * <tt>equals</tt> method; <tt>false</tt> otherwise.
+	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean containsKey(Object key) {
-		int hash = hash(key.hashCode());
-		return segmentFor(hash).containsKey(key, hash);
+		int hash = hash( key.hashCode() );
+		return segmentFor( hash ).containsKey( key, hash );
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map maps one or more keys to the
 	 * specified value. Note: This method requires a full internal
 	 * traversal of the hash table, and so is much slower than
 	 * method <tt>containsKey</tt>.
 	 *
 	 * @param value value whose presence in this map is to be tested
+	 *
 	 * @return <tt>true</tt> if this map maps one or more keys to the
-	 *         specified value
+	 * specified value
+	 *
 	 * @throws NullPointerException if the specified value is null
 	 */
 	@Override
 	public boolean containsValue(Object value) {
-		if (value == null) {
+		if ( value == null ) {
 			throw new NullPointerException();
 		}
 
 		// See explanation of modCount use above
 
 		final Segment<K, V>[] segments = this.segments;
 		int[] mc = new int[segments.length];
 
 		// Try a few times without locking
-		for (int k = 0; k < RETRIES_BEFORE_LOCK; ++ k) {
+		for ( int k = 0; k < RETRIES_BEFORE_LOCK; ++k ) {
 			int mcsum = 0;
-			for (int i = 0; i < segments.length; ++ i) {
+			for ( int i = 0; i < segments.length; ++i ) {
 				@SuppressWarnings("unused")
 				int c = segments[i].count; // read-volatile
 				mcsum += mc[i] = segments[i].modCount;
-				if (segments[i].containsValue(value)) {
+				if ( segments[i].containsValue( value ) ) {
 					return true;
 				}
 			}
 			boolean cleanSweep = true;
-			if (mcsum != 0) {
-				for (int i = 0; i < segments.length; ++ i) {
+			if ( mcsum != 0 ) {
+				for ( int i = 0; i < segments.length; ++i ) {
 					@SuppressWarnings("unused")
 					int c = segments[i].count; // read-volatile
-					if (mc[i] != segments[i].modCount) {
+					if ( mc[i] != segments[i].modCount ) {
 						cleanSweep = false;
 						break;
 					}
 				}
 			}
-			if (cleanSweep) {
+			if ( cleanSweep ) {
 				return false;
 			}
 		}
 		// Resort to locking all segments
-		for (int i = 0; i < segments.length; ++ i) {
+		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].lock();
 		}
 		boolean found = false;
 		try {
-			for (int i = 0; i < segments.length; ++ i) {
-				if (segments[i].containsValue(value)) {
+			for ( int i = 0; i < segments.length; ++i ) {
+				if ( segments[i].containsValue( value ) ) {
 					found = true;
 					break;
 				}
 			}
-		} finally {
-			for (int i = 0; i < segments.length; ++ i) {
+		}
+		finally {
+			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].unlock();
 			}
 		}
 		return found;
 	}
 
 	/**
 	 * Legacy method testing if some key maps into the specified value
 	 * in this table.  This method is identical in functionality to
 	 * {@link #containsValue}, and exists solely to ensure
-	 * full compatibility with class {@link Hashtable},
+	 * full compatibility with class {@link java.util.Hashtable},
 	 * which supported this method prior to introduction of the
 	 * Java Collections framework.
-
-	 * @param  value a value to search for
+	 *
+	 * @param value a value to search for
+	 *
 	 * @return <tt>true</tt> if and only if some key maps to the
-	 *         <tt>value</tt> argument in this table as
-	 *         determined by the <tt>equals</tt> method;
-	 *         <tt>false</tt> otherwise
+	 * <tt>value</tt> argument in this table as
+	 * determined by the <tt>equals</tt> method;
+	 * <tt>false</tt> otherwise
+	 *
 	 * @throws NullPointerException if the specified value is null
 	 */
 	public boolean contains(Object value) {
-		return containsValue(value);
+		return containsValue( value );
 	}
 
 	/**
 	 * Maps the specified key to the specified value in this table.
 	 * Neither the key nor the value can be null.
-	 *
+	 * <p/>
 	 * <p> The value can be retrieved by calling the <tt>get</tt> method
 	 * with a key that is equal to the original key.
 	 *
 	 * @param key key with which the specified value is to be associated
 	 * @param value value to be associated with the specified key
+	 *
 	 * @return the previous value associated with <tt>key</tt>, or
-	 *         <tt>null</tt> if there was no mapping for <tt>key</tt>
+	 * <tt>null</tt> if there was no mapping for <tt>key</tt>
+	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V put(K key, V value) {
-		if (value == null) {
+		if ( value == null ) {
 			throw new NullPointerException();
 		}
-		int hash = hash(key.hashCode());
-		return segmentFor(hash).put(key, hash, value, false);
+		int hash = hash( key.hashCode() );
+		return segmentFor( hash ).put( key, hash, value, false );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
-	 *         or <tt>null</tt> if there was no mapping for the key
+	 * or <tt>null</tt> if there was no mapping for the key
+	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V putIfAbsent(K key, V value) {
-		if (value == null) {
+		if ( value == null ) {
 			throw new NullPointerException();
 		}
-		int hash = hash(key.hashCode());
-		return segmentFor(hash).put(key, hash, value, true);
+		int hash = hash( key.hashCode() );
+		return segmentFor( hash ).put( key, hash, value, true );
 	}
 
 	/**
 	 * Copies all of the mappings from the specified map to this one.
 	 * These mappings replace any mappings that this map had for any of the
 	 * keys currently in the specified map.
 	 *
 	 * @param m mappings to be stored in this map
 	 */
 	@Override
 	public void putAll(Map<? extends K, ? extends V> m) {
-		for (Map.Entry<? extends K, ? extends V> e: m.entrySet()) {
-			put(e.getKey(), e.getValue());
+		for ( Map.Entry<? extends K, ? extends V> e : m.entrySet() ) {
+			put( e.getKey(), e.getValue() );
 		}
 	}
 
 	/**
 	 * Removes the key (and its corresponding value) from this map.
 	 * This method does nothing if the key is not in the map.
 	 *
-	 * @param  key the key that needs to be removed
+	 * @param key the key that needs to be removed
+	 *
 	 * @return the previous value associated with <tt>key</tt>, or
-	 *         <tt>null</tt> if there was no mapping for <tt>key</tt>
+	 * <tt>null</tt> if there was no mapping for <tt>key</tt>
+	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V remove(Object key) {
-		int hash = hash(key.hashCode());
-		return segmentFor(hash).remove(key, hash, null);
+		int hash = hash( key.hashCode() );
+		return segmentFor( hash ).remove( key, hash, null );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean remove(Object key, Object value) {
-		int hash = hash(key.hashCode());
-		if (value == null) {
+		int hash = hash( key.hashCode() );
+		if ( value == null ) {
 			return false;
 		}
-		return segmentFor(hash).remove(key, hash, value) != null;
+		return segmentFor( hash ).remove( key, hash, value ) != null;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @throws NullPointerException if any of the arguments are null
 	 */
 	@Override
 	public boolean replace(K key, V oldValue, V newValue) {
-		if (oldValue == null || newValue == null) {
+		if ( oldValue == null || newValue == null ) {
 			throw new NullPointerException();
 		}
-		int hash = hash(key.hashCode());
-		return segmentFor(hash).replace(key, hash, oldValue, newValue);
+		int hash = hash( key.hashCode() );
+		return segmentFor( hash ).replace( key, hash, oldValue, newValue );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
-	 *         or <tt>null</tt> if there was no mapping for the key
+	 * or <tt>null</tt> if there was no mapping for the key
+	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V replace(K key, V value) {
-		if (value == null) {
+		if ( value == null ) {
 			throw new NullPointerException();
 		}
-		int hash = hash(key.hashCode());
-		return segmentFor(hash).replace(key, hash, value);
+		int hash = hash( key.hashCode() );
+		return segmentFor( hash ).replace( key, hash, value );
 	}
 
 	/**
 	 * Removes all of the mappings from this map.
 	 */
 	@Override
 	public void clear() {
-		for (int i = 0; i < segments.length; ++ i) {
+		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].clear();
 		}
 	}
 
 	/**
 	 * Returns a {@link Set} view of the keys contained in this map.
 	 * The set is backed by the map, so changes to the map are
 	 * reflected in the set, and vice-versa.  The set supports element
 	 * removal, which removes the corresponding mapping from this map,
 	 * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
 	 * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
 	 * operations.  It does not support the <tt>add</tt> or
 	 * <tt>addAll</tt> operations.
-	 *
+	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
-	 * that will never throw {@link ConcurrentModificationException},
+	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Set<K> keySet() {
 		Set<K> ks = keySet;
-		return ks != null? ks : (keySet = new KeySet());
+		return ks != null ? ks : ( keySet = new KeySet() );
 	}
 
 	/**
 	 * Returns a {@link Collection} view of the values contained in this map.
 	 * The collection is backed by the map, so changes to the map are
 	 * reflected in the collection, and vice-versa.  The collection
 	 * supports element removal, which removes the corresponding
 	 * mapping from this map, via the <tt>Iterator.remove</tt>,
 	 * <tt>Collection.remove</tt>, <tt>removeAll</tt>,
 	 * <tt>retainAll</tt>, and <tt>clear</tt> operations.  It does not
 	 * support the <tt>add</tt> or <tt>addAll</tt> operations.
-	 *
+	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
-	 * that will never throw {@link ConcurrentModificationException},
+	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Collection<V> values() {
 		Collection<V> vs = values;
-		return vs != null? vs : (values = new Values());
+		return vs != null ? vs : ( values = new Values() );
 	}
 
 	/**
 	 * Returns a {@link Set} view of the mappings contained in this map.
 	 * The set is backed by the map, so changes to the map are
 	 * reflected in the set, and vice-versa.  The set supports element
 	 * removal, which removes the corresponding mapping from the map,
 	 * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
 	 * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
 	 * operations.  It does not support the <tt>add</tt> or
 	 * <tt>addAll</tt> operations.
-	 *
+	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
-	 * that will never throw {@link ConcurrentModificationException},
+	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Set<Map.Entry<K, V>> entrySet() {
 		Set<Map.Entry<K, V>> es = entrySet;
-		return es != null? es : (entrySet = new EntrySet());
+		return es != null ? es : ( entrySet = new EntrySet() );
 	}
 
 	/**
 	 * Returns an enumeration of the keys in this table.
 	 *
 	 * @return an enumeration of the keys in this table
+	 *
 	 * @see #keySet()
 	 */
 	public Enumeration<K> keys() {
 		return new KeyIterator();
 	}
 
 	/**
 	 * Returns an enumeration of the values in this table.
 	 *
 	 * @return an enumeration of the values in this table
+	 *
 	 * @see #values()
 	 */
 	public Enumeration<V> elements() {
 		return new ValueIterator();
 	}
 
 	/* ---------------- Iterator Support -------------- */
 
 	abstract class HashIterator {
 		int nextSegmentIndex;
 
 		int nextTableIndex;
 
 		HashEntry<K, V>[] currentTable;
 
 		HashEntry<K, V> nextEntry;
 
 		HashEntry<K, V> lastReturned;
 
 		HashIterator() {
 			nextSegmentIndex = segments.length - 1;
 			nextTableIndex = -1;
 			advance();
 		}
 
 		public boolean hasMoreElements() {
 			return hasNext();
 		}
 
 		final void advance() {
-			if (nextEntry != null && (nextEntry = nextEntry.next) != null) {
+			if ( nextEntry != null && ( nextEntry = nextEntry.next ) != null ) {
 				return;
 			}
 
-			while (nextTableIndex >= 0) {
-				if ((nextEntry = currentTable[nextTableIndex --]) != null) {
+			while ( nextTableIndex >= 0 ) {
+				if ( ( nextEntry = currentTable[nextTableIndex--] ) != null ) {
 					return;
 				}
 			}
 
-			while (nextSegmentIndex >= 0) {
-				Segment<K, V> seg = segments[nextSegmentIndex --];
-				if (seg.count != 0) {
+			while ( nextSegmentIndex >= 0 ) {
+				Segment<K, V> seg = segments[nextSegmentIndex--];
+				if ( seg.count != 0 ) {
 					currentTable = seg.table;
-					for (int j = currentTable.length - 1; j >= 0; -- j) {
-						if ((nextEntry = currentTable[j]) != null) {
+					for ( int j = currentTable.length - 1; j >= 0; --j ) {
+						if ( ( nextEntry = currentTable[j] ) != null ) {
 							nextTableIndex = j - 1;
 							return;
 						}
 					}
 				}
 			}
 		}
 
 		public boolean hasNext() {
 			return nextEntry != null;
 		}
 
 		HashEntry<K, V> nextEntry() {
-			if (nextEntry == null) {
+			if ( nextEntry == null ) {
 				throw new NoSuchElementException();
 			}
 			lastReturned = nextEntry;
 			advance();
 			return lastReturned;
 		}
 
 		public void remove() {
-			if (lastReturned == null) {
+			if ( lastReturned == null ) {
 				throw new IllegalStateException();
 			}
-			BoundedConcurrentHashMap.this.remove(lastReturned.key);
+			BoundedConcurrentHashMap.this.remove( lastReturned.key );
 			lastReturned = null;
 		}
 	}
 
 	final class KeyIterator extends HashIterator implements Iterator<K>, Enumeration<K> {
 		@Override
 		public K next() {
 			return super.nextEntry().key;
 		}
 
 		@Override
 		public K nextElement() {
 			return super.nextEntry().key;
 		}
 	}
 
 	final class ValueIterator extends HashIterator implements Iterator<V>, Enumeration<V> {
 		@Override
 		public V next() {
 			return super.nextEntry().value;
 		}
 
 		@Override
 		public V nextElement() {
 			return super.nextEntry().value;
 		}
 	}
 
 	/**
 	 * Custom Entry class used by EntryIterator.next(), that relays
 	 * setValue changes to the underlying map.
 	 */
 	final class WriteThroughEntry extends AbstractMap.SimpleEntry<K, V> {
 
 		private static final long serialVersionUID = -7041346694785573824L;
 
 		WriteThroughEntry(K k, V v) {
-			super(k, v);
+			super( k, v );
 		}
 
 		/**
 		 * Set our entry's value and write through to the map. The
 		 * value to return is somewhat arbitrary here. Since a
 		 * WriteThroughEntry does not necessarily track asynchronous
 		 * changes, the most recent "previous" value could be
 		 * different from what we return (or could even have been
 		 * removed in which case the put will re-establish). We do not
 		 * and cannot guarantee more.
 		 */
 		@Override
 		public V setValue(V value) {
-			if (value == null) {
+			if ( value == null ) {
 				throw new NullPointerException();
 			}
-			V v = super.setValue(value);
-			BoundedConcurrentHashMap.this.put(getKey(), value);
+			V v = super.setValue( value );
+			BoundedConcurrentHashMap.this.put( getKey(), value );
 			return v;
 		}
 	}
 
 	final class EntryIterator extends HashIterator implements Iterator<Entry<K, V>> {
 		@Override
 		public Map.Entry<K, V> next() {
 			HashEntry<K, V> e = super.nextEntry();
-			return new WriteThroughEntry(e.key, e.value);
+			return new WriteThroughEntry( e.key, e.value );
 		}
 	}
 
 	final class KeySet extends AbstractSet<K> {
 		@Override
 		public Iterator<K> iterator() {
 			return new KeyIterator();
 		}
 
 		@Override
 		public int size() {
 			return BoundedConcurrentHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return BoundedConcurrentHashMap.this.isEmpty();
 		}
 
 		@Override
 		public boolean contains(Object o) {
-			return BoundedConcurrentHashMap.this.containsKey(o);
+			return BoundedConcurrentHashMap.this.containsKey( o );
 		}
 
 		@Override
 		public boolean remove(Object o) {
-			return BoundedConcurrentHashMap.this.remove(o) != null;
+			return BoundedConcurrentHashMap.this.remove( o ) != null;
 		}
 
 		@Override
 		public void clear() {
 			BoundedConcurrentHashMap.this.clear();
 		}
 	}
 
 	final class Values extends AbstractCollection<V> {
 		@Override
 		public Iterator<V> iterator() {
 			return new ValueIterator();
 		}
 
 		@Override
 		public int size() {
 			return BoundedConcurrentHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return BoundedConcurrentHashMap.this.isEmpty();
 		}
 
 		@Override
 		public boolean contains(Object o) {
-			return BoundedConcurrentHashMap.this.containsValue(o);
+			return BoundedConcurrentHashMap.this.containsValue( o );
 		}
 
 		@Override
 		public void clear() {
 			BoundedConcurrentHashMap.this.clear();
 		}
 	}
 
 	final class EntrySet extends AbstractSet<Map.Entry<K, V>> {
 		@Override
 		public Iterator<Map.Entry<K, V>> iterator() {
 			return new EntryIterator();
 		}
 
 		@Override
 		public boolean contains(Object o) {
-			if (!(o instanceof Map.Entry)) {
+			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;
-			V v = BoundedConcurrentHashMap.this.get(e.getKey());
-			return v != null && v.equals(e.getValue());
+			V v = BoundedConcurrentHashMap.this.get( e.getKey() );
+			return v != null && v.equals( e.getValue() );
 		}
 
 		@Override
 		public boolean remove(Object o) {
-			if (!(o instanceof Map.Entry)) {
+			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;
-			return BoundedConcurrentHashMap.this.remove(e.getKey(), e.getValue());
+			return BoundedConcurrentHashMap.this.remove( e.getKey(), e.getValue() );
 		}
 
 		@Override
 		public int size() {
 			return BoundedConcurrentHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return BoundedConcurrentHashMap.this.isEmpty();
 		}
 
 		@Override
 		public void clear() {
 			BoundedConcurrentHashMap.this.clear();
 		}
 	}
 
 	/* ---------------- Serialization Support -------------- */
 
 	/**
 	 * Save the state of the <tt>ConcurrentHashMap</tt> instance to a
 	 * stream (i.e., serialize it).
+	 *
 	 * @param s the stream
-	 * @serialData
-	 * the key (Object) and value (Object)
+	 *
+	 * @serialData the key (Object) and value (Object)
 	 * for each key-value mapping, followed by a null pair.
 	 * The key-value mappings are emitted in no particular order.
 	 */
 	private void writeObject(java.io.ObjectOutputStream s) throws IOException {
 		s.defaultWriteObject();
 
-		for (int k = 0; k < segments.length; ++ k) {
+		for ( int k = 0; k < segments.length; ++k ) {
 			Segment<K, V> seg = segments[k];
 			seg.lock();
 			try {
 				HashEntry<K, V>[] tab = seg.table;
-				for (int i = 0; i < tab.length; ++ i) {
-					for (HashEntry<K, V> e = tab[i]; e != null; e = e.next) {
-						s.writeObject(e.key);
-						s.writeObject(e.value);
+				for ( int i = 0; i < tab.length; ++i ) {
+					for ( HashEntry<K, V> e = tab[i]; e != null; e = e.next ) {
+						s.writeObject( e.key );
+						s.writeObject( e.value );
 					}
 				}
-			} finally {
+			}
+			finally {
 				seg.unlock();
 			}
 		}
-		s.writeObject(null);
-		s.writeObject(null);
+		s.writeObject( null );
+		s.writeObject( null );
 	}
 
 	/**
 	 * Reconstitute the <tt>ConcurrentHashMap</tt> instance from a
 	 * stream (i.e., deserialize it).
+	 *
 	 * @param s the stream
 	 */
 	@SuppressWarnings("unchecked")
 	private void readObject(java.io.ObjectInputStream s) throws IOException,
 			ClassNotFoundException {
 		s.defaultReadObject();
 
 		// Initialize each segment to be minimally sized, and let grow.
-		for (int i = 0; i < segments.length; ++ i) {
-			segments[i].setTable(new HashEntry[1]);
+		for ( int i = 0; i < segments.length; ++i ) {
+			segments[i].setTable( new HashEntry[1] );
 		}
 
 		// Read the keys and values, and put the mappings in the table
-		for (;;) {
+		for (; ; ) {
 			K key = (K) s.readObject();
 			V value = (V) s.readObject();
-			if (key == null) {
+			if ( key == null ) {
 				break;
 			}
-			put(key, value);
+			put( key, value );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/CollectionHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/CollectionHelper.java
index 9bf9fb456d..1f88c68a29 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/CollectionHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/CollectionHelper.java
@@ -1,180 +1,184 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.collections;
 
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 
 /**
  * Various help for handling collections.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public final class CollectionHelper {
-    public static final int MINIMUM_INITIAL_CAPACITY = 16;
+	public static final int MINIMUM_INITIAL_CAPACITY = 16;
 	public static final float LOAD_FACTOR = 0.75f;
 
 	/**
 	 * @deprecated use  {@link java.util.Collections#EMPTY_LIST} or {@link java.util.Collections#emptyList()}  instead
 	 */
 	@Deprecated
 	public static final List EMPTY_LIST = Collections.EMPTY_LIST;
 	/**
 	 * @deprecated use {@link java.util.Collections#EMPTY_LIST} or {@link java.util.Collections#emptyList()}  instead
 	 */
 	@Deprecated
 	public static final Collection EMPTY_COLLECTION = Collections.EMPTY_LIST;
 	/**
 	 * @deprecated use {@link java.util.Collections#EMPTY_MAP} or {@link java.util.Collections#emptyMap()}  instead
 	 */
 	@Deprecated
 	public static final Map EMPTY_MAP = Collections.EMPTY_MAP;
 
 	private CollectionHelper() {
 	}
 
 	/**
 	 * Build a properly sized map, especially handling load size and load factor to prevent immediate resizing.
 	 * <p/>
 	 * Especially helpful for copy map contents.
 	 *
 	 * @param size The size to make the map.
+	 *
 	 * @return The sized map.
 	 */
-	public static <K,V> Map<K,V> mapOfSize(int size) {
-		return new HashMap<K,V>( determineProperSizing( size ), LOAD_FACTOR );
+	public static <K, V> Map<K, V> mapOfSize(int size) {
+		return new HashMap<K, V>( determineProperSizing( size ), LOAD_FACTOR );
 	}
 
 	/**
 	 * Given a map, determine the proper initial size for a new Map to hold the same number of values.
 	 * Specifically we want to account for load size and load factor to prevent immediate resizing.
 	 *
 	 * @param original The original map
+	 *
 	 * @return The proper size.
 	 */
 	public static int determineProperSizing(Map original) {
 		return determineProperSizing( original.size() );
 	}
 
 	/**
 	 * Given a set, determine the proper initial size for a new set to hold the same number of values.
 	 * Specifically we want to account for load size and load factor to prevent immediate resizing.
 	 *
 	 * @param original The original set
+	 *
 	 * @return The proper size.
 	 */
 	public static int determineProperSizing(Set original) {
 		return determineProperSizing( original.size() );
 	}
 
 	/**
 	 * Determine the proper initial size for a new collection in order for it to hold the given a number of elements.
 	 * Specifically we want to account for load size and load factor to prevent immediate resizing.
 	 *
 	 * @param numberOfElements The number of elements to be stored.
+	 *
 	 * @return The proper size.
 	 */
 	public static int determineProperSizing(int numberOfElements) {
-		int actual = ( (int) (numberOfElements / LOAD_FACTOR) ) + 1;
+		int actual = ( (int) ( numberOfElements / LOAD_FACTOR ) ) + 1;
 		return Math.max( actual, MINIMUM_INITIAL_CAPACITY );
 	}
 
 	/**
 	 * Create a properly sized {@link ConcurrentHashMap} based on the given expected number of elements.
 	 *
 	 * @param expectedNumberOfElements The expected number of elements for the created map
 	 * @param <K> The map key type
 	 * @param <V> The map value type
 	 *
 	 * @return The created map.
 	 */
-	public static <K,V> ConcurrentHashMap<K,V> concurrentMap(int expectedNumberOfElements) {
+	public static <K, V> ConcurrentHashMap<K, V> concurrentMap(int expectedNumberOfElements) {
 		return concurrentMap( expectedNumberOfElements, LOAD_FACTOR );
 	}
 
 	/**
 	 * Create a properly sized {@link ConcurrentHashMap} based on the given expected number of elements and an
 	 * explicit load factor
 	 *
 	 * @param expectedNumberOfElements The expected number of elements for the created map
 	 * @param loadFactor The collection load factor
 	 * @param <K> The map key type
 	 * @param <V> The map value type
 	 *
 	 * @return The created map.
 	 */
-	public static <K,V> ConcurrentHashMap<K,V> concurrentMap(int expectedNumberOfElements, float loadFactor) {
+	public static <K, V> ConcurrentHashMap<K, V> concurrentMap(int expectedNumberOfElements, float loadFactor) {
 		final int size = expectedNumberOfElements + 1 + (int) ( expectedNumberOfElements * loadFactor );
 		return new ConcurrentHashMap<K, V>( size, loadFactor );
 	}
 
 	public static <T> ArrayList<T> arrayList(int anticipatedSize) {
 		return new ArrayList<T>( anticipatedSize );
 	}
 
 	public static <T> Set<T> makeCopy(Set<T> source) {
 		if ( source == null ) {
 			return null;
 		}
 
 		final int size = source.size();
 		final Set<T> copy = new HashSet<T>( size + 1 );
 		copy.addAll( source );
 		return copy;
 	}
 
-    public static boolean isEmpty(Collection collection) {
-        return collection == null || collection.isEmpty();
-    }
+	public static boolean isEmpty(Collection collection) {
+		return collection == null || collection.isEmpty();
+	}
 
-    public static boolean isEmpty(Map map) {
-        return map == null || map.isEmpty();
-    }
+	public static boolean isEmpty(Map map) {
+		return map == null || map.isEmpty();
+	}
 
-    public static boolean isNotEmpty(Collection collection) {
-        return !isEmpty( collection );
-    }
+	public static boolean isNotEmpty(Collection collection) {
+		return !isEmpty( collection );
+	}
 
-    public static boolean isNotEmpty(Map map) {
-        return !isEmpty( map );
-    }
+	public static boolean isNotEmpty(Map map) {
+		return !isEmpty( map );
+	}
 
-	public static boolean isEmpty(Object[] objects){
-		return objects == null || objects.length==0;
+	public static boolean isEmpty(Object[] objects) {
+		return objects == null || objects.length == 0;
 	}
 
-	public static <X,Y> Map<X, Y> makeCopy(Map<X, Y> map) {
-		final Map<X,Y> copy = mapOfSize( map.size() + 1 );
+	public static <X, Y> Map<X, Y> makeCopy(Map<X, Y> map) {
+		final Map<X, Y> copy = mapOfSize( map.size() + 1 );
 		copy.putAll( map );
 		return copy;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ConcurrentReferenceHashMap.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ConcurrentReferenceHashMap.java
index 9fb8a40ea8..a216939605 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ConcurrentReferenceHashMap.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ConcurrentReferenceHashMap.java
@@ -1,1942 +1,1946 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 
 /*
  * Written by Doug Lea with assistance from members of JCP JSR-166
  * Expert Group and released to the public domain, as explained at
  * http://creativecommons.org/licenses/publicdomain
  */
 
 package org.hibernate.internal.util.collections;
 
 import java.io.IOException;
 import java.io.Serializable;
 import java.lang.ref.Reference;
 import java.lang.ref.ReferenceQueue;
 import java.lang.ref.SoftReference;
 import java.lang.ref.WeakReference;
 import java.util.AbstractCollection;
 import java.util.AbstractMap;
 import java.util.AbstractSet;
 import java.util.Collection;
-import java.util.ConcurrentModificationException;
 import java.util.EnumSet;
 import java.util.Enumeration;
-import java.util.HashMap;
-import java.util.Hashtable;
 import java.util.IdentityHashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.NoSuchElementException;
 import java.util.Set;
 import java.util.concurrent.locks.ReentrantLock;
 
 /**
  * An advanced hash table supporting configurable garbage collection semantics
  * of keys and values, optional referential-equality, full concurrency of
  * retrievals, and adjustable expected concurrency for updates.
- *
+ * <p/>
  * This table is designed around specific advanced use-cases. If there is any
  * doubt whether this table is for you, you most likely should be using
  * {@link java.util.concurrent.ConcurrentHashMap} instead.
- *
+ * <p/>
  * This table supports strong, weak, and soft keys and values. By default keys
  * are weak, and values are strong. Such a configuration offers similar behavior
  * to {@link java.util.WeakHashMap}, entries of this table are periodically
  * removed once their corresponding keys are no longer referenced outside of
  * this table. In other words, this table will not prevent a key from being
  * discarded by the garbage collector. Once a key has been discarded by the
  * collector, the corresponding entry is no longer visible to this table;
  * however, the entry may occupy space until a future table operation decides to
  * reclaim it. For this reason, summary functions such as <tt>size</tt> and
  * <tt>isEmpty</tt> might return a value greater than the observed number of
  * entries. In order to support a high level of concurrency, stale entries are
  * only reclaimed during blocking (usually mutating) operations.
- *
+ * <p/>
  * Enabling soft keys allows entries in this table to remain until their space
  * is absolutely needed by the garbage collector. This is unlike weak keys which
  * can be reclaimed as soon as they are no longer referenced by a normal strong
  * reference. The primary use case for soft keys is a cache, which ideally
  * occupies memory that is not in use for as long as possible.
- *
+ * <p/>
  * By default, values are held using a normal strong reference. This provides
  * the commonly desired guarantee that a value will always have at least the
  * same life-span as it's key. For this reason, care should be taken to ensure
  * that a value never refers, either directly or indirectly, to its key, thereby
  * preventing reclamation. If this is unavoidable, then it is recommended to use
  * the same reference type in use for the key. However, it should be noted that
  * non-strong values may disappear before their corresponding key.
- *
+ * <p/>
  * While this table does allow the use of both strong keys and values, it is
  * recommended to use {@link java.util.concurrent.ConcurrentHashMap} for such a
  * configuration, since it is optimized for that case.
- *
+ * <p/>
  * Just like {@link java.util.concurrent.ConcurrentHashMap}, this class obeys
  * the same functional specification as {@link java.util.Hashtable}, and
  * includes versions of methods corresponding to each method of
  * <tt>Hashtable</tt>. However, even though all operations are thread-safe,
  * retrieval operations do <em>not</em> entail locking, and there is
  * <em>not</em> any support for locking the entire table in a way that
  * prevents all access. This class is fully interoperable with
  * <tt>Hashtable</tt> in programs that rely on its thread safety but not on
  * its synchronization details.
- *
- * <p>
+ * <p/>
+ * <p/>
  * Retrieval operations (including <tt>get</tt>) generally do not block, so
  * may overlap with update operations (including <tt>put</tt> and
  * <tt>remove</tt>). Retrievals reflect the results of the most recently
  * <em>completed</em> update operations holding upon their onset. For
  * aggregate operations such as <tt>putAll</tt> and <tt>clear</tt>,
  * concurrent retrievals may reflect insertion or removal of only some entries.
  * Similarly, Iterators and Enumerations return elements reflecting the state of
  * the hash table at some point at or since the creation of the
  * iterator/enumeration. They do <em>not</em> throw
- * {@link ConcurrentModificationException}. However, iterators are designed to
+ * {@link java.util.ConcurrentModificationException}. However, iterators are designed to
  * be used by only one thread at a time.
- *
- * <p>
+ * <p/>
+ * <p/>
  * The allowed concurrency among update operations is guided by the optional
  * <tt>concurrencyLevel</tt> constructor argument (default <tt>16</tt>),
  * which is used as a hint for internal sizing. The table is internally
  * partitioned to try to permit the indicated number of concurrent updates
  * without contention. Because placement in hash tables is essentially random,
  * the actual concurrency will vary. Ideally, you should choose a value to
  * accommodate as many threads as will ever concurrently modify the table. Using
  * a significantly higher value than you need can waste space and time, and a
  * significantly lower value can lead to thread contention. But overestimates
  * and underestimates within an order of magnitude do not usually have much
  * noticeable impact. A value of one is appropriate when it is known that only
  * one thread will modify and all others will only read. Also, resizing this or
  * any other kind of hash table is a relatively slow operation, so, when
  * possible, it is a good idea to provide estimates of expected table sizes in
  * constructors.
- *
- * <p>
+ * <p/>
+ * <p/>
  * This class and its views and iterators implement all of the <em>optional</em>
  * methods of the {@link Map} and {@link Iterator} interfaces.
- *
- * <p>
- * Like {@link Hashtable} but unlike {@link HashMap}, this class does
+ * <p/>
+ * <p/>
+ * Like {@link java.util.Hashtable} but unlike {@link java.util.HashMap}, this class does
  * <em>not</em> allow <tt>null</tt> to be used as a key or value.
- *
- * <p>
+ * <p/>
+ * <p/>
  * This class is a member of the <a href="{@docRoot}/../technotes/guides/collections/index.html">
  * Java Collections Framework</a>.
  *
  * @param <K> the type of keys maintained by this map
  * @param <V> the type of mapped values
  *
  * @author Doug Lea
  * @author Jason T. Greene
  */
 public class ConcurrentReferenceHashMap<K, V> extends AbstractMap<K, V>
 		implements java.util.concurrent.ConcurrentMap<K, V>, Serializable {
 	private static final long serialVersionUID = 7249069246763182397L;
 
 	/*
 		 * The basic strategy is to subdivide the table among Segments,
 		 * each of which itself is a concurrently readable hash table.
 		 */
 
 	/**
 	 * An option specifying which Java reference type should be used to refer
 	 * to a key and/or value.
 	 */
 	public static enum ReferenceType {
 		/**
 		 * Indicates a normal Java strong reference should be used
 		 */
 		STRONG,
 		/**
 		 * Indicates a {@link WeakReference} should be used
 		 */
 		WEAK,
 		/**
 		 * Indicates a {@link SoftReference} should be used
 		 */
 		SOFT
 	}
 
 	;
 
 
 	public static enum Option {
 		/**
 		 * Indicates that referential-equality (== instead of .equals()) should
 		 * be used when locating keys. This offers similar behavior to {@link IdentityHashMap}
 		 */
 		IDENTITY_COMPARISONS
 	}
 
 	;
 
 	/* ---------------- Constants -------------- */
 
 	static final ReferenceType DEFAULT_KEY_TYPE = ReferenceType.WEAK;
 
 	static final ReferenceType DEFAULT_VALUE_TYPE = ReferenceType.STRONG;
 
 
 	/**
 	 * The default initial capacity for this table,
 	 * used when not otherwise specified in a constructor.
 	 */
 	static final int DEFAULT_INITIAL_CAPACITY = 16;
 
 	/**
 	 * The default load factor for this table, used when not
 	 * otherwise specified in a constructor.
 	 */
 	static final float DEFAULT_LOAD_FACTOR = 0.75f;
 
 	/**
 	 * The default concurrency level for this table, used when not
 	 * otherwise specified in a constructor.
 	 */
 	static final int DEFAULT_CONCURRENCY_LEVEL = 16;
 
 	/**
 	 * The maximum capacity, used if a higher value is implicitly
 	 * specified by either of the constructors with arguments.  MUST
 	 * be a power of two <= 1<<30 to ensure that entries are indexable
 	 * using ints.
 	 */
 	static final int MAXIMUM_CAPACITY = 1 << 30;
 
 	/**
 	 * The maximum number of segments to allow; used to bound
 	 * constructor arguments.
 	 */
 	static final int MAX_SEGMENTS = 1 << 16; // slightly conservative
 
 	/**
 	 * Number of unsynchronized retries in size and containsValue
 	 * methods before resorting to locking. This is used to avoid
 	 * unbounded retries if tables undergo continuous modification
 	 * which would make it impossible to obtain an accurate result.
 	 */
 	static final int RETRIES_BEFORE_LOCK = 2;
 
 	/* ---------------- Fields -------------- */
 
 	/**
 	 * Mask value for indexing into segments. The upper bits of a
 	 * key's hash code are used to choose the segment.
 	 */
 	final int segmentMask;
 
 	/**
 	 * Shift value for indexing within segments.
 	 */
 	final int segmentShift;
 
 	/**
 	 * The segments, each of which is a specialized hash table
 	 */
 	final Segment<K, V>[] segments;
 
 	boolean identityComparisons;
 
 	transient Set<K> keySet;
 	transient Set<Map.Entry<K, V>> entrySet;
 	transient Collection<V> values;
 
 	/* ---------------- Small Utilities -------------- */
 
 	/**
 	 * Applies a supplemental hash function to a given hashCode, which
 	 * defends against poor quality hash functions.  This is critical
 	 * because ConcurrentReferenceHashMap uses power-of-two length hash tables,
 	 * that otherwise encounter collisions for hashCodes that do not
 	 * differ in lower or upper bits.
 	 */
 	private static int hash(int h) {
 		// Spread bits to regularize both segment and index locations,
 		// using variant of single-word Wang/Jenkins hash.
 		h += ( h << 15 ) ^ 0xffffcd7d;
 		h ^= ( h >>> 10 );
 		h += ( h << 3 );
 		h ^= ( h >>> 6 );
 		h += ( h << 2 ) + ( h << 14 );
 		return h ^ ( h >>> 16 );
 	}
 
 	/**
 	 * Returns the segment that should be used for key with given hash
 	 *
 	 * @param hash the hash code for the key
 	 *
 	 * @return the segment
 	 */
 	final Segment<K, V> segmentFor(int hash) {
 		return segments[( hash >>> segmentShift ) & segmentMask];
 	}
 
 	private int hashOf(Object key) {
 		return hash(
 				identityComparisons ?
 						System.identityHashCode( key ) : key.hashCode()
 		);
 	}
 
 	/* ---------------- Inner Classes -------------- */
 
 	static interface KeyReference {
 		int keyHash();
 
 		Object keyRef();
 	}
 
 	/**
 	 * A weak-key reference which stores the key hash needed for reclamation.
 	 */
 	static final class WeakKeyReference<K> extends WeakReference<K> implements KeyReference {
 		final int hash;
 
 		WeakKeyReference(K key, int hash, ReferenceQueue<Object> refQueue) {
 			super( key, refQueue );
 			this.hash = hash;
 		}
 
 		@Override
 		public final int keyHash() {
 			return hash;
 		}
 
 		@Override
 		public final Object keyRef() {
 			return this;
 		}
 	}
 
 	/**
 	 * A soft-key reference which stores the key hash needed for reclamation.
 	 */
 	static final class SoftKeyReference<K> extends SoftReference<K> implements KeyReference {
 		final int hash;
 
 		SoftKeyReference(K key, int hash, ReferenceQueue<Object> refQueue) {
 			super( key, refQueue );
 			this.hash = hash;
 		}
 
 		@Override
 		public final int keyHash() {
 			return hash;
 		}
 
 		@Override
 		public final Object keyRef() {
 			return this;
 		}
 	}
 
 	static final class WeakValueReference<V> extends WeakReference<V> implements KeyReference {
 		final Object keyRef;
 		final int hash;
 
 		WeakValueReference(V value, Object keyRef, int hash, ReferenceQueue<Object> refQueue) {
 			super( value, refQueue );
 			this.keyRef = keyRef;
 			this.hash = hash;
 		}
 
 		@Override
 		public final int keyHash() {
 			return hash;
 		}
 
 		@Override
 		public final Object keyRef() {
 			return keyRef;
 		}
 	}
 
 	static final class SoftValueReference<V> extends SoftReference<V> implements KeyReference {
 		final Object keyRef;
 		final int hash;
 
 		SoftValueReference(V value, Object keyRef, int hash, ReferenceQueue<Object> refQueue) {
 			super( value, refQueue );
 			this.keyRef = keyRef;
 			this.hash = hash;
 		}
 
 		@Override
 		public final int keyHash() {
 			return hash;
 		}
 
 		@Override
 		public final Object keyRef() {
 			return keyRef;
 		}
 	}
 
 	/**
 	 * ConcurrentReferenceHashMap list entry. Note that this is never exported
 	 * out as a user-visible Map.Entry.
-	 *
+	 * <p/>
 	 * Because the value field is volatile, not final, it is legal wrt
 	 * the Java Memory Model for an unsynchronized reader to see null
 	 * instead of initial value when read via a data race.  Although a
 	 * reordering leading to this is not likely to ever actually
 	 * occur, the Segment.readValueUnderLock method is used as a
 	 * backup in case a null (pre-initialized) value is ever seen in
 	 * an unsynchronized access method.
 	 */
 	static final class HashEntry<K, V> {
 		final Object keyRef;
 		final int hash;
 		volatile Object valueRef;
 		final HashEntry<K, V> next;
 
-		HashEntry(K key, int hash, HashEntry<K, V> next, V value,
-				  ReferenceType keyType, ReferenceType valueType,
-				  ReferenceQueue<Object> refQueue) {
+		HashEntry(
+				K key, int hash, HashEntry<K, V> next, V value,
+				ReferenceType keyType, ReferenceType valueType,
+				ReferenceQueue<Object> refQueue) {
 			this.hash = hash;
 			this.next = next;
 			this.keyRef = newKeyReference( key, keyType, refQueue );
 			this.valueRef = newValueReference( value, valueType, refQueue );
 		}
 
-		final Object newKeyReference(K key, ReferenceType keyType,
-									 ReferenceQueue<Object> refQueue) {
+		final Object newKeyReference(
+				K key, ReferenceType keyType,
+				ReferenceQueue<Object> refQueue) {
 			if ( keyType == ReferenceType.WEAK ) {
 				return new WeakKeyReference<K>( key, hash, refQueue );
 			}
 			if ( keyType == ReferenceType.SOFT ) {
 				return new SoftKeyReference<K>( key, hash, refQueue );
 			}
 
 			return key;
 		}
 
-		final Object newValueReference(V value, ReferenceType valueType,
-									   ReferenceQueue<Object> refQueue) {
+		final Object newValueReference(
+				V value, ReferenceType valueType,
+				ReferenceQueue<Object> refQueue) {
 			if ( valueType == ReferenceType.WEAK ) {
 				return new WeakValueReference<V>( value, keyRef, hash, refQueue );
 			}
 			if ( valueType == ReferenceType.SOFT ) {
 				return new SoftValueReference<V>( value, keyRef, hash, refQueue );
 			}
 
 			return value;
 		}
 
 		@SuppressWarnings("unchecked")
 		final K key() {
 			if ( keyRef instanceof KeyReference ) {
 				return ( (Reference<K>) keyRef ).get();
 			}
 
 			return (K) keyRef;
 		}
 
 		final V value() {
 			return dereferenceValue( valueRef );
 		}
 
 		@SuppressWarnings("unchecked")
 		final V dereferenceValue(Object value) {
 			if ( value instanceof KeyReference ) {
 				return ( (Reference<V>) value ).get();
 			}
 
 			return (V) value;
 		}
 
 		final void setValue(V value, ReferenceType valueType, ReferenceQueue<Object> refQueue) {
 			this.valueRef = newValueReference( value, valueType, refQueue );
 		}
 
 		@SuppressWarnings("unchecked")
 		static final <K, V> HashEntry<K, V>[] newArray(int i) {
 			return new HashEntry[i];
 		}
 	}
 
 	/**
 	 * Segments are specialized versions of hash tables.  This
 	 * subclasses from ReentrantLock opportunistically, just to
 	 * simplify some locking and avoid separate construction.
 	 */
 	static final class Segment<K, V> extends ReentrantLock implements Serializable {
 		/*
 				 * Segments maintain a table of entry lists that are ALWAYS
 				 * kept in a consistent state, so can be read without locking.
 				 * Next fields of nodes are immutable (final).  All list
 				 * additions are performed at the front of each bin. This
 				 * makes it easy to check changes, and also fast to traverse.
 				 * When nodes would otherwise be changed, new nodes are
 				 * created to replace them. This works well for hash tables
 				 * since the bin lists tend to be short. (The average length
 				 * is less than two for the default load factor threshold.)
 				 *
 				 * Read operations can thus proceed without locking, but rely
 				 * on selected uses of volatiles to ensure that completed
 				 * write operations performed by other threads are
 				 * noticed. For most purposes, the "count" field, tracking the
 				 * number of elements, serves as that volatile variable
 				 * ensuring visibility.  This is convenient because this field
 				 * needs to be read in many read operations anyway:
 				 *
 				 *   - All (unsynchronized) read operations must first read the
 				 *     "count" field, and should not look at table entries if
 				 *     it is 0.
 				 *
 				 *   - All (synchronized) write operations should write to
 				 *     the "count" field after structurally changing any bin.
 				 *     The operations must not take any action that could even
 				 *     momentarily cause a concurrent read operation to see
 				 *     inconsistent data. This is made easier by the nature of
 				 *     the read operations in Map. For example, no operation
 				 *     can reveal that the table has grown but the threshold
 				 *     has not yet been updated, so there are no atomicity
 				 *     requirements for this with respect to reads.
 				 *
 				 * As a guide, all critical volatile reads and writes to the
 				 * count field are marked in code comments.
 				 */
 
 		private static final long serialVersionUID = 2249069246763182397L;
 
 		/**
 		 * The number of elements in this segment's region.
 		 */
 		transient volatile int count;
 
 		/**
 		 * Number of updates that alter the size of the table. This is
 		 * used during bulk-read methods to make sure they see a
 		 * consistent snapshot: If modCounts change during a traversal
 		 * of segments computing size or checking containsValue, then
 		 * we might have an inconsistent view of state so (usually)
 		 * must retry.
 		 */
 		transient int modCount;
 
 		/**
 		 * The table is rehashed when its size exceeds this threshold.
 		 * (The value of this field is always <tt>(int)(capacity *
 		 * loadFactor)</tt>.)
 		 */
 		transient int threshold;
 
 		/**
 		 * The per-segment table.
 		 */
 		transient volatile HashEntry<K, V>[] table;
 
 		/**
 		 * The load factor for the hash table.  Even though this value
 		 * is same for all segments, it is replicated to avoid needing
 		 * links to outer object.
 		 *
 		 * @serial
 		 */
 		final float loadFactor;
 
 		/**
 		 * The collected weak-key reference queue for this segment.
 		 * This should be (re)initialized whenever table is assigned,
 		 */
 		transient volatile ReferenceQueue<Object> refQueue;
 
 		final ReferenceType keyType;
 
 		final ReferenceType valueType;
 
 		final boolean identityComparisons;
 
-		Segment(int initialCapacity, float lf, ReferenceType keyType,
+		Segment(
+				int initialCapacity, float lf, ReferenceType keyType,
 				ReferenceType valueType, boolean identityComparisons) {
 			loadFactor = lf;
 			this.keyType = keyType;
 			this.valueType = valueType;
 			this.identityComparisons = identityComparisons;
 			setTable( HashEntry.<K, V>newArray( initialCapacity ) );
 		}
 
 		@SuppressWarnings("unchecked")
 		static final <K, V> Segment<K, V>[] newArray(int i) {
 			return new Segment[i];
 		}
 
 		private boolean keyEq(Object src, Object dest) {
 			return identityComparisons ? src == dest : src.equals( dest );
 		}
 
 		/**
 		 * Sets table to new HashEntry array.
 		 * Call only while holding lock or in constructor.
 		 */
 		void setTable(HashEntry<K, V>[] newTable) {
 			threshold = (int) ( newTable.length * loadFactor );
 			table = newTable;
 			refQueue = new ReferenceQueue<Object>();
 		}
 
 		/**
 		 * Returns properly casted first entry of bin for given hash.
 		 */
 		HashEntry<K, V> getFirst(int hash) {
 			HashEntry<K, V>[] tab = table;
 			return tab[hash & ( tab.length - 1 )];
 		}
 
 		HashEntry<K, V> newHashEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			return new HashEntry<K, V>( key, hash, next, value, keyType, valueType, refQueue );
 		}
 
 		/**
 		 * Reads value field of an entry under lock. Called if value
 		 * field ever appears to be null. This is possible only if a
 		 * compiler happens to reorder a HashEntry initialization with
 		 * its table assignment, which is legal under memory model
 		 * but is not known to ever occur.
 		 */
 		V readValueUnderLock(HashEntry<K, V> e) {
 			lock();
 			try {
 				removeStale();
 				return e.value();
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		/* Specialized implementations of map methods */
 
 		V get(Object key, int hash) {
 			if ( count != 0 ) { // read-volatile
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null ) {
 					if ( e.hash == hash && keyEq( key, e.key() ) ) {
 						Object opaque = e.valueRef;
 						if ( opaque != null ) {
 							return e.dereferenceValue( opaque );
 						}
 
 						return readValueUnderLock( e );  // recheck
 					}
 					e = e.next;
 				}
 			}
 			return null;
 		}
 
 		boolean containsKey(Object key, int hash) {
 			if ( count != 0 ) { // read-volatile
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null ) {
 					if ( e.hash == hash && keyEq( key, e.key() ) ) {
 						return true;
 					}
 					e = e.next;
 				}
 			}
 			return false;
 		}
 
 		boolean containsValue(Object value) {
 			if ( count != 0 ) { // read-volatile
 				HashEntry<K, V>[] tab = table;
 				int len = tab.length;
 				for ( int i = 0; i < len; i++ ) {
 					for ( HashEntry<K, V> e = tab[i]; e != null; e = e.next ) {
 						Object opaque = e.valueRef;
 						V v;
 
 						if ( opaque == null ) {
 							v = readValueUnderLock( e ); // recheck
 						}
 						else {
 							v = e.dereferenceValue( opaque );
 						}
 
 						if ( value.equals( v ) ) {
 							return true;
 						}
 					}
 				}
 			}
 			return false;
 		}
 
 		boolean replace(K key, int hash, V oldValue, V newValue) {
 			lock();
 			try {
 				removeStale();
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null && ( e.hash != hash || !keyEq( key, e.key() ) ) ) {
 					e = e.next;
 				}
 
 				boolean replaced = false;
 				if ( e != null && oldValue.equals( e.value() ) ) {
 					replaced = true;
 					e.setValue( newValue, valueType, refQueue );
 				}
 				return replaced;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		V replace(K key, int hash, V newValue) {
 			lock();
 			try {
 				removeStale();
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null && ( e.hash != hash || !keyEq( key, e.key() ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue = null;
 				if ( e != null ) {
 					oldValue = e.value();
 					e.setValue( newValue, valueType, refQueue );
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 
 		V put(K key, int hash, V value, boolean onlyIfAbsent) {
 			lock();
 			try {
 				removeStale();
 				int c = count;
 				if ( c++ > threshold ) {// ensure capacity
 					int reduced = rehash();
 					if ( reduced > 0 ) {
 						// adjust from possible weak cleanups
 						count = ( c -= reduced ) - 1; // write-volatile
 					}
 				}
 
 				HashEntry<K, V>[] tab = table;
 				int index = hash & ( tab.length - 1 );
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
 				while ( e != null && ( e.hash != hash || !keyEq( key, e.key() ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue;
 				if ( e != null ) {
 					oldValue = e.value();
 					if ( !onlyIfAbsent ) {
 						e.setValue( value, valueType, refQueue );
 					}
 				}
 				else {
 					oldValue = null;
 					++modCount;
 					tab[index] = newHashEntry( key, hash, first, value );
 					count = c; // write-volatile
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		int rehash() {
 			HashEntry<K, V>[] oldTable = table;
 			int oldCapacity = oldTable.length;
 			if ( oldCapacity >= MAXIMUM_CAPACITY ) {
 				return 0;
 			}
 
 			/*
 						 * Reclassify nodes in each list to new Map.  Because we are
 						 * using power-of-two expansion, the elements from each bin
 						 * must either stay at same index, or move with a power of two
 						 * offset. We eliminate unnecessary node creation by catching
 						 * cases where old nodes can be reused because their next
 						 * fields won't change. Statistically, at the default
 						 * threshold, only about one-sixth of them need cloning when
 						 * a table doubles. The nodes they replace will be garbage
 						 * collectable as soon as they are no longer referenced by any
 						 * reader thread that may be in the midst of traversing table
 						 * right now.
 						 */
 
 			HashEntry<K, V>[] newTable = HashEntry.newArray( oldCapacity << 1 );
 			threshold = (int) ( newTable.length * loadFactor );
 			int sizeMask = newTable.length - 1;
 			int reduce = 0;
 			for ( int i = 0; i < oldCapacity; i++ ) {
 				// We need to guarantee that any existing reads of old Map can
 				//  proceed. So we cannot yet null out each bin.
 				HashEntry<K, V> e = oldTable[i];
 
 				if ( e != null ) {
 					HashEntry<K, V> next = e.next;
 					int idx = e.hash & sizeMask;
 
 					//  Single node on list
 					if ( next == null ) {
 						newTable[idx] = e;
 					}
 
 					else {
 						// Reuse trailing consecutive sequence at same slot
 						HashEntry<K, V> lastRun = e;
 						int lastIdx = idx;
 						for ( HashEntry<K, V> last = next;
 							  last != null;
 							  last = last.next ) {
 							int k = last.hash & sizeMask;
 							if ( k != lastIdx ) {
 								lastIdx = k;
 								lastRun = last;
 							}
 						}
 						newTable[lastIdx] = lastRun;
 						// Clone all remaining nodes
 						for ( HashEntry<K, V> p = e; p != lastRun; p = p.next ) {
 							// Skip GC'd weak refs
 							K key = p.key();
 							if ( key == null ) {
 								reduce++;
 								continue;
 							}
 							int k = p.hash & sizeMask;
 							HashEntry<K, V> n = newTable[k];
 							newTable[k] = newHashEntry( key, p.hash, n, p.value() );
 						}
 					}
 				}
 			}
 			table = newTable;
 			return reduce;
 		}
 
 		/**
 		 * Remove; match on key only if value null, else match both.
 		 */
 		V remove(Object key, int hash, Object value, boolean refRemove) {
 			lock();
 			try {
 				if ( !refRemove ) {
 					removeStale();
 				}
 				int c = count - 1;
 				HashEntry<K, V>[] tab = table;
 				int index = hash & ( tab.length - 1 );
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
 				// a ref remove operation compares the Reference instance
 				while ( e != null && key != e.keyRef
 						&& ( refRemove || hash != e.hash || !keyEq( key, e.key() ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue = null;
 				if ( e != null ) {
 					V v = e.value();
 					if ( value == null || value.equals( v ) ) {
 						oldValue = v;
 						// All entries following removed node can stay
 						// in list, but all preceding ones need to be
 						// cloned.
 						++modCount;
 						HashEntry<K, V> newFirst = e.next;
 						for ( HashEntry<K, V> p = first; p != e; p = p.next ) {
 							K pKey = p.key();
 							if ( pKey == null ) { // Skip GC'd keys
 								c--;
 								continue;
 							}
 
 							newFirst = newHashEntry( pKey, p.hash, newFirst, p.value() );
 						}
 						tab[index] = newFirst;
 						count = c; // write-volatile
 					}
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		final void removeStale() {
 			KeyReference ref;
 			while ( ( ref = (KeyReference) refQueue.poll() ) != null ) {
 				remove( ref.keyRef(), ref.keyHash(), null, true );
 			}
 		}
 
 		void clear() {
 			if ( count != 0 ) {
 				lock();
 				try {
 					HashEntry<K, V>[] tab = table;
 					for ( int i = 0; i < tab.length; i++ ) {
 						tab[i] = null;
 					}
 					++modCount;
 					// replace the reference queue to avoid unnecessary stale cleanups
 					refQueue = new ReferenceQueue<Object>();
 					count = 0; // write-volatile
 				}
 				finally {
 					unlock();
 				}
 			}
 		}
 	}
 
 
 	/* ---------------- Public operations -------------- */
 
 	/**
 	 * Creates a new, empty map with the specified initial
 	 * capacity, reference types, load factor and concurrency level.
-	 *
+	 * <p/>
 	 * Behavioral changing options such as {@link Option#IDENTITY_COMPARISONS}
 	 * can also be specified.
 	 *
 	 * @param initialCapacity the initial capacity. The implementation
 	 * performs internal sizing to accommodate this many elements.
 	 * @param loadFactor the load factor threshold, used to control resizing.
 	 * Resizing may be performed when the average number of elements per
 	 * bin exceeds this threshold.
 	 * @param concurrencyLevel the estimated number of concurrently
 	 * updating threads. The implementation performs internal sizing
 	 * to try to accommodate this many threads.
 	 * @param keyType the reference type to use for keys
 	 * @param valueType the reference type to use for values
 	 * @param options the behavioral options
 	 *
 	 * @throws IllegalArgumentException if the initial capacity is
 	 * negative or the load factor or concurrencyLevel are
 	 * nonpositive.
 	 */
-	public ConcurrentReferenceHashMap(int initialCapacity,
-									  float loadFactor, int concurrencyLevel,
-									  ReferenceType keyType, ReferenceType valueType,
-									  EnumSet<Option> options) {
+	public ConcurrentReferenceHashMap(
+			int initialCapacity,
+			float loadFactor, int concurrencyLevel,
+			ReferenceType keyType, ReferenceType valueType,
+			EnumSet<Option> options) {
 		if ( !( loadFactor > 0 ) || initialCapacity < 0 || concurrencyLevel <= 0 ) {
 			throw new IllegalArgumentException();
 		}
 
 		if ( concurrencyLevel > MAX_SEGMENTS ) {
 			concurrencyLevel = MAX_SEGMENTS;
 		}
 
 		// Find power-of-two sizes best matching arguments
 		int sshift = 0;
 		int ssize = 1;
 		while ( ssize < concurrencyLevel ) {
 			++sshift;
 			ssize <<= 1;
 		}
 		segmentShift = 32 - sshift;
 		segmentMask = ssize - 1;
 		this.segments = Segment.newArray( ssize );
 
 		if ( initialCapacity > MAXIMUM_CAPACITY ) {
 			initialCapacity = MAXIMUM_CAPACITY;
 		}
 		int c = initialCapacity / ssize;
 		if ( c * ssize < initialCapacity ) {
 			++c;
 		}
 		int cap = 1;
 		while ( cap < c ) {
 			cap <<= 1;
 		}
 
 		identityComparisons = options != null && options.contains( Option.IDENTITY_COMPARISONS );
 
 		for ( int i = 0; i < this.segments.length; ++i ) {
 			this.segments[i] = new Segment<K, V>(
 					cap, loadFactor,
 					keyType, valueType, identityComparisons
 			);
 		}
 	}
 
 	/**
 	 * Creates a new, empty map with the specified initial
 	 * capacity, load factor and concurrency level.
 	 *
 	 * @param initialCapacity the initial capacity. The implementation
 	 * performs internal sizing to accommodate this many elements.
 	 * @param loadFactor the load factor threshold, used to control resizing.
 	 * Resizing may be performed when the average number of elements per
 	 * bin exceeds this threshold.
 	 * @param concurrencyLevel the estimated number of concurrently
 	 * updating threads. The implementation performs internal sizing
 	 * to try to accommodate this many threads.
 	 *
 	 * @throws IllegalArgumentException if the initial capacity is
 	 * negative or the load factor or concurrencyLevel are
 	 * nonpositive.
 	 */
-	public ConcurrentReferenceHashMap(int initialCapacity,
-									  float loadFactor, int concurrencyLevel) {
+	public ConcurrentReferenceHashMap(
+			int initialCapacity,
+			float loadFactor, int concurrencyLevel) {
 		this(
 				initialCapacity, loadFactor, concurrencyLevel,
 				DEFAULT_KEY_TYPE, DEFAULT_VALUE_TYPE, null
 		);
 	}
 
 	/**
 	 * Creates a new, empty map with the specified initial capacity
 	 * and load factor and with the default reference types (weak keys,
 	 * strong values), and concurrencyLevel (16).
 	 *
 	 * @param initialCapacity The implementation performs internal
 	 * sizing to accommodate this many elements.
 	 * @param loadFactor the load factor threshold, used to control resizing.
 	 * Resizing may be performed when the average number of elements per
 	 * bin exceeds this threshold.
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative or the load factor is nonpositive
 	 * @since 1.6
 	 */
 	public ConcurrentReferenceHashMap(int initialCapacity, float loadFactor) {
 		this( initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 
 	/**
 	 * Creates a new, empty map with the specified initial capacity,
 	 * reference types and with default load factor (0.75) and concurrencyLevel (16).
 	 *
 	 * @param initialCapacity the initial capacity. The implementation
 	 * performs internal sizing to accommodate this many elements.
 	 * @param keyType the reference type to use for keys
 	 * @param valueType the reference type to use for values
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative.
 	 */
-	public ConcurrentReferenceHashMap(int initialCapacity,
-									  ReferenceType keyType, ReferenceType valueType) {
+	public ConcurrentReferenceHashMap(
+			int initialCapacity,
+			ReferenceType keyType, ReferenceType valueType) {
 		this(
 				initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL,
 				keyType, valueType, null
 		);
 	}
 
 	/**
 	 * Creates a new, empty map with the specified initial capacity,
 	 * and with default reference types (weak keys, strong values),
 	 * load factor (0.75) and concurrencyLevel (16).
 	 *
 	 * @param initialCapacity the initial capacity. The implementation
 	 * performs internal sizing to accommodate this many elements.
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative.
 	 */
 	public ConcurrentReferenceHashMap(int initialCapacity) {
 		this( initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 	/**
 	 * Creates a new, empty map with a default initial capacity (16),
 	 * reference types (weak keys, strong values), default
 	 * load factor (0.75) and concurrencyLevel (16).
 	 */
 	public ConcurrentReferenceHashMap() {
 		this( DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 	/**
 	 * Creates a new map with the same mappings as the given map.
 	 * The map is created with a capacity of 1.5 times the number
 	 * of mappings in the given map or 16 (whichever is greater),
 	 * and a default load factor (0.75) and concurrencyLevel (16).
 	 *
 	 * @param m the map
 	 */
 	public ConcurrentReferenceHashMap(Map<? extends K, ? extends V> m) {
 		this(
 				Math.max(
 						(int) ( m.size() / DEFAULT_LOAD_FACTOR ) + 1,
 						DEFAULT_INITIAL_CAPACITY
 				),
 				DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL
 		);
 		putAll( m );
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map contains no key-value mappings.
 	 *
 	 * @return <tt>true</tt> if this map contains no key-value mappings
 	 */
 	@Override
 	public boolean isEmpty() {
 		final Segment<K, V>[] segments = this.segments;
 		/*
 				 * We keep track of per-segment modCounts to avoid ABA
 				 * problems in which an element in one segment was added and
 				 * in another removed during traversal, in which case the
 				 * table was never actually empty at any point. Note the
 				 * similar use of modCounts in the size() and containsValue()
 				 * methods, which are the only other methods also susceptible
 				 * to ABA problems.
 				 */
 		int[] mc = new int[segments.length];
 		int mcsum = 0;
 		for ( int i = 0; i < segments.length; ++i ) {
 			if ( segments[i].count != 0 ) {
 				return false;
 			}
 			else {
 				mcsum += mc[i] = segments[i].modCount;
 			}
 		}
 		// If mcsum happens to be zero, then we know we got a snapshot
 		// before any modifications at all were made.  This is
 		// probably common enough to bother tracking.
 		if ( mcsum != 0 ) {
 			for ( int i = 0; i < segments.length; ++i ) {
 				if ( segments[i].count != 0 ||
 						mc[i] != segments[i].modCount ) {
 					return false;
 				}
 			}
 		}
 		return true;
 	}
 
 	/**
 	 * Returns the number of key-value mappings in this map.  If the
 	 * map contains more than <tt>Integer.MAX_VALUE</tt> elements, returns
 	 * <tt>Integer.MAX_VALUE</tt>.
 	 *
 	 * @return the number of key-value mappings in this map
 	 */
 	@Override
 	public int size() {
 		final Segment<K, V>[] segments = this.segments;
 		long sum = 0;
 		long check = 0;
 		int[] mc = new int[segments.length];
 		// Try a few times to get accurate count. On failure due to
 		// continuous async changes in table, resort to locking.
 		for ( int k = 0; k < RETRIES_BEFORE_LOCK; ++k ) {
 			check = 0;
 			sum = 0;
 			int mcsum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				sum += segments[i].count;
 				mcsum += mc[i] = segments[i].modCount;
 			}
 			if ( mcsum != 0 ) {
 				for ( int i = 0; i < segments.length; ++i ) {
 					check += segments[i].count;
 					if ( mc[i] != segments[i].modCount ) {
 						check = -1; // force retry
 						break;
 					}
 				}
 			}
 			if ( check == sum ) {
 				break;
 			}
 		}
 		if ( check != sum ) { // Resort to locking all segments
 			sum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].lock();
 			}
 			for ( int i = 0; i < segments.length; ++i ) {
 				sum += segments[i].count;
 			}
 			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].unlock();
 			}
 		}
 		if ( sum > Integer.MAX_VALUE ) {
 			return Integer.MAX_VALUE;
 		}
 		else {
 			return (int) sum;
 		}
 	}
 
 	/**
 	 * Returns the value to which the specified key is mapped,
 	 * or {@code null} if this map contains no mapping for the key.
-	 *
+	 * <p/>
 	 * <p>More formally, if this map contains a mapping from a key
 	 * {@code k} to a value {@code v} such that {@code key.equals(k)},
 	 * then this method returns {@code v}; otherwise it returns
 	 * {@code null}.  (There can be at most one such mapping.)
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V get(Object key) {
 		if ( key == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).get( key, hash );
 	}
 
 	/**
 	 * Tests if the specified object is a key in this table.
 	 *
 	 * @param key possible key
 	 *
 	 * @return <tt>true</tt> if and only if the specified object
-	 *         is a key in this table, as determined by the
-	 *         <tt>equals</tt> method; <tt>false</tt> otherwise.
+	 * is a key in this table, as determined by the
+	 * <tt>equals</tt> method; <tt>false</tt> otherwise.
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean containsKey(Object key) {
 		if ( key == null ) {
 			return false;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).containsKey( key, hash );
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map maps one or more keys to the
 	 * specified value. Note: This method requires a full internal
 	 * traversal of the hash table, and so is much slower than
 	 * method <tt>containsKey</tt>.
 	 *
 	 * @param value value whose presence in this map is to be tested
 	 *
 	 * @return <tt>true</tt> if this map maps one or more keys to the
-	 *         specified value
+	 * specified value
 	 */
 	@Override
 	public boolean containsValue(Object value) {
 		if ( value == null ) {
 			return false;
 		}
 
 		// See explanation of modCount use above
 
 		final Segment<K, V>[] segments = this.segments;
 		int[] mc = new int[segments.length];
 
 		// Try a few times without locking
 		for ( int k = 0; k < RETRIES_BEFORE_LOCK; ++k ) {
 			int sum = 0;
 			int mcsum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				int c = segments[i].count;
 				mcsum += mc[i] = segments[i].modCount;
 				if ( segments[i].containsValue( value ) ) {
 					return true;
 				}
 			}
 			boolean cleanSweep = true;
 			if ( mcsum != 0 ) {
 				for ( int i = 0; i < segments.length; ++i ) {
 					int c = segments[i].count;
 					if ( mc[i] != segments[i].modCount ) {
 						cleanSweep = false;
 						break;
 					}
 				}
 			}
 			if ( cleanSweep ) {
 				return false;
 			}
 		}
 		// Resort to locking all segments
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].lock();
 		}
 		boolean found = false;
 		try {
 			for ( int i = 0; i < segments.length; ++i ) {
 				if ( segments[i].containsValue( value ) ) {
 					found = true;
 					break;
 				}
 			}
 		}
 		finally {
 			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].unlock();
 			}
 		}
 		return found;
 	}
 
 	/**
 	 * Legacy method testing if some key maps into the specified value
 	 * in this table.  This method is identical in functionality to
 	 * {@link #containsValue}, and exists solely to ensure
 	 * full compatibility with class {@link java.util.Hashtable},
 	 * which supported this method prior to introduction of the
 	 * Java Collections framework.
 	 *
 	 * @param value a value to search for
 	 *
 	 * @return <tt>true</tt> if and only if some key maps to the
-	 *         <tt>value</tt> argument in this table as
-	 *         determined by the <tt>equals</tt> method;
-	 *         <tt>false</tt> otherwise
+	 * <tt>value</tt> argument in this table as
+	 * determined by the <tt>equals</tt> method;
+	 * <tt>false</tt> otherwise
 	 *
 	 * @throws NullPointerException if the specified value is null
 	 */
 	public boolean contains(Object value) {
 		return containsValue( value );
 	}
 
 	/**
 	 * Maps the specified key to the specified value in this table.
 	 * Neither the key nor the value can be null.
-	 *
+	 * <p/>
 	 * <p> The value can be retrieved by calling the <tt>get</tt> method
 	 * with a key that is equal to the original key.
 	 *
 	 * @param key key with which the specified value is to be associated
 	 * @param value value to be associated with the specified key
 	 *
 	 * @return the previous value associated with <tt>key</tt>, or
-	 *         <tt>null</tt> if there was no mapping for <tt>key</tt>
+	 * <tt>null</tt> if there was no mapping for <tt>key</tt>
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V put(K key, V value) {
 		if ( key == null || value == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).put( key, hash, value, false );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
-	 *         or <tt>null</tt> if there was no mapping for the key
+	 * or <tt>null</tt> if there was no mapping for the key
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V putIfAbsent(K key, V value) {
 		if ( key == null || value == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).put( key, hash, value, true );
 	}
 
 	/**
 	 * Copies all of the mappings from the specified map to this one.
 	 * These mappings replace any mappings that this map had for any of the
 	 * keys currently in the specified map.
 	 *
 	 * @param m mappings to be stored in this map
 	 */
 	@Override
 	public void putAll(Map<? extends K, ? extends V> m) {
 		for ( Map.Entry<? extends K, ? extends V> e : m.entrySet() ) {
 			put( e.getKey(), e.getValue() );
 		}
 	}
 
 	/**
 	 * Removes the key (and its corresponding value) from this map.
 	 * This method does nothing if the key is not in the map.
 	 *
 	 * @param key the key that needs to be removed
 	 *
 	 * @return the previous value associated with <tt>key</tt>, or
-	 *         <tt>null</tt> if there was no mapping for <tt>key</tt>
+	 * <tt>null</tt> if there was no mapping for <tt>key</tt>
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V remove(Object key) {
 		if ( key == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).remove( key, hash, null, false );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean remove(Object key, Object value) {
 		if ( key == null || value == null ) {
 			return false;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).remove( key, hash, value, false ) != null;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @throws NullPointerException if any of the arguments are null
 	 */
 	@Override
 	public boolean replace(K key, V oldValue, V newValue) {
 		if ( key == null || oldValue == null || newValue == null ) {
 			throw new NullPointerException();
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).replace( key, hash, oldValue, newValue );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
-	 *         or <tt>null</tt> if there was no mapping for the key
+	 * or <tt>null</tt> if there was no mapping for the key
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V replace(K key, V value) {
 		if ( key == null || value == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).replace( key, hash, value );
 	}
 
 	/**
 	 * Removes all of the mappings from this map.
 	 */
 	@Override
 	public void clear() {
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].clear();
 		}
 	}
 
 	/**
 	 * Removes any stale entries whose keys have been finalized. Use of this
 	 * method is normally not necessary since stale entries are automatically
 	 * removed lazily, when blocking operations are required. However, there
 	 * are some cases where this operation should be performed eagerly, such
 	 * as cleaning up old references to a ClassLoader in a multi-classloader
 	 * environment.
-	 *
+	 * <p/>
 	 * Note: this method will acquire locks, one at a time, across all segments
 	 * of this table, so if it is to be used, it should be used sparingly.
 	 */
 	public void purgeStaleEntries() {
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].removeStale();
 		}
 	}
 
 
 	/**
 	 * Returns a {@link Set} view of the keys contained in this map.
 	 * The set is backed by the map, so changes to the map are
 	 * reflected in the set, and vice-versa.  The set supports element
 	 * removal, which removes the corresponding mapping from this map,
 	 * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
 	 * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
 	 * operations.  It does not support the <tt>add</tt> or
 	 * <tt>addAll</tt> operations.
-	 *
+	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
-	 * that will never throw {@link ConcurrentModificationException},
+	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Set<K> keySet() {
 		Set<K> ks = keySet;
 		return ( ks != null ) ? ks : ( keySet = new KeySet() );
 	}
 
 	/**
 	 * Returns a {@link Collection} view of the values contained in this map.
 	 * The collection is backed by the map, so changes to the map are
 	 * reflected in the collection, and vice-versa.  The collection
 	 * supports element removal, which removes the corresponding
 	 * mapping from this map, via the <tt>Iterator.remove</tt>,
 	 * <tt>Collection.remove</tt>, <tt>removeAll</tt>,
 	 * <tt>retainAll</tt>, and <tt>clear</tt> operations.  It does not
 	 * support the <tt>add</tt> or <tt>addAll</tt> operations.
-	 *
+	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
-	 * that will never throw {@link ConcurrentModificationException},
+	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Collection<V> values() {
 		Collection<V> vs = values;
 		return ( vs != null ) ? vs : ( values = new Values() );
 	}
 
 	/**
 	 * Returns a {@link Set} view of the mappings contained in this map.
 	 * The set is backed by the map, so changes to the map are
 	 * reflected in the set, and vice-versa.  The set supports element
 	 * removal, which removes the corresponding mapping from the map,
 	 * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
 	 * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
 	 * operations.  It does not support the <tt>add</tt> or
 	 * <tt>addAll</tt> operations.
-	 *
+	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
-	 * that will never throw {@link ConcurrentModificationException},
+	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Set<Map.Entry<K, V>> entrySet() {
 		Set<Map.Entry<K, V>> es = entrySet;
 		return ( es != null ) ? es : ( entrySet = new EntrySet() );
 	}
 
 	/**
 	 * Returns an enumeration of the keys in this table.
 	 *
 	 * @return an enumeration of the keys in this table
 	 *
 	 * @see #keySet()
 	 */
 	public Enumeration<K> keys() {
 		return new KeyIterator();
 	}
 
 	/**
 	 * Returns an enumeration of the values in this table.
 	 *
 	 * @return an enumeration of the values in this table
 	 *
 	 * @see #values()
 	 */
 	public Enumeration<V> elements() {
 		return new ValueIterator();
 	}
 
 	/* ---------------- Iterator Support -------------- */
 
 	abstract class HashIterator {
 		int nextSegmentIndex;
 		int nextTableIndex;
 		HashEntry<K, V>[] currentTable;
 		HashEntry<K, V> nextEntry;
 		HashEntry<K, V> lastReturned;
 		K currentKey; // Strong reference to weak key (prevents gc)
 
 		HashIterator() {
 			nextSegmentIndex = segments.length - 1;
 			nextTableIndex = -1;
 			advance();
 		}
 
 		public boolean hasMoreElements() {
 			return hasNext();
 		}
 
 		final void advance() {
 			if ( nextEntry != null && ( nextEntry = nextEntry.next ) != null ) {
 				return;
 			}
 
 			while ( nextTableIndex >= 0 ) {
 				if ( ( nextEntry = currentTable[nextTableIndex--] ) != null ) {
 					return;
 				}
 			}
 
 			while ( nextSegmentIndex >= 0 ) {
 				Segment<K, V> seg = segments[nextSegmentIndex--];
 				if ( seg.count != 0 ) {
 					currentTable = seg.table;
 					for ( int j = currentTable.length - 1; j >= 0; --j ) {
 						if ( ( nextEntry = currentTable[j] ) != null ) {
 							nextTableIndex = j - 1;
 							return;
 						}
 					}
 				}
 			}
 		}
 
 		public boolean hasNext() {
 			while ( nextEntry != null ) {
 				if ( nextEntry.key() != null ) {
 					return true;
 				}
 				advance();
 			}
 
 			return false;
 		}
 
 		HashEntry<K, V> nextEntry() {
 			do {
 				if ( nextEntry == null ) {
 					throw new NoSuchElementException();
 				}
 
 				lastReturned = nextEntry;
 				currentKey = lastReturned.key();
 				advance();
 			} while ( currentKey == null ); // Skip GC'd keys
 
 			return lastReturned;
 		}
 
 		public void remove() {
 			if ( lastReturned == null ) {
 				throw new IllegalStateException();
 			}
 			ConcurrentReferenceHashMap.this.remove( currentKey );
 			lastReturned = null;
 		}
 	}
 
 	final class KeyIterator
 			extends HashIterator
 			implements Iterator<K>, Enumeration<K> {
 		@Override
 		public K next() {
 			return super.nextEntry().key();
 		}
 
 		@Override
 		public K nextElement() {
 			return super.nextEntry().key();
 		}
 	}
 
 	final class ValueIterator
 			extends HashIterator
 			implements Iterator<V>, Enumeration<V> {
 		@Override
 		public V next() {
 			return super.nextEntry().value();
 		}
 
 		@Override
 		public V nextElement() {
 			return super.nextEntry().value();
 		}
 	}
 
 	/*
 		  * This class is needed for JDK5 compatibility.
 		  */
 	static class SimpleEntry<K, V> implements Entry<K, V>,
-			java.io.Serializable {
+											  java.io.Serializable {
 		private static final long serialVersionUID = -8499721149061103585L;
 
 		private final K key;
 		private V value;
 
 		public SimpleEntry(K key, V value) {
 			this.key = key;
 			this.value = value;
 		}
 
 		public SimpleEntry(Entry<? extends K, ? extends V> entry) {
 			this.key = entry.getKey();
 			this.value = entry.getValue();
 		}
 
 		@Override
 		public K getKey() {
 			return key;
 		}
 
 		@Override
 		public V getValue() {
 			return value;
 		}
 
 		@Override
 		public V setValue(V value) {
 			V oldValue = this.value;
 			this.value = value;
 			return oldValue;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			@SuppressWarnings("unchecked")
 			Map.Entry e = (Map.Entry) o;
 			return eq( key, e.getKey() ) && eq( value, e.getValue() );
 		}
 
 		@Override
 		public int hashCode() {
 			return ( key == null ? 0 : key.hashCode() )
 					^ ( value == null ? 0 : value.hashCode() );
 		}
 
 		@Override
 		public String toString() {
 			return key + "=" + value;
 		}
 
 		private static boolean eq(Object o1, Object o2) {
 			return o1 == null ? o2 == null : o1.equals( o2 );
 		}
 	}
 
 
 	/**
 	 * Custom Entry class used by EntryIterator.next(), that relays setValue
 	 * changes to the underlying map.
 	 */
 	final class WriteThroughEntry extends SimpleEntry<K, V> {
 		private static final long serialVersionUID = -7900634345345313646L;
 
 		WriteThroughEntry(K k, V v) {
 			super( k, v );
 		}
 
 		/**
 		 * Set our entry's value and write through to the map. The
 		 * value to return is somewhat arbitrary here. Since a
 		 * WriteThroughEntry does not necessarily track asynchronous
 		 * changes, the most recent "previous" value could be
 		 * different from what we return (or could even have been
 		 * removed in which case the put will re-establish). We do not
 		 * and cannot guarantee more.
 		 */
 		@Override
 		public V setValue(V value) {
 			if ( value == null ) {
 				throw new NullPointerException();
 			}
 			V v = super.setValue( value );
 			ConcurrentReferenceHashMap.this.put( getKey(), value );
 			return v;
 		}
 	}
 
 	final class EntryIterator
 			extends HashIterator
 			implements Iterator<Entry<K, V>> {
 		@Override
 		public Map.Entry<K, V> next() {
 			HashEntry<K, V> e = super.nextEntry();
 			return new WriteThroughEntry( e.key(), e.value() );
 		}
 	}
 
 	final class KeySet extends AbstractSet<K> {
 		@Override
 		public Iterator<K> iterator() {
 			return new KeyIterator();
 		}
 
 		@Override
 		public int size() {
 			return ConcurrentReferenceHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return ConcurrentReferenceHashMap.this.isEmpty();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			return ConcurrentReferenceHashMap.this.containsKey( o );
 		}
 
 		@Override
 		public boolean remove(Object o) {
 			return ConcurrentReferenceHashMap.this.remove( o ) != null;
 		}
 
 		@Override
 		public void clear() {
 			ConcurrentReferenceHashMap.this.clear();
 		}
 	}
 
 	final class Values extends AbstractCollection<V> {
 		@Override
 		public Iterator<V> iterator() {
 			return new ValueIterator();
 		}
 
 		@Override
 		public int size() {
 			return ConcurrentReferenceHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return ConcurrentReferenceHashMap.this.isEmpty();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			return ConcurrentReferenceHashMap.this.containsValue( o );
 		}
 
 		@Override
 		public void clear() {
 			ConcurrentReferenceHashMap.this.clear();
 		}
 	}
 
 	final class EntrySet extends AbstractSet<Map.Entry<K, V>> {
 		@Override
 		public Iterator<Map.Entry<K, V>> iterator() {
 			return new EntryIterator();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;
 			V v = ConcurrentReferenceHashMap.this.get( e.getKey() );
 			return v != null && v.equals( e.getValue() );
 		}
 
 		@Override
 		public boolean remove(Object o) {
 			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;
 			return ConcurrentReferenceHashMap.this.remove( e.getKey(), e.getValue() );
 		}
 
 		@Override
 		public int size() {
 			return ConcurrentReferenceHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return ConcurrentReferenceHashMap.this.isEmpty();
 		}
 
 		@Override
 		public void clear() {
 			ConcurrentReferenceHashMap.this.clear();
 		}
 	}
 
 	/* ---------------- Serialization Support -------------- */
 
 	/**
 	 * Save the state of the <tt>ConcurrentReferenceHashMap</tt> instance to a
 	 * stream (i.e., serialize it).
 	 *
 	 * @param s the stream
 	 *
 	 * @serialData the key (Object) and value (Object)
 	 * for each key-value mapping, followed by a null pair.
 	 * The key-value mappings are emitted in no particular order.
 	 */
 	private void writeObject(java.io.ObjectOutputStream s) throws IOException {
 		s.defaultWriteObject();
 
 		for ( int k = 0; k < segments.length; ++k ) {
 			Segment<K, V> seg = segments[k];
 			seg.lock();
 			try {
 				HashEntry<K, V>[] tab = seg.table;
 				for ( int i = 0; i < tab.length; ++i ) {
 					for ( HashEntry<K, V> e = tab[i]; e != null; e = e.next ) {
 						K key = e.key();
 						if ( key == null ) {
 							// Skip GC'd keys
 							continue;
 						}
 
 						s.writeObject( key );
 						s.writeObject( e.value() );
 					}
 				}
 			}
 			finally {
 				seg.unlock();
 			}
 		}
 		s.writeObject( null );
 		s.writeObject( null );
 	}
 
 	/**
 	 * Reconstitute the <tt>ConcurrentReferenceHashMap</tt> instance from a
 	 * stream (i.e., deserialize it).
 	 *
 	 * @param s the stream
 	 */
 	@SuppressWarnings("unchecked")
 	private void readObject(java.io.ObjectInputStream s)
 			throws IOException, ClassNotFoundException {
 		s.defaultReadObject();
 
 		// Initialize each segment to be minimally sized, and let grow.
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].setTable( new HashEntry[1] );
 		}
 
 		// Read the keys and values, and put the mappings in the table
 		for (; ; ) {
 			K key = (K) s.readObject();
 			V value = (V) s.readObject();
 			if ( key == null ) {
 				break;
 			}
 			put( key, value );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/IdentityMap.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/IdentityMap.java
index ee24b54412..8b3c978204 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/IdentityMap.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/IdentityMap.java
@@ -1,269 +1,269 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util.collections;
 
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.Map;
 import java.util.Set;
 
 /**
  * A <tt>Map</tt> where keys are compared by object identity,
  * rather than <tt>equals()</tt>.
  */
 public final class IdentityMap<K,V> implements Map<K,V> {
 	private final Map<IdentityKey<K>,V> map;
 	@SuppressWarnings( {"unchecked"})
 	private transient Entry<IdentityKey<K>,V>[] entryArray = new Entry[0];
 	private transient boolean dirty;
 
 	/**
 	 * Return a new instance of this class, with iteration
 	 * order defined as the order in which entries were added
 	 *
 	 * @param size The size of the map to create
 	 * @return The map
 	 */
 	public static <K,V> IdentityMap<K,V> instantiateSequenced(int size) {
 		return new IdentityMap<K,V>( new LinkedHashMap<IdentityKey<K>,V>( size ) );
 	}
 
 	/**
 	 * Private ctor used in serialization.
 	 *
 	 * @param underlyingMap The delegate map.
 	 */
 	private IdentityMap(Map<IdentityKey<K>,V> underlyingMap) {
 		map = underlyingMap;
 		dirty = true;
 	}
 
 	/**
 	 * Return the map entries (as instances of <tt>Map.Entry</tt> in a collection that
 	 * is safe from concurrent modification). ie. we may safely add new instances to
 	 * the underlying <tt>Map</tt> during iteration of the <tt>entries()</tt>.
 	 *
 	 * @param map The map of entries
 	 * @return Collection
 	 */
 	public static <K,V> Map.Entry<K,V>[] concurrentEntries(Map<K,V> map) {
 		return ( (IdentityMap<K,V>) map ).entryArray();
 	}
 
 	public Iterator<K> keyIterator() {
 		return new KeyIterator<K>( map.keySet().iterator() );
 	}
 
 	@Override
 	public int size() {
 		return map.size();
 	}
 
 	@Override
 	public boolean isEmpty() {
 		return map.isEmpty();
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public boolean containsKey(Object key) {
 		return map.containsKey( new IdentityKey( key ) );
 	}
 
 	@Override
 	public boolean containsValue(Object val) {
 		return map.containsValue(val);
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public V get(Object key) {
 		return map.get( new IdentityKey(key) );
 	}
 
 	@Override
 	public V put(K key, V value) {
 		dirty = true;
 		return map.put( new IdentityKey<K>(key), value );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public V remove(Object key) {
 		dirty = true;
 		return map.remove( new IdentityKey(key) );
 	}
 
 	@Override
 	public void putAll(Map<? extends K, ? extends V> otherMap) {
 		for ( Entry<? extends K, ? extends V> entry : otherMap.entrySet() ) {
 			put( entry.getKey(), entry.getValue() );
 		}
 	}
 
 	@Override
 	public void clear() {
 		dirty = true;
 		entryArray = null;
 		map.clear();
 	}
 
 	@Override
 	public Set<K> keySet() {
 		// would need an IdentitySet for this!
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public Collection<V> values() {
 		return map.values();
 	}
 
 	@Override
 	public Set<Entry<K,V>> entrySet() {
 		Set<Entry<K,V>> set = new HashSet<Entry<K,V>>( map.size() );
 		for ( Entry<IdentityKey<K>, V> entry : map.entrySet() ) {
 			set.add( new IdentityMapEntry<K,V>( entry.getKey().getRealKey(), entry.getValue() ) );
 		}
 		return set;
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public Map.Entry[] entryArray() {
 		if (dirty) {
 			entryArray = new Map.Entry[ map.size() ];
 			Iterator itr = map.entrySet().iterator();
 			int i=0;
 			while ( itr.hasNext() ) {
 				Map.Entry me = (Map.Entry) itr.next();
 				entryArray[i++] = new IdentityMapEntry( ( (IdentityKey) me.getKey() ).key, me.getValue() );
 			}
 			dirty = false;
 		}
 		return entryArray;
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return map.toString();
 	}
 
 	static final class KeyIterator<K> implements Iterator<K> {
 		private final Iterator<IdentityKey<K>> identityKeyIterator;
 
 		private KeyIterator(Iterator<IdentityKey<K>> iterator) {
 			identityKeyIterator = iterator;
 		}
 
 		public boolean hasNext() {
 			return identityKeyIterator.hasNext();
 		}
 
 		public K next() {
 			return identityKeyIterator.next().getRealKey();
 		}
 
 		public void remove() {
 			throw new UnsupportedOperationException();
 		}
 
 	}
 		public static final class IdentityMapEntry<K,V> implements java.util.Map.Entry<K,V> {
 		private final K key;
 		private V value;
 
 		IdentityMapEntry(final K key, final V value) {
 			this.key=key;
 			this.value=value;
 		}
 
 		public K getKey() {
 			return key;
 		}
 
 		public V getValue() {
 			return value;
 		}
 
 		public V setValue(final V value) {
 			V result = this.value;
 			this.value = value;
 			return result;
 		}
 	}
 
 	/**
 	 * We need to base the identity on {@link System#identityHashCode(Object)} but
 	 * attempt to lazily initialize and cache this value: being a native invocation
 	 * it is an expensive value to retrieve.
 	 */
 	public static final class IdentityKey<K> implements Serializable {
 
 		private final K key;
 		private int hash;
 
 		IdentityKey(K key) {
 			this.key = key;
 		}
 
 		@SuppressWarnings( {"EqualsWhichDoesntCheckParameterClass"})
 		@Override
 		public boolean equals(Object other) {
 			return key == ( (IdentityKey) other ).key;
 		}
 
 		@Override
 		public int hashCode() {
 			if ( this.hash == 0 ) {
 				//We consider "zero" as non-initialized value
 				final int newHash = System.identityHashCode( key );
 				if ( newHash == 0 ) {
 					//So make sure we don't store zeros as it would trigger initialization again:
 					//any value is fine as long as we're deterministic.
 					this.hash = -1;
 					return -1;
 				}
 				else {
 					this.hash = newHash;
 					return newHash;
 				}
 			}
 			return hash;
 		}
 
 		@Override
 		public String toString() {
 			return key.toString();
 		}
 
 		public K getRealKey() {
 			return key;
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java b/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
index cb3ed17598..23bb177450 100644
--- a/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
+++ b/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
@@ -1,202 +1,204 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.jdbc;
 
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.hibernate.HibernateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.exception.GenericJDBCException;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
-import org.jboss.logging.Logger;
-
 /**
  * Holds various often used {@link Expectation} definitions.
  *
  * @author Steve Ebersole
  */
 public class Expectations {
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( Expectations.class );
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Expectations.class.getName());
 	private static SqlExceptionHelper sqlExceptionHelper = new SqlExceptionHelper();
 
 	public static final int USUAL_EXPECTED_COUNT = 1;
 	public static final int USUAL_PARAM_POSITION = 1;
 
 
 	// Base Expectation impls ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public static class BasicExpectation implements Expectation {
 		private final int expectedRowCount;
 
 		protected BasicExpectation(int expectedRowCount) {
 			this.expectedRowCount = expectedRowCount;
 			if ( expectedRowCount < 0 ) {
 				throw new IllegalArgumentException( "Expected row count must be greater than zero" );
 			}
 		}
 
 		public final void verifyOutcome(int rowCount, PreparedStatement statement, int batchPosition) {
 			rowCount = determineRowCount( rowCount, statement );
 			if ( batchPosition < 0 ) {
 				checkNonBatched( rowCount );
 			}
 			else {
 				checkBatched( rowCount, batchPosition );
 			}
 		}
 
 		private void checkBatched(int rowCount, int batchPosition) {
-            if (rowCount == -2) {
-				LOG.debugf("Success of batch update unknown: %s", batchPosition);
+			if ( rowCount == -2 ) {
+				LOG.debugf( "Success of batch update unknown: %s", batchPosition );
 			}
-            else if (rowCount == -3) {
-				throw new BatchFailedException("Batch update failed: " + batchPosition);
+			else if ( rowCount == -3 ) {
+				throw new BatchFailedException( "Batch update failed: " + batchPosition );
 			}
 			else {
-                if (expectedRowCount > rowCount) {
+				if ( expectedRowCount > rowCount ) {
 					throw new StaleStateException(
 							"Batch update returned unexpected row count from update ["
 									+ batchPosition + "]; actual row count: " + rowCount
 									+ "; expected: " + expectedRowCount
 					);
 				}
 				if ( expectedRowCount < rowCount ) {
 					String msg = "Batch update returned unexpected row count from update [" +
-					             batchPosition + "]; actual row count: " + rowCount +
-					             "; expected: " + expectedRowCount;
+							batchPosition + "]; actual row count: " + rowCount +
+							"; expected: " + expectedRowCount;
 					throw new BatchedTooManyRowsAffectedException( msg, expectedRowCount, rowCount, batchPosition );
 				}
 			}
 		}
 
 		private void checkNonBatched(int rowCount) {
 			if ( expectedRowCount > rowCount ) {
 				throw new StaleStateException(
 						"Unexpected row count: " + rowCount + "; expected: " + expectedRowCount
 				);
 			}
 			if ( expectedRowCount < rowCount ) {
 				String msg = "Unexpected row count: " + rowCount + "; expected: " + expectedRowCount;
 				throw new TooManyRowsAffectedException( msg, expectedRowCount, rowCount );
 			}
 		}
 
 		public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
 			return 0;
 		}
 
 		public boolean canBeBatched() {
 			return true;
 		}
 
 		protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
 			return reportedRowCount;
 		}
 	}
 
 	public static class BasicParamExpectation extends BasicExpectation {
 		private final int parameterPosition;
+
 		protected BasicParamExpectation(int expectedRowCount, int parameterPosition) {
 			super( expectedRowCount );
 			this.parameterPosition = parameterPosition;
 		}
 
 		@Override
-        public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
+		public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
 			toCallableStatement( statement ).registerOutParameter( parameterPosition, Types.NUMERIC );
 			return 1;
 		}
 
 		@Override
-        public boolean canBeBatched() {
+		public boolean canBeBatched() {
 			return false;
 		}
 
 		@Override
-        protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
+		protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
 			try {
 				return toCallableStatement( statement ).getInt( parameterPosition );
 			}
-			catch( SQLException sqle ) {
+			catch (SQLException sqle) {
 				sqlExceptionHelper.logExceptions( sqle, "could not extract row counts from CallableStatement" );
 				throw new GenericJDBCException( "could not extract row counts from CallableStatement", sqle );
 			}
 		}
 
 		private CallableStatement toCallableStatement(PreparedStatement statement) {
-			if ( ! CallableStatement.class.isInstance( statement ) ) {
-				throw new HibernateException( "BasicParamExpectation operates exclusively on CallableStatements : " + statement.getClass() );
+			if ( !CallableStatement.class.isInstance( statement ) ) {
+				throw new HibernateException(
+						"BasicParamExpectation operates exclusively on CallableStatements : " + statement.getClass()
+				);
 			}
-			return ( CallableStatement ) statement;
+			return (CallableStatement) statement;
 		}
 	}
 
 
 	// Various Expectation instances ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public static final Expectation NONE = new Expectation() {
 		public void verifyOutcome(int rowCount, PreparedStatement statement, int batchPosition) {
 			// explicitly doAfterTransactionCompletion no checking...
 		}
 
 		public int prepare(PreparedStatement statement) {
 			return 0;
 		}
 
 		public boolean canBeBatched() {
 			return true;
 		}
 	};
 
 	public static final Expectation BASIC = new BasicExpectation( USUAL_EXPECTED_COUNT );
 
 	public static final Expectation PARAM = new BasicParamExpectation( USUAL_EXPECTED_COUNT, USUAL_PARAM_POSITION );
 
 
 	public static Expectation appropriateExpectation(ExecuteUpdateResultCheckStyle style) {
 		if ( style == ExecuteUpdateResultCheckStyle.NONE ) {
 			return NONE;
 		}
 		else if ( style == ExecuteUpdateResultCheckStyle.COUNT ) {
 			return BASIC;
 		}
 		else if ( style == ExecuteUpdateResultCheckStyle.PARAM ) {
 			return PARAM;
 		}
 		else {
 			throw new HibernateException( "unknown check style : " + style );
 		}
 	}
 
 	private Expectations() {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/jdbc/Work.java b/hibernate-core/src/main/java/org/hibernate/jdbc/Work.java
index 2e768dbe20..df92dbe525 100644
--- a/hibernate-core/src/main/java/org/hibernate/jdbc/Work.java
+++ b/hibernate-core/src/main/java/org/hibernate/jdbc/Work.java
@@ -1,45 +1,44 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.jdbc;
+
 import java.sql.Connection;
 import java.sql.SQLException;
 
-import org.hibernate.HibernateException;
-
 /**
  * Contract for performing a discrete piece of JDBC work.
  *
  * @author Steve Ebersole
  */
 public interface Work {
 	/**
 	 * Execute the discrete work encapsulated by this work instance using the supplied connection.
 	 *
 	 * @param connection The connection on which to perform the work.
+	 *
 	 * @throws SQLException Thrown during execution of the underlying JDBC interaction.
-	 * @throws HibernateException Generally indicates a wrapped SQLException.
+	 * @throws org.hibernate.HibernateException Generally indicates a wrapped SQLException.
 	 */
-	public void execute(Connection connection) throws SQLException;
+	void execute(Connection connection) throws SQLException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/jmx/internal/JmxServiceImpl.java b/hibernate-core/src/main/java/org/hibernate/jmx/internal/JmxServiceImpl.java
index 2502a3b33b..5c39197ba9 100644
--- a/hibernate-core/src/main/java/org/hibernate/jmx/internal/JmxServiceImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/jmx/internal/JmxServiceImpl.java
@@ -1,212 +1,211 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jmx.internal;
 
 import java.lang.management.ManagementFactory;
 import java.util.ArrayList;
 import java.util.Map;
 import javax.management.MBeanServer;
 import javax.management.MBeanServerFactory;
 import javax.management.MalformedObjectNameException;
 import javax.management.ObjectName;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jmx.spi.JmxService;
 import org.hibernate.service.Service;
 import org.hibernate.service.spi.Manageable;
 import org.hibernate.service.spi.Stoppable;
 
-import org.jboss.logging.Logger;
-
 /**
  * Standard implementation of JMX services
  *
  * @author Steve Ebersole
  */
 public class JmxServiceImpl implements JmxService, Stoppable {
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JmxServiceImpl.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( JmxServiceImpl.class );
 
 	public static final String OBJ_NAME_TEMPLATE = "%s:sessionFactory=%s,serviceRole=%s,serviceType=%s";
 
 	private final boolean usePlatformServer;
 	private final String agentId;
 	private final String defaultDomain;
 	private final String sessionFactoryName;
 
 	public JmxServiceImpl(Map configValues) {
 		usePlatformServer = ConfigurationHelper.getBoolean( AvailableSettings.JMX_PLATFORM_SERVER, configValues );
 		agentId = (String) configValues.get( AvailableSettings.JMX_AGENT_ID );
 		defaultDomain = (String) configValues.get( AvailableSettings.JMX_DOMAIN_NAME );
 		sessionFactoryName = ConfigurationHelper.getString(
 				AvailableSettings.JMX_SF_NAME,
 				configValues,
 				ConfigurationHelper.getString( Environment.SESSION_FACTORY_NAME, configValues )
 		);
 	}
 
 	private boolean startedServer;
 	private ArrayList<ObjectName> registeredMBeans;
 
 	@Override
 	public void stop() {
 		try {
 			// if we either started the JMX server or we registered some MBeans we at least need to look up
 			// MBean server and do *some* work on shutdown.
 			if ( startedServer || registeredMBeans != null ) {
 				MBeanServer mBeanServer = findServer();
 				if ( mBeanServer == null ) {
 					LOG.unableToLocateMBeanServer();
 					return;
 				}
 
 				// release any MBeans we registered
 				if ( registeredMBeans != null ) {
 					for ( ObjectName objectName : registeredMBeans ) {
 						try {
 							LOG.tracev( "Unregistering registered MBean [ON={0}]", objectName );
 							mBeanServer.unregisterMBean( objectName );
 						}
 						catch ( Exception e ) {
 							LOG.debugf( "Unable to unregsiter registered MBean [ON=%s] : %s", objectName, e.toString() );
 						}
 					}
 				}
 
 				// stop the MBean server if we started it
 				if ( startedServer ) {
 					LOG.trace( "Attempting to release created MBeanServer" );
 					try {
 						MBeanServerFactory.releaseMBeanServer( mBeanServer );
 					}
 					catch ( Exception e ) {
 						LOG.unableToReleaseCreatedMBeanServer( e.toString() );
 					}
 				}
 			}
 		}
 		finally {
 			startedServer = false;
 			if ( registeredMBeans != null ) {
 				registeredMBeans.clear();
 				registeredMBeans = null;
 			}
 		}
 	}
 
 
 	// todo : should serviceRole come first in ObjectName template?  depends on the groupings we want in the UI.
 	// 		as-is mbeans from each sessionFactory are grouped primarily.
 
 	@Override
 	public void registerService(Manageable service, Class<? extends Service> serviceRole) {
 		final String domain = service.getManagementDomain() == null
 				? AvailableSettings.JMX_DEFAULT_OBJ_NAME_DOMAIN
 				: service.getManagementDomain();
 		final String serviceType = service.getManagementServiceType() == null
 				? service.getClass().getName()
 				: service.getManagementServiceType();
 		try {
 			final ObjectName objectName = new ObjectName(
 					String.format(
 							OBJ_NAME_TEMPLATE,
 							domain,
 							sessionFactoryName,
 							serviceRole.getName(),
 							serviceType
 					)
 			);
 			registerMBean( objectName, service.getManagementBean() );
 		}
 		catch ( MalformedObjectNameException e ) {
 			throw new HibernateException( "Unable to generate service IbjectName", e );
 		}
 	}
 
 	@Override
 	public void registerMBean(ObjectName objectName, Object mBean) {
 		MBeanServer mBeanServer = findServer();
 		if ( mBeanServer == null ) {
 			if ( startedServer ) {
 				throw new HibernateException( "Could not locate previously started MBeanServer" );
 			}
 			mBeanServer = startMBeanServer();
 			startedServer = true;
 		}
 
 		try {
 			mBeanServer.registerMBean( mBean, objectName );
 			if ( registeredMBeans == null ) {
 				registeredMBeans = new ArrayList<ObjectName>();
 			}
 			registeredMBeans.add( objectName );
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Unable to register MBean [ON=" + objectName + "]", e );
 		}
 	}
 
 	/**
 	 * Locate the MBean server to use based on user input from startup.
 	 *
 	 * @return The MBean server to use.
 	 */
 	private MBeanServer findServer() {
 		if ( usePlatformServer ) {
 			// they specified to use the platform (vm) server
 			return ManagementFactory.getPlatformMBeanServer();
 		}
 
 		// otherwise lookup all servers by (optional) agentId.
 		// IMPL NOTE : the findMBeanServer call treats a null agentId to mean match all...
 		ArrayList<MBeanServer> mbeanServers = MBeanServerFactory.findMBeanServer( agentId );
 
 		if ( defaultDomain == null ) {
 			// they did not specify a domain by which to locate a particular MBeanServer to use, so chose the first
 			return mbeanServers.get( 0 );
 		}
 
 		for ( MBeanServer mbeanServer : mbeanServers ) {
 			// they did specify a domain, so attempt to locate an MBEanServer with a matching default domain, returning it
 			// if we find it.
 			if ( defaultDomain.equals( mbeanServer.getDefaultDomain() ) ) {
 				return mbeanServer;
 			}
 		}
 
 		return null;
 	}
 
 	private MBeanServer startMBeanServer() {
 		try {
 			return MBeanServerFactory.createMBeanServer( defaultDomain );
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Unable to start MBeanServer", e );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/AbstractEntityJoinWalker.java b/hibernate-core/src/main/java/org/hibernate/loader/AbstractEntityJoinWalker.java
index fa56e08fed..a42dde60c6 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/AbstractEntityJoinWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/AbstractEntityJoinWalker.java
@@ -1,220 +1,219 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
 import org.hibernate.FetchMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.Select;
 import org.hibernate.type.AssociationType;
 
 /**
  * Abstract walker for walkers which begin at an entity (criteria
  * queries and entity loaders).
  *
  * @author Gavin King
  */
 public abstract class AbstractEntityJoinWalker extends JoinWalker {
-
 	private final OuterJoinLoadable persister;
 	private final String alias;
 
 	public AbstractEntityJoinWalker(
 			OuterJoinLoadable persister,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		this( persister, factory, loadQueryInfluencers, null );
 	}
 
 	public AbstractEntityJoinWalker(
 			OuterJoinLoadable persister,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers,
 			String alias) {
 		super( factory, loadQueryInfluencers );
 		this.persister = persister;
 		this.alias = ( alias == null ) ? generateRootAlias( persister.getEntityName() ) : alias;
 	}
 
 	protected final void initAll(
 			final String whereString,
 			final String orderByString,
 			final LockOptions lockOptions) throws MappingException {
 		initAll( whereString, orderByString, lockOptions, AssociationInitCallback.NO_CALLBACK );
 	}
 
 	protected final void initAll(
 			final String whereString,
 			final String orderByString,
 			final LockOptions lockOptions,
 			final AssociationInitCallback callback) throws MappingException {
 		walkEntityTree( persister, getAlias() );
 		List allAssociations = new ArrayList();
 		allAssociations.addAll( associations );
 		allAssociations.add( OuterJoinableAssociation.createRoot( persister.getEntityType(), alias, getFactory() ) );
 		initPersisters( allAssociations, lockOptions, callback );
 		initStatementString( whereString, orderByString, lockOptions );
 	}
 
 	protected final void initProjection(
 			final String projectionString,
 			final String whereString,
 			final String orderByString,
 			final String groupByString,
 			final LockOptions lockOptions) throws MappingException {
 		walkEntityTree( persister, getAlias() );
 		persisters = new Loadable[0];
 		initStatementString(projectionString, whereString, orderByString, groupByString, lockOptions);
 	}
 
 	private void initStatementString(
 			final String condition,
 			final String orderBy,
 			final LockOptions lockOptions) throws MappingException {
 		initStatementString(null, condition, orderBy, "", lockOptions);
 	}
 
 	private void initStatementString(
 			final String projection,
 			final String condition,
 			final String orderBy,
 			final String groupBy,
 			final LockOptions lockOptions) throws MappingException {
 
 		final int joins = countEntityPersisters( associations );
 		suffixes = BasicLoader.generateSuffixes( joins + 1 );
 
 		JoinFragment ojf = mergeOuterJoins( associations );
 
 		Select select = new Select( getDialect() )
 				.setLockOptions( lockOptions )
 				.setSelectClause(
 						projection == null ?
 								persister.selectFragment( alias, suffixes[joins] ) + selectString( associations ) :
 								projection
 				)
 				.setFromClause(
 						getDialect().appendLockHint( lockOptions, persister.fromTableFragment( alias ) ) +
 								persister.fromJoinFragment( alias, true, true )
 				)
 				.setWhereClause( condition )
 				.setOuterJoins(
 						ojf.toFromFragmentString(),
 						ojf.toWhereFragmentString() + getWhereFragment()
 				)
 				.setOrderByClause( orderBy( associations, orderBy ) )
 				.setGroupByClause( groupBy );
 
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( getComment() );
 		}
 		sql = select.toStatementString();
 	}
 
 	protected String getWhereFragment() throws MappingException {
 		// here we do not bother with the discriminator.
 		return persister.whereJoinFragment(alias, true, true);
 	}
 
 	/**
 	 * The superclass deliberately excludes collections
 	 */
 	protected boolean isJoinedFetchEnabled(AssociationType type, FetchMode config, CascadeStyle cascadeStyle) {
 		return isJoinedFetchEnabledInMapping( config, type );
 	}
 
 	protected final boolean isJoinFetchEnabledByProfile(OuterJoinLoadable persister, PropertyPath path, int propertyNumber) {
 		if ( !getLoadQueryInfluencers().hasEnabledFetchProfiles() ) {
 			// perf optimization
 			return false;
 		}
 
 		// ugh, this stuff has to be made easier...
 		final String fullPath = path.getFullPath();
 		String rootPropertyName = persister.getSubclassPropertyName( propertyNumber );
 		int pos = fullPath.lastIndexOf( rootPropertyName );
 		String relativePropertyPath = pos >= 0
 				? fullPath.substring( pos )
 				: rootPropertyName;
 		String fetchRole = persister.getEntityName() + "." + relativePropertyPath;
 
 		for ( String profileName : getLoadQueryInfluencers().getEnabledFetchProfileNames() ) {
 			final FetchProfile profile = getFactory().getFetchProfile( profileName );
 			final Fetch fetch = profile.getFetchByRole( fetchRole );
 			if ( fetch != null && Fetch.Style.JOIN == fetch.getStyle() ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	public abstract String getComment();
 
 	@Override
-    protected boolean isDuplicateAssociation(final String foreignKeyTable, final String[] foreignKeyColumns) {
+	protected boolean isDuplicateAssociation(final String foreignKeyTable, final String[] foreignKeyColumns) {
 		//disable a join back to this same association
 		final boolean isSameJoin =
 				persister.getTableName().equals( foreignKeyTable ) &&
 						Arrays.equals( foreignKeyColumns, persister.getKeyColumnNames() );
 		return isSameJoin ||
 			super.isDuplicateAssociation(foreignKeyTable, foreignKeyColumns);
 	}
 
 
 
 	public final Loadable getPersister() {
 		return persister;
 	}
 
 	public final String getAlias() {
 		return alias;
 	}
 	
 	/**
 	 * For entities, orderings added by, for example, Criteria#addOrder need to come before the associations' @OrderBy
 	 * values.  However, other sub-classes of JoinWalker (BasicCollectionJoinWalker, OneToManyJoinWalker, etc.)
 	 * still need the other way around.  So, override here instead.  See HHH-7116.
 	 */
 	@Override
 	protected String orderBy(final List associations, final String orderBy) {
 		return mergeOrderings( orderBy, orderBy( associations ) );
 	}
 
 	public String toString() {
 		return getClass().getName() + '(' + getPersister().getEntityName() + ')';
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java b/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
index 4e02985dd3..76de310e7e 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
@@ -1,159 +1,160 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader;
+
 import java.util.Collections;
 import java.util.Map;
 
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 
 /**
  * CollectionAliases which handles the logic of selecting user provided aliases (via return-property),
- * before using the default aliases. 
+ * before using the default aliases.
  *
  * @author Steve Ebersole
  * @author Max Rydahl Andersen
  */
 public class GeneratedCollectionAliases implements CollectionAliases {
 	private final String suffix;
 	private final String[] keyAliases;
 	private final String[] indexAliases;
 	private final String[] elementAliases;
 	private final String identifierAlias;
 	private Map userProvidedAliases;
-	
+
 	public GeneratedCollectionAliases(Map userProvidedAliases, CollectionPersister persister, String suffix) {
 		this.suffix = suffix;
 		this.userProvidedAliases = userProvidedAliases;
 
 		this.keyAliases = getUserProvidedAliases(
-				"key", 
+				"key",
 				persister.getKeyColumnAliases( suffix )
 		);
 
 		this.indexAliases = getUserProvidedAliases(
 				"index",
 				persister.getIndexColumnAliases( suffix )
 		);
-		
+
 		this.elementAliases = getUserProvidedAliases(
 				"element",
 				persister.getElementColumnAliases( suffix )
 		);
-				
+
 		this.identifierAlias = getUserProvidedAlias(
 				"id",
 				persister.getIdentifierColumnAlias( suffix )
 		);
 	}
 
 	public GeneratedCollectionAliases(CollectionPersister persister, String string) {
-		this( Collections.EMPTY_MAP, persister, string);
+		this( Collections.EMPTY_MAP, persister, string );
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for columns making up the key for this collection (i.e., its FK to
 	 * its owner).
 	 *
 	 * @return The key result-set column aliases.
 	 */
 	public String[] getSuffixedKeyAliases() {
 		return keyAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the collumns making up the collection's index (map or list).
 	 *
 	 * @return The index result-set column aliases.
 	 */
 	public String[] getSuffixedIndexAliases() {
 		return indexAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the columns making up the collection's elements.
 	 *
 	 * @return The element result-set column aliases.
 	 */
 	public String[] getSuffixedElementAliases() {
 		return elementAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the column defining the collection's identifier (if any).
 	 *
 	 * @return The identifier result-set column aliases.
 	 */
 	public String getSuffixedIdentifierAlias() {
 		return identifierAlias;
 	}
 
 	/**
 	 * Returns the suffix used to unique the column aliases for this particular alias set.
 	 *
 	 * @return The uniqued column alias suffix.
 	 */
 	public String getSuffix() {
 		return suffix;
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return super.toString() + " [suffix=" + suffix +
-		        ", suffixedKeyAliases=[" + join( keyAliases ) +
-		        "], suffixedIndexAliases=[" + join( indexAliases ) +
-		        "], suffixedElementAliases=[" + join( elementAliases ) +
-		        "], suffixedIdentifierAlias=[" + identifierAlias + "]]";
+				", suffixedKeyAliases=[" + join( keyAliases ) +
+				"], suffixedIndexAliases=[" + join( indexAliases ) +
+				"], suffixedElementAliases=[" + join( elementAliases ) +
+				"], suffixedIdentifierAlias=[" + identifierAlias + "]]";
 	}
 
 	private String join(String[] aliases) {
-		if ( aliases == null) {
+		if ( aliases == null ) {
 			return null;
 		}
 
 		return StringHelper.join( ", ", aliases );
 	}
-	
+
 	private String[] getUserProvidedAliases(String propertyPath, String[] defaultAliases) {
-		String[] result = (String[]) userProvidedAliases.get(propertyPath);
-		if (result==null) {
-			return defaultAliases;			
-		} 
+		String[] result = (String[]) userProvidedAliases.get( propertyPath );
+		if ( result == null ) {
+			return defaultAliases;
+		}
 		else {
 			return result;
 		}
 	}
 
 	private String getUserProvidedAlias(String propertyPath, String defaultAlias) {
-		String[] columns = (String[]) userProvidedAliases.get(propertyPath);
-		if (columns==null) {
+		String[] columns = (String[]) userProvidedAliases.get( propertyPath );
+		if ( columns == null ) {
 			return defaultAlias;
-		} 
+		}
 		else {
 			return columns[0];
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java b/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
index 0330161811..710cfd861d 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
@@ -1,1134 +1,1148 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
+
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.FetchMode;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.sql.ConditionFragment;
 import org.hibernate.sql.DisjunctionFragment;
 import org.hibernate.sql.InFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.ForeignKeyDirection;
 import org.hibernate.type.Type;
 
 /**
  * Walks the metamodel, searching for joins, and collecting
  * together information needed by <tt>OuterJoinLoader</tt>.
- * 
- * @see OuterJoinLoader
+ *
  * @author Gavin King, Jon Lipsky
+ * @see OuterJoinLoader
  */
 public class JoinWalker {
-	
+
 	private final SessionFactoryImplementor factory;
 	protected final List associations = new ArrayList();
 	private final Set visitedAssociationKeys = new HashSet();
 	private final LoadQueryInfluencers loadQueryInfluencers;
 
 	protected String[] suffixes;
 	protected String[] collectionSuffixes;
 	protected Loadable[] persisters;
 	protected int[] owners;
 	protected EntityType[] ownerAssociationTypes;
 	protected CollectionPersister[] collectionPersisters;
 	protected int[] collectionOwners;
 	protected String[] aliases;
 	protected LockOptions lockOptions;
 	protected LockMode[] lockModeArray;
 	protected String sql;
 
 	protected JoinWalker(
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		this.factory = factory;
 		this.loadQueryInfluencers = loadQueryInfluencers;
 
 	}
 
 	public List getAssociations() {
 		return Collections.unmodifiableList( associations );
 	}
 
 	public String[] getCollectionSuffixes() {
 		return collectionSuffixes;
 	}
 
 	public void setCollectionSuffixes(String[] collectionSuffixes) {
 		this.collectionSuffixes = collectionSuffixes;
 	}
 
 	public LockOptions getLockModeOptions() {
 		return lockOptions;
 	}
 
 	public LockMode[] getLockModeArray() {
 		return lockModeArray;
 	}
 
 	public String[] getSuffixes() {
 		return suffixes;
 	}
 
 	public void setSuffixes(String[] suffixes) {
 		this.suffixes = suffixes;
 	}
 
 	public String[] getAliases() {
 		return aliases;
 	}
 
 	public void setAliases(String[] aliases) {
 		this.aliases = aliases;
 	}
 
 	public int[] getCollectionOwners() {
 		return collectionOwners;
 	}
 
 	public void setCollectionOwners(int[] collectionOwners) {
 		this.collectionOwners = collectionOwners;
 	}
 
 	public CollectionPersister[] getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	public void setCollectionPersisters(CollectionPersister[] collectionPersisters) {
 		this.collectionPersisters = collectionPersisters;
 	}
 
 	public EntityType[] getOwnerAssociationTypes() {
 		return ownerAssociationTypes;
 	}
 
 	public void setOwnerAssociationTypes(EntityType[] ownerAssociationType) {
 		this.ownerAssociationTypes = ownerAssociationType;
 	}
 
 	public int[] getOwners() {
 		return owners;
 	}
 
 	public void setOwners(int[] owners) {
 		this.owners = owners;
 	}
 
 	public Loadable[] getPersisters() {
 		return persisters;
 	}
 
 	public void setPersisters(Loadable[] persisters) {
 		this.persisters = persisters;
 	}
 
 	public String getSQLString() {
 		return sql;
 	}
 
 	public void setSql(String sql) {
 		this.sql = sql;
 	}
 
 	protected SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	protected Dialect getDialect() {
 		return factory.getDialect();
 	}
 
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return loadQueryInfluencers;
 	}
 
 	/**
-	 * Add on association (one-to-one, many-to-one, or a collection) to a list 
+	 * Add on association (one-to-one, many-to-one, or a collection) to a list
 	 * of associations to be fetched by outerjoin (if necessary)
 	 */
 	private void addAssociationToJoinTreeIfNecessary(
 			final AssociationType type,
 			final String[] aliasedLhsColumns,
 			final String alias,
 			final PropertyPath path,
 			int currentDepth,
 			final JoinType joinType) throws MappingException {
 		if ( joinType != JoinType.NONE ) {
 			addAssociationToJoinTree(
-					type, 
-					aliasedLhsColumns, 
-					alias, 
+					type,
+					aliasedLhsColumns,
+					alias,
 					path,
 					currentDepth,
 					joinType
 			);
 		}
 	}
 
-	protected boolean hasRestriction(PropertyPath path)	{
+	protected boolean hasRestriction(PropertyPath path) {
 		return false;
 	}
 
-	protected String getWithClause(PropertyPath path)	{
+	protected String getWithClause(PropertyPath path) {
 		return "";
 	}
-	
+
 	/**
-	 * Add on association (one-to-one, many-to-one, or a collection) to a list 
-	 * of associations to be fetched by outerjoin 
+	 * Add on association (one-to-one, many-to-one, or a collection) to a list
+	 * of associations to be fetched by outerjoin
 	 */
 	private void addAssociationToJoinTree(
 			final AssociationType type,
 			final String[] aliasedLhsColumns,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth,
 			final JoinType joinType) throws MappingException {
 
 		Joinable joinable = type.getAssociatedJoinable( getFactory() );
 
 		// important to generate alias based on size of association collection
 		// *before* adding this join to that collection
 		String subalias = generateTableAlias( associations.size() + 1, path, joinable );
 
 		// NOTE : it should be fine to continue to pass only filters below
 		// (instead of LoadQueryInfluencers) since "from that point on" we
 		// only need to worry about restrictions (and not say adding more
 		// joins)
 		OuterJoinableAssociation assoc = new OuterJoinableAssociation(
 				path,
-				type, 
-				alias, 
-				aliasedLhsColumns, 
-				subalias, 
-				joinType, 
-				getWithClause(path),
+				type,
+				alias,
+				aliasedLhsColumns,
+				subalias,
+				joinType,
+				getWithClause( path ),
 				hasRestriction( path ),
 				getFactory(),
 				loadQueryInfluencers.getEnabledFilters()
 		);
 		assoc.validateJoin( path.getFullPath() );
 		associations.add( assoc );
 
 		int nextDepth = currentDepth + 1;
 //		path = "";
 		if ( !joinable.isCollection() ) {
-			if (joinable instanceof OuterJoinLoadable) {
+			if ( joinable instanceof OuterJoinLoadable ) {
 				walkEntityTree(
-					(OuterJoinLoadable) joinable, 
-					subalias,
-					path, 
-					nextDepth
+						(OuterJoinLoadable) joinable,
+						subalias,
+						path,
+						nextDepth
 				);
 			}
 		}
 		else {
-			if (joinable instanceof QueryableCollection) {
+			if ( joinable instanceof QueryableCollection ) {
 				walkCollectionTree(
-					(QueryableCollection) joinable, 
-					subalias, 
-					path, 
-					nextDepth
+						(QueryableCollection) joinable,
+						subalias,
+						path,
+						nextDepth
 				);
 			}
 		}
 
 	}
 
 	/**
 	 * Walk the association tree for an entity, adding associations which should
 	 * be join fetched to the {@link #associations} inst var.  This form is the
 	 * entry point into the walking for a given entity, starting the recursive
-	 * calls into {@link #walkEntityTree(org.hibernate.persister.entity.OuterJoinLoadable, String, PropertyPath ,int)}.
+	 * calls into {@link #walkEntityTree(org.hibernate.persister.entity.OuterJoinLoadable, String, PropertyPath, int)}.
 	 *
 	 * @param persister The persister representing the entity to be walked.
 	 * @param alias The (root) alias to use for this entity/persister.
+	 *
 	 * @throws org.hibernate.MappingException ???
 	 */
 	protected final void walkEntityTree(
 			OuterJoinLoadable persister,
 			String alias) throws MappingException {
 		walkEntityTree( persister, alias, new PropertyPath(), 0 );
 	}
 
 	/**
 	 * For a collection role, return a list of associations to be fetched by outerjoin
 	 */
 	protected final void walkCollectionTree(QueryableCollection persister, String alias) throws MappingException {
 		walkCollectionTree( persister, alias, new PropertyPath(), 0 );
 		//TODO: when this is the entry point, we should use an INNER_JOIN for fetching the many-to-many elements!
 	}
 
 	/**
 	 * For a collection role, return a list of associations to be fetched by outerjoin
 	 */
 	private void walkCollectionTree(
 			final QueryableCollection persister,
 			final String alias,
 			final PropertyPath path,
-			final int currentDepth)	throws MappingException {
+			final int currentDepth) throws MappingException {
 
 		if ( persister.isOneToMany() ) {
 			walkEntityTree(
 					(OuterJoinLoadable) persister.getElementPersister(),
 					alias,
 					path,
 					currentDepth
-				);
+			);
 		}
 		else {
 			Type type = persister.getElementType();
 			if ( type.isAssociationType() ) {
 				// a many-to-many;
 				// decrement currentDepth here to allow join across the association table
 				// without exceeding MAX_FETCH_DEPTH (i.e. the "currentDepth - 1" bit)
 				AssociationType associationType = (AssociationType) type;
-				String[] aliasedLhsColumns = persister.getElementColumnNames(alias);
+				String[] aliasedLhsColumns = persister.getElementColumnNames( alias );
 				String[] lhsColumns = persister.getElementColumnNames();
 				// if the current depth is 0, the root thing being loaded is the
 				// many-to-many collection itself.  Here, it is alright to use
 				// an inner join...
 				boolean useInnerJoin = currentDepth == 0;
 				final JoinType joinType = getJoinType(
 						associationType,
 						persister.getFetchMode(),
 						path,
 						persister.getTableName(),
 						lhsColumns,
 						!useInnerJoin,
-						currentDepth - 1, 
+						currentDepth - 1,
 						null //operations which cascade as far as the collection also cascade to collection elements
 				);
 				addAssociationToJoinTreeIfNecessary(
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						path,
 						currentDepth - 1,
 						joinType
-					);
+				);
 			}
 			else if ( type.isComponentType() ) {
 				walkCompositeElementTree(
 						(CompositeType) type,
 						persister.getElementColumnNames(),
 						persister,
 						alias,
 						path,
 						currentDepth
-					);
+				);
 			}
 		}
 
 	}
-	
+
 	/**
 	 * Process a particular association owned by the entity
 	 *
 	 * @param associationType The type representing the association to be
 	 * processed.
 	 * @param persister The owner of the association to be processed.
 	 * @param propertyNumber The property number for the association
 	 * (relative to the persister).
 	 * @param alias The entity alias
 	 * @param path The path to the association
 	 * @param nullable is the association nullable (which I think is supposed
 	 * to indicate inner/outer join semantics).
 	 * @param currentDepth The current join depth
+	 *
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkEntityAssociationTree(
 			final AssociationType associationType,
 			final OuterJoinLoadable persister,
 			final int propertyNumber,
 			final String alias,
 			final PropertyPath path,
 			final boolean nullable,
 			final int currentDepth) throws MappingException {
 		String[] aliasedLhsColumns = JoinHelper.getAliasedLHSColumnNames(
 				associationType, alias, propertyNumber, persister, getFactory()
 		);
 		String[] lhsColumns = JoinHelper.getLHSColumnNames(
 				associationType, propertyNumber, persister, getFactory()
 		);
-		String lhsTable = JoinHelper.getLHSTableName(associationType, propertyNumber, persister);
+		String lhsTable = JoinHelper.getLHSTableName( associationType, propertyNumber, persister );
 
-		PropertyPath subPath = path.append( persister.getSubclassPropertyName(propertyNumber) );
+		PropertyPath subPath = path.append( persister.getSubclassPropertyName( propertyNumber ) );
 		JoinType joinType = getJoinType(
 				persister,
 				subPath,
 				propertyNumber,
 				associationType,
 				persister.getFetchMode( propertyNumber ),
 				persister.getCascadeStyle( propertyNumber ),
 				lhsTable,
 				lhsColumns,
 				nullable,
 				currentDepth
 		);
 		addAssociationToJoinTreeIfNecessary(
 				associationType,
 				aliasedLhsColumns,
 				alias,
 				subPath,
 				currentDepth,
 				joinType
 		);
 	}
 
 	/**
 	 * Determine the appropriate type of join (if any) to use to fetch the
 	 * given association.
 	 *
 	 * @param persister The owner of the association.
 	 * @param path The path to the association
 	 * @param propertyNumber The property number representing the association.
 	 * @param associationType The association type.
 	 * @param metadataFetchMode The metadata-defined fetch mode.
 	 * @param metadataCascadeStyle The metadata-defined cascade style.
 	 * @param lhsTable The owner table
 	 * @param lhsColumns The owner join columns
 	 * @param nullable Is the association nullable.
 	 * @param currentDepth Current join depth
+	 *
 	 * @return type of join to use ({@link org.hibernate.sql.JoinType#INNER_JOIN},
 	 * {@link org.hibernate.sql.JoinType#LEFT_OUTER_JOIN}, or -1 to indicate no joining.
+	 *
 	 * @throws MappingException ??
 	 */
 	protected JoinType getJoinType(
 			OuterJoinLoadable persister,
 			final PropertyPath path,
 			int propertyNumber,
 			AssociationType associationType,
 			FetchMode metadataFetchMode,
 			CascadeStyle metadataCascadeStyle,
 			String lhsTable,
 			String[] lhsColumns,
 			final boolean nullable,
 			final int currentDepth) throws MappingException {
 		return getJoinType(
 				associationType,
 				metadataFetchMode,
 				path,
 				lhsTable,
 				lhsColumns,
 				nullable,
 				currentDepth,
 				metadataCascadeStyle
 		);
 	}
 
 	/**
 	 * Determine the appropriate associationType of join (if any) to use to fetch the
 	 * given association.
 	 *
 	 * @param associationType The association associationType.
 	 * @param config The metadata-defined fetch mode.
 	 * @param path The path to the association
 	 * @param lhsTable The owner table
 	 * @param lhsColumns The owner join columns
 	 * @param nullable Is the association nullable.
 	 * @param currentDepth Current join depth
 	 * @param cascadeStyle The metadata-defined cascade style.
+	 *
 	 * @return type of join to use ({@link org.hibernate.sql.JoinType#INNER_JOIN},
 	 * {@link org.hibernate.sql.JoinType#LEFT_OUTER_JOIN}, or -1 to indicate no joining.
+	 *
 	 * @throws MappingException ??
 	 */
 	protected JoinType getJoinType(
 			AssociationType associationType,
 			FetchMode config,
 			PropertyPath path,
 			String lhsTable,
 			String[] lhsColumns,
 			boolean nullable,
 			int currentDepth,
 			CascadeStyle cascadeStyle) throws MappingException {
-		if  ( !isJoinedFetchEnabled( associationType, config, cascadeStyle ) ) {
+		if ( !isJoinedFetchEnabled( associationType, config, cascadeStyle ) ) {
 			return JoinType.NONE;
 		}
-		if ( isTooDeep(currentDepth) || ( associationType.isCollectionType() && isTooManyCollections() ) ) {
+		if ( isTooDeep( currentDepth ) || ( associationType.isCollectionType() && isTooManyCollections() ) ) {
 			return JoinType.NONE;
 		}
 		if ( isDuplicateAssociation( lhsTable, lhsColumns, associationType ) ) {
 			return JoinType.NONE;
 		}
 		return getJoinType( nullable, currentDepth );
 	}
 
 	/**
 	 * Walk the association tree for an entity, adding associations which should
 	 * be join fetched to the {@link #associations} inst var.  This form is the
 	 * entry point into the walking for a given entity, starting the recursive
-	 * calls into {@link #walkEntityTree(org.hibernate.persister.entity.OuterJoinLoadable, String, PropertyPath ,int)}.
+	 * calls into {@link #walkEntityTree(org.hibernate.persister.entity.OuterJoinLoadable, String, PropertyPath, int)}.
 	 *
 	 * @param persister The persister representing the entity to be walked.
 	 * @param alias The (root) alias to use for this entity/persister.
 	 * @param path The property path to the entity being walked
 	 * @param currentDepth The current join depth
+	 *
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkEntityTree(
 			final OuterJoinLoadable persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 		int n = persister.countSubclassProperties();
 		for ( int i = 0; i < n; i++ ) {
-			Type type = persister.getSubclassPropertyType(i);
+			Type type = persister.getSubclassPropertyType( i );
 			if ( type.isAssociationType() ) {
 				walkEntityAssociationTree(
-					( AssociationType ) type,
-					persister,
-					i,
-					alias,
-					path,
-					persister.isSubclassPropertyNullable(i),
-					currentDepth
+						(AssociationType) type,
+						persister,
+						i,
+						alias,
+						path,
+						persister.isSubclassPropertyNullable( i ),
+						currentDepth
 				);
 			}
 			else if ( type.isComponentType() ) {
 				walkComponentTree(
-						( CompositeType ) type,
+						(CompositeType) type,
 						i,
 						0,
 						persister,
 						alias,
-						path.append( persister.getSubclassPropertyName(i) ),
+						path.append( persister.getSubclassPropertyName( i ) ),
 						currentDepth
 				);
 			}
 		}
 
 		// if the entity has a composite identifier, see if we need to handle
 		// its sub-properties separately
 		final Type idType = persister.getIdentifierType();
 		if ( idType.isComponentType() ) {
 			final CompositeType cidType = (CompositeType) idType;
 			if ( cidType.isEmbedded() ) {
 				// we have an embedded composite identifier.  Most likely we need to process the composite
 				// properties separately, although there is an edge case where the identifier is really
 				// a simple identifier (single value) wrapped in a JPA @IdClass or even in the case of a
 				// a simple identifier (single value) wrapped in a Hibernate composite type.
 				//
 				// We really do not have a built-in method to determine that.  However, generally the
 				// persister would report that there is single, physical identifier property which is
 				// explicitly at odds with the notion of "embedded composite".  So we use that for now
 				if ( persister.getEntityMetamodel().getIdentifierProperty().isEmbedded() ) {
 					walkComponentTree(
 							cidType,
 							-1,
 							0,
 							persister,
 							alias,
 							path,
 							currentDepth
 					);
 				}
 			}
 		}
 	}
 
 	/**
 	 * For a component, add to a list of associations to be fetched by outerjoin
 	 *
-	 *
 	 * @param componentType The component type to be walked.
 	 * @param propertyNumber The property number for the component property (relative to
 	 * persister).
 	 * @param begin todo unknowm
 	 * @param persister The owner of the component property
 	 * @param alias The root alias
 	 * @param path The property access path
 	 * @param currentDepth The current join depth
+	 *
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkComponentTree(
 			final CompositeType componentType,
 			final int propertyNumber,
 			int begin,
 			final OuterJoinLoadable persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 		Type[] types = componentType.getSubtypes();
 		String[] propertyNames = componentType.getPropertyNames();
 		for ( int i = 0; i < types.length; i++ ) {
 			if ( types[i].isAssociationType() ) {
 				AssociationType associationType = (AssociationType) types[i];
 				String[] aliasedLhsColumns = JoinHelper.getAliasedLHSColumnNames(
-					associationType, alias, propertyNumber, begin, persister, getFactory()
+						associationType, alias, propertyNumber, begin, persister, getFactory()
 				);
 				String[] lhsColumns = JoinHelper.getLHSColumnNames(
-					associationType, propertyNumber, begin, persister, getFactory()
+						associationType, propertyNumber, begin, persister, getFactory()
 				);
-				String lhsTable = JoinHelper.getLHSTableName(associationType, propertyNumber, persister);
+				String lhsTable = JoinHelper.getLHSTableName( associationType, propertyNumber, persister );
 
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				final boolean[] propertyNullability = componentType.getPropertyNullability();
 				final JoinType joinType = getJoinType(
 						persister,
 						subPath,
 						propertyNumber,
 						associationType,
-						componentType.getFetchMode(i),
-						componentType.getCascadeStyle(i),
+						componentType.getFetchMode( i ),
+						componentType.getCascadeStyle( i ),
 						lhsTable,
 						lhsColumns,
-						propertyNullability==null || propertyNullability[i],
+						propertyNullability == null || propertyNullability[i],
 						currentDepth
 				);
-				addAssociationToJoinTreeIfNecessary(			
+				addAssociationToJoinTreeIfNecessary(
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						subPath,
 						currentDepth,
 						joinType
 				);
 
 			}
 			else if ( types[i].isComponentType() ) {
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				walkComponentTree(
-						( CompositeType ) types[i],
+						(CompositeType) types[i],
 						propertyNumber,
 						begin,
 						persister,
 						alias,
 						subPath,
 						currentDepth
 				);
 			}
 			begin += types[i].getColumnSpan( getFactory() );
 		}
 
 	}
 
 	/**
 	 * For a composite element, add to a list of associations to be fetched by outerjoin
 	 */
 	private void walkCompositeElementTree(
 			final CompositeType compositeType,
 			final String[] cols,
 			final QueryableCollection persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 
 		Type[] types = compositeType.getSubtypes();
 		String[] propertyNames = compositeType.getPropertyNames();
 		int begin = 0;
-		for ( int i=0; i <types.length; i++ ) {
+		for ( int i = 0; i < types.length; i++ ) {
 			int length = types[i].getColumnSpan( getFactory() );
-			String[] lhsColumns = ArrayHelper.slice(cols, begin, length);
+			String[] lhsColumns = ArrayHelper.slice( cols, begin, length );
 
 			if ( types[i].isAssociationType() ) {
 				AssociationType associationType = (AssociationType) types[i];
 
 				// simple, because we can't have a one-to-one or a collection 
 				// (or even a property-ref) in a composite-element:
-				String[] aliasedLhsColumns = StringHelper.qualify(alias, lhsColumns);
+				String[] aliasedLhsColumns = StringHelper.qualify( alias, lhsColumns );
 
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				final boolean[] propertyNullability = compositeType.getPropertyNullability();
 				final JoinType joinType = getJoinType(
 						associationType,
-						compositeType.getFetchMode(i),
+						compositeType.getFetchMode( i ),
 						subPath,
 						persister.getTableName(),
 						lhsColumns,
-						propertyNullability==null || propertyNullability[i],
-						currentDepth, 
-						compositeType.getCascadeStyle(i)
-					);
+						propertyNullability == null || propertyNullability[i],
+						currentDepth,
+						compositeType.getCascadeStyle( i )
+				);
 				addAssociationToJoinTreeIfNecessary(
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						subPath,
 						currentDepth,
 						joinType
-					);
+				);
 			}
 			else if ( types[i].isComponentType() ) {
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				walkCompositeElementTree(
 						(CompositeType) types[i],
 						lhsColumns,
 						persister,
 						alias,
 						subPath,
 						currentDepth
-					);
+				);
 			}
-			begin+=length;
+			begin += length;
 		}
 
 	}
 
 	/**
 	 * Use an inner join if it is a non-null association and this
 	 * is the "first" join in a series
 	 */
 	protected JoinType getJoinType(boolean nullable, int currentDepth) {
 		//TODO: this is too conservative; if all preceding joins were 
 		//      also inner joins, we could use an inner join here
 		//
 		// IMPL NOTE : currentDepth might be less-than zero if this is the
 		// 		root of a many-to-many collection initializer 
 		return !nullable && currentDepth <= 0
 				? JoinType.INNER_JOIN
 				: JoinType.LEFT_OUTER_JOIN;
 	}
 
 	protected boolean isTooDeep(int currentDepth) {
-		Integer maxFetchDepth = getFactory().getSettings().getMaximumFetchDepth();
-		return maxFetchDepth!=null && currentDepth >= maxFetchDepth;
+		Integer maxFetchDepth = getFactory().getSessionFactoryOptions().getMaximumFetchDepth();
+		return maxFetchDepth != null && currentDepth >= maxFetchDepth;
 	}
-	
+
 	protected boolean isTooManyCollections() {
 		return false;
 	}
-	
+
 	/**
 	 * Does the mapping, and Hibernate default semantics, specify that
 	 * this association should be fetched by outer joining
 	 */
-	protected boolean isJoinedFetchEnabledInMapping(FetchMode config, AssociationType type) 
-	throws MappingException {
+	protected boolean isJoinedFetchEnabledInMapping(FetchMode config, AssociationType type)
+			throws MappingException {
 		if ( !type.isEntityType() && !type.isCollectionType() ) {
 			return false;
 		}
 		else {
-			if (config==FetchMode.JOIN) {
+			if ( config == FetchMode.JOIN ) {
 				return true;
 			}
-			if (config==FetchMode.SELECT) {
+			if ( config == FetchMode.SELECT ) {
 				return false;
 			}
 			if ( type.isEntityType() ) {
 				//TODO: look at the owning property and check that it 
 				//      isn't lazy (by instrumentation)
-				EntityType entityType =(EntityType) type;
+				EntityType entityType = (EntityType) type;
 				EntityPersister persister = getFactory().getEntityPersister( entityType.getAssociatedEntityName() );
 				return !persister.hasProxy();
 			}
 			else {
 				return false;
 			}
 		}
 	}
 
 	/**
-	 * Override on subclasses to enable or suppress joining 
+	 * Override on subclasses to enable or suppress joining
 	 * of certain association types
 	 */
 	protected boolean isJoinedFetchEnabled(AssociationType type, FetchMode config, CascadeStyle cascadeStyle) {
-		return type.isEntityType() && isJoinedFetchEnabledInMapping(config, type) ;
+		return type.isEntityType() && isJoinedFetchEnabledInMapping( config, type );
 	}
-	
+
 	protected String generateTableAlias(final int n, final PropertyPath path, final Joinable joinable) {
 		return StringHelper.generateAlias( joinable.getName(), n );
 	}
 
 	protected String generateRootAlias(final String description) {
-		return StringHelper.generateAlias(description, 0);
+		return StringHelper.generateAlias( description, 0 );
 	}
 
 	/**
-	 * Used to detect circularities in the joined graph, note that 
+	 * Used to detect circularities in the joined graph, note that
 	 * this method is side-effecty
 	 */
 	protected boolean isDuplicateAssociation(final String foreignKeyTable, final String[] foreignKeyColumns) {
-		AssociationKey associationKey = new AssociationKey(foreignKeyColumns, foreignKeyTable);
+		AssociationKey associationKey = new AssociationKey( foreignKeyColumns, foreignKeyTable );
 		return !visitedAssociationKeys.add( associationKey );
 	}
-	
+
 	/**
-	 * Used to detect circularities in the joined graph, note that 
+	 * Used to detect circularities in the joined graph, note that
 	 * this method is side-effecty
 	 */
-	protected boolean isDuplicateAssociation(final String lhsTable, final String[] lhsColumnNames, final AssociationType type) {
+	protected boolean isDuplicateAssociation(
+			final String lhsTable,
+			final String[] lhsColumnNames,
+			final AssociationType type) {
 		final String foreignKeyTable;
 		final String[] foreignKeyColumns;
-		if ( type.getForeignKeyDirection()==ForeignKeyDirection.FROM_PARENT ) {
+		if ( type.getForeignKeyDirection() == ForeignKeyDirection.FROM_PARENT ) {
 			foreignKeyTable = lhsTable;
 			foreignKeyColumns = lhsColumnNames;
 		}
 		else {
 			foreignKeyTable = type.getAssociatedJoinable( getFactory() ).getTableName();
 			foreignKeyColumns = JoinHelper.getRHSColumnNames( type, getFactory() );
 		}
-		return isDuplicateAssociation(foreignKeyTable, foreignKeyColumns);
+		return isDuplicateAssociation( foreignKeyTable, foreignKeyColumns );
 	}
-	
+
 	/**
 	 * Uniquely identifier a foreign key, so that we don't
 	 * join it more than once, and create circularities
 	 */
 	private static final class AssociationKey {
 		private String[] columns;
 		private String table;
+
 		private AssociationKey(String[] columns, String table) {
 			this.columns = columns;
 			this.table = table;
 		}
+
 		@Override
-        public boolean equals(Object other) {
+		public boolean equals(Object other) {
 			AssociationKey that = (AssociationKey) other;
-			return that.table.equals(table) && Arrays.equals(columns, that.columns);
+			return that.table.equals( table ) && Arrays.equals( columns, that.columns );
 		}
+
 		@Override
-        public int hashCode() {
+		public int hashCode() {
 			return table.hashCode(); //TODO: inefficient
 		}
 	}
-	
+
 	/**
 	 * Should we join this association?
 	 */
 	protected boolean isJoinable(
 			final JoinType joinType,
 			final Set visitedAssociationKeys,
 			final String lhsTable,
 			final String[] lhsColumnNames,
 			final AssociationType type,
 			final int depth) {
 
 		if ( joinType == JoinType.NONE ) {
 			return false;
 		}
-		
+
 		if ( joinType == JoinType.INNER_JOIN ) {
 			return true;
 		}
 
 		Integer maxFetchDepth = getFactory().getSessionFactoryOptions().getMaximumFetchDepth();
-		final boolean tooDeep = maxFetchDepth!=null && depth >= maxFetchDepth;
-		
-		return !tooDeep && !isDuplicateAssociation(lhsTable, lhsColumnNames, type);
+		final boolean tooDeep = maxFetchDepth != null && depth >= maxFetchDepth;
+
+		return !tooDeep && !isDuplicateAssociation( lhsTable, lhsColumnNames, type );
 	}
-	
+
 	protected String orderBy(final List associations, final String orderBy) {
 		return mergeOrderings( orderBy( associations ), orderBy );
 	}
 
 	protected static String mergeOrderings(String ordering1, String ordering2) {
 		if ( ordering1.length() == 0 ) {
 			return ordering2;
 		}
 		else if ( ordering2.length() == 0 ) {
 			return ordering1;
 		}
 		else {
 			return ordering1 + ", " + ordering2;
 		}
 	}
-	
+
 	/**
 	 * Generate a sequence of <tt>LEFT OUTER JOIN</tt> clauses for the given associations.
 	 */
 	protected final JoinFragment mergeOuterJoins(List associations)
-	throws MappingException {
+			throws MappingException {
 		JoinFragment outerjoin = getDialect().createOuterJoinFragment();
 		Iterator iter = associations.iterator();
 		OuterJoinableAssociation last = null;
 		while ( iter.hasNext() ) {
 			final OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( last != null && last.isManyToManyWith( oj ) ) {
-				oj.addManyToManyJoin( outerjoin, ( QueryableCollection ) last.getJoinable() );
+				oj.addManyToManyJoin( outerjoin, (QueryableCollection) last.getJoinable() );
 			}
 			else {
-				oj.addJoins(outerjoin);
+				oj.addJoins( outerjoin );
 			}
 			last = oj;
 		}
 		last = null;
 		return outerjoin;
 	}
 
 	/**
 	 * Count the number of instances of Joinable which are actually
 	 * also instances of Loadable, or are one-to-many associations
 	 */
 	protected static int countEntityPersisters(List associations)
-	throws MappingException {
+			throws MappingException {
 		int result = 0;
 		for ( Object association : associations ) {
 			final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;
 			if ( oj.getJoinable().consumesEntityAlias() ) {
 				result++;
 			}
 		}
 		return result;
 	}
-	
+
 	/**
 	 * Count the number of instances of Joinable which are actually
 	 * also instances of PersistentCollection which are being fetched
 	 * by outer join
 	 */
 	protected static int countCollectionPersisters(List associations)
-	throws MappingException {
+			throws MappingException {
 		int result = 0;
 		for ( Object association : associations ) {
 			final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;
 			if ( oj.getJoinType() == JoinType.LEFT_OUTER_JOIN &&
 					oj.getJoinable().isCollection() &&
 					!oj.hasRestriction() ) {
 				result++;
 			}
 		}
 		return result;
 	}
-	
+
 	/**
 	 * Get the order by string required for collection fetching
 	 */
 	protected static String orderBy(List associations)
-	throws MappingException {
+			throws MappingException {
 		StringBuilder buf = new StringBuilder();
 		Iterator iter = associations.iterator();
 		OuterJoinableAssociation last = null;
 		while ( iter.hasNext() ) {
 			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( oj.getJoinType() == JoinType.LEFT_OUTER_JOIN ) { // why does this matter?
 				if ( oj.getJoinable().isCollection() ) {
 					final QueryableCollection queryableCollection = (QueryableCollection) oj.getJoinable();
 					if ( queryableCollection.hasOrdering() ) {
 						final String orderByString = queryableCollection.getSQLOrderByString( oj.getRHSAlias() );
-						buf.append( orderByString ).append(", ");
+						buf.append( orderByString ).append( ", " );
 					}
 				}
 				else {
 					// it might still need to apply a collection ordering based on a
 					// many-to-many defined order-by...
 					if ( last != null && last.getJoinable().isCollection() ) {
 						final QueryableCollection queryableCollection = (QueryableCollection) last.getJoinable();
 						if ( queryableCollection.isManyToMany() && last.isManyToManyWith( oj ) ) {
 							if ( queryableCollection.hasManyToManyOrdering() ) {
 								final String orderByString = queryableCollection.getManyToManyOrderByString( oj.getRHSAlias() );
-								buf.append( orderByString ).append(", ");
+								buf.append( orderByString ).append( ", " );
 							}
 						}
 					}
 				}
 			}
 			last = oj;
 		}
-		if ( buf.length()>0 ) {
-			buf.setLength( buf.length()-2 );
+		if ( buf.length() > 0 ) {
+			buf.setLength( buf.length() - 2 );
 		}
 		return buf.toString();
 	}
 
 	/**
 	 * Render the where condition for a (batch) load by identifier / collection key
 	 */
 	protected StringBuilder whereString(String alias, String[] columnNames, int batchSize) {
-		if ( columnNames.length==1 ) {
+		if ( columnNames.length == 1 ) {
 			// if not a composite key, use "foo in (?, ?, ?)" for batching
 			// if no batch, and not a composite key, use "foo = ?"
 			InFragment in = new InFragment().setColumn( alias, columnNames[0] );
-			for ( int i=0; i<batchSize; i++ ) {
-				in.addValue("?");
+			for ( int i = 0; i < batchSize; i++ ) {
+				in.addValue( "?" );
 			}
 			return new StringBuilder( in.toFragmentString() );
 		}
 		else {
 			//a composite key
 			ConditionFragment byId = new ConditionFragment()
-					.setTableAlias(alias)
+					.setTableAlias( alias )
 					.setCondition( columnNames, "?" );
-	
+
 			StringBuilder whereString = new StringBuilder();
-			if ( batchSize==1 ) {
+			if ( batchSize == 1 ) {
 				// if no batch, use "foo = ? and bar = ?"
 				whereString.append( byId.toFragmentString() );
 			}
 			else {
 				// if a composite key, use "( (foo = ? and bar = ?) or (foo = ? and bar = ?) )" for batching
-				whereString.append('('); //TODO: unnecessary for databases with ANSI-style joins
+				whereString.append( '(' ); //TODO: unnecessary for databases with ANSI-style joins
 				DisjunctionFragment df = new DisjunctionFragment();
-				for ( int i=0; i<batchSize; i++ ) {
-					df.addCondition(byId);
+				for ( int i = 0; i < batchSize; i++ ) {
+					df.addCondition( byId );
 				}
 				whereString.append( df.toFragmentString() );
-				whereString.append(')'); //TODO: unnecessary for databases with ANSI-style joins
+				whereString.append( ')' ); //TODO: unnecessary for databases with ANSI-style joins
 			}
 			return whereString;
 		}
 	}
 
 
 	protected void initPersisters(final List associations, final LockMode lockMode) throws MappingException {
-		initPersisters( associations, new LockOptions(lockMode));
+		initPersisters( associations, new LockOptions( lockMode ) );
 	}
 
 	protected interface AssociationInitCallback {
 		AssociationInitCallback NO_CALLBACK = new AssociationInitCallback() {
 			public void associationProcessed(OuterJoinableAssociation oja, int position) {
 			}
 		};
 
 		void associationProcessed(OuterJoinableAssociation oja, int position);
 	}
+
 	protected void initPersisters(final List associations, final LockOptions lockOptions) throws MappingException {
 		initPersisters( associations, lockOptions, AssociationInitCallback.NO_CALLBACK );
 	}
 
 	protected void initPersisters(
 			final List associations,
 			final LockOptions lockOptions,
 			final AssociationInitCallback callback) throws MappingException {
-		final int joins = countEntityPersisters(associations);
-		final int collections = countCollectionPersisters(associations);
+		final int joins = countEntityPersisters( associations );
+		final int collections = countCollectionPersisters( associations );
 
-		collectionOwners = collections==0 ? null : new int[collections];
-		collectionPersisters = collections==0 ? null : new CollectionPersister[collections];
+		collectionOwners = collections == 0 ? null : new int[collections];
+		collectionPersisters = collections == 0 ? null : new CollectionPersister[collections];
 		collectionSuffixes = BasicLoader.generateSuffixes( joins + 1, collections );
 
 		this.lockOptions = lockOptions;
 
 		persisters = new Loadable[joins];
 		aliases = new String[joins];
 		owners = new int[joins];
 		ownerAssociationTypes = new EntityType[joins];
 		lockModeArray = ArrayHelper.fillArray( lockOptions.getLockMode(), joins );
 
-		int i=0;
-		int j=0;
-		Iterator iter = associations.iterator();
-		while ( iter.hasNext() ) {
-			final OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
+		int i = 0;
+		int j = 0;
+		for ( Object association : associations ) {
+			final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;
 			if ( !oj.isCollection() ) {
-				
+
 				persisters[i] = (Loadable) oj.getJoinable();
 				aliases[i] = oj.getRHSAlias();
-				owners[i] = oj.getOwner(associations);
+				owners[i] = oj.getOwner( associations );
 				ownerAssociationTypes[i] = (EntityType) oj.getJoinableType();
 				callback.associationProcessed( oj, i );
 				i++;
-				
+
 			}
 			else {
-				
+
 				QueryableCollection collPersister = (QueryableCollection) oj.getJoinable();
-				if ( oj.getJoinType()==JoinType.LEFT_OUTER_JOIN && ! oj.hasRestriction() ) {
+				if ( oj.getJoinType() == JoinType.LEFT_OUTER_JOIN && !oj.hasRestriction() ) {
 					//it must be a collection fetch
 					collectionPersisters[j] = collPersister;
-					collectionOwners[j] = oj.getOwner(associations);
+					collectionOwners[j] = oj.getOwner( associations );
 					j++;
 				}
-	
+
 				if ( collPersister.isOneToMany() ) {
 					persisters[i] = (Loadable) collPersister.getElementPersister();
 					aliases[i] = oj.getRHSAlias();
 					callback.associationProcessed( oj, i );
 					i++;
 				}
 			}
 		}
 
-		if ( ArrayHelper.isAllNegative(owners) ) {
+		if ( ArrayHelper.isAllNegative( owners ) ) {
 			owners = null;
 		}
-		if ( collectionOwners!=null && ArrayHelper.isAllNegative(collectionOwners) ) {
+		if ( collectionOwners != null && ArrayHelper.isAllNegative( collectionOwners ) ) {
 			collectionOwners = null;
 		}
 	}
 
 	/**
 	 * Generate a select list of columns containing all properties of the entity classes
 	 */
 	protected final String selectString(List associations) throws MappingException {
 
-		if ( associations.size()==0 ) {
+		if ( associations.size() == 0 ) {
 			return "";
 		}
 		else {
 			StringBuilder buf = new StringBuilder( associations.size() * 100 );
-			int entityAliasCount=0;
-			int collectionAliasCount=0;
-			for ( int i=0; i<associations.size(); i++ ) {
-				OuterJoinableAssociation join = (OuterJoinableAssociation) associations.get(i);
-				OuterJoinableAssociation next = (i == associations.size() - 1)
-				        ? null
-				        : ( OuterJoinableAssociation ) associations.get( i + 1 );
+			int entityAliasCount = 0;
+			int collectionAliasCount = 0;
+			for ( int i = 0; i < associations.size(); i++ ) {
+				OuterJoinableAssociation join = (OuterJoinableAssociation) associations.get( i );
+				OuterJoinableAssociation next = ( i == associations.size() - 1 )
+						? null
+						: (OuterJoinableAssociation) associations.get( i + 1 );
 				final Joinable joinable = join.getJoinable();
 				final String entitySuffix = ( suffixes == null || entityAliasCount >= suffixes.length )
-				        ? null
-				        : suffixes[entityAliasCount];
+						? null
+						: suffixes[entityAliasCount];
 				final String collectionSuffix = ( collectionSuffixes == null || collectionAliasCount >= collectionSuffixes.length )
-				        ? null
-				        : collectionSuffixes[collectionAliasCount];
+						? null
+						: collectionSuffixes[collectionAliasCount];
 				final String selectFragment = joinable.selectFragment(
 						next == null ? null : next.getJoinable(),
 						next == null ? null : next.getRHSAlias(),
 						join.getRHSAlias(),
 						entitySuffix,
-				        collectionSuffix,
-						join.getJoinType()==JoinType.LEFT_OUTER_JOIN
+						collectionSuffix,
+						join.getJoinType() == JoinType.LEFT_OUTER_JOIN
 				);
-				if (selectFragment.trim().length() > 0) {
-					buf.append(", ").append(selectFragment);
+				if ( selectFragment.trim().length() > 0 ) {
+					buf.append( ", " ).append( selectFragment );
 				}
 				if ( joinable.consumesEntityAlias() ) {
 					entityAliasCount++;
 				}
 				if ( joinable.consumesCollectionAlias() &&
-						join.getJoinType()==JoinType.LEFT_OUTER_JOIN &&
+						join.getJoinType() == JoinType.LEFT_OUTER_JOIN &&
 						!join.hasRestriction() ) {
 					collectionAliasCount++;
 				}
 			}
 			return buf.toString();
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
index 2567cf6da3..8f306450f8 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
@@ -1,2721 +1,2716 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
-import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.WrongClassException;
 import org.hibernate.cache.spi.FilterKey;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.QueryKey;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.ReferenceCacheEntryImpl;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.dialect.pagination.NoopLimitHandler;
 import org.hibernate.engine.internal.CacheHelper;
 import org.hibernate.engine.internal.TwoPhaseLoad;
 import org.hibernate.engine.jdbc.ColumnNameCache;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.EntityUniqueKey;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.PostLoadEvent;
 import org.hibernate.event.spi.PreLoadEvent;
 import org.hibernate.hql.internal.HolderInstantiator;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FetchingScrollableResultsImpl;
 import org.hibernate.internal.ScrollableResultsImpl;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.UniqueKeyLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.transform.CacheableResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 import org.jboss.logging.Logger;
 
 /**
  * Abstract superclass of object loading (and querying) strategies. This class implements
  * useful common functionality that concrete loaders delegate to. It is not intended that this
  * functionality would be directly accessed by client code. (Hence, all methods of this class
  * are declared <tt>protected</tt> or <tt>private</tt>.) This class relies heavily upon the
  * <tt>Loadable</tt> interface, which is the contract between this class and
  * <tt>EntityPersister</tt>s that may be loaded by it.<br>
  * <br>
  * The present implementation is able to load any number of columns of entities and at most
  * one collection role per query.
  *
  * @author Gavin King
  * @see org.hibernate.persister.entity.Loadable
  */
 public abstract class Loader {
-
-	protected static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Loader.class.getName());
+	protected static final CoreMessageLogger LOG = CoreLogging.messageLogger( Loader.class );
 	protected static final boolean DEBUG_ENABLED = LOG.isDebugEnabled();
+
 	private final SessionFactoryImplementor factory;
 	private volatile ColumnNameCache columnNameCache;
 
 	private final boolean referenceCachingEnabled;
 
 	public Loader(SessionFactoryImplementor factory) {
 		this.factory = factory;
-		this.referenceCachingEnabled = factory.getSettings().isDirectReferenceCacheEntriesEnabled();
+		this.referenceCachingEnabled = factory.getSessionFactoryOptions().isDirectReferenceCacheEntriesEnabled();
 	}
 
 	/**
 	 * The SQL query string to be called; implemented by all subclasses
 	 *
 	 * @return The sql command this loader should use to get its {@link ResultSet}.
 	 */
 	public abstract String getSQLString();
 
 	/**
 	 * An array of persisters of entity classes contained in each row of results;
 	 * implemented by all subclasses
 	 *
 	 * @return The entity persisters.
 	 */
 	protected abstract Loadable[] getEntityPersisters();
 
 	/**
 	 * An array indicating whether the entities have eager property fetching
 	 * enabled.
 	 *
 	 * @return Eager property fetching indicators.
 	 */
 	protected boolean[] getEntityEagerPropertyFetches() {
 		return null;
 	}
 
 	/**
 	 * An array of indexes of the entity that owns a one-to-one association
 	 * to the entity at the given index (-1 if there is no "owner").  The
 	 * indexes contained here are relative to the result of
 	 * {@link #getEntityPersisters}.
 	 *
 	 * @return The owner indicators (see discussion above).
 	 */
 	protected int[] getOwners() {
 		return null;
 	}
 
 	/**
 	 * An array of the owner types corresponding to the {@link #getOwners()}
 	 * returns.  Indices indicating no owner would be null here.
 	 *
 	 * @return The types for the owners.
 	 */
 	protected EntityType[] getOwnerAssociationTypes() {
 		return null;
 	}
 
 	/**
 	 * An (optional) persister for a collection to be initialized; only
 	 * collection loaders return a non-null value
 	 */
 	protected CollectionPersister[] getCollectionPersisters() {
 		return null;
 	}
 
 	/**
 	 * Get the index of the entity that owns the collection, or -1
 	 * if there is no owner in the query results (ie. in the case of a
 	 * collection initializer) or no collection.
 	 */
 	protected int[] getCollectionOwners() {
 		return null;
 	}
 
 	protected int[][] getCompositeKeyManyToOneTargetIndices() {
 		return null;
 	}
 
 	/**
 	 * What lock options does this load entities with?
 	 *
 	 * @param lockOptions a collection of lock options specified dynamically via the Query interface
 	 */
 	//protected abstract LockOptions[] getLockOptions(Map lockOptions);
 	protected abstract LockMode[] getLockModes(LockOptions lockOptions);
 
 	/**
 	 * Append <tt>FOR UPDATE OF</tt> clause, if necessary. This
 	 * empty superclass implementation merely returns its first
 	 * argument.
 	 */
 	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 		return sql;
 	}
 
 	/**
 	 * Does this query return objects that might be already cached
 	 * by the session, whose lock mode may need upgrading
 	 */
 	protected boolean upgradeLocks() {
 		return false;
 	}
 
 	/**
 	 * Return false is this loader is a batch entity loader
 	 */
 	protected boolean isSingleRowLoader() {
 		return false;
 	}
 
 	/**
 	 * Get the SQL table aliases of entities whose
 	 * associations are subselect-loadable, returning
 	 * null if this loader does not support subselect
 	 * loading
 	 */
 	protected String[] getAliases() {
 		return null;
 	}
 
 	/**
 	 * Modify the SQL, adding lock hints and comments, if necessary
 	 */
 	protected String preprocessSQL(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 		sql = applyLocks( sql, parameters, dialect, afterLoadActions );
 		
 		// Keep this here, rather than moving to Select.  Some Dialects may need the hint to be appended to the very
 		// end or beginning of the finalized SQL statement, so wait until everything is processed.
 		if ( parameters.getQueryHints() != null && parameters.getQueryHints().size() > 0 ) {
 			sql = dialect.getQueryHintString( sql, parameters.getQueryHints() );
 		}
 		
-		return getFactory().getSettings().isCommentsEnabled()
+		return getFactory().getSessionFactoryOptions().isCommentsEnabled()
 				? prependComment( sql, parameters )
 				: sql;
 	}
 
 	protected boolean shouldUseFollowOnLocking(
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) {
 		if ( dialect.useFollowOnLocking() ) {
 			// currently only one lock mode is allowed in follow-on locking
 			final LockMode lockMode = determineFollowOnLockMode( parameters.getLockOptions() );
 			final LockOptions lockOptions = new LockOptions( lockMode );
 			if ( lockOptions.getLockMode() != LockMode.UPGRADE_SKIPLOCKED ) {
 				LOG.usingFollowOnLocking();
 				lockOptions.setTimeOut( parameters.getLockOptions().getTimeOut() );
 				lockOptions.setScope( parameters.getLockOptions().getScope() );
 				afterLoadActions.add(
 						new AfterLoadAction() {
 							@Override
 							public void afterLoad(SessionImplementor session, Object entity, Loadable persister) {
 								( (Session) session ).buildLockRequest( lockOptions ).lock( persister.getEntityName(), entity );
 							}
 						}
 				);
 				parameters.setLockOptions( new LockOptions() );
 				return true;
 			}
 		}
 		return false;
 	}
 
 	protected LockMode determineFollowOnLockMode(LockOptions lockOptions) {
 		final LockMode lockModeToUse = lockOptions.findGreatestLockMode();
 
 		if ( lockOptions.hasAliasSpecificLockModes() ) {
 			LOG.aliasSpecificLockingWithFollowOnLocking( lockModeToUse );
 		}
 
 		return lockModeToUse;
 	}
 
 	private String prependComment(String sql, QueryParameters parameters) {
 		String comment = parameters.getComment();
 		if ( comment == null ) {
 			return sql;
 		}
 		else {
-			return new StringBuilder( comment.length() + sql.length() + 5 )
-					.append( "/* " )
-					.append( comment )
-					.append( " */ " )
-					.append( sql )
-					.toString();
+			return "/* " + comment + " */ " + sql;
 		}
 	}
 
 	/**
 	 * Execute an SQL query and attempt to instantiate instances of the class mapped by the given
 	 * persister from each row of the <tt>ResultSet</tt>. If an object is supplied, will attempt to
 	 * initialize that object. If a collection is supplied, attempt to initialize that collection.
 	 */
 	public List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException, SQLException {
 		return doQueryAndInitializeNonLazyCollections(
 				session,
 				queryParameters,
 				returnProxies,
 				null
 		);
 	}
 
 	public List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer)
 			throws HibernateException, SQLException {
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 		if ( queryParameters.isReadOnlyInitialized() ) {
 			// The read-only/modifiable mode for the query was explicitly set.
 			// Temporarily set the default read-only/modifiable setting to the query's setting.
 			persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 		}
 		else {
 			// The read-only/modifiable setting for the query was not initialized.
 			// Use the default read-only/modifiable from the persistence context instead.
 			queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 		}
 		persistenceContext.beforeLoad();
 		List result;
 		try {
 			try {
 				result = doQuery( session, queryParameters, returnProxies, forcedResultTransformer );
 			}
 			finally {
 				persistenceContext.afterLoad();
 			}
 			persistenceContext.initializeNonLazyCollections();
 		}
 		finally {
 			// Restore the original default
 			persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 		}
 		return result;
 	}
 
 	/**
 	 * Loads a single row from the result set.  This is the processing used from the
 	 * ScrollableResults where no collection fetches were encountered.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSingleRow(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		final Object result;
 		try {
 			result = getRowFromResultSet(
 					resultSet,
 					session,
 					queryParameters,
 					getLockModes( queryParameters.getLockOptions() ),
 					null,
 					hydratedObjects,
 					new EntityKey[entitySpan],
 					returnProxies
 				);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not read next row of results",
 					getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 		);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private Object sequentialLoad(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final EntityKey keyToRead) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		Object result = null;
 		final EntityKey[] loadedKeys = new EntityKey[entitySpan];
 
 		try {
 			do {
 				Object loaded = getRowFromResultSet(
 						resultSet,
 						session,
 						queryParameters,
 						getLockModes( queryParameters.getLockOptions() ),
 						null,
 						hydratedObjects,
 						loadedKeys,
 						returnProxies
 				);
 				if ( ! keyToRead.equals( loadedKeys[0] ) ) {
 					throw new AssertionFailure(
 							String.format(
 									"Unexpected key read for row; expected [%s]; actual [%s]",
 									keyToRead,
 									loadedKeys[0] )
 					);
 				}
 				if ( result == null ) {
 					result = loaded;
 				}
 			}
 			while ( resultSet.next() &&
 					isCurrentRowForSameEntity( keyToRead, 0, resultSet, session ) );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not doAfterTransactionCompletion sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 		);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private boolean isCurrentRowForSameEntity(
 			final EntityKey keyToRead,
 			final int persisterIndex,
 			final ResultSet resultSet,
 			final SessionImplementor session) throws SQLException {
 		EntityKey currentRowKey = getKeyFromResultSet(
 				persisterIndex, getEntityPersisters()[persisterIndex], null, resultSet, session
 		);
 		return keyToRead.equals( currentRowKey );
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsForward(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isAfterLast() ) {
 				// don't even bother trying to read further
 				return null;
 			}
 
 			if ( resultSet.isBeforeFirst() ) {
 				resultSet.next();
 			}
 
 			// We call getKeyFromResultSet() here so that we can know the
 			// key value upon which to perform the breaking logic.  However,
 			// it is also then called from getRowFromResultSet() which is certainly
 			// not the most efficient.  But the call here is needed, and there
 			// currently is no other way without refactoring of the doQuery()/getRowFromResultSet()
 			// methods
 			final EntityKey currentKey = getKeyFromResultSet(
 					0,
 					getEntityPersisters()[0],
 					null,
 					resultSet,
 					session
 				);
 
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, currentKey );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not perform sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsReverse(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final boolean isLogicallyAfterLast) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isFirst() ) {
 				// don't even bother trying to read any further
 				return null;
 			}
 
 			EntityKey keyToRead = null;
 			// This check is needed since processing leaves the cursor
 			// after the last physical row for the current logical row;
 			// thus if we are after the last physical row, this might be
 			// caused by either:
 			//      1) scrolling to the last logical row
 			//      2) scrolling past the last logical row
 			// In the latter scenario, the previous logical row
 			// really is the last logical row.
 			//
 			// In all other cases, we should process back two
 			// logical records (the current logic row, plus the
 			// previous logical row).
 			if ( resultSet.isAfterLast() && isLogicallyAfterLast ) {
 				// position cursor to the last row
 				resultSet.last();
 				keyToRead = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 			}
 			else {
 				// Since the result set cursor is always left at the first
 				// physical row after the "last processed", we need to jump
 				// back one position to get the key value we are interested
 				// in skipping
 				resultSet.previous();
 
 				// sequentially read the result set in reverse until we recognize
 				// a change in the key value.  At that point, we are pointed at
 				// the last physical sequential row for the logical row in which
 				// we are interested in processing
 				boolean firstPass = true;
 				final EntityKey lastKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 				while ( resultSet.previous() ) {
 					EntityKey checkKey = getKeyFromResultSet(
 							0,
 							getEntityPersisters()[0],
 							null,
 							resultSet,
 							session
 						);
 
 					if ( firstPass ) {
 						firstPass = false;
 						keyToRead = checkKey;
 					}
 
 					if ( !lastKey.equals( checkKey ) ) {
 						break;
 					}
 				}
 
 			}
 
 			// Read backwards until we read past the first physical sequential
 			// row with the key we are interested in loading
 			while ( resultSet.previous() ) {
 				EntityKey checkKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 
 				if ( !keyToRead.equals( checkKey ) ) {
 					break;
 				}
 			}
 
 			// Finally, read ahead one row to position result set cursor
 			// at the first physical row we are interested in loading
 			resultSet.next();
 
 			// and doAfterTransactionCompletion the load
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, keyToRead );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not doAfterTransactionCompletion sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 	}
 
 	private static EntityKey getOptionalObjectKey(QueryParameters queryParameters, SessionImplementor session) {
 		final Object optionalObject = queryParameters.getOptionalObject();
 		final Serializable optionalId = queryParameters.getOptionalId();
 		final String optionalEntityName = queryParameters.getOptionalEntityName();
 
 		if ( optionalObject != null && optionalEntityName != null ) {
 			return session.generateEntityKey( optionalId, session.getEntityPersister( optionalEntityName, optionalObject ) );
 		}
 		else {
 			return null;
 		}
 
 	}
 
 	private Object getRowFromResultSet(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final LockMode[] lockModesArray,
 			final EntityKey optionalObjectKey,
 			final List hydratedObjects,
 			final EntityKey[] keys,
 			boolean returnProxies) throws SQLException, HibernateException {
 		return getRowFromResultSet(
 				resultSet,
 				session,
 				queryParameters,
 				lockModesArray,
 				optionalObjectKey,
 				hydratedObjects,
 				keys,
 				returnProxies,
 				null
 		);
 	}
 
 	private Object getRowFromResultSet(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final LockMode[] lockModesArray,
 			final EntityKey optionalObjectKey,
 			final List hydratedObjects,
 			final EntityKey[] keys,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 		final Loadable[] persisters = getEntityPersisters();
 		final int entitySpan = persisters.length;
 		extractKeysFromResultSet( persisters, queryParameters, resultSet, session, keys, lockModesArray, hydratedObjects );
 
 		registerNonExists( keys, persisters, session );
 
 		// this call is side-effecty
 		Object[] row = getRow(
 				resultSet,
 				persisters,
 				keys,
 				queryParameters.getOptionalObject(),
 				optionalObjectKey,
 				lockModesArray,
 				hydratedObjects,
 				session
 		);
 
 		readCollectionElements( row, resultSet, session );
 
 		if ( returnProxies ) {
 			// now get an existing proxy for each row element (if there is one)
 			for ( int i = 0; i < entitySpan; i++ ) {
 				Object entity = row[i];
 				Object proxy = session.getPersistenceContext().proxyFor( persisters[i], keys[i], entity );
 				if ( entity != proxy ) {
 					// force the proxy to resolve itself
 					( (HibernateProxy) proxy ).getHibernateLazyInitializer().setImplementation(entity);
 					row[i] = proxy;
 				}
 			}
 		}
 
 		applyPostLoadLocks( row, lockModesArray, session );
 
 		return forcedResultTransformer == null
 				? getResultColumnOrRow( row, queryParameters.getResultTransformer(), resultSet, session )
 				: forcedResultTransformer.transformTuple( getResultRow( row, resultSet, session ), getResultRowAliases() )
 		;
 	}
 
 	protected void extractKeysFromResultSet(
 			Loadable[] persisters,
 			QueryParameters queryParameters,
 			ResultSet resultSet,
 			SessionImplementor session,
 			EntityKey[] keys,
 			LockMode[] lockModes,
 			List hydratedObjects) throws SQLException {
 		final int entitySpan = persisters.length;
 
 		final int numberOfPersistersToProcess;
 		final Serializable optionalId = queryParameters.getOptionalId();
 		if ( isSingleRowLoader() && optionalId != null ) {
 			keys[ entitySpan - 1 ] = session.generateEntityKey( optionalId, persisters[ entitySpan - 1 ] );
 			// skip the last persister below...
 			numberOfPersistersToProcess = entitySpan - 1;
 		}
 		else {
 			numberOfPersistersToProcess = entitySpan;
 		}
 
 		final Object[] hydratedKeyState = new Object[numberOfPersistersToProcess];
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			hydratedKeyState[i] = idType.hydrate( resultSet, getEntityAliases()[i].getSuffixedKeyAliases(), session, null );
 		}
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			if ( idType.isComponentType() && getCompositeKeyManyToOneTargetIndices() != null ) {
 				// we may need to force resolve any key-many-to-one(s)
 				int[] keyManyToOneTargetIndices = getCompositeKeyManyToOneTargetIndices()[i];
 				// todo : better solution is to order the index processing based on target indices
 				//		that would account for multiple levels whereas this scheme does not
 				if ( keyManyToOneTargetIndices != null ) {
 					for ( int targetIndex : keyManyToOneTargetIndices ) {
 						if ( targetIndex < numberOfPersistersToProcess ) {
 							final Type targetIdType = persisters[targetIndex].getIdentifierType();
 							final Serializable targetId = (Serializable) targetIdType.resolve(
 									hydratedKeyState[targetIndex],
 									session,
 									null
 							);
 							// todo : need a way to signal that this key is resolved and its data resolved
 							keys[targetIndex] = session.generateEntityKey( targetId, persisters[targetIndex] );
 						}
 
 						// this part copied from #getRow, this section could be refactored out
 						Object object = session.getEntityUsingInterceptor( keys[targetIndex] );
 						if ( object != null ) {
 							//its already loaded so don't need to hydrate it
 							instanceAlreadyLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									keys[targetIndex],
 									object,
 									lockModes[targetIndex],
 									session
 							);
 						}
 						else {
 							instanceNotYetLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									getEntityAliases()[targetIndex].getRowIdAlias(),
 									keys[targetIndex],
 									lockModes[targetIndex],
 									getOptionalObjectKey( queryParameters, session ),
 									queryParameters.getOptionalObject(),
 									hydratedObjects,
 									session
 							);
 						}
 					}
 				}
 			}
 			final Serializable resolvedId = (Serializable) idType.resolve( hydratedKeyState[i], session, null );
 			keys[i] = resolvedId == null ? null : session.generateEntityKey( resolvedId, persisters[i] );
 		}
 	}
 
 	protected void applyPostLoadLocks(Object[] row, LockMode[] lockModesArray, SessionImplementor session) {
 	}
 
 	/**
 	 * Read any collection elements contained in a single row of the result set
 	 */
 	private void readCollectionElements(Object[] row, ResultSet resultSet, SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		//TODO: make this handle multiple collection roles!
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 
 			final CollectionAliases[] descriptors = getCollectionAliases();
 			final int[] collectionOwners = getCollectionOwners();
 
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 
 				final boolean hasCollectionOwners = collectionOwners !=null &&
 						collectionOwners[i] > -1;
 				//true if this is a query and we are loading multiple instances of the same collection role
 				//otherwise this is a CollectionInitializer and we are loading up a single collection or batch
 
 				final Object owner = hasCollectionOwners ?
 						row[ collectionOwners[i] ] :
 						null; //if null, owner will be retrieved from session
 
 				final CollectionPersister collectionPersister = collectionPersisters[i];
 				final Serializable key;
 				if ( owner == null ) {
 					key = null;
 				}
 				else {
 					key = collectionPersister.getCollectionType().getKeyOfOwner( owner, session );
 					//TODO: old version did not require hashmap lookup:
 					//keys[collectionOwner].getIdentifier()
 				}
 
 				readCollectionElement(
 						owner,
 						key,
 						collectionPersister,
 						descriptors[i],
 						resultSet,
 						session
 					);
 
 			}
 
 		}
 	}
 
 	private List doQuery(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 
 		final RowSelection selection = queryParameters.getRowSelection();
 		final int maxRows = LimitHelper.hasMaxRows( selection ) ?
 				selection.getMaxRows() :
 				Integer.MAX_VALUE;
 
 		final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 
 		final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
 		final ResultSet rs = wrapper.getResultSet();
 		final Statement st = wrapper.getStatement();
 
 // would be great to move all this below here into another method that could also be used
 // from the new scrolling stuff.
 //
 // Would need to change the way the max-row stuff is handled (i.e. behind an interface) so
 // that I could do the control breaking at the means to know when to stop
 
 		try {
 			return processResultSet( rs, queryParameters, session, returnProxies, forcedResultTransformer, maxRows, afterLoadActions );
 		}
 		finally {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 		}
 
 	}
 
 	protected List processResultSet(
 			ResultSet rs,
 			QueryParameters queryParameters,
 			SessionImplementor session,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer,
 			int maxRows,
 			List<AfterLoadAction> afterLoadActions) throws SQLException {
 		final int entitySpan = getEntityPersisters().length;
 		final EntityKey optionalObjectKey = getOptionalObjectKey( queryParameters, session );
 		final LockMode[] lockModesArray = getLockModes( queryParameters.getLockOptions() );
 		final boolean createSubselects = isSubselectLoadingEnabled();
 		final List subselectResultKeys = createSubselects ? new ArrayList() : null;
 		final ArrayList hydratedObjects = entitySpan == 0 ? null : new ArrayList( entitySpan * 10 );
 		final List results = new ArrayList();
 
 		handleEmptyCollections( queryParameters.getCollectionKeys(), rs, session );
 		EntityKey[] keys = new EntityKey[entitySpan]; //we can reuse it for each row
 		LOG.trace( "Processing result set" );
 		int count;
 
 		for ( count = 0; count < maxRows && rs.next(); count++ ) {
 			if ( DEBUG_ENABLED ) {
 				LOG.debugf( "Result set row: %s", count );
 			}
 			Object result = getRowFromResultSet(
 					rs,
 					session,
 					queryParameters,
 					lockModesArray,
 					optionalObjectKey,
 					hydratedObjects,
 					keys,
 					returnProxies,
 					forcedResultTransformer
 			);
 			results.add( result );
 			if ( createSubselects ) {
 				subselectResultKeys.add(keys);
 				keys = new EntityKey[entitySpan]; //can't reuse in this case
 			}
 		}
 
 		LOG.tracev( "Done processing result set ({0} rows)", count );
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				rs,
 				session,
 				queryParameters.isReadOnly( session ),
 				afterLoadActions
 		);
 		if ( createSubselects ) {
 			createSubselects( subselectResultKeys, queryParameters, session );
 		}
 		return results;
 	}
 
 	protected boolean isSubselectLoadingEnabled() {
 		return false;
 	}
 
 	protected boolean hasSubselectLoadableCollections() {
 		final Loadable[] loadables = getEntityPersisters();
 		for ( Loadable loadable : loadables ) {
 			if ( loadable.hasSubselectLoadableCollections() ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private static Set[] transpose( List keys ) {
 		Set[] result = new Set[ ( ( EntityKey[] ) keys.get(0) ).length ];
 		for ( int j=0; j<result.length; j++ ) {
 			result[j] = new HashSet( keys.size() );
 			for ( Object key : keys ) {
 				result[j].add( ( (EntityKey[]) key )[j] );
 			}
 		}
 		return result;
 	}
 
 	private void createSubselects(List keys, QueryParameters queryParameters, SessionImplementor session) {
 		if ( keys.size() > 1 ) { //if we only returned one entity, query by key is more efficient
 
 			Set[] keySets = transpose(keys);
 
 			Map namedParameterLocMap = buildNamedParameterLocMap( queryParameters );
 
 			final Loadable[] loadables = getEntityPersisters();
 			final String[] aliases = getAliases();
 			for ( Object key : keys ) {
 				final EntityKey[] rowKeys = (EntityKey[]) key;
 				for ( int i = 0; i < rowKeys.length; i++ ) {
 
 					if ( rowKeys[i] != null && loadables[i].hasSubselectLoadableCollections() ) {
 
 						SubselectFetch subselectFetch = new SubselectFetch(
 								//getSQLString(),
 								aliases[i],
 								loadables[i],
 								queryParameters,
 								keySets[i],
 								namedParameterLocMap
 						);
 
 						session.getPersistenceContext()
 								.getBatchFetchQueue()
 								.addSubselect( rowKeys[i], subselectFetch );
 					}
 
 				}
 
 			}
 		}
 	}
 
 	private Map buildNamedParameterLocMap(QueryParameters queryParameters) {
 		if ( queryParameters.getNamedParameters()!=null ) {
 			final Map namedParameterLocMap = new HashMap();
 			for(String name : queryParameters.getNamedParameters().keySet()){
 				namedParameterLocMap.put(
 						name,
 						getNamedParameterLocs(name)
 				);
 			}
 			return namedParameterLocMap;
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly) throws HibernateException {
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSetId,
 				session,
 				readOnly,
 				Collections.<AfterLoadAction>emptyList()
 		);
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
-			for ( int i=0; i<collectionPersisters.length; i++ ) {
-				if ( collectionPersisters[i].isArray() ) {
+			for ( CollectionPersister collectionPersister : collectionPersisters ) {
+				if ( collectionPersister.isArray() ) {
 					//for arrays, we should end the collection load before resolving
 					//the entities, since the actual array instances are not instantiated
 					//during loading
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
-					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
+					endCollectionLoad( resultSetId, session, collectionPersister );
 				}
 			}
 		}
 
 		//important: reuse the same event instances for performance!
 		final PreLoadEvent pre;
 		final PostLoadEvent post;
 		if ( session.isEventSource() ) {
 			pre = new PreLoadEvent( (EventSource) session );
 			post = new PostLoadEvent( (EventSource) session );
 		}
 		else {
 			pre = null;
 			post = null;
 		}
 
 		if ( hydratedObjects!=null ) {
 			int hydratedObjectsSize = hydratedObjects.size();
 			LOG.tracev( "Total objects hydrated: {0}", hydratedObjectsSize );
 			for ( Object hydratedObject : hydratedObjects ) {
 				TwoPhaseLoad.initializeEntity( hydratedObject, readOnly, session, pre );
 			}
 		}
 
 		if ( collectionPersisters != null ) {
 			for ( CollectionPersister collectionPersister : collectionPersisters ) {
 				if ( !collectionPersister.isArray() ) {
 					//for sets, we should end the collection load after resolving
 					//the entities, since we might call hashCode() on the elements
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersister );
 				}
 			}
 		}
 		
 		// Until this entire method is refactored w/ polymorphism, postLoad was
 		// split off from initializeEntity.  It *must* occur after
 		// endCollectionLoad to ensure the collection is in the
 		// persistence context.
 		if ( hydratedObjects != null ) {
 			for ( Object hydratedObject : hydratedObjects ) {
 				TwoPhaseLoad.postLoad( hydratedObject, session, post );
 				if ( afterLoadActions != null ) {
 					for ( AfterLoadAction afterLoadAction : afterLoadActions ) {
 						final EntityEntry entityEntry = session.getPersistenceContext().getEntry( hydratedObject );
 						if ( entityEntry == null ) {
 							// big problem
 							throw new HibernateException( "Could not locate EntityEntry immediately after two-phase load" );
 						}
 						afterLoadAction.afterLoad( session, hydratedObject, (Loadable) entityEntry.getPersister() );
 					}
 				}
 			}
 		}
 	}
 
 	private void endCollectionLoad(
 			final Object resultSetId,
 			final SessionImplementor session,
 			final CollectionPersister collectionPersister) {
 		//this is a query and we are loading multiple instances of the same collection role
 		session.getPersistenceContext()
 				.getLoadContexts()
 				.getCollectionLoadContext( ( ResultSet ) resultSetId )
 				.endLoadingCollections( collectionPersister );
 	}
 
 	/**
 	 * Determine the actual ResultTransformer that will be used to
 	 * transform query results.
 	 *
 	 * @param resultTransformer the specified result transformer
 	 * @return the actual result transformer
 	 */
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return resultTransformer;
 	}
 
 	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		return results;
 	}
 
 	/**
 	 * Are rows transformed immediately after being read from the ResultSet?
 	 * @return true, if getResultColumnOrRow() transforms the results; false, otherwise
 	 */
 	protected boolean areResultSetRowsTransformedImmediately() {
 		return false;
 	}
 
 	/**
 	 * Returns the aliases that corresponding to a result row.
 	 * @return Returns the aliases that corresponding to a result row.
 	 */
 	protected String[] getResultRowAliases() {
 		 return null;
 	}
 
 	/**
 	 * Get the actual object that is returned in the user-visible result list.
 	 * This empty implementation merely returns its first argument. This is
 	 * overridden by some subclasses.
 	 */
 	protected Object getResultColumnOrRow(
 			Object[] row,
 			ResultTransformer transformer,
 			ResultSet rs,
 			SessionImplementor session) throws SQLException, HibernateException {
 		return row;
 	}
 
 	protected boolean[] includeInResultRow() {
 		return null;
 	}
 
 	protected Object[] getResultRow(
 			Object[] row,
 			ResultSet rs,
 			SessionImplementor session) throws SQLException, HibernateException {
 		return row;
 	}
 
 	/**
 	 * For missing objects associated by one-to-one with another object in the
 	 * result set, register the fact that the the object is missing with the
 	 * session.
 	 */
 	private void registerNonExists(
 			final EntityKey[] keys,
 			final Loadable[] persisters,
 			final SessionImplementor session) {
 
 		final int[] owners = getOwners();
 		if ( owners != null ) {
 
 			EntityType[] ownerAssociationTypes = getOwnerAssociationTypes();
 			for ( int i = 0; i < keys.length; i++ ) {
 
 				int owner = owners[i];
 				if ( owner > -1 ) {
 					EntityKey ownerKey = keys[owner];
 					if ( keys[i] == null && ownerKey != null ) {
 
 						final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 						/*final boolean isPrimaryKey;
 						final boolean isSpecialOneToOne;
 						if ( ownerAssociationTypes == null || ownerAssociationTypes[i] == null ) {
 							isPrimaryKey = true;
 							isSpecialOneToOne = false;
 						}
 						else {
 							isPrimaryKey = ownerAssociationTypes[i].getRHSUniqueKeyPropertyName()==null;
 							isSpecialOneToOne = ownerAssociationTypes[i].getLHSPropertyName()!=null;
 						}*/
 
 						//TODO: can we *always* use the "null property" approach for everything?
 						/*if ( isPrimaryKey && !isSpecialOneToOne ) {
 							persistenceContext.addNonExistantEntityKey(
 									new EntityKey( ownerKey.getIdentifier(), persisters[i], session.getEntityMode() )
 							);
 						}
 						else if ( isSpecialOneToOne ) {*/
 						boolean isOneToOneAssociation = ownerAssociationTypes!=null &&
 								ownerAssociationTypes[i]!=null &&
 								ownerAssociationTypes[i].isOneToOne();
 						if ( isOneToOneAssociation ) {
 							persistenceContext.addNullProperty( ownerKey,
 									ownerAssociationTypes[i].getPropertyName() );
 						}
 						/*}
 						else {
 							persistenceContext.addNonExistantEntityUniqueKey( new EntityUniqueKey(
 									persisters[i].getEntityName(),
 									ownerAssociationTypes[i].getRHSUniqueKeyPropertyName(),
 									ownerKey.getIdentifier(),
 									persisters[owner].getIdentifierType(),
 									session.getEntityMode()
 							) );
 						}*/
 					}
 				}
 			}
 		}
 	}
 
 	/**
 	 * Read one collection element from the current row of the JDBC result set
 	 */
 	private void readCollectionElement(
 			final Object optionalOwner,
 			final Serializable optionalKey,
 			final CollectionPersister persister,
 			final CollectionAliases descriptor,
 			final ResultSet rs,
 			final SessionImplementor session)
 	throws HibernateException, SQLException {
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		final Serializable collectionRowKey = (Serializable) persister.readKey(
 				rs,
 				descriptor.getSuffixedKeyAliases(),
 				session
 			);
 
 		if ( collectionRowKey != null ) {
 			// we found a collection element in the result set
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Found row of collection: %s",
 						MessageHelper.collectionInfoString( persister, collectionRowKey, getFactory() ) );
 			}
 
 			Object owner = optionalOwner;
 			if ( owner == null ) {
 				owner = persistenceContext.getCollectionOwner( collectionRowKey, persister );
 				if ( owner == null ) {
 					//TODO: This is assertion is disabled because there is a bug that means the
 					//	  original owner of a transient, uninitialized collection is not known
 					//	  if the collection is re-referenced by a different object associated
 					//	  with the current Session
 					//throw new AssertionFailure("bug loading unowned collection");
 				}
 			}
 
 			PersistentCollection rowCollection = persistenceContext.getLoadContexts()
 					.getCollectionLoadContext( rs )
 					.getLoadingCollection( persister, collectionRowKey );
 
 			if ( rowCollection != null ) {
 				rowCollection.readFrom( rs, persister, descriptor, owner );
 			}
 
 		}
 		else if ( optionalKey != null ) {
 			// we did not find a collection element in the result set, so we
 			// ensure that a collection is created with the owner's identifier,
 			// since what we have is an empty collection
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Result set contains (possibly empty) collection: %s",
 						MessageHelper.collectionInfoString( persister, optionalKey, getFactory() ) );
 			}
 
 			persistenceContext.getLoadContexts()
 					.getCollectionLoadContext( rs )
 					.getLoadingCollection( persister, optionalKey ); // handle empty collection
 
 		}
 
 		// else no collection element, but also no owner
 
 	}
 
 	/**
 	 * If this is a collection initializer, we need to tell the session that a collection
 	 * is being initialized, to account for the possibility of the collection having
 	 * no elements (hence no rows in the result set).
 	 */
 	private void handleEmptyCollections(
 			final Serializable[] keys,
 			final Object resultSetId,
 			final SessionImplementor session) {
 
 		if ( keys != null ) {
 			final boolean debugEnabled = LOG.isDebugEnabled();
 			// this is a collection initializer, so we must create a collection
 			// for each of the passed-in keys, to account for the possibility
 			// that the collection is empty and has no rows in the result set
 			CollectionPersister[] collectionPersisters = getCollectionPersisters();
 			for ( CollectionPersister collectionPersister : collectionPersisters )
-				for ( int i = 0; i < keys.length; i++ ) {
+				for ( Serializable key : keys ) {
 					//handle empty collections
 					if ( debugEnabled ) {
 						LOG.debugf(
 								"Result set contains (possibly empty) collection: %s",
-								MessageHelper.collectionInfoString( collectionPersister, keys[i], getFactory() )
+								MessageHelper.collectionInfoString( collectionPersister, key, getFactory() )
 						);
 					}
 
 					session.getPersistenceContext()
 							.getLoadContexts()
 							.getCollectionLoadContext( (ResultSet) resultSetId )
-							.getLoadingCollection( collectionPersister, keys[i] );
+							.getLoadingCollection( collectionPersister, key );
 				}
 		}
 
 		// else this is not a collection initializer (and empty collections will
 		// be detected by looking for the owner's identifier in the result set)
 	}
 
 	/**
 	 * Read a row of <tt>Key</tt>s from the <tt>ResultSet</tt> into the given array.
 	 * Warning: this method is side-effecty.
 	 * <p/>
 	 * If an <tt>id</tt> is given, don't bother going to the <tt>ResultSet</tt>.
 	 */
 	private EntityKey getKeyFromResultSet(
 			final int i,
 			final Loadable persister,
 			final Serializable id,
 			final ResultSet rs,
 			final SessionImplementor session) throws HibernateException, SQLException {
 
 		Serializable resultId;
 
 		// if we know there is exactly 1 row, we can skip.
 		// it would be great if we could _always_ skip this;
 		// it is a problem for <key-many-to-one>
 
 		if ( isSingleRowLoader() && id != null ) {
 			resultId = id;
 		}
 		else {
 			final Type idType = persister.getIdentifierType();
 			resultId = (Serializable) idType.nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedKeyAliases(),
 					session,
 					null //problematic for <key-many-to-one>!
 			);
 
 			final boolean idIsResultId = id != null &&
 					resultId != null &&
 					idType.isEqual( id, resultId, factory );
 
 			if ( idIsResultId ) {
 				resultId = id; //use the id passed in
 			}
 		}
 
 		return resultId == null ? null : session.generateEntityKey( resultId, persister );
 	}
 
 	/**
 	 * Check the version of the object in the <tt>ResultSet</tt> against
 	 * the object version in the session cache, throwing an exception
 	 * if the version numbers are different
 	 */
 	private void checkVersion(
 			final int i,
 			final Loadable persister,
 			final Serializable id,
 			final Object entity,
 			final ResultSet rs,
 			final SessionImplementor session) throws HibernateException, SQLException {
 
 		Object version = session.getPersistenceContext().getEntry( entity ).getVersion();
 
 		if ( version != null ) { //null version means the object is in the process of being loaded somewhere else in the ResultSet
 			final VersionType versionType = persister.getVersionType();
 			final Object currentVersion = versionType.nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedVersionAliases(),
 					session,
 					null
 			);
 			if ( !versionType.isEqual(version, currentVersion) ) {
 				if ( session.getFactory().getStatistics().isStatisticsEnabled() ) {
 					session.getFactory().getStatisticsImplementor()
 							.optimisticFailure( persister.getEntityName() );
 				}
 				throw new StaleObjectStateException( persister.getEntityName(), id );
 			}
 		}
 
 	}
 
 	/**
 	 * Resolve any IDs for currently loaded objects, duplications within the
 	 * <tt>ResultSet</tt>, etc. Instantiate empty objects to be initialized from the
 	 * <tt>ResultSet</tt>. Return an array of objects (a row of results) and an
 	 * array of booleans (by side-effect) that determine whether the corresponding
 	 * object should be initialized.
 	 */
 	private Object[] getRow(
 			final ResultSet rs,
 			final Loadable[] persisters,
 			final EntityKey[] keys,
 			final Object optionalObject,
 			final EntityKey optionalObjectKey,
 			final LockMode[] lockModes,
 			final List hydratedObjects,
 			final SessionImplementor session) throws HibernateException, SQLException {
 		final int cols = persisters.length;
 		final EntityAliases[] descriptors = getEntityAliases();
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Result row: %s", StringHelper.toString( keys ) );
 		}
 
 		final Object[] rowResults = new Object[cols];
 
 		for ( int i = 0; i < cols; i++ ) {
 
 			Object object = null;
 			EntityKey key = keys[i];
 
 			if ( keys[i] == null ) {
 				//do nothing
 			}
 			else {
 				//If the object is already loaded, return the loaded one
 				object = session.getEntityUsingInterceptor( key );
 				if ( object != null ) {
 					//its already loaded so don't need to hydrate it
 					instanceAlreadyLoaded(
 							rs,
 							i,
 							persisters[i],
 							key,
 							object,
 							lockModes[i],
 							session
 					);
 				}
 				else {
 					object = instanceNotYetLoaded(
 							rs,
 							i,
 							persisters[i],
 							descriptors[i].getRowIdAlias(),
 							key,
 							lockModes[i],
 							optionalObjectKey,
 							optionalObject,
 							hydratedObjects,
 							session
 					);
 				}
 			}
 
 			rowResults[i] = object;
 
 		}
 
 		return rowResults;
 	}
 
 	/**
 	 * The entity instance is already in the session cache
 	 */
 	private void instanceAlreadyLoaded(
 			final ResultSet rs,
 			final int i,
 			final Loadable persister,
 			final EntityKey key,
 			final Object object,
 			final LockMode requestedLockMode,
 			final SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( !persister.isInstance( object ) ) {
 			throw new WrongClassException(
 					"loaded object was of wrong class " + object.getClass(),
 					key.getIdentifier(),
 					persister.getEntityName()
 			);
 		}
 
 		if ( LockMode.NONE != requestedLockMode && upgradeLocks() ) { //no point doing this if NONE was requested
 			final EntityEntry entry = session.getPersistenceContext().getEntry( object );
 			if ( entry.getLockMode().lessThan( requestedLockMode ) ) {
 				//we only check the version when _upgrading_ lock modes
 				if ( persister.isVersioned() ) {
 					checkVersion( i, persister, key.getIdentifier(), object, rs, session );
 				}
 				//we need to upgrade the lock mode to the mode requested
 				entry.setLockMode( requestedLockMode );
 			}
 		}
 	}
 
 
 	/**
 	 * The entity instance is not in the session cache
 	 */
 	private Object instanceNotYetLoaded(
 			final ResultSet rs,
 			final int i,
 			final Loadable persister,
 			final String rowIdAlias,
 			final EntityKey key,
 			final LockMode lockMode,
 			final EntityKey optionalObjectKey,
 			final Object optionalObject,
 			final List hydratedObjects,
 			final SessionImplementor session)
 	throws HibernateException, SQLException {
 		final String instanceClass = getInstanceClass(
 				rs,
 				i,
 				persister,
 				key.getIdentifier(),
 				session
 		);
 
 		// see if the entity defines reference caching, and if so use the cached reference (if one).
 		if ( session.getCacheMode().isGetEnabled() && persister.canUseReferenceCacheEntries() ) {
 			final Object cachedEntry = CacheHelper.fromSharedCache(
 					session,
 					session.generateCacheKey(
 							key.getIdentifier(),
 							persister.getEntityMetamodel().getEntityType(),
 							key.getEntityName()
 					),
 					persister.getCacheAccessStrategy()
 			);
 			if ( cachedEntry != null ) {
 				CacheEntry entry = (CacheEntry) persister.getCacheEntryStructure().destructure( cachedEntry, factory );
 				return ( (ReferenceCacheEntryImpl) entry ).getReference();
 			}
 		}
 
 		final Object object;
 		if ( optionalObjectKey != null && key.equals( optionalObjectKey ) ) {
 			//its the given optional object
 			object = optionalObject;
 		}
 		else {
 			// instantiate a new instance
 			object = session.instantiate( instanceClass, key.getIdentifier() );
 		}
 
 		//need to hydrate it.
 
 		// grab its state from the ResultSet and keep it in the Session
 		// (but don't yet initialize the object itself)
 		// note that we acquire LockMode.READ even if it was not requested
 		LockMode acquiredLockMode = lockMode == LockMode.NONE ? LockMode.READ : lockMode;
 		loadFromResultSet(
 				rs,
 				i,
 				object,
 				instanceClass,
 				key,
 				rowIdAlias,
 				acquiredLockMode,
 				persister,
 				session
 		);
 
 		//materialize associations (and initialize the object) later
 		hydratedObjects.add( object );
 
 		return object;
 	}
 
 	private boolean isEagerPropertyFetchEnabled(int i) {
 		boolean[] array = getEntityEagerPropertyFetches();
 		return array!=null && array[i];
 	}
 
 
 	/**
 	 * Hydrate the state an object from the SQL <tt>ResultSet</tt>, into
 	 * an array or "hydrated" values (do not resolve associations yet),
 	 * and pass the hydrates state to the session.
 	 */
 	private void loadFromResultSet(
 			final ResultSet rs,
 			final int i,
 			final Object object,
 			final String instanceEntityName,
 			final EntityKey key,
 			final String rowIdAlias,
 			final LockMode lockMode,
 			final Loadable rootPersister,
 			final SessionImplementor session) throws SQLException, HibernateException {
 
 		final Serializable id = key.getIdentifier();
 
 		// Get the persister for the _subclass_
 		final Loadable persister = (Loadable) getFactory().getEntityPersister( instanceEntityName );
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Initializing object from ResultSet: {0}", MessageHelper.infoString( persister, id, getFactory() ) );
 		}
 
 		boolean eagerPropertyFetch = isEagerPropertyFetchEnabled(i);
 
 		// add temp entry so that the next step is circular-reference
 		// safe - only needed because some types don't take proper
 		// advantage of two-phase-load (esp. components)
 		TwoPhaseLoad.addUninitializedEntity(
 				key,
 				object,
 				persister,
 				lockMode,
 				!eagerPropertyFetch,
 				session
 		);
 
 		//This is not very nice (and quite slow):
 		final String[][] cols = persister == rootPersister ?
 				getEntityAliases()[i].getSuffixedPropertyAliases() :
 				getEntityAliases()[i].getSuffixedPropertyAliases(persister);
 
 		final Object[] values = persister.hydrate(
 				rs,
 				id,
 				object,
 				rootPersister,
 				cols,
 				eagerPropertyFetch,
 				session
 		);
 
 		final Object rowId = persister.hasRowId() ? rs.getObject(rowIdAlias) : null;
 
 		final AssociationType[] ownerAssociationTypes = getOwnerAssociationTypes();
 		if ( ownerAssociationTypes != null && ownerAssociationTypes[i] != null ) {
 			String ukName = ownerAssociationTypes[i].getRHSUniqueKeyPropertyName();
 			if (ukName!=null) {
 				final int index = ( (UniqueKeyLoadable) persister ).getPropertyIndex(ukName);
 				final Type type = persister.getPropertyTypes()[index];
 
 				// polymorphism not really handled completely correctly,
 				// perhaps...well, actually its ok, assuming that the
 				// entity name used in the lookup is the same as the
 				// the one used here, which it will be
 
 				EntityUniqueKey euk = new EntityUniqueKey(
 						rootPersister.getEntityName(), //polymorphism comment above
 						ukName,
 						type.semiResolve( values[index], session, object ),
 						type,
 						persister.getEntityMode(),
 						session.getFactory()
 				);
 				session.getPersistenceContext().addEntity( euk, object );
 			}
 		}
 
 		TwoPhaseLoad.postHydrate(
 				persister,
 				id,
 				values,
 				rowId,
 				object,
 				lockMode,
 				!eagerPropertyFetch,
 				session
 		);
 
 	}
 
 	/**
 	 * Determine the concrete class of an instance in the <tt>ResultSet</tt>
 	 */
 	private String getInstanceClass(
 	        final ResultSet rs,
 	        final int i,
 	        final Loadable persister,
 	        final Serializable id,
 	        final SessionImplementor session) throws HibernateException, SQLException {
 
 		if ( persister.hasSubclasses() ) {
 
 			// Code to handle subclasses of topClass
 			final Object discriminatorValue = persister.getDiscriminatorType().nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedDiscriminatorAlias(),
 					session,
 					null
 			);
 
 			final String result = persister.getSubclassForDiscriminatorValue( discriminatorValue );
 
 			if ( result == null ) {
 				//woops we got an instance of another class hierarchy branch
 				throw new WrongClassException(
 						"Discriminator: " + discriminatorValue,
 						id,
 						persister.getEntityName()
 					);
 			}
 
 			return result;
 
 		}
 		else {
 			return persister.getEntityName();
 		}
 	}
 
 	/**
 	 * Advance the cursor to the first required row of the <tt>ResultSet</tt>
 	 */
 	private void advance(final ResultSet rs, final RowSelection selection) throws SQLException {
 
 		final int firstRow = LimitHelper.getFirstRow( selection );
 		if ( firstRow != 0 ) {
 			if ( getFactory().getSessionFactoryOptions().isScrollableResultSetsEnabled() ) {
 				// we can go straight to the first required row
 				rs.absolute( firstRow );
 			}
 			else {
 				// we need to step through the rows one row at a time (slow)
 				for ( int m = 0; m < firstRow; m++ ) {
 					rs.next();
 				}
 			}
 		}
 	}
 
 	/**
 	 * Build LIMIT clause handler applicable for given selection criteria. Returns {@link NoopLimitHandler} delegate
 	 * if dialect does not support LIMIT expression or processed query does not use pagination.
 	 *
 	 * @param selection Selection criteria.
 	 * @return LIMIT clause delegate.
 	 */
 	protected LimitHandler getLimitHandler(RowSelection selection) {
 		final LimitHandler limitHandler = getFactory().getDialect().getLimitHandler();
 		return LimitHelper.useLimit( limitHandler, selection ) ? limitHandler : NoopLimitHandler.INSTANCE;
 	}
 
 	private ScrollMode getScrollMode(boolean scroll, boolean hasFirstRow, boolean useLimitOffSet, QueryParameters queryParameters) {
-		final boolean canScroll = getFactory().getSettings().isScrollableResultSetsEnabled();
+		final boolean canScroll = getFactory().getSessionFactoryOptions().isScrollableResultSetsEnabled();
 		if ( canScroll ) {
 			if ( scroll ) {
 				return queryParameters.getScrollMode();
 			}
 			if ( hasFirstRow && !useLimitOffSet ) {
 				return ScrollMode.SCROLL_INSENSITIVE;
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Process query string by applying filters, LIMIT clause, locks and comments if necessary.
 	 * Finally execute SQL statement and advance to the first row.
 	 */
 	protected SqlStatementWrapper executeQueryStatement(
 			final QueryParameters queryParameters,
 			final boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			final SessionImplementor session) throws SQLException {
 		return executeQueryStatement( getSQLString(), queryParameters, scroll, afterLoadActions, session );
 	}
 
 	protected SqlStatementWrapper executeQueryStatement(
 			String sqlStatement,
 			QueryParameters queryParameters,
 			boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			SessionImplementor session) throws SQLException {
 
 		// Processing query filters.
 		queryParameters.processFilters( sqlStatement, session );
 
 		// Applying LIMIT clause.
 		final LimitHandler limitHandler = getLimitHandler(
 				queryParameters.getRowSelection()
 		);
 		String sql = limitHandler.processSql( queryParameters.getFilteredSQL(), queryParameters.getRowSelection() );
 
 		// Adding locks and comments.
 		sql = preprocessSQL( sql, queryParameters, getFactory().getDialect(), afterLoadActions );
 
 		final PreparedStatement st = prepareQueryStatement( sql, queryParameters, limitHandler, scroll, session );
 		return new SqlStatementWrapper( st, getResultSet( st, queryParameters.getRowSelection(), limitHandler, queryParameters.hasAutoDiscoverScalarTypes(), session ) );
 	}
 
 	/**
 	 * Obtain a <tt>PreparedStatement</tt> with all parameters pre-bound.
 	 * Bind JDBC-style <tt>?</tt> parameters, named parameters, and
 	 * limit parameters.
 	 */
 	protected final PreparedStatement prepareQueryStatement(
 	        String sql,
 	        final QueryParameters queryParameters,
 	        final LimitHandler limitHandler,
 	        final boolean scroll,
 	        final SessionImplementor session) throws SQLException, HibernateException {
 		final Dialect dialect = getFactory().getDialect();
 		final RowSelection selection = queryParameters.getRowSelection();
 		final boolean useLimit = LimitHelper.useLimit( limitHandler, selection );
 		final boolean hasFirstRow = LimitHelper.hasFirstRow( selection );
 		final boolean useLimitOffset = hasFirstRow && useLimit && limitHandler.supportsLimitOffset();
 		final boolean callable = queryParameters.isCallable();
 		final ScrollMode scrollMode = getScrollMode( scroll, hasFirstRow, useLimitOffset, queryParameters );
 		
 		PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareQueryStatement(
 				sql,
 				callable,
 				scrollMode
 		);
 
 		try {
 
 			int col = 1;
 			//TODO: can we limit stored procedures ?!
 			col += limitHandler.bindLimitParametersAtStartOfQuery( selection, st, col );
 
 			if (callable) {
 				col = dialect.registerResultSetOutParameter( (CallableStatement)st, col );
 			}
 
 			col += bindParameterValues( st, queryParameters, col, session );
 
 			col += limitHandler.bindLimitParametersAtEndOfQuery( selection, st, col );
 
 			limitHandler.setMaxRows( selection, st );
 
 			if ( selection != null ) {
 				if ( selection.getTimeout() != null ) {
 					st.setQueryTimeout( selection.getTimeout() );
 				}
 				if ( selection.getFetchSize() != null ) {
 					st.setFetchSize( selection.getFetchSize() );
 				}
 			}
 
 			// handle lock timeout...
 			LockOptions lockOptions = queryParameters.getLockOptions();
 			if ( lockOptions != null ) {
 				if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 					if ( !dialect.supportsLockTimeouts() ) {
 						if ( LOG.isDebugEnabled() ) {
 							LOG.debugf(
 									"Lock timeout [%s] requested but dialect reported to not support lock timeouts",
 									lockOptions.getTimeOut()
 							);
 						}
 					}
 					else if ( dialect.isLockTimeoutParameterized() ) {
 						st.setInt( col++, lockOptions.getTimeOut() );
 					}
 				}
 			}
 
 			if ( LOG.isTraceEnabled() )
 			   LOG.tracev( "Bound [{0}] parameters total", col );
 		}
 		catch ( SQLException sqle ) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 		catch ( HibernateException he ) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw he;
 		}
 
 		return st;
 	}
 
 	/**
 	 * Bind all parameter values into the prepared statement in preparation
 	 * for execution.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 */
 	protected int bindParameterValues(
 			PreparedStatement statement,
 			QueryParameters queryParameters,
 			int startIndex,
 			SessionImplementor session) throws SQLException {
 		int span = 0;
 		span += bindPositionalParameters( statement, queryParameters, startIndex, session );
 		span += bindNamedParameters( statement, queryParameters.getNamedParameters(), startIndex + span, session );
 		return span;
 	}
 
 	/**
 	 * Bind positional parameter values to the JDBC prepared statement.
 	 * <p/>
 	 * Positional parameters are those specified by JDBC-style ? parameters
 	 * in the source query.  It is (currently) expected that these come
 	 * before any named parameters in the source query.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindPositionalParameters(
 			final PreparedStatement statement,
 			final QueryParameters queryParameters,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		final Object[] values = queryParameters.getFilteredPositionalParameterValues();
 		final Type[] types = queryParameters.getFilteredPositionalParameterTypes();
 		int span = 0;
 		for ( int i = 0; i < values.length; i++ ) {
 			types[i].nullSafeSet( statement, values[i], startIndex + span, session );
 			span += types[i].getColumnSpan( getFactory() );
 		}
 		return span;
 	}
 
 	/**
 	 * Bind named parameters to the JDBC prepared statement.
 	 * <p/>
 	 * This is a generic implementation, the problem being that in the
 	 * general case we do not know enough information about the named
 	 * parameters to perform this in a complete manner here.  Thus this
 	 * is generally overridden on subclasses allowing named parameters to
 	 * apply the specific behavior.  The most usual limitation here is that
 	 * we need to assume the type span is always one...
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param namedParams A map of parameter names to values
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindNamedParameters(
 			final PreparedStatement statement,
 			final Map<String, TypedValue> namedParams,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		int result = 0;
 		if ( CollectionHelper.isEmpty( namedParams ) ) {
 			return result;
 		}
 
 		for ( String name : namedParams.keySet() ) {
 			TypedValue typedValue = namedParams.get( name );
 			int columnSpan = typedValue.getType().getColumnSpan( getFactory() );
 			int[] locs = getNamedParameterLocs( name );
 			for ( int loc : locs ) {
 				if ( DEBUG_ENABLED ) {
 					LOG.debugf(
 							"bindNamedParameters() %s -> %s [%s]",
 							typedValue.getValue(),
 							name,
 							loc + startIndex
 					);
 				}
 				int start = loc * columnSpan + startIndex;
 				typedValue.getType().nullSafeSet( statement, typedValue.getValue(), start, session );
 			}
 			result += locs.length;
 		}
 		return result;
 	}
 
 	public int[] getNamedParameterLocs(String name) {
 		throw new AssertionFailure("no named parameters");
 	}
 
 	/**
 	 * Execute given <tt>PreparedStatement</tt>, advance to the first result and return SQL <tt>ResultSet</tt>.
 	 */
 	protected final ResultSet getResultSet(
 			final PreparedStatement st,
 			final RowSelection selection,
 			final LimitHandler limitHandler,
 			final boolean autodiscovertypes,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		try {
 			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 			rs = wrapResultSetIfEnabled( rs , session );
 
 			if ( !limitHandler.supportsLimitOffset() || !LimitHelper.useLimit( limitHandler, selection ) ) {
 				advance( rs, selection );
 			}
 
 			if ( autodiscovertypes ) {
 				autoDiscoverTypes( rs );
 			}
 			return rs;
 		}
 		catch ( SQLException sqle ) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 	}
 
 	protected void autoDiscoverTypes(ResultSet rs) {
 		throw new AssertionFailure("Auto discover types not supported in this loader");
 
 	}
 
 	private ResultSet wrapResultSetIfEnabled(final ResultSet rs, final SessionImplementor session) {
 		if ( session.getFactory().getSessionFactoryOptions().isWrapResultSetsEnabled() ) {
 			try {
 				LOG.debugf( "Wrapping result set [%s]", rs );
 				return session.getFactory()
 						.getServiceRegistry()
 						.getService( JdbcServices.class )
 						.getResultSetWrapper().wrap( rs, retreiveColumnNameToIndexCache( rs ) );
 			}
 			catch(SQLException e) {
 				LOG.unableToWrapResultSet( e );
 				return rs;
 			}
 		}
 		else {
 			return rs;
 		}
 	}
 
 	private ColumnNameCache retreiveColumnNameToIndexCache(final ResultSet rs) throws SQLException {
 		final ColumnNameCache cache = columnNameCache;
 		if ( cache == null ) {
 			//there is no need for a synchronized second check, as in worst case
 			//we'll have allocated an unnecessary ColumnNameCache
 			LOG.trace( "Building columnName -> columnIndex cache" );
 			columnNameCache = new ColumnNameCache( rs.getMetaData().getColumnCount() );
 			return columnNameCache;
 		}
 		else {
 			return cache;
 		}
 	}
 
 	/**
 	 * Called by subclasses that load entities
 	 */
 	protected final List loadEntity(
 			final SessionImplementor session,
 			final Object id,
 			final Type identifierType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalIdentifier,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Loading entity: %s", MessageHelper.infoString( persister, id, identifierType, getFactory() ) );
 		}
 
 		List result;
 		try {
 			QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( new Type[] { identifierType } );
 			qp.setPositionalParameterValues( new Object[] { id } );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( optionalEntityName );
 			qp.setOptionalId( optionalIdentifier );
 			qp.setLockOptions( lockOptions );
 			result = doQueryAndInitializeNonLazyCollections( session, qp, false );
 		}
 		catch ( SQLException sqle ) {
 			final Loadable[] persisters = getEntityPersisters();
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load an entity: " +
 			        MessageHelper.infoString( persisters[persisters.length-1], id, identifierType, getFactory() ),
 			        getSQLString()
 			);
 		}
 
 		LOG.debug( "Done entity load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by subclasses that load entities
 	 * @param persister only needed for logging
 	 */
 	protected final List loadEntity(
 	        final SessionImplementor session,
 	        final Object key,
 	        final Object index,
 	        final Type keyType,
 	        final Type indexType,
 	        final EntityPersister persister) throws HibernateException {
 		LOG.debug( "Loading collection element by index" );
 
 		List result;
 		try {
 			result = doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters(
 							new Type[] { keyType, indexType },
 							new Object[] { key, index }
 					),
 					false
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load collection element by index",
 			        getSQLString()
 			);
 		}
 
 		LOG.debug( "Done entity load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by wrappers that batch load entities
 	 */
 	public final List loadEntityBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type idType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalId,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
 		if ( LOG.isDebugEnabled() )
 			LOG.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, getFactory() ) );
 
 		Type[] types = new Type[ids.length];
 		Arrays.fill( types, idType );
 		List result;
 		try {
 			QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( types );
 			qp.setPositionalParameterValues( ids );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( optionalEntityName );
 			qp.setOptionalId( optionalId );
 			qp.setLockOptions( lockOptions );
 			result = doQueryAndInitializeNonLazyCollections( session, qp, false );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load an entity batch: " +
 			        MessageHelper.infoString( getEntityPersisters()[0], ids, getFactory() ),
 			        getSQLString()
 			);
 		}
 
 		LOG.debug( "Done entity batch load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by subclasses that initialize collections
 	 */
 	public final void loadCollection(
 	        final SessionImplementor session,
 	        final Serializable id,
 	        final Type type) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Loading collection: %s",
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() )
 			);
 		}
 
 		Serializable[] ids = new Serializable[]{id};
 		try {
 			doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters( new Type[]{type}, ids, ids ),
 					true
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() ),
 					getSQLString()
 			);
 		}
 
 		LOG.debug( "Done loading collection" );
 	}
 
 	/**
 	 * Called by wrappers that batch initialize collections
 	 */
 	public final void loadCollectionBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type type) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Batch loading collection: %s",
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() )
 			);
 		}
 
 		Type[] idTypes = new Type[ids.length];
 		Arrays.fill( idTypes, type );
 		try {
 			doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters( idTypes, ids, ids ),
 					true
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection batch: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
 					getSQLString()
 			);
 		}
 
 		LOG.debug( "Done batch load" );
 	}
 
 	/**
 	 * Called by subclasses that batch initialize collections
 	 */
 	protected final void loadCollectionSubselect(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Object[] parameterValues,
 			final Type[] parameterTypes,
 			final Map<String, TypedValue> namedParameters,
 			final Type type) throws HibernateException {
 		final Type[] idTypes = new Type[ids.length];
 		Arrays.fill( idTypes, type );
 		try {
 			doQueryAndInitializeNonLazyCollections( session,
 					new QueryParameters( parameterTypes, parameterValues, namedParameters, ids ),
 					true
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not load collection by subselect: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
 					getSQLString()
 			);
 		}
 	}
 
 	/**
 	 * Return the query results, using the query cache, called
 	 * by subclasses that implement cacheable queries
 	 */
 	protected List list(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes) throws HibernateException {
 		final boolean cacheable = factory.getSessionFactoryOptions().isQueryCacheEnabled() &&
 			queryParameters.isCacheable();
 
 		if ( cacheable ) {
 			return listUsingQueryCache( session, queryParameters, querySpaces, resultTypes );
 		}
 		else {
 			return listIgnoreQueryCache( session, queryParameters );
 		}
 	}
 
 	private List listIgnoreQueryCache(SessionImplementor session, QueryParameters queryParameters) {
 		return getResultList( doList( session, queryParameters ), queryParameters.getResultTransformer() );
 	}
 
 	private List listUsingQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes) {
 
 		QueryCache queryCache = factory.getQueryCache( queryParameters.getCacheRegion() );
 
 		QueryKey key = generateQueryKey( session, queryParameters );
 
 		if ( querySpaces == null || querySpaces.size() == 0 ) {
 			LOG.tracev( "Unexpected querySpaces is {0}", ( querySpaces == null ? querySpaces : "empty" ) );
 		}
 		else {
 			LOG.tracev( "querySpaces is {0}", querySpaces );
 		}
 
 		List result = getResultFromQueryCache(
 				session,
 				queryParameters,
 				querySpaces,
 				resultTypes,
 				queryCache,
 				key
 		);
 
 		if ( result == null ) {
 			result = doList( session, queryParameters, key.getResultTransformer() );
 
 			putResultInQueryCache(
 					session,
 					queryParameters,
 					resultTypes,
 					queryCache,
 					key,
 					result
 			);
 		}
 
 		ResultTransformer resolvedTransformer = resolveResultTransformer( queryParameters.getResultTransformer() );
 		if ( resolvedTransformer != null ) {
 			result = (
 					areResultSetRowsTransformedImmediately() ?
 							key.getResultTransformer().retransformResults(
 									result,
 									getResultRowAliases(),
 									queryParameters.getResultTransformer(),
 									includeInResultRow()
 							) :
 							key.getResultTransformer().untransformToTuples(
 									result
 							)
 			);
 		}
 
 		return getResultList( result, queryParameters.getResultTransformer() );
 	}
 
 	private QueryKey generateQueryKey(
 			SessionImplementor session,
 			QueryParameters queryParameters) {
 		return QueryKey.generateQueryKey(
 				getSQLString(),
 				queryParameters,
 				FilterKey.createFilterKeys( session.getLoadQueryInfluencers().getEnabledFilters() ),
 				session,
 				createCacheableResultTransformer( queryParameters )
 		);
 	}
 
 	private CacheableResultTransformer createCacheableResultTransformer(QueryParameters queryParameters) {
 		return CacheableResultTransformer.create(
 				queryParameters.getResultTransformer(),
 				getResultRowAliases(),
 				includeInResultRow()
 		);
 	}
 
 	private List getResultFromQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key) {
 		List result = null;
 
 		if ( session.getCacheMode().isGetEnabled() ) {
 			boolean isImmutableNaturalKeyLookup =
 					queryParameters.isNaturalKeyLookup() &&
 							resultTypes.length == 1 &&
 							resultTypes[0].isEntityType() &&
 							getEntityPersister( EntityType.class.cast( resultTypes[0] ) )
 									.getEntityMetamodel()
 									.hasImmutableNaturalId();
 
 			final PersistenceContext persistenceContext = session.getPersistenceContext();
 			boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 			if ( queryParameters.isReadOnlyInitialized() ) {
 				// The read-only/modifiable mode for the query was explicitly set.
 				// Temporarily set the default read-only/modifiable setting to the query's setting.
 				persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 			}
 			else {
 				// The read-only/modifiable setting for the query was not initialized.
 				// Use the default read-only/modifiable from the persistence context instead.
 				queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 			}
 			try {
 				result = queryCache.get(
 						key,
 						key.getResultTransformer().getCachedResultTypes( resultTypes ),
 						isImmutableNaturalKeyLookup,
 						querySpaces,
 						session
 				);
 			}
 			finally {
 				persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 			}
 
 			if ( factory.getStatistics().isStatisticsEnabled() ) {
 				if ( result == null ) {
 					factory.getStatisticsImplementor()
 							.queryCacheMiss( getQueryIdentifier(), queryCache.getRegion().getName() );
 				}
 				else {
 					factory.getStatisticsImplementor()
 							.queryCacheHit( getQueryIdentifier(), queryCache.getRegion().getName() );
 				}
 			}
 		}
 
 		return result;
 	}
 
 	private EntityPersister getEntityPersister(EntityType entityType) {
 		return factory.getEntityPersister( entityType.getAssociatedEntityName() );
 	}
 
 	protected void putResultInQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key,
 			final List result) {
 		if ( session.getCacheMode().isPutEnabled() ) {
 			boolean put = queryCache.put(
 					key,
 					key.getResultTransformer().getCachedResultTypes( resultTypes ),
 					result,
 					queryParameters.isNaturalKeyLookup(),
 					session
 			);
 			if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 				factory.getStatisticsImplementor()
 						.queryCachePut( getQueryIdentifier(), queryCache.getRegion().getName() );
 			}
 		}
 	}
 
 	/**
 	 * Actually execute a query, ignoring the query cache
 	 */
 
 	protected List doList(final SessionImplementor session, final QueryParameters queryParameters)
 			throws HibernateException {
 		return doList( session, queryParameters, null);
 	}
 
 	private List doList(final SessionImplementor session,
 						final QueryParameters queryParameters,
 						final ResultTransformer forcedResultTransformer)
 			throws HibernateException {
 
 		final boolean stats = getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) {
 			startTime = System.nanoTime();
 		}
 
 		List result;
 		try {
 			result = doQueryAndInitializeNonLazyCollections( session, queryParameters, true, forcedResultTransformer );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query",
 					getSQLString()
 			);
 		}
 
 		if ( stats ) {
 			final long endTime = System.nanoTime();
 			final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 			getFactory().getStatisticsImplementor().queryExecuted(
 					getQueryIdentifier(),
 					result.size(),
 					milliseconds
 			);
 		}
 
 		return result;
 	}
 
 	/**
 	 * Check whether the current loader can support returning ScrollableResults.
 	 *
 	 * @throws HibernateException
 	 */
 	protected void checkScrollability() throws HibernateException {
 		// Allows various loaders (ok mainly the QueryLoader :) to check
 		// whether scrolling of their result set should be allowed.
 		//
 		// By default it is allowed.
 	}
 
 	/**
 	 * Does the result set to be scrolled contain collection fetches?
 	 *
 	 * @return True if it does, and thus needs the special fetching scroll
 	 * functionality; false otherwise.
 	 */
 	protected boolean needsFetchingScroll() {
 		return false;
 	}
 
 	/**
 	 * Return the query results, as an instance of <tt>ScrollableResults</tt>
 	 *
 	 * @param queryParameters The parameters with which the query should be executed.
 	 * @param returnTypes The expected return types of the query
 	 * @param holderInstantiator If the return values are expected to be wrapped
 	 * in a holder, this is the thing that knows how to wrap them.
 	 * @param session The session from which the scroll request originated.
 	 * @return The ScrollableResults instance.
 	 * @throws HibernateException Indicates an error executing the query, or constructing
 	 * the ScrollableResults.
 	 */
 	protected ScrollableResults scroll(
 			final QueryParameters queryParameters,
 			final Type[] returnTypes,
 			final HolderInstantiator holderInstantiator,
 			final SessionImplementor session) throws HibernateException {
 		checkScrollability();
 
 		final boolean stats = getQueryIdentifier() != null &&
 				getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) {
 			startTime = System.nanoTime();
 		}
 
 		try {
 			// Don't use Collections#emptyList() here -- follow on locking potentially adds AfterLoadActions,
 			// so the list cannot be immutable.
 			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, true, new ArrayList<AfterLoadAction>(), session );
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
 
 			if ( stats ) {
 				final long endTime = System.nanoTime();
 				final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 				getFactory().getStatisticsImplementor().queryExecuted(
 						getQueryIdentifier(),
 						0,
 						milliseconds
 				);
 			}
 
 			if ( needsFetchingScroll() ) {
 				return new FetchingScrollableResultsImpl(
 						rs,
 						st,
 						session,
 						this,
 						queryParameters,
 						returnTypes,
 						holderInstantiator
 				);
 			}
 			else {
 				return new ScrollableResultsImpl(
 						rs,
 						st,
 						session,
 						this,
 						queryParameters,
 						returnTypes,
 						holderInstantiator
 				);
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using scroll",
 					getSQLString()
 			);
 		}
 
 	}
 
 	/**
 	 * Calculate and cache select-clause suffixes. Must be
 	 * called by subclasses after instantiation.
 	 */
 	protected void postInstantiate() {}
 
 	/**
 	 * Get the result set descriptor
 	 */
 	protected abstract EntityAliases[] getEntityAliases();
 
 	protected abstract CollectionAliases[] getCollectionAliases();
 
 	/**
 	 * Identifies the query for statistics reporting, if null,
 	 * no statistics will be reported
 	 */
 	protected String getQueryIdentifier() {
 		return null;
 	}
 
 	public final SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getSQLString() + ')';
 	}
 
 	/**
 	 * Wrapper class for {@link Statement} and associated {@link ResultSet}.
 	 */
 	protected static class SqlStatementWrapper {
 		private final Statement statement;
 		private final ResultSet resultSet;
 
 		private SqlStatementWrapper(Statement statement, ResultSet resultSet) {
 			this.resultSet = resultSet;
 			this.statement = statement;
 		}
 
 		public ResultSet getResultSet() {
 			return resultSet;
 		}
 
 		public Statement getStatement() {
 			return statement;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinLoader.java
index 9d295cbe25..c0689f0d1b 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinLoader.java
@@ -1,133 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.loader;
+
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.type.EntityType;
 
 /**
  * Implements logic for walking a tree of associated classes.
  *
  * Generates an SQL select string containing all properties of those classes.
  * Tables are joined using an ANSI-style left outer join.
  *
  * @author Gavin King
  */
 public abstract class OuterJoinLoader extends BasicLoader {
-
 	protected Loadable[] persisters;
 	protected CollectionPersister[] collectionPersisters;
 	protected int[] collectionOwners;
 	protected String[] aliases;
 	private LockOptions lockOptions;
 	protected LockMode[] lockModeArray;
 	protected int[] owners;
 	protected EntityType[] ownerAssociationTypes;
 	protected String sql;
 	protected String[] suffixes;
 	protected String[] collectionSuffixes;
 
-    private LoadQueryInfluencers loadQueryInfluencers;
+	private LoadQueryInfluencers loadQueryInfluencers;
 
 	protected final Dialect getDialect() {
-    	return getFactory().getDialect();
-    }
+		return getFactory().getDialect();
+	}
 
 	public OuterJoinLoader(
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		super( factory );
 		this.loadQueryInfluencers = loadQueryInfluencers;
 	}
 
 	protected String[] getSuffixes() {
 		return suffixes;
 	}
 
 	protected String[] getCollectionSuffixes() {
 		return collectionSuffixes;
 	}
 
 	@Override
 	public final String getSQLString() {
 		return sql;
 	}
 
 	protected final Loadable[] getEntityPersisters() {
 		return persisters;
 	}
 
 	protected int[] getOwners() {
 		return owners;
 	}
 
 	protected EntityType[] getOwnerAssociationTypes() {
 		return ownerAssociationTypes;
 	}
 
 	protected LockMode[] getLockModes(LockOptions lockOptions) {
 		return lockModeArray;
 	}
 
 	protected LockOptions getLockOptions() {
 		return lockOptions;
 	}
 
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return loadQueryInfluencers;
 	}
 
 	protected final String[] getAliases() {
 		return aliases;
 	}
 
 	protected final CollectionPersister[] getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	protected final int[] getCollectionOwners() {
 		return collectionOwners;
 	}
 
 	protected void initFromWalker(JoinWalker walker) {
 		persisters = walker.getPersisters();
 		collectionPersisters = walker.getCollectionPersisters();
 		ownerAssociationTypes = walker.getOwnerAssociationTypes();
 		lockOptions = walker.getLockModeOptions();
 		lockModeArray = walker.getLockModeArray();
 		suffixes = walker.getSuffixes();
 		collectionSuffixes = walker.getCollectionSuffixes();
 		owners = walker.getOwners();
 		collectionOwners = walker.getCollectionOwners();
 		sql = walker.getSQLString();
 		aliases = walker.getAliases();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinableAssociation.java b/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinableAssociation.java
index b7b2c95ed9..919e4cba5a 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinableAssociation.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinableAssociation.java
@@ -1,230 +1,231 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
+
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 
 /**
  * Part of the Hibernate SQL rendering internals.  This class represents
  * a joinable association.
  *
  * @author Gavin King
  */
 public final class OuterJoinableAssociation {
 	private final PropertyPath propertyPath;
 	private final AssociationType joinableType;
 	private final Joinable joinable;
 	private final String lhsAlias; // belong to other persister
 	private final String[] lhsColumns; // belong to other persister
 	private final String rhsAlias;
 	private final String[] rhsColumns;
 	private final JoinType joinType;
 	private final String on;
 	private final Map enabledFilters;
 	private final boolean hasRestriction;
 
 	public static OuterJoinableAssociation createRoot(
 			AssociationType joinableType,
 			String alias,
 			SessionFactoryImplementor factory) {
 		return new OuterJoinableAssociation(
 				new PropertyPath(),
 				joinableType,
 				null,
 				null,
 				alias,
 				JoinType.LEFT_OUTER_JOIN,
 				null,
 				false,
 				factory,
 				Collections.EMPTY_MAP
 		);
 	}
 
 	public OuterJoinableAssociation(
 			PropertyPath propertyPath,
 			AssociationType joinableType,
 			String lhsAlias,
 			String[] lhsColumns,
 			String rhsAlias,
 			JoinType joinType,
 			String withClause,
 			boolean hasRestriction,
 			SessionFactoryImplementor factory,
 			Map enabledFilters) throws MappingException {
 		this.propertyPath = propertyPath;
 		this.joinableType = joinableType;
 		this.lhsAlias = lhsAlias;
 		this.lhsColumns = lhsColumns;
 		this.rhsAlias = rhsAlias;
 		this.joinType = joinType;
-		this.joinable = joinableType.getAssociatedJoinable(factory);
-		this.rhsColumns = JoinHelper.getRHSColumnNames(joinableType, factory);
-		this.on = joinableType.getOnCondition(rhsAlias, factory, enabledFilters)
-			+ ( withClause == null || withClause.trim().length() == 0 ? "" : " and ( " + withClause + " )" );
+		this.joinable = joinableType.getAssociatedJoinable( factory );
+		this.rhsColumns = JoinHelper.getRHSColumnNames( joinableType, factory );
+		this.on = joinableType.getOnCondition( rhsAlias, factory, enabledFilters )
+				+ ( withClause == null || withClause.trim().length() == 0 ? "" : " and ( " + withClause + " )" );
 		this.hasRestriction = hasRestriction;
 		this.enabledFilters = enabledFilters; // needed later for many-to-many/filter application
 	}
 
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	public JoinType getJoinType() {
 		return joinType;
 	}
 
 	public String getLhsAlias() {
 		return lhsAlias;
 	}
 
 	public String getRHSAlias() {
 		return rhsAlias;
 	}
 
 	public String getRhsAlias() {
 		return rhsAlias;
 	}
 
 	private boolean isOneToOne() {
-		if ( joinableType.isEntityType() )  {
+		if ( joinableType.isEntityType() ) {
 			EntityType etype = (EntityType) joinableType;
 			return etype.isOneToOne() /*&& etype.isReferenceToPrimaryKey()*/;
 		}
 		else {
 			return false;
 		}
 	}
-	
+
 	public AssociationType getJoinableType() {
 		return joinableType;
 	}
-	
+
 	public String getRHSUniqueKeyName() {
 		return joinableType.getRHSUniqueKeyPropertyName();
 	}
 
 	public boolean isCollection() {
 		return joinableType.isCollectionType();
 	}
 
 	public Joinable getJoinable() {
 		return joinable;
 	}
 
 	public boolean hasRestriction() {
 		return hasRestriction;
 	}
 
 	public int getOwner(final List associations) {
 		if ( isOneToOne() || isCollection() ) {
-			return getPosition(lhsAlias, associations);
+			return getPosition( lhsAlias, associations );
 		}
 		else {
 			return -1;
 		}
 	}
 
 	/**
 	 * Get the position of the join with the given alias in the
 	 * list of joins
 	 */
 	private static int getPosition(String lhsAlias, List associations) {
 		int result = 0;
 		for ( Object association : associations ) {
 			final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;
 			if ( oj.getJoinable().consumesEntityAlias() /*|| oj.getJoinable().consumesCollectionAlias() */ ) {
 				if ( oj.rhsAlias.equals( lhsAlias ) ) {
 					return result;
 				}
 				result++;
 			}
 		}
 		return -1;
 	}
 
 	public void addJoins(JoinFragment outerjoin) throws MappingException {
 		outerjoin.addJoin(
-			joinable.getTableName(),
-			rhsAlias,
-			lhsColumns,
-			rhsColumns,
-			joinType,
-			on
+				joinable.getTableName(),
+				rhsAlias,
+				lhsColumns,
+				rhsColumns,
+				joinType,
+				on
 		);
 		outerjoin.addJoins(
-			joinable.fromJoinFragment(rhsAlias, false, true),
-			joinable.whereJoinFragment(rhsAlias, false, true)
+				joinable.fromJoinFragment( rhsAlias, false, true ),
+				joinable.whereJoinFragment( rhsAlias, false, true )
 		);
 	}
 
 	public void validateJoin(String path) throws MappingException {
-		if ( rhsColumns==null || lhsColumns==null
-				|| lhsColumns.length!=rhsColumns.length || lhsColumns.length==0 ) {
-			throw new MappingException("invalid join columns for association: " + path);
+		if ( rhsColumns == null || lhsColumns == null
+				|| lhsColumns.length != rhsColumns.length || lhsColumns.length == 0 ) {
+			throw new MappingException( "invalid join columns for association: " + path );
 		}
 	}
 
 	public boolean isManyToManyWith(OuterJoinableAssociation other) {
 		if ( joinable.isCollection() ) {
-			QueryableCollection persister = ( QueryableCollection ) joinable;
+			QueryableCollection persister = (QueryableCollection) joinable;
 			if ( persister.isManyToMany() ) {
 				return persister.getElementType() == other.getJoinableType();
 			}
 		}
 		return false;
 	}
 
 	public void addManyToManyJoin(JoinFragment outerjoin, QueryableCollection collection) throws MappingException {
 		String manyToManyFilter = collection.getManyToManyFilterFragment( rhsAlias, enabledFilters );
 		String condition = "".equals( manyToManyFilter )
 				? on
 				: "".equals( on )
-						? manyToManyFilter
-						: on + " and " + manyToManyFilter;
+				? manyToManyFilter
+				: on + " and " + manyToManyFilter;
 		outerjoin.addJoin(
-		        joinable.getTableName(),
-		        rhsAlias,
-		        lhsColumns,
-		        rhsColumns,
-		        joinType,
-		        condition
+				joinable.getTableName(),
+				rhsAlias,
+				lhsColumns,
+				rhsColumns,
+				joinType,
+				condition
 		);
 		outerjoin.addJoins(
-			joinable.fromJoinFragment(rhsAlias, false, true),
-			joinable.whereJoinFragment(rhsAlias, false, true)
+				joinable.fromJoinFragment( rhsAlias, false, true ),
+				joinable.whereJoinFragment( rhsAlias, false, true )
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/collection/OneToManyJoinWalker.java b/hibernate-core/src/main/java/org/hibernate/loader/collection/OneToManyJoinWalker.java
index 89203000a5..10676ec667 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/collection/OneToManyJoinWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/collection/OneToManyJoinWalker.java
@@ -1,140 +1,151 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.loader.collection;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.loader.OuterJoinableAssociation;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.Select;
 
 /**
  * Walker for one-to-many associations
  *
- * @see OneToManyLoader
  * @author Gavin King
+ * @see OneToManyLoader
  */
 public class OneToManyJoinWalker extends CollectionJoinWalker {
 
 	private final QueryableCollection oneToManyPersister;
 
 	@Override
-    protected boolean isDuplicateAssociation(
-		final String foreignKeyTable,
-		final String[] foreignKeyColumns
-	) {
+	protected boolean isDuplicateAssociation(
+			final String foreignKeyTable,
+			final String[] foreignKeyColumns) {
 		//disable a join back to this same association
-		final boolean isSameJoin = oneToManyPersister.getTableName().equals(foreignKeyTable) &&
-			Arrays.equals( foreignKeyColumns, oneToManyPersister.getKeyColumnNames() );
+		final boolean isSameJoin = oneToManyPersister.getTableName().equals( foreignKeyTable ) &&
+				Arrays.equals( foreignKeyColumns, oneToManyPersister.getKeyColumnNames() );
 		return isSameJoin ||
-			super.isDuplicateAssociation(foreignKeyTable, foreignKeyColumns);
+				super.isDuplicateAssociation( foreignKeyTable, foreignKeyColumns );
 	}
 
 	public OneToManyJoinWalker(
 			QueryableCollection oneToManyPersister,
 			int batchSize,
 			String subquery,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		super( factory, loadQueryInfluencers );
 
 		this.oneToManyPersister = oneToManyPersister;
 
 		final OuterJoinLoadable elementPersister = (OuterJoinLoadable) oneToManyPersister.getElementPersister();
 		final String alias = generateRootAlias( oneToManyPersister.getRole() );
 
-		walkEntityTree(elementPersister, alias);
+		walkEntityTree( elementPersister, alias );
 
 		List allAssociations = new ArrayList();
-		allAssociations.addAll(associations);
-		allAssociations.add( OuterJoinableAssociation.createRoot( oneToManyPersister.getCollectionType(), alias, getFactory() ) );
-		initPersisters(allAssociations, LockMode.NONE);
-		initStatementString(elementPersister, alias, batchSize, subquery);
+		allAssociations.addAll( associations );
+		allAssociations.add(
+				OuterJoinableAssociation.createRoot(
+						oneToManyPersister.getCollectionType(),
+						alias,
+						getFactory()
+				)
+		);
+		initPersisters( allAssociations, LockMode.NONE );
+		initStatementString( elementPersister, alias, batchSize, subquery );
 	}
 
 	private void initStatementString(
-		final OuterJoinLoadable elementPersister,
-		final String alias,
-		final int batchSize,
-		final String subquery)
-	throws MappingException {
+			final OuterJoinLoadable elementPersister,
+			final String alias,
+			final int batchSize,
+			final String subquery)
+			throws MappingException {
 
 		final int joins = countEntityPersisters( associations );
 		suffixes = BasicLoader.generateSuffixes( joins + 1 );
 
 		final int collectionJoins = countCollectionPersisters( associations ) + 1;
 		collectionSuffixes = BasicLoader.generateSuffixes( joins + 1, collectionJoins );
 
 		StringBuilder whereString = whereString(
 				alias,
 				oneToManyPersister.getKeyColumnNames(),
 				subquery,
 				batchSize
-			);
+		);
 		String filter = oneToManyPersister.filterFragment( alias, getLoadQueryInfluencers().getEnabledFilters() );
 		whereString.insert( 0, StringHelper.moveAndToBeginning( filter ) );
 
-		JoinFragment ojf = mergeOuterJoins(associations);
+		JoinFragment ojf = mergeOuterJoins( associations );
 		Select select = new Select( getDialect() )
-			.setSelectClause(
-				oneToManyPersister.selectFragment(null, null, alias, suffixes[joins], collectionSuffixes[0], true) +
-				selectString(associations)
-			)
-			.setFromClause(
-				elementPersister.fromTableFragment(alias) +
-				elementPersister.fromJoinFragment(alias, true, true)
-			)
-			.setWhereClause( whereString.toString() )
-			.setOuterJoins(
-				ojf.toFromFragmentString(),
-				ojf.toWhereFragmentString() +
-				elementPersister.whereJoinFragment(alias, true, true)
-			);
-
-		select.setOrderByClause( orderBy( associations, oneToManyPersister.getSQLOrderByString(alias) ) );
-
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+				.setSelectClause(
+						oneToManyPersister.selectFragment(
+								null,
+								null,
+								alias,
+								suffixes[joins],
+								collectionSuffixes[0],
+								true
+						) +
+								selectString( associations )
+				)
+				.setFromClause(
+						elementPersister.fromTableFragment( alias ) +
+								elementPersister.fromJoinFragment( alias, true, true )
+				)
+				.setWhereClause( whereString.toString() )
+				.setOuterJoins(
+						ojf.toFromFragmentString(),
+						ojf.toWhereFragmentString() +
+								elementPersister.whereJoinFragment( alias, true, true )
+				);
+
+		select.setOrderByClause( orderBy( associations, oneToManyPersister.getSQLOrderByString( alias ) ) );
+
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "load one-to-many " + oneToManyPersister.getRole() );
 		}
 
 		sql = select.toStatementString();
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return getClass().getName() + '(' + oneToManyPersister.getRole() + ')';
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaInfoProvider.java b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaInfoProvider.java
index 3590e849d9..15aa252ff7 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaInfoProvider.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaInfoProvider.java
@@ -1,41 +1,43 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.loader.criteria;
 
 import java.io.Serializable;
 
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.type.Type;
 
 /**
  * @author David Mansfield
  */
 
 interface CriteriaInfoProvider {
-    String getName();
-    Serializable[] getSpaces();
-    PropertyMapping getPropertyMapping();
-    Type getType(String relativePath);
+	String getName();
+
+	Serializable[] getSpaces();
+
+	PropertyMapping getPropertyMapping();
+
+	Type getType(String relativePath);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaJoinWalker.java b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaJoinWalker.java
index 871cd3e122..30f0a17730 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaJoinWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaJoinWalker.java
@@ -1,312 +1,327 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.criteria;
+
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.Criteria;
 import org.hibernate.FetchMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CriteriaImpl;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.AbstractEntityJoinWalker;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 
 /**
  * A <tt>JoinWalker</tt> for <tt>Criteria</tt> queries.
  *
- * @see CriteriaLoader
  * @author Gavin King
+ * @see CriteriaLoader
  */
 public class CriteriaJoinWalker extends AbstractEntityJoinWalker {
 
 	//TODO: add a CriteriaImplementor interface
 	//      this class depends directly upon CriteriaImpl in the impl package...
 
 	private final CriteriaQueryTranslator translator;
 	private final Set querySpaces;
 	private final Type[] resultTypes;
 	private final boolean[] includeInResultRow;
 
 	//the user visible aliases, which are unknown to the superclass,
 	//these are not the actual "physical" SQL aliases
 	private final String[] userAliases;
 	private final List<String> userAliasList = new ArrayList<String>();
 	private final List<Type> resultTypeList = new ArrayList<Type>();
 	private final List<Boolean> includeInResultRowList = new ArrayList<Boolean>();
 
 	public Type[] getResultTypes() {
 		return resultTypes;
 	}
 
 	public String[] getUserAliases() {
 		return userAliases;
 	}
 
 	public boolean[] includeInResultRow() {
 		return includeInResultRow;
 	}
 
 	public CriteriaJoinWalker(
-			final OuterJoinLoadable persister, 
+			final OuterJoinLoadable persister,
 			final CriteriaQueryTranslator translator,
-			final SessionFactoryImplementor factory, 
-			final CriteriaImpl criteria, 
+			final SessionFactoryImplementor factory,
+			final CriteriaImpl criteria,
 			final String rootEntityName,
 			final LoadQueryInfluencers loadQueryInfluencers) {
 		this( persister, translator, factory, criteria, rootEntityName, loadQueryInfluencers, null );
 	}
 
 	public CriteriaJoinWalker(
 			final OuterJoinLoadable persister,
 			final CriteriaQueryTranslator translator,
 			final SessionFactoryImplementor factory,
 			final CriteriaImpl criteria,
 			final String rootEntityName,
 			final LoadQueryInfluencers loadQueryInfluencers,
 			final String alias) {
 		super( persister, factory, loadQueryInfluencers, alias );
 
 		this.translator = translator;
 
 		querySpaces = translator.getQuerySpaces();
 
-		if ( translator.hasProjection() ) {			
+		if ( translator.hasProjection() ) {
 			initProjection(
-					translator.getSelect(), 
-					translator.getWhereCondition(), 
+					translator.getSelect(),
+					translator.getWhereCondition(),
 					translator.getOrderBy(),
 					translator.getGroupBy(),
-					LockOptions.NONE  
-				);
+					LockOptions.NONE
+			);
 			resultTypes = translator.getProjectedTypes();
 			userAliases = translator.getProjectedAliases();
-			includeInResultRow = new boolean[ resultTypes.length ];
+			includeInResultRow = new boolean[resultTypes.length];
 			Arrays.fill( includeInResultRow, true );
 		}
 		else {
 			initAll( translator.getWhereCondition(), translator.getOrderBy(), LockOptions.NONE );
 			// root entity comes last
 			userAliasList.add( criteria.getAlias() ); //root entity comes *last*
 			resultTypeList.add( translator.getResultType( criteria ) );
 			includeInResultRowList.add( true );
 			userAliases = ArrayHelper.toStringArray( userAliasList );
 			resultTypes = ArrayHelper.toTypeArray( resultTypeList );
 			includeInResultRow = ArrayHelper.toBooleanArray( includeInResultRowList );
 		}
 	}
+
 	@Override
 	protected JoinType getJoinType(
 			OuterJoinLoadable persister,
 			final PropertyPath path,
 			int propertyNumber,
 			AssociationType associationType,
 			FetchMode metadataFetchMode,
 			CascadeStyle metadataCascadeStyle,
 			String lhsTable,
 			String[] lhsColumns,
 			final boolean nullable,
 			final int currentDepth) throws MappingException {
 		final JoinType resolvedJoinType;
 		if ( translator.isJoin( path.getFullPath() ) ) {
 			resolvedJoinType = translator.getJoinType( path.getFullPath() );
 		}
 		else {
 			if ( translator.hasProjection() ) {
 				resolvedJoinType = JoinType.NONE;
 			}
 			else {
 				FetchMode fetchMode = translator.getRootCriteria().getFetchMode( path.getFullPath() );
 				if ( isDefaultFetchMode( fetchMode ) ) {
 					if ( persister != null ) {
 						if ( isJoinFetchEnabledByProfile( persister, path, propertyNumber ) ) {
 							if ( isDuplicateAssociation( lhsTable, lhsColumns, associationType ) ) {
 								resolvedJoinType = JoinType.NONE;
 							}
-							else if ( isTooDeep(currentDepth) || ( associationType.isCollectionType() && isTooManyCollections() ) ) {
+							else if ( isTooDeep( currentDepth ) || ( associationType.isCollectionType() && isTooManyCollections() ) ) {
 								resolvedJoinType = JoinType.NONE;
 							}
 							else {
 								resolvedJoinType = getJoinType( nullable, currentDepth );
 							}
 						}
 						else {
 							resolvedJoinType = super.getJoinType(
 									persister,
 									path,
 									propertyNumber,
 									associationType,
 									metadataFetchMode,
 									metadataCascadeStyle,
 									lhsTable,
 									lhsColumns,
 									nullable,
 									currentDepth
 							);
 						}
 					}
 					else {
 						resolvedJoinType = super.getJoinType(
 								associationType,
 								metadataFetchMode,
 								path,
 								lhsTable,
 								lhsColumns,
 								nullable,
 								currentDepth,
 								metadataCascadeStyle
 						);
 
 					}
 				}
 				else {
 					if ( fetchMode == FetchMode.JOIN ) {
-						isDuplicateAssociation( lhsTable, lhsColumns, associationType ); //deliberately ignore return value!
+						isDuplicateAssociation(
+								lhsTable,
+								lhsColumns,
+								associationType
+						); //deliberately ignore return value!
 						resolvedJoinType = getJoinType( nullable, currentDepth );
 					}
 					else {
 						resolvedJoinType = JoinType.NONE;
 					}
 				}
 			}
 		}
 		return resolvedJoinType;
 	}
+
 	@Override
 	protected JoinType getJoinType(
 			AssociationType associationType,
 			FetchMode config,
 			PropertyPath path,
 			String lhsTable,
 			String[] lhsColumns,
 			boolean nullable,
 			int currentDepth,
 			CascadeStyle cascadeStyle) throws MappingException {
 		return getJoinType(
 				null,
 				path,
 				-1,
 				associationType,
 				config,
 				cascadeStyle,
 				lhsTable,
 				lhsColumns,
 				nullable,
 				currentDepth
 		);
 	}
 
 	private static boolean isDefaultFetchMode(FetchMode fetchMode) {
-		return fetchMode==null || fetchMode==FetchMode.DEFAULT;
+		return fetchMode == null || fetchMode == FetchMode.DEFAULT;
 	}
 
 	/**
 	 * Use the discriminator, to narrow the select to instances
 	 * of the queried subclass, also applying any filters.
 	 */
 	@Override
 	protected String getWhereFragment() throws MappingException {
 		return super.getWhereFragment() +
-			( (Queryable) getPersister() ).filterFragment( getAlias(), getLoadQueryInfluencers().getEnabledFilters() );
+				( (Queryable) getPersister() ).filterFragment(
+						getAlias(),
+						getLoadQueryInfluencers().getEnabledFilters()
+				);
 	}
+
 	@Override
 	protected String generateTableAlias(int n, PropertyPath path, Joinable joinable) {
 		// TODO: deal with side-effects (changes to includeInResultRowList, userAliasList, resultTypeList)!!!
 
 		// for collection-of-entity, we are called twice for given "path"
 		// once for the collection Joinable, once for the entity Joinable.
 		// the second call will/must "consume" the alias + perform side effects according to consumesEntityAlias()
 		// for collection-of-other, however, there is only one call 
 		// it must "consume" the alias + perform side effects, despite what consumeEntityAlias() return says
 		// 
 		// note: the logic for adding to the userAliasList is still strictly based on consumesEntityAlias return value
 		boolean checkForSqlAlias = joinable.consumesEntityAlias();
 
 		if ( !checkForSqlAlias && joinable.isCollection() ) {
 			// is it a collection-of-other (component or value) ?
-			CollectionPersister collectionPersister = (CollectionPersister)joinable;
+			CollectionPersister collectionPersister = (CollectionPersister) joinable;
 			Type elementType = collectionPersister.getElementType();
 			if ( elementType.isComponentType() || !elementType.isEntityType() ) {
 				checkForSqlAlias = true;
- 			}
+			}
 		}
 
 		String sqlAlias = null;
 
 		if ( checkForSqlAlias ) {
 			final Criteria subcriteria = translator.getCriteria( path.getFullPath() );
-			sqlAlias = subcriteria==null ? null : translator.getSQLAlias(subcriteria);
-			
-			if (joinable.consumesEntityAlias() && ! translator.hasProjection()) {
+			sqlAlias = subcriteria == null ? null : translator.getSQLAlias( subcriteria );
+
+			if ( joinable.consumesEntityAlias() && !translator.hasProjection() ) {
 				includeInResultRowList.add( subcriteria != null && subcriteria.getAlias() != null );
-				if (sqlAlias!=null) {
+				if ( sqlAlias != null ) {
 					if ( subcriteria.getAlias() != null ) {
 						userAliasList.add( subcriteria.getAlias() );
 						resultTypeList.add( translator.getResultType( subcriteria ) );
 					}
 				}
 			}
 		}
 
-		if (sqlAlias == null) {
+		if ( sqlAlias == null ) {
 			sqlAlias = super.generateTableAlias( n + translator.getSQLAliasCount(), path, joinable );
 		}
 
 		return sqlAlias;
 	}
+
 	@Override
 	protected String generateRootAlias(String tableName) {
 		return CriteriaQueryTranslator.ROOT_SQL_ALIAS;
 	}
 
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
+
 	@Override
 	public String getComment() {
 		return "criteria query";
 	}
+
 	@Override
 	protected String getWithClause(PropertyPath path) {
 		return translator.getWithClause( path.getFullPath() );
 	}
+
 	@Override
-	protected boolean hasRestriction(PropertyPath path)	{
+	protected boolean hasRestriction(PropertyPath path) {
 		return translator.hasRestriction( path.getFullPath() );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaLoader.java
index 01f3235bf6..b65d249f66 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaLoader.java
@@ -1,297 +1,312 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.criteria;
+
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CriteriaImpl;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.OuterJoinLoader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 
 /**
  * A <tt>Loader</tt> for <tt>Criteria</tt> queries. Note that criteria queries are
  * more like multi-object <tt>load()</tt>s than like HQL queries.
  *
  * @author Gavin King
  */
 public class CriteriaLoader extends OuterJoinLoader {
 
 	//TODO: this class depends directly upon CriteriaImpl, 
 	//      in the impl package ... add a CriteriaImplementor 
 	//      interface
 
 	//NOTE: unlike all other Loaders, this one is NOT
 	//      multithreaded, or cacheable!!
 
 	private final CriteriaQueryTranslator translator;
 	private final Set<Serializable> querySpaces;
 	private final Type[] resultTypes;
 	//the user visible aliases, which are unknown to the superclass,
 	//these are not the actual "physical" SQL aliases
 	private final String[] userAliases;
 	private final boolean[] includeInResultRow;
 	private final int resultRowLength;
 
 	public CriteriaLoader(
-			final OuterJoinLoadable persister, 
-			final SessionFactoryImplementor factory, 
-			final CriteriaImpl criteria, 
+			final OuterJoinLoadable persister,
+			final SessionFactoryImplementor factory,
+			final CriteriaImpl criteria,
 			final String rootEntityName,
 			final LoadQueryInfluencers loadQueryInfluencers) throws HibernateException {
 		super( factory, loadQueryInfluencers );
 
 		translator = new CriteriaQueryTranslator(
-				factory, 
-				criteria, 
-				rootEntityName, 
+				factory,
+				criteria,
+				rootEntityName,
 				CriteriaQueryTranslator.ROOT_SQL_ALIAS
-			);
+		);
 
 		querySpaces = translator.getQuerySpaces();
-		
+
 		CriteriaJoinWalker walker = new CriteriaJoinWalker(
-				persister, 
+				persister,
 				translator,
-				factory, 
-				criteria, 
-				rootEntityName, 
+				factory,
+				criteria,
+				rootEntityName,
 				loadQueryInfluencers
-			);
+		);
+
+		initFromWalker( walker );
 
-		initFromWalker(walker);
-		
 		userAliases = walker.getUserAliases();
 		resultTypes = walker.getResultTypes();
 		includeInResultRow = walker.includeInResultRow();
 		resultRowLength = ArrayHelper.countTrue( includeInResultRow );
 
 		postInstantiate();
 
 	}
-	
-	public ScrollableResults scroll(SessionImplementor session, ScrollMode scrollMode) 
-	throws HibernateException {
+
+	public ScrollableResults scroll(SessionImplementor session, ScrollMode scrollMode)
+			throws HibernateException {
 		QueryParameters qp = translator.getQueryParameters();
-		qp.setScrollMode(scrollMode);
-		return scroll(qp, resultTypes, null, session);
+		qp.setScrollMode( scrollMode );
+		return scroll( qp, resultTypes, null, session );
 	}
 
-	public List list(SessionImplementor session) 
-	throws HibernateException {
+	public List list(SessionImplementor session)
+			throws HibernateException {
 		return list( session, translator.getQueryParameters(), querySpaces, resultTypes );
 
 	}
+
 	@Override
 	protected String[] getResultRowAliases() {
 		return userAliases;
 	}
+
 	@Override
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return translator.getRootCriteria().getResultTransformer();
 	}
+
 	@Override
 	protected boolean areResultSetRowsTransformedImmediately() {
 		return true;
 	}
+
 	@Override
 	protected boolean[] includeInResultRow() {
 		return includeInResultRow;
 	}
+
 	@Override
-	protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
-	throws SQLException, HibernateException {
+	protected Object getResultColumnOrRow(
+			Object[] row,
+			ResultTransformer transformer,
+			ResultSet rs,
+			SessionImplementor session)
+			throws SQLException, HibernateException {
 		return resolveResultTransformer( transformer ).transformTuple(
-				getResultRow( row, rs, session),
+				getResultRow( row, rs, session ),
 				getResultRowAliases()
 		);
 	}
+
 	@Override
 	protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		final Object[] result;
 		if ( translator.hasProjection() ) {
 			Type[] types = translator.getProjectedTypes();
 			result = new Object[types.length];
 			String[] columnAliases = translator.getProjectedColumnAliases();
-			for ( int i=0, pos=0; i<result.length; i++ ) {
+			for ( int i = 0, pos = 0; i < result.length; i++ ) {
 				int numColumns = types[i].getColumnSpan( session.getFactory() );
 				if ( numColumns > 1 ) {
-			    	String[] typeColumnAliases = ArrayHelper.slice( columnAliases, pos, numColumns );
-					result[i] = types[i].nullSafeGet(rs, typeColumnAliases, session, null);
+					String[] typeColumnAliases = ArrayHelper.slice( columnAliases, pos, numColumns );
+					result[i] = types[i].nullSafeGet( rs, typeColumnAliases, session, null );
 				}
 				else {
-					result[i] = types[i].nullSafeGet(rs, columnAliases[pos], session, null);
+					result[i] = types[i].nullSafeGet( rs, columnAliases[pos], session, null );
 				}
 				pos += numColumns;
 			}
 		}
 		else {
 			result = toResultRow( row );
 		}
 		return result;
 	}
 
 	private Object[] toResultRow(Object[] row) {
 		if ( resultRowLength == row.length ) {
 			return row;
 		}
 		else {
-			Object[] result = new Object[ resultRowLength ];
+			Object[] result = new Object[resultRowLength];
 			int j = 0;
 			for ( int i = 0; i < row.length; i++ ) {
 				if ( includeInResultRow[i] ) {
 					result[j++] = row[i];
 				}
 			}
 			return result;
 		}
 	}
 
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	@Override
 	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws QueryException {
 		final LockOptions lockOptions = parameters.getLockOptions();
 
 		if ( lockOptions == null ||
-				(lockOptions.getLockMode() == LockMode.NONE && (lockOptions.getAliasLockCount() == 0
-						|| (lockOptions.getAliasLockCount() == 1 && lockOptions
-						.getAliasSpecificLockMode( "this_" ) == LockMode.NONE)
-				)) ) {
+				( lockOptions.getLockMode() == LockMode.NONE && ( lockOptions.getAliasLockCount() == 0
+						|| ( lockOptions.getAliasLockCount() == 1 && lockOptions
+						.getAliasSpecificLockMode( "this_" ) == LockMode.NONE )
+				) ) ) {
 			return sql;
 		}
 
 		if ( dialect.useFollowOnLocking() ) {
-            final LockMode lockMode = determineFollowOnLockMode( lockOptions );
-            if( lockMode != LockMode.UPGRADE_SKIPLOCKED ) {
+			final LockMode lockMode = determineFollowOnLockMode( lockOptions );
+			if ( lockMode != LockMode.UPGRADE_SKIPLOCKED ) {
 				// Dialect prefers to perform locking in a separate step
 				LOG.usingFollowOnLocking();
 
 				final LockOptions lockOptionsToUse = new LockOptions( lockMode );
 				lockOptionsToUse.setTimeOut( lockOptions.getTimeOut() );
 				lockOptionsToUse.setScope( lockOptions.getScope() );
 
 				afterLoadActions.add(
 						new AfterLoadAction() {
-								@Override
-								public void afterLoad(SessionImplementor session, Object entity, Loadable persister) {
-									( (Session) session ).buildLockRequest( lockOptionsToUse )
+							@Override
+							public void afterLoad(SessionImplementor session, Object entity, Loadable persister) {
+								( (Session) session ).buildLockRequest( lockOptionsToUse )
 										.lock( persister.getEntityName(), entity );
-								}
-				        }
+							}
+						}
 				);
 				parameters.setLockOptions( new LockOptions() );
 				return sql;
 			}
 		}
-		final LockOptions locks = new LockOptions(lockOptions.getLockMode());
-		locks.setScope( lockOptions.getScope());
-		locks.setTimeOut( lockOptions.getTimeOut());
+		final LockOptions locks = new LockOptions( lockOptions.getLockMode() );
+		locks.setScope( lockOptions.getScope() );
+		locks.setTimeOut( lockOptions.getTimeOut() );
 
 		final Map keyColumnNames = dialect.forUpdateOfColumns() ? new HashMap() : null;
 		final String[] drivingSqlAliases = getAliases();
 		for ( int i = 0; i < drivingSqlAliases.length; i++ ) {
 			final LockMode lockMode = lockOptions.getAliasSpecificLockMode( drivingSqlAliases[i] );
 			if ( lockMode != null ) {
-				final Lockable drivingPersister = ( Lockable ) getEntityPersisters()[i];
+				final Lockable drivingPersister = (Lockable) getEntityPersisters()[i];
 				final String rootSqlAlias = drivingPersister.getRootTableAlias( drivingSqlAliases[i] );
 				locks.setAliasSpecificLockMode( rootSqlAlias, lockMode );
 				if ( keyColumnNames != null ) {
 					keyColumnNames.put( rootSqlAlias, drivingPersister.getRootTableIdentifierColumnNames() );
 				}
 			}
 		}
 		return dialect.applyLocksToSql( sql, locks, keyColumnNames );
 	}
 
 
 	@Override
 	protected LockMode determineFollowOnLockMode(LockOptions lockOptions) {
 		final LockMode lockModeToUse = lockOptions.findGreatestLockMode();
 
 		if ( lockOptions.getAliasLockCount() > 1 ) {
 			// > 1 here because criteria always uses alias map for the root lock mode (under 'this_')
 			LOG.aliasSpecificLockingWithFollowOnLocking( lockModeToUse );
 		}
 
 		return lockModeToUse;
 	}
+
 	@Override
 	protected LockMode[] getLockModes(LockOptions lockOptions) {
 		final String[] entityAliases = getAliases();
 		if ( entityAliases == null ) {
 			return null;
 		}
 		final int size = entityAliases.length;
 		LockMode[] lockModesArray = new LockMode[size];
-		for ( int i=0; i<size; i++ ) {
+		for ( int i = 0; i < size; i++ ) {
 			LockMode lockMode = lockOptions.getAliasSpecificLockMode( entityAliases[i] );
-			lockModesArray[i] = lockMode==null ? lockOptions.getLockMode() : lockMode;
+			lockModesArray[i] = lockMode == null ? lockOptions.getLockMode() : lockMode;
 		}
 		return lockModesArray;
 	}
+
 	@Override
 	protected boolean isSubselectLoadingEnabled() {
 		return hasSubselectLoadableCollections();
 	}
+
 	@Override
 	protected List getResultList(List results, ResultTransformer resultTransformer) {
 		return resolveResultTransformer( resultTransformer ).transformList( results );
 	}
+
 	@Override
-	protected String getQueryIdentifier() { 
-		return "[CRITERIA] " + getSQLString(); 
+	protected String getQueryIdentifier() {
+		return "[CRITERIA] " + getSQLString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaQueryTranslator.java b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaQueryTranslator.java
index 0e1f6a0610..75bfa18a71 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaQueryTranslator.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaQueryTranslator.java
@@ -1,675 +1,688 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.criteria;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.Criteria;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.criterion.CriteriaQuery;
 import org.hibernate.criterion.Criterion;
 import org.hibernate.criterion.EnhancedProjection;
 import org.hibernate.criterion.Projection;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.hql.internal.ast.util.SessionFactoryHelper;
 import org.hibernate.internal.CriteriaImpl;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.StringRepresentableType;
 import org.hibernate.type.Type;
 
 /**
  * @author Gavin King
  */
 public class CriteriaQueryTranslator implements CriteriaQuery {
 
 	public static final String ROOT_SQL_ALIAS = Criteria.ROOT_ALIAS + '_';
 
 	private CriteriaQuery outerQueryTranslator;
 
 	private final CriteriaImpl rootCriteria;
 	private final String rootEntityName;
 	private final String rootSQLAlias;
 
 	private final Map<Criteria, CriteriaInfoProvider> criteriaInfoMap = new LinkedHashMap<Criteria, CriteriaInfoProvider>();
 	private final Map<String, CriteriaInfoProvider> nameCriteriaInfoMap = new LinkedHashMap<String, CriteriaInfoProvider>();
 	private final Map<Criteria, String> criteriaSQLAliasMap = new HashMap<Criteria, String>();
 	private final Map<String, Criteria> aliasCriteriaMap = new HashMap<String, Criteria>();
 	private final Map<String, Criteria> associationPathCriteriaMap = new LinkedHashMap<String, Criteria>();
-	private final Map<String, JoinType> associationPathJoinTypesMap = new LinkedHashMap<String,JoinType>();
+	private final Map<String, JoinType> associationPathJoinTypesMap = new LinkedHashMap<String, JoinType>();
 	private final Map<String, Criterion> withClauseMap = new HashMap<String, Criterion>();
-	
+
 	private final SessionFactoryImplementor sessionFactory;
 	private final SessionFactoryHelper helper;
 
 	public CriteriaQueryTranslator(
 			final SessionFactoryImplementor factory,
-	        final CriteriaImpl criteria,
-	        final String rootEntityName,
-	        final String rootSQLAlias,
-	        CriteriaQuery outerQuery) throws HibernateException {
+			final CriteriaImpl criteria,
+			final String rootEntityName,
+			final String rootSQLAlias,
+			CriteriaQuery outerQuery) throws HibernateException {
 		this( factory, criteria, rootEntityName, rootSQLAlias );
 		outerQueryTranslator = outerQuery;
 	}
 
 	public CriteriaQueryTranslator(
 			final SessionFactoryImplementor factory,
-	        final CriteriaImpl criteria,
-	        final String rootEntityName,
-	        final String rootSQLAlias) throws HibernateException {
+			final CriteriaImpl criteria,
+			final String rootEntityName,
+			final String rootSQLAlias) throws HibernateException {
 		this.rootCriteria = criteria;
 		this.rootEntityName = rootEntityName;
 		this.sessionFactory = factory;
 		this.rootSQLAlias = rootSQLAlias;
-		this.helper = new SessionFactoryHelper(factory);
+		this.helper = new SessionFactoryHelper( factory );
 		createAliasCriteriaMap();
 		createAssociationPathCriteriaMap();
 		createCriteriaEntityNameMap();
 		createCriteriaSQLAliasMap();
 	}
+
 	@Override
 	public String generateSQLAlias() {
 		int aliasCount = 0;
 		return StringHelper.generateAlias( Criteria.ROOT_ALIAS, aliasCount ) + '_';
 	}
 
 	public String getRootSQLALias() {
 		return rootSQLAlias;
 	}
 
 	private Criteria getAliasedCriteria(String alias) {
 		return aliasCriteriaMap.get( alias );
 	}
 
 	public boolean isJoin(String path) {
 		return associationPathCriteriaMap.containsKey( path );
 	}
 
 	public JoinType getJoinType(String path) {
 		JoinType result = associationPathJoinTypesMap.get( path );
 		return ( result == null ? JoinType.INNER_JOIN : result );
 	}
 
 	public Criteria getCriteria(String path) {
 		return associationPathCriteriaMap.get( path );
 	}
 
 	public Set<Serializable> getQuerySpaces() {
 		Set<Serializable> result = new HashSet<Serializable>();
 		for ( CriteriaInfoProvider info : criteriaInfoMap.values() ) {
 			result.addAll( Arrays.asList( info.getSpaces() ) );
 		}
 		return result;
 	}
 
 	private void createAliasCriteriaMap() {
 		aliasCriteriaMap.put( rootCriteria.getAlias(), rootCriteria );
 		Iterator<CriteriaImpl.Subcriteria> iter = rootCriteria.iterateSubcriteria();
 		while ( iter.hasNext() ) {
 			Criteria subcriteria = iter.next();
 			if ( subcriteria.getAlias() != null ) {
 				Object old = aliasCriteriaMap.put( subcriteria.getAlias(), subcriteria );
 				if ( old != null ) {
 					throw new QueryException( "duplicate alias: " + subcriteria.getAlias() );
 				}
 			}
 		}
 	}
 
 	private void createAssociationPathCriteriaMap() {
 		final Iterator<CriteriaImpl.Subcriteria> iter = rootCriteria.iterateSubcriteria();
 		while ( iter.hasNext() ) {
 			CriteriaImpl.Subcriteria crit = iter.next();
 			String wholeAssociationPath = getWholeAssociationPath( crit );
 			Object old = associationPathCriteriaMap.put( wholeAssociationPath, crit );
 			if ( old != null ) {
 				throw new QueryException( "duplicate association path: " + wholeAssociationPath );
 			}
 			JoinType joinType = crit.getJoinType();
 			old = associationPathJoinTypesMap.put( wholeAssociationPath, joinType );
 			if ( old != null ) {
 				// TODO : not so sure this is needed...
 				throw new QueryException( "duplicate association path: " + wholeAssociationPath );
 			}
 			if ( crit.getWithClause() != null ) {
 				this.withClauseMap.put( wholeAssociationPath, crit.getWithClause() );
 			}
 		}
 	}
 
 	private String getWholeAssociationPath(CriteriaImpl.Subcriteria subcriteria) {
 		String path = subcriteria.getPath();
 
 		// some messy, complex stuff here, since createCriteria() can take an
 		// aliased path, or a path rooted at the creating criteria instance
 		Criteria parent = null;
 		if ( path.indexOf( '.' ) > 0 ) {
 			// if it is a compound path
 			String testAlias = StringHelper.root( path );
 			if ( !testAlias.equals( subcriteria.getAlias() ) ) {
 				// and the qualifier is not the alias of this criteria
 				//      -> check to see if we belong to some criteria other
 				//          than the one that created us
 				parent = aliasCriteriaMap.get( testAlias );
 			}
 		}
 		if ( parent == null ) {
 			// otherwise assume the parent is the the criteria that created us
 			parent = subcriteria.getParent();
 		}
 		else {
 			path = StringHelper.unroot( path );
 		}
 
 		if ( parent.equals( rootCriteria ) ) {
 			// if its the root criteria, we are done
 			return path;
 		}
 		else {
 			// otherwise, recurse
-			return getWholeAssociationPath( ( CriteriaImpl.Subcriteria ) parent ) + '.' + path;
+			return getWholeAssociationPath( (CriteriaImpl.Subcriteria) parent ) + '.' + path;
 		}
 	}
 
 	private void createCriteriaEntityNameMap() {
 		// initialize the rootProvider first
 		final CriteriaInfoProvider rootProvider = new EntityCriteriaInfoProvider(
 				(Queryable) sessionFactory.getEntityPersister( rootEntityName )
 		);
-		criteriaInfoMap.put( rootCriteria, rootProvider);
+		criteriaInfoMap.put( rootCriteria, rootProvider );
 		nameCriteriaInfoMap.put( rootProvider.getName(), rootProvider );
 
 		for ( final String key : associationPathCriteriaMap.keySet() ) {
 			final Criteria value = associationPathCriteriaMap.get( key );
 			final CriteriaInfoProvider info = getPathInfo( key );
 			criteriaInfoMap.put( value, info );
 			nameCriteriaInfoMap.put( info.getName(), info );
 		}
 	}
 
 
 	private CriteriaInfoProvider getPathInfo(String path) {
 		StringTokenizer tokens = new StringTokenizer( path, "." );
 		String componentPath = "";
 
 		// start with the 'rootProvider'
 		CriteriaInfoProvider provider = nameCriteriaInfoMap.get( rootEntityName );
 
 		while ( tokens.hasMoreTokens() ) {
 			componentPath += tokens.nextToken();
 			final Type type = provider.getType( componentPath );
 			if ( type.isAssociationType() ) {
 				// CollectionTypes are always also AssociationTypes - but there's not always an associated entity...
 				final AssociationType atype = (AssociationType) type;
-				final CollectionType ctype = type.isCollectionType() ? (CollectionType)type : null;
-				final Type elementType = (ctype != null) ? ctype.getElementType( sessionFactory ) : null;
+				final CollectionType ctype = type.isCollectionType() ? (CollectionType) type : null;
+				final Type elementType = ( ctype != null ) ? ctype.getElementType( sessionFactory ) : null;
 				// is the association a collection of components or value-types? (i.e a colloction of valued types?)
-				if ( ctype != null  && elementType.isComponentType() ) {
-					provider = new ComponentCollectionCriteriaInfoProvider( helper.getCollectionPersister(ctype.getRole()) );
+				if ( ctype != null && elementType.isComponentType() ) {
+					provider = new ComponentCollectionCriteriaInfoProvider( helper.getCollectionPersister( ctype.getRole() ) );
 				}
 				else if ( ctype != null && !elementType.isEntityType() ) {
 					provider = new ScalarCollectionCriteriaInfoProvider( helper, ctype.getRole() );
 				}
 				else {
 					provider = new EntityCriteriaInfoProvider(
 							(Queryable) sessionFactory.getEntityPersister( atype.getAssociatedEntityName( sessionFactory ) )
 					);
 				}
-				
+
 				componentPath = "";
 			}
 			else if ( type.isComponentType() ) {
-				if (!tokens.hasMoreTokens()) {
+				if ( !tokens.hasMoreTokens() ) {
 					throw new QueryException(
 							"Criteria objects cannot be created directly on components.  Create a criteria on " +
 									"owning entity and use a dotted property to access component property: " + path
 					);
 				}
 				else {
 					componentPath += '.';
 				}
 			}
 			else {
 				throw new QueryException( "not an association: " + componentPath );
 			}
 		}
-		
+
 		return provider;
 	}
 
 	public int getSQLAliasCount() {
 		return criteriaSQLAliasMap.size();
 	}
 
 	private void createCriteriaSQLAliasMap() {
 		int i = 0;
-		for(final Criteria crit : criteriaInfoMap.keySet()){
+		for ( final Criteria crit : criteriaInfoMap.keySet() ) {
 			final CriteriaInfoProvider value = criteriaInfoMap.get( crit );
 			String alias = crit.getAlias();
 			if ( alias == null ) {
 				// the entity name
 				alias = value.getName();
 			}
 			criteriaSQLAliasMap.put( crit, StringHelper.generateAlias( alias, i++ ) );
 		}
 
 		criteriaSQLAliasMap.put( rootCriteria, rootSQLAlias );
 	}
 
 	public CriteriaImpl getRootCriteria() {
 		return rootCriteria;
 	}
 
 	public QueryParameters getQueryParameters() {
 		final RowSelection selection = new RowSelection();
 		selection.setFirstRow( rootCriteria.getFirstResult() );
 		selection.setMaxRows( rootCriteria.getMaxResults() );
 		selection.setTimeout( rootCriteria.getTimeout() );
 		selection.setFetchSize( rootCriteria.getFetchSize() );
 
 		final LockOptions lockOptions = new LockOptions();
 		final Map<String, LockMode> lockModeMap = rootCriteria.getLockModes();
 		for ( final String key : lockModeMap.keySet() ) {
 			final Criteria subcriteria = getAliasedCriteria( key );
 			lockOptions.setAliasSpecificLockMode( getSQLAlias( subcriteria ), lockModeMap.get( key ) );
 		}
 
 		final List<Object> values = new ArrayList<Object>();
 		final List<Type> types = new ArrayList<Type>();
 		final Iterator<CriteriaImpl.Subcriteria> subcriteriaIterator = rootCriteria.iterateSubcriteria();
 		while ( subcriteriaIterator.hasNext() ) {
 			final CriteriaImpl.Subcriteria subcriteria = subcriteriaIterator.next();
 			final LockMode lm = subcriteria.getLockMode();
 			if ( lm != null ) {
 				lockOptions.setAliasSpecificLockMode( getSQLAlias( subcriteria ), lm );
 			}
 			if ( subcriteria.getWithClause() != null ) {
 				final TypedValue[] tv = subcriteria.getWithClause().getTypedValues( subcriteria, this );
 				for ( TypedValue aTv : tv ) {
 					values.add( aTv.getValue() );
 					types.add( aTv.getType() );
 				}
 			}
 		}
 
 		// Type and value gathering for the WHERE clause needs to come AFTER lock mode gathering,
 		// because the lock mode gathering loop now contains join clauses which can contain
 		// parameter bindings (as in the HQL WITH clause).
 		final Iterator<CriteriaImpl.CriterionEntry> iter = rootCriteria.iterateExpressionEntries();
 		while ( iter.hasNext() ) {
 			final CriteriaImpl.CriterionEntry ce = iter.next();
 			final TypedValue[] tv = ce.getCriterion().getTypedValues( ce.getCriteria(), this );
 			for ( TypedValue aTv : tv ) {
 				values.add( aTv.getValue() );
 				types.add( aTv.getType() );
 			}
 		}
 
 		final Object[] valueArray = values.toArray();
 		final Type[] typeArray = ArrayHelper.toTypeArray( types );
 		return new QueryParameters(
 				typeArray,
-		        valueArray,
-		        lockOptions,
-		        selection,
-		        rootCriteria.isReadOnlyInitialized(),
-		        ( rootCriteria.isReadOnlyInitialized() && rootCriteria.isReadOnly() ),
-		        rootCriteria.getCacheable(),
-		        rootCriteria.getCacheRegion(),
-		        rootCriteria.getComment(),
-		        rootCriteria.getQueryHints(),
-		        rootCriteria.isLookupByNaturalKey(),
-		        rootCriteria.getResultTransformer()
+				valueArray,
+				lockOptions,
+				selection,
+				rootCriteria.isReadOnlyInitialized(),
+				( rootCriteria.isReadOnlyInitialized() && rootCriteria.isReadOnly() ),
+				rootCriteria.getCacheable(),
+				rootCriteria.getCacheRegion(),
+				rootCriteria.getComment(),
+				rootCriteria.getQueryHints(),
+				rootCriteria.isLookupByNaturalKey(),
+				rootCriteria.getResultTransformer()
 		);
 	}
 
 	public boolean hasProjection() {
 		return rootCriteria.getProjection() != null;
 	}
 
 	public String getGroupBy() {
 		if ( rootCriteria.getProjection().isGrouped() ) {
 			return rootCriteria.getProjection()
 					.toGroupSqlString( rootCriteria.getProjectionCriteria(), this );
 		}
 		else {
 			return "";
 		}
 	}
 
 	public String getSelect() {
 		return rootCriteria.getProjection().toSqlString(
 				rootCriteria.getProjectionCriteria(),
-		        0,
-		        this
+				0,
+				this
 		);
 	}
 
 	/* package-protected */
 	Type getResultType(Criteria criteria) {
 		return getFactory().getTypeResolver().getTypeFactory().manyToOne( getEntityName( criteria ) );
 	}
 
 	public Type[] getProjectedTypes() {
 		return rootCriteria.getProjection().getTypes( rootCriteria, this );
 	}
 
 	public String[] getProjectedColumnAliases() {
 		return rootCriteria.getProjection() instanceof EnhancedProjection ?
-				( ( EnhancedProjection ) rootCriteria.getProjection() ).getColumnAliases( 0, rootCriteria, this ) :
+				( (EnhancedProjection) rootCriteria.getProjection() ).getColumnAliases( 0, rootCriteria, this ) :
 				rootCriteria.getProjection().getColumnAliases( 0 );
 	}
 
 	public String[] getProjectedAliases() {
 		return rootCriteria.getProjection().getAliases();
 	}
 
 	public String getWhereCondition() {
 		StringBuilder condition = new StringBuilder( 30 );
 		Iterator<CriteriaImpl.CriterionEntry> criterionIterator = rootCriteria.iterateExpressionEntries();
 		while ( criterionIterator.hasNext() ) {
 			CriteriaImpl.CriterionEntry entry = criterionIterator.next();
 			String sqlString = entry.getCriterion().toSqlString( entry.getCriteria(), this );
 			condition.append( sqlString );
 			if ( criterionIterator.hasNext() ) {
 				condition.append( " and " );
 			}
 		}
 		return condition.toString();
 	}
 
 	public String getOrderBy() {
 		StringBuilder orderBy = new StringBuilder( 30 );
 		Iterator<CriteriaImpl.OrderEntry> criterionIterator = rootCriteria.iterateOrderings();
 		while ( criterionIterator.hasNext() ) {
 			CriteriaImpl.OrderEntry oe = criterionIterator.next();
 			orderBy.append( oe.getOrder().toSqlString( oe.getCriteria(), this ) );
 			if ( criterionIterator.hasNext() ) {
 				orderBy.append( ", " );
 			}
 		}
 		return orderBy.toString();
 	}
+
 	@Override
 	public SessionFactoryImplementor getFactory() {
 		return sessionFactory;
 	}
+
 	@Override
 	public String getSQLAlias(Criteria criteria) {
 		return criteriaSQLAliasMap.get( criteria );
 	}
+
 	@Override
 	public String getEntityName(Criteria criteria) {
 		final CriteriaInfoProvider infoProvider = criteriaInfoMap.get( criteria );
 		return infoProvider != null ? infoProvider.getName() : null;
 	}
+
 	@Override
 	public String getColumn(Criteria criteria, String propertyName) {
 		String[] cols = getColumns( propertyName, criteria );
 		if ( cols.length != 1 ) {
 			throw new QueryException( "property does not map to a single column: " + propertyName );
 		}
 		return cols[0];
 	}
 
 	/**
 	 * Get the names of the columns constrained
 	 * by this criterion.
 	 */
 	@Override
 	public String[] getColumnsUsingProjection(
 			Criteria subcriteria,
-	        String propertyName) throws HibernateException {
+			String propertyName) throws HibernateException {
 
 		//first look for a reference to a projection alias
 		final Projection projection = rootCriteria.getProjection();
 		String[] projectionColumns = null;
 		if ( projection != null ) {
 			projectionColumns = ( projection instanceof EnhancedProjection ?
-					( ( EnhancedProjection ) projection ).getColumnAliases( propertyName, 0, rootCriteria, this ) :
+					( (EnhancedProjection) projection ).getColumnAliases( propertyName, 0, rootCriteria, this ) :
 					projection.getColumnAliases( propertyName, 0 )
 			);
 		}
 		if ( projectionColumns == null ) {
 			//it does not refer to an alias of a projection,
 			//look for a property
 			try {
 				return getColumns( propertyName, subcriteria );
 			}
-			catch ( HibernateException he ) {
+			catch (HibernateException he) {
 				//not found in inner query , try the outer query
 				if ( outerQueryTranslator != null ) {
 					return outerQueryTranslator.getColumnsUsingProjection( subcriteria, propertyName );
 				}
 				else {
 					throw he;
 				}
 			}
 		}
 		else {
 			//it refers to an alias of a projection
 			return projectionColumns;
 		}
 	}
+
 	@Override
 	public String[] getIdentifierColumns(Criteria criteria) {
 		String[] idcols =
-				( ( Loadable ) getPropertyMapping( getEntityName( criteria ) ) ).getIdentifierColumnNames();
+				( (Loadable) getPropertyMapping( getEntityName( criteria ) ) ).getIdentifierColumnNames();
 		return StringHelper.qualify( getSQLAlias( criteria ), idcols );
 	}
+
 	@Override
 	public Type getIdentifierType(Criteria criteria) {
-		return ( ( Loadable ) getPropertyMapping( getEntityName( criteria ) ) ).getIdentifierType();
+		return ( (Loadable) getPropertyMapping( getEntityName( criteria ) ) ).getIdentifierType();
 	}
+
 	@Override
 	public TypedValue getTypedIdentifierValue(Criteria criteria, Object value) {
-		final Loadable loadable = ( Loadable ) getPropertyMapping( getEntityName( criteria ) );
+		final Loadable loadable = (Loadable) getPropertyMapping( getEntityName( criteria ) );
 		return new TypedValue( loadable.getIdentifierType(), value );
 	}
+
 	@Override
 	public String[] getColumns(
 			String propertyName,
-	        Criteria subcriteria) throws HibernateException {
+			Criteria subcriteria) throws HibernateException {
 		return getPropertyMapping( getEntityName( subcriteria, propertyName ) )
 				.toColumns(
 						getSQLAlias( subcriteria, propertyName ),
-				        getPropertyName( propertyName )
+						getPropertyName( propertyName )
 				);
 	}
 
 	/**
 	 * Get the names of the columns mapped by a property path; if the
 	 * property path is not found in subcriteria, try the "outer" query.
 	 * Projection aliases are ignored.
 	 */
 	@Override
-	public String[] findColumns(String propertyName, Criteria subcriteria )
-	throws HibernateException {
+	public String[] findColumns(String propertyName, Criteria subcriteria)
+			throws HibernateException {
 		try {
 			return getColumns( propertyName, subcriteria );
 		}
-		catch ( HibernateException he ) {
+		catch (HibernateException he) {
 			//not found in inner query, try the outer query
 			if ( outerQueryTranslator != null ) {
 				return outerQueryTranslator.findColumns( propertyName, subcriteria );
 			}
 			else {
 				throw he;
 			}
 		}
 	}
+
 	@Override
 	public Type getTypeUsingProjection(Criteria subcriteria, String propertyName)
 			throws HibernateException {
 
 		//first look for a reference to a projection alias
 		final Projection projection = rootCriteria.getProjection();
 		Type[] projectionTypes = projection == null ?
-		                         null :
-		                         projection.getTypes( propertyName, subcriteria, this );
+				null :
+				projection.getTypes( propertyName, subcriteria, this );
 
 		if ( projectionTypes == null ) {
 			try {
 				//it does not refer to an alias of a projection,
 				//look for a property
 				return getType( subcriteria, propertyName );
 			}
-			catch ( HibernateException he ) {
+			catch (HibernateException he) {
 				//not found in inner query , try the outer query
 				if ( outerQueryTranslator != null ) {
 					return outerQueryTranslator.getType( subcriteria, propertyName );
 				}
 				else {
 					throw he;
 				}
 			}
 		}
 		else {
 			if ( projectionTypes.length != 1 ) {
 				//should never happen, i think
 				throw new QueryException( "not a single-length projection: " + propertyName );
 			}
 			return projectionTypes[0];
 		}
 	}
+
 	@Override
 	public Type getType(Criteria subcriteria, String propertyName)
 			throws HibernateException {
 		return getPropertyMapping( getEntityName( subcriteria, propertyName ) )
 				.toType( getPropertyName( propertyName ) );
 	}
 
 	/**
 	 * Get the a typed value for the given property value.
 	 */
 	@Override
 	public TypedValue getTypedValue(Criteria subcriteria, String propertyName, Object value) throws HibernateException {
 		// Detect discriminator values...
 		if ( value instanceof Class ) {
 			final Class entityClass = (Class) value;
 			final Queryable q = SessionFactoryHelper.findQueryableUsingImports( sessionFactory, entityClass.getName() );
 			if ( q != null ) {
 				final Type type = q.getDiscriminatorType();
 				String stringValue = q.getDiscriminatorSQLValue();
 				if ( stringValue != null
 						&& stringValue.length() > 2
 						&& stringValue.startsWith( "'" )
 						&& stringValue.endsWith( "'" ) ) {
 					// remove the single quotes
 					stringValue = stringValue.substring( 1, stringValue.length() - 1 );
 				}
-				
+
 				// Convert the string value into the proper type.
 				if ( type instanceof StringRepresentableType ) {
 					final StringRepresentableType nullableType = (StringRepresentableType) type;
 					value = nullableType.fromStringValue( stringValue );
 				}
 				else {
 					throw new QueryException( "Unsupported discriminator type " + type );
 				}
 				return new TypedValue( type, value );
 			}
 		}
 		// Otherwise, this is an ordinary value.
 		return new TypedValue( getTypeUsingProjection( subcriteria, propertyName ), value );
 	}
 
 	private PropertyMapping getPropertyMapping(String entityName) throws MappingException {
 		final CriteriaInfoProvider info = nameCriteriaInfoMap.get( entityName );
 		if ( info == null ) {
 			throw new HibernateException( "Unknown entity: " + entityName );
 		}
 		return info.getPropertyMapping();
 	}
 
 	//TODO: use these in methods above
 	@Override
 	public String getEntityName(Criteria subcriteria, String propertyName) {
 		if ( propertyName.indexOf( '.' ) > 0 ) {
 			final String root = StringHelper.root( propertyName );
 			final Criteria crit = getAliasedCriteria( root );
 			if ( crit != null ) {
 				return getEntityName( crit );
 			}
 		}
 		return getEntityName( subcriteria );
 	}
+
 	@Override
 	public String getSQLAlias(Criteria criteria, String propertyName) {
 		if ( propertyName.indexOf( '.' ) > 0 ) {
 			final String root = StringHelper.root( propertyName );
 			final Criteria subcriteria = getAliasedCriteria( root );
 			if ( subcriteria != null ) {
 				return getSQLAlias( subcriteria );
 			}
 		}
 		return getSQLAlias( criteria );
 	}
+
 	@Override
 	public String getPropertyName(String propertyName) {
 		if ( propertyName.indexOf( '.' ) > 0 ) {
 			final String root = StringHelper.root( propertyName );
 			final Criteria criteria = getAliasedCriteria( root );
 			if ( criteria != null ) {
 				return propertyName.substring( root.length() + 1 );
 			}
 		}
 		return propertyName;
 	}
 
 	public String getWithClause(String path) {
 		final Criterion criterion = withClauseMap.get( path );
 		return criterion == null ? null : criterion.toSqlString( getCriteria( path ), this );
 	}
 
 	public boolean hasRestriction(String path) {
 		final CriteriaImpl.Subcriteria subcriteria = (CriteriaImpl.Subcriteria) getCriteria( path );
 		return subcriteria != null && subcriteria.hasRestriction();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/CollectionFetchReturn.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/CollectionFetchReturn.java
index 21cfeab08f..01b2b1aa41 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/CollectionFetchReturn.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/CollectionFetchReturn.java
@@ -1,58 +1,58 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.loader.custom;
+
 import org.hibernate.LockMode;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.EntityAliases;
 
 /**
  * Specifically a fetch return that refers to a collection association.
  *
  * @author Steve Ebersole
  */
 public class CollectionFetchReturn extends FetchReturn {
 	private final CollectionAliases collectionAliases;
 	private final EntityAliases elementEntityAliases;
 
 	public CollectionFetchReturn(
 			String alias,
 			NonScalarReturn owner,
 			String ownerProperty,
 			CollectionAliases collectionAliases,
-	        EntityAliases elementEntityAliases,
+			EntityAliases elementEntityAliases,
 			LockMode lockMode) {
 		super( owner, ownerProperty, alias, lockMode );
 		this.collectionAliases = collectionAliases;
 		this.elementEntityAliases = elementEntityAliases;
 	}
 
 	public CollectionAliases getCollectionAliases() {
 		return collectionAliases;
 	}
 
 	public EntityAliases getElementEntityAliases() {
 		return elementEntityAliases;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/CollectionReturn.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/CollectionReturn.java
index ce7b61da38..eb8799b6d5 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/CollectionReturn.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/CollectionReturn.java
@@ -1,83 +1,83 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.loader.custom;
+package org.hibernate.loader.custom;
+
 import org.hibernate.LockMode;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.EntityAliases;
 
 /**
  * Represents a return which names a collection role; it
  * is used in defining a custom query for loading an entity's
  * collection in non-fetching scenarios (i.e., loading the collection
  * itself as the "root" of the result).
  *
  * @author Steve Ebersole
  */
 public class CollectionReturn extends NonScalarReturn {
 	private final String ownerEntityName;
 	private final String ownerProperty;
 	private final CollectionAliases collectionAliases;
 	private final EntityAliases elementEntityAliases;
 
 	public CollectionReturn(
 			String alias,
 			String ownerEntityName,
 			String ownerProperty,
 			CollectionAliases collectionAliases,
-	        EntityAliases elementEntityAliases,
+			EntityAliases elementEntityAliases,
 			LockMode lockMode) {
 		super( alias, lockMode );
 		this.ownerEntityName = ownerEntityName;
 		this.ownerProperty = ownerProperty;
 		this.collectionAliases = collectionAliases;
 		this.elementEntityAliases = elementEntityAliases;
 	}
 
 	/**
 	 * Returns the class owning the collection.
 	 *
 	 * @return The class owning the collection.
 	 */
 	public String getOwnerEntityName() {
 		return ownerEntityName;
 	}
 
 	/**
 	 * Returns the name of the property representing the collection from the {@link #getOwnerEntityName}.
 	 *
 	 * @return The name of the property representing the collection on the owner class.
 	 */
 	public String getOwnerProperty() {
 		return ownerProperty;
 	}
 
 	public CollectionAliases getCollectionAliases() {
 		return collectionAliases;
 	}
 
 	public EntityAliases getElementEntityAliases() {
 		return elementEntityAliases;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/ColumnCollectionAliases.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/ColumnCollectionAliases.java
index 046bbd2fe7..0ee42b0b68 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/ColumnCollectionAliases.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/ColumnCollectionAliases.java
@@ -1,152 +1,154 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.loader.custom;
 
 import java.util.Map;
 
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.persister.collection.SQLLoadableCollection;
 
 /**
  * CollectionAliases that uses columnnames instead of generated aliases.
  * Aliases can still be overwritten via <return-property>
  *
  * @author Max Rydahl Andersen
- *
  */
 public class ColumnCollectionAliases implements CollectionAliases {
 	private final String[] keyAliases;
 	private final String[] indexAliases;
 	private final String[] elementAliases;
 	private final String identifierAlias;
 	private Map userProvidedAliases;
 
 
 	public ColumnCollectionAliases(Map userProvidedAliases, SQLLoadableCollection persister) {
 		this.userProvidedAliases = userProvidedAliases;
 
 		this.keyAliases = getUserProvidedAliases(
 				"key",
 				persister.getKeyColumnNames()
-			);
+		);
 
 		this.indexAliases = getUserProvidedAliases(
 				"index",
 				persister.getIndexColumnNames()
-				);
+		);
 
-		this.elementAliases = getUserProvidedAliases( "element",
+		this.elementAliases = getUserProvidedAliases(
+				"element",
 				persister.getElementColumnNames()
-				);
+		);
 
-		this.identifierAlias = getUserProvidedAlias( "id",
+		this.identifierAlias = getUserProvidedAlias(
+				"id",
 				persister.getIdentifierColumnName()
-				);
+		);
 
 	}
 
 
 	/**
 	 * Returns the suffixed result-set column-aliases for columns making up the key for this collection (i.e., its FK to
 	 * its owner).
 	 *
 	 * @return The key result-set column aliases.
 	 */
 	public String[] getSuffixedKeyAliases() {
 		return keyAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the collumns making up the collection's index (map or list).
 	 *
 	 * @return The index result-set column aliases.
 	 */
 	public String[] getSuffixedIndexAliases() {
 		return indexAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the columns making up the collection's elements.
 	 *
 	 * @return The element result-set column aliases.
 	 */
 	public String[] getSuffixedElementAliases() {
 		return elementAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the column defining the collection's identifier (if any).
 	 *
 	 * @return The identifier result-set column aliases.
 	 */
 	public String getSuffixedIdentifierAlias() {
 		return identifierAlias;
 	}
 
 	/**
 	 * Returns the suffix used to unique the column aliases for this particular alias set.
 	 *
 	 * @return The uniqued column alias suffix.
 	 */
 	public String getSuffix() {
 		return "";
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return super.toString() + " [ suffixedKeyAliases=[" + join( keyAliases ) +
-		        "], suffixedIndexAliases=[" + join( indexAliases ) +
-		        "], suffixedElementAliases=[" + join( elementAliases ) +
-		        "], suffixedIdentifierAlias=[" + identifierAlias + "]]";
+				"], suffixedIndexAliases=[" + join( indexAliases ) +
+				"], suffixedElementAliases=[" + join( elementAliases ) +
+				"], suffixedIdentifierAlias=[" + identifierAlias + "]]";
 	}
 
 	private String join(String[] aliases) {
-		if ( aliases == null) return null;
+		if ( aliases == null ) {
+			return null;
+		}
 
 		return StringHelper.join( ", ", aliases );
 	}
 
 	private String[] getUserProvidedAliases(String propertyPath, String[] defaultAliases) {
-		String[] result = (String[]) userProvidedAliases.get(propertyPath);
-		if (result==null) {
+		String[] result = (String[]) userProvidedAliases.get( propertyPath );
+		if ( result == null ) {
 			return defaultAliases;
 		}
 		else {
 			return result;
 		}
 	}
 
 	private String getUserProvidedAlias(String propertyPath, String defaultAlias) {
-		String[] columns = (String[]) userProvidedAliases.get(propertyPath);
-		if (columns==null) {
+		String[] columns = (String[]) userProvidedAliases.get( propertyPath );
+		if ( columns == null ) {
 			return defaultAlias;
 		}
 		else {
 			return columns[0];
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/CustomLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/CustomLoader.java
index 8e85de6033..36e362d7af 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/CustomLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/CustomLoader.java
@@ -1,557 +1,563 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.custom;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.QueryKey;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.EntityAliases;
 import org.hibernate.loader.Loader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 
 /**
  * Extension point for loaders which use a SQL result set with "unexpected" column aliases.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class CustomLoader extends Loader {
 
 	// Currently *not* cachable if autodiscover types is in effect (e.g. "select * ...")
 
 	private final String sql;
 	private final Set<Serializable> querySpaces = new HashSet<Serializable>();
 	private final Map namedParameterBindPoints;
 
 	private final Queryable[] entityPersisters;
 	private final int[] entiytOwners;
 	private final EntityAliases[] entityAliases;
 
 	private final QueryableCollection[] collectionPersisters;
 	private final int[] collectionOwners;
 	private final CollectionAliases[] collectionAliases;
 
 	private final LockMode[] lockModes;
 
 	private boolean[] includeInResultRow;
 
-//	private final String[] sqlAliases;
+	//	private final String[] sqlAliases;
 //	private final String[] sqlAliasSuffixes;
 	private final ResultRowProcessor rowProcessor;
 
 	// this is only needed (afaict) for processing results from the query cache;
 	// however, this cannot possibly work in the case of discovered types...
 	private Type[] resultTypes;
 
 	// this is only needed (afaict) for ResultTransformer processing...
 	private String[] transformerAliases;
 
 	public CustomLoader(CustomQuery customQuery, SessionFactoryImplementor factory) {
 		super( factory );
 
 		this.sql = customQuery.getSQL();
 		this.querySpaces.addAll( customQuery.getQuerySpaces() );
 		this.namedParameterBindPoints = customQuery.getNamedParameterBindPoints();
 
 		List<Queryable> entityPersisters = new ArrayList<Queryable>();
 		List<Integer> entityOwners = new ArrayList<Integer>();
 		List<EntityAliases> entityAliases = new ArrayList<EntityAliases>();
 
 		List<QueryableCollection> collectionPersisters = new ArrayList<QueryableCollection>();
 		List<Integer> collectionOwners = new ArrayList<Integer>();
 		List<CollectionAliases> collectionAliases = new ArrayList<CollectionAliases>();
 
 		List<LockMode> lockModes = new ArrayList<LockMode>();
 		List<ResultColumnProcessor> resultColumnProcessors = new ArrayList<ResultColumnProcessor>();
 		List<Return> nonScalarReturnList = new ArrayList<Return>();
 		List<Type> resultTypes = new ArrayList<Type>();
 		List<String> specifiedAliases = new ArrayList<String>();
 
 		int returnableCounter = 0;
 		boolean hasScalars = false;
 
 		List<Boolean> includeInResultRowList = new ArrayList<Boolean>();
 
 		for ( Return rtn : customQuery.getCustomQueryReturns() ) {
 			if ( rtn instanceof ScalarReturn ) {
 				ScalarReturn scalarRtn = (ScalarReturn) rtn;
 				resultTypes.add( scalarRtn.getType() );
 				specifiedAliases.add( scalarRtn.getColumnAlias() );
 				resultColumnProcessors.add(
 						new ScalarResultColumnProcessor(
 								StringHelper.unquote( scalarRtn.getColumnAlias(), factory.getDialect() ),
 								scalarRtn.getType()
 						)
 				);
 				includeInResultRowList.add( true );
 				hasScalars = true;
 			}
 			else if ( ConstructorReturn.class.isInstance( rtn ) ) {
 				final ConstructorReturn constructorReturn = (ConstructorReturn) rtn;
 				resultTypes.add( null ); // this bit makes me nervous
 				includeInResultRowList.add( true );
 				hasScalars = true;
 
 				ScalarResultColumnProcessor[] scalarProcessors = new ScalarResultColumnProcessor[constructorReturn.getScalars().length];
 				int i = 0;
 				for ( ScalarReturn scalarReturn : constructorReturn.getScalars() ) {
 					scalarProcessors[i++] = new ScalarResultColumnProcessor(
 							StringHelper.unquote( scalarReturn.getColumnAlias(), factory.getDialect() ),
 							scalarReturn.getType()
 					);
 				}
 
 				resultColumnProcessors.add(
 						new ConstructorResultColumnProcessor( constructorReturn.getTargetClass(), scalarProcessors )
 				);
 			}
 			else if ( rtn instanceof RootReturn ) {
 				RootReturn rootRtn = (RootReturn) rtn;
 				Queryable persister = (Queryable) factory.getEntityPersister( rootRtn.getEntityName() );
 				entityPersisters.add( persister );
-				lockModes.add( (rootRtn.getLockMode()) );
+				lockModes.add( ( rootRtn.getLockMode() ) );
 				resultColumnProcessors.add( new NonScalarResultColumnProcessor( returnableCounter++ ) );
 				nonScalarReturnList.add( rtn );
 				entityOwners.add( -1 );
 				resultTypes.add( persister.getType() );
 				specifiedAliases.add( rootRtn.getAlias() );
 				entityAliases.add( rootRtn.getEntityAliases() );
 				ArrayHelper.addAll( querySpaces, persister.getQuerySpaces() );
 				includeInResultRowList.add( true );
 			}
 			else if ( rtn instanceof CollectionReturn ) {
 				CollectionReturn collRtn = (CollectionReturn) rtn;
 				String role = collRtn.getOwnerEntityName() + "." + collRtn.getOwnerProperty();
 				QueryableCollection persister = (QueryableCollection) factory.getCollectionPersister( role );
 				collectionPersisters.add( persister );
 				lockModes.add( collRtn.getLockMode() );
 				resultColumnProcessors.add( new NonScalarResultColumnProcessor( returnableCounter++ ) );
 				nonScalarReturnList.add( rtn );
 				collectionOwners.add( -1 );
 				resultTypes.add( persister.getType() );
 				specifiedAliases.add( collRtn.getAlias() );
 				collectionAliases.add( collRtn.getCollectionAliases() );
 				// determine if the collection elements are entities...
 				Type elementType = persister.getElementType();
 				if ( elementType.isEntityType() ) {
-					Queryable elementPersister = (Queryable) ((EntityType) elementType).getAssociatedJoinable( factory );
+					Queryable elementPersister = (Queryable) ( (EntityType) elementType ).getAssociatedJoinable( factory );
 					entityPersisters.add( elementPersister );
 					entityOwners.add( -1 );
 					entityAliases.add( collRtn.getElementEntityAliases() );
 					ArrayHelper.addAll( querySpaces, elementPersister.getQuerySpaces() );
 				}
 				includeInResultRowList.add( true );
 			}
 			else if ( rtn instanceof EntityFetchReturn ) {
 				EntityFetchReturn fetchRtn = (EntityFetchReturn) rtn;
 				NonScalarReturn ownerDescriptor = fetchRtn.getOwner();
 				int ownerIndex = nonScalarReturnList.indexOf( ownerDescriptor );
 				entityOwners.add( ownerIndex );
 				lockModes.add( fetchRtn.getLockMode() );
 				Queryable ownerPersister = determineAppropriateOwnerPersister( ownerDescriptor );
 				EntityType fetchedType = (EntityType) ownerPersister.getPropertyType( fetchRtn.getOwnerProperty() );
 				String entityName = fetchedType.getAssociatedEntityName( getFactory() );
 				Queryable persister = (Queryable) factory.getEntityPersister( entityName );
 				entityPersisters.add( persister );
 				nonScalarReturnList.add( rtn );
 				specifiedAliases.add( fetchRtn.getAlias() );
 				entityAliases.add( fetchRtn.getEntityAliases() );
 				ArrayHelper.addAll( querySpaces, persister.getQuerySpaces() );
 				includeInResultRowList.add( false );
 			}
 			else if ( rtn instanceof CollectionFetchReturn ) {
 				CollectionFetchReturn fetchRtn = (CollectionFetchReturn) rtn;
 				NonScalarReturn ownerDescriptor = fetchRtn.getOwner();
 				int ownerIndex = nonScalarReturnList.indexOf( ownerDescriptor );
 				collectionOwners.add( ownerIndex );
 				lockModes.add( fetchRtn.getLockMode() );
 				Queryable ownerPersister = determineAppropriateOwnerPersister( ownerDescriptor );
 				String role = ownerPersister.getEntityName() + '.' + fetchRtn.getOwnerProperty();
 				QueryableCollection persister = (QueryableCollection) factory.getCollectionPersister( role );
 				collectionPersisters.add( persister );
 				nonScalarReturnList.add( rtn );
 				specifiedAliases.add( fetchRtn.getAlias() );
 				collectionAliases.add( fetchRtn.getCollectionAliases() );
 				// determine if the collection elements are entities...
 				Type elementType = persister.getElementType();
 				if ( elementType.isEntityType() ) {
-					Queryable elementPersister = (Queryable) ((EntityType) elementType).getAssociatedJoinable( factory );
+					Queryable elementPersister = (Queryable) ( (EntityType) elementType ).getAssociatedJoinable( factory );
 					entityPersisters.add( elementPersister );
 					entityOwners.add( ownerIndex );
 					entityAliases.add( fetchRtn.getElementEntityAliases() );
 					ArrayHelper.addAll( querySpaces, elementPersister.getQuerySpaces() );
 				}
 				includeInResultRowList.add( false );
 			}
 			else {
 				throw new HibernateException( "unexpected custom query return type : " + rtn.getClass().getName() );
 			}
 		}
 
-		this.entityPersisters = new Queryable[ entityPersisters.size() ];
+		this.entityPersisters = new Queryable[entityPersisters.size()];
 		for ( int i = 0; i < entityPersisters.size(); i++ ) {
 			this.entityPersisters[i] = entityPersisters.get( i );
 		}
 		this.entiytOwners = ArrayHelper.toIntArray( entityOwners );
-		this.entityAliases = new EntityAliases[ entityAliases.size() ];
+		this.entityAliases = new EntityAliases[entityAliases.size()];
 		for ( int i = 0; i < entityAliases.size(); i++ ) {
 			this.entityAliases[i] = entityAliases.get( i );
 		}
 
-		this.collectionPersisters = new QueryableCollection[ collectionPersisters.size() ];
+		this.collectionPersisters = new QueryableCollection[collectionPersisters.size()];
 		for ( int i = 0; i < collectionPersisters.size(); i++ ) {
 			this.collectionPersisters[i] = collectionPersisters.get( i );
 		}
 		this.collectionOwners = ArrayHelper.toIntArray( collectionOwners );
-		this.collectionAliases = new CollectionAliases[ collectionAliases.size() ];
+		this.collectionAliases = new CollectionAliases[collectionAliases.size()];
 		for ( int i = 0; i < collectionAliases.size(); i++ ) {
 			this.collectionAliases[i] = collectionAliases.get( i );
 		}
 
-		this.lockModes = new LockMode[ lockModes.size() ];
+		this.lockModes = new LockMode[lockModes.size()];
 		for ( int i = 0; i < lockModes.size(); i++ ) {
 			this.lockModes[i] = lockModes.get( i );
 		}
 
 		this.resultTypes = ArrayHelper.toTypeArray( resultTypes );
 		this.transformerAliases = ArrayHelper.toStringArray( specifiedAliases );
 
 		this.rowProcessor = new ResultRowProcessor(
 				hasScalars,
-				resultColumnProcessors.toArray( new ResultColumnProcessor[ resultColumnProcessors.size() ] )
+				resultColumnProcessors.toArray( new ResultColumnProcessor[resultColumnProcessors.size()] )
 		);
 
 		this.includeInResultRow = ArrayHelper.toBooleanArray( includeInResultRowList );
 	}
 
 	private Queryable determineAppropriateOwnerPersister(NonScalarReturn ownerDescriptor) {
 		String entityName = null;
 		if ( ownerDescriptor instanceof RootReturn ) {
-			entityName = ( ( RootReturn ) ownerDescriptor ).getEntityName();
+			entityName = ( (RootReturn) ownerDescriptor ).getEntityName();
 		}
 		else if ( ownerDescriptor instanceof CollectionReturn ) {
-			CollectionReturn collRtn = ( CollectionReturn ) ownerDescriptor;
+			CollectionReturn collRtn = (CollectionReturn) ownerDescriptor;
 			String role = collRtn.getOwnerEntityName() + "." + collRtn.getOwnerProperty();
 			CollectionPersister persister = getFactory().getCollectionPersister( role );
-			EntityType ownerType = ( EntityType ) persister.getElementType();
+			EntityType ownerType = (EntityType) persister.getElementType();
 			entityName = ownerType.getAssociatedEntityName( getFactory() );
 		}
 		else if ( ownerDescriptor instanceof FetchReturn ) {
-			FetchReturn fetchRtn = ( FetchReturn ) ownerDescriptor;
+			FetchReturn fetchRtn = (FetchReturn) ownerDescriptor;
 			Queryable persister = determineAppropriateOwnerPersister( fetchRtn.getOwner() );
 			Type ownerType = persister.getPropertyType( fetchRtn.getOwnerProperty() );
 			if ( ownerType.isEntityType() ) {
-				entityName = ( ( EntityType ) ownerType ).getAssociatedEntityName( getFactory() );
+				entityName = ( (EntityType) ownerType ).getAssociatedEntityName( getFactory() );
 			}
 			else if ( ownerType.isCollectionType() ) {
-				Type ownerCollectionElementType = ( ( CollectionType ) ownerType ).getElementType( getFactory() );
+				Type ownerCollectionElementType = ( (CollectionType) ownerType ).getElementType( getFactory() );
 				if ( ownerCollectionElementType.isEntityType() ) {
-					entityName = ( ( EntityType ) ownerCollectionElementType ).getAssociatedEntityName( getFactory() );
+					entityName = ( (EntityType) ownerCollectionElementType ).getAssociatedEntityName( getFactory() );
 				}
 			}
 		}
 
 		if ( entityName == null ) {
 			throw new HibernateException( "Could not determine fetch owner : " + ownerDescriptor );
 		}
 
-		return ( Queryable ) getFactory().getEntityPersister( entityName );
+		return (Queryable) getFactory().getEntityPersister( entityName );
 	}
 
 	@Override
-    protected String getQueryIdentifier() {
+	protected String getQueryIdentifier() {
 		return sql;
 	}
 
 	@Override
-    public String getSQLString() {
+	public String getSQLString() {
 		return sql;
 	}
 
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	@Override
-    protected LockMode[] getLockModes(LockOptions lockOptions) {
+	protected LockMode[] getLockModes(LockOptions lockOptions) {
 		return lockModes;
 	}
 
 	@Override
-    protected Loadable[] getEntityPersisters() {
+	protected Loadable[] getEntityPersisters() {
 		return entityPersisters;
 	}
 
 	@Override
-    protected CollectionPersister[] getCollectionPersisters() {
+	protected CollectionPersister[] getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	@Override
-    protected int[] getCollectionOwners() {
+	protected int[] getCollectionOwners() {
 		return collectionOwners;
 	}
 
 	@Override
-    protected int[] getOwners() {
+	protected int[] getOwners() {
 		return entiytOwners;
 	}
 
 	public List list(SessionImplementor session, QueryParameters queryParameters) throws HibernateException {
 		return list( session, queryParameters, querySpaces, resultTypes );
 	}
 
 	@Override
 	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws QueryException {
 		final LockOptions lockOptions = parameters.getLockOptions();
 		if ( lockOptions == null ||
 				( lockOptions.getLockMode() == LockMode.NONE && lockOptions.getAliasLockCount() == 0 ) ) {
 			return sql;
 		}
 
 		// user is request locking, lets see if we can apply locking directly to the SQL...
 
 		// 		some dialects wont allow locking with paging...
 		afterLoadActions.add(
 				new AfterLoadAction() {
 					private final LockOptions originalLockOptions = lockOptions.makeCopy();
+
 					@Override
 					public void afterLoad(SessionImplementor session, Object entity, Loadable persister) {
-						( (Session) session ).buildLockRequest( originalLockOptions ).lock( persister.getEntityName(), entity );
+						( (Session) session ).buildLockRequest( originalLockOptions ).lock(
+								persister.getEntityName(),
+								entity
+						);
 					}
 				}
 		);
 		parameters.getLockOptions().setLockMode( LockMode.READ );
 
 		return sql;
 	}
 
 	public ScrollableResults scroll(final QueryParameters queryParameters, final SessionImplementor session)
 			throws HibernateException {
 		return scroll(
 				queryParameters,
 				resultTypes,
 				getHolderInstantiator( queryParameters.getResultTransformer(), getReturnAliasesForTransformer() ),
 				session
 		);
 	}
 
-	static private HolderInstantiator getHolderInstantiator(ResultTransformer resultTransformer, String[] queryReturnAliases) {
+	static private HolderInstantiator getHolderInstantiator(
+			ResultTransformer resultTransformer,
+			String[] queryReturnAliases) {
 		if ( resultTransformer == null ) {
 			return HolderInstantiator.NOOP_INSTANTIATOR;
 		}
 		else {
-			return new HolderInstantiator(resultTransformer, queryReturnAliases);
+			return new HolderInstantiator( resultTransformer, queryReturnAliases );
 		}
 	}
 
 	@Override
-    protected String[] getResultRowAliases() {
+	protected String[] getResultRowAliases() {
 		return transformerAliases;
 	}
 
 	@Override
-    protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
+	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return HolderInstantiator.resolveResultTransformer( null, resultTransformer );
 	}
 
 	@Override
-    protected boolean[] includeInResultRow() {
+	protected boolean[] includeInResultRow() {
 		return includeInResultRow;
 	}
 
 	@Override
-    protected Object getResultColumnOrRow(
+	protected Object getResultColumnOrRow(
 			Object[] row,
-	        ResultTransformer transformer,
-	        ResultSet rs,
-	        SessionImplementor session) throws SQLException, HibernateException {
+			ResultTransformer transformer,
+			ResultSet rs,
+			SessionImplementor session) throws SQLException, HibernateException {
 		return rowProcessor.buildResultRow( row, rs, transformer != null, session );
 	}
 
 	@Override
-    protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
+	protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		return rowProcessor.buildResultRow( row, rs, session );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
-    protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
+	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		// meant to handle dynamic instantiation queries...(Copy from QueryLoader)
 		HolderInstantiator holderInstantiator = HolderInstantiator.getHolderInstantiator(
 				null,
 				resultTransformer,
 				getReturnAliasesForTransformer()
 		);
 		if ( holderInstantiator.isRequired() ) {
 			for ( int i = 0; i < results.size(); i++ ) {
-				Object[] row = ( Object[] ) results.get( i );
-				Object result = holderInstantiator.instantiate(row);
+				Object[] row = (Object[]) results.get( i );
+				Object result = holderInstantiator.instantiate( row );
 				results.set( i, result );
 			}
 
-			return resultTransformer.transformList(results);
+			return resultTransformer.transformList( results );
 		}
 		else {
 			return results;
 		}
 	}
 
 	private String[] getReturnAliasesForTransformer() {
 		return transformerAliases;
 	}
 
 	@Override
-    protected EntityAliases[] getEntityAliases() {
+	protected EntityAliases[] getEntityAliases() {
 		return entityAliases;
 	}
 
 	@Override
-    protected CollectionAliases[] getCollectionAliases() {
+	protected CollectionAliases[] getCollectionAliases() {
 		return collectionAliases;
 	}
 
 	@Override
-    public int[] getNamedParameterLocs(String name) throws QueryException {
+	public int[] getNamedParameterLocs(String name) throws QueryException {
 		Object loc = namedParameterBindPoints.get( name );
 		if ( loc == null ) {
 			throw new QueryException(
 					"Named parameter does not appear in Query: " + name,
 					sql
 			);
 		}
 		if ( loc instanceof Integer ) {
-			return new int[] { (Integer) loc };
+			return new int[] {(Integer) loc};
 		}
 		else {
-			return ArrayHelper.toIntArray( ( List ) loc );
+			return ArrayHelper.toIntArray( (List) loc );
 		}
 	}
 
 
 	@Override
-    protected void autoDiscoverTypes(ResultSet rs) {
+	protected void autoDiscoverTypes(ResultSet rs) {
 		try {
 			JdbcResultMetadata metadata = new JdbcResultMetadata( getFactory(), rs );
 			rowProcessor.prepareForAutoDiscovery( metadata );
 
 			List<String> aliases = new ArrayList<String>();
 			List<Type> types = new ArrayList<Type>();
 			for ( ResultColumnProcessor resultProcessor : rowProcessor.getColumnProcessors() ) {
 				resultProcessor.performDiscovery( metadata, types, aliases );
 			}
 
 			validateAliases( aliases );
 
 			resultTypes = ArrayHelper.toTypeArray( types );
 			transformerAliases = ArrayHelper.toStringArray( aliases );
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw new HibernateException( "Exception while trying to autodiscover types.", e );
 		}
 	}
 
 	private void validateAliases(List<String> aliases) {
 		// lets make sure we did not end up with duplicate aliases.  this can occur when the user supplied query
 		// did not rename same-named columns.  e.g.:
 		//		select u.username, u2.username from t_user u, t_user u2 ...
 		//
 		// the above will lead to an unworkable situation in most cases (the difference is how the driver/db
 		// handle this situation.  But if the 'aliases' variable contains duplicate names, then we have that
 		// troublesome condition, so lets throw an error.  See HHH-5992
 		final HashSet<String> aliasesSet = new HashSet<String>();
 		for ( String alias : aliases ) {
 			validateAlias( alias );
 			boolean alreadyExisted = !aliasesSet.add( alias );
 			if ( alreadyExisted ) {
 				throw new NonUniqueDiscoveredSqlAliasException(
 						"Encountered a duplicated sql alias [" + alias + "] during auto-discovery of a native-sql query"
 				);
 			}
 		}
 	}
 
 	@SuppressWarnings("UnusedParameters")
 	protected void validateAlias(String alias) {
 	}
-	
+
 	/**
 	 * {@link #resultTypes} can be overridden by {@link #autoDiscoverTypes(ResultSet)},
 	 * *after* {@link #list(SessionImplementor, QueryParameters)} has already been called.  It's a bit of a
 	 * chicken-and-the-egg issue since {@link #autoDiscoverTypes(ResultSet)} needs the {@link ResultSet}.
-	 * 
+	 * <p/>
 	 * As a hacky workaround, override
 	 * {@link #putResultInQueryCache(SessionImplementor, QueryParameters, Type[], QueryCache, QueryKey, List)} here
 	 * and provide the {@link #resultTypes}.
-	 * 
-	 * @see HHH-3051
+	 *
+	 * see HHH-3051
 	 */
 	@Override
 	protected void putResultInQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key,
 			final List result) {
 		super.putResultInQueryCache( session, queryParameters, this.resultTypes, queryCache, key, result );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryParser.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryParser.java
index 68fdd77821..4180cb4795 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryParser.java
@@ -1,345 +1,343 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.loader.custom.sql;
+
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.QueryException;
 import org.hibernate.engine.query.spi.ParameterParser;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.collection.SQLLoadableCollection;
 import org.hibernate.persister.entity.SQLLoadable;
 
 /**
  * @author Gavin King
  * @author Max Andersen
  * @author Steve Ebersole
  * @author Paul Benedict
  */
 public class SQLQueryParser {
 	private static final String HIBERNATE_PLACEHOLDER_PREFIX = "h-";
 	private static final String DOMAIN_PLACEHOLDER = "h-domain";
 	private static final String CATALOG_PLACEHOLDER = "h-catalog";
 	private static final String SCHEMA_PLACEHOLDER = "h-schema";
 
 	private final SessionFactoryImplementor factory;
 	private final String originalQueryString;
 	private final ParserContext context;
 
 	private final Map namedParameters = new HashMap();
 	private long aliasesFound;
 
-	static interface ParserContext {
+	interface ParserContext {
 		boolean isEntityAlias(String aliasName);
 		SQLLoadable getEntityPersisterByAlias(String alias);
 		String getEntitySuffixByAlias(String alias);
 		boolean isCollectionAlias(String aliasName);
 		SQLLoadableCollection getCollectionPersisterByAlias(String alias);
 		String getCollectionSuffixByAlias(String alias);
 		Map getPropertyResultsMapByAlias(String alias);
 	}
 
 	public SQLQueryParser(String queryString, ParserContext context, SessionFactoryImplementor factory) {
 		this.originalQueryString = queryString;
 		this.context = context;
 		this.factory = factory;
 	}
 
 	public Map getNamedParameters() {
 		return namedParameters;
 	}
 
 	public boolean queryHasAliases() {
 		return aliasesFound>0;
 	}
 
 	public String process() {
 		String processedSql = substituteBrackets( originalQueryString );
 		processedSql = substituteParams( processedSql );
 		return processedSql;
 	}
 
 	// TODO: should "record" how many properties we have reffered to - and if we 
 	//       don't get'em'all we throw an exception! Way better than trial and error ;)
 	private String substituteBrackets(String sqlQuery) throws QueryException {
 
 		StringBuilder result = new StringBuilder( sqlQuery.length() + 20 );
 		int left, right;
 
 		// replace {....} with corresponding column aliases
 		for ( int curr = 0; curr < sqlQuery.length(); curr = right + 1 ) {
 			if ( ( left = sqlQuery.indexOf( '{', curr ) ) < 0 ) {
 				// No additional open braces found in the string, append the
 				// rest of the string in its entirty and quit this loop
 				result.append( sqlQuery.substring( curr ) );
 				break;
 			}
 
 			// apend everything up until the next encountered open brace
 			result.append( sqlQuery.substring( curr, left ) );
 
 			if ( ( right = sqlQuery.indexOf( '}', left + 1 ) ) < 0 ) {
 				throw new QueryException( "Unmatched braces for alias path", sqlQuery );
 			}
 
 			final String aliasPath = sqlQuery.substring( left + 1, right );
 			boolean isPlaceholder = aliasPath.startsWith( HIBERNATE_PLACEHOLDER_PREFIX );
 
 			if ( isPlaceholder ) {
 				// Domain replacement
 				if ( DOMAIN_PLACEHOLDER.equals( aliasPath ) ) {
 					final String catalogName = factory.getSettings().getDefaultCatalogName();
 					if ( catalogName != null ) {
 						result.append( catalogName );
 						result.append( "." );
 					}
 					final String schemaName = factory.getSettings().getDefaultSchemaName();
 					if ( schemaName != null ) {
 						result.append( schemaName );
 						result.append( "." );
 					}
 				}
 				// Schema replacement
 				else if ( SCHEMA_PLACEHOLDER.equals( aliasPath ) ) {
 					final String schemaName = factory.getSettings().getDefaultSchemaName();
 					if ( schemaName != null ) {
 						result.append(schemaName);
 						result.append(".");
 					}
 				} 
 				// Catalog replacement
 				else if ( CATALOG_PLACEHOLDER.equals( aliasPath ) ) {
 					final String catalogName = factory.getSettings().getDefaultCatalogName();
 					if ( catalogName != null ) {
 						result.append( catalogName );
 						result.append( "." );
 					}
 				}
 				else {
 					throw new QueryException( "Unknown placeholder ", aliasPath );
 				}
 			}
 			else {
 				int firstDot = aliasPath.indexOf( '.' );
 				if ( firstDot == -1 ) {
 					if ( context.isEntityAlias( aliasPath ) ) {
 						// it is a simple table alias {foo}
 						result.append( aliasPath );
 						aliasesFound++;
 					} 
 					else {
 						// passing through anything we do not know : to support jdbc escape sequences HB-898
 						result.append( '{' ).append(aliasPath).append( '}' );					
 					}
 				}
 				else {
 					final String aliasName = aliasPath.substring( 0, firstDot );
 					if ( context.isCollectionAlias( aliasName ) ) {
 						// The current alias is referencing the collection to be eagerly fetched
 						String propertyName = aliasPath.substring( firstDot + 1 );
 						result.append( resolveCollectionProperties( aliasName, propertyName ) );
 						aliasesFound++;
 					} 
 					else if ( context.isEntityAlias( aliasName ) ) {
 						// it is a property reference {foo.bar}
 						String propertyName = aliasPath.substring( firstDot + 1 );
 						result.append( resolveProperties( aliasName, propertyName ) );
 						aliasesFound++;
 					}
 					else {
 						// passing through anything we do not know : to support jdbc escape sequences HB-898
 						result.append( '{' ).append(aliasPath).append( '}' );
 					}
 				}
 			}
 		}
 
 		// Possibly handle :something parameters for the query ?
 
 		return result.toString();
 	}	
 
 	private String resolveCollectionProperties(
 			String aliasName,
 			String propertyName) {
 
 		Map fieldResults = context.getPropertyResultsMapByAlias( aliasName );
 		SQLLoadableCollection collectionPersister = context.getCollectionPersisterByAlias( aliasName );
 		String collectionSuffix = context.getCollectionSuffixByAlias( aliasName );
 
 		if ( "*".equals( propertyName ) ) {
 			if( !fieldResults.isEmpty() ) {
 				throw new QueryException("Using return-propertys together with * syntax is not supported.");
 			}
 			
 			String selectFragment = collectionPersister.selectFragment( aliasName, collectionSuffix );
 			aliasesFound++;
 			return selectFragment 
 						+ ", " 
 						+ resolveProperties( aliasName, propertyName );
 		}
 		else if ( "element.*".equals( propertyName ) ) {
 			return resolveProperties( aliasName, "*" );
 		}
 		else {
 			String[] columnAliases;
 
 			// Let return-propertys override whatever the persister has for aliases.
 			columnAliases = ( String[] ) fieldResults.get(propertyName);
 			if ( columnAliases==null ) {
 				columnAliases = collectionPersister.getCollectionPropertyColumnAliases( propertyName, collectionSuffix );
 			}
 			
 			if ( columnAliases == null || columnAliases.length == 0 ) {
 				throw new QueryException(
 						"No column name found for property [" + propertyName + "] for alias [" + aliasName + "]",
 						originalQueryString
 				);
 			}
 			if ( columnAliases.length != 1 ) {
 				// TODO: better error message since we actually support composites if names are explicitly listed.
 				throw new QueryException(
 						"SQL queries only support properties mapped to a single column - property [" +
 						propertyName + "] is mapped to " + columnAliases.length + " columns.",
 						originalQueryString
 				);
 			}
 			aliasesFound++;
 			return columnAliases[0];
 		
 		}
 	}
-	private String resolveProperties(
-			String aliasName,
-	        String propertyName) {
+	private String resolveProperties(String aliasName, String propertyName) {
 		Map fieldResults = context.getPropertyResultsMapByAlias( aliasName );
 		SQLLoadable persister = context.getEntityPersisterByAlias( aliasName );
 		String suffix = context.getEntitySuffixByAlias( aliasName );
 
 		if ( "*".equals( propertyName ) ) {
 			if( !fieldResults.isEmpty() ) {
 				throw new QueryException("Using return-propertys together with * syntax is not supported.");
 			}			
 			aliasesFound++;
 			return persister.selectFragment( aliasName, suffix ) ;
 		}
 		else {
 
 			String[] columnAliases;
 
 			// Let return-propertys override whatever the persister has for aliases.
 			columnAliases = (String[]) fieldResults.get( propertyName );
 			if ( columnAliases == null ) {
 				columnAliases = persister.getSubclassPropertyColumnAliases( propertyName, suffix );
 			}
 
 			if ( columnAliases == null || columnAliases.length == 0 ) {
 				throw new QueryException(
 						"No column name found for property [" + propertyName + "] for alias [" + aliasName + "]",
 						originalQueryString
 				);
 			}
 			if ( columnAliases.length != 1 ) {
 				// TODO: better error message since we actually support composites if names are explicitly listed.
 				throw new QueryException(
 						"SQL queries only support properties mapped to a single column - property [" + propertyName + "] is mapped to " + columnAliases.length + " columns.",
 						originalQueryString
 				);
 			}			
 			aliasesFound++;
 			return columnAliases[0];
 		}
 	}
 
 	/**
 	 * Substitues JDBC parameter placeholders (?) for all encountered
 	 * parameter specifications.  It also tracks the positions of these
 	 * parameter specifications within the query string.  This accounts for
 	 * ordinal-params, named-params, and ejb3-positional-params.
 	 *
 	 * @param sqlString The query string.
 	 * @return The SQL query with parameter substitution complete.
 	 */
 	private String substituteParams(String sqlString) {
 		ParameterSubstitutionRecognizer recognizer = new ParameterSubstitutionRecognizer();
 		ParameterParser.parse( sqlString, recognizer );
 
 		namedParameters.clear();
 		namedParameters.putAll( recognizer.namedParameterBindPoints );
 
 		return recognizer.result.toString();
 	}
 
 	public static class ParameterSubstitutionRecognizer implements ParameterParser.Recognizer {
 		StringBuilder result = new StringBuilder();
 		Map namedParameterBindPoints = new HashMap();
 		int parameterCount;
 
 		@Override
 		public void outParameter(int position) {
 			result.append( '?' );
 		}
 
 		@Override
 		public void ordinalParameter(int position) {
 			result.append( '?' );
 		}
 
 		@Override
 		public void namedParameter(String name, int position) {
 			addNamedParameter( name );
 			result.append( '?' );
 		}
 
 		@Override
 		public void jpaPositionalParameter(String name, int position) {
 			namedParameter( name, position );
 		}
 
 		@Override
 		public void other(char character) {
 			result.append( character );
 		}
 
 		private void addNamedParameter(String name) {
 			Integer loc = parameterCount++;
 			Object o = namedParameterBindPoints.get( name );
 			if ( o == null ) {
 				namedParameterBindPoints.put( name, loc );
 			}
 			else if ( o instanceof Integer ) {
 				ArrayList list = new ArrayList( 4 );
 				list.add( o );
 				list.add( loc );
 				namedParameterBindPoints.put( name, list );
 			}
 			else {
 				( ( List ) o ).add( loc );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
index 0ac300d058..0bd312a096 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
@@ -1,573 +1,573 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.custom.sql;
 
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryCollectionReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryConstructorReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryJoinReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryNonScalarReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryScalarReturn;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.ColumnEntityAliases;
 import org.hibernate.loader.DefaultEntityAliases;
 import org.hibernate.loader.EntityAliases;
 import org.hibernate.loader.GeneratedCollectionAliases;
 import org.hibernate.loader.custom.CollectionFetchReturn;
 import org.hibernate.loader.custom.CollectionReturn;
 import org.hibernate.loader.custom.ColumnCollectionAliases;
 import org.hibernate.loader.custom.ConstructorReturn;
 import org.hibernate.loader.custom.EntityFetchReturn;
 import org.hibernate.loader.custom.FetchReturn;
 import org.hibernate.loader.custom.NonScalarReturn;
 import org.hibernate.loader.custom.Return;
 import org.hibernate.loader.custom.RootReturn;
 import org.hibernate.loader.custom.ScalarReturn;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.SQLLoadableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.SQLLoadable;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Responsible for processing the series of {@link org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn returns}
  * defined by a {@link org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification} and
  * breaking them down into a series of {@link Return returns} for use within the
  * {@link org.hibernate.loader.custom.CustomLoader}.
  *
  * @author Gavin King
  * @author Max Andersen
  * @author Steve Ebersole
  */
 public class SQLQueryReturnProcessor {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SQLQueryReturnProcessor.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SQLQueryReturnProcessor.class );
 
 	private static final NativeSQLQueryReturn[] NO_RETURNS = new NativeSQLQueryReturn[0];
 
 	private NativeSQLQueryReturn[] queryReturns;
 
 //	private final List persisters = new ArrayList();
 
 	private final Map alias2Return = new HashMap();
 	private final Map alias2OwnerAlias = new HashMap();
 
 	private final Map<String,EntityPersister> alias2Persister = new HashMap<String,EntityPersister>();
 	private final Map alias2Suffix = new HashMap();
 
 	private final Map<String,CollectionPersister> alias2CollectionPersister = new HashMap<String,CollectionPersister>();
 	private final Map alias2CollectionSuffix = new HashMap();
 
 	private final Map entityPropertyResultMaps = new HashMap();
 	private final Map collectionPropertyResultMaps = new HashMap();
 
 //	private final List scalarTypes = new ArrayList();
 //	private final List scalarColumnAliases = new ArrayList();
 
 	private final SessionFactoryImplementor factory;
 
 //	private List collectionOwnerAliases = new ArrayList();
 //	private List collectionAliases = new ArrayList();
 //	private List collectionPersisters = new ArrayList();
 //	private List collectionResults = new ArrayList();
 
 	private int entitySuffixSeed;
 	private int collectionSuffixSeed;
 
 
 	public SQLQueryReturnProcessor(NativeSQLQueryReturn[] queryReturns, SessionFactoryImplementor factory) {
 		this.queryReturns = queryReturns == null ? NO_RETURNS : queryReturns;
 		this.factory = factory;
 	}
 
 	public class ResultAliasContext {
 		public SQLLoadable getEntityPersister(String alias) {
 			return (SQLLoadable) alias2Persister.get( alias );
 		}
 
 		public SQLLoadableCollection getCollectionPersister(String alias) {
 			return (SQLLoadableCollection) alias2CollectionPersister.get( alias );
 		}
 
 		public String getEntitySuffix(String alias) {
 			return (String) alias2Suffix.get( alias );
 		}
 
 		public String getCollectionSuffix(String alias) {
 			return (String) alias2CollectionSuffix.get( alias );
 		}
 
 		public String getOwnerAlias(String alias) {
 			return (String) alias2OwnerAlias.get( alias );
 		}
 
 		public Map getPropertyResultsMap(String alias) {
 			return internalGetPropertyResultsMap( alias );
 		}
 
 		public String[] collectQuerySpaces() {
 			final HashSet<String> spaces = new HashSet<String>();
 			collectQuerySpaces( spaces );
 			return spaces.toArray( new String[ spaces.size() ] );
 		}
 
 		public void collectQuerySpaces(Collection<String> spaces) {
 			for ( EntityPersister persister : alias2Persister.values() ) {
 				Collections.addAll( spaces, (String[]) persister.getQuerySpaces() );
 			}
 			for ( CollectionPersister persister : alias2CollectionPersister.values() ) {
 				final Type elementType = persister.getElementType();
 				if ( elementType.isEntityType() && ! elementType.isAnyType() ) {
 					final Joinable joinable = ( (EntityType) elementType ).getAssociatedJoinable( factory );
 					Collections.addAll( spaces, (String[]) ( (EntityPersister) joinable ).getQuerySpaces() );
 				}
 			}
 		}
 	}
 
 	private Map internalGetPropertyResultsMap(String alias) {
 		NativeSQLQueryReturn rtn = ( NativeSQLQueryReturn ) alias2Return.get( alias );
 		if ( rtn instanceof NativeSQLQueryNonScalarReturn ) {
 			return ( ( NativeSQLQueryNonScalarReturn ) rtn ).getPropertyResultsMap();
 		}
 		else {
 			return null;
 		}
 	}
 
 	private boolean hasPropertyResultMap(String alias) {
 		Map propertyMaps = internalGetPropertyResultsMap( alias );
 		return propertyMaps != null && ! propertyMaps.isEmpty();
 	}
 
 	public ResultAliasContext process() {
 		// first, break down the returns into maps keyed by alias
 		// so that role returns can be more easily resolved to their owners
 		for ( NativeSQLQueryReturn queryReturn : queryReturns ) {
 			if ( queryReturn instanceof NativeSQLQueryNonScalarReturn ) {
 				NativeSQLQueryNonScalarReturn rtn = (NativeSQLQueryNonScalarReturn) queryReturn;
 				alias2Return.put( rtn.getAlias(), rtn );
 				if ( rtn instanceof NativeSQLQueryJoinReturn ) {
 					NativeSQLQueryJoinReturn fetchReturn = (NativeSQLQueryJoinReturn) rtn;
 					alias2OwnerAlias.put( fetchReturn.getAlias(), fetchReturn.getOwnerAlias() );
 				}
 			}
 		}
 
 		// Now, process the returns
 		for ( NativeSQLQueryReturn queryReturn : queryReturns ) {
 			processReturn( queryReturn );
 		}
 
 		return new ResultAliasContext();
 	}
 
 	public List<Return> generateCustomReturns(boolean queryHadAliases) {
 		List<Return> customReturns = new ArrayList<Return>();
 		Map<String,Return> customReturnsByAlias = new HashMap<String,Return>();
 		for ( NativeSQLQueryReturn queryReturn : queryReturns ) {
 			if ( queryReturn instanceof NativeSQLQueryScalarReturn ) {
 				NativeSQLQueryScalarReturn rtn = (NativeSQLQueryScalarReturn) queryReturn;
 				customReturns.add( new ScalarReturn( rtn.getType(), rtn.getColumnAlias() ) );
 			}
 			else if ( queryReturn instanceof NativeSQLQueryRootReturn ) {
 				NativeSQLQueryRootReturn rtn = (NativeSQLQueryRootReturn) queryReturn;
 				String alias = rtn.getAlias();
 				EntityAliases entityAliases;
 				if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
 					entityAliases = new DefaultEntityAliases(
 							(Map) entityPropertyResultMaps.get( alias ),
 							(SQLLoadable) alias2Persister.get( alias ),
 							(String) alias2Suffix.get( alias )
 					);
 				}
 				else {
 					entityAliases = new ColumnEntityAliases(
 							(Map) entityPropertyResultMaps.get( alias ),
 							(SQLLoadable) alias2Persister.get( alias ),
 							(String) alias2Suffix.get( alias )
 					);
 				}
 				RootReturn customReturn = new RootReturn(
 						alias,
 						rtn.getReturnEntityName(),
 						entityAliases,
 						rtn.getLockMode()
 				);
 				customReturns.add( customReturn );
 				customReturnsByAlias.put( rtn.getAlias(), customReturn );
 			}
 			else if ( queryReturn instanceof NativeSQLQueryCollectionReturn ) {
 				NativeSQLQueryCollectionReturn rtn = (NativeSQLQueryCollectionReturn) queryReturn;
 				String alias = rtn.getAlias();
 				SQLLoadableCollection persister = (SQLLoadableCollection) alias2CollectionPersister.get( alias );
 				boolean isEntityElements = persister.getElementType().isEntityType();
 				CollectionAliases collectionAliases;
 				EntityAliases elementEntityAliases = null;
 				if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
 					collectionAliases = new GeneratedCollectionAliases(
 							(Map) collectionPropertyResultMaps.get( alias ),
 							(SQLLoadableCollection) alias2CollectionPersister.get( alias ),
 							(String) alias2CollectionSuffix.get( alias )
 					);
 					if ( isEntityElements ) {
 						elementEntityAliases = new DefaultEntityAliases(
 								(Map) entityPropertyResultMaps.get( alias ),
 								(SQLLoadable) alias2Persister.get( alias ),
 								(String) alias2Suffix.get( alias )
 						);
 					}
 				}
 				else {
 					collectionAliases = new ColumnCollectionAliases(
 							(Map) collectionPropertyResultMaps.get( alias ),
 							(SQLLoadableCollection) alias2CollectionPersister.get( alias )
 					);
 					if ( isEntityElements ) {
 						elementEntityAliases = new ColumnEntityAliases(
 								(Map) entityPropertyResultMaps.get( alias ),
 								(SQLLoadable) alias2Persister.get( alias ),
 								(String) alias2Suffix.get( alias )
 						);
 					}
 				}
 				CollectionReturn customReturn = new CollectionReturn(
 						alias,
 						rtn.getOwnerEntityName(),
 						rtn.getOwnerProperty(),
 						collectionAliases,
 						elementEntityAliases,
 						rtn.getLockMode()
 				);
 				customReturns.add( customReturn );
 				customReturnsByAlias.put( rtn.getAlias(), customReturn );
 			}
 			else if ( queryReturn instanceof NativeSQLQueryJoinReturn ) {
 				NativeSQLQueryJoinReturn rtn = (NativeSQLQueryJoinReturn) queryReturn;
 				String alias = rtn.getAlias();
 				FetchReturn customReturn;
 				NonScalarReturn ownerCustomReturn = (NonScalarReturn) customReturnsByAlias.get( rtn.getOwnerAlias() );
 				if ( alias2CollectionPersister.containsKey( alias ) ) {
 					SQLLoadableCollection persister = (SQLLoadableCollection) alias2CollectionPersister.get( alias );
 					boolean isEntityElements = persister.getElementType().isEntityType();
 					CollectionAliases collectionAliases;
 					EntityAliases elementEntityAliases = null;
 					if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
 						collectionAliases = new GeneratedCollectionAliases(
 								(Map) collectionPropertyResultMaps.get( alias ),
 								persister,
 								(String) alias2CollectionSuffix.get( alias )
 						);
 						if ( isEntityElements ) {
 							elementEntityAliases = new DefaultEntityAliases(
 									(Map) entityPropertyResultMaps.get( alias ),
 									(SQLLoadable) alias2Persister.get( alias ),
 									(String) alias2Suffix.get( alias )
 							);
 						}
 					}
 					else {
 						collectionAliases = new ColumnCollectionAliases(
 								(Map) collectionPropertyResultMaps.get( alias ),
 								persister
 						);
 						if ( isEntityElements ) {
 							elementEntityAliases = new ColumnEntityAliases(
 									(Map) entityPropertyResultMaps.get( alias ),
 									(SQLLoadable) alias2Persister.get( alias ),
 									(String) alias2Suffix.get( alias )
 							);
 						}
 					}
 					customReturn = new CollectionFetchReturn(
 							alias,
 							ownerCustomReturn,
 							rtn.getOwnerProperty(),
 							collectionAliases,
 							elementEntityAliases,
 							rtn.getLockMode()
 					);
 				}
 				else {
 					EntityAliases entityAliases;
 					if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
 						entityAliases = new DefaultEntityAliases(
 								(Map) entityPropertyResultMaps.get( alias ),
 								(SQLLoadable) alias2Persister.get( alias ),
 								(String) alias2Suffix.get( alias )
 						);
 					}
 					else {
 						entityAliases = new ColumnEntityAliases(
 								(Map) entityPropertyResultMaps.get( alias ),
 								(SQLLoadable) alias2Persister.get( alias ),
 								(String) alias2Suffix.get( alias )
 						);
 					}
 					customReturn = new EntityFetchReturn(
 							alias,
 							entityAliases,
 							ownerCustomReturn,
 							rtn.getOwnerProperty(),
 							rtn.getLockMode()
 					);
 				}
 				customReturns.add( customReturn );
 				customReturnsByAlias.put( alias, customReturn );
 			}
 			else if ( NativeSQLQueryConstructorReturn.class.isInstance( queryReturn ) ) {
 				final NativeSQLQueryConstructorReturn constructorReturn = (NativeSQLQueryConstructorReturn) queryReturn;
 				final ScalarReturn[] scalars = new ScalarReturn[ constructorReturn.getColumnReturns().length ];
 				int i = 0;
 				for ( NativeSQLQueryScalarReturn scalarReturn : constructorReturn.getColumnReturns() ) {
 					scalars[i++] = new ScalarReturn( scalarReturn.getType(), scalarReturn.getColumnAlias() );
 				}
 				customReturns.add( new ConstructorReturn( constructorReturn.getTargetClass(), scalars ) );
 			}
 			else {
 				throw new IllegalStateException(
 						"Unrecognized NativeSQLQueryReturn concrete type : " + queryReturn
 				);
 			}
 		}
 		return customReturns;
 	}
 
 	private SQLLoadable getSQLLoadable(String entityName) throws MappingException {
 		EntityPersister persister = factory.getEntityPersister( entityName );
 		if ( !(persister instanceof SQLLoadable) ) {
 			throw new MappingException( "class persister is not SQLLoadable: " + entityName );
 		}
 		return (SQLLoadable) persister;
 	}
 
 	private String generateEntitySuffix() {
 		return BasicLoader.generateSuffixes( entitySuffixSeed++, 1 )[0];
 	}
 
 	private String generateCollectionSuffix() {
 		return collectionSuffixSeed++ + "__";
 	}
 
 	private void processReturn(NativeSQLQueryReturn rtn) {
 		if ( rtn instanceof NativeSQLQueryScalarReturn ) {
 			processScalarReturn( ( NativeSQLQueryScalarReturn ) rtn );
 		}
 		else if ( rtn instanceof NativeSQLQueryRootReturn ) {
 			processRootReturn( ( NativeSQLQueryRootReturn ) rtn );
 		}
 		else if ( rtn instanceof NativeSQLQueryCollectionReturn ) {
 			processCollectionReturn( (NativeSQLQueryCollectionReturn) rtn );
 		}
 		else if ( NativeSQLQueryJoinReturn.class.isInstance( rtn ) ) {
 			processJoinReturn( ( NativeSQLQueryJoinReturn ) rtn );
 		}
 		else if ( NativeSQLQueryConstructorReturn.class.isInstance(  rtn ) ) {
 			processConstructorReturn( (NativeSQLQueryConstructorReturn) rtn );
 		}
 		else {
 			throw new IllegalStateException(
 					"Unrecognized NativeSQLQueryReturn concrete type encountered : " + rtn
 			);
 		}
 	}
 
 	private void processConstructorReturn(NativeSQLQueryConstructorReturn rtn) {
 		//To change body of created methods use File | Settings | File Templates.
 	}
 
 	private void processScalarReturn(NativeSQLQueryScalarReturn typeReturn) {
 //		scalarColumnAliases.add( typeReturn.getColumnAlias() );
 //		scalarTypes.add( typeReturn.getType() );
 	}
 
 	private void processRootReturn(NativeSQLQueryRootReturn rootReturn) {
 		if ( alias2Persister.containsKey( rootReturn.getAlias() ) ) {
 			// already been processed...
 			return;
 		}
 
 		SQLLoadable persister = getSQLLoadable( rootReturn.getReturnEntityName() );
 		addPersister( rootReturn.getAlias(), rootReturn.getPropertyResultsMap(), persister );
 	}
 
 	private void addPersister(String alias, Map propertyResult, SQLLoadable persister) {
 		alias2Persister.put( alias, persister );
 		String suffix = generateEntitySuffix();
 		LOG.tracev( "Mapping alias [{0}] to entity-suffix [{1}]", alias, suffix );
 		alias2Suffix.put( alias, suffix );
 		entityPropertyResultMaps.put( alias, propertyResult );
 	}
 
 	private void addCollection(String role, String alias, Map propertyResults) {
 		SQLLoadableCollection collectionPersister = ( SQLLoadableCollection ) factory.getCollectionPersister( role );
 		alias2CollectionPersister.put( alias, collectionPersister );
 		String suffix = generateCollectionSuffix();
 		LOG.tracev( "Mapping alias [{0}] to collection-suffix [{1}]", alias, suffix );
 		alias2CollectionSuffix.put( alias, suffix );
 		collectionPropertyResultMaps.put( alias, propertyResults );
 
 		if ( collectionPersister.isOneToMany() || collectionPersister.isManyToMany() ) {
 			SQLLoadable persister = ( SQLLoadable ) collectionPersister.getElementPersister();
 			addPersister( alias, filter( propertyResults ), persister );
 		}
 	}
 
 	private Map filter(Map propertyResults) {
 		Map result = new HashMap( propertyResults.size() );
 
 		String keyPrefix = "element.";
 
 		Iterator iter = propertyResults.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry element = ( Map.Entry ) iter.next();
 			String path = ( String ) element.getKey();
 			if ( path.startsWith( keyPrefix ) ) {
 				result.put( path.substring( keyPrefix.length() ), element.getValue() );
 			}
 		}
 
 		return result;
 	}
 
 	private void processCollectionReturn(NativeSQLQueryCollectionReturn collectionReturn) {
 		// we are initializing an owned collection
 		//collectionOwners.add( new Integer(-1) );
 //		collectionOwnerAliases.add( null );
 		String role = collectionReturn.getOwnerEntityName() + '.' + collectionReturn.getOwnerProperty();
 		addCollection(
 				role,
 				collectionReturn.getAlias(),
 				collectionReturn.getPropertyResultsMap()
 		);
 	}
 
 	private void processJoinReturn(NativeSQLQueryJoinReturn fetchReturn) {
 		String alias = fetchReturn.getAlias();
 //		if ( alias2Persister.containsKey( alias ) || collectionAliases.contains( alias ) ) {
 		if ( alias2Persister.containsKey( alias ) || alias2CollectionPersister.containsKey( alias ) ) {
 			// already been processed...
 			return;
 		}
 
 		String ownerAlias = fetchReturn.getOwnerAlias();
 
 		// Make sure the owner alias is known...
 		if ( !alias2Return.containsKey( ownerAlias ) ) {
 			throw new HibernateException( "Owner alias [" + ownerAlias + "] is unknown for alias [" + alias + "]" );
 		}
 
 		// If this return's alias has not been processed yet, do so b4 further processing of this return
 		if ( !alias2Persister.containsKey( ownerAlias ) ) {
 			NativeSQLQueryNonScalarReturn ownerReturn = ( NativeSQLQueryNonScalarReturn ) alias2Return.get(ownerAlias);
 			processReturn( ownerReturn );
 		}
 
 		SQLLoadable ownerPersister = ( SQLLoadable ) alias2Persister.get( ownerAlias );
 		Type returnType = ownerPersister.getPropertyType( fetchReturn.getOwnerProperty() );
 
 		if ( returnType.isCollectionType() ) {
 			String role = ownerPersister.getEntityName() + '.' + fetchReturn.getOwnerProperty();
 			addCollection( role, alias, fetchReturn.getPropertyResultsMap() );
 //			collectionOwnerAliases.add( ownerAlias );
 		}
 		else if ( returnType.isEntityType() ) {
 			EntityType eType = ( EntityType ) returnType;
 			String returnEntityName = eType.getAssociatedEntityName();
 			SQLLoadable persister = getSQLLoadable( returnEntityName );
 			addPersister( alias, fetchReturn.getPropertyResultsMap(), persister );
 		}
 
 	}
 
 //	public List getCollectionAliases() {
 //		return collectionAliases;
 //	}
 //
 //	/*public List getCollectionOwners() {
 //		return collectionOwners;
 //	}*/
 //
 //	public List getCollectionOwnerAliases() {
 //		return collectionOwnerAliases;
 //	}
 //
 //	public List getCollectionPersisters() {
 //		return collectionPersisters;
 //	}
 //
 //	public Map getAlias2Persister() {
 //		return alias2Persister;
 //	}
 //
 //	/*public boolean isCollectionInitializer() {
 //		return isCollectionInitializer;
 //	}*/
 //
 ////	public List getPersisters() {
 ////		return persisters;
 ////	}
 //
 //	public Map getAlias2OwnerAlias() {
 //		return alias2OwnerAlias;
 //	}
 //
 //	public List getScalarTypes() {
 //		return scalarTypes;
 //	}
 //	public List getScalarColumnAliases() {
 //		return scalarColumnAliases;
 //	}
 //
 //	public List getPropertyResults() {
 //		return propertyResults;
 //	}
 //
 //	public List getCollectionPropertyResults() {
 //		return collectionResults;
 //	}
 //
 //
 //	public Map getAlias2Return() {
 //		return alias2Return;
 //	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/AbstractEntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/AbstractEntityLoader.java
index ebd1fca214..548b3311dd 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/AbstractEntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/AbstractEntityLoader.java
@@ -1,122 +1,125 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.entity;
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.loader.OuterJoinLoader;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 
-public abstract class AbstractEntityLoader extends OuterJoinLoader
+public abstract class AbstractEntityLoader
+		extends OuterJoinLoader
 		implements UniqueEntityLoader {
-
 	protected final OuterJoinLoadable persister;
 	protected final Type uniqueKeyType;
 	protected final String entityName;
 
 	public AbstractEntityLoader(
 			OuterJoinLoadable persister,
 			Type uniqueKeyType,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		super( factory, loadQueryInfluencers );
 		this.uniqueKeyType = uniqueKeyType;
 		this.entityName = persister.getEntityName();
 		this.persister = persister;
 
 	}
 
 	@Override
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session) {
 		// this form is deprecated!
 		return load( id, optionalObject, session, LockOptions.NONE );
 	}
 
 	@Override
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session, LockOptions lockOptions) {
 		return load( session, id, optionalObject, id, lockOptions );
 	}
 
 	protected Object load(
 			SessionImplementor session,
 			Object id,
 			Object optionalObject,
 			Serializable optionalId,
 			LockOptions lockOptions) {
 
 		List list = loadEntity(
 				session,
 				id,
 				uniqueKeyType,
 				optionalObject,
 				entityName,
 				optionalId,
 				persister,
 				lockOptions
 			);
 
 		if ( list.size()==1 ) {
 			return list.get(0);
 		}
 		else if ( list.size()==0 ) {
 			return null;
 		}
 		else {
 			if ( getCollectionOwners()!=null ) {
 				return list.get(0);
 			}
 			else {
 				throw new HibernateException(
 						"More than one row with the given identifier was found: " +
 						id +
 						", for class: " +
 						persister.getEntityName()
 					);
 			}
 		}
 
 	}
 
 	@Override
-    protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
-	throws SQLException, HibernateException {
+	protected Object getResultColumnOrRow(
+			Object[] row,
+			ResultTransformer transformer,
+			ResultSet rs,
+			SessionImplementor session) throws SQLException, HibernateException {
 		return row[row.length-1];
 	}
 
 	@Override
-    protected boolean isSingleRowLoader() {
+	protected boolean isSingleRowLoader() {
 		return true;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/CascadeEntityJoinWalker.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/CascadeEntityJoinWalker.java
index bd3d5f7abc..5e435c14f7 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/CascadeEntityJoinWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/CascadeEntityJoinWalker.java
@@ -1,70 +1,73 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.loader.entity;
+
 import java.util.Collections;
 
 import org.hibernate.FetchMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadingAction;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.AbstractEntityJoinWalker;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.type.AssociationType;
 
 public class CascadeEntityJoinWalker extends AbstractEntityJoinWalker {
-	
+
 	private final CascadingAction cascadeAction;
 
-	public CascadeEntityJoinWalker(OuterJoinLoadable persister, CascadingAction action, SessionFactoryImplementor factory)
-	throws MappingException {
+	public CascadeEntityJoinWalker(
+			OuterJoinLoadable persister,
+			CascadingAction action,
+			SessionFactoryImplementor factory)
+			throws MappingException {
 		super( persister, factory, LoadQueryInfluencers.NONE );
 		this.cascadeAction = action;
 		StringBuilder whereCondition = whereString( getAlias(), persister.getIdentifierColumnNames(), 1 )
 				//include the discriminator and class-level where, but not filters
 				.append( persister.filterFragment( getAlias(), Collections.EMPTY_MAP ) );
-	
+
 		initAll( whereCondition.toString(), "", LockOptions.READ );
 	}
 
 	@Override
-    protected boolean isJoinedFetchEnabled(AssociationType type, FetchMode config, CascadeStyle cascadeStyle) {
+	protected boolean isJoinedFetchEnabled(AssociationType type, FetchMode config, CascadeStyle cascadeStyle) {
 		return ( type.isEntityType() || type.isCollectionType() ) &&
-				( cascadeStyle==null || cascadeStyle.doCascade(cascadeAction) );
+				( cascadeStyle == null || cascadeStyle.doCascade( cascadeAction ) );
 	}
 
 	@Override
-    protected boolean isTooManyCollections() {
-		return countCollectionPersisters(associations)>0;
+	protected boolean isTooManyCollections() {
+		return countCollectionPersisters( associations ) > 0;
 	}
 
 	@Override
-    public String getComment() {
+	public String getComment() {
 		return "load " + getPersister().getEntityName();
 	}
-	
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/CollectionElementLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/CollectionElementLoader.java
index ea2dc1439d..0e9e08be0d 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/CollectionElementLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/CollectionElementLoader.java
@@ -1,136 +1,137 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.entity;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.JoinWalker;
 import org.hibernate.loader.OuterJoinLoader;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
- *
- *
  * @author Gavin King
  */
 public class CollectionElementLoader extends OuterJoinLoader {
 
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, CollectionElementLoader.class.getName() );
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
+			CoreMessageLogger.class,
+			CollectionElementLoader.class.getName()
+	);
 
 	private final OuterJoinLoadable persister;
 	private final Type keyType;
 	private final Type indexType;
 	private final String entityName;
 
 	public CollectionElementLoader(
 			QueryableCollection collectionPersister,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		super( factory, loadQueryInfluencers );
 
 		this.keyType = collectionPersister.getKeyType();
 		this.indexType = collectionPersister.getIndexType();
 		this.persister = (OuterJoinLoadable) collectionPersister.getElementPersister();
 		this.entityName = persister.getEntityName();
 
 		JoinWalker walker = new EntityJoinWalker(
-				persister, 
+				persister,
 				ArrayHelper.join(
 						collectionPersister.getKeyColumnNames(),
-						collectionPersister.toColumns("index")
+						collectionPersister.toColumns( "index" )
 				),
-				1, 
-				LockMode.NONE, 
-				factory, 
+				1,
+				LockMode.NONE,
+				factory,
 				loadQueryInfluencers
-			);
+		);
 		initFromWalker( walker );
 
 		postInstantiate();
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Static select for entity %s: %s", entityName, getSQLString() );
 		}
 
 	}
 
 	public Object loadElement(SessionImplementor session, Object key, Object index)
-	throws HibernateException {
+			throws HibernateException {
 
 		List list = loadEntity(
 				session,
 				key,
 				index,
 				keyType,
 				indexType,
 				persister
-			);
+		);
 
-		if ( list.size()==1 ) {
-			return list.get(0);
+		if ( list.size() == 1 ) {
+			return list.get( 0 );
 		}
-		else if ( list.size()==0 ) {
+		else if ( list.size() == 0 ) {
 			return null;
 		}
 		else {
-			if ( getCollectionOwners()!=null ) {
-				return list.get(0);
+			if ( getCollectionOwners() != null ) {
+				return list.get( 0 );
 			}
 			else {
-				throw new HibernateException("More than one row was found");
+				throw new HibernateException( "More than one row was found" );
 			}
 		}
 
 	}
 
 	@Override
-    protected Object getResultColumnOrRow(
-		Object[] row,
-		ResultTransformer transformer,
-		ResultSet rs, SessionImplementor session)
-	throws SQLException, HibernateException {
-		return row[row.length-1];
+	protected Object getResultColumnOrRow(
+			Object[] row,
+			ResultTransformer transformer,
+			ResultSet rs, SessionImplementor session)
+			throws SQLException, HibernateException {
+		return row[row.length - 1];
 	}
 
 	@Override
-    protected boolean isSingleRowLoader() {
+	protected boolean isSingleRowLoader() {
 		return true;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/EntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/EntityLoader.java
index 5aa490f944..3ddf573bb5 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/EntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/EntityLoader.java
@@ -1,173 +1,173 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.entity;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.type.Type;
 
 /**
  * Loads an entity instance using outerjoin fetching to fetch associated entities.
  * <br>
  * The <tt>EntityPersister</tt> must implement <tt>Loadable</tt>. For other entities,
  * create a customized subclass of <tt>Loader</tt>.
  *
  * @author Gavin King
  */
 public class EntityLoader extends AbstractEntityLoader {
 
 	private final boolean batchLoader;
 	private final int[][] compositeKeyManyToOneTargetIndices;
 
 	public EntityLoader(
 			OuterJoinLoadable persister,
 			LockMode lockMode,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		this( persister, 1, lockMode, factory, loadQueryInfluencers );
 	}
 
 	public EntityLoader(
 			OuterJoinLoadable persister,
 			LockOptions lockOptions,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		this( persister, 1, lockOptions, factory, loadQueryInfluencers );
 	}
 
 	public EntityLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockMode lockMode,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		this(
 				persister,
 				persister.getIdentifierColumnNames(),
 				persister.getIdentifierType(),
 				batchSize,
 				lockMode,
 				factory,
 				loadQueryInfluencers
 			);
 	}
 
 	public EntityLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockOptions lockOptions,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		this(
 				persister,
 				persister.getIdentifierColumnNames(),
 				persister.getIdentifierType(),
 				batchSize,
 				lockOptions,
 				factory,
 				loadQueryInfluencers
 			);
 	}
 
 	public EntityLoader(
 			OuterJoinLoadable persister,
 			String[] uniqueKey,
 			Type uniqueKeyType,
 			int batchSize,
 			LockMode lockMode,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		super( persister, uniqueKeyType, factory, loadQueryInfluencers );
 
 		EntityJoinWalker walker = new EntityJoinWalker(
 				persister,
 				uniqueKey,
 				batchSize,
 				lockMode,
 				factory,
 				loadQueryInfluencers
 		);
 		initFromWalker( walker );
 		this.compositeKeyManyToOneTargetIndices = walker.getCompositeKeyManyToOneTargetIndices();
 		postInstantiate();
 
 		batchLoader = batchSize > 1;
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Static select for entity %s [%s]: %s", entityName, lockMode, getSQLString() );
 		}
 	}
 
 	public EntityLoader(
 			OuterJoinLoadable persister,
 			String[] uniqueKey,
 			Type uniqueKeyType,
 			int batchSize,
 			LockOptions lockOptions,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		super( persister, uniqueKeyType, factory, loadQueryInfluencers );
 
 		EntityJoinWalker walker = new EntityJoinWalker(
 				persister,
 				uniqueKey,
 				batchSize,
 				lockOptions,
 				factory,
 				loadQueryInfluencers
 		);
 		initFromWalker( walker );
 		this.compositeKeyManyToOneTargetIndices = walker.getCompositeKeyManyToOneTargetIndices();
 		postInstantiate();
 
 		batchLoader = batchSize > 1;
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Static select for entity %s [%s:%s]: %s",
 					entityName,
 					lockOptions.getLockMode(),
 					lockOptions.getTimeOut(),
 					getSQLString() );
 		}
 	}
 
 	public Object loadByUniqueKey(SessionImplementor session,Object key) {
 		return load( session, key, null, null, LockOptions.NONE );
 	}
 
 	@Override
-    protected boolean isSingleRowLoader() {
+	protected boolean isSingleRowLoader() {
 		return !batchLoader;
 	}
 
 	@Override
-    public int[][] getCompositeKeyManyToOneTargetIndices() {
+	public int[][] getCompositeKeyManyToOneTargetIndices() {
 		return compositeKeyManyToOneTargetIndices;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/hql/QueryLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/hql/QueryLoader.java
index cd553624a9..ec0271dc89 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/hql/QueryLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/hql/QueryLoader.java
@@ -1,620 +1,648 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.hql;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.hql.internal.ast.QueryTranslatorImpl;
 import org.hibernate.hql.internal.ast.tree.AggregatedSelectExpression;
 import org.hibernate.hql.internal.ast.tree.FromElement;
 import org.hibernate.hql.internal.ast.tree.QueryNode;
 import org.hibernate.hql.internal.ast.tree.SelectClause;
 import org.hibernate.internal.IteratorImpl;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * A delegate that implements the Loader part of QueryTranslator.
  *
  * @author josh
  */
 public class QueryLoader extends BasicLoader {
 
 	/**
 	 * The query translator that is delegating to this object.
 	 */
 	private QueryTranslatorImpl queryTranslator;
 
 	private Queryable[] entityPersisters;
 	private String[] entityAliases;
 	private String[] sqlAliases;
 	private String[] sqlAliasSuffixes;
 	private boolean[] includeInSelect;
 
 	private String[] collectionSuffixes;
 
 	private boolean hasScalars;
 	private String[][] scalarColumnNames;
 	//private Type[] sqlResultTypes;
 	private Type[] queryReturnTypes;
 
-	private final Map<String, String> sqlAliasByEntityAlias = new HashMap<String, String>(8);
+	private final Map<String, String> sqlAliasByEntityAlias = new HashMap<String, String>( 8 );
 
 	private EntityType[] ownerAssociationTypes;
 	private int[] owners;
 	private boolean[] entityEagerPropertyFetches;
 
 	private int[] collectionOwners;
 	private QueryableCollection[] collectionPersisters;
 
 	private int selectLength;
 
 	private AggregatedSelectExpression aggregatedSelectExpression;
 	private String[] queryReturnAliases;
 
 	private LockMode[] defaultLockModes;
 
 
 	/**
 	 * Creates a new Loader implementation.
 	 *
 	 * @param queryTranslator The query translator that is the delegator.
 	 * @param factory The factory from which this loader is being created.
 	 * @param selectClause The AST representing the select clause for loading.
 	 */
 	public QueryLoader(
 			final QueryTranslatorImpl queryTranslator,
-	        final SessionFactoryImplementor factory,
-	        final SelectClause selectClause) {
+			final SessionFactoryImplementor factory,
+			final SelectClause selectClause) {
 		super( factory );
 		this.queryTranslator = queryTranslator;
 		initialize( selectClause );
 		postInstantiate();
 	}
 
 	private void initialize(SelectClause selectClause) {
 
 		List fromElementList = selectClause.getFromElementsForLoad();
 
 		hasScalars = selectClause.isScalarSelect();
 		scalarColumnNames = selectClause.getColumnNames();
 		//sqlResultTypes = selectClause.getSqlResultTypes();
 		queryReturnTypes = selectClause.getQueryReturnTypes();
 
 		aggregatedSelectExpression = selectClause.getAggregatedSelectExpression();
 		queryReturnAliases = selectClause.getQueryReturnAliases();
 
 		List collectionFromElements = selectClause.getCollectionFromElements();
-		if ( collectionFromElements != null && collectionFromElements.size()!=0 ) {
+		if ( collectionFromElements != null && collectionFromElements.size() != 0 ) {
 			int length = collectionFromElements.size();
 			collectionPersisters = new QueryableCollection[length];
 			collectionOwners = new int[length];
 			collectionSuffixes = new String[length];
-			for ( int i=0; i<length; i++ ) {
-				FromElement collectionFromElement = (FromElement) collectionFromElements.get(i);
+			for ( int i = 0; i < length; i++ ) {
+				FromElement collectionFromElement = (FromElement) collectionFromElements.get( i );
 				collectionPersisters[i] = collectionFromElement.getQueryableCollection();
 				collectionOwners[i] = fromElementList.indexOf( collectionFromElement.getOrigin() );
 //				collectionSuffixes[i] = collectionFromElement.getColumnAliasSuffix();
 //				collectionSuffixes[i] = Integer.toString( i ) + "_";
 				collectionSuffixes[i] = collectionFromElement.getCollectionSuffix();
 			}
 		}
 
 		int size = fromElementList.size();
 		entityPersisters = new Queryable[size];
 		entityEagerPropertyFetches = new boolean[size];
 		entityAliases = new String[size];
 		sqlAliases = new String[size];
 		sqlAliasSuffixes = new String[size];
 		includeInSelect = new boolean[size];
 		owners = new int[size];
 		ownerAssociationTypes = new EntityType[size];
 
 		for ( int i = 0; i < size; i++ ) {
-			final FromElement element = ( FromElement ) fromElementList.get( i );
-			entityPersisters[i] = ( Queryable ) element.getEntityPersister();
+			final FromElement element = (FromElement) fromElementList.get( i );
+			entityPersisters[i] = (Queryable) element.getEntityPersister();
 
 			if ( entityPersisters[i] == null ) {
 				throw new IllegalStateException( "No entity persister for " + element.toString() );
 			}
 
 			entityEagerPropertyFetches[i] = element.isAllPropertyFetch();
 			sqlAliases[i] = element.getTableAlias();
 			entityAliases[i] = element.getClassAlias();
 			sqlAliasByEntityAlias.put( entityAliases[i], sqlAliases[i] );
 			// TODO should we just collect these like with the collections above?
 			sqlAliasSuffixes[i] = ( size == 1 ) ? "" : Integer.toString( i ) + "_";
 //			sqlAliasSuffixes[i] = element.getColumnAliasSuffix();
 			includeInSelect[i] = !element.isFetch();
 			if ( includeInSelect[i] ) {
 				selectLength++;
 			}
 
 			owners[i] = -1; //by default
 			if ( element.isFetch() ) {
 				if ( element.isCollectionJoin() || element.getQueryableCollection() != null ) {
 					// This is now handled earlier in this method.
 				}
 				else if ( element.getDataType().isEntityType() ) {
-					EntityType entityType = ( EntityType ) element.getDataType();
+					EntityType entityType = (EntityType) element.getDataType();
 					if ( entityType.isOneToOne() ) {
 						owners[i] = fromElementList.indexOf( element.getOrigin() );
 					}
 					ownerAssociationTypes[i] = entityType;
 				}
 			}
 		}
 
 		//NONE, because its the requested lock mode, not the actual! 
 		defaultLockModes = ArrayHelper.fillArray( LockMode.NONE, size );
 	}
 
 	public AggregatedSelectExpression getAggregatedSelectExpression() {
 		return aggregatedSelectExpression;
 	}
 
 
 	// -- Loader implementation --
 
 	public final void validateScrollability() throws HibernateException {
 		queryTranslator.validateScrollability();
 	}
+
 	@Override
 	protected boolean needsFetchingScroll() {
 		return queryTranslator.containsCollectionFetches();
 	}
+
 	@Override
 	public Loadable[] getEntityPersisters() {
 		return entityPersisters;
 	}
+
 	@Override
 	public String[] getAliases() {
 		return sqlAliases;
 	}
 
 	public String[] getSqlAliasSuffixes() {
 		return sqlAliasSuffixes;
 	}
+
 	@Override
 	public String[] getSuffixes() {
 		return getSqlAliasSuffixes();
 	}
+
 	@Override
 	public String[] getCollectionSuffixes() {
 		return collectionSuffixes;
 	}
+
 	@Override
 	protected String getQueryIdentifier() {
 		return queryTranslator.getQueryIdentifier();
 	}
 
 	/**
 	 * The SQL query string to be called.
 	 */
 	@Override
 	public String getSQLString() {
 		return queryTranslator.getSQLString();
 	}
 
 	/**
 	 * An (optional) persister for a collection to be initialized; only collection loaders
 	 * return a non-null value
 	 */
 	@Override
 	protected CollectionPersister[] getCollectionPersisters() {
 		return collectionPersisters;
 	}
+
 	@Override
 	protected int[] getCollectionOwners() {
 		return collectionOwners;
 	}
+
 	@Override
 	protected boolean[] getEntityEagerPropertyFetches() {
 		return entityEagerPropertyFetches;
 	}
 
 	/**
 	 * An array of indexes of the entity that owns a one-to-one association
 	 * to the entity at the given index (-1 if there is no "owner")
 	 */
 	@Override
 	protected int[] getOwners() {
 		return owners;
 	}
+
 	@Override
 	protected EntityType[] getOwnerAssociationTypes() {
 		return ownerAssociationTypes;
 	}
 
 	// -- Loader overrides --
 	@Override
 	protected boolean isSubselectLoadingEnabled() {
 		return hasSubselectLoadableCollections();
 	}
 
 	/**
 	 * @param lockOptions a collection of lock modes specified dynamically via the Query interface
 	 */
 	@Override
 	protected LockMode[] getLockModes(LockOptions lockOptions) {
 		if ( lockOptions == null ) {
 			return defaultLockModes;
 		}
 
 		if ( lockOptions.getAliasLockCount() == 0
 				&& ( lockOptions.getLockMode() == null || LockMode.NONE.equals( lockOptions.getLockMode() ) ) ) {
 			return defaultLockModes;
 		}
 
 		// unfortunately this stuff can't be cached because
 		// it is per-invocation, not constant for the
 		// QueryTranslator instance
 
 		LockMode[] lockModesArray = new LockMode[entityAliases.length];
 		for ( int i = 0; i < entityAliases.length; i++ ) {
 			LockMode lockMode = lockOptions.getEffectiveLockMode( entityAliases[i] );
 			if ( lockMode == null ) {
 				//NONE, because its the requested lock mode, not the actual!
 				lockMode = LockMode.NONE;
 			}
 			lockModesArray[i] = lockMode;
 		}
 
 		return lockModesArray;
 	}
 
 	@Override
 	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws QueryException {
 		// can't cache this stuff either (per-invocation)
 		// we are given a map of user-alias -> lock mode
 		// create a new map of sql-alias -> lock mode
 
 		final LockOptions lockOptions = parameters.getLockOptions();
 
 		if ( lockOptions == null ||
-			( lockOptions.getLockMode() == LockMode.NONE && lockOptions.getAliasLockCount() == 0 ) ) {
+				( lockOptions.getLockMode() == LockMode.NONE && lockOptions.getAliasLockCount() == 0 ) ) {
 			return sql;
 		}
 
 
 		// user is request locking, lets see if we can apply locking directly to the SQL...
 
 		// 		some dialects wont allow locking with paging...
 		if ( shouldUseFollowOnLocking( parameters, dialect, afterLoadActions ) ) {
 			return sql;
 		}
 
 		//		there are other conditions we might want to add here, such as checking the result types etc
 		//		but those are better served after we have redone the SQL generation to use ASTs.
 
 
 		// we need both the set of locks and the columns to reference in locks
 		// as the ultimate output of this section...
 		final LockOptions locks = new LockOptions( lockOptions.getLockMode() );
-		final Map<String, String[]> keyColumnNames = dialect.forUpdateOfColumns() ? new HashMap<String, String[]>() : null;
+		final Map<String, String[]> keyColumnNames = dialect.forUpdateOfColumns() ?
+				new HashMap<String, String[]>() :
+				null;
 
 		locks.setScope( lockOptions.getScope() );
 		locks.setTimeOut( lockOptions.getTimeOut() );
 
 		for ( Map.Entry<String, String> entry : sqlAliasByEntityAlias.entrySet() ) {
-			final String userAlias =  entry.getKey();
+			final String userAlias = entry.getKey();
 			final String drivingSqlAlias = entry.getValue();
 			if ( drivingSqlAlias == null ) {
 				throw new IllegalArgumentException( "could not locate alias to apply lock mode : " + userAlias );
 			}
 			// at this point we have (drivingSqlAlias) the SQL alias of the driving table
 			// corresponding to the given user alias.  However, the driving table is not
 			// (necessarily) the table against which we want to apply locks.  Mainly,
 			// the exception case here is joined-subclass hierarchies where we instead
 			// want to apply the lock against the root table (for all other strategies,
 			// it just happens that driving and root are the same).
 			final QueryNode select = (QueryNode) queryTranslator.getSqlAST();
 			final Lockable drivingPersister = (Lockable) select.getFromClause()
 					.findFromElementByUserOrSqlAlias( userAlias, drivingSqlAlias )
 					.getQueryable();
 			final String sqlAlias = drivingPersister.getRootTableAlias( drivingSqlAlias );
 
 			final LockMode effectiveLockMode = lockOptions.getEffectiveLockMode( userAlias );
 			locks.setAliasSpecificLockMode( sqlAlias, effectiveLockMode );
 
 			if ( keyColumnNames != null ) {
 				keyColumnNames.put( sqlAlias, drivingPersister.getRootTableIdentifierColumnNames() );
 			}
 		}
 
 		// apply the collected locks and columns
 		return dialect.applyLocksToSql( sql, locks, keyColumnNames );
 	}
+
 	@Override
 	protected void applyPostLoadLocks(Object[] row, LockMode[] lockModesArray, SessionImplementor session) {
 		// todo : scalars???
 //		if ( row.length != lockModesArray.length ) {
 //			return;
 //		}
 //
 //		for ( int i = 0; i < lockModesArray.length; i++ ) {
 //			if ( LockMode.OPTIMISTIC_FORCE_INCREMENT.equals( lockModesArray[i] ) ) {
 //				final EntityEntry pcEntry =
 //			}
 //			else if ( LockMode.PESSIMISTIC_FORCE_INCREMENT.equals( lockModesArray[i] ) ) {
 //
 //			}
 //		}
 	}
+
 	@Override
 	protected boolean upgradeLocks() {
 		return true;
 	}
 
 	private boolean hasSelectNew() {
-		return aggregatedSelectExpression != null &&  aggregatedSelectExpression.getResultTransformer() != null;
+		return aggregatedSelectExpression != null && aggregatedSelectExpression.getResultTransformer() != null;
 	}
+
 	@Override
 	protected String[] getResultRowAliases() {
 		return queryReturnAliases;
 	}
+
 	@Override
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		final ResultTransformer implicitResultTransformer = aggregatedSelectExpression == null
 				? null
 				: aggregatedSelectExpression.getResultTransformer();
 		return HolderInstantiator.resolveResultTransformer( implicitResultTransformer, resultTransformer );
 	}
+
 	@Override
 	protected boolean[] includeInResultRow() {
 		boolean[] includeInResultTuple = includeInSelect;
 		if ( hasScalars ) {
-			includeInResultTuple = new boolean[ queryReturnTypes.length ];
+			includeInResultTuple = new boolean[queryReturnTypes.length];
 			Arrays.fill( includeInResultTuple, true );
 		}
 		return includeInResultTuple;
 	}
+
 	@Override
-	protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
+	protected Object getResultColumnOrRow(
+			Object[] row,
+			ResultTransformer transformer,
+			ResultSet rs,
+			SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		Object[] resultRow = getResultRow( row, rs, session );
-		boolean hasTransform = hasSelectNew() || transformer!=null;
-		return ( ! hasTransform && resultRow.length == 1 ?
-				resultRow[ 0 ] :
+		boolean hasTransform = hasSelectNew() || transformer != null;
+		return ( !hasTransform && resultRow.length == 1 ?
+				resultRow[0] :
 				resultRow
 		);
 	}
 
 	@Override
 	protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow;
 		if ( hasScalars ) {
 			String[][] scalarColumns = scalarColumnNames;
 			int queryCols = queryReturnTypes.length;
 			resultRow = new Object[queryCols];
 			for ( int i = 0; i < queryCols; i++ ) {
 				resultRow[i] = queryReturnTypes[i].nullSafeGet( rs, scalarColumns[i], session, null );
 			}
 		}
 		else {
 			resultRow = toResultRow( row );
 		}
 		return resultRow;
 	}
 
 	@SuppressWarnings("unchecked")
 	@Override
 	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		// meant to handle dynamic instantiation queries...
 		HolderInstantiator holderInstantiator = buildHolderInstantiator( resultTransformer );
 		if ( holderInstantiator.isRequired() ) {
 			for ( int i = 0; i < results.size(); i++ ) {
-				Object[] row = ( Object[] ) results.get( i );
-				Object result = holderInstantiator.instantiate(row);
+				Object[] row = (Object[]) results.get( i );
+				Object result = holderInstantiator.instantiate( row );
 				results.set( i, result );
 			}
 
 			if ( !hasSelectNew() && resultTransformer != null ) {
-				return resultTransformer.transformList(results);
+				return resultTransformer.transformList( results );
 			}
 			else {
 				return results;
 			}
 		}
 		else {
 			return results;
 		}
 	}
 
 	private HolderInstantiator buildHolderInstantiator(ResultTransformer queryLocalResultTransformer) {
 		final ResultTransformer implicitResultTransformer = aggregatedSelectExpression == null
 				? null
 				: aggregatedSelectExpression.getResultTransformer();
 		return HolderInstantiator.getHolderInstantiator(
 				implicitResultTransformer,
 				queryLocalResultTransformer,
 				queryReturnAliases
 		);
 	}
 	// --- Query translator methods ---
 
 	public List list(
 			SessionImplementor session,
 			QueryParameters queryParameters) throws HibernateException {
 		checkQuery( queryParameters );
 		return list( session, queryParameters, queryTranslator.getQuerySpaces(), queryReturnTypes );
 	}
 
 	private void checkQuery(QueryParameters queryParameters) {
 		if ( hasSelectNew() && queryParameters.getResultTransformer() != null ) {
 			throw new QueryException( "ResultTransformer is not allowed for 'select new' queries." );
 		}
 	}
 
 	public Iterator iterate(
 			QueryParameters queryParameters,
 			EventSource session) throws HibernateException {
 		checkQuery( queryParameters );
 		final boolean stats = session.getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) {
 			startTime = System.nanoTime();
 		}
 
 		try {
 			if ( queryParameters.isCallable() ) {
-				throw new QueryException("iterate() not supported for callable statements");
+				throw new QueryException( "iterate() not supported for callable statements" );
 			}
-			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, Collections.<AfterLoadAction>emptyList(), session );
+			final SqlStatementWrapper wrapper = executeQueryStatement(
+					queryParameters,
+					false,
+					Collections.<AfterLoadAction>emptyList(),
+					session
+			);
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
 			final Iterator result = new IteratorImpl(
 					rs,
-			        st,
-			        session,
-			        queryParameters.isReadOnly( session ),
-			        queryReturnTypes,
-			        queryTranslator.getColumnNames(),
-			        buildHolderInstantiator( queryParameters.getResultTransformer() )
+					st,
+					session,
+					queryParameters.isReadOnly( session ),
+					queryReturnTypes,
+					queryTranslator.getColumnNames(),
+					buildHolderInstantiator( queryParameters.getResultTransformer() )
 			);
 
 			if ( stats ) {
 				final long endTime = System.nanoTime();
 				final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 				session.getFactory().getStatisticsImplementor().queryExecuted(
 //						"HQL: " + queryTranslator.getQueryString(),
 						getQueryIdentifier(),
 						0,
 						milliseconds
 				);
 			}
 
 			return result;
 
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw getFactory().getSQLExceptionHelper().convert(
-			        sqle,
-			        "could not execute query using iterate",
-			        getSQLString()
-				);
+					sqle,
+					"could not execute query using iterate",
+					getSQLString()
+			);
 		}
 
 	}
 
 	public ScrollableResults scroll(
 			final QueryParameters queryParameters,
-	        final SessionImplementor session) throws HibernateException {
+			final SessionImplementor session) throws HibernateException {
 		checkQuery( queryParameters );
-		return scroll( 
+		return scroll(
 				queryParameters,
 				queryReturnTypes,
 				buildHolderInstantiator( queryParameters.getResultTransformer() ),
 				session
 		);
 	}
 
 	// -- Implementation private methods --
 
 	private Object[] toResultRow(Object[] row) {
 		if ( selectLength == row.length ) {
 			return row;
 		}
 		else {
 			Object[] result = new Object[selectLength];
 			int j = 0;
 			for ( int i = 0; i < row.length; i++ ) {
 				if ( includeInSelect[i] ) {
 					result[j++] = row[i];
 				}
 			}
 			return result;
 		}
 	}
 
 	/**
 	 * Returns the locations of all occurrences of the named parameter.
 	 */
 	@Override
 	public int[] getNamedParameterLocs(String name) throws QueryException {
 		return queryTranslator.getParameterTranslations().getNamedParameterSqlLocations( name );
 	}
 
 	/**
 	 * We specifically override this method here, because in general we know much more
 	 * about the parameters and their appropriate bind positions here then we do in
 	 * our super because we track them explicitly here through the ParameterSpecification
 	 * interface.
 	 *
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
+	 *
 	 * @return The number of JDBC bind positions actually bound during this method execution.
+	 *
 	 * @throws SQLException Indicates problems performing the binding.
 	 */
 	@Override
 	protected int bindParameterValues(
 			final PreparedStatement statement,
 			final QueryParameters queryParameters,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException {
 		int position = startIndex;
 		List<ParameterSpecification> parameterSpecs = queryTranslator.getCollectedParameterSpecifications();
 		for ( ParameterSpecification spec : parameterSpecs ) {
 			position += spec.bind( statement, queryParameters, session, position );
 		}
 		return position - startIndex;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/AbstractEntityGraphVisitationStrategy.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/AbstractEntityGraphVisitationStrategy.java
index ae99610819..034901bdcc 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/AbstractEntityGraphVisitationStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/AbstractEntityGraphVisitationStrategy.java
@@ -1,362 +1,359 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc..
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.plan.build.internal;
 
 import java.util.ArrayDeque;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-
 import javax.persistence.AttributeNode;
 import javax.persistence.Subgraph;
 import javax.persistence.metamodel.Attribute;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.graph.spi.AttributeNodeImplementor;
 import org.hibernate.graph.spi.GraphNodeImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.loader.plan.spi.EntityReturn;
-import org.hibernate.loader.plan.spi.FetchSource;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.Return;
-import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
-import org.hibernate.persister.walking.spi.AssociationKey;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.CollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CollectionIndexDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.persister.walking.spi.WalkingException;
+
 import org.jboss.logging.Logger;
 
 /**
  * Abstract strategy of building loadplan based on entity graph.
  *
  * The problem we're resolving here is, we have TWO trees to walk (only entity loading here):
  * <ul>
  * <ol>entity metadata and its associations</ol>
  * <ol>entity graph and attribute nodes</ol>
  * </ul>
  *
  * And most time, the entity graph tree is partial of entity metadata tree.
  *
  * So, the idea here is, we walk the entity metadata tree, just as how we build the static loadplan from mappings,
  * and we try to match the node to entity graph ( and subgraph ), if there is a match, then the attribute is fetched,
  * it is not, then depends on which property is used to apply this entity graph.
  *
  * @author Strong Liu <stliu@hibernate.org>
  * @author Brett Meyer
  */
 public abstract class AbstractEntityGraphVisitationStrategy
 		extends AbstractLoadPlanBuildingAssociationVisitationStrategy {
 	private static final Logger LOG = CoreLogging.logger( AbstractEntityGraphVisitationStrategy.class );
 	/**
 	 * The JPA 2.1 SPEC's Entity Graph only defines _WHEN_ to load an attribute, it doesn't define _HOW_ to load it
 	 * So I'm here just making an assumption that when it is EAGER, then we use JOIN, and when it is LAZY, then we use SELECT.
 	 *
 	 * NOTE: this may be changed in the near further, though ATM I have no idea how this will be changed to :)
 	 * -- stliu
 	 */
 	protected static final FetchStrategy DEFAULT_EAGER = new FetchStrategy( FetchTiming.IMMEDIATE, FetchStyle.JOIN );
 	protected static final FetchStrategy DEFAULT_LAZY = new FetchStrategy( FetchTiming.DELAYED, FetchStyle.SELECT );
 	protected final LoadQueryInfluencers loadQueryInfluencers;
 	// Queue containing entity/sub graphs to be visited.
 	private final ArrayDeque<GraphNodeImplementor> graphStack = new ArrayDeque<GraphNodeImplementor>();
 	// Queue containing attributes being visited, used eventually to determine the fetch strategy.
 	private final ArrayDeque<AttributeNodeImplementor> attributeStack = new ArrayDeque<AttributeNodeImplementor>();
 	// Queue of maps containing the current graph node's attributes.  Used for fast lookup, instead of iterating
 	// over graphStack.peekLast().attributeImplementorNodes().
 	private final ArrayDeque<Map<String, AttributeNodeImplementor>> attributeMapStack
 			= new ArrayDeque<Map<String, AttributeNodeImplementor>>();
 	private EntityReturn rootEntityReturn;
 	private final LockMode lockMode;
 
 	protected AbstractEntityGraphVisitationStrategy(
 			final SessionFactoryImplementor sessionFactory, final LoadQueryInfluencers loadQueryInfluencers,
 			final LockMode lockMode) {
 		super( sessionFactory );
 		this.loadQueryInfluencers = loadQueryInfluencers;
 		this.lockMode = lockMode;
 	}
 
 	@Override
 	public void start() {
 		super.start();
 		graphStack.addLast( getRootEntityGraph() );
 	}
 
 	@Override
 	public void finish() {
 		super.finish();
 		graphStack.removeLast();
 		//applying a little internal stack checking
 		if ( !graphStack.isEmpty() || !attributeStack.isEmpty() || !attributeMapStack.isEmpty() ) {
 			throw new WalkingException( "Internal stack error" );
 		}
 	}
 
 	@Override
 	public void startingEntity(final EntityDefinition entityDefinition) {
 		attributeMapStack.addLast( buildAttributeNodeMap() );
 		super.startingEntity( entityDefinition );
 	}
 
 	/**
 	 * Build "name" -- "attribute node" map from the current entity graph we're visiting.
 	 */
 	protected Map<String, AttributeNodeImplementor> buildAttributeNodeMap() {
 		GraphNodeImplementor graphNode = graphStack.peekLast();
 		List<AttributeNodeImplementor<?>> attributeNodeImplementors = graphNode.attributeImplementorNodes();
 		Map<String, AttributeNodeImplementor> attributeNodeImplementorMap = attributeNodeImplementors.isEmpty() ? Collections
 				.<String, AttributeNodeImplementor>emptyMap() : new HashMap<String, AttributeNodeImplementor>(
 				attributeNodeImplementors.size()
 		);
 		for ( AttributeNodeImplementor attribute : attributeNodeImplementors ) {
 			attributeNodeImplementorMap.put( attribute.getAttributeName(), attribute );
 		}
 		return attributeNodeImplementorMap;
 	}
 
 	@Override
 	public void finishingEntity(final EntityDefinition entityDefinition) {
 		attributeMapStack.removeLast();
 		super.finishingEntity( entityDefinition );
 	}
 
 	/**
 	 * I'm using NULL-OBJECT pattern here, for attributes that not existing in the EntityGraph,
 	 * a predefined NULL-ATTRIBUTE-NODE is pushed to the stack.
 	 *
 	 * and for an not existing sub graph, a predefined NULL-SUBGRAPH is pushed to the stack.
 	 *
 	 * So, whenever we're start visiting an attribute, there will be a attribute node pushed to the attribute stack,
 	 * and a subgraph node pushed to the graph stack.
 	 *
 	 * when we're finish visiting an attribute, these two will be poped from each stack.
 	 */
 	@Override
 	public boolean startingAttribute(AttributeDefinition attributeDefinition) {
 		Map<String, AttributeNodeImplementor> attributeMap = attributeMapStack.peekLast();
 		final String attrName = attributeDefinition.getName();
 		AttributeNodeImplementor attributeNode = NON_EXIST_ATTRIBUTE_NODE;
 		GraphNodeImplementor subGraphNode = NON_EXIST_SUBGRAPH_NODE;
 		//the attribute is in the EntityGraph, so, let's continue
 		if ( attributeMap.containsKey( attrName ) ) {
 			attributeNode = attributeMap.get( attrName );
 			//here we need to check if there is a subgraph (or sub key graph if it is an indexed attribute )
 			Map<Class, Subgraph> subGraphs = attributeNode.getSubgraphs();
 			Class javaType = attributeDefinition.getType().getReturnedClass();
 			if ( !subGraphs.isEmpty() && subGraphs.containsKey( javaType ) ) {
 				subGraphNode = (GraphNodeImplementor) subGraphs.get( javaType );
 			}
 
 		}
 		attributeStack.addLast( attributeNode );
 		graphStack.addLast( subGraphNode );
 		return super.startingAttribute( attributeDefinition );
 	}
 
 
 	@Override
 	public void finishingAttribute(final AttributeDefinition attributeDefinition) {
 		attributeStack.removeLast();
 		graphStack.removeLast();
 		super.finishingAttribute( attributeDefinition );
 	}
 
 
 	@Override
 	public void startingCollectionElements(
 			final CollectionElementDefinition elementDefinition) {
 		AttributeNodeImplementor attributeNode = attributeStack.peekLast();
 		GraphNodeImplementor subGraphNode = NON_EXIST_SUBGRAPH_NODE;
 		Map<Class, Subgraph> subGraphs = attributeNode.getSubgraphs();
 		Class javaType = elementDefinition.getType().getReturnedClass();
 		if ( !subGraphs.isEmpty() && subGraphs.containsKey( javaType ) ) {
 			subGraphNode = (GraphNodeImplementor) subGraphs.get( javaType );
 		}
 		graphStack.addLast( subGraphNode );
 		super.startingCollectionElements( elementDefinition );
 	}
 
 	@Override
 	public void finishingCollectionElements(
 			final CollectionElementDefinition elementDefinition) {
 		super.finishingCollectionElements( elementDefinition );
 		graphStack.removeLast();
 	}
 
 
 	@Override
 	public void startingCollectionIndex(final CollectionIndexDefinition indexDefinition) {
 		AttributeNodeImplementor attributeNode = attributeStack.peekLast();
 		GraphNodeImplementor subGraphNode = NON_EXIST_SUBGRAPH_NODE;
 		Map<Class, Subgraph> subGraphs = attributeNode.getKeySubgraphs();
 		Class javaType = indexDefinition.getType().getReturnedClass();
 		if ( !subGraphs.isEmpty() && subGraphs.containsKey( javaType ) ) {
 			subGraphNode = (GraphNodeImplementor) subGraphs.get( javaType );
 		}
 		graphStack.addLast( subGraphNode );
 		super.startingCollectionIndex( indexDefinition );
 	}
 
 	@Override
 	public void finishingCollectionIndex(final CollectionIndexDefinition indexDefinition) {
 		super.finishingCollectionIndex( indexDefinition );
 		graphStack.removeLast();
 	}
 
 
 	@Override
 	protected boolean supportsRootCollectionReturns() {
 		return false; //entity graph doesn't support root collection.
 	}
 
 
 	@Override
 	protected void addRootReturn(final Return rootReturn) {
 		if ( this.rootEntityReturn != null ) {
 			throw new HibernateException( "Root return already identified" );
 		}
 		if ( !( rootReturn instanceof EntityReturn ) ) {
 			throw new HibernateException( "Load entity graph only supports EntityReturn" );
 		}
 		this.rootEntityReturn = (EntityReturn) rootReturn;
 	}
 
 	@Override
 	protected FetchStrategy determineFetchStrategy(
 			final AssociationAttributeDefinition attributeDefinition) {
 		return attributeStack.peekLast() != NON_EXIST_ATTRIBUTE_NODE ? DEFAULT_EAGER : resolveImplicitFetchStrategyFromEntityGraph(
 				attributeDefinition
 		);
 	}
 
 	protected abstract FetchStrategy resolveImplicitFetchStrategyFromEntityGraph(
 			final AssociationAttributeDefinition attributeDefinition);
 
 	protected FetchStrategy adjustJoinFetchIfNeeded(
 			AssociationAttributeDefinition attributeDefinition, FetchStrategy fetchStrategy) {
 		if ( lockMode.greaterThan( LockMode.READ ) ) {
 			return new FetchStrategy( fetchStrategy.getTiming(), FetchStyle.SELECT );
 		}
 
 		final Integer maxFetchDepth = sessionFactory().getSettings().getMaximumFetchDepth();
 		if ( maxFetchDepth != null && currentDepth() > maxFetchDepth ) {
 			return new FetchStrategy( fetchStrategy.getTiming(), FetchStyle.SELECT );
 		}
 
 		if ( attributeDefinition.getType().isCollectionType() && isTooManyCollections() ) {
 			// todo : have this revert to batch or subselect fetching once "sql gen redesign" is in place
 			return new FetchStrategy( fetchStrategy.getTiming(), FetchStyle.SELECT );
 		}
 
 		return fetchStrategy;
 	}
 
 
 	@Override
 	public LoadPlan buildLoadPlan() {
 		LOG.debug( "Building LoadPlan..." );
 		return new LoadPlanImpl( rootEntityReturn, getQuerySpaces() );
 	}
 
 	abstract protected GraphNodeImplementor getRootEntityGraph();
 
 	private static final AttributeNodeImplementor NON_EXIST_ATTRIBUTE_NODE = new AttributeNodeImplementor() {
 		@Override
 		public Attribute getAttribute() {
 			return null;
 		}
 
 		@Override
 		public AttributeNodeImplementor makeImmutableCopy() {
 			return this;
 		}
 
 		@Override
 		public String getAttributeName() {
 			return null;
 		}
 
 		@Override
 		public Map<Class, Subgraph> getSubgraphs() {
 			return Collections.emptyMap();
 		}
 
 		@Override
 		public Map<Class, Subgraph> getKeySubgraphs() {
 			return Collections.emptyMap();
 		}
 
 		@Override
 		public String toString() {
 			return "Mocked NON-EXIST attribute node";
 		}
 	};
 	private static final GraphNodeImplementor NON_EXIST_SUBGRAPH_NODE = new GraphNodeImplementor() {
 		@Override
 		public List<AttributeNodeImplementor<?>> attributeImplementorNodes() {
 			return Collections.emptyList();
 		}
 
 		@Override
 		public List<AttributeNode<?>> attributeNodes() {
 			return Collections.emptyList();
 		}
 		
 		@Override
 		public boolean containsAttribute(String name) {
 			return false;
 		}
 	};
 
 	@Override
 	public void foundCircularAssociation(AssociationAttributeDefinition attributeDefinition) {
 		final FetchStrategy fetchStrategy = determineFetchStrategy( attributeDefinition );
 		if ( fetchStrategy.getStyle() != FetchStyle.JOIN ) {
 			return; // nothing to do
 		}
 
 		// Bi-directional association & the owning side was already visited.  If the current attribute node refers
 		// to it, fetch.
 		// ENTITY nature handled by super.
 		final GraphNodeImplementor graphNode = graphStack.peekLast();
 		if ( attributeDefinition.getAssociationNature() == AssociationAttributeDefinition.AssociationNature.COLLECTION
 				&& ! graphNode.equals( NON_EXIST_SUBGRAPH_NODE)
 				&& graphNode.containsAttribute( attributeDefinition.getName() )) {
 			currentSource().buildCollectionAttributeFetch( attributeDefinition, fetchStrategy );
 		}
 		
 		super.foundCircularAssociation( attributeDefinition );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/FetchStyleLoadPlanBuildingAssociationVisitationStrategy.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/FetchStyleLoadPlanBuildingAssociationVisitationStrategy.java
index f93f8a6467..07a374d4cb 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/FetchStyleLoadPlanBuildingAssociationVisitationStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/FetchStyleLoadPlanBuildingAssociationVisitationStrategy.java
@@ -1,149 +1,148 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.internal;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreLogging;
-import org.hibernate.loader.plan.build.spi.LoadPlanBuildingAssociationVisitationStrategy;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 
 import org.jboss.logging.Logger;
 
 /**
- * {@link LoadPlanBuildingAssociationVisitationStrategy} implementation used for building LoadPlans based on metamodel-defined fetching.  Built
+ * LoadPlanBuildingAssociationVisitationStrategy implementation used for building LoadPlans based on metamodel-defined fetching.  Built
  * LoadPlans contain a single root return object, either an {@link EntityReturn} or a {@link CollectionReturn}.
  *
  * @author Steve Ebersole
  */
 public class FetchStyleLoadPlanBuildingAssociationVisitationStrategy
 		extends AbstractLoadPlanBuildingAssociationVisitationStrategy {
 	private static final Logger log = CoreLogging.logger( FetchStyleLoadPlanBuildingAssociationVisitationStrategy.class );
 
 	private final LoadQueryInfluencers loadQueryInfluencers;
 	private final LockMode lockMode;
 
 	private Return rootReturn;
 
 	/**
 	 * Constructs a FetchStyleLoadPlanBuildingAssociationVisitationStrategy.
 	 *
 	 * @param sessionFactory The session factory
 	 * @param loadQueryInfluencers The options which can influence the SQL query needed to perform the load.
 	 * @param lockMode The lock mode.
 	 */
 	public FetchStyleLoadPlanBuildingAssociationVisitationStrategy(
 			SessionFactoryImplementor sessionFactory,
 			LoadQueryInfluencers loadQueryInfluencers,
 			LockMode lockMode) {
 		super( sessionFactory );
 		this.loadQueryInfluencers = loadQueryInfluencers;
 		this.lockMode = lockMode;
 	}
 
 	@Override
 	protected boolean supportsRootEntityReturns() {
 		return true;
 	}
 
 	@Override
 	protected boolean supportsRootCollectionReturns() {
 		return true;
 	}
 
 	@Override
 	protected void addRootReturn(Return rootReturn) {
 		if ( this.rootReturn != null ) {
 			throw new HibernateException( "Root return already identified" );
 		}
 		this.rootReturn = rootReturn;
 	}
 
 	@Override
 	public LoadPlan buildLoadPlan() {
 		log.debug( "Building LoadPlan..." );
 
 		if ( EntityReturn.class.isInstance( rootReturn ) ) {
 			return new LoadPlanImpl( (EntityReturn) rootReturn, getQuerySpaces() );
 		}
 		else if ( CollectionReturn.class.isInstance( rootReturn ) ) {
 			return new LoadPlanImpl( (CollectionReturn) rootReturn, getQuerySpaces() );
 		}
 		else {
 			throw new IllegalStateException( "Unexpected root Return type : " + rootReturn );
 		}
 	}
 
 	@Override
 	protected FetchStrategy determineFetchStrategy(AssociationAttributeDefinition attributeDefinition) {
 		FetchStrategy fetchStrategy = attributeDefinition.determineFetchPlan( loadQueryInfluencers, currentPropertyPath );
 		if ( fetchStrategy.getTiming() == FetchTiming.IMMEDIATE && fetchStrategy.getStyle() == FetchStyle.JOIN ) {
 			// see if we need to alter the join fetch to another form for any reason
 			fetchStrategy = adjustJoinFetchIfNeeded( attributeDefinition, fetchStrategy );
 		}
 		return fetchStrategy;
 	}
 
 	/**
 	 * If required by this strategy, returns a different {@link FetchStrategy} from what is specified
 	 * for the given association attribute.
 	 *
 	 * @param attributeDefinition The association attribute definition.
 	 * @param fetchStrategy The fetch strategy for <code>attributeDefinition</code>.
 	 * @return the {@link FetchStrategy}, possibly adjusted by this strategy.
 	 */
 	protected FetchStrategy adjustJoinFetchIfNeeded(
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy) {
 		if ( lockMode.greaterThan( LockMode.READ ) ) {
 			return new FetchStrategy( fetchStrategy.getTiming(), FetchStyle.SELECT );
 		}
 
-		final Integer maxFetchDepth = sessionFactory().getSettings().getMaximumFetchDepth();
+		final Integer maxFetchDepth = sessionFactory().getSessionFactoryOptions().getMaximumFetchDepth();
 		if ( maxFetchDepth != null && currentDepth() > maxFetchDepth ) {
 			return new FetchStrategy( fetchStrategy.getTiming(), FetchStyle.SELECT );
 		}
 
 		if ( attributeDefinition.getType().isCollectionType() && isTooManyCollections() ) {
 			// todo : have this revert to batch or subselect fetching once "sql gen redesign" is in place
 			return new FetchStrategy( fetchStrategy.getTiming(), FetchStyle.SELECT );
 		}
 
 		return fetchStrategy;
 	}
 
 	@Override
 	protected boolean isTooManyCollections() {
 		return CollectionReturn.class.isInstance( rootReturn );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/LoadPlanImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/LoadPlanImpl.java
index 7b36b72a01..726c466aaa 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/LoadPlanImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/LoadPlanImpl.java
@@ -1,127 +1,121 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.internal;
 
 import java.util.Collections;
 import java.util.List;
 
-import org.hibernate.internal.CoreLogging;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.QuerySpace;
 import org.hibernate.loader.plan.spi.QuerySpaces;
 import org.hibernate.loader.plan.spi.Return;
 
-import org.jboss.logging.Logger;
-
 /**
  * @author Steve Ebersole
  */
 public class LoadPlanImpl implements LoadPlan {
-	private static final Logger log = CoreLogging.logger( LoadPlanImpl.class );
-
 	private final List<? extends Return> returns;
 	private final QuerySpaces querySpaces;
 	private final Disposition disposition;
 	private final boolean areLazyAttributesForceFetched;
 
 	protected LoadPlanImpl(
 			List<? extends Return> returns,
 			QuerySpaces querySpaces,
 			Disposition disposition,
 			boolean areLazyAttributesForceFetched) {
 		this.returns = returns;
 		this.querySpaces = querySpaces;
 		this.disposition = disposition;
 		this.areLazyAttributesForceFetched = areLazyAttributesForceFetched;
 	}
 
 	/**
 	 * Creates a {@link Disposition#ENTITY_LOADER} LoadPlan.
 	 *
 	 * @param rootReturn The EntityReturn representation of the entity being loaded.
-	 * @param querySpaces The QuerySpaces containing all the {@link QuerySpace} references
+	 * @param querySpaces The QuerySpaces containing all the query space references
 	 *                    required for <code>rootReturn</code> and joined entity, collection,
 	 *                    and composite references.
 	 */
 	public LoadPlanImpl(EntityReturn rootReturn, QuerySpaces querySpaces) {
 		this( Collections.singletonList( rootReturn ), querySpaces, Disposition.ENTITY_LOADER, false );
 	}
 
 	/**
 	 * Creates a {@link Disposition#COLLECTION_INITIALIZER} LoadPlan.
 	 *
 	 * @param rootReturn The CollectionReturn representation of the collection being initialized.
-	 * @param querySpaces The QuerySpaces containing all the {@link QuerySpace} references
+	 * @param querySpaces The QuerySpaces containing all the query space references
 	 *                    required for <code>rootReturn</code> and joined entity, collection,
 	 *                    and composite references.
 	 */
 	public LoadPlanImpl(CollectionReturn rootReturn, QuerySpaces querySpaces) {
 		this( Collections.singletonList( rootReturn ), querySpaces, Disposition.COLLECTION_INITIALIZER, false );
 	}
 
 	/**
 	 * Creates a {@link Disposition#MIXED} LoadPlan.
 	 *
 	 * @param returns The mixed Return references
-	 * @param querySpaces The QuerySpaces containing all the {@link QuerySpace} references
+	 * @param querySpaces The QuerySpaces containing all the query space references
 	 *                    required for <code>rootReturn</code> and joined entity, collection,
 	 *                    and composite references.
 	 * @param areLazyAttributesForceFetched Should lazy attributes (bytecode enhanced laziness) be fetched also?  This
 	 * effects the eventual SQL SELECT-clause which is why we have it here.  Currently this is "all-or-none"; you
 	 * can request that all lazy properties across all entities in the loadplan be force fetched or none.  There is
 	 * no entity-by-entity option.  {@code FETCH ALL PROPERTIES} is the way this is requested in HQL.  Would be nice to
 	 * consider this entity-by-entity, as opposed to all-or-none.  For example, "fetch the LOB value for the Item.image
 	 * attribute, but no others (leave them lazy)".  Not too concerned about having it at the attribute level.
 	 */
 	public LoadPlanImpl(List<? extends Return> returns, QuerySpaces querySpaces, boolean areLazyAttributesForceFetched) {
 		this( returns, querySpaces, Disposition.MIXED, areLazyAttributesForceFetched );
 	}
 
 	@Override
 	public List<? extends Return> getReturns() {
 		return returns;
 	}
 
 	@Override
 	public QuerySpaces getQuerySpaces() {
 		return querySpaces;
 	}
 
 	@Override
 	public Disposition getDisposition() {
 		return disposition;
 	}
 
 	@Override
 	public boolean areLazyAttributesForceFetched() {
 		return areLazyAttributesForceFetched;
 	}
 
 	@Override
 	public boolean hasAnyScalarReturns() {
 		return disposition == Disposition.MIXED;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpaceHelper.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpaceHelper.java
index 2df29ae426..502953a08f 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpaceHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpaceHelper.java
@@ -1,213 +1,214 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.internal.spaces;
 
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.loader.plan.build.spi.ExpandingCollectionQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingCompositeQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingEntityQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingQuerySpace;
 import org.hibernate.loader.plan.spi.JoinDefinedByMetadata;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.WalkingException;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 
 /**
  * @author Gail Badner
  */
 public class QuerySpaceHelper {
 	/**
 	 * Singleton access
 	 */
 	public static final QuerySpaceHelper INSTANCE = new QuerySpaceHelper();
 
 	private QuerySpaceHelper() {
 	}
 
 	public ExpandingEntityQuerySpace makeEntityQuerySpace(
 			ExpandingQuerySpace lhsQuerySpace,
 			AssociationAttributeDefinition attribute,
 			String querySpaceUid,
 			FetchStrategy fetchStrategy) {
 		final EntityType fetchedType = (EntityType) attribute.getType();
 		final EntityPersister fetchedPersister = attribute.toEntityDefinition().getEntityPersister();
 
 		if ( fetchedPersister == null ) {
 			throw new WalkingException(
 					String.format(
 							"Unable to locate EntityPersister [%s] for fetch [%s]",
 							fetchedType.getAssociatedEntityName(),
 							attribute.getName()
 					)
 			);
 		}
 		// TODO: Queryable.isMultiTable() may be more broad than it needs to be...
 		final boolean isMultiTable = Queryable.class.cast( fetchedPersister ).isMultiTable();
 		final boolean required = lhsQuerySpace.canJoinsBeRequired() && !isMultiTable && !attribute.isNullable();
 
 		return makeEntityQuerySpace(
 				lhsQuerySpace,
 				fetchedPersister,
 				attribute.getName(),
 				(EntityType) attribute.getType(),
 				querySpaceUid,
 				required,
 				shouldIncludeJoin( fetchStrategy )
 		);
 	}
 
 	public ExpandingEntityQuerySpace makeEntityQuerySpace(
 			ExpandingQuerySpace lhsQuerySpace,
 			EntityPersister fetchedPersister,
 			String attributeName,
 			EntityType attributeType,
 			String querySpaceUid,
 			boolean required,
 			boolean shouldIncludeJoin) {
 
 		final ExpandingEntityQuerySpace rhs = lhsQuerySpace.getExpandingQuerySpaces().makeEntityQuerySpace(
 				querySpaceUid,
 				fetchedPersister,
 				required
 		);
 
 		if ( shouldIncludeJoin ) {
 			final JoinDefinedByMetadata join = JoinHelper.INSTANCE.createEntityJoin(
 					lhsQuerySpace,
 					attributeName,
 					rhs,
 					required,
 					attributeType,
 					fetchedPersister.getFactory()
 			);
 			lhsQuerySpace.addJoin( join );
 		}
 
 		return rhs;
 	}
 
 	public ExpandingCompositeQuerySpace makeCompositeQuerySpace(
 			ExpandingQuerySpace lhsQuerySpace,
 			AttributeDefinition attributeDefinition,
 			String querySpaceUid,
 			boolean shouldIncludeJoin) {
 		final boolean required = lhsQuerySpace.canJoinsBeRequired() && !attributeDefinition.isNullable();
- 		return makeCompositeQuerySpace(
-				 lhsQuerySpace,
-				 new CompositePropertyMapping(
-						 (CompositeType) attributeDefinition.getType(),
-						 lhsQuerySpace.getPropertyMapping(),
-						 attributeDefinition.getName()
-				 ),
-				 attributeDefinition.getName(),
-				 (CompositeType) attributeDefinition.getType(),
-				 querySpaceUid,
-				 required,
-				 shouldIncludeJoin
-		 );
+		return makeCompositeQuerySpace(
+				lhsQuerySpace,
+				new CompositePropertyMapping(
+						(CompositeType) attributeDefinition.getType(),
+						lhsQuerySpace.getPropertyMapping(),
+						attributeDefinition.getName()
+				),
+				attributeDefinition.getName(),
+				(CompositeType) attributeDefinition.getType(),
+				querySpaceUid,
+				required,
+				shouldIncludeJoin
+		);
 	}
 
 	public ExpandingCompositeQuerySpace makeCompositeQuerySpace(
 			ExpandingQuerySpace lhsQuerySpace,
 			CompositePropertyMapping compositePropertyMapping,
 			String attributeName,
 			CompositeType attributeType,
 			String querySpaceUid,
 			boolean required,
 			boolean shouldIncludeJoin) {
 
 		final ExpandingCompositeQuerySpace rhs = lhsQuerySpace.getExpandingQuerySpaces().makeCompositeQuerySpace(
 				querySpaceUid,
 				compositePropertyMapping,
 				required
 		);
 
 		if ( shouldIncludeJoin ) {
 			final JoinDefinedByMetadata join = JoinHelper.INSTANCE.createCompositeJoin(
 					lhsQuerySpace,
 					attributeName,
 					rhs,
 					required,
 					attributeType
 			);
 			lhsQuerySpace.addJoin( join );
 		}
 
 		return rhs;
 	}
 
 	public ExpandingCollectionQuerySpace makeCollectionQuerySpace(
 			ExpandingQuerySpace lhsQuerySpace,
 			AssociationAttributeDefinition attributeDefinition,
 			String querySpaceUid,
 			FetchStrategy fetchStrategy) {
 
 		final CollectionType fetchedType = (CollectionType) attributeDefinition.getType();
-		final CollectionPersister fetchedPersister = attributeDefinition.toCollectionDefinition().getCollectionPersister();
+		final CollectionPersister fetchedPersister = attributeDefinition.toCollectionDefinition()
+				.getCollectionPersister();
 
 		if ( fetchedPersister == null ) {
 			throw new WalkingException(
 					String.format(
 							"Unable to locate CollectionPersister [%s] for fetch [%s]",
 							fetchedType.getRole(),
 							attributeDefinition.getName()
 					)
 			);
 		}
 
 		final boolean required = lhsQuerySpace.canJoinsBeRequired() && !attributeDefinition.isNullable();
 
 		final ExpandingCollectionQuerySpace rhs = lhsQuerySpace.getExpandingQuerySpaces().makeCollectionQuerySpace(
 				querySpaceUid,
 				fetchedPersister,
 				required
 		);
 
 		if ( shouldIncludeJoin( fetchStrategy ) ) {
 			final JoinDefinedByMetadata join = JoinHelper.INSTANCE.createCollectionJoin(
 					lhsQuerySpace,
 					attributeDefinition.getName(),
 					rhs,
 					required,
 					(CollectionType) attributeDefinition.getType(),
 					fetchedPersister.getFactory()
 			);
 			lhsQuerySpace.addJoin( join );
 		}
 
 		return rhs;
 	}
 
 	public boolean shouldIncludeJoin(FetchStrategy fetchStrategy) {
 		return fetchStrategy.getTiming() == FetchTiming.IMMEDIATE && fetchStrategy.getStyle() == FetchStyle.JOIN;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpacesImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpacesImpl.java
index e4a1c36a64..5a2ec0df8e 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpacesImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpacesImpl.java
@@ -1,203 +1,202 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.internal.spaces;
 
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.loader.plan.build.spi.ExpandingCollectionQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingCompositeQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingEntityQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingQuerySpaces;
 import org.hibernate.loader.plan.spi.QuerySpace;
 import org.hibernate.loader.plan.spi.QuerySpaceUidNotRegisteredException;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
-import org.hibernate.persister.entity.JoinedSubclassEntityPersister;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Steve Ebersole
  */
 public class QuerySpacesImpl implements ExpandingQuerySpaces {
 	private static final Logger log = CoreLogging.logger( QuerySpacesImpl.class );
 
 	private final SessionFactoryImplementor sessionFactory;
 	private final List<QuerySpace> roots = new ArrayList<QuerySpace>();
 	private final Map<String,QuerySpace> querySpaceByUid = new ConcurrentHashMap<String, QuerySpace>();
 
 	public QuerySpacesImpl(SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 	}
 
 
 	// QuerySpaces impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public List<QuerySpace> getRootQuerySpaces() {
 		return roots;
 	}
 
 	@Override
 	public QuerySpace findQuerySpaceByUid(String uid) {
 		return querySpaceByUid.get( uid );
 	}
 
 	@Override
 	public QuerySpace getQuerySpaceByUid(String uid) {
 		final QuerySpace space = findQuerySpaceByUid( uid );
 		if ( space == null ) {
 			throw new QuerySpaceUidNotRegisteredException( uid );
 		}
 		return space;
 	}
 
 	// ExpandingQuerySpaces impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private int implicitUidBase;
 
 	@Override
 	public String generateImplicitUid() {
 		return "<gen:" + implicitUidBase++ + ">";
 	}
 
 	@Override
 	public ExpandingEntityQuerySpace makeRootEntityQuerySpace(String uid, EntityPersister entityPersister) {
 		final ExpandingEntityQuerySpace space = makeEntityQuerySpace( uid, entityPersister, true );
 		roots.add( space );
 		return space;
 	}
 
 	@Override
 	public ExpandingEntityQuerySpace makeEntityQuerySpace(
 			String uid,
 			EntityPersister entityPersister,
 			boolean canJoinsBeRequired) {
 
 		checkQuerySpaceDoesNotExist( uid );
 
 		// as a temporary fix for HHH-8980 and HHH-8830 we circumvent allowing
 		// inner joins (canJoinsBeRequired) when the persister is part of an
 		// entity inheritance.
 		//
 		// hasSubclasses() is the closest we can come to even knowing if the
 		// entity is part of a hierarchy.  But its enough, since if there are no
 		// subclasses we cannot have the case where the attribute to join comes from
 		// a subclass :)
 		//
 		// a better long term fix is to expose whether a joined association attribute
 		// is defined on the class/superClass(es) or on the subClass(es).  Attributes
 		// from the subClass(es) should not be inner joined; it is ok to inner join
 		// attributes from the class/superClass(es).
 
 		final EntityQuerySpaceImpl space = new EntityQuerySpaceImpl(
 				entityPersister,
 				uid,
 				this,
 				canJoinsBeRequired && !entityPersister.getEntityMetamodel().hasSubclasses()
 		);
 		registerQuerySpace( space );
 
 		return space;
 	}
 
 	@Override
 	public ExpandingCollectionQuerySpace makeRootCollectionQuerySpace(String uid, CollectionPersister collectionPersister) {
 		final ExpandingCollectionQuerySpace space = makeCollectionQuerySpace( uid, collectionPersister, true );
 		roots.add( space );
 		return space;
 	}
 
 	@Override
 	public ExpandingCollectionQuerySpace makeCollectionQuerySpace(
 			String uid,
 			CollectionPersister collectionPersister,
 			boolean canJoinsBeRequired) {
 
 		checkQuerySpaceDoesNotExist( uid );
 
 		final ExpandingCollectionQuerySpace space = new CollectionQuerySpaceImpl(
 				collectionPersister,
 				uid,
 				this,
 				canJoinsBeRequired
 		);
 		registerQuerySpace( space );
 
 		return space;
 	}
 
 	@Override
 	public ExpandingCompositeQuerySpace makeCompositeQuerySpace(
 			String uid,
 			CompositePropertyMapping compositePropertyMapping,
 			boolean canJoinsBeRequired) {
 
 		checkQuerySpaceDoesNotExist( uid );
 
 		final ExpandingCompositeQuerySpace space = new CompositeQuerySpaceImpl(
 				compositePropertyMapping,
 				uid,
 				this,
 				canJoinsBeRequired
 		);
 		registerQuerySpace( space );
 
 		return space;
 	}
 
 	@Override
 	public SessionFactoryImplementor getSessionFactory() {
 		return sessionFactory;
 	}
 
 	private void checkQuerySpaceDoesNotExist(String uid) {
 		if ( querySpaceByUid.containsKey( uid ) ) {
 			throw new IllegalStateException( "Encountered duplicate QuerySpace uid : " + uid );
 		}
 	}
 
 	/**
 	 * Feeds a QuerySpace into this spaces group.
 	 *
 	 * @param querySpace The space
 	 */
 	private void registerQuerySpace(QuerySpace querySpace) {
 		log.debugf(
 				"Adding QuerySpace : uid = %s -> %s]",
 				querySpace.getUid(),
 				querySpace
 		);
 		final QuerySpace previous = querySpaceByUid.put( querySpace.getUid(), querySpace );
 		if ( previous != null ) {
 			throw new IllegalStateException( "Encountered duplicate QuerySpace uid : " + querySpace.getUid() );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
index 3baccd5cef..63f2231a55 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
@@ -1,55 +1,55 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.spi;
 
 import org.hibernate.loader.plan.spi.CollectionQuerySpace;
 import org.hibernate.loader.plan.spi.Join;
-import org.hibernate.loader.plan.spi.JoinDefinedByMetadata;
 import org.hibernate.persister.collection.CollectionPropertyNames;
 
 /**
  * Describes a collection query space that allows adding joins with other
  * query spaces; used while building a {@link CollectionQuerySpace}.
  *
  * @see org.hibernate.loader.plan.spi.Join
  *
  * @author Gail Badner
  */
 public interface ExpandingCollectionQuerySpace extends CollectionQuerySpace, ExpandingQuerySpace {
 
 	/**
 	 * Adds a join with another query space for either a collection element or index. If {@code join}
-	 * is an instance of {@link JoinDefinedByMetadata}, then the only valid values returned by
-	 * {@link JoinDefinedByMetadata#getJoinedPropertyName} are {@link CollectionPropertyNames#COLLECTION_ELEMENTS}
-	 * and {@link CollectionPropertyNames#COLLECTION_INDICES}, for the collection element or index, respectively.
+	 * is an instance of {@link org.hibernate.loader.plan.spi.JoinDefinedByMetadata}, then the only valid
+	 * values returned by {@link org.hibernate.loader.plan.spi.JoinDefinedByMetadata#getJoinedPropertyName}
+	 * are {@link CollectionPropertyNames#COLLECTION_ELEMENTS} and {@link CollectionPropertyNames#COLLECTION_INDICES},
+	 * for the collection element or index, respectively.
 	 *
 	 * @param join The element or index join to add.
 	 *
-	 * @throws java.lang.IllegalArgumentException if {@code join} is an instance of {@link JoinDefinedByMetadata}
-	 * and {@code join.getJoinedPropertyName() is neither {@link CollectionPropertyNames#COLLECTION_ELEMENTS}
-	 * nor {@link CollectionPropertyNames#COLLECTION_INDICES}}.
+	 * @throws java.lang.IllegalArgumentException if {@code join} is an instance of
+	 * {@link org.hibernate.loader.plan.spi.JoinDefinedByMetadata} and {@code join.getJoinedPropertyName()
+	 * is neither {@link CollectionPropertyNames#COLLECTION_ELEMENTS} nor {@link CollectionPropertyNames#COLLECTION_INDICES}}.
 	 * @throws java.lang.IllegalStateException if there is already an existing join with the same joined property name.
 	 */
 	public void addJoin(Join join);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingQuerySpaces.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingQuerySpaces.java
index 85509a5ce3..138181b84b 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingQuerySpaces.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingQuerySpaces.java
@@ -1,176 +1,174 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.spi;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.plan.build.internal.spaces.CompositePropertyMapping;
-import org.hibernate.loader.plan.spi.Join;
-import org.hibernate.loader.plan.spi.QuerySpace;
 import org.hibernate.loader.plan.spi.QuerySpaces;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
- * Models a collection of {@link QuerySpace} references and
+ * Models a collection of {@link org.hibernate.loader.plan.spi.QuerySpace} references and
  * exposes the ability to create an {@link ExpandingQuerySpace} for "returns" and fetches;
  * used when building a load plan.
  *
  * @author Steve Ebersole
  */
 public interface ExpandingQuerySpaces extends QuerySpaces {
 
 	/**
 	 * Generate a unique ID to be used when creating an {@link ExpandingQuerySpace}.
 	 * <p/>
 	 * Using this method to generate a unique ID ensures that this object
-	 * does not contain a {@link QuerySpace} with the returned unique ID.
+	 * does not contain a {@link org.hibernate.loader.plan.spi.QuerySpace} with the returned unique ID.
 	 *
 	 * @return The unique ID.
 	 */
-	public String generateImplicitUid();
+	String generateImplicitUid();
 
 	/**
 	 * Create an {@link ExpandingEntityQuerySpace} for an entity "return" with the
 	 * specified unique ID.
 	 *
 	 * The unique ID should be generated using {@link #generateImplicitUid()},
 	 *
-	 * A unique suffix may be added to the unique ID for an existing {@link QuerySpace}.
+	 * A unique suffix may be added to the unique ID for an existing {@link org.hibernate.loader.plan.spi.QuerySpace}.
 	 * In this case, it is the caller's responsibility to ensure uniqueness.
 	 *
 	 * @param uid The unique ID for the root entity query space.
 	 * @param entityPersister The entity persister.
 	 * @return the {@link ExpandingEntityQuerySpace} with the specified unique ID.
 	 * @throws IllegalStateException if there is already a query space with the
 	 *         specified unique ID.
 	 *
 	 * @see org.hibernate.loader.plan.spi.EntityReturn
 	 */
-	public ExpandingEntityQuerySpace makeRootEntityQuerySpace(
+	ExpandingEntityQuerySpace makeRootEntityQuerySpace(
 			String uid,
 			EntityPersister entityPersister);
 
 	/**
 	 * Create an {@link ExpandingEntityQuerySpace} for an entity (that is not a "return")
 	 * with the specified unique ID.
 	 *
 	 * The unique ID should be generated using {@link #generateImplicitUid()},
 	 *
-	 * A unique suffix may be added to the unique ID for an existing {@link QuerySpace}.
+	 * A unique suffix may be added to the unique ID for an existing {@link org.hibernate.loader.plan.spi.QuerySpace}.
 	 * In this case, it is the caller's responsibility to ensure uniqueness.
 	 *
 	 * @param uid The unique ID for the entity query space.
 	 * @param entityPersister The entity persister.
 	 * @param canJoinsBeRequired <code>true</code> if joins added to the returned value
 	 *                          can be required joins; <code>false</code>, otherwise.
 	 *
 	 * @return the {@link ExpandingEntityQuerySpace} with the specified unique ID.
 	 * @throws IllegalStateException if there is already a query space with the
 	 *         specified unique ID.
 	 *
-	 * @see Join
+	 * @see org.hibernate.loader.plan.spi.Join
 	 */
-	public ExpandingEntityQuerySpace makeEntityQuerySpace(
+	ExpandingEntityQuerySpace makeEntityQuerySpace(
 			String uid,
 			EntityPersister entityPersister,
 			boolean canJoinsBeRequired);
 
 	/**
 	 * Create an {@link ExpandingCollectionQuerySpace} for a collection "return" with the
 	 * specified unique ID.
 	 *
 	 * The unique ID should be generated using {@link #generateImplicitUid()},
 	 *
-	 * A unique suffix may be added to the unique ID for an existing {@link QuerySpace}.
+	 * A unique suffix may be added to the unique ID for an existing {@link org.hibernate.loader.plan.spi.QuerySpace}.
 	 * In this case, it is the caller's responsibility to ensure uniqueness.
 	 *
 	 * @param uid The unique ID for the root collection query space.
 	 * @param collectionPersister The collection persister.
 	 * @return the {@link ExpandingCollectionQuerySpace} with the specified unique ID.
 	 * @throws IllegalStateException if there is already a query space with the
 	 *         specified unique ID.
 	 *
 	 * @see org.hibernate.loader.plan.spi.CollectionReturn
 	 */
-	public ExpandingCollectionQuerySpace makeRootCollectionQuerySpace(
+	ExpandingCollectionQuerySpace makeRootCollectionQuerySpace(
 			String uid,
 			CollectionPersister collectionPersister);
 
 	/**
 	 * Create an {@link ExpandingCollectionQuerySpace} for a collection (that is not a "return")
 	 * with the specified unique ID.
 	 *
 	 * The unique ID should be generated using {@link #generateImplicitUid()},
 	 *
-	 * A unique suffix may be added to the unique ID for an existing {@link QuerySpace}.
+	 * A unique suffix may be added to the unique ID for an existing {@link org.hibernate.loader.plan.spi.QuerySpace}.
 	 * In this case, it is the caller's responsibility to ensure uniqueness.
 	 *
 	 * @param uid The unique ID for the collection query space.
 	 * @param collectionPersister The collection persister.
 	 * @param canJoinsBeRequired <code>true</code> if joins added to the returned value
 	 *                          can be required joins; <code>false</code>, otherwise.
 	 *
 	 * @return the {@link ExpandingCollectionQuerySpace} with the specified unique ID.
 	 * @throws IllegalStateException if there is already a query space with the
 	 *         specified unique ID.
 	 *
-	 * @see Join
+	 * @see org.hibernate.loader.plan.spi.Join
 	 */
-	public ExpandingCollectionQuerySpace makeCollectionQuerySpace(
+	ExpandingCollectionQuerySpace makeCollectionQuerySpace(
 			String uid,
 			CollectionPersister collectionPersister,
 			boolean canJoinsBeRequired);
 
 	/**
 	 * Create an {@link ExpandingCompositeQuerySpace} for a composite
 	 * with the specified unique ID.
 	 *
 	 * The unique ID should be generated using {@link #generateImplicitUid()},
 	 *
-	 * A unique suffix may be added to the unique ID for an existing {@link QuerySpace}.
+	 * A unique suffix may be added to the unique ID for an existing {@link org.hibernate.loader.plan.spi.QuerySpace}.
 	 * In this case, it is the caller's responsibility to ensure uniqueness.
 	 *
 	 * @param uid The unique ID for the composite query space.
 	 * @param compositePropertyMapping The composite property mapping.
 	 * @param canJoinsBeRequired <code>true</code> if joins added to the returned value
 	 *                          can be required joins; <code>false</code>, otherwise.
 	 *
 	 * @return the {@link ExpandingCompositeQuerySpace} with the specified unique ID.
 	 * @throws IllegalStateException if there is already a query space with the
 	 *         specified unique ID.
 	 *
-	 * @see Join
+	 * @see org.hibernate.loader.plan.spi.Join
 	 */
-	public ExpandingCompositeQuerySpace makeCompositeQuerySpace(
+	ExpandingCompositeQuerySpace makeCompositeQuerySpace(
 			String uid,
 			CompositePropertyMapping compositePropertyMapping,
 			boolean canJoinsBeRequired);
 
 	/**
 	 * Gets the session factory.
 	 *
 	 * @return The session factory.
 	 */
-	public SessionFactoryImplementor getSessionFactory();
+	SessionFactoryImplementor getSessionFactory();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AbstractLoadQueryDetails.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AbstractLoadQueryDetails.java
index 0346771ce0..9e4b6f6e0a 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AbstractLoadQueryDetails.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AbstractLoadQueryDetails.java
@@ -1,294 +1,289 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.exec.internal;
 
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.plan.build.spi.LoadPlanTreePrinter;
-import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
-import org.hibernate.loader.plan.exec.internal.FetchStats;
-import org.hibernate.loader.plan.exec.internal.LoadQueryJoinAndFetchProcessor;
 import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
 import org.hibernate.loader.plan.exec.process.spi.CollectionReferenceInitializer;
 import org.hibernate.loader.plan.exec.process.spi.EntityReferenceInitializer;
 import org.hibernate.loader.plan.exec.process.spi.ReaderCollector;
 import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessor;
 import org.hibernate.loader.plan.exec.query.internal.SelectStatementBuilder;
 import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
 import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
 import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.FetchSource;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.QuerySpace;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.sql.ConditionFragment;
 import org.hibernate.sql.DisjunctionFragment;
 import org.hibernate.sql.InFragment;
 
 /**
  * @author Gail Badner
  */
 public abstract class AbstractLoadQueryDetails implements LoadQueryDetails {
 
 	private final LoadPlan loadPlan;
 	private final String[] keyColumnNames;
 	private final Return rootReturn;
 	private final LoadQueryJoinAndFetchProcessor queryProcessor;
 	private String sqlStatement;
 	private ResultSetProcessor resultSetProcessor;
 
 	/**
 	 * @param rootReturn The root return reference we are processing
-	 * @param select The SelectStatementBuilder
-	 * @param helper The Join/Fetch helper
 	 * @param factory The SessionFactory
 	 * @param buildingParameters The query building context
-	 * @param rootAlias The table alias to use
-	 * @param rootLoadable The persister
-	 * @param readerCollector Collector for EntityReferenceInitializer and CollectionReferenceInitializer references
-	*/
+	 */
 	protected AbstractLoadQueryDetails(
 			LoadPlan loadPlan,
 			AliasResolutionContextImpl aliasResolutionContext,
 			QueryBuildingParameters buildingParameters,
 			String[] keyColumnNames,
 			Return rootReturn,
 			SessionFactoryImplementor factory) {
 		this.keyColumnNames = keyColumnNames;
 		this.rootReturn = rootReturn;
 		this.loadPlan = loadPlan;
 		this.queryProcessor = new LoadQueryJoinAndFetchProcessor( aliasResolutionContext, buildingParameters, factory );
 	}
 
 	protected QuerySpace getQuerySpace(String querySpaceUid) {
 		return loadPlan.getQuerySpaces().getQuerySpaceByUid( querySpaceUid );
 	}
 
 	@Override
 	public String getSqlStatement() {
 		return sqlStatement;
 	}
 
 	@Override
 	public ResultSetProcessor getResultSetProcessor() {
 		return resultSetProcessor;
 	}
 
 	protected final Return getRootReturn() {
 		return rootReturn;
 	}
 
 	protected final AliasResolutionContext getAliasResolutionContext() {
 		return queryProcessor.getAliasResolutionContext();
 	}
 
 	protected final QueryBuildingParameters getQueryBuildingParameters() {
 		return queryProcessor.getQueryBuildingParameters();
 	}
 
 	protected final SessionFactoryImplementor getSessionFactory() {
 		return queryProcessor.getSessionFactory();
 	}
 	/**
 	 * Main entry point for properly handling the FROM clause and and joins and restrictions
 	 *
 	 */
 	protected void generate() {
 		// There are 2 high-level requirements to perform here:
 		// 	1) Determine the SQL required to carry out the given LoadPlan (and fulfill
 		// 		{@code LoadQueryDetails#getSqlStatement()}).  SelectStatementBuilder collects the ongoing efforts to
 		//		build the needed SQL.
 		// 	2) Determine how to read information out of the ResultSet resulting from executing the indicated SQL
 		//		(the SQL aliases).  ReaderCollector and friends are where this work happens, ultimately
 		//		producing a ResultSetProcessor
 
 		final SelectStatementBuilder select = new SelectStatementBuilder( queryProcessor.getSessionFactory().getDialect() );
 
 		// LoadPlan is broken down into 2 high-level pieces that we need to process here.
 		//
 		// First is the QuerySpaces, which roughly equates to the SQL FROM-clause.  We'll cycle through
 		// those first, generating aliases into the AliasContext in addition to writing SQL FROM-clause information
 		// into SelectStatementBuilder.  The AliasContext is populated here and the reused while process the SQL
 		// SELECT-clause into the SelectStatementBuilder and then again also to build the ResultSetProcessor
 
 		applyRootReturnTableFragments( select );
 
 		if ( shouldApplyRootReturnFilterBeforeKeyRestriction() ) {
 			applyRootReturnFilterRestrictions( select );
 			// add restrictions...
 			// first, the load key restrictions (which entity(s)/collection(s) do we want to load?)
 			applyKeyRestriction(
 					select,
 					getRootTableAlias(),
 					keyColumnNames,
 					getQueryBuildingParameters().getBatchSize()
 			);
 		}
 		else {
 			// add restrictions...
 			// first, the load key restrictions (which entity(s)/collection(s) do we want to load?)
 			applyKeyRestriction(
 					select,
 					getRootTableAlias(),
 					keyColumnNames,
 					getQueryBuildingParameters().getBatchSize()
 			);
 			applyRootReturnFilterRestrictions( select );
 		}
 
 
 		applyRootReturnWhereJoinRestrictions( select );
 
 		applyRootReturnOrderByFragments( select );
 		// then move on to joins...
 
 		applyRootReturnSelectFragments( select );
 
 		queryProcessor.processQuerySpaceJoins( getRootQuerySpace(), select );
 
 		// Next, we process the Returns and Fetches building the SELECT clause and at the same time building
 		// Readers for reading the described results out of a SQL ResultSet
 
 		FetchStats fetchStats = null;
 		if ( FetchSource.class.isInstance( rootReturn ) ) {
 			fetchStats = queryProcessor.processFetches(
 					(FetchSource) rootReturn,
 					select,
 					getReaderCollector()
 			);
 		}
 		else if ( CollectionReturn.class.isInstance( rootReturn ) ) {
 			final CollectionReturn collectionReturn = (CollectionReturn) rootReturn;
 			if ( collectionReturn.getElementGraph() != null ) {
 				fetchStats = queryProcessor.processFetches(
 						collectionReturn.getElementGraph(),
 						select,
 						getReaderCollector()
 				);
 			}
 			// TODO: what about index???
 		}
 
 		LoadPlanTreePrinter.INSTANCE.logTree( loadPlan, queryProcessor.getAliasResolutionContext() );
 
 		this.sqlStatement = select.toStatementString();
 		this.resultSetProcessor = new ResultSetProcessorImpl(
 				loadPlan,
 				getReaderCollector().buildRowReader(),
 				fetchStats != null && fetchStats.hasSubselectFetches()
 		);
 	}
 
 	protected abstract ReaderCollector getReaderCollector();
 	protected abstract QuerySpace getRootQuerySpace();
 	protected abstract String getRootTableAlias();
 	protected abstract boolean shouldApplyRootReturnFilterBeforeKeyRestriction();
 	protected abstract void applyRootReturnSelectFragments(SelectStatementBuilder selectStatementBuilder );
 	protected abstract void applyRootReturnTableFragments(SelectStatementBuilder selectStatementBuilder);
 	protected abstract void applyRootReturnFilterRestrictions(SelectStatementBuilder selectStatementBuilder);
 	protected abstract void applyRootReturnWhereJoinRestrictions(SelectStatementBuilder selectStatementBuilder);
 	protected abstract void applyRootReturnOrderByFragments(SelectStatementBuilder selectStatementBuilder);
 
 
 		private static void applyKeyRestriction(SelectStatementBuilder select, String alias, String[] keyColumnNames, int batchSize) {
 		if ( keyColumnNames.length==1 ) {
 			// NOT A COMPOSITE KEY
 			// 		for batching, use "foo in (?, ?, ?)" for batching
 			//		for no batching, use "foo = ?"
 			// (that distinction is handled inside InFragment)
 			final InFragment in = new InFragment().setColumn( alias, keyColumnNames[0] );
 			for ( int i = 0; i < batchSize; i++ ) {
 				in.addValue( "?" );
 			}
 			select.appendRestrictions( in.toFragmentString() );
 		}
 		else {
 			// A COMPOSITE KEY...
 			final ConditionFragment keyRestrictionBuilder = new ConditionFragment()
 					.setTableAlias( alias )
 					.setCondition( keyColumnNames, "?" );
 			final String keyRestrictionFragment = keyRestrictionBuilder.toFragmentString();
 
 			StringBuilder restrictions = new StringBuilder();
 			if ( batchSize==1 ) {
 				// for no batching, use "foo = ? and bar = ?"
 				restrictions.append( keyRestrictionFragment );
 			}
 			else {
 				// for batching, use "( (foo = ? and bar = ?) or (foo = ? and bar = ?) )"
 				restrictions.append( '(' );
 				DisjunctionFragment df = new DisjunctionFragment();
 				for ( int i=0; i<batchSize; i++ ) {
 					df.addCondition( keyRestrictionFragment );
 				}
 				restrictions.append( df.toFragmentString() );
 				restrictions.append( ')' );
 			}
 			select.appendRestrictions( restrictions.toString() );
 		}
 	}
 
 	protected abstract static class ReaderCollectorImpl implements ReaderCollector {
 		private final List<EntityReferenceInitializer> entityReferenceInitializers = new ArrayList<EntityReferenceInitializer>();
 		private List<CollectionReferenceInitializer> arrayReferenceInitializers;
 		private List<CollectionReferenceInitializer> collectionReferenceInitializers;
 
 		@Override
 		public void add(CollectionReferenceInitializer collectionReferenceInitializer) {
 			if ( collectionReferenceInitializer.getCollectionReference().getCollectionPersister().isArray() ) {
 				if ( arrayReferenceInitializers == null ) {
 					arrayReferenceInitializers = new ArrayList<CollectionReferenceInitializer>();
 				}
 				arrayReferenceInitializers.add( collectionReferenceInitializer );
 			}
 			else {
 				if ( collectionReferenceInitializers == null ) {
 					collectionReferenceInitializers = new ArrayList<CollectionReferenceInitializer>();
 				}
 				collectionReferenceInitializers.add( collectionReferenceInitializer );
 			}
 		}
 
 		@Override
 		public void add(EntityReferenceInitializer entityReferenceInitializer) {
 			entityReferenceInitializers.add( entityReferenceInitializer );
 		}
 
+		@Override
 		public final List<EntityReferenceInitializer> getEntityReferenceInitializers() {
 			return entityReferenceInitializers;
 		}
 
+		@Override
 		public List<CollectionReferenceInitializer> getArrayReferenceInitializers() {
 			return arrayReferenceInitializers;
 
 		}
 
+		@Override
 		public List<CollectionReferenceInitializer> getNonArrayCollectionReferenceInitializers() {
 			return collectionReferenceInitializers;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/connections/ThreadLocalCurrentSessionTest.java b/hibernate-core/src/test/java/org/hibernate/test/connections/ThreadLocalCurrentSessionTest.java
index 321ca7eda8..576a9951e0 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/connections/ThreadLocalCurrentSessionTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/connections/ThreadLocalCurrentSessionTest.java
@@ -1,138 +1,137 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.connections;
 
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.cfg.Environment;
 import org.hibernate.context.internal.ThreadLocalSessionContext;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.spi.LocalStatus;
 import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 import org.hibernate.testing.RequiresDialect;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Steve Ebersole
  */
 @RequiresDialect(H2Dialect.class)
 public class ThreadLocalCurrentSessionTest extends ConnectionManagementTestCase {
 	@Override
 	@SuppressWarnings("unchecked")
 	protected void addSettings(Map settings) {
 		super.addSettings( settings );
 
 		settings.put( Environment.CURRENT_SESSION_CONTEXT_CLASS, TestableThreadLocalContext.class.getName() );
 		settings.put( Environment.GENERATE_STATISTICS, "true" );
 	}
 
 	@Override
 	protected Session getSessionUnderTest() throws Throwable {
 		Session session = sessionFactory().getCurrentSession();
 		session.beginTransaction();
 		return session;
 	}
 
 	@Override
 	protected void release(Session session) {
 		if ( session.getTransaction().getStatus() != TransactionStatus.ACTIVE ) {
 			TestableThreadLocalContext.unbind( sessionFactory() );
 			return;
 		}
 		long initialCount = sessionFactory().getStatistics().getSessionCloseCount();
 		session.getTransaction().commit();
 		long subsequentCount = sessionFactory().getStatistics().getSessionCloseCount();
 		assertEquals( "Session still open after commit", initialCount + 1, subsequentCount );
 		// also make sure it was cleaned up from the internal ThreadLocal...
 		assertFalse( "session still bound to internal ThreadLocal", TestableThreadLocalContext.hasBind() );
 	}
 
 	@Override
 	protected void reconnect(Session session) throws Throwable {
 	}
 
 	@Override
 	protected void checkSerializedState(Session session) {
 		assertFalse( "session still bound after serialize", TestableThreadLocalContext.isSessionBound( session ) );
 	}
 
 	@Override
 	protected void checkDeserializedState(Session session) {
 		assertTrue( "session not bound after deserialize", TestableThreadLocalContext.isSessionBound( session ) );
 	}
 
 	@Test
 	public void testTransactionProtection() {
 		Session session = sessionFactory().getCurrentSession();
 		try {
 			session.createQuery( "from Silly" );
 			fail( "method other than beginTransaction{} allowed" );
 		}
 		catch ( HibernateException e ) {
 			// ok
 		}
 	}
 
 	@Test
 	public void testContextCleanup() {
 		Session session = sessionFactory().getCurrentSession();
 		session.beginTransaction();
 		session.getTransaction().commit();
 		assertFalse( "session open after txn completion", session.isOpen() );
 		assertFalse( "session still bound after txn completion", TestableThreadLocalContext.isSessionBound( session ) );
 
 		Session session2 = sessionFactory().getCurrentSession();
 		assertFalse( "same session returned after txn completion", session == session2 );
 		session2.close();
 		assertFalse( "session open after closing", session2.isOpen() );
 		assertFalse( "session still bound after closing", TestableThreadLocalContext.isSessionBound( session2 ) );
 	}
 
 	public static class TestableThreadLocalContext extends ThreadLocalSessionContext {
 		private static TestableThreadLocalContext me;
 
 		public TestableThreadLocalContext(SessionFactoryImplementor factory) {
 			super( factory );
 			me = this;
 		}
 
 		public static boolean isSessionBound(Session session) {
 			return sessionMap() != null && sessionMap().containsKey( me.factory() )
 					&& sessionMap().get( me.factory() ) == session;
 		}
 
 		public static boolean hasBind() {
 			return sessionMap() != null && sessionMap().containsKey( me.factory() );
 		}
 	}
 }
diff --git a/shared/config/checkstyle/checkstyle-eventual.xml b/shared/config/checkstyle/checkstyle-eventual.xml
deleted file mode 100644
index 6ad31b79c5..0000000000
--- a/shared/config/checkstyle/checkstyle-eventual.xml
+++ /dev/null
@@ -1,257 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  ~ Hibernate, Relational Persistence for Idiomatic Java
-  ~
-  ~ Copyright (c) 2013, Red Hat Inc. or third-party contributors as
-  ~ indicated by the @author tags or express copyright attribution
-  ~ statements applied by the authors.  All third-party contributions are
-  ~ distributed under license by Red Hat Inc.
-  ~
-  ~ This copyrighted material is made available to anyone wishing to use, modify,
-  ~ copy, or redistribute it subject to the terms and conditions of the GNU
-  ~ Lesser General Public License, as published by the Free Software Foundation.
-  ~
-  ~ This program is distributed in the hope that it will be useful,
-  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
-  ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
-  ~ for more details.
-  ~
-  ~ You should have received a copy of the GNU Lesser General Public License
-  ~ along with this distribution; if not, write to:
-  ~ Free Software Foundation, Inc.
-  ~ 51 Franklin Street, Fifth Floor
-  ~ Boston, MA  02110-1301  USA
-  -->
-<!DOCTYPE module PUBLIC "-//Puppy Crawl//DTD Check Configuration 1.1//EN" "http://www.puppycrawl.com/dtds/configuration_1_2.dtd">
-<module name="Checker">
-
-    <module name="TreeWalker">
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            General regex checks as part of the TreeWalker
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-<!--
-        <module name="Regexp">
-            <property name="format"
-                      value="\A(/\*\n \* Hibernate, Relational Persistence for Idiomatic Java\n \*\n \* Copyright \(c\) \d{4}(-\d{4})?, Red Hat(,)? Inc. (and/or its affiliates )?or third-party contributors as\n \* indicated by the @author tags or express copyright attribution\n \* statements applied by the authors. All third-party contributions are\n \* distributed under license by Red Hat(,)? Inc.\n \*\n \* This copyrighted material is made available to anyone wishing to use, modify,\n \* copy, or redistribute it subject to the terms and conditions of the GNU\n \* Lesser General Public License, as published by the Free Software Foundation.\n \*\n \* This program is distributed in the hope that it will be useful,\n \* but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n \* or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License\n \* for more details.\n \*\n \* You should have received a copy of the GNU Lesser General Public License\n \* along with this distribution; if not, write to:\n \* Free Software Foundation, Inc.\n \* 51 Franklin Street, Fifth Floor\n \* Boston, MA 02110-1301 USA\n \*/)|(/\* ?\n \* Hibernate, Relational Persistence for Idiomatic Java\n \* ?\n \* JBoss, Home of Professional Open Source\n \* Copyright \d{4} Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)|(/\*\n \* Hibernate, Relational Persistence for Idiomatic Java\n \*\n \* JBoss, Home of Professional Open Source\n \* Copyright \d{4}(-\d{4})? Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)|(/\* ?\n \* JBoss, Home of Professional Open Source\n \* Copyright 2011 Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)" />
-            <property name="message" value="Correct header not found" />
-        </module>
--->
-        <module name="RegexpSinglelineJava">
-            <property name="ignoreComments" value="true" />
-            <property name="format" value="^\t* +\t*\S" />
-            <property name="message" value="Line has leading space characters; indentation should be performed with tabs only." />
-        </module>
-
-<!--
-    For now this is disabled to minimize false conflicts with metamodel branch.
-
-        <module name="RegexpSinglelineJava">
-            <property name="ignoreComments" value="true" />
-            <property name="format" value="\s+$" />
-            <property name="message" value="White spaces at the end of line" />
-        </module>
--->
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Annotation checks
-
-            See http://checkstyle.sourceforge.net/config_annotation.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="MissingDeprecated" />
-        <module name="MissingOverride" />
-        <module name="PackageAnnotation" />
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Block checks
-
-            See http://checkstyle.sourceforge.net/config_blocks.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="AvoidNestedBlocks">
-            <property name="allowInSwitchCase" value="true" />
-            <property name="severity" value="warning" />
-        </module>
-        <module name="NeedBraces" />
-        <module name="LeftCurly">
-            <property name="option" value="eol" />
-        </module>
-        <module name="RightCurly">
-            <property name="option" value="alone" />
-        </module>
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Design checks
-
-            See http://checkstyle.sourceforge.net/config_design.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="HideUtilityClassConstructor" />
-        <module name="MutableException" />
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Coding checks
-
-            See http://checkstyle.sourceforge.net/config_coding.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="EmptyStatement" />
-        <module name="EqualsHashCode" />
-        <module name="FinalLocalVariable" />
-        <module name="MissingSwitchDefault" />
-        <module name="ModifiedControlVariable" />
-        <module name="SimplifyBooleanExpression" />
-        <module name="SimplifyBooleanReturn" />
-        <module name="StringLiteralEquality" />
-        <module name="NoFinalizer" />
-        <module name="ExplicitInitialization" />
-        <module name="MissingSwitchDefault" />
-        <module name="DefaultComesLast" />
-        <module name="FallThrough" />
-        <module name="OneStatementPerLine" />
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Import checks
-
-            See http://checkstyle.sourceforge.net/config_imports.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="AvoidStarImport" />
-        <module name="RedundantImport" />
-        <module name="UnusedImports" />
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Javadoc checks
-
-            See http://checkstyle.sourceforge.net/config_javadoc.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="JavadocType">
-            <property name="scope" value="public"/>
-            <property name="allowUnknownTags" value="true" />
-            <property name="allowMissingParamTags" value="true" />
-        </module>
-        <module name="JavadocMethod">
-            <property name="scope" value="public" />
-            <property name="allowUndeclaredRTE" value="true" />
-            <property name="allowMissingPropertyJavadoc" value="true" />
-        </module>
-        <module name="JavadocVariable">
-            <property name="scope" value="public" />
-        </module>
-        <module name="JavadocStyle">
-            <property name="scope" value="public" />
-            <property name="checkEmptyJavadoc" value="true" />
-            <property name="checkFirstSentence" value="false" />
-        </module>
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Misc checks
-
-            See http://checkstyle.sourceforge.net/config_misc.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="UpperEll" />
-        <module name="ArrayTypeStyle" />
-        <module name="TrailingComment">
-            <property name="severity" value="warning" />
-        </module>
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Modifier checks
-
-            See http://checkstyle.sourceforge.net/config_modifier.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="ModifierOrder"/>
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Naming checks
-
-            See http://checkstyle.sourceforge.net/config_naming.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="AbstractClassName">
-            <!-- we are just using this to make sure that classes matching the pattern (Abstract*) have the abstract modifier -->
-            <property name="format" value="^Abstract.*$" />
-            <property name="ignoreName" value="true" />
-        </module>
-        <module name="ClassTypeParameterName" />
-        <module name="ConstantName">
-            <property name="format" value="^[A-Z](_?[A-Z0-9]+)*$|log" />
-        </module>
-        <module name="LocalFinalVariableName" >
-            <property name="severity" value="warning" />
-        </module>
-        <module name="LocalVariableName" />
-        <module name="MemberName" />
-        <!--
-        The org.hibernate.engine.spi.ManagedEntity method names (prefixed with '&&_') muck with this
-        <module name="MethodName" />
-        -->
-        <module name="MethodTypeParameterName" />
-        <module name="PackageName" />
-        <module name="ParameterName" />
-        <module name="StaticVariableName" />
-        <module name="TypeName" />
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Whitespace checks
-
-            See http://checkstyle.sourceforge.net/config_whitespace.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="MethodParamPad" />
-        <module name="TypecastParenPad" />
-        <module name="ParenPad">
-            <property name="tokens" value="CTOR_CALL, METHOD_CALL, SUPER_CTOR_CALL" />
-            <property name="option" value="space" />
-        </module>
-
-    </module>
-
-
-    <!--
-        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        Javadoc checks
-
-        See http://checkstyle.sourceforge.net/config_javadoc.html
-        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    -->
-    <module name="JavadocPackage">
-        <property name="allowLegacy" value="true" />
-    </module>
-
-
-    <!--
-        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        Misc checks
-
-        See http://checkstyle.sourceforge.net/config_misc.html
-        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-    -->
-    <module name="NewlineAtEndOfFile" />
-
-</module>
diff --git a/shared/config/checkstyle/checkstyle.xml b/shared/config/checkstyle/checkstyle.xml
index dd6ee0527b..8b54c8e592 100644
--- a/shared/config/checkstyle/checkstyle.xml
+++ b/shared/config/checkstyle/checkstyle.xml
@@ -1,223 +1,231 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2013, Red Hat Inc. or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Inc.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 <!DOCTYPE module PUBLIC "-//Puppy Crawl//DTD Check Configuration 1.1//EN" "http://www.puppycrawl.com/dtds/configuration_1_2.dtd">
 <module name="Checker">
 
+    <module name="FileContentsHolder"/>
+
+    <module name="SuppressionCommentFilter">
+        <property name="offCommentFormat" value="CHECKSTYLE:START_ALLOW_FINALIZER"/>
+        <property name="onCommentFormat" value="CHECKSTYLE:END_ALLOW_FINALIZER"/>
+        <property name="checkFormat" value="NoFinalizer"/>
+    </module>
+
     <!-- See http://checkstyle.sourceforge.net/checks.html for details of the various checks -->
 
     <module name="TreeWalker">
 
         <!--
             High-priority warnings : fail the build...
         -->
         <module name="RegexpSinglelineJava">
             <property name="ignoreComments" value="true" />
             <property name="format" value="^\t* +\t*\S" />
             <property name="message" value="Line has leading space characters; indentation should be performed with tabs only." />
         </module>
 
         <module name="MissingDeprecated" />
 
         <module name="MissingOverride" />
 
         <module name="PackageAnnotation" />
 
         <module name="NeedBraces" />
 
         <module name="LeftCurly">
             <property name="option" value="eol" />
         </module>
 
         <module name="RightCurly">
             <property name="option" value="alone" />
         </module>
 
         <module name="EqualsHashCode" />
 
         <module name="StringLiteralEquality" />
 
         <module name="NoFinalizer" />
 
         <module name="OneStatementPerLine" />
 
         <module name="AvoidStarImport" />
 
         <module name="RedundantImport" />
 
         <module name="UnusedImports" />
 
         <module name="UpperEll" />
 
 
 
         <!--
             Medium and low priority warnings : do not fail build
         -->
 
         <module name="AvoidNestedBlocks">
             <property name="allowInSwitchCase" value="true" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="HideUtilityClassConstructor">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MutableException">
             <property name="severity" value="warning" />
         </module>
 
         <module name="EmptyStatement">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MissingSwitchDefault">
             <property name="severity" value="warning" />
         </module>
 
         <module name="DefaultComesLast">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ModifiedControlVariable">
             <property name="severity" value="warning" />
         </module>
 
         <module name="SimplifyBooleanExpression">
             <property name="severity" value="warning" />
         </module>
 
         <module name="SimplifyBooleanReturn">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ExplicitInitialization">
             <property name="severity" value="warning" />
         </module>
 
         <module name="FallThrough">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ArrayTypeStyle">
             <property name="severity" value="warning" />
         </module>
 
         <module name="TrailingComment">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ModifierOrder">
             <property name="severity" value="warning" />
         </module>
 
         <module name="AbstractClassName">
             <!-- we are just using this to make sure that classes matching the pattern (Abstract*) have the abstract modifier -->
             <property name="format" value="^Abstract.*$" />
             <property name="ignoreName" value="true" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="ClassTypeParameterName">
             <property name="format" value="^[A-Z][A-Z0-9]*$" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="ConstantName">
             <property name="format" value="^[A-Z](_?[A-Z0-9]+)*$|log" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="LocalFinalVariableName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="LocalVariableName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MemberName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MethodTypeParameterName">
             <property name="format" value="^[A-Z][A-Z0-9]*$" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="PackageName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ParameterName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="StaticVariableName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="TypeName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="AbbreviationAsWordInName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MethodParamPad">
             <property name="severity" value="warning" />
         </module>
 
         <module name="TypecastParenPad">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ParenPad">
             <property name="tokens" value="CTOR_CALL, METHOD_CALL, SUPER_CTOR_CALL" />
             <property name="option" value="space" />
             <property name="severity" value="warning" />
         </module>
 
     </module>
 
     <module name="JavadocPackage">
         <property name="allowLegacy" value="true" />
         <property name="severity" value="warning" />
     </module>
 
     <module name="NewlineAtEndOfFile" />
 
     <!--
         Used to collect "todo" comments into a single location
     -->
     <module name="TreeWalker">
         <module name="TodoComment">
             <property name="format" value="[Tt][Oo][Dd][Oo]"/>
             <property name="severity" value="info" />
         </module>
     </module>
 
 </module>
diff --git a/shared/config/checkstyle/todo-checks.xml b/shared/config/checkstyle/todo-checks.xml
deleted file mode 100644
index 9ba45b4189..0000000000
--- a/shared/config/checkstyle/todo-checks.xml
+++ /dev/null
@@ -1,15 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-
-<!DOCTYPE module PUBLIC "-//Puppy Crawl//DTD Check Configuration 1.1//EN" "http://www.puppycrawl.com/dtds/configuration_1_2.dtd">
-
-<module name="Checker">
-    <!--
-        Used to collect "todo" comments into a single location
-    -->
-    <module name="TreeWalker">
-        <module name="TodoComment">
-            <property name="format" value="[Tt][Oo][Dd][Oo]"/>
-            <property name="severity" value="info" />
-        </module>
-    </module>
-</module>
\ No newline at end of file
