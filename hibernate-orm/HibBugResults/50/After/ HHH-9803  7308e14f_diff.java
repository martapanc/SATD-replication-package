diff --git a/hibernate-core/src/main/java/org/hibernate/boot/MetadataSources.java b/hibernate-core/src/main/java/org/hibernate/boot/MetadataSources.java
index 10bb74e35a..0ac8969e94 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/MetadataSources.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/MetadataSources.java
@@ -1,505 +1,507 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot;
 
 import java.io.File;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.Serializable;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Enumeration;
 import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.jar.JarFile;
 import java.util.zip.ZipEntry;
 import javax.xml.transform.dom.DOMSource;
 
 import org.hibernate.boot.archive.spi.InputStreamAccess;
 import org.hibernate.boot.internal.MetadataBuilderImpl;
 import org.hibernate.boot.jaxb.Origin;
 import org.hibernate.boot.jaxb.SourceType;
 import org.hibernate.boot.jaxb.internal.CacheableFileXmlSource;
 import org.hibernate.boot.jaxb.internal.FileXmlSource;
 import org.hibernate.boot.jaxb.internal.InputStreamXmlSource;
 import org.hibernate.boot.jaxb.internal.JarFileEntryXmlSource;
 import org.hibernate.boot.jaxb.internal.JaxpSourceXmlSource;
 import org.hibernate.boot.jaxb.internal.MappingBinder;
 import org.hibernate.boot.jaxb.internal.UrlXmlSource;
 import org.hibernate.boot.jaxb.spi.Binder;
 import org.hibernate.boot.jaxb.spi.Binding;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.type.SerializationException;
 
 import org.w3c.dom.Document;
 
 /**
  * Entry point into working with sources of metadata information (mapping XML, annotations).   Tell Hibernate
  * about sources and then call {@link #buildMetadata()}, or use {@link #getMetadataBuilder()} to customize
  * how sources are processed (naming strategies, etc).
  *
  * @author Steve Ebersole
  *
  * @since 5.0
  */
 public class MetadataSources implements Serializable {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( MetadataSources.class );
 
 	private final ServiceRegistry serviceRegistry;
 
 	// NOTE : The boolean here indicates whether or not to perform validation as we load XML documents.
 	// Should we expose this setting?  Disabling would speed up JAXP and JAXB at runtime, but potentially
 	// at the cost of less obvious errors when a document is not valid.
 	private Binder mappingsBinder = new MappingBinder( true );
 
 	private List<Binding> xmlBindings = new ArrayList<Binding>();
 	private LinkedHashSet<Class<?>> annotatedClasses = new LinkedHashSet<Class<?>>();
 	private LinkedHashSet<String> annotatedClassNames = new LinkedHashSet<String>();
 	private LinkedHashSet<String> annotatedPackages = new LinkedHashSet<String>();
 
 	public MetadataSources() {
 		this( new BootstrapServiceRegistryBuilder().build() );
 	}
 
 	/**
 	 * Create a metadata sources using the specified service registry.
 	 *
 	 * @param serviceRegistry The service registry to use.
 	 */
 	public MetadataSources(ServiceRegistry serviceRegistry) {
 		// service registry really should be either BootstrapServiceRegistry or StandardServiceRegistry type...
 		if ( ! isExpectedServiceRegistryType( serviceRegistry ) ) {
 			LOG.debugf(
 					"Unexpected ServiceRegistry type [%s] encountered during building of MetadataSources; may cause " +
 							"problems later attempting to construct MetadataBuilder",
 					serviceRegistry.getClass().getName()
 			);
 		}
 		this.serviceRegistry = serviceRegistry;
 	}
 
 	protected static boolean isExpectedServiceRegistryType(ServiceRegistry serviceRegistry) {
 		return BootstrapServiceRegistry.class.isInstance( serviceRegistry )
 				|| StandardServiceRegistry.class.isInstance( serviceRegistry );
 	}
 
 	public List<Binding> getXmlBindings() {
 		return xmlBindings;
 	}
 
 	public Collection<String> getAnnotatedPackages() {
 		return annotatedPackages;
 	}
 
 	public Collection<Class<?>> getAnnotatedClasses() {
 		return annotatedClasses;
 	}
 
 	public Collection<String> getAnnotatedClassNames() {
 		return annotatedClassNames;
 	}
 
 	public ServiceRegistry getServiceRegistry() {
 		return serviceRegistry;
 	}
 
 	/**
 	 * Get a builder for metadata where non-default options can be specified.
 	 *
 	 * @return The built metadata.
 	 */
 	public MetadataBuilder getMetadataBuilder() {
 		return new MetadataBuilderImpl( this );
 	}
 
 	/**
 	 * Get a builder for metadata where non-default options can be specified.
 	 *
 	 * @return The built metadata.
 	 */
 	public MetadataBuilder getMetadataBuilder(StandardServiceRegistry serviceRegistry) {
 		return new MetadataBuilderImpl( this, serviceRegistry );
 	}
 
 	/**
 	 * Short-hand form of calling {@link #getMetadataBuilder()} and using its
 	 * {@link org.hibernate.boot.MetadataBuilder#build()} method in cases where the application wants
 	 * to accept the defaults.
 	 *
 	 * @return The built metadata.
 	 */
 	public Metadata buildMetadata() {
 		return getMetadataBuilder().build();
 	}
 
 	public Metadata buildMetadata(StandardServiceRegistry serviceRegistry) {
 		return getMetadataBuilder( serviceRegistry ).build();
 	}
 
 	/**
 	 * Read metadata from the annotations attached to the given class.
 	 *
 	 * @param annotatedClass The class containing annotations
 	 *
 	 * @return this (for method chaining)
 	 */
 	public MetadataSources addAnnotatedClass(Class annotatedClass) {
 		annotatedClasses.add( annotatedClass );
 		return this;
 	}
 
 	/**
 	 * Read metadata from the annotations attached to the given class.  The important
 	 * distinction here is that the {@link Class} will not be accessed until later
 	 * which is important for on-the-fly bytecode-enhancement
 	 *
 	 * @param annotatedClassName The name of a class containing annotations
 	 *
 	 * @return this (for method chaining)
 	 */
 	public MetadataSources addAnnotatedClassName(String annotatedClassName) {
 		annotatedClassNames.add( annotatedClassName );
 		return this;
 	}
 
 	/**
 	 * Read package-level metadata.
 	 *
 	 * @param packageName java package name without trailing '.', cannot be {@code null}
 	 *
 	 * @return this (for method chaining)
 	 */
 	public MetadataSources addPackage(String packageName) {
 		if ( packageName == null ) {
 			throw new IllegalArgumentException( "The specified package name cannot be null" );
 		}
 
 		if ( packageName.endsWith( "." ) ) {
 			packageName = packageName.substring( 0, packageName.length() - 1 );
 		}
 
 		annotatedPackages.add( packageName );
 
 		return this;
 	}
 
 	/**
 	 * Read package-level metadata.
 	 *
 	 * @param packageRef Java Package reference
 	 *
 	 * @return this (for method chaining)
 	 */
 	public MetadataSources addPackage(Package packageRef) {
 		annotatedPackages.add( packageRef.getName() );
 		return this;
 	}
 
 	/**
 	 * Read mappings as a application resourceName (i.e. classpath lookup).
 	 *
 	 * @param name The resource name
 	 *
 	 * @return this (for method chaining purposes)
 	 */
 	public MetadataSources addResource(String name) {
 		LOG.tracef( "reading mappings from resource : %s", name );
 
 		final Origin origin = new Origin( SourceType.RESOURCE, name );
 		final URL url = classLoaderService().locateResource( name );
 		if ( url == null ) {
 			throw new MappingNotFoundException( origin );
 		}
 
 		xmlBindings.add( new UrlXmlSource( origin, url ).doBind( mappingsBinder ) );
 
 		return this;
 	}
 
 	private ClassLoaderService classLoaderService() {
 		return serviceRegistry.getService( ClassLoaderService.class );
 	}
 
 	/**
 	 * Read a mapping as an application resource using the convention that a class named {@code foo.bar.Foo} is
 	 * mapped by a file named {@code foo/bar/Foo.hbm.xml} which can be resolved as a classpath resource.
 	 *
 	 * @param entityClass The mapped class. Cannot be {@code null} null.
 	 *
 	 * @return this (for method chaining purposes)
 	 *
 	 * @deprecated hbm.xml is a legacy mapping format now considered deprecated.
 	 */
 	@Deprecated
 	public MetadataSources addClass(Class entityClass) {
 		if ( entityClass == null ) {
 			throw new IllegalArgumentException( "The specified class cannot be null" );
 		}
 		LOG.debugf( "adding resource mappings from class convention : %s", entityClass.getName() );
 		final String mappingResourceName = entityClass.getName().replace( '.', '/' ) + ".hbm.xml";
 		addResource( mappingResourceName );
 		return this;
 	}
 
 	/**
 	 * Read mappings from a particular XML file
 	 *
 	 * @param path The path to a file.  Expected to be resolvable by {@link java.io.File#File(String)}
 	 *
 	 * @return this (for method chaining purposes)
 	 *
 	 * @see #addFile(java.io.File)
 	 */
 	public MetadataSources addFile(String path) {
 		addFile(
 				new Origin( SourceType.FILE, path ),
 				new File( path )
 		);
 		return this;
 	}
 
 	private void addFile(Origin origin, File file) {
 		LOG.tracef( "reading mappings from file : %s", origin.getName() );
 
 		if ( !file.exists() ) {
 			throw new MappingNotFoundException( origin );
 		}
 
 		xmlBindings.add( new FileXmlSource( origin, file ).doBind( mappingsBinder ) );
 	}
 
 	/**
 	 * Read mappings from a particular XML file
 	 *
 	 * @param file The reference to the XML file
 	 *
 	 * @return this (for method chaining purposes)
 	 */
 	public MetadataSources addFile(File file) {
 		addFile(
 				new Origin( SourceType.FILE, file.getPath() ),
 				file
 		);
 		return this;
 	}
 
 	/**
 	 * See {@link #addCacheableFile(java.io.File)} for description
 	 *
 	 * @param path The path to a file.  Expected to be resolvable by {@link java.io.File#File(String)}
 	 *
 	 * @return this (for method chaining purposes)
 	 *
 	 * @see #addCacheableFile(java.io.File)
 	 */
 	public MetadataSources addCacheableFile(String path) {
 		final Origin origin = new Origin( SourceType.FILE, path );
 		addCacheableFile( origin, new File( path ) );
 		return this;
 	}
 
 	private void addCacheableFile(Origin origin, File file) {
 		xmlBindings.add( new CacheableFileXmlSource( origin, file, false ).doBind( mappingsBinder ) );
 	}
 
 	/**
 	 * Add a cached mapping file.  A cached file is a serialized representation of the DOM structure of a
 	 * particular mapping.  It is saved from a previous call as a file with the name {@code {xmlFile}.bin}
 	 * where {@code {xmlFile}} is the name of the original mapping file.
 	 * </p>
 	 * If a cached {@code {xmlFile}.bin} exists and is newer than {@code {xmlFile}}, the {@code {xmlFile}.bin}
 	 * file will be read directly. Otherwise {@code {xmlFile}} is read and then serialized to {@code {xmlFile}.bin} for
 	 * use the next time.
 	 *
 	 * @param file The cacheable mapping file to be added, {@code {xmlFile}} in above discussion.
 	 *
 	 * @return this (for method chaining purposes)
 	 */
 	public MetadataSources addCacheableFile(File file) {
 		final Origin origin = new Origin( SourceType.FILE, file.getName() );
 		addCacheableFile( origin, file );
 		return this;
 	}
 
 	/**
 	 * <b>INTENDED FOR TESTSUITE USE ONLY!</b>
 	 * <p/>
 	 * Much like {@link #addCacheableFile(java.io.File)} except that here we will fail immediately if
 	 * the cache version cannot be found or used for whatever reason
 	 *
 	 * @param file The xml file, not the bin!
 	 *
 	 * @return The dom "deserialized" from the cached file.
 	 *
 	 * @throws org.hibernate.type.SerializationException Indicates a problem deserializing the cached dom tree
 	 * @throws java.io.FileNotFoundException Indicates that the cached file was not found or was not usable.
 	 */
 	public MetadataSources addCacheableFileStrictly(File file) throws SerializationException, FileNotFoundException {
 		final Origin origin = new Origin( SourceType.FILE, file.getAbsolutePath() );
 		xmlBindings.add( new CacheableFileXmlSource( origin, file, true ).doBind( mappingsBinder ) );
 		return this;
 	}
 
 	/**
 	 * Read metadata from an {@link java.io.InputStream} access
 	 *
 	 * @param xmlInputStreamAccess Access to an input stream containing a DOM.
 	 *
 	 * @return this (for method chaining purposes)
 	 */
 	public MetadataSources addInputStream(InputStreamAccess xmlInputStreamAccess) {
 		final Origin origin = new Origin( SourceType.INPUT_STREAM, xmlInputStreamAccess.getStreamName() );
 		InputStream xmlInputStream = xmlInputStreamAccess.accessInputStream();
 		try {
 			xmlBindings.add( new InputStreamXmlSource( origin, xmlInputStream, false ).doBind( mappingsBinder ) );
 		}
 		finally {
 			try {
 				xmlInputStream.close();
 			}
 			catch (IOException e) {
 				LOG.debugf( "Unable to close InputStream obtained from InputStreamAccess : " + xmlInputStreamAccess.getStreamName() );
 			}
 		}
 		return this;
 	}
 
 	/**
 	 * Read metadata from an {@link java.io.InputStream}.
 	 *
 	 * @param xmlInputStream The input stream containing a DOM.
 	 *
 	 * @return this (for method chaining purposes)
 	 */
 	public MetadataSources addInputStream(InputStream xmlInputStream) {
 		final Origin origin = new Origin( SourceType.INPUT_STREAM, null );
 		xmlBindings.add( new InputStreamXmlSource( origin, xmlInputStream, false ).doBind( mappingsBinder ) );
 		return this;
 	}
 
 	/**
 	 * Read mappings from a {@link java.net.URL}
 	 *
 	 * @param url The url for the mapping document to be read.
 	 *
 	 * @return this (for method chaining purposes)
 	 */
 	public MetadataSources addURL(URL url) {
 		final String urlExternalForm = url.toExternalForm();
 		LOG.debugf( "Reading mapping document from URL : %s", urlExternalForm );
 
 		final Origin origin = new Origin( SourceType.URL, urlExternalForm );
 		xmlBindings.add( new UrlXmlSource( origin, url ).doBind( mappingsBinder ) );
 		return this;
 	}
 
 	/**
 	 * Read mappings from a DOM {@link org.w3c.dom.Document}
 	 *
 	 * @param document The DOM document
 	 *
 	 * @return this (for method chaining purposes)
+	 *
+	 * @deprecated since 5.0.  Use one of the other methods for passing mapping source(s).
 	 */
 	@Deprecated
 	public MetadataSources addDocument(Document document) {
 		final Origin origin = new Origin( SourceType.DOM, Origin.UNKNOWN_FILE_PATH );
 		xmlBindings.add( new JaxpSourceXmlSource( origin, new DOMSource( document ) ).doBind( mappingsBinder ) );
 		return this;
 	}
 
 	/**
 	 * Read all mappings from a jar file.
 	 * <p/>
 	 * Assumes that any file named <tt>*.hbm.xml</tt> is a mapping document.
 	 *
 	 * @param jar a jar file
 	 *
 	 * @return this (for method chaining purposes)
 	 */
 	public MetadataSources addJar(File jar) {
 		LOG.debugf( "Seeking mapping documents in jar file : %s", jar.getName() );
 		final Origin origin = new Origin( SourceType.JAR, jar.getAbsolutePath() );
 		try {
 			JarFile jarFile = new JarFile( jar );
 			try {
 				Enumeration jarEntries = jarFile.entries();
 				while ( jarEntries.hasMoreElements() ) {
 					final ZipEntry zipEntry = (ZipEntry) jarEntries.nextElement();
 					if ( zipEntry.getName().endsWith( ".hbm.xml" ) ) {
 						LOG.tracef( "found mapping document : %s", zipEntry.getName() );
 						xmlBindings.add(
 								new JarFileEntryXmlSource( origin, jarFile, zipEntry ).doBind( mappingsBinder )
 						);
 					}
 				}
 			}
 			finally {
 				try {
 					jarFile.close();
 				}
 				catch ( Exception ignore ) {
 				}
 			}
 		}
 		catch ( IOException e ) {
 			throw new MappingNotFoundException( e, origin );
 		}
 		return this;
 	}
 
 	/**
 	 * Read all mapping documents from a directory tree.
 	 * <p/>
 	 * Assumes that any file named <tt>*.hbm.xml</tt> is a mapping document.
 	 *
 	 * @param dir The directory
 	 *
 	 * @return this (for method chaining purposes)
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems reading the jar file or
 	 * processing the contained mapping documents.
 	 */
 	public MetadataSources addDirectory(File dir) {
 		File[] files = dir.listFiles();
 		if ( files != null && files.length > 0 ) {
 			for ( File file : files ) {
 				if ( file.isDirectory() ) {
 					addDirectory( file );
 				}
 				else if ( file.getName().endsWith( ".hbm.xml" ) ) {
 					addFile( file );
 				}
 			}
 		}
 		return this;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/internal/InFlightMetadataCollectorImpl.java b/hibernate-core/src/main/java/org/hibernate/boot/internal/InFlightMetadataCollectorImpl.java
index 2e7d17961c..e151f5d7fd 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/internal/InFlightMetadataCollectorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/internal/InFlightMetadataCollectorImpl.java
@@ -503,1785 +503,1785 @@ public class InFlightMetadataCollectorImpl implements InFlightMetadataCollector
 		final IdentifierGeneratorDefinition old = idGeneratorDefinitionMap.put( generator.getName(), generator );
 		if ( old != null ) {
 			log.duplicateGeneratorName( old.getName() );
 		}
 	}
 
 	@Override
 	public void addDefaultIdentifierGenerator(IdentifierGeneratorDefinition generator) {
 		this.addIdentifierGenerator( generator );
 		defaultIdentifierGeneratorNames.add( generator.getName() );
 	}
 
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Named EntityGraph handling
 
 	@Override
 	public NamedEntityGraphDefinition getNamedEntityGraph(String name) {
 		return namedEntityGraphMap.get( name );
 	}
 
 	@Override
 	public Map<String, NamedEntityGraphDefinition> getNamedEntityGraphs() {
 		return namedEntityGraphMap;
 	}
 
 	@Override
 	public void addNamedEntityGraph(NamedEntityGraphDefinition definition) {
 		final String name = definition.getRegisteredName();
 		final NamedEntityGraphDefinition previous = namedEntityGraphMap.put( name, definition );
 		if ( previous != null ) {
 			throw new DuplicateMappingException(
 					DuplicateMappingException.Type.NAMED_ENTITY_GRAPH, name );
 		}
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Named query handling
 
 	public NamedQueryDefinition getNamedQueryDefinition(String name) {
 		if ( name == null ) {
 			throw new IllegalArgumentException( "null is not a valid query name" );
 		}
 		return namedQueryMap.get( name );
 	}
 
 	@Override
 	public java.util.Collection<NamedQueryDefinition> getNamedQueryDefinitions() {
 		return namedQueryMap.values();
 	}
 
 	@Override
 	public void addNamedQuery(NamedQueryDefinition def) {
 		if ( def == null ) {
 			throw new IllegalArgumentException( "Named query definition is null" );
 		}
 		else if ( def.getName() == null ) {
 			throw new IllegalArgumentException( "Named query definition name is null: " + def.getQueryString() );
 		}
 
 		if ( defaultNamedQueryNames.contains( def.getName() ) ) {
 			return;
 		}
 
 		applyNamedQuery( def.getName(), def );
 	}
 
 	private void applyNamedQuery(String name, NamedQueryDefinition query) {
 		checkQueryName( name );
 		namedQueryMap.put( name.intern(), query );
 	}
 
 	private void checkQueryName(String name) throws DuplicateMappingException {
 		if ( namedQueryMap.containsKey( name ) || namedNativeQueryMap.containsKey( name ) ) {
 			throw new DuplicateMappingException( DuplicateMappingException.Type.QUERY, name );
 		}
 	}
 
 	@Override
 	public void addDefaultQuery(NamedQueryDefinition queryDefinition) {
 		applyNamedQuery( queryDefinition.getName(), queryDefinition );
 		defaultNamedQueryNames.add( queryDefinition.getName() );
 	}
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Named native-query handling
 
 	@Override
 	public NamedSQLQueryDefinition getNamedNativeQueryDefinition(String name) {
 		return namedNativeQueryMap.get( name );
 	}
 
 	@Override
 	public java.util.Collection<NamedSQLQueryDefinition> getNamedNativeQueryDefinitions() {
 		return namedNativeQueryMap.values();
 	}
 
 	@Override
 	public void addNamedNativeQuery(NamedSQLQueryDefinition def) {
 		if ( def == null ) {
 			throw new IllegalArgumentException( "Named native query definition object is null" );
 		}
 		if ( def.getName() == null ) {
 			throw new IllegalArgumentException( "Named native query definition name is null: " + def.getQueryString() );
 		}
 
 		if ( defaultNamedNativeQueryNames.contains( def.getName() ) ) {
 			return;
 		}
 
 		applyNamedNativeQuery( def.getName(), def );
 	}
 
 	private void applyNamedNativeQuery(String name, NamedSQLQueryDefinition query) {
 		checkQueryName( name );
 		namedNativeQueryMap.put( name.intern(), query );
 	}
 
 	@Override
 	public void addDefaultNamedNativeQuery(NamedSQLQueryDefinition query) {
 		applyNamedNativeQuery( query.getName(), query );
 		defaultNamedNativeQueryNames.add( query.getName() );
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Named stored-procedure handling
 
 	@Override
 	public java.util.Collection<NamedProcedureCallDefinition> getNamedProcedureCallDefinitions() {
 		return namedProcedureCallMap.values();
 	}
 
 	@Override
 	public void addNamedProcedureCallDefinition(NamedProcedureCallDefinition definition) {
 		if ( definition == null ) {
 			throw new IllegalArgumentException( "Named query definition is null" );
 		}
 
 		final String name = definition.getRegisteredName();
 
 		if ( defaultNamedProcedureNames.contains( name ) ) {
 			return;
 		}
 
 		final NamedProcedureCallDefinition previous = namedProcedureCallMap.put( name, definition );
 		if ( previous != null ) {
 			throw new DuplicateMappingException( DuplicateMappingException.Type.PROCEDURE, name );
 		}
 	}
 
 	@Override
 	public void addDefaultNamedProcedureCallDefinition(NamedProcedureCallDefinition definition) {
 		addNamedProcedureCallDefinition( definition );
 		defaultNamedProcedureNames.add( definition.getRegisteredName() );
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// result-set mapping handling
 
 	@Override
 	public Map<String, ResultSetMappingDefinition> getResultSetMappingDefinitions() {
 		return sqlResultSetMappingMap;
 	}
 
 	@Override
 	public ResultSetMappingDefinition getResultSetMapping(String name) {
 		return sqlResultSetMappingMap.get( name );
 	}
 
 	@Override
 	public void addResultSetMapping(ResultSetMappingDefinition resultSetMappingDefinition) {
 		if ( resultSetMappingDefinition == null ) {
 			throw new IllegalArgumentException( "Result-set mapping was null" );
 		}
 
 		final String name = resultSetMappingDefinition.getName();
 		if ( name == null ) {
 			throw new IllegalArgumentException( "Result-set mapping name is null: " + resultSetMappingDefinition );
 		}
 
 		if ( defaultSqlResultSetMappingNames.contains( name ) ) {
 			return;
 		}
 
 		applyResultSetMapping( resultSetMappingDefinition );
 	}
 
 	public void applyResultSetMapping(ResultSetMappingDefinition resultSetMappingDefinition) {
 		final ResultSetMappingDefinition old = sqlResultSetMappingMap.put(
 				resultSetMappingDefinition.getName(),
 				resultSetMappingDefinition
 		);
 		if ( old != null ) {
 			throw new DuplicateMappingException(
 					DuplicateMappingException.Type.RESULT_SET_MAPPING,
 					resultSetMappingDefinition.getName()
 			);
 		}
 	}
 
 	@Override
 	public void addDefaultResultSetMapping(ResultSetMappingDefinition definition) {
 		final String name = definition.getName();
 		if ( !defaultSqlResultSetMappingNames.contains( name ) && sqlResultSetMappingMap.containsKey( name ) ) {
 			sqlResultSetMappingMap.remove( name );
 		}
 		applyResultSetMapping( definition );
 		defaultSqlResultSetMappingNames.add( name );
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// imports
 
 	@Override
 	public Map<String,String> getImports() {
 		return imports;
 	}
 
 	@Override
 	public void addImport(String importName, String entityName) {
 		if ( importName == null || entityName == null ) {
 			throw new IllegalArgumentException( "Import name or entity name is null" );
 		}
 		log.tracev( "Import: {0} -> {1}", importName, entityName );
 		String old = imports.put( importName, entityName );
 		if ( old != null ) {
 			log.debug( "import name [" + importName + "] overrode previous [{" + old + "}]" );
 		}
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Table handling
 
 	@Override
 	public Table addTable(
 			String schemaName,
 			String catalogName,
 			String name,
 			String subselectFragment,
 			boolean isAbstract) {
 		final Schema schema = getDatabase().locateSchema(
 				getDatabase().toIdentifier( catalogName ),
 				getDatabase().toIdentifier( schemaName )
 		);
 
 		// annotation binding depends on the "table name" for @Subselect bindings
 		// being set into the generated table (mainly to avoid later NPE), but for now we need to keep that :(
 		final Identifier logicalName;
 		if ( name != null ) {
 			logicalName = getDatabase().toIdentifier( name );
 		}
 		else {
 			logicalName = null;
 		}
 
 		if ( subselectFragment != null ) {
 			return new Table( schema, logicalName, subselectFragment, isAbstract );
 		}
 		else {
 			Table table = schema.locateTable( logicalName );
 			if ( table != null ) {
 				if ( !isAbstract ) {
 					table.setAbstract( false );
 				}
 				return table;
 			}
 			return schema.createTable( logicalName, isAbstract );
 		}
 	}
 
 	@Override
 	public Table addDenormalizedTable(
 			String schemaName,
 			String catalogName,
 			String name,
 			boolean isAbstract,
 			String subselectFragment,
 			Table includedTable) throws DuplicateMappingException {
 		final Schema schema = getDatabase().locateSchema(
 				getDatabase().toIdentifier( catalogName ),
 				getDatabase().toIdentifier( schemaName )
 		);
 
 		// annotation binding depends on the "table name" for @Subselect bindings
 		// being set into the generated table (mainly to avoid later NPE), but for now we need to keep that :(
 		final Identifier logicalName;
 		if ( name != null ) {
 			logicalName = getDatabase().toIdentifier( name );
 		}
 		else {
 			logicalName = null;
 		}
 
 		if ( subselectFragment != null ) {
 			return new DenormalizedTable( schema, logicalName, subselectFragment, isAbstract, includedTable );
 		}
 		else {
 			Table table = schema.locateTable( logicalName );
 			if ( table != null ) {
 				throw new DuplicateMappingException( DuplicateMappingException.Type.TABLE, logicalName.toString() );
 			}
 			else {
 				table = schema.createDenormalizedTable( logicalName, isAbstract, includedTable );
 			}
 			return table;
 		}
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Mapping impl
 
 	@Override
 	public org.hibernate.type.Type getIdentifierType(String entityName) throws MappingException {
 		final PersistentClass pc = entityBindingMap.get( entityName );
 		if ( pc == null ) {
 			throw new MappingException( "persistent class not known: " + entityName );
 		}
 		return pc.getIdentifier().getType();
 	}
 
 	@Override
 	public String getIdentifierPropertyName(String entityName) throws MappingException {
 		final PersistentClass pc = entityBindingMap.get( entityName );
 		if ( pc == null ) {
 			throw new MappingException( "persistent class not known: " + entityName );
 		}
 		if ( !pc.hasIdentifierProperty() ) {
 			return null;
 		}
 		return pc.getIdentifierProperty().getName();
 	}
 
 	@Override
 	public org.hibernate.type.Type getReferencedPropertyType(String entityName, String propertyName) throws MappingException {
 		final PersistentClass pc = entityBindingMap.get( entityName );
 		if ( pc == null ) {
 			throw new MappingException( "persistent class not known: " + entityName );
 		}
 		Property prop = pc.getReferencedProperty( propertyName );
 		if ( prop == null ) {
 			throw new MappingException(
 					"property not known: " +
 							entityName + '.' + propertyName
 			);
 		}
 		return prop.getType();
 	}
 
 
 	private Map<Identifier,Identifier> logicalToPhysicalTableNameMap = new HashMap<Identifier, Identifier>();
 	private Map<Identifier,Identifier> physicalToLogicalTableNameMap = new HashMap<Identifier, Identifier>();
 
 	@Override
 	public void addTableNameBinding(Identifier logicalName, Table table) {
 		logicalToPhysicalTableNameMap.put( logicalName, table.getNameIdentifier() );
 		physicalToLogicalTableNameMap.put( table.getNameIdentifier(), logicalName );
 	}
 
 	@Override
 	public void addTableNameBinding(String schema, String catalog, String logicalName, String realTableName, Table denormalizedSuperTable) {
 		final Identifier logicalNameIdentifier = getDatabase().toIdentifier( logicalName );
 		final Identifier physicalNameIdentifier = getDatabase().toIdentifier( realTableName );
 
 		logicalToPhysicalTableNameMap.put( logicalNameIdentifier, physicalNameIdentifier );
 		physicalToLogicalTableNameMap.put( physicalNameIdentifier, logicalNameIdentifier );
 	}
 
 	@Override
 	public String getLogicalTableName(Table ownerTable) {
 		final Identifier logicalName = physicalToLogicalTableNameMap.get( ownerTable.getNameIdentifier() );
 		if ( logicalName == null ) {
 			throw new MappingException( "Unable to find physical table: " + ownerTable.getName() );
 		}
 		return logicalName.render();
 	}
 
 	@Override
 	public String getPhysicalTableName(Identifier logicalName) {
 		final Identifier physicalName = logicalToPhysicalTableNameMap.get( logicalName );
 		return physicalName == null ? null : physicalName.render();
 	}
 
 	@Override
 	public String getPhysicalTableName(String logicalName) {
 		return getPhysicalTableName( getDatabase().toIdentifier( logicalName ) );
 	}
 
 	/**
 	 * Internal struct used to maintain xref between physical and logical column
 	 * names for a table.  Mainly this is used to ensure that the defined NamingStrategy
 	 * is not creating duplicate column names.
 	 */
 	private class TableColumnNameBinding implements Serializable {
 		private final String tableName;
 		private Map<Identifier, String> logicalToPhysical = new HashMap<Identifier,String>();
 		private Map<String, Identifier> physicalToLogical = new HashMap<String,Identifier>();
 
 		private TableColumnNameBinding(String tableName) {
 			this.tableName = tableName;
 		}
 
 		public void addBinding(Identifier logicalName, Column physicalColumn) {
 			final String physicalNameString = physicalColumn.getQuotedName( getDatabase().getJdbcEnvironment().getDialect() );
 
 			bindLogicalToPhysical( logicalName, physicalNameString );
 			bindPhysicalToLogical( logicalName, physicalNameString );
 		}
 
 		private void bindLogicalToPhysical(Identifier logicalName, String physicalName) throws DuplicateMappingException {
 			final String existingPhysicalNameMapping = logicalToPhysical.put( logicalName, physicalName );
 			if ( existingPhysicalNameMapping != null ) {
 				final boolean areSame = logicalName.isQuoted()
 						? physicalName.equals( existingPhysicalNameMapping )
 						: physicalName.equalsIgnoreCase( existingPhysicalNameMapping );
 				if ( !areSame ) {
 					throw new DuplicateMappingException(
 							String.format(
 									Locale.ENGLISH,
 									"Table [%s] contains logical column name [%s] referring to multiple physical " +
 											"column names: [%s], [%s]",
 									tableName,
 									logicalName,
 									existingPhysicalNameMapping,
 									physicalName
 							),
 							DuplicateMappingException.Type.COLUMN_BINDING,
 							tableName + "." + logicalName
 					);
 				}
 			}
 		}
 
 		private void bindPhysicalToLogical(Identifier logicalName, String physicalName) throws DuplicateMappingException {
 			final Identifier existingLogicalName = physicalToLogical.put( physicalName, logicalName );
 			if ( existingLogicalName != null && ! existingLogicalName.equals( logicalName ) ) {
 				throw new DuplicateMappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Table [%s] contains physical column name [%s] referred to by multiple physical " +
 										"column names: [%s], [%s]",
 								tableName,
 								physicalName,
 								logicalName,
 								existingLogicalName
 						),
 						DuplicateMappingException.Type.COLUMN_BINDING,
 						tableName + "." + physicalName
 				);
 			}
 		}
 	}
 
 	private Map<Table,TableColumnNameBinding> columnNameBindingByTableMap;
 
 	@Override
 	public void addColumnNameBinding(Table table, String logicalName, Column column) throws DuplicateMappingException {
 		addColumnNameBinding( table, getDatabase().toIdentifier( logicalName ), column );
 	}
 
 	@Override
 	public void addColumnNameBinding(Table table, Identifier logicalName, Column column) throws DuplicateMappingException {
 		TableColumnNameBinding binding = null;
 
 		if ( columnNameBindingByTableMap == null ) {
 			columnNameBindingByTableMap = new HashMap<Table, TableColumnNameBinding>();
 		}
 		else {
 			binding = columnNameBindingByTableMap.get( table );
 		}
 
 		if ( binding == null ) {
 			binding = new TableColumnNameBinding( table.getName() );
 			columnNameBindingByTableMap.put( table, binding );
 		}
 
 		binding.addBinding( logicalName, column );
 	}
 
 	@Override
 	public String getPhysicalColumnName(Table table, String logicalName) throws MappingException {
 		return getPhysicalColumnName( table, getDatabase().toIdentifier( logicalName ) );
 	}
 
 	@Override
 	public String getPhysicalColumnName(Table table, Identifier logicalName) throws MappingException {
 		if ( logicalName == null ) {
 			throw new MappingException( "Logical column name cannot be null" );
 		}
 
 		Table currentTable = table;
 		String physicalName = null;
 
 		while ( currentTable != null ) {
 			final TableColumnNameBinding binding = columnNameBindingByTableMap.get( currentTable );
 			if ( binding != null ) {
 				physicalName = binding.logicalToPhysical.get( logicalName );
 				if ( physicalName != null ) {
 					break;
 				}
 			}
 
 			if ( DenormalizedTable.class.isInstance( currentTable ) ) {
 				currentTable = ( (DenormalizedTable) currentTable ).getIncludedTable();
 			}
 			else {
 				currentTable = null;
 			}
 		}
 
 		if ( physicalName == null ) {
 			throw new MappingException(
 					"Unable to find column with logical name " + logicalName.render() + " in table " + table.getName()
 			);
 		}
 		return physicalName;
 	}
 
 	@Override
 	public String getLogicalColumnName(Table table, String physicalName) throws MappingException {
 		return getLogicalColumnName( table, getDatabase().toIdentifier( physicalName ) );
 	}
 
 
 	@Override
 	public String getLogicalColumnName(Table table, Identifier physicalName) throws MappingException {
 		final String physicalNameString = physicalName.render( getDatabase().getJdbcEnvironment().getDialect() );
 		Identifier logicalName = null;
 
 		Table currentTable = table;
 		while ( currentTable != null ) {
 			final TableColumnNameBinding binding = columnNameBindingByTableMap.get( currentTable );
 
 			if ( binding != null ) {
 				logicalName = binding.physicalToLogical.get( physicalNameString );
 				if ( logicalName != null ) {
 					break;
 				}
 			}
 
 			if ( DenormalizedTable.class.isInstance( currentTable ) ) {
 				currentTable = ( (DenormalizedTable) currentTable ).getIncludedTable();
 			}
 			else {
 				currentTable = null;
 			}
 		}
 
 		if ( logicalName == null ) {
 			throw new MappingException(
 					"Unable to find column with physical name " + physicalNameString + " in table " + table.getName()
 			);
 		}
 		return logicalName.render();
 	}
 
 	@Override
 	public void addAuxiliaryDatabaseObject(AuxiliaryDatabaseObject auxiliaryDatabaseObject) {
 		getDatabase().addAuxiliaryDatabaseObject( auxiliaryDatabaseObject );
 	}
 
 	private final Map<String,AnnotatedClassType> annotatedClassTypeMap = new HashMap<String, AnnotatedClassType>();
 
 	@Override
 	public AnnotatedClassType getClassType(XClass clazz) {
 		AnnotatedClassType type = annotatedClassTypeMap.get( clazz.getName() );
 		if ( type == null ) {
 			return addClassType( clazz );
 		}
 		else {
 			return type;
 		}
 	}
 
 	@Override
 	public AnnotatedClassType addClassType(XClass clazz) {
 		AnnotatedClassType type;
 		if ( clazz.isAnnotationPresent( Entity.class ) ) {
 			type = AnnotatedClassType.ENTITY;
 		}
 		else if ( clazz.isAnnotationPresent( Embeddable.class ) ) {
 			type = AnnotatedClassType.EMBEDDABLE;
 		}
 		else if ( clazz.isAnnotationPresent( javax.persistence.MappedSuperclass.class ) ) {
 			type = AnnotatedClassType.EMBEDDABLE_SUPERCLASS;
 		}
 		else {
 			type = AnnotatedClassType.NONE;
 		}
 		annotatedClassTypeMap.put( clazz.getName(), type );
 		return type;
 	}
 
 	@Override
 	public void addAnyMetaDef(AnyMetaDef defAnn) {
 		if ( anyMetaDefs == null ) {
 			anyMetaDefs = new HashMap<String, AnyMetaDef>();
 		}
 		else {
 			if ( anyMetaDefs.containsKey( defAnn.name() ) ) {
 				throw new AnnotationException( "Two @AnyMetaDef with the same name defined: " + defAnn.name() );
 			}
 		}
 
 		anyMetaDefs.put( defAnn.name(), defAnn );
 	}
 
 	@Override
 	public AnyMetaDef getAnyMetaDef(String name) {
 		if ( anyMetaDefs == null ) {
 			return null;
 		}
 		return anyMetaDefs.get( name );
 	}
 
 
 	@Override
 	public void addMappedSuperclass(Class type, MappedSuperclass mappedSuperclass) {
 		if ( mappedSuperClasses == null ) {
 			mappedSuperClasses = new HashMap<Class, MappedSuperclass>();
 		}
 		mappedSuperClasses.put( type, mappedSuperclass );
 	}
 
 	@Override
 	public MappedSuperclass getMappedSuperclass(Class type) {
 		if ( mappedSuperClasses == null ) {
 			return null;
 		}
 		return mappedSuperClasses.get( type );
 	}
 
 	@Override
 	public PropertyData getPropertyAnnotatedWithMapsId(XClass entityType, String propertyName) {
 		if ( propertiesAnnotatedWithMapsId == null ) {
 			return null;
 		}
 
 		final Map<String, PropertyData> map = propertiesAnnotatedWithMapsId.get( entityType );
 		return map == null ? null : map.get( propertyName );
 	}
 
 	@Override
 	public void addPropertyAnnotatedWithMapsId(XClass entityType, PropertyData property) {
 		if ( propertiesAnnotatedWithMapsId == null ) {
 			propertiesAnnotatedWithMapsId = new HashMap<XClass, Map<String, PropertyData>>();
 		}
 
 		Map<String, PropertyData> map = propertiesAnnotatedWithMapsId.get( entityType );
 		if ( map == null ) {
 			map = new HashMap<String, PropertyData>();
 			propertiesAnnotatedWithMapsId.put( entityType, map );
 		}
 		map.put( property.getProperty().getAnnotation( MapsId.class ).value(), property );
 	}
 
 	@Override
 	public void addPropertyAnnotatedWithMapsIdSpecj(XClass entityType, PropertyData property, String mapsIdValue) {
 		if ( propertiesAnnotatedWithMapsId == null ) {
 			propertiesAnnotatedWithMapsId = new HashMap<XClass, Map<String, PropertyData>>();
 		}
 
 		Map<String, PropertyData> map = propertiesAnnotatedWithMapsId.get( entityType );
 		if ( map == null ) {
 			map = new HashMap<String, PropertyData>();
 			propertiesAnnotatedWithMapsId.put( entityType, map );
 		}
 		map.put( mapsIdValue, property );
 	}
 
 	@Override
 	public PropertyData getPropertyAnnotatedWithIdAndToOne(XClass entityType, String propertyName) {
 		if ( propertiesAnnotatedWithIdAndToOne == null ) {
 			return null;
 		}
 
 		final Map<String, PropertyData> map = propertiesAnnotatedWithIdAndToOne.get( entityType );
 		return map == null ? null : map.get( propertyName );
 	}
 
 	@Override
 	public void addToOneAndIdProperty(XClass entityType, PropertyData property) {
 		if ( propertiesAnnotatedWithIdAndToOne == null ) {
 			propertiesAnnotatedWithIdAndToOne = new HashMap<XClass, Map<String, PropertyData>>();
 		}
 
 		Map<String, PropertyData> map = propertiesAnnotatedWithIdAndToOne.get( entityType );
 		if ( map == null ) {
 			map = new HashMap<String, PropertyData>();
 			propertiesAnnotatedWithIdAndToOne.put( entityType, map );
 		}
 		map.put( property.getPropertyName(), property );
 	}
 
 	@Override
 	public void addMappedBy(String entityName, String propertyName, String inversePropertyName) {
 		if ( mappedByResolver == null ) {
 			mappedByResolver = new HashMap<String, String>();
 		}
 		mappedByResolver.put( entityName + "." + propertyName, inversePropertyName );
 	}
 
 	@Override
 	public String getFromMappedBy(String entityName, String propertyName) {
 		if ( mappedByResolver == null ) {
 			return null;
 		}
 		return mappedByResolver.get( entityName + "." + propertyName );
 	}
 
 	@Override
 	public void addPropertyReferencedAssociation(String entityName, String propertyName, String propertyRef) {
 		if ( propertyRefResolver == null ) {
 			propertyRefResolver = new HashMap<String, String>();
 		}
 		propertyRefResolver.put( entityName + "." + propertyName, propertyRef );
 	}
 
 	@Override
 	public String getPropertyReferencedAssociation(String entityName, String propertyName) {
 		if ( propertyRefResolver == null ) {
 			return null;
 		}
 		return propertyRefResolver.get( entityName + "." + propertyName );
 	}
 
 	private static class DelayedPropertyReferenceHandlerAnnotationImpl implements DelayedPropertyReferenceHandler {
 		public final String referencedClass;
 		public final String propertyName;
 		public final boolean unique;
 
 		public DelayedPropertyReferenceHandlerAnnotationImpl(String referencedClass, String propertyName, boolean unique) {
 			this.referencedClass = referencedClass;
 			this.propertyName = propertyName;
 			this.unique = unique;
 		}
 
 		@Override
 		public void process(InFlightMetadataCollector metadataCollector) {
 			final PersistentClass clazz = metadataCollector.getEntityBinding( referencedClass );
 			if ( clazz == null ) {
 				throw new MappingException( "property-ref to unmapped class: " + referencedClass );
 			}
 
 			final Property prop = clazz.getReferencedProperty( propertyName );
 			if ( unique ) {
 				( (SimpleValue) prop.getValue() ).setAlternateUniqueKey( true );
 			}
 		}
 	}
 
 	@Override
 	public void addPropertyReference(String referencedClass, String propertyName) {
 		addDelayedPropertyReferenceHandler(
 				new DelayedPropertyReferenceHandlerAnnotationImpl( referencedClass, propertyName, false )
 		);
 	}
 
 	@Override
 	public void addDelayedPropertyReferenceHandler(DelayedPropertyReferenceHandler handler) {
 		if ( delayedPropertyReferenceHandlers == null ) {
 			delayedPropertyReferenceHandlers = new HashSet<DelayedPropertyReferenceHandler>();
 		}
 		delayedPropertyReferenceHandlers.add( handler );
 	}
 
 	@Override
 	public void addUniquePropertyReference(String referencedClass, String propertyName) {
 		addDelayedPropertyReferenceHandler(
 				new DelayedPropertyReferenceHandlerAnnotationImpl( referencedClass, propertyName, true )
 		);
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public void addUniqueConstraints(Table table, List uniqueConstraints) {
 		List<UniqueConstraintHolder> constraintHolders = new ArrayList<UniqueConstraintHolder>(
 				CollectionHelper.determineProperSizing( uniqueConstraints.size() )
 		);
 
 		int keyNameBase = determineCurrentNumberOfUniqueConstraintHolders( table );
 		for ( String[] columns : ( List<String[]> ) uniqueConstraints ) {
 			final String keyName = "key" + keyNameBase++;
 			constraintHolders.add(
 					new UniqueConstraintHolder().setName( keyName ).setColumns( columns )
 			);
 		}
 		addUniqueConstraintHolders( table, constraintHolders );
 	}
 
 	private int determineCurrentNumberOfUniqueConstraintHolders(Table table) {
 		List currentHolders = uniqueConstraintHoldersByTable == null ? null : uniqueConstraintHoldersByTable.get( table );
 		return currentHolders == null
 				? 0
 				: currentHolders.size();
 	}
 
 	@Override
 	public void addUniqueConstraintHolders(Table table, List<UniqueConstraintHolder> uniqueConstraintHolders) {
 		List<UniqueConstraintHolder> holderList = null;
 
 		if ( uniqueConstraintHoldersByTable == null ) {
 			uniqueConstraintHoldersByTable = new HashMap<Table, List<UniqueConstraintHolder>>();
 		}
 		else {
 			holderList = uniqueConstraintHoldersByTable.get( table );
 		}
 
 		if ( holderList == null ) {
 			holderList = new ArrayList<UniqueConstraintHolder>();
 			uniqueConstraintHoldersByTable.put( table, holderList );
 		}
 
 		holderList.addAll( uniqueConstraintHolders );
 	}
 
 	@Override
 	public void addJpaIndexHolders(Table table, List<JPAIndexHolder> holders) {
 		List<JPAIndexHolder> holderList = null;
 
 		if ( jpaIndexHoldersByTable == null ) {
 			jpaIndexHoldersByTable = new HashMap<Table, List<JPAIndexHolder>>();
 		}
 		else {
 			holderList = jpaIndexHoldersByTable.get( table );
 		}
 
 		if ( holderList == null ) {
 			holderList = new ArrayList<JPAIndexHolder>();
 			jpaIndexHoldersByTable.put( table, holderList );
 		}
 
 		holderList.addAll( holders );
 	}
 
 	private final Map<String,EntityTableXrefImpl> entityTableXrefMap = new HashMap<String, EntityTableXrefImpl>();
 
 	@Override
 	public EntityTableXref getEntityTableXref(String entityName) {
 		return entityTableXrefMap.get( entityName );
 	}
 
 	@Override
 	public EntityTableXref addEntityTableXref(
 			String entityName,
 			Identifier primaryTableLogicalName,
 			Table primaryTable,
 			EntityTableXref superEntityTableXref) {
 		final EntityTableXrefImpl entry = new EntityTableXrefImpl(
 				primaryTableLogicalName,
 				primaryTable,
 				(EntityTableXrefImpl) superEntityTableXref
 		);
 
 		entityTableXrefMap.put( entityName, entry );
 
 		return entry;
 	}
 
 	@Override
 	public Map<String, Join> getJoins(String entityName) {
 		EntityTableXrefImpl xrefEntry = entityTableXrefMap.get( entityName );
 		return xrefEntry == null ? null : xrefEntry.secondaryTableJoinMap;
 	}
 
 	private final class EntityTableXrefImpl implements EntityTableXref {
 		private final Identifier primaryTableLogicalName;
 		private final Table primaryTable;
 		private EntityTableXrefImpl superEntityTableXref;
 
 		//annotations needs a Map<String,Join>
 		//private Map<Identifier,Join> secondaryTableJoinMap;
 		private Map<String,Join> secondaryTableJoinMap;
 
 		public EntityTableXrefImpl(Identifier primaryTableLogicalName, Table primaryTable, EntityTableXrefImpl superEntityTableXref) {
 			this.primaryTableLogicalName = primaryTableLogicalName;
 			this.primaryTable = primaryTable;
 			this.superEntityTableXref = superEntityTableXref;
 		}
 
 		@Override
 		public void addSecondaryTable(LocalMetadataBuildingContext buildingContext, Identifier logicalName, Join secondaryTableJoin) {
 			if ( Identifier.areEqual( primaryTableLogicalName, logicalName ) ) {
 				throw new org.hibernate.boot.MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Attempt to add secondary table with same name as primary table [%s]",
 								primaryTableLogicalName
 						),
 						buildingContext.getOrigin()
 				);
 			}
 
 
 			if ( secondaryTableJoinMap == null ) {
 				//secondaryTableJoinMap = new HashMap<Identifier,Join>();
 				//secondaryTableJoinMap.put( logicalName, secondaryTableJoin );
 				secondaryTableJoinMap = new HashMap<String,Join>();
 				secondaryTableJoinMap.put( logicalName.getCanonicalName(), secondaryTableJoin );
 			}
 			else {
 				//final Join existing = secondaryTableJoinMap.put( logicalName, secondaryTableJoin );
 				final Join existing = secondaryTableJoinMap.put( logicalName.getCanonicalName(), secondaryTableJoin );
 
 				if ( existing != null ) {
 					throw new org.hibernate.boot.MappingException(
 							String.format(
 									Locale.ENGLISH,
 									"Added secondary table with same name [%s]",
 									logicalName
 							),
 							buildingContext.getOrigin()
 					);
 				}
 			}
 		}
 
 		@Override
 		public void addSecondaryTable(Identifier logicalName, Join secondaryTableJoin) {
 			if ( Identifier.areEqual( primaryTableLogicalName, logicalName ) ) {
 				throw new DuplicateSecondaryTableException( logicalName );
 			}
 
 
 			if ( secondaryTableJoinMap == null ) {
 				//secondaryTableJoinMap = new HashMap<Identifier,Join>();
 				//secondaryTableJoinMap.put( logicalName, secondaryTableJoin );
 				secondaryTableJoinMap = new HashMap<String,Join>();
 				secondaryTableJoinMap.put( logicalName.getCanonicalName(), secondaryTableJoin );
 			}
 			else {
 				//final Join existing = secondaryTableJoinMap.put( logicalName, secondaryTableJoin );
 				final Join existing = secondaryTableJoinMap.put( logicalName.getCanonicalName(), secondaryTableJoin );
 
 				if ( existing != null ) {
 					throw new DuplicateSecondaryTableException( logicalName );
 				}
 			}
 		}
 
 		@Override
 		public Table getPrimaryTable() {
 			return primaryTable;
 		}
 
 		@Override
 		public Table resolveTable(Identifier tableName) {
 			if ( tableName == null ) {
 				return primaryTable;
 			}
 
 			if ( Identifier.areEqual( primaryTableLogicalName, tableName ) ) {
 				return primaryTable;
 			}
 
 			Join secondaryTableJoin = null;
 			if ( secondaryTableJoinMap != null ) {
 				//secondaryTableJoin = secondaryTableJoinMap.get( tableName );
 				secondaryTableJoin = secondaryTableJoinMap.get( tableName.getCanonicalName() );
 			}
 
 			if ( secondaryTableJoin != null ) {
 				return secondaryTableJoin.getTable();
 			}
 
 			if ( superEntityTableXref != null ) {
 				return superEntityTableXref.resolveTable( tableName );
 			}
 
 			return null;
 		}
 
 		public Join locateJoin(Identifier tableName) {
 			if ( tableName == null ) {
 				return null;
 			}
 
 			Join join = null;
 			if ( secondaryTableJoinMap != null ) {
 				join = secondaryTableJoinMap.get( tableName.getCanonicalName() );
 			}
 
 			if ( join != null ) {
 				return join;
 			}
 
 			if ( superEntityTableXref != null ) {
 				return superEntityTableXref.locateJoin( tableName );
 			}
 
 			return null;
 		}
 	}
 
-	private ArrayList<PkDrivenByDefaultMapsIdSecondPass> pkDrivenByDefaultMapsId_secondPassList;
-	private ArrayList<SetSimpleValueTypeSecondPass> setSimpleValueType_secondPassList;
-	private ArrayList<CopyIdentifierComponentSecondPass> copyIdentifierComponent_secondPasList;
-	private ArrayList<FkSecondPass> fk_secondPassList;
-	private ArrayList<CreateKeySecondPass> createKey_secondPasList;
-	private ArrayList<SecondaryTableSecondPass> secondaryTable_secondPassList;
-	private ArrayList<QuerySecondPass> query_secondPassList;
-	private ArrayList<ConstraintSecondPass> constraint_secondPassList;
-	private ArrayList<ImplicitColumnNamingSecondPass> implicitColumnNaming_secondPassList;
+	private ArrayList<PkDrivenByDefaultMapsIdSecondPass> pkDrivenByDefaultMapsIdSecondPassList;
+	private ArrayList<SetSimpleValueTypeSecondPass> setSimpleValueTypeSecondPassList;
+	private ArrayList<CopyIdentifierComponentSecondPass> copyIdentifierComponentSecondPasList;
+	private ArrayList<FkSecondPass> fkSecondPassList;
+	private ArrayList<CreateKeySecondPass> createKeySecondPasList;
+	private ArrayList<SecondaryTableSecondPass> secondaryTableSecondPassList;
+	private ArrayList<QuerySecondPass> querySecondPassList;
+	private ArrayList<ConstraintSecondPass> constraintSecondPassList;
+	private ArrayList<ImplicitColumnNamingSecondPass> implicitColumnNamingSecondPassList;
 
-	private ArrayList<SecondPass> general_secondPassList;
+	private ArrayList<SecondPass> generalSecondPassList;
 
 	@Override
 	public void addSecondPass(SecondPass secondPass) {
 		addSecondPass( secondPass, false );
 	}
 
 	@Override
 	public void addSecondPass(SecondPass secondPass, boolean onTopOfTheQueue) {
 		if ( secondPass instanceof PkDrivenByDefaultMapsIdSecondPass ) {
 			addPkDrivenByDefaultMapsIdSecondPass( (PkDrivenByDefaultMapsIdSecondPass) secondPass, onTopOfTheQueue );
 		}
 		else if ( secondPass instanceof SetSimpleValueTypeSecondPass ) {
 			addSetSimpleValueTypeSecondPass( (SetSimpleValueTypeSecondPass) secondPass, onTopOfTheQueue );
 		}
 		else if ( secondPass instanceof CopyIdentifierComponentSecondPass ) {
 			addCopyIdentifierComponentSecondPass( (CopyIdentifierComponentSecondPass) secondPass, onTopOfTheQueue );
 		}
 		else if ( secondPass instanceof FkSecondPass ) {
 			addFkSecondPass( (FkSecondPass) secondPass, onTopOfTheQueue );
 		}
 		else if ( secondPass instanceof CreateKeySecondPass ) {
 			addCreateKeySecondPass( (CreateKeySecondPass) secondPass, onTopOfTheQueue );
 		}
 		else if ( secondPass instanceof SecondaryTableSecondPass ) {
 			addSecondaryTableSecondPass( (SecondaryTableSecondPass) secondPass, onTopOfTheQueue );
 		}
 		else if ( secondPass instanceof QuerySecondPass ) {
 			addQuerySecondPass( (QuerySecondPass) secondPass, onTopOfTheQueue );
 		}
 		else if ( secondPass instanceof ConstraintSecondPass ) {
 			addConstraintSecondPass( ( ConstraintSecondPass) secondPass, onTopOfTheQueue );
 		}
 		else if ( secondPass instanceof ImplicitColumnNamingSecondPass ) {
 			addImplicitColumnNamingSecondPass( (ImplicitColumnNamingSecondPass) secondPass );
 		}
 		else {
 			// add to the general SecondPass list
-			if ( general_secondPassList == null ) {
-				general_secondPassList = new ArrayList<SecondPass>();
+			if ( generalSecondPassList == null ) {
+				generalSecondPassList = new ArrayList<SecondPass>();
 			}
-			addSecondPass( secondPass, general_secondPassList, onTopOfTheQueue );
+			addSecondPass( secondPass, generalSecondPassList, onTopOfTheQueue );
 		}
 	}
 
 	private void addPkDrivenByDefaultMapsIdSecondPass(
 			PkDrivenByDefaultMapsIdSecondPass secondPass,
 			boolean onTopOfTheQueue) {
-		if ( pkDrivenByDefaultMapsId_secondPassList == null ) {
-			pkDrivenByDefaultMapsId_secondPassList = new ArrayList<PkDrivenByDefaultMapsIdSecondPass>();
+		if ( pkDrivenByDefaultMapsIdSecondPassList == null ) {
+			pkDrivenByDefaultMapsIdSecondPassList = new ArrayList<PkDrivenByDefaultMapsIdSecondPass>();
 		}
-		addSecondPass( secondPass, pkDrivenByDefaultMapsId_secondPassList, onTopOfTheQueue );
+		addSecondPass( secondPass, pkDrivenByDefaultMapsIdSecondPassList, onTopOfTheQueue );
 	}
 
 	private <T extends SecondPass> void addSecondPass(T secondPass, ArrayList<T> secondPassList, boolean onTopOfTheQueue) {
 		if ( onTopOfTheQueue ) {
 			secondPassList.add( 0, secondPass );
 		}
 		else {
 			secondPassList.add( secondPass );
 		}
 	}
 
 	private void addSetSimpleValueTypeSecondPass(SetSimpleValueTypeSecondPass secondPass, boolean onTopOfTheQueue) {
-		if ( setSimpleValueType_secondPassList == null ) {
-			setSimpleValueType_secondPassList = new ArrayList<SetSimpleValueTypeSecondPass>();
+		if ( setSimpleValueTypeSecondPassList == null ) {
+			setSimpleValueTypeSecondPassList = new ArrayList<SetSimpleValueTypeSecondPass>();
 		}
-		addSecondPass( secondPass, setSimpleValueType_secondPassList, onTopOfTheQueue );
+		addSecondPass( secondPass, setSimpleValueTypeSecondPassList, onTopOfTheQueue );
 	}
 
 	private void addCopyIdentifierComponentSecondPass(
 			CopyIdentifierComponentSecondPass secondPass,
 			boolean onTopOfTheQueue) {
-		if ( copyIdentifierComponent_secondPasList == null ) {
-			copyIdentifierComponent_secondPasList = new ArrayList<CopyIdentifierComponentSecondPass>();
+		if ( copyIdentifierComponentSecondPasList == null ) {
+			copyIdentifierComponentSecondPasList = new ArrayList<CopyIdentifierComponentSecondPass>();
 		}
-		addSecondPass( secondPass, copyIdentifierComponent_secondPasList, onTopOfTheQueue );
+		addSecondPass( secondPass, copyIdentifierComponentSecondPasList, onTopOfTheQueue );
 	}
 
 	private void addFkSecondPass(FkSecondPass secondPass, boolean onTopOfTheQueue) {
-		if ( fk_secondPassList == null ) {
-			fk_secondPassList = new ArrayList<FkSecondPass>();
+		if ( fkSecondPassList == null ) {
+			fkSecondPassList = new ArrayList<FkSecondPass>();
 		}
-		addSecondPass( secondPass, fk_secondPassList, onTopOfTheQueue );
+		addSecondPass( secondPass, fkSecondPassList, onTopOfTheQueue );
 	}
 
 	private void addCreateKeySecondPass(CreateKeySecondPass secondPass, boolean onTopOfTheQueue) {
-		if ( createKey_secondPasList == null ) {
-			createKey_secondPasList = new ArrayList<CreateKeySecondPass>();
+		if ( createKeySecondPasList == null ) {
+			createKeySecondPasList = new ArrayList<CreateKeySecondPass>();
 		}
-		addSecondPass( secondPass, createKey_secondPasList, onTopOfTheQueue );
+		addSecondPass( secondPass, createKeySecondPasList, onTopOfTheQueue );
 	}
 
 	private void addSecondaryTableSecondPass(SecondaryTableSecondPass secondPass, boolean onTopOfTheQueue) {
-		if ( secondaryTable_secondPassList == null ) {
-			secondaryTable_secondPassList = new ArrayList<SecondaryTableSecondPass>();
+		if ( secondaryTableSecondPassList == null ) {
+			secondaryTableSecondPassList = new ArrayList<SecondaryTableSecondPass>();
 		}
-		addSecondPass( secondPass, secondaryTable_secondPassList, onTopOfTheQueue );
+		addSecondPass( secondPass, secondaryTableSecondPassList, onTopOfTheQueue );
 	}
 
 	private void addQuerySecondPass(QuerySecondPass secondPass, boolean onTopOfTheQueue) {
-		if ( query_secondPassList == null ) {
-			query_secondPassList = new ArrayList<QuerySecondPass>();
+		if ( querySecondPassList == null ) {
+			querySecondPassList = new ArrayList<QuerySecondPass>();
 		}
-		addSecondPass( secondPass, query_secondPassList, onTopOfTheQueue );
+		addSecondPass( secondPass, querySecondPassList, onTopOfTheQueue );
 	}
 
 	private void addConstraintSecondPass(ConstraintSecondPass secondPass, boolean onTopOfTheQueue) {
-		if ( constraint_secondPassList == null ) {
-			constraint_secondPassList = new ArrayList<ConstraintSecondPass>();
+		if ( constraintSecondPassList == null ) {
+			constraintSecondPassList = new ArrayList<ConstraintSecondPass>();
 		}
-		addSecondPass( secondPass, constraint_secondPassList, onTopOfTheQueue );
+		addSecondPass( secondPass, constraintSecondPassList, onTopOfTheQueue );
 	}
 
 	private void addImplicitColumnNamingSecondPass(ImplicitColumnNamingSecondPass secondPass) {
-		if ( implicitColumnNaming_secondPassList == null ) {
-			implicitColumnNaming_secondPassList = new ArrayList<ImplicitColumnNamingSecondPass>();
+		if ( implicitColumnNamingSecondPassList == null ) {
+			implicitColumnNamingSecondPassList = new ArrayList<ImplicitColumnNamingSecondPass>();
 		}
-		implicitColumnNaming_secondPassList.add( secondPass );
+		implicitColumnNamingSecondPassList.add( secondPass );
 	}
 
 
 	private boolean inSecondPass = false;
 
 
 	/**
 	 * Ugh!  But we need this done before we ask Envers to produce its entities.
 	 */
 	public void processSecondPasses(MetadataBuildingContext buildingContext) {
 		inSecondPass = true;
 
 		try {
-			processSecondPasses( implicitColumnNaming_secondPassList );
+			processSecondPasses( implicitColumnNamingSecondPassList );
 
-			processSecondPasses( pkDrivenByDefaultMapsId_secondPassList );
-			processSecondPasses( setSimpleValueType_secondPassList );
-			processSecondPasses( copyIdentifierComponent_secondPasList );
+			processSecondPasses( pkDrivenByDefaultMapsIdSecondPassList );
+			processSecondPasses( setSimpleValueTypeSecondPassList );
+			processSecondPasses( copyIdentifierComponentSecondPasList );
 
 			processFkSecondPassesInOrder();
 
-			processSecondPasses( createKey_secondPasList );
-			processSecondPasses( secondaryTable_secondPassList );
+			processSecondPasses( createKeySecondPasList );
+			processSecondPasses( secondaryTableSecondPassList );
 
-			processSecondPasses( query_secondPassList );
-			processSecondPasses( general_secondPassList );
+			processSecondPasses( querySecondPassList );
+			processSecondPasses( generalSecondPassList );
 
 			processPropertyReferences();
 
 			secondPassCompileForeignKeys( buildingContext );
 
-			processSecondPasses( constraint_secondPassList );
+			processSecondPasses( constraintSecondPassList );
 			processUniqueConstraintHolders( buildingContext );
 			processJPAIndexHolders( buildingContext );
 
 			processNaturalIdUniqueKeyBinders();
 
 			processCachingOverrides();
 		}
 		finally {
 			inSecondPass = false;
 		}
 	}
 
 	private void processSecondPasses(ArrayList<? extends SecondPass> secondPasses) {
 		if ( secondPasses == null ) {
 			return;
 		}
 
 		for ( SecondPass secondPass : secondPasses ) {
 			secondPass.doSecondPass( getEntityBindingMap() );
 		}
 
 		secondPasses.clear();
 	}
 
 	private void processFkSecondPassesInOrder() {
-		if ( fk_secondPassList == null || fk_secondPassList.isEmpty() ) {
+		if ( fkSecondPassList == null || fkSecondPassList.isEmpty() ) {
 			return;
 		}
 
 		// split FkSecondPass instances into primary key and non primary key FKs.
 		// While doing so build a map of class names to FkSecondPass instances depending on this class.
 		Map<String, Set<FkSecondPass>> isADependencyOf = new HashMap<String, Set<FkSecondPass>>();
-		List<FkSecondPass> endOfQueueFkSecondPasses = new ArrayList<FkSecondPass>( fk_secondPassList.size() );
-		for ( FkSecondPass sp : fk_secondPassList ) {
+		List<FkSecondPass> endOfQueueFkSecondPasses = new ArrayList<FkSecondPass>( fkSecondPassList.size() );
+		for ( FkSecondPass sp : fkSecondPassList ) {
 			if ( sp.isInPrimaryKey() ) {
 				final String referenceEntityName = sp.getReferencedEntityName();
 				final PersistentClass classMapping = getEntityBinding( referenceEntityName );
 				final String dependentTable = classMapping.getTable().getQualifiedTableName().render();
 				if ( !isADependencyOf.containsKey( dependentTable ) ) {
 					isADependencyOf.put( dependentTable, new HashSet<FkSecondPass>() );
 				}
 				isADependencyOf.get( dependentTable ).add( sp );
 			}
 			else {
 				endOfQueueFkSecondPasses.add( sp );
 			}
 		}
 
 		// using the isADependencyOf map we order the FkSecondPass recursively instances into the right order for processing
-		List<FkSecondPass> orderedFkSecondPasses = new ArrayList<FkSecondPass>( fk_secondPassList.size() );
+		List<FkSecondPass> orderedFkSecondPasses = new ArrayList<FkSecondPass>( fkSecondPassList.size() );
 		for ( String tableName : isADependencyOf.keySet() ) {
 			buildRecursiveOrderedFkSecondPasses( orderedFkSecondPasses, isADependencyOf, tableName, tableName );
 		}
 
 		// process the ordered FkSecondPasses
 		for ( FkSecondPass sp : orderedFkSecondPasses ) {
 			sp.doSecondPass( getEntityBindingMap() );
 		}
 
 		processEndOfQueue( endOfQueueFkSecondPasses );
 
-		fk_secondPassList.clear();
+		fkSecondPassList.clear();
 	}
 
 	/**
 	 * Recursively builds a list of FkSecondPass instances ready to be processed in this order.
 	 * Checking all dependencies recursively seems quite expensive, but the original code just relied
 	 * on some sort of table name sorting which failed in certain circumstances.
 	 * <p/>
 	 * See <tt>ANN-722</tt> and <tt>ANN-730</tt>
 	 *
 	 * @param orderedFkSecondPasses The list containing the <code>FkSecondPass<code> instances ready
 	 * for processing.
 	 * @param isADependencyOf Our lookup data structure to determine dependencies between tables
 	 * @param startTable Table name to start recursive algorithm.
 	 * @param currentTable The current table name used to check for 'new' dependencies.
 	 */
 	private void buildRecursiveOrderedFkSecondPasses(
 			List<FkSecondPass> orderedFkSecondPasses,
 			Map<String, Set<FkSecondPass>> isADependencyOf,
 			String startTable,
 			String currentTable) {
 
 		Set<FkSecondPass> dependencies = isADependencyOf.get( currentTable );
 
 		// bottom out
 		if ( dependencies == null || dependencies.size() == 0 ) {
 			return;
 		}
 
 		for ( FkSecondPass sp : dependencies ) {
 			String dependentTable = sp.getValue().getTable().getQualifiedTableName().render();
 			if ( dependentTable.compareTo( startTable ) == 0 ) {
 				String sb = "Foreign key circularity dependency involving the following tables: ";
 				throw new AnnotationException( sb );
 			}
 			buildRecursiveOrderedFkSecondPasses( orderedFkSecondPasses, isADependencyOf, startTable, dependentTable );
 			if ( !orderedFkSecondPasses.contains( sp ) ) {
 				orderedFkSecondPasses.add( 0, sp );
 			}
 		}
 	}
 
 	private void processEndOfQueue(List<FkSecondPass> endOfQueueFkSecondPasses) {
 		/*
 		 * If a second pass raises a recoverableException, queue it for next round
 		 * stop of no pass has to be processed or if the number of pass to processes
 		 * does not diminish between two rounds.
 		 * If some failing pass remain, raise the original exception
 		 */
 		boolean stopProcess = false;
 		RuntimeException originalException = null;
 		while ( !stopProcess ) {
 			List<FkSecondPass> failingSecondPasses = new ArrayList<FkSecondPass>();
 			for ( FkSecondPass pass : endOfQueueFkSecondPasses ) {
 				try {
 					pass.doSecondPass( getEntityBindingMap() );
 				}
 				catch (RecoverableException e) {
 					failingSecondPasses.add( pass );
 					if ( originalException == null ) {
 						originalException = (RuntimeException) e.getCause();
 					}
 				}
 			}
 			stopProcess = failingSecondPasses.size() == 0 || failingSecondPasses.size() == endOfQueueFkSecondPasses.size();
 			endOfQueueFkSecondPasses = failingSecondPasses;
 		}
 		if ( endOfQueueFkSecondPasses.size() > 0 ) {
 			throw originalException;
 		}
 	}
 
 	private void secondPassCompileForeignKeys(MetadataBuildingContext buildingContext) {
 		int uniqueInteger = 0;
 		Set<ForeignKey> done = new HashSet<ForeignKey>();
 		for ( Table table : collectTableMappings() ) {
 			table.setUniqueInteger( uniqueInteger++ );
 			secondPassCompileForeignKeys( table, done, buildingContext );
 		}
 	}
 
 	protected void secondPassCompileForeignKeys(
 			final Table table,
 			Set<ForeignKey> done,
 			final MetadataBuildingContext buildingContext) throws MappingException {
 		table.createForeignKeys();
 
 		Iterator itr = table.getForeignKeyIterator();
 		while ( itr.hasNext() ) {
 			final ForeignKey fk = (ForeignKey) itr.next();
 			if ( !done.contains( fk ) ) {
 				done.add( fk );
 				final String referencedEntityName = fk.getReferencedEntityName();
 				if ( referencedEntityName == null ) {
 					throw new MappingException(
 							"An association from the table " +
 									fk.getTable().getName() +
 									" does not specify the referenced entity"
 					);
 				}
 
 				log.debugf( "Resolving reference to class: %s", referencedEntityName );
 				final PersistentClass referencedClass = getEntityBinding( referencedEntityName );
 				if ( referencedClass == null ) {
 					throw new MappingException(
 							"An association from the table " +
 									fk.getTable().getName() +
 									" refers to an unmapped class: " +
 									referencedEntityName
 					);
 				}
 				if ( referencedClass.isJoinedSubclass() ) {
 					secondPassCompileForeignKeys( referencedClass.getSuperclass().getTable(), done, buildingContext );
 				}
 
 				fk.setReferencedTable( referencedClass.getTable() );
 
 				// todo : should we apply a physical naming too?
 				if ( fk.getName() == null ) {
 					final Identifier nameIdentifier = getMetadataBuildingOptions().getImplicitNamingStrategy().determineForeignKeyName(
 							new ImplicitForeignKeyNameSource() {
 								final List<Identifier> columnNames = extractColumnNames( fk.getColumns() );
 								List<Identifier> referencedColumnNames = null;
 
 								@Override
 								public Identifier getTableName() {
 									return table.getNameIdentifier();
 								}
 
 								@Override
 								public List<Identifier> getColumnNames() {
 									return columnNames;
 								}
 
 								@Override
 								public Identifier getReferencedTableName() {
 									return fk.getReferencedTable().getNameIdentifier();
 								}
 
 								@Override
 								public List<Identifier> getReferencedColumnNames() {
 									if ( referencedColumnNames == null ) {
 										referencedColumnNames = extractColumnNames( fk.getReferencedColumns() );
 									}
 									return referencedColumnNames;
 								}
 
 								@Override
 								public MetadataBuildingContext getBuildingContext() {
 									return buildingContext;
 								}
 							}
 					);
 
 					fk.setName( nameIdentifier.render( getDatabase().getJdbcEnvironment().getDialect() ) );
 				}
 
 				fk.alignColumns();
 			}
 		}
 	}
 
 	private List<Identifier> toIdentifiers(List<String> names) {
 		if ( names == null || names.isEmpty() ) {
 			return Collections.emptyList();
 		}
 
 		final List<Identifier> columnNames = CollectionHelper.arrayList( names.size() );
 		for ( String name : names ) {
 			columnNames.add( getDatabase().toIdentifier( name ) );
 		}
 		return columnNames;
 	}
 
 	private List<Identifier> toIdentifiers(String[] names) {
 		if ( names == null ) {
 			return Collections.emptyList();
 		}
 
 		final List<Identifier> columnNames = CollectionHelper.arrayList( names.length );
 		for ( String name : names ) {
 			columnNames.add( getDatabase().toIdentifier( name ) );
 		}
 		return columnNames;
 	}
 
 	@SuppressWarnings("unchecked")
 	private List<Identifier> extractColumnNames(List columns) {
 		if ( columns == null || columns.isEmpty() ) {
 			return Collections.emptyList();
 		}
 
 		final List<Identifier> columnNames = CollectionHelper.arrayList( columns.size() );
 		for ( Column column : (List<Column>) columns ) {
 			columnNames.add( getDatabase().toIdentifier( column.getQuotedName() ) );
 		}
 		return columnNames;
 
 	}
 
 	private void processPropertyReferences() {
 		if ( delayedPropertyReferenceHandlers == null ) {
 			return;
 		}
 		log.debug( "Processing association property references" );
 
 		for ( DelayedPropertyReferenceHandler delayedPropertyReferenceHandler : delayedPropertyReferenceHandlers ) {
 			delayedPropertyReferenceHandler.process( this );
 		}
 
 		delayedPropertyReferenceHandlers.clear();
 	}
 
 	private void processUniqueConstraintHolders(MetadataBuildingContext buildingContext) {
 		if ( uniqueConstraintHoldersByTable == null ) {
 			return;
 		}
 
 		for ( Map.Entry<Table, List<UniqueConstraintHolder>> tableListEntry : uniqueConstraintHoldersByTable.entrySet() ) {
 			final Table table = tableListEntry.getKey();
 			final List<UniqueConstraintHolder> uniqueConstraints = tableListEntry.getValue();
 			for ( UniqueConstraintHolder holder : uniqueConstraints ) {
 				buildUniqueKeyFromColumnNames( table, holder.getName(), holder.getColumns(), buildingContext );
 			}
 		}
 
 		uniqueConstraintHoldersByTable.clear();
 	}
 
 	private void buildUniqueKeyFromColumnNames(
 			Table table,
 			String keyName,
 			String[] columnNames,
 			MetadataBuildingContext buildingContext) {
 		buildUniqueKeyFromColumnNames( table, keyName, columnNames, null, true, buildingContext );
 	}
 
 	private void buildUniqueKeyFromColumnNames(
 			final Table table,
 			String keyName,
 			final String[] columnNames,
 			String[] orderings,
 			boolean unique,
 			final MetadataBuildingContext buildingContext) {
 		int size = columnNames.length;
 		Column[] columns = new Column[size];
 		Set<Column> unbound = new HashSet<Column>();
 		Set<Column> unboundNoLogical = new HashSet<Column>();
 		for ( int index = 0; index < size; index++ ) {
 			final String logicalColumnName = columnNames[index];
 			try {
 				final String physicalColumnName = getPhysicalColumnName( table, logicalColumnName );
 				columns[index] = new Column( physicalColumnName );
 				unbound.add( columns[index] );
 				//column equals and hashcode is based on column name
 			}
 			catch ( MappingException e ) {
 				// If at least 1 columnName does exist, 'columns' will contain a mix of Columns and nulls.  In order
 				// to exhaustively report all of the unbound columns at once, w/o an NPE in
 				// Constraint#generateName's array sorting, simply create a fake Column.
 				columns[index] = new Column( logicalColumnName );
 				unboundNoLogical.add( columns[index] );
 			}
 		}
 
 		if ( unique ) {
 			if ( StringHelper.isEmpty( keyName ) ) {
 				final Identifier keyNameIdentifier = getMetadataBuildingOptions().getImplicitNamingStrategy().determineUniqueKeyName(
 						new ImplicitUniqueKeyNameSource() {
 							@Override
 							public MetadataBuildingContext getBuildingContext() {
 								return buildingContext;
 							}
 
 							@Override
 							public Identifier getTableName() {
 								return table.getNameIdentifier();
 							}
 
 							private List<Identifier> columnNameIdentifiers;
 
 							@Override
 							public List<Identifier> getColumnNames() {
 								// be lazy about building these
 								if ( columnNameIdentifiers == null ) {
 									columnNameIdentifiers = toIdentifiers( columnNames );
 								}
 								return columnNameIdentifiers;
 							}
 						}
 				);
 				keyName = keyNameIdentifier.render( getDatabase().getJdbcEnvironment().getDialect() );
 			}
 
 			UniqueKey uk = table.getOrCreateUniqueKey( keyName );
 			for ( int i = 0; i < columns.length; i++ ) {
 				Column column = columns[i];
 				String order = orderings != null ? orderings[i] : null;
 				if ( table.containsColumn( column ) ) {
 					uk.addColumn( column, order );
 					unbound.remove( column );
 				}
 			}
 		}
 		else {
 			if ( StringHelper.isEmpty( keyName ) ) {
 				final Identifier keyNameIdentifier = getMetadataBuildingOptions().getImplicitNamingStrategy().determineIndexName(
 						new ImplicitIndexNameSource() {
 							@Override
 							public MetadataBuildingContext getBuildingContext() {
 								return buildingContext;
 							}
 
 							@Override
 							public Identifier getTableName() {
 								return table.getNameIdentifier();
 							}
 
 							private List<Identifier> columnNameIdentifiers;
 
 							@Override
 							public List<Identifier> getColumnNames() {
 								// be lazy about building these
 								if ( columnNameIdentifiers == null ) {
 									columnNameIdentifiers = toIdentifiers( columnNames );
 								}
 								return columnNameIdentifiers;
 							}
 						}
 				);
 				keyName = keyNameIdentifier.render( getDatabase().getJdbcEnvironment().getDialect() );
 			}
 
 			Index index = table.getOrCreateIndex( keyName );
 			for ( int i = 0; i < columns.length; i++ ) {
 				Column column = columns[i];
 				String order = orderings != null ? orderings[i] : null;
 				if ( table.containsColumn( column ) ) {
 					index.addColumn( column, order );
 					unbound.remove( column );
 				}
 			}
 		}
 
 		if ( unbound.size() > 0 || unboundNoLogical.size() > 0 ) {
 			StringBuilder sb = new StringBuilder( "Unable to create unique key constraint (" );
 			for ( String columnName : columnNames ) {
 				sb.append( columnName ).append( ", " );
 			}
 			sb.setLength( sb.length() - 2 );
 			sb.append( ") on table " ).append( table.getName() ).append( ": database column " );
 			for ( Column column : unbound ) {
 				sb.append("'").append( column.getName() ).append( "', " );
 			}
 			for ( Column column : unboundNoLogical ) {
 				sb.append("'").append( column.getName() ).append( "', " );
 			}
 			sb.setLength( sb.length() - 2 );
 			sb.append( " not found. Make sure that you use the correct column name which depends on the naming strategy in use (it may not be the same as the property name in the entity, especially for relational types)" );
 			throw new AnnotationException( sb.toString() );
 		}
 	}
 
 	private void processJPAIndexHolders(MetadataBuildingContext buildingContext) {
 		if ( jpaIndexHoldersByTable == null ) {
 			return;
 		}
 
 		for ( Table table : jpaIndexHoldersByTable.keySet() ) {
 			final List<JPAIndexHolder> jpaIndexHolders = jpaIndexHoldersByTable.get( table );
 			for ( JPAIndexHolder holder : jpaIndexHolders ) {
 				buildUniqueKeyFromColumnNames(
 						table,
 						holder.getName(),
 						holder.getColumns(),
 						holder.getOrdering(),
 						holder.isUnique(),
 						buildingContext
 				);
 			}
 		}
 	}
 
 	private Map<String,NaturalIdUniqueKeyBinder> naturalIdUniqueKeyBinderMap;
 
 	@Override
 	public NaturalIdUniqueKeyBinder locateNaturalIdUniqueKeyBinder(String entityName) {
 		if ( naturalIdUniqueKeyBinderMap == null ) {
 			return null;
 		}
 		return naturalIdUniqueKeyBinderMap.get( entityName );
 	}
 
 	@Override
 	public void registerNaturalIdUniqueKeyBinder(String entityName, NaturalIdUniqueKeyBinder ukBinder) {
 		if ( naturalIdUniqueKeyBinderMap == null ) {
 			naturalIdUniqueKeyBinderMap = new HashMap<String, NaturalIdUniqueKeyBinder>();
 		}
 		final NaturalIdUniqueKeyBinder previous = naturalIdUniqueKeyBinderMap.put( entityName, ukBinder );
 		if ( previous != null ) {
 			throw new AssertionFailure( "Previous NaturalIdUniqueKeyBinder already registered for entity name : " + entityName );
 		}
 	}
 
 	private void processNaturalIdUniqueKeyBinders() {
 		if ( naturalIdUniqueKeyBinderMap == null ) {
 			return;
 		}
 
 		for ( NaturalIdUniqueKeyBinder naturalIdUniqueKeyBinder : naturalIdUniqueKeyBinderMap.values() ) {
 			naturalIdUniqueKeyBinder.process();
 		}
 
 		naturalIdUniqueKeyBinderMap.clear();
 	}
 
 	private void processCachingOverrides() {
 		if ( options.getCacheRegionDefinitions() == null ) {
 			return;
 		}
 
 		for ( CacheRegionDefinition cacheRegionDefinition : options.getCacheRegionDefinitions() ) {
 			if ( cacheRegionDefinition.getRegionType() == CacheRegionDefinition.CacheRegionType.ENTITY ) {
 				final PersistentClass entityBinding = getEntityBinding( cacheRegionDefinition.getRole() );
 				if ( entityBinding == null ) {
 					throw new HibernateException(
 							"Cache override referenced an unknown entity : " + cacheRegionDefinition.getRole()
 					);
 				}
 				if ( !RootClass.class.isInstance( entityBinding ) ) {
 					throw new HibernateException(
 							"Cache override referenced a non-root entity : " + cacheRegionDefinition.getRole()
 					);
 				}
 				( (RootClass) entityBinding ).setCacheRegionName( cacheRegionDefinition.getRegion() );
 				( (RootClass) entityBinding ).setCacheConcurrencyStrategy( cacheRegionDefinition.getUsage() );
 				( (RootClass) entityBinding ).setLazyPropertiesCacheable( cacheRegionDefinition.isCacheLazy() );
 			}
 			else if ( cacheRegionDefinition.getRegionType() == CacheRegionDefinition.CacheRegionType.COLLECTION ) {
 				final Collection collectionBinding = getCollectionBinding( cacheRegionDefinition.getRole() );
 				if ( collectionBinding == null ) {
 					throw new HibernateException(
 							"Cache override referenced an unknown collection role : " + cacheRegionDefinition.getRole()
 					);
 				}
 				collectionBinding.setCacheRegionName( cacheRegionDefinition.getRegion() );
 				collectionBinding.setCacheConcurrencyStrategy( cacheRegionDefinition.getUsage() );
 			}
 		}
 	}
 
 	@Override
 	public boolean isInSecondPass() {
 		return inSecondPass;
 	}
 
 	/**
 	 * Builds the complete and immutable Metadata instance from the collected info.
 	 *
 	 * @return The complete and immutable Metadata instance
 	 */
 	public MetadataImpl buildMetadataInstance(MetadataBuildingContext buildingContext) {
 		processSecondPasses( buildingContext );
 		processExportableProducers( buildingContext );
 
 		return new MetadataImpl(
 				uuid,
 				options,
 				typeResolver,
 				identifierGeneratorFactory,
 				entityBindingMap,
 				mappedSuperClasses,
 				collectionBindingMap,
 				typeDefinitionMap,
 				filterDefinitionMap,
 				fetchProfileMap,
 				imports,
 				idGeneratorDefinitionMap,
 				namedQueryMap,
 				namedNativeQueryMap,
 				namedProcedureCallMap,
 				sqlResultSetMappingMap,
 				namedEntityGraphMap,
 				sqlFunctionMap,
 				getDatabase()
 		);
 	}
 
 	private void processExportableProducers(MetadataBuildingContext buildingContext) {
 		// for now we only handle id generators as ExportableProducers
 
 		final Dialect dialect = getDatabase().getJdbcEnvironment().getDialect();
 		final String defaultCatalog = extractName( getDatabase().getDefaultSchema().getName().getCatalog(), dialect );
 		final String defaultSchema = extractName( getDatabase().getDefaultSchema().getName().getSchema(), dialect );
 
 		for ( PersistentClass entityBinding : entityBindingMap.values() ) {
 			if ( entityBinding.isInherited() ) {
 				continue;
 			}
 
 			handleIdentifierValueBinding(
 					entityBinding.getIdentifier(),
 					dialect,
 					defaultCatalog,
 					defaultSchema,
 					(RootClass) entityBinding
 			);
 		}
 
 		for ( Collection collection : collectionBindingMap.values() ) {
 			if ( !IdentifierCollection.class.isInstance( collection ) ) {
 				continue;
 			}
 
 			handleIdentifierValueBinding(
 					( (IdentifierCollection) collection ).getIdentifier(),
 					dialect,
 					defaultCatalog,
 					defaultSchema,
 					null
 			);
 		}
 	}
 
 	private void handleIdentifierValueBinding(
 			KeyValue identifierValueBinding,
 			Dialect dialect,
 			String defaultCatalog,
 			String defaultSchema,
 			RootClass entityBinding) {
 		// todo : store this result (back into the entity or into the KeyValue, maybe?)
 		// 		This process of instantiating the id-generator is called multiple times.
 		//		It was done this way in the old code too, so no "regression" here; but
 		//		it could be done better
 		try {
 			final IdentifierGenerator ig = identifierValueBinding.createIdentifierGenerator(
 					getIdentifierGeneratorFactory(),
 					dialect,
 					defaultCatalog,
 					defaultSchema,
 					entityBinding
 			);
 
 			if ( ig instanceof ExportableProducer ) {
 				( (ExportableProducer) ig ).registerExportables( getDatabase() );
 			}
 		}
 		catch (MappingException e) {
 			// ignore this for now.  The reasoning being "non-reflective" binding as needed
 			// by tools.  We want to hold off requiring classes being present until we
 			// try to build a SF.  Here, just building the Metadata, it is "ok" for an
 			// exception to occur, the same exception will happen later as we build the SF.
 			log.debugf( "Ignoring exception thrown when trying to build IdentifierGenerator as part of Metadata building", e );
 		}
 	}
 
 	private String extractName(Identifier identifier, Dialect dialect) {
 		if ( identifier == null ) {
 			return null;
 		}
 		return identifier.render( dialect );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/internal/stax/SupportedOrmXsdVersion.java b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/internal/stax/SupportedOrmXsdVersion.java
index 87f53a1870..c2ebc4cfed 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/internal/stax/SupportedOrmXsdVersion.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/internal/stax/SupportedOrmXsdVersion.java
@@ -1,84 +1,86 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.jaxb.internal.stax;
 
 import java.net.URL;
 import javax.xml.validation.Schema;
 
 import org.hibernate.boot.jaxb.Origin;
 
 /**
  * @author Steve Ebersole
+ *
+ * @deprecated since 5.0; no longer used internally.
  */
 @Deprecated
 public enum SupportedOrmXsdVersion {
 	ORM_1_0( "org/hibernate/jpa/orm_1_0.xsd" ),
 	ORM_2_0( "org/hibernate/jpa/orm_2_0.xsd" ),
 	ORM_2_1( "org/hibernate/jpa/orm_2_1.xsd" ),
 	ORM_2_1_0( "org/hibernate/xsd/mapping/mapping-2.1.0.xsd" ),
 	HBM_4_0( "org/hibernate/xsd/mapping/legacy-mapping-4.0.xsd" );
 
 	private final String schemaResourceName;
 
 	SupportedOrmXsdVersion(String schemaResourceName) {
 		this.schemaResourceName = schemaResourceName;
 	}
 
 	public static SupportedOrmXsdVersion parse(String name, Origin origin) {
 		if ( "1.0".equals( name ) ) {
 			return ORM_1_0;
 		}
 		else if ( "2.0".equals( name ) ) {
 			return ORM_2_0;
 		}
 		else if ( "2.1".equals( name ) ) {
 			return ORM_2_1;
 		}
 		else if ( "2.1.0".equals( name ) ) {
 			return ORM_2_1_0;
 		}
 		else if ( "4.0".equals( name ) ) {
 			return HBM_4_0;
 		}
 		throw new UnsupportedOrmXsdVersionException( name, origin );
 	}
 
 	private URL schemaUrl;
 
 	public URL getSchemaUrl() {
 		if ( schemaUrl == null ) {
 			schemaUrl = LocalSchemaLocator.resolveLocalSchemaUrl( schemaResourceName );
 		}
 		return schemaUrl;
 	}
 
 	private Schema schema;
 
 	public Schema getSchema() {
 		if ( schema == null ) {
 			schema = LocalSchemaLocator.resolveLocalSchema( getSchemaUrl() );
 		}
 		return schema;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/internal/stax/UnsupportedOrmXsdVersionException.java b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/internal/stax/UnsupportedOrmXsdVersionException.java
index 3a297b60fd..5e546a74e4 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/internal/stax/UnsupportedOrmXsdVersionException.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/internal/stax/UnsupportedOrmXsdVersionException.java
@@ -1,45 +1,46 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.jaxb.internal.stax;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.jaxb.Origin;
 
 /**
  * @author Steve Ebersole
+ *
  * @deprecated Use {@link org.hibernate.boot.UnsupportedOrmXsdVersionException} instead
  */
 @Deprecated
 public class UnsupportedOrmXsdVersionException extends HibernateException {
 	public UnsupportedOrmXsdVersionException(String requestedVersion, Origin origin) {
 		super(
 				String.format(
 						"Encountered unsupported orm.xml xsd version [%s] in mapping document [type=%s, name=%s]",
 						requestedVersion,
 						origin.getType(),
 						origin.getName()
 				)
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ModelBinder.java b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ModelBinder.java
index d3228203c6..9e42994db7 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ModelBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/model/source/internal/hbm/ModelBinder.java
@@ -1,2635 +1,2637 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.model.source.internal.hbm;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Properties;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.boot.MappingException;
 import org.hibernate.boot.jaxb.Origin;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmNamedNativeQueryType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmNamedQueryType;
 import org.hibernate.boot.model.Caching;
 import org.hibernate.boot.model.IdentifierGeneratorDefinition;
 import org.hibernate.boot.model.TruthValue;
 import org.hibernate.boot.model.TypeDefinition;
 import org.hibernate.boot.model.naming.EntityNaming;
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.model.naming.ImplicitBasicColumnNameSource;
 import org.hibernate.boot.model.naming.ImplicitCollectionTableNameSource;
 import org.hibernate.boot.model.naming.ImplicitEntityNameSource;
 import org.hibernate.boot.model.naming.ImplicitIdentifierColumnNameSource;
 import org.hibernate.boot.model.naming.ImplicitIndexColumnNameSource;
 import org.hibernate.boot.model.naming.ImplicitJoinColumnNameSource;
 import org.hibernate.boot.model.naming.ImplicitMapKeyColumnNameSource;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategy;
 import org.hibernate.boot.model.naming.ImplicitUniqueKeyNameSource;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.boot.model.relational.Database;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.boot.model.source.internal.ConstraintSecondPass;
 import org.hibernate.boot.model.source.internal.ImplicitColumnNamingSecondPass;
 import org.hibernate.boot.model.source.spi.AnyMappingSource;
 import org.hibernate.boot.model.source.spi.AttributePath;
 import org.hibernate.boot.model.source.spi.AttributeRole;
 import org.hibernate.boot.model.source.spi.AttributeSource;
 import org.hibernate.boot.model.source.spi.CascadeStyleSource;
 import org.hibernate.boot.model.source.spi.CollectionIdSource;
 import org.hibernate.boot.model.source.spi.ColumnSource;
 import org.hibernate.boot.model.source.spi.CompositeIdentifierSource;
 import org.hibernate.boot.model.source.spi.ConstraintSource;
 import org.hibernate.boot.model.source.spi.EmbeddableSource;
 import org.hibernate.boot.model.source.spi.EntitySource;
 import org.hibernate.boot.model.source.spi.FilterSource;
 import org.hibernate.boot.model.source.spi.HibernateTypeSource;
 import org.hibernate.boot.model.source.spi.IdentifiableTypeSource;
 import org.hibernate.boot.model.source.spi.IdentifierSourceAggregatedComposite;
 import org.hibernate.boot.model.source.spi.IdentifierSourceNonAggregatedComposite;
 import org.hibernate.boot.model.source.spi.IdentifierSourceSimple;
 import org.hibernate.boot.model.source.spi.InLineViewSource;
 import org.hibernate.boot.model.source.spi.LocalMetadataBuildingContext;
 import org.hibernate.boot.model.source.spi.NaturalIdMutability;
 import org.hibernate.boot.model.source.spi.Orderable;
 import org.hibernate.boot.model.source.spi.PluralAttributeElementSourceBasic;
 import org.hibernate.boot.model.source.spi.PluralAttributeElementSourceEmbedded;
 import org.hibernate.boot.model.source.spi.PluralAttributeElementSourceManyToAny;
 import org.hibernate.boot.model.source.spi.PluralAttributeElementSourceManyToMany;
 import org.hibernate.boot.model.source.spi.PluralAttributeElementSourceOneToMany;
 import org.hibernate.boot.model.source.spi.PluralAttributeMapKeyManyToAnySource;
 import org.hibernate.boot.model.source.spi.PluralAttributeMapKeyManyToManySource;
 import org.hibernate.boot.model.source.spi.PluralAttributeMapKeySourceBasic;
 import org.hibernate.boot.model.source.spi.PluralAttributeMapKeySourceEmbedded;
 import org.hibernate.boot.model.source.spi.PluralAttributeSequentialIndexSource;
 import org.hibernate.boot.model.source.spi.PluralAttributeSource;
 import org.hibernate.boot.model.source.spi.PluralAttributeSourceArray;
 import org.hibernate.boot.model.source.spi.RelationalValueSource;
 import org.hibernate.boot.model.source.spi.RelationalValueSourceContainer;
 import org.hibernate.boot.model.source.spi.SecondaryTableSource;
 import org.hibernate.boot.model.source.spi.SingularAttributeSource;
 import org.hibernate.boot.model.source.spi.SingularAttributeSourceAny;
 import org.hibernate.boot.model.source.spi.SingularAttributeSourceBasic;
 import org.hibernate.boot.model.source.spi.SingularAttributeSourceEmbedded;
 import org.hibernate.boot.model.source.spi.SingularAttributeSourceManyToOne;
 import org.hibernate.boot.model.source.spi.SingularAttributeSourceOneToOne;
 import org.hibernate.boot.model.source.spi.Sortable;
 import org.hibernate.boot.model.source.spi.TableSource;
 import org.hibernate.boot.model.source.spi.TableSpecificationSource;
 import org.hibernate.boot.model.source.spi.VersionAttributeSource;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.boot.spi.InFlightMetadataCollector;
 import org.hibernate.boot.spi.InFlightMetadataCollector.EntityTableXref;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.boot.spi.NaturalIdUniqueKeyBinder;
 import org.hibernate.cfg.FkSecondPass;
 import org.hibernate.cfg.SecondPass;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.FilterDefinition;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.compare.EqualsHelper;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.mapping.Any;
 import org.hibernate.mapping.Array;
 import org.hibernate.mapping.AttributeContainer;
 import org.hibernate.mapping.Backref;
 import org.hibernate.mapping.Bag;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.DenormalizedTable;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.IdentifierBag;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.IndexBackref;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.JoinedSubclass;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.ManyToOne;
 import org.hibernate.mapping.OneToMany;
 import org.hibernate.mapping.OneToOne;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.PrimitiveArray;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Set;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.SingleTableSubclass;
 import org.hibernate.mapping.SyntheticProperty;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.UnionSubclass;
 import org.hibernate.mapping.UniqueKey;
 import org.hibernate.mapping.Value;
 import org.hibernate.tuple.GeneratedValueGeneration;
 import org.hibernate.tuple.GenerationTiming;
 import org.hibernate.type.DiscriminatorType;
 import org.hibernate.type.ForeignKeyDirection;
 
 /**
  * Responsible for coordinating the binding of all information inside entity tags ({@code <class/>}, etc).
  *
  * @author Steve Ebersole
  */
 public class ModelBinder {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( ModelBinder.class );
 	private static final boolean debugEnabled = log.isDebugEnabled();
 
 	private final Database database;
 	private final ObjectNameNormalizer objectNameNormalizer;
 	private final ImplicitNamingStrategy implicitNamingStrategy;
 	private final RelationalObjectBinder relationalObjectBinder;
 
 	public static ModelBinder prepare(MetadataBuildingContext context) {
 		return new ModelBinder( context );
 	}
 
 	public ModelBinder(final MetadataBuildingContext context) {
 		this.database = context.getMetadataCollector().getDatabase();
 		this.objectNameNormalizer = new ObjectNameNormalizer() {
 			@Override
 			protected MetadataBuildingContext getBuildingContext() {
 				return context;
 			}
 		};
 		this.implicitNamingStrategy = context.getBuildingOptions().getImplicitNamingStrategy();
 		this.relationalObjectBinder = new RelationalObjectBinder( context );
 	}
 
 	public void finishUp(MetadataBuildingContext context) {
 	}
 
 	public void bindEntityHierarchy(EntityHierarchySourceImpl hierarchySource) {
 		final RootClass rootEntityDescriptor = new RootClass();
 		bindRootEntity( hierarchySource, rootEntityDescriptor );
 		hierarchySource.getRoot()
 				.getLocalMetadataBuildingContext()
 				.getMetadataCollector()
 				.addEntityBinding( rootEntityDescriptor );
 
 		switch ( hierarchySource.getHierarchyInheritanceType() ) {
 			case NO_INHERITANCE: {
 				// nothing to do
 				break;
 			}
 			case DISCRIMINATED: {
 				bindDiscriminatorSubclassEntities( hierarchySource.getRoot(), rootEntityDescriptor );
 				break;
 			}
 			case JOINED: {
 				bindJoinedSubclassEntities( hierarchySource.getRoot(), rootEntityDescriptor );
 				break;
 			}
 			case UNION: {
 				bindUnionSubclassEntities( hierarchySource.getRoot(), rootEntityDescriptor );
 				break;
 			}
 		}
 	}
 
 	private void bindRootEntity(EntityHierarchySourceImpl hierarchySource, RootClass rootEntityDescriptor) {
 		final MappingDocument mappingDocument = hierarchySource.getRoot().sourceMappingDocument();
 
 		bindBasicEntityValues(
 				mappingDocument,
 				hierarchySource.getRoot(),
 				rootEntityDescriptor
 		);
 
 		final Table primaryTable = bindEntityTableSpecification(
 				mappingDocument,
 				hierarchySource.getRoot().getPrimaryTable(),
 				null,
 				hierarchySource.getRoot(),
 				rootEntityDescriptor
 		);
 
 		rootEntityDescriptor.setTable( primaryTable );
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Mapping class: %s -> %s", rootEntityDescriptor.getEntityName(), primaryTable.getName() );
 		}
 
 		rootEntityDescriptor.setOptimisticLockStyle( hierarchySource.getOptimisticLockStyle() );
 		rootEntityDescriptor.setMutable( hierarchySource.isMutable() );
 		rootEntityDescriptor.setWhere( hierarchySource.getWhere() );
 		rootEntityDescriptor.setExplicitPolymorphism( hierarchySource.isExplicitPolymorphism() );
 
 		bindEntityIdentifier(
 				mappingDocument,
 				hierarchySource,
 				rootEntityDescriptor
 		);
 
 		if ( hierarchySource.getVersionAttributeSource() != null ) {
 			bindEntityVersion(
 					mappingDocument,
 					hierarchySource,
 					rootEntityDescriptor
 			);
 		}
 
 		if ( hierarchySource.getDiscriminatorSource() != null ) {
 			bindEntityDiscriminator(
 					mappingDocument,
 					hierarchySource,
 					rootEntityDescriptor
 			);
 		}
 
 		applyCaching( mappingDocument, hierarchySource.getCaching(), rootEntityDescriptor );
 
 		// Primary key constraint
 		rootEntityDescriptor.createPrimaryKey();
 
 		bindAllEntityAttributes(
 				mappingDocument,
 				hierarchySource.getRoot(),
 				rootEntityDescriptor
 		);
 
 		if ( hierarchySource.getNaturalIdCaching() != null ) {
 			if ( hierarchySource.getNaturalIdCaching().getRequested() == TruthValue.TRUE ) {
 				rootEntityDescriptor.setNaturalIdCacheRegionName( hierarchySource.getNaturalIdCaching().getRegion() );
 			}
 		}
 	}
 
 	private void applyCaching(MappingDocument mappingDocument, Caching caching, RootClass rootEntityDescriptor) {
 		if ( caching == null || caching.getRequested() == TruthValue.UNKNOWN ) {
 			// see if JPA's SharedCacheMode indicates we should implicitly apply caching
 			//
 			// here we only really look for ALL.  Ideally we could look at NONE too as a means
 			// to selectively disable all caching, but historically hbm.xml mappings were processed
 			// outside this concept and whether to cache or not was defined wholly by what
 			// is defined in the mapping document.  So for backwards compatibility we
 			// do not consider ENABLE_SELECTIVE nor DISABLE_SELECTIVE here.
 			//
 			// Granted, ALL was not historically considered either, but I have a practical
 			// reason for wanting to support this... our legacy tests built using
 			// Configuration applied a similar logic but that capability is no longer
 			// accessible from Configuration
 			switch ( mappingDocument.getBuildingOptions().getSharedCacheMode() ) {
 				case ALL: {
 					caching = new Caching(
 							null,
 							mappingDocument.getBuildingOptions().getImplicitCacheAccessType(),
 							false,
 							TruthValue.UNKNOWN
 					);
+					break;
 				}
 				case NONE: {
 					// Ideally we'd disable all caching...
 					break;
 				}
 				case ENABLE_SELECTIVE: {
 					// this is default behavior for hbm.xml
 					break;
 				}
 				case DISABLE_SELECTIVE: {
 					// really makes no sense for hbm.xml
 					break;
 				}
 				default: {
 					// null or UNSPECIFIED, nothing to do.  IMO for hbm.xml this is equivalent
 					// to ENABLE_SELECTIVE
 					break;
 				}
 			}
 		}
 
 		if ( caching == null || caching.getRequested() == TruthValue.FALSE ) {
 			return;
 		}
 
 		if ( caching.getAccessType() != null ) {
 			rootEntityDescriptor.setCacheConcurrencyStrategy( caching.getAccessType().getExternalName() );
 		}
 		else {
 			rootEntityDescriptor.setCacheConcurrencyStrategy( mappingDocument.getBuildingOptions().getImplicitCacheAccessType().getExternalName() );
 		}
 		rootEntityDescriptor.setCacheRegionName( caching.getRegion() );
 		rootEntityDescriptor.setLazyPropertiesCacheable( caching.isCacheLazyProperties() );
 		rootEntityDescriptor.setCachingExplicitlyRequested( caching.getRequested() != TruthValue.UNKNOWN );
 	}
 
 	private void bindEntityIdentifier(
 			MappingDocument mappingDocument,
 			EntityHierarchySourceImpl hierarchySource,
 			RootClass rootEntityDescriptor) {
 		switch ( hierarchySource.getIdentifierSource().getNature() ) {
 			case SIMPLE: {
 				bindSimpleEntityIdentifier(
 						mappingDocument,
 						hierarchySource,
 						rootEntityDescriptor
 				);
 				break;
 			}
 			case AGGREGATED_COMPOSITE: {
 				bindAggregatedCompositeEntityIdentifier(
 						mappingDocument,
 						hierarchySource,
 						rootEntityDescriptor
 				);
 				break;
 			}
 			case NON_AGGREGATED_COMPOSITE: {
 				bindNonAggregatedCompositeEntityIdentifier(
 						mappingDocument,
 						hierarchySource,
 						rootEntityDescriptor
 				);
 				break;
 			}
 			default: {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Unexpected entity identifier nature [%s] for entity %s",
 								hierarchySource.getIdentifierSource().getNature(),
 								hierarchySource.getRoot().getEntityNamingSource().getEntityName()
 						),
 						mappingDocument.getOrigin()
 				);
 			}
 		}
 	}
 
 	private void bindBasicEntityValues(
 			MappingDocument sourceDocument,
 			AbstractEntitySourceImpl entitySource,
 			PersistentClass entityDescriptor) {
 		entityDescriptor.setEntityName( entitySource.getEntityNamingSource().getEntityName() );
 		entityDescriptor.setJpaEntityName( entitySource.getEntityNamingSource().getJpaEntityName() );
 		entityDescriptor.setClassName( entitySource.getEntityNamingSource().getClassName() );
 
 		entityDescriptor.setDiscriminatorValue(
 				entitySource.getDiscriminatorMatchValue() != null
 						? entitySource.getDiscriminatorMatchValue()
 						: entityDescriptor.getEntityName()
 		);
 
 		// NOTE : entitySource#isLazy already accounts for MappingDefaults#areEntitiesImplicitlyLazy
 		if ( StringHelper.isNotEmpty( entitySource.getProxy() ) ) {
 			final String qualifiedProxyName = sourceDocument.qualifyClassName( entitySource.getProxy() );
 			entityDescriptor.setProxyInterfaceName( qualifiedProxyName );
 			entityDescriptor.setLazy( true );
 		}
 		else if ( entitySource.isLazy() ) {
 			entityDescriptor.setProxyInterfaceName( entityDescriptor.getClassName() );
 			entityDescriptor.setLazy( true );
 		}
 		else {
 			entityDescriptor.setProxyInterfaceName( null );
 			entityDescriptor.setLazy( false );
 		}
 
 		entityDescriptor.setAbstract( entitySource.isAbstract() );
 
 		sourceDocument.getMetadataCollector().addImport(
 				entitySource.getEntityNamingSource().getEntityName(),
 				entitySource.getEntityNamingSource().getEntityName()
 		);
 
 		if ( sourceDocument.getMappingDefaults().isAutoImportEnabled() && entitySource.getEntityNamingSource().getEntityName().indexOf( '.' ) > 0 ) {
 			sourceDocument.getMetadataCollector().addImport(
 					StringHelper.unqualify( entitySource.getEntityNamingSource().getEntityName() ),
 					entitySource.getEntityNamingSource().getEntityName()
 			);
 		}
 
 		if ( entitySource.getTuplizerClassMap() != null ) {
 			if ( entitySource.getTuplizerClassMap().size() > 1 ) {
 				DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfMultipleEntityModeSupport();
 			}
 			for ( Map.Entry<EntityMode,String> tuplizerEntry : entitySource.getTuplizerClassMap().entrySet() ) {
 				entityDescriptor.addTuplizer(
 						tuplizerEntry.getKey(),
 						tuplizerEntry.getValue()
 				);
 			}
 		}
 
 		if ( StringHelper.isNotEmpty( entitySource.getXmlNodeName() ) ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfDomEntityModeSupport();
 			entityDescriptor.setNodeName( entitySource.getXmlNodeName() );
 		}
 
 		entityDescriptor.setDynamicInsert( entitySource.isDynamicInsert() );
 		entityDescriptor.setDynamicUpdate( entitySource.isDynamicUpdate() );
 		entityDescriptor.setBatchSize( entitySource.getBatchSize() );
 		entityDescriptor.setSelectBeforeUpdate( entitySource.isSelectBeforeUpdate() );
 
 		if ( StringHelper.isNotEmpty( entitySource.getCustomPersisterClassName() ) ) {
 			try {
 				entityDescriptor.setEntityPersisterClass(
 						sourceDocument.getClassLoaderAccess().classForName( entitySource.getCustomPersisterClassName() )
 				);
 			}
 			catch (ClassLoadingException e) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Unable to load specified persister class : %s",
 								entitySource.getCustomPersisterClassName()
 						),
 						e,
 						sourceDocument.getOrigin()
 				);
 			}
 		}
 
 		bindCustomSql( sourceDocument, entitySource, entityDescriptor );
 
 		for ( String tableName : entitySource.getSynchronizedTableNames() ) {
 			entityDescriptor.addSynchronizedTable( tableName );
 		}
 
 		for ( FilterSource filterSource : entitySource.getFilterSources() ) {
 			String condition = filterSource.getCondition();
 			if ( condition == null ) {
 				final FilterDefinition filterDefinition = sourceDocument.getMetadataCollector().getFilterDefinition( filterSource.getName() );
 				if ( filterDefinition != null ) {
 					condition = filterDefinition.getDefaultFilterCondition();
 				}
 			}
 
 			entityDescriptor.addFilter(
 					filterSource.getName(),
 					condition,
 					filterSource.shouldAutoInjectAliases(),
 					filterSource.getAliasToTableMap(),
 					filterSource.getAliasToEntityMap()
 			);
 		}
 
 		for ( JaxbHbmNamedQueryType namedQuery : entitySource.getNamedQueries() ) {
 			NamedQueryBinder.processNamedQuery(
 					sourceDocument,
 					namedQuery,
 					entitySource.getEntityNamingSource().getEntityName() + "."
 			);
 		}
 		for ( JaxbHbmNamedNativeQueryType namedQuery : entitySource.getNamedNativeQueries() ) {
 			NamedQueryBinder.processNamedNativeQuery(
 					sourceDocument,
 					namedQuery,
 					entitySource.getEntityNamingSource().getEntityName() + "."
 			);
 		}
 
 		entityDescriptor.setMetaAttributes( entitySource.getToolingHintContext().getMetaAttributeMap() );
 	}
 
 	private void bindDiscriminatorSubclassEntities(
 			AbstractEntitySourceImpl entitySource,
 			PersistentClass superEntityDescriptor) {
 		for ( IdentifiableTypeSource subType : entitySource.getSubTypes() ) {
 			final SingleTableSubclass subEntityDescriptor = new SingleTableSubclass( superEntityDescriptor );
 			bindDiscriminatorSubclassEntity( (SubclassEntitySourceImpl) subType, subEntityDescriptor );
 			superEntityDescriptor.addSubclass( subEntityDescriptor );
 			entitySource.getLocalMetadataBuildingContext().getMetadataCollector().addEntityBinding( subEntityDescriptor );
 		}
 	}
 
 	private void bindDiscriminatorSubclassEntity(
 			SubclassEntitySourceImpl entitySource,
 			SingleTableSubclass entityDescriptor) {
 
 		bindBasicEntityValues(
 				entitySource.sourceMappingDocument(),
 				entitySource,
 				entityDescriptor
 		);
 
 		final String superEntityName = ( (EntitySource) entitySource.getSuperType() ).getEntityNamingSource()
 				.getEntityName();
 		final EntityTableXref superEntityTableXref = entitySource.getLocalMetadataBuildingContext()
 				.getMetadataCollector()
 				.getEntityTableXref( superEntityName );
 		if ( superEntityTableXref == null ) {
 			throw new MappingException(
 					String.format(
 							Locale.ENGLISH,
 							"Unable to locate entity table xref for entity [%s] super-type [%s]",
 							entityDescriptor.getEntityName(),
 							superEntityName
 					),
 					entitySource.origin()
 			);
 		}
 
 		entitySource.getLocalMetadataBuildingContext().getMetadataCollector().addEntityTableXref(
 				entitySource.getEntityNamingSource().getEntityName(),
 				database.toIdentifier(
 						entitySource.getLocalMetadataBuildingContext().getMetadataCollector().getLogicalTableName(
 								entityDescriptor.getTable()
 						)
 				),
 				entityDescriptor.getTable(),
 				superEntityTableXref
 		);
 
 		bindAllEntityAttributes(
 				entitySource.sourceMappingDocument(),
 				entitySource,
 				entityDescriptor
 		);
 
 		bindDiscriminatorSubclassEntities( entitySource, entityDescriptor );
 	}
 
 	private void bindJoinedSubclassEntities(
 			AbstractEntitySourceImpl entitySource,
 			PersistentClass superEntityDescriptor) {
 		for ( IdentifiableTypeSource subType : entitySource.getSubTypes() ) {
 			final JoinedSubclass subEntityDescriptor = new JoinedSubclass( superEntityDescriptor );
 			bindJoinedSubclassEntity( (JoinedSubclassEntitySourceImpl) subType, subEntityDescriptor );
 			superEntityDescriptor.addSubclass( subEntityDescriptor );
 			entitySource.getLocalMetadataBuildingContext().getMetadataCollector().addEntityBinding( subEntityDescriptor );
 		}
 	}
 
 	private void bindJoinedSubclassEntity(
 			JoinedSubclassEntitySourceImpl entitySource,
 			JoinedSubclass entityDescriptor) {
 		MappingDocument mappingDocument = entitySource.sourceMappingDocument();
 
 		bindBasicEntityValues(
 				mappingDocument,
 				entitySource,
 				entityDescriptor
 		);
 
 		final Table primaryTable = bindEntityTableSpecification(
 				mappingDocument,
 				entitySource.getPrimaryTable(),
 				null,
 				entitySource,
 				entityDescriptor
 		);
 
 		entityDescriptor.setTable( primaryTable );
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Mapping joined-subclass: %s -> %s", entityDescriptor.getEntityName(), primaryTable.getName() );
 		}
 
 		// KEY
 		final SimpleValue keyBinding = new DependantValue(
 				mappingDocument.getMetadataCollector(),
 				primaryTable,
 				entityDescriptor.getIdentifier()
 		);
 		if ( mappingDocument.getBuildingOptions().useNationalizedCharacterData() ) {
 			keyBinding.makeNationalized();
 		}
 		entityDescriptor.setKey( keyBinding );
 		keyBinding.setCascadeDeleteEnabled( entitySource.isCascadeDeleteEnabled() );
 		relationalObjectBinder.bindColumns(
 				mappingDocument,
 				entitySource.getPrimaryKeyColumnSources(),
 				keyBinding,
 				false,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					int count = 0;
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						final Column column = primaryTable.getPrimaryKey().getColumn( count++ );
 						return database.toIdentifier( column.getQuotedName() );
 					}
 				}
 		);
 
 		// model.getKey().setType( new Type( model.getIdentifier() ) );
 		entityDescriptor.createPrimaryKey();
 		entityDescriptor.createForeignKey();
 
 		// todo : tooling hints
 
 		bindAllEntityAttributes(
 				entitySource.sourceMappingDocument(),
 				entitySource,
 				entityDescriptor
 		);
 
 		bindJoinedSubclassEntities( entitySource, entityDescriptor );
 	}
 
 	private void bindUnionSubclassEntities(
 			EntitySource entitySource,
 			PersistentClass superEntityDescriptor) {
 		for ( IdentifiableTypeSource subType : entitySource.getSubTypes() ) {
 			final UnionSubclass subEntityDescriptor = new UnionSubclass( superEntityDescriptor );
 			bindUnionSubclassEntity( (SubclassEntitySourceImpl) subType, subEntityDescriptor );
 			superEntityDescriptor.addSubclass( subEntityDescriptor );
 			entitySource.getLocalMetadataBuildingContext().getMetadataCollector().addEntityBinding( subEntityDescriptor );
 		}
 	}
 
 	private void bindUnionSubclassEntity(
 			SubclassEntitySourceImpl entitySource,
 			UnionSubclass entityDescriptor) {
 		MappingDocument mappingDocument = entitySource.sourceMappingDocument();
 
 		bindBasicEntityValues(
 				mappingDocument,
 				entitySource,
 				entityDescriptor
 		);
 
 		final Table primaryTable = bindEntityTableSpecification(
 				mappingDocument,
 				entitySource.getPrimaryTable(),
 				entityDescriptor.getSuperclass().getTable(),
 				entitySource,
 				entityDescriptor
 		);
 		entityDescriptor.setTable( primaryTable );
 
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Mapping union-subclass: %s -> %s", entityDescriptor.getEntityName(), primaryTable.getName() );
 		}
 
 		// todo : tooling hints
 
 		bindAllEntityAttributes(
 				entitySource.sourceMappingDocument(),
 				entitySource,
 				entityDescriptor
 		);
 
 		bindUnionSubclassEntities( entitySource, entityDescriptor );
 	}
 
 	private void bindSimpleEntityIdentifier(
 			MappingDocument sourceDocument,
 			final EntityHierarchySourceImpl hierarchySource,
 			RootClass rootEntityDescriptor) {
 		final IdentifierSourceSimple idSource = (IdentifierSourceSimple) hierarchySource.getIdentifierSource();
 
 		final SimpleValue idValue = new SimpleValue(
 				sourceDocument.getMetadataCollector(),
 				rootEntityDescriptor.getTable()
 		);
 		rootEntityDescriptor.setIdentifier( idValue );
 
 		bindSimpleValueType(
 				sourceDocument,
 				idSource.getIdentifierAttributeSource().getTypeInformation(),
 				idValue
 		);
 
 		final String propertyName = idSource.getIdentifierAttributeSource().getName();
 		if ( propertyName == null || !rootEntityDescriptor.hasPojoRepresentation() ) {
 			if ( !idValue.isTypeSpecified() ) {
 				throw new MappingException(
 						"must specify an identifier type: " + rootEntityDescriptor.getEntityName(),
 						sourceDocument.getOrigin()
 				);
 			}
 		}
 		else {
 			idValue.setTypeUsingReflection( rootEntityDescriptor.getClassName(), propertyName );
 		}
 
 		relationalObjectBinder.bindColumnsAndFormulas(
 				sourceDocument,
 				( (RelationalValueSourceContainer) idSource.getIdentifierAttributeSource() ).getRelationalValueSources(),
 				idValue,
 				false,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(final LocalMetadataBuildingContext context) {
 						context.getBuildingOptions().getImplicitNamingStrategy().determineIdentifierColumnName(
 								new ImplicitIdentifierColumnNameSource() {
 									@Override
 									public EntityNaming getEntityNaming() {
 										return hierarchySource.getRoot().getEntityNamingSource();
 									}
 
 									@Override
 									public AttributePath getIdentifierAttributePath() {
 										return idSource.getIdentifierAttributeSource().getAttributePath();
 									}
 
 									@Override
 									public MetadataBuildingContext getBuildingContext() {
 										return context;
 									}
 								}
 						);
 						return database.toIdentifier( propertyName );
 					}
 				}
 		);
 
 		if ( propertyName != null ) {
 			Property prop = new Property();
 			prop.setValue( idValue );
 			bindProperty(
 					sourceDocument,
 					idSource.getIdentifierAttributeSource(),
 					prop
 			);
 			rootEntityDescriptor.setIdentifierProperty( prop );
 			rootEntityDescriptor.setDeclaredIdentifierProperty( prop );
 		}
 
 		makeIdentifier(
 				sourceDocument,
 				idSource.getIdentifierGeneratorDescriptor(),
 				idSource.getUnsavedValue(),
 				idValue
 		);
 	}
 
 	private void makeIdentifier(
 			final MappingDocument sourceDocument,
 			IdentifierGeneratorDefinition generator,
 			String unsavedValue,
 			SimpleValue identifierValue) {
 		if ( generator != null ) {
 			String generatorName = generator.getStrategy();
 			Properties params = new Properties();
 
 			// see if the specified generator name matches a registered <identifier-generator/>
 			IdentifierGeneratorDefinition generatorDef = sourceDocument.getMetadataCollector().getIdentifierGenerator( generatorName );
 			if ( generatorDef != null ) {
 				generatorName = generatorDef.getStrategy();
 				params.putAll( generatorDef.getParameters() );
 			}
 
 			identifierValue.setIdentifierGeneratorStrategy( generatorName );
 
 			// YUCK!  but cannot think of a clean way to do this given the string-config based scheme
 			params.put( PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER, objectNameNormalizer);
 
 			if ( database.getDefaultSchema().getPhysicalName().getSchema() != null ) {
 				params.setProperty(
 						PersistentIdentifierGenerator.SCHEMA,
 						database.getDefaultSchema().getPhysicalName().getSchema().render( database.getDialect() )
 				);
 			}
 			if ( database.getDefaultSchema().getPhysicalName().getCatalog() != null ) {
 				params.setProperty(
 						PersistentIdentifierGenerator.CATALOG,
 						database.getDefaultSchema().getPhysicalName().getCatalog().render( database.getDialect() )
 				);
 			}
 
 			params.putAll( generator.getParameters() );
 
 			identifierValue.setIdentifierGeneratorProperties( params );
 		}
 
 		identifierValue.getTable().setIdentifierValue( identifierValue );
 
 		if ( StringHelper.isNotEmpty( unsavedValue ) ) {
 			identifierValue.setNullValue( unsavedValue );
 		}
 		else {
 			if ( "assigned".equals( identifierValue.getIdentifierGeneratorStrategy() ) ) {
 				identifierValue.setNullValue( "undefined" );
 			}
 			else {
 				identifierValue.setNullValue( null );
 			}
 		}
 	}
 
 	private void bindAggregatedCompositeEntityIdentifier(
 			MappingDocument mappingDocument,
 			EntityHierarchySourceImpl hierarchySource,
 			RootClass rootEntityDescriptor) {
 
 		// an aggregated composite-id is a composite-id that defines a singular
 		// (composite) attribute as part of the entity to represent the id.
 
 		final IdentifierSourceAggregatedComposite identifierSource
 				= (IdentifierSourceAggregatedComposite) hierarchySource.getIdentifierSource();
 
 		final Component cid = new Component( mappingDocument.getMetadataCollector(), rootEntityDescriptor );
 		cid.setKey( true );
 		rootEntityDescriptor.setIdentifier( cid );
 
 		final String idClassName = extractIdClassName( identifierSource );
 
 		final String idPropertyName = identifierSource.getIdentifierAttributeSource().getName();
 		final String pathPart = idPropertyName == null ? "<id>" : idPropertyName;
 
 		bindComponent(
 				mappingDocument,
 				hierarchySource.getRoot().getAttributeRoleBase().append( pathPart ).getFullPath(),
 				identifierSource.getEmbeddableSource(),
 				cid,
 				idClassName,
 				rootEntityDescriptor.getClassName(),
 				idPropertyName,
 				idClassName == null && idPropertyName == null,
 				identifierSource.getEmbeddableSource().isDynamic(),
 				identifierSource.getIdentifierAttributeSource().getXmlNodeName()
 		);
 
 		finishBindingCompositeIdentifier(
 				mappingDocument,
 				rootEntityDescriptor,
 				identifierSource,
 				cid,
 				idPropertyName
 		);
 	}
 
 	private String extractIdClassName(IdentifierSourceAggregatedComposite identifierSource) {
 		if ( identifierSource.getEmbeddableSource().getTypeDescriptor() == null ) {
 			return null;
 		}
 
 		return identifierSource.getEmbeddableSource().getTypeDescriptor().getName();
 	}
 
 	private static final String ID_MAPPER_PATH_PART = '<' + PropertyPath.IDENTIFIER_MAPPER_PROPERTY + '>';
 
 	private void bindNonAggregatedCompositeEntityIdentifier(
 			MappingDocument mappingDocument,
 			EntityHierarchySourceImpl hierarchySource,
 			RootClass rootEntityDescriptor) {
 		final IdentifierSourceNonAggregatedComposite identifierSource
 				= (IdentifierSourceNonAggregatedComposite) hierarchySource.getIdentifierSource();
 
 		final Component cid = new Component( mappingDocument.getMetadataCollector(), rootEntityDescriptor );
 		cid.setKey( true );
 		rootEntityDescriptor.setIdentifier( cid );
 
 		final String idClassName = extractIdClassName( identifierSource );
 
 		bindComponent(
 				mappingDocument,
 				hierarchySource.getRoot().getAttributeRoleBase().append( "<id>" ).getFullPath(),
 				identifierSource.getEmbeddableSource(),
 				cid,
 				idClassName,
 				rootEntityDescriptor.getClassName(),
 				null,
 				idClassName == null,
 				false,
 				null
 		);
 
 		if ( idClassName != null ) {
 			// we also need to bind the "id mapper".  ugh, terrible name.  Basically we need to
 			// create a virtual (embedded) composite for the non-aggregated attributes on the entity
 			// itself.
 			final Component mapper = new Component( mappingDocument.getMetadataCollector(), rootEntityDescriptor );
 			bindComponent(
 					mappingDocument,
 					hierarchySource.getRoot().getAttributeRoleBase().append( ID_MAPPER_PATH_PART ).getFullPath(),
 					identifierSource.getEmbeddableSource(),
 					mapper,
 					rootEntityDescriptor.getClassName(),
 					null,
 					null,
 					true,
 					false,
 					null
 			);
 
 			rootEntityDescriptor.setIdentifierMapper(mapper);
 			Property property = new Property();
 			property.setName( PropertyPath.IDENTIFIER_MAPPER_PROPERTY );
 			property.setNodeName( "id" );
 			property.setUpdateable( false );
 			property.setInsertable( false );
 			property.setValue( mapper );
 			property.setPropertyAccessorName( "embedded" );
 			rootEntityDescriptor.addProperty( property );
 		}
 
 		finishBindingCompositeIdentifier( mappingDocument, rootEntityDescriptor, identifierSource, cid, null );
 	}
 
 	private String extractIdClassName(IdentifierSourceNonAggregatedComposite identifierSource) {
 		if ( identifierSource.getIdClassSource() == null ) {
 			return null;
 		}
 
 		if ( identifierSource.getIdClassSource().getTypeDescriptor() == null ) {
 			return null;
 		}
 
 		return identifierSource.getIdClassSource().getTypeDescriptor().getName();
 	}
 
 	private void finishBindingCompositeIdentifier(
 			MappingDocument sourceDocument,
 			RootClass rootEntityDescriptor,
 			CompositeIdentifierSource identifierSource,
 			Component cid,
 			String propertyName) {
 		if ( propertyName == null ) {
 			rootEntityDescriptor.setEmbeddedIdentifier( cid.isEmbedded() );
 			if ( cid.isEmbedded() ) {
 				// todo : what is the implication of this?
 				cid.setDynamic( !rootEntityDescriptor.hasPojoRepresentation() );
 				/*
 				 * Property prop = new Property(); prop.setName("id");
 				 * prop.setPropertyAccessorName("embedded"); prop.setValue(id);
 				 * entity.setIdentifierProperty(prop);
 				 */
 			}
 		}
 		else {
 			Property prop = new Property();
 			prop.setValue( cid );
 			bindProperty(
 					sourceDocument,
 					( (IdentifierSourceAggregatedComposite) identifierSource ).getIdentifierAttributeSource(),
 					prop
 			);
 			rootEntityDescriptor.setIdentifierProperty( prop );
 			rootEntityDescriptor.setDeclaredIdentifierProperty( prop );
 		}
 
 		makeIdentifier(
 				sourceDocument,
 				identifierSource.getIdentifierGeneratorDescriptor(),
 				null,
 				cid
 		);
 	}
 
 	private void bindEntityVersion(
 			MappingDocument sourceDocument,
 			EntityHierarchySourceImpl hierarchySource,
 			RootClass rootEntityDescriptor) {
 		final VersionAttributeSource versionAttributeSource = hierarchySource.getVersionAttributeSource();
 
 		final SimpleValue versionValue = new SimpleValue(
 				sourceDocument.getMetadataCollector(),
 				rootEntityDescriptor.getTable()
 		);
 
 		bindSimpleValueType(
 				sourceDocument,
 				versionAttributeSource.getTypeInformation(),
 				versionValue
 		);
 
 		relationalObjectBinder.bindColumnsAndFormulas(
 				sourceDocument,
 				versionAttributeSource.getRelationalValueSources(),
 				versionValue,
 				false,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						return implicitNamingStrategy.determineBasicColumnName( versionAttributeSource );
 					}
 				}
 		);
 
 		Property prop = new Property();
 		prop.setValue( versionValue );
 		bindProperty(
 				sourceDocument,
 				versionAttributeSource,
 				prop
 		);
 
 		// for version properties marked as being generated, make sure they are "always"
 		// generated; aka, "insert" is invalid; this is dis-allowed by the DTD,
 		// but just to make sure...
 		if ( prop.getValueGenerationStrategy() != null ) {
 			if ( prop.getValueGenerationStrategy().getGenerationTiming() == GenerationTiming.INSERT ) {
 				throw new MappingException(
 						"'generated' attribute cannot be 'insert' for version/timestamp property",
 						sourceDocument.getOrigin()
 				);
 			}
 		}
 
 		if ( versionAttributeSource.getUnsavedValue() != null ) {
 			versionValue.setNullValue( versionAttributeSource.getUnsavedValue() );
 		}
 		else {
 			versionValue.setNullValue( "undefined" );
 		}
 
 		rootEntityDescriptor.setVersion( prop );
 		rootEntityDescriptor.addProperty( prop );
 	}
 
 	private void bindEntityDiscriminator(
 			MappingDocument sourceDocument,
 			final EntityHierarchySourceImpl hierarchySource,
 			RootClass rootEntityDescriptor) {
 		final SimpleValue discriminatorValue = new SimpleValue(
 				sourceDocument.getMetadataCollector(),
 				rootEntityDescriptor.getTable()
 		);
 		rootEntityDescriptor.setDiscriminator( discriminatorValue );
 
 		String typeName = hierarchySource.getDiscriminatorSource().getExplicitHibernateTypeName();
 		if ( typeName == null ) {
 			typeName = "string";
 		}
 		bindSimpleValueType(
 				sourceDocument,
 				new HibernateTypeSourceImpl( typeName ),
 				discriminatorValue
 		);
 
 		relationalObjectBinder.bindColumnOrFormula(
 				sourceDocument,
 				hierarchySource.getDiscriminatorSource().getDiscriminatorRelationalValueSource(),
 				discriminatorValue,
 				false,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(final LocalMetadataBuildingContext context) {
 						return implicitNamingStrategy.determineDiscriminatorColumnName(
 								hierarchySource.getDiscriminatorSource()
 						);
 					}
 				}
 		);
 
 		rootEntityDescriptor.setPolymorphic( true );
 		rootEntityDescriptor.setDiscriminatorInsertable( hierarchySource.getDiscriminatorSource().isInserted() );
 
 		// todo : currently isForced() is defined as boolean, not Boolean
 		//		although it has always been that way (DTD too)
 		final boolean force = hierarchySource.getDiscriminatorSource().isForced()
 				|| sourceDocument.getBuildingOptions().shouldImplicitlyForceDiscriminatorInSelect();
 		rootEntityDescriptor.setForceDiscriminator( force );
 	}
 
 	private void bindAllEntityAttributes(
 			MappingDocument mappingDocument,
 			EntitySource entitySource,
 			PersistentClass entityDescriptor) {
 		final EntityTableXref entityTableXref = mappingDocument.getMetadataCollector().getEntityTableXref(
 				entityDescriptor.getEntityName()
 		);
 		if ( entityTableXref == null ) {
 			throw new AssertionFailure(
 					String.format(
 							Locale.ENGLISH,
 							"Unable to locate EntityTableXref for entity [%s] : %s",
 							entityDescriptor.getEntityName(),
 							mappingDocument.getOrigin()
 					)
 			);
 		}
 
 		// make sure we bind secondary tables first!
 		for ( SecondaryTableSource secondaryTableSource : entitySource.getSecondaryTableMap().values() ) {
 			final Join secondaryTableJoin = new Join();
 			secondaryTableJoin.setPersistentClass( entityDescriptor );
 			bindSecondaryTable(
 					mappingDocument,
 					secondaryTableSource,
 					secondaryTableJoin,
 					entityTableXref
 			);
 			entityDescriptor.addJoin( secondaryTableJoin );
 		}
 
 		for ( AttributeSource attributeSource : entitySource.attributeSources() ) {
 			if ( PluralAttributeSource.class.isInstance( attributeSource ) ) {
 				// plural attribute
 				final Property attribute = createPluralAttribute(
 						mappingDocument,
 						(PluralAttributeSource) attributeSource,
 						entityDescriptor
 				);
 				entityDescriptor.addProperty( attribute );
 			}
 			else {
 				// singular attribute
 				if ( SingularAttributeSourceBasic.class.isInstance( attributeSource ) ) {
 					final SingularAttributeSourceBasic basicAttributeSource = (SingularAttributeSourceBasic) attributeSource;
 					final Identifier tableName = determineTable( mappingDocument, basicAttributeSource.getName(), basicAttributeSource );
 					final AttributeContainer attributeContainer;
 					final Table table;
 					final Join secondaryTableJoin = entityTableXref.locateJoin( tableName );
 					if ( secondaryTableJoin == null ) {
 						table = entityDescriptor.getTable();
 						attributeContainer = entityDescriptor;
 					}
 					else {
 						table = secondaryTableJoin.getTable();
 						attributeContainer = secondaryTableJoin;
 					}
 
 					final Property attribute = createBasicAttribute(
 							mappingDocument,
 							basicAttributeSource,
 							new SimpleValue( mappingDocument.getMetadataCollector(), table ),
 							entityDescriptor.getClassName()
 					);
 
 					if ( secondaryTableJoin != null ) {
 						attribute.setOptional( secondaryTableJoin.isOptional() );
 					}
 
 					attributeContainer.addProperty( attribute );
 
 					handleNaturalIdBinding(
 							mappingDocument,
 							entityDescriptor,
 							attribute,
 							basicAttributeSource.getNaturalIdMutability()
 					);
 				}
 				else if ( SingularAttributeSourceEmbedded.class.isInstance( attributeSource ) ) {
 					final SingularAttributeSourceEmbedded embeddedAttributeSource = (SingularAttributeSourceEmbedded) attributeSource;
 					final Identifier tableName = determineTable( mappingDocument, embeddedAttributeSource );
 					final AttributeContainer attributeContainer;
 					final Table table;
 					final Join secondaryTableJoin = entityTableXref.locateJoin( tableName );
 					if ( secondaryTableJoin == null ) {
 						table = entityDescriptor.getTable();
 						attributeContainer = entityDescriptor;
 					}
 					else {
 						table = secondaryTableJoin.getTable();
 						attributeContainer = secondaryTableJoin;
 					}
 
 					final Property attribute = createEmbeddedAttribute(
 							mappingDocument,
 							(SingularAttributeSourceEmbedded) attributeSource,
 							new Component( mappingDocument.getMetadataCollector(), table, entityDescriptor ),
 							entityDescriptor.getClassName()
 					);
 
 					if ( secondaryTableJoin != null ) {
 						attribute.setOptional( secondaryTableJoin.isOptional() );
 					}
 
 					attributeContainer.addProperty( attribute );
 
 					handleNaturalIdBinding(
 							mappingDocument,
 							entityDescriptor,
 							attribute,
 							embeddedAttributeSource.getNaturalIdMutability()
 					);
 				}
 				else if ( SingularAttributeSourceManyToOne.class.isInstance( attributeSource ) ) {
 					final SingularAttributeSourceManyToOne manyToOneAttributeSource = (SingularAttributeSourceManyToOne) attributeSource;
 					final Identifier tableName = determineTable( mappingDocument, manyToOneAttributeSource.getName(), manyToOneAttributeSource );
 					final AttributeContainer attributeContainer;
 					final Table table;
 					final Join secondaryTableJoin = entityTableXref.locateJoin( tableName );
 					if ( secondaryTableJoin == null ) {
 						table = entityDescriptor.getTable();
 						attributeContainer = entityDescriptor;
 					}
 					else {
 						table = secondaryTableJoin.getTable();
 						attributeContainer = secondaryTableJoin;
 					}
 
 					final Property attribute = createManyToOneAttribute(
 							mappingDocument,
 							manyToOneAttributeSource,
 							new ManyToOne( mappingDocument.getMetadataCollector(), table ),
 							entityDescriptor.getClassName()
 					);
 
 					if ( secondaryTableJoin != null ) {
 						attribute.setOptional( secondaryTableJoin.isOptional() );
 					}
 
 					attributeContainer.addProperty( attribute );
 
 					handleNaturalIdBinding(
 							mappingDocument,
 							entityDescriptor,
 							attribute,
 							manyToOneAttributeSource.getNaturalIdMutability()
 					);
 				}
 				else if ( SingularAttributeSourceOneToOne.class.isInstance( attributeSource ) ) {
 					final SingularAttributeSourceOneToOne oneToOneAttributeSource = (SingularAttributeSourceOneToOne) attributeSource;
 					final Table table = entityDescriptor.getTable();
 					final Property attribute = createOneToOneAttribute(
 							mappingDocument,
 							oneToOneAttributeSource,
 							new OneToOne( mappingDocument.getMetadataCollector(), table, entityDescriptor ),
 							entityDescriptor.getClassName()
 					);
 					entityDescriptor.addProperty( attribute );
 
 					handleNaturalIdBinding(
 							mappingDocument,
 							entityDescriptor,
 							attribute,
 							oneToOneAttributeSource.getNaturalIdMutability()
 					);
 				}
 				else if ( SingularAttributeSourceAny.class.isInstance( attributeSource ) ) {
 					final SingularAttributeSourceAny anyAttributeSource = (SingularAttributeSourceAny) attributeSource;
 					final Identifier tableName = determineTable(
 							mappingDocument,
 							anyAttributeSource.getName(),
 							anyAttributeSource.getKeySource().getRelationalValueSources()
 					);
 					final AttributeContainer attributeContainer;
 					final Table table;
 					final Join secondaryTableJoin = entityTableXref.locateJoin( tableName );
 					if ( secondaryTableJoin == null ) {
 						table = entityDescriptor.getTable();
 						attributeContainer = entityDescriptor;
 					}
 					else {
 						table = secondaryTableJoin.getTable();
 						attributeContainer = secondaryTableJoin;
 					}
 
 					final Property attribute = createAnyAssociationAttribute(
 							mappingDocument,
 							anyAttributeSource,
 							new Any( mappingDocument.getMetadataCollector(), table ),
 							entityDescriptor.getEntityName()
 					);
 
 					if ( secondaryTableJoin != null ) {
 						attribute.setOptional( secondaryTableJoin.isOptional() );
 					}
 
 					attributeContainer.addProperty( attribute );
 
 					handleNaturalIdBinding(
 							mappingDocument,
 							entityDescriptor,
 							attribute,
 							anyAttributeSource.getNaturalIdMutability()
 					);
 				}
 			}
 		}
 
 		registerConstraintSecondPasses( mappingDocument, entitySource, entityTableXref );
 	}
 
 	private void handleNaturalIdBinding(
 			MappingDocument mappingDocument,
 			PersistentClass entityBinding,
 			Property attributeBinding,
 			NaturalIdMutability naturalIdMutability) {
 		if ( naturalIdMutability == NaturalIdMutability.NOT_NATURAL_ID ) {
 			return;
 		}
 
 		attributeBinding.setNaturalIdentifier( true );
 
 		if ( naturalIdMutability == NaturalIdMutability.IMMUTABLE ) {
 			attributeBinding.setUpdateable( false );
 		}
 
 		NaturalIdUniqueKeyBinder ukBinder = mappingDocument.getMetadataCollector().locateNaturalIdUniqueKeyBinder(
 				entityBinding.getEntityName()
 		);
 
 		if ( ukBinder == null ) {
 			ukBinder = new NaturalIdUniqueKeyBinderImpl( mappingDocument, entityBinding );
 			mappingDocument.getMetadataCollector().registerNaturalIdUniqueKeyBinder(
 					entityBinding.getEntityName(),
 					ukBinder
 			);
 		}
 
 		ukBinder.addAttributeBinding( attributeBinding );
 	}
 
 	private void registerConstraintSecondPasses(
 			MappingDocument mappingDocument,
 			EntitySource entitySource,
 			final EntityTableXref entityTableXref) {
 		if ( entitySource.getConstraints() == null ) {
 			return;
 		}
 
 		for ( ConstraintSource constraintSource : entitySource.getConstraints() ) {
 			final String logicalTableName = constraintSource.getTableName();
 			final Table table = entityTableXref.resolveTable( database.toIdentifier( logicalTableName ) );
 
 			mappingDocument.getMetadataCollector().addSecondPass(
 					new ConstraintSecondPass(
 							mappingDocument,
 							table,
 							constraintSource
 					)
 			);
 		}
 	}
 
 	private Property createPluralAttribute(
 			MappingDocument sourceDocument,
 			PluralAttributeSource attributeSource,
 			PersistentClass entityDescriptor) {
 		final Collection collectionBinding;
 
 		if ( attributeSource instanceof PluralAttributeSourceListImpl ) {
 			collectionBinding = new org.hibernate.mapping.List( sourceDocument.getMetadataCollector(), entityDescriptor );
 			bindCollectionMetadata( sourceDocument, attributeSource, collectionBinding );
 
 			registerSecondPass(
 					new PluralAttributeListSecondPass(
 							sourceDocument,
 							(IndexedPluralAttributeSource) attributeSource,
 							(org.hibernate.mapping.List) collectionBinding
 					),
 					sourceDocument
 			);
 		}
 		else if ( attributeSource instanceof PluralAttributeSourceSetImpl ) {
 			collectionBinding = new Set( sourceDocument.getMetadataCollector(), entityDescriptor );
 			bindCollectionMetadata( sourceDocument, attributeSource, collectionBinding );
 
 			registerSecondPass(
 					new PluralAttributeSetSecondPass( sourceDocument, attributeSource, collectionBinding ),
 					sourceDocument
 			);
 		}
 		else if ( attributeSource instanceof PluralAttributeSourceMapImpl ) {
 			collectionBinding = new org.hibernate.mapping.Map( sourceDocument.getMetadataCollector(), entityDescriptor );
 			bindCollectionMetadata( sourceDocument, attributeSource, collectionBinding );
 
 			registerSecondPass(
 					new PluralAttributeMapSecondPass(
 							sourceDocument,
 							(IndexedPluralAttributeSource) attributeSource,
 							(org.hibernate.mapping.Map) collectionBinding
 					),
 					sourceDocument
 			);
 		}
 		else if ( attributeSource instanceof PluralAttributeSourceBagImpl ) {
 			collectionBinding = new Bag( sourceDocument.getMetadataCollector(), entityDescriptor );
 			bindCollectionMetadata( sourceDocument, attributeSource, collectionBinding );
 
 			registerSecondPass(
 					new PluralAttributeBagSecondPass( sourceDocument, attributeSource, collectionBinding ),
 					sourceDocument
 			);
 		}
 		else if ( attributeSource instanceof PluralAttributeSourceIdBagImpl ) {
 			collectionBinding = new IdentifierBag( sourceDocument.getMetadataCollector(), entityDescriptor );
 			bindCollectionMetadata( sourceDocument, attributeSource, collectionBinding );
 
 			registerSecondPass(
 					new PluralAttributeIdBagSecondPass( sourceDocument, attributeSource, collectionBinding ),
 					sourceDocument
 			);
 		}
 		else if ( attributeSource instanceof PluralAttributeSourceArrayImpl ) {
 			final PluralAttributeSourceArray arraySource = (PluralAttributeSourceArray) attributeSource;
 			collectionBinding = new Array( sourceDocument.getMetadataCollector(), entityDescriptor );
 			bindCollectionMetadata( sourceDocument, attributeSource, collectionBinding );
 
 			( (Array) collectionBinding ).setElementClassName(
 					sourceDocument.qualifyClassName( arraySource.getElementClass() )
 			);
 
 			registerSecondPass(
 					new PluralAttributeArraySecondPass(
 							sourceDocument,
 							arraySource,
 							(Array) collectionBinding
 					),
 					sourceDocument
 			);
 		}
 		else if ( attributeSource instanceof PluralAttributeSourcePrimitiveArrayImpl ) {
 			collectionBinding = new PrimitiveArray( sourceDocument.getMetadataCollector(), entityDescriptor );
 			bindCollectionMetadata( sourceDocument, attributeSource, collectionBinding );
 
 			registerSecondPass(
 					new PluralAttributePrimitiveArraySecondPass(
 							sourceDocument,
 							(IndexedPluralAttributeSource) attributeSource,
 							(PrimitiveArray) collectionBinding
 					),
 					sourceDocument
 			);
 		}
 		else {
 			throw new AssertionFailure(
 					"Unexpected PluralAttributeSource type : " + attributeSource.getClass().getName()
 			);
 		}
 
 		sourceDocument.getMetadataCollector().addCollectionBinding( collectionBinding );
 
 		final Property attribute = new Property();
 		attribute.setValue( collectionBinding );
 		bindProperty(
 				sourceDocument,
 				attributeSource,
 				attribute
 		);
 
 		return attribute;
 	}
 
 	private void bindCollectionMetadata(MappingDocument mappingDocument, PluralAttributeSource source, Collection binding) {
 		binding.setRole( source.getAttributeRole().getFullPath() );
 		binding.setInverse( source.isInverse() );
 		binding.setMutable( source.isMutable() );
 		binding.setOptimisticLocked( source.isIncludedInOptimisticLocking() );
 
 		if ( source.getCustomPersisterClassName() != null ) {
 			binding.setCollectionPersisterClass(
 					mappingDocument.getClassLoaderAccess().classForName(
 							mappingDocument.qualifyClassName( source.getCustomPersisterClassName() )
 					)
 			);
 		}
 
 		applyCaching( mappingDocument, source.getCaching(), binding );
 
 		// bind the collection type info
 		String typeName = source.getTypeInformation().getName();
 		Map typeParameters = new HashMap();
 		if ( typeName != null ) {
 			// see if there is a corresponding type-def
 			final TypeDefinition typeDef = mappingDocument.getMetadataCollector().getTypeDefinition( typeName );
 			if ( typeDef != null ) {
 				typeName = typeDef.getTypeImplementorClass().getName();
 				if ( typeDef.getParameters() != null ) {
 					typeParameters.putAll( typeDef.getParameters() );
 				}
 			}
 			else {
 				// it could be a unqualified class name, in which case we should qualify
 				// it with the implicit package name for this context, if one.
 				typeName = mappingDocument.qualifyClassName( typeName );
 			}
 		}
 		if ( source.getTypeInformation().getParameters() != null ) {
 			typeParameters.putAll( source.getTypeInformation().getParameters() );
 		}
 
 		binding.setTypeName( typeName );
 		binding.setTypeParameters( typeParameters );
 
 		if ( source.getFetchCharacteristics().getFetchTiming() == FetchTiming.DELAYED ) {
 			binding.setLazy( true );
 			binding.setExtraLazy( source.getFetchCharacteristics().isExtraLazy() );
 		}
 		else {
 			binding.setLazy( false );
 		}
 
 		switch ( source.getFetchCharacteristics().getFetchStyle() ) {
 			case SELECT: {
 				binding.setFetchMode( FetchMode.SELECT );
 				break;
 			}
 			case JOIN: {
 				binding.setFetchMode( FetchMode.JOIN );
 				break;
 			}
 			case BATCH: {
 				binding.setFetchMode( FetchMode.SELECT );
 				binding.setBatchSize( source.getFetchCharacteristics().getBatchSize() );
 				break;
 			}
 			case SUBSELECT: {
 				binding.setFetchMode( FetchMode.SELECT );
 				binding.setSubselectLoadable( true );
 				// todo : this could totally be done using a "symbol map" approach
 				binding.getOwner().setSubselectLoadableCollections( true );
 				break;
 			}
 			default: {
 				throw new AssertionFailure( "Unexpected FetchStyle : " + source.getFetchCharacteristics().getFetchStyle().name() );
 			}
 		}
 
 		for ( String name : source.getSynchronizedTableNames() ) {
 			binding.getSynchronizedTables().add( name );
 		}
 
 		binding.setWhere( source.getWhere() );
 		binding.setLoaderName( source.getCustomLoaderName() );
 		if ( source.getCustomSqlInsert() != null ) {
 			binding.setCustomSQLInsert(
 					source.getCustomSqlInsert().getSql(),
 					source.getCustomSqlInsert().isCallable(),
 					source.getCustomSqlInsert().getCheckStyle()
 			);
 		}
 		if ( source.getCustomSqlUpdate() != null ) {
 			binding.setCustomSQLUpdate(
 					source.getCustomSqlUpdate().getSql(),
 					source.getCustomSqlUpdate().isCallable(),
 					source.getCustomSqlUpdate().getCheckStyle()
 			);
 		}
 		if ( source.getCustomSqlDelete() != null ) {
 			binding.setCustomSQLDelete(
 					source.getCustomSqlDelete().getSql(),
 					source.getCustomSqlDelete().isCallable(),
 					source.getCustomSqlDelete().getCheckStyle()
 			);
 		}
 		if ( source.getCustomSqlDeleteAll() != null ) {
 			binding.setCustomSQLDeleteAll(
 					source.getCustomSqlDeleteAll().getSql(),
 					source.getCustomSqlDeleteAll().isCallable(),
 					source.getCustomSqlDeleteAll().getCheckStyle()
 			);
 		}
 
 		if ( source instanceof Sortable ) {
 			final Sortable sortable = (Sortable) source;
 			if ( sortable.isSorted() ) {
 				binding.setSorted( true );
 				if ( ! sortable.getComparatorName().equals( "natural" ) ) {
 					binding.setComparatorClassName( sortable.getComparatorName() );
 				}
 			}
 			else {
 				binding.setSorted( false );
 			}
 		}
 
 		if ( source instanceof Orderable ) {
 			if ( ( (Orderable) source ).isOrdered() ) {
 				binding.setOrderBy( ( (Orderable) source ).getOrder() );
 			}
 		}
 
 		final String cascadeStyle = source.getCascadeStyleName();
 		if ( cascadeStyle != null && cascadeStyle.contains( "delete-orphan" ) ) {
 			binding.setOrphanDelete( true );
 		}
 
 		for ( FilterSource filterSource : source.getFilterSources() ) {
 			String condition = filterSource.getCondition();
 			if ( condition == null ) {
 				final FilterDefinition filterDefinition = mappingDocument.getMetadataCollector().getFilterDefinition( filterSource.getName() );
 				if ( filterDefinition != null ) {
 					condition = filterDefinition.getDefaultFilterCondition();
 				}
 			}
 
 			binding.addFilter(
 					filterSource.getName(),
 					condition,
 					filterSource.shouldAutoInjectAliases(),
 					filterSource.getAliasToTableMap(),
 					filterSource.getAliasToEntityMap()
 			);
 		}
 	}
 
 	private void applyCaching(MappingDocument mappingDocument, Caching caching, Collection collection) {
 		if ( caching == null || caching.getRequested() == TruthValue.UNKNOWN ) {
 			// see if JPA's SharedCacheMode indicates we should implicitly apply caching
 			switch ( mappingDocument.getBuildingOptions().getSharedCacheMode() ) {
 				case ALL: {
 					caching = new Caching(
 							null,
 							mappingDocument.getBuildingOptions().getImplicitCacheAccessType(),
 							false,
 							TruthValue.UNKNOWN
 					);
+					break;
 				}
 				case NONE: {
 					// Ideally we'd disable all caching...
 					break;
 				}
 				case ENABLE_SELECTIVE: {
 					// this is default behavior for hbm.xml
 					break;
 				}
 				case DISABLE_SELECTIVE: {
 					// really makes no sense for hbm.xml
 					break;
 				}
 				default: {
 					// null or UNSPECIFIED, nothing to do.  IMO for hbm.xml this is equivalent
 					// to ENABLE_SELECTIVE
 					break;
 				}
 			}
 		}
 
 		if ( caching == null || caching.getRequested() == TruthValue.FALSE ) {
 			return;
 		}
 
 		if ( caching.getAccessType() != null ) {
 			collection.setCacheConcurrencyStrategy( caching.getAccessType().getExternalName() );
 		}
 		else {
 			collection.setCacheConcurrencyStrategy( mappingDocument.getBuildingOptions().getImplicitCacheAccessType().getExternalName() );
 		}
 		collection.setCacheRegionName( caching.getRegion() );
 //		collection.setCachingExplicitlyRequested( caching.getRequested() != TruthValue.UNKNOWN );
 	}
 
 	private Identifier determineTable(
 			MappingDocument sourceDocument,
 			String attributeName,
 			RelationalValueSourceContainer relationalValueSourceContainer) {
 		return determineTable( sourceDocument, attributeName, relationalValueSourceContainer.getRelationalValueSources() );
 	}
 
 	private Identifier determineTable(
 			MappingDocument mappingDocument,
 			SingularAttributeSourceEmbedded embeddedAttributeSource) {
 		Identifier tableName = null;
 		for ( AttributeSource attributeSource : embeddedAttributeSource.getEmbeddableSource().attributeSources() ) {
 			final Identifier determinedName;
 			if ( RelationalValueSourceContainer.class.isInstance( attributeSource ) ) {
 				determinedName = determineTable(
 						mappingDocument,
 						embeddedAttributeSource.getAttributeRole().getFullPath(),
 						(RelationalValueSourceContainer) attributeSource
 
 				);
 			}
 			else if ( SingularAttributeSourceEmbedded.class.isInstance( attributeSource ) ) {
 				determinedName = determineTable( mappingDocument, (SingularAttributeSourceEmbedded) attributeSource );
 			}
 			else if ( SingularAttributeSourceAny.class.isInstance( attributeSource ) ) {
 				determinedName = determineTable(
 						mappingDocument,
 						attributeSource.getAttributeRole().getFullPath(),
 						( (SingularAttributeSourceAny) attributeSource ).getKeySource().getRelationalValueSources()
 				);
 			}
 			else {
 				continue;
 			}
 
 			if (  EqualsHelper.equals( tableName, determinedName ) ) {
 				continue;
 			}
 
 			if ( tableName != null ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Attribute [%s] referenced columns from multiple tables: %s, %s",
 								embeddedAttributeSource.getAttributeRole().getFullPath(),
 								tableName,
 								determinedName
 						),
 						mappingDocument.getOrigin()
 				);
 			}
 
 			tableName = determinedName;
 		}
 
 		return tableName;
 	}
 
 	private Identifier determineTable(
 			MappingDocument mappingDocument,
 			String attributeName,
 			List<RelationalValueSource> relationalValueSources) {
 		String tableName = null;
 		for ( RelationalValueSource relationalValueSource : relationalValueSources ) {
 			if ( ColumnSource.class.isInstance( relationalValueSource ) ) {
 				final ColumnSource columnSource = (ColumnSource) relationalValueSource;
 				if ( EqualsHelper.equals( tableName, columnSource.getContainingTableName() ) ) {
 					continue;
 				}
 
 				if ( tableName != null ) {
 					throw new MappingException(
 							String.format(
 									Locale.ENGLISH,
 									"Attribute [%s] referenced columns from multiple tables: %s, %s",
 									attributeName,
 									tableName,
 									columnSource.getContainingTableName()
 							),
 							mappingDocument.getOrigin()
 					);
 				}
 
 				tableName = columnSource.getContainingTableName();
 			}
 		}
 
 		return database.toIdentifier( tableName );
 	}
 
 	private void bindSecondaryTable(
 			MappingDocument mappingDocument,
 			SecondaryTableSource secondaryTableSource,
 			Join secondaryTableJoin,
 			final EntityTableXref entityTableXref) {
 		final PersistentClass persistentClass = secondaryTableJoin.getPersistentClass();
 
 		final Identifier catalogName = determineCatalogName( secondaryTableSource.getTableSource() );
 		final Identifier schemaName = determineSchemaName( secondaryTableSource.getTableSource() );
 		final Schema schema = database.locateSchema( catalogName, schemaName );
 
 		Table secondaryTable;
 		final Identifier logicalTableName;
 
 		if ( TableSource.class.isInstance( secondaryTableSource.getTableSource() ) ) {
 			final TableSource tableSource = (TableSource) secondaryTableSource.getTableSource();
 			logicalTableName = database.toIdentifier( tableSource.getExplicitTableName() );
 			secondaryTable = schema.locateTable( logicalTableName );
 			if ( secondaryTable == null ) {
 				secondaryTable = schema.createTable( logicalTableName, false );
 			}
 			else {
 				secondaryTable.setAbstract( false );
 			}
 
 			secondaryTable.setComment( tableSource.getComment() );
 		}
 		else {
 			final InLineViewSource inLineViewSource = (InLineViewSource) secondaryTableSource.getTableSource();
 			secondaryTable = new Table(
 					schema,
 					inLineViewSource.getSelectStatement(),
 					false
 			);
 			logicalTableName = Identifier.toIdentifier( inLineViewSource.getLogicalName() );
 		}
 
 		secondaryTableJoin.setTable( secondaryTable );
 		entityTableXref.addSecondaryTable( mappingDocument, logicalTableName, secondaryTableJoin );
 
 		bindCustomSql(
 				mappingDocument,
 				secondaryTableSource,
 				secondaryTableJoin
 		);
 
 		secondaryTableJoin.setSequentialSelect( secondaryTableSource.getFetchStyle() == FetchStyle.SELECT );
 		secondaryTableJoin.setInverse( secondaryTableSource.isInverse() );
 		secondaryTableJoin.setOptional( secondaryTableSource.isOptional() );
 
 		if ( log.isDebugEnabled() ) {
 			log.debugf(
 					"Mapping entity secondary-table: %s -> %s",
 					persistentClass.getEntityName(),
 					secondaryTable.getName()
 			);
 		}
 
 		final SimpleValue keyBinding = new DependantValue(
 				mappingDocument.getMetadataCollector(),
 				secondaryTable,
 				persistentClass.getIdentifier()
 		);
 		if ( mappingDocument.getBuildingOptions().useNationalizedCharacterData() ) {
 			keyBinding.makeNationalized();
 		}
 		secondaryTableJoin.setKey( keyBinding );
 
 		keyBinding.setCascadeDeleteEnabled( secondaryTableSource.isCascadeDeleteEnabled() );
 
 		// NOTE : no Type info to bind...
 
 		relationalObjectBinder.bindColumns(
 				mappingDocument,
 				secondaryTableSource.getPrimaryKeyColumnSources(),
 				keyBinding,
 				secondaryTableSource.isOptional(),
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					int count = 0;
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						final Column correspondingColumn = entityTableXref.getPrimaryTable().getPrimaryKey().getColumn( count++ );
 						return database.toIdentifier( correspondingColumn.getQuotedName() );
 					}
 				}
 		);
 
 		keyBinding.setForeignKeyName( secondaryTableSource.getExplicitForeignKeyName() );
 
 		secondaryTableJoin.createPrimaryKey();
 		secondaryTableJoin.createForeignKey();
 	}
 
 	private Property createEmbeddedAttribute(
 			MappingDocument sourceDocument,
 			SingularAttributeSourceEmbedded embeddedSource,
 			Component componentBinding,
 			String containingClassName) {
 		final String attributeName = embeddedSource.getName();
 
 		bindComponent(
 				sourceDocument,
 				embeddedSource.getEmbeddableSource(),
 				componentBinding,
 				containingClassName,
 				attributeName,
 				embeddedSource.getXmlNodeName(),
 				embeddedSource.isVirtualAttribute()
 		);
 
 		prepareValueTypeViaReflection(
 				sourceDocument,
 				componentBinding,
 				componentBinding.getComponentClassName(),
 				attributeName,
 				embeddedSource.getAttributeRole()
 		);
 
 		componentBinding.createForeignKey();
 
 		final Property attribute;
 		if ( embeddedSource.isVirtualAttribute() ) {
 			attribute = new SyntheticProperty() {
 				@Override
 				public String getPropertyAccessorName() {
 					return "embedded";
 				}
 			};
 		}
 		else {
 			attribute = new Property();
 		}
 		attribute.setValue( componentBinding );
 		bindProperty(
 				sourceDocument,
 				embeddedSource,
 				attribute
 		);
 
 		final String xmlNodeName = determineXmlNodeName( embeddedSource, componentBinding.getOwner().getNodeName() );
 		componentBinding.setNodeName( xmlNodeName );
 		attribute.setNodeName( xmlNodeName );
 
 		return attribute;
 	}
 
 	private Property createBasicAttribute(
 			MappingDocument sourceDocument,
 			final SingularAttributeSourceBasic attributeSource,
 			SimpleValue value,
 			String containingClassName) {
 		final String attributeName = attributeSource.getName();
 
 		bindSimpleValueType(
 				sourceDocument,
 				attributeSource.getTypeInformation(),
 				value
 		);
 
 		relationalObjectBinder.bindColumnsAndFormulas(
 				sourceDocument,
 				attributeSource.getRelationalValueSources(),
 				value,
 				true,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						return implicitNamingStrategy.determineBasicColumnName( attributeSource );
 					}
 				}
 		);
 
 
 		prepareValueTypeViaReflection(
 				sourceDocument,
 				value,
 				containingClassName,
 				attributeName,
 				attributeSource.getAttributeRole()
 		);
 
 //		// this is done here 'cos we might only know the type here (ugly!)
 //		// TODO: improve this a lot:
 //		if ( value instanceof ToOne ) {
 //			ToOne toOne = (ToOne) value;
 //			String propertyRef = toOne.getReferencedEntityAttributeName();
 //			if ( propertyRef != null ) {
 //				mappings.addUniquePropertyReference( toOne.getReferencedEntityName(), propertyRef );
 //			}
 //			toOne.setCascadeDeleteEnabled( "cascade".equals( subnode.attributeValue( "on-delete" ) ) );
 //		}
 //		else if ( value instanceof Collection ) {
 //			Collection coll = (Collection) value;
 //			String propertyRef = coll.getReferencedEntityAttributeName();
 //			// not necessarily a *unique* property reference
 //			if ( propertyRef != null ) {
 //				mappings.addPropertyReference( coll.getOwnerEntityName(), propertyRef );
 //			}
 //		}
 
 		value.createForeignKey();
 
 		Property property = new Property();
 		property.setValue( value );
 		bindProperty(
 				sourceDocument,
 				attributeSource,
 				property
 		);
 
 		return property;
 	}
 
 	private Property createOneToOneAttribute(
 			MappingDocument sourceDocument,
 			SingularAttributeSourceOneToOne oneToOneSource,
 			OneToOne oneToOneBinding,
 			String containingClassName) {
 		bindOneToOne( sourceDocument, oneToOneSource, oneToOneBinding );
 
 		prepareValueTypeViaReflection(
 				sourceDocument,
 				oneToOneBinding,
 				containingClassName,
 				oneToOneSource.getName(),
 				oneToOneSource.getAttributeRole()
 		);
 
 		final String propertyRef = oneToOneBinding.getReferencedPropertyName();
 		if ( propertyRef != null ) {
 			handlePropertyReference(
 					sourceDocument,
 					oneToOneBinding.getReferencedEntityName(),
 					propertyRef,
 					true,
 					"<one-to-one name=\"" + oneToOneSource.getName() + "\"/>"
 			);
 		}
 
 		oneToOneBinding.createForeignKey();
 
 		Property prop = new Property();
 		prop.setValue( oneToOneBinding );
 		bindProperty(
 				sourceDocument,
 				oneToOneSource,
 				prop
 		);
 
 		return prop;
 	}
 
 	private void handlePropertyReference(
 			MappingDocument mappingDocument,
 			String referencedEntityName,
 			String referencedPropertyName,
 			boolean isUnique,
 			String sourceElementSynopsis) {
 		PersistentClass entityBinding = mappingDocument.getMetadataCollector().getEntityBinding( referencedEntityName );
 		if ( entityBinding == null ) {
 			// entity may just not have been processed yet - set up a delayed handler
 			registerDelayedPropertyReferenceHandler(
 					new DelayedPropertyReferenceHandlerImpl(
 							referencedEntityName,
 							referencedPropertyName,
 							isUnique,
 							sourceElementSynopsis,
 							mappingDocument.getOrigin()
 					),
 					mappingDocument
 			);
 		}
 		else {
 			Property propertyBinding = entityBinding.getReferencedProperty( referencedPropertyName );
 			if ( propertyBinding == null ) {
 				// attribute may just not have been processed yet - set up a delayed handler
 				registerDelayedPropertyReferenceHandler(
 						new DelayedPropertyReferenceHandlerImpl(
 								referencedEntityName,
 								referencedPropertyName,
 								isUnique,
 								sourceElementSynopsis,
 								mappingDocument.getOrigin()
 						),
 						mappingDocument
 				);
 			}
 			else {
 				log.tracef(
 						"Property [%s.%s] referenced by property-ref [%s] was available - no need for delayed handling",
 						referencedEntityName,
 						referencedPropertyName,
 						sourceElementSynopsis
 				);
 				if ( isUnique ) {
 					( (SimpleValue) propertyBinding.getValue() ).setAlternateUniqueKey( true );
 				}
 			}
 		}
 	}
 
 	private void registerDelayedPropertyReferenceHandler(
 			DelayedPropertyReferenceHandlerImpl handler,
 			MetadataBuildingContext buildingContext) {
 		log.tracef(
 				"Property [%s.%s] referenced by property-ref [%s] was not yet available - creating delayed handler",
 				handler.referencedEntityName,
 				handler.referencedPropertyName,
 				handler.sourceElementSynopsis
 		);
 		buildingContext.getMetadataCollector().addDelayedPropertyReferenceHandler( handler );
 	}
 
 	public void bindOneToOne(
 			final MappingDocument sourceDocument,
 			final SingularAttributeSourceOneToOne oneToOneSource,
 			final OneToOne oneToOneBinding) {
 		oneToOneBinding.setPropertyName( oneToOneSource.getName() );
 
 		relationalObjectBinder.bindFormulas(
 				sourceDocument,
 				oneToOneSource.getFormulaSources(),
 				oneToOneBinding
 		);
 
 
 		if ( oneToOneSource.isConstrained() ) {
 			if ( oneToOneSource.getCascadeStyleName() != null
 					&& oneToOneSource.getCascadeStyleName().contains( "delete-orphan" ) ) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"one-to-one attribute [%s] cannot specify orphan delete cascading as it is constrained",
 								oneToOneSource.getAttributeRole().getFullPath()
 						),
 						sourceDocument.getOrigin()
 				);
 			}
 			oneToOneBinding.setConstrained( true );
 			oneToOneBinding.setForeignKeyType( ForeignKeyDirection.FROM_PARENT );
 		}
 		else {
 			oneToOneBinding.setForeignKeyType( ForeignKeyDirection.TO_PARENT );
 		}
 
 		oneToOneBinding.setLazy( oneToOneSource.getFetchCharacteristics().getFetchTiming() == FetchTiming.DELAYED );
 		oneToOneBinding.setFetchMode(
 				oneToOneSource.getFetchCharacteristics().getFetchStyle() == FetchStyle.SELECT
 						? FetchMode.SELECT
 						: FetchMode.JOIN
 		);
 		oneToOneBinding.setUnwrapProxy( oneToOneSource.getFetchCharacteristics().isUnwrapProxies() );
 
 
 		if ( StringHelper.isNotEmpty( oneToOneSource.getReferencedEntityAttributeName() ) ) {
 			oneToOneBinding.setReferencedPropertyName( oneToOneSource.getReferencedEntityAttributeName() );
 			oneToOneBinding.setReferenceToPrimaryKey( false );
 		}
 		else {
 			oneToOneBinding.setReferenceToPrimaryKey( true );
 		}
 
 		// todo : probably need some reflection here if null
 		oneToOneBinding.setReferencedEntityName( oneToOneSource.getReferencedEntityName() );
 
 		if ( oneToOneSource.isEmbedXml() ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfEmbedXmlSupport();
 		}
 		oneToOneBinding.setEmbedded( oneToOneSource.isEmbedXml() );
 
 		if ( StringHelper.isNotEmpty( oneToOneSource.getExplicitForeignKeyName() ) ) {
 			oneToOneBinding.setForeignKeyName( oneToOneSource.getExplicitForeignKeyName() );
 		}
 
 		oneToOneBinding.setCascadeDeleteEnabled( oneToOneSource.isCascadeDeleteEnabled() );
 	}
 
 	private Property createManyToOneAttribute(
 			MappingDocument sourceDocument,
 			SingularAttributeSourceManyToOne manyToOneSource,
 			ManyToOne manyToOneBinding,
 			String containingClassName) {
 		final String attributeName = manyToOneSource.getName();
 
 		final String referencedEntityName;
 		if ( manyToOneSource.getReferencedEntityName() != null ) {
 			referencedEntityName = manyToOneSource.getReferencedEntityName();
 		}
 		else {
 			Class reflectedPropertyClass = Helper.reflectedPropertyClass( sourceDocument, containingClassName, attributeName );
 			if ( reflectedPropertyClass != null ) {
 				referencedEntityName = reflectedPropertyClass.getName();
 			}
 			else {
 				prepareValueTypeViaReflection(
 						sourceDocument,
 						manyToOneBinding,
 						containingClassName,
 						attributeName,
 						manyToOneSource.getAttributeRole()
 				);
 				referencedEntityName = manyToOneBinding.getTypeName();
 			}
 		}
 
 		if ( manyToOneSource.isUnique() ) {
 			manyToOneBinding.markAsLogicalOneToOne();
 		}
 
 		bindManyToOneAttribute( sourceDocument, manyToOneSource, manyToOneBinding, referencedEntityName );
 
 		final String propertyRef = manyToOneBinding.getReferencedPropertyName();
 
 		if ( propertyRef != null ) {
 			handlePropertyReference(
 					sourceDocument,
 					manyToOneBinding.getReferencedEntityName(),
 					propertyRef,
 					true,
 					"<many-to-one name=\"" + manyToOneSource.getName() + "\"/>"
 			);
 		}
 
 		Property prop = new Property();
 		prop.setValue( manyToOneBinding );
 		bindProperty(
 				sourceDocument,
 				manyToOneSource,
 				prop
 		);
 
 		if ( StringHelper.isNotEmpty( manyToOneSource.getCascadeStyleName() ) ) {
 			// todo : would be better to delay this the end of binding (second pass, etc)
 			// in order to properly allow for a singular unique column for a many-to-one to
 			// also trigger a "logical one-to-one".  As-is, this can occasionally lead to
 			// false exceptions if the many-to-one column binding is delayed and the
 			// uniqueness is indicated on the <column/> rather than on the <many-to-one/>
 			//
 			// Ideally, would love to see a SimpleValue#validate approach, rather than a
 			// SimpleValue#isValid that is then handled at a higher level (Property, etc).
 			// The reason being that the current approach misses the exact reason
 			// a "validation" fails since it loses "context"
 			if ( manyToOneSource.getCascadeStyleName().contains( "delete-orphan" ) ) {
 				if ( !manyToOneBinding.isLogicalOneToOne() ) {
 					throw new MappingException(
 							String.format(
 									Locale.ENGLISH,
 									"many-to-one attribute [%s] specified delete-orphan but is not specified as unique; " +
 											"remove delete-orphan cascading or specify unique=\"true\"",
 									manyToOneSource.getAttributeRole().getFullPath()
 							),
 							sourceDocument.getOrigin()
 					);
 				}
 			}
 		}
 
 		return prop;
 	}
 
 	private void bindManyToOneAttribute(
 			final MappingDocument sourceDocument,
 			final SingularAttributeSourceManyToOne manyToOneSource,
 			ManyToOne manyToOneBinding,
 			String referencedEntityName) {
 		// NOTE : no type information to bind
 
 		manyToOneBinding.setReferencedEntityName( referencedEntityName );
 		if ( StringHelper.isNotEmpty( manyToOneSource.getReferencedEntityAttributeName() ) ) {
 			manyToOneBinding.setReferencedPropertyName( manyToOneSource.getReferencedEntityAttributeName() );
 			manyToOneBinding.setReferenceToPrimaryKey( false );
 		}
 		else {
 			manyToOneBinding.setReferenceToPrimaryKey( true );
 		}
 
 		manyToOneBinding.setLazy( manyToOneSource.getFetchCharacteristics().getFetchTiming() == FetchTiming.DELAYED );
 		manyToOneBinding.setUnwrapProxy( manyToOneSource.getFetchCharacteristics().isUnwrapProxies() );
 		manyToOneBinding.setFetchMode(
 				manyToOneSource.getFetchCharacteristics().getFetchStyle() == FetchStyle.SELECT
 						? FetchMode.SELECT
 						: FetchMode.JOIN
 		);
 
 		if ( manyToOneSource.isEmbedXml() ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfEmbedXmlSupport();
 		}
 		manyToOneBinding.setEmbedded( manyToOneSource.isEmbedXml() );
 
 		manyToOneBinding.setIgnoreNotFound( manyToOneSource.isIgnoreNotFound() );
 
 		if ( StringHelper.isNotEmpty( manyToOneSource.getExplicitForeignKeyName() ) ) {
 			manyToOneBinding.setForeignKeyName( manyToOneSource.getExplicitForeignKeyName() );
 		}
 
 		final ManyToOneColumnBinder columnBinder = new ManyToOneColumnBinder(
 				sourceDocument,
 				manyToOneSource,
 				manyToOneBinding,
 				referencedEntityName
 		);
 		final boolean canBindColumnsImmediately = columnBinder.canProcessImmediately();
 		if ( canBindColumnsImmediately ) {
 			columnBinder.doSecondPass( null );
 		}
 		else {
 			sourceDocument.getMetadataCollector().addSecondPass( columnBinder );
 		}
 
 		if ( !manyToOneSource.isIgnoreNotFound() ) {
 			// we skip creating the FK here since this setting tells us there
 			// cannot be a suitable/proper FK
 			final ManyToOneFkSecondPass fkSecondPass = new ManyToOneFkSecondPass(
 					sourceDocument,
 					manyToOneSource,
 					manyToOneBinding,
 					referencedEntityName
 			);
 
 			if ( canBindColumnsImmediately && fkSecondPass.canProcessImmediately() ) {
 				fkSecondPass.doSecondPass( null );
 			}
 			else {
 				sourceDocument.getMetadataCollector().addSecondPass( fkSecondPass );
 			}
 		}
 
 		manyToOneBinding.setCascadeDeleteEnabled( manyToOneSource.isCascadeDeleteEnabled() );
 	}
 
 	private Property createAnyAssociationAttribute(
 			MappingDocument sourceDocument,
 			SingularAttributeSourceAny anyMapping,
 			Any anyBinding,
 			String entityName) {
 		final String attributeName = anyMapping.getName();
 
 		bindAny( sourceDocument, anyMapping, anyBinding, anyMapping.getAttributeRole(), anyMapping.getAttributePath() );
 
 		prepareValueTypeViaReflection( sourceDocument, anyBinding, entityName, attributeName, anyMapping.getAttributeRole() );
 
 		anyBinding.createForeignKey();
 
 		Property prop = new Property();
 		prop.setValue( anyBinding );
 		bindProperty(
 				sourceDocument,
 				anyMapping,
 				prop
 		);
 
 		return prop;
 	}
 
 	private void bindAny(
 			MappingDocument sourceDocument,
 			final AnyMappingSource anyMapping,
 			Any anyBinding,
 			final AttributeRole attributeRole,
 			AttributePath attributePath) {
 		final TypeResolution keyTypeResolution = resolveType(
 				sourceDocument,
 				anyMapping.getKeySource().getTypeSource()
 		);
 		if ( keyTypeResolution != null ) {
 			anyBinding.setIdentifierType( keyTypeResolution.typeName );
 		}
 
 		final TypeResolution discriminatorTypeResolution = resolveType(
 				sourceDocument,
 				anyMapping.getDiscriminatorSource().getTypeSource()
 		);
 
 		if ( discriminatorTypeResolution != null ) {
 			anyBinding.setMetaType( discriminatorTypeResolution.typeName );
 			try {
 				final DiscriminatorType metaType = (DiscriminatorType) sourceDocument.getMetadataCollector()
 						.getTypeResolver()
 						.heuristicType( discriminatorTypeResolution.typeName );
 
 				final HashMap anyValueBindingMap = new HashMap();
 				for ( Map.Entry<String,String> discriminatorValueMappings : anyMapping.getDiscriminatorSource().getValueMappings().entrySet() ) {
 					try {
 						final Object discriminatorValue = metaType.stringToObject( discriminatorValueMappings.getKey() );
 						final String mappedEntityName = sourceDocument.qualifyClassName( discriminatorValueMappings.getValue() );
 
 						//noinspection unchecked
 						anyValueBindingMap.put( discriminatorValue, mappedEntityName );
 					}
 					catch (Exception e) {
 						throw new MappingException(
 								String.format(
 										Locale.ENGLISH,
 										"Unable to interpret <meta-value value=\"%s\" class=\"%s\"/> defined as part of <any/> attribute [%s]",
 										discriminatorValueMappings.getKey(),
 										discriminatorValueMappings.getValue(),
 										attributeRole.getFullPath()
 								),
 								e,
 								sourceDocument.getOrigin()
 						);
 					}
 
 				}
 				anyBinding.setMetaValues( anyValueBindingMap );
 			}
 			catch (ClassCastException e) {
 				throw new MappingException(
 						String.format(
 								Locale.ENGLISH,
 								"Specified meta-type [%s] for <any/> attribute [%s] did not implement DiscriminatorType",
 								discriminatorTypeResolution.typeName,
 								attributeRole.getFullPath()
 						),
 						e,
 						sourceDocument.getOrigin()
 				);
 			}
 		}
 
 		relationalObjectBinder.bindColumnOrFormula(
 				sourceDocument,
 				anyMapping.getDiscriminatorSource().getRelationalValueSource(),
 				anyBinding,
 				true,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						return implicitNamingStrategy.determineAnyDiscriminatorColumnName(
 								anyMapping.getDiscriminatorSource()
 						);
 					}
 				}
 		);
 
 		relationalObjectBinder.bindColumnsAndFormulas(
 				sourceDocument,
 				anyMapping.getKeySource().getRelationalValueSources(),
 				anyBinding,
 				true,
 				new RelationalObjectBinder.ColumnNamingDelegate() {
 					@Override
 					public Identifier determineImplicitName(LocalMetadataBuildingContext context) {
 						return implicitNamingStrategy.determineAnyKeyColumnName(
 								anyMapping.getKeySource()
 						);
 					}
 				}
 		);
 	}
 
 	private void prepareValueTypeViaReflection(
 			MappingDocument sourceDocument,
 			Value value,
 			String containingClassName,
 			String propertyName,
 			AttributeRole attributeRole) {
 		if ( StringHelper.isEmpty( propertyName ) ) {
 			throw new MappingException(
 					String.format(
 							Locale.ENGLISH,
 							"Attribute mapping must define a name attribute: containingClassName=[%s], propertyName=[%s], role=[%s]",
 							containingClassName,
 							propertyName,
 							attributeRole.getFullPath()
 					),
 					sourceDocument.getOrigin()
 			);
 		}
 
 		try {
 			value.setTypeUsingReflection( containingClassName, propertyName );
 		}
 		catch (org.hibernate.MappingException ome) {
 			throw new MappingException(
 					String.format(
 							Locale.ENGLISH,
 							"Error calling Value#setTypeUsingReflection: containingClassName=[%s], propertyName=[%s], role=[%s]",
 							containingClassName,
 							propertyName,
 							attributeRole.getFullPath()
 					),
 					ome,
 					sourceDocument.getOrigin()
 			);
 		}
 	}
 
 	private void bindProperty(
 			MappingDocument mappingDocument,
 			AttributeSource propertySource,
 			Property property) {
 		property.setName( propertySource.getName() );
 		property.setNodeName( determineXmlNodeName( propertySource, null ) );
 
 		property.setPropertyAccessorName(
 				StringHelper.isNotEmpty( propertySource.getPropertyAccessorName() )
 						? propertySource.getPropertyAccessorName()
 						: mappingDocument.getMappingDefaults().getImplicitPropertyAccessorName()
 		);
 
 		if ( propertySource instanceof CascadeStyleSource ) {
 			final CascadeStyleSource cascadeStyleSource = (CascadeStyleSource) propertySource;
 
 			property.setCascade(
 					StringHelper.isNotEmpty( cascadeStyleSource.getCascadeStyleName() )
 							? cascadeStyleSource.getCascadeStyleName()
 							: mappingDocument.getMappingDefaults().getImplicitCascadeStyleName()
 			);
 		}
 
 		property.setOptimisticLocked( propertySource.isIncludedInOptimisticLocking() );
 
 		if ( propertySource.isSingular() ) {
 			final SingularAttributeSource singularAttributeSource = (SingularAttributeSource) propertySource;
 
 			property.setInsertable( singularAttributeSource.isInsertable() );
 			property.setUpdateable( singularAttributeSource.isUpdatable() );
 
 			// NOTE : Property#is refers to whether a property is lazy via bytecode enhancement (not proxies)
 			property.setLazy( singularAttributeSource.isBytecodeLazy() );
 
 			final GenerationTiming generationTiming = singularAttributeSource.getGenerationTiming();
 			if ( generationTiming == GenerationTiming.ALWAYS || generationTiming == GenerationTiming.INSERT ) {
 				// we had generation specified...
 				//   	HBM only supports "database generated values"
 				property.setValueGenerationStrategy( new GeneratedValueGeneration( generationTiming ) );
 
 				// generated properties can *never* be insertable...
 				if ( property.isInsertable() ) {
 					if ( singularAttributeSource.isInsertable() == null ) {
 						// insertable simply because that is the user did not specify
 						// anything; just override it
 						property.setInsertable( false );
 					}
 					else {
 						// the user specifically supplied insert="true",
 						// which constitutes an illegal combo
 						throw new MappingException(
 								String.format(
 										Locale.ENGLISH,
 										"Cannot specify both insert=\"true\" and generated=\"%s\" for property %s",
 										generationTiming.name().toLowerCase(Locale.ROOT),
 										propertySource.getName()
 								),
 								mappingDocument.getOrigin()
 						);
 					}
 				}
 
 				// properties generated on update can never be updatable...
 				if ( property.isUpdateable() && generationTiming == GenerationTiming.ALWAYS ) {
 					if ( singularAttributeSource.isUpdatable() == null ) {
 						// updatable only because the user did not specify
 						// anything; just override it
 						property.setUpdateable( false );
 					}
 					else {
 						// the user specifically supplied update="true",
 						// which constitutes an illegal combo
 						throw new MappingException(
 								String.format(
 										Locale.ENGLISH,
 										"Cannot specify both update=\"true\" and generated=\"%s\" for property %s",
 										generationTiming.name().toLowerCase(Locale.ROOT),
 										propertySource.getName()
 								),
 								mappingDocument.getOrigin()
 						);
 					}
 				}
 			}
 		}
 
 		property.setMetaAttributes( propertySource.getToolingHintContext().getMetaAttributeMap() );
 
 		if ( log.isDebugEnabled() ) {
 			final StringBuilder message = new StringBuilder()
 					.append( "Mapped property: " )
 					.append( propertySource.getName() )
 					.append( " -> [" );
 			final Iterator itr = property.getValue().getColumnIterator();
 			while ( itr.hasNext() ) {
 				message.append( ( (Selectable) itr.next() ).getText() );
 				if ( itr.hasNext() ) {
 					message.append( ", " );
 				}
 			}
 			message.append( "]" );
 			log.debug( message.toString() );
 		}
 	}
 
 	private String determineXmlNodeName(AttributeSource propertySource, String fallbackXmlNodeName) {
 		String nodeName = propertySource.getXmlNodeName();
 		if ( StringHelper.isNotEmpty( nodeName ) ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecationOfDomEntityModeSupport();
 		}
 		else {
 			nodeName = propertySource.getName();
 		}
 		if ( nodeName == null ) {
 			nodeName = fallbackXmlNodeName;
 		}
 
 		return nodeName;
 	}
 
 	private void bindComponent(
 			MappingDocument sourceDocument,
 			EmbeddableSource embeddableSource,
 			Component component,
 			String containingClassName,
 			String propertyName,
 			String xmlNodeName,
 			boolean isVirtual) {
 		final String fullRole = embeddableSource.getAttributeRoleBase().getFullPath();
 		final String explicitComponentClassName = extractExplicitComponentClassName( embeddableSource );
 
 		bindComponent(
 				sourceDocument,
 				fullRole,
 				embeddableSource,
 				component,
 				explicitComponentClassName,
 				containingClassName,
 				propertyName,
 				isVirtual,
 				embeddableSource.isDynamic(),
 				xmlNodeName
 		);
 	}
 
 	private String extractExplicitComponentClassName(EmbeddableSource embeddableSource) {
 		if ( embeddableSource.getTypeDescriptor() == null ) {
 			return null;
 		}
 
 		return embeddableSource.getTypeDescriptor().getName();
 	}
 
 	private void bindComponent(
 			MappingDocument sourceDocument,
 			String role,
 			EmbeddableSource embeddableSource,
 			Component componentBinding,
 			String explicitComponentClassName,
 			String containingClassName,
 			String propertyName,
 			boolean isVirtual,
 			boolean isDynamic,
 			String xmlNodeName) {
 
 		componentBinding.setMetaAttributes( embeddableSource.getToolingHintContext().getMetaAttributeMap() );
 
 		componentBinding.setRoleName( role );
 
 		componentBinding.setEmbedded( isVirtual );
 
 		// todo : better define the conditions in this if/else
 		if ( isDynamic ) {
 			// dynamic is represented as a Map
 			log.debugf( "Binding dynamic-component [%s]", role );
 			componentBinding.setDynamic( true );
 		}
 		else if ( isVirtual ) {
 			// virtual (what used to be called embedded) is just a conceptual composition...
 			// <properties/> for example
 			if ( componentBinding.getOwner().hasPojoRepresentation() ) {
 				log.debugf( "Binding virtual component [%s] to owner class [%s]", role, componentBinding.getOwner().getClassName() );
 				componentBinding.setComponentClassName( componentBinding.getOwner().getClassName() );
 			}
 			else {
 				log.debugf( "Binding virtual component [%s] as dynamic", role );
 				componentBinding.setDynamic( true );
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/spi/AbstractDelegatingSessionFactoryBuilder.java b/hibernate-core/src/main/java/org/hibernate/boot/spi/AbstractDelegatingSessionFactoryBuilder.java
index ccac4c7f7d..56742fb424 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/spi/AbstractDelegatingSessionFactoryBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/spi/AbstractDelegatingSessionFactoryBuilder.java
@@ -1,389 +1,387 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.spi;
 
 import java.util.Map;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.Interceptor;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.NullPrecedence;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.boot.SessionFactoryBuilder;
 import org.hibernate.boot.TempTableDdlTransactionHandling;
 import org.hibernate.cache.spi.QueryCacheFactory;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.loader.BatchFetchStyle;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.tuple.entity.EntityTuplizerFactory;
 
 /**
  * Convenience base class for custom implementors of SessionFactoryBuilder, using delegation
  *
  * @author Steve Ebersole
  * @author Gunnar Morling
  * @param <T> The type of a specific sub-class; Allows sub-classes to narrow down the return-type of the contract methods
  * to a specialization of {@link SessionFactoryBuilder}
  */
 public abstract class AbstractDelegatingSessionFactoryBuilder<T extends AbstractDelegatingSessionFactoryBuilder<T>> implements SessionFactoryBuilder {
 	private final SessionFactoryBuilder delegate;
 
 	public AbstractDelegatingSessionFactoryBuilder(SessionFactoryBuilder delegate) {
 		this.delegate = delegate;
 	}
 
 	/**
 	 * Returns a specific implementation. See the <a
 	 * href="http://www.angelikalanger.com/GenericsFAQ/FAQSections/ProgrammingIdioms.html#FAQ206">What is the
 	 * "getThis trick?"</a>.
 	 */
 	protected abstract T getThis();
 
 	@Override
 	public T applyValidatorFactory(Object validatorFactory) {
 		delegate.applyValidatorFactory( validatorFactory );
 		return getThis();
 	}
 
 	@Override
 	public T applyBeanManager(Object beanManager) {
 		delegate.applyBeanManager( beanManager );
 		return getThis();
 	}
 
 	@Override
 	public T applyName(String sessionFactoryName) {
 		delegate.applyName( sessionFactoryName );
 		return getThis();
 	}
 
 	@Override
 	public T applyNameAsJndiName(boolean isJndiName) {
 		delegate.applyNameAsJndiName( isJndiName );
 		return getThis();
 	}
 
 	@Override
 	public T applyAutoClosing(boolean enabled) {
 		delegate.applyAutoClosing( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyAutoFlushing(boolean enabled) {
 		delegate.applyAutoFlushing( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyStatisticsSupport(boolean enabled) {
 		delegate.applyStatisticsSupport( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyInterceptor(Interceptor interceptor) {
 		delegate.applyInterceptor( interceptor );
 		return getThis();
 	}
 
 	@Override
 	public T applyStatementInspector(StatementInspector statementInspector) {
 		delegate.applyStatementInspector( statementInspector );
 		return getThis();
 	}
 
 	@Override
 	public T addSessionFactoryObservers(SessionFactoryObserver... observers) {
 		delegate.addSessionFactoryObservers( observers );
 		return getThis();
 	}
 
 	@Override
 	public T applyCustomEntityDirtinessStrategy(CustomEntityDirtinessStrategy strategy) {
 		delegate.applyCustomEntityDirtinessStrategy( strategy );
 		return getThis();
 	}
 
 	@Override
 	public T addEntityNameResolver(EntityNameResolver... entityNameResolvers) {
 		delegate.addEntityNameResolver( entityNameResolvers );
 		return getThis();
 	}
 
 	@Override
 	public T applyEntityNotFoundDelegate(EntityNotFoundDelegate entityNotFoundDelegate) {
 		delegate.applyEntityNotFoundDelegate( entityNotFoundDelegate );
 		return getThis();
 	}
 
 	@Override
 	public T applyIdentifierRollbackSupport(boolean enabled) {
 		delegate.applyIdentifierRollbackSupport( enabled );
 		return getThis();
 	}
 
 	@Override
-	@Deprecated
 	@SuppressWarnings("deprecation")
 	public T applyDefaultEntityMode(EntityMode entityMode) {
 		delegate.applyDefaultEntityMode( entityMode );
 		return getThis();
 	}
 
 	@Override
 	public T applyNullabilityChecking(boolean enabled) {
 		delegate.applyNullabilityChecking( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyLazyInitializationOutsideTransaction(boolean enabled) {
 		delegate.applyLazyInitializationOutsideTransaction( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyEntityTuplizerFactory(EntityTuplizerFactory entityTuplizerFactory) {
 		delegate.applyEntityTuplizerFactory( entityTuplizerFactory );
 		return getThis();
 	}
 
 	@Override
 	public T applyEntityTuplizer(
 			EntityMode entityMode,
 			Class<? extends EntityTuplizer> tuplizerClass) {
 		delegate.applyEntityTuplizer( entityMode, tuplizerClass );
 		return getThis();
 	}
 
 	@Override
 	public T applyMultiTableBulkIdStrategy(MultiTableBulkIdStrategy strategy) {
 		delegate.applyMultiTableBulkIdStrategy( strategy );
 		return getThis();
 	}
 
 	@Override
 	public T applyTempTableDdlTransactionHandling(TempTableDdlTransactionHandling handling) {
 		delegate.applyTempTableDdlTransactionHandling( handling );
 		return getThis();
 	}
 
 	@Override
 	public T applyBatchFetchStyle(BatchFetchStyle style) {
 		delegate.applyBatchFetchStyle( style );
 		return getThis();
 	}
 
 	@Override
 	public T applyDefaultBatchFetchSize(int size) {
 		delegate.applyDefaultBatchFetchSize( size );
 		return getThis();
 	}
 
 	@Override
 	public T applyMaximumFetchDepth(int depth) {
 		delegate.applyMaximumFetchDepth( depth );
 		return getThis();
 	}
 
 	@Override
 	public T applyDefaultNullPrecedence(NullPrecedence nullPrecedence) {
 		delegate.applyDefaultNullPrecedence( nullPrecedence );
 		return getThis();
 	}
 
 	@Override
 	public T applyOrderingOfInserts(boolean enabled) {
 		delegate.applyOrderingOfInserts( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyOrderingOfUpdates(boolean enabled) {
 		delegate.applyOrderingOfUpdates( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyMultiTenancyStrategy(MultiTenancyStrategy strategy) {
 		delegate.applyMultiTenancyStrategy( strategy );
 		return getThis();
 	}
 
 	@Override
 	public T applyCurrentTenantIdentifierResolver(CurrentTenantIdentifierResolver resolver) {
 		delegate.applyCurrentTenantIdentifierResolver( resolver );
 		return getThis();
 	}
 
 	@Override
 	public T applyJtaTrackingByThread(boolean enabled) {
 		delegate.applyJtaTrackingByThread( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyPreferUserTransactions(boolean preferUserTransactions) {
 		delegate.applyPreferUserTransactions( preferUserTransactions );
 		return getThis();
 	}
 
 	@Override
-	@Deprecated
 	@SuppressWarnings("deprecation")
 	public T applyQuerySubstitutions(Map substitutions) {
 		delegate.applyQuerySubstitutions( substitutions );
 		return getThis();
 	}
 
 	@Override
 	public T applyStrictJpaQueryLanguageCompliance(boolean enabled) {
 		delegate.applyStrictJpaQueryLanguageCompliance( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyNamedQueryCheckingOnStartup(boolean enabled) {
 		delegate.applyNamedQueryCheckingOnStartup( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applySecondLevelCacheSupport(boolean enabled) {
 		delegate.applySecondLevelCacheSupport( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyQueryCacheSupport(boolean enabled) {
 		delegate.applyQueryCacheSupport( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyQueryCacheFactory(QueryCacheFactory factory) {
 		delegate.applyQueryCacheFactory( factory );
 		return getThis();
 	}
 
 	@Override
 	public T applyCacheRegionPrefix(String prefix) {
 		delegate.applyCacheRegionPrefix( prefix );
 		return getThis();
 	}
 
 	@Override
 	public T applyMinimalPutsForCaching(boolean enabled) {
 		delegate.applyMinimalPutsForCaching( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyStructuredCacheEntries(boolean enabled) {
 		delegate.applyStructuredCacheEntries( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyDirectReferenceCaching(boolean enabled) {
 		delegate.applyDirectReferenceCaching( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyAutomaticEvictionOfCollectionCaches(boolean enabled) {
 		delegate.applyAutomaticEvictionOfCollectionCaches( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyJdbcBatchSize(int size) {
 		delegate.applyJdbcBatchSize( size );
 		return getThis();
 	}
 
 	@Override
 	public T applyJdbcBatchingForVersionedEntities(boolean enabled) {
 		delegate.applyJdbcBatchingForVersionedEntities( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyScrollableResultsSupport(boolean enabled) {
 		delegate.applyScrollableResultsSupport( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyResultSetsWrapping(boolean enabled) {
 		delegate.applyResultSetsWrapping( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyGetGeneratedKeysSupport(boolean enabled) {
 		delegate.applyGetGeneratedKeysSupport( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applyJdbcFetchSize(int size) {
 		delegate.applyJdbcFetchSize( size );
 		return getThis();
 	}
 
 	@Override
 	public T applyConnectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 		delegate.applyConnectionReleaseMode( connectionReleaseMode );
 		return getThis();
 	}
 
 	@Override
 	public T applySqlComments(boolean enabled) {
 		delegate.applySqlComments( enabled );
 		return getThis();
 	}
 
 	@Override
 	public T applySqlFunction(
 			String registrationName,
 			SQLFunction sqlFunction) {
 		delegate.applySqlFunction( registrationName, sqlFunction );
 		return getThis();
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <S extends SessionFactoryBuilder> S unwrap(Class<S> type) {
 		return (S) this;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/collection/internal/PersistentIndexedElementHolder.java b/hibernate-core/src/main/java/org/hibernate/collection/internal/PersistentIndexedElementHolder.java
index b4695e5867..5828d8da2b 100755
--- a/hibernate-core/src/main/java/org/hibernate/collection/internal/PersistentIndexedElementHolder.java
+++ b/hibernate-core/src/main/java/org/hibernate/collection/internal/PersistentIndexedElementHolder.java
@@ -1,300 +1,300 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.collection.internal;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.persister.collection.CollectionPersister;
+import org.hibernate.type.StringRepresentableType;
 import org.hibernate.type.Type;
-import org.hibernate.type.XmlRepresentableType;
 
 import org.dom4j.Element;
 
 /**
  * A persistent wrapper for an XML element
  *
  * @author Gavin King
  *
  * @deprecated To be removed in 5.  Removed as part of removing the notion of DOM entity-mode.  See Jira issues
  * <a href="https://hibernate.onjira.com/browse/HHH-7782">HHH-7782</a> and
  * <a href="https://hibernate.onjira.com/browse/HHH-7783">HHH-7783</a> for more information.
  */
 @Deprecated
 public abstract class PersistentIndexedElementHolder extends AbstractPersistentCollection {
 	protected Element element;
 
 	/**
 	 * Constructs a PersistentIndexedElementHolder.
 	 *
 	 * @param session The session
 	 * @param element The DOM element being wrapped
 	 */
 	public PersistentIndexedElementHolder(SessionImplementor session, Element element) {
 		super( session );
 		this.element = element;
 		setInitialized();
 	}
 
 	/**
 	 * Constructs a PersistentIndexedElementHolder.
 	 *
 	 * @param session The session
 	 * @param persister The collection persister
 	 * @param key The collection key (fk value)@throws HibernateException
 	 */
 	public PersistentIndexedElementHolder(SessionImplementor session, CollectionPersister persister, Serializable key) {
 		super( session );
 		final Element owner = (Element) session.getPersistenceContext().getCollectionOwner( key, persister );
 		if ( owner == null ) {
 			throw new AssertionFailure( "null owner" );
 		}
 
 		final String nodeName = persister.getNodeName();
 		if ( ".".equals( nodeName ) ) {
 			element = owner;
 		}
 		else {
 			element = owner.element( nodeName );
 			if ( element == null ) {
 				element = owner.addElement( nodeName );
 			}
 		}
 	}
 
 	/**
 	 * A struct representing the index/value pair.
 	 */
 	public static final class IndexedValue {
 		final String index;
 		final Object value;
 
 		IndexedValue(String index, Object value) {
 			this.index = index;
 			this.value = value;
 		}
 	}
 	
 	protected static String getIndex(Element element, String indexNodeName, int i) {
 		if ( indexNodeName != null ) {
 			return element.attributeValue( indexNodeName );
 		}
 		else {
 			return Integer.toString( i );
 		}
 	}
 	
 	protected static void setIndex(Element element, String indexNodeName, String index) {
 		if ( indexNodeName != null ) {
 			element.addAttribute( indexNodeName, index );
 		}
 	}
 
 	protected static String getIndexAttributeName(CollectionPersister persister) {
 		final String node = persister.getIndexNodeName();
 		return node == null ? null : node.substring( 1 );
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked", "deprecation"})
 	public Serializable getSnapshot(CollectionPersister persister) throws HibernateException {
 		final Type elementType = persister.getElementType();
 		final String indexNode = getIndexAttributeName( persister );
 		final List elements = element.elements( persister.getElementNodeName() );
 		final HashMap snapshot = new HashMap( elements.size() );
 		for ( int i=0; i<elements.size(); i++ ) {
 			final Element elem = (Element) elements.get( i );
 			final Object value = elementType.fromXMLNode( elem, persister.getFactory() );
 			final Object copy = elementType.deepCopy( value, persister.getFactory() );
 			snapshot.put( getIndex( elem, indexNode, i ), copy );
 		}
 		return snapshot;
 		
 	}
 
 	@Override
 	public Collection getOrphans(Serializable snapshot, String entityName) {
 		//orphan delete not supported for EntityMode.DOM4J
 		return Collections.EMPTY_LIST;
 	}
 
 	@Override
 	public boolean isWrapper(Object collection) {
 		return element==collection;
 	}
 
 	@Override
 	@SuppressWarnings("deprecation")
 	public boolean equalsSnapshot(CollectionPersister persister) throws HibernateException {
 		final Type elementType = persister.getElementType();
 		final String indexNode = getIndexAttributeName( persister );
 		final HashMap snapshot = (HashMap) getSnapshot();
 		final List elements = element.elements( persister.getElementNodeName() );
 
 		if ( snapshot.size() !=  elements.size() ) {
 			return false;
 		}
 
 		for ( int i=0; i<snapshot.size(); i++ ) {
 			final Element elem = (Element) elements.get( i );
 			final Object old = snapshot.get( getIndex( elem, indexNode, i ) );
 			final Object current = elementType.fromXMLNode( elem, persister.getFactory() );
 			if ( elementType.isDirty( old, current, getSession() ) ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	@Override
 	public boolean isSnapshotEmpty(Serializable snapshot) {
 		return ( (HashMap) snapshot ).isEmpty();
 	}
 
 	@Override
 	public boolean empty() {
 		return !element.elementIterator().hasNext();
 	}
 
 	@Override
 	@SuppressWarnings({"deprecation", "unchecked"})
 	public Object readFrom(ResultSet rs, CollectionPersister persister, CollectionAliases descriptor, Object owner)
 			throws HibernateException, SQLException {
 		final Object object = persister.readElement( rs, owner, descriptor.getSuffixedElementAliases(), getSession() );
 		final Type elementType = persister.getElementType();
 		final SessionFactoryImplementor factory = persister.getFactory();
 		final String indexNode = getIndexAttributeName( persister );
 
 		final Element elem = element.addElement( persister.getElementNodeName() );
 		elementType.setToXMLNode( elem, object, factory ); 
 
 		final Type indexType = persister.getIndexType();
 		final Object indexValue = persister.readIndex( rs, descriptor.getSuffixedIndexAliases(), getSession() );
-		final String index = ( (XmlRepresentableType) indexType ).toXMLString( indexValue, factory );
+		final String index = ( (StringRepresentableType) indexType ).toString( indexValue );
 		setIndex( elem, indexNode, index );
 		return object;
 	}
 
 	@Override
 	@SuppressWarnings({"deprecation", "unchecked"})
 	public Iterator entries(CollectionPersister persister) {
 		final Type elementType = persister.getElementType();
 		final String indexNode = getIndexAttributeName( persister );
 		final List elements =  element.elements( persister.getElementNodeName() );
 		final int length = elements.size();
 		final List result = new ArrayList( length );
 		for ( int i=0; i<length; i++ ) {
 			final Element elem = (Element) elements.get( i );
 			final Object object = elementType.fromXMLNode( elem, persister.getFactory() );
 			result.add( new IndexedValue( getIndex( elem, indexNode, i ), object ) );
 		}
 		return result.iterator();
 	}
 
 	@Override
 	public void beforeInitialize(CollectionPersister persister, int anticipatedSize) {
 	}
 
 	@Override
 	public boolean isDirectlyAccessible() {
 		return true;
 	}
 
 	@Override
 	public Object getValue() {
 		return element;
 	}
 
 	@Override
 	@SuppressWarnings({"deprecation", "unchecked"})
 	public Iterator getDeletes(CollectionPersister persister, boolean indexIsFormula) throws HibernateException {
 		final Type indexType = persister.getIndexType();
 		final HashMap snapshot = (HashMap) getSnapshot();
 		final HashMap deletes = (HashMap) snapshot.clone();
 		deletes.keySet().removeAll( ( (HashMap) getSnapshot( persister ) ).keySet() );
 		final ArrayList deleteList = new ArrayList( deletes.size() );
 		for ( Object o : deletes.entrySet() ) {
 			final Map.Entry me = (Map.Entry) o;
 			final Object object = indexIsFormula
 					? me.getValue()
-					: ( (XmlRepresentableType) indexType ).fromXMLString( (String) me.getKey(), persister.getFactory() );
+					: ( (StringRepresentableType) indexType ).fromStringValue( (String) me.getKey() );
 			if ( object != null ) {
 				deleteList.add( object );
 			}
 		}
 		return deleteList.iterator();
 	}
 
 	@Override
 	public boolean needsInserting(Object entry, int i, Type elementType) throws HibernateException {
 		final HashMap snapshot = (HashMap) getSnapshot();
 		final IndexedValue iv = (IndexedValue) entry;
 		return iv.value!=null && snapshot.get( iv.index )==null;
 	}
 
 	@Override
 	public boolean needsUpdating(Object entry, int i, Type elementType) throws HibernateException {
 		final HashMap snapshot = (HashMap) getSnapshot();
 		final IndexedValue iv = (IndexedValue) entry;
 		final Object old = snapshot.get( iv.index );
 		return old!=null && elementType.isDirty( old, iv.value, getSession() );
 	}
 
 	@Override
 	@SuppressWarnings("deprecation")
 	public Object getIndex(Object entry, int i, CollectionPersister persister) {
 		final String index = ( (IndexedValue) entry ).index;
 		final Type indexType = persister.getIndexType();
-		return ( (XmlRepresentableType) indexType ).fromXMLString( index, persister.getFactory() );
+		return ( (StringRepresentableType) indexType ).fromStringValue( index );
 	}
 
 	@Override
 	public Object getElement(Object entry) {
 		return ( (IndexedValue) entry ).value;
 	}
 
 	@Override
 	public Object getSnapshotElement(Object entry, int i) {
 		return ( (HashMap) getSnapshot() ).get( ( (IndexedValue) entry ).index );
 	}
 
 	@Override
 	public boolean entryExists(Object entry, int i) {
 		return entry!=null;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/collection/internal/PersistentMapElementHolder.java b/hibernate-core/src/main/java/org/hibernate/collection/internal/PersistentMapElementHolder.java
index f097001936..6b156a6f6a 100755
--- a/hibernate-core/src/main/java/org/hibernate/collection/internal/PersistentMapElementHolder.java
+++ b/hibernate-core/src/main/java/org/hibernate/collection/internal/PersistentMapElementHolder.java
@@ -1,113 +1,113 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.collection.internal;
 
 import java.io.Serializable;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
+import org.hibernate.type.StringRepresentableType;
 import org.hibernate.type.Type;
-import org.hibernate.type.XmlRepresentableType;
 
 import org.dom4j.Element;
 
 /**
  * Wraps a collection of DOM sub-elements as a Map
  *
  * @author Gavin King
  *
  * @deprecated To be removed in 5.  Removed as part of removing the notion of DOM entity-mode.  See Jira issues
  * <a href="https://hibernate.onjira.com/browse/HHH-7782">HHH-7782</a> and
  * <a href="https://hibernate.onjira.com/browse/HHH-7783">HHH-7783</a> for more information.
  */
 @SuppressWarnings({"UnusedDeclaration", "deprecation"})
 @Deprecated
 public class PersistentMapElementHolder extends PersistentIndexedElementHolder {
 
 	/**
 	 * Constructs a PersistentMapElementHolder.
 	 *
 	 * @param session The session
 	 * @param element The owning DOM element
 	 */
 	public PersistentMapElementHolder(SessionImplementor session, Element element) {
 		super( session, element );
 	}
 
 	/**
 	 * Constructs a PersistentMapElementHolder.
 	 *
 	 * @param session The session
 	 * @param persister The collection persister
 	 * @param key The collection key (fk value)
 	 */
 	public PersistentMapElementHolder(SessionImplementor session, CollectionPersister persister, Serializable key) {
 		super( session, persister, key );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public void initializeFromCache(CollectionPersister persister, Serializable disassembled, Object owner) {
 		final Type elementType = persister.getElementType();
 		final Type indexType = persister.getIndexType();
 		final String indexNodeName = getIndexAttributeName( persister );
 
 		final Serializable[] cached = (Serializable[]) disassembled;
 		int i = 0;
 		while ( i < cached.length ) {
 			final Object index = indexType.assemble( cached[i++], getSession(), owner );
 			final Object object = elementType.assemble( cached[i++], getSession(), owner );
 
 			final Element subElement = element.addElement( persister.getElementNodeName() );
 			elementType.setToXMLNode( subElement, object, persister.getFactory() );
 
-			final String indexString = ( (XmlRepresentableType) indexType ).toXMLString( index, persister.getFactory() );
+			final String indexString = ( (StringRepresentableType) indexType ).toString( index );
 			setIndex( subElement, indexNodeName, indexString );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public Serializable disassemble(CollectionPersister persister) throws HibernateException {
 		final Type elementType = persister.getElementType();
 		final Type indexType = persister.getIndexType();
 		final String indexNodeName = getIndexAttributeName( persister );
 
 		final List elements =  element.elements( persister.getElementNodeName() );
 		final int length = elements.size();
 		final Serializable[] result = new Serializable[length*2];
 		int i = 0;
 		while ( i < length*2 ) {
 			final Element elem = (Element) elements.get( i/2 );
 			final Object object = elementType.fromXMLNode( elem, persister.getFactory() );
 			final String indexString = getIndex( elem, indexNodeName, i );
-			final Object index = ( (XmlRepresentableType) indexType ).fromXMLString( indexString, persister.getFactory() );
+			final Object index = ( (StringRepresentableType) indexType ).fromStringValue( indexString );
 			result[i++] = indexType.disassemble( index, getSession(), null );
 			result[i++] = elementType.disassemble( object, getSession(), null );
 		}
 		return result;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/function/StandardAnsiSqlAggregationFunctions.java b/hibernate-core/src/main/java/org/hibernate/dialect/function/StandardAnsiSqlAggregationFunctions.java
index a8fd8abb0f..e04dbea095 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/function/StandardAnsiSqlAggregationFunctions.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/function/StandardAnsiSqlAggregationFunctions.java
@@ -1,241 +1,245 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.function;
 
 import java.sql.Types;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * Centralized definition of standard ANSI SQL aggregation functions
  *
  * @author Steve Ebersole
  */
 public class StandardAnsiSqlAggregationFunctions {
 	/**
 	 * Definition of a standard ANSI SQL compliant <tt>COUNT</tt> function
 	 */
 	public static class CountFunction extends StandardSQLFunction {
 		/**
 		 * Singleton access
 		 */
 		public static final CountFunction INSTANCE = new CountFunction();
 
 		protected CountFunction() {
 			super( "count", StandardBasicTypes.LONG );
 		}
 
 		@Override
 		public String render(Type firstArgumentType, List arguments, SessionFactoryImplementor factory) {
 			if ( arguments.size() > 1 ) {
 				if ( "distinct".equalsIgnoreCase( arguments.get( 0 ).toString() ) ) {
 					return renderCountDistinct( arguments, factory.getDialect() );
 				}
 			}
 			return super.render( firstArgumentType, arguments, factory );
 		}
 
 		private String renderCountDistinct(List arguments, Dialect dialect) {
 			final StringBuilder buffer = new StringBuilder();
 			buffer.append( "count(distinct " );
-			if (dialect.requiresParensForTupleDistinctCounts()) buffer.append("(");
+			if (dialect.requiresParensForTupleDistinctCounts()) {
+				buffer.append("(");
+			}
 			String sep = "";
 			final Iterator itr = arguments.iterator();
 			// intentionally skip first
 			itr.next();
 			while ( itr.hasNext() ) {
 				buffer.append( sep ).append( itr.next() );
 				sep = ", ";
 			}
-			if (dialect.requiresParensForTupleDistinctCounts()) buffer.append(")");
+			if (dialect.requiresParensForTupleDistinctCounts()) {
+				buffer.append(")");
+			}
 			return buffer.append( ")" ).toString();
 		}
 	}
 
 	/**
 	 * Definition of a standard ANSI SQL compliant <tt>AVG</tt> function
 	 */
 	public static class AvgFunction extends StandardSQLFunction {
 		/**
 		 * Singleton access
 		 */
 		public static final AvgFunction INSTANCE = new AvgFunction();
 
 		protected AvgFunction() {
 			super( "avg", StandardBasicTypes.DOUBLE );
 		}
 
 		@Override
 		public String render(Type firstArgumentType, List arguments, SessionFactoryImplementor factory) throws QueryException {
 			final int jdbcTypeCode = determineJdbcTypeCode( firstArgumentType, factory );
 			return render( jdbcTypeCode, arguments.get( 0 ).toString(), factory );
 		}
 
 		protected final int determineJdbcTypeCode(Type firstArgumentType, SessionFactoryImplementor factory) throws QueryException {
 			try {
 				final int[] jdbcTypeCodes = firstArgumentType.sqlTypes( factory );
 				if ( jdbcTypeCodes.length != 1 ) {
 					throw new QueryException( "multiple-column type in avg()" );
 				}
 				return jdbcTypeCodes[0];
 			}
 			catch ( MappingException me ) {
 				throw new QueryException( me );
 			}
 		}
 
 		@SuppressWarnings("UnusedParameters")
 		protected String render(int firstArgumentJdbcType, String argument, SessionFactoryImplementor factory) {
 			return "avg(" + renderArgument( argument, firstArgumentJdbcType ) + ")";
 		}
 
 		protected String renderArgument(String argument, int firstArgumentJdbcType) {
 			return argument;
 		}
 	}
 
 	/**
 	 * Definition of a standard ANSI SQL compliant <tt>MAX</tt> function
 	 */
 	public static class MaxFunction extends StandardSQLFunction {
 		/**
 		 * Singleton access
 		 */
 		public static final MaxFunction INSTANCE = new MaxFunction();
 
 		protected MaxFunction() {
 			super( "max" );
 		}
 	}
 
 	/**
 	 * Definition of a standard ANSI SQL compliant <tt>MIN</tt> function
 	 */
 	public static class MinFunction extends StandardSQLFunction {
 		/**
 		 * Singleton access
 		 */
 		public static final MinFunction INSTANCE = new MinFunction();
 
 		protected MinFunction() {
 			super( "min" );
 		}
 	}
 
 
 	/**
 	 * Definition of a standard ANSI SQL compliant <tt>SUM</tt> function
 	 */
 	public static class SumFunction extends StandardSQLFunction {
 		/**
 		 * Singleton access
 		 */
 		public static final SumFunction INSTANCE = new SumFunction();
 
 		protected SumFunction() {
 			super( "sum" );
 		}
 
 		@Override
 		public Type getReturnType(Type firstArgumentType, Mapping mapping) {
 			final int jdbcType = determineJdbcTypeCode( firstArgumentType, mapping );
 
 			// First allow the actual type to control the return value; the underlying sqltype could
 			// actually be different
 			if ( firstArgumentType == StandardBasicTypes.BIG_INTEGER ) {
 				return StandardBasicTypes.BIG_INTEGER;
 			}
 			else if ( firstArgumentType == StandardBasicTypes.BIG_DECIMAL ) {
 				return StandardBasicTypes.BIG_DECIMAL;
 			}
 			else if ( firstArgumentType == StandardBasicTypes.LONG
 					|| firstArgumentType == StandardBasicTypes.SHORT
 					|| firstArgumentType == StandardBasicTypes.INTEGER ) {
 				return StandardBasicTypes.LONG;
 			}
 			else if ( firstArgumentType == StandardBasicTypes.FLOAT || firstArgumentType == StandardBasicTypes.DOUBLE)  {
 				return StandardBasicTypes.DOUBLE;
 			}
 
 			// finally use the jdbcType if == on Hibernate types did not find a match.
 			//
 			//	IMPL NOTE : we do not match on Types.NUMERIC because it could be either, so we fall-through to the
 			// 		first argument type
 			if ( jdbcType == Types.FLOAT
 					|| jdbcType == Types.DOUBLE
 					|| jdbcType == Types.DECIMAL
 					|| jdbcType == Types.REAL) {
 				return StandardBasicTypes.DOUBLE;
 			}
 			else if ( jdbcType == Types.BIGINT
 					|| jdbcType == Types.INTEGER
 					|| jdbcType == Types.SMALLINT
 					|| jdbcType == Types.TINYINT ) {
 				return StandardBasicTypes.LONG;
 			}
 
 			// as a last resort, return the type of the first argument
 			return firstArgumentType;
 		}
 
 		protected final int determineJdbcTypeCode(Type type, Mapping mapping) throws QueryException {
 			try {
 				final int[] jdbcTypeCodes = type.sqlTypes( mapping );
 				if ( jdbcTypeCodes.length != 1 ) {
 					throw new QueryException( "multiple-column type in sum()" );
 				}
 				return jdbcTypeCodes[0];
 			}
 			catch ( MappingException me ) {
 				throw new QueryException( me );
 			}
 		}
 
 	}
 
 	/**
 	 * Push the functions defined on StandardAnsiSqlAggregationFunctions into the given map
 	 *
 	 * @param functionMap The map of functions to push to
 	 */
 	public static void primeFunctionMap(Map<String, SQLFunction> functionMap) {
 		functionMap.put( AvgFunction.INSTANCE.getName(), AvgFunction.INSTANCE );
 		functionMap.put( CountFunction.INSTANCE.getName(), CountFunction.INSTANCE );
 		functionMap.put( MaxFunction.INSTANCE.getName(), MaxFunction.INSTANCE );
 		functionMap.put( MinFunction.INSTANCE.getName(), MinFunction.INSTANCE );
 		functionMap.put( SumFunction.INSTANCE.getName(), SumFunction.INSTANCE );
 	}
 
 	private StandardAnsiSqlAggregationFunctions() {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/query/spi/HQLQueryPlan.java b/hibernate-core/src/main/java/org/hibernate/engine/query/spi/HQLQueryPlan.java
index 687a931105..8fd16d5e70 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/query/spi/HQLQueryPlan.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/query/spi/HQLQueryPlan.java
@@ -1,446 +1,448 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.query.spi;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.Filter;
 import org.hibernate.HibernateException;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.QuerySplitter;
 import org.hibernate.hql.spi.FilterTranslator;
 import org.hibernate.hql.spi.ParameterTranslations;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.hql.spi.QueryTranslatorFactory;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.collections.EmptyIterator;
 import org.hibernate.internal.util.collections.IdentitySet;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.type.Type;
 
 /**
  * Defines a query execution plan for an HQL query (or filter).
  *
  * @author Steve Ebersole
  */
 public class HQLQueryPlan implements Serializable {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( HQLQueryPlan.class );
 
     // TODO : keep separate notions of QT[] here for shallow/non-shallow queries...
 
 	private final String sourceQuery;
 	private final QueryTranslator[] translators;
 	private final String[] sqlStrings;
 
 	private final ParameterMetadata parameterMetadata;
 	private final ReturnMetadata returnMetadata;
 	private final Set querySpaces;
 
 	private final Set<String> enabledFilterNames;
 	private final boolean shallow;
 
 	/**
 	* We'll check the trace level only once per instance
 	*/
-	private final boolean TRACE_ENABLED = LOG.isTraceEnabled();
+	private final boolean traceEnabled = LOG.isTraceEnabled();
 
 	/**
 	 * Constructs a HQLQueryPlan
 	 *
 	 * @param hql The HQL query
 	 * @param shallow Whether the execution is to be shallow or not
 	 * @param enabledFilters The enabled filters (we only keep the names)
 	 * @param factory The factory
 	 */
 	public HQLQueryPlan(String hql, boolean shallow, Map<String,Filter> enabledFilters,
 			SessionFactoryImplementor factory) {
 		this( hql, null, shallow, enabledFilters, factory, null );
 	}
 	
 	public HQLQueryPlan(String hql, boolean shallow, Map<String,Filter> enabledFilters,
 			SessionFactoryImplementor factory, EntityGraphQueryHint entityGraphQueryHint) {
 		this( hql, null, shallow, enabledFilters, factory, entityGraphQueryHint );
 	}
 
 	@SuppressWarnings("unchecked")
 	protected HQLQueryPlan(
 			String hql,
 			String collectionRole,
 			boolean shallow,
 			Map<String,Filter> enabledFilters,
 			SessionFactoryImplementor factory,
 			EntityGraphQueryHint entityGraphQueryHint) {
 		this.sourceQuery = hql;
 		this.shallow = shallow;
 
 		final Set<String> copy = new HashSet<String>();
 		copy.addAll( enabledFilters.keySet() );
 		this.enabledFilterNames = java.util.Collections.unmodifiableSet( copy );
 
 		final String[] concreteQueryStrings = QuerySplitter.concreteQueries( hql, factory );
 		final int length = concreteQueryStrings.length;
 		this.translators = new QueryTranslator[length];
 
 		final List<String> sqlStringList = new ArrayList<String>();
 		final Set<Serializable> combinedQuerySpaces = new HashSet<Serializable>();
 
 		final boolean hasCollectionRole = (collectionRole == null);
-		final Map querySubstitutions = factory.getSettings().getQuerySubstitutions();
-		final QueryTranslatorFactory queryTranslatorFactory = factory.getSettings().getQueryTranslatorFactory();
+		final Map querySubstitutions = factory.getSessionFactoryOptions().getQuerySubstitutions();
+		final QueryTranslatorFactory queryTranslatorFactory = factory.getServiceRegistry().getService( QueryTranslatorFactory.class );
+
 
 		for ( int i=0; i<length; i++ ) {
 			if ( hasCollectionRole ) {
 				translators[i] = queryTranslatorFactory
 						.createQueryTranslator( hql, concreteQueryStrings[i], enabledFilters, factory, entityGraphQueryHint );
 				translators[i].compile( querySubstitutions, shallow );
 			}
 			else {
 				translators[i] = queryTranslatorFactory
 						.createFilterTranslator( hql, concreteQueryStrings[i], enabledFilters, factory );
 				( (FilterTranslator) translators[i] ).compile( collectionRole, querySubstitutions, shallow );
 			}
 			combinedQuerySpaces.addAll( translators[i].getQuerySpaces() );
 			sqlStringList.addAll( translators[i].collectSqlStrings() );
 		}
 
 		this.sqlStrings = ArrayHelper.toStringArray( sqlStringList );
 		this.querySpaces = combinedQuerySpaces;
 
 		if ( length == 0 ) {
 			parameterMetadata = new ParameterMetadata( null, null );
 			returnMetadata = null;
 		}
 		else {
 			this.parameterMetadata = buildParameterMetadata( translators[0].getParameterTranslations(), hql );
 			if ( translators[0].isManipulationStatement() ) {
 				returnMetadata = null;
 			}
 			else {
 				final Type[] types = ( length > 1 ) ? new Type[translators[0].getReturnTypes().length] : translators[0].getReturnTypes();
 				returnMetadata = new ReturnMetadata( translators[0].getReturnAliases(), types );
 			}
 		}
 	}
 
 	public String getSourceQuery() {
 		return sourceQuery;
 	}
 
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	public ParameterMetadata getParameterMetadata() {
 		return parameterMetadata;
 	}
 
 	public ReturnMetadata getReturnMetadata() {
 		return returnMetadata;
 	}
 
 	public Set getEnabledFilterNames() {
 		return enabledFilterNames;
 	}
 
 	public String[] getSqlStrings() {
 		return sqlStrings;
 	}
 
 	public Set getUtilizedFilterNames() {
 		// TODO : add this info to the translator and aggregate it here...
 		return null;
 	}
 
 	public boolean isShallow() {
 		return shallow;
 	}
 
 	/**
 	 * Coordinates the efforts to perform a list across all the included query translators.
 	 *
 	 * @param queryParameters The query parameters
 	 * @param session The session
 	 *
 	 * @return The query result list
 	 *
 	 * @throws HibernateException Indicates a problem performing the query
 	 */
 	@SuppressWarnings("unchecked")
 	public List performList(
 			QueryParameters queryParameters,
 			SessionImplementor session) throws HibernateException {
-		if ( TRACE_ENABLED ) {
+		if ( traceEnabled ) {
 			LOG.tracev( "Find: {0}", getSourceQuery() );
 			queryParameters.traceParameters( session.getFactory() );
 		}
 
 		final RowSelection rowSelection = queryParameters.getRowSelection();
 		final boolean hasLimit = rowSelection != null
 				&& rowSelection.definesLimits();
 		final boolean needsLimit = hasLimit && translators.length > 1;
 
 		final QueryParameters queryParametersToUse;
 		if ( needsLimit ) {
 			LOG.needsLimit();
 			final RowSelection selection = new RowSelection();
 			selection.setFetchSize( queryParameters.getRowSelection().getFetchSize() );
 			selection.setTimeout( queryParameters.getRowSelection().getTimeout() );
 			queryParametersToUse = queryParameters.createCopyUsing( selection );
 		}
 		else {
 			queryParametersToUse = queryParameters;
 		}
 
 		final int guessedResultSize = guessResultSize( rowSelection );
 		final List combinedResults = new ArrayList( guessedResultSize );
 		final IdentitySet distinction = new IdentitySet( guessedResultSize );
 		int includedCount = -1;
 		translator_loop:
 		for ( QueryTranslator translator : translators ) {
 			final List tmp = translator.list( session, queryParametersToUse );
 			if ( needsLimit ) {
 				// NOTE : firstRow is zero-based
 				final int first = queryParameters.getRowSelection().getFirstRow() == null
 						? 0
 						: queryParameters.getRowSelection().getFirstRow();
 				final int max = queryParameters.getRowSelection().getMaxRows() == null
 						? -1
 						: queryParameters.getRowSelection().getMaxRows();
 				for ( final Object result : tmp ) {
 					if ( !distinction.add( result ) ) {
 						continue;
 					}
 					includedCount++;
 					if ( includedCount < first ) {
 						continue;
 					}
 					combinedResults.add( result );
 					if ( max >= 0 && includedCount > max ) {
 						// break the outer loop !!!
 						break translator_loop;
 					}
 				}
 			}
 			else {
 				combinedResults.addAll( tmp );
 			}
 		}
 		return combinedResults;
 	}
 
 	/**
 	 * If we're able to guess a likely size of the results we can optimize allocation
 	 * of our datastructures.
 	 * Essentially if we detect the user is not using pagination, we attempt to use the FetchSize
 	 * as a reasonable hint. If fetch size is not being set either, it is reasonable to expect
 	 * that we're going to have a single hit. In such a case it would be tempting to return a constant
 	 * of value one, but that's dangerous as it doesn't scale up appropriately for example
 	 * with an ArrayList if the guess is wrong.
 	 *
 	 * @param rowSelection
 	 * @return a reasonable size to use for allocation
 	 */
-	private final int guessResultSize(RowSelection rowSelection) {
+	@SuppressWarnings("UnnecessaryUnboxing")
+	private int guessResultSize(RowSelection rowSelection) {
 		if ( rowSelection != null ) {
 			final int maxReasonableAllocation = rowSelection.getFetchSize() != null ? rowSelection.getFetchSize().intValue() : 100;
 			if ( rowSelection.getMaxRows() != null && rowSelection.getMaxRows().intValue() > 0 ) {
 				return Math.min( maxReasonableAllocation, rowSelection.getMaxRows().intValue() );
 			}
 			else if ( rowSelection.getFetchSize() != null && rowSelection.getFetchSize().intValue() > 0 ) {
 				return rowSelection.getFetchSize().intValue();
 			}
 		}
 		return 7;//magic number guessed as a reasonable default.
 	}
 
 	/**
 	 * Coordinates the efforts to perform an iterate across all the included query translators.
 	 *
 	 * @param queryParameters The query parameters
 	 * @param session The session
 	 *
 	 * @return The query result iterator
 	 *
 	 * @throws HibernateException Indicates a problem performing the query
 	 */
 	@SuppressWarnings("unchecked")
 	public Iterator performIterate(
 			QueryParameters queryParameters,
 			EventSource session) throws HibernateException {
-		if ( TRACE_ENABLED ) {
+		if ( traceEnabled ) {
 			LOG.tracev( "Iterate: {0}", getSourceQuery() );
 			queryParameters.traceParameters( session.getFactory() );
 		}
 		if ( translators.length == 0 ) {
 			return EmptyIterator.INSTANCE;
 		}
 
 		final boolean many = translators.length > 1;
 		Iterator[] results = null;
 		if ( many ) {
 			results = new Iterator[translators.length];
 		}
 
 		Iterator result = null;
 		for ( int i = 0; i < translators.length; i++ ) {
 			result = translators[i].iterate( queryParameters, session );
 			if ( many ) {
 				results[i] = result;
 			}
 		}
 
 		return many ? new JoinedIterator( results ) : result;
 	}
 
 	/**
 	 * Coordinates the efforts to perform a scroll across all the included query translators.
 	 *
 	 * @param queryParameters The query parameters
 	 * @param session The session
 	 *
 	 * @return The query result iterator
 	 *
 	 * @throws HibernateException Indicates a problem performing the query
 	 */
 	public ScrollableResults performScroll(
 			QueryParameters queryParameters,
 			SessionImplementor session) throws HibernateException {
-		if ( TRACE_ENABLED ) {
+		if ( traceEnabled ) {
 			LOG.tracev( "Iterate: {0}", getSourceQuery() );
 			queryParameters.traceParameters( session.getFactory() );
 		}
 		if ( translators.length != 1 ) {
 			throw new QueryException( "implicit polymorphism not supported for scroll() queries" );
 		}
 		if ( queryParameters.getRowSelection().definesLimits() && translators[0].containsCollectionFetches() ) {
 			throw new QueryException( "firstResult/maxResults not supported in conjunction with scroll() of a query containing collection fetches" );
 		}
 
 		return translators[0].scroll( queryParameters, session );
 	}
 
 	/**
 	 * Coordinates the efforts to perform an execution across all the included query translators.
 	 *
 	 * @param queryParameters The query parameters
 	 * @param session The session
 	 *
 	 * @return The aggregated "affected row" count
 	 *
 	 * @throws HibernateException Indicates a problem performing the execution
 	 */
 	public int performExecuteUpdate(QueryParameters queryParameters, SessionImplementor session)
 			throws HibernateException {
-		if ( TRACE_ENABLED ) {
+		if ( traceEnabled ) {
 			LOG.tracev( "Execute update: {0}", getSourceQuery() );
 			queryParameters.traceParameters( session.getFactory() );
 		}
 		if ( translators.length != 1 ) {
 			LOG.splitQueries( getSourceQuery(), translators.length );
 		}
 		int result = 0;
 		for ( QueryTranslator translator : translators ) {
 			result += translator.executeUpdate( queryParameters, session );
 		}
 		return result;
 	}
 
 	private ParameterMetadata buildParameterMetadata(ParameterTranslations parameterTranslations, String hql) {
-		final long start = TRACE_ENABLED ? System.nanoTime() : 0;
+		final long start = traceEnabled ? System.nanoTime() : 0;
 		final ParamLocationRecognizer recognizer = ParamLocationRecognizer.parseLocations( hql );
 
-		if ( TRACE_ENABLED ) {
+		if ( traceEnabled ) {
 			final long end = System.nanoTime();
 			LOG.tracev( "HQL param location recognition took {0} nanoseconds ({1})", ( end - start ), hql );
 		}
 
 		int ordinalParamCount = parameterTranslations.getOrdinalParameterCount();
 		final int[] locations = ArrayHelper.toIntArray( recognizer.getOrdinalParameterLocationList() );
 		if ( parameterTranslations.supportsOrdinalParameterMetadata() && locations.length != ordinalParamCount ) {
 			throw new HibernateException( "ordinal parameter mismatch" );
 		}
 		ordinalParamCount = locations.length;
 
 		final OrdinalParameterDescriptor[] ordinalParamDescriptors = new OrdinalParameterDescriptor[ordinalParamCount];
 		for ( int i = 1; i <= ordinalParamCount; i++ ) {
 			ordinalParamDescriptors[ i - 1 ] = new OrdinalParameterDescriptor(
 					i,
 					parameterTranslations.supportsOrdinalParameterMetadata()
 							? parameterTranslations.getOrdinalParameterExpectedType( i )
 							: null,
 					locations[ i - 1 ]
 			);
 		}
 
 		final Map<String, NamedParameterDescriptor> namedParamDescriptorMap = new HashMap<String, NamedParameterDescriptor>();
 		final Map<String, ParamLocationRecognizer.NamedParameterDescription> map = recognizer.getNamedParameterDescriptionMap();
 		for ( final String name : map.keySet() ) {
 			final ParamLocationRecognizer.NamedParameterDescription description = map.get( name );
 			namedParamDescriptorMap.put(
 					name,
 					new NamedParameterDescriptor(
 							name,
 							parameterTranslations.getNamedParameterExpectedType( name ),
 							description.buildPositionsArray(),
 							description.isJpaStyle()
 					)
 			);
 		}
 		return new ParameterMetadata( ordinalParamDescriptors, namedParamDescriptorMap );
 	}
 
 	/**
 	 * Access to the underlying translators associated with this query
 	 *
 	 * @return The translators
 	 */
 	public QueryTranslator[] getTranslators() {
 		final QueryTranslator[] copy = new QueryTranslator[translators.length];
 		System.arraycopy( translators, 0, copy, 0, copy.length );
 		return copy;
 	}
 
 	public Class getDynamicInstantiationResultType() {
 		return translators[0].getDynamicInstantiationResultType();
 	}
 
 	public boolean isSelect() {
 		return !translators[0].isManipulationStatement();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionFactoryImplementor.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionFactoryImplementor.java
index bf746c5b05..961db9f192 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionFactoryImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionFactoryImplementor.java
@@ -1,321 +1,322 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cfg.Settings;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.spi.QueryPlanCache;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.NamedQueryRepository;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
 /**
  * Defines the internal contract between the <tt>SessionFactory</tt> and other parts of
  * Hibernate such as implementors of <tt>Type</tt>.
  *
  * @see org.hibernate.SessionFactory
  * @see org.hibernate.internal.SessionFactoryImpl
  * @author Gavin King
  */
 public interface SessionFactoryImplementor extends Mapping, SessionFactory {
 	@Override
 	SessionBuilderImplementor withOptions();
 
 	/**
 	 * Retrieve the {@link Type} resolver associated with this factory.
 	 *
 	 * @return The type resolver
 	 */
 	TypeResolver getTypeResolver();
 
 	/**
 	 * Get a copy of the Properties used to configure this session factory.
 	 *
 	 * @return The properties.
 	 */
 	Properties getProperties();
 
 	/**
 	 * Get the persister for the named entity
 	 *
 	 * @param entityName The name of the entity for which to retrieve the persister.
 	 * @return The persister
 	 * @throws MappingException Indicates persister could not be found with that name.
 	 */
 	EntityPersister getEntityPersister(String entityName) throws MappingException;
 
 	/**
 	 * Get all entity persisters as a Map, which entity name its the key and the persister is the value.
 	 *
 	 * @return The Map contains all entity persisters.
 	 */
 	Map<String,EntityPersister> getEntityPersisters();
 
 	/**
 	 * Get the persister object for a collection role.
 	 *
 	 * @param role The role (name) of the collection for which to retrieve the
 	 * persister.
 	 * @return The persister
 	 * @throws MappingException Indicates persister could not be found with that role.
 	 */
 	CollectionPersister getCollectionPersister(String role) throws MappingException;
 
 	/**
 	 * Get all collection persisters as a Map, which collection role as the key and the persister is the value.
 	 *
 	 * @return The Map contains all collection persisters.
 	 */
 	Map<String, CollectionPersister> getCollectionPersisters();
 
 	/**
 	 * Get the JdbcServices.
 	 *
 	 * @return the JdbcServices
 	 *
 	 * @deprecated since 5.0; use {@link #getServiceRegistry()} instead to locate the JdbcServices
 	 */
+	@Deprecated
 	JdbcServices getJdbcServices();
 
 	/**
 	 * Get the SQL dialect.
 	 * <p/>
 	 * Shorthand for {@code getJdbcServices().getDialect()}
 	 *
 	 * @return The dialect
 	 */
 	Dialect getDialect();
 
 	/**
 	 * Get the factory scoped interceptor for this factory.
 	 *
 	 * @return The factory scope interceptor, or null if none.
 	 */
 	Interceptor getInterceptor();
 
 	QueryPlanCache getQueryPlanCache();
 
 	/**
 	 * Get the return types of a query
 	 */
 	Type[] getReturnTypes(String queryString) throws HibernateException;
 
 	/**
 	 * Get the return aliases of a query
 	 */
 	String[] getReturnAliases(String queryString) throws HibernateException;
 
 	/**
 	 * Get the names of all persistent classes that implement/extend the given interface/class
 	 */
 	String[] getImplementors(String className) throws MappingException;
 	/**
 	 * Get a class name, using query language imports
 	 */
 	String getImportedClassName(String name);
 
 	/**
 	 * Get the default query cache
 	 */
 	QueryCache getQueryCache();
 	/**
 	 * Get a particular named query cache, or the default cache
 	 * @param regionName the name of the cache region, or null for the default query cache
 	 * @return the existing cache, or a newly created cache if none by that region name
 	 */
 	QueryCache getQueryCache(String regionName) throws HibernateException;
 
 	/**
 	 * Get the cache of table update timestamps
 	 */
 	UpdateTimestampsCache getUpdateTimestampsCache();
 	/**
 	 * Statistics SPI
 	 */
 	StatisticsImplementor getStatisticsImplementor();
 
 	NamedQueryDefinition getNamedQuery(String queryName);
 
 	void registerNamedQueryDefinition(String name, NamedQueryDefinition definition);
 
 	NamedSQLQueryDefinition getNamedSQLQuery(String queryName);
 
 	void registerNamedSQLQueryDefinition(String name, NamedSQLQueryDefinition definition);
 
 	ResultSetMappingDefinition getResultSetMapping(String name);
 
 	/**
 	 * Get the identifier generator for the hierarchy
 	 */
 	IdentifierGenerator getIdentifierGenerator(String rootEntityName);
 
 	/**
 	 * Get a named second-level cache region
 	 *
 	 * @param regionName The name of the region to retrieve.
 	 * @return The region
 	 */
 	Region getSecondLevelCacheRegion(String regionName);
 	
 	/**
 	 * Get a named naturalId cache region
 	 *
 	 * @param regionName The name of the region to retrieve.
 	 * @return The region
 	 */
 	Region getNaturalIdCacheRegion(String regionName);
 
 	/**
 	 * Get a map of all the second level cache regions currently maintained in
 	 * this session factory.  The map is structured with the region name as the
 	 * key and the {@link Region} instances as the values.
 	 *
 	 * @return The map of regions
 	 */
 	Map getAllSecondLevelCacheRegions();
 
 	/**
 	 * Retrieves the SQLExceptionConverter in effect for this SessionFactory.
 	 *
 	 * @return The SQLExceptionConverter for this SessionFactory.
 	 *
 	 * @deprecated since 5.0; use {@link JdbcServices#getSqlExceptionHelper()} ->
 	 * {@link SqlExceptionHelper#getSqlExceptionConverter()} instead as obtained from {@link #getServiceRegistry()}
 	 */
 	@Deprecated
 	SQLExceptionConverter getSQLExceptionConverter();
 
 	/**
 	 * Retrieves the SqlExceptionHelper in effect for this SessionFactory.
 	 *
 	 * @return The SqlExceptionHelper for this SessionFactory.
 	 *
 	 * @deprecated since 5.0; use {@link JdbcServices#getSqlExceptionHelper()} instead as
 	 * obtained from {@link #getServiceRegistry()}
 	 */
 	@Deprecated
 	SqlExceptionHelper getSQLExceptionHelper();
 
 	/**
 	 * @deprecated since 5.0; use {@link #getSessionFactoryOptions()} instead
 	 */
 	@Deprecated
 	@SuppressWarnings("deprecation")
 	Settings getSettings();
 
 	/**
 	 * Get a non-transactional "current" session for Hibernate EntityManager
 	 */
 	Session openTemporarySession() throws HibernateException;
 
 	/**
 	 * Retrieves a set of all the collection roles in which the given entity
 	 * is a participant, as either an index or an element.
 	 *
 	 * @param entityName The entity name for which to get the collection roles.
 	 * @return set of all the collection roles in which the given entityName participates.
 	 */
 	Set<String> getCollectionRolesByEntityParticipant(String entityName);
 
 	EntityNotFoundDelegate getEntityNotFoundDelegate();
 
 	SQLFunctionRegistry getSqlFunctionRegistry();
 
 	/**
 	 * Retrieve fetch profile by name.
 	 *
 	 * @param name The name of the profile to retrieve.
 	 * @return The profile definition
 	 */
 	FetchProfile getFetchProfile(String name);
 
 	ServiceRegistryImplementor getServiceRegistry();
 
 	void addObserver(SessionFactoryObserver observer);
 
 	CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy();
 
 	CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver();
 
 	/**
 	 * Provides access to the named query repository
 	 *
 	 * @return The repository for named query definitions
 	 */
 	NamedQueryRepository getNamedQueryRepository();
 
 	Iterable<EntityNameResolver> iterateEntityNameResolvers();
 
 	/**
 	 * Locate an EntityPersister by the entity class.  The passed Class might refer to either
 	 * the entity name directly, or it might name a proxy interface for the entity.  This
 	 * method accounts for both, preferring the direct named entity name.
 	 *
 	 * @param byClass The concrete Class or proxy interface for the entity to locate the persister for.
 	 *
 	 * @return The located EntityPersister, never {@code null}
 	 *
 	 * @throws HibernateException If a matching EntityPersister cannot be located
 	 */
 	EntityPersister locateEntityPersister(Class byClass);
 
 	/**
 	 * Locate the entity persister by name.
 	 *
 	 * @param byName The entity name
 	 *
 	 * @return The located EntityPersister, never {@code null}
 	 *
 	 * @throws HibernateException If a matching EntityPersister cannot be located
 	 */
 	EntityPersister locateEntityPersister(String byName);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/jta/platform/internal/WebSphereExtendedJtaPlatform.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/jta/platform/internal/WebSphereExtendedJtaPlatform.java
index 9983fd6a9c..50a78abc49 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/jta/platform/internal/WebSphereExtendedJtaPlatform.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/jta/platform/internal/WebSphereExtendedJtaPlatform.java
@@ -1,254 +1,256 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.jta.platform.internal;
 
 import java.lang.reflect.InvocationHandler;
 import java.lang.reflect.Method;
 import java.lang.reflect.Proxy;
 import javax.transaction.NotSupportedException;
 import javax.transaction.RollbackException;
 import javax.transaction.Status;
 import javax.transaction.Synchronization;
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import javax.transaction.UserTransaction;
 import javax.transaction.xa.XAResource;
 
 import org.hibernate.HibernateException;
 
 /**
  * JTA platform implementation intended for use with WebSphere Application Server (WAS).
  * <p/>
  * WAS, unlike every other app server on the planet, does not allow direct access to the JTS TransactionManager.
  * Instead, for common transaction-related tasks users must utilize a proprietary API known as ExtendedJTATransaction.
  * <p/>
  * Even more unfortunate, the exact TransactionManagerLookup to use inside of WAS is highly dependent upon<ul>
  *     <li>WAS version</li>
  *     <li>the WAS container in which Hibernate will be utilized</li>
  * </ul>
  * <p/>
  * This class is reported to work on WAS version 6 in any of the standard J2EE/JEE component containers.
  *
  * @author Gavin King
  * @author <a href="mailto:jesper@udby.com>Jesper Udby</a>
  * @author Steve Ebersole
  */
 public class WebSphereExtendedJtaPlatform extends AbstractJtaPlatform {
 	public static final String UT_NAME = "java:comp/UserTransaction";
 
 	@Override
 	protected boolean canCacheTransactionManager() {
 		return true;
 	}
 
 	@Override
 	protected TransactionManager locateTransactionManager() {
 		return new TransactionManagerAdapter();
 	}
 
 	@Override
 	protected UserTransaction locateUserTransaction() {
 		return (UserTransaction) jndiService().locate( UT_NAME );
 	}
 
 	@Override
 	public Object getTransactionIdentifier(Transaction transaction) {
 		// WebSphere, however, is not a sane JEE/JTA container...
 		return transaction.hashCode();
 	}
 
 	public class TransactionManagerAdapter implements TransactionManager {
 		private final Class synchronizationCallbackClass;
 		private final Method registerSynchronizationMethod;
 		private final Method getLocalIdMethod;
 		private Object extendedJTATransaction;
 
 		private TransactionManagerAdapter() throws HibernateException {
 			try {
 				synchronizationCallbackClass = Class.forName( "com.ibm.websphere.jtaextensions.SynchronizationCallback" );
 				Class extendedJTATransactionClass = Class.forName( "com.ibm.websphere.jtaextensions.ExtendedJTATransaction" );
 				registerSynchronizationMethod = extendedJTATransactionClass.getMethod(
 						"registerSynchronizationCallbackForCurrentTran",
 						new Class[] { synchronizationCallbackClass }
 				);
 				getLocalIdMethod = extendedJTATransactionClass.getMethod( "getLocalId", (Class[]) null );
 			}
 			catch ( ClassNotFoundException cnfe ) {
 				throw new HibernateException( cnfe );
 			}
 			catch ( NoSuchMethodException nsme ) {
 				throw new HibernateException( nsme );
 			}
 		}
 
 		@Override
 		public void begin() throws NotSupportedException, SystemException {
 			throw new UnsupportedOperationException();
 		}
 
 		@Override
 		public void commit() throws UnsupportedOperationException {
 			throw new UnsupportedOperationException();
 		}
 
 		@Override
 		public int getStatus() throws SystemException {
 			return getTransaction() == null ? Status.STATUS_NO_TRANSACTION : getTransaction().getStatus();
 		}
 
 		@Override
 		public Transaction getTransaction() throws SystemException {
 			return new TransactionAdapter();
 		}
 
 		@Override
 		public void resume(Transaction txn) throws UnsupportedOperationException {
 			throw new UnsupportedOperationException();
 		}
 
 		@Override
 		public void rollback() throws UnsupportedOperationException {
 			throw new UnsupportedOperationException();
 		}
 
 		@Override
 		public void setRollbackOnly() throws UnsupportedOperationException {
 			throw new UnsupportedOperationException();
 		}
 
 		@Override
 		public void setTransactionTimeout(int i) throws UnsupportedOperationException {
 			throw new UnsupportedOperationException();
 		}
 
 		@Override
 		public Transaction suspend() throws UnsupportedOperationException {
 			throw new UnsupportedOperationException();
 		}
 
 		public class TransactionAdapter implements Transaction {
 
 			private TransactionAdapter() {
 				if ( extendedJTATransaction == null ) {
 					extendedJTATransaction = jndiService().locate( "java:comp/websphere/ExtendedJTATransaction" );
 				}
 			}
 
 			@Override
 			public void registerSynchronization(final Synchronization synchronization)
 					throws RollbackException, IllegalStateException,
 					SystemException {
 
 				final InvocationHandler ih = new InvocationHandler() {
 
 					@Override
 					public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
 						if ( "afterCompletion".equals( method.getName() ) ) {
 							int status = args[2].equals(Boolean.TRUE) ?
 									Status.STATUS_COMMITTED :
 									Status.STATUS_UNKNOWN;
 							synchronization.afterCompletion(status);
 						}
 						else if ( "beforeCompletion".equals( method.getName() ) ) {
 							synchronization.beforeCompletion();
 						}
 						else if ( "toString".equals( method.getName() ) ) {
 							return synchronization.toString();
 						}
 						return null;
 					}
 
 				};
 
 				final Object synchronizationCallback = Proxy.newProxyInstance(
 						getClass().getClassLoader(),
 						new Class[] {synchronizationCallbackClass},
 						ih
 				);
 
 				try {
 					registerSynchronizationMethod.invoke( extendedJTATransaction, synchronizationCallback );
 				}
 				catch (Exception e) {
 					throw new HibernateException(e);
 				}
 
 			}
 
 			@Override
 			public int hashCode() {
 				return getLocalId().hashCode();
 			}
 
 			@Override
 			public boolean equals(Object other) {
-				if ( !(other instanceof TransactionAdapter) ) return false;
+				if ( !(other instanceof TransactionAdapter) ) {
+					return false;
+				}
 				TransactionAdapter that = (TransactionAdapter) other;
 				return getLocalId().equals( that.getLocalId() );
 			}
 
 			private Object getLocalId() throws HibernateException {
 				try {
 					return getLocalIdMethod.invoke( extendedJTATransaction, (Object[]) null );
 				}
 				catch ( Exception e ) {
 					throw new HibernateException( e );
 				}
 			}
 
 			@Override
 			public void commit() throws UnsupportedOperationException {
 				throw new UnsupportedOperationException();
 			}
 
 			@Override
 			public boolean delistResource(XAResource resource, int i) throws UnsupportedOperationException {
 				throw new UnsupportedOperationException();
 			}
 
 			@Override
 			public boolean enlistResource(XAResource resource) throws UnsupportedOperationException {
 				throw new UnsupportedOperationException();
 			}
 
 			@Override
 			public int getStatus() {
 				return Integer.valueOf( 0 ).equals( getLocalId() ) ?
 						Status.STATUS_NO_TRANSACTION : Status.STATUS_ACTIVE;
 			}
 
 			@Override
 			public void rollback() throws UnsupportedOperationException {
 				throw new UnsupportedOperationException();
 			}
 
 			@Override
 			public void setRollbackOnly() throws UnsupportedOperationException {
 				throw new UnsupportedOperationException();
 			}
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultDirtyCheckEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultDirtyCheckEventListener.java
index 5180a288f7..df5f090730 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultDirtyCheckEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultDirtyCheckEventListener.java
@@ -1,68 +1,66 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import org.hibernate.HibernateException;
 import org.hibernate.event.spi.DirtyCheckEvent;
 import org.hibernate.event.spi.DirtyCheckEventListener;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
-import org.jboss.logging.Logger;
-
 /**
  * Defines the default dirty-check event listener used by hibernate for
  * checking the session for dirtiness in response to generated dirty-check
  * events.
  *
  * @author Steve Ebersole
  */
 public class DefaultDirtyCheckEventListener extends AbstractFlushingEventListener implements DirtyCheckEventListener {
-
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, DefaultDirtyCheckEventListener.class.getName() );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( DefaultDirtyCheckEventListener.class );
 
 	/**
 	 * Handle the given dirty-check event.
 	 * 
 	 * @param event The dirty-check event to be handled.
 	 * @throws HibernateException
 	 */
 	public void onDirtyCheck(DirtyCheckEvent event) throws HibernateException {
-
 		int oldSize = event.getSession().getActionQueue().numberOfCollectionRemovals();
 
 		try {
 			flushEverythingToExecutions(event);
 			boolean wasNeeded = event.getSession().getActionQueue().hasAnyQueuedActions();
-			if ( wasNeeded )
+			if ( wasNeeded ) {
 				LOG.debug( "Session dirty" );
-			else
+			}
+			else {
 				LOG.debug( "Session not dirty" );
+			}
 			event.setDirty( wasNeeded );
 		}
 		finally {
 			event.getSession().getActionQueue().clearFromFlushNeededCheck( oldSize );
 		}
-
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultResolveNaturalIdEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultResolveNaturalIdEventListener.java
index d5c2cb4da2..51f1c4e506 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultResolveNaturalIdEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultResolveNaturalIdEventListener.java
@@ -1,151 +1,160 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import java.io.Serializable;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.event.spi.ResolveNaturalIdEvent;
 import org.hibernate.event.spi.ResolveNaturalIdEventListener;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * Defines the default load event listeners used by hibernate for loading entities
  * in response to generated load events.
  * 
  * @author Eric Dalquist
  * @author Steve Ebersole
  */
 public class DefaultResolveNaturalIdEventListener
 		extends AbstractLockUpgradeEventListener
 		implements ResolveNaturalIdEventListener {
 
 	public static final Object REMOVED_ENTITY_MARKER = new Object();
 	public static final Object INCONSISTENT_RTN_CLASS_MARKER = new Object();
 
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( DefaultResolveNaturalIdEventListener.class );
 
 	@Override
 	public void onResolveNaturalId(ResolveNaturalIdEvent event) throws HibernateException {
 		final Serializable entityId = resolveNaturalId( event );
 		event.setEntityId( entityId );
 	}
 
 	/**
 	 * Coordinates the efforts to load a given entity. First, an attempt is
 	 * made to load the entity from the session-level cache. If not found there,
 	 * an attempt is made to locate it in second-level cache. Lastly, an
 	 * attempt is made to load it directly from the datasource.
 	 * 
 	 * @param event The load event
 	 *
 	 * @return The loaded entity, or null.
 	 */
 	protected Serializable resolveNaturalId(final ResolveNaturalIdEvent event) {
 		final EntityPersister persister = event.getEntityPersister();
 
 		final boolean traceEnabled = LOG.isTraceEnabled();
-		if ( traceEnabled )
-			LOG.tracev( "Attempting to resolve: {0}",
-					MessageHelper.infoString( persister, event.getNaturalIdValues(), event.getSession().getFactory() ) );
+		if ( traceEnabled ) {
+			LOG.tracev(
+					"Attempting to resolve: {0}",
+					MessageHelper.infoString( persister, event.getNaturalIdValues(), event.getSession().getFactory() )
+			);
+		}
 
 		Serializable entityId = resolveFromCache( event );
 		if ( entityId != null ) {
-			if ( traceEnabled )
-				LOG.tracev( "Resolved object in cache: {0}",
-						MessageHelper.infoString( persister, event.getNaturalIdValues(), event.getSession().getFactory() ) );
+			if ( traceEnabled ) {
+				LOG.tracev(
+						"Resolved object in cache: {0}",
+						MessageHelper.infoString( persister, event.getNaturalIdValues(), event.getSession().getFactory() )
+				);
+			}
 			return entityId;
 		}
 
-		if ( traceEnabled )
-			LOG.tracev( "Object not resolved in any cache: {0}",
-					MessageHelper.infoString( persister, event.getNaturalIdValues(), event.getSession().getFactory() ) );
+		if ( traceEnabled ) {
+			LOG.tracev(
+					"Object not resolved in any cache: {0}",
+					MessageHelper.infoString( persister, event.getNaturalIdValues(), event.getSession().getFactory() )
+			);
+		}
 
 		return loadFromDatasource( event );
 	}
 
 	/**
 	 * Attempts to resolve the entity id corresponding to the event's natural id values from the session
 	 * 
 	 * @param event The load event
 	 *
 	 * @return The entity from the cache, or null.
 	 */
 	protected Serializable resolveFromCache(final ResolveNaturalIdEvent event) {
 		return event.getSession().getPersistenceContext().getNaturalIdHelper().findCachedNaturalIdResolution(
 				event.getEntityPersister(),
 				event.getOrderedNaturalIdValues()
 		);
 	}
 
 	/**
 	 * Performs the process of loading an entity from the configured
 	 * underlying datasource.
 	 * 
 	 * @param event The load event
 	 *
 	 * @return The object loaded from the datasource, or null if not found.
 	 */
 	protected Serializable loadFromDatasource(final ResolveNaturalIdEvent event) {
 		final SessionFactoryImplementor factory = event.getSession().getFactory();
 		final boolean stats = factory.getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) {
 			startTime = System.nanoTime();
 		}
 		
 		final Serializable pk = event.getEntityPersister().loadEntityIdByNaturalId(
 				event.getOrderedNaturalIdValues(),
 				event.getLockOptions(),
 				event.getSession()
 		);
 		
 		if ( stats ) {
 			final NaturalIdRegionAccessStrategy naturalIdCacheAccessStrategy = event.getEntityPersister().getNaturalIdCacheAccessStrategy();
 			final String regionName = naturalIdCacheAccessStrategy == null ? null : naturalIdCacheAccessStrategy.getRegion().getName();
 			final long endTime = System.nanoTime();
 			final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 			factory.getStatisticsImplementor().naturalIdQueryExecuted(
 					regionName,
 					milliseconds );
 		}
 		
 		//PK can be null if the entity doesn't exist
 		if (pk != null) {
 			event.getSession().getPersistenceContext().getNaturalIdHelper().cacheNaturalIdCrossReferenceFromLoad(
 					event.getEntityPersister(),
 					pk,
 					event.getOrderedNaturalIdValues()
 			);
 		}
 		
 		return pk;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/EvictVisitor.java b/hibernate-core/src/main/java/org/hibernate/event/internal/EvictVisitor.java
index 1e761023f1..ba995c97bb 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/EvictVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/EvictVisitor.java
@@ -1,96 +1,98 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import org.hibernate.HibernateException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.CollectionKey;
 import org.hibernate.event.spi.EventSource;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.CollectionType;
 
 import org.jboss.logging.Logger;
 
 /**
  * Evict any collections referenced by the object from the session cache.
  * This will NOT pick up any collections that were dereferenced, so they
  * will be deleted (suboptimal but not exactly incorrect).
  *
  * @author Gavin King
  */
 public class EvictVisitor extends AbstractVisitor {
-
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, EvictVisitor.class.getName() );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( EvictVisitor.class );
 
 	EvictVisitor(EventSource session) {
 		super(session);
 	}
 
 	@Override
-	Object processCollection(Object collection, CollectionType type)
-		throws HibernateException {
-
-		if (collection!=null) evictCollection(collection, type);
+	Object processCollection(Object collection, CollectionType type) throws HibernateException {
+		if (collection != null) {
+			evictCollection(collection, type);
+		}
 
 		return null;
 	}
 	public void evictCollection(Object value, CollectionType type) {
-
 		final Object pc;
 		if ( type.hasHolder() ) {
 			pc = getSession().getPersistenceContext().removeCollectionHolder(value);
 		}
 		else if ( value instanceof PersistentCollection ) {
 			pc = value;
 		}
 		else {
 			return; //EARLY EXIT!
 		}
 
 		PersistentCollection collection = (PersistentCollection) pc;
-		if ( collection.unsetSession( getSession() ) ) evictCollection(collection);
+		if ( collection.unsetSession( getSession() ) ) {
+			evictCollection(collection);
+		}
 	}
 
 	private void evictCollection(PersistentCollection collection) {
 		CollectionEntry ce = (CollectionEntry) getSession().getPersistenceContext().getCollectionEntries().remove(collection);
 		if ( LOG.isDebugEnabled() ) {
-			LOG.debugf( "Evicting collection: %s",
+			LOG.debugf(
+					"Evicting collection: %s",
 					MessageHelper.collectionInfoString( ce.getLoadedPersister(),
 							collection,
 							ce.getLoadedKey(),
 							getSession() ) );
 		}
 		if (ce.getLoadedPersister() != null && ce.getLoadedPersister().getBatchSize() > 1) {
 			getSession().getPersistenceContext().getBatchFetchQueue().removeBatchLoadableCollection(ce);
 		}
 		if ( ce.getLoadedPersister() != null && ce.getLoadedKey() != null ) {
 			//TODO: is this 100% correct?
 			getSession().getPersistenceContext().getCollectionsByKey().remove(
 					new CollectionKey( ce.getLoadedPersister(), ce.getLoadedKey() )
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
index f08473ce81..eb96909c44 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
@@ -1,705 +1,706 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.TypeDiscriminatorMetadata;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.DiscriminatorMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Represents a single mapped class mentioned in an HQL FROM clause.  Each
  * class reference will have the following symbols:
  * <ul>
  * <li>A class name - This is the name of the Java class that is mapped by Hibernate.</li>
  * <li>[optional] an HQL alias for the mapped class.</li>
  * <li>A table name - The name of the table that is mapped to the Java class.</li>
  * <li>A table alias - The alias for the table that will be used in the resulting SQL.</li>
  * </ul>
  *
  * @author josh
  */
 public class FromElement extends HqlSqlWalkerNode implements DisplayableNode, ParameterContainer {
     private static final CoreMessageLogger LOG = CoreLogging.messageLogger( FromElement.class );
 
 	private String className;
 	private String classAlias;
 	private String tableAlias;
 	private String collectionTableAlias;
 	private FromClause fromClause;
 	private boolean includeSubclasses = true;
 	private boolean collectionJoin;
 	private FromElement origin;
 	private String[] columns;
 	private String role;
 	private boolean fetch;
 	private boolean isAllPropertyFetch;
 	private boolean filter;
 	private int sequence = -1;
 	private boolean useFromFragment;
 	private boolean initialized;
 	private FromElementType elementType;
 	private boolean useWhereFragment = true;
 	private List destinations = new LinkedList();
 	private boolean manyToMany;
 	private String withClauseFragment;
 	private String withClauseJoinAlias;
 	private boolean dereferencedBySuperclassProperty;
 	private boolean dereferencedBySubclassProperty;
 
 	public FromElement() {
 	}
 
 	/**
 	 * Constructor form used to initialize {@link ComponentJoin}
 	 *
 	 * @param fromClause The FROM clause to which this element belongs
 	 * @param origin The origin (LHS) of this element
 	 * @param alias The alias applied to this element
 	 */
 	protected FromElement(
 			FromClause fromClause,
 			FromElement origin,
 			String alias) {
 		this.fromClause = fromClause;
 		this.origin = origin;
 		this.classAlias = alias;
 		this.tableAlias = origin.getTableAlias();
 		super.initialize( fromClause.getWalker() );
 
 	}
 
 	protected void initializeComponentJoin(FromElementType elementType) {
 		fromClause.registerFromElement( this );
 		elementType.applyTreatAsDeclarations( getWalker().getTreatAsDeclarationsByPath( classAlias ) );
 		this.elementType = elementType;
 		initialized = true;
 	}
 
 	public String getCollectionSuffix() {
 		return elementType.getCollectionSuffix();
 	}
 
 	public void setCollectionSuffix(String suffix) {
 		elementType.setCollectionSuffix(suffix);
 	}
 
 	public void initializeCollection(FromClause fromClause, String classAlias, String tableAlias) {
 		doInitialize( fromClause, tableAlias, null, classAlias, null, null );
 		initialized = true;
 	}
 
 	public void initializeEntity(
 	        FromClause fromClause,
 	        String className,
 	        EntityPersister persister,
 	        EntityType type,
 	        String classAlias,
 	        String tableAlias) {
 		doInitialize( fromClause, tableAlias, className, classAlias, persister, type );
 		this.sequence = fromClause.nextFromElementCounter();
 		initialized = true;
 	}
 
 	private void doInitialize(FromClause fromClause, String tableAlias, String className, String classAlias,
 							  EntityPersister persister, EntityType type) {
 		if ( initialized ) {
 			throw new IllegalStateException( "Already initialized!!" );
 		}
 		this.fromClause = fromClause;
 		this.tableAlias = tableAlias;
 		this.className = className;
 		this.classAlias = classAlias;
 		this.elementType = new FromElementType( this, persister, type );
 		// Register the FromElement with the FROM clause, now that we have the names and aliases.
 		fromClause.registerFromElement( this );
 		LOG.debugf( "%s : %s (%s) -> %s", fromClause, className, classAlias == null ? "<no alias>" : classAlias, tableAlias );
 	}
 
 	public EntityPersister getEntityPersister() {
 		return elementType.getEntityPersister();
 	}
 
 	@Override
     public Type getDataType() {
 		return elementType.getDataType();
 	}
 
 	public Type getSelectType() {
 		return elementType.getSelectType();
 	}
 
 	public Queryable getQueryable() {
 		return elementType.getQueryable();
 	}
 
 	public String getClassName() {
 		return className;
 	}
 
 	public String getClassAlias() {
 		return classAlias;
 		//return classAlias == null ? className : classAlias;
 	}
 
 	private String getTableName() {
 		Queryable queryable = getQueryable();
 		return ( queryable != null ) ? queryable.getTableName() : "{none}";
 	}
 
 	public String getTableAlias() {
 		return tableAlias;
 	}
 
 	/**
 	 * Render the identifier select, but in a 'scalar' context (i.e. generate the column alias).
 	 *
 	 * @param i the sequence of the returned type
 	 * @return the identifier select with the column alias.
 	 */
 	String renderScalarIdentifierSelect(int i) {
 		return elementType.renderScalarIdentifierSelect( i );
 	}
 
 	void checkInitialized() {
 		if ( !initialized ) {
 			throw new IllegalStateException( "FromElement has not been initialized!" );
 		}
 	}
 
 	/**
 	 * Returns the identifier select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the identifier select SQL fragment.
 	 */
 	String renderIdentifierSelect(int size, int k) {
 		return elementType.renderIdentifierSelect( size, k );
 	}
 
 	/**
 	 * Returns the property select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the property select SQL fragment.
 	 */
 	String renderPropertySelect(int size, int k) {
 		return elementType.renderPropertySelect( size, k, isAllPropertyFetch );
 	}
 
 	String renderCollectionSelectFragment(int size, int k) {
 		return elementType.renderCollectionSelectFragment( size, k );
 	}
 
 	String renderValueCollectionSelectFragment(int size, int k) {
 		return elementType.renderValueCollectionSelectFragment( size, k );
 	}
 
 	public FromClause getFromClause() {
 		return fromClause;
 	}
 
 	/**
 	 * Returns true if this FromElement was implied by a path, or false if this FROM element is explicitly declared in
 	 * the FROM clause.
 	 *
 	 * @return true if this FromElement was implied by a path, or false if this FROM element is explicitly declared
 	 */
 	public boolean isImplied() {
 		return false;	// This is an explicit FROM element.
 	}
 
 	/**
 	 * Returns additional display text for the AST node.
 	 *
 	 * @return String - The additional display text.
 	 */
 	public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 		buf.append( "FromElement{" );
 		appendDisplayText( buf );
 		buf.append( "}" );
 		return buf.toString();
 	}
 
 	protected void appendDisplayText(StringBuilder buf) {
 		buf.append( isImplied() ? (
 				isImpliedInFromClause() ? "implied in FROM clause" : "implied" )
 				: "explicit" );
 		buf.append( "," ).append( isCollectionJoin() ? "collection join" : "not a collection join" );
 		buf.append( "," ).append( fetch ? "fetch join" : "not a fetch join" );
 		buf.append( "," ).append( isAllPropertyFetch ? "fetch all properties" : "fetch non-lazy properties" );
 		buf.append( ",classAlias=" ).append( getClassAlias() );
 		buf.append( ",role=" ).append( role );
 		buf.append( ",tableName=" ).append( getTableName() );
 		buf.append( ",tableAlias=" ).append( getTableAlias() );
 		FromElement origin = getRealOrigin();
 		buf.append( ",origin=" ).append( origin == null ? "null" : origin.getText() );
 		buf.append( ",columns={" );
 		if ( columns != null ) {
 			for ( int i = 0; i < columns.length; i++ ) {
 				buf.append( columns[i] );
 				if ( i < columns.length ) {
 					buf.append( " " );
 				}
 			}
 		}
 		buf.append( ",className=" ).append( className );
 		buf.append( "}" );
 	}
 
 	@Override
     public int hashCode() {
 		return super.hashCode();
 	}
 
 	@Override
     public boolean equals(Object obj) {
 		return super.equals( obj );
 	}
 
 
 	public void setJoinSequence(JoinSequence joinSequence) {
 		elementType.setJoinSequence( joinSequence );
 	}
 
 	public JoinSequence getJoinSequence() {
 		return elementType.getJoinSequence();
 	}
 
 	public void setIncludeSubclasses(boolean includeSubclasses) {
-		if ( !includeSubclasses && isDereferencedBySuperclassOrSubclassProperty() && LOG.isTraceEnabled() )
+		if ( !includeSubclasses && isDereferencedBySuperclassOrSubclassProperty() && LOG.isTraceEnabled() ) {
 			LOG.trace( "Attempt to disable subclass-inclusions : ", new Exception( "Stack-trace source" ) );
+		}
 		this.includeSubclasses = includeSubclasses;
 	}
 
 	public boolean isIncludeSubclasses() {
 		return includeSubclasses;
 	}
 
 	public boolean isDereferencedBySuperclassOrSubclassProperty() {
 		return dereferencedBySubclassProperty || dereferencedBySuperclassProperty;
 	}
 
 	public String getIdentityColumn() {
 		final String[] cols = getIdentityColumns();
 		if ( cols.length == 1 ) {
 			return cols[0];
 		}
 		else {
 			return "(" + StringHelper.join( ", ", cols ) + ")";
 		}
 	}
 
 	public String[] getIdentityColumns() {
 		checkInitialized();
 		final String table = getTableAlias();
 		if ( table == null ) {
 			throw new IllegalStateException( "No table alias for node " + this );
 		}
 
 		final String propertyName;
 		if ( getEntityPersister() != null && getEntityPersister().getEntityMetamodel() != null
 				&& getEntityPersister().getEntityMetamodel().hasNonIdentifierPropertyNamedId() ) {
 			propertyName = getEntityPersister().getIdentifierPropertyName();
 		}
 		else {
 			propertyName = EntityPersister.ENTITY_ID;
 		}
 
 		if ( getWalker().getStatementType() == HqlSqlTokenTypes.SELECT ) {
 			return getPropertyMapping( propertyName ).toColumns( table, propertyName );
 		}
 		else {
 			return getPropertyMapping( propertyName ).toColumns( propertyName );
 		}
 	}
 
 	public void setCollectionJoin(boolean collectionJoin) {
 		this.collectionJoin = collectionJoin;
 	}
 
 	public boolean isCollectionJoin() {
 		return collectionJoin;
 	}
 
 	public void setRole(String role) {
 		this.role = role;
 		applyTreatAsDeclarations( getWalker().getTreatAsDeclarationsByPath( role ) );
 	}
 
 	public void applyTreatAsDeclarations(Set<String> treatAsDeclarationsByPath) {
 		elementType.applyTreatAsDeclarations( treatAsDeclarationsByPath );
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public void setQueryableCollection(QueryableCollection queryableCollection) {
 		elementType.setQueryableCollection( queryableCollection );
 	}
 
 	public QueryableCollection getQueryableCollection() {
 		return elementType.getQueryableCollection();
 	}
 
 	public void setColumns(String[] columns) {
 		this.columns = columns;
 	}
 
 	public void setOrigin(FromElement origin, boolean manyToMany) {
 		this.origin = origin;
 		this.manyToMany = manyToMany;
 		origin.addDestination( this );
 		if ( origin.getFromClause() == this.getFromClause() ) {
 			// TODO: Figure out a better way to get the FROM elements in a proper tree structure.
 			// If this is not the destination of a many-to-many, add it as a child of the origin.
 			if ( manyToMany ) {
 				ASTUtil.appendSibling( origin, this );
 			}
 			else {
 				if ( !getWalker().isInFrom() && !getWalker().isInSelect() && !getWalker().isInEntityGraph()) {
 					getFromClause().addChild( this );
 				}
 				else {
 					origin.addChild( this );
 				}
 			}
 		}
 		else if ( !getWalker().isInFrom() ) {
 			// HHH-276 : implied joins in a subselect where clause - The destination needs to be added
 			// to the destination's from clause.
 			getFromClause().addChild( this );	// Not sure if this is will fix everything, but it works.
 		}
 		else {
 			// Otherwise, the destination node was implied by the FROM clause and the FROM clause processor
 			// will automatically add it in the right place.
 		}
 	}
 
 	public boolean isManyToMany() {
 		return manyToMany;
 	}
 
 	private void addDestination(FromElement fromElement) {
 		destinations.add( fromElement );
 	}
 
 	public List getDestinations() {
 		return destinations;
 	}
 
 	public FromElement getOrigin() {
 		return origin;
 	}
 
 	public FromElement getRealOrigin() {
 		if ( origin == null ) {
 			return null;
 		}
 		if ( origin.getText() == null || "".equals( origin.getText() ) ) {
 			return origin.getRealOrigin();
 		}
 		return origin;
 	}
 
 	public static final String DISCRIMINATOR_PROPERTY_NAME = "class";
 	private TypeDiscriminatorMetadata typeDiscriminatorMetadata;
 
 	private static class TypeDiscriminatorMetadataImpl implements TypeDiscriminatorMetadata {
 		private final DiscriminatorMetadata persisterDiscriminatorMetadata;
 		private final String alias;
 
 		private TypeDiscriminatorMetadataImpl(
 				DiscriminatorMetadata persisterDiscriminatorMetadata,
 				String alias) {
 			this.persisterDiscriminatorMetadata = persisterDiscriminatorMetadata;
 			this.alias = alias;
 		}
 
 		@Override
 		public String getSqlFragment() {
 			return persisterDiscriminatorMetadata.getSqlFragment( alias );
 		}
 
 		@Override
 		public Type getResolutionType() {
 			return persisterDiscriminatorMetadata.getResolutionType();
 		}
 	}
 
 	public TypeDiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( typeDiscriminatorMetadata == null ) {
 			typeDiscriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return typeDiscriminatorMetadata;
 	}
 
 	private TypeDiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		final String aliasToUse = getTableAlias();
 		Queryable queryable = getQueryable();
 		if ( queryable == null ) {
 			QueryableCollection collection = getQueryableCollection();
 			if ( ! collection.getElementType().isEntityType() ) {
 				throw new QueryException( "type discrimination cannot be applied to value collection [" + collection.getRole() + "]" );
 			}
 			queryable = (Queryable) collection.getElementPersister();
 		}
 
 		handlePropertyBeingDereferenced( getDataType(), DISCRIMINATOR_PROPERTY_NAME );
 
 		return new TypeDiscriminatorMetadataImpl( queryable.getTypeDiscriminatorMetadata(), aliasToUse );
 	}
 
 	public Type getPropertyType(String propertyName, String propertyPath) {
 		return elementType.getPropertyType( propertyName, propertyPath );
 	}
 
 	public String[] toColumns(String tableAlias, String path, boolean inSelect) {
 		return elementType.toColumns( tableAlias, path, inSelect );
 	}
 
 	public String[] toColumns(String tableAlias, String path, boolean inSelect, boolean forceAlias) {
 		return elementType.toColumns( tableAlias, path, inSelect, forceAlias );
 	}
 
 	public PropertyMapping getPropertyMapping(String propertyName) {
 		return elementType.getPropertyMapping( propertyName );
 	}
 
 	public void setFetch(boolean fetch) {
 		this.fetch = fetch;
 		// Fetch can't be used with scroll() or iterate().
 		if ( fetch && getWalker().isShallowQuery() ) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_FETCH_WITH_ITERATE );
 		}
 	}
 
 	public boolean isFetch() {
 		return fetch;
 	}
 
 	public int getSequence() {
 		return sequence;
 	}
 
 	public void setFilter(boolean b) {
 		filter = b;
 	}
 
 	public boolean isFilter() {
 		return filter;
 	}
 
 	public boolean useFromFragment() {
 		checkInitialized();
 		// If it's not implied or it is implied and it's a many to many join where the target wasn't found.
 		return !isImplied() || this.useFromFragment;
 	}
 
 	public void setUseFromFragment(boolean useFromFragment) {
 		this.useFromFragment = useFromFragment;
 	}
 
 	public boolean useWhereFragment() {
 		return useWhereFragment;
 	}
 
 	public void setUseWhereFragment(boolean b) {
 		useWhereFragment = b;
 	}
 
 
 	public void setCollectionTableAlias(String collectionTableAlias) {
 		this.collectionTableAlias = collectionTableAlias;
 	}
 
 	public String getCollectionTableAlias() {
 		return collectionTableAlias;
 	}
 
 	public boolean isCollectionOfValuesOrComponents() {
 		return elementType.isCollectionOfValuesOrComponents();
 	}
 
 	public boolean isEntity() {
 		return elementType.isEntity();
 	}
 
 	public void setImpliedInFromClause(boolean flag) {
 		throw new UnsupportedOperationException( "Explicit FROM elements can't be implied in the FROM clause!" );
 	}
 
 	public boolean isImpliedInFromClause() {
 		return false;	// Since this is an explicit FROM element, it can't be implied in the FROM clause.
 	}
 
 	public void setInProjectionList(boolean inProjectionList) {
 		// Do nothing, eplicit from elements are *always* in the projection list.
 	}
 
 	public boolean inProjectionList() {
 		return !isImplied() && isFromOrJoinFragment();
 	}
 
 	public boolean isFromOrJoinFragment() {
 		return getType() == SqlTokenTypes.FROM_FRAGMENT || getType() == SqlTokenTypes.JOIN_FRAGMENT;
 	}
 
 	public boolean isAllPropertyFetch() {
 		return isAllPropertyFetch;
 	}
 
 	public void setAllPropertyFetch(boolean fetch) {
 		isAllPropertyFetch = fetch;
 	}
 
 	public String getWithClauseFragment() {
 		return withClauseFragment;
 	}
 
 	public String getWithClauseJoinAlias() {
 		return withClauseJoinAlias;
 	}
 
 	public void setWithClauseFragment(String withClauseJoinAlias, String withClauseFragment) {
 		this.withClauseJoinAlias = withClauseJoinAlias;
 		this.withClauseFragment = withClauseFragment;
 	}
 
 	public boolean hasCacheablePersister() {
 		if ( getQueryableCollection() != null ) {
 			return getQueryableCollection().hasCache();
 		}
 		else {
 			return getQueryable().hasCache();
 		}
 	}
 
 	public void handlePropertyBeingDereferenced(Type propertySource, String propertyName) {
 		if ( getQueryableCollection() != null && CollectionProperties.isCollectionProperty( propertyName ) ) {
 			// propertyName refers to something like collection.size...
 			return;
 		}
 		if ( propertySource.isComponentType() ) {
 			// property name is a sub-path of a component...
 			return;
 		}
 
 		Queryable persister = getQueryable();
 		if ( persister != null ) {
 			try {
 				Queryable.Declarer propertyDeclarer = persister.getSubclassPropertyDeclarer( propertyName );
 				if ( LOG.isTraceEnabled() ) {
 					LOG.tracev( "Handling property dereference [{0} ({1}) -> {2} ({3})]",
 							persister.getEntityName(), getClassAlias(), propertyName, propertyDeclarer );
 				}
 				if ( propertyDeclarer == Queryable.Declarer.SUBCLASS ) {
 					dereferencedBySubclassProperty = true;
 					includeSubclasses = true;
 				}
 				else if ( propertyDeclarer == Queryable.Declarer.SUPERCLASS ) {
 					dereferencedBySuperclassProperty = true;
 				}
 			}
 			catch( QueryException ignore ) {
 				// ignore it; the incoming property could not be found so we
 				// cannot be sure what to do here.  At the very least, the
 				// safest is to simply not apply any dereference toggling...
 
 			}
 		}
 	}
 
 	public boolean isDereferencedBySuperclassProperty() {
 		return dereferencedBySuperclassProperty;
 	}
 
 	public boolean isDereferencedBySubclassProperty() {
 		return dereferencedBySubclassProperty;
 	}
 
 
 	// ParameterContainer impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private List<ParameterSpecification> embeddedParameters;
 
 	@Override
 	public void addEmbeddedParameter(ParameterSpecification specification) {
 		if ( embeddedParameters == null ) {
 			embeddedParameters = new ArrayList<ParameterSpecification>();
 		}
 		embeddedParameters.add( specification );
 	}
 
 	@Override
 	public boolean hasEmbeddedParameters() {
 		return embeddedParameters != null && ! embeddedParameters.isEmpty();
 	}
 
 	@Override
 	public ParameterSpecification[] getEmbeddedParameters() {
 		return embeddedParameters.toArray( new ParameterSpecification[ embeddedParameters.size() ] );
 	}
 
 	public ParameterSpecification getIndexCollectionSelectorParamSpec() {
 		return elementType.getIndexCollectionSelectorParamSpec();
 	}
 
 	public void setIndexCollectionSelectorParamSpec(ParameterSpecification indexCollectionSelectorParamSpec) {
 		if ( indexCollectionSelectorParamSpec == null ) {
 			if ( elementType.getIndexCollectionSelectorParamSpec() != null ) {
 				embeddedParameters.remove( elementType.getIndexCollectionSelectorParamSpec() );
 				elementType.setIndexCollectionSelectorParamSpec( null );
 			}
 		}
 		else {
 			elementType.setIndexCollectionSelectorParamSpec( indexCollectionSelectorParamSpec );
 			addEmbeddedParameter( indexCollectionSelectorParamSpec );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
index 8f692dce1b..3187915cdf 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
@@ -1,145 +1,147 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 
 import org.hibernate.QueryException;
 
 /**
  * Parses the Hibernate query into its constituent clauses.
  */
 public class ClauseParser implements Parser {
 	private Parser child;
 	private List<String> selectTokens;
 	private boolean cacheSelectTokens;
 	private boolean byExpected;
 	private int parenCount;
 
 	@Override
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 		String lcToken = token.toLowerCase(Locale.ROOT);
 
 		if ( "(".equals( token ) ) {
 			parenCount++;
 		}
 		else if ( ")".equals( token ) ) {
 			parenCount--;
 		}
 
 		if ( byExpected && !lcToken.equals( "by" ) ) {
 			throw new QueryException( "BY expected after GROUP or ORDER: " + token );
 		}
 
 		boolean isClauseStart = parenCount == 0; //ignore subselect keywords
 
 		if ( isClauseStart ) {
 			if ( lcToken.equals( "select" ) ) {
 				selectTokens = new ArrayList<String>();
 				cacheSelectTokens = true;
 			}
 			else if ( lcToken.equals( "from" ) ) {
 				child = new FromParser();
 				child.start( q );
 				cacheSelectTokens = false;
 			}
 			else if ( lcToken.equals( "where" ) ) {
 				endChild( q );
 				child = new WhereParser();
 				child.start( q );
 			}
 			else if ( lcToken.equals( "order" ) ) {
 				endChild( q );
 				child = new OrderByParser();
 				byExpected = true;
 			}
 			else if ( lcToken.equals( "having" ) ) {
 				endChild( q );
 				child = new HavingParser();
 				child.start( q );
 			}
 			else if ( lcToken.equals( "group" ) ) {
 				endChild( q );
 				child = new GroupByParser();
 				byExpected = true;
 			}
 			else if ( lcToken.equals( "by" ) ) {
-				if ( !byExpected ) throw new QueryException( "GROUP or ORDER expected before BY" );
+				if ( !byExpected ) {
+					throw new QueryException( "GROUP or ORDER expected before BY" );
+				}
 				child.start( q );
 				byExpected = false;
 			}
 			else {
 				isClauseStart = false;
 			}
 		}
 
 		if ( !isClauseStart ) {
 			if ( cacheSelectTokens ) {
 				selectTokens.add( token );
 			}
 			else {
 				if ( child == null ) {
 					throw new QueryException( "query must begin with SELECT or FROM: " + token );
 				}
 				else {
 					child.token( token, q );
 				}
 			}
 		}
 
 	}
 
 	private void endChild(QueryTranslatorImpl q) throws QueryException {
 		if ( child == null ) {
 			//null child could occur for no from clause in a filter
 			cacheSelectTokens = false;
 		}
 		else {
 			child.end( q );
 		}
 	}
 
 	@Override
 	public void start(QueryTranslatorImpl q) {
 	}
 
 	@Override
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		endChild( q );
 		if ( selectTokens != null ) {
 			child = new SelectParser();
 			child.start( q );
 			for ( String selectToken : selectTokens ) {
 				token( selectToken, q );
 			}
 			child.end( q );
 		}
 		byExpected = false;
 		parenCount = 0;
 		cacheSelectTokens = false;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
index bc736eb265..9bf9bcc3fb 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/FromParser.java
@@ -1,303 +1,333 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
 
 import org.hibernate.QueryException;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 
 /**
  * Parses the from clause of a hibernate query, looking for tables and
  * aliases for the SQL query.
  */
 
 public class FromParser implements Parser {
 
 	private final PathExpressionParser peParser = new FromPathExpressionParser();
 	private String entityName;
 	private String alias;
 	private boolean afterIn;
 	private boolean afterAs;
 	private boolean afterClass;
 	private boolean expectingJoin;
 	private boolean expectingIn;
 	private boolean expectingAs;
 	private boolean afterJoinType;
 	private JoinType joinType = JoinType.INNER_JOIN;
 	private boolean afterFetch;
 	
 	//support collection member declarations
 	//e.g. "from Customer c, in(c.orders) as o"
 	private boolean memberDeclarations;
 	private boolean expectingPathExpression;
 	private boolean afterMemberDeclarations;
 	private String collectionName;
 
 	private static final Map<String,JoinType> JOIN_TYPES = new HashMap<String,JoinType>();
 
 	static {
 		JOIN_TYPES.put( "left", JoinType.LEFT_OUTER_JOIN );
 		JOIN_TYPES.put( "right", JoinType.RIGHT_OUTER_JOIN );
 		JOIN_TYPES.put( "full", JoinType.FULL_JOIN );
 		JOIN_TYPES.put( "inner", JoinType.INNER_JOIN );
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
 		// start by looking for HQL keywords...
 		String lcToken = token.toLowerCase(Locale.ROOT);
 		if ( lcToken.equals( "," ) ) {
-			if ( !( expectingJoin | expectingAs ) ) throw new QueryException( "unexpected token: ," );
+			if ( !( expectingJoin | expectingAs ) ) {
+				throw new QueryException( "unexpected token: ," );
+			}
 			expectingJoin = false;
 			expectingAs = false;
 		}
 		else if ( lcToken.equals( "join" ) ) {
 			if ( !afterJoinType ) {
 				if ( !( expectingJoin | expectingAs ) ) throw new QueryException( "unexpected token: join" );
 				// inner joins can be abbreviated to 'join'
 				joinType = JoinType.INNER_JOIN;
 				expectingJoin = false;
 				expectingAs = false;
 			}
 			else {
 				afterJoinType = false;
 			}
 		}
 		else if ( lcToken.equals( "fetch" ) ) {
-			if ( q.isShallowQuery() ) throw new QueryException( QueryTranslator.ERROR_CANNOT_FETCH_WITH_ITERATE );
-			if ( joinType == JoinType.NONE ) throw new QueryException( "unexpected token: fetch" );
+			if ( q.isShallowQuery() ) {
+				throw new QueryException( QueryTranslator.ERROR_CANNOT_FETCH_WITH_ITERATE );
+			}
+			if ( joinType == JoinType.NONE ) {
+				throw new QueryException( "unexpected token: fetch" );
+			}
 			if ( joinType == JoinType.FULL_JOIN || joinType == JoinType.RIGHT_OUTER_JOIN ) {
 				throw new QueryException( "fetch may only be used with inner join or left outer join" );
 			}
 			afterFetch = true;
 		}
 		else if ( lcToken.equals( "outer" ) ) {
 			// 'outer' is optional and is ignored
 			if ( !afterJoinType ||
 					( joinType != JoinType.LEFT_OUTER_JOIN && joinType != JoinType.RIGHT_OUTER_JOIN )
 			) {
 				throw new QueryException( "unexpected token: outer" );
 			}
 		}
 		else if ( JOIN_TYPES.containsKey( lcToken ) ) {
-			if ( !( expectingJoin | expectingAs ) ) throw new QueryException( "unexpected token: " + token );
+			if ( !( expectingJoin | expectingAs ) ) {
+				throw new QueryException( "unexpected token: " + token );
+			}
 			joinType = JOIN_TYPES.get( lcToken );
 			afterJoinType = true;
 			expectingJoin = false;
 			expectingAs = false;
 		}
 		else if ( lcToken.equals( "class" ) ) {
-			if ( !afterIn ) throw new QueryException( "unexpected token: class" );
-			if ( joinType != JoinType.NONE ) throw new QueryException( "outer or full join must be followed by path expression" );
+			if ( !afterIn ) {
+				throw new QueryException( "unexpected token: class" );
+			}
+			if ( joinType != JoinType.NONE ) {
+				throw new QueryException( "outer or full join must be followed by path expression" );
+			}
 			afterClass = true;
 		}
 		else if ( lcToken.equals( "in" ) ) {
 			if (alias == null ){
 				memberDeclarations = true;
 				afterMemberDeclarations = false;
 			}
 			else if ( !expectingIn ) {
 				throw new QueryException( "unexpected token: in" );
-			} else {
+			}
+			else {
 				afterIn = true;
 				expectingIn = false;
 			}
 		}
 		else if ( lcToken.equals( "as" ) ) {
-			if ( !expectingAs ) throw new QueryException( "unexpected token: as" );
+			if ( !expectingAs ) {
+				throw new QueryException( "unexpected token: as" );
+			}
 			afterAs = true;
 			expectingAs = false;
 		}
 		else if ( "(".equals( token ) ){
-			if( !memberDeclarations ) throw new QueryException( "unexpected token: (" );
+			if( !memberDeclarations ) {
+				throw new QueryException( "unexpected token: (" );
+			}
 			//TODO alias should be null here
 			expectingPathExpression = true;
 			
 		}
 		else if ( ")".equals( token ) ){
 //			memberDeclarations = false;
 //			expectingPathExpression = false;
 			afterMemberDeclarations = true;
 		}
 		else {
-
-			if ( afterJoinType ) throw new QueryException( "join expected: " + token );
-			if ( expectingJoin ) throw new QueryException( "unexpected token: " + token );
-			if ( expectingIn ) throw new QueryException( "in expected: " + token );
+			if ( afterJoinType ) {
+				throw new QueryException( "join expected: " + token );
+			}
+			if ( expectingJoin ) {
+				throw new QueryException( "unexpected token: " + token );
+			}
+			if ( expectingIn ) {
+				throw new QueryException( "in expected: " + token );
+			}
 
 			// now anything that is not a HQL keyword
 
 			if ( afterAs || expectingAs ) {
 
 				// (AS is always optional, for consistency with SQL/OQL)
 
 				// process the "new" HQL style where aliases are assigned
 				// _after_ the class name or path expression ie. using
 				// the AS construction
 
 				if ( entityName != null ) {
 					q.setAliasName( token, entityName );
 				}
 				else if ( collectionName != null ) {
 					q.setAliasName( token, collectionName );
 				}
 				else {
 					throw new QueryException( "unexpected: as " + token );
 				}
 				afterAs = false;
 				expectingJoin = true;
 				expectingAs = false;
 				entityName = null;
 				collectionName = null;
 				memberDeclarations = false;
 				expectingPathExpression = false;
 				afterMemberDeclarations = false;
 
 			}
 			else if ( afterIn ) {
 
 				// process the "old" HQL style where aliases appear _first_
 				// ie. using the IN or IN CLASS constructions
 
-				if ( alias == null ) throw new QueryException( "alias not specified for: " + token );
+				if ( alias == null ) {
+					throw new QueryException( "alias not specified for: " + token );
+				}
 
-				if ( joinType != JoinType.NONE ) throw new QueryException( "outer or full join must be followed by path expression" );
+				if ( joinType != JoinType.NONE ) {
+					throw new QueryException( "outer or full join must be followed by path expression" );
+				}
 
 				if ( afterClass ) {
 					// treat it as a classname
 					Queryable p = q.getEntityPersisterUsingImports( token );
 					if ( p == null ) throw new QueryException( "persister not found: " + token );
 					q.addFromClass( alias, p );
 				}
 				else {
 					// treat it as a path expression
 					peParser.setJoinType( JoinType.INNER_JOIN );
 					peParser.setUseThetaStyleJoin( true );
 					ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 					if ( !peParser.isCollectionValued() ) throw new QueryException( "path expression did not resolve to collection: " + token );
 					String nm = peParser.addFromCollection( q );
 					q.setAliasName( alias, nm );
 				}
 
 				alias = null;
 				afterIn = false;
 				afterClass = false;
 				expectingJoin = true;
 			}
 			else if( memberDeclarations && expectingPathExpression ){
 				expectingAs = true;
 				peParser.setJoinType( JoinType.INNER_JOIN );
 				peParser.setUseThetaStyleJoin( false );
 				ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
-				if ( !peParser.isCollectionValued() ) throw new QueryException( "path expression did not resolve to collection: " + token );
+				if ( !peParser.isCollectionValued() ) {
+					throw new QueryException( "path expression did not resolve to collection: " + token );
+				}
 				collectionName = peParser.addFromCollection( q );
 				expectingPathExpression = false;
 				memberDeclarations = false;
 			}
 			else {
 
 				// handle a path expression or class name that
 				// appears at the start, in the "new" HQL
 				// style or an alias that appears at the start
 				// in the "old" HQL style
 
 				Queryable p = q.getEntityPersisterUsingImports( token );
 				if ( p != null ) {
 					// starts with the name of a mapped class (new style)
-					if ( joinType != JoinType.NONE ) throw new QueryException( "outer or full join must be followed by path expression" );
+					if ( joinType != JoinType.NONE ) {
+						throw new QueryException( "outer or full join must be followed by path expression" );
+					}
 					entityName = q.createNameFor( p.getEntityName() );
 					q.addFromClass( entityName, p );
 					expectingAs = true;
 				}
 				else if ( token.indexOf( '.' ) < 0 ) {
 					// starts with an alias (old style)
 					// semi-bad thing about this: can't re-alias another alias.....
 					alias = token;
 					expectingIn = true;
 				}
 				else {
 
 					// starts with a path expression (new style)
 
 					// force HQL style: from Person p inner join p.cars c
 					//if (joinType==NONE) throw new QueryException("path expression must be preceded by full, left, right or inner join");
 
 					//allow ODMG OQL style: from Person p, p.cars c
 					if ( joinType != JoinType.NONE ) {
 						peParser.setJoinType( joinType );
 					}
 					else {
 						peParser.setJoinType( JoinType.INNER_JOIN );
 					}
 					peParser.setUseThetaStyleJoin( q.isSubquery() );
 
 					ParserHelper.parse( peParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 					entityName = peParser.addFromAssociation( q );
 
 					joinType = JoinType.NONE;
 					peParser.setJoinType( JoinType.INNER_JOIN );
 
 					if ( afterFetch ) {
 						peParser.fetch( q, entityName );
 						afterFetch = false;
 					}
 
 					expectingAs = true;
 
 				}
 			}
 		}
 
 	}
 
 	public void start(QueryTranslatorImpl q) {
 		entityName = null;
 		collectionName = null;
 		alias = null;
 		afterIn = false;
 		afterAs = false;
 		afterClass = false;
 		expectingJoin = false;
 		expectingIn = false;
 		expectingAs = false;
 		memberDeclarations = false;
 		expectingPathExpression = false;
 		afterMemberDeclarations = false;
 		joinType = JoinType.NONE;
 	}
 
 	public void end(QueryTranslatorImpl q) {
-		if( afterMemberDeclarations ){
+		if( afterMemberDeclarations ) {
 			//The exception throwned by the AST query translator contains the error token location, respensent by line and colum, 
 			//but it hard to get that info here.
 			throw new QueryException("alias not specified for IN");
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PathExpressionParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PathExpressionParser.java
index 7f9dd413bf..e4a4cf1d8c 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PathExpressionParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PathExpressionParser.java
@@ -1,525 +1,542 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 import java.util.LinkedList;
 import java.util.Map;
 
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.internal.CollectionSubqueryFactory;
 import org.hibernate.persister.collection.CollectionPropertyMapping;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Parses an expression of the form foo.bar.baz and builds up an expression
  * involving two less table joins than there are path components.
  */
 public class PathExpressionParser implements Parser {
 
 	//TODO: this class does too many things! we need a different
 	//kind of path expression parser for each of the diffferent
 	//ways in which path expressions can occur
 
 	//We should actually rework this class to not implement Parser
 	//and just process path expressions in the most convenient way.
 
 	//The class is now way to complex!
 
 	private int dotcount;
 	private String currentName;
 	private String currentProperty;
 	private String oneToOneOwnerName;
 	private AssociationType ownerAssociationType;
 	private String[] columns;
 	private String collectionName;
 	private String collectionOwnerName;
 	private String collectionRole;
 	private final StringBuilder componentPath = new StringBuilder();
 	private Type type;
 	private final StringBuilder path = new StringBuilder();
 	private boolean ignoreInitialJoin;
 	private boolean continuation;
 	private JoinType joinType = JoinType.INNER_JOIN; //default mode
 	private boolean useThetaStyleJoin = true;
 	private PropertyMapping currentPropertyMapping;
 	private JoinSequence joinSequence;
 
 	private boolean expectingCollectionIndex;
 	private LinkedList collectionElements = new LinkedList();
 
 	void setJoinType(JoinType joinType) {
 		this.joinType = joinType;
 	}
 
 	void setUseThetaStyleJoin(boolean useThetaStyleJoin) {
 		this.useThetaStyleJoin = useThetaStyleJoin;
 	}
 
 	private void addJoin(String name, AssociationType joinableType) throws QueryException {
 		try {
 			joinSequence.addJoin( joinableType, name, joinType, currentColumns() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void addJoin(String name, AssociationType joinableType, String[] foreignKeyColumns) throws QueryException {
 		try {
 			joinSequence.addJoin( joinableType, name, joinType, foreignKeyColumns );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	String continueFromManyToMany(String entityName, String[] joinColumns, QueryTranslatorImpl q) throws QueryException {
 		start( q );
 		continuation = true;
 		currentName = q.createNameFor( entityName );
 		q.addType( currentName, entityName );
 		Queryable classPersister = q.getEntityPersister( entityName );
 		//QueryJoinFragment join = q.createJoinFragment(useThetaStyleJoin);
 		addJoin( currentName, q.getFactory().getTypeResolver().getTypeFactory().manyToOne( entityName ), joinColumns );
 		currentPropertyMapping = classPersister;
 		return currentName;
 	}
 
 	public void ignoreInitialJoin() {
 		ignoreInitialJoin = true;
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
-		if ( token != null ) path.append( token );
+		if ( token != null ) {
+			path.append( token );
+		}
 
 		String alias = q.getPathAlias( path.toString() );
 		if ( alias != null ) {
 			reset( q ); //reset the dotcount (but not the path)
 			currentName = alias; //after reset!
 			currentPropertyMapping = q.getPropertyMapping( currentName );
 			if ( !ignoreInitialJoin ) {
 				JoinSequence ojf = q.getPathJoin( path.toString() );
 				try {
 					joinSequence.addCondition( ojf.toJoinFragment( q.getEnabledFilters(), true ).toWhereFragmentString() ); //after reset!
 				}
 				catch ( MappingException me ) {
 					throw new QueryException( me );
 				}
 				// we don't need to worry about any condition in the ON clause
 				// here (toFromFragmentString), since anything in the ON condition
 				// is already applied to the whole query
 			}
 		}
 		else if ( ".".equals( token ) ) {
 			dotcount++;
 		}
 		else {
 			if ( dotcount == 0 ) {
 				if ( !continuation ) {
-					if ( !q.isName( token ) ) throw new QueryException( "undefined alias: " + token );
+					if ( !q.isName( token ) ) {
+						throw new QueryException( "undefined alias: " + token );
+					}
 					currentName = token;
 					currentPropertyMapping = q.getPropertyMapping( currentName );
 				}
 			}
 			else if ( dotcount == 1 ) {
 				if ( currentName != null ) {
 					currentProperty = token;
 				}
 				else if ( collectionName != null ) {
 					//processCollectionProperty(token, q.getCollectionPersister(collectionRole), collectionName);
 					continuation = false;
 				}
 				else {
 					throw new QueryException( "unexpected" );
 				}
 			}
 			else { // dotcount>=2
 
 				// Do the corresponding RHS
 				Type propertyType = getPropertyType();
 
 				if ( propertyType == null ) {
 					throw new QueryException( "unresolved property: " + path );
 				}
 
 				if ( propertyType.isComponentType() ) {
 					dereferenceComponent( token );
 				}
 				else if ( propertyType.isEntityType() ) {
-					if ( !isCollectionValued() ) dereferenceEntity( token, ( EntityType ) propertyType, q );
+					if ( !isCollectionValued() ) {
+						dereferenceEntity( token, ( EntityType ) propertyType, q );
+					}
 				}
 				else if ( propertyType.isCollectionType() ) {
 					dereferenceCollection( token, ( ( CollectionType ) propertyType ).getRole(), q );
 
 				}
 				else {
-					if ( token != null ) throw new QueryException( "dereferenced: " + path );
+					if ( token != null ) {
+						throw new QueryException( "dereferenced: " + path );
+					}
 				}
 
 			}
 		}
 	}
 
 	private void dereferenceEntity(String propertyName, EntityType propertyType, QueryTranslatorImpl q)
 			throws QueryException {
 		//NOTE: we avoid joining to the next table if the named property is just the foreign key value
 
 		//if its "id"
-		boolean isIdShortcut = EntityPersister.ENTITY_ID.equals( propertyName ) &&
-				propertyType.isReferenceToPrimaryKey();
+		boolean isIdShortcut = EntityPersister.ENTITY_ID.equals( propertyName )
+				&& propertyType.isReferenceToPrimaryKey();
 
 		//or its the id property name
 		final String idPropertyName;
 		try {
 			idPropertyName = propertyType.getIdentifierOrUniqueKeyPropertyName( q.getFactory() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 		boolean isNamedIdPropertyShortcut = idPropertyName != null
 				&& idPropertyName.equals( propertyName )
 				&& propertyType.isReferenceToPrimaryKey();
 
 
 		if ( isIdShortcut || isNamedIdPropertyShortcut ) {
 			// special shortcut for id properties, skip the join!
 			// this must only occur at the _end_ of a path expression
-			if ( componentPath.length() > 0 ) componentPath.append( '.' );
+			if ( componentPath.length() > 0 ) {
+				componentPath.append( '.' );
+			}
 			componentPath.append( propertyName );
 		}
 		else {
 			String entityClass = propertyType.getAssociatedEntityName();
 			String name = q.createNameFor( entityClass );
 			q.addType( name, entityClass );
 			addJoin( name, propertyType );
-			if ( propertyType.isOneToOne() ) oneToOneOwnerName = currentName;
+			if ( propertyType.isOneToOne() ) {
+				oneToOneOwnerName = currentName;
+			}
 			ownerAssociationType = propertyType;
 			currentName = name;
 			currentProperty = propertyName;
 			q.addPathAliasAndJoin( path.substring( 0, path.toString().lastIndexOf( '.' ) ), name, joinSequence.copy() );
 			componentPath.setLength( 0 );
 			currentPropertyMapping = q.getEntityPersister( entityClass );
 		}
 	}
 
 	private void dereferenceComponent(String propertyName) {
 		if ( propertyName != null ) {
-			if ( componentPath.length() > 0 ) componentPath.append( '.' );
+			if ( componentPath.length() > 0 ) {
+				componentPath.append( '.' );
+			}
 			componentPath.append( propertyName );
 		}
 	}
 
 	private void dereferenceCollection(String propertyName, String role, QueryTranslatorImpl q) throws QueryException {
 		collectionRole = role;
 		QueryableCollection collPersister = q.getCollectionPersister( role );
 		String name = q.createNameForCollection( role );
 		addJoin( name, collPersister.getCollectionType() );
 		//if ( collPersister.hasWhere() ) join.addCondition( collPersister.getSQLWhereString(name) );
 		collectionName = name;
 		collectionOwnerName = currentName;
 		currentName = name;
 		currentProperty = propertyName;
 		componentPath.setLength( 0 );
 		currentPropertyMapping = new CollectionPropertyMapping( collPersister );
 	}
 
 	private String getPropertyPath() {
 		if ( currentProperty == null ) {
 			return EntityPersister.ENTITY_ID;
 		}
 		else {
 			if ( componentPath.length() > 0 ) {
-				return new StringBuilder()
-						.append( currentProperty )
-						.append( '.' )
-						.append( componentPath.toString() )
-						.toString();
+				return currentProperty + '.' + componentPath.toString();
 			}
 			else {
 				return currentProperty;
 			}
 		}
 	}
 
 	private PropertyMapping getPropertyMapping() {
 		return currentPropertyMapping;
 	}
 
 	private void setType() throws QueryException {
 		if ( currentProperty == null ) {
 			type = getPropertyMapping().getType();
 		}
 		else {
 			type = getPropertyType();
 		}
 	}
 
 	protected Type getPropertyType() throws QueryException {
 		String propertyPath = getPropertyPath();
 		Type propertyType = getPropertyMapping().toType( propertyPath );
 		if ( propertyType == null ) {
 			throw new QueryException( "could not resolve property type: " + propertyPath );
 		}
 		return propertyType;
 	}
 
 	protected String[] currentColumns() throws QueryException {
 		String propertyPath = getPropertyPath();
 		String[] propertyColumns = getPropertyMapping().toColumns( currentName, propertyPath );
 		if ( propertyColumns == null ) {
 			throw new QueryException( "could not resolve property columns: " + propertyPath );
 		}
 		return propertyColumns;
 	}
 
 	private void reset(QueryTranslatorImpl q) {
 		//join = q.createJoinFragment(useThetaStyleJoin);
 		dotcount = 0;
 		currentName = null;
 		currentProperty = null;
 		collectionName = null;
 		collectionRole = null;
 		componentPath.setLength( 0 );
 		type = null;
 		collectionName = null;
 		columns = null;
 		expectingCollectionIndex = false;
 		continuation = false;
 		currentPropertyMapping = null;
 	}
 
 	public void start(QueryTranslatorImpl q) {
 		if ( !continuation ) {
 			reset( q );
 			path.setLength( 0 );
 			joinSequence = new JoinSequence( q.getFactory() ).setUseThetaStyle( useThetaStyleJoin );
 		}
 	}
 
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		ignoreInitialJoin = false;
 
 		Type propertyType = getPropertyType();
 		if ( propertyType != null && propertyType.isCollectionType() ) {
 			collectionRole = ( ( CollectionType ) propertyType ).getRole();
 			collectionName = q.createNameForCollection( collectionRole );
 			prepareForIndex( q );
 		}
 		else {
 			columns = currentColumns();
 			setType();
 		}
 
 		//important!!
 		continuation = false;
 
 	}
 
 	private void prepareForIndex(QueryTranslatorImpl q) throws QueryException {
 
 		QueryableCollection collPersister = q.getCollectionPersister( collectionRole );
 
-		if ( !collPersister.hasIndex() ) throw new QueryException( "unindexed collection before []: " + path );
+		if ( !collPersister.hasIndex() ) {
+			throw new QueryException( "unindexed collection before []: " + path );
+		}
+
 		String[] indexCols = collPersister.getIndexColumnNames();
-		if ( indexCols.length != 1 ) throw new QueryException( "composite-index appears in []: " + path );
+		if ( indexCols.length != 1 ) {
+			throw new QueryException( "composite-index appears in []: " + path );
+		}
 		//String[] keyCols = collPersister.getKeyColumnNames();
 
 		JoinSequence fromJoins = new JoinSequence( q.getFactory() )
 				.setUseThetaStyle( useThetaStyleJoin )
 				.setRoot( collPersister, collectionName )
 				.setNext( joinSequence.copy() );
 
-		if ( !continuation ) addJoin( collectionName, collPersister.getCollectionType() );
+		if ( !continuation ) {
+			addJoin( collectionName, collPersister.getCollectionType() );
+		}
 
 		joinSequence.addCondition( collectionName + '.' + indexCols[0] + " = " ); //TODO: get SQL rendering out of here
 
 		CollectionElement elem = new CollectionElement();
 		elem.elementColumns = collPersister.getElementColumnNames(collectionName);
 		elem.elementType = collPersister.getElementType();
 		elem.isOneToMany = collPersister.isOneToMany();
 		elem.alias = collectionName;
 		elem.joinSequence = joinSequence;
 		collectionElements.addLast( elem );
 		setExpectingCollectionIndex();
 
 		q.addCollection( collectionName, collectionRole );
 		q.addFromJoinOnly( collectionName, fromJoins );
 	}
 
 	static final class CollectionElement {
 		Type elementType;
 		boolean isOneToMany;
 		String alias;
 		String[] elementColumns;
 		JoinSequence joinSequence;
 		StringBuilder indexValue = new StringBuilder();
 	}
 
 	public CollectionElement lastCollectionElement() {
 		return ( CollectionElement ) collectionElements.removeLast();
 	}
 
 	public void setLastCollectionElementIndexValue(String value) {
 		( ( CollectionElement ) collectionElements.getLast() ).indexValue.append( value );
 	}
 
 	public boolean isExpectingCollectionIndex() {
 		return expectingCollectionIndex;
 	}
 
 	protected void setExpectingCollectionIndex() throws QueryException {
 		expectingCollectionIndex = true;
 	}
 
 	public JoinSequence getWhereJoin() {
 		return joinSequence;
 	}
 
 	public String getWhereColumn() throws QueryException {
 		if ( columns.length != 1 ) {
 			throw new QueryException( "path expression ends in a composite value: " + path );
 		}
 		return columns[0];
 	}
 
 	public String[] getWhereColumns() {
 		return columns;
 	}
 
 	public Type getWhereColumnType() {
 		return type;
 	}
 
 	public String getName() {
 		return currentName == null ? collectionName : currentName;
 	}
 
 
 	public String getCollectionSubquery(Map enabledFilters) throws QueryException {
 		return CollectionSubqueryFactory.createCollectionSubquery( joinSequence, enabledFilters, currentColumns() );
 	}
 
 	public boolean isCollectionValued() throws QueryException {
 		//TODO: is there a better way?
 		return collectionName != null && !getPropertyType().isCollectionType();
 	}
 
 	public void addAssociation(QueryTranslatorImpl q) throws QueryException {
 		q.addJoin( getName(), joinSequence );
 	}
 
 	public String addFromAssociation(QueryTranslatorImpl q) throws QueryException {
 		if ( isCollectionValued() ) {
 			return addFromCollection( q );
 		}
 		else {
 			q.addFrom( currentName, joinSequence );
 			return currentName;
 		}
 	}
 
 	public String addFromCollection(QueryTranslatorImpl q) throws QueryException {
 		Type collectionElementType = getPropertyType();
 
 		if ( collectionElementType == null ) {
 			throw new QueryException( "must specify 'elements' for collection valued property in from clause: " + path );
 		}
 
 		if ( collectionElementType.isEntityType() ) {
 			// an association
 			QueryableCollection collectionPersister = q.getCollectionPersister( collectionRole );
 			Queryable entityPersister = ( Queryable ) collectionPersister.getElementPersister();
 			String clazz = entityPersister.getEntityName();
 
 			final String elementName;
 			if ( collectionPersister.isOneToMany() ) {
 				elementName = collectionName;
 				//allow index() function:
 				q.decoratePropertyMapping( elementName, collectionPersister );
 			}
 			else { //many-to-many
 				q.addCollection( collectionName, collectionRole );
 				elementName = q.createNameFor( clazz );
 				addJoin( elementName, ( AssociationType ) collectionElementType );
 			}
 			q.addFrom( elementName, clazz, joinSequence );
 			currentPropertyMapping = new CollectionPropertyMapping( collectionPersister );
 			return elementName;
 		}
 		else {
 			// collections of values
 			q.addFromCollection( collectionName, collectionRole, joinSequence );
 			return collectionName;
 		}
 
 	}
 
 	String getCollectionName() {
 		return collectionName;
 	}
 
 	String getCollectionRole() {
 		return collectionRole;
 	}
 
 	String getCollectionOwnerName() {
 		return collectionOwnerName;
 	}
 
 	String getOneToOneOwnerName() {
 		return oneToOneOwnerName;
 	}
 
 	AssociationType getOwnerAssociationType() {
 		return ownerAssociationType;
 	}
 
 	String getCurrentProperty() {
 		return currentProperty;
 	}
 
 	String getCurrentName() {
 		return currentName;
 	}
 
 	public void fetch(QueryTranslatorImpl q, String entityName) throws QueryException {
 		if ( isCollectionValued() ) {
 			q.setCollectionToFetch( getCollectionRole(), getCollectionName(), getCollectionOwnerName(), entityName );
 		}
 		else {
 			q.addEntityToFetch( entityName, getOneToOneOwnerName(), getOwnerAssociationType() );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
index a4002548a3..9b45d71d9c 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
@@ -1,1247 +1,1278 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.io.Serializable;
 import java.lang.reflect.Constructor;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.hql.internal.NameGenerator;
 import org.hibernate.hql.spi.FilterTranslator;
 import org.hibernate.hql.spi.ParameterTranslations;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.IteratorImpl;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.sql.QuerySelect;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * An instance of <tt>QueryTranslator</tt> translates a Hibernate
  * query string to SQL.
  */
 public class QueryTranslatorImpl extends BasicLoader implements FilterTranslator {
     private static final CoreMessageLogger LOG = CoreLogging.messageLogger( QueryTranslatorImpl.class );
 
 	private static final String[] NO_RETURN_ALIASES = new String[] {};
 
 	private final String queryIdentifier;
 	private final String queryString;
 
 	private final Map typeMap = new LinkedHashMap();
 	private final Map collections = new LinkedHashMap();
 	private List returnedTypes = new ArrayList();
 	private final List fromTypes = new ArrayList();
 	private final List scalarTypes = new ArrayList();
 	private final Map namedParameters = new HashMap();
 	private final Map aliasNames = new HashMap();
 	private final Map oneToOneOwnerNames = new HashMap();
 	private final Map uniqueKeyOwnerReferences = new HashMap();
 	private final Map decoratedPropertyMappings = new HashMap();
 
 	private final List scalarSelectTokens = new ArrayList();
 	private final List whereTokens = new ArrayList();
 	private final List havingTokens = new ArrayList();
 	private final Map joins = new LinkedHashMap();
 	private final List orderByTokens = new ArrayList();
 	private final List groupByTokens = new ArrayList();
 	private final Set<Serializable> querySpaces = new HashSet<Serializable>();
 	private final Set entitiesToFetch = new HashSet();
 
 	private final Map pathAliases = new HashMap();
 	private final Map pathJoins = new HashMap();
 
 	private Queryable[] persisters;
 	private int[] owners;
 	private EntityType[] ownerAssociationTypes;
 	private String[] names;
 	private boolean[] includeInSelect;
 	private int selectLength;
 	private Type[] returnTypes;
 	private Type[] actualReturnTypes;
 	private String[][] scalarColumnNames;
 	private Map tokenReplacements;
 	private int nameCount;
 	private int parameterCount;
 	private boolean distinct;
 	private boolean compiled;
 	private String sqlString;
 	private Class holderClass;
 	private Constructor holderConstructor;
 	private boolean hasScalars;
 	private boolean shallowQuery;
 	private QueryTranslatorImpl superQuery;
 
 	private QueryableCollection collectionPersister;
 	private int collectionOwnerColumn = -1;
 	private String collectionOwnerName;
 	private String fetchName;
 
 	private String[] suffixes;
 
 	private Map enabledFilters;
 
 	/**
 	 * Construct a query translator
 	 *
 	 * @param queryIdentifier A unique identifier for the query of which this
 	 * translation is part; typically this is the original, user-supplied query string.
 	 * @param queryString The "preprocessed" query string; at the very least
 	 * already processed by {@link org.hibernate.hql.internal.QuerySplitter}.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 			String queryIdentifier,
 	        String queryString,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		super( factory );
 		this.queryIdentifier = queryIdentifier;
 		this.queryString = queryString;
 		this.enabledFilters = enabledFilters;
 	}
 
 	/**
 	 * Construct a query translator; this form used internally.
 	 *
 	 * @param queryString The query string to process.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 	        String queryString,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		this( queryString, queryString, enabledFilters, factory );
 	}
 
 	/**
 	 * Compile a subquery.
 	 *
 	 * @param superquery The containing query of the query to be compiled.
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	void compile(QueryTranslatorImpl superquery) throws QueryException, MappingException {
 		this.tokenReplacements = superquery.tokenReplacements;
 		this.superQuery = superquery;
 		this.shallowQuery = true;
 		this.enabledFilters = superquery.getEnabledFilters();
 		compile();
 	}
 
 
 	/**
 	 * Compile a "normal" query. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 		if ( !compiled ) {
 			this.tokenReplacements = replacements;
 			this.shallowQuery = scalar;
 			compile();
 		}
 	}
 
 	/**
 	 * Compile a filter. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			String collectionRole,
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 
 		if ( !isCompiled() ) {
 			addFromAssociation( "this", collectionRole );
 			compile( replacements, scalar );
 		}
 	}
 
 	/**
 	 * Compile the query (generate the SQL).
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	private void compile() throws QueryException, MappingException {
 		LOG.trace( "Compiling query" );
 		try {
 			ParserHelper.parse( new PreprocessingParser( tokenReplacements ),
 					queryString,
 					ParserHelper.HQL_SEPARATORS,
 					this );
 			renderSQL();
 		}
 		catch ( QueryException qe ) {
 			if ( qe.getQueryString() == null ) {
 				throw qe.wrapWithQueryString( queryString );
 			}
 			else {
 				throw qe;
 			}
 		}
 		catch ( MappingException me ) {
 			throw me;
 		}
 		catch ( Exception e ) {
 			LOG.debug( "Unexpected query compilation problem", e );
 			e.printStackTrace();
 			throw new QueryException( "Incorrect query syntax", queryString, e );
 		}
 
 		postInstantiate();
 
 		compiled = true;
 
 	}
 
 	@Override
     public String getSQLString() {
 		return sqlString;
 	}
 
 	public List<String> collectSqlStrings() {
 		return ArrayHelper.toList( new String[] { sqlString } );
 	}
 
 	public String getQueryString() {
 		return queryString;
 	}
 
 	/**
 	 * Persisters for the return values of a <tt>find()</tt> style query.
 	 *
 	 * @return an array of <tt>EntityPersister</tt>s.
 	 */
 	@Override
     protected Loadable[] getEntityPersisters() {
 		return persisters;
 	}
 
 	/**
 	 * Types of the return values of an <tt>iterate()</tt> style query.
 	 *
 	 * @return an array of <tt>Type</tt>s.
 	 */
 	public Type[] getReturnTypes() {
 		return actualReturnTypes;
 	}
 
 	public String[] getReturnAliases() {
 		// return aliases not supported in classic translator!
 		return NO_RETURN_ALIASES;
 	}
 
 	public String[][] getColumnNames() {
 		return scalarColumnNames;
 	}
 
 	private static void logQuery(String hql, String sql) {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "HQL: %s", hql );
 			LOG.debugf( "SQL: %s", sql );
 		}
 	}
 
 	void setAliasName(String alias, String name) {
 		aliasNames.put( alias, name );
 	}
 
 	public String getAliasName(String alias) {
 		String name = ( String ) aliasNames.get( alias );
 		if ( name == null ) {
 			if ( superQuery != null ) {
 				name = superQuery.getAliasName( alias );
 			}
 			else {
 				name = alias;
 			}
 		}
 		return name;
 	}
 
 	String unalias(String path) {
 		String alias = StringHelper.root( path );
 		String name = getAliasName( alias );
-        if (name != null) return name + path.substring(alias.length());
+        if (name != null) {
+			return name + path.substring(alias.length());
+		}
         return path;
 	}
 
 	void addEntityToFetch(String name, String oneToOneOwnerName, AssociationType ownerAssociationType) {
 		addEntityToFetch( name );
-		if ( oneToOneOwnerName != null ) oneToOneOwnerNames.put( name, oneToOneOwnerName );
-		if ( ownerAssociationType != null ) uniqueKeyOwnerReferences.put( name, ownerAssociationType );
+		if ( oneToOneOwnerName != null ) {
+			oneToOneOwnerNames.put( name, oneToOneOwnerName );
+		}
+		if ( ownerAssociationType != null ) {
+			uniqueKeyOwnerReferences.put( name, ownerAssociationType );
+		}
 	}
 
 	private void addEntityToFetch(String name) {
 		entitiesToFetch.add( name );
 	}
 
 	private int nextCount() {
 		return ( superQuery == null ) ? nameCount++ : superQuery.nameCount++;
 	}
 
 	String createNameFor(String type) {
 		return StringHelper.generateAlias( type, nextCount() );
 	}
 
 	String createNameForCollection(String role) {
 		return StringHelper.generateAlias( role, nextCount() );
 	}
 
 	private String getType(String name) {
 		String type = ( String ) typeMap.get( name );
 		if ( type == null && superQuery != null ) {
 			type = superQuery.getType( name );
 		}
 		return type;
 	}
 
 	private String getRole(String name) {
 		String role = ( String ) collections.get( name );
 		if ( role == null && superQuery != null ) {
 			role = superQuery.getRole( name );
 		}
 		return role;
 	}
 
 	boolean isName(String name) {
 		return aliasNames.containsKey( name ) ||
 				typeMap.containsKey( name ) ||
 				collections.containsKey( name ) || (
 				superQuery != null && superQuery.isName( name )
 				);
 	}
 
 	PropertyMapping getPropertyMapping(String name) throws QueryException {
 		PropertyMapping decorator = getDecoratedPropertyMapping( name );
-		if ( decorator != null ) return decorator;
+		if ( decorator != null ) {
+			return decorator;
+		}
 
 		String type = getType( name );
 		if ( type == null ) {
 			String role = getRole( name );
 			if ( role == null ) {
 				throw new QueryException( "alias not found: " + name );
 			}
 			return getCollectionPersister( role ); //.getElementPropertyMapping();
 		}
 		else {
 			Queryable persister = getEntityPersister( type );
-			if ( persister == null ) throw new QueryException( "persistent class not found: " + type );
+			if ( persister == null ) {
+				throw new QueryException( "persistent class not found: " + type );
+			}
 			return persister;
 		}
 	}
 
 	private PropertyMapping getDecoratedPropertyMapping(String name) {
 		return ( PropertyMapping ) decoratedPropertyMappings.get( name );
 	}
 
 	void decoratePropertyMapping(String name, PropertyMapping mapping) {
 		decoratedPropertyMappings.put( name, mapping );
 	}
 
 	private Queryable getEntityPersisterForName(String name) throws QueryException {
 		String type = getType( name );
 		Queryable persister = getEntityPersister( type );
-		if ( persister == null ) throw new QueryException( "persistent class not found: " + type );
+		if ( persister == null ) {
+			throw new QueryException( "persistent class not found: " + type );
+		}
 		return persister;
 	}
 
 	Queryable getEntityPersisterUsingImports(String className) {
 		final String importedClassName = getFactory().getImportedClassName( className );
 		if ( importedClassName == null ) {
 			return null;
 		}
 		try {
 			return ( Queryable ) getFactory().getEntityPersister( importedClassName );
 		}
 		catch ( MappingException me ) {
 			return null;
 		}
 	}
 
 	Queryable getEntityPersister(String entityName) throws QueryException {
 		try {
 			return ( Queryable ) getFactory().getEntityPersister( entityName );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( "persistent class not found: " + entityName );
 		}
 	}
 
 	QueryableCollection getCollectionPersister(String role) throws QueryException {
 		try {
 			return ( QueryableCollection ) getFactory().getCollectionPersister( role );
 		}
 		catch ( ClassCastException cce ) {
 			throw new QueryException( "collection role is not queryable: " + role );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( "collection role not found: " + role );
 		}
 	}
 
 	void addType(String name, String type) {
 		typeMap.put( name, type );
 	}
 
 	void addCollection(String name, String role) {
 		collections.put( name, role );
 	}
 
 	void addFrom(String name, String type, JoinSequence joinSequence)
 			throws QueryException {
 		addType( name, type );
 		addFrom( name, joinSequence );
 	}
 
 	void addFromCollection(String name, String collectionRole, JoinSequence joinSequence)
 			throws QueryException {
 		//register collection role
 		addCollection( name, collectionRole );
 		addJoin( name, joinSequence );
 	}
 
 	void addFrom(String name, JoinSequence joinSequence)
 			throws QueryException {
 		fromTypes.add( name );
 		addJoin( name, joinSequence );
 	}
 
 	void addFromClass(String name, Queryable classPersister)
 			throws QueryException {
 		JoinSequence joinSequence = new JoinSequence( getFactory() )
 				.setRoot( classPersister, name );
 		//crossJoins.add(name);
 		addFrom( name, classPersister.getEntityName(), joinSequence );
 	}
 
 	void addSelectClass(String name) {
 		returnedTypes.add( name );
 	}
 
 	void addSelectScalar(Type type) {
 		scalarTypes.add( type );
 	}
 
 	void appendWhereToken(String token) {
 		whereTokens.add( token );
 	}
 
 	void appendHavingToken(String token) {
 		havingTokens.add( token );
 	}
 
 	void appendOrderByToken(String token) {
 		orderByTokens.add( token );
 	}
 
 	void appendGroupByToken(String token) {
 		groupByTokens.add( token );
 	}
 
 	void appendScalarSelectToken(String token) {
 		scalarSelectTokens.add( token );
 	}
 
 	void appendScalarSelectTokens(String[] tokens) {
 		scalarSelectTokens.add( tokens );
 	}
 
 	void addFromJoinOnly(String name, JoinSequence joinSequence) throws QueryException {
 		addJoin( name, joinSequence.getFromPart() );
 	}
 
 	void addJoin(String name, JoinSequence joinSequence) throws QueryException {
-		if ( !joins.containsKey( name ) ) joins.put( name, joinSequence );
+		if ( !joins.containsKey( name ) ) {
+			joins.put( name, joinSequence );
+		}
 	}
 
 	void addNamedParameter(String name) {
-		if ( superQuery != null ) superQuery.addNamedParameter( name );
+		if ( superQuery != null ) {
+			superQuery.addNamedParameter( name );
+		}
 		Integer loc = parameterCount++;
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
 			( ( ArrayList ) o ).add( loc );
 		}
 	}
 
 	@Override
     public int[] getNamedParameterLocs(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			throw new QueryException( ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name, queryString );
 		}
-		if ( o instanceof Integer ) return new int[] { (Integer) o };
+		if ( o instanceof Integer ) {
+			return new int[] { (Integer) o };
+		}
 		else {
 			return ArrayHelper.toIntArray( ( ArrayList ) o );
 		}
 	}
 
 	private void renderSQL() throws QueryException, MappingException {
 
 		final int rtsize;
 		if ( returnedTypes.size() == 0 && scalarTypes.size() == 0 ) {
 			//ie no select clause in HQL
 			returnedTypes = fromTypes;
 			rtsize = returnedTypes.size();
 		}
 		else {
 			rtsize = returnedTypes.size();
 			Iterator iter = entitiesToFetch.iterator();
 			while ( iter.hasNext() ) {
 				returnedTypes.add( iter.next() );
 			}
 		}
 		int size = returnedTypes.size();
 		persisters = new Queryable[size];
 		names = new String[size];
 		owners = new int[size];
 		ownerAssociationTypes = new EntityType[size];
 		suffixes = new String[size];
 		includeInSelect = new boolean[size];
 		for ( int i = 0; i < size; i++ ) {
 			String name = ( String ) returnedTypes.get( i );
 			//if ( !isName(name) ) throw new QueryException("unknown type: " + name);
 			persisters[i] = getEntityPersisterForName( name );
 			// TODO: cannot use generateSuffixes() - it handles the initial suffix differently.
 			suffixes[i] = ( size == 1 ) ? "" : Integer.toString( i ) + '_';
 			names[i] = name;
 			includeInSelect[i] = !entitiesToFetch.contains( name );
-			if ( includeInSelect[i] ) selectLength++;
-			if ( name.equals( collectionOwnerName ) ) collectionOwnerColumn = i;
+			if ( includeInSelect[i] ) {
+				selectLength++;
+			}
+			if ( name.equals( collectionOwnerName ) ) {
+				collectionOwnerColumn = i;
+			}
 			String oneToOneOwner = ( String ) oneToOneOwnerNames.get( name );
 			owners[i] = ( oneToOneOwner == null ) ? -1 : returnedTypes.indexOf( oneToOneOwner );
 			ownerAssociationTypes[i] = (EntityType) uniqueKeyOwnerReferences.get( name );
 		}
 
-		if ( ArrayHelper.isAllNegative( owners ) ) owners = null;
+		if ( ArrayHelper.isAllNegative( owners ) ) {
+			owners = null;
+		}
 
 		String scalarSelect = renderScalarSelect(); //Must be done here because of side-effect! yuck...
 
 		int scalarSize = scalarTypes.size();
 		hasScalars = scalarTypes.size() != rtsize;
 
 		returnTypes = new Type[scalarSize];
 		for ( int i = 0; i < scalarSize; i++ ) {
 			returnTypes[i] = ( Type ) scalarTypes.get( i );
 		}
 
 		QuerySelect sql = new QuerySelect( getFactory().getDialect() );
 		sql.setDistinct( distinct );
 
 		if ( !shallowQuery ) {
 			renderIdentifierSelect( sql );
 			renderPropertiesSelect( sql );
 		}
 
 		if ( collectionPersister != null ) {
 			sql.addSelectFragmentString( collectionPersister.selectFragment( fetchName, "__" ) );
 		}
 
-		if ( hasScalars || shallowQuery ) sql.addSelectFragmentString( scalarSelect );
+		if ( hasScalars || shallowQuery ) {
+			sql.addSelectFragmentString( scalarSelect );
+		}
 
 		//TODO: for some dialects it would be appropriate to add the renderOrderByPropertiesSelect() to other select strings
 		mergeJoins( sql.getJoinFragment() );
 
 		sql.setWhereTokens( whereTokens.iterator() );
 
 		sql.setGroupByTokens( groupByTokens.iterator() );
 		sql.setHavingTokens( havingTokens.iterator() );
 		sql.setOrderByTokens( orderByTokens.iterator() );
 
 		if ( collectionPersister != null && collectionPersister.hasOrdering() ) {
 			sql.addOrderBy( collectionPersister.getSQLOrderByString( fetchName ) );
 		}
 
 		scalarColumnNames = NameGenerator.generateColumnNames( returnTypes, getFactory() );
 
 		// initialize the Set of queried identifier spaces (ie. tables)
 		Iterator iter = collections.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = getCollectionPersister( ( String ) iter.next() );
 			addQuerySpaces( p.getCollectionSpaces() );
 		}
 		iter = typeMap.keySet().iterator();
 		while ( iter.hasNext() ) {
 			Queryable p = getEntityPersisterForName( ( String ) iter.next() );
 			addQuerySpaces( p.getQuerySpaces() );
 		}
 
 		sqlString = sql.toQueryString();
 
-		if ( holderClass != null ) holderConstructor = ReflectHelper.getConstructor( holderClass, returnTypes );
+		if ( holderClass != null ) {
+			holderConstructor = ReflectHelper.getConstructor( holderClass, returnTypes );
+		}
 
 		if ( hasScalars ) {
 			actualReturnTypes = returnTypes;
 		}
 		else {
 			actualReturnTypes = new Type[selectLength];
 			int j = 0;
 			for ( int i = 0; i < persisters.length; i++ ) {
 				if ( includeInSelect[i] ) {
 					actualReturnTypes[j++] = getFactory().getTypeResolver()
 							.getTypeFactory()
 							.manyToOne( persisters[i].getEntityName(), shallowQuery );
 				}
 			}
 		}
 
 	}
 
 	private void renderIdentifierSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 
 		for ( int k = 0; k < size; k++ ) {
 			String name = ( String ) returnedTypes.get( k );
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			sql.addSelectFragmentString( persisters[k].identifierSelectFragment( name, suffix ) );
 		}
 
 	}
 
 	/*private String renderOrderByPropertiesSelect() {
 		StringBuffer buf = new StringBuffer(10);
 
 		//add the columns we are ordering by to the select ID select clause
 		Iterator iter = orderByTokens.iterator();
 		while ( iter.hasNext() ) {
 			String token = (String) iter.next();
 			if ( token.lastIndexOf(".") > 0 ) {
 				//ie. it is of form "foo.bar", not of form "asc" or "desc"
 				buf.append(StringHelper.COMMA_SPACE).append(token);
 			}
 		}
 
 		return buf.toString();
 	}*/
 
 	private void renderPropertiesSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 		for ( int k = 0; k < size; k++ ) {
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			String name = ( String ) returnedTypes.get( k );
 			sql.addSelectFragmentString( persisters[k].propertySelectFragment( name, suffix, false ) );
 		}
 	}
 
 	/**
 	 * WARNING: side-effecty
 	 */
 	private String renderScalarSelect() {
 
 		boolean isSubselect = superQuery != null;
 
 		StringBuilder buf = new StringBuilder( 20 );
 
 		if ( scalarTypes.size() == 0 ) {
 			//ie. no select clause
 			int size = returnedTypes.size();
 			for ( int k = 0; k < size; k++ ) {
 
 				scalarTypes.add(
 						getFactory().getTypeResolver().getTypeFactory().manyToOne( persisters[k].getEntityName(), shallowQuery )
 				);
 
 				String[] idColumnNames = persisters[k].getIdentifierColumnNames();
 				for ( int i = 0; i < idColumnNames.length; i++ ) {
 					buf.append( returnedTypes.get( k ) ).append( '.' ).append( idColumnNames[i] );
-					if ( !isSubselect ) buf.append( " as " ).append( NameGenerator.scalarName( k, i ) );
-					if ( i != idColumnNames.length - 1 || k != size - 1 ) buf.append( ", " );
+					if ( !isSubselect ) {
+						buf.append( " as " ).append( NameGenerator.scalarName( k, i ) );
+					}
+					if ( i != idColumnNames.length - 1 || k != size - 1 ) {
+						buf.append( ", " );
+					}
 				}
 
 			}
 
 		}
 		else {
 			//there _was_ a select clause
 			Iterator iter = scalarSelectTokens.iterator();
 			int c = 0;
 			boolean nolast = false; //real hacky...
 			int parenCount = 0; // used to count the nesting of parentheses
 			while ( iter.hasNext() ) {
 				Object next = iter.next();
 				if ( next instanceof String ) {
 					String token = ( String ) next;
 
 					if ( "(".equals( token ) ) {
 						parenCount++;
 					}
 					else if ( ")".equals( token ) ) {
 						parenCount--;
 					}
 
 					String lc = token.toLowerCase(Locale.ROOT);
 					if ( lc.equals( ", " ) ) {
 						if ( nolast ) {
 							nolast = false;
 						}
 						else {
 							if ( !isSubselect && parenCount == 0 ) {
 								int x = c++;
-								buf.append( " as " )
-										.append( NameGenerator.scalarName( x, 0 ) );
+								buf.append( " as " ).append( NameGenerator.scalarName( x, 0 ) );
 							}
 						}
 					}
 					buf.append( token );
 					if ( lc.equals( "distinct" ) || lc.equals( "all" ) ) {
 						buf.append( ' ' );
 					}
 				}
 				else {
 					nolast = true;
 					String[] tokens = ( String[] ) next;
 					for ( int i = 0; i < tokens.length; i++ ) {
 						buf.append( tokens[i] );
 						if ( !isSubselect ) {
-							buf.append( " as " )
-									.append( NameGenerator.scalarName( c, i ) );
+							buf.append( " as " ).append( NameGenerator.scalarName( c, i ) );
+						}
+						if ( i != tokens.length - 1 ) {
+							buf.append( ", " );
 						}
-						if ( i != tokens.length - 1 ) buf.append( ", " );
 					}
 					c++;
 				}
 			}
 			if ( !isSubselect && !nolast ) {
 				int x = c++;
-				buf.append( " as " )
-						.append( NameGenerator.scalarName( x, 0 ) );
+				buf.append( " as " ).append( NameGenerator.scalarName( x, 0 ) );
 			}
 
 		}
 
 		return buf.toString();
 	}
 
 	private void mergeJoins(JoinFragment ojf) throws MappingException, QueryException {
 
 		Iterator iter = joins.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = ( Map.Entry ) iter.next();
 			String name = ( String ) me.getKey();
 			JoinSequence join = ( JoinSequence ) me.getValue();
 			join.setSelector( new JoinSequence.Selector() {
 				public boolean includeSubclasses(String alias) {
-					boolean include = returnedTypes.contains( alias ) && !isShallowQuery();
-					return include;
+					return returnedTypes.contains( alias ) && !isShallowQuery();
 				}
 			} );
 
 			if ( typeMap.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 			else if ( collections.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
-			else {
-				//name from a super query (a bit inelegant that it shows up here)
-			}
-
 		}
 
 	}
 
 	public final Set<Serializable> getQuerySpaces() {
 		return querySpaces;
 	}
 
 	/**
 	 * Is this query called by scroll() or iterate()?
 	 *
 	 * @return true if it is, false if it is called by find() or list()
 	 */
 	boolean isShallowQuery() {
 		return shallowQuery;
 	}
 
 	void addQuerySpaces(Serializable[] spaces) {
 		Collections.addAll( querySpaces, spaces );
 		if ( superQuery != null ) superQuery.addQuerySpaces( spaces );
 	}
 
 	void setDistinct(boolean distinct) {
 		this.distinct = distinct;
 	}
 
 	boolean isSubquery() {
 		return superQuery != null;
 	}
 
 	/**
 	 * Overrides method from Loader
 	 */
 	@Override
     public CollectionPersister[] getCollectionPersisters() {
 		return collectionPersister == null ? null : new CollectionPersister[] { collectionPersister };
 	}
 
 	@Override
     protected String[] getCollectionSuffixes() {
 		return collectionPersister == null ? null : new String[] { "__" };
 	}
 
 	void setCollectionToFetch(String role, String name, String ownerName, String entityName)
 			throws QueryException {
 		fetchName = name;
 		collectionPersister = getCollectionPersister( role );
 		collectionOwnerName = ownerName;
 		if ( collectionPersister.getElementType().isEntityType() ) {
 			addEntityToFetch( entityName );
 		}
 	}
 
 	@Override
     protected String[] getSuffixes() {
 		return suffixes;
 	}
 
 	@Override
     protected String[] getAliases() {
 		return names;
 	}
 
 	/**
 	 * Used for collection filters
 	 */
 	private void addFromAssociation(final String elementName, final String collectionRole)
 			throws QueryException {
 		//q.addCollection(collectionName, collectionRole);
 		QueryableCollection persister = getCollectionPersister( collectionRole );
 		Type collectionElementType = persister.getElementType();
 		if ( !collectionElementType.isEntityType() ) {
 			throw new QueryException( "collection of values in filter: " + elementName );
 		}
 
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		//if (keyColumnNames.length!=1) throw new QueryException("composite-key collection in filter: " + collectionRole);
 
 		String collectionName;
 		JoinSequence join = new JoinSequence( getFactory() );
 		collectionName = persister.isOneToMany() ?
 				elementName :
 				createNameForCollection( collectionRole );
 		join.setRoot( persister, collectionName );
 		if ( !persister.isOneToMany() ) {
 			//many-to-many
 			addCollection( collectionName, collectionRole );
 			try {
 				join.addJoin( ( AssociationType ) persister.getElementType(),
 						elementName,
 						JoinType.INNER_JOIN,
 						persister.getElementColumnNames(collectionName) );
 			}
 			catch ( MappingException me ) {
 				throw new QueryException( me );
 			}
 		}
 		join.addCondition( collectionName, keyColumnNames, " = ?" );
 		//if ( persister.hasWhere() ) join.addCondition( persister.getSQLWhereString(collectionName) );
 		EntityType elemType = ( EntityType ) collectionElementType;
 		addFrom( elementName, elemType.getAssociatedEntityName(), join );
 
 	}
 
 	String getPathAlias(String path) {
 		return ( String ) pathAliases.get( path );
 	}
 
 	JoinSequence getPathJoin(String path) {
 		return ( JoinSequence ) pathJoins.get( path );
 	}
 
 	void addPathAliasAndJoin(String path, String alias, JoinSequence joinSequence) {
 		pathAliases.put( path, alias );
 		pathJoins.put( path, joinSequence );
 	}
 
 	@Override
 	public List list(SessionImplementor session, QueryParameters queryParameters)
 			throws HibernateException {
 		return list( session, queryParameters, getQuerySpaces(), actualReturnTypes );
 	}
 
 	/**
 	 * Return the query results as an iterator
 	 */
 	@Override
 	public Iterator iterate(QueryParameters queryParameters, EventSource session)
 			throws HibernateException {
 
 		boolean stats = session.getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
-		if ( stats ) startTime = System.nanoTime();
+		if ( stats ) {
+			startTime = System.nanoTime();
+		}
 
 		try {
 			final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
 			HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(holderConstructor, queryParameters.getResultTransformer());
 			Iterator result = new IteratorImpl( rs, st, session, queryParameters.isReadOnly( session ), returnTypes, getColumnNames(), hi );
 
 			if ( stats ) {
 				final long endTime = System.nanoTime();
 				final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 				session.getFactory().getStatisticsImplementor().queryExecuted(
 						"HQL: " + queryString,
 						0,
 						milliseconds
 					);
 			}
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using iterate",
 					getSQLString()
 				);
 		}
 
 	}
 
 	public int executeUpdate(QueryParameters queryParameters, SessionImplementor session) throws HibernateException {
 		throw new UnsupportedOperationException( "Not supported!  Use the AST translator...");
 	}
 
 	@Override
     protected boolean[] includeInResultRow() {
 		boolean[] isResultReturned = includeInSelect;
 		if ( hasScalars ) {
 			isResultReturned = new boolean[ returnedTypes.size() ];
 			Arrays.fill( isResultReturned, true );
 		}
 		return isResultReturned;
 	}
 
 
 	@Override
     protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return HolderInstantiator.resolveClassicResultTransformer(
 				holderConstructor,
 				resultTransformer
 		);
 	}
 
 	@Override
     protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow = getResultRow( row, rs, session );
 		return ( holderClass == null && resultRow.length == 1 ?
 				resultRow[ 0 ] :
 				resultRow
 		);
 	}
 
 	@Override
     protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow;
 		if ( hasScalars ) {
 			String[][] scalarColumns = getColumnNames();
 			int queryCols = returnTypes.length;
 			resultRow = new Object[queryCols];
 			for ( int i = 0; i < queryCols; i++ ) {
 				resultRow[i] = returnTypes[i].nullSafeGet( rs, scalarColumns[i], session, null );
 			}
 		}
 		else {
 			resultRow = toResultRow( row );
 		}
 		return resultRow;
 	}
 
 	@Override
     protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		if ( holderClass != null ) {
 			for ( int i = 0; i < results.size(); i++ ) {
 				Object[] row = ( Object[] ) results.get( i );
 				try {
 					results.set( i, holderConstructor.newInstance( row ) );
 				}
 				catch ( Exception e ) {
 					throw new QueryException( "could not instantiate: " + holderClass, e );
 				}
 			}
 		}
 		return results;
 	}
 
 	private Object[] toResultRow(Object[] row) {
 		if ( selectLength == row.length ) {
 			return row;
 		}
 		else {
 			Object[] result = new Object[selectLength];
 			int j = 0;
 			for ( int i = 0; i < row.length; i++ ) {
 				if ( includeInSelect[i] ) result[j++] = row[i];
 			}
 			return result;
 		}
 	}
 
 	void setHolderClass(Class clazz) {
 		holderClass = clazz;
 	}
 
 	@Override
     protected LockMode[] getLockModes(LockOptions lockOptions) {
 
 		// unfortunately this stuff can't be cached because
 		// it is per-invocation, not constant for the
 		// QueryTranslator instance
 		HashMap nameLockOptions = new HashMap();
 		if ( lockOptions == null) {
 			lockOptions = LockOptions.NONE;
 		}
 
 		if ( lockOptions.getAliasLockCount() > 0 ) {
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
 				Map.Entry me = ( Map.Entry ) iter.next();
 				nameLockOptions.put( getAliasName( ( String ) me.getKey() ),
 						me.getValue() );
 			}
 		}
 		LockMode[] lockModesArray = new LockMode[names.length];
 		for ( int i = 0; i < names.length; i++ ) {
 			LockMode lm = ( LockMode ) nameLockOptions.get( names[i] );
 			//if ( lm == null ) lm = LockOptions.NONE;
-			if ( lm == null ) lm = lockOptions.getLockMode();
+			if ( lm == null ) {
+				lm = lockOptions.getLockMode();
+			}
 			lockModesArray[i] = lm;
 		}
 		return lockModesArray;
 	}
 
 	@Override
     protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws QueryException {
 		// can't cache this stuff either (per-invocation)
 		final LockOptions lockOptions = parameters.getLockOptions();
 		final String result;
 		if ( lockOptions == null ||
 			( lockOptions.getLockMode() == LockMode.NONE && lockOptions.getAliasLockCount() == 0 ) ) {
 			return sql;
 		}
 		else {
 			LockOptions locks = new LockOptions();
 			locks.setLockMode(lockOptions.getLockMode());
 			locks.setTimeOut(lockOptions.getTimeOut());
 			locks.setScope(lockOptions.getScope());
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
 				Map.Entry me = ( Map.Entry ) iter.next();
 				locks.setAliasSpecificLockMode( getAliasName( ( String ) me.getKey() ), (LockMode) me.getValue() );
 			}
 			Map keyColumnNames = null;
 			if ( dialect.forUpdateOfColumns() ) {
 				keyColumnNames = new HashMap();
 				for ( int i = 0; i < names.length; i++ ) {
 					keyColumnNames.put( names[i], persisters[i].getIdentifierColumnNames() );
 				}
 			}
 			result = dialect.applyLocksToSql( sql, locks, keyColumnNames );
 		}
 		logQuery( queryString, result );
 		return result;
 	}
 
 	@Override
     protected boolean upgradeLocks() {
 		return true;
 	}
 
 	@Override
     protected int[] getCollectionOwners() {
 		return new int[] { collectionOwnerColumn };
 	}
 
 	protected boolean isCompiled() {
 		return compiled;
 	}
 
 	@Override
     public String toString() {
 		return queryString;
 	}
 
 	@Override
     protected int[] getOwners() {
 		return owners;
 	}
 
 	@Override
     protected EntityType[] getOwnerAssociationTypes() {
 		return ownerAssociationTypes;
 	}
 
 	public Class getHolderClass() {
 		return holderClass;
 	}
 
 	public Map getEnabledFilters() {
 		return enabledFilters;
 	}
 
-	public ScrollableResults scroll(final QueryParameters queryParameters,
-									final SessionImplementor session)
-			throws HibernateException {
+	public ScrollableResults scroll(
+			final QueryParameters queryParameters,
+			final SessionImplementor session) throws HibernateException {
 		HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(
-				holderConstructor, queryParameters.getResultTransformer()
+				holderConstructor,
+				queryParameters.getResultTransformer()
 		);
 		return scroll( queryParameters, returnTypes, hi, session );
 	}
 
 	@Override
     public String getQueryIdentifier() {
 		return queryIdentifier;
 	}
 
 	@Override
     protected boolean isSubselectLoadingEnabled() {
 		return hasSubselectLoadableCollections();
 	}
 
 	public void validateScrollability() throws HibernateException {
 		// This is the legacy behaviour for HQL queries...
 		if ( getCollectionPersisters() != null ) {
 			throw new HibernateException( "Cannot scroll queries which initialize collections" );
 		}
 	}
 
 	public boolean containsCollectionFetches() {
 		return false;
 	}
 
 	public boolean isManipulationStatement() {
 		// classic parser does not support bulk manipulation statements
 		return false;
 	}
 
 	@Override
 	public Class getDynamicInstantiationResultType() {
 		return holderClass;
 	}
 
 	public ParameterTranslations getParameterTranslations() {
 		return new ParameterTranslations() {
 
 			public boolean supportsOrdinalParameterMetadata() {
 				// classic translator does not support collection of ordinal
 				// param metadata
 				return false;
 			}
 
 			public int getOrdinalParameterCount() {
 				return 0; // not known!
 			}
 
 			public int getOrdinalParameterSqlLocation(int ordinalPosition) {
 				return 0; // not known!
 			}
 
 			public Type getOrdinalParameterExpectedType(int ordinalPosition) {
 				return null; // not known!
 			}
 
 			public Set getNamedParameterNames() {
 				return namedParameters.keySet();
 			}
 
 			public int[] getNamedParameterSqlLocations(String name) {
 				return getNamedParameterLocs( name );
 			}
 
 			public Type getNamedParameterExpectedType(String name) {
 				return null; // not known!
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
index b475830709..bc8ad8a880 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/SelectParser.java
@@ -1,256 +1,263 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Locale;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.internal.QuerySplitter;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * Parsers the select clause of a Hibernate query.
  *
  * @author Gavin King, David Channon
  */
 public class SelectParser implements Parser {
 
 	//TODO: arithmetic expressions, multiple new Foo(...)
 
-	private static final Set COUNT_MODIFIERS = new HashSet();
+	private static final Set<String> COUNT_MODIFIERS = new HashSet<String>();
 
 	static {
 		COUNT_MODIFIERS.add( "distinct" );
 		COUNT_MODIFIERS.add( "all" );
 		COUNT_MODIFIERS.add( "*" );
 	}
 
-	private LinkedList aggregateFuncTokenList = new LinkedList();
+	private LinkedList<String> aggregateFuncTokenList = new LinkedList<String>();
 
 	private boolean ready;
 	private boolean aggregate;
 	private boolean first;
 	private boolean afterNew;
 	private boolean insideNew;
 	private boolean aggregateAddSelectScalar;
 	private Class holderClass;
 
 	private final SelectPathExpressionParser pathExpressionParser;
 	private final PathExpressionParser aggregatePathExpressionParser;
 
 	{
 		pathExpressionParser = new SelectPathExpressionParser();
 		aggregatePathExpressionParser = new PathExpressionParser();
 		//TODO: would be nice to use false, but issues with MS SQL
 		pathExpressionParser.setUseThetaStyleJoin( true );
 		aggregatePathExpressionParser.setUseThetaStyleJoin( true );
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
-
 		String lctoken = token.toLowerCase(Locale.ROOT);
 
 		if ( first ) {
 			first = false;
 			if ( "distinct".equals( lctoken ) ) {
 				q.setDistinct( true );
 				return;
 			}
 			else if ( "all".equals( lctoken ) ) {
 				q.setDistinct( false );
 				return;
 			}
 		}
 
 		if ( afterNew ) {
 			afterNew = false;
 			try {
 				holderClass = ReflectHelper.classForName( QuerySplitter.getImportedClass( token, q.getFactory() ) );
 			}
 			catch ( ClassNotFoundException cnfe ) {
 				throw new QueryException( cnfe );
 			}
-			if ( holderClass == null ) throw new QueryException( "class not found: " + token );
+			if ( holderClass == null ) {
+				throw new QueryException( "class not found: " + token );
+			}
 			q.setHolderClass( holderClass );
 			insideNew = true;
 		}
 		else if ( token.equals( "," ) ) {
-			if ( !aggregate && ready ) throw new QueryException( "alias or expression expected in SELECT" );
+			if ( !aggregate && ready ) {
+				throw new QueryException( "alias or expression expected in SELECT" );
+			}
 			q.appendScalarSelectToken( ", " );
 			ready = true;
 		}
 		else if ( "new".equals( lctoken ) ) {
 			afterNew = true;
 			ready = false;
 		}
 		else if ( "(".equals( token ) ) {
 			if ( insideNew && !aggregate && !ready ) {
 				//opening paren in new Foo ( ... )
 				ready = true;
 			}
 			else if ( aggregate ) {
 				q.appendScalarSelectToken( token );
 			}
 			else {
 				throw new QueryException( "aggregate function expected before ( in SELECT" );
 			}
 			ready = true;
 		}
 		else if ( ")".equals( token ) ) {
 			if ( insideNew && !aggregate && !ready ) {
 				//if we are inside a new Result(), but not inside a nested function
 				insideNew = false;
 			}
 			else if ( aggregate && ready ) {
 				q.appendScalarSelectToken( token );
 				aggregateFuncTokenList.removeLast();
 				if ( aggregateFuncTokenList.size() < 1 ) {
 					aggregate = false;
 					ready = false;
 				}
 			}
 			else {
 				throw new QueryException( "( expected before ) in select" );
 			}
 		}
 		else if ( COUNT_MODIFIERS.contains( lctoken ) ) {
 			if ( !ready || !aggregate ) {
 				throw new QueryException( token + " only allowed inside aggregate function in SELECT" );
 			}
 			q.appendScalarSelectToken( token );
 			if ( "*".equals( token ) ) {
 				// special case
 				q.addSelectScalar( getFunction( "count", q ).getReturnType( StandardBasicTypes.LONG, q.getFactory() ) );
 			}
 		}
 		else if ( getFunction( lctoken, q ) != null && token.equals( q.unalias( token ) ) ) {
 			// the name of an SQL function
 			if ( !ready ) throw new QueryException( ", expected before aggregate function in SELECT: " + token );
 			aggregate = true;
 			aggregateAddSelectScalar = true;
 			aggregateFuncTokenList.add( lctoken );
 			ready = false;
 			q.appendScalarSelectToken( token );
 			if ( !aggregateHasArgs( lctoken, q ) ) {
 				q.addSelectScalar( aggregateType( aggregateFuncTokenList, null, q ) );
 				if ( !aggregateFuncNoArgsHasParenthesis( lctoken, q ) ) {
 					aggregateFuncTokenList.removeLast();
 					if ( aggregateFuncTokenList.size() < 1 ) {
 						aggregate = false;
 						ready = false;
 					}
 					else {
 						ready = true;
 					}
 				}
 			}
 		}
 		else if ( aggregate ) {
 			boolean constantToken = false;
-			if ( !ready ) throw new QueryException( "( expected after aggregate function in SELECT" );
+			if ( !ready ) {
+				throw new QueryException( "( expected after aggregate function in SELECT" );
+			}
 			try {
 				ParserHelper.parse( aggregatePathExpressionParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 			}
 			catch ( QueryException qex ) {
 				constantToken = true;
 			}
 
 			if ( constantToken ) {
 				q.appendScalarSelectToken( token );
 			}
 			else {
 				if ( aggregatePathExpressionParser.isCollectionValued() ) {
 					q.addCollection( aggregatePathExpressionParser.getCollectionName(),
 							aggregatePathExpressionParser.getCollectionRole() );
 				}
 				q.appendScalarSelectToken( aggregatePathExpressionParser.getWhereColumn() );
 				if ( aggregateAddSelectScalar ) {
 					q.addSelectScalar( aggregateType( aggregateFuncTokenList, aggregatePathExpressionParser.getWhereColumnType(), q ) );
 					aggregateAddSelectScalar = false;
 				}
 				aggregatePathExpressionParser.addAssociation( q );
 			}
 		}
 		else {
-			if ( !ready ) throw new QueryException( ", expected in SELECT" );
+			if ( !ready ) {
+				throw new QueryException( ", expected in SELECT" );
+			}
 			ParserHelper.parse( pathExpressionParser, q.unalias( token ), ParserHelper.PATH_SEPARATORS, q );
 			if ( pathExpressionParser.isCollectionValued() ) {
 				q.addCollection( pathExpressionParser.getCollectionName(),
 						pathExpressionParser.getCollectionRole() );
 			}
 			else if ( pathExpressionParser.getWhereColumnType().isEntityType() ) {
 				q.addSelectClass( pathExpressionParser.getSelectName() );
 			}
 			q.appendScalarSelectTokens( pathExpressionParser.getWhereColumns() );
 			q.addSelectScalar( pathExpressionParser.getWhereColumnType() );
 			pathExpressionParser.addAssociation( q );
 
 			ready = false;
 		}
 	}
 
 	public boolean aggregateHasArgs(String funcToken, QueryTranslatorImpl q) {
 		return getFunction( funcToken, q ).hasArguments();
 	}
 
 	public boolean aggregateFuncNoArgsHasParenthesis(String funcToken, QueryTranslatorImpl q) {
 		return getFunction( funcToken, q ).hasParenthesesIfNoArguments();
 	}
 
 	public Type aggregateType(List funcTokenList, Type type, QueryTranslatorImpl q) throws QueryException {
 		Type retType = type;
 		Type argType;
 		for ( int i = funcTokenList.size() - 1; i >= 0; i-- ) {
 			argType = retType;
 			String funcToken = ( String ) funcTokenList.get( i );
 			retType = getFunction( funcToken, q ).getReturnType( argType, q.getFactory() );
 		}
 		return retType;
 	}
 
 	private SQLFunction getFunction(String name, QueryTranslatorImpl q) {
 		return q.getFactory().getSqlFunctionRegistry().findSQLFunction( name );
 	}
 
 	public void start(QueryTranslatorImpl q) {
 		ready = true;
 		first = true;
 		aggregate = false;
 		afterNew = false;
 		insideNew = false;
 		holderClass = null;
 		aggregateFuncTokenList.clear();
 	}
 
 	public void end(QueryTranslatorImpl q) {
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
index 16c90faf79..3c7d56ae49 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
@@ -1,516 +1,530 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPropertyNames;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.InFragment;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.LiteralType;
 import org.hibernate.type.Type;
 
 /**
  * Parses the where clause of a hibernate query and translates it to an
  * SQL where clause.
  */
 
 // We should reengineer this class so that, rather than the current ad -
 // hoc linear approach to processing a stream of tokens, we instead
 // build up a tree of expressions.
 
 // We would probably refactor to have LogicParser (builds a tree of simple
 // expressions connected by and, or, not), ExpressionParser (translates
 // from OO terms like foo, foo.Bar, foo.Bar.Baz to SQL terms like
 // FOOS.ID, FOOS.BAR_ID, etc) and PathExpressionParser (which does much
 // the same thing it does now)
 
 public class WhereParser implements Parser {
 
 	private final PathExpressionParser pathExpressionParser;
 
 	{
 		pathExpressionParser = new PathExpressionParser();
 		pathExpressionParser.setUseThetaStyleJoin( true ); //Need this, since join condition can appear inside parens!
 	}
 
-	private static final Set EXPRESSION_TERMINATORS = new HashSet();   //tokens that close a sub expression
-	private static final Set EXPRESSION_OPENERS = new HashSet();       //tokens that open a sub expression
-	private static final Set BOOLEAN_OPERATORS = new HashSet();        //tokens that would indicate a sub expression is a boolean expression
-	private static final Map NEGATIONS = new HashMap();
+	private static final Set<String> EXPRESSION_TERMINATORS = new HashSet<String>();   //tokens that close a sub expression
+	private static final Set<String> EXPRESSION_OPENERS = new HashSet<String>();       //tokens that open a sub expression
+	private static final Set<String> BOOLEAN_OPERATORS = new HashSet<String>();        //tokens that would indicate a sub expression is a boolean expression
+	private static final Map<String,String> NEGATIONS = new HashMap<String,String>();
 
 	static {
 		EXPRESSION_TERMINATORS.add( "and" );
 		EXPRESSION_TERMINATORS.add( "or" );
 		EXPRESSION_TERMINATORS.add( ")" );
 		//expressionTerminators.add(","); // deliberately excluded
 
 		EXPRESSION_OPENERS.add( "and" );
 		EXPRESSION_OPENERS.add( "or" );
 		EXPRESSION_OPENERS.add( "(" );
 		//expressionOpeners.add(","); // deliberately excluded
 
 		BOOLEAN_OPERATORS.add( "<" );
 		BOOLEAN_OPERATORS.add( "=" );
 		BOOLEAN_OPERATORS.add( ">" );
 		BOOLEAN_OPERATORS.add( "#" );
 		BOOLEAN_OPERATORS.add( "~" );
 		BOOLEAN_OPERATORS.add( "like" );
 		BOOLEAN_OPERATORS.add( "ilike" );
 		BOOLEAN_OPERATORS.add( "regexp" );
 		BOOLEAN_OPERATORS.add( "rlike" );
 		BOOLEAN_OPERATORS.add( "is" );
 		BOOLEAN_OPERATORS.add( "in" );
 		BOOLEAN_OPERATORS.add( "any" );
 		BOOLEAN_OPERATORS.add( "some" );
 		BOOLEAN_OPERATORS.add( "all" );
 		BOOLEAN_OPERATORS.add( "exists" );
 		BOOLEAN_OPERATORS.add( "between" );
 		BOOLEAN_OPERATORS.add( "<=" );
 		BOOLEAN_OPERATORS.add( ">=" );
 		BOOLEAN_OPERATORS.add( "=>" );
 		BOOLEAN_OPERATORS.add( "=<" );
 		BOOLEAN_OPERATORS.add( "!=" );
 		BOOLEAN_OPERATORS.add( "<>" );
 		BOOLEAN_OPERATORS.add( "!#" );
 		BOOLEAN_OPERATORS.add( "!~" );
 		BOOLEAN_OPERATORS.add( "!<" );
 		BOOLEAN_OPERATORS.add( "!>" );
 		BOOLEAN_OPERATORS.add( "is not" );
 		BOOLEAN_OPERATORS.add( "not like" );
 		BOOLEAN_OPERATORS.add( "not ilike" );
 		BOOLEAN_OPERATORS.add( "not regexp" );
 		BOOLEAN_OPERATORS.add( "not rlike" );
 		BOOLEAN_OPERATORS.add( "not in" );
 		BOOLEAN_OPERATORS.add( "not between" );
 		BOOLEAN_OPERATORS.add( "not exists" );
 
 		NEGATIONS.put( "and", "or" );
 		NEGATIONS.put( "or", "and" );
 		NEGATIONS.put( "<", ">=" );
 		NEGATIONS.put( "=", "<>" );
 		NEGATIONS.put( ">", "<=" );
 		NEGATIONS.put( "#", "!#" );
 		NEGATIONS.put( "~", "!~" );
 		NEGATIONS.put( "like", "not like" );
 		NEGATIONS.put( "ilike", "not ilike" );
 		NEGATIONS.put( "regexp", "not regexp" );
 		NEGATIONS.put( "rlike", "not rlike" );
 		NEGATIONS.put( "is", "is not" );
 		NEGATIONS.put( "in", "not in" );
 		NEGATIONS.put( "exists", "not exists" );
 		NEGATIONS.put( "between", "not between" );
 		NEGATIONS.put( "<=", ">" );
 		NEGATIONS.put( ">=", "<" );
 		NEGATIONS.put( "=>", "<" );
 		NEGATIONS.put( "=<", ">" );
 		NEGATIONS.put( "!=", "=" );
 		NEGATIONS.put( "<>", "=" );
 		NEGATIONS.put( "!#", "#" );
 		NEGATIONS.put( "!~", "~" );
 		NEGATIONS.put( "!<", "<" );
 		NEGATIONS.put( "!>", ">" );
 		NEGATIONS.put( "is not", "is" );
 		NEGATIONS.put( "not like", "like" );
 		NEGATIONS.put( "not ilike", "ilike" );
 		NEGATIONS.put( "not regexp", "regexp" );
 		NEGATIONS.put( "not rlike", "rlike" );
 		NEGATIONS.put( "not in", "in" );
 		NEGATIONS.put( "not between", "between" );
 		NEGATIONS.put( "not exists", "exists" );
 
 	}
 	// Handles things like:
 	// a and b or c
 	// a and ( b or c )
 	// not a and not b
 	// not ( a and b )
 	// x between y and z            (overloaded "and")
 	// x in ( a, b, c )             (overloaded brackets)
 	// not not a
 	// a is not null                (overloaded "not")
 	// etc......
 	// and expressions like
 	// foo = bar                    (maps to: foo.id = bar.id)
 	// foo.Bar = 'foo'              (maps to: foo.bar = 'foo')
 	// foo.Bar.Baz = 1.0            (maps to: foo.bar = bar.id and bar.baz = 1.0)
 	// 1.0 = foo.Bar.Baz            (maps to: bar.baz = 1.0 and foo.Bar = bar.id)
 	// foo.Bar.Baz = a.B.C          (maps to: bar.Baz = b.C and foo.Bar = bar.id and a.B = b.id)
 	// foo.Bar.Baz + a.B.C          (maps to: bar.Baz + b.C and foo.Bar = bar.id and a.B = b.id)
 	// ( foo.Bar.Baz + 1.0 ) < 2.0  (maps to: ( bar.Baz + 1.0 ) < 2.0 and foo.Bar = bar.id)
 
 	private boolean betweenSpecialCase;       //Inside a BETWEEN ... AND ... expression
 	private boolean negated;
 
 	private boolean inSubselect;
 	private int bracketsSinceSelect;
 	private StringBuilder subselect;
 
 	private boolean expectingPathContinuation;
 	private int expectingIndex;
 
 	// The following variables are stacks that keep information about each subexpression
 	// in the list of nested subexpressions we are currently processing.
 
 	private LinkedList<Boolean> nots = new LinkedList<Boolean>();           //were an odd or even number of NOTs encountered
-	private LinkedList joins = new LinkedList();          //the join string built up by compound paths inside this expression
+	private LinkedList<StringBuilder> joins = new LinkedList<StringBuilder>();          //the join string built up by compound paths inside this expression
 	private LinkedList<Boolean> booleanTests = new LinkedList<Boolean>();   //a flag indicating if the subexpression is known to be boolean
 
 	private String getElementName(PathExpressionParser.CollectionElement element, QueryTranslatorImpl q) throws QueryException {
 		String name;
 		if ( element.isOneToMany ) {
 			name = element.alias;
 		}
 		else {
 			Type type = element.elementType;
 			if ( type.isEntityType() ) { //ie. a many-to-many
 				String entityName = ( ( EntityType ) type ).getAssociatedEntityName();
 				name = pathExpressionParser.continueFromManyToMany( entityName, element.elementColumns, q );
 			}
 			else {
 				throw new QueryException( "illegally dereferenced collection element" );
 			}
 		}
 		return name;
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
-
 		String lcToken = token.toLowerCase(Locale.ROOT);
 
 		//Cope with [,]
 		if ( token.equals( "[" ) && !expectingPathContinuation ) {
 			expectingPathContinuation = false;
-			if ( expectingIndex == 0 ) throw new QueryException( "unexpected [" );
+			if ( expectingIndex == 0 ) {
+				throw new QueryException( "unexpected [" );
+			}
 			return;
 		}
 		else if ( token.equals( "]" ) ) {
 			expectingIndex--;
 			expectingPathContinuation = true;
 			return;
 		}
 
 		//Cope with a continued path expression (ie. ].baz)
 		if ( expectingPathContinuation ) {
 			boolean pathExpressionContinuesFurther = continuePathExpression( token, q );
-			if ( pathExpressionContinuesFurther ) return; //NOTE: early return
+			if ( pathExpressionContinuesFurther ) {
+				return; //NOTE: early return
+			}
 		}
 
 		//Cope with a subselect
 		if ( !inSubselect && ( lcToken.equals( "select" ) || lcToken.equals( "from" ) ) ) {
 			inSubselect = true;
 			subselect = new StringBuilder( 20 );
 		}
 		if ( inSubselect && token.equals( ")" ) ) {
 			bracketsSinceSelect--;
 
 			if ( bracketsSinceSelect == -1 ) {
 				QueryTranslatorImpl subq = new QueryTranslatorImpl(
 				        subselect.toString(),
 						q.getEnabledFilters(),
 						q.getFactory()
 				);
 				try {
 					subq.compile( q );
 				}
 				catch ( MappingException me ) {
 					throw new QueryException( "MappingException occurred compiling subquery", me );
 				}
 				appendToken( q, subq.getSQLString() );
 				inSubselect = false;
 				bracketsSinceSelect = 0;
 			}
 		}
 		if ( inSubselect ) {
-			if ( token.equals( "(" ) ) bracketsSinceSelect++;
+			if ( token.equals( "(" ) ) {
+				bracketsSinceSelect++;
+			}
 			subselect.append( token ).append( ' ' );
 			return;
 		}
 
 		//Cope with special cases of AND, NOT, ()
 		specialCasesBefore( lcToken );
 
 		//Close extra brackets we opened
 		if ( !betweenSpecialCase && EXPRESSION_TERMINATORS.contains( lcToken ) ) {
 			closeExpression( q, lcToken );
 		}
 
 		//take note when this is a boolean expression
 		if ( BOOLEAN_OPERATORS.contains( lcToken ) ) {
 			booleanTests.removeLast();
 			booleanTests.addLast( Boolean.TRUE );
 		}
 
 		if ( lcToken.equals( "not" ) ) {
 			nots.addLast(  !(  nots.removeLast() ) );
 			negated = !negated;
 			return; //NOTE: early return
 		}
 
 		//process a token, mapping OO path expressions to SQL expressions
 		doToken( token, q );
 
 		//Open any extra brackets we might need.
 		if ( !betweenSpecialCase && EXPRESSION_OPENERS.contains( lcToken ) ) {
 			openExpression( q, lcToken );
 		}
 
 		//Cope with special cases of AND, NOT, )
 		specialCasesAfter( lcToken );
 
 	}
 
 	public void start(QueryTranslatorImpl q) throws QueryException {
 		token( "(", q );
 	}
 
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		if ( expectingPathContinuation ) {
 			expectingPathContinuation = false;
 			PathExpressionParser.CollectionElement element = pathExpressionParser.lastCollectionElement();
-			if ( element.elementColumns.length != 1 ) throw new QueryException( "path expression ended in composite collection element" );
+			if ( element.elementColumns.length != 1 ) {
+				throw new QueryException( "path expression ended in composite collection element" );
+			}
 			appendToken( q, element.elementColumns[0] );
 			addToCurrentJoin( element );
 		}
 		token( ")", q );
 	}
 
 	private void closeExpression(QueryTranslatorImpl q, String lcToken) {
 		if ( booleanTests.removeLast() ) { //it was a boolean expression
 
 			if ( booleanTests.size() > 0 ) {
 				// the next one up must also be
 				booleanTests.removeLast();
 				booleanTests.addLast( Boolean.TRUE );
 			}
 
 			// Add any joins
 			appendToken( q, ( joins.removeLast() ).toString() );
 
 		}
 		else {
-			StringBuilder join = ( StringBuilder ) joins.removeLast();
-			( ( StringBuilder ) joins.getLast() ).append( join.toString() );
+			StringBuilder join = joins.removeLast();
+			joins.getLast().append( join.toString() );
 		}
 
-		if ( nots.removeLast() ) negated = !negated;
+		if ( nots.removeLast() ) {
+			negated = !negated;
+		}
 
-		if ( !")".equals( lcToken ) ) appendToken( q, ")" );
+		if ( !")".equals( lcToken ) ) {
+			appendToken( q, ")" );
+		}
 	}
 
 	private void openExpression(QueryTranslatorImpl q, String lcToken) {
 		nots.addLast( Boolean.FALSE );
 		booleanTests.addLast( Boolean.FALSE );
 		joins.addLast( new StringBuilder() );
-		if ( !"(".equals( lcToken ) ) appendToken( q, "(" );
+		if ( !"(".equals( lcToken ) ) {
+			appendToken( q, "(" );
+		}
 	}
 
 	private void preprocess(String token, QueryTranslatorImpl q) throws QueryException {
 		// ugly hack for cases like "elements(foo.bar.collection)"
 		// (multi-part path expression ending in elements or indices)
 		String[] tokens = StringHelper.split( ".", token, true );
 		if (
 				tokens.length > 5 &&
 				( CollectionPropertyNames.COLLECTION_ELEMENTS.equals( tokens[tokens.length - 1] )
 				|| CollectionPropertyNames.COLLECTION_INDICES.equals( tokens[tokens.length - 1] ) )
 		) {
 			pathExpressionParser.start( q );
 			for ( int i = 0; i < tokens.length - 3; i++ ) {
 				pathExpressionParser.token( tokens[i], q );
 			}
 			pathExpressionParser.token( null, q );
 			pathExpressionParser.end( q );
 			addJoin( pathExpressionParser.getWhereJoin(), q );
 			pathExpressionParser.ignoreInitialJoin();
 		}
 	}
 
 	private void doPathExpression(String token, QueryTranslatorImpl q) throws QueryException {
 
 		preprocess( token, q );
 
 		StringTokenizer tokens = new StringTokenizer( token, ".", true );
 		pathExpressionParser.start( q );
 		while ( tokens.hasMoreTokens() ) {
 			pathExpressionParser.token( tokens.nextToken(), q );
 		}
 		pathExpressionParser.end( q );
 		if ( pathExpressionParser.isCollectionValued() ) {
 			openExpression( q, "" );
 			appendToken( q, pathExpressionParser.getCollectionSubquery( q.getEnabledFilters() ) );
 			closeExpression( q, "" );
 			// this is ugly here, but needed because its a subquery
 			q.addQuerySpaces( q.getCollectionPersister( pathExpressionParser.getCollectionRole() ).getCollectionSpaces() );
 		}
 		else {
 			if ( pathExpressionParser.isExpectingCollectionIndex() ) {
 				expectingIndex++;
 			}
 			else {
 				addJoin( pathExpressionParser.getWhereJoin(), q );
 				appendToken( q, pathExpressionParser.getWhereColumn() );
 			}
 		}
 	}
 
 	private void addJoin(JoinSequence joinSequence, QueryTranslatorImpl q) throws QueryException {
 		//JoinFragment fromClause = q.createJoinFragment(true);
 		//fromClause.addJoins( join.toJoinFragment().toFromFragmentString(), StringHelper.EMPTY_STRING );
 		q.addFromJoinOnly( pathExpressionParser.getName(), joinSequence );
 		try {
 			addToCurrentJoin( joinSequence.toJoinFragment( q.getEnabledFilters(), true ).toWhereFragmentString() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void doToken(String token, QueryTranslatorImpl q) throws QueryException {
 		if ( q.isName( StringHelper.root( token ) ) ) { //path expression
 			doPathExpression( q.unalias( token ), q );
 		}
 		else if ( token.startsWith( ParserHelper.HQL_VARIABLE_PREFIX ) ) { //named query parameter
 			q.addNamedParameter( token.substring( 1 ) );
 			appendToken( q, "?" );
 		}
 		else {
 			Queryable persister = q.getEntityPersisterUsingImports( token );
 			if ( persister != null ) { // the name of a class
 				final String discrim = persister.getDiscriminatorSQLValue();
 				if ( InFragment.NULL.equals(discrim) || InFragment.NOT_NULL.equals(discrim) ) {
 					throw new QueryException( "subclass test not allowed for null or not null discriminator" );
 				}
 				else {
 					appendToken( q, discrim );
 				}
 			}
 			else {
 				Object constant;
 				if (
 						token.indexOf( '.' ) > -1 &&
 						( constant = ReflectHelper.getConstantValue( token ) ) != null
 				) {
 					Type type;
 					try {
 						type = q.getFactory().getTypeResolver().heuristicType( constant.getClass().getName() );
 					}
 					catch ( MappingException me ) {
 						throw new QueryException( me );
 					}
 					if ( type == null ) throw new QueryException( QueryTranslator.ERROR_CANNOT_DETERMINE_TYPE + token );
 					try {
+						//noinspection unchecked
 						appendToken( q, ( ( LiteralType ) type ).objectToSQLString( constant, q.getFactory().getDialect() ) );
 					}
 					catch ( Exception e ) {
 						throw new QueryException( QueryTranslator.ERROR_CANNOT_FORMAT_LITERAL + token, e );
 					}
 				}
 				else { //anything else
 
-					String negatedToken = negated ? ( String ) NEGATIONS.get( token.toLowerCase(Locale.ROOT) ) : null;
+					String negatedToken = negated ? NEGATIONS.get( token.toLowerCase(Locale.ROOT) ) : null;
 					if ( negatedToken != null && ( !betweenSpecialCase || !"or".equals( negatedToken ) ) ) {
 						appendToken( q, negatedToken );
 					}
 					else {
 						appendToken( q, token );
 					}
 				}
 			}
 		}
 	}
 
 	private void addToCurrentJoin(String sql) {
-		( ( StringBuilder ) joins.getLast() ).append( sql );
+		joins.getLast().append( sql );
 	}
 
 	private void addToCurrentJoin(PathExpressionParser.CollectionElement ce)
 			throws QueryException {
 		try {
 			addToCurrentJoin( ce.joinSequence.toJoinFragment().toWhereFragmentString() + ce.indexValue.toString() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void specialCasesBefore(String lcToken) {
 		if ( lcToken.equals( "between" ) || lcToken.equals( "not between" ) ) {
 			betweenSpecialCase = true;
 		}
 	}
 
 	private void specialCasesAfter(String lcToken) {
 		if ( betweenSpecialCase && lcToken.equals( "and" ) ) {
 			betweenSpecialCase = false;
 		}
 	}
 
 	void appendToken(QueryTranslatorImpl q, String token) {
 		if ( expectingIndex > 0 ) {
 			pathExpressionParser.setLastCollectionElementIndexValue( token );
 		}
 		else {
 			q.appendWhereToken( token );
 		}
 	}
 
 	private boolean continuePathExpression(String token, QueryTranslatorImpl q) throws QueryException {
 
 		expectingPathContinuation = false;
 
 		PathExpressionParser.CollectionElement element = pathExpressionParser.lastCollectionElement();
 
 		if ( token.startsWith( "." ) ) { // the path expression continues after a ]
 
 			doPathExpression( getElementName( element, q ) + token, q ); // careful with this!
 
 			addToCurrentJoin( element );
 			return true; //NOTE: EARLY EXIT!
 
 		}
 
 		else { // the path expression ends at the ]
 			if ( element.elementColumns.length != 1 ) {
 				throw new QueryException( "path expression ended in composite collection element" );
 			}
 			appendToken( q, element.elementColumns[0] );
 			addToCurrentJoin( element );
 			return false;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/AbstractUUIDGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/AbstractUUIDGenerator.java
index 129871daea..ac77e8d3c2 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/AbstractUUIDGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/AbstractUUIDGenerator.java
@@ -1,100 +1,102 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.id;
+
 import java.net.InetAddress;
 
 import org.hibernate.internal.util.BytesHelper;
 
 /**
  * The base class for identifier generators that use a UUID algorithm. This
  * class implements the algorithm, subclasses define the identifier
  * format.
  *
  * @see UUIDHexGenerator
  * @author Gavin King
  */
-
 public abstract class AbstractUUIDGenerator implements IdentifierGenerator {
 
 	private static final int IP;
 	static {
 		int ipadd;
 		try {
 			ipadd = BytesHelper.toInt( InetAddress.getLocalHost().getAddress() );
 		}
 		catch (Exception e) {
 			ipadd = 0;
 		}
 		IP = ipadd;
 	}
+
 	private static short counter = (short) 0;
 	private static final int JVM = (int) ( System.currentTimeMillis() >>> 8 );
 
 	public AbstractUUIDGenerator() {
 	}
 
 	/**
 	 * Unique across JVMs on this machine (unless they load this class
 	 * in the same quater second - very unlikely)
 	 */
 	protected int getJVM() {
 		return JVM;
 	}
 
 	/**
 	 * Unique in a millisecond for this JVM instance (unless there
 	 * are > Short.MAX_VALUE instances created in a millisecond)
 	 */
 	protected short getCount() {
 		synchronized(AbstractUUIDGenerator.class) {
-			if (counter<0) counter=0;
+			if ( counter < 0 ) {
+				counter=0;
+			}
 			return counter++;
 		}
 	}
 
 	/**
 	 * Unique in a local network
 	 */
 	protected int getIP() {
 		return IP;
 	}
 
 	/**
 	 * Unique down to millisecond
 	 */
 	protected short getHiTime() {
 		return (short) ( System.currentTimeMillis() >>> 32 );
 	}
+
 	protected int getLoTime() {
 		return (int) System.currentTimeMillis();
 	}
 
-
 }
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
index d3e78c0b76..f1683e2200 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
@@ -1,155 +1,157 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * <b>increment</b><br>
  * <br>
  * An <tt>IdentifierGenerator</tt> that returns a <tt>long</tt>, constructed by
  * counting from the maximum primary key value at startup. Not safe for use in a
  * cluster!<br>
  * <br>
  * Mapping parameters supported, but not usually needed: tables, column.
  * (The tables parameter specified a comma-separated list of table names.)
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public class IncrementGenerator implements IdentifierGenerator, Configurable {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, IncrementGenerator.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( IncrementGenerator.class );
 
 	private Class returnClass;
 	private String sql;
 
 	private IntegralDataTypeHolder previousValueHolder;
 
 	public synchronized Serializable generate(SessionImplementor session, Object object) throws HibernateException {
 		if ( sql != null ) {
 			initializePreviousValueHolder( session );
 		}
 		return previousValueHolder.makeValueThenIncrement();
 	}
 
 	@Override
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		returnClass = type.getReturnedClass();
 
 		ObjectNameNormalizer normalizer =
 				( ObjectNameNormalizer ) params.get( PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER );
 
 		String column = params.getProperty( "column" );
 		if ( column == null ) {
 			column = params.getProperty( PersistentIdentifierGenerator.PK );
 		}
 		column = normalizer.normalizeIdentifierQuoting( column ).render( jdbcEnv.getDialect() );
 
 		String tableList = params.getProperty( "tables" );
 		if ( tableList == null ) {
 			tableList = params.getProperty( PersistentIdentifierGenerator.TABLES );
 		}
 		String[] tables = StringHelper.split( ", ", tableList );
 
 		final String schema = normalizer.toDatabaseIdentifierText(
 				params.getProperty( PersistentIdentifierGenerator.SCHEMA )
 		);
 		final String catalog = normalizer.toDatabaseIdentifierText(
 				params.getProperty( PersistentIdentifierGenerator.CATALOG )
 		);
 
 		StringBuilder buf = new StringBuilder();
 		for ( int i=0; i < tables.length; i++ ) {
 			final String tableName = normalizer.toDatabaseIdentifierText( tables[i] );
 			if ( tables.length > 1 ) {
 				buf.append( "select max(" ).append( column ).append( ") as mx from " );
 			}
 			buf.append( Table.qualify( catalog, schema, tableName ) );
 			if ( i < tables.length-1 ) {
 				buf.append( " union " );
 			}
 		}
 		if ( tables.length > 1 ) {
 			buf.insert( 0, "( " ).append( " ) ids_" );
 			column = "ids_.mx";
 		}
 
 		sql = "select max(" + column + ") from " + buf.toString();
 	}
 
 	private void initializePreviousValueHolder(SessionImplementor session) {
 		previousValueHolder = IdentifierGeneratorHelper.getIntegralDataTypeHolder( returnClass );
 
 		final boolean debugEnabled = LOG.isDebugEnabled();
 		if ( debugEnabled ) {
 			LOG.debugf( "Fetching initial value: %s", sql );
 		}
 		try {
 			PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
-                    if (rs.next()) previousValueHolder.initialize(rs, 0L).increment();
-                    else previousValueHolder.initialize(1L);
+                    if (rs.next()) {
+						previousValueHolder.initialize(rs, 0L).increment();
+					}
+                    else {
+						previousValueHolder.initialize(1L);
+					}
 					sql = null;
 					if ( debugEnabled ) {
 						LOG.debugf( "First free id: %s", previousValueHolder.makeValue() );
 					}
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not fetch initial value for increment generator",
 					sql
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/AbstractQueryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/AbstractQueryImpl.java
index 2b8b29bb24..6f7265b282 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/AbstractQueryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/AbstractQueryImpl.java
@@ -1,1045 +1,1047 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Calendar;
 import java.util.Collection;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.NonUniqueResultException;
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.Session;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.hql.internal.classic.ParserHelper;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.property.Getter;
 import org.hibernate.proxy.HibernateProxyHelper;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.SerializableType;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Abstract implementation of the Query interface.
  *
  * @author Gavin King
  * @author Max Andersen
  */
 public abstract class AbstractQueryImpl implements Query {
 	private static final CoreMessageLogger log = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			AbstractQueryImpl.class.getName()
 	);
 
 	private static final Object UNSET_PARAMETER = new MarkerObject("<unset parameter>");
 	private static final Object UNSET_TYPE = new MarkerObject("<unset type>");
 
 	private final String queryString;
 	protected final SessionImplementor session;
 	protected final ParameterMetadata parameterMetadata;
 
 	// parameter bind values...
 	private List values = new ArrayList(4);
 	private List types = new ArrayList(4);
 	private Map<String,TypedValue> namedParameters = new HashMap<String, TypedValue>(4);
 	private Map<String, TypedValue> namedParameterLists = new HashMap<String, TypedValue>(4);
 
 	private Object optionalObject;
 	private Serializable optionalId;
 	private String optionalEntityName;
 
 	private RowSelection selection;
 	private boolean cacheable;
 	private String cacheRegion;
 	private String comment;
 	private final List<String> queryHints = new ArrayList<String>();
 	private FlushMode flushMode;
 	private CacheMode cacheMode;
 	private FlushMode sessionFlushMode;
 	private CacheMode sessionCacheMode;
 	private Serializable collectionKey;
 	private Boolean readOnly;
 	private ResultTransformer resultTransformer;
 	
 	private HQLQueryPlan queryPlan;
 
 	public AbstractQueryImpl(
 			String queryString,
 	        FlushMode flushMode,
 	        SessionImplementor session,
 	        ParameterMetadata parameterMetadata) {
 		this.session = session;
 		this.queryString = queryString;
 		this.selection = new RowSelection();
 		this.flushMode = flushMode;
 		this.cacheMode = null;
 		this.parameterMetadata = parameterMetadata;
 	}
 
 	public ParameterMetadata getParameterMetadata() {
 		return parameterMetadata;
 	}
 
 	@Override
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) + '(' + queryString + ')';
 	}
 
 	@Override
 	public final String getQueryString() {
 		return queryString;
 	}
 
 	@Override
 	public boolean isCacheable() {
 		return cacheable;
 	}
 
 	@Override
 	public Query setCacheable(boolean cacheable) {
 		this.cacheable = cacheable;
 		return this;
 	}
 
 	@Override
 	public String getCacheRegion() {
 		return cacheRegion;
 	}
 
 	@Override
 	public Query setCacheRegion(String cacheRegion) {
 		if (cacheRegion != null) {
 			this.cacheRegion = cacheRegion.trim();
 		}
 		return this;
 	}
 
 	@Override
 	public FlushMode getFlushMode() {
 		return flushMode;
 	}
 
 	@Override
 	public Query setFlushMode(FlushMode flushMode) {
 		this.flushMode = flushMode;
 		return this;
 	}
 
 	@Override
 	public CacheMode getCacheMode() {
 		return cacheMode;
 	}
 
 	@Override
 	public Query setCacheMode(CacheMode cacheMode) {
 		this.cacheMode = cacheMode;
 		return this;
 	}
 
 	@Override
 	public String getComment() {
 		return comment;
 	}
 
 	@Override
 	public Query setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
 	  
 	@Override
 	public Query addQueryHint(String queryHint) {
 		queryHints.add( queryHint );
 		return this;
 	} 
 
 	@Override
 	public Integer getFirstResult() {
 		return selection.getFirstRow();
 	}
 
 	@Override
 	public Query setFirstResult(int firstResult) {
 		selection.setFirstRow( firstResult);
 		return this;
 	}
 
 	@Override
 	public Integer getMaxResults() {
 		return selection.getMaxRows();
 	}
 
 	@Override
 	public Query setMaxResults(int maxResults) {
 		if ( maxResults <= 0 ) {
 			// treat zero and negatives specically as meaning no limit...
 			selection.setMaxRows( null );
 		}
 		else {
 			selection.setMaxRows( maxResults);
 		}
 		return this;
 	}
 
 	@Override
 	public Integer getTimeout() {
 		return selection.getTimeout();
 	}
 
 	@Override
 	public Query setTimeout(int timeout) {
 		selection.setTimeout( timeout);
 		return this;
 	}
 
 	@Override
 	public Integer getFetchSize() {
 		return selection.getFetchSize();
 	}
 
 	@Override
 	public Query setFetchSize(int fetchSize) {
 		selection.setFetchSize( fetchSize);
 		return this;
 	}
 
 	public Type[] getReturnTypes() throws HibernateException {
 		return session.getFactory().getReturnTypes( queryString );
 	}
 
 	public String[] getReturnAliases() throws HibernateException {
 		return session.getFactory().getReturnAliases( queryString );
 	}
 
 	public Query setCollectionKey(Serializable collectionKey) {
 		this.collectionKey = collectionKey;
 		return this;
 	}
 
 	@Override
 	public boolean isReadOnly() {
 		return ( readOnly == null ?
 				getSession().getPersistenceContext().isDefaultReadOnly() :
 				readOnly
 		);
 	}
 
 	@Override
 	public Query setReadOnly(boolean readOnly) {
 		this.readOnly = readOnly;
 		return this;
 	}
 	@Override
 	public Query setResultTransformer(ResultTransformer transformer) {
 		this.resultTransformer = transformer;
 		return this;
 	}
 	
 	public void setOptionalEntityName(String optionalEntityName) {
 		this.optionalEntityName = optionalEntityName;
 	}
 
 	public void setOptionalId(Serializable optionalId) {
 		this.optionalId = optionalId;
 	}
 
 	public void setOptionalObject(Object optionalObject) {
 		this.optionalObject = optionalObject;
 	}
 
 	SessionImplementor getSession() {
 		return session;
 	}
 	@Override
 	public abstract LockOptions getLockOptions();
 
 
 	// Parameter handling code ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Returns a shallow copy of the named parameter value map.
 	 *
 	 * @return Shallow copy of the named parameter value map
 	 */
 	protected Map<String, TypedValue> getNamedParams() {
 		return new HashMap<String, TypedValue>( namedParameters );
 	}
 
 	/**
 	 * Returns an array representing all named parameter names encountered
 	 * during (intial) parsing of the query.
 	 * <p/>
 	 * Note <i>initial</i> here means different things depending on whether
 	 * this is a native-sql query or an HQL/filter query.  For native-sql, a
 	 * precursory inspection of the query string is performed specifically to
 	 * locate defined parameters.  For HQL/filter queries, this is the
 	 * information returned from the query-translator.  This distinction
 	 * holds true for all parameter metadata exposed here.
 	 *
 	 * @return Array of named parameter names.
 	 * @throws HibernateException
 	 */
 	@Override
 	public String[] getNamedParameters() throws HibernateException {
 		return ArrayHelper.toStringArray( parameterMetadata.getNamedParameterNames() );
 	}
 
 	/**
 	 * Does this query contain named parameters?
 	 *
 	 * @return True if the query was found to contain named parameters; false
 	 * otherwise;
 	 */
 	public boolean hasNamedParameters() {
 		return parameterMetadata.getNamedParameterNames().size() > 0;
 	}
 
 	/**
 	 * Retreive the value map for any named parameter lists (i.e., for
 	 * auto-expansion) bound to this query.
 	 *
 	 * @return The parameter list value map.
 	 */
 	protected Map<String, TypedValue> getNamedParameterLists() {
 		return namedParameterLists;
 	}
 
 	/**
 	 * Retreives the list of parameter values bound to this query for
 	 * ordinal parameters.
 	 *
 	 * @return The ordinal parameter values.
 	 */
 	protected List getValues() {
 		return values;
 	}
 
 	/**
 	 * Retreives the list of parameter {@link Type type}s bound to this query for
 	 * ordinal parameters.
 	 *
 	 * @return The ordinal parameter types.
 	 */
 	protected List getTypes() {
 		return types;
 	}
 
 	/**
 	 * Perform parameter validation.  Used prior to executing the encapsulated
 	 * query.
 	 *
 	 * @throws QueryException
 	 */
 	protected void verifyParameters() throws QueryException {
 		verifyParameters(false);
 	}
 
 	/**
 	 * Perform parameter validation.  Used prior to executing the encapsulated
 	 * query.
 	 *
 	 * @param reserveFirstParameter if true, the first ? will not be verified since
 	 * its needed for e.g. callable statements returning a out parameter
 	 * @throws HibernateException
 	 */
 	protected void verifyParameters(boolean reserveFirstParameter) throws HibernateException {
 		if ( parameterMetadata.getNamedParameterNames().size() != namedParameters.size() + namedParameterLists.size() ) {
 			Set<String> missingParams = new HashSet<String>( parameterMetadata.getNamedParameterNames() );
 			missingParams.removeAll( namedParameterLists.keySet() );
 			missingParams.removeAll( namedParameters.keySet() );
 			throw new QueryException( "Not all named parameters have been set: " + missingParams, getQueryString() );
 		}
 
 		int positionalValueSpan = 0;
 		for ( int i = 0; i < values.size(); i++ ) {
 			Object object = types.get( i );
 			if( values.get( i ) == UNSET_PARAMETER || object == UNSET_TYPE ) {
 				if ( reserveFirstParameter && i==0 ) {
 					continue;
 				}
 				else {
 					throw new QueryException( "Unset positional parameter at position: " + i, getQueryString() );
 				}
 			}
 			positionalValueSpan += ( (Type) object ).getColumnSpan( session.getFactory() );
 		}
 
 		if ( parameterMetadata.getOrdinalParameterCount() != positionalValueSpan ) {
 			if ( reserveFirstParameter && parameterMetadata.getOrdinalParameterCount() - 1 != positionalValueSpan ) {
 				throw new QueryException(
 				 		"Expected positional parameter count: " +
 				 		(parameterMetadata.getOrdinalParameterCount()-1) +
 				 		", actual parameters: " +
 				 		values,
 				 		getQueryString()
 				 	);
 			}
 			else if ( !reserveFirstParameter ) {
 				throw new QueryException(
 				 		"Expected positional parameter count: " +
 				 		parameterMetadata.getOrdinalParameterCount() +
 				 		", actual parameters: " +
 				 		values,
 				 		getQueryString()
 				 	);
 			}
 		}
 	}
 
 	public Query setParameter(int position, Object val, Type type) {
 		if ( parameterMetadata.getOrdinalParameterCount() == 0 ) {
 			throw new IllegalArgumentException("No positional parameters in query: " + getQueryString() );
 		}
 		if ( position < 0 || position > parameterMetadata.getOrdinalParameterCount() - 1 ) {
 			throw new IllegalArgumentException("Positional parameter does not exist: " + position + " in query: " + getQueryString() );
 		}
 		int size = values.size();
 		if ( position < size ) {
 			values.set( position, val );
 			types.set( position, type );
 		}
 		else {
 			// prepend value and type list with null for any positions before the wanted position.
 			for ( int i = 0; i < position - size; i++ ) {
 				values.add( UNSET_PARAMETER );
 				types.add( UNSET_TYPE );
 			}
 			values.add( val );
 			types.add( type );
 		}
 		return this;
 	}
 
 	public Query setParameter(String name, Object val, Type type) {
 		if ( !parameterMetadata.getNamedParameterNames().contains( name ) ) {
 			throw new IllegalArgumentException("Parameter " + name + " does not exist as a named parameter in [" + getQueryString() + "]");
 		}
 		else {
 			 namedParameters.put( name, new TypedValue( type, val  ) );
 			 return this;
 		}
 	}
 
 	public Query setParameter(int position, Object val) throws HibernateException {
 		if (val == null) {
 			setParameter( position, val, StandardBasicTypes.SERIALIZABLE );
 		}
 		else {
 			setParameter( position, val, determineType( position, val ) );
 		}
 		return this;
 	}
 
 	public Query setParameter(String name, Object val) throws HibernateException {
 		if (val == null) {
 			Type type = parameterMetadata.getNamedParameterExpectedType( name );
 			if ( type == null ) {
 				type = StandardBasicTypes.SERIALIZABLE;
 			}
 			setParameter( name, val, type );
 		}
 		else {
 			setParameter( name, val, determineType( name, val ) );
 		}
 		return this;
 	}
 
 	protected Type determineType(int paramPosition, Object paramValue, Type defaultType) {
 		Type type = parameterMetadata.getOrdinalParameterExpectedType( paramPosition + 1 );
 		if ( type == null ) {
 			type = defaultType;
 		}
 		return type;
 	}
 
 	protected Type determineType(int paramPosition, Object paramValue) throws HibernateException {
 		Type type = parameterMetadata.getOrdinalParameterExpectedType( paramPosition + 1 );
 		if ( type == null ) {
 			type = guessType( paramValue );
 		}
 		return type;
 	}
 
 	protected Type determineType(String paramName, Object paramValue, Type defaultType) {
 		Type type = parameterMetadata.getNamedParameterExpectedType( paramName );
 		if ( type == null ) {
 			type = defaultType;
 		}
 		return type;
 	}
 
 	protected Type determineType(String paramName, Object paramValue) throws HibernateException {
 		Type type = parameterMetadata.getNamedParameterExpectedType( paramName );
 		if ( type == null ) {
 			type = guessType( paramValue );
 		}
 		return type;
 	}
 
 	protected Type determineType(String paramName, Class clazz) throws HibernateException {
 		Type type = parameterMetadata.getNamedParameterExpectedType( paramName );
 		if ( type == null ) {
 			type = guessType( clazz );
 		}
 		return type;
 	}
 
 	private Type guessType(Object param) throws HibernateException {
 		Class clazz = HibernateProxyHelper.getClassWithoutInitializingProxy( param );
 		return guessType( clazz );
 	}
 
 	private Type guessType(Class clazz) throws HibernateException {
 		String typename = clazz.getName();
 		Type type = session.getFactory().getTypeResolver().heuristicType(typename);
 		boolean serializable = type!=null && type instanceof SerializableType;
 		if (type==null || serializable) {
 			try {
 				session.getFactory().getEntityPersister( clazz.getName() );
 			}
 			catch (MappingException me) {
 				if (serializable) {
 					return type;
 				}
 				else {
 					throw new HibernateException("Could not determine a type for class: " + typename);
 				}
 			}
 			return ( (Session) session ).getTypeHelper().entity( clazz );
 		}
 		else {
 			return type;
 		}
 	}
 
 	public Query setString(int position, String val) {
 		setParameter(position, val, StandardBasicTypes.STRING);
 		return this;
 	}
 
 	public Query setCharacter(int position, char val) {
 		setParameter( position, Character.valueOf( val ), StandardBasicTypes.CHARACTER );
 		return this;
 	}
 
 	public Query setBoolean(int position, boolean val) {
 		Boolean valueToUse = val;
 		Type typeToUse = determineType( position, valueToUse, StandardBasicTypes.BOOLEAN );
 		setParameter( position, valueToUse, typeToUse );
 		return this;
 	}
 
 	public Query setByte(int position, byte val) {
 		setParameter(position, val, StandardBasicTypes.BYTE);
 		return this;
 	}
 
 	public Query setShort(int position, short val) {
 		setParameter(position, val, StandardBasicTypes.SHORT);
 		return this;
 	}
 
 	public Query setInteger(int position, int val) {
 		setParameter(position, val, StandardBasicTypes.INTEGER);
 		return this;
 	}
 
 	public Query setLong(int position, long val) {
 		setParameter(position, val, StandardBasicTypes.LONG);
 		return this;
 	}
 
 	public Query setFloat(int position, float val) {
 		setParameter(position, val, StandardBasicTypes.FLOAT);
 		return this;
 	}
 
 	public Query setDouble(int position, double val) {
 		setParameter(position, val, StandardBasicTypes.DOUBLE);
 		return this;
 	}
 
 	public Query setBinary(int position, byte[] val) {
 		setParameter(position, val, StandardBasicTypes.BINARY);
 		return this;
 	}
 
 	public Query setText(int position, String val) {
 		setParameter(position, val, StandardBasicTypes.TEXT);
 		return this;
 	}
 
 	public Query setSerializable(int position, Serializable val) {
 		setParameter(position, val, StandardBasicTypes.SERIALIZABLE);
 		return this;
 	}
 
 	public Query setDate(int position, Date date) {
 		setParameter(position, date, StandardBasicTypes.DATE);
 		return this;
 	}
 
 	public Query setTime(int position, Date date) {
 		setParameter(position, date, StandardBasicTypes.TIME);
 		return this;
 	}
 
 	public Query setTimestamp(int position, Date date) {
 		setParameter(position, date, StandardBasicTypes.TIMESTAMP);
 		return this;
 	}
 
 	public Query setEntity(int position, Object val) {
 		setParameter( position, val, ( (Session) session ).getTypeHelper().entity( resolveEntityName( val ) ) );
 		return this;
 	}
 
 	private String resolveEntityName(Object val) {
 		if ( val == null ) {
 			throw new IllegalArgumentException( "entity for parameter binding cannot be null" );
 		}
 		return session.bestGuessEntityName( val );
 	}
 
 	public Query setLocale(int position, Locale locale) {
 		setParameter(position, locale, StandardBasicTypes.LOCALE);
 		return this;
 	}
 
 	public Query setCalendar(int position, Calendar calendar) {
 		setParameter(position, calendar, StandardBasicTypes.CALENDAR);
 		return this;
 	}
 
 	public Query setCalendarDate(int position, Calendar calendar) {
 		setParameter(position, calendar, StandardBasicTypes.CALENDAR_DATE);
 		return this;
 	}
 
 	public Query setBinary(String name, byte[] val) {
 		setParameter(name, val, StandardBasicTypes.BINARY);
 		return this;
 	}
 
 	public Query setText(String name, String val) {
 		setParameter(name, val, StandardBasicTypes.TEXT);
 		return this;
 	}
 
 	public Query setBoolean(String name, boolean val) {
 		Boolean valueToUse = val;
 		Type typeToUse = determineType( name, valueToUse, StandardBasicTypes.BOOLEAN );
 		setParameter( name, valueToUse, typeToUse );
 		return this;
 	}
 
 	public Query setByte(String name, byte val) {
 		setParameter(name, val, StandardBasicTypes.BYTE);
 		return this;
 	}
 
 	public Query setCharacter(String name, char val) {
 		setParameter(name, val, StandardBasicTypes.CHARACTER);
 		return this;
 	}
 
 	public Query setDate(String name, Date date) {
 		setParameter(name, date, StandardBasicTypes.DATE);
 		return this;
 	}
 
 	public Query setDouble(String name, double val) {
 		setParameter(name, val, StandardBasicTypes.DOUBLE);
 		return this;
 	}
 
 	public Query setEntity(String name, Object val) {
 		setParameter( name, val, ( (Session) session ).getTypeHelper().entity( resolveEntityName( val ) ) );
 		return this;
 	}
 
 	public Query setFloat(String name, float val) {
 		setParameter(name, val, StandardBasicTypes.FLOAT);
 		return this;
 	}
 
 	public Query setInteger(String name, int val) {
 		setParameter(name, val, StandardBasicTypes.INTEGER);
 		return this;
 	}
 
 	public Query setLocale(String name, Locale locale) {
 		setParameter(name, locale, StandardBasicTypes.LOCALE);
 		return this;
 	}
 
 	public Query setCalendar(String name, Calendar calendar) {
 		setParameter(name, calendar, StandardBasicTypes.CALENDAR);
 		return this;
 	}
 
 	public Query setCalendarDate(String name, Calendar calendar) {
 		setParameter(name, calendar, StandardBasicTypes.CALENDAR_DATE);
 		return this;
 	}
 
 	public Query setLong(String name, long val) {
 		setParameter(name, val, StandardBasicTypes.LONG);
 		return this;
 	}
 
 	public Query setSerializable(String name, Serializable val) {
 		setParameter(name, val, StandardBasicTypes.SERIALIZABLE);
 		return this;
 	}
 
 	public Query setShort(String name, short val) {
 		setParameter(name, val, StandardBasicTypes.SHORT);
 		return this;
 	}
 
 	public Query setString(String name, String val) {
 		setParameter(name, val, StandardBasicTypes.STRING);
 		return this;
 	}
 
 	public Query setTime(String name, Date date) {
 		setParameter(name, date, StandardBasicTypes.TIME);
 		return this;
 	}
 
 	public Query setTimestamp(String name, Date date) {
 		setParameter(name, date, StandardBasicTypes.TIMESTAMP);
 		return this;
 	}
 
 	public Query setBigDecimal(int position, BigDecimal number) {
 		setParameter(position, number, StandardBasicTypes.BIG_DECIMAL);
 		return this;
 	}
 
 	public Query setBigDecimal(String name, BigDecimal number) {
 		setParameter(name, number, StandardBasicTypes.BIG_DECIMAL);
 		return this;
 	}
 
 	public Query setBigInteger(int position, BigInteger number) {
 		setParameter(position, number, StandardBasicTypes.BIG_INTEGER);
 		return this;
 	}
 
 	public Query setBigInteger(String name, BigInteger number) {
 		setParameter(name, number, StandardBasicTypes.BIG_INTEGER);
 		return this;
 	}
 
 	@Override
 	public Query setParameterList(String name, Collection vals, Type type) throws HibernateException {
 		if ( !parameterMetadata.getNamedParameterNames().contains( name ) ) {
 			throw new IllegalArgumentException("Parameter " + name + " does not exist as a named parameter in [" + getQueryString() + "]");
 		}
 		namedParameterLists.put( name, new TypedValue( type, vals ) );
 		return this;
 	}
 	
 	/**
 	 * Warning: adds new parameters to the argument by side-effect, as well as
 	 * mutating the query string!
 	 */
 	protected String expandParameterLists(Map namedParamsCopy) {
 		String query = this.queryString;
 		for ( Map.Entry<String, TypedValue> stringTypedValueEntry : namedParameterLists.entrySet() ) {
 			Map.Entry me = (Map.Entry) stringTypedValueEntry;
 			query = expandParameterList( query, (String) me.getKey(), (TypedValue) me.getValue(), namedParamsCopy );
 		}
 		return query;
 	}
 
 	/**
 	 * Warning: adds new parameters to the argument by side-effect, as well as
 	 * mutating the query string!
 	 */
 	private String expandParameterList(String query, String name, TypedValue typedList, Map namedParamsCopy) {
 		Collection vals = (Collection) typedList.getValue();
 		
 		// HHH-1123
 		// Some DBs limit number of IN expressions.  For now, warn...
 		final Dialect dialect = session.getFactory().getDialect();
 		final int inExprLimit = dialect.getInExpressionCountLimit();
 		if ( inExprLimit > 0 && vals.size() > inExprLimit ) {
 			log.tooManyInExpressions( dialect.getClass().getName(), inExprLimit, name, vals.size() );
 		}
 
 		Type type = typedList.getType();
 
 		boolean isJpaPositionalParam = parameterMetadata.getNamedParameterDescriptor( name ).isJpaStyle();
 		String paramPrefix = isJpaPositionalParam ? "?" : ParserHelper.HQL_VARIABLE_PREFIX;
 		String placeholder =
 				new StringBuilder( paramPrefix.length() + name.length() )
 						.append( paramPrefix ).append(  name )
 						.toString();
 
 		if ( query == null ) {
 			return query;
 		}
 		int loc = query.indexOf( placeholder );
 
 		if ( loc < 0 ) {
 			return query;
 		}
 
 		String beforePlaceholder = query.substring( 0, loc );
 		String afterPlaceholder =  query.substring( loc + placeholder.length() );
 
 		// check if placeholder is already immediately enclosed in parentheses
 		// (ignoring whitespace)
 		boolean isEnclosedInParens =
 				StringHelper.getLastNonWhitespaceCharacter( beforePlaceholder ) == '(' &&
 				StringHelper.getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')';
 
 		if ( vals.size() == 1  && isEnclosedInParens ) {
 			// short-circuit for performance when only 1 value and the
 			// placeholder is already enclosed in parentheses...
 			namedParamsCopy.put( name, new TypedValue( type, vals.iterator().next() ) );
 			return query;
 		}
 
 		StringBuilder list = new StringBuilder( 16 );
 		Iterator iter = vals.iterator();
 		int i = 0;
 		while ( iter.hasNext() ) {
 			// Variable 'name' can represent a number or contain digit at the end. Surrounding it with
 			// characters to avoid ambiguous definition after concatenating value of 'i' counter.
 			String alias = ( isJpaPositionalParam ? 'x' + name : name ) + '_' + i++ + '_';
 			if ( namedParamsCopy.put( alias, new TypedValue( type, iter.next() ) ) != null ) {
 				throw new HibernateException( "Repeated usage of alias '" + alias + "' while expanding list parameter." );
 			}
 			list.append( ParserHelper.HQL_VARIABLE_PREFIX ).append( alias );
 			if ( iter.hasNext() ) {
 				list.append( ", " );
 			}
 		}
 		return StringHelper.replace(
 				beforePlaceholder,
 				afterPlaceholder,
 				placeholder.toString(),
 				list.toString(),
 				true,
 				true
 		);
 	}
 
 	public Query setParameterList(String name, Collection vals) throws HibernateException {
 		if ( vals == null ) {
 			throw new QueryException( "Collection must be not null!" );
 		}
 
 		if( vals.size() == 0 ) {
 			setParameterList( name, vals, null );
 		}
 		else {
 			setParameterList(name, vals, determineType( name, vals.iterator().next() ) );
 		}
 
 		return this;
 	}
 
 	public Query setParameterList(String name, Object[] vals, Type type) throws HibernateException {
 		return setParameterList( name, Arrays.asList(vals), type );
 	}
 
 	public Query setParameterList(String name, Object[] values) throws HibernateException {
 		return setParameterList( name, Arrays.asList( values ) );
 	}
 
 	public Query setProperties(Map map) throws HibernateException {
 		String[] params = getNamedParameters();
 		for (int i = 0; i < params.length; i++) {
 			String namedParam = params[i];
 				final Object object = map.get(namedParam);
 				if(object==null) {
 					continue;
 				}
 				Class retType = object.getClass();
 				if ( Collection.class.isAssignableFrom( retType ) ) {
 					setParameterList( namedParam, ( Collection ) object );
 				}
 				else if ( retType.isArray() ) {
 					setParameterList( namedParam, ( Object[] ) object );
 				}
 				else {
 					setParameter( namedParam, object, determineType( namedParam, retType ) );
 				}
 
 			
 		}
 		return this;				
 	}
 	
 	public Query setProperties(Object bean) throws HibernateException {
 		Class clazz = bean.getClass();
 		String[] params = getNamedParameters();
 		for (int i = 0; i < params.length; i++) {
 			String namedParam = params[i];
 			try {
 				Getter getter = ReflectHelper.getGetter( clazz, namedParam );
 				Class retType = getter.getReturnType();
 				final Object object = getter.get( bean );
 				if ( Collection.class.isAssignableFrom( retType ) ) {
 					setParameterList( namedParam, ( Collection ) object );
 				}
 				else if ( retType.isArray() ) {
 				 	setParameterList( namedParam, ( Object[] ) object );
 				}
 				else {
 					setParameter( namedParam, object, determineType( namedParam, retType ) );
 				}
 			}
 			catch (PropertyNotFoundException pnfe) {
 				// ignore
 			}
 		}
 		return this;
 	}
 
 	public Query setParameters(Object[] values, Type[] types) {
 		this.values = Arrays.asList(values);
 		this.types = Arrays.asList(types);
 		return this;
 	}
 
 
 	// Execution methods ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Object uniqueResult() throws HibernateException {
 		return uniqueElement( list() );
 	}
 
 	static Object uniqueElement(List list) throws NonUniqueResultException {
 		int size = list.size();
-		if (size==0) return null;
+		if (size==0) {
+			return null;
+		}
 		Object first = list.get(0);
 		for ( int i=1; i<size; i++ ) {
 			if ( list.get(i)!=first ) {
 				throw new NonUniqueResultException( list.size() );
 			}
 		}
 		return first;
 	}
 
 	protected RowSelection getRowSelection() {
 		return selection;
 	}
 
 	public Type[] typeArray() {
 		return ArrayHelper.toTypeArray( getTypes() );
 	}
 	
 	public Object[] valueArray() {
 		return getValues().toArray();
 	}
 
 	public QueryParameters getQueryParameters(Map namedParams) {
 		QueryParameters queryParameters = new QueryParameters(
 				typeArray(),
 				valueArray(),
 				namedParams,
 				getLockOptions(),
 				getRowSelection(),
 				true,
 				isReadOnly(),
 				cacheable,
 				cacheRegion,
 				comment,
 				queryHints,
 				collectionKey == null ? null : new Serializable[] { collectionKey },
 				optionalObject,
 				optionalEntityName,
 				optionalId,
 				resultTransformer
 		);
 		queryParameters.setQueryPlan( queryPlan );
 		return queryParameters;
 	}
 	
 	protected void before() {
 		if ( flushMode!=null ) {
 			sessionFlushMode = getSession().getFlushMode();
 			getSession().setFlushMode(flushMode);
 		}
 		if ( cacheMode!=null ) {
 			sessionCacheMode = getSession().getCacheMode();
 			getSession().setCacheMode(cacheMode);
 		}
 	}
 	
 	protected void after() {
 		if (sessionFlushMode!=null) {
 			getSession().setFlushMode(sessionFlushMode);
 			sessionFlushMode = null;
 		}
 		if (sessionCacheMode!=null) {
 			getSession().setCacheMode(sessionCacheMode);
 			sessionCacheMode = null;
 		}
 	}
 
 	public HQLQueryPlan getQueryPlan() {
 		return queryPlan;
 	}
 
 	public void setQueryPlan(HQLQueryPlan queryPlan) {
 		this.queryPlan = queryPlan;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/CollectionFilterImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/CollectionFilterImpl.java
index 5c6208dc66..e035662414 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/CollectionFilterImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/CollectionFilterImpl.java
@@ -1,103 +1,107 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.type.Type;
 
 /**
  * implementation of the <tt>Query</tt> interface for collection filters
  * @author Gavin King
  */
 public class CollectionFilterImpl extends QueryImpl {
 
 	private Object collection;
 
 	public CollectionFilterImpl(
 			String queryString,
 	        Object collection,
 	        SessionImplementor session,
 	        ParameterMetadata parameterMetadata) {
 		super( queryString, session, parameterMetadata );
 		this.collection = collection;
 	}
 
 
 	/**
 	 * @see org.hibernate.Query#iterate()
 	 */
 	public Iterator iterate() throws HibernateException {
 		verifyParameters();
 		Map namedParams = getNamedParams();
 		return getSession().iterateFilter( 
 				collection, 
 				expandParameterLists(namedParams),
 				getQueryParameters(namedParams) 
 		);
 	}
 
 	/**
 	 * @see org.hibernate.Query#list()
 	 */
 	public List list() throws HibernateException {
 		verifyParameters();
 		Map namedParams = getNamedParams();
 		return getSession().listFilter( 
 				collection, 
 				expandParameterLists(namedParams),
 				getQueryParameters(namedParams) 
 		);
 	}
 
 	/**
 	 * @see org.hibernate.Query#scroll()
 	 */
 	public ScrollableResults scroll() throws HibernateException {
 		throw new UnsupportedOperationException("Can't scroll filters");
 	}
 
 	public Type[] typeArray() {
 		List typeList = getTypes();
 		int size = typeList.size();
 		Type[] result = new Type[size+1];
-		for (int i=0; i<size; i++) result[i+1] = (Type) typeList.get(i);
+		for (int i=0; i<size; i++) {
+			result[i+1] = (Type) typeList.get(i);
+		}
 		return result;
 	}
 
 	public Object[] valueArray() {
 		List valueList = getValues();
 		int size = valueList.size();
 		Object[] result = new Object[size+1];
-		for (int i=0; i<size; i++) result[i+1] = valueList.get(i);
+		for (int i=0; i<size; i++) {
+			result[i+1] = valueList.get(i);
+		}
 		return result;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
index 67345978ba..210d6df332 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
@@ -1,174 +1,176 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.NoSuchElementException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.engine.HibernateIterator;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * An implementation of <tt>java.util.Iterator</tt> that is
  * returned by <tt>iterate()</tt> query execution methods.
  * @author Gavin King
  */
 public final class IteratorImpl implements HibernateIterator {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, IteratorImpl.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( IteratorImpl.class );
 
 	private ResultSet rs;
 	private final EventSource session;
 	private boolean readOnly;
 	private final Type[] types;
 	private final boolean single;
 	private Object currentResult;
 	private boolean hasNext;
 	private final String[][] names;
 	private PreparedStatement ps;
 	private HolderInstantiator holderInstantiator;
 
 	public IteratorImpl(
 	        ResultSet rs,
 	        PreparedStatement ps,
 	        EventSource sess,
 	        boolean readOnly,
 	        Type[] types,
 	        String[][] columnNames,
 	        HolderInstantiator holderInstantiator)
 	throws HibernateException, SQLException {
 
 		this.rs=rs;
 		this.ps=ps;
 		this.session = sess;
 		this.readOnly = readOnly;
 		this.types = types;
 		this.names = columnNames;
 		this.holderInstantiator = holderInstantiator;
 
 		single = types.length==1;
 
 		postNext();
 	}
 
 	public void close() throws JDBCException {
 		if (ps!=null) {
-			LOG.debug("Closing iterator");
+			LOG.debug( "Closing iterator" );
 			session.getJdbcCoordinator().getResourceRegistry().release( ps );
-			session.getJdbcCoordinator().afterStatementExecution();
-			ps = null;
-			rs = null;
-			hasNext = false;
 			try {
 				session.getPersistenceContext().getLoadContexts().cleanup( rs );
 			}
 			catch( Throwable ignore ) {
 				// ignore this error for now
                 LOG.debugf("Exception trying to cleanup load context : %s", ignore.getMessage());
 			}
+			session.getJdbcCoordinator().afterStatementExecution();
+			ps = null;
+			rs = null;
+			hasNext = false;
 		}
 	}
 
 	private void postNext() throws SQLException {
 		LOG.debug("Attempting to retrieve next results");
 		this.hasNext = rs.next();
 		if (!hasNext) {
 			LOG.debug("Exhausted results");
 			close();
-		} else LOG.debug("Retrieved next results");
+		}
+		else {
+			LOG.debug("Retrieved next results");
+		}
 	}
 
 	public boolean hasNext() {
 		return hasNext;
 	}
 
 	public Object next() throws HibernateException {
-		if ( !hasNext ) throw new NoSuchElementException("No more results");
+		if ( !hasNext ) {
+			throw new NoSuchElementException("No more results");
+		}
 		boolean sessionDefaultReadOnlyOrig = session.isDefaultReadOnly();
 		session.setDefaultReadOnly( readOnly );
 		try {
 			boolean isHolder = holderInstantiator.isRequired();
 
 			LOG.debugf( "Assembling results" );
 			if ( single && !isHolder ) {
 				currentResult = types[0].nullSafeGet( rs, names[0], session, null );
 			}
 			else {
 				Object[] currentResults = new Object[types.length];
 				for (int i=0; i<types.length; i++) {
 					currentResults[i] = types[i].nullSafeGet( rs, names[i], session, null );
 				}
 
 				if (isHolder) {
 					currentResult = holderInstantiator.instantiate(currentResults);
 				}
 				else {
 					currentResult = currentResults;
 				}
 			}
 
 			postNext();
 			LOG.debugf( "Returning current results" );
 			return currentResult;
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not get next iterator result"
 				);
 		}
 		finally {
 			session.setDefaultReadOnly( sessionDefaultReadOnlyOrig );
 		}
 	}
 
 	public void remove() {
 		if (!single) {
 			throw new UnsupportedOperationException("Not a single column hibernate query result set");
 		}
 		if (currentResult==null) {
 			throw new IllegalStateException("Called Iterator.remove() before next()");
 		}
 		if ( !( types[0] instanceof EntityType ) ) {
 			throw new UnsupportedOperationException("Not an entity");
 		}
 
 		session.delete(
 				( (EntityType) types[0] ).getAssociatedEntityName(),
 				currentResult,
 				false,
 		        null
-			);
+		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
index 904464946b..ab3cc2b683 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
@@ -1,1535 +1,1535 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.StatelessSession;
 import org.hibernate.StatelessSessionBuilder;
 import org.hibernate.Transaction;
 import org.hibernate.TypeHelper;
 import org.hibernate.boot.cfgxml.spi.CfgXmlAccessService;
 import org.hibernate.boot.cfgxml.spi.LoadedConfig;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.internal.CacheDataDescriptionImpl;
 import org.hibernate.cache.spi.CollectionRegion;
 import org.hibernate.cache.spi.EntityRegion;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
 import org.hibernate.context.internal.JTASessionContext;
 import org.hibernate.context.internal.ManagedSessionContext;
 import org.hibernate.context.internal.ThreadLocalSessionContext;
 import org.hibernate.context.spi.CurrentSessionContext;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider;
 import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jndi.spi.JndiService;
 import org.hibernate.engine.profile.Association;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.spi.QueryPlanCache;
 import org.hibernate.engine.query.spi.ReturnMetadata;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CacheImplementor;
 import org.hibernate.engine.spi.FilterDefinition;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionBuilderImplementor;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.integrator.spi.IntegratorService;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.config.ConfigurationException;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.persister.spi.PersisterFactory;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.secure.spi.GrantedPermission;
 import org.hibernate.secure.spi.JaccPermissionDeclarations;
 import org.hibernate.secure.spi.JaccService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistryFactory;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.tool.hbm2ddl.ImportSqlCommandExtractor;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 import org.hibernate.tool.hbm2ddl.SchemaValidator;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
 
 /**
  * Concrete implementation of the <tt>SessionFactory</tt> interface. Has the following
  * responsibilities
  * <ul>
  * <li>caches configuration settings (immutably)
  * <li>caches "compiled" mappings ie. <tt>EntityPersister</tt>s and
  *     <tt>CollectionPersister</tt>s (immutable)
  * <li>caches "compiled" queries (memory sensitive cache)
  * <li>manages <tt>PreparedStatement</tt>s
  * <li> delegates JDBC <tt>Connection</tt> management to the <tt>ConnectionProvider</tt>
  * <li>factory for instances of <tt>SessionImpl</tt>
  * </ul>
  * This class must appear immutable to clients, even if it does all kinds of caching
  * and pooling under the covers. It is crucial that the class is not only thread
  * safe, but also highly concurrent. Synchronization must be used extremely sparingly.
  *
  * @see org.hibernate.engine.jdbc.connections.spi.ConnectionProvider
  * @see org.hibernate.Session
  * @see org.hibernate.hql.spi.QueryTranslator
  * @see org.hibernate.persister.entity.EntityPersister
  * @see org.hibernate.persister.collection.CollectionPersister
  * @author Gavin King
  */
 public final class SessionFactoryImpl implements SessionFactoryImplementor {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			SessionFactoryImpl.class.getName()
 	);
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
 	private final String name;
 	private final String uuid;
 
 	private final transient Map<String,EntityPersister> entityPersisters;
 	private final transient Map<String,ClassMetadata> classMetadata;
 	private final transient Map<Class,String> entityProxyInterfaceMap;
 	private final transient Map<String,CollectionPersister> collectionPersisters;
 	private final transient Map<String,CollectionMetadata> collectionMetadata;
 	private final transient Map<String,Set<String>> collectionRolesByEntityParticipant;
 	private final transient Map<String,IdentifierGenerator> identifierGenerators;
 	private final transient NamedQueryRepository namedQueryRepository;
 	private final transient Map<String, FilterDefinition> filters;
 	private final transient Map<String, FetchProfile> fetchProfiles;
 	private final transient Map<String,String> imports;
 	private final transient SessionFactoryServiceRegistry serviceRegistry;
 	private final transient JdbcServices jdbcServices;
 	private final transient Dialect dialect;
 	private final transient Settings settings;
 	private final transient Properties properties;
 	private transient SchemaExport schemaExport;
 	private final transient CurrentSessionContext currentSessionContext;
 	private final transient SQLFunctionRegistry sqlFunctionRegistry;
 	private final transient SessionFactoryObserverChain observer = new SessionFactoryObserverChain();
 	private final transient ConcurrentMap<EntityNameResolver,Object> entityNameResolvers = new ConcurrentHashMap<EntityNameResolver, Object>();
 	private final transient QueryPlanCache queryPlanCache;
 	private final transient CacheImplementor cacheAccess;
 	private transient boolean isClosed;
 	private final transient TypeResolver typeResolver;
 	private final transient TypeHelper typeHelper;
 	private final transient SessionFactoryOptions sessionFactoryOptions;
 
 	public SessionFactoryImpl(final MetadataImplementor metadata, SessionFactoryOptions options) {
 		LOG.debug( "Building session factory" );
 
 		this.sessionFactoryOptions = options;
 		this.settings = new Settings( options, metadata );
 
 		this.serviceRegistry = options.getServiceRegistry()
 				.getService( SessionFactoryServiceRegistryFactory.class )
 				.buildServiceRegistry( this, options );
 
 		final CfgXmlAccessService cfgXmlAccessService = serviceRegistry.getService( CfgXmlAccessService.class );
 
 		String sfName = settings.getSessionFactoryName();
 		if ( cfgXmlAccessService.getAggregatedConfig() != null ) {
 			if ( sfName == null ) {
 				sfName = cfgXmlAccessService.getAggregatedConfig().getSessionFactoryName();
 			}
 			applyCfgXmlValues( cfgXmlAccessService.getAggregatedConfig(), serviceRegistry );
 		}
 
 		this.name = sfName;
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 
 		this.properties = new Properties();
 		this.properties.putAll( serviceRegistry.getService( ConfigurationService.class ).getSettings() );
 
 		this.jdbcServices = this.serviceRegistry.getService( JdbcServices.class );
 		this.dialect = this.jdbcServices.getDialect();
 		this.cacheAccess = this.serviceRegistry.getService( CacheImplementor.class );
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), options.getCustomSqlFunctionMap() );
 
 		for ( SessionFactoryObserver sessionFactoryObserver : options.getSessionFactoryObservers() ) {
 			this.observer.addObserver( sessionFactoryObserver );
 		}
 
 		this.typeResolver = metadata.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap<String, FilterDefinition>();
 		this.filters.putAll( metadata.getFilterDefinitions() );
 
 		LOG.debugf( "Session factory constructed with filter configurations : %s", filters );
 		LOG.debugf( "Instantiating session factory with properties: %s", properties );
 
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
 				integrators.clear();
 			}
 		}
 		final IntegratorObserver integratorObserver = new IntegratorObserver();
 		this.observer.addObserver( integratorObserver );
 		for ( Integrator integrator : serviceRegistry.getService( IntegratorService.class ).getIntegrators() ) {
 			integrator.integrate( metadata, this, this.serviceRegistry );
 			integratorObserver.integrators.add( integrator );
 		}
 
 		//Generators:
 
 		this.identifierGenerators = new HashMap<String, IdentifierGenerator>();
 		for ( PersistentClass model : metadata.getEntityBindings() ) {
 			if ( !model.isInherited() ) {
 				IdentifierGenerator generator = model.getIdentifier().createIdentifierGenerator(
 						metadata.getIdentifierGeneratorFactory(),
 						getDialect(),
 						settings.getDefaultCatalogName(),
 						settings.getDefaultSchemaName(),
 						(RootClass) model
 				);
 				identifierGenerators.put( model.getEntityName(), generator );
 			}
 		}
 
 		this.imports = new HashMap<String,String>( metadata.getImports() );
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		final PersisterCreationContext persisterCreationContext = new PersisterCreationContext() {
 			@Override
 			public SessionFactoryImplementor getSessionFactory() {
 				return SessionFactoryImpl.this;
 			}
 
 			@Override
 			public MetadataImplementor getMetadata() {
 				return metadata;
 			}
 		};
 
 		final RegionFactory regionFactory = cacheAccess.getRegionFactory();
 		final String cacheRegionPrefix = settings.getCacheRegionPrefix() == null ? "" : settings.getCacheRegionPrefix() + ".";
 		final PersisterFactory persisterFactory = serviceRegistry.getService( PersisterFactory.class );
 
 		// todo : consider removing this silliness and just have EntityPersister directly implement ClassMetadata
 		//		EntityPersister.getClassMetadata() for the internal impls simply "return this";
 		//		collapsing those would allow us to remove this "extra" Map
 		//
 		// todo : similar for CollectionPersister/CollectionMetadata
 
 		this.entityPersisters = new HashMap<String,EntityPersister>();
 		Map cacheAccessStrategiesMap = new HashMap();
 		Map<String,ClassMetadata> inFlightClassMetadataMap = new HashMap<String,ClassMetadata>();
 		this.entityProxyInterfaceMap = CollectionHelper.concurrentMap( metadata.getEntityBindings().size() );
 		for ( final PersistentClass model : metadata.getEntityBindings() ) {
 			final String cacheRegionName = cacheRegionPrefix + model.getRootClass().getCacheRegionName();
 			// cache region is defined by the root-class in the hierarchy...
 			final EntityRegionAccessStrategy accessStrategy = determineEntityRegionAccessStrategy(
 					regionFactory,
 					cacheAccessStrategiesMap,
 					model,
 					cacheRegionName
 			);
 
 			final NaturalIdRegionAccessStrategy naturalIdAccessStrategy = determineNaturalIdRegionAccessStrategy(
 					regionFactory,
 					cacheRegionPrefix,
 					cacheAccessStrategiesMap,
 					model
 			);
 
 			final EntityPersister cp = persisterFactory.createEntityPersister(
 					model,
 					accessStrategy,
 					naturalIdAccessStrategy,
 					persisterCreationContext
 			);
 			entityPersisters.put( model.getEntityName(), cp );
 			inFlightClassMetadataMap.put( model.getEntityName(), cp.getClassMetadata() );
 
 			if ( cp.getConcreteProxyClass() != null
 					&& cp.getConcreteProxyClass().isInterface()
 					&& !Map.class.isAssignableFrom( cp.getConcreteProxyClass() )
 					&& cp.getMappedClass() != cp.getConcreteProxyClass() ) {
 				// IMPL NOTE : we exclude Map based proxy interfaces here because that should
 				//		indicate MAP entity mode.0
 
 				if ( cp.getMappedClass().equals( cp.getConcreteProxyClass() ) ) {
 					// this part handles an odd case in the Hibernate test suite where we map an interface
 					// as the class and the proxy.  I cannot think of a real life use case for that
 					// specific test, but..
 					LOG.debugf( "Entity [%s] mapped same interface [%s] as class and proxy", cp.getEntityName(), cp.getMappedClass() );
 				}
 				else {
 					final String old = entityProxyInterfaceMap.put( cp.getConcreteProxyClass(), cp.getEntityName() );
 					if ( old != null ) {
 						throw new HibernateException(
 								String.format(
 										Locale.ENGLISH,
 										"Multiple entities [%s, %s] named the same interface [%s] as their proxy which is not supported",
 										old,
 										cp.getEntityName(),
 										cp.getConcreteProxyClass().getName()
 								)
 						);
 					}
 				}
 			}
 		}
 		this.classMetadata = Collections.unmodifiableMap( inFlightClassMetadataMap );
 
 		this.collectionPersisters = new HashMap<String,CollectionPersister>();
 		Map<String,Set<String>> inFlightEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		Map<String,CollectionMetadata> tmpCollectionMetadata = new HashMap<String,CollectionMetadata>();
 		for ( final Collection model : metadata.getCollectionBindings() ) {
 			final String cacheRegionName = cacheRegionPrefix + model.getCacheRegionName();
 			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			final CollectionRegionAccessStrategy accessStrategy;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
 				LOG.tracev( "Building shared cache region for collection data [{0}]", model.getRole() );
 				CollectionRegion collectionRegion = regionFactory.buildCollectionRegion(
 						cacheRegionName,
 						properties,
 						CacheDataDescriptionImpl.decode( model )
 				);
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				cacheAccessStrategiesMap.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion( cacheRegionName, collectionRegion );
 			}
 			else {
 				accessStrategy = null;
 			}
 
 			final CollectionPersister persister = persisterFactory.createCollectionPersister(
 					model,
 					accessStrategy,
 					persisterCreationContext
 			);
 			collectionPersisters.put( model.getRole(), persister );
 			tmpCollectionMetadata.put( model.getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set<String> roles = inFlightEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					inFlightEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set<String> roles = inFlightEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					inFlightEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		this.collectionMetadata = Collections.unmodifiableMap( tmpCollectionMetadata );
 
 		for ( Map.Entry<String,Set<String>> entityToCollectionRoleMapEntry : inFlightEntityToCollectionRoleMap.entrySet() ) {
 			entityToCollectionRoleMapEntry.setValue(
 					Collections.unmodifiableSet( entityToCollectionRoleMapEntry.getValue() )
 			);
 		}
 		this.collectionRolesByEntityParticipant = Collections.unmodifiableMap( inFlightEntityToCollectionRoleMap );
 
 		//Named Queries:
 		this.namedQueryRepository = metadata.buildNamedQueryRepository( this );
 
 		// after *all* persisters and named queries are registered
 		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.generateEntityDefinition();
 		}
 
 		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 		}
 		for ( CollectionPersister persister : collectionPersisters.values() ) {
 			persister.postInstantiate();
 		}
 
 		LOG.debug( "Instantiated session factory" );
 
 		settings.getMultiTableBulkIdStrategy().prepare(
 				jdbcServices,
 				buildLocalConnectionAccess(),
 				metadata,
 				sessionFactoryOptions
 		);
 
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( serviceRegistry, metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) )
 					.create( false, true );
 		}
 		if ( settings.isAutoUpdateSchema() ) {
 			new SchemaUpdate( serviceRegistry, metadata ).execute( false, true );
 		}
 		if ( settings.isAutoValidateSchema() ) {
 			new SchemaValidator( serviceRegistry, metadata ).validate();
 		}
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( serviceRegistry, metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			final Map<String,HibernateException> errors = checkNamedQueries();
 			if ( ! errors.isEmpty() ) {
 				StringBuilder failingQueries = new StringBuilder( "Errors in named queries: " );
 				String sep = "";
 				for ( Map.Entry<String,HibernateException> entry : errors.entrySet() ) {
 					LOG.namedQueryError( entry.getKey(), entry.getValue() );
 					failingQueries.append( sep ).append( entry.getKey() );
 					sep = ", ";
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap<String,FetchProfile>();
 		for ( org.hibernate.mapping.FetchProfile mappingProfile : metadata.getFetchProfiles() ) {
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			for ( org.hibernate.mapping.FetchProfile.Fetch mappingFetch : mappingProfile.getFetches() ) {
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = entityName == null
 						? null
 						: entityPersisters.get( entityName );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || !associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				((Loadable) owner).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.observer.sessionFactoryCreated( this );
 
 		SessionFactoryRegistry.INSTANCE.addSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				this,
 				serviceRegistry.getService( JndiService.class )
 		);
 	}
 
 	private void applyCfgXmlValues(LoadedConfig aggregatedConfig, SessionFactoryServiceRegistry serviceRegistry) {
 		final JaccService jaccService = serviceRegistry.getService( JaccService.class );
 		if ( jaccService.getContextId() != null ) {
 			final JaccPermissionDeclarations permissions = aggregatedConfig.getJaccPermissions( jaccService.getContextId() );
 			if ( permissions != null ) {
 				for ( GrantedPermission grantedPermission : permissions.getPermissionDeclarations() ) {
 					jaccService.addPermission( grantedPermission );
 				}
 			}
 		}
 
 		if ( aggregatedConfig.getEventListenerMap() != null ) {
 			final ClassLoaderService cls = serviceRegistry.getService( ClassLoaderService.class );
 			final EventListenerRegistry eventListenerRegistry = serviceRegistry.getService( EventListenerRegistry.class );
 			for ( Map.Entry<EventType, Set<String>> entry : aggregatedConfig.getEventListenerMap().entrySet() ) {
 				final EventListenerGroup group = eventListenerRegistry.getEventListenerGroup( entry.getKey() );
 				for ( String listenerClassName : entry.getValue() ) {
 					try {
 						group.appendListener( cls.classForName( listenerClassName ).newInstance() );
 					}
 					catch (Exception e) {
 						throw new ConfigurationException( "Unable to instantiate event listener class : " + listenerClassName, e );
 					}
 				}
 			}
 		}
 	}
 
 	private NaturalIdRegionAccessStrategy determineNaturalIdRegionAccessStrategy(
 			RegionFactory regionFactory,
 			String cacheRegionPrefix,
 			Map cacheAccessStrategiesMap,
 			PersistentClass model) {
 		NaturalIdRegionAccessStrategy naturalIdAccessStrategy = null;
 		if ( model.hasNaturalId() && model.getNaturalIdCacheRegionName() != null ) {
 			final String naturalIdCacheRegionName = cacheRegionPrefix + model.getNaturalIdCacheRegionName();
 			naturalIdAccessStrategy = ( NaturalIdRegionAccessStrategy ) cacheAccessStrategiesMap.get( naturalIdCacheRegionName );
 
 			if ( naturalIdAccessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 				final CacheDataDescriptionImpl cacheDataDescription = CacheDataDescriptionImpl.decode( model );
 
 				NaturalIdRegion naturalIdRegion = null;
 				try {
 					naturalIdRegion = regionFactory.buildNaturalIdRegion(
 							naturalIdCacheRegionName,
 							properties,
 							cacheDataDescription
 					);
 				}
 				catch ( UnsupportedOperationException e ) {
 					LOG.warnf(
 							"Shared cache region factory [%s] does not support natural id caching; " +
 									"shared NaturalId caching will be disabled for not be enabled for %s",
 							regionFactory.getClass().getName(),
 							model.getEntityName()
 					);
 				}
 
 				if (naturalIdRegion != null) {
 					naturalIdAccessStrategy = naturalIdRegion.buildAccessStrategy( regionFactory.getDefaultAccessType() );
 					cacheAccessStrategiesMap.put( naturalIdCacheRegionName, naturalIdAccessStrategy );
 					cacheAccess.addCacheRegion(  naturalIdCacheRegionName, naturalIdRegion );
 				}
 			}
 		}
 		return naturalIdAccessStrategy;
 	}
 
 	private EntityRegionAccessStrategy determineEntityRegionAccessStrategy(
 			RegionFactory regionFactory,
 			Map cacheAccessStrategiesMap,
 			PersistentClass model,
 			String cacheRegionName) {
 		EntityRegionAccessStrategy accessStrategy = ( EntityRegionAccessStrategy ) cacheAccessStrategiesMap.get( cacheRegionName );
 		if ( accessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			if ( accessType != null ) {
 				LOG.tracef( "Building shared cache region for entity data [%s]", model.getEntityName() );
 				EntityRegion entityRegion = regionFactory.buildEntityRegion( cacheRegionName, properties, CacheDataDescriptionImpl
 																					 .decode( model ) );
 				accessStrategy = entityRegion.buildAccessStrategy( accessType );
 				cacheAccessStrategiesMap.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion( cacheRegionName, entityRegion );
 			}
 		}
 		return accessStrategy;
 	}
 
 	private JdbcConnectionAccess buildLocalConnectionAccess() {
 		return new JdbcConnectionAccess() {
 			@Override
 			public Connection obtainConnection() throws SQLException {
 				return settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE
 						? serviceRegistry.getService( ConnectionProvider.class ).getConnection()
 						: serviceRegistry.getService( MultiTenantConnectionProvider.class ).getAnyConnection();
 			}
 
 			@Override
 			public void releaseConnection(Connection connection) throws SQLException {
 				if ( settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE ) {
 					serviceRegistry.getService( ConnectionProvider.class ).closeConnection( connection );
 				}
 				else {
 					serviceRegistry.getService( MultiTenantConnectionProvider.class ).releaseAnyConnection( connection );
 				}
 			}
 
 			@Override
 			public boolean supportsAggressiveRelease() {
 				return false;
 			}
 		};
 	}
 
 	@SuppressWarnings( {"unchecked"} )
 	private static Properties createPropertiesFromMap(Map map) {
 		Properties properties = new Properties();
 		properties.putAll( map );
 		return properties;
 	}
 
 	public Session openSession() throws HibernateException {
 		return withOptions().openSession();
 	}
 
 	public Session openTemporarySession() throws HibernateException {
 		return withOptions()
 				.autoClose( false )
 				.flushBeforeCompletion( false )
 				.connectionReleaseMode( ConnectionReleaseMode.AFTER_STATEMENT )
 				.openSession();
 	}
 
 	public Session getCurrentSession() throws HibernateException {
 		if ( currentSessionContext == null ) {
 			throw new HibernateException( "No CurrentSessionContext configured!" );
 		}
 		return currentSessionContext.currentSession();
 	}
 
 	@Override
 	public SessionBuilderImplementor withOptions() {
 		return new SessionBuilderImpl( this );
 	}
 
 	@Override
 	public StatelessSessionBuilder withStatelessOptions() {
 		return new StatelessSessionBuilderImpl( this );
 	}
 
 	public StatelessSession openStatelessSession() {
 		return withStatelessOptions().openStatelessSession();
 	}
 
 	public StatelessSession openStatelessSession(Connection connection) {
 		return withStatelessOptions().connection( connection ).openStatelessSession();
 	}
 
 	@Override
 	public void addObserver(SessionFactoryObserver observer) {
 		this.observer.addObserver( observer );
 	}
 
 	public Properties getProperties() {
 		return properties;
 	}
 
 	public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return null;
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	private void registerEntityNameResolvers(EntityPersister persister) {
 		if ( persister.getEntityMetamodel() == null || persister.getEntityMetamodel().getTuplizer() == null ) {
 			return;
 		}
 		registerEntityNameResolvers( persister.getEntityMetamodel().getTuplizer() );
 	}
 
 	private void registerEntityNameResolvers(EntityTuplizer tuplizer) {
 		EntityNameResolver[] resolvers = tuplizer.getEntityNameResolvers();
 		if ( resolvers == null ) {
 			return;
 		}
 
 		for ( EntityNameResolver resolver : resolvers ) {
 			registerEntityNameResolver( resolver );
 		}
 	}
 
 	private static final Object ENTITY_NAME_RESOLVER_MAP_VALUE = new Object();
 
 	public void registerEntityNameResolver(EntityNameResolver resolver) {
 		entityNameResolvers.put( resolver, ENTITY_NAME_RESOLVER_MAP_VALUE );
 	}
 
 	@Override
 	public Iterable<EntityNameResolver> iterateEntityNameResolvers() {
 		return entityNameResolvers.keySet();
 	}
 
 	public QueryPlanCache getQueryPlanCache() {
 		return queryPlanCache;
 	}
 
 	private Map<String,HibernateException> checkNamedQueries() throws HibernateException {
 		return namedQueryRepository.checkNamedQueries( queryPlanCache );
 	}
 
 	@Override
 	public Map<String, EntityPersister> getEntityPersisters() {
 		return entityPersisters;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister(String entityName) throws MappingException {
 		EntityPersister result = entityPersisters.get( entityName );
 		if ( result == null ) {
 			throw new MappingException( "Unknown entity: " + entityName );
 		}
 		return result;
 	}
 
 	@Override
 	public EntityPersister locateEntityPersister(Class byClass) {
 		EntityPersister entityPersister = entityPersisters.get( byClass.getName() );
 		if ( entityPersister == null ) {
 			String mappedEntityName = entityProxyInterfaceMap.get( byClass );
 			if ( mappedEntityName != null ) {
 				entityPersister = entityPersisters.get( mappedEntityName );
 			}
 		}
 
 		if ( entityPersister == null ) {
 			throw new HibernateException( "Unable to locate persister: " + byClass.getName() );
 		}
 
 		return entityPersister;
 	}
 
 	@Override
 	public EntityPersister locateEntityPersister(String byName) {
 		final EntityPersister entityPersister = entityPersisters.get( byName );
 		if ( entityPersister == null ) {
 			throw new HibernateException( "Unable to locate persister: " + byName );
 		}
 		return entityPersister;
 	}
 
 	@Override
 	public Map<String, CollectionPersister> getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	public CollectionPersister getCollectionPersister(String role) throws MappingException {
 		CollectionPersister result = collectionPersisters.get(role);
 		if ( result == null ) {
 			throw new MappingException( "Unknown collection role: " + role );
 		}
 		return result;
 	}
 
-	@Deprecated
+	@SuppressWarnings("deprecation")
 	public Settings getSettings() {
 		return settings;
 	}
 
 	@Override
 	public SessionFactoryOptions getSessionFactoryOptions() {
 		return sessionFactoryOptions;
 	}
 
 	public JdbcServices getJdbcServices() {
 		return jdbcServices;
 	}
 
 	public Dialect getDialect() {
 		if ( serviceRegistry == null ) {
 			throw new IllegalStateException( "Cannot determine dialect because serviceRegistry is null." );
 		}
 		return dialect;
 	}
 
 	public Interceptor getInterceptor() {
 		return sessionFactoryOptions.getInterceptor();
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	public SqlExceptionHelper getSQLExceptionHelper() {
 		return getJdbcServices().getSqlExceptionHelper();
 	}
 
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName) {
 		return collectionRolesByEntityParticipant.get( entityName );
 	}
 
 	@Override
 	public Reference getReference() {
 		// from javax.naming.Referenceable
         LOG.debug( "Returning a Reference to the SessionFactory" );
 		return new Reference(
 				SessionFactoryImpl.class.getName(),
 				new StringRefAddr("uuid", uuid),
 				SessionFactoryRegistry.ObjectFactoryImpl.class.getName(),
 				null
 		);
 	}
 
 	@Override
 	public NamedQueryRepository getNamedQueryRepository() {
 		return namedQueryRepository;
 	}
 
 	public void registerNamedQueryDefinition(String name, NamedQueryDefinition definition) {
 		namedQueryRepository.registerNamedQueryDefinition( name, definition );
 	}
 
 	public NamedQueryDefinition getNamedQuery(String queryName) {
 		return namedQueryRepository.getNamedQueryDefinition( queryName );
 	}
 
 	public void registerNamedSQLQueryDefinition(String name, NamedSQLQueryDefinition definition) {
 		namedQueryRepository.registerNamedSQLQueryDefinition( name, definition );
 	}
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName) {
 		return namedQueryRepository.getNamedSQLQueryDefinition( queryName );
 	}
 
 	public ResultSetMappingDefinition getResultSetMapping(String mappingName) {
 		return namedQueryRepository.getResultSetMappingDefinition( mappingName );
 	}
 
 	public Type getIdentifierType(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierType();
 	}
 	public String getIdentifierPropertyName(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierPropertyName();
 	}
 
 	public Type[] getReturnTypes(String queryString) throws HibernateException {
 		final ReturnMetadata metadata = queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata();
 		return metadata == null ? null : metadata.getReturnTypes();
 	}
 
 	public String[] getReturnAliases(String queryString) throws HibernateException {
 		final ReturnMetadata metadata = queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata();
 		return metadata == null ? null : metadata.getReturnAliases();
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getClassMetadata( persistentClass.getName() );
 	}
 
 	public CollectionMetadata getCollectionMetadata(String roleName) throws HibernateException {
 		return collectionMetadata.get( roleName );
 	}
 
 	public ClassMetadata getClassMetadata(String entityName) throws HibernateException {
 		return classMetadata.get( entityName );
 	}
 
 	/**
 	 * Given the name of an entity class, determine all the class and interface names by which it can be
 	 * referenced in an HQL query.
 	 *
      * @param className The name of the entity class
 	 *
 	 * @return the names of all persistent (mapped) classes that extend or implement the
 	 *     given class or interface, accounting for implicit/explicit polymorphism settings
 	 *     and excluding mapped subclasses/joined-subclasses of other classes in the result.
 	 * @throws MappingException
 	 */
 	public String[] getImplementors(String className) throws MappingException {
 
 		final Class clazz;
 		try {
 			clazz = serviceRegistry.getService( ClassLoaderService.class ).classForName( className );
 		}
 		catch (ClassLoadingException cnfe) {
 			return new String[] { className }; //for a dynamic-class
 		}
 
 		ArrayList<String> results = new ArrayList<String>();
 		for ( EntityPersister checkPersister : entityPersisters.values() ) {
 			if ( ! Queryable.class.isInstance( checkPersister ) ) {
 				continue;
 			}
 			final Queryable checkQueryable = Queryable.class.cast( checkPersister );
 			final String checkQueryableEntityName = checkQueryable.getEntityName();
 			final boolean isMappedClass = className.equals( checkQueryableEntityName );
 			if ( checkQueryable.isExplicitPolymorphism() ) {
 				if ( isMappedClass ) {
 					return new String[] { className }; //NOTE EARLY EXIT
 				}
 			}
 			else {
 				if ( isMappedClass ) {
 					results.add( checkQueryableEntityName );
 				}
 				else {
 					final Class mappedClass = checkQueryable.getMappedClass();
 					if ( mappedClass != null && clazz.isAssignableFrom( mappedClass ) ) {
 						final boolean assignableSuperclass;
 						if ( checkQueryable.isInherited() ) {
 							Class mappedSuperclass = getEntityPersister( checkQueryable.getMappedSuperclass() ).getMappedClass();
 							assignableSuperclass = clazz.isAssignableFrom( mappedSuperclass );
 						}
 						else {
 							assignableSuperclass = false;
 						}
 						if ( !assignableSuperclass ) {
 							results.add( checkQueryableEntityName );
 						}
 					}
 				}
 			}
 		}
 		return results.toArray( new String[results.size()] );
 	}
 
 	@Override
 	public String getImportedClassName(String className) {
 		String result = imports.get( className );
 		if ( result == null ) {
 			try {
 				serviceRegistry.getService( ClassLoaderService.class ).classForName( className );
 				imports.put( className, className );
 				return className;
 			}
 			catch ( ClassLoadingException cnfe ) {
 				return null;
 			}
 		}
 		else {
 			return result;
 		}
 	}
 
 	public Map<String,ClassMetadata> getAllClassMetadata() throws HibernateException {
 		return classMetadata;
 	}
 
 	public Map getAllCollectionMetadata() throws HibernateException {
 		return collectionMetadata;
 	}
 
 	public Type getReferencedPropertyType(String className, String propertyName)
 		throws MappingException {
 		return getEntityPersister( className ).getPropertyType( propertyName );
 	}
 
 	/**
 	 * Closes the session factory, releasing all held resources.
 	 *
 	 * <ol>
 	 * <li>cleans up used cache regions and "stops" the cache provider.
 	 * <li>close the JDBC connection
 	 * <li>remove the JNDI binding
 	 * </ol>
 	 *
 	 * Note: Be aware that the sessionFactory instance still can
 	 * be a "heavy" object memory wise after close() has been called.  Thus
 	 * it is important to not keep referencing the instance to let the garbage
 	 * collector release the memory.
 	 * @throws HibernateException
 	 */
 	public void close() throws HibernateException {
 
 		if ( isClosed ) {
 			LOG.trace( "Already closed" );
 			return;
 		}
 
 		LOG.closing();
 
 		isClosed = true;
 
 		settings.getMultiTableBulkIdStrategy().release( jdbcServices, buildLocalConnectionAccess() );
 
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			EntityPersister p = (EntityPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = (CollectionPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		cacheAccess.close();
 
 		queryPlanCache.cleanup();
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport.drop( false, true );
 		}
 
 		SessionFactoryRegistry.INSTANCE.removeSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				serviceRegistry.getService( JndiService.class )
 		);
 
 		observer.sessionFactoryClosed( this );
 		serviceRegistry.destroy();
 	}
 
 	public Cache getCache() {
 		return cacheAccess;
 	}
 
 	public void evictEntity(String entityName, Serializable id) throws HibernateException {
 		getCache().evictEntity( entityName, id );
 	}
 
 	public void evictEntity(String entityName) throws HibernateException {
 		getCache().evictEntityRegion( entityName );
 	}
 
 	public void evict(Class persistentClass, Serializable id) throws HibernateException {
 		getCache().evictEntity( persistentClass, id );
 	}
 
 	public void evict(Class persistentClass) throws HibernateException {
 		getCache().evictEntityRegion( persistentClass );
 	}
 
 	public void evictCollection(String roleName, Serializable id) throws HibernateException {
 		getCache().evictCollection( roleName, id );
 	}
 
 	public void evictCollection(String roleName) throws HibernateException {
 		getCache().evictCollectionRegion( roleName );
 	}
 
 	public void evictQueries() throws HibernateException {
 		cacheAccess.evictQueries();
 	}
 
 	public void evictQueries(String regionName) throws HibernateException {
 		getCache().evictQueryRegion( regionName );
 	}
 
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return cacheAccess.getUpdateTimestampsCache();
 	}
 
 	public QueryCache getQueryCache() {
 		return cacheAccess.getQueryCache();
 	}
 
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		return cacheAccess.getQueryCache( regionName );
 	}
 
 	public Region getSecondLevelCacheRegion(String regionName) {
 		return cacheAccess.getSecondLevelCacheRegion( regionName );
 	}
 
 	public Region getNaturalIdCacheRegion(String regionName) {
 		return cacheAccess.getNaturalIdCacheRegion( regionName );
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public Map getAllSecondLevelCacheRegions() {
 		return cacheAccess.getAllSecondLevelCacheRegions();
 	}
 
 	public boolean isClosed() {
 		return isClosed;
 	}
 
 	public Statistics getStatistics() {
 		return getStatisticsImplementor();
 	}
 
 	public StatisticsImplementor getStatisticsImplementor() {
 		return serviceRegistry.getService( StatisticsImplementor.class );
 	}
 
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException {
 		FilterDefinition def = filters.get( filterName );
 		if ( def == null ) {
 			throw new HibernateException( "No such filter configured [" + filterName + "]" );
 		}
 		return def;
 	}
 
 	public boolean containsFetchProfileDefinition(String name) {
 		return fetchProfiles.containsKey( name );
 	}
 
 	public Set getDefinedFilterNames() {
 		return filters.keySet();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName) {
 		return identifierGenerators.get(rootEntityName);
 	}
 
 	private boolean canAccessTransactionManager() {
 		try {
 			return serviceRegistry.getService( JtaPlatform.class ).retrieveTransactionManager() != null;
 		}
 		catch (Exception e) {
 			return false;
 		}
 	}
 
 	private CurrentSessionContext buildCurrentSessionContext() {
 		String impl = properties.getProperty( Environment.CURRENT_SESSION_CONTEXT_CLASS );
 		// for backward-compatibility
 		if ( impl == null ) {
 			if ( canAccessTransactionManager() ) {
 				impl = "jta";
 			}
 			else {
 				return null;
 			}
 		}
 
 		if ( "jta".equals( impl ) ) {
 //			if ( ! transactionFactory().compatibleWithJtaSynchronization() ) {
 //				LOG.autoFlushWillNotWork();
 //			}
 			return new JTASessionContext( this );
 		}
 		else if ( "thread".equals( impl ) ) {
 			return new ThreadLocalSessionContext( this );
 		}
 		else if ( "managed".equals( impl ) ) {
 			return new ManagedSessionContext( this );
 		}
 		else {
 			try {
 				Class implClass = serviceRegistry.getService( ClassLoaderService.class ).classForName( impl );
 				return ( CurrentSessionContext ) implClass
 						.getConstructor( new Class[] { SessionFactoryImplementor.class } )
 						.newInstance( this );
 			}
 			catch( Throwable t ) {
 				LOG.unableToConstructCurrentSessionContext( impl, t );
 				return null;
 			}
 		}
 	}
 
 	@Override
 	public ServiceRegistryImplementor getServiceRegistry() {
 		return serviceRegistry;
 	}
 
 	@Override
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return sessionFactoryOptions.getEntityNotFoundDelegate();
 	}
 
 	public SQLFunctionRegistry getSqlFunctionRegistry() {
 		return sqlFunctionRegistry;
 	}
 
 	public FetchProfile getFetchProfile(String name) {
 		return fetchProfiles.get( name );
 	}
 
 	public TypeHelper getTypeHelper() {
 		return typeHelper;
 	}
 
 	static class SessionBuilderImpl implements SessionBuilderImplementor {
 		private static final Logger log = CoreLogging.logger( SessionBuilderImpl.class );
 
 		private final SessionFactoryImpl sessionFactory;
 		private SessionOwner sessionOwner;
 		private Interceptor interceptor;
 		private StatementInspector statementInspector;
 		private Connection connection;
 		private ConnectionReleaseMode connectionReleaseMode;
 		private boolean autoClose;
 		private boolean autoJoinTransactions = true;
 		private boolean flushBeforeCompletion;
 		private String tenantIdentifier;
 		private List<SessionEventListener> listeners;
 
 		SessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 			this.sessionOwner = null;
 			final Settings settings = sessionFactory.settings;
 
 			// set up default builder values...
 			this.interceptor = sessionFactory.getInterceptor();
 			this.statementInspector = sessionFactory.getSessionFactoryOptions().getStatementInspector();
 			this.connectionReleaseMode = settings.getConnectionReleaseMode();
 			this.autoClose = settings.isAutoCloseSessionEnabled();
 			this.flushBeforeCompletion = settings.isFlushBeforeCompletionEnabled();
 
 			if ( sessionFactory.getCurrentTenantIdentifierResolver() != null ) {
 				tenantIdentifier = sessionFactory.getCurrentTenantIdentifierResolver().resolveCurrentTenantIdentifier();
 			}
 
 			listeners = settings.getBaselineSessionEventsListenerBuilder().buildBaselineList();
 		}
 
 		protected TransactionCoordinator getTransactionCoordinator() {
 			return null;
 		}
 
 		protected JdbcCoordinatorImpl getJdbcCoordinator() {
 			return null;
 		}
 
 		protected Transaction getTransaction() {
 			return null;
 		}
 
 		protected ActionQueue.TransactionCompletionProcesses getTransactionCompletionProcesses() {
 			return null;
 		}
 
 		@Override
 		public Session openSession() {
 			log.tracef( "Opening Hibernate Session.  tenant=%s, owner=%s", tenantIdentifier, sessionOwner );
 			final SessionImpl session = new SessionImpl(
 					connection,
 					sessionFactory,
 					sessionOwner,
 					getTransactionCoordinator(),
 					getJdbcCoordinator(),
 					getTransaction(),
 					getTransactionCompletionProcesses(),
 					autoJoinTransactions,
 					sessionFactory.settings.getRegionFactory().nextTimestamp(),
 					interceptor,
 					statementInspector,
 					flushBeforeCompletion,
 					autoClose,
 					connectionReleaseMode,
 					tenantIdentifier
 			);
 
 			for ( SessionEventListener listener : listeners ) {
 				session.getEventListenerManager().addListener( listener );
 			}
 
 			return session;
 		}
 
 		@Override
 		public SessionBuilder owner(SessionOwner sessionOwner) {
 			this.sessionOwner = sessionOwner;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder interceptor(Interceptor interceptor) {
 			this.interceptor = interceptor;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder noInterceptor() {
 			this.interceptor = EmptyInterceptor.INSTANCE;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder statementInspector(StatementInspector statementInspector) {
 			this.statementInspector = statementInspector;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder connection(Connection connection) {
 			this.connection = connection;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder connectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 			this.connectionReleaseMode = connectionReleaseMode;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder autoJoinTransactions(boolean autoJoinTransactions) {
 			this.autoJoinTransactions = autoJoinTransactions;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder autoClose(boolean autoClose) {
 			this.autoClose = autoClose;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder flushBeforeCompletion(boolean flushBeforeCompletion) {
 			this.flushBeforeCompletion = flushBeforeCompletion;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder tenantIdentifier(String tenantIdentifier) {
 			this.tenantIdentifier = tenantIdentifier;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder eventListeners(SessionEventListener... listeners) {
 			Collections.addAll( this.listeners, listeners );
 			return this;
 		}
 
 		@Override
 		public SessionBuilder clearEventListeners() {
 			listeners.clear();
 			return this;
 		}
 	}
 
 	public static class StatelessSessionBuilderImpl implements StatelessSessionBuilder {
 		private final SessionFactoryImpl sessionFactory;
 		private Connection connection;
 		private String tenantIdentifier;
 
 		public StatelessSessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 
 			if ( sessionFactory.getCurrentTenantIdentifierResolver() != null ) {
 				tenantIdentifier = sessionFactory.getCurrentTenantIdentifierResolver().resolveCurrentTenantIdentifier();
 			}
 		}
 
 		@Override
 		public StatelessSession openStatelessSession() {
 			return new StatelessSessionImpl( connection, tenantIdentifier, sessionFactory,
 					sessionFactory.settings.getRegionFactory().nextTimestamp() );
 		}
 
 		@Override
 		public StatelessSessionBuilder connection(Connection connection) {
 			this.connection = connection;
 			return this;
 		}
 
 		@Override
 		public StatelessSessionBuilder tenantIdentifier(String tenantIdentifier) {
 			this.tenantIdentifier = tenantIdentifier;
 			return this;
 		}
 	}
 
 	@Override
 	public CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy() {
 		return getSessionFactoryOptions().getCustomEntityDirtinessStrategy();
 	}
 
 	@Override
 	public CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver() {
 		return getSessionFactoryOptions().getCurrentTenantIdentifierResolver();
 	}
 
 
 	// Serialization handling ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly serialized
 	 *
 	 * @param out The stream into which the object is being serialized.
 	 *
 	 * @throws IOException Can be thrown by the stream
 	 */
 	private void writeObject(ObjectOutputStream out) throws IOException {
 		LOG.debugf( "Serializing: %s", uuid );
 		out.defaultWriteObject();
 		LOG.trace( "Serialized" );
 	}
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly deserialized
 	 *
 	 * @param in The stream from which the object is being deserialized.
 	 *
 	 * @throws IOException Can be thrown by the stream
 	 * @throws ClassNotFoundException Again, can be thrown by the stream
 	 */
 	private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
 		LOG.trace( "Deserializing" );
 		in.defaultReadObject();
 		LOG.debugf( "Deserialized: %s", uuid );
 	}
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly deserialized.
 	 * Here we resolve the uuid/name read from the stream previously to resolve the SessionFactory
 	 * instance to use based on the registrations with the {@link SessionFactoryRegistry}
 	 *
 	 * @return The resolved factory to use.
 	 *
 	 * @throws InvalidObjectException Thrown if we could not resolve the factory by uuid/name.
 	 */
 	private Object readResolve() throws InvalidObjectException {
 		LOG.trace( "Resolving serialized SessionFactory" );
 		return locateSessionFactoryOnDeserialization( uuid, name );
 	}
 
 	private static SessionFactory locateSessionFactoryOnDeserialization(String uuid, String name) throws InvalidObjectException{
 		final SessionFactory uuidResult = SessionFactoryRegistry.INSTANCE.getSessionFactory( uuid );
 		if ( uuidResult != null ) {
 			LOG.debugf( "Resolved SessionFactory by UUID [%s]", uuid );
 			return uuidResult;
 		}
 
 		// in case we were deserialized in a different JVM, look for an instance with the same name
 		// (provided we were given a name)
 		if ( name != null ) {
 			final SessionFactory namedResult = SessionFactoryRegistry.INSTANCE.getNamedSessionFactory( name );
 			if ( namedResult != null ) {
 				LOG.debugf( "Resolved SessionFactory by name [%s]", name );
 				return namedResult;
 			}
 		}
 
 		throw new InvalidObjectException( "Could not find a SessionFactory [uuid=" + uuid + ",name=" + name + "]" );
 	}
 
 	/**
 	 * Custom serialization hook used during Session serialization.
 	 *
 	 * @param oos The stream to which to write the factory
 	 * @throws IOException Indicates problems writing out the serial data stream
 	 */
 	void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeUTF( uuid );
 		oos.writeBoolean( name != null );
 		if ( name != null ) {
 			oos.writeUTF( name );
 		}
 	}
 
 	/**
 	 * Custom deserialization hook used during Session deserialization.
 	 *
 	 * @param ois The stream from which to "read" the factory
 	 * @return The deserialized factory
 	 * @throws IOException indicates problems reading back serial data stream
 	 * @throws ClassNotFoundException indicates problems reading back serial data stream
 	 */
 	static SessionFactoryImpl deserialize(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		LOG.trace( "Deserializing SessionFactory from Session" );
 		final String uuid = ois.readUTF();
 		boolean isNamed = ois.readBoolean();
 		final String name = isNamed ? ois.readUTF() : null;
 		return (SessionFactoryImpl) locateSessionFactoryOnDeserialization( uuid, name );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
index 08a5ed3b90..f26abfaa9c 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
@@ -1,206 +1,208 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
 import java.net.MalformedURLException;
 import java.net.URL;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * A simple class to centralize logic needed to locate config files on the system.
  *
  * @todo : Update usages to use {@link org.hibernate.boot.registry.classloading.spi.ClassLoaderService}
  *
  * @author Steve Ebersole
  */
 public final class ConfigHelper {
-
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ConfigHelper.class.getName());
 
 	/** Try to locate a local URL representing the incoming path.  The first attempt
 	 * assumes that the incoming path is an actual URL string (file://, etc).  If this
 	 * does not work, then the next attempts try to locate this UURL as a java system
 	 * resource.
 	 *
 	 * @param path The path representing the config location.
 	 * @return An appropriate URL or null.
 	 */
 	public static URL locateConfig(final String path) {
 		try {
 			return new URL(path);
 		}
 		catch(MalformedURLException e) {
 			return findAsResource(path);
 		}
 	}
 
 	/**
 	 * Try to locate a local URL representing the incoming path.
 	 * This method <b>only</b> attempts to locate this URL as a
 	 * java system resource.
 	 *
 	 * @param path The path representing the config location.
 	 * @return An appropriate URL or null.
 	 */
 	public static URL findAsResource(final String path) {
 		URL url = null;
 
 		// First, try to locate this resource through the current
 		// context classloader.
 		ClassLoader contextClassLoader = ClassLoaderHelper.getContextClassLoader();
 		if (contextClassLoader!=null) {
 			url = contextClassLoader.getResource(path);
 		}
-		if (url != null)
+		if (url != null) {
 			return url;
+		}
 
 		// Next, try to locate this resource through this class's classloader
 		url = ConfigHelper.class.getClassLoader().getResource(path);
-		if (url != null)
+		if (url != null) {
 			return url;
+		}
 
 		// Next, try to locate this resource through the system classloader
 		url = ClassLoader.getSystemClassLoader().getResource(path);
 
 		// Anywhere else we should look?
 		return url;
 	}
 
 	/** Open an InputStream to the URL represented by the incoming path.  First makes a call
 	 * to {@link #locateConfig(java.lang.String)} in order to find an appropriate URL.
 	 * {@link java.net.URL#openStream()} is then called to obtain the stream.
 	 *
 	 * @param path The path representing the config location.
 	 * @return An input stream to the requested config resource.
 	 * @throws HibernateException Unable to open stream to that resource.
 	 */
 	public static InputStream getConfigStream(final String path) throws HibernateException {
 		final URL url = ConfigHelper.locateConfig(path);
 
 		if (url == null) {
             String msg = LOG.unableToLocateConfigFile(path);
             LOG.error(msg);
 			throw new HibernateException(msg);
 		}
 
 		try {
 			return url.openStream();
         }
 		catch(IOException e) {
 	        throw new HibernateException("Unable to open config file: " + path, e);
         }
 	}
 
 	/** Open an Reader to the URL represented by the incoming path.  First makes a call
 	 * to {@link #locateConfig(java.lang.String)} in order to find an appropriate URL.
 	 * {@link java.net.URL#openStream()} is then called to obtain a stream, which is then
 	 * wrapped in a Reader.
 	 *
 	 * @param path The path representing the config location.
 	 * @return An input stream to the requested config resource.
 	 * @throws HibernateException Unable to open reader to that resource.
 	 */
 	public static Reader getConfigStreamReader(final String path) throws HibernateException {
 		return new InputStreamReader( getConfigStream(path) );
 	}
 
 	/** Loads a properties instance based on the data at the incoming config location.
 	 *
 	 * @param path The path representing the config location.
 	 * @return The loaded properties instance.
 	 * @throws HibernateException Unable to load properties from that resource.
 	 */
 	public static Properties getConfigProperties(String path) throws HibernateException {
 		try {
 			Properties properties = new Properties();
 			properties.load( getConfigStream(path) );
 			return properties;
 		}
 		catch(IOException e) {
 			throw new HibernateException("Unable to load properties from specified config file: " + path, e);
 		}
 	}
 
 	private ConfigHelper() {}
 
 	public static InputStream getResourceAsStream(String resource) {
-		String stripped = resource.startsWith("/") ?
-				resource.substring(1) : resource;
+		String stripped = resource.startsWith("/")
+				? resource.substring(1)
+				: resource;
 
 		InputStream stream = null;
 		ClassLoader classLoader = ClassLoaderHelper.getContextClassLoader();
 		if (classLoader!=null) {
 			stream = classLoader.getResourceAsStream( stripped );
 		}
 		if ( stream == null ) {
 			stream = Environment.class.getResourceAsStream( resource );
 		}
 		if ( stream == null ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( stripped );
 		}
 		if ( stream == null ) {
 			throw new HibernateException( resource + " not found" );
 		}
 		return stream;
 	}
 
 
 	public static InputStream getUserResourceAsStream(String resource) {
 		boolean hasLeadingSlash = resource.startsWith( "/" );
 		String stripped = hasLeadingSlash ? resource.substring(1) : resource;
 
 		InputStream stream = null;
 
 		ClassLoader classLoader = ClassLoaderHelper.getContextClassLoader();
 		if ( classLoader != null ) {
 			stream = classLoader.getResourceAsStream( resource );
 			if ( stream == null && hasLeadingSlash ) {
 				stream = classLoader.getResourceAsStream( stripped );
 			}
 		}
 
 		if ( stream == null ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( resource );
 		}
 		if ( stream == null && hasLeadingSlash ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( stripped );
 		}
 
 		if ( stream == null ) {
 			throw new HibernateException( resource + " not found" );
 		}
 
 		return stream;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/EntityPrinter.java b/hibernate-core/src/main/java/org/hibernate/internal/util/EntityPrinter.java
index df357d7d14..5cfce5f089 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/EntityPrinter.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/EntityPrinter.java
@@ -1,128 +1,129 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.TypedValue;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * Renders entities and query parameters to a nicely readable string.
  * @author Gavin King
  */
 public final class EntityPrinter {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityPrinter.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( EntityPrinter.class );
 
     private SessionFactoryImplementor factory;
 
 	/**
 	 * Renders an entity to a string.
 	 *
 	 * @param entityName the entity name
 	 * @param entity an actual entity object, not a proxy!
 	 * @return the entity rendered to a string
 	 */
 	public String toString(String entityName, Object entity) throws HibernateException {
 		EntityPersister entityPersister = factory.getEntityPersister( entityName );
 
 		if ( entityPersister == null ) {
 			return entity.getClass().getName();
 		}
 
 		Map<String,String> result = new HashMap<String,String>();
 
 		if ( entityPersister.hasIdentifierProperty() ) {
 			result.put(
 				entityPersister.getIdentifierPropertyName(),
 				entityPersister.getIdentifierType().toLoggableString( entityPersister.getIdentifier( entity ), factory )
 			);
 		}
 
 		Type[] types = entityPersister.getPropertyTypes();
 		String[] names = entityPersister.getPropertyNames();
 		Object[] values = entityPersister.getPropertyValues( entity );
 		for ( int i=0; i<types.length; i++ ) {
 			if ( !names[i].startsWith("_") ) {
 				String strValue = values[i]==LazyPropertyInitializer.UNFETCHED_PROPERTY ?
 					values[i].toString() :
 					types[i].toLoggableString( values[i], factory );
 				result.put( names[i], strValue );
 			}
 		}
 		return entityName + result.toString();
 	}
 
 	public String toString(Type[] types, Object[] values) throws HibernateException {
 		StringBuilder buffer = new StringBuilder();
 		for ( int i=0; i<types.length; i++ ) {
 			if ( types[i]!=null ) {
 				buffer.append( types[i].toLoggableString( values[i], factory ) ).append( ", " );
 			}
 		}
 		return buffer.toString();
 	}
 
 	public String toString(Map<String,TypedValue> namedTypedValues) throws HibernateException {
 		Map<String,String> result = new HashMap<String,String>();
 		for ( Map.Entry<String, TypedValue> entry : namedTypedValues.entrySet() ) {
 			result.put(
 					entry.getKey(), entry.getValue().getType().toLoggableString(
-					entry.getValue().getValue(),
-					factory
-			)
+							entry.getValue().getValue(),
+							factory
+					)
 			);
 		}
 		return result.toString();
 	}
 
 	// Cannot use Map as an argument because it clashes with the previous method (due to type erasure)
 	public void toString(Iterable<Map.Entry<EntityKey,Object>> entitiesByEntityKey) throws HibernateException {
-        if ( ! LOG.isDebugEnabled() || ! entitiesByEntityKey.iterator().hasNext() ) return;
+        if ( ! LOG.isDebugEnabled() || ! entitiesByEntityKey.iterator().hasNext() ) {
+			return;
+		}
+
         LOG.debug( "Listing entities:" );
 		int i=0;
 		for (  Map.Entry<EntityKey,Object> entityKeyAndEntity : entitiesByEntityKey ) {
 			if (i++>20) {
                 LOG.debug("More......");
 				break;
 			}
             LOG.debug( toString( entityKeyAndEntity.getKey().getEntityName(), entityKeyAndEntity.getValue() ) );
 		}
 	}
 
 	public EntityPrinter(SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
index 4f5b59a299..d94fbf393c 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
@@ -1,378 +1,380 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.ObjectStreamClass;
 import java.io.OutputStream;
 import java.io.Serializable;
 
 import org.hibernate.Hibernate;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.SerializationException;
 
 import org.jboss.logging.Logger;
 
 /**
  * <p>Assists with the serialization process and performs additional functionality based
  * on serialization.</p>
  * <p>
  * <ul>
  * <li>Deep clone using serialization
  * <li>Serialize managing finally and IOException
  * <li>Deserialize managing finally and IOException
  * </ul>
  *
  * <p>This class throws exceptions for invalid <code>null</code> inputs.
  * Each method documents its behaviour in more detail.</p>
  *
  * @author <a href="mailto:nissim@nksystems.com">Nissim Karpenstein</a>
  * @author <a href="mailto:janekdb@yahoo.co.uk">Janek Bogucki</a>
  * @author <a href="mailto:dlr@finemaltcoding.com">Daniel Rall</a>
  * @author Stephen Colebourne
  * @author Jeff Varszegi
  * @author Gary Gregory
  * @version $Id: SerializationHelper.java 9180 2006-01-30 23:51:27Z steveebersole $
  * @since 1.0
  */
 public final class SerializationHelper {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SerializationHelper.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SerializationHelper.class );
 
 	private SerializationHelper() {
 	}
 
 	// Clone
 	//-----------------------------------------------------------------------
 
 	/**
 	 * <p>Deep clone an <code>Object</code> using serialization.</p>
 	 *
 	 * <p>This is many times slower than writing clone methods by hand
 	 * on all objects in your object graph. However, for complex object
 	 * graphs, or for those that don't support deep cloning this can
 	 * be a simple alternative implementation. Of course all the objects
 	 * must be <code>Serializable</code>.</p>
 	 *
 	 * @param object the <code>Serializable</code> object to clone
 	 *
 	 * @return the cloned object
 	 *
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object clone(Serializable object) throws SerializationException {
 		LOG.trace( "Starting clone through serialization" );
 		if ( object == null ) {
 			return null;
 		}
 		return deserialize( serialize( object ), object.getClass().getClassLoader() );
 	}
 
 	// Serialize
 	//-----------------------------------------------------------------------
 
 	/**
 	 * <p>Serializes an <code>Object</code> to the specified stream.</p>
 	 *
 	 * <p>The stream will be closed once the object is written.
 	 * This avoids the need for a finally clause, and maybe also exception
 	 * handling, in the application code.</p>
 	 *
 	 * <p>The stream passed in is not buffered internally within this method.
 	 * This is the responsibility of your application if desired.</p>
 	 *
 	 * @param obj the object to serialize to bytes, may be null
 	 * @param outputStream the stream to write to, must not be null
 	 *
 	 * @throws IllegalArgumentException if <code>outputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static void serialize(Serializable obj, OutputStream outputStream) throws SerializationException {
 		if ( outputStream == null ) {
 			throw new IllegalArgumentException( "The OutputStream must not be null" );
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			if ( Hibernate.isInitialized( obj ) ) {
 				LOG.tracev( "Starting serialization of object [{0}]", obj );
 			}
 			else {
 				LOG.trace( "Starting serialization of [uninitialized proxy]" );
 			}
 		}
 
 		ObjectOutputStream out = null;
 		try {
 			// stream closed in the finally
 			out = new ObjectOutputStream( outputStream );
 			out.writeObject( obj );
 
 		}
 		catch ( IOException ex ) {
 			throw new SerializationException( "could not serialize", ex );
 		}
 		finally {
 			try {
 				if ( out != null ) {
 					out.close();
 				}
 			}
 			catch ( IOException ignored ) {
 			}
 		}
 	}
 
 	/**
 	 * <p>Serializes an <code>Object</code> to a byte array for
 	 * storage/serialization.</p>
 	 *
 	 * @param obj the object to serialize to bytes
 	 *
 	 * @return a byte[] with the converted Serializable
 	 *
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static byte[] serialize(Serializable obj) throws SerializationException {
 		ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream( 512 );
 		serialize( obj, byteArrayOutputStream );
 		return byteArrayOutputStream.toByteArray();
 	}
 
 	// Deserialize
 	//-----------------------------------------------------------------------
 
 	/**
 	 * Deserializes an object from the specified stream using the Thread Context
 	 * ClassLoader (TCCL).
 	 * <p/>
 	 * Delegates to {@link #doDeserialize}
 	 *
 	 * @param inputStream the serialized object input stream, must not be null
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>inputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static <T> T deserialize(InputStream inputStream) throws SerializationException {
 		return doDeserialize( inputStream, defaultClassLoader(), hibernateClassLoader(), null );
 	}
 
 	/**
 	 * Returns the Thread Context ClassLoader (TCCL).
 	 *
 	 * @return The current TCCL
 	 */
 	public static ClassLoader defaultClassLoader() {
 		return ClassLoaderHelper.getContextClassLoader();
 	}
 
 	public static ClassLoader hibernateClassLoader() {
 		return SerializationHelper.class.getClassLoader();
 	}
 
 	/**
 	 * Deserializes an object from the specified stream using the Thread Context
 	 * ClassLoader (TCCL).  If there is no TCCL set, the classloader of the calling
 	 * class is used.
 	 * <p/>
 	 * The stream will be closed once the object is read. This avoids the need
 	 * for a finally clause, and maybe also exception handling, in the application
 	 * code.
 	 * <p/>
 	 * The stream passed in is not buffered internally within this method.  This is
 	 * the responsibility of the caller, if desired.
 	 *
 	 * @param inputStream the serialized object input stream, must not be null
 	 * @param loader The classloader to use
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>inputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(InputStream inputStream, ClassLoader loader) throws SerializationException {
 		return doDeserialize( inputStream, loader, defaultClassLoader(), hibernateClassLoader() );
 	}
 
 	@SuppressWarnings("unchecked")
 	public static <T> T doDeserialize(
 			InputStream inputStream,
 			ClassLoader loader,
 			ClassLoader fallbackLoader1,
 			ClassLoader fallbackLoader2) throws SerializationException {
 		if ( inputStream == null ) {
 			throw new IllegalArgumentException( "The InputStream must not be null" );
 		}
 
 		LOG.trace( "Starting deserialization of object" );
 
 		try {
 			CustomObjectInputStream in = new CustomObjectInputStream(
 					inputStream,
 					loader,
 					fallbackLoader1,
 					fallbackLoader2
 			);
 			try {
 				return (T) in.readObject();
 			}
 			catch ( ClassNotFoundException e ) {
 				throw new SerializationException( "could not deserialize", e );
 			}
 			catch ( IOException e ) {
 				throw new SerializationException( "could not deserialize", e );
 			}
 			finally {
 				try {
 					in.close();
 				}
 				catch ( IOException ignore ) {
 					// ignore
 				}
 			}
 		}
 		catch ( IOException e ) {
 			throw new SerializationException( "could not deserialize", e );
 		}
 	}
 
 	/**
 	 * Deserializes an object from an array of bytes using the Thread Context
 	 * ClassLoader (TCCL).  If there is no TCCL set, the classloader of the calling
 	 * class is used.
 	 * <p/>
 	 * Delegates to {@link #deserialize(byte[], ClassLoader)}
 	 *
 	 * @param objectData the serialized object, must not be null
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>objectData</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(byte[] objectData) throws SerializationException {
 		return doDeserialize( wrap( objectData ), defaultClassLoader(), hibernateClassLoader(), null );
 	}
 
 	private static InputStream wrap(byte[] objectData) {
 		if ( objectData == null ) {
 			throw new IllegalArgumentException( "The byte[] must not be null" );
 		}
 		return new ByteArrayInputStream( objectData );
 	}
 
 	/**
 	 * Deserializes an object from an array of bytes.
 	 * <p/>
 	 * Delegates to {@link #deserialize(java.io.InputStream, ClassLoader)} using a
 	 * {@link ByteArrayInputStream} to wrap the array.
 	 *
 	 * @param objectData the serialized object, must not be null
 	 * @param loader The classloader to use
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>objectData</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(byte[] objectData, ClassLoader loader) throws SerializationException {
 		return doDeserialize( wrap( objectData ), loader, defaultClassLoader(), hibernateClassLoader() );
 	}
 
 
 	/**
 	 * By default, to resolve the classes being deserialized JDK serialization uses the
 	 * classes loader which loaded the class which initiated the deserialization call.  Here
 	 * that would be hibernate classes.  However, there are cases where that is not the correct
 	 * class loader to use; mainly here we are worried about deserializing user classes in
 	 * environments (app servers, etc) where Hibernate is on a parent classes loader.  To
 	 * facilitate for that we allow passing in the class loader we should use.
 	 */
 	private static final class CustomObjectInputStream extends ObjectInputStream {
 		private final ClassLoader loader1;
 		private final ClassLoader loader2;
 		private final ClassLoader loader3;
 
 		private CustomObjectInputStream(
 				InputStream in,
 				ClassLoader loader1,
 				ClassLoader loader2,
 				ClassLoader loader3) throws IOException {
 			super( in );
 			this.loader1 = loader1;
 			this.loader2 = loader2;
 			this.loader3 = loader3;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		@Override
 		protected Class resolveClass(ObjectStreamClass v) throws IOException, ClassNotFoundException {
 			final String className = v.getName();
 			LOG.tracev( "Attempting to locate class [{0}]", className );
 
 			try {
 				return Class.forName( className, false, loader1 );
 			}
 			catch ( ClassNotFoundException e ) {
 				LOG.trace( "Unable to locate class using given classloader" );
 			}
 
 			if ( different( loader1, loader2 ) ) {
 				try {
 					return Class.forName( className, false, loader2 );
 				}
 				catch ( ClassNotFoundException e ) {
 					LOG.trace( "Unable to locate class using given classloader" );
 				}
 			}
 
 			if ( different( loader1, loader3 ) && different( loader2, loader3 ) ) {
 				try {
 					return Class.forName( className, false, loader3 );
 				}
 				catch ( ClassNotFoundException e ) {
 					LOG.trace( "Unable to locate class using given classloader" );
 				}
 			}
 
 			// By default delegate to normal JDK deserialization which will use the class loader
 			// of the class which is calling this deserialization.
 			return super.resolveClass( v );
 		}
 
 		private boolean different(ClassLoader one, ClassLoader other) {
-            if (one == null) return other != null;
+            if (one == null) {
+				return other != null;
+			}
             return !one.equals(other);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
index 0016bdc82f..226092c73b 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
@@ -1,782 +1,788 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.BitSet;
 import java.util.Iterator;
 import java.util.Locale;
 import java.util.StringTokenizer;
 
 public final class StringHelper {
 
 	private static final int ALIAS_TRUNCATE_LENGTH = 10;
 	public static final String WHITESPACE = " \n\r\f\t";
 	public static final String[] EMPTY_STRINGS = new String[0];
 
 	private StringHelper() { /* static methods only - hide constructor */
 	}
-	
-	/*public static boolean containsDigits(String string) {
-		for ( int i=0; i<string.length(); i++ ) {
-			if ( Character.isDigit( string.charAt(i) ) ) return true;
-		}
-		return false;
-	}*/
 
 	public static int lastIndexOfLetter(String string) {
 		for ( int i=0; i<string.length(); i++ ) {
 			char character = string.charAt(i);
 			// Include "_".  See HHH-8073
-			if ( !Character.isLetter(character) && !('_'==character) ) return i-1;
+			if ( !Character.isLetter(character) && !('_'==character) ) {
+				return i-1;
+			}
 		}
 		return string.length()-1;
 	}
 
 	public static String join(String seperator, String[] strings) {
 		int length = strings.length;
-		if ( length == 0 ) return "";
+		if ( length == 0 ) {
+			return "";
+		}
 		StringBuilder buf = new StringBuilder( length * strings[0].length() )
 				.append( strings[0] );
 		for ( int i = 1; i < length; i++ ) {
 			buf.append( seperator ).append( strings[i] );
 		}
 		return buf.toString();
 	}
 
 	public static String joinWithQualifierAndSuffix(String[] values, String qualifier, String suffix, String deliminator) {
 		int length = values.length;
-		if ( length == 0 ) return "";
+		if ( length == 0 ) {
+			return "";
+		}
 		StringBuilder buf = new StringBuilder( length * ( values[0].length() + suffix.length() ) )
 				.append( qualify( qualifier, values[0] ) ).append( suffix );
 		for ( int i = 1; i < length; i++ ) {
 			buf.append( deliminator ).append( qualify( qualifier, values[i] ) ).append( suffix );
 		}
 		return buf.toString();
 	}
 
 	public static String join(String seperator, Iterator objects) {
 		StringBuilder buf = new StringBuilder();
-		if ( objects.hasNext() ) buf.append( objects.next() );
+		if ( objects.hasNext() ) {
+			buf.append( objects.next() );
+		}
 		while ( objects.hasNext() ) {
 			buf.append( seperator ).append( objects.next() );
 		}
 		return buf.toString();
 	}
 
 	public static String join(String separator, Iterable objects) {
 		return join( separator, objects.iterator() );
 	}
 
 	public static String[] add(String[] x, String sep, String[] y) {
 		final String[] result = new String[x.length];
 		for ( int i = 0; i < x.length; i++ ) {
 			result[i] = x[i] + sep + y[i];
 		}
 		return result;
 	}
 
 	public static String repeat(String string, int times) {
 		StringBuilder buf = new StringBuilder( string.length() * times );
-		for ( int i = 0; i < times; i++ ) buf.append( string );
+		for ( int i = 0; i < times; i++ ) {
+			buf.append( string );
+		}
 		return buf.toString();
 	}
 
 	public static String repeat(String string, int times, String deliminator) {
 		StringBuilder buf = new StringBuilder(  ( string.length() * times ) + ( deliminator.length() * (times-1) ) )
 				.append( string );
 		for ( int i = 1; i < times; i++ ) {
 			buf.append( deliminator ).append( string );
 		}
 		return buf.toString();
 	}
 
 	public static String repeat(char character, int times) {
 		char[] buffer = new char[times];
 		Arrays.fill( buffer, character );
 		return new String( buffer );
 	}
 
 
 	public static String replace(String template, String placeholder, String replacement) {
 		return replace( template, placeholder, replacement, false );
 	}
 
 	public static String[] replace(String[] templates, String placeholder, String replacement) {
 		String[] result = new String[templates.length];
 		for ( int i =0; i<templates.length; i++ ) {
 			result[i] = replace( templates[i], placeholder, replacement );
 		}
 		return result;
 	}
 
 	public static String replace(String template, String placeholder, String replacement, boolean wholeWords) {
 		return replace( template, placeholder, replacement, wholeWords, false );
 	}
 
-	public static String replace(String template,
-								 String placeholder,
-								 String replacement,
-								 boolean wholeWords,
-								 boolean encloseInParensIfNecessary) {
+	public static String replace(
+			String template,
+			String placeholder,
+			String replacement,
+			boolean wholeWords,
+			boolean encloseInParensIfNecessary) {
 		if ( template == null ) {
-			return template;
+			return null;
 		}
 		int loc = template.indexOf( placeholder );
 		if ( loc < 0 ) {
 			return template;
 		}
 		else {
 			String beforePlaceholder = template.substring( 0, loc );
 			String afterPlaceholder = template.substring( loc + placeholder.length() );
 			return replace( beforePlaceholder, afterPlaceholder, placeholder, replacement, wholeWords, encloseInParensIfNecessary );
 		}
 	}
 
 
-	public static String replace(String beforePlaceholder,
-								 String afterPlaceholder,
-								 String placeholder,
-								 String replacement,
-								 boolean wholeWords,
-								 boolean encloseInParensIfNecessary) {
+	public static String replace(
+			String beforePlaceholder,
+			String afterPlaceholder,
+			String placeholder,
+			String replacement,
+			boolean wholeWords,
+			boolean encloseInParensIfNecessary) {
 		final boolean actuallyReplace =
-				! wholeWords ||
-				afterPlaceholder.length() == 0 ||
-				! Character.isJavaIdentifierPart( afterPlaceholder.charAt( 0 ) );
+				! wholeWords
+						|| afterPlaceholder.length() == 0
+						|| ! Character.isJavaIdentifierPart( afterPlaceholder.charAt( 0 ) );
 		boolean encloseInParens =
-				actuallyReplace &&
-				encloseInParensIfNecessary &&
-				! ( getLastNonWhitespaceCharacter( beforePlaceholder ) == '(' ) &&
-				! ( getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')' );		
+				actuallyReplace
+						&& encloseInParensIfNecessary
+						&& ! ( getLastNonWhitespaceCharacter( beforePlaceholder ) == '(' )
+						&& ! ( getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')' );
 		StringBuilder buf = new StringBuilder( beforePlaceholder );
 		if ( encloseInParens ) {
 			buf.append( '(' );
 		}
 		buf.append( actuallyReplace ? replacement : placeholder );
 		if ( encloseInParens ) {
 			buf.append( ')' );
 		}
 		buf.append(
 				replace(
 						afterPlaceholder,
 						placeholder,
 						replacement,
 						wholeWords,
 						encloseInParensIfNecessary
 				)
 		);
 		return buf.toString();
 	}
 
 	public static char getLastNonWhitespaceCharacter(String str) {
 		if ( str != null && str.length() > 0 ) {
 			for ( int i = str.length() - 1 ; i >= 0 ; i-- ) {
 				char ch = str.charAt( i );
 				if ( ! Character.isWhitespace( ch ) ) {
 					return ch;
 				}
 			}
 		}
 		return '\0';
 	}
 
 	public static char getFirstNonWhitespaceCharacter(String str) {
 		if ( str != null && str.length() > 0 ) {
 			for ( int i = 0 ; i < str.length() ; i++ ) {
 				char ch = str.charAt( i );
 				if ( ! Character.isWhitespace( ch ) ) {
 					return ch;
 				}
 			}
 		}
 		return '\0';
 	}
 
 	public static String replaceOnce(String template, String placeholder, String replacement) {
 		if ( template == null ) {
-			return template; // returnign null!
+			return null;  // returnign null!
 		}
         int loc = template.indexOf( placeholder );
 		if ( loc < 0 ) {
 			return template;
 		}
 		else {
-			return new StringBuilder( template.substring( 0, loc ) )
-					.append( replacement )
-					.append( template.substring( loc + placeholder.length() ) )
-					.toString();
+			return template.substring( 0, loc ) + replacement + template.substring( loc + placeholder.length() );
 		}
 	}
 
 
 	public static String[] split(String seperators, String list) {
 		return split( seperators, list, false );
 	}
 
 	public static String[] split(String seperators, String list, boolean include) {
 		StringTokenizer tokens = new StringTokenizer( list, seperators, include );
 		String[] result = new String[ tokens.countTokens() ];
 		int i = 0;
 		while ( tokens.hasMoreTokens() ) {
 			result[i++] = tokens.nextToken();
 		}
 		return result;
 	}
 
 	public static String unqualify(String qualifiedName) {
 		int loc = qualifiedName.lastIndexOf(".");
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc + 1 );
 	}
 
 	public static String qualifier(String qualifiedName) {
 		int loc = qualifiedName.lastIndexOf(".");
 		return ( loc < 0 ) ? "" : qualifiedName.substring( 0, loc );
 	}
 
 	/**
 	 * Collapses a name.  Mainly intended for use with classnames, where an example might serve best to explain.
 	 * Imagine you have a class named <samp>'org.hibernate.internal.util.StringHelper'</samp>; calling collapse on that
 	 * classname will result in <samp>'o.h.u.StringHelper'<samp>.
 	 *
 	 * @param name The name to collapse.
 	 * @return The collapsed name.
 	 */
 	public static String collapse(String name) {
 		if ( name == null ) {
 			return null;
 		}
 		int breakPoint = name.lastIndexOf( '.' );
 		if ( breakPoint < 0 ) {
 			return name;
 		}
 		return collapseQualifier( name.substring( 0, breakPoint ), true ) + name.substring( breakPoint ); // includes last '.'
 	}
 
 	/**
 	 * Given a qualifier, collapse it.
 	 *
 	 * @param qualifier The qualifier to collapse.
 	 * @param includeDots Should we include the dots in the collapsed form?
 	 *
 	 * @return The collapsed form.
 	 */
 	public static String collapseQualifier(String qualifier, boolean includeDots) {
 		StringTokenizer tokenizer = new StringTokenizer( qualifier, "." );
 		String collapsed = Character.toString( tokenizer.nextToken().charAt( 0 ) );
 		while ( tokenizer.hasMoreTokens() ) {
 			if ( includeDots ) {
 				collapsed += '.';
 			}
 			collapsed += tokenizer.nextToken().charAt( 0 );
 		}
 		return collapsed;
 	}
 
 	/**
 	 * Partially unqualifies a qualified name.  For example, with a base of 'org.hibernate' the name
 	 * 'org.hibernate.internal.util.StringHelper' would become 'util.StringHelper'.
 	 *
 	 * @param name The (potentially) qualified name.
 	 * @param qualifierBase The qualifier base.
 	 *
 	 * @return The name itself, or the partially unqualified form if it begins with the qualifier base.
 	 */
 	public static String partiallyUnqualify(String name, String qualifierBase) {
 		if ( name == null || ! name.startsWith( qualifierBase ) ) {
 			return name;
 		}
 		return name.substring( qualifierBase.length() + 1 ); // +1 to start after the following '.'
 	}
 
 	/**
 	 * Cross between {@link #collapse} and {@link #partiallyUnqualify}.  Functions much like {@link #collapse}
 	 * except that only the qualifierBase is collapsed.  For example, with a base of 'org.hibernate' the name
 	 * 'org.hibernate.internal.util.StringHelper' would become 'o.h.util.StringHelper'.
 	 *
 	 * @param name The (potentially) qualified name.
 	 * @param qualifierBase The qualifier base.
 	 *
 	 * @return The name itself if it does not begin with the qualifierBase, or the properly collapsed form otherwise.
 	 */
 	public static String collapseQualifierBase(String name, String qualifierBase) {
 		if ( name == null || ! name.startsWith( qualifierBase ) ) {
 			return collapse( name );
 		}
 		return collapseQualifier( qualifierBase, true ) + name.substring( qualifierBase.length() );
 	}
 
 	public static String[] suffix(String[] columns, String suffix) {
 		if ( suffix == null ) return columns;
 		String[] qualified = new String[columns.length];
 		for ( int i = 0; i < columns.length; i++ ) {
 			qualified[i] = suffix( columns[i], suffix );
 		}
 		return qualified;
 	}
 
 	private static String suffix(String name, String suffix) {
 		return ( suffix == null ) ? name : name + suffix;
 	}
 
 	public static String root(String qualifiedName) {
 		int loc = qualifiedName.indexOf( "." );
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( 0, loc );
 	}
 
 	public static String unroot(String qualifiedName) {
 		int loc = qualifiedName.indexOf( "." );
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc+1, qualifiedName.length() );
 	}
 
 	public static boolean booleanValue(String tfString) {
-		String trimmed = tfString.trim().toLowerCase(Locale.ROOT);
+		String trimmed = tfString.trim().toLowerCase( Locale.ROOT );
 		return trimmed.equals( "true" ) || trimmed.equals( "t" );
 	}
 
 	public static String toString(Object[] array) {
 		int len = array.length;
-		if ( len == 0 ) return "";
+		if ( len == 0 ) {
+			return "";
+		}
 		StringBuilder buf = new StringBuilder( len * 12 );
 		for ( int i = 0; i < len - 1; i++ ) {
 			buf.append( array[i] ).append(", ");
 		}
 		return buf.append( array[len - 1] ).toString();
 	}
 
 	public static String[] multiply(String string, Iterator placeholders, Iterator replacements) {
 		String[] result = new String[]{string};
 		while ( placeholders.hasNext() ) {
 			result = multiply( result, ( String ) placeholders.next(), ( String[] ) replacements.next() );
 		}
 		return result;
 	}
 
 	private static String[] multiply(String[] strings, String placeholder, String[] replacements) {
 		String[] results = new String[replacements.length * strings.length];
 		int n = 0;
-		for ( int i = 0; i < replacements.length; i++ ) {
-			for ( int j = 0; j < strings.length; j++ ) {
-				results[n++] = replaceOnce( strings[j], placeholder, replacements[i] );
+		for ( String replacement : replacements ) {
+			for ( String string : strings ) {
+				results[n++] = replaceOnce( string, placeholder, replacement );
 			}
 		}
 		return results;
 	}
 
 	public static int countUnquoted(String string, char character) {
 		if ( '\'' == character ) {
 			throw new IllegalArgumentException( "Unquoted count of quotes is invalid" );
 		}
 		if (string == null)
 			return 0;
 		// Impl note: takes advantage of the fact that an escpaed single quote
 		// embedded within a quote-block can really be handled as two seperate
 		// quote-blocks for the purposes of this method...
 		int count = 0;
 		int stringLength = string.length();
 		boolean inQuote = false;
 		for ( int indx = 0; indx < stringLength; indx++ ) {
 			char c = string.charAt( indx );
 			if ( inQuote ) {
 				if ( '\'' == c ) {
 					inQuote = false;
 				}
 			}
 			else if ( '\'' == c ) {
 				inQuote = true;
 			}
 			else if ( c == character ) {
 				count++;
 			}
 		}
 		return count;
 	}
 
 	public static int[] locateUnquoted(String string, char character) {
 		if ( '\'' == character ) {
 			throw new IllegalArgumentException( "Unquoted count of quotes is invalid" );
 		}
 		if (string == null) {
 			return new int[0];
 		}
 
 		ArrayList locations = new ArrayList( 20 );
 
 		// Impl note: takes advantage of the fact that an escpaed single quote
 		// embedded within a quote-block can really be handled as two seperate
 		// quote-blocks for the purposes of this method...
 		int stringLength = string.length();
 		boolean inQuote = false;
 		for ( int indx = 0; indx < stringLength; indx++ ) {
 			char c = string.charAt( indx );
 			if ( inQuote ) {
 				if ( '\'' == c ) {
 					inQuote = false;
 				}
 			}
 			else if ( '\'' == c ) {
 				inQuote = true;
 			}
 			else if ( c == character ) {
 				locations.add( indx );
 			}
 		}
 		return ArrayHelper.toIntArray( locations );
 	}
 
 	public static boolean isNotEmpty(String string) {
 		return string != null && string.length() > 0;
 	}
 
 	public static boolean isEmpty(String string) {
 		return string == null || string.length() == 0;
 	}
 
 	public static boolean isEmptyOrWhiteSpace(String string){
 		return isEmpty( string ) || isEmpty( string.trim() );
 	}
 
 	public static String qualify(String prefix, String name) {
 		if ( name == null || prefix == null ) {
 			throw new NullPointerException( "prefix or name were null attempting to build qualified name" );
 		}
 		return prefix + '.' + name;
 	}
 
 	public static String[] qualify(String prefix, String[] names) {
 		if ( prefix == null ) {
 			return names;
 		}
 		int len = names.length;
 		String[] qualified = new String[len];
 		for ( int i = 0; i < len; i++ ) {
 			qualified[i] = qualify( prefix, names[i] );
 		}
 		return qualified;
 	}
 
 	public static String[] qualifyIfNot(String prefix, String[] names) {
 		if ( prefix == null ) {
 			return names;
 		}
 		int len = names.length;
 		String[] qualified = new String[len];
 		for ( int i = 0; i < len; i++ ) {
 			if ( names[i].indexOf( '.' ) < 0 ) {
 				qualified[i] = qualify( prefix, names[i] );
 			}
 			else {
 				qualified[i] = names[i];
 			}
 		}
 		return qualified;
 	}
 
 	public static int firstIndexOfChar(String sqlString, BitSet keys, int startindex) {
 		for ( int i = startindex, size = sqlString.length(); i < size; i++ ) {
 			if ( keys.get( sqlString.charAt( i ) ) ) {
 				return i;
 			}
 		}
 		return -1;
 
 	}
 
 	public static int firstIndexOfChar(String sqlString, String string, int startindex) {
 		BitSet keys = new BitSet();
 		for ( int i = 0, size = string.length(); i < size; i++ ) {
 			keys.set( string.charAt( i ) );
 		}
 		return firstIndexOfChar( sqlString, keys, startindex );
 
 	}
 
 	public static String truncate(String string, int length) {
 		if ( string.length() <= length ) {
 			return string;
 		}
 		else {
 			return string.substring( 0, length );
 		}
 	}
 
 	public static String generateAlias(String description) {
 		return generateAliasRoot(description) + '_';
 	}
 
 	/**
 	 * Generate a nice alias for the given class name or collection role name and unique integer. Subclasses of
 	 * Loader do <em>not</em> have to use aliases of this form.
 	 *
 	 * @param description The base name (usually an entity-name or collection-role)
 	 * @param unique A uniquing value
 	 *
 	 * @return an alias of the form <samp>foo1_</samp>
 	 */
 	public static String generateAlias(String description, int unique) {
-		return generateAliasRoot(description) +
-			Integer.toString(unique) +
-			'_';
+		return generateAliasRoot(description)
+				+ Integer.toString(unique)
+				+ '_';
 	}
 
 	/**
 	 * Generates a root alias by truncating the "root name" defined by
 	 * the incoming decription and removing/modifying any non-valid
 	 * alias characters.
 	 *
 	 * @param description The root name from which to generate a root alias.
 	 * @return The generated root alias.
 	 */
 	private static String generateAliasRoot(String description) {
 		String result = truncate( unqualifyEntityName(description), ALIAS_TRUNCATE_LENGTH )
 				.toLowerCase(Locale.ROOT)
 		        .replace( '/', '_' ) // entityNames may now include slashes for the representations
 				.replace( '$', '_' ); //classname may be an inner class
 		result = cleanAlias( result );
 		if ( Character.isDigit( result.charAt(result.length()-1) ) ) {
 			return result + "x"; //ick!
 		}
 		else {
 			return result;
 		}
 	}
 
 	/**
 	 * Clean the generated alias by removing any non-alpha characters from the
 	 * beginning.
 	 *
 	 * @param alias The generated alias to be cleaned.
 	 * @return The cleaned alias, stripped of any leading non-alpha characters.
 	 */
 	private static String cleanAlias(String alias) {
 		char[] chars = alias.toCharArray();
 		// short cut check...
 		if ( !Character.isLetter( chars[0] ) ) {
 			for ( int i = 1; i < chars.length; i++ ) {
 				// as soon as we encounter our first letter, return the substring
 				// from that position
 				if ( Character.isLetter( chars[i] ) ) {
 					return alias.substring( i );
 				}
 			}
 		}
 		return alias;
 	}
 
 	public static String unqualifyEntityName(String entityName) {
 		String result = unqualify(entityName);
 		int slashPos = result.indexOf( '/' );
 		if ( slashPos > 0 ) {
 			result = result.substring( 0, slashPos - 1 );
 		}
 		return result;
 	}
 
 	public static String moveAndToBeginning(String filter) {
 		if ( filter.trim().length()>0 ){
 			filter += " and ";
-			if ( filter.startsWith(" and ") ) filter = filter.substring(4);
+			if ( filter.startsWith(" and ") ) {
+				filter = filter.substring(4);
+			}
 		}
 		return filter;
 	}
 
 	/**
 	 * Determine if the given string is quoted (wrapped by '`' characters at beginning and end).
 	 *
 	 * @param name The name to check.
 	 * @return True if the given string starts and ends with '`'; false otherwise.
 	 */
 	public static boolean isQuoted(String name) {
 		return name != null && name.length() != 0 
 				&& ( ( name.charAt( 0 ) == '`' && name.charAt( name.length() - 1 ) == '`' )
 						|| ( name.charAt( 0 ) == '"' && name.charAt( name.length() - 1 ) == '"' ) );
 	}
 
 	/**
 	 * Return a representation of the given name ensuring quoting (wrapped with '`' characters).  If already wrapped
 	 * return name.
 	 *
 	 * @param name The name to quote.
 	 * @return The quoted version.
 	 */
 	public static String quote(String name) {
 		if ( isEmpty( name ) || isQuoted( name ) ) {
 			return name;
 		}
 		// Convert the JPA2 specific quoting character (double quote) to Hibernate's (back tick)
         else if ( name.startsWith( "\"" ) && name.endsWith( "\"" ) ) {
             name = name.substring( 1, name.length() - 1 );
         }
 
-		return new StringBuilder( name.length() + 2 ).append('`').append( name ).append( '`' ).toString();
+		return "`" + name + '`';
 	}
 
 	/**
 	 * Return the unquoted version of name (stripping the start and end '`' characters if present).
 	 *
 	 * @param name The name to be unquoted.
 	 * @return The unquoted version.
 	 */
 	public static String unquote(String name) {
 		return isQuoted( name ) ? name.substring( 1, name.length() - 1 ) : name;
 	}
 
 	/**
 	 * Determine if the given name is quoted.  It is considered quoted if either:
 	 * <ol>
 	 * <li>starts AND ends with backticks (`)</li>
 	 * <li>starts with dialect-specified {@link org.hibernate.dialect.Dialect#openQuote() open-quote}
 	 * 		AND ends with dialect-specified {@link org.hibernate.dialect.Dialect#closeQuote() close-quote}</li>
 	 * </ol>
 	 *
 	 * @param name The name to check
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return True if quoted, false otherwise
 	 */
 	public static boolean isQuoted(String name, Dialect dialect) {
 		return name != null && name.length() != 0 
 				&& ( ( name.charAt( 0 ) == '`' && name.charAt( name.length() - 1 ) == '`' )
 						|| ( name.charAt( 0 ) == '"' && name.charAt( name.length() - 1 ) == '"' )
 						|| ( name.charAt( 0 ) == dialect.openQuote()
 								&& name.charAt( name.length() - 1 ) == dialect.closeQuote() ) );
 	}
 
 	/**
 	 * Return the unquoted version of name stripping the start and end quote characters.
 	 *
 	 * @param name The name to be unquoted.
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return The unquoted version.
 	 */
 	public static String unquote(String name, Dialect dialect) {
 		return isQuoted( name, dialect ) ? name.substring( 1, name.length() - 1 ) : name;
 	}
 
 	/**
 	 * Return the unquoted version of name stripping the start and end quote characters.
 	 *
 	 * @param names The names to be unquoted.
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return The unquoted versions.
 	 */
 	public static String[] unquote(String[] names, Dialect dialect) {
 		if ( names == null ) {
 			return null;
 		}
 		String[] unquoted = new String[ names.length ];
 		for ( int i = 0; i < names.length; i++ ) {
 			unquoted[i] = unquote( names[i], dialect );
 		}
 		return unquoted;
 	}
 
 
 	public static final String BATCH_ID_PLACEHOLDER = "$$BATCH_ID_PLACEHOLDER$$";
 
 	public static StringBuilder buildBatchFetchRestrictionFragment(
 			String alias,
 			String[] columnNames,
 			Dialect dialect) {
 		// the general idea here is to just insert a placeholder that we can easily find later...
 		if ( columnNames.length == 1 ) {
 			// non-composite key
 			return new StringBuilder( StringHelper.qualify( alias, columnNames[0] ) )
 					.append( " in (" ).append( BATCH_ID_PLACEHOLDER ).append( ")" );
 		}
 		else {
 			// composite key - the form to use here depends on what the dialect supports.
 			if ( dialect.supportsRowValueConstructorSyntaxInInList() ) {
 				// use : (col1, col2) in ( (?,?), (?,?), ... )
 				StringBuilder builder = new StringBuilder();
 				builder.append( "(" );
 				boolean firstPass = true;
 				String deliminator = "";
 				for ( String columnName : columnNames ) {
 					builder.append( deliminator ).append( StringHelper.qualify( alias, columnName ) );
 					if ( firstPass ) {
 						firstPass = false;
 						deliminator = ",";
 					}
 				}
 				builder.append( ") in (" );
 				builder.append( BATCH_ID_PLACEHOLDER );
 				builder.append( ")" );
 				return builder;
 			}
 			else {
 				// use : ( (col1 = ? and col2 = ?) or (col1 = ? and col2 = ?) or ... )
 				//		unfortunately most of this building needs to be held off until we know
 				//		the exact number of ids :(
 				return new StringBuilder( "(" ).append( BATCH_ID_PLACEHOLDER ).append( ")" );
 			}
 		}
 	}
 
 	public static String expandBatchIdPlaceholder(
 			String sql,
 			Serializable[] ids,
 			String alias,
 			String[] keyColumnNames,
 			Dialect dialect) {
 		if ( keyColumnNames.length == 1 ) {
 			// non-composite
 			return StringHelper.replace( sql, BATCH_ID_PLACEHOLDER, repeat( "?", ids.length, "," ) );
 		}
 		else {
 			// composite
 			if ( dialect.supportsRowValueConstructorSyntaxInInList() ) {
 				final String tuple = "(" + StringHelper.repeat( "?", keyColumnNames.length, "," ) + ")";
 				return StringHelper.replace( sql, BATCH_ID_PLACEHOLDER, repeat( tuple, ids.length, "," ) );
 			}
 			else {
 				final String keyCheck = "(" +  joinWithQualifierAndSuffix( keyColumnNames, alias, " = ?", " and " ) + ")";
 				return replace( sql, BATCH_ID_PLACEHOLDER, repeat( keyCheck, ids.length, " or " ) );
 			}
 		}
 	}
 	
 	/**
 	 * Takes a String s and returns a new String[1] with s as the only element.
 	 * If s is null or "", return String[0].
 	 * 
 	 * @param s
 	 * @return String[]
 	 */
 	public static String[] toArrayElement(String s) {
 		return ( s == null || s.length() == 0 ) ? new String[0] : new String[] { s };
 	}
 
 	public static String nullIfEmpty(String value) {
 		return isEmpty( value ) ? null : value;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ArrayHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ArrayHelper.java
index 8a928d2642..697743be59 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ArrayHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ArrayHelper.java
@@ -1,432 +1,459 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util.collections;
 
 import java.io.Serializable;
 import java.lang.reflect.Array;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.type.Type;
 
 public final class ArrayHelper {
 	
 	public static boolean contains(Object[] array, Object object) {
 		return indexOf( array, object ) > -1;
 	}
 	
 	public static int indexOf(Object[] array, Object object) {
 		for ( int i = 0; i < array.length; i++ ) {
-			if ( array[i].equals( object ) )
+			if ( array[i].equals( object ) ) {
 				return i;
+			}
 		}
 		return -1;
 	}
 	
 	/*public static Object[] clone(Class elementClass, Object[] array) {
 		Object[] result = (Object[]) Array.newInstance( elementClass, array.length );
 		System.arraycopy(array, 0, result, 0, array.length);
 		return result;
 	}*/
 
 	public static String[] toStringArray(Object[] objects) {
 		int length=objects.length;
 		String[] result = new String[length];
 		for (int i=0; i<length; i++) {
 			result[i] = objects[i].toString();
 		}
 		return result;
 	}
 
 	public static String[] fillArray(String value, int length) {
 		String[] result = new String[length];
 		Arrays.fill(result, value);
 		return result;
 	}
 
 	public static int[] fillArray(int value, int length) {
 		int[] result = new int[length];
 		Arrays.fill(result, value);
 		return result;
 	}
 
 	public static LockMode[] fillArray(LockMode lockMode, int length) {
 		LockMode[] array = new LockMode[length];
 		Arrays.fill(array, lockMode);
 		return array;
 	}
 
 	public static LockOptions[] fillArray(LockOptions lockOptions, int length) {
 		LockOptions[] array = new LockOptions[length];
 		Arrays.fill(array, lockOptions);
 		return array;
 	}
 
 	public static String[] toStringArray(Collection coll) {
 		return (String[]) coll.toArray( new String[coll.size()] );
 	}
 	
 	public static String[][] to2DStringArray(Collection coll) {
 		return (String[][]) coll.toArray( new String[ coll.size() ][] );
 	}
 	
 	public static int[][] to2DIntArray(Collection coll) {
 		return (int[][]) coll.toArray( new int[ coll.size() ][] );
 	}
 	
 	public static Type[] toTypeArray(Collection coll) {
 		return (Type[]) coll.toArray( new Type[coll.size()] );
 	}
 
 	public static int[] toIntArray(Collection coll) {
 		Iterator iter = coll.iterator();
 		int[] arr = new int[ coll.size() ];
 		int i=0;
 		while( iter.hasNext() ) {
 			arr[i++] = (Integer) iter.next();
 		}
 		return arr;
 	}
 
 	public static boolean[] toBooleanArray(Collection coll) {
 		Iterator iter = coll.iterator();
 		boolean[] arr = new boolean[ coll.size() ];
 		int i=0;
 		while( iter.hasNext() ) {
 			arr[i++] = (Boolean) iter.next();
 		}
 		return arr;
 	}
 
 	public static Object[] typecast(Object[] array, Object[] to) {
 		return java.util.Arrays.asList(array).toArray(to);
 	}
 
 	//Arrays.asList doesn't do primitive arrays
 	public static List toList(Object array) {
 		if ( array instanceof Object[] ) return Arrays.asList( (Object[]) array ); //faster?
 		int size = Array.getLength(array);
 		ArrayList list = new ArrayList(size);
 		for (int i=0; i<size; i++) {
 			list.add( Array.get(array, i) );
 		}
 		return list;
 	}
 
 	public static String[] slice(String[] strings, int begin, int length) {
 		String[] result = new String[length];
 		System.arraycopy( strings, begin, result, 0, length );
 		return result;
 	}
 
 	public static Object[] slice(Object[] objects, int begin, int length) {
 		Object[] result = new Object[length];
 		System.arraycopy( objects, begin, result, 0, length );
 		return result;
 	}
 
 	public static List toList(Iterator iter) {
 		List list = new ArrayList();
 		while ( iter.hasNext() ) {
 			list.add( iter.next() );
 		}
 		return list;
 	}
 
 	public static String[] join(String[] x, String[] y) {
 		String[] result = new String[ x.length + y.length ];
 		System.arraycopy( x, 0, result, 0, x.length );
 		System.arraycopy( y, 0, result, x.length, y.length );
 		return result;
 	}
 
 	public static String[] join(String[] x, String[] y, boolean[] use) {
 		String[] result = new String[ x.length + countTrue(use) ];
 		System.arraycopy( x, 0, result, 0, x.length );
 		int k = x.length;
 		for ( int i=0; i<y.length; i++ ) {
 			if ( use[i] ) {
 				result[k++] = y[i];
 			}
 		}
 		return result;
 	}
 
 	public static int[] join(int[] x, int[] y) {
 		int[] result = new int[ x.length + y.length ];
 		System.arraycopy( x, 0, result, 0, x.length );
 		System.arraycopy( y, 0, result, x.length, y.length );
 		return result;
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public static <T> T[] join(T[] x, T... y) {
 		T[] result = (T[]) Array.newInstance( x.getClass().getComponentType(), x.length + y.length );
 		System.arraycopy( x, 0, result, 0, x.length );
 		System.arraycopy( y, 0, result, x.length, y.length );
 		return result;
 	}
 
 	public static final boolean[] TRUE = { true };
 	public static final boolean[] FALSE = { false };
 
 	private ArrayHelper() {}
 
 	public static String toString( Object[] array ) {
 		StringBuilder sb = new StringBuilder();
 		sb.append("[");
 		for (int i = 0; i < array.length; i++) {
 			sb.append( array[i] );
-			if( i<array.length-1 ) sb.append(",");
+			if( i<array.length-1 ) {
+				sb.append(",");
+			}
 		}
 		sb.append("]");
 		return sb.toString();
 	}
 
 	public static boolean isAllNegative(int[] array) {
 		for ( int anArray : array ) {
 			if ( anArray >= 0 ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public static boolean isAllTrue(boolean[] array) {
 		for ( boolean anArray : array ) {
 			if ( !anArray ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public static int countTrue(boolean[] array) {
 		int result=0;
 		for ( boolean anArray : array ) {
 			if ( anArray ) {
 				result++;
 			}
 		}
 		return result;
 	}
 
 	/*public static int countFalse(boolean[] array) {
 		int result=0;
 		for ( int i=0; i<array.length; i++ ) {
 			if ( !array[i] ) result++;
 		}
 		return result;
 	}*/
 
 	public static boolean isAllFalse(boolean[] array) {
 		for ( boolean anArray : array ) {
 			if ( anArray ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
-	public static void addAll(Collection collection, Object[] array) {
+	public static <T> void addAll(Collection<T> collection, T[] array) {
 		collection.addAll( Arrays.asList( array ) );
 	}
 
 	public static final String[] EMPTY_STRING_ARRAY = {};
 	public static final int[] EMPTY_INT_ARRAY = {};
 	public static final boolean[] EMPTY_BOOLEAN_ARRAY = {};
 	public static final Class[] EMPTY_CLASS_ARRAY = {};
 	public static final Object[] EMPTY_OBJECT_ARRAY = {};
 	public static final Type[] EMPTY_TYPE_ARRAY = {};
 	public static final byte[] EMPTY_BYTE_ARRAY = {};
 	
 	public static int[] getBatchSizes(int maxBatchSize) {
 		int batchSize = maxBatchSize;
 		int n=1;
 		while ( batchSize>1 ) {
 			batchSize = getNextBatchSize(batchSize);
 			n++;
 		}
 		int[] result = new int[n];
 		batchSize = maxBatchSize;
 		for ( int i=0; i<n; i++ ) {
 			result[i] = batchSize;
 			batchSize = getNextBatchSize(batchSize);
 		}
 		return result;
 	}
 	
 	private static int getNextBatchSize(int batchSize) {
 		if (batchSize<=10) {
 			return batchSize-1; //allow 9,8,7,6,5,4,3,2,1
 		}
 		else if (batchSize/2 < 10) {
 			return 10;
 		}
 		else {
 			return batchSize / 2;
 		}
 	}
 
 	private static int SEED = 23;
 	private static int PRIME_NUMER = 37;
 
 	/**
 	 * calculate the array hash (only the first level)
 	 */
 	public static int hash(Object[] array) {
 		int length = array.length;
 		int seed = SEED;
 		for ( Object anArray : array ) {
 			seed = hash( seed, anArray == null ? 0 : anArray.hashCode() );
 		}
 		return seed;
 	}
 
 	/**
 	 * calculate the array hash (only the first level)
 	 */
 	public static int hash(char[] array) {
 		int length = array.length;
 		int seed = SEED;
 		for ( char anArray : array ) {
 			seed = hash( seed, anArray );
 		}
 		return seed;
 	}
 
 	/**
 	 * calculate the array hash (only the first level)
 	 */
 	public static int hash(byte[] bytes) {
 		int length = bytes.length;
 		int seed = SEED;
 		for ( byte aByte : bytes ) {
 			seed = hash( seed, aByte );
 		}
 		return seed;
 	}
 
 	private static int hash(int seed, int i) {
 		return PRIME_NUMER * seed + i;
 	}
 
 	/**
 	 * Compare 2 arrays only at the first level
 	 */
 	public static boolean isEquals(Object[] o1, Object[] o2) {
-		if (o1 == o2) return true;
-		if (o1 == null || o2 == null) return false;
+		if (o1 == o2) {
+			return true;
+		}
+		if (o1 == null || o2 == null) {
+			return false;
+		}
 		int length = o1.length;
-		if (length != o2.length) return false;
+		if (length != o2.length) {
+			return false;
+		}
 		for (int index = 0 ; index < length ; index++) {
-			if ( ! o1[index].equals( o2[index] ) ) return false;
+			if ( ! o1[index].equals( o2[index] ) ) {
+				return false;
+			}
 		}
         return true;
 	}
 
 	/**
 	 * Compare 2 arrays only at the first level
 	 */
 	public static boolean isEquals(char[] o1, char[] o2) {
-		if (o1 == o2) return true;
-		if (o1 == null || o2 == null) return false;
+		if (o1 == o2) {
+			return true;
+		}
+		if (o1 == null || o2 == null) {
+			return false;
+		}
 		int length = o1.length;
-		if (length != o2.length) return false;
+		if (length != o2.length) {
+			return false;
+		}
 		for (int index = 0 ; index < length ; index++) {
-			if ( ! ( o1[index] == o2[index] ) ) return false;
+			if ( ! ( o1[index] == o2[index] ) ) {
+				return false;
+			}
 		}
         return true;
 	}
 
 	/**
 	 * Compare 2 arrays only at the first level
 	 */
 	public static boolean isEquals(byte[] b1, byte[] b2) {
-		if (b1 == b2) return true;
-		if (b1 == null || b2 == null) return false;
+		if (b1 == b2) {
+			return true;
+		}
+		if (b1 == null || b2 == null) {
+			return false;
+		}
 		int length = b1.length;
-		if (length != b2.length) return false;
+		if (length != b2.length) {
+			return false;
+		}
 		for (int index = 0 ; index < length ; index++) {
-			if ( ! ( b1[index] == b2[index] ) ) return false;
+			if ( ! ( b1[index] == b2[index] ) ) {
+				return false;
+			}
 		}
         return true;
 	}
 
 	public static Serializable[] extractNonNull(Serializable[] array) {
 		final int nonNullCount = countNonNull( array );
 		final Serializable[] result = new Serializable[nonNullCount];
 		int i = 0;
 		for ( Serializable element : array ) {
 			if ( element != null ) {
 				result[i++] = element;
 			}
 		}
 		if ( i != nonNullCount ) {
 			throw new HibernateException( "Number of non-null elements varied between iterations" );
 		}
 		return result;
 	}
 
 	public static int countNonNull(Serializable[] array) {
 		int i = 0;
 		for ( Serializable element : array ) {
 			if ( element != null ) {
 				i++;
 			}
 		}
 		return i;
 	}
 
 	public static String[] reverse(String[] source) {
 		final int length = source.length;
 		final String[] destination = new String[length];
 		for ( int i = 0; i < length; i++ ) {
 			final int x = length - i - 1;
 			destination[x] = source[i];
 		}
 		return destination;
 	}
 
 	public static void main(String... args) {
 		int[] batchSizes = ArrayHelper.getBatchSizes( 32 );
 
 		System.out.println( "Forward ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~" );
 		for ( int i = 0; i < batchSizes.length; i++ ) {
 			System.out.println( "[" + i + "] -> " + batchSizes[i] );
 		}
 
 		System.out.println( "Backward ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~" );
 		for ( int i = batchSizes.length-1; i >= 0; i-- ) {
 			System.out.println( "[" + i + "] -> " + batchSizes[i] );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java b/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
index 57dacf0a9f..cb3ed17598 100644
--- a/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
+++ b/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
@@ -1,195 +1,202 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.jdbc;
 
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.hibernate.HibernateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.exception.GenericJDBCException;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * Holds various often used {@link Expectation} definitions.
  *
  * @author Steve Ebersole
  */
 public class Expectations {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Expectations.class.getName());
 	private static SqlExceptionHelper sqlExceptionHelper = new SqlExceptionHelper();
 
 	public static final int USUAL_EXPECTED_COUNT = 1;
 	public static final int USUAL_PARAM_POSITION = 1;
 
 
 	// Base Expectation impls ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public static class BasicExpectation implements Expectation {
 		private final int expectedRowCount;
 
 		protected BasicExpectation(int expectedRowCount) {
 			this.expectedRowCount = expectedRowCount;
 			if ( expectedRowCount < 0 ) {
 				throw new IllegalArgumentException( "Expected row count must be greater than zero" );
 			}
 		}
 
 		public final void verifyOutcome(int rowCount, PreparedStatement statement, int batchPosition) {
 			rowCount = determineRowCount( rowCount, statement );
 			if ( batchPosition < 0 ) {
 				checkNonBatched( rowCount );
 			}
 			else {
 				checkBatched( rowCount, batchPosition );
 			}
 		}
 
 		private void checkBatched(int rowCount, int batchPosition) {
-            if (rowCount == -2) LOG.debugf("Success of batch update unknown: %s", batchPosition);
-            else if (rowCount == -3) throw new BatchFailedException("Batch update failed: " + batchPosition);
+            if (rowCount == -2) {
+				LOG.debugf("Success of batch update unknown: %s", batchPosition);
+			}
+            else if (rowCount == -3) {
+				throw new BatchFailedException("Batch update failed: " + batchPosition);
+			}
 			else {
-                if (expectedRowCount > rowCount) throw new StaleStateException(
-                                                                               "Batch update returned unexpected row count from update ["
-                                                                               + batchPosition + "]; actual row count: " + rowCount
-                                                                               + "; expected: " + expectedRowCount);
+                if (expectedRowCount > rowCount) {
+					throw new StaleStateException(
+							"Batch update returned unexpected row count from update ["
+									+ batchPosition + "]; actual row count: " + rowCount
+									+ "; expected: " + expectedRowCount
+					);
+				}
 				if ( expectedRowCount < rowCount ) {
 					String msg = "Batch update returned unexpected row count from update [" +
 					             batchPosition + "]; actual row count: " + rowCount +
 					             "; expected: " + expectedRowCount;
 					throw new BatchedTooManyRowsAffectedException( msg, expectedRowCount, rowCount, batchPosition );
 				}
 			}
 		}
 
 		private void checkNonBatched(int rowCount) {
 			if ( expectedRowCount > rowCount ) {
 				throw new StaleStateException(
 						"Unexpected row count: " + rowCount + "; expected: " + expectedRowCount
 				);
 			}
 			if ( expectedRowCount < rowCount ) {
 				String msg = "Unexpected row count: " + rowCount + "; expected: " + expectedRowCount;
 				throw new TooManyRowsAffectedException( msg, expectedRowCount, rowCount );
 			}
 		}
 
 		public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
 			return 0;
 		}
 
 		public boolean canBeBatched() {
 			return true;
 		}
 
 		protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
 			return reportedRowCount;
 		}
 	}
 
 	public static class BasicParamExpectation extends BasicExpectation {
 		private final int parameterPosition;
 		protected BasicParamExpectation(int expectedRowCount, int parameterPosition) {
 			super( expectedRowCount );
 			this.parameterPosition = parameterPosition;
 		}
 
 		@Override
         public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
 			toCallableStatement( statement ).registerOutParameter( parameterPosition, Types.NUMERIC );
 			return 1;
 		}
 
 		@Override
         public boolean canBeBatched() {
 			return false;
 		}
 
 		@Override
         protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
 			try {
 				return toCallableStatement( statement ).getInt( parameterPosition );
 			}
 			catch( SQLException sqle ) {
 				sqlExceptionHelper.logExceptions( sqle, "could not extract row counts from CallableStatement" );
 				throw new GenericJDBCException( "could not extract row counts from CallableStatement", sqle );
 			}
 		}
 
 		private CallableStatement toCallableStatement(PreparedStatement statement) {
 			if ( ! CallableStatement.class.isInstance( statement ) ) {
 				throw new HibernateException( "BasicParamExpectation operates exclusively on CallableStatements : " + statement.getClass() );
 			}
 			return ( CallableStatement ) statement;
 		}
 	}
 
 
 	// Various Expectation instances ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public static final Expectation NONE = new Expectation() {
 		public void verifyOutcome(int rowCount, PreparedStatement statement, int batchPosition) {
 			// explicitly doAfterTransactionCompletion no checking...
 		}
 
 		public int prepare(PreparedStatement statement) {
 			return 0;
 		}
 
 		public boolean canBeBatched() {
 			return true;
 		}
 	};
 
 	public static final Expectation BASIC = new BasicExpectation( USUAL_EXPECTED_COUNT );
 
 	public static final Expectation PARAM = new BasicParamExpectation( USUAL_EXPECTED_COUNT, USUAL_PARAM_POSITION );
 
 
 	public static Expectation appropriateExpectation(ExecuteUpdateResultCheckStyle style) {
 		if ( style == ExecuteUpdateResultCheckStyle.NONE ) {
 			return NONE;
 		}
 		else if ( style == ExecuteUpdateResultCheckStyle.COUNT ) {
 			return BASIC;
 		}
 		else if ( style == ExecuteUpdateResultCheckStyle.PARAM ) {
 			return PARAM;
 		}
 		else {
 			throw new HibernateException( "unknown check style : " + style );
 		}
 	}
 
 	private Expectations() {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/BasicLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/BasicLoader.java
index b7a8601151..0b48b08e2b 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/BasicLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/BasicLoader.java
@@ -1,124 +1,126 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader;
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.type.BagType;
 
 /**
  * Uses the default mapping from property to result set column 
  * alias defined by the entities' persisters. Used when Hibernate
  * is generating result set column aliases.
  * 
  * @author Gavin King
  */
 public abstract class BasicLoader extends Loader {
 
 	protected static final String[] NO_SUFFIX = {""};
 
 	private EntityAliases[] descriptors;
 	private CollectionAliases[] collectionDescriptors;
 
 	public BasicLoader(SessionFactoryImplementor factory) {
 		super(factory);
 	}
 
 	protected final EntityAliases[] getEntityAliases() {
 		return descriptors;
 	}
 
 	protected final CollectionAliases[] getCollectionAliases() {
 		return collectionDescriptors;
 	}
 
 	protected abstract String[] getSuffixes();
 	protected abstract String[] getCollectionSuffixes();
 
 	protected void postInstantiate() {
 		Loadable[] persisters = getEntityPersisters();
 		String[] suffixes = getSuffixes();
 		descriptors = new EntityAliases[persisters.length];
 		for ( int i=0; i<descriptors.length; i++ ) {
 			descriptors[i] = new DefaultEntityAliases( persisters[i], suffixes[i] );
 		}
 
 		CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		List bagRoles = null;
 		if ( collectionPersisters != null ) {
 			String[] collectionSuffixes = getCollectionSuffixes();
 			collectionDescriptors = new CollectionAliases[collectionPersisters.length];
 			for ( int i = 0; i < collectionPersisters.length; i++ ) {
 				if ( isBag( collectionPersisters[i] ) ) {
 					if ( bagRoles == null ) {
 						bagRoles = new ArrayList();
 					}
 					bagRoles.add( collectionPersisters[i].getRole() );
 				}
 				collectionDescriptors[i] = new GeneratedCollectionAliases(
 						collectionPersisters[i],
 						collectionSuffixes[i]
 					);
 			}
 		}
 		else {
 			collectionDescriptors = null;
 		}
 		if ( bagRoles != null && bagRoles.size() > 1 ) {
 			throw new MultipleBagFetchException( bagRoles );
 		}
 	}
 
 	private boolean isBag(CollectionPersister collectionPersister) {
 		return collectionPersister.getCollectionType().getClass().isAssignableFrom( BagType.class );
 	}
 
 	/**
 	 * Utility method that generates 0_, 1_ suffixes. Subclasses don't
 	 * necessarily need to use this algorithm, but it is intended that
 	 * they will in most cases.
 	 *
 	 * @param length The number of suffixes to generate
 	 *
 	 * @return The array of generated suffixes (with length=length).
 	 */
 	public static String[] generateSuffixes(int length) {
 		return generateSuffixes( 0, length );
 	}
 
 	public static String[] generateSuffixes(int seed, int length) {
-		if ( length == 0 ) return NO_SUFFIX;
+		if ( length == 0 ) {
+			return NO_SUFFIX;
+		}
 
 		String[] suffixes = new String[length];
 		for ( int i = 0; i < length; i++ ) {
 			suffixes[i] = Integer.toString( i + seed ) + "_";
 		}
 		return suffixes;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java b/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
index dafb0837c0..4e02985dd3 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
@@ -1,157 +1,159 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader;
 import java.util.Collections;
 import java.util.Map;
 
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 
 /**
  * CollectionAliases which handles the logic of selecting user provided aliases (via return-property),
  * before using the default aliases. 
  *
  * @author Steve Ebersole
  * @author Max Rydahl Andersen
  */
 public class GeneratedCollectionAliases implements CollectionAliases {
 	private final String suffix;
 	private final String[] keyAliases;
 	private final String[] indexAliases;
 	private final String[] elementAliases;
 	private final String identifierAlias;
 	private Map userProvidedAliases;
 	
 	public GeneratedCollectionAliases(Map userProvidedAliases, CollectionPersister persister, String suffix) {
 		this.suffix = suffix;
 		this.userProvidedAliases = userProvidedAliases;
 
 		this.keyAliases = getUserProvidedAliases(
 				"key", 
 				persister.getKeyColumnAliases( suffix )
 		);
 
 		this.indexAliases = getUserProvidedAliases(
 				"index",
 				persister.getIndexColumnAliases( suffix )
 		);
 		
 		this.elementAliases = getUserProvidedAliases(
 				"element",
 				persister.getElementColumnAliases( suffix )
 		);
 				
 		this.identifierAlias = getUserProvidedAlias(
 				"id",
 				persister.getIdentifierColumnAlias( suffix )
 		);
 	}
 
 	public GeneratedCollectionAliases(CollectionPersister persister, String string) {
 		this( Collections.EMPTY_MAP, persister, string);
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for columns making up the key for this collection (i.e., its FK to
 	 * its owner).
 	 *
 	 * @return The key result-set column aliases.
 	 */
 	public String[] getSuffixedKeyAliases() {
 		return keyAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the collumns making up the collection's index (map or list).
 	 *
 	 * @return The index result-set column aliases.
 	 */
 	public String[] getSuffixedIndexAliases() {
 		return indexAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the columns making up the collection's elements.
 	 *
 	 * @return The element result-set column aliases.
 	 */
 	public String[] getSuffixedElementAliases() {
 		return elementAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the column defining the collection's identifier (if any).
 	 *
 	 * @return The identifier result-set column aliases.
 	 */
 	public String getSuffixedIdentifierAlias() {
 		return identifierAlias;
 	}
 
 	/**
 	 * Returns the suffix used to unique the column aliases for this particular alias set.
 	 *
 	 * @return The uniqued column alias suffix.
 	 */
 	public String getSuffix() {
 		return suffix;
 	}
 
 	@Override
     public String toString() {
 		return super.toString() + " [suffix=" + suffix +
 		        ", suffixedKeyAliases=[" + join( keyAliases ) +
 		        "], suffixedIndexAliases=[" + join( indexAliases ) +
 		        "], suffixedElementAliases=[" + join( elementAliases ) +
 		        "], suffixedIdentifierAlias=[" + identifierAlias + "]]";
 	}
 
 	private String join(String[] aliases) {
-		if ( aliases == null) return null;
+		if ( aliases == null) {
+			return null;
+		}
 
 		return StringHelper.join( ", ", aliases );
 	}
 	
 	private String[] getUserProvidedAliases(String propertyPath, String[] defaultAliases) {
 		String[] result = (String[]) userProvidedAliases.get(propertyPath);
 		if (result==null) {
 			return defaultAliases;			
 		} 
 		else {
 			return result;
 		}
 	}
 
 	private String getUserProvidedAlias(String propertyPath, String defaultAlias) {
 		String[] columns = (String[]) userProvidedAliases.get(propertyPath);
 		if (columns==null) {
 			return defaultAlias;
 		} 
 		else {
 			return columns[0];
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java b/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
index aaf131700c..0330161811 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
@@ -1,1125 +1,1134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.FetchMode;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.sql.ConditionFragment;
 import org.hibernate.sql.DisjunctionFragment;
 import org.hibernate.sql.InFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.ForeignKeyDirection;
 import org.hibernate.type.Type;
 
 /**
  * Walks the metamodel, searching for joins, and collecting
  * together information needed by <tt>OuterJoinLoader</tt>.
  * 
  * @see OuterJoinLoader
  * @author Gavin King, Jon Lipsky
  */
 public class JoinWalker {
 	
 	private final SessionFactoryImplementor factory;
 	protected final List associations = new ArrayList();
 	private final Set visitedAssociationKeys = new HashSet();
 	private final LoadQueryInfluencers loadQueryInfluencers;
 
 	protected String[] suffixes;
 	protected String[] collectionSuffixes;
 	protected Loadable[] persisters;
 	protected int[] owners;
 	protected EntityType[] ownerAssociationTypes;
 	protected CollectionPersister[] collectionPersisters;
 	protected int[] collectionOwners;
 	protected String[] aliases;
 	protected LockOptions lockOptions;
 	protected LockMode[] lockModeArray;
 	protected String sql;
 
 	protected JoinWalker(
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		this.factory = factory;
 		this.loadQueryInfluencers = loadQueryInfluencers;
 
 	}
 
 	public List getAssociations() {
 		return Collections.unmodifiableList( associations );
 	}
 
 	public String[] getCollectionSuffixes() {
 		return collectionSuffixes;
 	}
 
 	public void setCollectionSuffixes(String[] collectionSuffixes) {
 		this.collectionSuffixes = collectionSuffixes;
 	}
 
 	public LockOptions getLockModeOptions() {
 		return lockOptions;
 	}
 
 	public LockMode[] getLockModeArray() {
 		return lockModeArray;
 	}
 
 	public String[] getSuffixes() {
 		return suffixes;
 	}
 
 	public void setSuffixes(String[] suffixes) {
 		this.suffixes = suffixes;
 	}
 
 	public String[] getAliases() {
 		return aliases;
 	}
 
 	public void setAliases(String[] aliases) {
 		this.aliases = aliases;
 	}
 
 	public int[] getCollectionOwners() {
 		return collectionOwners;
 	}
 
 	public void setCollectionOwners(int[] collectionOwners) {
 		this.collectionOwners = collectionOwners;
 	}
 
 	public CollectionPersister[] getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	public void setCollectionPersisters(CollectionPersister[] collectionPersisters) {
 		this.collectionPersisters = collectionPersisters;
 	}
 
 	public EntityType[] getOwnerAssociationTypes() {
 		return ownerAssociationTypes;
 	}
 
 	public void setOwnerAssociationTypes(EntityType[] ownerAssociationType) {
 		this.ownerAssociationTypes = ownerAssociationType;
 	}
 
 	public int[] getOwners() {
 		return owners;
 	}
 
 	public void setOwners(int[] owners) {
 		this.owners = owners;
 	}
 
 	public Loadable[] getPersisters() {
 		return persisters;
 	}
 
 	public void setPersisters(Loadable[] persisters) {
 		this.persisters = persisters;
 	}
 
 	public String getSQLString() {
 		return sql;
 	}
 
 	public void setSql(String sql) {
 		this.sql = sql;
 	}
 
 	protected SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	protected Dialect getDialect() {
 		return factory.getDialect();
 	}
 
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return loadQueryInfluencers;
 	}
 
 	/**
 	 * Add on association (one-to-one, many-to-one, or a collection) to a list 
 	 * of associations to be fetched by outerjoin (if necessary)
 	 */
 	private void addAssociationToJoinTreeIfNecessary(
 			final AssociationType type,
 			final String[] aliasedLhsColumns,
 			final String alias,
 			final PropertyPath path,
 			int currentDepth,
 			final JoinType joinType) throws MappingException {
 		if ( joinType != JoinType.NONE ) {
 			addAssociationToJoinTree(
 					type, 
 					aliasedLhsColumns, 
 					alias, 
 					path,
 					currentDepth,
 					joinType
 			);
 		}
 	}
 
 	protected boolean hasRestriction(PropertyPath path)	{
 		return false;
 	}
 
 	protected String getWithClause(PropertyPath path)	{
 		return "";
 	}
 	
 	/**
 	 * Add on association (one-to-one, many-to-one, or a collection) to a list 
 	 * of associations to be fetched by outerjoin 
 	 */
 	private void addAssociationToJoinTree(
 			final AssociationType type,
 			final String[] aliasedLhsColumns,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth,
 			final JoinType joinType) throws MappingException {
 
 		Joinable joinable = type.getAssociatedJoinable( getFactory() );
 
 		// important to generate alias based on size of association collection
 		// *before* adding this join to that collection
 		String subalias = generateTableAlias( associations.size() + 1, path, joinable );
 
 		// NOTE : it should be fine to continue to pass only filters below
 		// (instead of LoadQueryInfluencers) since "from that point on" we
 		// only need to worry about restrictions (and not say adding more
 		// joins)
 		OuterJoinableAssociation assoc = new OuterJoinableAssociation(
 				path,
 				type, 
 				alias, 
 				aliasedLhsColumns, 
 				subalias, 
 				joinType, 
 				getWithClause(path),
 				hasRestriction( path ),
 				getFactory(),
 				loadQueryInfluencers.getEnabledFilters()
 		);
 		assoc.validateJoin( path.getFullPath() );
 		associations.add( assoc );
 
 		int nextDepth = currentDepth + 1;
 //		path = "";
 		if ( !joinable.isCollection() ) {
 			if (joinable instanceof OuterJoinLoadable) {
 				walkEntityTree(
 					(OuterJoinLoadable) joinable, 
 					subalias,
 					path, 
 					nextDepth
 				);
 			}
 		}
 		else {
 			if (joinable instanceof QueryableCollection) {
 				walkCollectionTree(
 					(QueryableCollection) joinable, 
 					subalias, 
 					path, 
 					nextDepth
 				);
 			}
 		}
 
 	}
 
 	/**
 	 * Walk the association tree for an entity, adding associations which should
 	 * be join fetched to the {@link #associations} inst var.  This form is the
 	 * entry point into the walking for a given entity, starting the recursive
 	 * calls into {@link #walkEntityTree(org.hibernate.persister.entity.OuterJoinLoadable, String, PropertyPath ,int)}.
 	 *
 	 * @param persister The persister representing the entity to be walked.
 	 * @param alias The (root) alias to use for this entity/persister.
 	 * @throws org.hibernate.MappingException ???
 	 */
 	protected final void walkEntityTree(
 			OuterJoinLoadable persister,
 			String alias) throws MappingException {
 		walkEntityTree( persister, alias, new PropertyPath(), 0 );
 	}
 
 	/**
 	 * For a collection role, return a list of associations to be fetched by outerjoin
 	 */
 	protected final void walkCollectionTree(QueryableCollection persister, String alias) throws MappingException {
 		walkCollectionTree( persister, alias, new PropertyPath(), 0 );
 		//TODO: when this is the entry point, we should use an INNER_JOIN for fetching the many-to-many elements!
 	}
 
 	/**
 	 * For a collection role, return a list of associations to be fetched by outerjoin
 	 */
 	private void walkCollectionTree(
 			final QueryableCollection persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth)	throws MappingException {
 
 		if ( persister.isOneToMany() ) {
 			walkEntityTree(
 					(OuterJoinLoadable) persister.getElementPersister(),
 					alias,
 					path,
 					currentDepth
 				);
 		}
 		else {
 			Type type = persister.getElementType();
 			if ( type.isAssociationType() ) {
 				// a many-to-many;
 				// decrement currentDepth here to allow join across the association table
 				// without exceeding MAX_FETCH_DEPTH (i.e. the "currentDepth - 1" bit)
 				AssociationType associationType = (AssociationType) type;
 				String[] aliasedLhsColumns = persister.getElementColumnNames(alias);
 				String[] lhsColumns = persister.getElementColumnNames();
 				// if the current depth is 0, the root thing being loaded is the
 				// many-to-many collection itself.  Here, it is alright to use
 				// an inner join...
 				boolean useInnerJoin = currentDepth == 0;
 				final JoinType joinType = getJoinType(
 						associationType,
 						persister.getFetchMode(),
 						path,
 						persister.getTableName(),
 						lhsColumns,
 						!useInnerJoin,
 						currentDepth - 1, 
 						null //operations which cascade as far as the collection also cascade to collection elements
 				);
 				addAssociationToJoinTreeIfNecessary(
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						path,
 						currentDepth - 1,
 						joinType
 					);
 			}
 			else if ( type.isComponentType() ) {
 				walkCompositeElementTree(
 						(CompositeType) type,
 						persister.getElementColumnNames(),
 						persister,
 						alias,
 						path,
 						currentDepth
 					);
 			}
 		}
 
 	}
 	
 	/**
 	 * Process a particular association owned by the entity
 	 *
 	 * @param associationType The type representing the association to be
 	 * processed.
 	 * @param persister The owner of the association to be processed.
 	 * @param propertyNumber The property number for the association
 	 * (relative to the persister).
 	 * @param alias The entity alias
 	 * @param path The path to the association
 	 * @param nullable is the association nullable (which I think is supposed
 	 * to indicate inner/outer join semantics).
 	 * @param currentDepth The current join depth
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkEntityAssociationTree(
 			final AssociationType associationType,
 			final OuterJoinLoadable persister,
 			final int propertyNumber,
 			final String alias,
 			final PropertyPath path,
 			final boolean nullable,
 			final int currentDepth) throws MappingException {
 		String[] aliasedLhsColumns = JoinHelper.getAliasedLHSColumnNames(
 				associationType, alias, propertyNumber, persister, getFactory()
 		);
 		String[] lhsColumns = JoinHelper.getLHSColumnNames(
 				associationType, propertyNumber, persister, getFactory()
 		);
 		String lhsTable = JoinHelper.getLHSTableName(associationType, propertyNumber, persister);
 
 		PropertyPath subPath = path.append( persister.getSubclassPropertyName(propertyNumber) );
 		JoinType joinType = getJoinType(
 				persister,
 				subPath,
 				propertyNumber,
 				associationType,
 				persister.getFetchMode( propertyNumber ),
 				persister.getCascadeStyle( propertyNumber ),
 				lhsTable,
 				lhsColumns,
 				nullable,
 				currentDepth
 		);
 		addAssociationToJoinTreeIfNecessary(
 				associationType,
 				aliasedLhsColumns,
 				alias,
 				subPath,
 				currentDepth,
 				joinType
 		);
 	}
 
 	/**
 	 * Determine the appropriate type of join (if any) to use to fetch the
 	 * given association.
 	 *
 	 * @param persister The owner of the association.
 	 * @param path The path to the association
 	 * @param propertyNumber The property number representing the association.
 	 * @param associationType The association type.
 	 * @param metadataFetchMode The metadata-defined fetch mode.
 	 * @param metadataCascadeStyle The metadata-defined cascade style.
 	 * @param lhsTable The owner table
 	 * @param lhsColumns The owner join columns
 	 * @param nullable Is the association nullable.
 	 * @param currentDepth Current join depth
 	 * @return type of join to use ({@link org.hibernate.sql.JoinType#INNER_JOIN},
 	 * {@link org.hibernate.sql.JoinType#LEFT_OUTER_JOIN}, or -1 to indicate no joining.
 	 * @throws MappingException ??
 	 */
 	protected JoinType getJoinType(
 			OuterJoinLoadable persister,
 			final PropertyPath path,
 			int propertyNumber,
 			AssociationType associationType,
 			FetchMode metadataFetchMode,
 			CascadeStyle metadataCascadeStyle,
 			String lhsTable,
 			String[] lhsColumns,
 			final boolean nullable,
 			final int currentDepth) throws MappingException {
 		return getJoinType(
 				associationType,
 				metadataFetchMode,
 				path,
 				lhsTable,
 				lhsColumns,
 				nullable,
 				currentDepth,
 				metadataCascadeStyle
 		);
 	}
 
 	/**
 	 * Determine the appropriate associationType of join (if any) to use to fetch the
 	 * given association.
 	 *
 	 * @param associationType The association associationType.
 	 * @param config The metadata-defined fetch mode.
 	 * @param path The path to the association
 	 * @param lhsTable The owner table
 	 * @param lhsColumns The owner join columns
 	 * @param nullable Is the association nullable.
 	 * @param currentDepth Current join depth
 	 * @param cascadeStyle The metadata-defined cascade style.
 	 * @return type of join to use ({@link org.hibernate.sql.JoinType#INNER_JOIN},
 	 * {@link org.hibernate.sql.JoinType#LEFT_OUTER_JOIN}, or -1 to indicate no joining.
 	 * @throws MappingException ??
 	 */
 	protected JoinType getJoinType(
 			AssociationType associationType,
 			FetchMode config,
 			PropertyPath path,
 			String lhsTable,
 			String[] lhsColumns,
 			boolean nullable,
 			int currentDepth,
 			CascadeStyle cascadeStyle) throws MappingException {
 		if  ( !isJoinedFetchEnabled( associationType, config, cascadeStyle ) ) {
 			return JoinType.NONE;
 		}
 		if ( isTooDeep(currentDepth) || ( associationType.isCollectionType() && isTooManyCollections() ) ) {
 			return JoinType.NONE;
 		}
 		if ( isDuplicateAssociation( lhsTable, lhsColumns, associationType ) ) {
 			return JoinType.NONE;
 		}
 		return getJoinType( nullable, currentDepth );
 	}
 
 	/**
 	 * Walk the association tree for an entity, adding associations which should
 	 * be join fetched to the {@link #associations} inst var.  This form is the
 	 * entry point into the walking for a given entity, starting the recursive
 	 * calls into {@link #walkEntityTree(org.hibernate.persister.entity.OuterJoinLoadable, String, PropertyPath ,int)}.
 	 *
 	 * @param persister The persister representing the entity to be walked.
 	 * @param alias The (root) alias to use for this entity/persister.
 	 * @param path The property path to the entity being walked
 	 * @param currentDepth The current join depth
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkEntityTree(
 			final OuterJoinLoadable persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 		int n = persister.countSubclassProperties();
 		for ( int i = 0; i < n; i++ ) {
 			Type type = persister.getSubclassPropertyType(i);
 			if ( type.isAssociationType() ) {
 				walkEntityAssociationTree(
 					( AssociationType ) type,
 					persister,
 					i,
 					alias,
 					path,
 					persister.isSubclassPropertyNullable(i),
 					currentDepth
 				);
 			}
 			else if ( type.isComponentType() ) {
 				walkComponentTree(
 						( CompositeType ) type,
 						i,
 						0,
 						persister,
 						alias,
 						path.append( persister.getSubclassPropertyName(i) ),
 						currentDepth
 				);
 			}
 		}
 
 		// if the entity has a composite identifier, see if we need to handle
 		// its sub-properties separately
 		final Type idType = persister.getIdentifierType();
 		if ( idType.isComponentType() ) {
 			final CompositeType cidType = (CompositeType) idType;
 			if ( cidType.isEmbedded() ) {
 				// we have an embedded composite identifier.  Most likely we need to process the composite
 				// properties separately, although there is an edge case where the identifier is really
 				// a simple identifier (single value) wrapped in a JPA @IdClass or even in the case of a
 				// a simple identifier (single value) wrapped in a Hibernate composite type.
 				//
 				// We really do not have a built-in method to determine that.  However, generally the
 				// persister would report that there is single, physical identifier property which is
 				// explicitly at odds with the notion of "embedded composite".  So we use that for now
 				if ( persister.getEntityMetamodel().getIdentifierProperty().isEmbedded() ) {
 					walkComponentTree(
 							cidType,
 							-1,
 							0,
 							persister,
 							alias,
 							path,
 							currentDepth
 					);
 				}
 			}
 		}
 	}
 
 	/**
 	 * For a component, add to a list of associations to be fetched by outerjoin
 	 *
 	 *
 	 * @param componentType The component type to be walked.
 	 * @param propertyNumber The property number for the component property (relative to
 	 * persister).
 	 * @param begin todo unknowm
 	 * @param persister The owner of the component property
 	 * @param alias The root alias
 	 * @param path The property access path
 	 * @param currentDepth The current join depth
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkComponentTree(
 			final CompositeType componentType,
 			final int propertyNumber,
 			int begin,
 			final OuterJoinLoadable persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 		Type[] types = componentType.getSubtypes();
 		String[] propertyNames = componentType.getPropertyNames();
 		for ( int i = 0; i < types.length; i++ ) {
 			if ( types[i].isAssociationType() ) {
 				AssociationType associationType = (AssociationType) types[i];
 				String[] aliasedLhsColumns = JoinHelper.getAliasedLHSColumnNames(
 					associationType, alias, propertyNumber, begin, persister, getFactory()
 				);
 				String[] lhsColumns = JoinHelper.getLHSColumnNames(
 					associationType, propertyNumber, begin, persister, getFactory()
 				);
 				String lhsTable = JoinHelper.getLHSTableName(associationType, propertyNumber, persister);
 
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				final boolean[] propertyNullability = componentType.getPropertyNullability();
 				final JoinType joinType = getJoinType(
 						persister,
 						subPath,
 						propertyNumber,
 						associationType,
 						componentType.getFetchMode(i),
 						componentType.getCascadeStyle(i),
 						lhsTable,
 						lhsColumns,
 						propertyNullability==null || propertyNullability[i],
 						currentDepth
 				);
 				addAssociationToJoinTreeIfNecessary(			
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						subPath,
 						currentDepth,
 						joinType
 				);
 
 			}
 			else if ( types[i].isComponentType() ) {
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				walkComponentTree(
 						( CompositeType ) types[i],
 						propertyNumber,
 						begin,
 						persister,
 						alias,
 						subPath,
 						currentDepth
 				);
 			}
 			begin += types[i].getColumnSpan( getFactory() );
 		}
 
 	}
 
 	/**
 	 * For a composite element, add to a list of associations to be fetched by outerjoin
 	 */
 	private void walkCompositeElementTree(
 			final CompositeType compositeType,
 			final String[] cols,
 			final QueryableCollection persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 
 		Type[] types = compositeType.getSubtypes();
 		String[] propertyNames = compositeType.getPropertyNames();
 		int begin = 0;
 		for ( int i=0; i <types.length; i++ ) {
 			int length = types[i].getColumnSpan( getFactory() );
 			String[] lhsColumns = ArrayHelper.slice(cols, begin, length);
 
 			if ( types[i].isAssociationType() ) {
 				AssociationType associationType = (AssociationType) types[i];
 
 				// simple, because we can't have a one-to-one or a collection 
 				// (or even a property-ref) in a composite-element:
 				String[] aliasedLhsColumns = StringHelper.qualify(alias, lhsColumns);
 
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				final boolean[] propertyNullability = compositeType.getPropertyNullability();
 				final JoinType joinType = getJoinType(
 						associationType,
 						compositeType.getFetchMode(i),
 						subPath,
 						persister.getTableName(),
 						lhsColumns,
 						propertyNullability==null || propertyNullability[i],
 						currentDepth, 
 						compositeType.getCascadeStyle(i)
 					);
 				addAssociationToJoinTreeIfNecessary(
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						subPath,
 						currentDepth,
 						joinType
 					);
 			}
 			else if ( types[i].isComponentType() ) {
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				walkCompositeElementTree(
 						(CompositeType) types[i],
 						lhsColumns,
 						persister,
 						alias,
 						subPath,
 						currentDepth
 					);
 			}
 			begin+=length;
 		}
 
 	}
 
 	/**
 	 * Use an inner join if it is a non-null association and this
 	 * is the "first" join in a series
 	 */
 	protected JoinType getJoinType(boolean nullable, int currentDepth) {
 		//TODO: this is too conservative; if all preceding joins were 
 		//      also inner joins, we could use an inner join here
 		//
 		// IMPL NOTE : currentDepth might be less-than zero if this is the
 		// 		root of a many-to-many collection initializer 
 		return !nullable && currentDepth <= 0
 				? JoinType.INNER_JOIN
 				: JoinType.LEFT_OUTER_JOIN;
 	}
 
 	protected boolean isTooDeep(int currentDepth) {
 		Integer maxFetchDepth = getFactory().getSettings().getMaximumFetchDepth();
 		return maxFetchDepth!=null && currentDepth >= maxFetchDepth;
 	}
 	
 	protected boolean isTooManyCollections() {
 		return false;
 	}
 	
 	/**
 	 * Does the mapping, and Hibernate default semantics, specify that
 	 * this association should be fetched by outer joining
 	 */
 	protected boolean isJoinedFetchEnabledInMapping(FetchMode config, AssociationType type) 
 	throws MappingException {
 		if ( !type.isEntityType() && !type.isCollectionType() ) {
 			return false;
 		}
 		else {
-			if (config==FetchMode.JOIN) return true;
-			if (config==FetchMode.SELECT) return false;
+			if (config==FetchMode.JOIN) {
+				return true;
+			}
+			if (config==FetchMode.SELECT) {
+				return false;
+			}
 			if ( type.isEntityType() ) {
 				//TODO: look at the owning property and check that it 
 				//      isn't lazy (by instrumentation)
 				EntityType entityType =(EntityType) type;
 				EntityPersister persister = getFactory().getEntityPersister( entityType.getAssociatedEntityName() );
 				return !persister.hasProxy();
 			}
 			else {
 				return false;
 			}
 		}
 	}
 
 	/**
 	 * Override on subclasses to enable or suppress joining 
 	 * of certain association types
 	 */
 	protected boolean isJoinedFetchEnabled(AssociationType type, FetchMode config, CascadeStyle cascadeStyle) {
 		return type.isEntityType() && isJoinedFetchEnabledInMapping(config, type) ;
 	}
 	
 	protected String generateTableAlias(final int n, final PropertyPath path, final Joinable joinable) {
 		return StringHelper.generateAlias( joinable.getName(), n );
 	}
 
 	protected String generateRootAlias(final String description) {
 		return StringHelper.generateAlias(description, 0);
 	}
 
 	/**
 	 * Used to detect circularities in the joined graph, note that 
 	 * this method is side-effecty
 	 */
 	protected boolean isDuplicateAssociation(final String foreignKeyTable, final String[] foreignKeyColumns) {
 		AssociationKey associationKey = new AssociationKey(foreignKeyColumns, foreignKeyTable);
 		return !visitedAssociationKeys.add( associationKey );
 	}
 	
 	/**
 	 * Used to detect circularities in the joined graph, note that 
 	 * this method is side-effecty
 	 */
 	protected boolean isDuplicateAssociation(final String lhsTable, final String[] lhsColumnNames, final AssociationType type) {
 		final String foreignKeyTable;
 		final String[] foreignKeyColumns;
 		if ( type.getForeignKeyDirection()==ForeignKeyDirection.FROM_PARENT ) {
 			foreignKeyTable = lhsTable;
 			foreignKeyColumns = lhsColumnNames;
 		}
 		else {
 			foreignKeyTable = type.getAssociatedJoinable( getFactory() ).getTableName();
 			foreignKeyColumns = JoinHelper.getRHSColumnNames( type, getFactory() );
 		}
 		return isDuplicateAssociation(foreignKeyTable, foreignKeyColumns);
 	}
 	
 	/**
 	 * Uniquely identifier a foreign key, so that we don't
 	 * join it more than once, and create circularities
 	 */
 	private static final class AssociationKey {
 		private String[] columns;
 		private String table;
 		private AssociationKey(String[] columns, String table) {
 			this.columns = columns;
 			this.table = table;
 		}
 		@Override
         public boolean equals(Object other) {
 			AssociationKey that = (AssociationKey) other;
 			return that.table.equals(table) && Arrays.equals(columns, that.columns);
 		}
 		@Override
         public int hashCode() {
 			return table.hashCode(); //TODO: inefficient
 		}
 	}
 	
 	/**
 	 * Should we join this association?
 	 */
 	protected boolean isJoinable(
 			final JoinType joinType,
 			final Set visitedAssociationKeys,
 			final String lhsTable,
 			final String[] lhsColumnNames,
 			final AssociationType type,
 			final int depth) {
 
 		if ( joinType == JoinType.NONE ) {
 			return false;
 		}
 		
 		if ( joinType == JoinType.INNER_JOIN ) {
 			return true;
 		}
 
-		Integer maxFetchDepth = getFactory().getSettings().getMaximumFetchDepth();
+		Integer maxFetchDepth = getFactory().getSessionFactoryOptions().getMaximumFetchDepth();
 		final boolean tooDeep = maxFetchDepth!=null && depth >= maxFetchDepth;
 		
 		return !tooDeep && !isDuplicateAssociation(lhsTable, lhsColumnNames, type);
 	}
 	
 	protected String orderBy(final List associations, final String orderBy) {
 		return mergeOrderings( orderBy( associations ), orderBy );
 	}
 
 	protected static String mergeOrderings(String ordering1, String ordering2) {
 		if ( ordering1.length() == 0 ) {
 			return ordering2;
 		}
 		else if ( ordering2.length() == 0 ) {
 			return ordering1;
 		}
 		else {
 			return ordering1 + ", " + ordering2;
 		}
 	}
 	
 	/**
 	 * Generate a sequence of <tt>LEFT OUTER JOIN</tt> clauses for the given associations.
 	 */
 	protected final JoinFragment mergeOuterJoins(List associations)
 	throws MappingException {
 		JoinFragment outerjoin = getDialect().createOuterJoinFragment();
 		Iterator iter = associations.iterator();
 		OuterJoinableAssociation last = null;
 		while ( iter.hasNext() ) {
-			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
+			final OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( last != null && last.isManyToManyWith( oj ) ) {
 				oj.addManyToManyJoin( outerjoin, ( QueryableCollection ) last.getJoinable() );
 			}
 			else {
 				oj.addJoins(outerjoin);
 			}
 			last = oj;
 		}
 		last = null;
 		return outerjoin;
 	}
 
 	/**
 	 * Count the number of instances of Joinable which are actually
 	 * also instances of Loadable, or are one-to-many associations
 	 */
-	protected static final int countEntityPersisters(List associations)
+	protected static int countEntityPersisters(List associations)
 	throws MappingException {
 		int result = 0;
-		Iterator iter = associations.iterator();
-		while ( iter.hasNext() ) {
-			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
+		for ( Object association : associations ) {
+			final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;
 			if ( oj.getJoinable().consumesEntityAlias() ) {
 				result++;
 			}
 		}
 		return result;
 	}
 	
 	/**
 	 * Count the number of instances of Joinable which are actually
 	 * also instances of PersistentCollection which are being fetched
 	 * by outer join
 	 */
-	protected static final int countCollectionPersisters(List associations)
+	protected static int countCollectionPersisters(List associations)
 	throws MappingException {
 		int result = 0;
-		Iterator iter = associations.iterator();
-		while ( iter.hasNext() ) {
-			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
-			if ( oj.getJoinType()==JoinType.LEFT_OUTER_JOIN &&
+		for ( Object association : associations ) {
+			final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;
+			if ( oj.getJoinType() == JoinType.LEFT_OUTER_JOIN &&
 					oj.getJoinable().isCollection() &&
-					! oj.hasRestriction() ) {
+					!oj.hasRestriction() ) {
 				result++;
 			}
 		}
 		return result;
 	}
 	
 	/**
 	 * Get the order by string required for collection fetching
 	 */
-	protected static final String orderBy(List associations)
+	protected static String orderBy(List associations)
 	throws MappingException {
 		StringBuilder buf = new StringBuilder();
 		Iterator iter = associations.iterator();
 		OuterJoinableAssociation last = null;
 		while ( iter.hasNext() ) {
 			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( oj.getJoinType() == JoinType.LEFT_OUTER_JOIN ) { // why does this matter?
 				if ( oj.getJoinable().isCollection() ) {
 					final QueryableCollection queryableCollection = (QueryableCollection) oj.getJoinable();
 					if ( queryableCollection.hasOrdering() ) {
 						final String orderByString = queryableCollection.getSQLOrderByString( oj.getRHSAlias() );
 						buf.append( orderByString ).append(", ");
 					}
 				}
 				else {
 					// it might still need to apply a collection ordering based on a
 					// many-to-many defined order-by...
 					if ( last != null && last.getJoinable().isCollection() ) {
 						final QueryableCollection queryableCollection = (QueryableCollection) last.getJoinable();
 						if ( queryableCollection.isManyToMany() && last.isManyToManyWith( oj ) ) {
 							if ( queryableCollection.hasManyToManyOrdering() ) {
 								final String orderByString = queryableCollection.getManyToManyOrderByString( oj.getRHSAlias() );
 								buf.append( orderByString ).append(", ");
 							}
 						}
 					}
 				}
 			}
 			last = oj;
 		}
-		if ( buf.length()>0 ) buf.setLength( buf.length()-2 );
+		if ( buf.length()>0 ) {
+			buf.setLength( buf.length()-2 );
+		}
 		return buf.toString();
 	}
 
 	/**
 	 * Render the where condition for a (batch) load by identifier / collection key
 	 */
 	protected StringBuilder whereString(String alias, String[] columnNames, int batchSize) {
 		if ( columnNames.length==1 ) {
 			// if not a composite key, use "foo in (?, ?, ?)" for batching
 			// if no batch, and not a composite key, use "foo = ?"
 			InFragment in = new InFragment().setColumn( alias, columnNames[0] );
-			for ( int i=0; i<batchSize; i++ ) in.addValue("?");
+			for ( int i=0; i<batchSize; i++ ) {
+				in.addValue("?");
+			}
 			return new StringBuilder( in.toFragmentString() );
 		}
 		else {
 			//a composite key
 			ConditionFragment byId = new ConditionFragment()
 					.setTableAlias(alias)
 					.setCondition( columnNames, "?" );
 	
 			StringBuilder whereString = new StringBuilder();
 			if ( batchSize==1 ) {
 				// if no batch, use "foo = ? and bar = ?"
 				whereString.append( byId.toFragmentString() );
 			}
 			else {
 				// if a composite key, use "( (foo = ? and bar = ?) or (foo = ? and bar = ?) )" for batching
 				whereString.append('('); //TODO: unnecessary for databases with ANSI-style joins
 				DisjunctionFragment df = new DisjunctionFragment();
 				for ( int i=0; i<batchSize; i++ ) {
 					df.addCondition(byId);
 				}
 				whereString.append( df.toFragmentString() );
 				whereString.append(')'); //TODO: unnecessary for databases with ANSI-style joins
 			}
 			return whereString;
 		}
 	}
 
 
 	protected void initPersisters(final List associations, final LockMode lockMode) throws MappingException {
 		initPersisters( associations, new LockOptions(lockMode));
 	}
 
-	protected static interface AssociationInitCallback {
-		public static final AssociationInitCallback NO_CALLBACK = new AssociationInitCallback() {
+	protected interface AssociationInitCallback {
+		AssociationInitCallback NO_CALLBACK = new AssociationInitCallback() {
 			public void associationProcessed(OuterJoinableAssociation oja, int position) {
 			}
 		};
 
-		public void associationProcessed(OuterJoinableAssociation oja, int position);
+		void associationProcessed(OuterJoinableAssociation oja, int position);
 	}
 	protected void initPersisters(final List associations, final LockOptions lockOptions) throws MappingException {
 		initPersisters( associations, lockOptions, AssociationInitCallback.NO_CALLBACK );
 	}
 
 	protected void initPersisters(
 			final List associations,
 			final LockOptions lockOptions,
 			final AssociationInitCallback callback) throws MappingException {
 		final int joins = countEntityPersisters(associations);
 		final int collections = countCollectionPersisters(associations);
 
 		collectionOwners = collections==0 ? null : new int[collections];
 		collectionPersisters = collections==0 ? null : new CollectionPersister[collections];
 		collectionSuffixes = BasicLoader.generateSuffixes( joins + 1, collections );
 
 		this.lockOptions = lockOptions;
 
 		persisters = new Loadable[joins];
 		aliases = new String[joins];
 		owners = new int[joins];
 		ownerAssociationTypes = new EntityType[joins];
 		lockModeArray = ArrayHelper.fillArray( lockOptions.getLockMode(), joins );
 
 		int i=0;
 		int j=0;
 		Iterator iter = associations.iterator();
 		while ( iter.hasNext() ) {
 			final OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( !oj.isCollection() ) {
 				
 				persisters[i] = (Loadable) oj.getJoinable();
 				aliases[i] = oj.getRHSAlias();
 				owners[i] = oj.getOwner(associations);
 				ownerAssociationTypes[i] = (EntityType) oj.getJoinableType();
 				callback.associationProcessed( oj, i );
 				i++;
 				
 			}
 			else {
 				
 				QueryableCollection collPersister = (QueryableCollection) oj.getJoinable();
 				if ( oj.getJoinType()==JoinType.LEFT_OUTER_JOIN && ! oj.hasRestriction() ) {
 					//it must be a collection fetch
 					collectionPersisters[j] = collPersister;
 					collectionOwners[j] = oj.getOwner(associations);
 					j++;
 				}
 	
 				if ( collPersister.isOneToMany() ) {
 					persisters[i] = (Loadable) collPersister.getElementPersister();
 					aliases[i] = oj.getRHSAlias();
 					callback.associationProcessed( oj, i );
 					i++;
 				}
 			}
 		}
 
-		if ( ArrayHelper.isAllNegative(owners) ) owners = null;
+		if ( ArrayHelper.isAllNegative(owners) ) {
+			owners = null;
+		}
 		if ( collectionOwners!=null && ArrayHelper.isAllNegative(collectionOwners) ) {
 			collectionOwners = null;
 		}
 	}
 
 	/**
 	 * Generate a select list of columns containing all properties of the entity classes
 	 */
-	protected final String selectString(List associations)
-	throws MappingException {
+	protected final String selectString(List associations) throws MappingException {
 
 		if ( associations.size()==0 ) {
 			return "";
 		}
 		else {
 			StringBuilder buf = new StringBuilder( associations.size() * 100 );
 			int entityAliasCount=0;
 			int collectionAliasCount=0;
 			for ( int i=0; i<associations.size(); i++ ) {
 				OuterJoinableAssociation join = (OuterJoinableAssociation) associations.get(i);
 				OuterJoinableAssociation next = (i == associations.size() - 1)
 				        ? null
 				        : ( OuterJoinableAssociation ) associations.get( i + 1 );
 				final Joinable joinable = join.getJoinable();
 				final String entitySuffix = ( suffixes == null || entityAliasCount >= suffixes.length )
 				        ? null
 				        : suffixes[entityAliasCount];
 				final String collectionSuffix = ( collectionSuffixes == null || collectionAliasCount >= collectionSuffixes.length )
 				        ? null
 				        : collectionSuffixes[collectionAliasCount];
 				final String selectFragment = joinable.selectFragment(
 						next == null ? null : next.getJoinable(),
 						next == null ? null : next.getRHSAlias(),
 						join.getRHSAlias(),
 						entitySuffix,
 				        collectionSuffix,
 						join.getJoinType()==JoinType.LEFT_OUTER_JOIN
 				);
 				if (selectFragment.trim().length() > 0) {
 					buf.append(", ").append(selectFragment);
 				}
-				if ( joinable.consumesEntityAlias() ) entityAliasCount++;
+				if ( joinable.consumesEntityAlias() ) {
+					entityAliasCount++;
+				}
 				if ( joinable.consumesCollectionAlias() &&
 						join.getJoinType()==JoinType.LEFT_OUTER_JOIN &&
 						!join.hasRestriction() ) {
 					collectionAliasCount++;
 				}
 			}
 			return buf.toString();
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
index e9b47b4660..2567cf6da3 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
@@ -1,2729 +1,2721 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.WrongClassException;
 import org.hibernate.cache.spi.FilterKey;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.QueryKey;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.ReferenceCacheEntryImpl;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.dialect.pagination.NoopLimitHandler;
 import org.hibernate.engine.internal.CacheHelper;
 import org.hibernate.engine.internal.TwoPhaseLoad;
 import org.hibernate.engine.jdbc.ColumnNameCache;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.EntityUniqueKey;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.PostLoadEvent;
 import org.hibernate.event.spi.PreLoadEvent;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FetchingScrollableResultsImpl;
 import org.hibernate.internal.ScrollableResultsImpl;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.UniqueKeyLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.transform.CacheableResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 import org.jboss.logging.Logger;
 
 /**
  * Abstract superclass of object loading (and querying) strategies. This class implements
  * useful common functionality that concrete loaders delegate to. It is not intended that this
  * functionality would be directly accessed by client code. (Hence, all methods of this class
  * are declared <tt>protected</tt> or <tt>private</tt>.) This class relies heavily upon the
  * <tt>Loadable</tt> interface, which is the contract between this class and
  * <tt>EntityPersister</tt>s that may be loaded by it.<br>
  * <br>
  * The present implementation is able to load any number of columns of entities and at most
  * one collection role per query.
  *
  * @author Gavin King
  * @see org.hibernate.persister.entity.Loadable
  */
 public abstract class Loader {
 
 	protected static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Loader.class.getName());
 	protected static final boolean DEBUG_ENABLED = LOG.isDebugEnabled();
 	private final SessionFactoryImplementor factory;
 	private volatile ColumnNameCache columnNameCache;
 
 	private final boolean referenceCachingEnabled;
 
 	public Loader(SessionFactoryImplementor factory) {
 		this.factory = factory;
 		this.referenceCachingEnabled = factory.getSettings().isDirectReferenceCacheEntriesEnabled();
 	}
 
 	/**
 	 * The SQL query string to be called; implemented by all subclasses
 	 *
 	 * @return The sql command this loader should use to get its {@link ResultSet}.
 	 */
 	public abstract String getSQLString();
 
 	/**
 	 * An array of persisters of entity classes contained in each row of results;
 	 * implemented by all subclasses
 	 *
 	 * @return The entity persisters.
 	 */
 	protected abstract Loadable[] getEntityPersisters();
 
 	/**
 	 * An array indicating whether the entities have eager property fetching
 	 * enabled.
 	 *
 	 * @return Eager property fetching indicators.
 	 */
 	protected boolean[] getEntityEagerPropertyFetches() {
 		return null;
 	}
 
 	/**
 	 * An array of indexes of the entity that owns a one-to-one association
 	 * to the entity at the given index (-1 if there is no "owner").  The
 	 * indexes contained here are relative to the result of
 	 * {@link #getEntityPersisters}.
 	 *
 	 * @return The owner indicators (see discussion above).
 	 */
 	protected int[] getOwners() {
 		return null;
 	}
 
 	/**
 	 * An array of the owner types corresponding to the {@link #getOwners()}
 	 * returns.  Indices indicating no owner would be null here.
 	 *
 	 * @return The types for the owners.
 	 */
 	protected EntityType[] getOwnerAssociationTypes() {
 		return null;
 	}
 
 	/**
 	 * An (optional) persister for a collection to be initialized; only
 	 * collection loaders return a non-null value
 	 */
 	protected CollectionPersister[] getCollectionPersisters() {
 		return null;
 	}
 
 	/**
 	 * Get the index of the entity that owns the collection, or -1
 	 * if there is no owner in the query results (ie. in the case of a
 	 * collection initializer) or no collection.
 	 */
 	protected int[] getCollectionOwners() {
 		return null;
 	}
 
 	protected int[][] getCompositeKeyManyToOneTargetIndices() {
 		return null;
 	}
 
 	/**
 	 * What lock options does this load entities with?
 	 *
 	 * @param lockOptions a collection of lock options specified dynamically via the Query interface
 	 */
 	//protected abstract LockOptions[] getLockOptions(Map lockOptions);
 	protected abstract LockMode[] getLockModes(LockOptions lockOptions);
 
 	/**
 	 * Append <tt>FOR UPDATE OF</tt> clause, if necessary. This
 	 * empty superclass implementation merely returns its first
 	 * argument.
 	 */
 	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 		return sql;
 	}
 
 	/**
 	 * Does this query return objects that might be already cached
 	 * by the session, whose lock mode may need upgrading
 	 */
 	protected boolean upgradeLocks() {
 		return false;
 	}
 
 	/**
 	 * Return false is this loader is a batch entity loader
 	 */
 	protected boolean isSingleRowLoader() {
 		return false;
 	}
 
 	/**
 	 * Get the SQL table aliases of entities whose
 	 * associations are subselect-loadable, returning
 	 * null if this loader does not support subselect
 	 * loading
 	 */
 	protected String[] getAliases() {
 		return null;
 	}
 
 	/**
 	 * Modify the SQL, adding lock hints and comments, if necessary
 	 */
 	protected String preprocessSQL(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 		sql = applyLocks( sql, parameters, dialect, afterLoadActions );
 		
 		// Keep this here, rather than moving to Select.  Some Dialects may need the hint to be appended to the very
 		// end or beginning of the finalized SQL statement, so wait until everything is processed.
 		if ( parameters.getQueryHints() != null && parameters.getQueryHints().size() > 0 ) {
 			sql = dialect.getQueryHintString( sql, parameters.getQueryHints() );
 		}
 		
 		return getFactory().getSettings().isCommentsEnabled()
 				? prependComment( sql, parameters )
 				: sql;
 	}
 
 	protected boolean shouldUseFollowOnLocking(
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) {
 		if ( dialect.useFollowOnLocking() ) {
 			// currently only one lock mode is allowed in follow-on locking
 			final LockMode lockMode = determineFollowOnLockMode( parameters.getLockOptions() );
 			final LockOptions lockOptions = new LockOptions( lockMode );
 			if ( lockOptions.getLockMode() != LockMode.UPGRADE_SKIPLOCKED ) {
 				LOG.usingFollowOnLocking();
 				lockOptions.setTimeOut( parameters.getLockOptions().getTimeOut() );
 				lockOptions.setScope( parameters.getLockOptions().getScope() );
 				afterLoadActions.add(
 						new AfterLoadAction() {
 							@Override
 							public void afterLoad(SessionImplementor session, Object entity, Loadable persister) {
 								( (Session) session ).buildLockRequest( lockOptions ).lock( persister.getEntityName(), entity );
 							}
 						}
 				);
 				parameters.setLockOptions( new LockOptions() );
 				return true;
 			}
 		}
 		return false;
 	}
 
 	protected LockMode determineFollowOnLockMode(LockOptions lockOptions) {
 		final LockMode lockModeToUse = lockOptions.findGreatestLockMode();
 
 		if ( lockOptions.hasAliasSpecificLockModes() ) {
 			LOG.aliasSpecificLockingWithFollowOnLocking( lockModeToUse );
 		}
 
 		return lockModeToUse;
 	}
 
 	private String prependComment(String sql, QueryParameters parameters) {
 		String comment = parameters.getComment();
 		if ( comment == null ) {
 			return sql;
 		}
 		else {
 			return new StringBuilder( comment.length() + sql.length() + 5 )
 					.append( "/* " )
 					.append( comment )
 					.append( " */ " )
 					.append( sql )
 					.toString();
 		}
 	}
 
 	/**
 	 * Execute an SQL query and attempt to instantiate instances of the class mapped by the given
 	 * persister from each row of the <tt>ResultSet</tt>. If an object is supplied, will attempt to
 	 * initialize that object. If a collection is supplied, attempt to initialize that collection.
 	 */
 	public List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException, SQLException {
 		return doQueryAndInitializeNonLazyCollections(
 				session,
 				queryParameters,
 				returnProxies,
 				null
 		);
 	}
 
 	public List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer)
 			throws HibernateException, SQLException {
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 		if ( queryParameters.isReadOnlyInitialized() ) {
 			// The read-only/modifiable mode for the query was explicitly set.
 			// Temporarily set the default read-only/modifiable setting to the query's setting.
 			persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 		}
 		else {
 			// The read-only/modifiable setting for the query was not initialized.
 			// Use the default read-only/modifiable from the persistence context instead.
 			queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 		}
 		persistenceContext.beforeLoad();
 		List result;
 		try {
 			try {
 				result = doQuery( session, queryParameters, returnProxies, forcedResultTransformer );
 			}
 			finally {
 				persistenceContext.afterLoad();
 			}
 			persistenceContext.initializeNonLazyCollections();
 		}
 		finally {
 			// Restore the original default
 			persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 		}
 		return result;
 	}
 
 	/**
 	 * Loads a single row from the result set.  This is the processing used from the
 	 * ScrollableResults where no collection fetches were encountered.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSingleRow(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		final Object result;
 		try {
 			result = getRowFromResultSet(
 					resultSet,
 					session,
 					queryParameters,
 					getLockModes( queryParameters.getLockOptions() ),
 					null,
 					hydratedObjects,
 					new EntityKey[entitySpan],
 					returnProxies
 				);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not read next row of results",
 					getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 		);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private Object sequentialLoad(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final EntityKey keyToRead) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		Object result = null;
 		final EntityKey[] loadedKeys = new EntityKey[entitySpan];
 
 		try {
 			do {
 				Object loaded = getRowFromResultSet(
 						resultSet,
 						session,
 						queryParameters,
 						getLockModes( queryParameters.getLockOptions() ),
 						null,
 						hydratedObjects,
 						loadedKeys,
 						returnProxies
 				);
 				if ( ! keyToRead.equals( loadedKeys[0] ) ) {
 					throw new AssertionFailure(
 							String.format(
 									"Unexpected key read for row; expected [%s]; actual [%s]",
 									keyToRead,
 									loadedKeys[0] )
 					);
 				}
 				if ( result == null ) {
 					result = loaded;
 				}
 			}
 			while ( resultSet.next() &&
 					isCurrentRowForSameEntity( keyToRead, 0, resultSet, session ) );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not doAfterTransactionCompletion sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 		);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private boolean isCurrentRowForSameEntity(
 			final EntityKey keyToRead,
 			final int persisterIndex,
 			final ResultSet resultSet,
 			final SessionImplementor session) throws SQLException {
 		EntityKey currentRowKey = getKeyFromResultSet(
 				persisterIndex, getEntityPersisters()[persisterIndex], null, resultSet, session
 		);
 		return keyToRead.equals( currentRowKey );
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsForward(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isAfterLast() ) {
 				// don't even bother trying to read further
 				return null;
 			}
 
 			if ( resultSet.isBeforeFirst() ) {
 				resultSet.next();
 			}
 
 			// We call getKeyFromResultSet() here so that we can know the
 			// key value upon which to perform the breaking logic.  However,
 			// it is also then called from getRowFromResultSet() which is certainly
 			// not the most efficient.  But the call here is needed, and there
 			// currently is no other way without refactoring of the doQuery()/getRowFromResultSet()
 			// methods
 			final EntityKey currentKey = getKeyFromResultSet(
 					0,
 					getEntityPersisters()[0],
 					null,
 					resultSet,
 					session
 				);
 
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, currentKey );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not perform sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsReverse(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final boolean isLogicallyAfterLast) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isFirst() ) {
 				// don't even bother trying to read any further
 				return null;
 			}
 
 			EntityKey keyToRead = null;
 			// This check is needed since processing leaves the cursor
 			// after the last physical row for the current logical row;
 			// thus if we are after the last physical row, this might be
 			// caused by either:
 			//      1) scrolling to the last logical row
 			//      2) scrolling past the last logical row
 			// In the latter scenario, the previous logical row
 			// really is the last logical row.
 			//
 			// In all other cases, we should process back two
 			// logical records (the current logic row, plus the
 			// previous logical row).
 			if ( resultSet.isAfterLast() && isLogicallyAfterLast ) {
 				// position cursor to the last row
 				resultSet.last();
 				keyToRead = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 			}
 			else {
 				// Since the result set cursor is always left at the first
 				// physical row after the "last processed", we need to jump
 				// back one position to get the key value we are interested
 				// in skipping
 				resultSet.previous();
 
 				// sequentially read the result set in reverse until we recognize
 				// a change in the key value.  At that point, we are pointed at
 				// the last physical sequential row for the logical row in which
 				// we are interested in processing
 				boolean firstPass = true;
 				final EntityKey lastKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 				while ( resultSet.previous() ) {
 					EntityKey checkKey = getKeyFromResultSet(
 							0,
 							getEntityPersisters()[0],
 							null,
 							resultSet,
 							session
 						);
 
 					if ( firstPass ) {
 						firstPass = false;
 						keyToRead = checkKey;
 					}
 
 					if ( !lastKey.equals( checkKey ) ) {
 						break;
 					}
 				}
 
 			}
 
 			// Read backwards until we read past the first physical sequential
 			// row with the key we are interested in loading
 			while ( resultSet.previous() ) {
 				EntityKey checkKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 
 				if ( !keyToRead.equals( checkKey ) ) {
 					break;
 				}
 			}
 
 			// Finally, read ahead one row to position result set cursor
 			// at the first physical row we are interested in loading
 			resultSet.next();
 
 			// and doAfterTransactionCompletion the load
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, keyToRead );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not doAfterTransactionCompletion sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 	}
 
 	private static EntityKey getOptionalObjectKey(QueryParameters queryParameters, SessionImplementor session) {
 		final Object optionalObject = queryParameters.getOptionalObject();
 		final Serializable optionalId = queryParameters.getOptionalId();
 		final String optionalEntityName = queryParameters.getOptionalEntityName();
 
 		if ( optionalObject != null && optionalEntityName != null ) {
 			return session.generateEntityKey( optionalId, session.getEntityPersister( optionalEntityName, optionalObject ) );
 		}
 		else {
 			return null;
 		}
 
 	}
 
 	private Object getRowFromResultSet(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final LockMode[] lockModesArray,
 			final EntityKey optionalObjectKey,
 			final List hydratedObjects,
 			final EntityKey[] keys,
 			boolean returnProxies) throws SQLException, HibernateException {
 		return getRowFromResultSet(
 				resultSet,
 				session,
 				queryParameters,
 				lockModesArray,
 				optionalObjectKey,
 				hydratedObjects,
 				keys,
 				returnProxies,
 				null
 		);
 	}
 
 	private Object getRowFromResultSet(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final LockMode[] lockModesArray,
 			final EntityKey optionalObjectKey,
 			final List hydratedObjects,
 			final EntityKey[] keys,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 		final Loadable[] persisters = getEntityPersisters();
 		final int entitySpan = persisters.length;
 		extractKeysFromResultSet( persisters, queryParameters, resultSet, session, keys, lockModesArray, hydratedObjects );
 
 		registerNonExists( keys, persisters, session );
 
 		// this call is side-effecty
 		Object[] row = getRow(
 				resultSet,
 				persisters,
 				keys,
 				queryParameters.getOptionalObject(),
 				optionalObjectKey,
 				lockModesArray,
 				hydratedObjects,
 				session
 		);
 
 		readCollectionElements( row, resultSet, session );
 
 		if ( returnProxies ) {
 			// now get an existing proxy for each row element (if there is one)
 			for ( int i = 0; i < entitySpan; i++ ) {
 				Object entity = row[i];
 				Object proxy = session.getPersistenceContext().proxyFor( persisters[i], keys[i], entity );
 				if ( entity != proxy ) {
 					// force the proxy to resolve itself
 					( (HibernateProxy) proxy ).getHibernateLazyInitializer().setImplementation(entity);
 					row[i] = proxy;
 				}
 			}
 		}
 
 		applyPostLoadLocks( row, lockModesArray, session );
 
 		return forcedResultTransformer == null
 				? getResultColumnOrRow( row, queryParameters.getResultTransformer(), resultSet, session )
 				: forcedResultTransformer.transformTuple( getResultRow( row, resultSet, session ), getResultRowAliases() )
 		;
 	}
 
 	protected void extractKeysFromResultSet(
 			Loadable[] persisters,
 			QueryParameters queryParameters,
 			ResultSet resultSet,
 			SessionImplementor session,
 			EntityKey[] keys,
 			LockMode[] lockModes,
 			List hydratedObjects) throws SQLException {
 		final int entitySpan = persisters.length;
 
 		final int numberOfPersistersToProcess;
 		final Serializable optionalId = queryParameters.getOptionalId();
 		if ( isSingleRowLoader() && optionalId != null ) {
 			keys[ entitySpan - 1 ] = session.generateEntityKey( optionalId, persisters[ entitySpan - 1 ] );
 			// skip the last persister below...
 			numberOfPersistersToProcess = entitySpan - 1;
 		}
 		else {
 			numberOfPersistersToProcess = entitySpan;
 		}
 
 		final Object[] hydratedKeyState = new Object[numberOfPersistersToProcess];
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			hydratedKeyState[i] = idType.hydrate( resultSet, getEntityAliases()[i].getSuffixedKeyAliases(), session, null );
 		}
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			if ( idType.isComponentType() && getCompositeKeyManyToOneTargetIndices() != null ) {
 				// we may need to force resolve any key-many-to-one(s)
 				int[] keyManyToOneTargetIndices = getCompositeKeyManyToOneTargetIndices()[i];
 				// todo : better solution is to order the index processing based on target indices
 				//		that would account for multiple levels whereas this scheme does not
 				if ( keyManyToOneTargetIndices != null ) {
 					for ( int targetIndex : keyManyToOneTargetIndices ) {
 						if ( targetIndex < numberOfPersistersToProcess ) {
 							final Type targetIdType = persisters[targetIndex].getIdentifierType();
 							final Serializable targetId = (Serializable) targetIdType.resolve(
 									hydratedKeyState[targetIndex],
 									session,
 									null
 							);
 							// todo : need a way to signal that this key is resolved and its data resolved
 							keys[targetIndex] = session.generateEntityKey( targetId, persisters[targetIndex] );
 						}
 
 						// this part copied from #getRow, this section could be refactored out
 						Object object = session.getEntityUsingInterceptor( keys[targetIndex] );
 						if ( object != null ) {
 							//its already loaded so don't need to hydrate it
 							instanceAlreadyLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									keys[targetIndex],
 									object,
 									lockModes[targetIndex],
 									session
 							);
 						}
 						else {
 							instanceNotYetLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									getEntityAliases()[targetIndex].getRowIdAlias(),
 									keys[targetIndex],
 									lockModes[targetIndex],
 									getOptionalObjectKey( queryParameters, session ),
 									queryParameters.getOptionalObject(),
 									hydratedObjects,
 									session
 							);
 						}
 					}
 				}
 			}
 			final Serializable resolvedId = (Serializable) idType.resolve( hydratedKeyState[i], session, null );
 			keys[i] = resolvedId == null ? null : session.generateEntityKey( resolvedId, persisters[i] );
 		}
 	}
 
 	protected void applyPostLoadLocks(Object[] row, LockMode[] lockModesArray, SessionImplementor session) {
 	}
 
 	/**
 	 * Read any collection elements contained in a single row of the result set
 	 */
 	private void readCollectionElements(Object[] row, ResultSet resultSet, SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		//TODO: make this handle multiple collection roles!
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 
 			final CollectionAliases[] descriptors = getCollectionAliases();
 			final int[] collectionOwners = getCollectionOwners();
 
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 
 				final boolean hasCollectionOwners = collectionOwners !=null &&
 						collectionOwners[i] > -1;
 				//true if this is a query and we are loading multiple instances of the same collection role
 				//otherwise this is a CollectionInitializer and we are loading up a single collection or batch
 
 				final Object owner = hasCollectionOwners ?
 						row[ collectionOwners[i] ] :
 						null; //if null, owner will be retrieved from session
 
 				final CollectionPersister collectionPersister = collectionPersisters[i];
 				final Serializable key;
 				if ( owner == null ) {
 					key = null;
 				}
 				else {
 					key = collectionPersister.getCollectionType().getKeyOfOwner( owner, session );
 					//TODO: old version did not require hashmap lookup:
 					//keys[collectionOwner].getIdentifier()
 				}
 
 				readCollectionElement(
 						owner,
 						key,
 						collectionPersister,
 						descriptors[i],
 						resultSet,
 						session
 					);
 
 			}
 
 		}
 	}
 
 	private List doQuery(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 
 		final RowSelection selection = queryParameters.getRowSelection();
 		final int maxRows = LimitHelper.hasMaxRows( selection ) ?
 				selection.getMaxRows() :
 				Integer.MAX_VALUE;
 
 		final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 
 		final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
 		final ResultSet rs = wrapper.getResultSet();
 		final Statement st = wrapper.getStatement();
 
 // would be great to move all this below here into another method that could also be used
 // from the new scrolling stuff.
 //
 // Would need to change the way the max-row stuff is handled (i.e. behind an interface) so
 // that I could do the control breaking at the means to know when to stop
 
 		try {
 			return processResultSet( rs, queryParameters, session, returnProxies, forcedResultTransformer, maxRows, afterLoadActions );
 		}
 		finally {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 		}
 
 	}
 
 	protected List processResultSet(
 			ResultSet rs,
 			QueryParameters queryParameters,
 			SessionImplementor session,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer,
 			int maxRows,
 			List<AfterLoadAction> afterLoadActions) throws SQLException {
 		final int entitySpan = getEntityPersisters().length;
 		final EntityKey optionalObjectKey = getOptionalObjectKey( queryParameters, session );
 		final LockMode[] lockModesArray = getLockModes( queryParameters.getLockOptions() );
 		final boolean createSubselects = isSubselectLoadingEnabled();
 		final List subselectResultKeys = createSubselects ? new ArrayList() : null;
 		final ArrayList hydratedObjects = entitySpan == 0 ? null : new ArrayList( entitySpan * 10 );
 		final List results = new ArrayList();
 
 		handleEmptyCollections( queryParameters.getCollectionKeys(), rs, session );
 		EntityKey[] keys = new EntityKey[entitySpan]; //we can reuse it for each row
 		LOG.trace( "Processing result set" );
 		int count;
 
 		for ( count = 0; count < maxRows && rs.next(); count++ ) {
-			if ( DEBUG_ENABLED )
+			if ( DEBUG_ENABLED ) {
 				LOG.debugf( "Result set row: %s", count );
+			}
 			Object result = getRowFromResultSet(
 					rs,
 					session,
 					queryParameters,
 					lockModesArray,
 					optionalObjectKey,
 					hydratedObjects,
 					keys,
 					returnProxies,
 					forcedResultTransformer
 			);
 			results.add( result );
 			if ( createSubselects ) {
 				subselectResultKeys.add(keys);
 				keys = new EntityKey[entitySpan]; //can't reuse in this case
 			}
 		}
 
 		LOG.tracev( "Done processing result set ({0} rows)", count );
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				rs,
 				session,
 				queryParameters.isReadOnly( session ),
 				afterLoadActions
 		);
 		if ( createSubselects ) {
 			createSubselects( subselectResultKeys, queryParameters, session );
 		}
 		return results;
 	}
 
 	protected boolean isSubselectLoadingEnabled() {
 		return false;
 	}
 
 	protected boolean hasSubselectLoadableCollections() {
 		final Loadable[] loadables = getEntityPersisters();
 		for ( Loadable loadable : loadables ) {
 			if ( loadable.hasSubselectLoadableCollections() ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private static Set[] transpose( List keys ) {
 		Set[] result = new Set[ ( ( EntityKey[] ) keys.get(0) ).length ];
 		for ( int j=0; j<result.length; j++ ) {
 			result[j] = new HashSet( keys.size() );
 			for ( Object key : keys ) {
 				result[j].add( ( (EntityKey[]) key )[j] );
 			}
 		}
 		return result;
 	}
 
 	private void createSubselects(List keys, QueryParameters queryParameters, SessionImplementor session) {
 		if ( keys.size() > 1 ) { //if we only returned one entity, query by key is more efficient
 
 			Set[] keySets = transpose(keys);
 
 			Map namedParameterLocMap = buildNamedParameterLocMap( queryParameters );
 
 			final Loadable[] loadables = getEntityPersisters();
 			final String[] aliases = getAliases();
-			final Iterator iter = keys.iterator();
-			while ( iter.hasNext() ) {
-
-				final EntityKey[] rowKeys = (EntityKey[]) iter.next();
-				for ( int i=0; i<rowKeys.length; i++ ) {
+			for ( Object key : keys ) {
+				final EntityKey[] rowKeys = (EntityKey[]) key;
+				for ( int i = 0; i < rowKeys.length; i++ ) {
 
-					if ( rowKeys[i]!=null && loadables[i].hasSubselectLoadableCollections() ) {
+					if ( rowKeys[i] != null && loadables[i].hasSubselectLoadableCollections() ) {
 
 						SubselectFetch subselectFetch = new SubselectFetch(
 								//getSQLString(),
 								aliases[i],
 								loadables[i],
 								queryParameters,
 								keySets[i],
 								namedParameterLocMap
-							);
+						);
 
 						session.getPersistenceContext()
 								.getBatchFetchQueue()
 								.addSubselect( rowKeys[i], subselectFetch );
 					}
 
 				}
 
 			}
 		}
 	}
 
 	private Map buildNamedParameterLocMap(QueryParameters queryParameters) {
 		if ( queryParameters.getNamedParameters()!=null ) {
 			final Map namedParameterLocMap = new HashMap();
 			for(String name : queryParameters.getNamedParameters().keySet()){
 				namedParameterLocMap.put(
 						name,
 						getNamedParameterLocs(name)
 				);
 			}
 			return namedParameterLocMap;
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly) throws HibernateException {
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSetId,
 				session,
 				readOnly,
 				Collections.<AfterLoadAction>emptyList()
 		);
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 				if ( collectionPersisters[i].isArray() ) {
 					//for arrays, we should end the collection load before resolving
 					//the entities, since the actual array instances are not instantiated
 					//during loading
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
 				}
 			}
 		}
 
 		//important: reuse the same event instances for performance!
 		final PreLoadEvent pre;
 		final PostLoadEvent post;
 		if ( session.isEventSource() ) {
 			pre = new PreLoadEvent( (EventSource) session );
 			post = new PostLoadEvent( (EventSource) session );
 		}
 		else {
 			pre = null;
 			post = null;
 		}
 
 		if ( hydratedObjects!=null ) {
 			int hydratedObjectsSize = hydratedObjects.size();
 			LOG.tracev( "Total objects hydrated: {0}", hydratedObjectsSize );
-			for ( int i = 0; i < hydratedObjectsSize; i++ ) {
-				TwoPhaseLoad.initializeEntity( hydratedObjects.get(i), readOnly, session, pre );
+			for ( Object hydratedObject : hydratedObjects ) {
+				TwoPhaseLoad.initializeEntity( hydratedObject, readOnly, session, pre );
 			}
 		}
 
 		if ( collectionPersisters != null ) {
-			for ( int i=0; i<collectionPersisters.length; i++ ) {
-				if ( !collectionPersisters[i].isArray() ) {
+			for ( CollectionPersister collectionPersister : collectionPersisters ) {
+				if ( !collectionPersister.isArray() ) {
 					//for sets, we should end the collection load after resolving
 					//the entities, since we might call hashCode() on the elements
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
-					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
+					endCollectionLoad( resultSetId, session, collectionPersister );
 				}
 			}
 		}
 		
 		// Until this entire method is refactored w/ polymorphism, postLoad was
 		// split off from initializeEntity.  It *must* occur after
 		// endCollectionLoad to ensure the collection is in the
 		// persistence context.
 		if ( hydratedObjects != null ) {
 			for ( Object hydratedObject : hydratedObjects ) {
 				TwoPhaseLoad.postLoad( hydratedObject, session, post );
 				if ( afterLoadActions != null ) {
 					for ( AfterLoadAction afterLoadAction : afterLoadActions ) {
 						final EntityEntry entityEntry = session.getPersistenceContext().getEntry( hydratedObject );
 						if ( entityEntry == null ) {
 							// big problem
 							throw new HibernateException( "Could not locate EntityEntry immediately after two-phase load" );
 						}
 						afterLoadAction.afterLoad( session, hydratedObject, (Loadable) entityEntry.getPersister() );
 					}
 				}
 			}
 		}
 	}
 
 	private void endCollectionLoad(
 			final Object resultSetId,
 			final SessionImplementor session,
 			final CollectionPersister collectionPersister) {
 		//this is a query and we are loading multiple instances of the same collection role
 		session.getPersistenceContext()
 				.getLoadContexts()
 				.getCollectionLoadContext( ( ResultSet ) resultSetId )
 				.endLoadingCollections( collectionPersister );
 	}
 
 	/**
 	 * Determine the actual ResultTransformer that will be used to
 	 * transform query results.
 	 *
 	 * @param resultTransformer the specified result transformer
 	 * @return the actual result transformer
 	 */
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return resultTransformer;
 	}
 
 	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		return results;
 	}
 
 	/**
 	 * Are rows transformed immediately after being read from the ResultSet?
 	 * @return true, if getResultColumnOrRow() transforms the results; false, otherwise
 	 */
 	protected boolean areResultSetRowsTransformedImmediately() {
 		return false;
 	}
 
 	/**
 	 * Returns the aliases that corresponding to a result row.
 	 * @return Returns the aliases that corresponding to a result row.
 	 */
 	protected String[] getResultRowAliases() {
 		 return null;
 	}
 
 	/**
 	 * Get the actual object that is returned in the user-visible result list.
 	 * This empty implementation merely returns its first argument. This is
 	 * overridden by some subclasses.
 	 */
 	protected Object getResultColumnOrRow(
 			Object[] row,
 			ResultTransformer transformer,
 			ResultSet rs,
 			SessionImplementor session) throws SQLException, HibernateException {
 		return row;
 	}
 
 	protected boolean[] includeInResultRow() {
 		return null;
 	}
 
 	protected Object[] getResultRow(
 			Object[] row,
 			ResultSet rs,
 			SessionImplementor session) throws SQLException, HibernateException {
 		return row;
 	}
 
 	/**
 	 * For missing objects associated by one-to-one with another object in the
 	 * result set, register the fact that the the object is missing with the
 	 * session.
 	 */
 	private void registerNonExists(
 			final EntityKey[] keys,
 			final Loadable[] persisters,
 			final SessionImplementor session) {
 
 		final int[] owners = getOwners();
 		if ( owners != null ) {
 
 			EntityType[] ownerAssociationTypes = getOwnerAssociationTypes();
 			for ( int i = 0; i < keys.length; i++ ) {
 
 				int owner = owners[i];
 				if ( owner > -1 ) {
 					EntityKey ownerKey = keys[owner];
 					if ( keys[i] == null && ownerKey != null ) {
 
 						final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 						/*final boolean isPrimaryKey;
 						final boolean isSpecialOneToOne;
 						if ( ownerAssociationTypes == null || ownerAssociationTypes[i] == null ) {
 							isPrimaryKey = true;
 							isSpecialOneToOne = false;
 						}
 						else {
 							isPrimaryKey = ownerAssociationTypes[i].getRHSUniqueKeyPropertyName()==null;
 							isSpecialOneToOne = ownerAssociationTypes[i].getLHSPropertyName()!=null;
 						}*/
 
 						//TODO: can we *always* use the "null property" approach for everything?
 						/*if ( isPrimaryKey && !isSpecialOneToOne ) {
 							persistenceContext.addNonExistantEntityKey(
 									new EntityKey( ownerKey.getIdentifier(), persisters[i], session.getEntityMode() )
 							);
 						}
 						else if ( isSpecialOneToOne ) {*/
 						boolean isOneToOneAssociation = ownerAssociationTypes!=null &&
 								ownerAssociationTypes[i]!=null &&
 								ownerAssociationTypes[i].isOneToOne();
 						if ( isOneToOneAssociation ) {
 							persistenceContext.addNullProperty( ownerKey,
 									ownerAssociationTypes[i].getPropertyName() );
 						}
 						/*}
 						else {
 							persistenceContext.addNonExistantEntityUniqueKey( new EntityUniqueKey(
 									persisters[i].getEntityName(),
 									ownerAssociationTypes[i].getRHSUniqueKeyPropertyName(),
 									ownerKey.getIdentifier(),
 									persisters[owner].getIdentifierType(),
 									session.getEntityMode()
 							) );
 						}*/
 					}
 				}
 			}
 		}
 	}
 
 	/**
 	 * Read one collection element from the current row of the JDBC result set
 	 */
 	private void readCollectionElement(
 			final Object optionalOwner,
 			final Serializable optionalKey,
 			final CollectionPersister persister,
 			final CollectionAliases descriptor,
 			final ResultSet rs,
 			final SessionImplementor session)
 	throws HibernateException, SQLException {
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		final Serializable collectionRowKey = (Serializable) persister.readKey(
 				rs,
 				descriptor.getSuffixedKeyAliases(),
 				session
 			);
 
 		if ( collectionRowKey != null ) {
 			// we found a collection element in the result set
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Found row of collection: %s",
 						MessageHelper.collectionInfoString( persister, collectionRowKey, getFactory() ) );
 			}
 
 			Object owner = optionalOwner;
 			if ( owner == null ) {
 				owner = persistenceContext.getCollectionOwner( collectionRowKey, persister );
 				if ( owner == null ) {
 					//TODO: This is assertion is disabled because there is a bug that means the
 					//	  original owner of a transient, uninitialized collection is not known
 					//	  if the collection is re-referenced by a different object associated
 					//	  with the current Session
 					//throw new AssertionFailure("bug loading unowned collection");
 				}
 			}
 
 			PersistentCollection rowCollection = persistenceContext.getLoadContexts()
 					.getCollectionLoadContext( rs )
 					.getLoadingCollection( persister, collectionRowKey );
 
 			if ( rowCollection != null ) {
 				rowCollection.readFrom( rs, persister, descriptor, owner );
 			}
 
 		}
 		else if ( optionalKey != null ) {
 			// we did not find a collection element in the result set, so we
 			// ensure that a collection is created with the owner's identifier,
 			// since what we have is an empty collection
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Result set contains (possibly empty) collection: %s",
 						MessageHelper.collectionInfoString( persister, optionalKey, getFactory() ) );
 			}
 
 			persistenceContext.getLoadContexts()
 					.getCollectionLoadContext( rs )
 					.getLoadingCollection( persister, optionalKey ); // handle empty collection
 
 		}
 
 		// else no collection element, but also no owner
 
 	}
 
 	/**
 	 * If this is a collection initializer, we need to tell the session that a collection
 	 * is being initialized, to account for the possibility of the collection having
 	 * no elements (hence no rows in the result set).
 	 */
 	private void handleEmptyCollections(
 			final Serializable[] keys,
 			final Object resultSetId,
 			final SessionImplementor session) {
 
 		if ( keys != null ) {
 			final boolean debugEnabled = LOG.isDebugEnabled();
 			// this is a collection initializer, so we must create a collection
 			// for each of the passed-in keys, to account for the possibility
 			// that the collection is empty and has no rows in the result set
 			CollectionPersister[] collectionPersisters = getCollectionPersisters();
-			for ( int j=0; j<collectionPersisters.length; j++ ) {
+			for ( CollectionPersister collectionPersister : collectionPersisters )
 				for ( int i = 0; i < keys.length; i++ ) {
 					//handle empty collections
-
 					if ( debugEnabled ) {
-						LOG.debugf( "Result set contains (possibly empty) collection: %s",
-								MessageHelper.collectionInfoString( collectionPersisters[j], keys[i], getFactory() ) );
+						LOG.debugf(
+								"Result set contains (possibly empty) collection: %s",
+								MessageHelper.collectionInfoString( collectionPersister, keys[i], getFactory() )
+						);
 					}
 
 					session.getPersistenceContext()
 							.getLoadContexts()
-							.getCollectionLoadContext( ( ResultSet ) resultSetId )
-							.getLoadingCollection( collectionPersisters[j], keys[i] );
+							.getCollectionLoadContext( (ResultSet) resultSetId )
+							.getLoadingCollection( collectionPersister, keys[i] );
 				}
-			}
 		}
 
 		// else this is not a collection initializer (and empty collections will
 		// be detected by looking for the owner's identifier in the result set)
 	}
 
 	/**
 	 * Read a row of <tt>Key</tt>s from the <tt>ResultSet</tt> into the given array.
 	 * Warning: this method is side-effecty.
 	 * <p/>
 	 * If an <tt>id</tt> is given, don't bother going to the <tt>ResultSet</tt>.
 	 */
 	private EntityKey getKeyFromResultSet(
 			final int i,
 			final Loadable persister,
 			final Serializable id,
 			final ResultSet rs,
 			final SessionImplementor session) throws HibernateException, SQLException {
 
 		Serializable resultId;
 
 		// if we know there is exactly 1 row, we can skip.
 		// it would be great if we could _always_ skip this;
 		// it is a problem for <key-many-to-one>
 
 		if ( isSingleRowLoader() && id != null ) {
 			resultId = id;
 		}
 		else {
-
-			Type idType = persister.getIdentifierType();
+			final Type idType = persister.getIdentifierType();
 			resultId = (Serializable) idType.nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedKeyAliases(),
 					session,
 					null //problematic for <key-many-to-one>!
-				);
+			);
 
 			final boolean idIsResultId = id != null &&
 					resultId != null &&
 					idType.isEqual( id, resultId, factory );
 
-			if ( idIsResultId ) resultId = id; //use the id passed in
+			if ( idIsResultId ) {
+				resultId = id; //use the id passed in
+			}
 		}
 
 		return resultId == null ? null : session.generateEntityKey( resultId, persister );
 	}
 
 	/**
 	 * Check the version of the object in the <tt>ResultSet</tt> against
 	 * the object version in the session cache, throwing an exception
 	 * if the version numbers are different
 	 */
 	private void checkVersion(
 			final int i,
 			final Loadable persister,
 			final Serializable id,
 			final Object entity,
 			final ResultSet rs,
-			final SessionImplementor session)
-	throws HibernateException, SQLException {
+			final SessionImplementor session) throws HibernateException, SQLException {
 
 		Object version = session.getPersistenceContext().getEntry( entity ).getVersion();
 
 		if ( version != null ) { //null version means the object is in the process of being loaded somewhere else in the ResultSet
-			VersionType versionType = persister.getVersionType();
-			Object currentVersion = versionType.nullSafeGet(
+			final VersionType versionType = persister.getVersionType();
+			final Object currentVersion = versionType.nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedVersionAliases(),
 					session,
 					null
-				);
+			);
 			if ( !versionType.isEqual(version, currentVersion) ) {
 				if ( session.getFactory().getStatistics().isStatisticsEnabled() ) {
 					session.getFactory().getStatisticsImplementor()
 							.optimisticFailure( persister.getEntityName() );
 				}
 				throw new StaleObjectStateException( persister.getEntityName(), id );
 			}
 		}
 
 	}
 
 	/**
 	 * Resolve any IDs for currently loaded objects, duplications within the
 	 * <tt>ResultSet</tt>, etc. Instantiate empty objects to be initialized from the
 	 * <tt>ResultSet</tt>. Return an array of objects (a row of results) and an
 	 * array of booleans (by side-effect) that determine whether the corresponding
 	 * object should be initialized.
 	 */
 	private Object[] getRow(
 			final ResultSet rs,
 			final Loadable[] persisters,
 			final EntityKey[] keys,
 			final Object optionalObject,
 			final EntityKey optionalObjectKey,
 			final LockMode[] lockModes,
 			final List hydratedObjects,
-			final SessionImplementor session)
-	throws HibernateException, SQLException {
-
+			final SessionImplementor session) throws HibernateException, SQLException {
 		final int cols = persisters.length;
 		final EntityAliases[] descriptors = getEntityAliases();
 
-		if ( LOG.isDebugEnabled() ) LOG.debugf( "Result row: %s", StringHelper.toString( keys ) );
+		if ( LOG.isDebugEnabled() ) {
+			LOG.debugf( "Result row: %s", StringHelper.toString( keys ) );
+		}
 
 		final Object[] rowResults = new Object[cols];
 
 		for ( int i = 0; i < cols; i++ ) {
 
 			Object object = null;
 			EntityKey key = keys[i];
 
 			if ( keys[i] == null ) {
 				//do nothing
 			}
 			else {
-
 				//If the object is already loaded, return the loaded one
 				object = session.getEntityUsingInterceptor( key );
 				if ( object != null ) {
 					//its already loaded so don't need to hydrate it
 					instanceAlreadyLoaded(
 							rs,
 							i,
 							persisters[i],
 							key,
 							object,
 							lockModes[i],
 							session
-						);
+					);
 				}
 				else {
 					object = instanceNotYetLoaded(
 							rs,
 							i,
 							persisters[i],
 							descriptors[i].getRowIdAlias(),
 							key,
 							lockModes[i],
 							optionalObjectKey,
 							optionalObject,
 							hydratedObjects,
 							session
-						);
+					);
 				}
-
 			}
 
 			rowResults[i] = object;
 
 		}
 
 		return rowResults;
 	}
 
 	/**
 	 * The entity instance is already in the session cache
 	 */
 	private void instanceAlreadyLoaded(
 			final ResultSet rs,
 			final int i,
 			final Loadable persister,
 			final EntityKey key,
 			final Object object,
 			final LockMode requestedLockMode,
 			final SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( !persister.isInstance( object ) ) {
 			throw new WrongClassException(
 					"loaded object was of wrong class " + object.getClass(),
 					key.getIdentifier(),
 					persister.getEntityName()
 			);
 		}
 
 		if ( LockMode.NONE != requestedLockMode && upgradeLocks() ) { //no point doing this if NONE was requested
 			final EntityEntry entry = session.getPersistenceContext().getEntry( object );
 			if ( entry.getLockMode().lessThan( requestedLockMode ) ) {
 				//we only check the version when _upgrading_ lock modes
 				if ( persister.isVersioned() ) {
 					checkVersion( i, persister, key.getIdentifier(), object, rs, session );
 				}
 				//we need to upgrade the lock mode to the mode requested
 				entry.setLockMode( requestedLockMode );
 			}
 		}
 	}
 
 
 	/**
 	 * The entity instance is not in the session cache
 	 */
 	private Object instanceNotYetLoaded(
 			final ResultSet rs,
 			final int i,
 			final Loadable persister,
 			final String rowIdAlias,
 			final EntityKey key,
 			final LockMode lockMode,
 			final EntityKey optionalObjectKey,
 			final Object optionalObject,
 			final List hydratedObjects,
 			final SessionImplementor session)
 	throws HibernateException, SQLException {
 		final String instanceClass = getInstanceClass(
 				rs,
 				i,
 				persister,
 				key.getIdentifier(),
 				session
 		);
 
 		// see if the entity defines reference caching, and if so use the cached reference (if one).
 		if ( session.getCacheMode().isGetEnabled() && persister.canUseReferenceCacheEntries() ) {
 			final Object cachedEntry = CacheHelper.fromSharedCache(
 					session,
 					session.generateCacheKey(
 							key.getIdentifier(),
 							persister.getEntityMetamodel().getEntityType(),
 							key.getEntityName()
 					),
 					persister.getCacheAccessStrategy()
 			);
 			if ( cachedEntry != null ) {
 				CacheEntry entry = (CacheEntry) persister.getCacheEntryStructure().destructure( cachedEntry, factory );
 				return ( (ReferenceCacheEntryImpl) entry ).getReference();
 			}
 		}
 
 		final Object object;
 		if ( optionalObjectKey != null && key.equals( optionalObjectKey ) ) {
 			//its the given optional object
 			object = optionalObject;
 		}
 		else {
 			// instantiate a new instance
 			object = session.instantiate( instanceClass, key.getIdentifier() );
 		}
 
 		//need to hydrate it.
 
 		// grab its state from the ResultSet and keep it in the Session
 		// (but don't yet initialize the object itself)
 		// note that we acquire LockMode.READ even if it was not requested
 		LockMode acquiredLockMode = lockMode == LockMode.NONE ? LockMode.READ : lockMode;
 		loadFromResultSet(
 				rs,
 				i,
 				object,
 				instanceClass,
 				key,
 				rowIdAlias,
 				acquiredLockMode,
 				persister,
 				session
-			);
+		);
 
 		//materialize associations (and initialize the object) later
 		hydratedObjects.add( object );
 
 		return object;
 	}
 
 	private boolean isEagerPropertyFetchEnabled(int i) {
 		boolean[] array = getEntityEagerPropertyFetches();
 		return array!=null && array[i];
 	}
 
 
 	/**
 	 * Hydrate the state an object from the SQL <tt>ResultSet</tt>, into
 	 * an array or "hydrated" values (do not resolve associations yet),
 	 * and pass the hydrates state to the session.
 	 */
 	private void loadFromResultSet(
 			final ResultSet rs,
 			final int i,
 			final Object object,
 			final String instanceEntityName,
 			final EntityKey key,
 			final String rowIdAlias,
 			final LockMode lockMode,
 			final Loadable rootPersister,
-			final SessionImplementor session)
-	throws SQLException, HibernateException {
+			final SessionImplementor session) throws SQLException, HibernateException {
 
 		final Serializable id = key.getIdentifier();
 
 		// Get the persister for the _subclass_
 		final Loadable persister = (Loadable) getFactory().getEntityPersister( instanceEntityName );
 
-		if ( LOG.isTraceEnabled() )
+		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Initializing object from ResultSet: {0}", MessageHelper.infoString( persister, id, getFactory() ) );
+		}
 
 		boolean eagerPropertyFetch = isEagerPropertyFetchEnabled(i);
 
 		// add temp entry so that the next step is circular-reference
 		// safe - only needed because some types don't take proper
 		// advantage of two-phase-load (esp. components)
 		TwoPhaseLoad.addUninitializedEntity(
 				key,
 				object,
 				persister,
 				lockMode,
 				!eagerPropertyFetch,
 				session
-			);
+		);
 
 		//This is not very nice (and quite slow):
 		final String[][] cols = persister == rootPersister ?
 				getEntityAliases()[i].getSuffixedPropertyAliases() :
 				getEntityAliases()[i].getSuffixedPropertyAliases(persister);
 
 		final Object[] values = persister.hydrate(
 				rs,
 				id,
 				object,
 				rootPersister,
 				cols,
 				eagerPropertyFetch,
 				session
-			);
+		);
 
 		final Object rowId = persister.hasRowId() ? rs.getObject(rowIdAlias) : null;
 
 		final AssociationType[] ownerAssociationTypes = getOwnerAssociationTypes();
 		if ( ownerAssociationTypes != null && ownerAssociationTypes[i] != null ) {
 			String ukName = ownerAssociationTypes[i].getRHSUniqueKeyPropertyName();
 			if (ukName!=null) {
 				final int index = ( (UniqueKeyLoadable) persister ).getPropertyIndex(ukName);
 				final Type type = persister.getPropertyTypes()[index];
 
 				// polymorphism not really handled completely correctly,
 				// perhaps...well, actually its ok, assuming that the
 				// entity name used in the lookup is the same as the
 				// the one used here, which it will be
 
 				EntityUniqueKey euk = new EntityUniqueKey(
 						rootPersister.getEntityName(), //polymorphism comment above
 						ukName,
 						type.semiResolve( values[index], session, object ),
 						type,
 						persister.getEntityMode(),
 						session.getFactory()
 				);
 				session.getPersistenceContext().addEntity( euk, object );
 			}
 		}
 
 		TwoPhaseLoad.postHydrate(
 				persister,
 				id,
 				values,
 				rowId,
 				object,
 				lockMode,
 				!eagerPropertyFetch,
 				session
 		);
 
 	}
 
 	/**
 	 * Determine the concrete class of an instance in the <tt>ResultSet</tt>
 	 */
 	private String getInstanceClass(
 	        final ResultSet rs,
 	        final int i,
 	        final Loadable persister,
 	        final Serializable id,
-	        final SessionImplementor session)
-	throws HibernateException, SQLException {
+	        final SessionImplementor session) throws HibernateException, SQLException {
 
 		if ( persister.hasSubclasses() ) {
 
 			// Code to handle subclasses of topClass
-			Object discriminatorValue = persister.getDiscriminatorType().nullSafeGet(
+			final Object discriminatorValue = persister.getDiscriminatorType().nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedDiscriminatorAlias(),
 					session,
 					null
-				);
+			);
 
 			final String result = persister.getSubclassForDiscriminatorValue( discriminatorValue );
 
 			if ( result == null ) {
 				//woops we got an instance of another class hierarchy branch
 				throw new WrongClassException(
 						"Discriminator: " + discriminatorValue,
 						id,
 						persister.getEntityName()
 					);
 			}
 
 			return result;
 
 		}
 		else {
 			return persister.getEntityName();
 		}
 	}
 
 	/**
 	 * Advance the cursor to the first required row of the <tt>ResultSet</tt>
 	 */
-	private void advance(final ResultSet rs, final RowSelection selection)
-			throws SQLException {
+	private void advance(final ResultSet rs, final RowSelection selection) throws SQLException {
 
 		final int firstRow = LimitHelper.getFirstRow( selection );
 		if ( firstRow != 0 ) {
-			if ( getFactory().getSettings().isScrollableResultSetsEnabled() ) {
+			if ( getFactory().getSessionFactoryOptions().isScrollableResultSetsEnabled() ) {
 				// we can go straight to the first required row
 				rs.absolute( firstRow );
 			}
 			else {
 				// we need to step through the rows one row at a time (slow)
-				for ( int m = 0; m < firstRow; m++ ) rs.next();
+				for ( int m = 0; m < firstRow; m++ ) {
+					rs.next();
+				}
 			}
 		}
 	}
 
 	/**
 	 * Build LIMIT clause handler applicable for given selection criteria. Returns {@link NoopLimitHandler} delegate
 	 * if dialect does not support LIMIT expression or processed query does not use pagination.
 	 *
 	 * @param selection Selection criteria.
 	 * @return LIMIT clause delegate.
 	 */
 	protected LimitHandler getLimitHandler(RowSelection selection) {
 		final LimitHandler limitHandler = getFactory().getDialect().getLimitHandler();
 		return LimitHelper.useLimit( limitHandler, selection ) ? limitHandler : NoopLimitHandler.INSTANCE;
 	}
 
 	private ScrollMode getScrollMode(boolean scroll, boolean hasFirstRow, boolean useLimitOffSet, QueryParameters queryParameters) {
 		final boolean canScroll = getFactory().getSettings().isScrollableResultSetsEnabled();
 		if ( canScroll ) {
 			if ( scroll ) {
 				return queryParameters.getScrollMode();
 			}
 			if ( hasFirstRow && !useLimitOffSet ) {
 				return ScrollMode.SCROLL_INSENSITIVE;
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Process query string by applying filters, LIMIT clause, locks and comments if necessary.
 	 * Finally execute SQL statement and advance to the first row.
 	 */
 	protected SqlStatementWrapper executeQueryStatement(
 			final QueryParameters queryParameters,
 			final boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			final SessionImplementor session) throws SQLException {
 		return executeQueryStatement( getSQLString(), queryParameters, scroll, afterLoadActions, session );
 	}
 
 	protected SqlStatementWrapper executeQueryStatement(
 			String sqlStatement,
 			QueryParameters queryParameters,
 			boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			SessionImplementor session) throws SQLException {
 
 		// Processing query filters.
 		queryParameters.processFilters( sqlStatement, session );
 
 		// Applying LIMIT clause.
 		final LimitHandler limitHandler = getLimitHandler(
 				queryParameters.getRowSelection()
 		);
 		String sql = limitHandler.processSql( queryParameters.getFilteredSQL(), queryParameters.getRowSelection() );
 
 		// Adding locks and comments.
 		sql = preprocessSQL( sql, queryParameters, getFactory().getDialect(), afterLoadActions );
 
 		final PreparedStatement st = prepareQueryStatement( sql, queryParameters, limitHandler, scroll, session );
 		return new SqlStatementWrapper( st, getResultSet( st, queryParameters.getRowSelection(), limitHandler, queryParameters.hasAutoDiscoverScalarTypes(), session ) );
 	}
 
 	/**
 	 * Obtain a <tt>PreparedStatement</tt> with all parameters pre-bound.
 	 * Bind JDBC-style <tt>?</tt> parameters, named parameters, and
 	 * limit parameters.
 	 */
 	protected final PreparedStatement prepareQueryStatement(
 	        String sql,
 	        final QueryParameters queryParameters,
 	        final LimitHandler limitHandler,
 	        final boolean scroll,
 	        final SessionImplementor session) throws SQLException, HibernateException {
 		final Dialect dialect = getFactory().getDialect();
 		final RowSelection selection = queryParameters.getRowSelection();
-		boolean useLimit = LimitHelper.useLimit( limitHandler, selection );
-		boolean hasFirstRow = LimitHelper.hasFirstRow( selection );
-		boolean useLimitOffset = hasFirstRow && useLimit && limitHandler.supportsLimitOffset();
-		boolean callable = queryParameters.isCallable();
+		final boolean useLimit = LimitHelper.useLimit( limitHandler, selection );
+		final boolean hasFirstRow = LimitHelper.hasFirstRow( selection );
+		final boolean useLimitOffset = hasFirstRow && useLimit && limitHandler.supportsLimitOffset();
+		final boolean callable = queryParameters.isCallable();
 		final ScrollMode scrollMode = getScrollMode( scroll, hasFirstRow, useLimitOffset, queryParameters );
 		
 		PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareQueryStatement(
 				sql,
 				callable,
 				scrollMode
 		);
 
 		try {
 
 			int col = 1;
 			//TODO: can we limit stored procedures ?!
 			col += limitHandler.bindLimitParametersAtStartOfQuery( selection, st, col );
 
 			if (callable) {
 				col = dialect.registerResultSetOutParameter( (CallableStatement)st, col );
 			}
 
 			col += bindParameterValues( st, queryParameters, col, session );
 
 			col += limitHandler.bindLimitParametersAtEndOfQuery( selection, st, col );
 
 			limitHandler.setMaxRows( selection, st );
 
 			if ( selection != null ) {
 				if ( selection.getTimeout() != null ) {
 					st.setQueryTimeout( selection.getTimeout() );
 				}
 				if ( selection.getFetchSize() != null ) {
 					st.setFetchSize( selection.getFetchSize() );
 				}
 			}
 
 			// handle lock timeout...
 			LockOptions lockOptions = queryParameters.getLockOptions();
 			if ( lockOptions != null ) {
 				if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 					if ( !dialect.supportsLockTimeouts() ) {
 						if ( LOG.isDebugEnabled() ) {
 							LOG.debugf(
 									"Lock timeout [%s] requested but dialect reported to not support lock timeouts",
 									lockOptions.getTimeOut()
 							);
 						}
 					}
 					else if ( dialect.isLockTimeoutParameterized() ) {
 						st.setInt( col++, lockOptions.getTimeOut() );
 					}
 				}
 			}
 
 			if ( LOG.isTraceEnabled() )
 			   LOG.tracev( "Bound [{0}] parameters total", col );
 		}
 		catch ( SQLException sqle ) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 		catch ( HibernateException he ) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw he;
 		}
 
 		return st;
 	}
 
 	/**
 	 * Bind all parameter values into the prepared statement in preparation
 	 * for execution.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 */
 	protected int bindParameterValues(
 			PreparedStatement statement,
 			QueryParameters queryParameters,
 			int startIndex,
 			SessionImplementor session) throws SQLException {
 		int span = 0;
 		span += bindPositionalParameters( statement, queryParameters, startIndex, session );
 		span += bindNamedParameters( statement, queryParameters.getNamedParameters(), startIndex + span, session );
 		return span;
 	}
 
 	/**
 	 * Bind positional parameter values to the JDBC prepared statement.
 	 * <p/>
 	 * Positional parameters are those specified by JDBC-style ? parameters
 	 * in the source query.  It is (currently) expected that these come
 	 * before any named parameters in the source query.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindPositionalParameters(
 			final PreparedStatement statement,
 			final QueryParameters queryParameters,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		final Object[] values = queryParameters.getFilteredPositionalParameterValues();
 		final Type[] types = queryParameters.getFilteredPositionalParameterTypes();
 		int span = 0;
 		for ( int i = 0; i < values.length; i++ ) {
 			types[i].nullSafeSet( statement, values[i], startIndex + span, session );
 			span += types[i].getColumnSpan( getFactory() );
 		}
 		return span;
 	}
 
 	/**
 	 * Bind named parameters to the JDBC prepared statement.
 	 * <p/>
 	 * This is a generic implementation, the problem being that in the
 	 * general case we do not know enough information about the named
 	 * parameters to perform this in a complete manner here.  Thus this
 	 * is generally overridden on subclasses allowing named parameters to
 	 * apply the specific behavior.  The most usual limitation here is that
 	 * we need to assume the type span is always one...
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param namedParams A map of parameter names to values
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindNamedParameters(
 			final PreparedStatement statement,
 			final Map<String, TypedValue> namedParams,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		int result = 0;
 		if ( CollectionHelper.isEmpty( namedParams ) ) {
 			return result;
 		}
 
 		for ( String name : namedParams.keySet() ) {
 			TypedValue typedValue = namedParams.get( name );
 			int columnSpan = typedValue.getType().getColumnSpan( getFactory() );
 			int[] locs = getNamedParameterLocs( name );
 			for ( int loc : locs ) {
 				if ( DEBUG_ENABLED ) {
 					LOG.debugf(
 							"bindNamedParameters() %s -> %s [%s]",
 							typedValue.getValue(),
 							name,
 							loc + startIndex
 					);
 				}
 				int start = loc * columnSpan + startIndex;
 				typedValue.getType().nullSafeSet( statement, typedValue.getValue(), start, session );
 			}
 			result += locs.length;
 		}
 		return result;
 	}
 
 	public int[] getNamedParameterLocs(String name) {
 		throw new AssertionFailure("no named parameters");
 	}
 
 	/**
 	 * Execute given <tt>PreparedStatement</tt>, advance to the first result and return SQL <tt>ResultSet</tt>.
 	 */
 	protected final ResultSet getResultSet(
 			final PreparedStatement st,
 			final RowSelection selection,
 			final LimitHandler limitHandler,
 			final boolean autodiscovertypes,
-			final SessionImplementor session)
-	throws SQLException, HibernateException {
-
+			final SessionImplementor session) throws SQLException, HibernateException {
 		try {
 			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 			rs = wrapResultSetIfEnabled( rs , session );
 
 			if ( !limitHandler.supportsLimitOffset() || !LimitHelper.useLimit( limitHandler, selection ) ) {
 				advance( rs, selection );
 			}
 
 			if ( autodiscovertypes ) {
 				autoDiscoverTypes( rs );
 			}
 			return rs;
 		}
 		catch ( SQLException sqle ) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 	}
 
 	protected void autoDiscoverTypes(ResultSet rs) {
 		throw new AssertionFailure("Auto discover types not supported in this loader");
 
 	}
 
 	private ResultSet wrapResultSetIfEnabled(final ResultSet rs, final SessionImplementor session) {
 		if ( session.getFactory().getSessionFactoryOptions().isWrapResultSetsEnabled() ) {
 			try {
 				LOG.debugf( "Wrapping result set [%s]", rs );
 				return session.getFactory()
 						.getServiceRegistry()
 						.getService( JdbcServices.class )
 						.getResultSetWrapper().wrap( rs, retreiveColumnNameToIndexCache( rs ) );
 			}
 			catch(SQLException e) {
 				LOG.unableToWrapResultSet( e );
 				return rs;
 			}
 		}
 		else {
 			return rs;
 		}
 	}
 
 	private ColumnNameCache retreiveColumnNameToIndexCache(final ResultSet rs) throws SQLException {
 		final ColumnNameCache cache = columnNameCache;
 		if ( cache == null ) {
 			//there is no need for a synchronized second check, as in worst case
 			//we'll have allocated an unnecessary ColumnNameCache
 			LOG.trace( "Building columnName -> columnIndex cache" );
 			columnNameCache = new ColumnNameCache( rs.getMetaData().getColumnCount() );
 			return columnNameCache;
 		}
 		else {
 			return cache;
 		}
 	}
 
 	/**
 	 * Called by subclasses that load entities
-	 * @param persister only needed for logging
-	 * @param lockOptions
 	 */
 	protected final List loadEntity(
 			final SessionImplementor session,
 			final Object id,
 			final Type identifierType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalIdentifier,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
-
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Loading entity: %s", MessageHelper.infoString( persister, id, identifierType, getFactory() ) );
 		}
 
 		List result;
 		try {
 			QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( new Type[] { identifierType } );
 			qp.setPositionalParameterValues( new Object[] { id } );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( optionalEntityName );
 			qp.setOptionalId( optionalIdentifier );
 			qp.setLockOptions( lockOptions );
 			result = doQueryAndInitializeNonLazyCollections( session, qp, false );
 		}
 		catch ( SQLException sqle ) {
 			final Loadable[] persisters = getEntityPersisters();
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load an entity: " +
 			        MessageHelper.infoString( persisters[persisters.length-1], id, identifierType, getFactory() ),
 			        getSQLString()
-				);
+			);
 		}
 
 		LOG.debug( "Done entity load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by subclasses that load entities
 	 * @param persister only needed for logging
 	 */
 	protected final List loadEntity(
 	        final SessionImplementor session,
 	        final Object key,
 	        final Object index,
 	        final Type keyType,
 	        final Type indexType,
 	        final EntityPersister persister) throws HibernateException {
-
 		LOG.debug( "Loading collection element by index" );
 
 		List result;
 		try {
 			result = doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters(
 							new Type[] { keyType, indexType },
 							new Object[] { key, index }
 					),
 					false
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load collection element by index",
 			        getSQLString()
-				);
+			);
 		}
 
 		LOG.debug( "Done entity load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by wrappers that batch load entities
-	 * @param persister only needed for logging
-	 * @param lockOptions
 	 */
 	public final List loadEntityBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type idType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalId,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
-
 		if ( LOG.isDebugEnabled() )
 			LOG.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, getFactory() ) );
 
 		Type[] types = new Type[ids.length];
 		Arrays.fill( types, idType );
 		List result;
 		try {
 			QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( types );
 			qp.setPositionalParameterValues( ids );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( optionalEntityName );
 			qp.setOptionalId( optionalId );
 			qp.setLockOptions( lockOptions );
 			result = doQueryAndInitializeNonLazyCollections( session, qp, false );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load an entity batch: " +
 			        MessageHelper.infoString( getEntityPersisters()[0], ids, getFactory() ),
 			        getSQLString()
-				);
+			);
 		}
 
 		LOG.debug( "Done entity batch load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by subclasses that initialize collections
 	 */
 	public final void loadCollection(
 	        final SessionImplementor session,
 	        final Serializable id,
 	        final Type type) throws HibernateException {
-
-		if ( LOG.isDebugEnabled() )
-			LOG.debugf( "Loading collection: %s",
-					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() ) );
+		if ( LOG.isDebugEnabled() ) {
+			LOG.debugf(
+					"Loading collection: %s",
+					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() )
+			);
+		}
 
 		Serializable[] ids = new Serializable[]{id};
 		try {
 			doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters( new Type[]{type}, ids, ids ),
 					true
-				);
+			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() ),
 					getSQLString()
-				);
+			);
 		}
 
 		LOG.debug( "Done loading collection" );
-
 	}
 
 	/**
 	 * Called by wrappers that batch initialize collections
 	 */
 	public final void loadCollectionBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type type) throws HibernateException {
-
-		if ( LOG.isDebugEnabled() )
-			LOG.debugf( "Batch loading collection: %s",
-					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ) );
+		if ( LOG.isDebugEnabled() ) {
+			LOG.debugf(
+					"Batch loading collection: %s",
+					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() )
+			);
+		}
 
 		Type[] idTypes = new Type[ids.length];
 		Arrays.fill( idTypes, type );
 		try {
 			doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters( idTypes, ids, ids ),
 					true
-				);
+			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection batch: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
 					getSQLString()
-				);
+			);
 		}
 
 		LOG.debug( "Done batch load" );
-
 	}
 
 	/**
 	 * Called by subclasses that batch initialize collections
 	 */
 	protected final void loadCollectionSubselect(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Object[] parameterValues,
 			final Type[] parameterTypes,
 			final Map<String, TypedValue> namedParameters,
 			final Type type) throws HibernateException {
-
-		Type[] idTypes = new Type[ids.length];
+		final Type[] idTypes = new Type[ids.length];
 		Arrays.fill( idTypes, type );
 		try {
 			doQueryAndInitializeNonLazyCollections( session,
 					new QueryParameters( parameterTypes, parameterValues, namedParameters, ids ),
 					true
-				);
+			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not load collection by subselect: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
 					getSQLString()
-				);
+			);
 		}
 	}
 
 	/**
 	 * Return the query results, using the query cache, called
 	 * by subclasses that implement cacheable queries
 	 */
 	protected List list(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes) throws HibernateException {
-
-		final boolean cacheable = factory.getSettings().isQueryCacheEnabled() &&
+		final boolean cacheable = factory.getSessionFactoryOptions().isQueryCacheEnabled() &&
 			queryParameters.isCacheable();
 
 		if ( cacheable ) {
 			return listUsingQueryCache( session, queryParameters, querySpaces, resultTypes );
 		}
 		else {
 			return listIgnoreQueryCache( session, queryParameters );
 		}
 	}
 
 	private List listIgnoreQueryCache(SessionImplementor session, QueryParameters queryParameters) {
 		return getResultList( doList( session, queryParameters ), queryParameters.getResultTransformer() );
 	}
 
 	private List listUsingQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes) {
 
 		QueryCache queryCache = factory.getQueryCache( queryParameters.getCacheRegion() );
 
 		QueryKey key = generateQueryKey( session, queryParameters );
 
-		if ( querySpaces == null || querySpaces.size() == 0 )
+		if ( querySpaces == null || querySpaces.size() == 0 ) {
 			LOG.tracev( "Unexpected querySpaces is {0}", ( querySpaces == null ? querySpaces : "empty" ) );
+		}
 		else {
 			LOG.tracev( "querySpaces is {0}", querySpaces );
 		}
 
 		List result = getResultFromQueryCache(
 				session,
 				queryParameters,
 				querySpaces,
 				resultTypes,
 				queryCache,
 				key
-			);
+		);
 
 		if ( result == null ) {
 			result = doList( session, queryParameters, key.getResultTransformer() );
 
 			putResultInQueryCache(
 					session,
 					queryParameters,
 					resultTypes,
 					queryCache,
 					key,
 					result
 			);
 		}
 
 		ResultTransformer resolvedTransformer = resolveResultTransformer( queryParameters.getResultTransformer() );
 		if ( resolvedTransformer != null ) {
 			result = (
 					areResultSetRowsTransformedImmediately() ?
 							key.getResultTransformer().retransformResults(
 									result,
 									getResultRowAliases(),
 									queryParameters.getResultTransformer(),
 									includeInResultRow()
 							) :
 							key.getResultTransformer().untransformToTuples(
 									result
 							)
 			);
 		}
 
 		return getResultList( result, queryParameters.getResultTransformer() );
 	}
 
 	private QueryKey generateQueryKey(
 			SessionImplementor session,
 			QueryParameters queryParameters) {
 		return QueryKey.generateQueryKey(
 				getSQLString(),
 				queryParameters,
 				FilterKey.createFilterKeys( session.getLoadQueryInfluencers().getEnabledFilters() ),
 				session,
 				createCacheableResultTransformer( queryParameters )
 		);
 	}
 
 	private CacheableResultTransformer createCacheableResultTransformer(QueryParameters queryParameters) {
 		return CacheableResultTransformer.create(
 				queryParameters.getResultTransformer(),
 				getResultRowAliases(),
 				includeInResultRow()
 		);
 	}
 
 	private List getResultFromQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key) {
 		List result = null;
 
 		if ( session.getCacheMode().isGetEnabled() ) {
 			boolean isImmutableNaturalKeyLookup =
 					queryParameters.isNaturalKeyLookup() &&
 							resultTypes.length == 1 &&
 							resultTypes[0].isEntityType() &&
 							getEntityPersister( EntityType.class.cast( resultTypes[0] ) )
 									.getEntityMetamodel()
 									.hasImmutableNaturalId();
 
 			final PersistenceContext persistenceContext = session.getPersistenceContext();
 			boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 			if ( queryParameters.isReadOnlyInitialized() ) {
 				// The read-only/modifiable mode for the query was explicitly set.
 				// Temporarily set the default read-only/modifiable setting to the query's setting.
 				persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 			}
 			else {
 				// The read-only/modifiable setting for the query was not initialized.
 				// Use the default read-only/modifiable from the persistence context instead.
 				queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 			}
 			try {
 				result = queryCache.get(
 						key,
 						key.getResultTransformer().getCachedResultTypes( resultTypes ),
 						isImmutableNaturalKeyLookup,
 						querySpaces,
 						session
 				);
 			}
 			finally {
 				persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 			}
 
 			if ( factory.getStatistics().isStatisticsEnabled() ) {
 				if ( result == null ) {
 					factory.getStatisticsImplementor()
 							.queryCacheMiss( getQueryIdentifier(), queryCache.getRegion().getName() );
 				}
 				else {
 					factory.getStatisticsImplementor()
 							.queryCacheHit( getQueryIdentifier(), queryCache.getRegion().getName() );
 				}
 			}
 		}
 
 		return result;
 	}
 
 	private EntityPersister getEntityPersister(EntityType entityType) {
 		return factory.getEntityPersister( entityType.getAssociatedEntityName() );
 	}
 
 	protected void putResultInQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key,
 			final List result) {
 		if ( session.getCacheMode().isPutEnabled() ) {
 			boolean put = queryCache.put(
 					key,
 					key.getResultTransformer().getCachedResultTypes( resultTypes ),
 					result,
 					queryParameters.isNaturalKeyLookup(),
 					session
 			);
 			if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 				factory.getStatisticsImplementor()
 						.queryCachePut( getQueryIdentifier(), queryCache.getRegion().getName() );
 			}
 		}
 	}
 
 	/**
 	 * Actually execute a query, ignoring the query cache
 	 */
 
 	protected List doList(final SessionImplementor session, final QueryParameters queryParameters)
 			throws HibernateException {
 		return doList( session, queryParameters, null);
 	}
 
 	private List doList(final SessionImplementor session,
 						final QueryParameters queryParameters,
 						final ResultTransformer forcedResultTransformer)
 			throws HibernateException {
 
 		final boolean stats = getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
-		if ( stats ) startTime = System.nanoTime();
+		if ( stats ) {
+			startTime = System.nanoTime();
+		}
 
 		List result;
 		try {
 			result = doQueryAndInitializeNonLazyCollections( session, queryParameters, true, forcedResultTransformer );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query",
 					getSQLString()
-				);
+			);
 		}
 
 		if ( stats ) {
 			final long endTime = System.nanoTime();
 			final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 			getFactory().getStatisticsImplementor().queryExecuted(
 					getQueryIdentifier(),
 					result.size(),
 					milliseconds
-				);
+			);
 		}
 
 		return result;
 	}
 
 	/**
 	 * Check whether the current loader can support returning ScrollableResults.
 	 *
 	 * @throws HibernateException
 	 */
 	protected void checkScrollability() throws HibernateException {
 		// Allows various loaders (ok mainly the QueryLoader :) to check
 		// whether scrolling of their result set should be allowed.
 		//
 		// By default it is allowed.
 	}
 
 	/**
 	 * Does the result set to be scrolled contain collection fetches?
 	 *
 	 * @return True if it does, and thus needs the special fetching scroll
 	 * functionality; false otherwise.
 	 */
 	protected boolean needsFetchingScroll() {
 		return false;
 	}
 
 	/**
 	 * Return the query results, as an instance of <tt>ScrollableResults</tt>
 	 *
 	 * @param queryParameters The parameters with which the query should be executed.
 	 * @param returnTypes The expected return types of the query
 	 * @param holderInstantiator If the return values are expected to be wrapped
 	 * in a holder, this is the thing that knows how to wrap them.
 	 * @param session The session from which the scroll request originated.
 	 * @return The ScrollableResults instance.
 	 * @throws HibernateException Indicates an error executing the query, or constructing
 	 * the ScrollableResults.
 	 */
 	protected ScrollableResults scroll(
 			final QueryParameters queryParameters,
 			final Type[] returnTypes,
 			final HolderInstantiator holderInstantiator,
 			final SessionImplementor session) throws HibernateException {
-
 		checkScrollability();
 
 		final boolean stats = getQueryIdentifier() != null &&
 				getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
-		if ( stats ) startTime = System.nanoTime();
+		if ( stats ) {
+			startTime = System.nanoTime();
+		}
 
 		try {
 			// Don't use Collections#emptyList() here -- follow on locking potentially adds AfterLoadActions,
 			// so the list cannot be immutable.
 			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, true, new ArrayList<AfterLoadAction>(), session );
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
 
 			if ( stats ) {
 				final long endTime = System.nanoTime();
 				final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 				getFactory().getStatisticsImplementor().queryExecuted(
 						getQueryIdentifier(),
 						0,
 						milliseconds
-					);
+				);
 			}
 
 			if ( needsFetchingScroll() ) {
 				return new FetchingScrollableResultsImpl(
 						rs,
 						st,
 						session,
 						this,
 						queryParameters,
 						returnTypes,
 						holderInstantiator
-					);
+				);
 			}
 			else {
 				return new ScrollableResultsImpl(
 						rs,
 						st,
 						session,
 						this,
 						queryParameters,
 						returnTypes,
 						holderInstantiator
-					);
+				);
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using scroll",
 					getSQLString()
-				);
+			);
 		}
 
 	}
 
 	/**
 	 * Calculate and cache select-clause suffixes. Must be
 	 * called by subclasses after instantiation.
 	 */
 	protected void postInstantiate() {}
 
 	/**
 	 * Get the result set descriptor
 	 */
 	protected abstract EntityAliases[] getEntityAliases();
 
 	protected abstract CollectionAliases[] getCollectionAliases();
 
 	/**
 	 * Identifies the query for statistics reporting, if null,
 	 * no statistics will be reported
 	 */
 	protected String getQueryIdentifier() {
 		return null;
 	}
 
 	public final SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getSQLString() + ')';
 	}
 
 	/**
 	 * Wrapper class for {@link Statement} and associated {@link ResultSet}.
 	 */
 	protected static class SqlStatementWrapper {
 		private final Statement statement;
 		private final ResultSet resultSet;
 
 		private SqlStatementWrapper(Statement statement, ResultSet resultSet) {
 			this.resultSet = resultSet;
 			this.statement = statement;
 		}
 
 		public ResultSet getResultSet() {
 			return resultSet;
 		}
 
 		public Statement getStatement() {
 			return statement;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinableAssociation.java b/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinableAssociation.java
index 379e82dc7d..b7b2c95ed9 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinableAssociation.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/OuterJoinableAssociation.java
@@ -1,228 +1,230 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 
 /**
  * Part of the Hibernate SQL rendering internals.  This class represents
  * a joinable association.
  *
  * @author Gavin King
  */
 public final class OuterJoinableAssociation {
 	private final PropertyPath propertyPath;
 	private final AssociationType joinableType;
 	private final Joinable joinable;
 	private final String lhsAlias; // belong to other persister
 	private final String[] lhsColumns; // belong to other persister
 	private final String rhsAlias;
 	private final String[] rhsColumns;
 	private final JoinType joinType;
 	private final String on;
 	private final Map enabledFilters;
 	private final boolean hasRestriction;
 
 	public static OuterJoinableAssociation createRoot(
 			AssociationType joinableType,
 			String alias,
 			SessionFactoryImplementor factory) {
 		return new OuterJoinableAssociation(
 				new PropertyPath(),
 				joinableType,
 				null,
 				null,
 				alias,
 				JoinType.LEFT_OUTER_JOIN,
 				null,
 				false,
 				factory,
 				Collections.EMPTY_MAP
 		);
 	}
 
 	public OuterJoinableAssociation(
 			PropertyPath propertyPath,
 			AssociationType joinableType,
 			String lhsAlias,
 			String[] lhsColumns,
 			String rhsAlias,
 			JoinType joinType,
 			String withClause,
 			boolean hasRestriction,
 			SessionFactoryImplementor factory,
 			Map enabledFilters) throws MappingException {
 		this.propertyPath = propertyPath;
 		this.joinableType = joinableType;
 		this.lhsAlias = lhsAlias;
 		this.lhsColumns = lhsColumns;
 		this.rhsAlias = rhsAlias;
 		this.joinType = joinType;
 		this.joinable = joinableType.getAssociatedJoinable(factory);
 		this.rhsColumns = JoinHelper.getRHSColumnNames(joinableType, factory);
 		this.on = joinableType.getOnCondition(rhsAlias, factory, enabledFilters)
 			+ ( withClause == null || withClause.trim().length() == 0 ? "" : " and ( " + withClause + " )" );
 		this.hasRestriction = hasRestriction;
 		this.enabledFilters = enabledFilters; // needed later for many-to-many/filter application
 	}
 
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	public JoinType getJoinType() {
 		return joinType;
 	}
 
 	public String getLhsAlias() {
 		return lhsAlias;
 	}
 
 	public String getRHSAlias() {
 		return rhsAlias;
 	}
 
 	public String getRhsAlias() {
 		return rhsAlias;
 	}
 
 	private boolean isOneToOne() {
 		if ( joinableType.isEntityType() )  {
 			EntityType etype = (EntityType) joinableType;
 			return etype.isOneToOne() /*&& etype.isReferenceToPrimaryKey()*/;
 		}
 		else {
 			return false;
 		}
 	}
 	
 	public AssociationType getJoinableType() {
 		return joinableType;
 	}
 	
 	public String getRHSUniqueKeyName() {
 		return joinableType.getRHSUniqueKeyPropertyName();
 	}
 
 	public boolean isCollection() {
 		return joinableType.isCollectionType();
 	}
 
 	public Joinable getJoinable() {
 		return joinable;
 	}
 
 	public boolean hasRestriction() {
 		return hasRestriction;
 	}
 
 	public int getOwner(final List associations) {
 		if ( isOneToOne() || isCollection() ) {
 			return getPosition(lhsAlias, associations);
 		}
 		else {
 			return -1;
 		}
 	}
 
 	/**
 	 * Get the position of the join with the given alias in the
 	 * list of joins
 	 */
 	private static int getPosition(String lhsAlias, List associations) {
 		int result = 0;
-		for ( int i=0; i<associations.size(); i++ ) {
-			OuterJoinableAssociation oj = (OuterJoinableAssociation) associations.get(i);
+		for ( Object association : associations ) {
+			final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;
 			if ( oj.getJoinable().consumesEntityAlias() /*|| oj.getJoinable().consumesCollectionAlias() */ ) {
-				if ( oj.rhsAlias.equals(lhsAlias) ) return result;
+				if ( oj.rhsAlias.equals( lhsAlias ) ) {
+					return result;
+				}
 				result++;
 			}
 		}
 		return -1;
 	}
 
 	public void addJoins(JoinFragment outerjoin) throws MappingException {
 		outerjoin.addJoin(
 			joinable.getTableName(),
 			rhsAlias,
 			lhsColumns,
 			rhsColumns,
 			joinType,
 			on
 		);
 		outerjoin.addJoins(
 			joinable.fromJoinFragment(rhsAlias, false, true),
 			joinable.whereJoinFragment(rhsAlias, false, true)
 		);
 	}
 
 	public void validateJoin(String path) throws MappingException {
 		if ( rhsColumns==null || lhsColumns==null
 				|| lhsColumns.length!=rhsColumns.length || lhsColumns.length==0 ) {
 			throw new MappingException("invalid join columns for association: " + path);
 		}
 	}
 
 	public boolean isManyToManyWith(OuterJoinableAssociation other) {
 		if ( joinable.isCollection() ) {
 			QueryableCollection persister = ( QueryableCollection ) joinable;
 			if ( persister.isManyToMany() ) {
 				return persister.getElementType() == other.getJoinableType();
 			}
 		}
 		return false;
 	}
 
 	public void addManyToManyJoin(JoinFragment outerjoin, QueryableCollection collection) throws MappingException {
 		String manyToManyFilter = collection.getManyToManyFilterFragment( rhsAlias, enabledFilters );
 		String condition = "".equals( manyToManyFilter )
 				? on
 				: "".equals( on )
 						? manyToManyFilter
 						: on + " and " + manyToManyFilter;
 		outerjoin.addJoin(
 		        joinable.getTableName(),
 		        rhsAlias,
 		        lhsColumns,
 		        rhsColumns,
 		        joinType,
 		        condition
 		);
 		outerjoin.addJoins(
 			joinable.fromJoinFragment(rhsAlias, false, true),
 			joinable.whereJoinFragment(rhsAlias, false, true)
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/collection/CollectionJoinWalker.java b/hibernate-core/src/main/java/org/hibernate/loader/collection/CollectionJoinWalker.java
index c1f30add76..9092f3f110 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/collection/CollectionJoinWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/collection/CollectionJoinWalker.java
@@ -1,61 +1,64 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.collection;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.loader.JoinWalker;
 
 /**
  * Superclass of walkers for collection initializers
  * 
  * @see CollectionLoader
  * @see OneToManyJoinWalker
  * @see BasicCollectionJoinWalker
  * @author Gavin King
  */
 public abstract class CollectionJoinWalker extends JoinWalker {
-	
 	public CollectionJoinWalker(SessionFactoryImplementor factory, LoadQueryInfluencers loadQueryInfluencers) {
 		super( factory, loadQueryInfluencers );
 	}
 
 	protected StringBuilder whereString(String alias, String[] columnNames, String subselect, int batchSize) {
 		if (subselect==null) {
 			return whereString(alias, columnNames, batchSize);
 		}
 		else {
 			StringBuilder buf = new StringBuilder();
-			if (columnNames.length>1) buf.append('(');
+			if (columnNames.length>1) {
+				buf.append('(');
+			}
 			buf.append( StringHelper.join(", ", StringHelper.qualify(alias, columnNames) ) );
-			if (columnNames.length>1) buf.append(')');
+			if (columnNames.length>1) {
+				buf.append(')');
+			}
 			buf.append(" in ")
 				.append('(')
 				.append(subselect) 
 				.append(')');
 			return buf;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/collection/DynamicBatchingCollectionInitializerBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/collection/DynamicBatchingCollectionInitializerBuilder.java
index 27259f806b..a5a82042e8 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/collection/DynamicBatchingCollectionInitializerBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/collection/DynamicBatchingCollectionInitializerBuilder.java
@@ -1,271 +1,274 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.collection;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.JoinWalker;
 import org.hibernate.loader.Loader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 /**
  * A BatchingCollectionInitializerBuilder that builds CollectionInitializer instances capable of dynamically building
  * its batch-fetch SQL based on the actual number of collections keys waiting to be fetched.
  *
  * @author Steve Ebersole
  */
 public class DynamicBatchingCollectionInitializerBuilder extends BatchingCollectionInitializerBuilder {
 	public static final DynamicBatchingCollectionInitializerBuilder INSTANCE = new DynamicBatchingCollectionInitializerBuilder();
 
 	@Override
 	protected CollectionInitializer createRealBatchingCollectionInitializer(
 			QueryableCollection persister,
 			int maxBatchSize,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		return new DynamicBatchingCollectionInitializer( persister, maxBatchSize, factory, influencers );
 	}
 
 	@Override
 	protected CollectionInitializer createRealBatchingOneToManyInitializer(
 			QueryableCollection persister,
 			int maxBatchSize,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		return new DynamicBatchingCollectionInitializer( persister, maxBatchSize, factory, influencers );
 	}
 
 	public static class DynamicBatchingCollectionInitializer extends BatchingCollectionInitializer {
 		private final int maxBatchSize;
 		private final Loader singleKeyLoader;
 		private final DynamicBatchingCollectionLoader batchLoader;
 
 		public DynamicBatchingCollectionInitializer(
 				QueryableCollection collectionPersister,
 				int maxBatchSize,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers influencers) {
 			super( collectionPersister );
 			this.maxBatchSize = maxBatchSize;
 
 			if ( collectionPersister.isOneToMany() ) {
 				this.singleKeyLoader = new OneToManyLoader( collectionPersister, 1, factory, influencers );
 			}
 			else {
 				this.singleKeyLoader = new BasicCollectionLoader( collectionPersister, 1, factory, influencers );
 			}
 
 			this.batchLoader = new DynamicBatchingCollectionLoader( collectionPersister, factory, influencers );
 		}
 
 		@Override
 		public void initialize(Serializable id, SessionImplementor session) throws HibernateException {
 			// first, figure out how many batchable ids we have...
 			final Serializable[] batch = session.getPersistenceContext()
 					.getBatchFetchQueue()
 					.getCollectionBatch( collectionPersister(), id, maxBatchSize );
 			final int numberOfIds = ArrayHelper.countNonNull( batch );
 			if ( numberOfIds <= 1 ) {
 				singleKeyLoader.loadCollection( session, id, collectionPersister().getKeyType() );
 				return;
 			}
 
 			final Serializable[] idsToLoad = new Serializable[numberOfIds];
 			System.arraycopy( batch, 0, idsToLoad, 0, numberOfIds );
 
 			batchLoader.doBatchedCollectionLoad( session, idsToLoad, collectionPersister().getKeyType() );
 		}
 	}
 
 	private static class DynamicBatchingCollectionLoader extends CollectionLoader {
 		// todo : this represents another case where the current Loader contract is unhelpful
 		//		the other recent case was stored procedure support.  Really any place where the SQL
 		//		generation is dynamic but the "loading plan" remains constant.  The long term plan
 		//		is to split Loader into (a) PreparedStatement generation/execution and (b) ResultSet
 		// 		processing.
 		//
 		// Same holds true for org.hibernate.loader.entity.DynamicBatchingEntityLoaderBuilder.DynamicBatchingEntityLoader
 		//
 		// for now I will essentially semi-re-implement the collection loader contract here to be able to alter
 		// 		the SQL (specifically to be able to dynamically build the WHERE-clause IN-condition) later, when
 		//		we actually know the ids to batch fetch
 
 		private final String sqlTemplate;
 		private final String alias;
 
 		public DynamicBatchingCollectionLoader(
 				QueryableCollection collectionPersister,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers influencers) {
 			super( collectionPersister, factory, influencers );
 
 			JoinWalker walker = buildJoinWalker( collectionPersister, factory, influencers );
 			initFromWalker( walker );
 			this.sqlTemplate = walker.getSQLString();
 			this.alias = StringHelper.generateAlias( collectionPersister.getRole(), 0 );
 			postInstantiate();
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf(
 						"SQL-template for dynamic collection [%s] batch-fetching : %s",
 						collectionPersister.getRole(),
 						sqlTemplate
 				);
 			}
 		}
 
 		private JoinWalker buildJoinWalker(
 				QueryableCollection collectionPersister,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers influencers) {
 
 			if ( collectionPersister.isOneToMany() ) {
 				return new OneToManyJoinWalker( collectionPersister, -1, null, factory, influencers ) {
 					@Override
 					protected StringBuilder whereString(String alias, String[] columnNames, String subselect, int batchSize) {
 						if ( subselect != null ) {
 							return super.whereString( alias, columnNames, subselect, batchSize );
 						}
 
 						return StringHelper.buildBatchFetchRestrictionFragment( alias, columnNames, getFactory().getDialect() );
 					}
 				};
 			}
 			else {
 				return new BasicCollectionJoinWalker( collectionPersister, -1, null, factory, influencers ) {
 					@Override
 					protected StringBuilder whereString(String alias, String[] columnNames, String subselect, int batchSize) {
 						if ( subselect != null ) {
 							return super.whereString( alias, columnNames, subselect, batchSize );
 						}
 
 						return StringHelper.buildBatchFetchRestrictionFragment( alias, columnNames, getFactory().getDialect() );
 					}
 				};
 			}
 		}
 
 		public final void doBatchedCollectionLoad(
 				final SessionImplementor session,
 				final Serializable[] ids,
 				final Type type) throws HibernateException {
 
-			if ( LOG.isDebugEnabled() )
-				LOG.debugf( "Batch loading collection: %s",
-							MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ) );
+			if ( LOG.isDebugEnabled() ) {
+				LOG.debugf(
+						"Batch loading collection: %s",
+						MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() )
+				);
+			}
 
 			final Type[] idTypes = new Type[ids.length];
 			Arrays.fill( idTypes, type );
 			final QueryParameters queryParameters = new QueryParameters( idTypes, ids, ids );
 
 			final String sql = StringHelper.expandBatchIdPlaceholder(
 					sqlTemplate,
 					ids,
 					alias,
 					collectionPersister().getKeyColumnNames(),
 					getFactory().getDialect()
 			);
 
 			try {
 				final PersistenceContext persistenceContext = session.getPersistenceContext();
 				boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 				if ( queryParameters.isReadOnlyInitialized() ) {
 					// The read-only/modifiable mode for the query was explicitly set.
 					// Temporarily set the default read-only/modifiable setting to the query's setting.
 					persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 				}
 				else {
 					// The read-only/modifiable setting for the query was not initialized.
 					// Use the default read-only/modifiable from the persistence context instead.
 					queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 				}
 				persistenceContext.beforeLoad();
 				try {
 					try {
 						doTheLoad( sql, queryParameters, session );
 					}
 					finally {
 						persistenceContext.afterLoad();
 					}
 					persistenceContext.initializeNonLazyCollections();
 				}
 				finally {
 					// Restore the original default
 					persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 				}
 			}
 			catch ( SQLException e ) {
 				throw getFactory().getSQLExceptionHelper().convert(
 						e,
 						"could not initialize a collection batch: " +
 								MessageHelper.collectionInfoString( collectionPersister(), ids, getFactory() ),
 						sql
 				);
 			}
 
 			LOG.debug( "Done batch load" );
 
 		}
 
 		private void doTheLoad(String sql, QueryParameters queryParameters, SessionImplementor session) throws SQLException {
 			final RowSelection selection = queryParameters.getRowSelection();
 			final int maxRows = LimitHelper.hasMaxRows( selection ) ?
 					selection.getMaxRows() :
 					Integer.MAX_VALUE;
 
 			final List<AfterLoadAction> afterLoadActions = Collections.emptyList();
 			final SqlStatementWrapper wrapper = executeQueryStatement( sql, queryParameters, false, afterLoadActions, session );
 			final ResultSet rs = wrapper.getResultSet();
 			final Statement st = wrapper.getStatement();
 			try {
 				processResultSet( rs, queryParameters, session, true, null, maxRows, afterLoadActions );
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/collection/plan/AbstractLoadPlanBasedCollectionInitializer.java b/hibernate-core/src/main/java/org/hibernate/loader/collection/plan/AbstractLoadPlanBasedCollectionInitializer.java
index 0d29e00bc3..483035df02 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/collection/plan/AbstractLoadPlanBasedCollectionInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/collection/plan/AbstractLoadPlanBasedCollectionInitializer.java
@@ -1,139 +1,139 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.collection.plan;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.plan.build.internal.FetchStyleLoadPlanBuildingAssociationVisitationStrategy;
 import org.hibernate.loader.plan.build.spi.MetamodelDrivenLoadPlanBuilder;
 import org.hibernate.loader.plan.exec.internal.AbstractLoadPlanBasedLoader;
 import org.hibernate.loader.plan.exec.internal.BatchingLoadQueryDetailsFactory;
 import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
 import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 /**
  * An abstract {@link CollectionInitializer} implementation based on using LoadPlans
  *
  * @author Gail Badner
  */
 public abstract class AbstractLoadPlanBasedCollectionInitializer
 		extends AbstractLoadPlanBasedLoader  implements CollectionInitializer {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( AbstractLoadPlanBasedCollectionInitializer.class );
 
 	private final QueryableCollection collectionPersister;
 	private final LoadQueryDetails staticLoadQuery;
 
 	public AbstractLoadPlanBasedCollectionInitializer(
 			QueryableCollection collectionPersister,
 			QueryBuildingParameters buildingParameters) {
 		super( collectionPersister.getFactory() );
 		this.collectionPersister = collectionPersister;
 
 		final FetchStyleLoadPlanBuildingAssociationVisitationStrategy strategy =
 				new FetchStyleLoadPlanBuildingAssociationVisitationStrategy(
 						collectionPersister.getFactory(),
 						buildingParameters.getQueryInfluencers(),
 						buildingParameters.getLockMode() != null
 								? buildingParameters.getLockMode()
 								: buildingParameters.getLockOptions().getLockMode()
 		);
 
 		final LoadPlan plan = MetamodelDrivenLoadPlanBuilder.buildRootCollectionLoadPlan( strategy, collectionPersister );
-		this.staticLoadQuery = BatchingLoadQueryDetailsFactory.makeCollectionLoadQueryDetails(
+		this.staticLoadQuery = BatchingLoadQueryDetailsFactory.INSTANCE.makeCollectionLoadQueryDetails(
 				collectionPersister,
 				plan,
 				buildingParameters
 		);
 	}
 
 	@Override
 	public void initialize(Serializable id, SessionImplementor session)
 			throws HibernateException {
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Loading collection: %s",
 					MessageHelper.collectionInfoString( collectionPersister, id, getFactory() ) );
 		}
 
 
 		final Serializable[] ids = new Serializable[]{id};
 		try {
 			final QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( new Type[]{ collectionPersister.getKeyType() } );
 			qp.setPositionalParameterValues( ids );
 			qp.setCollectionKeys( ids );
 
 			executeLoad(
 					session,
 					qp,
 					staticLoadQuery,
 					true,
 					null
 
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection: " +
 							MessageHelper.collectionInfoString( collectionPersister, id, getFactory() ),
 					staticLoadQuery.getSqlStatement()
 			);
 		}
 
 		log.debug( "Done loading collection" );
 	}
 
 	protected QueryableCollection collectionPersister() {
 		return collectionPersister;
 	}
 
 	@Override
 	protected LoadQueryDetails getStaticLoadQuery() {
 		return staticLoadQuery;
 	}
 
 	@Override
 	protected int[] getNamedParameterLocs(String name) {
 		throw new AssertionFailure("no named parameters");
 	}
 
 	@Override
 	protected void autoDiscoverTypes(ResultSet rs) {
 		throw new AssertionFailure("Auto discover types not supported in this loader");
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaLoader.java
index aa2033b078..01f3235bf6 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/criteria/CriteriaLoader.java
@@ -1,295 +1,297 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.criteria;
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CriteriaImpl;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.OuterJoinLoader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 
 /**
  * A <tt>Loader</tt> for <tt>Criteria</tt> queries. Note that criteria queries are
  * more like multi-object <tt>load()</tt>s than like HQL queries.
  *
  * @author Gavin King
  */
 public class CriteriaLoader extends OuterJoinLoader {
 
 	//TODO: this class depends directly upon CriteriaImpl, 
 	//      in the impl package ... add a CriteriaImplementor 
 	//      interface
 
 	//NOTE: unlike all other Loaders, this one is NOT
 	//      multithreaded, or cacheable!!
 
 	private final CriteriaQueryTranslator translator;
 	private final Set<Serializable> querySpaces;
 	private final Type[] resultTypes;
 	//the user visible aliases, which are unknown to the superclass,
 	//these are not the actual "physical" SQL aliases
 	private final String[] userAliases;
 	private final boolean[] includeInResultRow;
 	private final int resultRowLength;
 
 	public CriteriaLoader(
 			final OuterJoinLoadable persister, 
 			final SessionFactoryImplementor factory, 
 			final CriteriaImpl criteria, 
 			final String rootEntityName,
 			final LoadQueryInfluencers loadQueryInfluencers) throws HibernateException {
 		super( factory, loadQueryInfluencers );
 
 		translator = new CriteriaQueryTranslator(
 				factory, 
 				criteria, 
 				rootEntityName, 
 				CriteriaQueryTranslator.ROOT_SQL_ALIAS
 			);
 
 		querySpaces = translator.getQuerySpaces();
 		
 		CriteriaJoinWalker walker = new CriteriaJoinWalker(
 				persister, 
 				translator,
 				factory, 
 				criteria, 
 				rootEntityName, 
 				loadQueryInfluencers
 			);
 
 		initFromWalker(walker);
 		
 		userAliases = walker.getUserAliases();
 		resultTypes = walker.getResultTypes();
 		includeInResultRow = walker.includeInResultRow();
 		resultRowLength = ArrayHelper.countTrue( includeInResultRow );
 
 		postInstantiate();
 
 	}
 	
 	public ScrollableResults scroll(SessionImplementor session, ScrollMode scrollMode) 
 	throws HibernateException {
 		QueryParameters qp = translator.getQueryParameters();
 		qp.setScrollMode(scrollMode);
 		return scroll(qp, resultTypes, null, session);
 	}
 
 	public List list(SessionImplementor session) 
 	throws HibernateException {
 		return list( session, translator.getQueryParameters(), querySpaces, resultTypes );
 
 	}
 	@Override
 	protected String[] getResultRowAliases() {
 		return userAliases;
 	}
 	@Override
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return translator.getRootCriteria().getResultTransformer();
 	}
 	@Override
 	protected boolean areResultSetRowsTransformedImmediately() {
 		return true;
 	}
 	@Override
 	protected boolean[] includeInResultRow() {
 		return includeInResultRow;
 	}
 	@Override
 	protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
 	throws SQLException, HibernateException {
 		return resolveResultTransformer( transformer ).transformTuple(
 				getResultRow( row, rs, session),
 				getResultRowAliases()
 		);
 	}
 	@Override
 	protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		final Object[] result;
 		if ( translator.hasProjection() ) {
 			Type[] types = translator.getProjectedTypes();
 			result = new Object[types.length];
 			String[] columnAliases = translator.getProjectedColumnAliases();
 			for ( int i=0, pos=0; i<result.length; i++ ) {
 				int numColumns = types[i].getColumnSpan( session.getFactory() );
 				if ( numColumns > 1 ) {
 			    	String[] typeColumnAliases = ArrayHelper.slice( columnAliases, pos, numColumns );
 					result[i] = types[i].nullSafeGet(rs, typeColumnAliases, session, null);
 				}
 				else {
 					result[i] = types[i].nullSafeGet(rs, columnAliases[pos], session, null);
 				}
 				pos += numColumns;
 			}
 		}
 		else {
 			result = toResultRow( row );
 		}
 		return result;
 	}
 
 	private Object[] toResultRow(Object[] row) {
 		if ( resultRowLength == row.length ) {
 			return row;
 		}
 		else {
 			Object[] result = new Object[ resultRowLength ];
 			int j = 0;
 			for ( int i = 0; i < row.length; i++ ) {
-				if ( includeInResultRow[i] ) result[j++] = row[i];
+				if ( includeInResultRow[i] ) {
+					result[j++] = row[i];
+				}
 			}
 			return result;
 		}
 	}
 
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	@Override
 	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws QueryException {
 		final LockOptions lockOptions = parameters.getLockOptions();
 
 		if ( lockOptions == null ||
 				(lockOptions.getLockMode() == LockMode.NONE && (lockOptions.getAliasLockCount() == 0
 						|| (lockOptions.getAliasLockCount() == 1 && lockOptions
 						.getAliasSpecificLockMode( "this_" ) == LockMode.NONE)
 				)) ) {
 			return sql;
 		}
 
 		if ( dialect.useFollowOnLocking() ) {
             final LockMode lockMode = determineFollowOnLockMode( lockOptions );
             if( lockMode != LockMode.UPGRADE_SKIPLOCKED ) {
 				// Dialect prefers to perform locking in a separate step
 				LOG.usingFollowOnLocking();
 
 				final LockOptions lockOptionsToUse = new LockOptions( lockMode );
 				lockOptionsToUse.setTimeOut( lockOptions.getTimeOut() );
 				lockOptionsToUse.setScope( lockOptions.getScope() );
 
 				afterLoadActions.add(
 						new AfterLoadAction() {
 								@Override
 								public void afterLoad(SessionImplementor session, Object entity, Loadable persister) {
 									( (Session) session ).buildLockRequest( lockOptionsToUse )
 										.lock( persister.getEntityName(), entity );
 								}
 				        }
 				);
 				parameters.setLockOptions( new LockOptions() );
 				return sql;
 			}
 		}
 		final LockOptions locks = new LockOptions(lockOptions.getLockMode());
 		locks.setScope( lockOptions.getScope());
 		locks.setTimeOut( lockOptions.getTimeOut());
 
 		final Map keyColumnNames = dialect.forUpdateOfColumns() ? new HashMap() : null;
 		final String[] drivingSqlAliases = getAliases();
 		for ( int i = 0; i < drivingSqlAliases.length; i++ ) {
 			final LockMode lockMode = lockOptions.getAliasSpecificLockMode( drivingSqlAliases[i] );
 			if ( lockMode != null ) {
 				final Lockable drivingPersister = ( Lockable ) getEntityPersisters()[i];
 				final String rootSqlAlias = drivingPersister.getRootTableAlias( drivingSqlAliases[i] );
 				locks.setAliasSpecificLockMode( rootSqlAlias, lockMode );
 				if ( keyColumnNames != null ) {
 					keyColumnNames.put( rootSqlAlias, drivingPersister.getRootTableIdentifierColumnNames() );
 				}
 			}
 		}
 		return dialect.applyLocksToSql( sql, locks, keyColumnNames );
 	}
 
 
 	@Override
 	protected LockMode determineFollowOnLockMode(LockOptions lockOptions) {
 		final LockMode lockModeToUse = lockOptions.findGreatestLockMode();
 
 		if ( lockOptions.getAliasLockCount() > 1 ) {
 			// > 1 here because criteria always uses alias map for the root lock mode (under 'this_')
 			LOG.aliasSpecificLockingWithFollowOnLocking( lockModeToUse );
 		}
 
 		return lockModeToUse;
 	}
 	@Override
 	protected LockMode[] getLockModes(LockOptions lockOptions) {
 		final String[] entityAliases = getAliases();
 		if ( entityAliases == null ) {
 			return null;
 		}
 		final int size = entityAliases.length;
 		LockMode[] lockModesArray = new LockMode[size];
 		for ( int i=0; i<size; i++ ) {
 			LockMode lockMode = lockOptions.getAliasSpecificLockMode( entityAliases[i] );
 			lockModesArray[i] = lockMode==null ? lockOptions.getLockMode() : lockMode;
 		}
 		return lockModesArray;
 	}
 	@Override
 	protected boolean isSubselectLoadingEnabled() {
 		return hasSubselectLoadableCollections();
 	}
 	@Override
 	protected List getResultList(List results, ResultTransformer resultTransformer) {
 		return resolveResultTransformer( resultTransformer ).transformList( results );
 	}
 	@Override
 	protected String getQueryIdentifier() { 
 		return "[CRITERIA] " + getSQLString(); 
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/BatchingEntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/BatchingEntityLoader.java
index bd97df9286..ff45d3cfe6 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/BatchingEntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/BatchingEntityLoader.java
@@ -1,129 +1,128 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.entity;
 
 import java.io.Serializable;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.List;
 
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.loader.Loader;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * The base contract for loaders capable of performing batch-fetch loading of entities using multiple primary key
  * values in the SQL <tt>WHERE</tt> clause.
  *
  * @author Gavin King
  * @author Steve Ebersole
  *
  * @see BatchingEntityLoaderBuilder
  * @see UniqueEntityLoader
  */
 public abstract class BatchingEntityLoader implements UniqueEntityLoader {
 	private static final Logger log = Logger.getLogger( BatchingEntityLoader.class );
 
 	private final EntityPersister persister;
 
 	public BatchingEntityLoader(EntityPersister persister) {
 		this.persister = persister;
 	}
 
 	public EntityPersister persister() {
 		return persister;
 	}
 
 	@Override
-	@Deprecated
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session) {
 		return load( id, optionalObject, session, LockOptions.NONE );
 	}
 
 	protected QueryParameters buildQueryParameters(
 			Serializable id,
 			Serializable[] ids,
 			Object optionalObject,
 			LockOptions lockOptions) {
 		Type[] types = new Type[ids.length];
 		Arrays.fill( types, persister().getIdentifierType() );
 
 		QueryParameters qp = new QueryParameters();
 		qp.setPositionalParameterTypes( types );
 		qp.setPositionalParameterValues( ids );
 		qp.setOptionalObject( optionalObject );
 		qp.setOptionalEntityName( persister().getEntityName() );
 		qp.setOptionalId( id );
 		qp.setLockOptions( lockOptions );
 		return qp;
 	}
 
 	protected Object getObjectFromList(List results, Serializable id, SessionImplementor session) {
 		for ( Object obj : results ) {
 			final boolean equal = persister.getIdentifierType().isEqual(
 					id,
 					session.getContextEntityIdentifier( obj ),
 					session.getFactory()
 			);
 			if ( equal ) {
 				return obj;
 			}
 		}
 		return null;
 	}
 
 	protected Object doBatchLoad(
 			Serializable id,
 			Loader loaderToUse,
 			SessionImplementor session,
 			Serializable[] ids,
 			Object optionalObject,
 			LockOptions lockOptions) {
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, session.getFactory() ) );
 		}
 
 		QueryParameters qp = buildQueryParameters( id, ids, optionalObject, lockOptions );
 
 		try {
 			final List results = loaderToUse.doQueryAndInitializeNonLazyCollections( session, qp, false );
 			log.debug( "Done entity batch load" );
 			return getObjectFromList(results, id, session);
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not load an entity batch: " + MessageHelper.infoString( persister(), ids, session.getFactory() ),
 					loaderToUse.getSQLString()
 			);
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractLoadPlanBasedEntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractLoadPlanBasedEntityLoader.java
index 2b08976621..18072e6e01 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractLoadPlanBasedEntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractLoadPlanBasedEntityLoader.java
@@ -1,244 +1,243 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.entity.plan;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.List;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.loader.plan.build.internal.FetchGraphLoadPlanBuildingStrategy;
 import org.hibernate.loader.plan.build.internal.FetchStyleLoadPlanBuildingAssociationVisitationStrategy;
 import org.hibernate.loader.plan.build.internal.LoadGraphLoadPlanBuildingStrategy;
 import org.hibernate.loader.plan.build.spi.LoadPlanBuildingAssociationVisitationStrategy;
 import org.hibernate.loader.plan.build.spi.MetamodelDrivenLoadPlanBuilder;
 import org.hibernate.loader.plan.exec.internal.AbstractLoadPlanBasedLoader;
 import org.hibernate.loader.plan.exec.internal.BatchingLoadQueryDetailsFactory;
 import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
 import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 /**
  * A UniqueEntityLoader implementation based on using LoadPlans
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractLoadPlanBasedEntityLoader extends AbstractLoadPlanBasedLoader implements UniqueEntityLoader {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( AbstractLoadPlanBasedEntityLoader.class );
 
 	private final OuterJoinLoadable entityPersister;
 	private final Type uniqueKeyType;
 	private final String entityName;
 
 	private final LoadQueryDetails staticLoadQuery;
 
 	public AbstractLoadPlanBasedEntityLoader(
 			OuterJoinLoadable entityPersister,
 			SessionFactoryImplementor factory,
 			String[] uniqueKeyColumnNames,
 			Type uniqueKeyType,
 			QueryBuildingParameters buildingParameters) {
 		super( factory );
 		this.entityPersister = entityPersister;
 		this.uniqueKeyType = uniqueKeyType;
 		this.entityName = entityPersister.getEntityName();
 
 		final LoadPlanBuildingAssociationVisitationStrategy strategy;
 		if ( buildingParameters.getQueryInfluencers().getFetchGraph() != null ) {
 			strategy = new FetchGraphLoadPlanBuildingStrategy(
 					factory, buildingParameters.getQueryInfluencers(),buildingParameters.getLockMode()
 			);
 		}
 		else if ( buildingParameters.getQueryInfluencers().getLoadGraph() != null ) {
 			strategy = new LoadGraphLoadPlanBuildingStrategy(
 					factory, buildingParameters.getQueryInfluencers(),buildingParameters.getLockMode()
 			);
 		}
 		else {
 			strategy = new FetchStyleLoadPlanBuildingAssociationVisitationStrategy(
 					factory, buildingParameters.getQueryInfluencers(),buildingParameters.getLockMode()
 			);
 		}
 
 		final LoadPlan plan = MetamodelDrivenLoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-		this.staticLoadQuery = BatchingLoadQueryDetailsFactory.makeEntityLoadQueryDetails(
+		this.staticLoadQuery = BatchingLoadQueryDetailsFactory.INSTANCE.makeEntityLoadQueryDetails(
 				plan,
 				uniqueKeyColumnNames,
 				buildingParameters,
 				factory
 		);
 	}
 
 	@Override
 	protected LoadQueryDetails getStaticLoadQuery() {
 		return staticLoadQuery;
 	}
 
 	protected String getEntityName() {
 		return entityName;
 	}
 
 	/**
 	 * Called by wrappers that batch load entities
 	 * @param persister only needed for logging
 	 * @param lockOptions
 	 */
 	public final List loadEntityBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type idType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalId,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
 
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, getFactory() ) );
 		}
 
 		final Type[] types = new Type[ids.length];
 		Arrays.fill( types, idType );
 		List result;
 		try {
 			final QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( types );
 			qp.setPositionalParameterValues( ids );
 			qp.setLockOptions( lockOptions );
 
 			result = executeLoad(
 					session,
 					qp,
 					staticLoadQuery,
 					false,
 					null
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not load an entity batch: " + MessageHelper.infoString( entityPersister, ids, getFactory() ),
 					staticLoadQuery.getSqlStatement()
 			);
 		}
 
 		log.debug( "Done entity batch load" );
 
 		return result;
 
 	}
 
 	@Override
-	@Deprecated
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session) throws HibernateException {
 		return load( id, optionalObject, session, LockOptions.NONE );
 	}
 
 	@Override
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session, LockOptions lockOptions) {
 
 		final Object result;
 		try {
 			final QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( new Type[] { entityPersister.getIdentifierType() } );
 			qp.setPositionalParameterValues( new Object[] { id } );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( entityPersister.getEntityName() );
 			qp.setOptionalId( id );
 			qp.setLockOptions( lockOptions );
 
 			final List results = executeLoad(
 					session,
 					qp,
 					staticLoadQuery,
 					false,
 					null
 			);
 			result = extractEntityResult( results );
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not load an entity: " + MessageHelper.infoString(
 							entityPersister,
 							id,
 							entityPersister.getIdentifierType(),
 							getFactory()
 					),
 					staticLoadQuery.getSqlStatement()
 			);
 		}
 
 		log.debugf( "Done entity load : %s#%s", getEntityName(), id );
 		return result;
 	}
 
 	protected Object extractEntityResult(List results) {
 		if ( results.size() == 0 ) {
 			return null;
 		}
 		else if ( results.size() == 1 ) {
 			return results.get( 0 );
 		}
 		else {
 			final Object row = results.get( 0 );
 			if ( row.getClass().isArray() ) {
 				// the logical type of the result list is List<Object[]>.  See if the contained
 				// array contains just one element, and return that if so
 				final Object[] rowArray = (Object[]) row;
 				if ( rowArray.length == 1 ) {
 					return rowArray[0];
 				}
 			}
 			else {
 				return row;
 			}
 		}
 
 		throw new HibernateException( "Unable to interpret given query results in terms of a load-entity query" );
 	}
 
 	protected int[] getNamedParameterLocs(String name) {
 		throw new AssertionFailure("no named parameters");
 	}
 
 	protected void autoDiscoverTypes(ResultSet rs) {
 		throw new AssertionFailure("Auto discover types not supported in this loader");
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/BatchingEntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/BatchingEntityLoader.java
index 036a76c87b..370cac8569 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/BatchingEntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/BatchingEntityLoader.java
@@ -1,132 +1,131 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.entity.plan;
 
 import java.io.Serializable;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.List;
 
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.loader.Loader;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * The base contract for UniqueEntityLoader implementations capable of performing batch-fetch loading of entities
  * using multiple primary key values in the SQL <tt>WHERE</tt> clause.
  * <p/>
  * Typically these are
  *
  * @author Gavin King
  * @author Steve Ebersole
  *
  * @see org.hibernate.loader.entity.BatchingEntityLoaderBuilder
  * @see org.hibernate.loader.entity.UniqueEntityLoader
  */
 public abstract class BatchingEntityLoader implements UniqueEntityLoader {
 	private static final Logger log = Logger.getLogger( BatchingEntityLoader.class );
 
 	private final EntityPersister persister;
 
 	public BatchingEntityLoader(EntityPersister persister) {
 		this.persister = persister;
 	}
 
 	public EntityPersister persister() {
 		return persister;
 	}
 
 	@Override
-	@Deprecated
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session) {
 		return load( id, optionalObject, session, LockOptions.NONE );
 	}
 
 	protected QueryParameters buildQueryParameters(
 			Serializable id,
 			Serializable[] ids,
 			Object optionalObject,
 			LockOptions lockOptions) {
 		Type[] types = new Type[ids.length];
 		Arrays.fill( types, persister().getIdentifierType() );
 
 		QueryParameters qp = new QueryParameters();
 		qp.setPositionalParameterTypes( types );
 		qp.setPositionalParameterValues( ids );
 		qp.setOptionalObject( optionalObject );
 		qp.setOptionalEntityName( persister().getEntityName() );
 		qp.setOptionalId( id );
 		qp.setLockOptions( lockOptions );
 		return qp;
 	}
 
 	protected Object getObjectFromList(List results, Serializable id, SessionImplementor session) {
 		for ( Object obj : results ) {
 			final boolean equal = persister.getIdentifierType().isEqual(
 					id,
 					session.getContextEntityIdentifier( obj ),
 					session.getFactory()
 			);
 			if ( equal ) {
 				return obj;
 			}
 		}
 		return null;
 	}
 
 	protected Object doBatchLoad(
 			Serializable id,
 			Loader loaderToUse,
 			SessionImplementor session,
 			Serializable[] ids,
 			Object optionalObject,
 			LockOptions lockOptions) {
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, session.getFactory() ) );
 		}
 
 		QueryParameters qp = buildQueryParameters( id, ids, optionalObject, lockOptions );
 
 		try {
 			final List results = loaderToUse.doQueryAndInitializeNonLazyCollections( session, qp, false );
 			log.debug( "Done entity batch load" );
 			return getObjectFromList(results, id, session);
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not load an entity batch: " + MessageHelper.infoString( persister(), ids, session.getFactory() ),
 					loaderToUse.getSQLString()
 			);
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/BatchingLoadQueryDetailsFactory.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/BatchingLoadQueryDetailsFactory.java
index 87dbbbce6d..1a29a2a098 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/BatchingLoadQueryDetailsFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/BatchingLoadQueryDetailsFactory.java
@@ -1,118 +1,123 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.exec.internal;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
 import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.Queryable;
 
 /**
  * A factory class for creating a {@link org.hibernate.loader.plan.exec.spi.LoadQueryDetails} object.
  */
 public class BatchingLoadQueryDetailsFactory {
-	public final BatchingLoadQueryDetailsFactory INSTANCE = new BatchingLoadQueryDetailsFactory();
+	/**
+	 * Singleton access
+	 */
+	public static final BatchingLoadQueryDetailsFactory INSTANCE = new BatchingLoadQueryDetailsFactory();
 
-	// protect against external instantiation.
+	/**
+	 * Private to disallow instantiation
+	 */
 	private BatchingLoadQueryDetailsFactory() {
 	}
 
 	/**
 	 * Returns a EntityLoadQueryDetails object from the given inputs.
 	 *
 	 * @param loadPlan The load plan
 	 * @param keyColumnNames The columns to load the entity by (the PK columns or some other unique set of columns)
 	 * @param buildingParameters And influencers that would affect the generated SQL (mostly we are concerned with those
 	 * that add additional joins here)
 	 * @param factory The SessionFactory
 	 *
 	 * @return The EntityLoadQueryDetails
 	 */
-	public static LoadQueryDetails makeEntityLoadQueryDetails(
+	public LoadQueryDetails makeEntityLoadQueryDetails(
 			LoadPlan loadPlan,
 			String[] keyColumnNames,
 			QueryBuildingParameters buildingParameters,
 			SessionFactoryImplementor factory) {
 
 		// TODO: how should shouldUseOptionalEntityInformation be used?
 		// final int batchSize = buildingParameters.getBatchSize();
 		// final boolean shouldUseOptionalEntityInformation = batchSize == 1;
 
 		final EntityReturn rootReturn = RootHelper.INSTANCE.extractRootReturn( loadPlan, EntityReturn.class );
 		final String[] keyColumnNamesToUse = keyColumnNames != null
 				? keyColumnNames
 				: ( (Queryable) rootReturn.getEntityPersister() ).getIdentifierColumnNames();
 		// Should be just one querySpace (of type EntityQuerySpace) in querySpaces.  Should we validate that?
 		// Should we make it a util method on Helper like we do for extractRootReturn ?
 		final AliasResolutionContextImpl aliasResolutionContext = new AliasResolutionContextImpl( factory );
 		return new EntityLoadQueryDetails(
 				loadPlan,
 				keyColumnNamesToUse,
 				aliasResolutionContext,
 				rootReturn,
 				buildingParameters,
 				factory
 		);
 	}
 
 	/**
 	 * Constructs a BasicCollectionLoadQueryDetails object from the given inputs.
 	 *
 	 * @param collectionPersister The collection persister.
 	 * @param loadPlan The load plan.
 	 * @param buildingParameters And influencers that would affect the generated SQL (mostly we are concerned with those
 	 * that add additional joins here)
 	 *
 	 * @return The EntityLoadQueryDetails
 	 */
-	public static LoadQueryDetails makeCollectionLoadQueryDetails(
+	public LoadQueryDetails makeCollectionLoadQueryDetails(
 			CollectionPersister collectionPersister,
 			LoadPlan loadPlan,
 			QueryBuildingParameters buildingParameters) {
 		final CollectionReturn rootReturn = RootHelper.INSTANCE.extractRootReturn( loadPlan, CollectionReturn.class );
 		final AliasResolutionContextImpl aliasResolutionContext = new AliasResolutionContextImpl(
 				collectionPersister.getFactory()
 		);
 		return collectionPersister.isOneToMany() ?
 				new OneToManyLoadQueryDetails(
 						loadPlan,
 						aliasResolutionContext,
 						rootReturn,
 						buildingParameters,
 						collectionPersister.getFactory()
 				) :
 				new BasicCollectionLoadQueryDetails(
 						loadPlan,
 						aliasResolutionContext,
 						rootReturn,
 						buildingParameters,
 						collectionPersister.getFactory()
 				);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/lob/ReaderInputStream.java b/hibernate-core/src/main/java/org/hibernate/lob/ReaderInputStream.java
index 2f96eb9ca8..273b68a460 100644
--- a/hibernate-core/src/main/java/org/hibernate/lob/ReaderInputStream.java
+++ b/hibernate-core/src/main/java/org/hibernate/lob/ReaderInputStream.java
@@ -1,44 +1,45 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.lob;
+
 import java.io.IOException;
 import java.io.Reader;
 
 /**
  * Exposes a {@link java.io.Reader} as an {@link java.io.InputStream}.
  *
  * @deprecated Should not be used anymore. 
  */
+@Deprecated
 public class ReaderInputStream extends org.hibernate.engine.jdbc.ReaderInputStream {
 
 	public ReaderInputStream(Reader reader) {
 		super(reader);
 	}
 
 	public int read() throws IOException {
 		return super.read();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Column.java b/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
index 539f8feb3f..cd5c0ea641 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
@@ -1,377 +1,382 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 import java.io.Serializable;
 import java.util.Locale;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.Template;
 
 /**
  * A column of a relational database table
  * @author Gavin King
  */
 public class Column implements Selectable, Serializable, Cloneable {
 
 	public static final int DEFAULT_LENGTH = 255;
 	public static final int DEFAULT_PRECISION = 19;
 	public static final int DEFAULT_SCALE = 2;
 
 	private int length=DEFAULT_LENGTH;
 	private int precision=DEFAULT_PRECISION;
 	private int scale=DEFAULT_SCALE;
 	private Value value;
 	private int typeIndex;
 	private String name;
 	private boolean nullable=true;
 	private boolean unique;
 	private String sqlType;
 	private Integer sqlTypeCode;
 	private boolean quoted;
 	int uniqueInteger;
 	private String checkConstraint;
 	private String comment;
 	private String defaultValue;
 	private String customWrite;
 	private String customRead;
 
 	public Column() {
 	}
 
 	public Column(String columnName) {
 		setName(columnName);
 	}
 
 	public int getLength() {
 		return length;
 	}
 	public void setLength(int length) {
 		this.length = length;
 	}
 	public Value getValue() {
 		return value;
 	}
 	public void setValue(Value value) {
 		this.value= value;
 	}
 	public String getName() {
 		return name;
 	}
 	public void setName(String name) {
 		if (
 			StringHelper.isNotEmpty( name ) &&
 			Dialect.QUOTE.indexOf( name.charAt(0) ) > -1 //TODO: deprecated, remove eventually
 		) {
 			quoted=true;
 			this.name=name.substring( 1, name.length()-1 );
 		}
 		else {
 			this.name = name;
 		}
 	}
 
 	/** returns quoted name as it would be in the mapping file. */
 	public String getQuotedName() {
 		return quoted ?
 				"`" + name + "`" :
 				name;
 	}
 
 	public String getQuotedName(Dialect d) {
 		return quoted ?
 			d.openQuote() + name + d.closeQuote() :
 			name;
 	}
 	
 	@Override
 	public String getAlias(Dialect dialect) {
 		final int lastLetter = StringHelper.lastIndexOfLetter( name );
 		final String suffix = Integer.toString(uniqueInteger) + '_';
 
 		String alias = name;
 		if ( lastLetter == -1 ) {
 			alias = "column";
 		}
 		else if ( name.length() > lastLetter + 1 ) {
 			alias = name.substring( 0, lastLetter + 1 );
 		}
 
 		boolean useRawName = name.length() + suffix.length() <= dialect.getMaxAliasLength()
 				&& !quoted && !name.toLowerCase(Locale.ROOT).equals( "rowid" );
 		if ( !useRawName ) {
 			if ( suffix.length() >= dialect.getMaxAliasLength() ) {
 				throw new MappingException( String.format(
 						"Unique suffix [%s] length must be less than maximum [%d]",
 						suffix, dialect.getMaxAliasLength() ) );
 			}
 			if ( alias.length() + suffix.length() > dialect.getMaxAliasLength() ) {
 				alias = alias.substring( 0, dialect.getMaxAliasLength() - suffix.length() );
 			}
 		}
 		return alias + suffix;
 	}
 	
 	/**
 	 * Generate a column alias that is unique across multiple tables
 	 */
 	@Override
 	public String getAlias(Dialect dialect, Table table) {
 		return getAlias(dialect) + table.getUniqueInteger() + '_';
 	}
 
 	public boolean isNullable() {
 		return nullable;
 	}
 
 	public void setNullable(boolean nullable) {
 		this.nullable=nullable;
 	}
 
 	public int getTypeIndex() {
 		return typeIndex;
 	}
 	public void setTypeIndex(int typeIndex) {
 		this.typeIndex = typeIndex;
 	}
 
 	public boolean isUnique() {
 		return unique;
 	}
 
 	@Override
 	public int hashCode() {
 		//used also for generation of FK names!
 		return isQuoted() ?
 			name.hashCode() :
 			name.toLowerCase(Locale.ROOT).hashCode();
 	}
 
 	@Override
 	public boolean equals(Object object) {
 		return object instanceof Column && equals( (Column) object );
 	}
 
+	@SuppressWarnings("SimplifiableIfStatement")
 	public boolean equals(Column column) {
-		if (null == column) return false;
-		if (this == column) return true;
+		if (null == column) {
+			return false;
+		}
+		if (this == column) {
+			return true;
+		}
 
-		return isQuoted() ? 
+		return isQuoted() ?
 			name.equals(column.name) :
 			name.equalsIgnoreCase(column.name);
 	}
 
     public int getSqlTypeCode(Mapping mapping) throws MappingException {
         org.hibernate.type.Type type = getValue().getType();
         try {
             int sqlTypeCode = type.sqlTypes( mapping )[getTypeIndex()];
             if ( getSqlTypeCode() != null && getSqlTypeCode() != sqlTypeCode ) {
                 throw new MappingException( "SQLType code's does not match. mapped as " + sqlTypeCode + " but is " + getSqlTypeCode() );
             }
             return sqlTypeCode;
         }
         catch ( Exception e ) {
             throw new MappingException(
                     "Could not determine type for column " +
                             name +
                             " of type " +
                             type.getClass().getName() +
                             ": " +
                             e.getClass().getName(),
                     e
             );
         }
     }
 
     /**
      * Returns the underlying columns sqltypecode.
      * If null, it is because the sqltype code is unknown.
      *
      * Use #getSqlTypeCode(Mapping) to retreive the sqltypecode used
      * for the columns associated Value/Type.
      *
      * @return sqlTypeCode if it is set, otherwise null.
      */
     public Integer getSqlTypeCode() {
         return sqlTypeCode;
     }
 
     public void setSqlTypeCode(Integer typeCode) {
         sqlTypeCode=typeCode;
     }
 
     public String getSqlType(Dialect dialect, Mapping mapping) throws HibernateException {
         if ( sqlType == null ) {
             sqlType = dialect.getTypeName( getSqlTypeCode( mapping ), getLength(), getPrecision(), getScale() );
         }
         return sqlType;
     }
 
 	public String getSqlType() {
 		return sqlType;
 	}
 
 	public void setSqlType(String sqlType) {
 		this.sqlType = sqlType;
 	}
 
 	public void setUnique(boolean unique) {
 		this.unique = unique;
 	}
 
 	public boolean isQuoted() {
 		return quoted;
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getName() + ')';
 	}
 
 	public String getCheckConstraint() {
 		return checkConstraint;
 	}
 
 	public void setCheckConstraint(String checkConstraint) {
 		this.checkConstraint = checkConstraint;
 	}
 
 	public boolean hasCheckConstraint() {
 		return checkConstraint!=null;
 	}
 
 	@Override
 	public String getTemplate(Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return hasCustomRead()
 				? Template.renderWhereStringTemplate( customRead, dialect, functionRegistry )
 				: Template.TEMPLATE + '.' + getQuotedName( dialect );
 	}
 
 	public boolean hasCustomRead() {
 		return ( customRead != null && customRead.length() > 0 );
 	}
 
 	public String getReadExpr(Dialect dialect) {
 		return hasCustomRead() ? customRead : getQuotedName( dialect );
 	}
 	
 	public String getWriteExpr() {
 		return ( customWrite != null && customWrite.length() > 0 ) ? customWrite : "?";
 	}
 
 	@Override
 	public boolean isFormula() {
 		return false;
 	}
 
 	@Override
 	public String getText(Dialect d) {
 		return getQuotedName(d);
 	}
 
 	@Override
 	public String getText() {
 		return getName();
 	}
 	
 	public int getPrecision() {
 		return precision;
 	}
 	public void setPrecision(int scale) {
 		this.precision = scale;
 	}
 
 	public int getScale() {
 		return scale;
 	}
 	public void setScale(int scale) {
 		this.scale = scale;
 	}
 
 	public String getComment() {
 		return comment;
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public String getDefaultValue() {
 		return defaultValue;
 	}
 
 	public void setDefaultValue(String defaultValue) {
 		this.defaultValue = defaultValue;
 	}
 
 	public String getCustomWrite() {
 		return customWrite;
 	}
 
 	public void setCustomWrite(String customWrite) {
 		this.customWrite = customWrite;
 	}
 
 	public String getCustomRead() {
 		return customRead;
 	}
 
 	public void setCustomRead(String customRead) {
 		this.customRead = customRead;
 	}
 
 	public String getCanonicalName() {
 		return quoted ? name : name.toLowerCase(Locale.ROOT);
 	}
 
 	/**
 	 * Shallow copy, the value is not copied
 	 */
 	@Override
 	public Column clone() {
 		Column copy = new Column();
 		copy.setLength( length );
 		copy.setScale( scale );
 		copy.setValue( value );
 		copy.setTypeIndex( typeIndex );
 		copy.setName( getQuotedName() );
 		copy.setNullable( nullable );
 		copy.setPrecision( precision );
 		copy.setUnique( unique );
 		copy.setSqlType( sqlType );
 		copy.setSqlTypeCode( sqlTypeCode );
 		copy.uniqueInteger = uniqueInteger; //usually useless
 		copy.setCheckConstraint( checkConstraint );
 		copy.setComment( comment );
 		copy.setDefaultValue( defaultValue );
 		copy.setCustomRead( customRead );
 		copy.setCustomWrite( customWrite );
 		return copy;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Constraint.java b/hibernate-core/src/main/java/org/hibernate/mapping/Constraint.java
index 23610deba3..3799c83bc1 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Constraint.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Constraint.java
@@ -1,233 +1,230 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 import java.io.Serializable;
 import java.math.BigInteger;
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Comparator;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Locale;
 
 import org.hibernate.HibernateException;
 import org.hibernate.annotations.common.util.StringHelper;
 import org.hibernate.boot.model.relational.Exportable;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.Mapping;
 
 /**
  * A relational constraint.
  *
  * @author Gavin King
  * @author Brett Meyer
  */
 public abstract class Constraint implements RelationalModel, Exportable, Serializable {
 
 	private String name;
 	private final ArrayList<Column> columns = new ArrayList<Column>();
 	private Table table;
 
 	public String getName() {
 		return name;
 	}
 
 	public void setName(String name) {
 		this.name = name;
 	}
 	
 	/**
 	 * If a constraint is not explicitly named, this is called to generate
 	 * a unique hash using the table and column names.
 	 * Static so the name can be generated prior to creating the Constraint.
 	 * They're cached, keyed by name, in multiple locations.
-	 * 
-	 * @param prefix
-	 *            Appended to the beginning of the generated name
-	 * @param table
-	 * @param columns
+	 *
 	 * @return String The generated name
 	 */
 	public static String generateName(String prefix, Table table, Column... columns) {
 		// Use a concatenation that guarantees uniqueness, even if identical names
 		// exist between all table and column identifiers.
 
 		StringBuilder sb = new StringBuilder( "table`" + table.getName() + "`" );
 
 		// Ensure a consistent ordering of columns, regardless of the order
 		// they were bound.
 		// Clone the list, as sometimes a set of order-dependent Column
 		// bindings are given.
 		Column[] alphabeticalColumns = columns.clone();
 		Arrays.sort( alphabeticalColumns, ColumnComparator.INSTANCE );
 		for ( Column column : alphabeticalColumns ) {
 			String columnName = column == null ? "" : column.getName();
-			sb.append( "column`" + columnName + "`" );
+			sb.append( "column`" ).append( columnName ).append( "`" );
 		}
 		return prefix + hashedName( sb.toString() );
 	}
 
 	/**
 	 * Helper method for {@link #generateName(String, Table, Column...)}.
-	 * 
-	 * @param prefix
-	 *            Appended to the beginning of the generated name
-	 * @param table
-	 * @param columns
+	 *
 	 * @return String The generated name
 	 */
 	public static String generateName(String prefix, Table table, List<Column> columns) {
 		return generateName( prefix, table, columns.toArray( new Column[columns.size()] ) );
 	}
 
 	/**
 	 * Hash a constraint name using MD5. Convert the MD5 digest to base 35
 	 * (full alphanumeric), guaranteeing
 	 * that the length of the name will always be smaller than the 30
 	 * character identifier restriction enforced by a few dialects.
 	 * 
 	 * @param s
 	 *            The name to be hashed.
 	 * @return String The hased name.
 	 */
 	public static String hashedName(String s) {
 		try {
 			MessageDigest md = MessageDigest.getInstance( "MD5" );
 			md.reset();
 			md.update( s.getBytes() );
 			byte[] digest = md.digest();
 			BigInteger bigInt = new BigInteger( 1, digest );
 			// By converting to base 35 (full alphanumeric), we guarantee
 			// that the length of the name will always be smaller than the 30
 			// character identifier restriction enforced by a few dialects.
 			return bigInt.toString( 35 );
 		}
 		catch ( NoSuchAlgorithmException e ) {
 			throw new HibernateException( "Unable to generate a hashed Constraint name!", e );
 		}
 	}
 
 	private static class ColumnComparator implements Comparator<Column> {
 		public static ColumnComparator INSTANCE = new ColumnComparator();
 
 		public int compare(Column col1, Column col2) {
 			return col1.getName().compareTo( col2.getName() );
 		}
 	}
 
 	public void addColumn(Column column) {
-		if ( !columns.contains( column ) ) columns.add( column );
+		if ( !columns.contains( column ) ) {
+			columns.add( column );
+		}
 	}
 
 	public void addColumns(Iterator columnIterator) {
 		while ( columnIterator.hasNext() ) {
 			Selectable col = (Selectable) columnIterator.next();
-			if ( !col.isFormula() ) addColumn( (Column) col );
+			if ( !col.isFormula() ) {
+				addColumn( (Column) col );
+			}
 		}
 	}
 
 	/**
-	 * @param column
 	 * @return true if this constraint already contains a column with same name.
 	 */
 	public boolean containsColumn(Column column) {
 		return columns.contains( column );
 	}
 
 	public int getColumnSpan() {
 		return columns.size();
 	}
 
 	public Column getColumn(int i) {
 		return  columns.get( i );
 	}
 	//todo duplicated method, remove one
 	public Iterator<Column> getColumnIterator() {
 		return columns.iterator();
 	}
 
 	public Iterator<Column> columnIterator() {
 		return columns.iterator();
 	}
 
 	public Table getTable() {
 		return table;
 	}
 
 	public void setTable(Table table) {
 		this.table = table;
 	}
 
 	public boolean isGenerated(Dialect dialect) {
 		return true;
 	}
 
 	public String sqlDropString(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		if ( isGenerated( dialect ) ) {
-			return new StringBuilder()
-					.append( "alter table " )
-					.append( getTable().getQualifiedName( dialect, defaultCatalog, defaultSchema ) )
-					.append( " drop constraint " )
-					.append( dialect.quote( getName() ) )
-					.toString();
+			return String.format(
+					Locale.ROOT,
+					"alter table %s drop constraint %s",
+					getTable().getQualifiedName( dialect, defaultCatalog, defaultSchema ),
+					dialect.quote( getName() )
+			);
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String sqlCreateString(Dialect dialect, Mapping p, String defaultCatalog, String defaultSchema) {
 		if ( isGenerated( dialect ) ) {
 			// Certain dialects (ex: HANA) don't support FKs as expected, but other constraints can still be created.
 			// If that's the case, hasAlterTable() will be true, but getAddForeignKeyConstraintString will return
 			// empty string.  Prevent blank "alter table" statements.
 			String constraintString = sqlConstraintString( dialect, getName(), defaultCatalog, defaultSchema );
 			if ( !StringHelper.isEmpty( constraintString ) ) {
-				StringBuilder buf = new StringBuilder( "alter table " )
-						.append( getTable().getQualifiedName( dialect, defaultCatalog, defaultSchema ) )
-						.append( constraintString );
-				return buf.toString();
+				return "alter table " + getTable().getQualifiedName( dialect, defaultCatalog, defaultSchema )
+						+ constraintString;
 			}
 		}
 		return null;
 	}
 
 	public List getColumns() {
 		return columns;
 	}
 
-	public abstract String sqlConstraintString(Dialect d, String constraintName, String defaultCatalog,
-											   String defaultSchema);
+	public abstract String sqlConstraintString(
+			Dialect d,
+			String constraintName,
+			String defaultCatalog,
+			String defaultSchema);
 
 	public String toString() {
 		return getClass().getName() + '(' + getTable().getName() + getColumns() + ") as " + name;
 	}
 	
 	/**
 	 * @return String The prefix to use in generated constraint names.  Examples:
 	 * "UK_", "FK_", and "PK_".
 	 */
 	public abstract String generatedConstraintNamePrefix();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/ForeignKey.java b/hibernate-core/src/main/java/org/hibernate/mapping/ForeignKey.java
index dad5f2e4e1..9e93c07b39 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/ForeignKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/ForeignKey.java
@@ -1,231 +1,233 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A foreign key constraint
  * @author Gavin King
  */
 public class ForeignKey extends Constraint {
-
 	private Table referencedTable;
 	private String referencedEntityName;
 	private boolean cascadeDeleteEnabled;
-	private List referencedColumns = new ArrayList();
+	private List<Column> referencedColumns = new ArrayList<Column>();
 	private boolean creationEnabled = true;
 
 	public ForeignKey() {
 	}
 
 	@Override
 	public String getExportIdentifier() {
 		// NOt sure name is always set.  Might need some implicit naming
 		return StringHelper.qualify( getTable().getName(), "FK-" + getName() );
 	}
 
 	public void disableCreation() {
 		creationEnabled = false;
 	}
 
 	public boolean isCreationEnabled() {
 		return creationEnabled;
 	}
 
 	@Override
 	public void setName(String name) {
 		super.setName( name );
 		// the FK name "none" is a magic value in the hbm.xml binding that indicated to
 		// not create a FK.
 		if ( "none".equals( name ) ) {
 			disableCreation();
 		}
 	}
 
 	public String sqlConstraintString(Dialect dialect, String constraintName, String defaultCatalog, String defaultSchema) {
 		String[] columnNames = new String[ getColumnSpan() ];
 		String[] referencedColumnNames = new String[ getColumnSpan() ];
 
-		final Iterator referencedColumnItr;
+		final Iterator<Column> referencedColumnItr;
 		if ( isReferenceToPrimaryKey() ) {
 			referencedColumnItr = referencedTable.getPrimaryKey().getColumnIterator();
 		} 
 		else {
 			referencedColumnItr = referencedColumns.iterator();
 		}
 		
 		Iterator columnItr = getColumnIterator();
 		int i=0;
 		while ( columnItr.hasNext() ) {
 			columnNames[i] = ( (Column) columnItr.next() ).getQuotedName(dialect);
-			referencedColumnNames[i] = ( (Column) referencedColumnItr.next() ).getQuotedName(dialect);
+			referencedColumnNames[i] = referencedColumnItr.next().getQuotedName(dialect);
 			i++;
 		}
 
 		final String result = dialect.getAddForeignKeyConstraintString(
 			constraintName,
 			columnNames,
 			referencedTable.getQualifiedName(dialect, defaultCatalog, defaultSchema),
 			referencedColumnNames,
 			isReferenceToPrimaryKey()
 		);
 		return cascadeDeleteEnabled && dialect.supportsCascadeDelete()
 				? result + " on delete cascade"
 				: result;
 	}
 
 	public Table getReferencedTable() {
 		return referencedTable;
 	}
 
 	private void appendColumns(StringBuilder buf, Iterator columns) {
 		while( columns.hasNext() ) {
 			Column column = (Column) columns.next();
 			buf.append( column.getName() );
-			if ( columns.hasNext() ) buf.append(",");
+			if ( columns.hasNext() ) {
+				buf.append(",");
+			}
 		}
 	}
 
 	public void setReferencedTable(Table referencedTable) throws MappingException {
 		//if( isReferenceToPrimaryKey() ) alignColumns(referencedTable); // TODO: possibly remove to allow more piecemal building of a foreignkey.  
 		
 		this.referencedTable = referencedTable;
 	}
 
 	/**
 	 * Validates that columnspan of the foreignkey and the primarykey is the same.
 	 * 
 	 * Furthermore it aligns the length of the underlying tables columns.
 	 */
 	public void alignColumns() {
-		if ( isReferenceToPrimaryKey() ) alignColumns(referencedTable);
+		if ( isReferenceToPrimaryKey() ) {
+			alignColumns(referencedTable);
+		}
 	}
 	
 	private void alignColumns(Table referencedTable) {
 		final int referencedPkColumnSpan = referencedTable.getPrimaryKey().getColumnSpan();
 		if ( referencedPkColumnSpan != getColumnSpan() ) {
 			StringBuilder sb = new StringBuilder();
 			sb.append( "Foreign key (" ).append( getName() ).append( ":" )
-				.append( getTable().getName() )
-				.append(" [");
+					.append( getTable().getName() )
+					.append( " [" );
 			appendColumns( sb, getColumnIterator() );
 			sb.append("])")
-				.append(") must have same number of columns as the referenced primary key (")
-				.append( referencedTable.getName() )
-				.append(" [");
+					.append( ") must have same number of columns as the referenced primary key (" )
+					.append( referencedTable.getName() )
+					.append( " [" );
 			appendColumns( sb, referencedTable.getPrimaryKey().getColumnIterator() );
 			sb.append("])");
 			throw new MappingException( sb.toString() );
 		}
 		
 		Iterator fkCols = getColumnIterator();
 		Iterator pkCols = referencedTable.getPrimaryKey().getColumnIterator();
 		while ( pkCols.hasNext() ) {
 			( (Column) fkCols.next() ).setLength( ( (Column) pkCols.next() ).getLength() );
 		}
 
 	}
 
 	public String getReferencedEntityName() {
 		return referencedEntityName;
 	}
 
 	public void setReferencedEntityName(String referencedEntityName) {
 		this.referencedEntityName = referencedEntityName;
 	}
 
 	public String sqlDropString(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		final StringBuilder buf = new StringBuilder( "alter table " );
 		buf.append( getTable().getQualifiedName(dialect, defaultCatalog, defaultSchema) );
 		buf.append( dialect.getDropForeignKeyString() );
 		if ( dialect.supportsIfExistsBeforeConstraintName() ) {
 			buf.append( "if exists " );
 		}
 		buf.append( dialect.quote( getName() ) );
 		if ( dialect.supportsIfExistsAfterConstraintName() ) {
 			buf.append( " if exists" );
 		}
 		return buf.toString();
 	}
 
 	public boolean isCascadeDeleteEnabled() {
 		return cascadeDeleteEnabled;
 	}
 
 	public void setCascadeDeleteEnabled(boolean cascadeDeleteEnabled) {
 		this.cascadeDeleteEnabled = cascadeDeleteEnabled;
 	}
 	
 	public boolean isPhysicalConstraint() {
 		return referencedTable.isPhysicalTable()
 				&& getTable().isPhysicalTable()
 				&& !referencedTable.hasDenormalizedTables();
 	}
 
 	/** Returns the referenced columns if the foreignkey does not refer to the primary key */
 	public List getReferencedColumns() {
 		return referencedColumns;		
 	}
 
 	/** Does this foreignkey reference the primary key of the reference table */ 
 	public boolean isReferenceToPrimaryKey() {
 		return referencedColumns.isEmpty();
 	}
 
 	public void addReferencedColumns(Iterator referencedColumnsIterator) {
 		while ( referencedColumnsIterator.hasNext() ) {
 			Selectable col = (Selectable) referencedColumnsIterator.next();
 			if ( !col.isFormula() ) addReferencedColumn( (Column) col );
 		}
 	}
 
 	private void addReferencedColumn(Column column) {
 		if ( !referencedColumns.contains(column) ) {
 			referencedColumns.add( column );
 		}
 	}
 	
 	public String toString() {
 		if(!isReferenceToPrimaryKey() ) {
-			StringBuilder result = new StringBuilder(getClass().getName() + '(' + getTable().getName() + getColumns() );
-			result.append( " ref-columns:" + '(' + getReferencedColumns() );
-			result.append( ") as " + getName() );
-			return result.toString();
+			return getClass().getName()
+					+ '(' + getTable().getName() + getColumns()
+					+ " ref-columns:" + '(' + getReferencedColumns() + ") as " + getName() + ")";
 		} 
 		else {
 			return super.toString();
 		}
 		
 	}
 	
 	public String generatedConstraintNamePrefix() {
 		return "FK_";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Index.java b/hibernate-core/src/main/java/org/hibernate/mapping/Index.java
index 841bad574a..d667145afa 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Index.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Index.java
@@ -1,245 +1,249 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.model.relational.Exportable;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A relational table index
  *
  * @author Gavin King
  */
 public class Index implements RelationalModel, Exportable, Serializable {
 	private Table table;
 	private java.util.List<Column> columns = new ArrayList<Column>();
 	private java.util.Map<Column, String> columnOrderMap = new HashMap<Column, String>(  );
 	private String name;
 
 	public String sqlCreateString(Dialect dialect, Mapping mapping, String defaultCatalog, String defaultSchema)
 			throws HibernateException {
 		return buildSqlCreateIndexString(
 				dialect,
 				getName(),
 				getTable(),
 				getColumnIterator(),
 				columnOrderMap,
 				false,
 				defaultCatalog,
 				defaultSchema
 		);
 	}
 
 	public static String buildSqlDropIndexString(
 			Dialect dialect,
 			Table table,
 			String name,
 			String defaultCatalog,
 			String defaultSchema) {
 		return buildSqlDropIndexString( name, table.getQualifiedName( dialect, defaultCatalog, defaultSchema ) );
 	}
 
 	public static String buildSqlDropIndexString(
 			String name,
 			String tableName) {
 		return "drop index " + StringHelper.qualify( tableName, name );
 	}
 
 	public static String buildSqlCreateIndexString(
 			Dialect dialect,
 			String name,
 			Table table,
 			Iterator<Column> columns,
 			java.util.Map<Column, String> columnOrderMap,
 			boolean unique,
 			String defaultCatalog,
 			String defaultSchema) {
 		return buildSqlCreateIndexString(
 				dialect,
 				name,
 				table.getQualifiedName( dialect, defaultCatalog, defaultSchema ),
 				columns,
 				columnOrderMap,
 				unique
 		);
 	}
 
 	public static String buildSqlCreateIndexString(
 			Dialect dialect,
 			String name,
 			String tableName,
 			Iterator<Column> columns,
 			java.util.Map<Column, String> columnOrderMap,
 			boolean unique) {
 		StringBuilder buf = new StringBuilder( "create" )
 				.append( unique ? " unique" : "" )
 				.append( " index " )
 				.append( dialect.qualifyIndexName() ? name : StringHelper.unqualify( name ) )
 				.append( " on " )
 				.append( tableName )
 				.append( " (" );
 		while ( columns.hasNext() ) {
 			Column column = columns.next();
 			buf.append( column.getQuotedName( dialect ) );
 			if ( columnOrderMap.containsKey( column ) ) {
 				buf.append( " " ).append( columnOrderMap.get( column ) );
 			}
-			if ( columns.hasNext() ) buf.append( ", " );
+			if ( columns.hasNext() ) {
+				buf.append( ", " );
+			}
 		}
 		buf.append( ")" );
 		return buf.toString();
 	}
 
 	public static String buildSqlCreateIndexString(
 			Dialect dialect,
 			String name,
 			Table table,
 			Iterator<Column> columns,
 			boolean unique,
 			String defaultCatalog,
 			String defaultSchema) {
 		return buildSqlCreateIndexString(
 				dialect,
 				name,
 				table,
 				columns,
 				Collections.EMPTY_MAP,
 				unique,
 				defaultCatalog,
 				defaultSchema
 		);
 	}
 
 	public static String buildSqlCreateIndexString(
 			Dialect dialect,
 			String name,
 			Table table,
 			Iterator<Column> columns,
 			java.util.Map<Column, String> columnOrderMap,
 			boolean unique,
 			Metadata metadata) {
 		final JdbcEnvironment jdbcEnvironment = metadata.getDatabase().getJdbcEnvironment();
 
 		final String tableName = jdbcEnvironment.getQualifiedObjectNameFormatter().format(
 				table.getQualifiedTableName(),
 				dialect
 		);
 
 		return buildSqlCreateIndexString(
 				dialect,
 				name,
 				tableName,
 				columns,
 				columnOrderMap,
 				unique
 		);
 	}
 
 
 	// Used only in Table for sqlCreateString (but commented out at the moment)
 	public String sqlConstraintString(Dialect dialect) {
 		StringBuilder buf = new StringBuilder( " index (" );
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			buf.append( ( (Column) iter.next() ).getQuotedName( dialect ) );
 			if ( iter.hasNext() ) buf.append( ", " );
 		}
 		return buf.append( ')' ).toString();
 	}
 
 	public String sqlDropString(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		return "drop index " +
 				StringHelper.qualify(
 						table.getQualifiedName( dialect, defaultCatalog, defaultSchema ),
 						name
 				);
 	}
 
 	public Table getTable() {
 		return table;
 	}
 
 	public void setTable(Table table) {
 		this.table = table;
 	}
 
 	public int getColumnSpan() {
 		return columns.size();
 	}
 
 	public Iterator<Column> getColumnIterator() {
 		return columns.iterator();
 	}
 
 	public void addColumn(Column column) {
-		if ( !columns.contains( column ) ) columns.add( column );
+		if ( !columns.contains( column ) ) {
+			columns.add( column );
+		}
 	}
 
 	public void addColumn(Column column, String order) {
 		addColumn( column );
 		if ( StringHelper.isNotEmpty( order ) ) {
 			columnOrderMap.put( column, order );
 		}
 	}
 
 	public void addColumns(Iterator extraColumns) {
 		while ( extraColumns.hasNext() ) addColumn( (Column) extraColumns.next() );
 	}
 
 	/**
 	 * @param column
 	 * @return true if this constraint already contains a column with same name.
 	 */
 	public boolean containsColumn(Column column) {
 		return columns.contains( column );
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public void setName(String name) {
 		this.name = name;
 	}
 
 	public String toString() {
 		return getClass().getName() + "(" + getName() + ")";
 	}
 
 	@Override
 	public String getExportIdentifier() {
 		return StringHelper.qualify( getTable().getName(), "IDX-" + getName() );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/IndexedCollection.java b/hibernate-core/src/main/java/org/hibernate/mapping/IndexedCollection.java
index 771fea0ff0..3546151a43 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/IndexedCollection.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/IndexedCollection.java
@@ -1,120 +1,122 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.util.Iterator;
 
 import org.hibernate.MappingException;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.engine.spi.Mapping;
 
 /**
  * Indexed collections include Lists, Maps, arrays and
  * primitive arrays.
  * @author Gavin King
  */
 public abstract class IndexedCollection extends Collection {
 
 	public static final String DEFAULT_INDEX_COLUMN_NAME = "idx";
 
 	private Value index;
 	private String indexNodeName;
 
 	public IndexedCollection(MetadataImplementor metadata, PersistentClass owner) {
 		super( metadata, owner );
 	}
 
 	public Value getIndex() {
 		return index;
 	}
 	public void setIndex(Value index) {
 		this.index = index;
 	}
 	public final boolean isIndexed() {
 		return true;
 	}
 
 	void createPrimaryKey() {
 		if ( !isOneToMany() ) {
 			PrimaryKey pk = new PrimaryKey();
 			pk.addColumns( getKey().getColumnIterator() );
 			
 			// index should be last column listed
 			boolean isFormula = false;
 			Iterator iter = getIndex().getColumnIterator();
 			while ( iter.hasNext() ) {
-				if ( ( (Selectable) iter.next() ).isFormula() ) isFormula=true;
+				if ( ( (Selectable) iter.next() ).isFormula() ) {
+					isFormula=true;
+				}
 			}
 			if (isFormula) {
 				//if it is a formula index, use the element columns in the PK
 				pk.addColumns( getElement().getColumnIterator() );
 			}
 			else {
 				pk.addColumns( getIndex().getColumnIterator() ); 
 			}
 			getCollectionTable().setPrimaryKey(pk);
 		}
 		else {
 			// don't create a unique key, 'cos some
 			// databases don't like a UK on nullable
 			// columns
 			/*ArrayList list = new ArrayList();
 			list.addAll( getKey().getConstraintColumns() );
 			list.addAll( getIndex().getConstraintColumns() );
 			getCollectionTable().createUniqueKey(list);*/
 		}
 	}
 
 	public void validate(Mapping mapping) throws MappingException {
 		super.validate( mapping );
 
 		assert getElement() != null : "IndexedCollection index not bound : " + getRole();
 
 		if ( !getIndex().isValid(mapping) ) {
 			throw new MappingException(
 				"collection index mapping has wrong number of columns: " +
 				getRole() +
 				" type: " +
 				getIndex().getType().getName()
 			);
 		}
 		if ( indexNodeName!=null && !indexNodeName.startsWith("@") ) {
 			throw new MappingException("index node must be an attribute: " + indexNodeName );
 		}
 	}
 	
 	public boolean isList() {
 		return false;
 	}
 
 	public String getIndexNodeName() {
 		return indexNodeName;
 	}
 
 	public void setIndexNodeName(String indexNodeName) {
 		this.indexNodeName = indexNodeName;
 	}
 	
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Join.java b/hibernate-core/src/main/java/org/hibernate/mapping/Join.java
index a10bd928e1..99ab96ab9e 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Join.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Join.java
@@ -1,211 +1,213 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Iterator;
 
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.sql.Alias;
 
 /**
  * @author Gavin King
  */
 public class Join implements AttributeContainer, Serializable {
 
 	private static final Alias PK_ALIAS = new Alias(15, "PK");
 
 	private ArrayList properties = new ArrayList();
 	private ArrayList declaredProperties = new ArrayList();
 	private Table table;
 	private KeyValue key;
 	private PersistentClass persistentClass;
 	private boolean sequentialSelect;
 	private boolean inverse;
 	private boolean optional;
 
 	// Custom SQL
 	private String customSQLInsert;
 	private boolean customInsertCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private String customSQLUpdate;
 	private boolean customUpdateCallable;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private String customSQLDelete;
 	private boolean customDeleteCallable;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 
 	@Override
 	public void addProperty(Property prop) {
 		properties.add(prop);
 		declaredProperties.add(prop);
 		prop.setPersistentClass( getPersistentClass() );
 	}
 
 	public void addMappedsuperclassProperty(Property prop) {
 		properties.add(prop);
 		prop.setPersistentClass( getPersistentClass() );
 	}
 
 	public Iterator getDeclaredPropertyIterator() {
 		return declaredProperties.iterator();
 	}
 
 	public boolean containsProperty(Property prop) {
 		return properties.contains(prop);
 	}
 	public Iterator getPropertyIterator() {
 		return properties.iterator();
 	}
 
 	public Table getTable() {
 		return table;
 	}
 	public void setTable(Table table) {
 		this.table = table;
 	}
 
 	public KeyValue getKey() {
 		return key;
 	}
 	public void setKey(KeyValue key) {
 		this.key = key;
 	}
 
 	public PersistentClass getPersistentClass() {
 		return persistentClass;
 	}
 
 	public void setPersistentClass(PersistentClass persistentClass) {
 		this.persistentClass = persistentClass;
 	}
 
 	public void createForeignKey() {
 		getKey().createForeignKeyOfEntity( persistentClass.getEntityName() );
 	}
 
 	public void createPrimaryKey() {
 		//Primary key constraint
 		PrimaryKey pk = new PrimaryKey();
 		pk.setTable(table);
 		pk.setName( PK_ALIAS.toAliasString( table.getName() ) );
 		table.setPrimaryKey(pk);
 
 		pk.addColumns( getKey().getColumnIterator() );
 	}
 
 	public int getPropertySpan() {
 		return properties.size();
 	}
 
 	public void setCustomSQLInsert(String customSQLInsert, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLInsert = customSQLInsert;
 		this.customInsertCallable = callable;
 		this.insertCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLInsert() {
 		return customSQLInsert;
 	}
 
 	public boolean isCustomInsertCallable() {
 		return customInsertCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLInsertCheckStyle() {
 		return insertCheckStyle;
 	}
 
 	public void setCustomSQLUpdate(String customSQLUpdate, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLUpdate = customSQLUpdate;
 		this.customUpdateCallable = callable;
 		this.updateCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLUpdate() {
 		return customSQLUpdate;
 	}
 
 	public boolean isCustomUpdateCallable() {
 		return customUpdateCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLUpdateCheckStyle() {
 		return updateCheckStyle;
 	}
 
 	public void setCustomSQLDelete(String customSQLDelete, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLDelete = customSQLDelete;
 		this.customDeleteCallable = callable;
 		this.deleteCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLDelete() {
 		return customSQLDelete;
 	}
 
 	public boolean isCustomDeleteCallable() {
 		return customDeleteCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLDeleteCheckStyle() {
 		return deleteCheckStyle;
 	}
 
 	public boolean isSequentialSelect() {
 		return sequentialSelect;
 	}
 	public void setSequentialSelect(boolean deferred) {
 		this.sequentialSelect = deferred;
 	}
 
 	public boolean isInverse() {
 		return inverse;
 	}
 
 	public void setInverse(boolean leftJoin) {
 		this.inverse = leftJoin;
 	}
 
 	public String toString() {
 		return getClass().getName() + '(' + table.toString() + ')';
 	}
 
 	public boolean isLazy() {
 		Iterator iter = getPropertyIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
-			if ( !prop.isLazy() ) return false;
+			if ( !prop.isLazy() ) {
+				return false;
+			}
 		}
 		return true;
 	}
 
 	public boolean isOptional() {
 		return optional;
 	}
 	public void setOptional(boolean nullable) {
 		this.optional = nullable;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/OneToOne.java b/hibernate-core/src/main/java/org/hibernate/mapping/OneToOne.java
index bac5a0a8f4..21d3fa161e 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/OneToOne.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/OneToOne.java
@@ -1,165 +1,167 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.util.ArrayList;
 import java.util.Iterator;
 
 import org.hibernate.MappingException;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.ForeignKeyDirection;
 import org.hibernate.type.Type;
 
 /**
  * A one-to-one association mapping
  * @author Gavin King
  */
 public class OneToOne extends ToOne {
 
 	private boolean constrained;
 	private ForeignKeyDirection foreignKeyType;
 	private KeyValue identifier;
 	private String propertyName;
 	private String entityName;
 
 	public OneToOne(MetadataImplementor metadata, Table table, PersistentClass owner) throws MappingException {
 		super( metadata, table );
 		this.identifier = owner.getKey();
 		this.entityName = owner.getEntityName();
 	}
 
 	public String getPropertyName() {
 		return propertyName;
 	}
 
 	public void setPropertyName(String propertyName) {
 		this.propertyName = propertyName==null ? null : propertyName.intern();
 	}
 	
 	public String getEntityName() {
 		return entityName;
 	}
 
 	public void setEntityName(String propertyName) {
 		this.entityName = entityName==null ? null : entityName.intern();
 	}
 	
 	public Type getType() throws MappingException {
 		if ( getColumnIterator().hasNext() ) {
 			return getMetadata().getTypeResolver().getTypeFactory().specialOneToOne(
 					getReferencedEntityName(), 
 					foreignKeyType,
 					referenceToPrimaryKey, 
 					referencedPropertyName,
 					isLazy(),
 					isUnwrapProxy(),
 					entityName,
 					propertyName
 			);
 		}
 		else {
 			return getMetadata().getTypeResolver().getTypeFactory().oneToOne(
 					getReferencedEntityName(), 
 					foreignKeyType,
 					referenceToPrimaryKey, 
 					referencedPropertyName,
 					isLazy(),
 					isUnwrapProxy(),
 					entityName,
 					propertyName
 			);
 		}
 	}
 
 	public void createForeignKey() throws MappingException {
 		if ( constrained && referencedPropertyName==null) {
 			//TODO: handle the case of a foreign key to something other than the pk
 			createForeignKeyOfEntity( ( (EntityType) getType() ).getAssociatedEntityName() );
 		}
 	}
 
 	public java.util.List getConstraintColumns() {
 		ArrayList list = new ArrayList();
 		Iterator iter = identifier.getColumnIterator();
-		while ( iter.hasNext() ) list.add( iter.next() );
+		while ( iter.hasNext() ) {
+			list.add( iter.next() );
+		}
 		return list;
 	}
 	/**
 	 * Returns the constrained.
 	 * @return boolean
 	 */
 	public boolean isConstrained() {
 		return constrained;
 	}
 
 	/**
 	 * Returns the foreignKeyType.
 	 * @return AssociationType.ForeignKeyType
 	 */
 	public ForeignKeyDirection getForeignKeyType() {
 		return foreignKeyType;
 	}
 
 	/**
 	 * Returns the identifier.
 	 * @return Value
 	 */
 	public KeyValue getIdentifier() {
 		return identifier;
 	}
 
 	/**
 	 * Sets the constrained.
 	 * @param constrained The constrained to set
 	 */
 	public void setConstrained(boolean constrained) {
 		this.constrained = constrained;
 	}
 
 	/**
 	 * Sets the foreignKeyType.
 	 * @param foreignKeyType The foreignKeyType to set
 	 */
 	public void setForeignKeyType(ForeignKeyDirection foreignKeyType) {
 		this.foreignKeyType = foreignKeyType;
 	}
 
 	/**
 	 * Sets the identifier.
 	 * @param identifier The identifier to set
 	 */
 	public void setIdentifier(KeyValue identifier) {
 		this.identifier = identifier;
 	}
 
 	public boolean isNullable() {
 		return !constrained;
 	}
 
 	public Object accept(ValueVisitor visitor) {
 		return visitor.accept(this);
 	}
 	
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/PersistentClass.java b/hibernate-core/src/main/java/org/hibernate/mapping/PersistentClass.java
index 24fa192726..77fc5431d9 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/PersistentClass.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/PersistentClass.java
@@ -1,875 +1,886 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.EntityMode;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.FilterConfiguration;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.EmptyIterator;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.internal.util.collections.SingletonIterator;
 import org.hibernate.sql.Alias;
 
 /**
  * Mapping for an entity.
  *
  * @author Gavin King
  */
 public abstract class PersistentClass implements AttributeContainer, Serializable, Filterable, MetaAttributable {
 
 	private static final Alias PK_ALIAS = new Alias(15, "PK");
 
 	public static final String NULL_DISCRIMINATOR_MAPPING = "null";
 	public static final String NOT_NULL_DISCRIMINATOR_MAPPING = "not null";
 
 	private String entityName;
 
 	private String className;
 	private transient Class mappedClass;
 	
 	private String proxyInterfaceName;
 	private transient Class proxyInterface;
 	
 	private String nodeName;
 	private String jpaEntityName;
 
 	private String discriminatorValue;
 	private boolean lazy;
 	private ArrayList properties = new ArrayList();
 	private ArrayList declaredProperties = new ArrayList();
-	private final ArrayList subclasses = new ArrayList();
+	private final ArrayList<Subclass> subclasses = new ArrayList<Subclass>();
 	private final ArrayList subclassProperties = new ArrayList();
 	private final ArrayList subclassTables = new ArrayList();
 	private boolean dynamicInsert;
 	private boolean dynamicUpdate;
 	private int batchSize=-1;
 	private boolean selectBeforeUpdate;
 	private java.util.Map metaAttributes;
-	private ArrayList joins = new ArrayList();
+	private ArrayList<Join> joins = new ArrayList<Join>();
 	private final ArrayList subclassJoins = new ArrayList();
 	private final java.util.List filters = new ArrayList();
 	protected final java.util.Set synchronizedTables = new HashSet();
 	private String loaderName;
 	private Boolean isAbstract;
 	private boolean hasSubselectLoadableCollections;
 	private Component identifierMapper;
 
 	// Custom SQL
 	private String customSQLInsert;
 	private boolean customInsertCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private String customSQLUpdate;
 	private boolean customUpdateCallable;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private String customSQLDelete;
 	private boolean customDeleteCallable;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 
 	private java.util.Map tuplizerImpls;
 
 	private MappedSuperclass superMappedSuperclass;
 	private Component declaredIdentifierMapper;
 	private OptimisticLockStyle optimisticLockStyle;
 
 	public String getClassName() {
 		return className;
 	}
 
 	public void setClassName(String className) {
 		this.className = className==null ? null : className.intern();
 		this.mappedClass = null;
 	}
 
 	public String getProxyInterfaceName() {
 		return proxyInterfaceName;
 	}
 
 	public void setProxyInterfaceName(String proxyInterfaceName) {
 		this.proxyInterfaceName = proxyInterfaceName;
 		this.proxyInterface = null;
 	}
 
 	public Class getMappedClass() throws MappingException {
-		if (className==null) return null;
+		if (className==null) {
+			return null;
+		}
 		try {
-			if(mappedClass == null) {
+			if (mappedClass == null) {
 				mappedClass = ReflectHelper.classForName(className);
 			}
 			return mappedClass;
 		}
 		catch (ClassNotFoundException cnfe) {
 			throw new MappingException("entity class not found: " + className, cnfe);
 		}
 	}
 
 	public Class getProxyInterface() {
-		if (proxyInterfaceName==null) return null;
+		if (proxyInterfaceName==null) {
+			return null;
+		}
 		try {
-			if(proxyInterface == null) {
+			if (proxyInterface == null) {
 				proxyInterface = ReflectHelper.classForName( proxyInterfaceName );
 			}
 			return proxyInterface;
 		}
 		catch (ClassNotFoundException cnfe) {
 			throw new MappingException("proxy class not found: " + proxyInterfaceName, cnfe);
 		}
 	}
+
 	public boolean useDynamicInsert() {
 		return dynamicInsert;
 	}
 
 	abstract int nextSubclassId();
 	public abstract int getSubclassId();
 	
 	public boolean useDynamicUpdate() {
 		return dynamicUpdate;
 	}
 
 	public void setDynamicInsert(boolean dynamicInsert) {
 		this.dynamicInsert = dynamicInsert;
 	}
 
 	public void setDynamicUpdate(boolean dynamicUpdate) {
 		this.dynamicUpdate = dynamicUpdate;
 	}
 
 
 	public String getDiscriminatorValue() {
 		return discriminatorValue;
 	}
 
 	public void addSubclass(Subclass subclass) throws MappingException {
 		// inheritance cycle detection (paranoid check)
 		PersistentClass superclass = getSuperclass();
 		while (superclass!=null) {
-			if( subclass.getEntityName().equals( superclass.getEntityName() ) ) {
+			if ( subclass.getEntityName().equals( superclass.getEntityName() ) ) {
 				throw new MappingException(
 					"Circular inheritance mapping detected: " +
 					subclass.getEntityName() +
 					" will have it self as superclass when extending " +
 					getEntityName()
 				);
 			}
 			superclass = superclass.getSuperclass();
 		}
 		subclasses.add(subclass);
 	}
 
 	public boolean hasSubclasses() {
 		return subclasses.size() > 0;
 	}
 
 	public int getSubclassSpan() {
 		int n = subclasses.size();
 		Iterator iter = subclasses.iterator();
 		while ( iter.hasNext() ) {
 			n += ( (Subclass) iter.next() ).getSubclassSpan();
 		}
 		return n;
 	}
 	/**
 	 * Iterate over subclasses in a special 'order', most derived subclasses
 	 * first.
 	 */
 	public Iterator getSubclassIterator() {
 		Iterator[] iters = new Iterator[ subclasses.size() + 1 ];
 		Iterator iter = subclasses.iterator();
 		int i=0;
 		while ( iter.hasNext() ) {
 			iters[i++] = ( (Subclass) iter.next() ).getSubclassIterator();
 		}
 		iters[i] = subclasses.iterator();
 		return new JoinedIterator(iters);
 	}
 
 	public Iterator getSubclassClosureIterator() {
 		ArrayList iters = new ArrayList();
 		iters.add( new SingletonIterator(this) );
 		Iterator iter = getSubclassIterator();
 		while ( iter.hasNext() ) {
 			PersistentClass clazz = (PersistentClass)  iter.next();
 			iters.add( clazz.getSubclassClosureIterator() );
 		}
 		return new JoinedIterator(iters);
 	}
 	
 	public Table getIdentityTable() {
 		return getRootTable();
 	}
 	
 	public Iterator getDirectSubclasses() {
 		return subclasses.iterator();
 	}
 
 	@Override
 	public void addProperty(Property p) {
 		properties.add(p);
 		declaredProperties.add(p);
 		p.setPersistentClass(this);
 	}
 
 	public abstract Table getTable();
 
 	public String getEntityName() {
 		return entityName;
 	}
 
 	public abstract boolean isMutable();
 	public abstract boolean hasIdentifierProperty();
 	public abstract Property getIdentifierProperty();
 	public abstract Property getDeclaredIdentifierProperty();
 	public abstract KeyValue getIdentifier();
 	public abstract Property getVersion();
 	public abstract Property getDeclaredVersion();
 	public abstract Value getDiscriminator();
 	public abstract boolean isInherited();
 	public abstract boolean isPolymorphic();
 	public abstract boolean isVersioned();
 	public abstract String getNaturalIdCacheRegionName();
 	public abstract String getCacheConcurrencyStrategy();
 	public abstract PersistentClass getSuperclass();
 	public abstract boolean isExplicitPolymorphism();
 	public abstract boolean isDiscriminatorInsertable();
 
 	public abstract Iterator getPropertyClosureIterator();
 	public abstract Iterator getTableClosureIterator();
 	public abstract Iterator getKeyClosureIterator();
 
 	protected void addSubclassProperty(Property prop) {
 		subclassProperties.add(prop);
 	}
 	protected void addSubclassJoin(Join join) {
 		subclassJoins.add(join);
 	}
 	protected void addSubclassTable(Table subclassTable) {
 		subclassTables.add(subclassTable);
 	}
 	public Iterator getSubclassPropertyClosureIterator() {
 		ArrayList iters = new ArrayList();
 		iters.add( getPropertyClosureIterator() );
 		iters.add( subclassProperties.iterator() );
 		for ( int i=0; i<subclassJoins.size(); i++ ) {
 			Join join = (Join) subclassJoins.get(i);
 			iters.add( join.getPropertyIterator() );
 		}
 		return new JoinedIterator(iters);
 	}
 	public Iterator getSubclassJoinClosureIterator() {
 		return new JoinedIterator( getJoinClosureIterator(), subclassJoins.iterator() );
 	}
 	public Iterator getSubclassTableClosureIterator() {
 		return new JoinedIterator( getTableClosureIterator(), subclassTables.iterator() );
 	}
 
 	public boolean isClassOrSuperclassJoin(Join join) {
 		return joins.contains(join);
 	}
 
 	public boolean isClassOrSuperclassTable(Table closureTable) {
 		return getTable()==closureTable;
 	}
 
 	public boolean isLazy() {
 		return lazy;
 	}
 
 	public void setLazy(boolean lazy) {
 		this.lazy = lazy;
 	}
 
 	public abstract boolean hasEmbeddedIdentifier();
 	public abstract Class getEntityPersisterClass();
 	public abstract void setEntityPersisterClass(Class classPersisterClass);
 	public abstract Table getRootTable();
 	public abstract RootClass getRootClass();
 	public abstract KeyValue getKey();
 
 	public void setDiscriminatorValue(String discriminatorValue) {
 		this.discriminatorValue = discriminatorValue;
 	}
 
 	public void setEntityName(String entityName) {
 		this.entityName = entityName==null ? null : entityName.intern();
 	}
 
 	public void createPrimaryKey() {
 		//Primary key constraint
 		PrimaryKey pk = new PrimaryKey();
 		Table table = getTable();
 		pk.setTable(table);
 		pk.setName( PK_ALIAS.toAliasString( table.getName() ) );
 		table.setPrimaryKey(pk);
 
 		pk.addColumns( getKey().getColumnIterator() );
 	}
 
 	public abstract String getWhere();
 
 	public int getBatchSize() {
 		return batchSize;
 	}
 
 	public void setBatchSize(int batchSize) {
 		this.batchSize = batchSize;
 	}
 
 	public boolean hasSelectBeforeUpdate() {
 		return selectBeforeUpdate;
 	}
 
 	public void setSelectBeforeUpdate(boolean selectBeforeUpdate) {
 		this.selectBeforeUpdate = selectBeforeUpdate;
 	}
 
 	/**
 	 * Build an iterator of properties which are "referenceable".
 	 *
 	 * @see #getReferencedProperty for a discussion of "referenceable"
 	 * @return The property iterator.
 	 */
 	public Iterator getReferenceablePropertyIterator() {
 		return getPropertyClosureIterator();
 	}
 
 	/**
 	 * Given a property path, locate the appropriate referenceable property reference.
 	 * <p/>
 	 * A referenceable property is a property  which can be a target of a foreign-key
 	 * mapping (an identifier or explcitly named in a property-ref).
 	 *
 	 * @param propertyPath The property path to resolve into a property reference.
 	 * @return The property reference (never null).
 	 * @throws MappingException If the property could not be found.
 	 */
 	public Property getReferencedProperty(String propertyPath) throws MappingException {
 		try {
 			return getRecursiveProperty( propertyPath, getReferenceablePropertyIterator() );
 		}
 		catch ( MappingException e ) {
 			throw new MappingException(
 					"property-ref [" + propertyPath + "] not found on entity [" + getEntityName() + "]", e
 			);
 		}
 	}
 
 	public Property getRecursiveProperty(String propertyPath) throws MappingException {
 		try {
 			return getRecursiveProperty( propertyPath, getPropertyIterator() );
 		}
 		catch ( MappingException e ) {
 			throw new MappingException(
 					"property [" + propertyPath + "] not found on entity [" + getEntityName() + "]", e
 			);
 		}
 	}
 
 	private Property getRecursiveProperty(String propertyPath, Iterator iter) throws MappingException {
 		Property property = null;
 		StringTokenizer st = new StringTokenizer( propertyPath, ".", false );
 		try {
 			while ( st.hasMoreElements() ) {
 				final String element = ( String ) st.nextElement();
 				if ( property == null ) {
 					Property identifierProperty = getIdentifierProperty();
 					if ( identifierProperty != null && identifierProperty.getName().equals( element ) ) {
 						// we have a mapped identifier property and the root of
 						// the incoming property path matched that identifier
 						// property
 						property = identifierProperty;
 					}
 					else if ( identifierProperty == null && getIdentifierMapper() != null ) {
 						// we have an embedded composite identifier
 						try {
 							identifierProperty = getProperty( element, getIdentifierMapper().getPropertyIterator() );
 							if ( identifierProperty != null ) {
 								// the root of the incoming property path matched one
 								// of the embedded composite identifier properties
 								property = identifierProperty;
 							}
 						}
 						catch( MappingException ignore ) {
 							// ignore it...
 						}
 					}
 
 					if ( property == null ) {
 						property = getProperty( element, iter );
 					}
 				}
 				else {
 					//flat recursive algorithm
 					property = ( ( Component ) property.getValue() ).getProperty( element );
 				}
 			}
 		}
 		catch ( MappingException e ) {
 			throw new MappingException( "property [" + propertyPath + "] not found on entity [" + getEntityName() + "]" );
 		}
 
 		return property;
 	}
 
 	private Property getProperty(String propertyName, Iterator iterator) throws MappingException {
 		if(iterator.hasNext()) {
 			String root = StringHelper.root(propertyName);
 			while ( iterator.hasNext() ) {
 				Property prop = (Property) iterator.next();
 				if ( prop.getName().equals( root ) ) {
 					return prop;
 				}
 			}
 		}
 		throw new MappingException( "property [" + propertyName + "] not found on entity [" + getEntityName() + "]" );
 	}
 
 	public Property getProperty(String propertyName) throws MappingException {
 		Iterator iter = getPropertyClosureIterator();
 		Property identifierProperty = getIdentifierProperty();
 		if ( identifierProperty != null
-				&& identifierProperty.getName().equals( StringHelper.root(propertyName) )
-				) {
+				&& identifierProperty.getName().equals( StringHelper.root(propertyName) ) ) {
 			return identifierProperty;
 		}
 		else {
 			return getProperty( propertyName, iter );
 		}
 	}
 
+	/**
+	 * @deprecated prefer {@link #getOptimisticLockStyle}
+	 */
 	@Deprecated
 	public int getOptimisticLockMode() {
 		return getOptimisticLockStyle().getOldCode();
 	}
 
+	/**
+	 * @deprecated prefer {@link #setOptimisticLockStyle}
+	 */
 	@Deprecated
 	public void setOptimisticLockMode(int optimisticLockMode) {
 		setOptimisticLockStyle( OptimisticLockStyle.interpretOldCode( optimisticLockMode ) );
 	}
 
 	public OptimisticLockStyle getOptimisticLockStyle() {
 		return optimisticLockStyle;
 	}
 
 	public void setOptimisticLockStyle(OptimisticLockStyle optimisticLockStyle) {
 		this.optimisticLockStyle = optimisticLockStyle;
 	}
 
 	public void validate(Mapping mapping) throws MappingException {
 		Iterator iter = getPropertyIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			if ( !prop.isValid(mapping) ) {
 				throw new MappingException(
 						"property mapping has wrong number of columns: " +
 						StringHelper.qualify( getEntityName(), prop.getName() ) +
 						" type: " +
 						prop.getType().getName()
-					);
+				);
 			}
 		}
 		checkPropertyDuplication();
 		checkColumnDuplication();
 	}
 	
 	private void checkPropertyDuplication() throws MappingException {
-		HashSet names = new HashSet();
+		HashSet<String> names = new HashSet<String>();
 		Iterator iter = getPropertyIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			if ( !names.add( prop.getName() ) ) {
 				throw new MappingException( "Duplicate property mapping of " + prop.getName() + " found in " + getEntityName());
 			}
 		}
 	}
 
 	public boolean isDiscriminatorValueNotNull() {
 		return NOT_NULL_DISCRIMINATOR_MAPPING.equals( getDiscriminatorValue() );
 	}
 	public boolean isDiscriminatorValueNull() {
 		return NULL_DISCRIMINATOR_MAPPING.equals( getDiscriminatorValue() );
 	}
 
 	public java.util.Map getMetaAttributes() {
 		return metaAttributes;
 	}
 
 	public void setMetaAttributes(java.util.Map metas) {
 		this.metaAttributes = metas;
 	}
 
 	public MetaAttribute getMetaAttribute(String name) {
 		return metaAttributes == null
 				? null
 				: (MetaAttribute) metaAttributes.get( name );
 	}
 
 	@Override
     public String toString() {
 		return getClass().getName() + '(' + getEntityName() + ')';
 	}
 	
 	public Iterator getJoinIterator() {
 		return joins.iterator();
 	}
 
 	public Iterator getJoinClosureIterator() {
 		return joins.iterator();
 	}
 
 	public void addJoin(Join join) {
 		joins.add(join);
 		join.setPersistentClass(this);
 	}
 
 	public int getJoinClosureSpan() {
 		return joins.size();
 	}
 
 	public int getPropertyClosureSpan() {
 		int span = properties.size();
-		for ( int i=0; i<joins.size(); i++ ) {
-			Join join = (Join) joins.get(i);
+		for ( Join join : joins ) {
 			span += join.getPropertySpan();
 		}
 		return span;
 	}
 
 	public int getJoinNumber(Property prop) {
 		int result=1;
 		Iterator iter = getSubclassJoinClosureIterator();
 		while ( iter.hasNext() ) {
 			Join join = (Join) iter.next();
-			if ( join.containsProperty(prop) ) return result;
+			if ( join.containsProperty(prop) ) {
+				return result;
+			}
 			result++;
 		}
 		return 0;
 	}
 
 	/**
 	 * Build an iterator over the properties defined on this class.  The returned
 	 * iterator only accounts for "normal" properties (i.e. non-identifier
 	 * properties).
 	 * <p/>
 	 * Differs from {@link #getUnjoinedPropertyIterator} in that the iterator
 	 * we return here will include properties defined as part of a join.
 	 *
 	 * @return An iterator over the "normal" properties.
 	 */
 	public Iterator getPropertyIterator() {
 		ArrayList iterators = new ArrayList();
 		iterators.add( properties.iterator() );
 		for ( int i = 0; i < joins.size(); i++ ) {
 			Join join = ( Join ) joins.get( i );
 			iterators.add( join.getPropertyIterator() );
 		}
 		return new JoinedIterator( iterators );
 	}
 
 	/**
 	 * Build an iterator over the properties defined on this class <b>which
 	 * are not defined as part of a join</b>.  As with {@link #getPropertyIterator},
 	 * the returned iterator only accounts for non-identifier properties.
 	 *
 	 * @return An iterator over the non-joined "normal" properties.
 	 */
 	public Iterator getUnjoinedPropertyIterator() {
 		return properties.iterator();
 	}
 
 	public void setCustomSQLInsert(String customSQLInsert, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLInsert = customSQLInsert;
 		this.customInsertCallable = callable;
 		this.insertCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLInsert() {
 		return customSQLInsert;
 	}
 
 	public boolean isCustomInsertCallable() {
 		return customInsertCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLInsertCheckStyle() {
 		return insertCheckStyle;
 	}
 
 	public void setCustomSQLUpdate(String customSQLUpdate, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLUpdate = customSQLUpdate;
 		this.customUpdateCallable = callable;
 		this.updateCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLUpdate() {
 		return customSQLUpdate;
 	}
 
 	public boolean isCustomUpdateCallable() {
 		return customUpdateCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLUpdateCheckStyle() {
 		return updateCheckStyle;
 	}
 
 	public void setCustomSQLDelete(String customSQLDelete, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLDelete = customSQLDelete;
 		this.customDeleteCallable = callable;
 		this.deleteCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLDelete() {
 		return customSQLDelete;
 	}
 
 	public boolean isCustomDeleteCallable() {
 		return customDeleteCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLDeleteCheckStyle() {
 		return deleteCheckStyle;
 	}
 
 	public void addFilter(String name, String condition, boolean autoAliasInjection, java.util.Map<String,String> aliasTableMap, java.util.Map<String,String> aliasEntityMap) {
 		filters.add(new FilterConfiguration(name, condition, autoAliasInjection, aliasTableMap, aliasEntityMap,  this));
 	}
 
 	public java.util.List getFilters() {
 		return filters;
 	}
 
 	public boolean isForceDiscriminator() {
 		return false;
 	}
 
 	public abstract boolean isJoinedSubclass();
 
 	public String getLoaderName() {
 		return loaderName;
 	}
 
 	public void setLoaderName(String loaderName) {
 		this.loaderName = loaderName==null ? null : loaderName.intern();
 	}
 
 	public abstract java.util.Set getSynchronizedTables();
 	
 	public void addSynchronizedTable(String table) {
 		synchronizedTables.add(table);
 	}
 
 	public Boolean isAbstract() {
 		return isAbstract;
 	}
 
 	public void setAbstract(Boolean isAbstract) {
 		this.isAbstract = isAbstract;
 	}
 
 	protected void checkColumnDuplication(Set distinctColumns, Iterator columns) 
 	throws MappingException {
 		while ( columns.hasNext() ) {
 			Selectable columnOrFormula = (Selectable) columns.next();
 			if ( !columnOrFormula.isFormula() ) {
 				Column col = (Column) columnOrFormula;
 				if ( !distinctColumns.add( col.getName() ) ) {
 					throw new MappingException( 
 							"Repeated column in mapping for entity: " +
 							getEntityName() +
 							" column: " +
 							col.getName() + 
 							" (should be mapped with insert=\"false\" update=\"false\")"
 						);
 				}
 			}
 		}
 	}
 	
 	protected void checkPropertyColumnDuplication(Set distinctColumns, Iterator properties) 
 	throws MappingException {
 		while ( properties.hasNext() ) {
 			Property prop = (Property) properties.next();
 			if ( prop.getValue() instanceof Component ) { //TODO: remove use of instanceof!
 				Component component = (Component) prop.getValue();
 				checkPropertyColumnDuplication( distinctColumns, component.getPropertyIterator() );
 			}
 			else {
 				if ( prop.isUpdateable() || prop.isInsertable() ) {
 					checkColumnDuplication( distinctColumns, prop.getColumnIterator() );
 				}
 			}
 		}
 	}
 	
 	protected Iterator getNonDuplicatedPropertyIterator() {
 		return getUnjoinedPropertyIterator();
 	}
 	
 	protected Iterator getDiscriminatorColumnIterator() {
 		return EmptyIterator.INSTANCE;
 	}
 	
 	protected void checkColumnDuplication() {
 		HashSet cols = new HashSet();
 		if (getIdentifierMapper() == null ) {
 			//an identifier mapper => getKey will be included in the getNonDuplicatedPropertyIterator()
 			//and checked later, so it needs to be excluded
 			checkColumnDuplication( cols, getKey().getColumnIterator() );
 		}
 		checkColumnDuplication( cols, getDiscriminatorColumnIterator() );
 		checkPropertyColumnDuplication( cols, getNonDuplicatedPropertyIterator() );
 		Iterator iter = getJoinIterator();
 		while ( iter.hasNext() ) {
 			cols.clear();
 			Join join = (Join) iter.next();
 			checkColumnDuplication( cols, join.getKey().getColumnIterator() );
 			checkPropertyColumnDuplication( cols, join.getPropertyIterator() );
 		}
 	}
 	
 	public abstract Object accept(PersistentClassVisitor mv);
 	
 	public String getNodeName() {
 		return nodeName;
 	}
 	
 	public void setNodeName(String nodeName) {
 		this.nodeName = nodeName;
 	}
 
 	public String getJpaEntityName() {
 		return jpaEntityName;
 	}
 	
 	public void setJpaEntityName(String jpaEntityName) {
 		this.jpaEntityName = jpaEntityName;
 	}
 	
 	public boolean hasPojoRepresentation() {
 		return getClassName()!=null;
 	}
 
 	public boolean hasDom4jRepresentation() {
 		return getNodeName()!=null;
 	}
 
 	public boolean hasSubselectLoadableCollections() {
 		return hasSubselectLoadableCollections;
 	}
 	
 	public void setSubselectLoadableCollections(boolean hasSubselectCollections) {
 		this.hasSubselectLoadableCollections = hasSubselectCollections;
 	}
 
 	public Component getIdentifierMapper() {
 		return identifierMapper;
 	}
 
 	public Component getDeclaredIdentifierMapper() {
 		return declaredIdentifierMapper;
 	}
 
 	public void setDeclaredIdentifierMapper(Component declaredIdentifierMapper) {
 		this.declaredIdentifierMapper = declaredIdentifierMapper;
 	}
 
 	public boolean hasIdentifierMapper() {
 		return identifierMapper != null;
 	}
 
 	public void setIdentifierMapper(Component handle) {
 		this.identifierMapper = handle;
 	}
 
 	public void addTuplizer(EntityMode entityMode, String implClassName) {
 		if ( tuplizerImpls == null ) {
 			tuplizerImpls = new HashMap();
 		}
 		tuplizerImpls.put( entityMode, implClassName );
 	}
 
 	public String getTuplizerImplClassName(EntityMode mode) {
 		if ( tuplizerImpls == null ) return null;
 		return ( String ) tuplizerImpls.get( mode );
 	}
 
 	public java.util.Map getTuplizerMap() {
 		if ( tuplizerImpls == null ) {
 			return null;
 		}
 		return java.util.Collections.unmodifiableMap( tuplizerImpls );
 	}
 
 	public boolean hasNaturalId() {
 		Iterator props = getRootClass().getPropertyIterator();
 		while ( props.hasNext() ) {
 			if ( ( (Property) props.next() ).isNaturalIdentifier() ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	public abstract boolean isLazyPropertiesCacheable();
 
 	// The following methods are added to support @MappedSuperclass in the metamodel
 	public Iterator getDeclaredPropertyIterator() {
 		ArrayList iterators = new ArrayList();
 		iterators.add( declaredProperties.iterator() );
 		for ( int i = 0; i < joins.size(); i++ ) {
 			Join join = ( Join ) joins.get( i );
 			iterators.add( join.getDeclaredPropertyIterator() );
 		}
 		return new JoinedIterator( iterators );
 	}
 
 	public void addMappedsuperclassProperty(Property p) {
 		properties.add(p);
 		p.setPersistentClass(this);
 	}
 
 	public MappedSuperclass getSuperMappedSuperclass() {
 		return superMappedSuperclass;
 	}
 
 	public void setSuperMappedSuperclass(MappedSuperclass superMappedSuperclass) {
 		this.superMappedSuperclass = superMappedSuperclass;
 	}
 
 	// End of @Mappedsuperclass support
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/PrimaryKey.java b/hibernate-core/src/main/java/org/hibernate/mapping/PrimaryKey.java
index ce441fa9dc..eab2be5596 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/PrimaryKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/PrimaryKey.java
@@ -1,66 +1,70 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 import java.util.Iterator;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A primary key constraint
  * @author Gavin King
  */
 public class PrimaryKey extends Constraint {
 
 	public String sqlConstraintString(Dialect dialect) {
 		StringBuilder buf = new StringBuilder("primary key (");
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			buf.append( ( (Column) iter.next() ).getQuotedName(dialect) );
-			if ( iter.hasNext() ) buf.append(", ");
+			if ( iter.hasNext() ) {
+				buf.append(", ");
+			}
 		}
 		return buf.append(')').toString();
 	}
 
 	public String sqlConstraintString(Dialect dialect, String constraintName, String defaultCatalog, String defaultSchema) {
 		StringBuilder buf = new StringBuilder(
 			dialect.getAddPrimaryKeyConstraintString(constraintName)
 		).append('(');
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			buf.append( ( (Column) iter.next() ).getQuotedName(dialect) );
-			if ( iter.hasNext() ) buf.append(", ");
+			if ( iter.hasNext() ) {
+				buf.append(", ");
+			}
 		}
 		return buf.append(')').toString();
 	}
 	
 	public String generatedConstraintNamePrefix() {
 		return "PK_";
 	}
 
 	@Override
 	public String getExportIdentifier() {
 		return StringHelper.qualify( getTable().getName(), "PK-" + getName() );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java b/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
index 3d463fa0f6..8478a005ef 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
@@ -1,371 +1,374 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.SingletonIterator;
 
 import org.jboss.logging.Logger;
 
 /**
  * The root class of an inheritance hierarchy
  * @author Gavin King
  */
 public class RootClass extends PersistentClass implements TableOwner {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, RootClass.class.getName());
 
 	public static final String DEFAULT_IDENTIFIER_COLUMN_NAME = "id";
 	public static final String DEFAULT_DISCRIMINATOR_COLUMN_NAME = "class";
 
 	private Property identifierProperty;
 	private KeyValue identifier;
 	private Property version;
 	private boolean polymorphic;
 	private String cacheConcurrencyStrategy;
 	private String cacheRegionName;
 	private String naturalIdCacheRegionName;
 	private boolean lazyPropertiesCacheable = true;
 	private Value discriminator;
 	private boolean mutable = true;
 	private boolean embeddedIdentifier;
 	private boolean explicitPolymorphism;
 	private Class entityPersisterClass;
 	private boolean forceDiscriminator;
 	private String where;
 	private Table table;
 	private boolean discriminatorInsertable = true;
 	private int nextSubclassId;
 	private Property declaredIdentifierProperty;
 	private Property declaredVersion;
 	private boolean cachingExplicitlyRequested;
 
 	@Override
     int nextSubclassId() {
 		return ++nextSubclassId;
 	}
 
 	@Override
     public int getSubclassId() {
 		return 0;
 	}
 
 	public void setTable(Table table) {
 		this.table=table;
 	}
 	@Override
     public Table getTable() {
 		return table;
 	}
 
 	@Override
     public Property getIdentifierProperty() {
 		return identifierProperty;
 	}
 
 	@Override
     public Property getDeclaredIdentifierProperty() {
 		return declaredIdentifierProperty;
 	}
 
 	public void setDeclaredIdentifierProperty(Property declaredIdentifierProperty) {
 		this.declaredIdentifierProperty = declaredIdentifierProperty;
 	}
 
 	@Override
     public KeyValue getIdentifier() {
 		return identifier;
 	}
 	@Override
     public boolean hasIdentifierProperty() {
 		return identifierProperty!=null;
 	}
 
 	@Override
     public Value getDiscriminator() {
 		return discriminator;
 	}
 
 	@Override
     public boolean isInherited() {
 		return false;
 	}
 	@Override
     public boolean isPolymorphic() {
 		return polymorphic;
 	}
 
 	public void setPolymorphic(boolean polymorphic) {
 		this.polymorphic = polymorphic;
 	}
 
 	@Override
     public RootClass getRootClass() {
 		return this;
 	}
 
 	@Override
     public Iterator getPropertyClosureIterator() {
 		return getPropertyIterator();
 	}
 	@Override
     public Iterator getTableClosureIterator() {
 		return new SingletonIterator( getTable() );
 	}
 	@Override
     public Iterator getKeyClosureIterator() {
 		return new SingletonIterator( getKey() );
 	}
 
 	@Override
     public void addSubclass(Subclass subclass) throws MappingException {
 		super.addSubclass(subclass);
 		setPolymorphic(true);
 	}
 
 	@Override
     public boolean isExplicitPolymorphism() {
 		return explicitPolymorphism;
 	}
 
 	@Override
     public Property getVersion() {
 		return version;
 	}
 
 	@Override
     public Property getDeclaredVersion() {
 		return declaredVersion;
 	}
 
 	public void setDeclaredVersion(Property declaredVersion) {
 		this.declaredVersion = declaredVersion;
 	}
 
 	public void setVersion(Property version) {
 		this.version = version;
 	}
 	@Override
     public boolean isVersioned() {
 		return version!=null;
 	}
 
 	@Override
     public boolean isMutable() {
 		return mutable;
 	}
 	@Override
     public boolean hasEmbeddedIdentifier() {
 		return embeddedIdentifier;
 	}
 
 	@Override
     public Class getEntityPersisterClass() {
 		return entityPersisterClass;
 	}
 
 	@Override
     public Table getRootTable() {
 		return getTable();
 	}
 
 	@Override
     public void setEntityPersisterClass(Class persister) {
 		this.entityPersisterClass = persister;
 	}
 
 	@Override
     public PersistentClass getSuperclass() {
 		return null;
 	}
 
 	@Override
     public KeyValue getKey() {
 		return getIdentifier();
 	}
 
 	public void setDiscriminator(Value discriminator) {
 		this.discriminator = discriminator;
 	}
 
 	public void setEmbeddedIdentifier(boolean embeddedIdentifier) {
 		this.embeddedIdentifier = embeddedIdentifier;
 	}
 
 	public void setExplicitPolymorphism(boolean explicitPolymorphism) {
 		this.explicitPolymorphism = explicitPolymorphism;
 	}
 
 	public void setIdentifier(KeyValue identifier) {
 		this.identifier = identifier;
 	}
 
 	public void setIdentifierProperty(Property identifierProperty) {
 		this.identifierProperty = identifierProperty;
 		identifierProperty.setPersistentClass(this);
 
 	}
 
 	public void setMutable(boolean mutable) {
 		this.mutable = mutable;
 	}
 
 	@Override
     public boolean isDiscriminatorInsertable() {
 		return discriminatorInsertable;
 	}
 
 	public void setDiscriminatorInsertable(boolean insertable) {
 		this.discriminatorInsertable = insertable;
 	}
 
 	@Override
     public boolean isForceDiscriminator() {
 		return forceDiscriminator;
 	}
 
 	public void setForceDiscriminator(boolean forceDiscriminator) {
 		this.forceDiscriminator = forceDiscriminator;
 	}
 
 	@Override
     public String getWhere() {
 		return where;
 	}
 
 	public void setWhere(String string) {
 		where = string;
 	}
 
 	@Override
     public void validate(Mapping mapping) throws MappingException {
 		super.validate(mapping);
 		if ( !getIdentifier().isValid(mapping) ) {
 			throw new MappingException(
 				"identifier mapping has wrong number of columns: " +
 				getEntityName() +
 				" type: " +
 				getIdentifier().getType().getName()
 			);
 		}
 		checkCompositeIdentifier();
 	}
 
 	private void checkCompositeIdentifier() {
 		if ( getIdentifier() instanceof Component ) {
 			Component id = (Component) getIdentifier();
 			if ( !id.isDynamic() ) {
 				final Class idClass = id.getComponentClass();
 				if ( idClass != null ) {
 					final String idComponentClassName = idClass.getName();
 					if ( !ReflectHelper.overridesEquals( idClass ) ) {
 						LOG.compositeIdClassDoesNotOverrideEquals( idComponentClassName );
 					}
 					if ( !ReflectHelper.overridesHashCode( idClass ) ) {
 						LOG.compositeIdClassDoesNotOverrideHashCode( idComponentClassName );
 					}
 					if ( !Serializable.class.isAssignableFrom( idClass ) ) {
 						throw new MappingException(
 								"Composite-id class must implement Serializable: " + idComponentClassName
 						);
 					}
 				}
 			}
 		}
 	}
 
 	@Override
     public String getCacheConcurrencyStrategy() {
 		return cacheConcurrencyStrategy;
 	}
 
 	public void setCacheConcurrencyStrategy(String cacheConcurrencyStrategy) {
 		this.cacheConcurrencyStrategy = cacheConcurrencyStrategy;
 	}
 
 	public String getCacheRegionName() {
 		return cacheRegionName==null ? getEntityName() : cacheRegionName;
 	}
 	public void setCacheRegionName(String cacheRegionName) {
 		this.cacheRegionName = cacheRegionName;
 	}
 	
 	@Override
 	public String getNaturalIdCacheRegionName() {
 		return naturalIdCacheRegionName;
 	}
 	public void setNaturalIdCacheRegionName(String naturalIdCacheRegionName) {
 		this.naturalIdCacheRegionName = naturalIdCacheRegionName;
 	}
 	
 	@Override
     public boolean isLazyPropertiesCacheable() {
 		return lazyPropertiesCacheable;
 	}
 
 	public void setLazyPropertiesCacheable(boolean lazyPropertiesCacheable) {
 		this.lazyPropertiesCacheable = lazyPropertiesCacheable;
 	}
 
 	@Override
     public boolean isJoinedSubclass() {
 		return false;
 	}
 
 	@Override
     public java.util.Set getSynchronizedTables() {
 		return synchronizedTables;
 	}
 
-	public Set getIdentityTables() {
-		Set tables = new HashSet();
+	@SuppressWarnings("UnnecessaryUnboxing")
+	public Set<Table> getIdentityTables() {
+		Set<Table> tables = new HashSet<Table>();
 		Iterator iter = getSubclassClosureIterator();
 		while ( iter.hasNext() ) {
 			PersistentClass clazz = (PersistentClass) iter.next();
-			if ( clazz.isAbstract() == null || !clazz.isAbstract().booleanValue() ) tables.add( clazz.getIdentityTable() );
+			if ( clazz.isAbstract() == null || !clazz.isAbstract().booleanValue() ) {
+				tables.add( clazz.getIdentityTable() );
+			}
 		}
 		return tables;
 	}
 
 	@Override
     public Object accept(PersistentClassVisitor mv) {
 		return mv.accept(this);
 	}
 
 	public void setCachingExplicitlyRequested(boolean explicitlyRequested) {
 		this.cachingExplicitlyRequested = explicitlyRequested;
 	}
 
 	public boolean isCachingExplicitlyRequested() {
 		return cachingExplicitlyRequested;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/SimpleValue.java b/hibernate-core/src/main/java/org/hibernate/mapping/SimpleValue.java
index 2577ae23f6..dbbb8714ff 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/SimpleValue.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/SimpleValue.java
@@ -1,644 +1,648 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.lang.annotation.Annotation;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Properties;
 import javax.persistence.AttributeConverter;
 
 import org.hibernate.FetchMode;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.cfg.AttributeConverterDefinition;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.config.spi.StandardConverters;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.Type;
 import org.hibernate.type.descriptor.converter.AttributeConverterSqlTypeDescriptorAdapter;
 import org.hibernate.type.descriptor.converter.AttributeConverterTypeAdapter;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptorRegistry;
 import org.hibernate.type.descriptor.sql.JdbcTypeJavaClassMappings;
 import org.hibernate.type.descriptor.sql.NationalizedTypeMappings;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptorRegistry;
 import org.hibernate.usertype.DynamicParameterizedType;
 
 /**
  * Any value that maps to columns.
  * @author Gavin King
  */
 public class SimpleValue implements KeyValue {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( SimpleValue.class );
 
 	public static final String DEFAULT_ID_GEN_STRATEGY = "assigned";
 
 	private final MetadataImplementor metadata;
 
 	private final List<Selectable> columns = new ArrayList<Selectable>();
 
 	private String typeName;
 	private Properties typeParameters;
 	private boolean isNationalized;
 
 	private Properties identifierGeneratorProperties;
 	private String identifierGeneratorStrategy = DEFAULT_ID_GEN_STRATEGY;
 	private String nullValue;
 	private Table table;
 	private String foreignKeyName;
 	private boolean alternateUniqueKey;
 	private boolean cascadeDeleteEnabled;
 
 	private AttributeConverterDefinition attributeConverterDefinition;
 	private Type type;
 
 	public SimpleValue(MetadataImplementor metadata) {
 		this.metadata = metadata;
 	}
 
 	public SimpleValue(MetadataImplementor metadata, Table table) {
 		this( metadata );
 		this.table = table;
 	}
 
 	public MetadataImplementor getMetadata() {
 		return metadata;
 	}
 
 	@Override
 	public boolean isCascadeDeleteEnabled() {
 		return cascadeDeleteEnabled;
 	}
 
 	public void setCascadeDeleteEnabled(boolean cascadeDeleteEnabled) {
 		this.cascadeDeleteEnabled = cascadeDeleteEnabled;
 	}
 	
 	public void addColumn(Column column) {
-		if ( !columns.contains(column) ) columns.add(column);
+		if ( !columns.contains(column) ) {
+			columns.add(column);
+		}
 		column.setValue(this);
 		column.setTypeIndex( columns.size()-1 );
 	}
 	
 	public void addFormula(Formula formula) {
 		columns.add(formula);
 	}
 
 	@Override
 	public boolean hasFormula() {
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			Object o = iter.next();
-			if (o instanceof Formula) return true;
+			if (o instanceof Formula) {
+				return true;
+			}
 		}
 		return false;
 	}
 
 	@Override
 	public int getColumnSpan() {
 		return columns.size();
 	}
 
 	@Override
 	public Iterator<Selectable> getColumnIterator() {
 		return columns.iterator();
 	}
 
 	public List getConstraintColumns() {
 		return columns;
 	}
 
 	public String getTypeName() {
 		return typeName;
 	}
 
 	public void setTypeName(String typeName) {
 		if ( typeName != null && typeName.startsWith( AttributeConverterTypeAdapter.NAME_PREFIX ) ) {
 			final String converterClassName = typeName.substring( AttributeConverterTypeAdapter.NAME_PREFIX.length() );
 			final ClassLoaderService cls = getMetadata().getMetadataBuildingOptions()
 					.getServiceRegistry()
 					.getService( ClassLoaderService.class );
 			try {
 				final Class<AttributeConverter> converterClass = cls.classForName( converterClassName );
 				attributeConverterDefinition = new AttributeConverterDefinition( converterClass.newInstance(), false );
 				return;
 			}
 			catch (Exception e) {
 				log.logBadHbmAttributeConverterType( typeName, e.getMessage() );
 			}
 		}
 
 		this.typeName = typeName;
 	}
 
 	public void makeNationalized() {
 		this.isNationalized = true;
 	}
 
 	public boolean isNationalized() {
 		return isNationalized;
 	}
 
 	public void setTable(Table table) {
 		this.table = table;
 	}
 
 	@Override
 	public void createForeignKey() throws MappingException {}
 
 	@Override
 	public void createForeignKeyOfEntity(String entityName) {
 		if ( !hasFormula() && !"none".equals(getForeignKeyName())) {
 			ForeignKey fk = table.createForeignKey( getForeignKeyName(), getConstraintColumns(), entityName );
 			fk.setCascadeDeleteEnabled(cascadeDeleteEnabled);
 		}
 	}
 
 	@Override
 	public IdentifierGenerator createIdentifierGenerator(
 			IdentifierGeneratorFactory identifierGeneratorFactory,
 			Dialect dialect, 
 			String defaultCatalog, 
 			String defaultSchema, 
 			RootClass rootClass) throws MappingException {
 		
 		Properties params = new Properties();
 		
 		//if the hibernate-mapping did not specify a schema/catalog, use the defaults
 		//specified by properties - but note that if the schema/catalog were specified
 		//in hibernate-mapping, or as params, they will already be initialized and
 		//will override the values set here (they are in identifierGeneratorProperties)
 		if ( defaultSchema!=null ) {
 			params.setProperty(PersistentIdentifierGenerator.SCHEMA, defaultSchema);
 		}
 		if ( defaultCatalog!=null ) {
 			params.setProperty(PersistentIdentifierGenerator.CATALOG, defaultCatalog);
 		}
 		
 		//pass the entity-name, if not a collection-id
 		if (rootClass!=null) {
 			params.setProperty( IdentifierGenerator.ENTITY_NAME, rootClass.getEntityName() );
 			params.setProperty( IdentifierGenerator.JPA_ENTITY_NAME, rootClass.getJpaEntityName() );
 		}
 		
 		//init the table here instead of earlier, so that we can get a quoted table name
 		//TODO: would it be better to simply pass the qualified table name, instead of
 		//      splitting it up into schema/catalog/table names
 		String tableName = getTable().getQuotedName(dialect);
 		params.setProperty( PersistentIdentifierGenerator.TABLE, tableName );
 		
 		//pass the column name (a generated id almost always has a single column)
 		String columnName = ( (Column) getColumnIterator().next() ).getQuotedName(dialect);
 		params.setProperty( PersistentIdentifierGenerator.PK, columnName );
 		
 		if (rootClass!=null) {
 			StringBuilder tables = new StringBuilder();
 			Iterator iter = rootClass.getIdentityTables().iterator();
 			while ( iter.hasNext() ) {
 				Table table= (Table) iter.next();
 				tables.append( table.getQuotedName(dialect) );
 				if ( iter.hasNext() ) tables.append(", ");
 			}
 			params.setProperty( PersistentIdentifierGenerator.TABLES, tables.toString() );
 		}
 		else {
 			params.setProperty( PersistentIdentifierGenerator.TABLES, tableName );
 		}
 
 		if (identifierGeneratorProperties!=null) {
 			params.putAll(identifierGeneratorProperties);
 		}
 
 		// TODO : we should pass along all settings once "config lifecycle" is hashed out...
 		final ConfigurationService cs = metadata.getMetadataBuildingOptions().getServiceRegistry()
 				.getService( ConfigurationService.class );
 
 		params.put(
 				AvailableSettings.PREFER_POOLED_VALUES_LO,
 				cs.getSetting( AvailableSettings.PREFER_POOLED_VALUES_LO, StandardConverters.BOOLEAN, false )
 		);
 
 		identifierGeneratorFactory.setDialect( dialect );
 		return identifierGeneratorFactory.createIdentifierGenerator( identifierGeneratorStrategy, getType(), params );
 	}
 
 	public boolean isUpdateable() {
 		//needed to satisfy KeyValue
 		return true;
 	}
 	
 	public FetchMode getFetchMode() {
 		return FetchMode.SELECT;
 	}
 
 	public Properties getIdentifierGeneratorProperties() {
 		return identifierGeneratorProperties;
 	}
 
 	public String getNullValue() {
 		return nullValue;
 	}
 
 	public Table getTable() {
 		return table;
 	}
 
 	/**
 	 * Returns the identifierGeneratorStrategy.
 	 * @return String
 	 */
 	public String getIdentifierGeneratorStrategy() {
 		return identifierGeneratorStrategy;
 	}
 	
 	public boolean isIdentityColumn(IdentifierGeneratorFactory identifierGeneratorFactory, Dialect dialect) {
 		identifierGeneratorFactory.setDialect( dialect );
 		return identifierGeneratorFactory.getIdentifierGeneratorClass( identifierGeneratorStrategy )
 				.equals( IdentityGenerator.class );
 	}
 
 	/**
 	 * Sets the identifierGeneratorProperties.
 	 * @param identifierGeneratorProperties The identifierGeneratorProperties to set
 	 */
 	public void setIdentifierGeneratorProperties(Properties identifierGeneratorProperties) {
 		this.identifierGeneratorProperties = identifierGeneratorProperties;
 	}
 
 	/**
 	 * Sets the identifierGeneratorStrategy.
 	 * @param identifierGeneratorStrategy The identifierGeneratorStrategy to set
 	 */
 	public void setIdentifierGeneratorStrategy(String identifierGeneratorStrategy) {
 		this.identifierGeneratorStrategy = identifierGeneratorStrategy;
 	}
 
 	/**
 	 * Sets the nullValue.
 	 * @param nullValue The nullValue to set
 	 */
 	public void setNullValue(String nullValue) {
 		this.nullValue = nullValue;
 	}
 
 	public String getForeignKeyName() {
 		return foreignKeyName;
 	}
 
 	public void setForeignKeyName(String foreignKeyName) {
 		this.foreignKeyName = foreignKeyName;
 	}
 
 	public boolean isAlternateUniqueKey() {
 		return alternateUniqueKey;
 	}
 
 	public void setAlternateUniqueKey(boolean unique) {
 		this.alternateUniqueKey = unique;
 	}
 
 	public boolean isNullable() {
 		Iterator itr = getColumnIterator();
 		while ( itr.hasNext() ) {
 			final Object selectable = itr.next();
 			if ( selectable instanceof Formula ) {
 				// if there are *any* formulas, then the Value overall is
 				// considered nullable
 				return true;
 			}
 			else if ( !( (Column) selectable ).isNullable() ) {
 				// if there is a single non-nullable column, the Value
 				// overall is considered non-nullable.
 				return false;
 			}
 		}
 		// nullable by default
 		return true;
 	}
 
 	public boolean isSimpleValue() {
 		return true;
 	}
 
 	public boolean isValid(Mapping mapping) throws MappingException {
 		return getColumnSpan()==getType().getColumnSpan(mapping);
 	}
 
 	public Type getType() throws MappingException {
 		if ( type != null ) {
 			return type;
 		}
 
 		if ( typeName == null ) {
 			throw new MappingException( "No type name" );
 		}
 
 		if ( typeParameters != null
 				&& Boolean.valueOf( typeParameters.getProperty( DynamicParameterizedType.IS_DYNAMIC ) )
 				&& typeParameters.get( DynamicParameterizedType.PARAMETER_TYPE ) == null ) {
 			createParameterImpl();
 		}
 
 		Type result = metadata.getTypeResolver().heuristicType( typeName, typeParameters );
 		if ( result == null ) {
 			String msg = "Could not determine type for: " + typeName;
 			if ( table != null ) {
 				msg += ", at table: " + table.getName();
 			}
 			if ( columns != null && columns.size() > 0 ) {
 				msg += ", for columns: " + columns;
 			}
 			throw new MappingException( msg );
 		}
 
 		return result;
 	}
 
 	public void setTypeUsingReflection(String className, String propertyName) throws MappingException {
 		// NOTE : this is called as the last piece in setting SimpleValue type information, and implementations
 		// rely on that fact, using it as a signal that all information it is going to get is defined at this point...
 
 		if ( typeName != null ) {
 			// assume either (a) explicit type was specified or (b) determine was already performed
 			return;
 		}
 
 		if ( type != null ) {
 			return;
 		}
 
 		if ( attributeConverterDefinition == null ) {
 			// this is here to work like legacy.  This should change when we integrate with metamodel to
 			// look for SqlTypeDescriptor and JavaTypeDescriptor individually and create the BasicType (well, really
 			// keep a registry of [SqlTypeDescriptor,JavaTypeDescriptor] -> BasicType...)
 			if ( className == null ) {
 				throw new MappingException( "Attribute types for a dynamic entity must be explicitly specified: " + propertyName );
 			}
 			typeName = ReflectHelper.reflectedPropertyClass( className, propertyName ).getName();
 			// todo : to fully support isNationalized here we need do the process hinted at above
 			// 		essentially, much of the logic from #buildAttributeConverterTypeAdapter wrt resolving
 			//		a (1) SqlTypeDescriptor, a (2) JavaTypeDescriptor and dynamically building a BasicType
 			// 		combining them.
 			return;
 		}
 
 		// we had an AttributeConverter...
 		type = buildAttributeConverterTypeAdapter();
 	}
 
 	/**
 	 * Build a Hibernate Type that incorporates the JPA AttributeConverter.  AttributeConverter works totally in
 	 * memory, meaning it converts between one Java representation (the entity attribute representation) and another
 	 * (the value bound into JDBC statements or extracted from results).  However, the Hibernate Type system operates
 	 * at the lower level of actually dealing directly with those JDBC objects.  So even though we have an
 	 * AttributeConverter, we still need to "fill out" the rest of the BasicType data and bridge calls
 	 * to bind/extract through the converter.
 	 * <p/>
 	 * Essentially the idea here is that an intermediate Java type needs to be used.  Let's use an example as a means
 	 * to illustrate...  Consider an {@code AttributeConverter<Integer,String>}.  This tells Hibernate that the domain
 	 * model defines this attribute as an Integer value (the 'entityAttributeJavaType'), but that we need to treat the
 	 * value as a String (the 'databaseColumnJavaType') when dealing with JDBC (aka, the database type is a
 	 * VARCHAR/CHAR):<ul>
 	 *     <li>
 	 *         When binding values to PreparedStatements we need to convert the Integer value from the entity
 	 *         into a String and pass that String to setString.  The conversion is handled by calling
 	 *         {@link AttributeConverter#convertToDatabaseColumn(Object)}
 	 *     </li>
 	 *     <li>
 	 *         When extracting values from ResultSets (or CallableStatement parameters) we need to handle the
 	 *         value via getString, and convert that returned String to an Integer.  That conversion is handled
 	 *         by calling {@link AttributeConverter#convertToEntityAttribute(Object)}
 	 *     </li>
 	 * </ul>
 	 *
 	 * @return The built AttributeConverter -> Type adapter
 	 *
 	 * @todo : ultimately I want to see attributeConverterJavaType and attributeConverterJdbcTypeCode specify-able separately
 	 * then we can "play them against each other" in terms of determining proper typing
 	 *
 	 * @todo : see if we already have previously built a custom on-the-fly BasicType for this AttributeConverter; see note below about caching
 	 */
 	@SuppressWarnings("unchecked")
 	private Type buildAttributeConverterTypeAdapter() {
 		// todo : validate the number of columns present here?
 
 		final Class entityAttributeJavaType = attributeConverterDefinition.getEntityAttributeType();
 		final Class databaseColumnJavaType = attributeConverterDefinition.getDatabaseColumnType();
 
 
 		// resolve the JavaTypeDescriptor ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// For the JavaTypeDescriptor portion we simply resolve the "entity attribute representation" part of
 		// the AttributeConverter to resolve the corresponding descriptor.
 		final JavaTypeDescriptor entityAttributeJavaTypeDescriptor = JavaTypeDescriptorRegistry.INSTANCE.getDescriptor( entityAttributeJavaType );
 
 
 		// build the SqlTypeDescriptor adapter ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Going back to the illustration, this should be a SqlTypeDescriptor that handles the Integer <-> String
 		//		conversions.  This is the more complicated piece.  First we need to determine the JDBC type code
 		//		corresponding to the AttributeConverter's declared "databaseColumnJavaType" (how we read that value out
 		// 		of ResultSets).  See JdbcTypeJavaClassMappings for details.  Again, given example, this should return
 		// 		VARCHAR/CHAR
 		int jdbcTypeCode = JdbcTypeJavaClassMappings.INSTANCE.determineJdbcTypeCodeForJavaClass( databaseColumnJavaType );
 		if ( isNationalized() ) {
 			jdbcTypeCode = NationalizedTypeMappings.INSTANCE.getCorrespondingNationalizedCode( jdbcTypeCode );
 		}
 		// find the standard SqlTypeDescriptor for that JDBC type code.
 		final SqlTypeDescriptor sqlTypeDescriptor = SqlTypeDescriptorRegistry.INSTANCE.getDescriptor( jdbcTypeCode );
 		// find the JavaTypeDescriptor representing the "intermediate database type representation".  Back to the
 		// 		illustration, this should be the type descriptor for Strings
 		final JavaTypeDescriptor intermediateJavaTypeDescriptor = JavaTypeDescriptorRegistry.INSTANCE.getDescriptor( databaseColumnJavaType );
 		// and finally construct the adapter, which injects the AttributeConverter calls into the binding/extraction
 		// 		process...
 		final SqlTypeDescriptor sqlTypeDescriptorAdapter = new AttributeConverterSqlTypeDescriptorAdapter(
 				attributeConverterDefinition.getAttributeConverter(),
 				sqlTypeDescriptor,
 				intermediateJavaTypeDescriptor
 		);
 
 		// todo : cache the AttributeConverterTypeAdapter in case that AttributeConverter is applied multiple times.
 
 		final String name = AttributeConverterTypeAdapter.NAME_PREFIX + attributeConverterDefinition.getAttributeConverter().getClass().getName();
 		final String description = String.format(
 				"BasicType adapter for AttributeConverter<%s,%s>",
 				entityAttributeJavaType.getSimpleName(),
 				databaseColumnJavaType.getSimpleName()
 		);
 		return new AttributeConverterTypeAdapter(
 				name,
 				description,
 				attributeConverterDefinition.getAttributeConverter(),
 				sqlTypeDescriptorAdapter,
 				entityAttributeJavaType,
 				databaseColumnJavaType,
 				entityAttributeJavaTypeDescriptor
 		);
 	}
 
 	public boolean isTypeSpecified() {
 		return typeName!=null;
 	}
 
 	public void setTypeParameters(Properties parameterMap) {
 		this.typeParameters = parameterMap;
 	}
 	
 	public Properties getTypeParameters() {
 		return typeParameters;
 	}
 
 	@Override
     public String toString() {
 		return getClass().getName() + '(' + columns.toString() + ')';
 	}
 
 	public Object accept(ValueVisitor visitor) {
 		return visitor.accept(this);
 	}
 	
 	public boolean[] getColumnInsertability() {
 		boolean[] result = new boolean[ getColumnSpan() ];
 		int i = 0;
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			Selectable s = (Selectable) iter.next();
 			result[i++] = !s.isFormula();
 		}
 		return result;
 	}
 	
 	public boolean[] getColumnUpdateability() {
 		return getColumnInsertability();
 	}
 
 	public void setJpaAttributeConverterDefinition(AttributeConverterDefinition attributeConverterDefinition) {
 		this.attributeConverterDefinition = attributeConverterDefinition;
 	}
 
 	private void createParameterImpl() {
 		try {
 			String[] columnsNames = new String[columns.size()];
 			for ( int i = 0; i < columns.size(); i++ ) {
 				Selectable column = columns.get(i);
 				if (column instanceof Column){
 					columnsNames[i] = ((Column) column).getName();
 				}
 			}
 
 			final XProperty xProperty = (XProperty) typeParameters.get( DynamicParameterizedType.XPROPERTY );
 			// todo : not sure this works for handling @MapKeyEnumerated
 			final Annotation[] annotations = xProperty == null
 					? null
 					: xProperty.getAnnotations();
 
 			typeParameters.put(
 					DynamicParameterizedType.PARAMETER_TYPE,
 					new ParameterTypeImpl(
 							ReflectHelper.classForName(
 									typeParameters.getProperty( DynamicParameterizedType.RETURNED_CLASS )
 							),
 							annotations,
 							table.getCatalog(),
 							table.getSchema(),
 							table.getName(),
 							Boolean.valueOf( typeParameters.getProperty( DynamicParameterizedType.IS_PRIMARY_KEY ) ),
 							columnsNames
 					)
 			);
 		}
 		catch ( ClassNotFoundException cnfe ) {
 			throw new MappingException( "Could not create DynamicParameterizedType for type: " + typeName, cnfe );
 		}
 	}
 
 	private final class ParameterTypeImpl implements DynamicParameterizedType.ParameterType {
 
 		private final Class returnedClass;
 		private final Annotation[] annotationsMethod;
 		private final String catalog;
 		private final String schema;
 		private final String table;
 		private final boolean primaryKey;
 		private final String[] columns;
 
 		private ParameterTypeImpl(Class returnedClass, Annotation[] annotationsMethod, String catalog, String schema,
 				String table, boolean primaryKey, String[] columns) {
 			this.returnedClass = returnedClass;
 			this.annotationsMethod = annotationsMethod;
 			this.catalog = catalog;
 			this.schema = schema;
 			this.table = table;
 			this.primaryKey = primaryKey;
 			this.columns = columns;
 		}
 
 		@Override
 		public Class getReturnedClass() {
 			return returnedClass;
 		}
 
 		@Override
 		public Annotation[] getAnnotationsMethod() {
 			return annotationsMethod;
 		}
 
 		@Override
 		public String getCatalog() {
 			return catalog;
 		}
 
 		@Override
 		public String getSchema() {
 			return schema;
 		}
 
 		@Override
 		public String getTable() {
 			return table;
 		}
 
 		@Override
 		public boolean isPrimaryKey() {
 			return primaryKey;
 		}
 
 		@Override
 		public String[] getColumns() {
 			return columns;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/metadata/ClassMetadata.java b/hibernate-core/src/main/java/org/hibernate/metadata/ClassMetadata.java
index c27c095f8f..8a8a643ce3 100644
--- a/hibernate-core/src/main/java/org/hibernate/metadata/ClassMetadata.java
+++ b/hibernate-core/src/main/java/org/hibernate/metadata/ClassMetadata.java
@@ -1,227 +1,228 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.metadata;
 
 import java.io.Serializable;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.type.Type;
 
 /**
  * Exposes entity class metadata to the application
  *
  * @see org.hibernate.SessionFactory#getClassMetadata(Class)
  * @author Gavin King
  */
 @SuppressWarnings( {"JavaDoc"})
 public interface ClassMetadata {
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     // stuff that is persister-centric and/or EntityInfo-centric ~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * The name of the entity
 	 */
-	public String getEntityName();
+	String getEntityName();
 
 	/**
 	 * Get the name of the identifier property (or return null)
 	 */
-	public String getIdentifierPropertyName();
+	String getIdentifierPropertyName();
 
 	/**
 	 * Get the names of the class' persistent properties
 	 */
-	public String[] getPropertyNames();
+	String[] getPropertyNames();
 
 	/**
 	 * Get the identifier Hibernate type
 	 */
-	public Type getIdentifierType();
+	Type getIdentifierType();
 
 	/**
 	 * Get the Hibernate types of the class properties
 	 */
-	public Type[] getPropertyTypes();
+	Type[] getPropertyTypes();
 
 	/**
 	 * Get the type of a particular (named) property
 	 */
-	public Type getPropertyType(String propertyName) throws HibernateException;
+	Type getPropertyType(String propertyName) throws HibernateException;
 
 	/**
 	 * Does this class support dynamic proxies?
 	 */
-	public boolean hasProxy();
+	boolean hasProxy();
 
 	/**
 	 * Are instances of this class mutable?
 	 */
-	public boolean isMutable();
+	boolean isMutable();
 
 	/**
 	 * Are instances of this class versioned by a timestamp or version number column?
 	 */
-	public boolean isVersioned();
+	boolean isVersioned();
 
 	/**
 	 * Get the index of the version property
 	 */
-	public int getVersionProperty();
+	int getVersionProperty();
 
 	/**
 	 * Get the nullability of the class' persistent properties
 	 */
-	public boolean[] getPropertyNullability();
+	boolean[] getPropertyNullability();
 
 
 	/**
 	 * Get the "laziness" of the properties of this class
 	 */
-	public boolean[] getPropertyLaziness();
+	boolean[] getPropertyLaziness();
 
 	/**
 	 * Does this class have an identifier property?
 	 */
-	public boolean hasIdentifierProperty();
+	boolean hasIdentifierProperty();
 
 	/**
 	 * Does this entity declare a natural id?
 	 */
-	public boolean hasNaturalIdentifier();
+	boolean hasNaturalIdentifier();
 
 	/**
 	 * Which properties hold the natural id?
 	 */
-	public int[] getNaturalIdentifierProperties();
+	int[] getNaturalIdentifierProperties();
 	
 	/**
 	 * Does this entity have mapped subclasses?
 	 */
-	public boolean hasSubclasses();
+	boolean hasSubclasses();
 	
 	/**
 	 * Does this entity extend a mapped superclass?
 	 */
-	public boolean isInherited();
+	boolean isInherited();
 	
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// stuff that is tuplizer-centric, but is passed a session ~~~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Return the values of the mapped properties of the object
 	 */
 	@SuppressWarnings( {"UnusedDeclaration"})
-	public Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session)
+	Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session)
 	throws HibernateException;
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// stuff that is Tuplizer-centric ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * The persistent class, or null
 	 */
-	public Class getMappedClass();
+	Class getMappedClass();
 
 	/**
 	 * Create a class instance initialized with the given identifier
 	 *
 	 * @param id The identifier value to use (may be null to represent no value)
 	 * @param session The session from which the request originated.
 	 *
 	 * @return The instantiated entity.
 	 */
-	public Object instantiate(Serializable id, SessionImplementor session);
+	Object instantiate(Serializable id, SessionImplementor session);
 
 	/**
 	 * Get the value of a particular (named) property
 	 */
-	public Object getPropertyValue(Object object, String propertyName) throws HibernateException;
+	Object getPropertyValue(Object object, String propertyName) throws HibernateException;
 
 	/**
 	 * Extract the property values from the given entity.
 	 *
 	 * @param entity The entity from which to extract the property values.
 	 * @return The property values.
 	 * @throws HibernateException
 	 */
-	public Object[] getPropertyValues(Object entity) throws HibernateException;
+	Object[] getPropertyValues(Object entity) throws HibernateException;
 
 	/**
 	 * Set the value of a particular (named) property
 	 */
-	public void setPropertyValue(Object object, String propertyName, Object value) throws HibernateException;
+	void setPropertyValue(Object object, String propertyName, Object value) throws HibernateException;
 
 	/**
 	 * Set the given values to the mapped properties of the given object
 	 */
-	public void setPropertyValues(Object object, Object[] values) throws HibernateException;
+	void setPropertyValues(Object object, Object[] values) throws HibernateException;
 
 	/**
 	 * Get the identifier of an instance (throw an exception if no identifier property)
 	 *
 	 * @deprecated Use {@link #getIdentifier(Object,SessionImplementor)} instead
 	 */
+	@Deprecated
 	@SuppressWarnings( {"JavaDoc"})
-	public Serializable getIdentifier(Object object) throws HibernateException;
+	Serializable getIdentifier(Object object) throws HibernateException;
 
 	/**
 	 * Get the identifier of an instance (throw an exception if no identifier property)
 	 *
 	 * @param entity The entity for which to get the identifier
 	 * @param session The session from which the request originated
 	 *
 	 * @return The identifier
 	 */
-	public Serializable getIdentifier(Object entity, SessionImplementor session);
+	Serializable getIdentifier(Object entity, SessionImplementor session);
 
 	/**
 	 * Inject the identifier value into the given entity.
 	 *
 	 * @param entity The entity to inject with the identifier value.
 	 * @param id The value to be injected as the identifier.
 	 * @param session The session from which is requests originates
 	 */
-	public void setIdentifier(Object entity, Serializable id, SessionImplementor session);
+	void setIdentifier(Object entity, Serializable id, SessionImplementor session);
 
 
 	/**
 	 * Does the class implement the <tt>Lifecycle</tt> interface?
 	 */
 	@SuppressWarnings( {"UnusedDeclaration"})
-	public boolean implementsLifecycle();
+	boolean implementsLifecycle();
 
 	/**
 	 * Get the version number (or timestamp) from the object's version property
 	 * (or return null if not versioned)
 	 */
-	public Object getVersion(Object object) throws HibernateException;
+	Object getVersion(Object object) throws HibernateException;
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
index ae3cc03e07..ae729d57c9 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
@@ -1,1686 +1,1694 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.cache.spi.entry.StructuredCollectionCacheEntry;
 import org.hibernate.cache.spi.entry.StructuredMapCacheEntry;
 import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.List;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Table;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.persister.walking.internal.CompositionSingularSubAttributesHelper;
 import org.hibernate.persister.walking.internal.StandardAnyTypeDefinition;
 import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.CollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CollectionIndexDefinition;
 import org.hibernate.persister.walking.spi.CompositeCollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.ordering.antlr.ColumnMapper;
 import org.hibernate.sql.ordering.antlr.ColumnReference;
 import org.hibernate.sql.ordering.antlr.FormulaReference;
 import org.hibernate.sql.ordering.antlr.OrderByAliasResolver;
 import org.hibernate.sql.ordering.antlr.OrderByTranslation;
 import org.hibernate.sql.ordering.antlr.SqlValueReference;
 import org.hibernate.type.AnyType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Base implementation of the <tt>QueryableCollection</tt> interface.
  *
  * @author Gavin King
  * @see BasicCollectionPersister
  * @see OneToManyPersister
  */
 public abstract class AbstractCollectionPersister
 		implements CollectionMetadata, SQLLoadableCollection {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class,
 			AbstractCollectionPersister.class.getName() );
 
 	// TODO: encapsulate the protected instance variables!
 
 	private final String role;
 
 	// SQL statements
 	private final String sqlDeleteString;
 	private final String sqlInsertRowString;
 	private final String sqlUpdateRowString;
 	private final String sqlDeleteRowString;
 	private final String sqlSelectSizeString;
 	private final String sqlSelectRowByIndexString;
 	private final String sqlDetectRowByIndexString;
 	private final String sqlDetectRowByElementString;
 
 	protected final boolean hasWhere;
 	protected final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	private final boolean hasOrder;
 	private final OrderByTranslation orderByTranslation;
 
 	private final boolean hasManyToManyOrder;
 	private final OrderByTranslation manyToManyOrderByTranslation;
 
 	private final int baseIndex;
 
 	private final String nodeName;
 	private final String elementNodeName;
 	private final String indexNodeName;
 	private String mappedByProperty;
 
 	protected final boolean indexContainsFormula;
 	protected final boolean elementIsPureFormula;
 
 	// types
 	private final Type keyType;
 	private final Type indexType;
 	protected final Type elementType;
 	private final Type identifierType;
 
 	// columns
 	protected final String[] keyColumnNames;
 	protected final String[] indexColumnNames;
 	protected final String[] indexFormulaTemplates;
 	protected final String[] indexFormulas;
 	protected final boolean[] indexColumnIsSettable;
 	protected final String[] elementColumnNames;
 	protected final String[] elementColumnWriters;
 	protected final String[] elementColumnReaders;
 	protected final String[] elementColumnReaderTemplates;
 	protected final String[] elementFormulaTemplates;
 	protected final String[] elementFormulas;
 	protected final boolean[] elementColumnIsSettable;
 	protected final boolean[] elementColumnIsInPrimaryKey;
 	protected final String[] indexColumnAliases;
 	protected final String[] elementColumnAliases;
 	protected final String[] keyColumnAliases;
 
 	protected final String identifierColumnName;
 	private final String identifierColumnAlias;
 	// private final String unquotedIdentifierColumnName;
 
 	protected final String qualifiedTableName;
 
 	private final String queryLoaderName;
 
 	private final boolean isPrimitiveArray;
 	private final boolean isArray;
 	protected final boolean hasIndex;
 	protected final boolean hasIdentifier;
 	private final boolean isLazy;
 	private final boolean isExtraLazy;
 	protected final boolean isInverse;
 	private final boolean isMutable;
 	private final boolean isVersioned;
 	protected final int batchSize;
 	private final FetchMode fetchMode;
 	private final boolean hasOrphanDelete;
 	private final boolean subselectLoadable;
 
 	// extra information about the element type
 	private final Class elementClass;
 	private final String entityName;
 
 	private final Dialect dialect;
 	protected final SqlExceptionHelper sqlExceptionHelper;
 	private final SessionFactoryImplementor factory;
 	private final EntityPersister ownerPersister;
 	private final IdentifierGenerator identifierGenerator;
 	private final PropertyMapping elementPropertyMapping;
 	private final EntityPersister elementPersister;
 	private final CollectionRegionAccessStrategy cacheAccessStrategy;
 	private final CollectionType collectionType;
 	private CollectionInitializer initializer;
 
 	private final CacheEntryStructure cacheEntryStructure;
 
 	// dynamic filters for the collection
 	private final FilterHelper filterHelper;
 
 	// dynamic filters specifically for many-to-many inside the collection
 	private final FilterHelper manyToManyFilterHelper;
 
 	private final String manyToManyWhereString;
 	private final String manyToManyWhereTemplate;
 
 	// custom sql
 	private final boolean insertCallable;
 	private final boolean updateCallable;
 	private final boolean deleteCallable;
 	private final boolean deleteAllCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteAllCheckStyle;
 
 	private final Serializable[] spaces;
 
 	private Map collectionPropertyColumnAliases = new HashMap();
 	private Map collectionPropertyColumnNames = new HashMap();
 
 	public AbstractCollectionPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 
 		this.factory = creationContext.getSessionFactory();
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		if ( factory.getSettings().isStructuredCacheEntriesEnabled() ) {
 			cacheEntryStructure = collectionBinding.isMap()
 					? StructuredMapCacheEntry.INSTANCE
 					: StructuredCollectionCacheEntry.INSTANCE;
 		}
 		else {
 			cacheEntryStructure = UnstructuredCacheEntry.INSTANCE;
 		}
 
 		dialect = factory.getDialect();
 		sqlExceptionHelper = factory.getSQLExceptionHelper();
 		collectionType = collectionBinding.getCollectionType();
 		role = collectionBinding.getRole();
 		entityName = collectionBinding.getOwnerEntityName();
 		ownerPersister = factory.getEntityPersister( entityName );
 		queryLoaderName = collectionBinding.getLoaderName();
 		nodeName = collectionBinding.getNodeName();
 		isMutable = collectionBinding.isMutable();
 		mappedByProperty = collectionBinding.getMappedByProperty();
 
 		Table table = collectionBinding.getCollectionTable();
 		fetchMode = collectionBinding.getElement().getFetchMode();
 		elementType = collectionBinding.getElement().getType();
 		// isSet = collectionBinding.isSet();
 		// isSorted = collectionBinding.isSorted();
 		isPrimitiveArray = collectionBinding.isPrimitiveArray();
 		isArray = collectionBinding.isArray();
 		subselectLoadable = collectionBinding.isSubselectLoadable();
 
 		qualifiedTableName = table.getQualifiedName(
 				dialect,
 				factory.getSettings().getDefaultCatalogName(),
 				factory.getSettings().getDefaultSchemaName()
 				);
 
 		int spacesSize = 1 + collectionBinding.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = qualifiedTableName;
 		Iterator iter = collectionBinding.getSynchronizedTables().iterator();
 		for ( int i = 1; i < spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
 
 		sqlWhereString = StringHelper.isNotEmpty( collectionBinding.getWhere() ) ? "( " + collectionBinding.getWhere() + ") " : null;
 		hasWhere = sqlWhereString != null;
 		sqlWhereStringTemplate = hasWhere ?
 				Template.renderWhereStringTemplate( sqlWhereString, dialect, factory.getSqlFunctionRegistry() ) :
 				null;
 
 		hasOrphanDelete = collectionBinding.hasOrphanDelete();
 
 		int batch = collectionBinding.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 
 		isVersioned = collectionBinding.isOptimisticLocked();
 
 		// KEY
 
 		keyType = collectionBinding.getKey().getType();
 		iter = collectionBinding.getKey().getColumnIterator();
 		int keySpan = collectionBinding.getKey().getColumnSpan();
 		keyColumnNames = new String[keySpan];
 		keyColumnAliases = new String[keySpan];
 		int k = 0;
 		while ( iter.hasNext() ) {
 			// NativeSQL: collect key column and auto-aliases
 			Column col = ( (Column) iter.next() );
 			keyColumnNames[k] = col.getQuotedName( dialect );
 			keyColumnAliases[k] = col.getAlias( dialect, collectionBinding.getOwner().getRootTable() );
 			k++;
 		}
 
 		// unquotedKeyColumnNames = StringHelper.unQuote(keyColumnAliases);
 
 		// ELEMENT
 
 		String elemNode = collectionBinding.getElementNodeName();
 		if ( elementType.isEntityType() ) {
 			String entityName = ( (EntityType) elementType ).getAssociatedEntityName();
 			elementPersister = factory.getEntityPersister( entityName );
 			if ( elemNode == null ) {
 				elemNode = creationContext.getMetadata().getEntityBinding( entityName ).getNodeName();
 			}
 			// NativeSQL: collect element column and auto-aliases
 
 		}
 		else {
 			elementPersister = null;
 		}
 		elementNodeName = elemNode;
 
 		int elementSpan = collectionBinding.getElement().getColumnSpan();
 		elementColumnAliases = new String[elementSpan];
 		elementColumnNames = new String[elementSpan];
 		elementColumnWriters = new String[elementSpan];
 		elementColumnReaders = new String[elementSpan];
 		elementColumnReaderTemplates = new String[elementSpan];
 		elementFormulaTemplates = new String[elementSpan];
 		elementFormulas = new String[elementSpan];
 		elementColumnIsSettable = new boolean[elementSpan];
 		elementColumnIsInPrimaryKey = new boolean[elementSpan];
 		boolean isPureFormula = true;
 		boolean hasNotNullableColumns = false;
 		int j = 0;
 		iter = collectionBinding.getElement().getColumnIterator();
 		while ( iter.hasNext() ) {
 			Selectable selectable = (Selectable) iter.next();
 			elementColumnAliases[j] = selectable.getAlias( dialect, table );
 			if ( selectable.isFormula() ) {
 				Formula form = (Formula) selectable;
 				elementFormulaTemplates[j] = form.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 				elementFormulas[j] = form.getFormula();
 			}
 			else {
 				Column col = (Column) selectable;
 				elementColumnNames[j] = col.getQuotedName( dialect );
 				elementColumnWriters[j] = col.getWriteExpr();
 				elementColumnReaders[j] = col.getReadExpr( dialect );
 				elementColumnReaderTemplates[j] = col.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 				elementColumnIsSettable[j] = true;
 				elementColumnIsInPrimaryKey[j] = !col.isNullable();
 				if ( !col.isNullable() ) {
 					hasNotNullableColumns = true;
 				}
 				isPureFormula = false;
 			}
 			j++;
 		}
 		elementIsPureFormula = isPureFormula;
 
 		// workaround, for backward compatibility of sets with no
 		// not-null columns, assume all columns are used in the
 		// row locator SQL
 		if ( !hasNotNullableColumns ) {
 			Arrays.fill( elementColumnIsInPrimaryKey, true );
 		}
 
 		// INDEX AND ROW SELECT
 
 		hasIndex = collectionBinding.isIndexed();
 		if ( hasIndex ) {
 			// NativeSQL: collect index column and auto-aliases
 			IndexedCollection indexedCollection = (IndexedCollection) collectionBinding;
 			indexType = indexedCollection.getIndex().getType();
 			int indexSpan = indexedCollection.getIndex().getColumnSpan();
 			iter = indexedCollection.getIndex().getColumnIterator();
 			indexColumnNames = new String[indexSpan];
 			indexFormulaTemplates = new String[indexSpan];
 			indexFormulas = new String[indexSpan];
 			indexColumnIsSettable = new boolean[indexSpan];
 			indexColumnAliases = new String[indexSpan];
 			int i = 0;
 			boolean hasFormula = false;
 			while ( iter.hasNext() ) {
 				Selectable s = (Selectable) iter.next();
 				indexColumnAliases[i] = s.getAlias( dialect );
 				if ( s.isFormula() ) {
 					Formula indexForm = (Formula) s;
 					indexFormulaTemplates[i] = indexForm.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 					indexFormulas[i] = indexForm.getFormula();
 					hasFormula = true;
 				}
 				else {
 					Column indexCol = (Column) s;
 					indexColumnNames[i] = indexCol.getQuotedName( dialect );
 					indexColumnIsSettable[i] = true;
 				}
 				i++;
 			}
 			indexContainsFormula = hasFormula;
 			baseIndex = indexedCollection.isList() ?
 					( (List) indexedCollection ).getBaseIndex() : 0;
 
 			indexNodeName = indexedCollection.getIndexNodeName();
 
 		}
 		else {
 			indexContainsFormula = false;
 			indexColumnIsSettable = null;
 			indexFormulaTemplates = null;
 			indexFormulas = null;
 			indexType = null;
 			indexColumnNames = null;
 			indexColumnAliases = null;
 			baseIndex = 0;
 			indexNodeName = null;
 		}
 
 		hasIdentifier = collectionBinding.isIdentified();
 		if ( hasIdentifier ) {
 			if ( collectionBinding.isOneToMany() ) {
 				throw new MappingException( "one-to-many collections with identifiers are not supported" );
 			}
 			IdentifierCollection idColl = (IdentifierCollection) collectionBinding;
 			identifierType = idColl.getIdentifier().getType();
 			iter = idColl.getIdentifier().getColumnIterator();
 			Column col = (Column) iter.next();
 			identifierColumnName = col.getQuotedName( dialect );
 			identifierColumnAlias = col.getAlias( dialect );
 			// unquotedIdentifierColumnName = identifierColumnAlias;
 			identifierGenerator = idColl.getIdentifier().createIdentifierGenerator(
 					creationContext.getMetadata().getIdentifierGeneratorFactory(),
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName(),
 					null
 					);
 		}
 		else {
 			identifierType = null;
 			identifierColumnName = null;
 			identifierColumnAlias = null;
 			// unquotedIdentifierColumnName = null;
 			identifierGenerator = null;
 		}
 
 		// GENERATE THE SQL:
 
 		// sqlSelectString = sqlSelectString();
 		// sqlSelectRowString = sqlSelectRowString();
 
 		if ( collectionBinding.getCustomSQLInsert() == null ) {
 			sqlInsertRowString = generateInsertRowString();
 			insertCallable = false;
 			insertCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlInsertRowString = collectionBinding.getCustomSQLInsert();
 			insertCallable = collectionBinding.isCustomInsertCallable();
 			insertCheckStyle = collectionBinding.getCustomSQLInsertCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collectionBinding.getCustomSQLInsert(), insertCallable )
 					: collectionBinding.getCustomSQLInsertCheckStyle();
 		}
 
 		if ( collectionBinding.getCustomSQLUpdate() == null ) {
 			sqlUpdateRowString = generateUpdateRowString();
 			updateCallable = false;
 			updateCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlUpdateRowString = collectionBinding.getCustomSQLUpdate();
 			updateCallable = collectionBinding.isCustomUpdateCallable();
 			updateCheckStyle = collectionBinding.getCustomSQLUpdateCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collectionBinding.getCustomSQLUpdate(), insertCallable )
 					: collectionBinding.getCustomSQLUpdateCheckStyle();
 		}
 
 		if ( collectionBinding.getCustomSQLDelete() == null ) {
 			sqlDeleteRowString = generateDeleteRowString();
 			deleteCallable = false;
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteRowString = collectionBinding.getCustomSQLDelete();
 			deleteCallable = collectionBinding.isCustomDeleteCallable();
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		if ( collectionBinding.getCustomSQLDeleteAll() == null ) {
 			sqlDeleteString = generateDeleteString();
 			deleteAllCallable = false;
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteString = collectionBinding.getCustomSQLDeleteAll();
 			deleteAllCallable = collectionBinding.isCustomDeleteAllCallable();
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		sqlSelectSizeString = generateSelectSizeString( collectionBinding.isIndexed() && !collectionBinding.isMap() );
 		sqlDetectRowByIndexString = generateDetectRowByIndexString();
 		sqlDetectRowByElementString = generateDetectRowByElementString();
 		sqlSelectRowByIndexString = generateSelectRowByIndexString();
 
 		logStaticSQL();
 
 		isLazy = collectionBinding.isLazy();
 		isExtraLazy = collectionBinding.isExtraLazy();
 
 		isInverse = collectionBinding.isInverse();
 
 		if ( collectionBinding.isArray() ) {
 			elementClass = ( (org.hibernate.mapping.Array) collectionBinding ).getElementClass();
 		}
 		else {
 			// for non-arrays, we don't need to know the element class
 			elementClass = null; // elementType.returnedClass();
 		}
 
 		if ( elementType.isComponentType() ) {
 			elementPropertyMapping = new CompositeElementPropertyMapping(
 					elementColumnNames,
 					elementColumnReaders,
 					elementColumnReaderTemplates,
 					elementFormulaTemplates,
 					(CompositeType) elementType,
 					factory
 					);
 		}
 		else if ( !elementType.isEntityType() ) {
 			elementPropertyMapping = new ElementPropertyMapping(
 					elementColumnNames,
 					elementType
 					);
 		}
 		else {
 			if ( elementPersister instanceof PropertyMapping ) { // not all classpersisters implement PropertyMapping!
 				elementPropertyMapping = (PropertyMapping) elementPersister;
 			}
 			else {
 				elementPropertyMapping = new ElementPropertyMapping(
 						elementColumnNames,
 						elementType
 						);
 			}
 		}
 
 		hasOrder = collectionBinding.getOrderBy() != null;
 		if ( hasOrder ) {
 			orderByTranslation = Template.translateOrderBy(
 					collectionBinding.getOrderBy(),
 					new ColumnMapperImpl(),
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			orderByTranslation = null;
 		}
 
 		// Handle any filters applied to this collectionBinding
 		filterHelper = new FilterHelper( collectionBinding.getFilters(), factory);
 
 		// Handle any filters applied to this collectionBinding for many-to-many
 		manyToManyFilterHelper = new FilterHelper( collectionBinding.getManyToManyFilters(), factory);
 		manyToManyWhereString = StringHelper.isNotEmpty( collectionBinding.getManyToManyWhere() ) ?
 				"( " + collectionBinding.getManyToManyWhere() + ")" :
 				null;
 		manyToManyWhereTemplate = manyToManyWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( manyToManyWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		hasManyToManyOrder = collectionBinding.getManyToManyOrdering() != null;
 		if ( hasManyToManyOrder ) {
 			manyToManyOrderByTranslation = Template.translateOrderBy(
 					collectionBinding.getManyToManyOrdering(),
 					new ColumnMapperImpl(),
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			manyToManyOrderByTranslation = null;
 		}
 
 		initCollectionPropertyMap();
 	}
 
 	private class ColumnMapperImpl implements ColumnMapper {
 		@Override
 		public SqlValueReference[] map(String reference) {
 			final String[] columnNames;
 			final String[] formulaTemplates;
 
 			// handle the special "$element$" property name...
 			if ( "$element$".equals( reference ) ) {
 				columnNames = elementColumnNames;
 				formulaTemplates = elementFormulaTemplates;
 			}
 			else {
 				columnNames = elementPropertyMapping.toColumns( reference );
 				formulaTemplates = formulaTemplates( reference, columnNames.length );
 			}
 
 			final SqlValueReference[] result = new SqlValueReference[ columnNames.length ];
 			int i = 0;
 			for ( final String columnName : columnNames ) {
 				if ( columnName == null ) {
 					// if the column name is null, it indicates that this index in the property value mapping is
 					// actually represented by a formula.
 //					final int propertyIndex = elementPersister.getEntityMetamodel().getPropertyIndex( reference );
 					final String formulaTemplate = formulaTemplates[i];
 					result[i] = new FormulaReference() {
 						@Override
 						public String getFormulaFragment() {
 							return formulaTemplate;
 						}
 					};
 				}
 				else {
 					result[i] = new ColumnReference() {
 						@Override
 						public String getColumnName() {
 							return columnName;
 						}
 					};
 				}
 				i++;
 			}
 			return result;
 		}
 	}
 
 	private String[] formulaTemplates(String reference, int expectedSize) {
 		try {
 			final int propertyIndex = elementPersister.getEntityMetamodel().getPropertyIndex( reference );
 			return  ( (Queryable) elementPersister ).getSubclassPropertyFormulaTemplateClosure()[propertyIndex];
 		}
 		catch (Exception e) {
 			return new String[expectedSize];
 		}
 	}
 
 	@Override
 	public void postInstantiate() throws MappingException {
 		initializer = queryLoaderName == null ?
 				createCollectionInitializer( LoadQueryInfluencers.NONE ) :
 				new NamedQueryCollectionInitializer( queryLoaderName, this );
 	}
 
 	protected void logStaticSQL() {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Static SQL for collection: %s", getRole() );
-			if ( getSQLInsertRowString() != null ) LOG.debugf( " Row insert: %s", getSQLInsertRowString() );
-			if ( getSQLUpdateRowString() != null ) LOG.debugf( " Row update: %s", getSQLUpdateRowString() );
-			if ( getSQLDeleteRowString() != null ) LOG.debugf( " Row delete: %s", getSQLDeleteRowString() );
-			if ( getSQLDeleteString() != null ) LOG.debugf( " One-shot delete: %s", getSQLDeleteString() );
+			if ( getSQLInsertRowString() != null ) {
+				LOG.debugf( " Row insert: %s", getSQLInsertRowString() );
+			}
+			if ( getSQLUpdateRowString() != null ) {
+				LOG.debugf( " Row update: %s", getSQLUpdateRowString() );
+			}
+			if ( getSQLDeleteRowString() != null ) {
+				LOG.debugf( " Row delete: %s", getSQLDeleteRowString() );
+			}
+			if ( getSQLDeleteString() != null ) {
+				LOG.debugf( " One-shot delete: %s", getSQLDeleteString() );
+			}
 		}
 	}
 
 	@Override
 	public void initialize(Serializable key, SessionImplementor session) throws HibernateException {
 		getAppropriateInitializer( key, session ).initialize( key, session );
 	}
 
 	protected CollectionInitializer getAppropriateInitializer(Serializable key, SessionImplementor session) {
 		if ( queryLoaderName != null ) {
 			// if there is a user-specified loader, return that
 			// TODO: filters!?
 			return initializer;
 		}
 		CollectionInitializer subselectInitializer = getSubselectInitializer( key, session );
 		if ( subselectInitializer != null ) {
 			return subselectInitializer;
 		}
 		else if ( session.getLoadQueryInfluencers().getEnabledFilters().isEmpty() ) {
 			return initializer;
 		}
 		else {
 			return createCollectionInitializer( session.getLoadQueryInfluencers() );
 		}
 	}
 
 	private CollectionInitializer getSubselectInitializer(Serializable key, SessionImplementor session) {
 
 		if ( !isSubselectLoadable() ) {
 			return null;
 		}
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		SubselectFetch subselect = persistenceContext.getBatchFetchQueue()
 				.getSubselect( session.generateEntityKey( key, getOwnerEntityPersister() ) );
 
 		if ( subselect == null ) {
 			return null;
 		}
 		else {
 
 			// Take care of any entities that might have
 			// been evicted!
 			Iterator iter = subselect.getResult().iterator();
 			while ( iter.hasNext() ) {
 				if ( !persistenceContext.containsEntity( (EntityKey) iter.next() ) ) {
 					iter.remove();
 				}
 			}
 
 			// Run a subquery loader
 			return createSubselectInitializer( subselect, session );
 		}
 	}
 
 	protected abstract CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session);
 
 	protected abstract CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException;
 
 	@Override
 	public CollectionRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	@Override
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	@Override
 	public CollectionType getCollectionType() {
 		return collectionType;
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	@Override
 	public String getSQLOrderByString(String alias) {
 		return hasOrdering()
 				? orderByTranslation.injectAliases( new StandardOrderByAliasResolver( alias ) )
 				: "";
 	}
 
 	@Override
 	public String getManyToManyOrderByString(String alias) {
 		return hasManyToManyOrdering()
 				? manyToManyOrderByTranslation.injectAliases( new StandardOrderByAliasResolver( alias ) )
 				: "";
 	}
 
 	@Override
 	public FetchMode getFetchMode() {
 		return fetchMode;
 	}
 
 	@Override
 	public boolean hasOrdering() {
 		return hasOrder;
 	}
 
 	@Override
 	public boolean hasManyToManyOrdering() {
 		return isManyToMany() && hasManyToManyOrder;
 	}
 
 	@Override
 	public boolean hasWhere() {
 		return hasWhere;
 	}
 
 	protected String getSQLDeleteString() {
 		return sqlDeleteString;
 	}
 
 	protected String getSQLInsertRowString() {
 		return sqlInsertRowString;
 	}
 
 	protected String getSQLUpdateRowString() {
 		return sqlUpdateRowString;
 	}
 
 	protected String getSQLDeleteRowString() {
 		return sqlDeleteRowString;
 	}
 
 	@Override
 	public Type getKeyType() {
 		return keyType;
 	}
 
 	@Override
 	public Type getIndexType() {
 		return indexType;
 	}
 
 	@Override
 	public Type getElementType() {
 		return elementType;
 	}
 
 	/**
 	 * Return the element class of an array, or null otherwise.  needed by arrays
 	 */
 	@Override
 	public Class getElementClass() {
 		return elementClass;
 	}
 
 	@Override
 	public Object readElement(ResultSet rs, Object owner, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getElementType().nullSafeGet( rs, aliases, session, owner );
 	}
 
 	@Override
 	public Object readIndex(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object index = getIndexType().nullSafeGet( rs, aliases, session, null );
 		if ( index == null ) {
 			throw new HibernateException( "null index column for collection: " + role );
 		}
 		index = decrementIndexByBase( index );
 		return index;
 	}
 
 	protected Object decrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
             index = (Integer)index - baseIndex;
 		}
 		return index;
 	}
 
 	@Override
 	public Object readIdentifier(ResultSet rs, String alias, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object id = getIdentifierType().nullSafeGet( rs, alias, session, null );
 		if ( id == null ) {
 			throw new HibernateException( "null identifier column for collection: " + role );
 		}
 		return id;
 	}
 
 	@Override
 	public Object readKey(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getKeyType().nullSafeGet( rs, aliases, session, null );
 	}
 
 	/**
 	 * Write the key to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeKey(PreparedStatement st, Serializable key, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		if ( key == null ) {
 			throw new NullPointerException( "null key for collection: " + role ); // an assertion
 		}
 		getKeyType().nullSafeSet( st, key, i, session );
 		return i + keyColumnAliases.length;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElement(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( elementColumnIsSettable );
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndex(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, indexColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( indexColumnIsSettable );
 	}
 
 	protected Object incrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
             index = (Integer)index + baseIndex;
 		}
 		return index;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElementToWhere(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( elementIsPureFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based element in the where condition" );
 		}
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsInPrimaryKey, session );
 		return i + elementColumnAliases.length;
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndexToWhere(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( indexContainsFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based index in the where condition" );
 		}
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, session );
 		return i + indexColumnAliases.length;
 	}
 
 	/**
 	 * Write the identifier to a JDBC <tt>PreparedStatement</tt>
 	 */
 	public int writeIdentifier(PreparedStatement st, Object id, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		getIdentifierType().nullSafeSet( st, id, i, session );
 		return i + 1;
 	}
 
 	@Override
 	public boolean isPrimitiveArray() {
 		return isPrimitiveArray;
 	}
 
 	@Override
 	public boolean isArray() {
 		return isArray;
 	}
 
 	@Override
 	public String[] getKeyColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( keyColumnAliases );
 	}
 
 	@Override
 	public String[] getElementColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( elementColumnAliases );
 	}
 
 	@Override
 	public String[] getIndexColumnAliases(String suffix) {
 		if ( hasIndex ) {
 			return new Alias( suffix ).toAliasStrings( indexColumnAliases );
 		}
 		else {
 			return null;
 		}
 	}
 
 	@Override
 	public String getIdentifierColumnAlias(String suffix) {
 		if ( hasIdentifier ) {
 			return new Alias( suffix ).toAliasString( identifierColumnAlias );
 		}
 		else {
 			return null;
 		}
 	}
 
 	@Override
 	public String getIdentifierColumnName() {
 		if ( hasIdentifier ) {
 			return identifierColumnName;
 		}
 		else {
 			return null;
 		}
 	}
 
 	/**
 	 * Generate a list of collection index, key and element columns
 	 */
 	@Override
 	public String selectFragment(String alias, String columnSuffix) {
 		SelectFragment frag = generateSelectFragment( alias, columnSuffix );
 		appendElementColumns( frag, alias );
 		appendIndexColumns( frag, alias );
 		appendIdentifierColumns( frag, alias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); // strip leading ','
 	}
 
 	protected String generateSelectSizeString(boolean isIntegerIndexed) {
 		String selectValue = isIntegerIndexed ?
 				"max(" + getIndexColumnNames()[0] + ") + 1" : // lists, arrays
 				"count(" + getElementColumnNames()[0] + ")"; // sets, maps, bags
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addColumn( selectValue )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected String generateSelectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumns( getElementColumnNames(), elementColumnAliases )
 				.addColumns( indexFormulas, indexColumnAliases )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByElementString() {
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getElementColumnNames(), "=?" )
 				.addCondition( elementFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected SelectFragment generateSelectFragment(String alias, String columnSuffix) {
 		return new SelectFragment()
 				.setSuffix( columnSuffix )
 				.addColumns( alias, keyColumnNames, keyColumnAliases );
 	}
 
 	protected void appendElementColumns(SelectFragment frag, String elemAlias) {
 		for ( int i = 0; i < elementColumnIsSettable.length; i++ ) {
 			if ( elementColumnIsSettable[i] ) {
 				frag.addColumnTemplate( elemAlias, elementColumnReaderTemplates[i], elementColumnAliases[i] );
 			}
 			else {
 				frag.addFormula( elemAlias, elementFormulaTemplates[i], elementColumnAliases[i] );
 			}
 		}
 	}
 
 	protected void appendIndexColumns(SelectFragment frag, String alias) {
 		if ( hasIndex ) {
 			for ( int i = 0; i < indexColumnIsSettable.length; i++ ) {
 				if ( indexColumnIsSettable[i] ) {
 					frag.addColumn( alias, indexColumnNames[i], indexColumnAliases[i] );
 				}
 				else {
 					frag.addFormula( alias, indexFormulaTemplates[i], indexColumnAliases[i] );
 				}
 			}
 		}
 	}
 
 	protected void appendIdentifierColumns(SelectFragment frag, String alias) {
 		if ( hasIdentifier ) {
 			frag.addColumn( alias, identifierColumnName, identifierColumnAlias );
 		}
 	}
 
 	@Override
 	public String[] getIndexColumnNames() {
 		return indexColumnNames;
 	}
 
 	@Override
 	public String[] getIndexFormulas() {
 		return indexFormulas;
 	}
 
 	@Override
 	public String[] getIndexColumnNames(String alias) {
 		return qualify( alias, indexColumnNames, indexFormulaTemplates );
 	}
 
 	@Override
 	public String[] getElementColumnNames(String alias) {
 		return qualify( alias, elementColumnNames, elementFormulaTemplates );
 	}
 
 	private static String[] qualify(String alias, String[] columnNames, String[] formulaTemplates) {
 		int span = columnNames.length;
 		String[] result = new String[span];
 		for ( int i = 0; i < span; i++ ) {
 			if ( columnNames[i] == null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.qualify( alias, columnNames[i] );
 			}
 		}
 		return result;
 	}
 
 	@Override
 	public String[] getElementColumnNames() {
 		return elementColumnNames; // TODO: something with formulas...
 	}
 
 	@Override
 	public String[] getKeyColumnNames() {
 		return keyColumnNames;
 	}
 
 	@Override
 	public boolean hasIndex() {
 		return hasIndex;
 	}
 
 	@Override
 	public boolean isLazy() {
 		return isLazy;
 	}
 
 	@Override
 	public boolean isInverse() {
 		return isInverse;
 	}
 
 	@Override
 	public String getTableName() {
 		return qualifiedTableName;
 	}
 
 	private BasicBatchKey removeBatchKey;
 
 	@Override
 	public void remove(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !isInverse && isRowDeleteEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Deleting collection: %s",
 						MessageHelper.collectionInfoString( this, id, getFactory() ) );
 			}
 
 			// Remove all the old entries
 
 			try {
 				int offset = 1;
 				PreparedStatement st = null;
 				Expectation expectation = Expectations.appropriateExpectation( getDeleteAllCheckStyle() );
 				boolean callable = isDeleteAllCallable();
 				boolean useBatch = expectation.canBeBatched();
 				String sql = getSQLDeleteString();
 				if ( useBatch ) {
 					if ( removeBatchKey == null ) {
 						removeBatchKey = new BasicBatchKey(
 								getRole() + "#REMOVE",
 								expectation
 								);
 					}
 					st = session
 							.getJdbcCoordinator()
 							.getBatch( removeBatchKey )
 							.getBatchStatement( sql, callable );
 				}
 				else {
 					st = session
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql, callable );
 				}
 
 				try {
 					offset += expectation.prepare( st );
 
 					writeKey( st, id, offset, session );
 					if ( useBatch ) {
 						session
 								.getJdbcCoordinator()
 								.getBatch( removeBatchKey )
 								.addToBatch();
 					}
 					else {
 						expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 					}
 				}
 				catch ( SQLException sqle ) {
 					if ( useBatch ) {
 						session.getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( st );
 						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 
 				LOG.debug( "Done deleting collection" );
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not delete collection: " +
 								MessageHelper.collectionInfoString( this, id, getFactory() ),
 						getSQLDeleteString()
 						);
 			}
 
 		}
 
 	}
 
 	protected BasicBatchKey recreateBatchKey;
 
 	@Override
 	public void recreate(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowInsertEnabled() ) {
 			return;
 		}
 
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Inserting collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		try {
 			// create all the new entries
 			Iterator entries = collection.entries( this );
 			if ( entries.hasNext() ) {
 				Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				collection.preInsert( this );
 				int i = 0;
 				int count = 0;
 				while ( entries.hasNext() ) {
 
 					final Object entry = entries.next();
 					if ( collection.entryExists( entry, i ) ) {
 						int offset = 1;
 						PreparedStatement st = null;
 						boolean callable = isInsertCallable();
 						boolean useBatch = expectation.canBeBatched();
 						String sql = getSQLInsertRowString();
 
 						if ( useBatch ) {
 							if ( recreateBatchKey == null ) {
 								recreateBatchKey = new BasicBatchKey(
 										getRole() + "#RECREATE",
 										expectation
 								);
 							}
 							st = session
 									.getJdbcCoordinator()
 									.getBatch( recreateBatchKey )
 									.getBatchStatement( sql, callable );
 						}
 						else {
 							st = session
 									.getJdbcCoordinator()
 									.getStatementPreparer()
 									.prepareStatement( sql, callable );
 						}
 
 						try {
 							offset += expectation.prepare( st );
 
 							// TODO: copy/paste from insertRows()
 							int loc = writeKey( st, id, offset, session );
 							if ( hasIdentifier ) {
 								loc = writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 							}
 							if ( hasIndex /* && !indexIsFormula */) {
 								loc = writeIndex( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 							loc = writeElement( st, collection.getElement( entry ), loc, session );
 
 							if ( useBatch ) {
 								session
 										.getJdbcCoordinator()
 										.getBatch( recreateBatchKey )
 										.addToBatch();
 							}
 							else {
 								expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 
 							collection.afterRowInsert( this, entry, i );
 							count++;
 						}
 						catch ( SQLException sqle ) {
 							if ( useBatch ) {
 								session.getJdbcCoordinator().abortBatch();
 							}
 							throw sqle;
 						}
 						finally {
 							if ( !useBatch ) {
 								session.getJdbcCoordinator().getResourceRegistry().release( st );
 								session.getJdbcCoordinator().afterStatementExecution();
 							}
 						}
 
 					}
 					i++;
 				}
 
 				LOG.debugf( "Done inserting collection: %s rows inserted", count );
 
 			}
 			else {
 				LOG.debug( "Collection was empty" );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not insert collection: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	protected boolean isRowDeleteEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	@Override
 	public void deleteRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowDeleteEnabled() ) {
 			return;
 		}
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Deleting rows of collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		boolean deleteByIndex = !isOneToMany() && hasIndex && !indexContainsFormula;
 		final Expectation expectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 		try {
 			// delete all the deleted entries
 			Iterator deletes = collection.getDeletes( this, !deleteByIndex );
 			if ( deletes.hasNext() ) {
 				int offset = 1;
 				int count = 0;
 				while ( deletes.hasNext() ) {
 					PreparedStatement st = null;
 					boolean callable = isDeleteCallable();
 					boolean useBatch = expectation.canBeBatched();
 					String sql = getSQLDeleteRowString();
 
 					if ( useBatch ) {
 						if ( deleteBatchKey == null ) {
 							deleteBatchKey = new BasicBatchKey(
 									getRole() + "#DELETE",
 									expectation
 									);
 						}
 						st = session
 								.getJdbcCoordinator()
 								.getBatch( deleteBatchKey )
 								.getBatchStatement( sql, callable );
 					}
 					else {
 						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						expectation.prepare( st );
 
 						Object entry = deletes.next();
 						int loc = offset;
 						if ( hasIdentifier ) {
 							writeIdentifier( st, entry, loc, session );
 						}
 						else {
 							loc = writeKey( st, id, loc, session );
 							if ( deleteByIndex ) {
 								writeIndexToWhere( st, entry, loc, session );
 							}
 							else {
 								writeElementToWhere( st, entry, loc, session );
 							}
 						}
 
 						if ( useBatch ) {
 							session
 									.getJdbcCoordinator()
 									.getBatch( deleteBatchKey )
 									.addToBatch();
 						}
 						else {
 							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 						}
 						count++;
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
 							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
 							session.getJdbcCoordinator().getResourceRegistry().release( st );
 							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 
 					LOG.debugf( "Done deleting collection rows: %s deleted", count );
 				}
 			}
 			else {
 				LOG.debug( "No rows to delete" );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not delete collection rows: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLDeleteRowString()
 			);
 		}
 	}
 
 	protected boolean isRowInsertEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey insertBatchKey;
 
 	@Override
 	public void insertRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowInsertEnabled() ) {
 			return;
 		}
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Inserting rows of collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		try {
 			// insert all the new entries
 			collection.preInsert( this );
 			Iterator entries = collection.entries( this );
 			Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 			boolean callable = isInsertCallable();
 			boolean useBatch = expectation.canBeBatched();
 			String sql = getSQLInsertRowString();
 			int i = 0;
 			int count = 0;
 			while ( entries.hasNext() ) {
 				int offset = 1;
 				Object entry = entries.next();
 				PreparedStatement st = null;
 				if ( collection.needsInserting( entry, i, elementType ) ) {
 
 					if ( useBatch ) {
 						if ( insertBatchKey == null ) {
 							insertBatchKey = new BasicBatchKey(
 									getRole() + "#INSERT",
 									expectation
 									);
 						}
 						if ( st == null ) {
 							st = session
 									.getJdbcCoordinator()
 									.getBatch( insertBatchKey )
 									.getBatchStatement( sql, callable );
 						}
 					}
 					else {
 						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						offset += expectation.prepare( st );
 						// TODO: copy/paste from recreate()
 						offset = writeKey( st, id, offset, session );
 						if ( hasIdentifier ) {
 							offset = writeIdentifier( st, collection.getIdentifier( entry, i ), offset, session );
 						}
 						if ( hasIndex /* && !indexIsFormula */) {
 							offset = writeIndex( st, collection.getIndex( entry, i, this ), offset, session );
 						}
 						writeElement( st, collection.getElement( entry ), offset, session );
 
 						if ( useBatch ) {
 							session.getJdbcCoordinator().getBatch( insertBatchKey ).addToBatch();
 						}
 						else {
 							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 						}
 						collection.afterRowInsert( this, entry, i );
 						count++;
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
 							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
 							session.getJdbcCoordinator().getResourceRegistry().release( st );
 							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 				}
 				i++;
 			}
 			LOG.debugf( "Done inserting rows: %s inserted", count );
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not insert collection rows: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	@Override
 	public String getRole() {
 		return role;
 	}
 
 	public String getOwnerEntityName() {
 		return entityName;
 	}
 
 	@Override
 	public EntityPersister getOwnerEntityPersister() {
 		return ownerPersister;
 	}
 
 	@Override
 	public IdentifierGenerator getIdentifierGenerator() {
 		return identifierGenerator;
 	}
 
 	@Override
 	public Type getIdentifierType() {
 		return identifierType;
 	}
 
 	@Override
 	public boolean hasOrphanDelete() {
 		return hasOrphanDelete;
 	}
 
 	@Override
 	public Type toType(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return indexType;
 		}
 		return elementPropertyMapping.toType( propertyName );
 	}
 
 	@Override
 	public abstract boolean isManyToMany();
 
 	@Override
 	public String getManyToManyFilterFragment(String alias, Map enabledFilters) {
 		StringBuilder buffer = new StringBuilder();
 		manyToManyFilterHelper.render( buffer, elementPersister.getFilterAliasGenerator(alias), enabledFilters );
 
 		if ( manyToManyWhereString != null ) {
 			buffer.append( " and " )
 					.append( StringHelper.replace( manyToManyWhereTemplate, Template.TEMPLATE, alias ) );
 		}
 
 		return buffer.toString();
 	}
 
 	@Override
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return qualify( alias, indexColumnNames, indexFormulaTemplates );
 		}
 		return elementPropertyMapping.toColumns( alias, propertyName );
 	}
 
 	private String[] indexFragments;
 
 	@Override
 	public String[] toColumns(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			if ( indexFragments == null ) {
 				String[] tmp = new String[indexColumnNames.length];
 				for ( int i = 0; i < indexColumnNames.length; i++ ) {
 					tmp[i] = indexColumnNames[i] == null
 							? indexFormulas[i]
 							: indexColumnNames[i];
 					indexFragments = tmp;
 				}
 			}
 			return indexFragments;
 		}
 
 		return elementPropertyMapping.toColumns( propertyName );
 	}
 
 	@Override
 	public Type getType() {
 		return elementPropertyMapping.getType(); // ==elementType ??
 	}
 
 	@Override
 	public String getName() {
 		return getRole();
 	}
 
 	@Override
 	public EntityPersister getElementPersister() {
 		if ( elementPersister == null ) {
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
index 396a111558..d8332ebe97 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
@@ -1,384 +1,382 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.StaticFilterAliasGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.BatchingCollectionInitializerBuilder;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.collection.SubselectCollectionLoader;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.Update;
 import org.hibernate.type.AssociationType;
 
 /**
  * Collection persister for collections of values and many-to-many associations.
  *
  * @author Gavin King
  */
 public class BasicCollectionPersister extends AbstractCollectionPersister {
 
 	public boolean isCascadeDeleteEnabled() {
 		return false;
 	}
 
 	public BasicCollectionPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 		super( collectionBinding, cacheAccessStrategy, creationContext );
 	}
 
 	/**
 	 * Generate the SQL DELETE that deletes all rows
 	 */
 	@Override
     protected String generateDeleteString() {
-		
-		Delete delete = new Delete()
+		final Delete delete = new Delete()
 				.setTableName( qualifiedTableName )
 				.addPrimaryKeyColumns( keyColumnNames );
 		
-		if ( hasWhere ) delete.setWhere( sqlWhereString );
+		if ( hasWhere ) {
+			delete.setWhere( sqlWhereString );
+		}
 		
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			delete.setComment( "delete collection " + getRole() );
 		}
 		
 		return delete.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL INSERT that creates a new row
 	 */
 	@Override
     protected String generateInsertRowString() {
-		
-		Insert insert = new Insert( getDialect() )
+		final Insert insert = new Insert( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames );
 		
-		if ( hasIdentifier) insert.addColumn( identifierColumnName );
+		if ( hasIdentifier) {
+			insert.addColumn( identifierColumnName );
+		}
 		
 		if ( hasIndex /*&& !indexIsFormula*/ ) {
 			insert.addColumns( indexColumnNames, indexColumnIsSettable );
 		}
 		
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			insert.setComment( "insert collection row " + getRole() );
 		}
 		
 		//if ( !elementIsFormula ) {
 			insert.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		//}
 		
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a row
 	 */
 	@Override
     protected String generateUpdateRowString() {
-		
-		Update update = new Update( getDialect() )
+		final Update update = new Update( getDialect() )
 			.setTableName( qualifiedTableName );
 		
 		//if ( !elementIsFormula ) {
 			update.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		//}
 		
 		if ( hasIdentifier ) {
 			update.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
 		}
 		else if ( hasIndex && !indexContainsFormula ) {
 			update.addPrimaryKeyColumns( ArrayHelper.join( keyColumnNames, indexColumnNames ) );
 		}
 		else {
 			update.addPrimaryKeyColumns( keyColumnNames );
 			update.addPrimaryKeyColumns( elementColumnNames, elementColumnIsInPrimaryKey, elementColumnWriters );
 		}
 		
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "update collection row " + getRole() );
 		}
 		
 		return update.toStatementString();
 	}
 	
 	@Override
 	protected void doProcessQueuedOps(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		// nothing to do
 	}
 
 	/**
 	 * Generate the SQL DELETE that deletes a particular row
 	 */
 	@Override
     protected String generateDeleteRowString() {
-		
-		Delete delete = new Delete()
-			.setTableName( qualifiedTableName );
+		final Delete delete = new Delete().setTableName( qualifiedTableName );
 		
 		if ( hasIdentifier ) {
 			delete.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
 		}
 		else if ( hasIndex && !indexContainsFormula ) {
 			delete.addPrimaryKeyColumns( ArrayHelper.join( keyColumnNames, indexColumnNames ) );
 		}
 		else {
 			delete.addPrimaryKeyColumns( keyColumnNames );
 			delete.addPrimaryKeyColumns( elementColumnNames, elementColumnIsInPrimaryKey, elementColumnWriters );
 		}
 		
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			delete.setComment( "delete collection row " + getRole() );
 		}
 		
 		return delete.toStatementString();
 	}
 
 	public boolean consumesEntityAlias() {
 		return false;
 	}
 
 	public boolean consumesCollectionAlias() {
 //		return !isOneToMany();
 		return true;
 	}
 
 	public boolean isOneToMany() {
 		return false;
 	}
 
 	@Override
     public boolean isManyToMany() {
 		return elementType.isEntityType(); //instanceof AssociationType;
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	@Override
-    protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session)
-			throws HibernateException {
-		
-		if ( ArrayHelper.isAllFalse(elementColumnIsSettable) ) return 0;
+    protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session) throws HibernateException {
+		if ( ArrayHelper.isAllFalse(elementColumnIsSettable) ) {
+			return 0;
+		}
 
 		try {
 			PreparedStatement st = null;
 			Expectation expectation = Expectations.appropriateExpectation( getUpdateCheckStyle() );
 			boolean callable = isUpdateCallable();
 			boolean useBatch = expectation.canBeBatched();
 			Iterator entries = collection.entries( this );
 			String sql = getSQLUpdateRowString();
 			int i = 0;
 			int count = 0;
 			while ( entries.hasNext() ) {
 				Object entry = entries.next();
 				if ( collection.needsUpdating( entry, i, elementType ) ) {
 					int offset = 1;
 
 					if ( useBatch ) {
 						if ( updateBatchKey == null ) {
 							updateBatchKey = new BasicBatchKey(
 									getRole() + "#UPDATE",
 									expectation
 							);
 						}
 						st = session
 								.getJdbcCoordinator()
 								.getBatch( updateBatchKey )
 								.getBatchStatement( sql, callable );
 					}
 					else {
 						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						offset+= expectation.prepare( st );
 						int loc = writeElement( st, collection.getElement( entry ), offset, session );
 						if ( hasIdentifier ) {
 							writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 						}
 						else {
 							loc = writeKey( st, id, loc, session );
 							if ( hasIndex && !indexContainsFormula ) {
 								writeIndexToWhere( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 							else {
 								writeElementToWhere( st, collection.getSnapshotElement( entry, i ), loc, session );
 							}
 						}
 
 						if ( useBatch ) {
-							session
-									.getJdbcCoordinator()
+							session.getJdbcCoordinator()
 									.getBatch( updateBatchKey )
 									.addToBatch();
 						}
 						else {
 							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 						}
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
 							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
 							session.getJdbcCoordinator().getResourceRegistry().release( st );
 							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 					count++;
 				}
 				i++;
 			}
 			return count;
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not update collection rows: " + MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLUpdateRowString()
-				);
+			);
 		}
 	}
 
 	public String selectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String entitySuffix,
 	        String collectionSuffix,
 	        boolean includeCollectionColumns) {
 		// we need to determine the best way to know that two joinables
 		// represent a single many-to-many...
 		if ( rhs != null && isManyToMany() && !rhs.isCollection() ) {
 			AssociationType elementType = ( ( AssociationType ) getElementType() );
 			if ( rhs.equals( elementType.getAssociatedJoinable( getFactory() ) ) ) {
 				return manyToManySelectFragment( rhs, rhsAlias, lhsAlias, collectionSuffix );
 			}
 		}
 		return includeCollectionColumns ? selectFragment( lhsAlias, collectionSuffix ) : "";
 	}
 
 	private String manyToManySelectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String collectionSuffix) {
 		SelectFragment frag = generateSelectFragment( lhsAlias, collectionSuffix );
 
 		String[] elementColumnNames = rhs.getKeyColumnNames();
 		frag.addColumns( rhsAlias, elementColumnNames, elementColumnAliases );
 		appendIndexColumns( frag, lhsAlias );
 		appendIdentifierColumns( frag, lhsAlias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); //strip leading ','
 	}
 
 	/**
 	 * Create the <tt>CollectionLoader</tt>
 	 *
 	 * @see org.hibernate.loader.collection.BasicCollectionLoader
 	 */
 	@Override
     protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException {
 		return BatchingCollectionInitializerBuilder.getBuilder( getFactory() )
 				.createBatchingCollectionInitializer( this, batchSize, getFactory(), loadQueryInfluencers );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return "";
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
 		return "";
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return "";
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
 		return "";
 	}
 
 	@Override
     protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
 		return new SubselectCollectionLoader( 
 				this,
 				subselect.toSubselectString( getCollectionType().getLHSPropertyName() ),
 				subselect.getResult(),
 				subselect.getQueryParameters(),
 				subselect.getNamedParameterLocMap(),
 				session.getFactory(),
 				session.getLoadQueryInfluencers() 
 		);
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
 		return new StaticFilterAliasGenerator(rootAlias);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyMapping.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyMapping.java
index 9a6e0f0b69..884ad24f5b 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyMapping.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyMapping.java
@@ -1,123 +1,136 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.collection;
 
 import org.hibernate.QueryException;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * @author Gavin King
  */
 public class CollectionPropertyMapping implements PropertyMapping {
-
 	private final QueryableCollection memberPersister;
 
 	public CollectionPropertyMapping(QueryableCollection memberPersister) {
 		this.memberPersister = memberPersister;
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		if ( propertyName.equals(CollectionPropertyNames.COLLECTION_ELEMENTS) ) {
 			return memberPersister.getElementType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_INDICES) ) {
 			if ( !memberPersister.hasIndex() ) throw new QueryException("unindexed collection before indices()");
 			return memberPersister.getIndexType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_SIZE) ) {
 			return StandardBasicTypes.INTEGER;
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MAX_INDEX) ) {
 			return memberPersister.getIndexType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MIN_INDEX) ) {
 			return memberPersister.getIndexType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MAX_ELEMENT) ) {
 			return memberPersister.getElementType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MIN_ELEMENT) ) {
 			return memberPersister.getElementType();
 		}
 		else {
 			//return memberPersister.getPropertyType(propertyName);
 			throw new QueryException("illegal syntax near collection: " + propertyName);
 		}
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		if ( propertyName.equals(CollectionPropertyNames.COLLECTION_ELEMENTS) ) {
 			return memberPersister.getElementColumnNames(alias);
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_INDICES) ) {
-			if ( !memberPersister.hasIndex() ) throw new QueryException("unindexed collection in indices()");
+			if ( !memberPersister.hasIndex() ) {
+				throw new QueryException("unindexed collection in indices()");
+			}
 			return memberPersister.getIndexColumnNames(alias);
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_SIZE) ) {
 			String[] cols = memberPersister.getKeyColumnNames();
 			return new String[] { "count(" + alias + '.' + cols[0] + ')' };
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MAX_INDEX) ) {
-			if ( !memberPersister.hasIndex() ) throw new QueryException("unindexed collection in maxIndex()");
+			if ( !memberPersister.hasIndex() ) {
+				throw new QueryException("unindexed collection in maxIndex()");
+			}
 			String[] cols = memberPersister.getIndexColumnNames(alias);
-			if ( cols.length!=1 ) throw new QueryException("composite collection index in maxIndex()");
+			if ( cols.length!=1 ) {
+				throw new QueryException("composite collection index in maxIndex()");
+			}
 			return new String[] { "max(" + cols[0] + ')' };
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MIN_INDEX) ) {
-			if ( !memberPersister.hasIndex() ) throw new QueryException("unindexed collection in minIndex()");
+			if ( !memberPersister.hasIndex() ) {
+				throw new QueryException("unindexed collection in minIndex()");
+			}
 			String[] cols = memberPersister.getIndexColumnNames(alias);
-			if ( cols.length!=1 ) throw new QueryException("composite collection index in minIndex()");
+			if ( cols.length!=1 ) {
+				throw new QueryException("composite collection index in minIndex()");
+			}
 			return new String[] { "min(" + cols[0] + ')' };
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MAX_ELEMENT) ) {
 			String[] cols = memberPersister.getElementColumnNames(alias);
-			if ( cols.length!=1 ) throw new QueryException("composite collection element in maxElement()");
+			if ( cols.length!=1 ) {
+				throw new QueryException("composite collection element in maxElement()");
+			}
 			return new String[] { "max(" + cols[0] + ')' };
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MIN_ELEMENT) ) {
 			String[] cols = memberPersister.getElementColumnNames(alias);
-			if ( cols.length!=1 ) throw new QueryException("composite collection element in minElement()");
+			if ( cols.length!=1 ) {
+				throw new QueryException("composite collection element in minElement()");
+			}
 			return new String[] { "min(" + cols[0] + ')' };
 		}
 		else {
 			//return memberPersister.toColumns(alias, propertyName);
 			throw new QueryException("illegal syntax near collection: " + propertyName);
 		}
 	}
 
 	/**
 	 * Given a property path, return the corresponding column name(s).
 	 */
 	public String[] toColumns(String propertyName) throws QueryException, UnsupportedOperationException {
 		throw new UnsupportedOperationException( "References to collections must be define a SQL alias" );
 	}
 
 	public Type getType() {
 		//return memberPersister.getType();
 		return memberPersister.getCollectionType();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
index 9532169fe1..f45f2abf0f 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
@@ -1,562 +1,567 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.BatchingCollectionInitializerBuilder;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.collection.SubselectOneToManyLoader;
 import org.hibernate.loader.entity.CollectionElementLoader;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 
 /**
  * Collection persister for one-to-many associations.
  *
  * @author Gavin King
  * @author Brett Meyer
  */
 public class OneToManyPersister extends AbstractCollectionPersister {
 
 	private final boolean cascadeDeleteEnabled;
 	private final boolean keyIsNullable;
 	private final boolean keyIsUpdateable;
 
 	@Override
     protected boolean isRowDeleteEnabled() {
 		return keyIsUpdateable && keyIsNullable;
 	}
 
 	@Override
     protected boolean isRowInsertEnabled() {
 		return keyIsUpdateable;
 	}
 
 	public boolean isCascadeDeleteEnabled() {
 		return cascadeDeleteEnabled;
 	}
 
 	public OneToManyPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 		super( collectionBinding, cacheAccessStrategy, creationContext );
 		cascadeDeleteEnabled = collectionBinding.getKey().isCascadeDeleteEnabled()
 				&& creationContext.getSessionFactory().getDialect().supportsCascadeDelete();
 		keyIsNullable = collectionBinding.getKey().isNullable();
 		keyIsUpdateable = collectionBinding.getKey().isUpdateable();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates all the foreign keys to null
 	 */
 	@Override
     protected String generateDeleteString() {
-		
-		Update update = new Update( getDialect() )
+		final Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames, "null" )
 				.addPrimaryKeyColumns( keyColumnNames );
 		
-		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames, "null" );
+		if ( hasIndex && !indexContainsFormula ) {
+			update.addColumns( indexColumnNames, "null" );
+		}
 		
-		if ( hasWhere ) update.setWhere( sqlWhereString );
+		if ( hasWhere ) {
+			update.setWhere( sqlWhereString );
+		}
 		
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "delete one-to-many " + getRole() );
 		}
 		
 		return update.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a foreign key to a value
 	 */
 	@Override
     protected String generateInsertRowString() {
-		
-		Update update = new Update( getDialect() )
+		final Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames );
 		
-		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames );
+		if ( hasIndex && !indexContainsFormula ) {
+			update.addColumns( indexColumnNames );
+		}
 		
 		//identifier collections not supported for 1-to-many
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "create one-to-many row " + getRole() );
 		}
 		
 		return update.addPrimaryKeyColumns( elementColumnNames, elementColumnWriters )
 				.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that inserts a collection index
 	 */
 	@Override
     protected String generateUpdateRowString() {
-		Update update = new Update( getDialect() ).setTableName( qualifiedTableName );
+		final Update update = new Update( getDialect() ).setTableName( qualifiedTableName );
 		update.addPrimaryKeyColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		if ( hasIdentifier ) {
 			update.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
 		}
 		if ( hasIndex && !indexContainsFormula ) {
 			update.addColumns( indexColumnNames );
 		}
 		
 		return update.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a particular row's foreign
 	 * key to null
 	 */
 	@Override
     protected String generateDeleteRowString() {
-		
-		Update update = new Update( getDialect() )
+		final Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames, "null" );
 		
-		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames, "null" );
+		if ( hasIndex && !indexContainsFormula ) {
+			update.addColumns( indexColumnNames, "null" );
+		}
 		
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "delete one-to-many row " + getRole() );
 		}
 		
 		//use a combination of foreign key columns and pk columns, since
 		//the ordering of removal and addition is not guaranteed when
 		//a child moves from one parent to another
 		String[] rowSelectColumnNames = ArrayHelper.join( keyColumnNames, elementColumnNames );
 		return update.addPrimaryKeyColumns( rowSelectColumnNames )
 				.toStatementString();
 	}
 	
 	@Override
 	public void recreate(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		super.recreate( collection, id, session );
 		writeIndex( collection, collection.entries( this ), id, true, session );
 	}
 	
 	@Override
 	public void insertRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		super.insertRows( collection, id, session );
 		writeIndex( collection, collection.entries( this ), id, true, session );
 	}
 	
 	@Override
 	protected void doProcessQueuedOps(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		writeIndex( collection, collection.queuedAdditionIterator(), id, false, session );
 	}
 
 	private void writeIndex(
 			PersistentCollection collection,
 			Iterator entries,
 			Serializable id,
 			boolean resetIndex,
 			SessionImplementor session) {
 		// If one-to-many and inverse, still need to create the index.  See HHH-5732.
 		if ( isInverse && hasIndex && !indexContainsFormula ) {
 			try {
 				if ( entries.hasNext() ) {
 					int nextIndex = resetIndex ? 0 : getSize( id, session );
 					Expectation expectation = Expectations.appropriateExpectation( getUpdateCheckStyle() );
 					while ( entries.hasNext() ) {
 
 						final Object entry = entries.next();
 						if ( entry != null && collection.entryExists( entry, nextIndex ) ) {
 							int offset = 1;
 							PreparedStatement st = null;
 							boolean callable = isUpdateCallable();
 							boolean useBatch = expectation.canBeBatched();
 							String sql = getSQLUpdateRowString();
 
 							if ( useBatch ) {
 								if ( recreateBatchKey == null ) {
 									recreateBatchKey = new BasicBatchKey(
 											getRole() + "#RECREATE",
 											expectation
 											);
 								}
 								st = session
 										.getJdbcCoordinator()
 										.getBatch( recreateBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
 								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							try {
 								offset += expectation.prepare( st );
 								if ( hasIdentifier ) {
 									offset = writeIdentifier( st, collection.getIdentifier( entry, nextIndex ), offset, session );
 								}
 								offset = writeIndex( st, collection.getIndex( entry, nextIndex, this ), offset, session );
 								offset = writeElement( st, collection.getElement( entry ), offset, session );
 
 								if ( useBatch ) {
-									session
-											.getJdbcCoordinator()
+									session.getJdbcCoordinator()
 											.getBatch( recreateBatchKey )
 											.addToBatch();
 								}
 								else {
 									expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 								}
 							}
 							catch ( SQLException sqle ) {
 								if ( useBatch ) {
 									session.getJdbcCoordinator().abortBatch();
 								}
 								throw sqle;
 							}
 							finally {
 								if ( !useBatch ) {
 									session.getJdbcCoordinator().getResourceRegistry().release( st );
 									session.getJdbcCoordinator().afterStatementExecution();
 								}
 							}
 
 						}
 						nextIndex++;
 					}
 				}
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not update collection: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLUpdateRowString()
-						);
+				);
 			}
 		}
 	}
 
 	public boolean consumesEntityAlias() {
 		return true;
 	}
 	public boolean consumesCollectionAlias() {
 		return true;
 	}
 
 	public boolean isOneToMany() {
 		return true;
 	}
 
 	@Override
     public boolean isManyToMany() {
 		return false;
 	}
 
 	private BasicBatchKey deleteRowBatchKey;
 	private BasicBatchKey insertRowBatchKey;
 
 	@Override
     protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session) {
 
 		// we finish all the "removes" first to take care of possible unique
 		// constraints and so that we can take better advantage of batching
 		
 		try {
 			int count = 0;
 			if ( isRowDeleteEnabled() ) {
 				final Expectation deleteExpectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 				final boolean useBatch = deleteExpectation.canBeBatched();
 				if ( useBatch && deleteRowBatchKey == null ) {
 					deleteRowBatchKey = new BasicBatchKey(
 							getRole() + "#DELETEROW",
 							deleteExpectation
 					);
 				}
 				final String sql = getSQLDeleteRowString();
 
 				PreparedStatement st = null;
 				// update removed rows fks to null
 				try {
 					int i = 0;
 					Iterator entries = collection.entries( this );
 					int offset = 1;
 					while ( entries.hasNext() ) {
 						Object entry = entries.next();
 						if ( collection.needsUpdating( entry, i, elementType ) ) {  // will still be issued when it used to be null
 							if ( useBatch ) {
 								st = session
 										.getJdbcCoordinator()
 										.getBatch( deleteRowBatchKey )
 										.getBatchStatement( sql, isDeleteCallable() );
 							}
 							else {
 								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, isDeleteCallable() );
 							}
 							int loc = writeKey( st, id, offset, session );
 							writeElementToWhere( st, collection.getSnapshotElement(entry, i), loc, session );
 							if ( useBatch ) {
 								session
 										.getJdbcCoordinator()
 										.getBatch( deleteRowBatchKey )
 										.addToBatch();
 							}
 							else {
 								deleteExpectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 							count++;
 						}
 						i++;
 					}
 				}
 				catch ( SQLException e ) {
 					if ( useBatch ) {
 						session.getJdbcCoordinator().abortBatch();
 					}
 					throw e;
 				}
 				finally {
 					if ( !useBatch ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( st );
 						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 			}
 			
 			if ( isRowInsertEnabled() ) {
 				final Expectation insertExpectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				boolean useBatch = insertExpectation.canBeBatched();
 				boolean callable = isInsertCallable();
 				if ( useBatch && insertRowBatchKey == null ) {
 					insertRowBatchKey = new BasicBatchKey(
 							getRole() + "#INSERTROW",
 							insertExpectation
 					);
 				}
 				final String sql = getSQLInsertRowString();
 
 				PreparedStatement st = null;
 				// now update all changed or added rows fks
 				try {
 					int i = 0;
 					Iterator entries = collection.entries( this );
 					while ( entries.hasNext() ) {
 						Object entry = entries.next();
 						int offset = 1;
 						if ( collection.needsUpdating( entry, i, elementType ) ) {
 							if ( useBatch ) {
 								st = session
 										.getJdbcCoordinator()
 										.getBatch( insertRowBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
 								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							offset += insertExpectation.prepare( st );
 
 							int loc = writeKey( st, id, offset, session );
 							if ( hasIndex && !indexContainsFormula ) {
 								loc = writeIndexToWhere( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 
 							writeElementToWhere( st, collection.getElement( entry ), loc, session );
 
 							if ( useBatch ) {
 								session.getJdbcCoordinator().getBatch( insertRowBatchKey ).addToBatch();
 							}
 							else {
 								insertExpectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 							count++;
 						}
 						i++;
 					}
 				}
 				catch ( SQLException sqle ) {
 					if ( useBatch ) {
 						session.getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( st );
 						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 			}
 
 			return count;
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not update collection rows: " + 
 					MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	public String selectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String entitySuffix,
 	        String collectionSuffix,
 	        boolean includeCollectionColumns) {
 		StringBuilder buf = new StringBuilder();
 		if ( includeCollectionColumns ) {
 //			buf.append( selectFragment( lhsAlias, "" ) )//ignore suffix for collection columns!
 			buf.append( selectFragment( lhsAlias, collectionSuffix ) )
 					.append( ", " );
 		}
 		OuterJoinLoadable ojl = ( OuterJoinLoadable ) getElementPersister();
 		return buf.append( ojl.selectFragment( lhsAlias, entitySuffix ) )//use suffix for the entity columns
 				.toString();
 	}
 
 	/**
 	 * Create the <tt>OneToManyLoader</tt>
 	 *
 	 * @see org.hibernate.loader.collection.OneToManyLoader
 	 */
 	@Override
     protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException {
 		return BatchingCollectionInitializerBuilder.getBuilder( getFactory() )
 				.createBatchingOneToManyInitializer( this, batchSize, getFactory(), loadQueryInfluencers );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return ( (Joinable) getElementPersister() ).fromJoinFragment( alias, innerJoin, includeSubclasses );
 	}
 
 	@Override
 	public String fromJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		return ( (Joinable) getElementPersister() ).fromJoinFragment( alias, innerJoin, includeSubclasses, treatAsDeclarations );
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return ( (Joinable) getElementPersister() ).whereJoinFragment( alias, innerJoin, includeSubclasses );
 	}
 
 	@Override
 	public String whereJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		return ( (Joinable) getElementPersister() ).whereJoinFragment( alias, innerJoin, includeSubclasses, treatAsDeclarations );
 	}
 
 	@Override
     public String getTableName() {
 		return ( (Joinable) getElementPersister() ).getTableName();
 	}
 
 	@Override
     public String filterFragment(String alias) throws MappingException {
 		String result = super.filterFragment( alias );
 		if ( getElementPersister() instanceof Joinable ) {
 			result += ( ( Joinable ) getElementPersister() ).oneToManyFilterFragment( alias );
 		}
 		return result;
 
 	}
 
 	@Override
 	protected String filterFragment(String alias, Set<String> treatAsDeclarations) throws MappingException {
 		String result = super.filterFragment( alias );
 		if ( getElementPersister() instanceof Joinable ) {
 			result += ( ( Joinable ) getElementPersister() ).oneToManyFilterFragment( alias, treatAsDeclarations );
 		}
 		return result;
 	}
 
 	@Override
     protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
 		return new SubselectOneToManyLoader( 
 				this,
 				subselect.toSubselectString( getCollectionType().getLHSPropertyName() ),
 				subselect.getResult(),
 				subselect.getQueryParameters(),
 				subselect.getNamedParameterLocMap(),
 				session.getFactory(),
 				session.getLoadQueryInfluencers()
 			);
 	}
 
 	@Override
     public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
 		return new CollectionElementLoader( this, getFactory(), session.getLoadQueryInfluencers() )
 				.loadElement( session, key, incrementIndexByBase(index) );
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
 		return getElementPersister().getFilterAliasGenerator(rootAlias);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
index d2062ee53c..cf5e286bb3 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
@@ -1,5113 +1,5129 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.bytecode.spi.EntityInstrumentationMetadata;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.cache.spi.entry.ReferenceCacheEntryImpl;
 import org.hibernate.cache.spi.entry.StandardCacheEntryImpl;
 import org.hibernate.cache.spi.entry.StructuredCacheEntry;
 import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.internal.CacheHelper;
 import org.hibernate.engine.internal.MutableEntityEntryFactory;
 import org.hibernate.engine.internal.ImmutableEntityEntryFactory;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.internal.Versioning;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.CachedNaturalIdValueSource;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadingActions;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityEntryFactory;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.PersistenceContext.NaturalIdHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.ValueInclusion;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.id.insert.Binder;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.jdbc.TooManyRowsAffectedException;
 import org.hibernate.loader.entity.BatchingEntityLoaderBuilder;
 import org.hibernate.loader.entity.CascadeEntityLoader;
 import org.hibernate.loader.entity.EntityLoader;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.persister.walking.internal.EntityIdentifierDefinitionHelper;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.EntityIdentifierDefinition;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.property.BackrefPropertyAccessor;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.sql.Select;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.Update;
 import org.hibernate.tuple.GenerationTiming;
 import org.hibernate.tuple.InDatabaseValueGenerationStrategy;
 import org.hibernate.tuple.InMemoryValueGenerationStrategy;
 import org.hibernate.tuple.NonIdentifierAttribute;
 import org.hibernate.tuple.ValueGeneration;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 import org.hibernate.type.VersionType;
 import org.jboss.logging.Logger;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 /**
  * Basic functionality for persisting an entity via JDBC
  * through either generated or custom SQL
  *
  * @author Gavin King
  */
 public abstract class AbstractEntityPersister
 		implements OuterJoinLoadable, Queryable, ClassMetadata, UniqueKeyLoadable,
 		SQLLoadable, LazyPropertyInitializer, PostInsertIdentityPersister, Lockable {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, AbstractEntityPersister.class.getName() );
 
 	public static final String ENTITY_CLASS = "class";
 
 	// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final SessionFactoryImplementor factory;
 	private final EntityRegionAccessStrategy cacheAccessStrategy;
 	private final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy;
 	private final boolean isLazyPropertiesCacheable;
 	private final CacheEntryHelper cacheEntryHelper;
 	private final EntityMetamodel entityMetamodel;
 	private final EntityTuplizer entityTuplizer;
 	private final EntityEntryFactory entityEntryFactory;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private final String[] rootTableKeyColumnNames;
 	private final String[] rootTableKeyColumnReaders;
 	private final String[] rootTableKeyColumnReaderTemplates;
 	private final String[] identifierAliases;
 	private final int identifierColumnSpan;
 	private final String versionColumnName;
 	private final boolean hasFormulaProperties;
 	private final int batchSize;
 	private final boolean hasSubselectLoadableCollections;
 	protected final String rowIdName;
 
 	private final Set lazyProperties;
 
 	// The optional SQL string defined in the where attribute
 	private final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	//information about properties of this class,
 	//including inherited properties
 	//(only really needed for updatable/insertable properties)
 	private final int[] propertyColumnSpans;
 	private final String[] propertySubclassNames;
 	private final String[][] propertyColumnAliases;
 	private final String[][] propertyColumnNames;
 	private final String[][] propertyColumnFormulaTemplates;
 	private final String[][] propertyColumnReaderTemplates;
 	private final String[][] propertyColumnWriters;
 	private final boolean[][] propertyColumnUpdateable;
 	private final boolean[][] propertyColumnInsertable;
 	private final boolean[] propertyUniqueness;
 	private final boolean[] propertySelectable;
 	
 	private final List<Integer> lobProperties = new ArrayList<Integer>();
 
 	//information about lazy properties of this class
 	private final String[] lazyPropertyNames;
 	private final int[] lazyPropertyNumbers;
 	private final Type[] lazyPropertyTypes;
 	private final String[][] lazyPropertyColumnAliases;
 
 	//information about all properties in class hierarchy
 	private final String[] subclassPropertyNameClosure;
 	private final String[] subclassPropertySubclassNameClosure;
 	private final Type[] subclassPropertyTypeClosure;
 	private final String[][] subclassPropertyFormulaTemplateClosure;
 	private final String[][] subclassPropertyColumnNameClosure;
 	private final String[][] subclassPropertyColumnReaderClosure;
 	private final String[][] subclassPropertyColumnReaderTemplateClosure;
 	private final FetchMode[] subclassPropertyFetchModeClosure;
 	private final boolean[] subclassPropertyNullabilityClosure;
 	private final boolean[] propertyDefinedOnSubclass;
 	private final int[][] subclassPropertyColumnNumberClosure;
 	private final int[][] subclassPropertyFormulaNumberClosure;
 	private final CascadeStyle[] subclassPropertyCascadeStyleClosure;
 
 	//information about all columns/formulas in class hierarchy
 	private final String[] subclassColumnClosure;
 	private final boolean[] subclassColumnLazyClosure;
 	private final String[] subclassColumnAliasClosure;
 	private final boolean[] subclassColumnSelectableClosure;
 	private final String[] subclassColumnReaderTemplateClosure;
 	private final String[] subclassFormulaClosure;
 	private final String[] subclassFormulaTemplateClosure;
 	private final String[] subclassFormulaAliasClosure;
 	private final boolean[] subclassFormulaLazyClosure;
 
 	// dynamic filters attached to the class-level
 	private final FilterHelper filterHelper;
 
 	private final Set<String> affectingFetchProfileNames = new HashSet<String>();
 
 	private final Map uniqueKeyLoaders = new HashMap();
 	private final Map lockers = new HashMap();
 	private final Map loaders = new HashMap();
 
 	// SQL strings
 	private String sqlVersionSelectString;
 	private String sqlSnapshotSelectString;
 	private String sqlLazySelectString;
 
 	private String sqlIdentityInsertString;
 	private String sqlUpdateByRowIdString;
 	private String sqlLazyUpdateByRowIdString;
 
 	private String[] sqlDeleteStrings;
 	private String[] sqlInsertStrings;
 	private String[] sqlUpdateStrings;
 	private String[] sqlLazyUpdateStrings;
 
 	private String sqlInsertGeneratedValuesSelectString;
 	private String sqlUpdateGeneratedValuesSelectString;
 
 	//Custom SQL (would be better if these were private)
 	protected boolean[] insertCallable;
 	protected boolean[] updateCallable;
 	protected boolean[] deleteCallable;
 	protected String[] customSQLInsert;
 	protected String[] customSQLUpdate;
 	protected String[] customSQLDelete;
 	protected ExecuteUpdateResultCheckStyle[] insertResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] updateResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] deleteResultCheckStyles;
 
 	private InsertGeneratedIdentifierDelegate identityDelegate;
 
 	private boolean[] tableHasColumns;
 
 	private final String loaderName;
 
 	private UniqueEntityLoader queryLoader;
 
 	private final Map subclassPropertyAliases = new HashMap();
 	private final Map subclassPropertyColumnNames = new HashMap();
 
 	protected final BasicEntityPropertyMapping propertyMapping;
 
 	private final boolean useReferenceCacheEntries;
 
 	protected void addDiscriminatorToInsert(Insert insert) {}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {}
 
 	protected abstract int[] getSubclassColumnTableNumberClosure();
 
 	protected abstract int[] getSubclassFormulaTableNumberClosure();
 
 	public abstract String getSubclassTableName(int j);
 
 	protected abstract String[] getSubclassTableKeyColumns(int j);
 
 	protected abstract boolean isClassOrSuperclassTable(int j);
 
 	protected abstract int getSubclassTableSpan();
 
 	protected abstract int getTableSpan();
 
 	protected abstract boolean isTableCascadeDeleteEnabled(int j);
 
 	protected abstract String getTableName(int j);
 
 	protected abstract String[] getKeyColumns(int j);
 
 	protected abstract boolean isPropertyOfTable(int property, int j);
 
 	protected abstract int[] getPropertyTableNumbersInSelect();
 
 	protected abstract int[] getPropertyTableNumbers();
 
 	protected abstract int getSubclassPropertyTableNumber(int i);
 
 	protected abstract String filterFragment(String alias) throws MappingException;
 
 	protected abstract String filterFragment(String alias, Set<String> treatAsDeclarations);
 
 	private static final String DISCRIMINATOR_ALIAS = "clazz_";
 
 	public String getDiscriminatorColumnName() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaderTemplate() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorAlias() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return null;
 	}
 
 	protected boolean isInverseTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableSubclassTable(int j) {
 		return false;
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return false;
 	}
 
 	public boolean isSubclassEntityName(String entityName) {
 		return entityMetamodel.getSubclassEntityNames().contains(entityName);
 	}
 
 	private boolean[] getTableHasColumns() {
 		return tableHasColumns;
 	}
 
 	public String[] getRootTableKeyColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	protected String[] getSQLUpdateByRowIdStrings() {
 		if ( sqlUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan() + 1];
 		result[0] = sqlUpdateByRowIdString;
 		System.arraycopy( sqlUpdateStrings, 0, result, 1, getTableSpan() );
 		return result;
 	}
 
 	protected String[] getSQLLazyUpdateByRowIdStrings() {
 		if ( sqlLazyUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan()];
 		result[0] = sqlLazyUpdateByRowIdString;
 		for ( int i = 1; i < getTableSpan(); i++ ) {
 			result[i] = sqlLazyUpdateStrings[i];
 		}
 		return result;
 	}
 
 	protected String getSQLSnapshotSelectString() {
 		return sqlSnapshotSelectString;
 	}
 
 	protected String getSQLLazySelectString() {
 		return sqlLazySelectString;
 	}
 
 	protected String[] getSQLDeleteStrings() {
 		return sqlDeleteStrings;
 	}
 
 	protected String[] getSQLInsertStrings() {
 		return sqlInsertStrings;
 	}
 
 	protected String[] getSQLUpdateStrings() {
 		return sqlUpdateStrings;
 	}
 
 	protected String[] getSQLLazyUpdateStrings() {
 		return sqlLazyUpdateStrings;
 	}
 
 	/**
 	 * The query that inserts a row, letting the database generate an id
 	 *
 	 * @return The IDENTITY-based insertion query.
 	 */
 	protected String getSQLIdentityInsertString() {
 		return sqlIdentityInsertString;
 	}
 
 	protected String getVersionSelectString() {
 		return sqlVersionSelectString;
 	}
 
 	protected boolean isInsertCallable(int j) {
 		return insertCallable[j];
 	}
 
 	protected boolean isUpdateCallable(int j) {
 		return updateCallable[j];
 	}
 
 	protected boolean isDeleteCallable(int j) {
 		return deleteCallable[j];
 	}
 
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return false;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return false;
 	}
 
 	public boolean hasSequentialSelect() {
 		return false;
 	}
 
 	/**
 	 * Decide which tables need to be updated.
 	 * <p/>
 	 * The return here is an array of boolean values with each index corresponding
 	 * to a given table in the scope of this persister.
 	 *
 	 * @param dirtyProperties The indices of all the entity properties considered dirty.
 	 * @param hasDirtyCollection Whether any collections owned by the entity which were considered dirty.
 	 *
 	 * @return Array of booleans indicating which table require updating.
 	 */
 	protected boolean[] getTableUpdateNeeded(final int[] dirtyProperties, boolean hasDirtyCollection) {
 
 		if ( dirtyProperties == null ) {
 			return getTableHasColumns(); // for objects that came in via update()
 		}
 		else {
 			boolean[] updateability = getPropertyUpdateability();
 			int[] propertyTableNumbers = getPropertyTableNumbers();
 			boolean[] tableUpdateNeeded = new boolean[ getTableSpan() ];
 			for ( int i = 0; i < dirtyProperties.length; i++ ) {
 				int property = dirtyProperties[i];
 				int table = propertyTableNumbers[property];
 				tableUpdateNeeded[table] = tableUpdateNeeded[table] ||
 						( getPropertyColumnSpan(property) > 0 && updateability[property] );
 			}
 			if ( isVersioned() ) {
 				tableUpdateNeeded[0] = tableUpdateNeeded[0] ||
 					Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
 			}
 			return tableUpdateNeeded;
 		}
 	}
 
 	public boolean hasRowId() {
 		return rowIdName != null;
 	}
 
 	protected boolean[][] getPropertyColumnUpdateable() {
 		return propertyColumnUpdateable;
 	}
 
 	protected boolean[][] getPropertyColumnInsertable() {
 		return propertyColumnInsertable;
 	}
 
 	protected boolean[] getPropertySelectable() {
 		return propertySelectable;
 	}
 
 	public AbstractEntityPersister(
 			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final PersisterCreationContext creationContext) throws HibernateException {
 
 		// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		this.factory = creationContext.getSessionFactory();
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		this.naturalIdRegionAccessStrategy = naturalIdRegionAccessStrategy;
 		isLazyPropertiesCacheable = persistentClass.isLazyPropertiesCacheable();
 
 		this.entityMetamodel = new EntityMetamodel( persistentClass, this, factory );
 		this.entityTuplizer = this.entityMetamodel.getTuplizer();
 
 		if( entityMetamodel.isMutable() ) {
 			this.entityEntryFactory = MutableEntityEntryFactory.INSTANCE;
 		}
 		else {
 			this.entityEntryFactory = ImmutableEntityEntryFactory.INSTANCE;
 		}
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		int batch = persistentClass.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 		hasSubselectLoadableCollections = persistentClass.hasSubselectLoadableCollections();
 
 		propertyMapping = new BasicEntityPropertyMapping( this );
 
 		// IDENTIFIER
 
 		identifierColumnSpan = persistentClass.getIdentifier().getColumnSpan();
 		rootTableKeyColumnNames = new String[identifierColumnSpan];
 		rootTableKeyColumnReaders = new String[identifierColumnSpan];
 		rootTableKeyColumnReaderTemplates = new String[identifierColumnSpan];
 		identifierAliases = new String[identifierColumnSpan];
 
 		rowIdName = persistentClass.getRootTable().getRowId();
 
 		loaderName = persistentClass.getLoaderName();
 
 		Iterator iter = persistentClass.getIdentifier().getColumnIterator();
 		int i = 0;
 		while ( iter.hasNext() ) {
 			Column col = ( Column ) iter.next();
 			rootTableKeyColumnNames[i] = col.getQuotedName( factory.getDialect() );
 			rootTableKeyColumnReaders[i] = col.getReadExpr( factory.getDialect() );
 			rootTableKeyColumnReaderTemplates[i] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 			identifierAliases[i] = col.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 			i++;
 		}
 
 		// VERSION
 
 		if ( persistentClass.isVersioned() ) {
 			versionColumnName = ( ( Column ) persistentClass.getVersion().getColumnIterator().next() ).getQuotedName( factory.getDialect() );
 		}
 		else {
 			versionColumnName = null;
 		}
 
 		//WHERE STRING
 
 		sqlWhereString = StringHelper.isNotEmpty( persistentClass.getWhere() ) ? "( " + persistentClass.getWhere() + ") " : null;
 		sqlWhereStringTemplate = sqlWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( sqlWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		// PROPERTIES
 
 		final boolean lazyAvailable = isInstrumented();
 
 		int hydrateSpan = entityMetamodel.getPropertySpan();
 		propertyColumnSpans = new int[hydrateSpan];
 		propertySubclassNames = new String[hydrateSpan];
 		propertyColumnAliases = new String[hydrateSpan][];
 		propertyColumnNames = new String[hydrateSpan][];
 		propertyColumnFormulaTemplates = new String[hydrateSpan][];
 		propertyColumnReaderTemplates = new String[hydrateSpan][];
 		propertyColumnWriters = new String[hydrateSpan][];
 		propertyUniqueness = new boolean[hydrateSpan];
 		propertySelectable = new boolean[hydrateSpan];
 		propertyColumnUpdateable = new boolean[hydrateSpan][];
 		propertyColumnInsertable = new boolean[hydrateSpan][];
 		HashSet thisClassProperties = new HashSet();
 
 		lazyProperties = new HashSet();
 		ArrayList lazyNames = new ArrayList();
 		ArrayList lazyNumbers = new ArrayList();
 		ArrayList lazyTypes = new ArrayList();
 		ArrayList lazyColAliases = new ArrayList();
 
 		iter = persistentClass.getPropertyClosureIterator();
 		i = 0;
 		boolean foundFormula = false;
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			thisClassProperties.add( prop );
 
 			int span = prop.getColumnSpan();
 			propertyColumnSpans[i] = span;
 			propertySubclassNames[i] = prop.getPersistentClass().getEntityName();
 			String[] colNames = new String[span];
 			String[] colAliases = new String[span];
 			String[] colReaderTemplates = new String[span];
 			String[] colWriters = new String[span];
 			String[] formulaTemplates = new String[span];
 			Iterator colIter = prop.getColumnIterator();
 			int k = 0;
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				colAliases[k] = thing.getAlias( factory.getDialect() , prop.getValue().getTable() );
 				if ( thing.isFormula() ) {
 					foundFormula = true;
 					formulaTemplates[k] = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				}
 				else {
 					Column col = (Column)thing;
 					colNames[k] = col.getQuotedName( factory.getDialect() );
 					colReaderTemplates[k] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					colWriters[k] = col.getWriteExpr();
 				}
 				k++;
 			}
 			propertyColumnNames[i] = colNames;
 			propertyColumnFormulaTemplates[i] = formulaTemplates;
 			propertyColumnReaderTemplates[i] = colReaderTemplates;
 			propertyColumnWriters[i] = colWriters;
 			propertyColumnAliases[i] = colAliases;
 
 			if ( lazyAvailable && prop.isLazy() ) {
 				lazyProperties.add( prop.getName() );
 				lazyNames.add( prop.getName() );
 				lazyNumbers.add( i );
 				lazyTypes.add( prop.getValue().getType() );
 				lazyColAliases.add( colAliases );
 			}
 
 			propertyColumnUpdateable[i] = prop.getValue().getColumnUpdateability();
 			propertyColumnInsertable[i] = prop.getValue().getColumnInsertability();
 
 			propertySelectable[i] = prop.isSelectable();
 
 			propertyUniqueness[i] = prop.getValue().isAlternateUniqueKey();
 			
 			if (prop.isLob() && getFactory().getDialect().forceLobAsLastValue() ) {
 				lobProperties.add( i );
 			}
 
 			i++;
 
 		}
 		hasFormulaProperties = foundFormula;
 		lazyPropertyColumnAliases = ArrayHelper.to2DStringArray( lazyColAliases );
 		lazyPropertyNames = ArrayHelper.toStringArray( lazyNames );
 		lazyPropertyNumbers = ArrayHelper.toIntArray( lazyNumbers );
 		lazyPropertyTypes = ArrayHelper.toTypeArray( lazyTypes );
 
 		// SUBCLASS PROPERTY CLOSURE
 
 		ArrayList columns = new ArrayList();
 		ArrayList columnsLazy = new ArrayList();
 		ArrayList columnReaderTemplates = new ArrayList();
 		ArrayList aliases = new ArrayList();
 		ArrayList formulas = new ArrayList();
 		ArrayList formulaAliases = new ArrayList();
 		ArrayList formulaTemplates = new ArrayList();
 		ArrayList formulasLazy = new ArrayList();
 		ArrayList types = new ArrayList();
 		ArrayList names = new ArrayList();
 		ArrayList classes = new ArrayList();
 		ArrayList templates = new ArrayList();
 		ArrayList propColumns = new ArrayList();
 		ArrayList propColumnReaders = new ArrayList();
 		ArrayList propColumnReaderTemplates = new ArrayList();
 		ArrayList joinedFetchesList = new ArrayList();
 		ArrayList cascades = new ArrayList();
 		ArrayList definedBySubclass = new ArrayList();
 		ArrayList propColumnNumbers = new ArrayList();
 		ArrayList propFormulaNumbers = new ArrayList();
 		ArrayList columnSelectables = new ArrayList();
 		ArrayList propNullables = new ArrayList();
 
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			names.add( prop.getName() );
 			classes.add( prop.getPersistentClass().getEntityName() );
 			boolean isDefinedBySubclass = !thisClassProperties.contains( prop );
 			definedBySubclass.add( Boolean.valueOf( isDefinedBySubclass ) );
 			propNullables.add( Boolean.valueOf( prop.isOptional() || isDefinedBySubclass ) ); //TODO: is this completely correct?
 			types.add( prop.getType() );
 
 			Iterator colIter = prop.getColumnIterator();
 			String[] cols = new String[prop.getColumnSpan()];
 			String[] readers = new String[prop.getColumnSpan()];
 			String[] readerTemplates = new String[prop.getColumnSpan()];
 			String[] forms = new String[prop.getColumnSpan()];
 			int[] colnos = new int[prop.getColumnSpan()];
 			int[] formnos = new int[prop.getColumnSpan()];
 			int l = 0;
 			Boolean lazy = Boolean.valueOf( prop.isLazy() && lazyAvailable );
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				if ( thing.isFormula() ) {
 					String template = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					formnos[l] = formulaTemplates.size();
 					colnos[l] = -1;
 					formulaTemplates.add( template );
 					forms[l] = template;
 					formulas.add( thing.getText( factory.getDialect() ) );
 					formulaAliases.add( thing.getAlias( factory.getDialect() ) );
 					formulasLazy.add( lazy );
 				}
 				else {
 					Column col = (Column)thing;
 					String colName = col.getQuotedName( factory.getDialect() );
 					colnos[l] = columns.size(); //before add :-)
 					formnos[l] = -1;
 					columns.add( colName );
 					cols[l] = colName;
 					aliases.add( thing.getAlias( factory.getDialect(), prop.getValue().getTable() ) );
 					columnsLazy.add( lazy );
 					columnSelectables.add( Boolean.valueOf( prop.isSelectable() ) );
 
 					readers[l] = col.getReadExpr( factory.getDialect() );
 					String readerTemplate = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					readerTemplates[l] = readerTemplate;
 					columnReaderTemplates.add( readerTemplate );
 				}
 				l++;
 			}
 			propColumns.add( cols );
 			propColumnReaders.add( readers );
 			propColumnReaderTemplates.add( readerTemplates );
 			templates.add( forms );
 			propColumnNumbers.add( colnos );
 			propFormulaNumbers.add( formnos );
 
 			joinedFetchesList.add( prop.getValue().getFetchMode() );
 			cascades.add( prop.getCascadeStyle() );
 		}
 		subclassColumnClosure = ArrayHelper.toStringArray( columns );
 		subclassColumnAliasClosure = ArrayHelper.toStringArray( aliases );
 		subclassColumnLazyClosure = ArrayHelper.toBooleanArray( columnsLazy );
 		subclassColumnSelectableClosure = ArrayHelper.toBooleanArray( columnSelectables );
 		subclassColumnReaderTemplateClosure = ArrayHelper.toStringArray( columnReaderTemplates );
 
 		subclassFormulaClosure = ArrayHelper.toStringArray( formulas );
 		subclassFormulaTemplateClosure = ArrayHelper.toStringArray( formulaTemplates );
 		subclassFormulaAliasClosure = ArrayHelper.toStringArray( formulaAliases );
 		subclassFormulaLazyClosure = ArrayHelper.toBooleanArray( formulasLazy );
 
 		subclassPropertyNameClosure = ArrayHelper.toStringArray( names );
 		subclassPropertySubclassNameClosure = ArrayHelper.toStringArray( classes );
 		subclassPropertyTypeClosure = ArrayHelper.toTypeArray( types );
 		subclassPropertyNullabilityClosure = ArrayHelper.toBooleanArray( propNullables );
 		subclassPropertyFormulaTemplateClosure = ArrayHelper.to2DStringArray( templates );
 		subclassPropertyColumnNameClosure = ArrayHelper.to2DStringArray( propColumns );
 		subclassPropertyColumnReaderClosure = ArrayHelper.to2DStringArray( propColumnReaders );
 		subclassPropertyColumnReaderTemplateClosure = ArrayHelper.to2DStringArray( propColumnReaderTemplates );
 		subclassPropertyColumnNumberClosure = ArrayHelper.to2DIntArray( propColumnNumbers );
 		subclassPropertyFormulaNumberClosure = ArrayHelper.to2DIntArray( propFormulaNumbers );
 
 		subclassPropertyCascadeStyleClosure = new CascadeStyle[cascades.size()];
 		iter = cascades.iterator();
 		int j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyCascadeStyleClosure[j++] = ( CascadeStyle ) iter.next();
 		}
 		subclassPropertyFetchModeClosure = new FetchMode[joinedFetchesList.size()];
 		iter = joinedFetchesList.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyFetchModeClosure[j++] = ( FetchMode ) iter.next();
 		}
 
 		propertyDefinedOnSubclass = new boolean[definedBySubclass.size()];
 		iter = definedBySubclass.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			propertyDefinedOnSubclass[j++] = (Boolean) iter.next();
 		}
 
 		// Handle any filters applied to the class level
 		filterHelper = new FilterHelper( persistentClass.getFilters(), factory );
 
 		// Check if we can use Reference Cached entities in 2lc
 		// todo : should really validate that the cache access type is read-only
 		boolean refCacheEntries = true;
 		if ( ! factory.getSettings().isDirectReferenceCacheEntriesEnabled() ) {
 			refCacheEntries = false;
 		}
 
 		// for now, limit this to just entities that:
 		// 		1) are immutable
 		if ( entityMetamodel.isMutable() ) {
 			refCacheEntries =  false;
 		}
 
 		//		2)  have no associations.  Eventually we want to be a little more lenient with associations.
 		for ( Type type : getSubclassPropertyTypeClosure() ) {
 			if ( type.isAssociationType() ) {
 				refCacheEntries =  false;
 			}
 		}
 
 		useReferenceCacheEntries = refCacheEntries;
 
 		this.cacheEntryHelper = buildCacheEntryHelper();
 
 	}
 
 	protected CacheEntryHelper buildCacheEntryHelper() {
 		if ( cacheAccessStrategy == null ) {
 			// the entity defined no caching...
 			return NoopCacheEntryHelper.INSTANCE;
 		}
 
 		if ( canUseReferenceCacheEntries() ) {
 			entityMetamodel.setLazy( false );
 			// todo : do we also need to unset proxy factory?
 			return new ReferenceCacheEntryHelper( this );
 		}
 
 		return factory.getSettings().isStructuredCacheEntriesEnabled()
 				? new StructuredCacheEntryHelper( this )
 				: new StandardCacheEntryHelper( this );
 	}
 
 	public boolean canUseReferenceCacheEntries() {
 		return useReferenceCacheEntries;
 	}
 
 	protected static String getTemplateFromString(String string, SessionFactoryImplementor factory) {
 		return string == null ?
 				null :
 				Template.renderWhereStringTemplate( string, factory.getDialect(), factory.getSqlFunctionRegistry() );
 	}
 
 	protected String generateLazySelectString() {
 
 		if ( !entityMetamodel.hasLazyProperties() ) {
 			return null;
 		}
 
 		HashSet tableNumbers = new HashSet();
 		ArrayList columnNumbers = new ArrayList();
 		ArrayList formulaNumbers = new ArrayList();
 		for ( int i = 0; i < lazyPropertyNames.length; i++ ) {
 			// all this only really needs to consider properties
 			// of this class, not its subclasses, but since we
 			// are reusing code used for sequential selects, we
 			// use the subclass closure
 			int propertyNumber = getSubclassPropertyIndex( lazyPropertyNames[i] );
 
 			int tableNumber = getSubclassPropertyTableNumber( propertyNumber );
 			tableNumbers.add(  tableNumber );
 
 			int[] colNumbers = subclassPropertyColumnNumberClosure[propertyNumber];
 			for ( int j = 0; j < colNumbers.length; j++ ) {
 				if ( colNumbers[j]!=-1 ) {
 					columnNumbers.add( colNumbers[j] );
 				}
 			}
 			int[] formNumbers = subclassPropertyFormulaNumberClosure[propertyNumber];
 			for ( int j = 0; j < formNumbers.length; j++ ) {
 				if ( formNumbers[j]!=-1 ) {
 					formulaNumbers.add( formNumbers[j] );
 				}
 			}
 		}
 
 		if ( columnNumbers.size()==0 && formulaNumbers.size()==0 ) {
 			// only one-to-one is lazy fetched
 			return null;
 		}
 
-		return renderSelect( ArrayHelper.toIntArray( tableNumbers ),
+		return renderSelect(
+				ArrayHelper.toIntArray( tableNumbers ),
 				ArrayHelper.toIntArray( columnNumbers ),
-				ArrayHelper.toIntArray( formulaNumbers ) );
+				ArrayHelper.toIntArray( formulaNumbers )
+		);
 
 	}
 
 	public Object initializeLazyProperty(String fieldName, Object entity, SessionImplementor session)
 			throws HibernateException {
 
 		final Serializable id = session.getContextEntityIdentifier( entity );
 
 		final EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 		if ( entry == null ) {
 			throw new HibernateException( "entity is not associated with the session: " + id );
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Initializing lazy properties of: {0}, field access: {1}", MessageHelper.infoString( this, id, getFactory() ), fieldName );
 		}
 
 		if ( session.getCacheMode().isGetEnabled() && hasCache() ) {
 			final CacheKey cacheKey = session.generateCacheKey( id, getIdentifierType(), getEntityName() );
 			final Object ce = CacheHelper.fromSharedCache( session, cacheKey, getCacheAccessStrategy() );
 			if ( ce != null ) {
 				final CacheEntry cacheEntry = (CacheEntry) getCacheEntryStructure().destructure(ce, factory);
 				if ( !cacheEntry.areLazyPropertiesUnfetched() ) {
 					//note early exit here:
 					return initializeLazyPropertiesFromCache( fieldName, entity, session, entry, cacheEntry );
 				}
 			}
 		}
 
 		return initializeLazyPropertiesFromDatastore( fieldName, entity, session, id, entry );
 
 	}
 
 	private Object initializeLazyPropertiesFromDatastore(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Serializable id,
 			final EntityEntry entry) {
 
-		if ( !hasLazyProperties() ) throw new AssertionFailure( "no lazy properties" );
+		if ( !hasLazyProperties() ) {
+			throw new AssertionFailure( "no lazy properties" );
+		}
 
 		LOG.trace( "Initializing lazy properties from datastore" );
 
 		try {
 
 			Object result = null;
 			PreparedStatement ps = null;
 			try {
 				final String lazySelect = getSQLLazySelectString();
 				ResultSet rs = null;
 				try {
 					if ( lazySelect != null ) {
 						// null sql means that the only lazy properties
 						// are shared PK one-to-one associations which are
 						// handled differently in the Type#nullSafeGet code...
 						ps = session.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( lazySelect );
 						getIdentifierType().nullSafeSet( ps, id, 1, session );
 						rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 						rs.next();
 					}
 					final Object[] snapshot = entry.getLoadedState();
 					for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 						Object propValue = lazyPropertyTypes[j].nullSafeGet( rs, lazyPropertyColumnAliases[j], session, entity );
 						if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 							result = propValue;
 						}
 					}
 				}
 				finally {
 					if ( rs != null ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 					}
 				}
 			}
 			finally {
 				if ( ps != null ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( ps );
 					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 			LOG.trace( "Done initializing lazy properties" );
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize lazy properties: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getSQLLazySelectString()
 				);
 		}
 	}
 
 	private Object initializeLazyPropertiesFromCache(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final EntityEntry entry,
 			final CacheEntry cacheEntry
 	) {
 
 		LOG.trace( "Initializing lazy properties from second-level cache" );
 
 		Object result = null;
 		Serializable[] disassembledValues = cacheEntry.getDisassembledState();
 		final Object[] snapshot = entry.getLoadedState();
 		for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 			final Object propValue = lazyPropertyTypes[j].assemble(
 					disassembledValues[ lazyPropertyNumbers[j] ],
 					session,
 					entity
 				);
 			if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 				result = propValue;
 			}
 		}
 
 		LOG.trace( "Done initializing lazy properties" );
 
 		return result;
 	}
 
 	private boolean initializeLazyProperty(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Object[] snapshot,
 			final int j,
 			final Object propValue) {
 		setPropertyValue( entity, lazyPropertyNumbers[j], propValue );
 		if ( snapshot != null ) {
 			// object have been loaded with setReadOnly(true); HHH-2236
 			snapshot[ lazyPropertyNumbers[j] ] = lazyPropertyTypes[j].deepCopy( propValue, factory );
 		}
 		return fieldName.equals( lazyPropertyNames[j] );
 	}
 
 	public boolean isBatchable() {
 		return optimisticLockStyle() == OptimisticLockStyle.NONE
 				|| ( !isVersioned() && optimisticLockStyle() == OptimisticLockStyle.VERSION )
 				|| getFactory().getSettings().isJdbcBatchVersionedData();
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return getPropertySpaces();
 	}
 
 	protected Set getLazyProperties() {
 		return lazyProperties;
 	}
 
 	public boolean isBatchLoadable() {
 		return batchSize > 1;
 	}
 
 	public String[] getIdentifierColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		return rootTableKeyColumnReaders;
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		return rootTableKeyColumnReaderTemplates;
 	}
 
 	protected int getIdentifierColumnSpan() {
 		return identifierColumnSpan;
 	}
 
 	protected String[] getIdentifierAliases() {
 		return identifierAliases;
 	}
 
 	public String getVersionColumnName() {
 		return versionColumnName;
 	}
 
 	protected String getVersionedTableName() {
 		return getTableName( 0 );
 	}
 
 	protected boolean[] getSubclassColumnLazyiness() {
 		return subclassColumnLazyClosure;
 	}
 
 	protected boolean[] getSubclassFormulaLazyiness() {
 		return subclassFormulaLazyClosure;
 	}
 
 	/**
 	 * We can't immediately add to the cache if we have formulas
 	 * which must be evaluated, or if we have the possibility of
 	 * two concurrent updates to the same item being merged on
 	 * the database. This can happen if (a) the item is not
 	 * versioned and either (b) we have dynamic update enabled
 	 * or (c) we have multiple tables holding the state of the
 	 * item.
 	 */
 	public boolean isCacheInvalidationRequired() {
 		return hasFormulaProperties() ||
 				( !isVersioned() && ( entityMetamodel.isDynamicUpdate() || getTableSpan() > 1 ) );
 	}
 
 	public boolean isLazyPropertiesCacheable() {
 		return isLazyPropertiesCacheable;
 	}
 
 	public String selectFragment(String alias, String suffix) {
 		return identifierSelectFragment( alias, suffix ) +
 				propertySelectFragment( alias, suffix, false );
 	}
 
 	public String[] getIdentifierAliases(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getIdentiferColumnNames() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return new Alias( suffix ).toAliasStrings( getIdentifierAliases() );
 	}
 
 	public String[] getPropertyAliases(String suffix, int i) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		return new Alias( suffix ).toUnquotedAliasStrings( propertyColumnAliases[i] );
 	}
 
 	public String getDiscriminatorAlias(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getdiscriminatorColumnName() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return entityMetamodel.hasSubclasses() ?
 				new Alias( suffix ).toAliasString( getDiscriminatorAlias() ) :
 				null;
 	}
 
 	public String identifierSelectFragment(String name, String suffix) {
 		return new SelectFragment()
 				.setSuffix( suffix )
 				.addColumns( name, getIdentifierColumnNames(), getIdentifierAliases() )
 				.toFragmentString()
 				.substring( 2 ); //strip leading ", "
 	}
 
 
 	public String propertySelectFragment(String tableAlias, String suffix, boolean allProperties) {
 		return propertySelectFragmentFragment( tableAlias, suffix, allProperties ).toFragmentString();
 	}
 
 	public SelectFragment propertySelectFragmentFragment(
 			String tableAlias,
 			String suffix,
 			boolean allProperties) {
 		SelectFragment select = new SelectFragment()
 				.setSuffix( suffix )
 				.setUsedAliases( getIdentifierAliases() );
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < getSubclassColumnClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassColumnLazyClosure[i] ) &&
 				!isSubclassTableSequentialSelect( columnTableNumbers[i] ) &&
 				subclassColumnSelectableClosure[i];
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, columnTableNumbers[i] );
 				select.addColumnTemplate( subalias, columnReaderTemplates[i], columnAliases[i] );
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < getSubclassFormulaTemplateClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassFormulaLazyClosure[i] )
 				&& !isSubclassTableSequentialSelect( formulaTableNumbers[i] );
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, formulaTableNumbers[i] );
 				select.addFormula( subalias, formulaTemplates[i], formulaAliases[i] );
 			}
 		}
 
 		if ( entityMetamodel.hasSubclasses() ) {
 			addDiscriminatorToSelect( select, tableAlias, suffix );
 		}
 
 		if ( hasRowId() ) {
 			select.addColumn( tableAlias, rowIdName, ROWID_ALIAS );
 		}
 
 		return select;
 	}
 
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting current persistent state for: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getSQLSnapshotSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				//if ( isVersioned() ) getVersionType().nullSafeSet( ps, version, getIdentifierColumnSpan()+1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					//otherwise return the "hydrated" state (ie. associations are not resolved)
 					Type[] types = getPropertyTypes();
 					Object[] values = new Object[types.length];
 					boolean[] includeProperty = getPropertyUpdateability();
 					for ( int i = 0; i < types.length; i++ ) {
 						if ( includeProperty[i] ) {
 							values[i] = types[i].hydrate( rs, getPropertyAliases( "", i ), session, null ); //null owner ok??
 						}
 					}
 					return values;
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
 			        getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	@Override
 	public Serializable getIdByUniqueKey(Serializable key, String uniquePropertyName, SessionImplementor session) throws HibernateException {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"resolving unique key [%s] to identifier for entity [%s]",
 					key,
 					getEntityName()
 			);
 		}
 
 		int propertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		if ( propertyIndex < 0 ) {
 			throw new HibernateException(
 					"Could not determine Type for property [" + uniquePropertyName + "] on entity [" + getEntityName() + "]"
 			);
 		}
 		Type propertyType = getSubclassPropertyType( propertyIndex );
 
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( generateIdByUniqueKeySelectString( uniquePropertyName ) );
 			try {
 				propertyType.nullSafeSet( ps, key, 1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					return (Serializable) getIdentifierType().nullSafeGet( rs, getIdentifierAliases(), session, null );
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve unique property [%s] to identifier for entity [%s]",
 							uniquePropertyName,
 							getEntityName()
 					),
 					getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	protected String generateIdByUniqueKeySelectString(String uniquePropertyName) {
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "resolve id by unique property [" + getEntityName() + "." + uniquePropertyName + "]" );
 		}
 
 		final String rooAlias = getRootAlias();
 
 		select.setFromClause( fromTableFragment( rooAlias ) + fromJoinFragment( rooAlias, true, false ) );
 
 		SelectFragment selectFragment = new SelectFragment();
 		selectFragment.addColumns( rooAlias, getIdentifierColumnNames(), getIdentifierAliases() );
 		select.setSelectClause( selectFragment );
 
 		StringBuilder whereClauseBuffer = new StringBuilder();
 		final int uniquePropertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		final String uniquePropertyTableAlias = generateTableAlias(
 				rooAlias,
 				getSubclassPropertyTableNumber( uniquePropertyIndex )
 		);
 		String sep = "";
 		for ( String columnTemplate : getSubclassPropertyColumnReaderTemplateClosure()[uniquePropertyIndex] ) {
 			if ( columnTemplate == null ) {
 				continue;
 			}
 			final String columnReference = StringHelper.replace( columnTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
 			whereClauseBuffer.append( sep ).append( columnReference ).append( "=?" );
 			sep = " and ";
 		}
 		for ( String formulaTemplate : getSubclassPropertyFormulaTemplateClosure()[uniquePropertyIndex] ) {
 			if ( formulaTemplate == null ) {
 				continue;
 			}
 			final String formulaReference = StringHelper.replace( formulaTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
 			whereClauseBuffer.append( sep ).append( formulaReference ).append( "=?" );
 			sep = " and ";
 		}
 		whereClauseBuffer.append( whereJoinFragment( rooAlias, true, false ) );
 
 		select.setWhereClause( whereClauseBuffer.toString() );
 
 		return select.setOuterJoins( "", "" ).toStatementString();
 	}
 
 
 	/**
 	 * Generate the SQL that selects the version number by id
 	 */
 	protected String generateSelectVersionString() {
 		SimpleSelect select = new SimpleSelect( getFactory().getDialect() )
 				.setTableName( getVersionedTableName() );
 		if ( isVersioned() ) {
 			select.addColumn( versionColumnName );
 		}
 		else {
 			select.addColumns( rootTableKeyColumnNames );
 		}
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get version " + getEntityName() );
 		}
 		return select.addCondition( rootTableKeyColumnNames, "=?" ).toStatementString();
 	}
 
 	public boolean[] getPropertyUniqueness() {
 		return propertyUniqueness;
 	}
 
 	protected String generateInsertGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( GenerationTiming.INSERT );
 	}
 
 	protected String generateUpdateGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( GenerationTiming.ALWAYS );
 	}
 
 	private String generateGeneratedValuesSelectString(final GenerationTiming generationTimingToMatch) {
 		Select select = new Select( getFactory().getDialect() );
 
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get generated state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 
 		// Here we render the select column list based on the properties defined as being generated.
 		// For partial component generation, we currently just re-select the whole component
 		// rather than trying to handle the individual generated portions.
 		String selectClause = concretePropertySelectFragment(
 				getRootAlias(),
 				new InclusionChecker() {
 					@Override
 					public boolean includeProperty(int propertyNumber) {
 						final InDatabaseValueGenerationStrategy generationStrategy
 								= entityMetamodel.getInDatabaseValueGenerationStrategies()[propertyNumber];
 						return generationStrategy != null
 								&& timingsMatch( generationStrategy.getGenerationTiming(), generationTimingToMatch );
 					}
 				}
 		);
 		selectClause = selectClause.substring( 2 );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 				.append( StringHelper.join( "=? and ", aliasedIdColumns ) )
 				.append( "=?" )
 				.append( whereJoinFragment( getRootAlias(), true, false ) )
 				.toString();
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	protected static interface InclusionChecker {
 		public boolean includeProperty(int propertyNumber);
 	}
 
 	protected String concretePropertySelectFragment(String alias, final boolean[] includeProperty) {
 		return concretePropertySelectFragment(
 				alias,
 				new InclusionChecker() {
 					public boolean includeProperty(int propertyNumber) {
 						return includeProperty[propertyNumber];
 					}
 				}
 		);
 	}
 
 	protected String concretePropertySelectFragment(String alias, InclusionChecker inclusionChecker) {
 		int propertyCount = getPropertyNames().length;
 		int[] propertyTableNumbers = getPropertyTableNumbersInSelect();
 		SelectFragment frag = new SelectFragment();
 		for ( int i = 0; i < propertyCount; i++ ) {
 			if ( inclusionChecker.includeProperty( i ) ) {
 				frag.addColumnTemplates(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnReaderTemplates[i],
 						propertyColumnAliases[i]
 				);
 				frag.addFormulas(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnFormulaTemplates[i],
 						propertyColumnAliases[i]
 				);
 			}
 		}
 		return frag.toFragmentString();
 	}
 
 	protected String generateSnapshotSelectString() {
 
 		//TODO: should we use SELECT .. FOR UPDATE?
 
 		Select select = new Select( getFactory().getDialect() );
 
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get current state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String selectClause = StringHelper.join( ", ", aliasedIdColumns ) +
 				concretePropertySelectFragment( getRootAlias(), getPropertyUpdateability() );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 			.append( StringHelper.join( "=? and ",
 					aliasedIdColumns ) )
 			.append( "=?" )
 			.append( whereJoinFragment( getRootAlias(), true, false ) )
 			.toString();
 
 		/*if ( isVersioned() ) {
 			where.append(" and ")
 				.append( getVersionColumnName() )
 				.append("=?");
 		}*/
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session) {
 		if ( !isVersioned() ) {
 			throw new AssertionFailure( "cannot force version increment on non-versioned entity" );
 		}
 
 		if ( isVersionPropertyGenerated() ) {
 			// the difficulty here is exactly what do we update in order to
 			// force the version to be incremented in the db...
 			throw new HibernateException( "LockMode.FORCE is currently not supported for generated version properties" );
 		}
 
 		Object nextVersion = getVersionType().next( currentVersion, session );
-        if (LOG.isTraceEnabled()) LOG.trace("Forcing version increment [" + MessageHelper.infoString(this, id, getFactory()) + "; "
-                                            + getVersionType().toLoggableString(currentVersion, getFactory()) + " -> "
-                                            + getVersionType().toLoggableString(nextVersion, getFactory()) + "]");
+        if ( LOG.isTraceEnabled() ) {
+			LOG.trace(
+					"Forcing version increment [" + MessageHelper.infoString( this, id, getFactory() ) + "; "
+							+ getVersionType().toLoggableString( currentVersion, getFactory() ) + " -> "
+							+ getVersionType().toLoggableString( nextVersion, getFactory() ) + "]"
+			);
+		}
 
 		// todo : cache this sql...
 		String versionIncrementString = generateVersionIncrementUpdateString();
 		PreparedStatement st = null;
 		try {
 			st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( versionIncrementString, false );
 			try {
 				getVersionType().nullSafeSet( st, nextVersion, 1, session );
 				getIdentifierType().nullSafeSet( st, id, 2, session );
 				getVersionType().nullSafeSet( st, currentVersion, 2 + getIdentifierColumnSpan(), session );
 				int rows = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 				if ( rows != 1 ) {
 					throw new StaleObjectStateException( getEntityName(), id );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve version: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
-				);
+			);
 		}
 
 		return nextVersion;
 	}
 
 	private String generateVersionIncrementUpdateString() {
 		Update update = new Update( getFactory().getDialect() );
 		update.setTableName( getTableName( 0 ) );
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "forced version increment" );
 		}
 		update.addColumn( getVersionColumnName() );
 		update.addPrimaryKeyColumns( getIdentifierColumnNames() );
 		update.setVersionColumnName( getVersionColumnName() );
 		return update.toStatementString();
 	}
 
 	/**
 	 * Retrieve the version number
 	 */
 	public Object getCurrentVersion(Serializable id, SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting version: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
 			PreparedStatement st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getVersionSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( st, id, 1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( !rs.next() ) {
 						return null;
 					}
 					if ( !isVersioned() ) {
 						return this;
 					}
 					return getVersionType().nullSafeGet( rs, getVersionColumnName(), session, null );
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve version: " + MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 			);
 		}
 	}
 
 	protected void initLockers() {
 		lockers.put( LockMode.READ, generateLocker( LockMode.READ ) );
 		lockers.put( LockMode.UPGRADE, generateLocker( LockMode.UPGRADE ) );
 		lockers.put( LockMode.UPGRADE_NOWAIT, generateLocker( LockMode.UPGRADE_NOWAIT ) );
 		lockers.put( LockMode.UPGRADE_SKIPLOCKED, generateLocker( LockMode.UPGRADE_SKIPLOCKED ) );
 		lockers.put( LockMode.FORCE, generateLocker( LockMode.FORCE ) );
 		lockers.put( LockMode.PESSIMISTIC_READ, generateLocker( LockMode.PESSIMISTIC_READ ) );
 		lockers.put( LockMode.PESSIMISTIC_WRITE, generateLocker( LockMode.PESSIMISTIC_WRITE ) );
 		lockers.put( LockMode.PESSIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.PESSIMISTIC_FORCE_INCREMENT ) );
 		lockers.put( LockMode.OPTIMISTIC, generateLocker( LockMode.OPTIMISTIC ) );
 		lockers.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.OPTIMISTIC_FORCE_INCREMENT ) );
 	}
 
 	protected LockingStrategy generateLocker(LockMode lockMode) {
 		return factory.getDialect().getLockingStrategy( this, lockMode );
 	}
 
 	private LockingStrategy getLocker(LockMode lockMode) {
 		return ( LockingStrategy ) lockers.get( lockMode );
 	}
 
 	public void lock(
 			Serializable id,
 	        Object version,
 	        Object object,
 	        LockMode lockMode,
 	        SessionImplementor session) throws HibernateException {
 		getLocker( lockMode ).lock( id, version, object, LockOptions.WAIT_FOREVER, session );
 	}
 
 	public void lock(
 			Serializable id,
 	        Object version,
 	        Object object,
 	        LockOptions lockOptions,
 	        SessionImplementor session) throws HibernateException {
 		getLocker( lockOptions.getLockMode() ).lock( id, version, object, lockOptions.getTimeOut(), session );
 	}
 
 	public String getRootTableName() {
 		return getSubclassTableName( 0 );
 	}
 
 	public String getRootTableAlias(String drivingAlias) {
 		return drivingAlias;
 	}
 
 	public String[] getRootTableIdentifierColumnNames() {
 		return getRootTableKeyColumnNames();
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		return propertyMapping.toColumns( alias, propertyName );
 	}
 
 	public String[] toColumns(String propertyName) throws QueryException {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public String[] getPropertyColumnNames(String propertyName) {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	/**
 	 * Warning:
 	 * When there are duplicated property names in the subclasses
 	 * of the class, this method may return the wrong table
 	 * number for the duplicated subclass property (note that
 	 * SingleTableEntityPersister defines an overloaded form
 	 * which takes the entity name.
 	 */
 	public int getSubclassPropertyTableNumber(String propertyPath) {
-		String rootPropertyName = StringHelper.root(propertyPath);
+		String rootPropertyName = StringHelper.root( propertyPath );
 		Type type = propertyMapping.toType(rootPropertyName);
 		if ( type.isAssociationType() ) {
 			AssociationType assocType = ( AssociationType ) type;
 			if ( assocType.useLHSPrimaryKey() ) {
 				// performance op to avoid the array search
 				return 0;
 			}
 			else if ( type.isCollectionType() ) {
 				// properly handle property-ref-based associations
 				rootPropertyName = assocType.getLHSPropertyName();
 			}
 		}
 		//Enable for HHH-440, which we don't like:
 		/*if ( type.isComponentType() && !propertyName.equals(rootPropertyName) ) {
 			String unrooted = StringHelper.unroot(propertyName);
 			int idx = ArrayHelper.indexOf( getSubclassColumnClosure(), unrooted );
 			if ( idx != -1 ) {
 				return getSubclassColumnTableNumberClosure()[idx];
 			}
 		}*/
 		int index = ArrayHelper.indexOf( getSubclassPropertyNameClosure(), rootPropertyName); //TODO: optimize this better!
 		return index==-1 ? 0 : getSubclassPropertyTableNumber(index);
 	}
 
 	public Declarer getSubclassPropertyDeclarer(String propertyPath) {
 		int tableIndex = getSubclassPropertyTableNumber( propertyPath );
 		if ( tableIndex == 0 ) {
 			return Declarer.CLASS;
 		}
 		else if ( isClassOrSuperclassTable( tableIndex ) ) {
 			return Declarer.SUPERCLASS;
 		}
 		else {
 			return Declarer.SUBCLASS;
 		}
 	}
 
 	private DiscriminatorMetadata discriminatorMetadata;
 
 	public DiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( discriminatorMetadata == null ) {
 			discriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return discriminatorMetadata;
 	}
 
 	private DiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		return new DiscriminatorMetadata() {
 			public String getSqlFragment(String sqlQualificationAlias) {
 				return toColumns( sqlQualificationAlias, ENTITY_CLASS )[0];
 			}
 
 			public Type getResolutionType() {
 				return new DiscriminatorType( getDiscriminatorType(), AbstractEntityPersister.this );
 			}
 		};
 	}
 
 	public static String generateTableAlias(String rootAlias, int tableNumber) {
 		if ( tableNumber == 0 ) {
 			return rootAlias;
 		}
 		StringBuilder buf = new StringBuilder().append( rootAlias );
 		if ( !rootAlias.endsWith( "_" ) ) {
 			buf.append( '_' );
 		}
 		return buf.append( tableNumber ).append( '_' ).toString();
 	}
 
 	public String[] toColumns(String name, final int i) {
 		final String alias = generateTableAlias( name, getSubclassPropertyTableNumber( i ) );
 		String[] cols = getSubclassPropertyColumnNames( i );
 		String[] templates = getSubclassPropertyFormulaTemplateClosure()[i];
 		String[] result = new String[cols.length];
 		for ( int j = 0; j < cols.length; j++ ) {
 			if ( cols[j] == null ) {
 				result[j] = StringHelper.replace( templates[j], Template.TEMPLATE, alias );
 			}
 			else {
 				result[j] = StringHelper.qualify( alias, cols[j] );
 			}
 		}
 		return result;
 	}
 
 	private int getSubclassPropertyIndex(String propertyName) {
 		return ArrayHelper.indexOf(subclassPropertyNameClosure, propertyName);
 	}
 
 	protected String[] getPropertySubclassNames() {
 		return propertySubclassNames;
 	}
 
 	public String[] getPropertyColumnNames(int i) {
 		return propertyColumnNames[i];
 	}
 
 	public String[] getPropertyColumnWriters(int i) {
 		return propertyColumnWriters[i];
 	}
 
 	protected int getPropertyColumnSpan(int i) {
 		return propertyColumnSpans[i];
 	}
 
 	protected boolean hasFormulaProperties() {
 		return hasFormulaProperties;
 	}
 
 	public FetchMode getFetchMode(int i) {
 		return subclassPropertyFetchModeClosure[i];
 	}
 
 	public CascadeStyle getCascadeStyle(int i) {
 		return subclassPropertyCascadeStyleClosure[i];
 	}
 
 	public Type getSubclassPropertyType(int i) {
 		return subclassPropertyTypeClosure[i];
 	}
 
 	public String getSubclassPropertyName(int i) {
 		return subclassPropertyNameClosure[i];
 	}
 
 	public int countSubclassProperties() {
 		return subclassPropertyTypeClosure.length;
 	}
 
 	public String[] getSubclassPropertyColumnNames(int i) {
 		return subclassPropertyColumnNameClosure[i];
 	}
 
 	public boolean isDefinedOnSubclass(int i) {
 		return propertyDefinedOnSubclass[i];
 	}
 
 	@Override
 	public String[][] getSubclassPropertyFormulaTemplateClosure() {
 		return subclassPropertyFormulaTemplateClosure;
 	}
 
 	protected Type[] getSubclassPropertyTypeClosure() {
 		return subclassPropertyTypeClosure;
 	}
 
 	protected String[][] getSubclassPropertyColumnNameClosure() {
 		return subclassPropertyColumnNameClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderClosure() {
 		return subclassPropertyColumnReaderClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderTemplateClosure() {
 		return subclassPropertyColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassPropertyNameClosure() {
 		return subclassPropertyNameClosure;
 	}
 
 	@Override
 	public int[] resolveAttributeIndexes(Set<String> properties) {
 		Iterator<String> iter = properties.iterator();
 		int[] fields = new int[properties.size()];
 		int counter = 0;
 		while(iter.hasNext()) {
 			Integer index = entityMetamodel.getPropertyIndexOrNull( iter.next() );
-			if ( index != null )
+			if ( index != null ) {
 				fields[counter++] = index;
+			}
 		}
 		return fields;
 	}
 
 	protected String[] getSubclassPropertySubclassNameClosure() {
 		return subclassPropertySubclassNameClosure;
 	}
 
 	protected String[] getSubclassColumnClosure() {
 		return subclassColumnClosure;
 	}
 
 	protected String[] getSubclassColumnAliasClosure() {
 		return subclassColumnAliasClosure;
 	}
 
 	public String[] getSubclassColumnReaderTemplateClosure() {
 		return subclassColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaClosure() {
 		return subclassFormulaClosure;
 	}
 
 	protected String[] getSubclassFormulaTemplateClosure() {
 		return subclassFormulaTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaAliasClosure() {
 		return subclassFormulaAliasClosure;
 	}
 
 	public String[] getSubclassPropertyColumnAliases(String propertyName, String suffix) {
 		String[] rawAliases = ( String[] ) subclassPropertyAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
 		String[] result = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	public String[] getSubclassPropertyColumnNames(String propertyName) {
 		//TODO: should we allow suffixes on these ?
 		return ( String[] ) subclassPropertyColumnNames.get( propertyName );
 	}
 
 
 
 	//This is really ugly, but necessary:
 	/**
 	 * Must be called by subclasses, at the end of their constructors
 	 */
 	protected void initSubclassPropertyAliasesMap(PersistentClass model) throws MappingException {
 
 		// ALIASES
 		internalInitSubclassPropertyAliasesMap( null, model.getSubclassPropertyClosureIterator() );
 
 		// aliases for identifier ( alias.id ); skip if the entity defines a non-id property named 'id'
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			subclassPropertyAliases.put( ENTITY_ID, getIdentifierAliases() );
 			subclassPropertyColumnNames.put( ENTITY_ID, getIdentifierColumnNames() );
 		}
 
 		// aliases named identifier ( alias.idname )
 		if ( hasIdentifierProperty() ) {
 			subclassPropertyAliases.put( getIdentifierPropertyName(), getIdentifierAliases() );
 			subclassPropertyColumnNames.put( getIdentifierPropertyName(), getIdentifierColumnNames() );
 		}
 
 		// aliases for composite-id's
 		if ( getIdentifierType().isComponentType() ) {
 			// Fetch embedded identifiers propertynames from the "virtual" identifier component
 			CompositeType componentId = ( CompositeType ) getIdentifierType();
 			String[] idPropertyNames = componentId.getPropertyNames();
 			String[] idAliases = getIdentifierAliases();
 			String[] idColumnNames = getIdentifierColumnNames();
 
 			for ( int i = 0; i < idPropertyNames.length; i++ ) {
 				if ( entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 					subclassPropertyAliases.put(
 							ENTITY_ID + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							ENTITY_ID + "." + getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 //				if (hasIdentifierProperty() && !ENTITY_ID.equals( getIdentifierPropertyName() ) ) {
 				if ( hasIdentifierProperty() ) {
 					subclassPropertyAliases.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 				else {
 					// embedded composite ids ( alias.idname1, alias.idname2 )
 					subclassPropertyAliases.put( idPropertyNames[i], new String[] { idAliases[i] } );
 					subclassPropertyColumnNames.put( idPropertyNames[i],  new String[] { idColumnNames[i] } );
 				}
 			}
 		}
 
 		if ( entityMetamodel.isPolymorphic() ) {
 			subclassPropertyAliases.put( ENTITY_CLASS, new String[] { getDiscriminatorAlias() } );
 			subclassPropertyColumnNames.put( ENTITY_CLASS, new String[] { getDiscriminatorColumnName() } );
 		}
 
 	}
 
 	private void internalInitSubclassPropertyAliasesMap(String path, Iterator propertyIterator) {
 		while ( propertyIterator.hasNext() ) {
 
 			Property prop = ( Property ) propertyIterator.next();
 			String propname = path == null ? prop.getName() : path + "." + prop.getName();
 			if ( prop.isComposite() ) {
 				Component component = ( Component ) prop.getValue();
 				Iterator compProps = component.getPropertyIterator();
 				internalInitSubclassPropertyAliasesMap( propname, compProps );
 			}
 			else {
 				String[] aliases = new String[prop.getColumnSpan()];
 				String[] cols = new String[prop.getColumnSpan()];
 				Iterator colIter = prop.getColumnIterator();
 				int l = 0;
 				while ( colIter.hasNext() ) {
 					Selectable thing = ( Selectable ) colIter.next();
 					aliases[l] = thing.getAlias( getFactory().getDialect(), prop.getValue().getTable() );
 					cols[l] = thing.getText( getFactory().getDialect() ); // TODO: skip formulas?
 					l++;
 				}
 
 				subclassPropertyAliases.put( propname, aliases );
 				subclassPropertyColumnNames.put( propname, cols );
 			}
 		}
 
 	}
 
 	public Object loadByUniqueKey(
 			String propertyName,
 			Object uniqueKey,
 			SessionImplementor session) throws HibernateException {
 		return getAppropriateUniqueKeyLoader( propertyName, session ).loadByUniqueKey( session, uniqueKey );
 	}
 
 	private EntityLoader getAppropriateUniqueKeyLoader(String propertyName, SessionImplementor session) {
 		final boolean useStaticLoader = !session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& !session.getLoadQueryInfluencers().hasEnabledFetchProfiles()
 				&& propertyName.indexOf('.')<0; //ugly little workaround for fact that createUniqueKeyLoaders() does not handle component properties
 
 		if ( useStaticLoader ) {
 			return ( EntityLoader ) uniqueKeyLoaders.get( propertyName );
 		}
 		else {
 			return createUniqueKeyLoader(
 					propertyMapping.toType( propertyName ),
 					propertyMapping.toColumns( propertyName ),
 					session.getLoadQueryInfluencers()
 			);
 		}
 	}
 
 	public int getPropertyIndex(String propertyName) {
 		return entityMetamodel.getPropertyIndex(propertyName);
 	}
 
 	protected void createUniqueKeyLoaders() throws MappingException {
 		Type[] propertyTypes = getPropertyTypes();
 		String[] propertyNames = getPropertyNames();
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( propertyUniqueness[i] ) {
 				//don't need filters for the static loaders
 				uniqueKeyLoaders.put(
 						propertyNames[i],
 						createUniqueKeyLoader(
 								propertyTypes[i],
 								getPropertyColumnNames( i ),
 								LoadQueryInfluencers.NONE
 						)
 				);
 				//TODO: create uk loaders for component properties
 			}
 		}
 	}
 
 	private EntityLoader createUniqueKeyLoader(
 			Type uniqueKeyType,
 			String[] columns,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		if ( uniqueKeyType.isEntityType() ) {
 			String className = ( ( EntityType ) uniqueKeyType ).getAssociatedEntityName();
 			uniqueKeyType = getFactory().getEntityPersister( className ).getIdentifierType();
 		}
 		return new EntityLoader(
 				this,
 				columns,
 				uniqueKeyType,
 				1,
 				LockMode.NONE,
 				getFactory(),
 				loadQueryInfluencers
 		);
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	protected boolean hasWhere() {
 		return sqlWhereString != null;
 	}
 
 	private void initOrdinaryPropertyPaths(Mapping mapping) throws MappingException {
 		for ( int i = 0; i < getSubclassPropertyNameClosure().length; i++ ) {
 			propertyMapping.initPropertyPaths(
 					getSubclassPropertyNameClosure()[i],
 					getSubclassPropertyTypeClosure()[i],
 					getSubclassPropertyColumnNameClosure()[i],
 					getSubclassPropertyColumnReaderClosure()[i],
 					getSubclassPropertyColumnReaderTemplateClosure()[i],
 					getSubclassPropertyFormulaTemplateClosure()[i],
 					mapping
 			);
 		}
 	}
 
 	private void initIdentifierPropertyPaths(Mapping mapping) throws MappingException {
 		String idProp = getIdentifierPropertyName();
 		if ( idProp != null ) {
 			propertyMapping.initPropertyPaths( idProp, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
 			propertyMapping.initPropertyPaths( null, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			propertyMapping.initPropertyPaths( ENTITY_ID, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 	}
 
 	private void initDiscriminatorPropertyPath(Mapping mapping) throws MappingException {
-		propertyMapping.initPropertyPaths( ENTITY_CLASS,
+		propertyMapping.initPropertyPaths(
+				ENTITY_CLASS,
 				getDiscriminatorType(),
-				new String[]{getDiscriminatorColumnName()},
-				new String[]{getDiscriminatorColumnReaders()},
-				new String[]{getDiscriminatorColumnReaderTemplate()},
-				new String[]{getDiscriminatorFormulaTemplate()},
-				getFactory() );
+				new String[] {getDiscriminatorColumnName()},
+				new String[] {getDiscriminatorColumnReaders()},
+				new String[] {getDiscriminatorColumnReaderTemplate()},
+				new String[] {getDiscriminatorFormulaTemplate()},
+				getFactory()
+		);
 	}
 
 	protected void initPropertyPaths(Mapping mapping) throws MappingException {
 		initOrdinaryPropertyPaths(mapping);
 		initOrdinaryPropertyPaths(mapping); //do two passes, for collection property-ref!
 		initIdentifierPropertyPaths(mapping);
 		if ( entityMetamodel.isPolymorphic() ) {
 			initDiscriminatorPropertyPath( mapping );
 		}
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockMode lockMode,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockMode, getFactory(), loadQueryInfluencers );
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockOptions lockOptions,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockOptions, getFactory(), loadQueryInfluencers );
 	}
 
 	/**
 	 * Used internally to create static loaders.  These are the default set of loaders used to handle get()/load()
 	 * processing.  lock() handling is done by the LockingStrategy instances (see {@link #getLocker})
 	 *
 	 * @param lockMode The lock mode to apply to the thing being loaded.
 	 * @return
 	 *
 	 * @throws MappingException
 	 */
 	protected UniqueEntityLoader createEntityLoader(LockMode lockMode) throws MappingException {
 		return createEntityLoader( lockMode, LoadQueryInfluencers.NONE );
 	}
 
 	protected boolean check(int rows, Serializable id, int tableNumber, Expectation expectation, PreparedStatement statement) throws HibernateException {
 		try {
 			expectation.verifyOutcome( rows, statement, -1 );
 		}
 		catch( StaleStateException e ) {
 			if ( !isNullableTable( tableNumber ) ) {
 				if ( getFactory().getStatistics().isStatisticsEnabled() ) {
 					getFactory().getStatisticsImplementor()
 							.optimisticFailure( getEntityName() );
 				}
 				throw new StaleObjectStateException( getEntityName(), id );
 			}
 			return false;
 		}
 		catch( TooManyRowsAffectedException e ) {
 			throw new HibernateException(
 					"Duplicate identifier in table for: " +
 					MessageHelper.infoString( this, id, getFactory() )
 			);
 		}
 		catch ( Throwable t ) {
 			return false;
 		}
 		return true;
 	}
 
 	protected String generateUpdateString(boolean[] includeProperty, int j, boolean useRowId) {
 		return generateUpdateString( includeProperty, j, null, useRowId );
 	}
 
 	/**
 	 * Generate the SQL that updates a row by id (and version)
 	 */
 	protected String generateUpdateString(final boolean[] includeProperty,
 										  final int j,
 										  final Object[] oldFields,
 										  final boolean useRowId) {
 
 		Update update = new Update( getFactory().getDialect() ).setTableName( getTableName( j ) );
 
 		// select the correct row by either pk or rowid
 		if ( useRowId ) {
 			update.addPrimaryKeyColumns( new String[]{rowIdName} ); //TODO: eventually, rowIdName[j]
 		}
 		else {
 			update.addPrimaryKeyColumns( getKeyColumns( j ) );
 		}
 
 		boolean hasColumns = false;
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) 
 					&& !lobProperties.contains( i ) ) {
 				// this is a property of the table, which we are updating
 				update.addColumns( getPropertyColumnNames(i),
 						propertyColumnUpdateable[i], propertyColumnWriters[i] );
 				hasColumns = hasColumns || getPropertyColumnSpan( i ) > 0;
 			}
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				update.addColumns( getPropertyColumnNames(i),
 						propertyColumnUpdateable[i], propertyColumnWriters[i] );
 				hasColumns = true;
 			}
 		}
 
 		if ( j == 0 && isVersioned() && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 			// this is the root (versioned) table, and we are using version-based
 			// optimistic locking;  if we are not updating the version, also don't
 			// check it (unless this is a "generated" version column)!
 			if ( checkVersion( includeProperty ) ) {
 				update.setVersionColumnName( getVersionColumnName() );
 				hasColumns = true;
 			}
 		}
 		else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 			// we are using "all" or "dirty" property-based optimistic locking
 
 			boolean[] includeInWhere = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
 					? getPropertyUpdateability() //optimistic-lock="all", include all updatable properties
 					: includeProperty; 			 //optimistic-lock="dirty", include all properties we are updating this time
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				boolean include = includeInWhere[i] &&
 						isPropertyOfTable( i, j ) &&
 						versionability[i];
 				if ( include ) {
 					// this property belongs to the table, and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					String[] propertyColumnWriters = getPropertyColumnWriters( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( oldFields[i], getFactory() );
 					for ( int k=0; k<propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							update.addWhereColumn( propertyColumnNames[k], "=" + propertyColumnWriters[k] );
 						}
 						else {
 							update.addWhereColumn( propertyColumnNames[k], " is null" );
 						}
 					}
 				}
 			}
 
 		}
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "update " + getEntityName() );
 		}
 
 		return hasColumns ? update.toStatementString() : null;
 	}
 
 	private boolean checkVersion(final boolean[] includeProperty) {
 		return includeProperty[ getVersionProperty() ]
 				|| entityMetamodel.isVersionGenerated();
 	}
 
 	protected String generateInsertString(boolean[] includeProperty, int j) {
 		return generateInsertString( false, includeProperty, j );
 	}
 
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty) {
 		return generateInsertString( identityInsert, includeProperty, 0 );
 	}
 
 	/**
 	 * Generate the SQL that inserts a row
 	 */
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty, int j) {
 
 		// todo : remove the identityInsert param and variations;
 		//   identity-insert strings are now generated from generateIdentityInsertString()
 
 		Insert insert = new Insert( getFactory().getDialect() )
 				.setTableName( getTableName( j ) );
 
 		// add normal properties
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			// the incoming 'includeProperty' array only accounts for insertable defined at the root level, it
 			// does not account for partially generated composites etc.  We also need to account for generation
 			// values
 			if ( isPropertyOfTable( i, j ) ) {
 				if ( !lobProperties.contains( i ) ) {
 					final InDatabaseValueGenerationStrategy generationStrategy = entityMetamodel.getInDatabaseValueGenerationStrategies()[i];
 					if ( generationStrategy != null && generationStrategy.getGenerationTiming().includesInsert() ) {
 						if ( generationStrategy.referenceColumnsInSql() ) {
 							final String[] values;
 							if ( generationStrategy.getReferencedColumnValues() == null ) {
 								values = propertyColumnWriters[i];
 							}
 							else {
 								final int numberOfColumns = propertyColumnWriters[i].length;
 								values = new String[ numberOfColumns ];
 								for ( int x = 0; x < numberOfColumns; x++ ) {
 									if ( generationStrategy.getReferencedColumnValues()[x] != null ) {
 										values[x] = generationStrategy.getReferencedColumnValues()[x];
 									}
 									else {
 										values[x] = propertyColumnWriters[i][x];
 									}
 								}
 							}
 							insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], values );
 						}
 					}
 					else if ( includeProperty[i] ) {
 						insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 					}
 				}
 			}
 		}
 
 		// add the discriminator
 		if ( j == 0 ) {
 			addDiscriminatorToInsert( insert );
 		}
 
 		// add the primary key
 		if ( j == 0 && identityInsert ) {
 			insert.addIdentityColumn( getKeyColumns( 0 )[0] );
 		}
 		else {
 			insert.addColumns( getKeyColumns( j ) );
 		}
 
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns(
 						getPropertyColumnNames(i),
 						propertyColumnInsertable[i],
 						propertyColumnWriters[i]
 				);
 			}
 		}
 
 		String result = insert.toStatementString();
 
 		// append the SQL to return the generated identifier
 		if ( j == 0 && identityInsert && useInsertSelectIdentity() ) { //TODO: suck into Insert
 			result = getFactory().getDialect().appendIdentitySelectToInsert( result );
 		}
 
 		return result;
 	}
 
 	/**
 	 * Used to generate an insery statement against the root table in the
 	 * case of identifier generation strategies where the insert statement
 	 * executions actually generates the identifier value.
 	 *
 	 * @param includeProperty indices of the properties to include in the
 	 * insert statement.
 	 * @return The insert SQL statement string
 	 */
 	protected String generateIdentityInsertString(boolean[] includeProperty) {
 		Insert insert = identityDelegate.prepareIdentifierGeneratingInsert();
 		insert.setTableName( getTableName( 0 ) );
 
 		// add normal properties except lobs
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) && !lobProperties.contains( i ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// HHH-4635 & HHH-8103
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) ) {
 				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// add the discriminator
 		addDiscriminatorToInsert( insert );
 
 		// delegate already handles PK columns
 
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL that deletes a row by id (and version)
 	 */
 	protected String generateDeleteString(int j) {
-		Delete delete = new Delete()
+		final Delete delete = new Delete()
 				.setTableName( getTableName( j ) )
 				.addPrimaryKeyColumns( getKeyColumns( j ) );
 		if ( j == 0 ) {
 			delete.setVersionColumnName( getVersionColumnName() );
 		}
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			delete.setComment( "delete " + getEntityName() );
 		}
 		return delete.toStatementString();
 	}
 
 	protected int dehydrate(
 			Serializable id,
 			Object[] fields,
 			boolean[] includeProperty,
 			boolean[][] includeColumns,
 			int j,
 			PreparedStatement st,
 			SessionImplementor session,
 			boolean isUpdate) throws HibernateException, SQLException {
 		return dehydrate( id, fields, null, includeProperty, includeColumns, j, st, session, 1, isUpdate );
 	}
 
 	/**
 	 * Marshall the fields of a persistent instance to a prepared statement
 	 */
 	protected int dehydrate(
 			final Serializable id,
 			final Object[] fields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final boolean[][] includeColumns,
 			final int j,
 			final PreparedStatement ps,
 			final SessionImplementor session,
 			int index,
 			boolean isUpdate ) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Dehydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j )
 					&& !lobProperties.contains( i )) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
 		
 		if ( !isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
 		
 		if ( isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 
 		return index;
 
 	}
 	
 	private int dehydrateId( 
 			final Serializable id,
 			final Object rowId,
 			final PreparedStatement ps,
 			final SessionImplementor session,
 			int index ) throws SQLException {
 		if ( rowId != null ) {
 			ps.setObject( index, rowId );
 			return 1;
 		}
 		else if ( id != null ) {
 			getIdentifierType().nullSafeSet( ps, id, index, session );
 			return getIdentifierColumnSpan();
 		}
 		return 0;
 	}
 
 	/**
 	 * Unmarshall the fields of a persistent instance from a result set,
 	 * without resolving associations or collections. Question: should
 	 * this really be here, or should it be sent back to Loader?
 	 */
 	public Object[] hydrate(
 			final ResultSet rs,
 			final Serializable id,
 			final Object object,
 			final Loadable rootLoadable,
 			final String[][] suffixedPropertyColumns,
 			final boolean allProperties,
 			final SessionImplementor session) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Hydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		final AbstractEntityPersister rootPersister = (AbstractEntityPersister) rootLoadable;
 
 		final boolean hasDeferred = rootPersister.hasSequentialSelect();
 		PreparedStatement sequentialSelect = null;
 		ResultSet sequentialResultSet = null;
 		boolean sequentialSelectEmpty = false;
 		try {
 
 			if ( hasDeferred ) {
 				final String sql = rootPersister.getSequentialSelect( getEntityName() );
 				if ( sql != null ) {
 					//TODO: I am not so sure about the exception handling in this bit!
 					sequentialSelect = session
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql );
 					rootPersister.getIdentifierType().nullSafeSet( sequentialSelect, id, 1, session );
 					sequentialResultSet = session.getJdbcCoordinator().getResultSetReturn().extract( sequentialSelect );
 					if ( !sequentialResultSet.next() ) {
 						// TODO: Deal with the "optional" attribute in the <join> mapping;
 						// this code assumes that optional defaults to "true" because it
 						// doesn't actually seem to work in the fetch="join" code
 						//
 						// Note that actual proper handling of optional-ality here is actually
 						// more involved than this patch assumes.  Remember that we might have
 						// multiple <join/> mappings associated with a single entity.  Really
 						// a couple of things need to happen to properly handle optional here:
 						//  1) First and foremost, when handling multiple <join/>s, we really
 						//      should be using the entity root table as the driving table;
 						//      another option here would be to choose some non-optional joined
 						//      table to use as the driving table.  In all likelihood, just using
 						//      the root table is much simplier
 						//  2) Need to add the FK columns corresponding to each joined table
 						//      to the generated select list; these would then be used when
 						//      iterating the result set to determine whether all non-optional
 						//      data is present
 						// My initial thoughts on the best way to deal with this would be
 						// to introduce a new SequentialSelect abstraction that actually gets
 						// generated in the persisters (ok, SingleTable...) and utilized here.
 						// It would encapsulated all this required optional-ality checking...
 						sequentialSelectEmpty = true;
 					}
 				}
 			}
 
 			final String[] propNames = getPropertyNames();
 			final Type[] types = getPropertyTypes();
 			final Object[] values = new Object[types.length];
 			final boolean[] laziness = getPropertyLaziness();
 			final String[] propSubclassNames = getSubclassPropertySubclassNameClosure();
 
 			for ( int i = 0; i < types.length; i++ ) {
 				if ( !propertySelectable[i] ) {
 					values[i] = BackrefPropertyAccessor.UNKNOWN;
 				}
 				else if ( allProperties || !laziness[i] ) {
 					//decide which ResultSet to get the property value from:
 					final boolean propertyIsDeferred = hasDeferred &&
 							rootPersister.isSubclassPropertyDeferred( propNames[i], propSubclassNames[i] );
 					if ( propertyIsDeferred && sequentialSelectEmpty ) {
 						values[i] = null;
 					}
 					else {
 						final ResultSet propertyResultSet = propertyIsDeferred ? sequentialResultSet : rs;
 						final String[] cols = propertyIsDeferred ? propertyColumnAliases[i] : suffixedPropertyColumns[i];
 						values[i] = types[i].hydrate( propertyResultSet, cols, session, object );
 					}
 				}
 				else {
 					values[i] = LazyPropertyInitializer.UNFETCHED_PROPERTY;
 				}
 			}
 
 			if ( sequentialResultSet != null ) {
 				session.getJdbcCoordinator().getResourceRegistry().release( sequentialResultSet, sequentialSelect );
 			}
 
 			return values;
 
 		}
 		finally {
 			if ( sequentialSelect != null ) {
 				session.getJdbcCoordinator().getResourceRegistry().release( sequentialSelect );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 	}
 
 	protected boolean useInsertSelectIdentity() {
 		return !useGetGeneratedKeys() && getFactory().getDialect().supportsInsertSelectIdentity();
 	}
 
 	protected boolean useGetGeneratedKeys() {
 		return getFactory().getSettings().isGetGeneratedKeysEnabled();
 	}
 
 	protected String getSequentialSelect(String entityName) {
 		throw new UnsupportedOperationException("no sequential selects");
 	}
 
 	/**
 	 * Perform an SQL INSERT, and then retrieve a generated identifier.
 	 * <p/>
 	 * This form is used for PostInsertIdentifierGenerator-style ids (IDENTITY,
 	 * select, etc).
 	 */
 	protected Serializable insert(
 			final Object[] fields,
 			final boolean[] notNull,
 			String sql,
 			final Object object,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0} (native id)", getEntityName() );
 			if ( isVersioned() ) {
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 			}
 		}
 
 		Binder binder = new Binder() {
 			public void bindValues(PreparedStatement ps) throws SQLException {
 				dehydrate( null, fields, notNull, propertyColumnInsertable, 0, ps, session, false );
 			}
 			public Object getEntity() {
 				return object;
 			}
 		};
 
 		return identityDelegate.performInsert( sql, session, binder );
 	}
 
 	public String getIdentitySelectString() {
 		//TODO: cache this in an instvar
 		return getFactory().getDialect().getIdentitySelectString(
-				getTableName(0),
-				getKeyColumns(0)[0],
+				getTableName( 0 ),
+				getKeyColumns( 0 )[0],
 				getIdentifierType().sqlTypes( getFactory() )[0]
 		);
 	}
 
 	public String getSelectByUniqueKeyString(String propertyName) {
 		return new SimpleSelect( getFactory().getDialect() )
 			.setTableName( getTableName(0) )
 			.addColumns( getKeyColumns(0) )
 			.addCondition( getPropertyColumnNames(propertyName), "=?" )
 			.toStatementString();
 	}
 
 	private BasicBatchKey inserBatchKey;
 
 	/**
 	 * Perform an SQL INSERT.
 	 * <p/>
 	 * This for is used for all non-root tables as well as the root table
 	 * in cases where the identifier value is known before the insert occurs.
 	 */
 	protected void insert(
 			final Serializable id,
 			final Object[] fields,
 			final boolean[] notNull,
 			final int j,
 			final String sql,
 			final Object object,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		//note: it is conceptually possible that a UserType could map null to
 		//	  a non-null value, so the following is arguable:
 		if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 			return;
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
-			if ( j == 0 && isVersioned() )
+			if ( j == 0 && isVersioned() ) {
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
+			}
 		}
 
 		// TODO : shouldn't inserts be Expectations.NONE?
 		final Expectation expectation = Expectations.appropriateExpectation( insertResultCheckStyles[j] );
 		// we can't batch joined inserts, *especially* not if it is an identity insert;
 		// nor can we batch statements where the expectation is based on an output param
 		final boolean useBatch = j == 0 && expectation.canBeBatched();
 		if ( useBatch && inserBatchKey == null ) {
 			inserBatchKey = new BasicBatchKey(
 					getEntityName() + "#INSERT",
 					expectation
 			);
 		}
 		final boolean callable = isInsertCallable( j );
 
 		try {
 			// Render the SQL query
 			final PreparedStatement insert;
 			if ( useBatch ) {
 				insert = session
 						.getJdbcCoordinator()
 						.getBatch( inserBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				insert = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 				int index = 1;
 				index += expectation.prepare( insert );
 
 				// Write the values of fields onto the prepared statement - we MUST use the state at the time the
 				// insert was issued (cos of foreign key constraints). Not necessarily the object's current state
 
 				dehydrate( id, fields, null, notNull, propertyColumnInsertable, j, insert, session, index, false );
 
 				if ( useBatch ) {
 					session.getJdbcCoordinator().getBatch( inserBatchKey ).addToBatch();
 				}
 				else {
 					expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert ), insert, -1 );
 				}
 
 			}
 			catch ( SQLException e ) {
 				if ( useBatch ) {
 					session.getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( insert );
 					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not insert: " + MessageHelper.infoString( this ),
 					sql
 			);
 		}
 
 	}
 
 	/**
 	 * Perform an SQL UPDATE or SQL INSERT
 	 */
 	protected void updateOrInsert(
 			final Serializable id,
 			final Object[] fields,
 			final Object[] oldFields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final int j,
 			final Object oldVersion,
 			final Object object,
 			final String sql,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( !isInverseTable( j ) ) {
 
 			final boolean isRowToUpdate;
 			if ( isNullableTable( j ) && oldFields != null && isAllNull( oldFields, j ) ) {
 				//don't bother trying to update, we know there is no row there yet
 				isRowToUpdate = false;
 			}
 			else if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 				//if all fields are null, we might need to delete existing row
 				isRowToUpdate = true;
 				delete( id, oldVersion, j, object, getSQLDeleteStrings()[j], session, null );
 			}
 			else {
 				//there is probably a row there, so try to update
 				//if no rows were updated, we will find out
 				isRowToUpdate = update( id, fields, oldFields, rowId, includeProperty, j, oldVersion, object, sql, session );
 			}
 
 			if ( !isRowToUpdate && !isAllNull( fields, j ) ) {
 				// assume that the row was not there since it previously had only null
 				// values, so do an INSERT instead
 				//TODO: does not respect dynamic-insert
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 
 		}
 
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	protected boolean update(
 			final Serializable id,
 			final Object[] fields,
 			final Object[] oldFields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final int j,
 			final Object oldVersion,
 			final Object object,
 			final String sql,
 			final SessionImplementor session) throws HibernateException {
 
 		final Expectation expectation = Expectations.appropriateExpectation( updateResultCheckStyles[j] );
 		final boolean useBatch = j == 0 && expectation.canBeBatched() && isBatchable(); //note: updates to joined tables can't be batched...
 		if ( useBatch && updateBatchKey == null ) {
 			updateBatchKey = new BasicBatchKey(
 					getEntityName() + "#UPDATE",
 					expectation
 			);
 		}
 		final boolean callable = isUpdateCallable( j );
 		final boolean useVersion = j == 0 && isVersioned();
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Updating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( useVersion )
 				LOG.tracev( "Existing version: {0} -> New version:{1}", oldVersion, fields[getVersionProperty()] );
 		}
 
 		try {
 			int index = 1; // starting index
 			final PreparedStatement update;
 			if ( useBatch ) {
 				update = session
 						.getJdbcCoordinator()
 						.getBatch( updateBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				update = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 				index+= expectation.prepare( update );
 
 				//Now write the values of fields onto the prepared statement
 				index = dehydrate( id, fields, rowId, includeProperty, propertyColumnUpdateable, j, update, session, index, true );
 
 				// Write any appropriate versioning conditional parameters
 				if ( useVersion && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 					if ( checkVersion( includeProperty ) ) {
 						getVersionType().nullSafeSet( update, oldVersion, index, session );
 					}
 				}
 				else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 					boolean[] versionability = getPropertyVersionability(); //TODO: is this really necessary????
 					boolean[] includeOldField = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
 							? getPropertyUpdateability()
 							: includeProperty;
 					Type[] types = getPropertyTypes();
 					for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 						boolean include = includeOldField[i] &&
 								isPropertyOfTable( i, j ) &&
 								versionability[i]; //TODO: is this really necessary????
 						if ( include ) {
 							boolean[] settable = types[i].toColumnNullness( oldFields[i], getFactory() );
 							types[i].nullSafeSet(
 									update,
 									oldFields[i],
 									index,
 									settable,
 									session
 								);
 							index += ArrayHelper.countTrue(settable);
 						}
 					}
 				}
 
 				if ( useBatch ) {
 					session.getJdbcCoordinator().getBatch( updateBatchKey ).addToBatch();
 					return true;
 				}
 				else {
 					return check( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( update ), id, j, expectation, update );
 				}
 
 			}
 			catch ( SQLException e ) {
 				if ( useBatch ) {
 					session.getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( update );
 					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not update: " + MessageHelper.infoString( this, id, getFactory() ),
 					sql
-				);
+			);
 		}
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	/**
 	 * Perform an SQL DELETE
 	 */
 	protected void delete(
 			final Serializable id,
 			final Object version,
 			final int j,
 			final Object object,
 			final String sql,
 			final SessionImplementor session,
 			final Object[] loadedState) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		final boolean useVersion = j == 0 && isVersioned();
 		final boolean callable = isDeleteCallable( j );
 		final Expectation expectation = Expectations.appropriateExpectation( deleteResultCheckStyles[j] );
 		final boolean useBatch = j == 0 && isBatchable() && expectation.canBeBatched();
 		if ( useBatch && deleteBatchKey == null ) {
 			deleteBatchKey = new BasicBatchKey(
 					getEntityName() + "#DELETE",
 					expectation
 			);
 		}
 
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		if ( traceEnabled ) {
 			LOG.tracev( "Deleting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( useVersion )
 				LOG.tracev( "Version: {0}", version );
 		}
 
 		if ( isTableCascadeDeleteEnabled( j ) ) {
 			if ( traceEnabled ) {
 				LOG.tracev( "Delete handled by foreign key constraint: {0}", getTableName( j ) );
 			}
 			return; //EARLY EXIT!
 		}
 
 		try {
 			//Render the SQL query
 			PreparedStatement delete;
 			int index = 1;
 			if ( useBatch ) {
 				delete = session
 						.getJdbcCoordinator()
 						.getBatch( deleteBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				delete = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 
 				index += expectation.prepare( delete );
 
 				// Do the key. The key is immutable so we can use the _current_ object state - not necessarily
 				// the state at the time the delete was issued
 				getIdentifierType().nullSafeSet( delete, id, index, session );
 				index += getIdentifierColumnSpan();
 
 				// We should use the _current_ object state (ie. after any updates that occurred during flush)
 
 				if ( useVersion ) {
 					getVersionType().nullSafeSet( delete, version, index, session );
 				}
 				else if ( isAllOrDirtyOptLocking() && loadedState != null ) {
 					boolean[] versionability = getPropertyVersionability();
 					Type[] types = getPropertyTypes();
 					for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 						if ( isPropertyOfTable( i, j ) && versionability[i] ) {
 							// this property belongs to the table and it is not specifically
 							// excluded from optimistic locking by optimistic-lock="false"
 							boolean[] settable = types[i].toColumnNullness( loadedState[i], getFactory() );
 							types[i].nullSafeSet( delete, loadedState[i], index, settable, session );
 							index += ArrayHelper.countTrue( settable );
 						}
 					}
 				}
 
 				if ( useBatch ) {
 					session.getJdbcCoordinator().getBatch( deleteBatchKey ).addToBatch();
 				}
 				else {
 					check( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( delete ), id, j, expectation, delete );
 				}
 
 			}
 			catch ( SQLException sqle ) {
 				if ( useBatch ) {
 					session.getJdbcCoordinator().abortBatch();
 				}
 				throw sqle;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( delete );
 					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not delete: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					sql
-				);
+			);
 
 		}
 
 	}
 
 	private String[] getUpdateStrings(boolean byRowId, boolean lazy) {
 		if ( byRowId ) {
 			return lazy ? getSQLLazyUpdateByRowIdStrings() : getSQLUpdateByRowIdStrings();
 		}
 		else {
 			return lazy ? getSQLLazyUpdateStrings() : getSQLUpdateStrings();
 		}
 	}
 
 	/**
 	 * Update an object
 	 */
 	public void update(
 			final Serializable id,
 			final Object[] fields,
 			final int[] dirtyFields,
 			final boolean hasDirtyCollection,
 			final Object[] oldFields,
 			final Object oldVersion,
 			final Object object,
 			final Object rowId,
 			final SessionImplementor session) throws HibernateException {
 
 		// apply any pre-update in-memory value generation
 		if ( getEntityMetamodel().hasPreUpdateGeneratedValues() ) {
 			final InMemoryValueGenerationStrategy[] strategies = getEntityMetamodel().getInMemoryValueGenerationStrategies();
 			for ( int i = 0; i < strategies.length; i++ ) {
 				if ( strategies[i] != null && strategies[i].getGenerationTiming().includesUpdate() ) {
 					fields[i] = strategies[i].getValueGenerator().generateValue( (Session) session, object );
 					setPropertyValue( object, i, fields[i] );
 					// todo : probably best to add to dirtyFields if not-null
 				}
 			}
 		}
 
 		//note: dirtyFields==null means we had no snapshot, and we couldn't get one using select-before-update
 		//	  oldFields==null just means we had no snapshot to begin with (we might have used select-before-update to get the dirtyFields)
 
 		final boolean[] tableUpdateNeeded = getTableUpdateNeeded( dirtyFields, hasDirtyCollection );
 		final int span = getTableSpan();
 
 		final boolean[] propsToUpdate;
 		final String[] updateStrings;
 		EntityEntry entry = session.getPersistenceContext().getEntry( object );
 
 		// Ensure that an immutable or non-modifiable entity is not being updated unless it is
 		// in the process of being deleted.
 		if ( entry == null && ! isMutable() ) {
 			throw new IllegalStateException( "Updating immutable entity that is not in session yet!" );
 		}
 		if ( ( entityMetamodel.isDynamicUpdate() && dirtyFields != null ) ) {
 			// We need to generate the UPDATE SQL when dynamic-update="true"
 			propsToUpdate = getPropertiesToUpdate( dirtyFields, hasDirtyCollection );
 			// don't need to check laziness (dirty checking algorithm handles that)
 			updateStrings = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				updateStrings[j] = tableUpdateNeeded[j] ?
 						generateUpdateString( propsToUpdate, j, oldFields, j == 0 && rowId != null ) :
 						null;
 			}
 		}
 		else if ( ! isModifiableEntity( entry ) ) {
 			// We need to generate UPDATE SQL when a non-modifiable entity (e.g., read-only or immutable)
 			// needs:
 			// - to have references to transient entities set to null before being deleted
 			// - to have version incremented do to a "dirty" association
 			// If dirtyFields == null, then that means that there are no dirty properties to
 			// to be updated; an empty array for the dirty fields needs to be passed to
 			// getPropertiesToUpdate() instead of null.
 			propsToUpdate = getPropertiesToUpdate(
 					( dirtyFields == null ? ArrayHelper.EMPTY_INT_ARRAY : dirtyFields ),
 					hasDirtyCollection
 			);
 			// don't need to check laziness (dirty checking algorithm handles that)
 			updateStrings = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				updateStrings[j] = tableUpdateNeeded[j] ?
 						generateUpdateString( propsToUpdate, j, oldFields, j == 0 && rowId != null ) :
 						null;
 			}
 		}
 		else {
 			// For the case of dynamic-update="false", or no snapshot, we use the static SQL
 			updateStrings = getUpdateStrings(
 					rowId != null,
 					hasUninitializedLazyProperties( object )
 			);
 			propsToUpdate = getPropertyUpdateability( object );
 		}
 
 		for ( int j = 0; j < span; j++ ) {
 			// Now update only the tables with dirty properties (and the table with the version number)
 			if ( tableUpdateNeeded[j] ) {
 				updateOrInsert(
 						id,
 						fields,
 						oldFields,
 						j == 0 ? rowId : null,
 						propsToUpdate,
 						j,
 						oldVersion,
 						object,
 						updateStrings[j],
 						session
-					);
+				);
 			}
 		}
 	}
 
 	public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 			throws HibernateException {
 		// apply any pre-insert in-memory value generation
 		preInsertInMemoryValueGeneration( fields, object, session );
 		
 		final int span = getTableSpan();
 		final Serializable id;
 		if ( entityMetamodel.isDynamicInsert() ) {
 			// For the case of dynamic-insert="true", we need to generate the INSERT SQL
 			boolean[] notNull = getPropertiesToInsert( fields );
 			id = insert( fields, notNull, generateInsertString( true, notNull ), object, session );
 			for ( int j = 1; j < span; j++ ) {
 				insert( id, fields, notNull, j, generateInsertString( notNull, j ), object, session );
 			}
 		}
 		else {
 			// For the case of dynamic-insert="false", use the static SQL
 			id = insert( fields, getPropertyInsertability(), getSQLIdentityInsertString(), object, session );
 			for ( int j = 1; j < span; j++ ) {
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 		}
 		return id;
 	}
 
 	public void insert(Serializable id, Object[] fields, Object object, SessionImplementor session) {
 		// apply any pre-insert in-memory value generation
 		preInsertInMemoryValueGeneration( fields, object, session );
 
 		final int span = getTableSpan();
 		if ( entityMetamodel.isDynamicInsert() ) {
 			// For the case of dynamic-insert="true", we need to generate the INSERT SQL
 			boolean[] notNull = getPropertiesToInsert( fields );
 			for ( int j = 0; j < span; j++ ) {
 				insert( id, fields, notNull, j, generateInsertString( notNull, j ), object, session );
 			}
 		}
 		else {
 			// For the case of dynamic-insert="false", use the static SQL
 			for ( int j = 0; j < span; j++ ) {
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 		}
 	}
 	
 	private void preInsertInMemoryValueGeneration(Object[] fields, Object object, SessionImplementor session) {
 		if ( getEntityMetamodel().hasPreInsertGeneratedValues() ) {
 			final InMemoryValueGenerationStrategy[] strategies = getEntityMetamodel().getInMemoryValueGenerationStrategies();
 			for ( int i = 0; i < strategies.length; i++ ) {
 				if ( strategies[i] != null && strategies[i].getGenerationTiming().includesInsert() ) {
 					fields[i] = strategies[i].getValueGenerator().generateValue( (Session) session, object );
 					setPropertyValue( object, i, fields[i] );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Delete an object
 	 */
 	public void delete(Serializable id, Object version, Object object, SessionImplementor session)
 			throws HibernateException {
 		final int span = getTableSpan();
 		boolean isImpliedOptimisticLocking = !entityMetamodel.isVersioned() && isAllOrDirtyOptLocking();
 		Object[] loadedState = null;
 		if ( isImpliedOptimisticLocking ) {
 			// need to treat this as if it where optimistic-lock="all" (dirty does *not* make sense);
 			// first we need to locate the "loaded" state
 			//
 			// Note, it potentially could be a proxy, so doAfterTransactionCompletion the location the safe way...
 			final EntityKey key = session.generateEntityKey( id, this );
 			Object entity = session.getPersistenceContext().getEntity( key );
 			if ( entity != null ) {
 				EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 				loadedState = entry.getLoadedState();
 			}
 		}
 
 		final String[] deleteStrings;
 		if ( isImpliedOptimisticLocking && loadedState != null ) {
 			// we need to utilize dynamic delete statements
 			deleteStrings = generateSQLDeletStrings( loadedState );
 		}
 		else {
 			// otherwise, utilize the static delete statements
 			deleteStrings = getSQLDeleteStrings();
 		}
 
 		for ( int j = span - 1; j >= 0; j-- ) {
 			delete( id, version, j, object, deleteStrings[j], session, loadedState );
 		}
 
 	}
 
 	private boolean isAllOrDirtyOptLocking() {
 		return entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.DIRTY
 				|| entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL;
 	}
 
 	private String[] generateSQLDeletStrings(Object[] loadedState) {
 		int span = getTableSpan();
 		String[] deleteStrings = new String[span];
 		for ( int j = span - 1; j >= 0; j-- ) {
 			Delete delete = new Delete()
 					.setTableName( getTableName( j ) )
 					.addPrimaryKeyColumns( getKeyColumns( j ) );
-			if ( getFactory().getSettings().isCommentsEnabled() ) {
+			if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 				delete.setComment( "delete " + getEntityName() + " [" + j + "]" );
 			}
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				if ( isPropertyOfTable( i, j ) && versionability[i] ) {
 					// this property belongs to the table and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( loadedState[i], getFactory() );
 					for ( int k = 0; k < propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							delete.addWhereFragment( propertyColumnNames[k] + " = ?" );
 						}
 						else {
 							delete.addWhereFragment( propertyColumnNames[k] + " is null" );
 						}
 					}
 				}
 			}
 			deleteStrings[j] = delete.toStatementString();
 		}
 		return deleteStrings;
 	}
 
 	protected void logStaticSQL() {
         if ( LOG.isDebugEnabled() ) {
             LOG.debugf( "Static SQL for entity: %s", getEntityName() );
             if ( sqlLazySelectString != null ) {
 				LOG.debugf( " Lazy select: %s", sqlLazySelectString );
 			}
             if ( sqlVersionSelectString != null ) {
 				LOG.debugf( " Version select: %s", sqlVersionSelectString );
 			}
             if ( sqlSnapshotSelectString != null ) {
 				LOG.debugf( " Snapshot select: %s", sqlSnapshotSelectString );
 			}
 			for ( int j = 0; j < getTableSpan(); j++ ) {
                 LOG.debugf( " Insert %s: %s", j, getSQLInsertStrings()[j] );
                 LOG.debugf( " Update %s: %s", j, getSQLUpdateStrings()[j] );
                 LOG.debugf( " Delete %s: %s", j, getSQLDeleteStrings()[j] );
 			}
             if ( sqlIdentityInsertString != null ) {
 				LOG.debugf( " Identity insert: %s", sqlIdentityInsertString );
 			}
             if ( sqlUpdateByRowIdString != null ) {
 				LOG.debugf( " Update by row id (all fields): %s", sqlUpdateByRowIdString );
 			}
             if ( sqlLazyUpdateByRowIdString != null ) {
 				LOG.debugf( " Update by row id (non-lazy fields): %s", sqlLazyUpdateByRowIdString );
 			}
             if ( sqlInsertGeneratedValuesSelectString != null ) {
 				LOG.debugf( " Insert-generated property select: %s", sqlInsertGeneratedValuesSelectString );
 			}
             if ( sqlUpdateGeneratedValuesSelectString != null ) {
 				LOG.debugf( " Update-generated property select: %s", sqlUpdateGeneratedValuesSelectString );
 			}
 		}
 	}
 
 	@Override
 	public String filterFragment(String alias, Map enabledFilters) throws MappingException {
 		final StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 		return sessionFilterFragment.append( filterFragment( alias ) ).toString();
 	}
 
 	@Override
 	public String filterFragment(String alias, Map enabledFilters, Set<String> treatAsDeclarations) {
 		final StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 		return sessionFilterFragment.append( filterFragment( alias, treatAsDeclarations ) ).toString();
 	}
 
 	public String generateFilterConditionAlias(String rootAlias) {
 		return rootAlias;
 	}
 
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return "";
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		return oneToManyFilterFragment( alias );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, Collections.<String>emptySet() ).toFromFragmentString();
 	}
 
 	@Override
 	public String fromJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, treatAsDeclarations ).toFromFragmentString();
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, Collections.<String>emptySet() ).toWhereFragmentString();
 	}
 
 	@Override
 	public String whereJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, treatAsDeclarations ).toWhereFragmentString();
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return false;
 	}
 
 	protected JoinFragment createJoin(String name, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
 		// IMPL NOTE : all joins join to the pk of the driving table
 		final String[] idCols = StringHelper.qualify( name, getIdentifierColumnNames() );
 		final JoinFragment join = getFactory().getDialect().createOuterJoinFragment();
 		final int tableSpan = getSubclassTableSpan();
 		// IMPL NOTE : notice that we skip the first table; it is the driving table!
 		for ( int j = 1; j < tableSpan; j++ ) {
 			final JoinType joinType = determineSubclassTableJoinType(
 					j,
 					innerJoin,
 					includeSubclasses,
 					treatAsDeclarations
 			);
 
 			if ( joinType != null && joinType != JoinType.NONE ) {
 				join.addJoin(
 						getSubclassTableName( j ),
 						generateTableAlias( name, j ),
 						idCols,
 						getSubclassTableKeyColumns( j ),
 						joinType
 				);
 			}
 		}
 		return join;
 	}
 
 	protected JoinType determineSubclassTableJoinType(
 			int subclassTableNumber,
 			boolean canInnerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 
 		if ( isClassOrSuperclassTable( subclassTableNumber ) ) {
 			final boolean shouldInnerJoin = canInnerJoin
 					&& !isInverseTable( subclassTableNumber )
 					&& !isNullableTable( subclassTableNumber );
 			// the table is either this persister's driving table or (one of) its super class persister's driving
 			// tables which can be inner joined as long as the `shouldInnerJoin` condition resolves to true
 			return shouldInnerJoin ? JoinType.INNER_JOIN : JoinType.LEFT_OUTER_JOIN;
 		}
 
 		// otherwise we have a subclass table and need to look a little deeper...
 
 		// IMPL NOTE : By default includeSubclasses indicates that all subclasses should be joined and that each
 		// subclass ought to be joined by outer-join.  However, TREAT-AS always requires that an inner-join be used
 		// so we give TREAT-AS higher precedence...
 
 		if ( isSubclassTableIndicatedByTreatAsDeclarations( subclassTableNumber, treatAsDeclarations ) ) {
 			return JoinType.INNER_JOIN;
 		}
 
 		if ( includeSubclasses
 				&& !isSubclassTableSequentialSelect( subclassTableNumber )
 				&& !isSubclassTableLazy( subclassTableNumber ) ) {
 			return JoinType.LEFT_OUTER_JOIN;
 		}
 
 		return JoinType.NONE;
 	}
 
 	protected boolean isSubclassTableIndicatedByTreatAsDeclarations(
 			int subclassTableNumber,
 			Set<String> treatAsDeclarations) {
 		return false;
 	}
 
 
 	protected JoinFragment createJoin(int[] tableNumbers, String drivingAlias) {
 		final String[] keyCols = StringHelper.qualify( drivingAlias, getSubclassTableKeyColumns( tableNumbers[0] ) );
 		final JoinFragment jf = getFactory().getDialect().createOuterJoinFragment();
 		// IMPL NOTE : notice that we skip the first table; it is the driving table!
 		for ( int i = 1; i < tableNumbers.length; i++ ) {
 			final int j = tableNumbers[i];
 			jf.addJoin( getSubclassTableName( j ),
 					generateTableAlias( getRootAlias(), j ),
 					keyCols,
 					getSubclassTableKeyColumns( j ),
 					isInverseSubclassTable( j ) || isNullableSubclassTable( j )
 							? JoinType.LEFT_OUTER_JOIN
 							: JoinType.INNER_JOIN
 			);
 		}
 		return jf;
 	}
 
 	protected SelectFragment createSelect(final int[] subclassColumnNumbers,
 										  final int[] subclassFormulaNumbers) {
 
 		SelectFragment selectFragment = new SelectFragment();
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < subclassColumnNumbers.length; i++ ) {
 			int columnNumber = subclassColumnNumbers[i];
 			if ( subclassColumnSelectableClosure[columnNumber] ) {
 				final String subalias = generateTableAlias( getRootAlias(), columnTableNumbers[columnNumber] );
 				selectFragment.addColumnTemplate( subalias, columnReaderTemplates[columnNumber], columnAliases[columnNumber] );
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < subclassFormulaNumbers.length; i++ ) {
 			int formulaNumber = subclassFormulaNumbers[i];
 			final String subalias = generateTableAlias( getRootAlias(), formulaTableNumbers[formulaNumber] );
 			selectFragment.addFormula( subalias, formulaTemplates[formulaNumber], formulaAliases[formulaNumber] );
 		}
 
 		return selectFragment;
 	}
 
 	protected String createFrom(int tableNumber, String alias) {
 		return getSubclassTableName( tableNumber ) + ' ' + alias;
 	}
 
 	protected String createWhereByKey(int tableNumber, String alias) {
 		//TODO: move to .sql package, and refactor with similar things!
 		return StringHelper.join( "=? and ",
 				StringHelper.qualify( alias, getSubclassTableKeyColumns( tableNumber ) ) ) + "=?";
 	}
 
 	protected String renderSelect(
 			final int[] tableNumbers,
 	        final int[] columnNumbers,
 	        final int[] formulaNumbers) {
 
 		Arrays.sort( tableNumbers ); //get 'em in the right order (not that it really matters)
 
 		//render the where and from parts
 		int drivingTable = tableNumbers[0];
 		final String drivingAlias = generateTableAlias( getRootAlias(), drivingTable ); //we *could* regerate this inside each called method!
 		final String where = createWhereByKey( drivingTable, drivingAlias );
 		final String from = createFrom( drivingTable, drivingAlias );
 
 		//now render the joins
 		JoinFragment jf = createJoin( tableNumbers, drivingAlias );
 
 		//now render the select clause
 		SelectFragment selectFragment = createSelect( columnNumbers, formulaNumbers );
 
 		//now tie it all together
 		Select select = new Select( getFactory().getDialect() );
 		select.setSelectClause( selectFragment.toFragmentString().substring( 2 ) );
 		select.setFromClause( from );
 		select.setWhereClause( where );
 		select.setOuterJoins( jf.toFromFragmentString(), jf.toWhereFragmentString() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "sequential select " + getEntityName() );
 		}
 		return select.toStatementString();
 	}
 
 	private String getRootAlias() {
 		return StringHelper.generateAlias( getEntityName() );
 	}
 
 	/**
 	 * Post-construct is a callback for AbstractEntityPersister subclasses to call after they are all done with their
 	 * constructor processing.  It allows AbstractEntityPersister to extend its construction after all subclass-specific
 	 * details have been handled.
 	 *
 	 * @param mapping The mapping
 	 *
 	 * @throws MappingException Indicates a problem accessing the Mapping
 	 */
 	protected void postConstruct(Mapping mapping) throws MappingException {
 		initPropertyPaths( mapping );
 
 		//doLateInit();
 		prepareEntityIdentifierDefinition();
 	}
 
 	private void doLateInit() {
 		//insert/update/delete SQL
 		final int joinSpan = getTableSpan();
 		sqlDeleteStrings = new String[joinSpan];
 		sqlInsertStrings = new String[joinSpan];
 		sqlUpdateStrings = new String[joinSpan];
 		sqlLazyUpdateStrings = new String[joinSpan];
 
 		sqlUpdateByRowIdString = rowIdName == null ?
 				null :
 				generateUpdateString( getPropertyUpdateability(), 0, true );
 		sqlLazyUpdateByRowIdString = rowIdName == null ?
 				null :
 				generateUpdateString( getNonLazyPropertyUpdateability(), 0, true );
 
 		for ( int j = 0; j < joinSpan; j++ ) {
 			sqlInsertStrings[j] = customSQLInsert[j] == null ?
 					generateInsertString( getPropertyInsertability(), j ) :
 					customSQLInsert[j];
 			sqlUpdateStrings[j] = customSQLUpdate[j] == null ?
 					generateUpdateString( getPropertyUpdateability(), j, false ) :
 					customSQLUpdate[j];
 			sqlLazyUpdateStrings[j] = customSQLUpdate[j] == null ?
 					generateUpdateString( getNonLazyPropertyUpdateability(), j, false ) :
 					customSQLUpdate[j];
 			sqlDeleteStrings[j] = customSQLDelete[j] == null ?
 					generateDeleteString( j ) :
 					customSQLDelete[j];
 		}
 
 		tableHasColumns = new boolean[joinSpan];
 		for ( int j = 0; j < joinSpan; j++ ) {
 			tableHasColumns[j] = sqlUpdateStrings[j] != null;
 		}
 
 		//select SQL
 		sqlSnapshotSelectString = generateSnapshotSelectString();
 		sqlLazySelectString = generateLazySelectString();
 		sqlVersionSelectString = generateSelectVersionString();
 		if ( hasInsertGeneratedProperties() ) {
 			sqlInsertGeneratedValuesSelectString = generateInsertGeneratedValuesSelectString();
 		}
 		if ( hasUpdateGeneratedProperties() ) {
 			sqlUpdateGeneratedValuesSelectString = generateUpdateGeneratedValuesSelectString();
 		}
 		if ( isIdentifierAssignedByInsert() ) {
 			identityDelegate = ( ( PostInsertIdentifierGenerator ) getIdentifierGenerator() )
 					.getInsertGeneratedIdentifierDelegate( this, getFactory().getDialect(), useGetGeneratedKeys() );
 			sqlIdentityInsertString = customSQLInsert[0] == null
 					? generateIdentityInsertString( getPropertyInsertability() )
 					: customSQLInsert[0];
 		}
 		else {
 			sqlIdentityInsertString = null;
 		}
 
 		logStaticSQL();
 	}
 
 	public final void postInstantiate() throws MappingException {
 		doLateInit();
 
 		createLoaders();
 		createUniqueKeyLoaders();
 		createQueryLoader();
 
 		doPostInstantiate();
 	}
 
 	protected void doPostInstantiate() {
 	}
 
 	//needed by subclasses to override the createLoader strategy
 	protected Map getLoaders() {
 		return loaders;
 	}
 
 	//Relational based Persisters should be content with this implementation
 	protected void createLoaders() {
 		final Map loaders = getLoaders();
 		loaders.put( LockMode.NONE, createEntityLoader( LockMode.NONE ) );
 
 		UniqueEntityLoader readLoader = createEntityLoader( LockMode.READ );
 		loaders.put( LockMode.READ, readLoader );
 
 		//TODO: inexact, what we really need to know is: are any outer joins used?
 		boolean disableForUpdate = getSubclassTableSpan() > 1 &&
 				hasSubclasses() &&
 				!getFactory().getDialect().supportsOuterJoinForUpdate();
 
 		loaders.put(
 				LockMode.UPGRADE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE )
 			);
 		loaders.put(
 				LockMode.UPGRADE_NOWAIT,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE_NOWAIT )
 			);
 		loaders.put(
 				LockMode.UPGRADE_SKIPLOCKED,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE_SKIPLOCKED )
 			);
 		loaders.put(
 				LockMode.FORCE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.FORCE )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_READ,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_READ )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_WRITE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_WRITE )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_FORCE_INCREMENT,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_FORCE_INCREMENT )
 			);
 		loaders.put( LockMode.OPTIMISTIC, createEntityLoader( LockMode.OPTIMISTIC) );
 		loaders.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, createEntityLoader(LockMode.OPTIMISTIC_FORCE_INCREMENT) );
 
 		loaders.put(
 				"merge",
 				new CascadeEntityLoader( this, CascadingActions.MERGE, getFactory() )
 			);
 		loaders.put(
 				"refresh",
 				new CascadeEntityLoader( this, CascadingActions.REFRESH, getFactory() )
 			);
 	}
 
 	protected void createQueryLoader() {
 		if ( loaderName != null ) {
 			queryLoader = new NamedQueryLoader( loaderName, this );
 		}
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	public Object load(Serializable id, Object optionalObject, LockMode lockMode, SessionImplementor session) {
 		return load( id, optionalObject, new LockOptions().setLockMode(lockMode), session );
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	public Object load(Serializable id, Object optionalObject, LockOptions lockOptions, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Fetching entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		final UniqueEntityLoader loader = getAppropriateLoader(lockOptions, session );
 		return loader.load( id, optionalObject, session, lockOptions );
 	}
 
 	public void registerAffectingFetchProfile(String fetchProfileName) {
 		affectingFetchProfileNames.add( fetchProfileName );
 	}
 
 	private boolean isAffectedByEntityGraph(SessionImplementor session) {
 		return session.getLoadQueryInfluencers().getFetchGraph() != null || session.getLoadQueryInfluencers()
 				.getLoadGraph() != null;
 	}
 
 	private boolean isAffectedByEnabledFetchProfiles(SessionImplementor session) {
 		for ( String s : session.getLoadQueryInfluencers().getEnabledFetchProfileNames() ) {
 			if ( affectingFetchProfileNames.contains( s ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private boolean isAffectedByEnabledFilters(SessionImplementor session) {
 		return session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& filterHelper.isAffectedBy( session.getLoadQueryInfluencers().getEnabledFilters() );
 	}
 
 	private UniqueEntityLoader getAppropriateLoader(LockOptions lockOptions, SessionImplementor session) {
 		if ( queryLoader != null ) {
 			// if the user specified a custom query loader we need to that
 			// regardless of any other consideration
 			return queryLoader;
 		}
 		else if ( isAffectedByEnabledFilters( session ) ) {
 			// because filters affect the rows returned (because they add
 			// restrictions) these need to be next in precedence
 			return createEntityLoader(lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( session.getLoadQueryInfluencers().getInternalFetchProfile() != null && LockMode.UPGRADE.greaterThan( lockOptions.getLockMode() ) ) {
 			// Next, we consider whether an 'internal' fetch profile has been set.
 			// This indicates a special fetch profile Hibernate needs applied
 			// (for its merge loading process e.g.).
 			return ( UniqueEntityLoader ) getLoaders().get( session.getLoadQueryInfluencers().getInternalFetchProfile() );
 		}
 		else if ( isAffectedByEnabledFetchProfiles( session ) ) {
 			// If the session has associated influencers we need to adjust the
 			// SQL query used for loading based on those influencers
 			return createEntityLoader(lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( isAffectedByEntityGraph( session ) ) {
 			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else {
 			return ( UniqueEntityLoader ) getLoaders().get( lockOptions.getLockMode() );
 		}
 	}
 
 	private boolean isAllNull(Object[] array, int tableNumber) {
 		for ( int i = 0; i < array.length; i++ ) {
 			if ( isPropertyOfTable( i, tableNumber ) && array[i] != null ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public boolean isSubclassPropertyNullable(int i) {
 		return subclassPropertyNullabilityClosure[i];
 	}
 
 	/**
 	 * Transform the array of property indexes to an array of booleans,
 	 * true when the property is dirty
 	 */
 	protected final boolean[] getPropertiesToUpdate(final int[] dirtyProperties, final boolean hasDirtyCollection) {
 		final boolean[] propsToUpdate = new boolean[ entityMetamodel.getPropertySpan() ];
 		final boolean[] updateability = getPropertyUpdateability(); //no need to check laziness, dirty checking handles that
 		for ( int j = 0; j < dirtyProperties.length; j++ ) {
 			int property = dirtyProperties[j];
 			if ( updateability[property] ) {
 				propsToUpdate[property] = true;
 			}
 		}
 		if ( isVersioned() && updateability[getVersionProperty() ]) {
 			propsToUpdate[ getVersionProperty() ] =
 				Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
 		}
 		return propsToUpdate;
 	}
 
 	/**
 	 * Transform the array of property indexes to an array of booleans,
 	 * true when the property is insertable and non-null
 	 */
 	protected boolean[] getPropertiesToInsert(Object[] fields) {
 		boolean[] notNull = new boolean[fields.length];
 		boolean[] insertable = getPropertyInsertability();
 		for ( int i = 0; i < fields.length; i++ ) {
 			notNull[i] = insertable[i] && fields[i] != null;
 		}
 		return notNull;
 	}
 
 	/**
 	 * Locate the property-indices of all properties considered to be dirty.
 	 *
 	 * @param currentState The current state of the entity (the state to be checked).
 	 * @param previousState The previous state of the entity (the state to be checked against).
 	 * @param entity The entity for which we are checking state dirtiness.
 	 * @param session The session in which the check is occurring.
 	 * @return <tt>null</tt> or the indices of the dirty properties
 	 * @throws HibernateException
 	 */
 	public int[] findDirty(Object[] currentState, Object[] previousState, Object entity, SessionImplementor session)
 	throws HibernateException {
 		int[] props = TypeHelper.findDirty(
 				entityMetamodel.getProperties(),
 				currentState,
 				previousState,
 				propertyColumnUpdateable,
 				hasUninitializedLazyProperties( entity ),
 				session
-			);
+		);
 		if ( props == null ) {
 			return null;
 		}
 		else {
 			logDirtyProperties( props );
 			return props;
 		}
 	}
 
 	/**
 	 * Locate the property-indices of all properties considered to be dirty.
 	 *
 	 * @param old The old state of the entity.
 	 * @param current The current state of the entity.
 	 * @param entity The entity for which we are checking state modification.
 	 * @param session The session in which the check is occurring.
 	 * @return <tt>null</tt> or the indices of the modified properties
 	 * @throws HibernateException
 	 */
 	public int[] findModified(Object[] old, Object[] current, Object entity, SessionImplementor session)
 	throws HibernateException {
 		int[] props = TypeHelper.findModified(
 				entityMetamodel.getProperties(),
 				current,
 				old,
 				propertyColumnUpdateable,
 				hasUninitializedLazyProperties( entity ),
 				session
-			);
+		);
 		if ( props == null ) {
 			return null;
 		}
 		else {
 			logDirtyProperties( props );
 			return props;
 		}
 	}
 
 	/**
 	 * Which properties appear in the SQL update?
 	 * (Initialized, updateable ones!)
 	 */
 	protected boolean[] getPropertyUpdateability(Object entity) {
 		return hasUninitializedLazyProperties( entity )
 				? getNonLazyPropertyUpdateability()
 				: getPropertyUpdateability();
 	}
 
 	private void logDirtyProperties(int[] props) {
 		if ( LOG.isTraceEnabled() ) {
 			for ( int i = 0; i < props.length; i++ ) {
 				String propertyName = entityMetamodel.getProperties()[ props[i] ].getName();
 				LOG.trace( StringHelper.qualify( getEntityName(), propertyName ) + " is dirty" );
 			}
 		}
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	public EntityMetamodel getEntityMetamodel() {
 		return entityMetamodel;
 	}
 
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	public EntityRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	@Override
 	public CacheEntryStructure getCacheEntryStructure() {
 		return cacheEntryHelper.getCacheEntryStructure();
 	}
 
 	@Override
 	public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 		return cacheEntryHelper.buildCacheEntry( entity, state, version, session );
 	}
 
 	public boolean hasNaturalIdCache() {
 		return naturalIdRegionAccessStrategy != null;
 	}
 	
 	public NaturalIdRegionAccessStrategy getNaturalIdCacheAccessStrategy() {
 		return naturalIdRegionAccessStrategy;
 	}
 
 	public Comparator getVersionComparator() {
 		return isVersioned() ? getVersionType().getComparator() : null;
 	}
 
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public final String getEntityName() {
 		return entityMetamodel.getName();
 	}
 
 	public EntityType getEntityType() {
 		return entityMetamodel.getEntityType();
 	}
 
 	public boolean isPolymorphic() {
 		return entityMetamodel.isPolymorphic();
 	}
 
 	public boolean isInherited() {
 		return entityMetamodel.isInherited();
 	}
 
 	public boolean hasCascades() {
 		return entityMetamodel.hasCascades();
 	}
 
 	public boolean hasIdentifierProperty() {
 		return !entityMetamodel.getIdentifierProperty().isVirtual();
 	}
 
 	public VersionType getVersionType() {
 		return ( VersionType ) locateVersionType();
 	}
 
 	private Type locateVersionType() {
 		return entityMetamodel.getVersionProperty() == null ?
 				null :
 				entityMetamodel.getVersionProperty().getType();
 	}
 
 	public int getVersionProperty() {
 		return entityMetamodel.getVersionPropertyIndex();
 	}
 
 	public boolean isVersioned() {
 		return entityMetamodel.isVersioned();
 	}
 
 	public boolean isIdentifierAssignedByInsert() {
 		return entityMetamodel.getIdentifierProperty().isIdentifierAssignedByInsert();
 	}
 
 	public boolean hasLazyProperties() {
 		return entityMetamodel.hasLazyProperties();
 	}
 
 //	public boolean hasUninitializedLazyProperties(Object entity) {
 //		if ( hasLazyProperties() ) {
 //			InterceptFieldCallback callback = ( ( InterceptFieldEnabled ) entity ).getInterceptFieldCallback();
 //			return callback != null && !( ( FieldInterceptor ) callback ).isInitialized();
 //		}
 //		else {
 //			return false;
 //		}
 //	}
 
 	public void afterReassociate(Object entity, SessionImplementor session) {
 		if ( getEntityMetamodel().getInstrumentationMetadata().isInstrumented() ) {
 			FieldInterceptor interceptor = getEntityMetamodel().getInstrumentationMetadata().extractInterceptor( entity );
 			if ( interceptor != null ) {
 				interceptor.setSession( session );
 			}
 			else {
 				FieldInterceptor fieldInterceptor = getEntityMetamodel().getInstrumentationMetadata().injectInterceptor(
 						entity,
 						getEntityName(),
 						null,
 						session
 				);
 				fieldInterceptor.dirty();
 			}
 		}
 
 		handleNaturalIdReattachment( entity, session );
 	}
 
 	private void handleNaturalIdReattachment(Object entity, SessionImplementor session) {
 		if ( ! hasNaturalIdentifier() ) {
 			return;
 		}
 
 		if ( getEntityMetamodel().hasImmutableNaturalId() ) {
 			// we assume there were no changes to natural id during detachment for now, that is validated later
 			// during flush.
 			return;
 		}
 
 		final NaturalIdHelper naturalIdHelper = session.getPersistenceContext().getNaturalIdHelper();
 		final Serializable id = getIdentifier( entity, session );
 
 		// for reattachment of mutable natural-ids, we absolutely positively have to grab the snapshot from the
 		// database, because we have no other way to know if the state changed while detached.
 		final Object[] naturalIdSnapshot;
 		final Object[] entitySnapshot = session.getPersistenceContext().getDatabaseSnapshot( id, this );
 		if ( entitySnapshot == StatefulPersistenceContext.NO_ROW ) {
 			naturalIdSnapshot = null;
 		}
 		else {
 			naturalIdSnapshot = naturalIdHelper.extractNaturalIdValues( entitySnapshot, this );
 		}
 
 		naturalIdHelper.removeSharedNaturalIdCrossReference( this, id, naturalIdSnapshot );
 		naturalIdHelper.manageLocalNaturalIdCrossReference(
 				this,
 				id,
 				naturalIdHelper.extractNaturalIdValues( entity, this ),
 				naturalIdSnapshot,
 				CachedNaturalIdValueSource.UPDATE
 		);
 	}
 
 	public Boolean isTransient(Object entity, SessionImplementor session) throws HibernateException {
 		final Serializable id;
 		if ( canExtractIdOutOfEntity() ) {
 			id = getIdentifier( entity, session );
 		}
 		else {
 			id = null;
 		}
 		// we *always* assume an instance with a null
 		// identifier or no identifier property is unsaved!
 		if ( id == null ) {
 			return Boolean.TRUE;
 		}
 
 		// check the version unsaved-value, if appropriate
 		final Object version = getVersion( entity );
 		if ( isVersioned() ) {
 			// let this take precedence if defined, since it works for
 			// assigned identifiers
 			Boolean result = entityMetamodel.getVersionProperty()
 					.getUnsavedValue().isUnsaved( version );
 			if ( result != null ) {
 				return result;
 			}
 		}
 
 		// check the id unsaved-value
 		Boolean result = entityMetamodel.getIdentifierProperty()
 				.getUnsavedValue().isUnsaved( id );
 		if ( result != null ) {
 			return result;
 		}
 
 		// check to see if it is in the second-level cache
 		if ( session.getCacheMode().isGetEnabled() && hasCache() ) {
 			final CacheKey ck = session.generateCacheKey( id, getIdentifierType(), getRootEntityName() );
 			final Object ce = CacheHelper.fromSharedCache( session, ck, getCacheAccessStrategy() );
 			if ( ce != null ) {
 				return Boolean.FALSE;
 			}
 		}
 
 		return null;
 	}
 
 	public boolean hasCollections() {
 		return entityMetamodel.hasCollections();
 	}
 
 	public boolean hasMutableProperties() {
 		return entityMetamodel.hasMutableProperties();
 	}
 
 	public boolean isMutable() {
 		return entityMetamodel.isMutable();
 	}
 
 	private boolean isModifiableEntity(EntityEntry entry) {
-
 		return ( entry == null ? isMutable() : entry.isModifiableEntity() );
 	}
 
 	public boolean isAbstract() {
 		return entityMetamodel.isAbstract();
 	}
 
 	public boolean hasSubclasses() {
 		return entityMetamodel.hasSubclasses();
 	}
 
 	public boolean hasProxy() {
 		return entityMetamodel.isLazy();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator() throws HibernateException {
 		return entityMetamodel.getIdentifierProperty().getIdentifierGenerator();
 	}
 
 	public String getRootEntityName() {
 		return entityMetamodel.getRootName();
 	}
 
 	public ClassMetadata getClassMetadata() {
 		return this;
 	}
 
 	public String getMappedSuperclass() {
 		return entityMetamodel.getSuperclass();
 	}
 
 	public boolean isExplicitPolymorphism() {
 		return entityMetamodel.isExplicitPolymorphism();
 	}
 
 	protected boolean useDynamicUpdate() {
 		return entityMetamodel.isDynamicUpdate();
 	}
 
 	protected boolean useDynamicInsert() {
 		return entityMetamodel.isDynamicInsert();
 	}
 
 	protected boolean hasEmbeddedCompositeIdentifier() {
 		return entityMetamodel.getIdentifierProperty().isEmbedded();
 	}
 
 	public boolean canExtractIdOutOfEntity() {
 		return hasIdentifierProperty() || hasEmbeddedCompositeIdentifier() || hasIdentifierMapper();
 	}
 
 	private boolean hasIdentifierMapper() {
 		return entityMetamodel.getIdentifierProperty().hasIdentifierMapper();
 	}
 
 	public String[] getKeyColumnNames() {
 		return getIdentifierColumnNames();
 	}
 
 	public String getName() {
 		return getEntityName();
 	}
 
 	public boolean isCollection() {
 		return false;
 	}
 
 	public boolean consumesEntityAlias() {
 		return true;
 	}
 
 	public boolean consumesCollectionAlias() {
 		return false;
 	}
 
 	public Type getPropertyType(String propertyName) throws MappingException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public Type getType() {
 		return entityMetamodel.getEntityType();
 	}
 
 	public boolean isSelectBeforeUpdateRequired() {
 		return entityMetamodel.isSelectBeforeUpdate();
 	}
 
 	protected final OptimisticLockStyle optimisticLockStyle() {
 		return entityMetamodel.getOptimisticLockStyle();
 	}
 
 	public Object createProxy(Serializable id, SessionImplementor session) throws HibernateException {
 		return entityMetamodel.getTuplizer().createProxy( id, session );
 	}
 
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) +
 				'(' + entityMetamodel.getName() + ')';
 	}
 
 	public final String selectFragment(
 			Joinable rhs,
 			String rhsAlias,
 			String lhsAlias,
 			String entitySuffix,
 			String collectionSuffix,
 			boolean includeCollectionColumns) {
 		return selectFragment( lhsAlias, entitySuffix );
 	}
 
 	public boolean isInstrumented() {
 		return entityMetamodel.isInstrumented();
 	}
 
 	public boolean hasInsertGeneratedProperties() {
 		return entityMetamodel.hasInsertGeneratedValues();
 	}
 
 	public boolean hasUpdateGeneratedProperties() {
 		return entityMetamodel.hasUpdateGeneratedValues();
 	}
 
 	public boolean isVersionPropertyGenerated() {
 		return isVersioned() && getEntityMetamodel().isVersionGenerated();
 	}
 
 	public boolean isVersionPropertyInsertable() {
 		return isVersioned() && getPropertyInsertability() [ getVersionProperty() ];
 	}
 
 	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
 		getEntityTuplizer().afterInitialize( entity, lazyPropertiesAreUnfetched, session );
 	}
 
 	public String[] getPropertyNames() {
 		return entityMetamodel.getPropertyNames();
 	}
 
 	public Type[] getPropertyTypes() {
 		return entityMetamodel.getPropertyTypes();
 	}
 
 	public boolean[] getPropertyLaziness() {
 		return entityMetamodel.getPropertyLaziness();
 	}
 
 	public boolean[] getPropertyUpdateability() {
 		return entityMetamodel.getPropertyUpdateability();
 	}
 
 	public boolean[] getPropertyCheckability() {
 		return entityMetamodel.getPropertyCheckability();
 	}
 
 	public boolean[] getNonLazyPropertyUpdateability() {
 		return entityMetamodel.getNonlazyPropertyUpdateability();
 	}
 
 	public boolean[] getPropertyInsertability() {
 		return entityMetamodel.getPropertyInsertability();
 	}
 
+	/**
+	 * @deprecated no simple, direct replacement
+	 */
 	@Deprecated
 	public ValueInclusion[] getPropertyInsertGenerationInclusions() {
 		return null;
 	}
 
+	/**
+	 * @deprecated no simple, direct replacement
+	 */
 	@Deprecated
 	public ValueInclusion[] getPropertyUpdateGenerationInclusions() {
 		return null;
 	}
 
 	public boolean[] getPropertyNullability() {
 		return entityMetamodel.getPropertyNullability();
 	}
 
 	public boolean[] getPropertyVersionability() {
 		return entityMetamodel.getPropertyVersionability();
 	}
 
 	public CascadeStyle[] getPropertyCascadeStyles() {
 		return entityMetamodel.getCascadeStyles();
 	}
 
 	public final Class getMappedClass() {
 		return getEntityTuplizer().getMappedClass();
 	}
 
 	public boolean implementsLifecycle() {
 		return getEntityTuplizer().isLifecycleImplementor();
 	}
 
 	public Class getConcreteProxyClass() {
 		return getEntityTuplizer().getConcreteProxyClass();
 	}
 
 	public void setPropertyValues(Object object, Object[] values) {
 		getEntityTuplizer().setPropertyValues( object, values );
 	}
 
 	public void setPropertyValue(Object object, int i, Object value) {
 		getEntityTuplizer().setPropertyValue( object, i, value );
 	}
 
 	public Object[] getPropertyValues(Object object) {
 		return getEntityTuplizer().getPropertyValues( object );
 	}
 
 	@Override
 	public Object getPropertyValue(Object object, int i) {
 		return getEntityTuplizer().getPropertyValue( object, i );
 	}
 
 	@Override
 	public Object getPropertyValue(Object object, String propertyName) {
 		return getEntityTuplizer().getPropertyValue( object, propertyName );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object object) {
 		return getEntityTuplizer().getIdentifier( object, null );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object entity, SessionImplementor session) {
 		return getEntityTuplizer().getIdentifier( entity, session );
 	}
 
 	@Override
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 		getEntityTuplizer().setIdentifier( entity, id, session );
 	}
 
 	@Override
 	public Object getVersion(Object object) {
 		return getEntityTuplizer().getVersion( object );
 	}
 
 	@Override
 	public Object instantiate(Serializable id, SessionImplementor session) {
 		return getEntityTuplizer().instantiate( id, session );
 	}
 
 	@Override
 	public boolean isInstance(Object object) {
 		return getEntityTuplizer().isInstance( object );
 	}
 
 	@Override
 	public boolean hasUninitializedLazyProperties(Object object) {
 		return getEntityTuplizer().hasUninitializedLazyProperties( object );
 	}
 
 	@Override
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session) {
 		getEntityTuplizer().resetIdentifier( entity, currentId, currentVersion, session );
 	}
 
 	@Override
 	public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory) {
 		if ( !hasSubclasses() ) {
 			return this;
 		}
 		else {
 			final String concreteEntityName = getEntityTuplizer().determineConcreteSubclassEntityName(
 					instance,
 					factory
 			);
 			if ( concreteEntityName == null || getEntityName().equals( concreteEntityName ) ) {
 				// the contract of EntityTuplizer.determineConcreteSubclassEntityName says that returning null
 				// is an indication that the specified entity-name (this.getEntityName) should be used.
 				return this;
 			}
 			else {
 				return factory.getEntityPersister( concreteEntityName );
 			}
 		}
 	}
 
 	public boolean isMultiTable() {
 		return false;
 	}
 
 	protected int getPropertySpan() {
 		return entityMetamodel.getPropertySpan();
 	}
 
 	public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session) throws HibernateException {
 		return getEntityTuplizer().getPropertyValuesToInsert( object, mergeMap, session );
 	}
 
 	public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 		if ( !hasInsertGeneratedProperties() ) {
 			throw new AssertionFailure("no insert-generated properties");
 		}
 		processGeneratedProperties( id, entity, state, session, sqlInsertGeneratedValuesSelectString, GenerationTiming.INSERT );
 	}
 
 	public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 		if ( !hasUpdateGeneratedProperties() ) {
 			throw new AssertionFailure("no update-generated properties");
 		}
 		processGeneratedProperties( id, entity, state, session, sqlUpdateGeneratedValuesSelectString, GenerationTiming.ALWAYS );
 	}
 
 	private void processGeneratedProperties(
 			Serializable id,
 	        Object entity,
 	        Object[] state,
 	        SessionImplementor session,
 	        String selectionSQL,
 			GenerationTiming matchTiming) {
 		// force immediate execution of the insert batch (if one)
 		session.getJdbcCoordinator().executeBatch();
 
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( selectionSQL );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					if ( !rs.next() ) {
 						throw new HibernateException(
 								"Unable to locate row for retrieval of generated properties: " +
 								MessageHelper.infoString( this, id, getFactory() )
 							);
 					}
 					int propertyIndex = -1;
 					for ( NonIdentifierAttribute attribute : entityMetamodel.getProperties() ) {
 						propertyIndex++;
 						final ValueGeneration valueGeneration = attribute.getValueGenerationStrategy();
 						if ( isReadRequired( valueGeneration, matchTiming ) ) {
 							final Object hydratedState = attribute.getType().hydrate(
 									rs, getPropertyAliases(
 									"",
 									propertyIndex
 							), session, entity
 							);
 							state[propertyIndex] = attribute.getType().resolve( hydratedState, session, entity );
 							setPropertyValue( entity, propertyIndex, state[propertyIndex] );
 						}
 					}
 //					for ( int i = 0; i < getPropertySpan(); i++ ) {
 //						if ( includeds[i] != ValueInclusion.NONE ) {
 //							Object hydratedState = getPropertyTypes()[i].hydrate( rs, getPropertyAliases( "", i ), session, entity );
 //							state[i] = getPropertyTypes()[i].resolve( hydratedState, session, entity );
 //							setPropertyValue( entity, i, state[i] );
 //						}
 //					}
 				}
 				finally {
 					if ( rs != null ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 					}
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"unable to select generated column values",
 					selectionSQL
 			);
 		}
 
 	}
 
 	/**
 	 * Whether the given value generation strategy requires to read the value from the database or not.
 	 */
 	private boolean isReadRequired(ValueGeneration valueGeneration, GenerationTiming matchTiming) {
 		return valueGeneration != null &&
 				valueGeneration.getValueGenerator() == null &&
 				timingsMatch( valueGeneration.getGenerationTiming(), matchTiming );
 	}
 
 	private boolean timingsMatch(GenerationTiming timing, GenerationTiming matchTiming) {
 		return
 				(matchTiming == GenerationTiming.INSERT && timing.includesInsert()) ||
 						(matchTiming == GenerationTiming.ALWAYS && timing.includesUpdate());
 	}
 
 	public String getIdentifierPropertyName() {
 		return entityMetamodel.getIdentifierProperty().getName();
 	}
 
 	public Type getIdentifierType() {
 		return entityMetamodel.getIdentifierProperty().getType();
 	}
 
 	public boolean hasSubselectLoadableCollections() {
 		return hasSubselectLoadableCollections;
 	}
 
 	public int[] getNaturalIdentifierProperties() {
 		return entityMetamodel.getNaturalIdentifierProperties();
 	}
 
 	public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !hasNaturalIdentifier() ) {
 			throw new MappingException( "persistent class did not define a natural-id : " + MessageHelper.infoString( this ) );
 		}
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting current natural-id snapshot state for: {0}",
 					MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		int[] naturalIdPropertyIndexes = getNaturalIdentifierProperties();
 		int naturalIdPropertyCount = naturalIdPropertyIndexes.length;
 		boolean[] naturalIdMarkers = new boolean[ getPropertySpan() ];
 		Type[] extractionTypes = new Type[ naturalIdPropertyCount ];
 		for ( int i = 0; i < naturalIdPropertyCount; i++ ) {
 			extractionTypes[i] = getPropertyTypes()[ naturalIdPropertyIndexes[i] ];
 			naturalIdMarkers[ naturalIdPropertyIndexes[i] ] = true;
 		}
 
 		///////////////////////////////////////////////////////////////////////
 		// TODO : look at perhaps caching this...
 		Select select = new Select( getFactory().getDialect() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get current natural-id state " + getEntityName() );
 		}
 		select.setSelectClause( concretePropertySelectFragmentSansLeadingComma( getRootAlias(), naturalIdMarkers ) );
 		select.setFromClause( fromTableFragment( getRootAlias() ) + fromJoinFragment( getRootAlias(), true, false ) );
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String whereClause = new StringBuilder()
 			.append( StringHelper.join( "=? and ",
 					aliasedIdColumns ) )
 			.append( "=?" )
 			.append( whereJoinFragment( getRootAlias(), true, false ) )
 			.toString();
 
 		String sql = select.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 		///////////////////////////////////////////////////////////////////////
 
 		Object[] snapshot = new Object[ naturalIdPropertyCount ];
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sql );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					final EntityKey key = session.generateEntityKey( id, this );
 					Object owner = session.getPersistenceContext().getEntity( key );
 					for ( int i = 0; i < naturalIdPropertyCount; i++ ) {
 						snapshot[i] = extractionTypes[i].hydrate( rs, getPropertyAliases( "", naturalIdPropertyIndexes[i] ), session, null );
 						if (extractionTypes[i].isEntityType()) {
 							snapshot[i] = extractionTypes[i].resolve(snapshot[i], session, owner);
 						}
 					}
 					return snapshot;
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
 			        sql
 			);
 		}
 	}
 
 	@Override
 	public Serializable loadEntityIdByNaturalId(
 			Object[] naturalIdValues,
 			LockOptions lockOptions,
 			SessionImplementor session) {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"Resolving natural-id [%s] to id : %s ",
 					naturalIdValues,
 					MessageHelper.infoString( this )
 			);
 		}
 
 		final boolean[] valueNullness = determineValueNullness( naturalIdValues );
 		final String sqlEntityIdByNaturalIdString = determinePkByNaturalIdQuery( valueNullness );
 
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlEntityIdByNaturalIdString );
 			try {
 				int positions = 1;
 				int loop = 0;
 				for ( int idPosition : getNaturalIdentifierProperties() ) {
 					final Object naturalIdValue = naturalIdValues[loop++];
 					if ( naturalIdValue != null ) {
 						final Type type = getPropertyTypes()[idPosition];
 						type.nullSafeSet( ps, naturalIdValue, positions, session );
 						positions += type.getColumnSpan( session.getFactory() );
 					}
 				}
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					// if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 
 					final Object hydratedId = getIdentifierType().hydrate( rs, getIdentifierAliases(), session, null );
 					return (Serializable) getIdentifierType().resolve( hydratedId, session, null );
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve natural-id [%s] to id : %s",
 							naturalIdValues,
 							MessageHelper.infoString( this )
 					),
 					sqlEntityIdByNaturalIdString
 			);
 		}
 	}
 
 	private boolean[] determineValueNullness(Object[] naturalIdValues) {
 		boolean[] nullness = new boolean[ naturalIdValues.length ];
 		for ( int i = 0; i < naturalIdValues.length; i++ ) {
 			nullness[i] = naturalIdValues[i] == null;
 		}
 		return nullness;
 	}
 
 	private Boolean naturalIdIsNonNullable;
 	private String cachedPkByNonNullableNaturalIdQuery;
 
 	private String determinePkByNaturalIdQuery(boolean[] valueNullness) {
 		if ( ! hasNaturalIdentifier() ) {
 			throw new HibernateException( "Attempt to build natural-id -> PK resolution query for entity that does not define natural id" );
 		}
 
 		// performance shortcut for cases where the natural-id is defined as completely non-nullable
 		if ( isNaturalIdNonNullable() ) {
 			if ( valueNullness != null && ! ArrayHelper.isAllFalse( valueNullness ) ) {
 				throw new HibernateException( "Null value(s) passed to lookup by non-nullable natural-id" );
 			}
 			if ( cachedPkByNonNullableNaturalIdQuery == null ) {
 				cachedPkByNonNullableNaturalIdQuery = generateEntityIdByNaturalIdSql( null );
 			}
 			return cachedPkByNonNullableNaturalIdQuery;
 		}
 
 		// Otherwise, regenerate it each time
 		return generateEntityIdByNaturalIdSql( valueNullness );
 	}
 
 	protected boolean isNaturalIdNonNullable() {
 		if ( naturalIdIsNonNullable == null ) {
 			naturalIdIsNonNullable = determineNaturalIdNullability();
 		}
 		return naturalIdIsNonNullable;
 	}
 
 	private boolean determineNaturalIdNullability() {
 		boolean[] nullability = getPropertyNullability();
 		for ( int position : getNaturalIdentifierProperties() ) {
 			// if any individual property is nullable, return false
 			if ( nullability[position] ) {
 				return false;
 			}
 		}
 		// return true if we found no individually nullable properties
 		return true;
 	}
 
 	private String generateEntityIdByNaturalIdSql(boolean[] valueNullness) {
 		EntityPersister rootPersister = getFactory().getEntityPersister( getRootEntityName() );
 		if ( rootPersister != this ) {
 			if ( rootPersister instanceof AbstractEntityPersister ) {
 				return ( (AbstractEntityPersister) rootPersister ).generateEntityIdByNaturalIdSql( valueNullness );
 			}
 		}
 
 		Select select = new Select( getFactory().getDialect() );
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get current natural-id->entity-id state " + getEntityName() );
 		}
 
 		final String rootAlias = getRootAlias();
 
 		select.setSelectClause( identifierSelectFragment( rootAlias, "" ) );
 		select.setFromClause( fromTableFragment( rootAlias ) + fromJoinFragment( rootAlias, true, false ) );
 
 		final StringBuilder whereClause = new StringBuilder();
 		final int[] propertyTableNumbers = getPropertyTableNumbers();
 		final int[] naturalIdPropertyIndexes = this.getNaturalIdentifierProperties();
 		int valuesIndex = -1;
 		for ( int propIdx = 0; propIdx < naturalIdPropertyIndexes.length; propIdx++ ) {
 			valuesIndex++;
 			if ( propIdx > 0 ) {
 				whereClause.append( " and " );
 			}
 
 			final int naturalIdIdx = naturalIdPropertyIndexes[propIdx];
 			final String tableAlias = generateTableAlias( rootAlias, propertyTableNumbers[naturalIdIdx] );
 			final String[] propertyColumnNames = getPropertyColumnNames( naturalIdIdx );
 			final String[] aliasedPropertyColumns = StringHelper.qualify( tableAlias, propertyColumnNames );
 
 			if ( valueNullness != null && valueNullness[valuesIndex] ) {
 				whereClause.append( StringHelper.join( " is null and ", aliasedPropertyColumns ) ).append( " is null" );
 			}
 			else {
 				whereClause.append( StringHelper.join( "=? and ", aliasedPropertyColumns ) ).append( "=?" );
 			}
 		}
 
 		whereClause.append( whereJoinFragment( getRootAlias(), true, false ) );
 
 		return select.setOuterJoins( "", "" ).setWhereClause( whereClause.toString() ).toStatementString();
 	}
 
 	protected String concretePropertySelectFragmentSansLeadingComma(String alias, boolean[] include) {
 		String concretePropertySelectFragment = concretePropertySelectFragment( alias, include );
 		int firstComma = concretePropertySelectFragment.indexOf( ", " );
 		if ( firstComma == 0 ) {
 			concretePropertySelectFragment = concretePropertySelectFragment.substring( 2 );
 		}
 		return concretePropertySelectFragment;
 	}
 
 	public boolean hasNaturalIdentifier() {
 		return entityMetamodel.hasNaturalIdentifier();
 	}
 
 	public void setPropertyValue(Object object, String propertyName, Object value) {
 		getEntityTuplizer().setPropertyValue( object, propertyName, value );
 	}
 	
 	public static int getTableId(String tableName, String[] tables) {
 		for ( int j = 0; j < tables.length; j++ ) {
 			if ( tableName.equalsIgnoreCase( tables[j] ) ) {
 				return j;
 			}
 		}
 		throw new AssertionFailure( "Table " + tableName + " not found" );
 	}
 	
 	@Override
 	public EntityMode getEntityMode() {
 		return entityMetamodel.getEntityMode();
 	}
 
 	@Override
 	public EntityTuplizer getEntityTuplizer() {
 		return entityTuplizer;
 	}
 
 	@Override
 	public EntityInstrumentationMetadata getInstrumentationMetadata() {
 		return entityMetamodel.getInstrumentationMetadata();
 	}
 
 	@Override
 	public String getTableAliasForColumn(String columnName, String rootAlias) {
 		return generateTableAlias( rootAlias, determineTableNumberForColumn( columnName ) );
 	}
 
 	public int determineTableNumberForColumn(String columnName) {
 		return 0;
 	}
 
 	@Override
 	public EntityEntryFactory getEntityEntryFactory() {
 		return this.entityEntryFactory;
 	}
 
 	/**
 	 * Consolidated these onto a single helper because the 2 pieces work in tandem.
 	 */
-	public static interface CacheEntryHelper {
-		public CacheEntryStructure getCacheEntryStructure();
-
-		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session);
+	public interface CacheEntryHelper {
+		CacheEntryStructure getCacheEntryStructure();
+		CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session);
 	}
 
 	private static class StandardCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 
 		private StandardCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new StandardCacheEntryImpl(
 					state,
 					persister,
 					persister.hasUninitializedLazyProperties( entity ),
 					version,
 					session,
 					entity
 			);
 		}
 	}
 
 	private static class ReferenceCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 
 		private ReferenceCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new ReferenceCacheEntryImpl( entity, persister );
 		}
 	}
 
 	private static class StructuredCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 		private final StructuredCacheEntry structure;
 
 		private StructuredCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 			this.structure = new StructuredCacheEntry( persister );
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return structure;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new StandardCacheEntryImpl(
 					state,
 					persister,
 					persister.hasUninitializedLazyProperties( entity ),
 					version,
 					session,
 					entity
 			);
 		}
 	}
 
 	private static class NoopCacheEntryHelper implements CacheEntryHelper {
 		public static final NoopCacheEntryHelper INSTANCE = new NoopCacheEntryHelper();
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			throw new HibernateException( "Illegal attempt to build cache entry for non-cached entity" );
 		}
 	}
 
 
 	// EntityDefinition impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private EntityIdentifierDefinition entityIdentifierDefinition;
 	private Iterable<AttributeDefinition> embeddedCompositeIdentifierAttributes;
 	private Iterable<AttributeDefinition> attributeDefinitions;
 
 	@Override
 	public void generateEntityDefinition() {
 		prepareEntityIdentifierDefinition();
 		collectAttributeDefinitions();
 	}
 
 	@Override
 	public EntityPersister getEntityPersister() {
 		return this;
 	}
 
 	@Override
 	public EntityIdentifierDefinition getEntityKeyDefinition() {
 		return entityIdentifierDefinition;
 	}
 
 	@Override
 	public Iterable<AttributeDefinition> getAttributes() {
 		return attributeDefinitions;
 	}
 
 
 	private void prepareEntityIdentifierDefinition() {
 		if ( entityIdentifierDefinition != null ) {
 			return;
 		}
 		final Type idType = getIdentifierType();
 
 		if ( !idType.isComponentType() ) {
 			entityIdentifierDefinition =
 					EntityIdentifierDefinitionHelper.buildSimpleEncapsulatedIdentifierDefinition( this );
 			return;
 		}
 
 		final CompositeType cidType = (CompositeType) idType;
 		if ( !cidType.isEmbedded() ) {
 			entityIdentifierDefinition =
 					EntityIdentifierDefinitionHelper.buildEncapsulatedCompositeIdentifierDefinition( this );
 			return;
 		}
 
 		entityIdentifierDefinition =
 				EntityIdentifierDefinitionHelper.buildNonEncapsulatedCompositeIdentifierDefinition( this );
 	}
 
 	private void collectAttributeDefinitions(
 			Map<String,AttributeDefinition> attributeDefinitionsByName,
 			EntityMetamodel metamodel) {
 		for ( int i = 0; i < metamodel.getPropertySpan(); i++ ) {
 			final AttributeDefinition attributeDefinition = metamodel.getProperties()[i];
 			// Don't replace an attribute definition if it is already in attributeDefinitionsByName
 			// because the new value will be from a subclass.
 			final AttributeDefinition oldAttributeDefinition = attributeDefinitionsByName.get(
 					attributeDefinition.getName()
 			);
 			if ( oldAttributeDefinition != null ) {
 				if ( LOG.isTraceEnabled() ) {
 						LOG.tracef(
 								"Ignoring subclass attribute definition [%s.%s] because it is defined in a superclass ",
 								entityMetamodel.getName(),
 								attributeDefinition.getName()
 						);
 				}
 			}
 			else {
 				attributeDefinitionsByName.put( attributeDefinition.getName(), attributeDefinition );
 			}
 		}
 
 		// see if there are any subclass persisters...
 		final Set<String> subClassEntityNames = metamodel.getSubclassEntityNames();
 		if ( subClassEntityNames == null ) {
 			return;
 		}
 
 		// see if we can find the persisters...
 		for ( String subClassEntityName : subClassEntityNames ) {
 			if ( metamodel.getName().equals( subClassEntityName ) ) {
 				// skip it
 				continue;
 			}
 			try {
 				final EntityPersister subClassEntityPersister = factory.getEntityPersister( subClassEntityName );
 				collectAttributeDefinitions( attributeDefinitionsByName, subClassEntityPersister.getEntityMetamodel() );
 			}
 			catch (MappingException e) {
 				throw new IllegalStateException(
 						String.format(
 								"Could not locate subclass EntityPersister [%s] while processing EntityPersister [%s]",
 								subClassEntityName,
 								metamodel.getName()
 						),
 						e
 				);
 			}
 		}
 	}
 
 	private void collectAttributeDefinitions() {
 		// todo : I think this works purely based on luck atm
 		// 		specifically in terms of the sub/super class entity persister(s) being available.  Bit of chicken-egg
 		// 		problem there:
 		//			* If I do this during postConstruct (as it is now), it works as long as the
 		//			super entity persister is already registered, but I don't think that is necessarily true.
 		//			* If I do this during postInstantiate then lots of stuff in postConstruct breaks if we want
 		//			to try and drive SQL generation on these (which we do ultimately).  A possible solution there
 		//			would be to delay all SQL generation until postInstantiate
 
 		Map<String,AttributeDefinition> attributeDefinitionsByName = new LinkedHashMap<String,AttributeDefinition>();
 		collectAttributeDefinitions( attributeDefinitionsByName, getEntityMetamodel() );
 
 
 //		EntityMetamodel currentEntityMetamodel = this.getEntityMetamodel();
 //		while ( currentEntityMetamodel != null ) {
 //			for ( int i = 0; i < currentEntityMetamodel.getPropertySpan(); i++ ) {
 //				attributeDefinitions.add( currentEntityMetamodel.getProperties()[i] );
 //			}
 //			// see if there is a super class EntityMetamodel
 //			final String superEntityName = currentEntityMetamodel.getSuperclass();
 //			if ( superEntityName != null ) {
 //				currentEntityMetamodel = factory.getEntityPersister( superEntityName ).getEntityMetamodel();
 //			}
 //			else {
 //				currentEntityMetamodel = null;
 //			}
 //		}
 
 		this.attributeDefinitions = Collections.unmodifiableList(
 				new ArrayList<AttributeDefinition>( attributeDefinitionsByName.values() )
 		);
 //		// todo : leverage the attribute definitions housed on EntityMetamodel
 //		// 		for that to work, we'd have to be able to walk our super entity persister(s)
 //		this.attributeDefinitions = new Iterable<AttributeDefinition>() {
 //			@Override
 //			public Iterator<AttributeDefinition> iterator() {
 //				return new Iterator<AttributeDefinition>() {
 ////					private final int numberOfAttributes = countSubclassProperties();
 ////					private final int numberOfAttributes = entityMetamodel.getPropertySpan();
 //
 //					EntityMetamodel currentEntityMetamodel = entityMetamodel;
 //					int numberOfAttributesInCurrentEntityMetamodel = currentEntityMetamodel.getPropertySpan();
 //
 //					private int currentAttributeNumber;
 //
 //					@Override
 //					public boolean hasNext() {
 //						return currentEntityMetamodel != null
 //								&& currentAttributeNumber < numberOfAttributesInCurrentEntityMetamodel;
 //					}
 //
 //					@Override
 //					public AttributeDefinition next() {
 //						final int attributeNumber = currentAttributeNumber;
 //						currentAttributeNumber++;
 //						final AttributeDefinition next = currentEntityMetamodel.getProperties()[ attributeNumber ];
 //
 //						if ( currentAttributeNumber >= numberOfAttributesInCurrentEntityMetamodel ) {
 //							// see if there is a super class EntityMetamodel
 //							final String superEntityName = currentEntityMetamodel.getSuperclass();
 //							if ( superEntityName != null ) {
 //								currentEntityMetamodel = factory.getEntityPersister( superEntityName ).getEntityMetamodel();
 //								if ( currentEntityMetamodel != null ) {
 //									numberOfAttributesInCurrentEntityMetamodel = currentEntityMetamodel.getPropertySpan();
 //									currentAttributeNumber = 0;
 //								}
 //							}
 //						}
 //
 //						return next;
 //					}
 //
 //					@Override
 //					public void remove() {
 //						throw new UnsupportedOperationException( "Remove operation not supported here" );
 //					}
 //				};
 //			}
 //		};
 	}
 
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
index 13d4a09e39..6b77d61c0d 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
@@ -1,298 +1,299 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.entity;
 
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.spi.Mapping;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.sql.Template;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Basic implementation of the {@link PropertyMapping} contract.
  *
  * @author Gavin King
  */
 public abstract class AbstractPropertyMapping implements PropertyMapping {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
-                                                                       AbstractPropertyMapping.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( AbstractPropertyMapping.class );
 
 	private final Map typesByPropertyPath = new HashMap();
 	private final Map columnsByPropertyPath = new HashMap();
 	private final Map columnReadersByPropertyPath = new HashMap();
 	private final Map columnReaderTemplatesByPropertyPath = new HashMap();
 	private final Map formulaTemplatesByPropertyPath = new HashMap();
 
 	public String[] getIdentifierColumnNames() {
 		throw new UnsupportedOperationException("one-to-one is not supported here");
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		throw new UnsupportedOperationException("one-to-one is not supported here");
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		throw new UnsupportedOperationException("one-to-one is not supported here");
 	}
 
 	protected abstract String getEntityName();
 
 	public Type toType(String propertyName) throws QueryException {
 		Type type = (Type) typesByPropertyPath.get(propertyName);
 		if ( type == null ) {
 			throw propertyException( propertyName );
 		}
 		return type;
 	}
 
 	protected final QueryException propertyException(String propertyName) throws QueryException {
 		return new QueryException( "could not resolve property: " + propertyName + " of: " + getEntityName() );
 	}
 
 	public String[] getColumnNames(String propertyName) {
 		String[] cols = (String[]) columnsByPropertyPath.get(propertyName);
 		if (cols==null) {
 			throw new MappingException("unknown property: " + propertyName);
 		}
 		return cols;
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		//TODO: *two* hashmap lookups here is one too many...
 		String[] columns = (String[]) columnsByPropertyPath.get(propertyName);
 		if ( columns == null ) {
 			throw propertyException( propertyName );
 		}
 		String[] formulaTemplates = (String[]) formulaTemplatesByPropertyPath.get(propertyName);
 		String[] columnReaderTemplates = (String[]) columnReaderTemplatesByPropertyPath.get(propertyName);
 		String[] result = new String[columns.length];
 		for ( int i=0; i<columns.length; i++ ) {
 			if ( columnReaderTemplates[i]==null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.replace( columnReaderTemplates[i], Template.TEMPLATE, alias );
 			}
 		}
 		return result;
 	}
 
 	public String[] toColumns(String propertyName) throws QueryException {
 		String[] columns = (String[]) columnsByPropertyPath.get(propertyName);
 		if ( columns == null ) {
 			throw propertyException( propertyName );
 		}
 		String[] formulaTemplates = (String[]) formulaTemplatesByPropertyPath.get(propertyName);
 		String[] columnReaders = (String[]) columnReadersByPropertyPath.get(propertyName);
 		String[] result = new String[columns.length];
 		for ( int i=0; i<columns.length; i++ ) {
 			if ( columnReaders[i]==null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, "" );
 			}
 			else {
 				result[i] = columnReaders[i];
 			}
 		}
 		return result;
 	}
 
 	protected void addPropertyPath(
 			String path,
 			Type type,
 			String[] columns,
 			String[] columnReaders,
 			String[] columnReaderTemplates,
 			String[] formulaTemplates) {
 		// TODO : not quite sure yet of the difference, but this is only needed from annotations for @Id @ManyToOne support
 		if ( typesByPropertyPath.containsKey( path ) ) {
 			if ( LOG.isTraceEnabled() ) {
 				LOG.tracev( "Skipping duplicate registration of path [{0}], existing type = [{1}], incoming type = [{2}]", path, typesByPropertyPath.get( path ), type );
 			}
 			return;
 		}
 		typesByPropertyPath.put(path, type);
 		columnsByPropertyPath.put(path, columns);
 		columnReadersByPropertyPath.put(path, columnReaders);
 		columnReaderTemplatesByPropertyPath.put(path, columnReaderTemplates);
 		if (formulaTemplates!=null) {
 			formulaTemplatesByPropertyPath.put(path, formulaTemplates);
 		}
 	}
 
 	/*protected void initPropertyPaths(
 			final String path,
 			final Type type,
 			final String[] columns,
 			final String[] formulaTemplates,
 			final Mapping factory)
 	throws MappingException {
 		//addFormulaPropertyPath(path, type, formulaTemplates);
 		initPropertyPaths(path, type, columns, formulaTemplates, factory);
 	}*/
 
 	protected void initPropertyPaths(
 			final String path,
 			final Type type,
 			String[] columns,
 			String[] columnReaders,
 			String[] columnReaderTemplates,
 			final String[] formulaTemplates,
 			final Mapping factory) throws MappingException {
 		assert columns != null : "Incoming columns should not be null : " + path;
 		assert type != null : "Incoming type should not be null : " + path;
 
 		if ( columns.length!=type.getColumnSpan(factory) ) {
 			throw new MappingException(
 					"broken column mapping for: " + path +
 					" of: " + getEntityName()
 				);
 		}
 
 		if ( type.isAssociationType() ) {
 			AssociationType actype = (AssociationType) type;
 			if ( actype.useLHSPrimaryKey() ) {
 				columns = getIdentifierColumnNames();
 				columnReaders = getIdentifierColumnReaders();
 				columnReaderTemplates = getIdentifierColumnReaderTemplates();
 			}
 			else {
 				String foreignKeyProperty = actype.getLHSPropertyName();
 				if ( foreignKeyProperty!=null && !path.equals(foreignKeyProperty) ) {
 					//TODO: this requires that the collection is defined after the
 					//      referenced property in the mapping file (ok?)
 					columns = (String[]) columnsByPropertyPath.get(foreignKeyProperty);
 					if (columns==null) return; //get em on the second pass!
 					columnReaders = (String[]) columnReadersByPropertyPath.get(foreignKeyProperty);
 					columnReaderTemplates = (String[]) columnReaderTemplatesByPropertyPath.get(foreignKeyProperty);
 				}
 			}
 		}
 
-		if (path!=null) addPropertyPath(path, type, columns, columnReaders, columnReaderTemplates, formulaTemplates);
+		if (path!=null) {
+			addPropertyPath(path, type, columns, columnReaders, columnReaderTemplates, formulaTemplates);
+		}
 
 		if ( type.isComponentType() ) {
 			CompositeType actype = (CompositeType) type;
 			initComponentPropertyPaths( path, actype, columns, columnReaders, columnReaderTemplates, formulaTemplates, factory );
 			if ( actype.isEmbedded() ) {
 				initComponentPropertyPaths(
 						path==null ? null : StringHelper.qualifier(path),
 						actype,
 						columns,
 						columnReaders,
 						columnReaderTemplates,
 						formulaTemplates,
 						factory
 					);
 			}
 		}
 		else if ( type.isEntityType() ) {
 			initIdentifierPropertyPaths( path, (EntityType) type, columns, columnReaders, columnReaderTemplates, factory );
 		}
 	}
 
 	protected void initIdentifierPropertyPaths(
 			final String path,
 			final EntityType etype,
 			final String[] columns,
 			final String[] columnReaders,
 			final String[] columnReaderTemplates,
 			final Mapping factory) throws MappingException {
 
 		Type idtype = etype.getIdentifierOrUniqueKeyType( factory );
 		String idPropName = etype.getIdentifierOrUniqueKeyPropertyName(factory);
 		boolean hasNonIdentifierPropertyNamedId = hasNonIdentifierPropertyNamedId( etype, factory );
 
 		if ( etype.isReferenceToPrimaryKey() ) {
 			if ( !hasNonIdentifierPropertyNamedId ) {
 				String idpath1 = extendPath(path, EntityPersister.ENTITY_ID);
 				addPropertyPath(idpath1, idtype, columns, columnReaders, columnReaderTemplates, null);
 				initPropertyPaths(idpath1, idtype, columns, columnReaders, columnReaderTemplates, null, factory);
 			}
 		}
 
 		if (idPropName!=null) {
 			String idpath2 = extendPath(path, idPropName);
 			addPropertyPath(idpath2, idtype, columns, columnReaders, columnReaderTemplates, null);
 			initPropertyPaths(idpath2, idtype, columns, columnReaders, columnReaderTemplates, null, factory);
 		}
 	}
 
 	private boolean hasNonIdentifierPropertyNamedId(final EntityType entityType, final Mapping factory) {
 		// TODO : would be great to have a Mapping#hasNonIdentifierPropertyNamedId method
 		// I don't believe that Mapping#getReferencedPropertyType accounts for the identifier property; so
 		// if it returns for a property named 'id', then we should have a non-id field named id
 		try {
 			return factory.getReferencedPropertyType( entityType.getAssociatedEntityName(), EntityPersister.ENTITY_ID ) != null;
 		}
 		catch( MappingException e ) {
 			return false;
 		}
 	}
 
 	protected void initComponentPropertyPaths(
 			final String path,
 			final CompositeType type,
 			final String[] columns,
 			final String[] columnReaders,
 			final String[] columnReaderTemplates,
 			String[] formulaTemplates, final Mapping factory) throws MappingException {
 
 		Type[] types = type.getSubtypes();
 		String[] properties = type.getPropertyNames();
 		int begin=0;
 		for ( int i=0; i<properties.length; i++ ) {
 			String subpath = extendPath( path, properties[i] );
 			try {
 				int length = types[i].getColumnSpan(factory);
 				String[] columnSlice = ArrayHelper.slice(columns, begin, length);
 				String[] columnReaderSlice = ArrayHelper.slice(columnReaders, begin, length);
 				String[] columnReaderTemplateSlice = ArrayHelper.slice( columnReaderTemplates, begin, length );
 				String[] formulaSlice = formulaTemplates==null ?
 						null : ArrayHelper.slice(formulaTemplates, begin, length);
 				initPropertyPaths(subpath, types[i], columnSlice, columnReaderSlice, columnReaderTemplateSlice, formulaSlice, factory);
 				begin+=length;
 			}
 			catch (Exception e) {
 				throw new MappingException("bug in initComponentPropertyPaths", e);
 			}
 		}
 	}
 
 	private static String extendPath(String path, String property) {
 		return StringHelper.isEmpty( path ) ? property : StringHelper.qualify( path, property );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/EntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/EntityPersister.java
index 6c18c110b3..862c8be588 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/EntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/EntityPersister.java
@@ -1,806 +1,807 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.bytecode.spi.EntityInstrumentationMetadata;
 import org.hibernate.cache.spi.OptimisticCacheSource;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.EntityEntryFactory;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.ValueInclusion;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * Contract describing mapping information and persistence logic for a particular strategy of entity mapping.  A given
  * persister instance corresponds to a given mapped entity class.
  * <p/>
  * Implementations must be thread-safe (preferably immutable).
  * <p/>
  * Unless a custom {@link org.hibernate.persister.spi.PersisterFactory} is used, it is expected
  * that implementations of EntityPersister define a constructor accepting the following arguments:<ol>
  *     <li>
  *         {@link org.hibernate.mapping.PersistentClass} - describes the metadata about the entity
  *         to be handled by the persister
  *     </li>
  *     <li>
  *         {@link EntityRegionAccessStrategy} - the second level caching strategy for this entity
  *     </li>
  *     <li>
  *         {@link NaturalIdRegionAccessStrategy} - the second level caching strategy for the natural-id
  *         defined for this entity, if one
  *     </li>
  *     <li>
  *         {@link org.hibernate.persister.spi.PersisterCreationContext} - access to additional
  *         information useful while constructing the persister.
  *     </li>
  * </ol>
  *
  * @author Gavin King
  * @author Steve Ebersole
  *
  * @see org.hibernate.persister.spi.PersisterFactory
  * @see org.hibernate.persister.spi.PersisterClassResolver
  */
 public interface EntityPersister extends OptimisticCacheSource, EntityDefinition {
 
 	/**
 	 * The property name of the "special" identifier property in HQL
 	 */
 	public static final String ENTITY_ID = "id";
 
 	/**
 	 * Generate the entity definition for this object. This must be done for all
 	 * entity persisters before calling {@link #postInstantiate()}.
 	 */
 	public void generateEntityDefinition();
 
 	/**
 	 * Finish the initialization of this object. {@link #generateEntityDefinition()}
 	 * must be called for all entity persisters before calling this method.
 	 * <p/>
 	 * Called only once per {@link org.hibernate.SessionFactory} lifecycle,
 	 * after all entity persisters have been instantiated.
 	 *
 	 * @throws org.hibernate.MappingException Indicates an issue in the metadata.
 	 */
 	public void postInstantiate() throws MappingException;
 
 	/**
 	 * Return the SessionFactory to which this persister "belongs".
 	 *
 	 * @return The owning SessionFactory.
 	 */
 	public SessionFactoryImplementor getFactory();
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     // stuff that is persister-centric and/or EntityInfo-centric ~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Get the EntityEntryFactory indicated for the entity mapped by this persister.
 	 *
 	 * @return The proper EntityEntryFactory.
 	 */
 	public EntityEntryFactory getEntityEntryFactory();
 
 	/**
 	 * Returns an object that identifies the space in which identifiers of
 	 * this entity hierarchy are unique.  Might be a table name, a JNDI URL, etc.
 	 *
 	 * @return The root entity name.
 	 */
 	public String getRootEntityName();
 
 	/**
 	 * The entity name which this persister maps.
 	 *
 	 * @return The name of the entity which this persister maps.
 	 */
 	public String getEntityName();
 
 	/**
 	 * Retrieve the underlying entity metamodel instance...
 	 *
 	 *@return The metamodel
 	 */
 	public EntityMetamodel getEntityMetamodel();
 
 	/**
 	 * Determine whether the given name represents a subclass entity
 	 * (or this entity itself) of the entity mapped by this persister.
 	 *
 	 * @param entityName The entity name to be checked.
 	 * @return True if the given entity name represents either the entity
 	 * mapped by this persister or one of its subclass entities; false
 	 * otherwise.
 	 */
 	public boolean isSubclassEntityName(String entityName);
 
 	/**
 	 * Returns an array of objects that identify spaces in which properties of
 	 * this entity are persisted, for instances of this class only.
 	 * <p/>
 	 * For most implementations, this returns the complete set of table names
 	 * to which instances of the mapped entity are persisted (not accounting
 	 * for superclass entity mappings).
 	 *
 	 * @return The property spaces.
 	 */
 	public Serializable[] getPropertySpaces();
 
 	/**
 	 * Returns an array of objects that identify spaces in which properties of
 	 * this entity are persisted, for instances of this class and its subclasses.
 	 * <p/>
 	 * Much like {@link #getPropertySpaces()}, except that here we include subclass
 	 * entity spaces.
 	 *
 	 * @return The query spaces.
 	 */
 	public Serializable[] getQuerySpaces();
 
 	/**
 	 * Determine whether this entity supports dynamic proxies.
 	 *
 	 * @return True if the entity has dynamic proxy support; false otherwise.
 	 */
 	public boolean hasProxy();
 
 	/**
 	 * Determine whether this entity contains references to persistent collections.
 	 *
 	 * @return True if the entity does contain persistent collections; false otherwise.
 	 */
 	public boolean hasCollections();
 
 	/**
 	 * Determine whether any properties of this entity are considered mutable.
 	 *
 	 * @return True if any properties of the entity are mutable; false otherwise (meaning none are).
 	 */
 	public boolean hasMutableProperties();
 
 	/**
 	 * Determine whether this entity contains references to persistent collections
 	 * which are fetchable by subselect?
 	 *
 	 * @return True if the entity contains collections fetchable by subselect; false otherwise.
 	 */
 	public boolean hasSubselectLoadableCollections();
 
 	/**
 	 * Determine whether this entity has any non-none cascading.
 	 *
 	 * @return True if the entity has any properties with a cascade other than NONE;
 	 * false otherwise (aka, no cascading).
 	 */
 	public boolean hasCascades();
 
 	/**
 	 * Determine whether instances of this entity are considered mutable.
 	 *
 	 * @return True if the entity is considered mutable; false otherwise.
 	 */
 	public boolean isMutable();
 
 	/**
 	 * Determine whether the entity is inherited one or more other entities.
 	 * In other words, is this entity a subclass of other entities.
 	 *
 	 * @return True if other entities extend this entity; false otherwise.
 	 */
 	public boolean isInherited();
 
 	/**
 	 * Are identifiers of this entity assigned known before the insert execution?
 	 * Or, are they generated (in the database) by the insert execution.
 	 *
 	 * @return True if identifiers for this entity are generated by the insert
 	 * execution.
 	 */
 	public boolean isIdentifierAssignedByInsert();
 
 	/**
 	 * Get the type of a particular property by name.
 	 *
 	 * @param propertyName The name of the property for which to retrieve
 	 * the type.
 	 * @return The type.
 	 * @throws org.hibernate.MappingException Typically indicates an unknown
 	 * property name.
 	 */
 	public Type getPropertyType(String propertyName) throws MappingException;
 
 	/**
 	 * Compare the two snapshots to determine if they represent dirty state.
 	 *
 	 * @param currentState The current snapshot
 	 * @param previousState The baseline snapshot
 	 * @param owner The entity containing the state
 	 * @param session The originating session
 	 * @return The indices of all dirty properties, or null if no properties
 	 * were dirty.
 	 */
 	public int[] findDirty(Object[] currentState, Object[] previousState, Object owner, SessionImplementor session);
 
 	/**
 	 * Compare the two snapshots to determine if they represent modified state.
 	 *
 	 * @param old The baseline snapshot
 	 * @param current The current snapshot
 	 * @param object The entity containing the state
 	 * @param session The originating session
 	 * @return The indices of all modified properties, or null if no properties
 	 * were modified.
 	 */
 	public int[] findModified(Object[] old, Object[] current, Object object, SessionImplementor session);
 
 	/**
 	 * Determine whether the entity has a particular property holding
 	 * the identifier value.
 	 *
 	 * @return True if the entity has a specific property holding identifier value.
 	 */
 	public boolean hasIdentifierProperty();
 
 	/**
 	 * Determine whether detached instances of this entity carry their own
 	 * identifier value.
 	 * <p/>
 	 * The other option is the deprecated feature where users could supply
 	 * the id during session calls.
 	 *
 	 * @return True if either (1) {@link #hasIdentifierProperty()} or
 	 * (2) the identifier is an embedded composite identifier; false otherwise.
 	 */
 	public boolean canExtractIdOutOfEntity();
 
 	/**
 	 * Determine whether optimistic locking by column is enabled for this
 	 * entity.
 	 *
 	 * @return True if optimistic locking by column (i.e., <version/> or
 	 * <timestamp/>) is enabled; false otherwise.
 	 */
 	public boolean isVersioned();
 
 	/**
 	 * If {@link #isVersioned()}, then what is the type of the property
 	 * holding the locking value.
 	 *
 	 * @return The type of the version property; or null, if not versioned.
 	 */
 	public VersionType getVersionType();
 
 	/**
 	 * If {@link #isVersioned()}, then what is the index of the property
 	 * holding the locking value.
 	 *
 	 * @return The type of the version property; or -66, if not versioned.
 	 */
 	public int getVersionProperty();
 
 	/**
 	 * Determine whether this entity defines a natural identifier.
 	 *
 	 * @return True if the entity defines a natural id; false otherwise.
 	 */
 	public boolean hasNaturalIdentifier();
 
 	/**
 	 * If the entity defines a natural id ({@link #hasNaturalIdentifier()}), which
 	 * properties make up the natural id.
 	 *
 	 * @return The indices of the properties making of the natural id; or
 	 * null, if no natural id is defined.
 	 */
 	public int[] getNaturalIdentifierProperties();
 
 	/**
 	 * Retrieve the current state of the natural-id properties from the database.
 	 *
 	 * @param id The identifier of the entity for which to retrieve the natural-id values.
 	 * @param session The session from which the request originated.
 	 * @return The natural-id snapshot.
 	 */
 	public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session);
 
 	/**
 	 * Determine which identifier generation strategy is used for this entity.
 	 *
 	 * @return The identifier generation strategy.
 	 */
 	public IdentifierGenerator getIdentifierGenerator();
 
 	/**
 	 * Determine whether this entity defines any lazy properties (ala
 	 * bytecode instrumentation).
 	 *
 	 * @return True if the entity has properties mapped as lazy; false otherwise.
 	 */
 	public boolean hasLazyProperties();
 
 	/**
 	 * Load the id for the entity based on the natural id.
 	 */
 	public Serializable loadEntityIdByNaturalId(Object[] naturalIdValues, LockOptions lockOptions,
 			SessionImplementor session);
 
 	/**
 	 * Load an instance of the persistent class.
 	 */
 	public Object load(Serializable id, Object optionalObject, LockMode lockMode, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Load an instance of the persistent class.
 	 */
 	public Object load(Serializable id, Object optionalObject, LockOptions lockOptions, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Do a version check (optional operation)
 	 */
 	public void lock(Serializable id, Object version, Object object, LockMode lockMode, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Do a version check (optional operation)
 	 */
 	public void lock(Serializable id, Object version, Object object, LockOptions lockOptions, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Persist an instance
 	 */
 	public void insert(Serializable id, Object[] fields, Object object, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Persist an instance, using a natively generated identifier (optional operation)
 	 */
 	public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Delete a persistent instance
 	 */
 	public void delete(Serializable id, Object version, Object object, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Update a persistent instance
 	 */
 	public void update(
 		Serializable id,
 		Object[] fields,
 		int[] dirtyFields,
 		boolean hasDirtyCollection,
 		Object[] oldFields,
 		Object oldVersion,
 		Object object,
 		Object rowId,
 		SessionImplementor session
 	) throws HibernateException;
 
 	/**
 	 * Get the Hibernate types of the class properties
 	 */
 	public Type[] getPropertyTypes();
 
 	/**
 	 * Get the names of the class properties - doesn't have to be the names of the
 	 * actual Java properties (used for XML generation only)
 	 */
 	public String[] getPropertyNames();
 
 	/**
 	 * Get the "insertability" of the properties of this class
 	 * (does the property appear in an SQL INSERT)
 	 */
 	public boolean[] getPropertyInsertability();
 
 	/**
 	 * Which of the properties of this class are database generated values on insert?
 	 *
 	 * @deprecated Replaced internally with InMemoryValueGenerationStrategy / InDatabaseValueGenerationStrategy
 	 */
 	@Deprecated
 	public ValueInclusion[] getPropertyInsertGenerationInclusions();
 
 	/**
 	 * Which of the properties of this class are database generated values on update?
 	 *
 	 * @deprecated Replaced internally with InMemoryValueGenerationStrategy / InDatabaseValueGenerationStrategy
 	 */
 	@Deprecated
 	public ValueInclusion[] getPropertyUpdateGenerationInclusions();
 
 	/**
 	 * Get the "updateability" of the properties of this class
 	 * (does the property appear in an SQL UPDATE)
 	 */
 	public boolean[] getPropertyUpdateability();
 
 	/**
 	 * Get the "checkability" of the properties of this class
 	 * (is the property dirty checked, does the cache need
 	 * to be updated)
 	 */
 	public boolean[] getPropertyCheckability();
 
 	/**
 	 * Get the nullability of the properties of this class
 	 */
 	public boolean[] getPropertyNullability();
 
 	/**
 	 * Get the "versionability" of the properties of this class
 	 * (is the property optimistic-locked)
 	 */
 	public boolean[] getPropertyVersionability();
 	public boolean[] getPropertyLaziness();
 	/**
 	 * Get the cascade styles of the properties (optional operation)
 	 */
 	public CascadeStyle[] getPropertyCascadeStyles();
 
 	/**
 	 * Get the identifier type
 	 */
 	public Type getIdentifierType();
 
 	/**
 	 * Get the name of the identifier property (or return null) - need not return the
 	 * name of an actual Java property
 	 */
 	public String getIdentifierPropertyName();
 
 	/**
 	 * Should we always invalidate the cache instead of
 	 * recaching updated state
 	 */
 	public boolean isCacheInvalidationRequired();
 	/**
 	 * Should lazy properties of this entity be cached?
 	 */
 	public boolean isLazyPropertiesCacheable();
 	/**
 	 * Does this class have a cache.
 	 */
 	public boolean hasCache();
 	/**
 	 * Get the cache (optional operation)
 	 */
 	public EntityRegionAccessStrategy getCacheAccessStrategy();
 	/**
 	 * Get the cache structure
 	 */
 	public CacheEntryStructure getCacheEntryStructure();
 
 	public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session);
 
 	/**
 	 * Does this class have a natural id cache
 	 */
 	public boolean hasNaturalIdCache();
 	
 	/**
 	 * Get the NaturalId cache (optional operation)
 	 */
 	public NaturalIdRegionAccessStrategy getNaturalIdCacheAccessStrategy();
 
 	/**
 	 * Get the user-visible metadata for the class (optional operation)
 	 */
 	public ClassMetadata getClassMetadata();
 
 	/**
 	 * Is batch loading enabled?
 	 */
 	public boolean isBatchLoadable();
 
 	/**
 	 * Is select snapshot before update enabled?
 	 */
 	public boolean isSelectBeforeUpdateRequired();
 
 	/**
 	 * Get the current database state of the object, in a "hydrated" form, without
 	 * resolving identifiers
 	 * @return null if there is no row in the database
 	 */
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 	throws HibernateException;
 
 	public Serializable getIdByUniqueKey(Serializable key, String uniquePropertyName, SessionImplementor session);
 
 	/**
 	 * Get the current version of the object, or return null if there is no row for
 	 * the given identifier. In the case of unversioned data, return any object
 	 * if the row exists.
 	 */
 	public Object getCurrentVersion(Serializable id, SessionImplementor session)
 	throws HibernateException;
 
 	public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Has the class actually been bytecode instrumented?
 	 */
 	public boolean isInstrumented();
 
 	/**
 	 * Does this entity define any properties as being database generated on insert?
 	 *
 	 * @return True if this entity contains at least one property defined
 	 * as generated (including version property, but not identifier).
 	 */
 	public boolean hasInsertGeneratedProperties();
 
 	/**
 	 * Does this entity define any properties as being database generated on update?
 	 *
 	 * @return True if this entity contains at least one property defined
 	 * as generated (including version property, but not identifier).
 	 */
 	public boolean hasUpdateGeneratedProperties();
 
 	/**
 	 * Does this entity contain a version property that is defined
 	 * to be database generated?
 	 *
 	 * @return true if this entity contains a version property and that
 	 * property has been marked as generated.
 	 */
 	public boolean isVersionPropertyGenerated();
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// stuff that is tuplizer-centric, but is passed a session ~~~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Called just after the entities properties have been initialized
 	 */
 	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session);
 
 	/**
 	 * Called just after the entity has been reassociated with the session
 	 */
 	public void afterReassociate(Object entity, SessionImplementor session);
 
 	/**
 	 * Create a new proxy instance
 	 */
 	public Object createProxy(Serializable id, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Is this a new transient instance?
 	 */
 	public Boolean isTransient(Object object, SessionImplementor session) throws HibernateException;
 
 	/**
 	 * Return the values of the insertable properties of the object (including backrefs)
 	 */
 	public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session) throws HibernateException;
 
 	/**
 	 * Perform a select to retrieve the values of any generated properties
 	 * back from the database, injecting these generated values into the
 	 * given entity as well as writing this state to the
 	 * {@link org.hibernate.engine.spi.PersistenceContext}.
 	 * <p/>
 	 * Note, that because we update the PersistenceContext here, callers
 	 * need to take care that they have already written the initial snapshot
 	 * to the PersistenceContext before calling this method.
 	 *
 	 * @param id The entity's id value.
 	 * @param entity The entity for which to get the state.
 	 * @param state
 	 * @param session The session
 	 */
 	public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session);
 	/**
 	 * Perform a select to retrieve the values of any generated properties
 	 * back from the database, injecting these generated values into the
 	 * given entity as well as writing this state to the
 	 * {@link org.hibernate.engine.spi.PersistenceContext}.
 	 * <p/>
 	 * Note, that because we update the PersistenceContext here, callers
 	 * need to take care that they have already written the initial snapshot
 	 * to the PersistenceContext before calling this method.
 	 *
 	 * @param id The entity's id value.
 	 * @param entity The entity for which to get the state.
 	 * @param state
 	 * @param session The session
 	 */
 	public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session);
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// stuff that is Tuplizer-centric ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * The persistent class, or null
 	 */
 	public Class getMappedClass();
 
 	/**
 	 * Does the class implement the {@link org.hibernate.classic.Lifecycle} interface.
 	 */
 	public boolean implementsLifecycle();
 
 	/**
 	 * Get the proxy interface that instances of <em>this</em> concrete class will be
 	 * cast to (optional operation).
 	 */
 	public Class getConcreteProxyClass();
 
 	/**
 	 * Set the given values to the mapped properties of the given object
 	 */
 	public void setPropertyValues(Object object, Object[] values);
 
 	/**
 	 * Set the value of a particular property
 	 */
 	public void setPropertyValue(Object object, int i, Object value);
 
 	/**
 	 * Return the (loaded) values of the mapped properties of the object (not including backrefs)
 	 */
 	public Object[] getPropertyValues(Object object);
 
 	/**
 	 * Get the value of a particular property
 	 */
 	public Object getPropertyValue(Object object, int i) throws HibernateException;
 
 	/**
 	 * Get the value of a particular property
 	 */
 	public Object getPropertyValue(Object object, String propertyName);
 
 	/**
 	 * Get the identifier of an instance (throw an exception if no identifier property)
 	 *
 	 * @deprecated Use {@link #getIdentifier(Object,SessionImplementor)} instead
 	 */
+	@Deprecated
 	@SuppressWarnings( {"JavaDoc"})
 	public Serializable getIdentifier(Object object) throws HibernateException;
 
 	/**
 	 * Get the identifier of an instance (throw an exception if no identifier property)
 	 *
 	 * @param entity The entity for which to get the identifier
 	 * @param session The session from which the request originated
 	 *
 	 * @return The identifier
 	 */
 	public Serializable getIdentifier(Object entity, SessionImplementor session);
 
     /**
      * Inject the identifier value into the given entity.
      *
      * @param entity The entity to inject with the identifier value.
      * @param id The value to be injected as the identifier.
 	 * @param session The session from which is requests originates
      */
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session);
 
 	/**
 	 * Get the version number (or timestamp) from the object's version property (or return null if not versioned)
 	 */
 	public Object getVersion(Object object) throws HibernateException;
 
 	/**
 	 * Create a class instance initialized with the given identifier
 	 *
 	 * @param id The identifier value to use (may be null to represent no value)
 	 * @param session The session from which the request originated.
 	 *
 	 * @return The instantiated entity.
 	 */
 	public Object instantiate(Serializable id, SessionImplementor session);
 
 	/**
 	 * Is the given object an instance of this entity?
 	 */
 	public boolean isInstance(Object object);
 
 	/**
 	 * Does the given instance have any uninitialized lazy properties?
 	 */
 	public boolean hasUninitializedLazyProperties(Object object);
 
 	/**
 	 * Set the identifier and version of the given instance back to its "unsaved" value.
 	 *
 	 * @param entity The entity instance
 	 * @param currentId The currently assigned identifier value.
 	 * @param currentVersion The currently assigned version value.
 	 * @param session The session from which the request originated.
 	 */
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session);
 
 	/**
 	 * A request has already identified the entity-name of this persister as the mapping for the given instance.
 	 * However, we still need to account for possible subclassing and potentially re-route to the more appropriate
 	 * persister.
 	 * <p/>
 	 * For example, a request names <tt>Animal</tt> as the entity-name which gets resolved to this persister.  But the
 	 * actual instance is really an instance of <tt>Cat</tt> which is a subclass of <tt>Animal</tt>.  So, here the
 	 * <tt>Animal</tt> persister is being asked to return the persister specific to <tt>Cat</tt>.
 	 * <p/>
 	 * It is also possible that the instance is actually an <tt>Animal</tt> instance in the above example in which
 	 * case we would return <tt>this</tt> from this method.
 	 *
 	 * @param instance The entity instance
 	 * @param factory Reference to the SessionFactory
 	 *
 	 * @return The appropriate persister
 	 *
 	 * @throws HibernateException Indicates that instance was deemed to not be a subclass of the entity mapped by
 	 * this persister.
 	 */
 	public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory);
 
 	public EntityMode getEntityMode();
 	public EntityTuplizer getEntityTuplizer();
 
 	public EntityInstrumentationMetadata getInstrumentationMetadata();
 	
 	public FilterAliasGenerator getFilterAliasGenerator(final String rootAlias);
 
 	public int[] resolveAttributeIndexes(Set<String> properties);
 
 	public boolean canUseReferenceCacheEntries();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
index 8df0bd709c..36cfdd4b6f 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
@@ -1,825 +1,837 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.DynamicFilterAliasGenerator;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.Value;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.sql.InFragment;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.DiscriminatorType;
 import org.hibernate.type.Type;
 
 /**
  * The default implementation of the <tt>EntityPersister</tt> interface.
  * Implements the "table-per-class-hierarchy" or "roll-up" mapping strategy
  * for an entity class and its inheritence hierarchy.  This is implemented
  * as a single table holding all classes in the hierarchy with a discrimator
  * column used to determine which concrete class is referenced.
  *
  * @author Gavin King
  */
 public class SingleTableEntityPersister extends AbstractEntityPersister {
 
 	// the class hierarchy structure
 	private final int joinSpan;
 	private final String[] qualifiedTableNames;
 	private final boolean[] isInverseTable;
 	private final boolean[] isNullableTable;
 	private final String[][] keyColumnNames;
 	private final boolean[] cascadeDeleteEnabled;
 	private final boolean hasSequentialSelects;
 	
 	private final String[] spaces;
 
 	private final String[] subclassClosure;
 
 	private final String[] subclassTableNameClosure;
 	private final boolean[] subclassTableIsLazyClosure;
 	private final boolean[] isInverseSubclassTable;
 	private final boolean[] isNullableSubclassTable;
 	private final boolean[] subclassTableSequentialSelect;
 	private final String[][] subclassTableKeyColumnClosure;
 	private final boolean[] isClassOrSuperclassTable;
 
 	// properties of this class, including inherited properties
 	private final int[] propertyTableNumbers;
 
 	// the closure of all columns used by the entire hierarchy including
 	// subclasses and superclasses of this class
 	private final int[] subclassPropertyTableNumberClosure;
 
 	private final int[] subclassColumnTableNumberClosure;
 	private final int[] subclassFormulaTableNumberClosure;
 
 	// discriminator column
 	private final Map subclassesByDiscriminatorValue = new HashMap();
 	private final boolean forceDiscriminator;
 	private final String discriminatorColumnName;
 	private final String discriminatorColumnReaders;
 	private final String discriminatorColumnReaderTemplate;
 	private final String discriminatorFormula;
 	private final String discriminatorFormulaTemplate;
 	private final String discriminatorAlias;
 	private final Type discriminatorType;
 	private final Object discriminatorValue;
 	private final String discriminatorSQLValue;
 	private final boolean discriminatorInsertable;
 
 	private final String[] constraintOrderedTableNames;
 	private final String[][] constraintOrderedKeyColumnNames;
 
 	//private final Map propertyTableNumbersByName = new HashMap();
 	private final Map propertyTableNumbersByNameAndSubclass = new HashMap();
 	
 	private final Map sequentialSelectStringsByEntityName = new HashMap();
 
 	private static final Object NULL_DISCRIMINATOR = new MarkerObject("<null discriminator>");
 	private static final Object NOT_NULL_DISCRIMINATOR = new MarkerObject("<not null discriminator>");
 	private static final String NULL_STRING = "null";
 	private static final String NOT_NULL_STRING = "not null";
 
 	//INITIALIZATION:
 
 	public SingleTableEntityPersister(
 			final PersistentClass persistentClass, 
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final PersisterCreationContext creationContext) throws HibernateException {
 
 		super( persistentClass, cacheAccessStrategy, naturalIdRegionAccessStrategy, creationContext );
 
 		final SessionFactoryImplementor factory = creationContext.getSessionFactory();
 
 		// CLASS + TABLE
 
 		joinSpan = persistentClass.getJoinClosureSpan()+1;
 		qualifiedTableNames = new String[joinSpan];
 		isInverseTable = new boolean[joinSpan];
 		isNullableTable = new boolean[joinSpan];
 		keyColumnNames = new String[joinSpan][];
 		final Table table = persistentClass.getRootTable();
 		qualifiedTableNames[0] = table.getQualifiedName( 
 				factory.getDialect(), 
 				factory.getSettings().getDefaultCatalogName(), 
 				factory.getSettings().getDefaultSchemaName() 
 		);
 		isInverseTable[0] = false;
 		isNullableTable[0] = false;
 		keyColumnNames[0] = getIdentifierColumnNames();
 		cascadeDeleteEnabled = new boolean[joinSpan];
 
 		// Custom sql
 		customSQLInsert = new String[joinSpan];
 		customSQLUpdate = new String[joinSpan];
 		customSQLDelete = new String[joinSpan];
 		insertCallable = new boolean[joinSpan];
 		updateCallable = new boolean[joinSpan];
 		deleteCallable = new boolean[joinSpan];
 		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 
 		customSQLInsert[0] = persistentClass.getCustomSQLInsert();
 		insertCallable[0] = customSQLInsert[0] != null && persistentClass.isCustomInsertCallable();
 		insertResultCheckStyles[0] = persistentClass.getCustomSQLInsertCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[0], insertCallable[0] )
 									  : persistentClass.getCustomSQLInsertCheckStyle();
 		customSQLUpdate[0] = persistentClass.getCustomSQLUpdate();
 		updateCallable[0] = customSQLUpdate[0] != null && persistentClass.isCustomUpdateCallable();
 		updateResultCheckStyles[0] = persistentClass.getCustomSQLUpdateCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[0], updateCallable[0] )
 									  : persistentClass.getCustomSQLUpdateCheckStyle();
 		customSQLDelete[0] = persistentClass.getCustomSQLDelete();
 		deleteCallable[0] = customSQLDelete[0] != null && persistentClass.isCustomDeleteCallable();
 		deleteResultCheckStyles[0] = persistentClass.getCustomSQLDeleteCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[0], deleteCallable[0] )
 									  : persistentClass.getCustomSQLDeleteCheckStyle();
 
 		// JOINS
 
 		Iterator joinIter = persistentClass.getJoinClosureIterator();
 		int j = 1;
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			qualifiedTableNames[j] = join.getTable().getQualifiedName( 
 					factory.getDialect(), 
 					factory.getSettings().getDefaultCatalogName(), 
 					factory.getSettings().getDefaultSchemaName() 
 			);
 			isInverseTable[j] = join.isInverse();
 			isNullableTable[j] = join.isOptional();
 			cascadeDeleteEnabled[j] = join.getKey().isCascadeDeleteEnabled() && 
 				factory.getDialect().supportsCascadeDelete();
 
 			customSQLInsert[j] = join.getCustomSQLInsert();
 			insertCallable[j] = customSQLInsert[j] != null && join.isCustomInsertCallable();
 			insertResultCheckStyles[j] = join.getCustomSQLInsertCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[j], insertCallable[j] )
 		                                  : join.getCustomSQLInsertCheckStyle();
 			customSQLUpdate[j] = join.getCustomSQLUpdate();
 			updateCallable[j] = customSQLUpdate[j] != null && join.isCustomUpdateCallable();
 			updateResultCheckStyles[j] = join.getCustomSQLUpdateCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[j], updateCallable[j] )
 		                                  : join.getCustomSQLUpdateCheckStyle();
 			customSQLDelete[j] = join.getCustomSQLDelete();
 			deleteCallable[j] = customSQLDelete[j] != null && join.isCustomDeleteCallable();
 			deleteResultCheckStyles[j] = join.getCustomSQLDeleteCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[j], deleteCallable[j] )
 		                                  : join.getCustomSQLDeleteCheckStyle();
 
 			Iterator iter = join.getKey().getColumnIterator();
 			keyColumnNames[j] = new String[ join.getKey().getColumnSpan() ];
 			int i = 0;
 			while ( iter.hasNext() ) {
 				Column col = (Column) iter.next();
 				keyColumnNames[j][i++] = col.getQuotedName( factory.getDialect() );
 			}
 
 			j++;
 		}
 
 		constraintOrderedTableNames = new String[qualifiedTableNames.length];
 		constraintOrderedKeyColumnNames = new String[qualifiedTableNames.length][];
 		for ( int i = qualifiedTableNames.length - 1, position = 0; i >= 0; i--, position++ ) {
 			constraintOrderedTableNames[position] = qualifiedTableNames[i];
 			constraintOrderedKeyColumnNames[position] = keyColumnNames[i];
 		}
 
 		spaces = ArrayHelper.join(
 				qualifiedTableNames, 
 				ArrayHelper.toStringArray( persistentClass.getSynchronizedTables() )
 		);
 		
 		final boolean lazyAvailable = isInstrumented();
 
 		boolean hasDeferred = false;
 		ArrayList subclassTables = new ArrayList();
 		ArrayList joinKeyColumns = new ArrayList();
 		ArrayList<Boolean> isConcretes = new ArrayList<Boolean>();
 		ArrayList<Boolean> isDeferreds = new ArrayList<Boolean>();
 		ArrayList<Boolean> isInverses = new ArrayList<Boolean>();
 		ArrayList<Boolean> isNullables = new ArrayList<Boolean>();
 		ArrayList<Boolean> isLazies = new ArrayList<Boolean>();
 		subclassTables.add( qualifiedTableNames[0] );
 		joinKeyColumns.add( getIdentifierColumnNames() );
 		isConcretes.add(Boolean.TRUE);
 		isDeferreds.add(Boolean.FALSE);
 		isInverses.add(Boolean.FALSE);
 		isNullables.add(Boolean.FALSE);
 		isLazies.add(Boolean.FALSE);
 		joinIter = persistentClass.getSubclassJoinClosureIterator();
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			isConcretes.add( persistentClass.isClassOrSuperclassJoin(join) );
 			isDeferreds.add( join.isSequentialSelect() );
 			isInverses.add( join.isInverse() );
 			isNullables.add( join.isOptional() );
 			isLazies.add( lazyAvailable && join.isLazy() );
-			if ( join.isSequentialSelect() && !persistentClass.isClassOrSuperclassJoin(join) ) hasDeferred = true;
+			if ( join.isSequentialSelect() && !persistentClass.isClassOrSuperclassJoin(join) ) {
+				hasDeferred = true;
+			}
 			subclassTables.add( join.getTable().getQualifiedName( 
 					factory.getDialect(), 
 					factory.getSettings().getDefaultCatalogName(), 
 					factory.getSettings().getDefaultSchemaName() 
 			) );
 			Iterator iter = join.getKey().getColumnIterator();
 			String[] keyCols = new String[ join.getKey().getColumnSpan() ];
 			int i = 0;
 			while ( iter.hasNext() ) {
 				Column col = (Column) iter.next();
 				keyCols[i++] = col.getQuotedName( factory.getDialect() );
 			}
 			joinKeyColumns.add(keyCols);
 		}
 		
 		subclassTableSequentialSelect = ArrayHelper.toBooleanArray(isDeferreds);
 		subclassTableNameClosure = ArrayHelper.toStringArray(subclassTables);
 		subclassTableIsLazyClosure = ArrayHelper.toBooleanArray(isLazies);
 		subclassTableKeyColumnClosure = ArrayHelper.to2DStringArray( joinKeyColumns );
 		isClassOrSuperclassTable = ArrayHelper.toBooleanArray(isConcretes);
 		isInverseSubclassTable = ArrayHelper.toBooleanArray(isInverses);
 		isNullableSubclassTable = ArrayHelper.toBooleanArray(isNullables);
 		hasSequentialSelects = hasDeferred;
 
 		// DISCRIMINATOR
 
 		if ( persistentClass.isPolymorphic() ) {
 			Value discrimValue = persistentClass.getDiscriminator();
 			if (discrimValue==null) {
 				throw new MappingException("discriminator mapping required for single table polymorphic persistence");
 			}
 			forceDiscriminator = persistentClass.isForceDiscriminator();
 			Selectable selectable = (Selectable) discrimValue.getColumnIterator().next();
 			if ( discrimValue.hasFormula() ) {
 				Formula formula = (Formula) selectable;
 				discriminatorFormula = formula.getFormula();
 				discriminatorFormulaTemplate = formula.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				discriminatorColumnName = null;
 				discriminatorColumnReaders = null;
 				discriminatorColumnReaderTemplate = null;
 				discriminatorAlias = "clazz_";
 			}
 			else {
 				Column column = (Column) selectable;
 				discriminatorColumnName = column.getQuotedName( factory.getDialect() );
 				discriminatorColumnReaders = column.getReadExpr( factory.getDialect() );
 				discriminatorColumnReaderTemplate = column.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				discriminatorAlias = column.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 				discriminatorFormula = null;
 				discriminatorFormulaTemplate = null;
 			}
 			discriminatorType = persistentClass.getDiscriminator().getType();
 			if ( persistentClass.isDiscriminatorValueNull() ) {
 				discriminatorValue = NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NULL;
 				discriminatorInsertable = false;
 			}
 			else if ( persistentClass.isDiscriminatorValueNotNull() ) {
 				discriminatorValue = NOT_NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NOT_NULL;
 				discriminatorInsertable = false;
 			}
 			else {
 				discriminatorInsertable = persistentClass.isDiscriminatorInsertable() && !discrimValue.hasFormula();
 				try {
 					DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 					discriminatorValue = dtype.stringToObject( persistentClass.getDiscriminatorValue() );
 					discriminatorSQLValue = dtype.objectToSQLString( discriminatorValue, factory.getDialect() );
 				}
 				catch (ClassCastException cce) {
 					throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
 				}
 				catch (Exception e) {
 					throw new MappingException("Could not format discriminator value to SQL string", e);
 				}
 			}
 		}
 		else {
 			forceDiscriminator = false;
 			discriminatorInsertable = false;
 			discriminatorColumnName = null;
 			discriminatorColumnReaders = null;
 			discriminatorColumnReaderTemplate = null;
 			discriminatorAlias = null;
 			discriminatorType = null;
 			discriminatorValue = null;
 			discriminatorSQLValue = null;
 			discriminatorFormula = null;
 			discriminatorFormulaTemplate = null;
 		}
 
 		// PROPERTIES
 
 		propertyTableNumbers = new int[ getPropertySpan() ];
 		Iterator iter = persistentClass.getPropertyClosureIterator();
 		int i=0;
 		while( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			propertyTableNumbers[i++] = persistentClass.getJoinNumber(prop);
 
 		}
 
 		//TODO: code duplication with JoinedSubclassEntityPersister
 		
 		ArrayList columnJoinNumbers = new ArrayList();
 		ArrayList formulaJoinedNumbers = new ArrayList();
 		ArrayList propertyJoinNumbers = new ArrayList();
 		
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			Integer join = persistentClass.getJoinNumber(prop);
 			propertyJoinNumbers.add(join);
 
 			//propertyTableNumbersByName.put( prop.getName(), join );
 			propertyTableNumbersByNameAndSubclass.put( 
 					prop.getPersistentClass().getEntityName() + '.' + prop.getName(), 
 					join 
 			);
 
 			Iterator citer = prop.getColumnIterator();
 			while ( citer.hasNext() ) {
 				Selectable thing = (Selectable) citer.next();
 				if ( thing.isFormula() ) {
 					formulaJoinedNumbers.add(join);
 				}
 				else {
 					columnJoinNumbers.add(join);
 				}
 			}
 		}
 		subclassColumnTableNumberClosure = ArrayHelper.toIntArray(columnJoinNumbers);
 		subclassFormulaTableNumberClosure = ArrayHelper.toIntArray(formulaJoinedNumbers);
 		subclassPropertyTableNumberClosure = ArrayHelper.toIntArray(propertyJoinNumbers);
 
 		int subclassSpan = persistentClass.getSubclassSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[0] = getEntityName();
 		if ( persistentClass.isPolymorphic() ) {
 			addSubclassByDiscriminatorValue( discriminatorValue, getEntityName() );
 		}
 
 		// SUBCLASSES
 		if ( persistentClass.isPolymorphic() ) {
 			iter = persistentClass.getSubclassIterator();
 			int k=1;
 			while ( iter.hasNext() ) {
 				Subclass sc = (Subclass) iter.next();
 				subclassClosure[k++] = sc.getEntityName();
 				if ( sc.isDiscriminatorValueNull() ) {
 					addSubclassByDiscriminatorValue( NULL_DISCRIMINATOR, sc.getEntityName() );
 				}
 				else if ( sc.isDiscriminatorValueNotNull() ) {
 					addSubclassByDiscriminatorValue( NOT_NULL_DISCRIMINATOR, sc.getEntityName() );
 				}
 				else {
 					try {
 						DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 						addSubclassByDiscriminatorValue(
 							dtype.stringToObject( sc.getDiscriminatorValue() ),
 							sc.getEntityName()
 						);
 					}
 					catch (ClassCastException cce) {
 						throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
 					}
 					catch (Exception e) {
 						throw new MappingException("Error parsing discriminator value", e);
 					}
 				}
 			}
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap( persistentClass );
 		
 		postConstruct( creationContext.getMetadata() );
 
 	}
 
 	private void addSubclassByDiscriminatorValue(Object discriminatorValue, String entityName) {
 		String mappedEntityName = (String) subclassesByDiscriminatorValue.put( discriminatorValue, entityName );
 		if ( mappedEntityName != null ) {
 			throw new MappingException(
 					"Entities [" + entityName + "] and [" + mappedEntityName
 							+ "] are mapped with the same discriminator value '" + discriminatorValue + "'."
 			);
 		}
 	}
 
 	protected boolean isInverseTable(int j) {
 		return isInverseTable[j];
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return isInverseSubclassTable[j];
 	}
 
 	public String getDiscriminatorColumnName() {
 		return discriminatorColumnName;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return discriminatorColumnReaders;
 	}			
 	
 	public String getDiscriminatorColumnReaderTemplate() {
 		return discriminatorColumnReaderTemplate;
 	}	
 	
 	protected String getDiscriminatorAlias() {
 		return discriminatorAlias;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return discriminatorFormulaTemplate;
 	}
 
 	public String getTableName() {
 		return qualifiedTableNames[0];
 	}
 
 	public Type getDiscriminatorType() {
 		return discriminatorType;
 	}
 
 	public Object getDiscriminatorValue() {
 		return discriminatorValue;
 	}
 
 	public String getDiscriminatorSQLValue() {
 		return discriminatorSQLValue;
 	}
 
 	public String[] getSubclassClosure() {
 		return subclassClosure;
 	}
 
 	public String getSubclassForDiscriminatorValue(Object value) {
 		if (value==null) {
 			return (String) subclassesByDiscriminatorValue.get(NULL_DISCRIMINATOR);
 		}
 		else {
 			String result = (String) subclassesByDiscriminatorValue.get(value);
-			if (result==null) result = (String) subclassesByDiscriminatorValue.get(NOT_NULL_DISCRIMINATOR);
+			if (result==null) {
+				result = (String) subclassesByDiscriminatorValue.get(NOT_NULL_DISCRIMINATOR);
+			}
 			return result;
 		}
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return spaces;
 	}
 
 	//Access cached SQL
 
 	protected boolean isDiscriminatorFormula() {
 		return discriminatorColumnName==null;
 	}
 
 	protected String getDiscriminatorFormula() {
 		return discriminatorFormula;
 	}
 
 	protected String getTableName(int j) {
 		return qualifiedTableNames[j];
 	}
 	
 	protected String[] getKeyColumns(int j) {
 		return keyColumnNames[j];
 	}
 	
 	protected boolean isTableCascadeDeleteEnabled(int j) {
 		return cascadeDeleteEnabled[j];
 	}
 	
 	protected boolean isPropertyOfTable(int property, int j) {
 		return propertyTableNumbers[property]==j;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return subclassTableSequentialSelect[j] && !isClassOrSuperclassTable[j];
 	}
 	
 	// Execute the SQL:
 
 	public String fromTableFragment(String name) {
 		return getTableName() + ' ' + name;
 	}
 
 	@Override
 	public String filterFragment(String alias) throws MappingException {
 		String result = discriminatorFilterFragment(alias);
-		if ( hasWhere() ) result += " and " + getSQLWhereString(alias);
+		if ( hasWhere() ) {
+			result += " and " + getSQLWhereString(alias);
+		}
 		return result;
 	}
 
 	private String discriminatorFilterFragment(String alias) throws MappingException {
 		return discriminatorFilterFragment( alias, null );
 	}
 	
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return forceDiscriminator
 				? discriminatorFilterFragment( alias, null )
 				: "";
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		return needsDiscriminator()
 				? discriminatorFilterFragment( alias, treatAsDeclarations )
 				: "";
 	}
 
 	@Override
 	public String filterFragment(String alias, Set<String> treatAsDeclarations) {
 		String result = discriminatorFilterFragment( alias, treatAsDeclarations );
 		if ( hasWhere() ) {
 			result += " and " + getSQLWhereString( alias );
 		}
 		return result;
 	}
 
 	private String discriminatorFilterFragment(String alias, Set<String> treatAsDeclarations)  {
 		final boolean hasTreatAs = treatAsDeclarations != null && !treatAsDeclarations.isEmpty();
 
 		if ( !needsDiscriminator() && !hasTreatAs) {
 			return "";
 		}
 
 		final InFragment frag = new InFragment();
 		if ( isDiscriminatorFormula() ) {
 			frag.setFormula( alias, getDiscriminatorFormulaTemplate() );
 		}
 		else {
 			frag.setColumn( alias, getDiscriminatorColumnName() );
 		}
 
 		if ( hasTreatAs ) {
 			frag.addValues( decodeTreatAsRequests( treatAsDeclarations ) );
 		}
 		else {
 			frag.addValues( fullDiscriminatorValues() );
 		}
 
 		return " and " + frag.toFragmentString();
 	}
 
 	private boolean needsDiscriminator() {
 		return forceDiscriminator || isInherited();
 	}
 
 	private String[] decodeTreatAsRequests(Set<String> treatAsDeclarations) {
 		final List<String> values = new ArrayList<String>();
 		for ( String subclass : treatAsDeclarations ) {
 			final Queryable queryable = (Queryable) getFactory().getEntityPersister( subclass );
 			if ( !queryable.isAbstract() ) {
 				values.add( queryable.getDiscriminatorSQLValue() );
 			}
 		}
 		return values.toArray( new String[ values.size() ] );
 	}
 
 	private String[] fullDiscriminatorValues;
 
 	private String[] fullDiscriminatorValues() {
 		if ( fullDiscriminatorValues == null ) {
 			// first access; build it
 			final List<String> values = new ArrayList<String>();
 			for ( String subclass : getSubclassClosure() ) {
 				final Queryable queryable = (Queryable) getFactory().getEntityPersister( subclass );
 				if ( !queryable.isAbstract() ) {
 					values.add( queryable.getDiscriminatorSQLValue() );
 				}
 			}
 			fullDiscriminatorValues = values.toArray( new String[values.size() ] );
 		}
 
 		return fullDiscriminatorValues;
 	}
 
 	public String getSubclassPropertyTableName(int i) {
 		return subclassTableNameClosure[ subclassPropertyTableNumberClosure[i] ];
 	}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
 		if ( isDiscriminatorFormula() ) {
 			select.addFormula( name, getDiscriminatorFormulaTemplate(), getDiscriminatorAlias() );
 		}
 		else {
 			select.addColumn( name, getDiscriminatorColumnName(),  getDiscriminatorAlias() );
 		}
 	}
 	
 	protected int[] getPropertyTableNumbersInSelect() {
 		return propertyTableNumbers;
 	}
 
 	protected int getSubclassPropertyTableNumber(int i) {
 		return subclassPropertyTableNumberClosure[i];
 	}
 
 	public int getTableSpan() {
 		return joinSpan;
 	}
 
 	protected void addDiscriminatorToInsert(Insert insert) {
 
 		if (discriminatorInsertable) {
 			insert.addColumn( getDiscriminatorColumnName(), discriminatorSQLValue );
 		}
 
 	}
 
 	protected int[] getSubclassColumnTableNumberClosure() {
 		return subclassColumnTableNumberClosure;
 	}
 
 	protected int[] getSubclassFormulaTableNumberClosure() {
 		return subclassFormulaTableNumberClosure;
 	}
 
 	protected int[] getPropertyTableNumbers() {
 		return propertyTableNumbers;
 	}
 		
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return hasSequentialSelects && 
 			isSubclassTableSequentialSelect( getSubclassPropertyTableNumber(propertyName, entityName) );
 	}
 	
 	public boolean hasSequentialSelect() {
 		return hasSequentialSelects;
 	}
 	
 	private int getSubclassPropertyTableNumber(String propertyName, String entityName) {
 		Type type = propertyMapping.toType(propertyName);
-		if ( type.isAssociationType() && ( (AssociationType) type ).useLHSPrimaryKey() ) return 0;
+		if ( type.isAssociationType() && ( (AssociationType) type ).useLHSPrimaryKey() ) {
+			return 0;
+		}
 		final Integer tabnum = (Integer) propertyTableNumbersByNameAndSubclass.get(entityName + '.' + propertyName);
 		return tabnum==null ? 0 : tabnum;
 	}
 	
 	protected String getSequentialSelect(String entityName) {
 		return (String) sequentialSelectStringsByEntityName.get(entityName);
 	}
 
 	private String generateSequentialSelect(Loadable persister) {
 		//if ( this==persister || !hasSequentialSelects ) return null;
 
 		//note that this method could easily be moved up to BasicEntityPersister,
 		//if we ever needed to reuse it from other subclasses
 		
 		//figure out which tables need to be fetched
 		AbstractEntityPersister subclassPersister = (AbstractEntityPersister) persister;
 		HashSet tableNumbers = new HashSet();
 		String[] props = subclassPersister.getPropertyNames();
 		String[] classes = subclassPersister.getPropertySubclassNames();
 		for ( int i=0; i<props.length; i++ ) {
 			int propTableNumber = getSubclassPropertyTableNumber( props[i], classes[i] );
 			if ( isSubclassTableSequentialSelect(propTableNumber) && !isSubclassTableLazy(propTableNumber) ) {
 				tableNumbers.add( propTableNumber);
 			}
 		}
-		if ( tableNumbers.isEmpty() ) return null;
+		if ( tableNumbers.isEmpty() ) {
+			return null;
+		}
 		
 		//figure out which columns are needed
 		ArrayList columnNumbers = new ArrayList();
 		final int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		for ( int i=0; i<getSubclassColumnClosure().length; i++ ) {
 			if ( tableNumbers.contains( columnTableNumbers[i] ) ) {
 				columnNumbers.add( i );
 			}
 		}
 		
 		//figure out which formulas are needed
 		ArrayList formulaNumbers = new ArrayList();
 		final int[] formulaTableNumbers = getSubclassColumnTableNumberClosure();
 		for ( int i=0; i<getSubclassFormulaTemplateClosure().length; i++ ) {
 			if ( tableNumbers.contains( formulaTableNumbers[i] ) ) {
 				formulaNumbers.add( i );
 			}
 		}
 		
 		//render the SQL
 		return renderSelect( 
 			ArrayHelper.toIntArray(tableNumbers),
 			ArrayHelper.toIntArray(columnNumbers),
 			ArrayHelper.toIntArray(formulaNumbers)
 		);
 	}
 		
 		
 	protected String[] getSubclassTableKeyColumns(int j) {
 		return subclassTableKeyColumnClosure[j];
 	}
 
 	public String getSubclassTableName(int j) {
 		return subclassTableNameClosure[j];
 	}
 
 	public int getSubclassTableSpan() {
 		return subclassTableNameClosure.length;
 	}
 
 	protected boolean isClassOrSuperclassTable(int j) {
 		return isClassOrSuperclassTable[j];
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return subclassTableIsLazyClosure[j];
 	}
 	
 	protected boolean isNullableTable(int j) {
 		return isNullableTable[j];
 	}
 	
 	protected boolean isNullableSubclassTable(int j) {
 		return isNullableSubclassTable[j];
 	}
 
 	public String getPropertyTableName(String propertyName) {
 		Integer index = getEntityMetamodel().getPropertyIndexOrNull(propertyName);
-		if (index==null) return null;
+		if (index==null) {
+			return null;
+		}
 		return qualifiedTableNames[ propertyTableNumbers[index] ];
 	}
 	
 	protected void doPostInstantiate() {
 		if (hasSequentialSelects) {
 			String[] entityNames = getSubclassClosure();
 			for ( int i=1; i<entityNames.length; i++ ) {
 				Loadable loadable = (Loadable) getFactory().getEntityPersister( entityNames[i] );
 				if ( !loadable.isAbstract() ) { //perhaps not really necessary...
 					String sequentialSelect = generateSequentialSelect(loadable);
 					sequentialSelectStringsByEntityName.put( entityNames[i], sequentialSelect );
 				}
 			}
 		}
 	}
 
 	public boolean isMultiTable() {
 		return getTableSpan() > 1;
 	}
 
 	public String[] getConstraintOrderedTableNameClosure() {
 		return constraintOrderedTableNames;
 	}
 
 	public String[][] getContraintOrderedTableKeyColumnClosure() {
 		return constraintOrderedKeyColumnNames;
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
 		return new DynamicFilterAliasGenerator(qualifiedTableNames, rootAlias);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
index cb55c4ce1e..696dbddcf4 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
@@ -1,506 +1,514 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashSet;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cfg.Settings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.StaticFilterAliasGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.internal.util.collections.SingletonIterator;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * Implementation of the "table-per-concrete-class" or "roll-down" mapping 
  * strategy for an entity and its inheritence hierarchy.
  *
  * @author Gavin King
  */
 public class UnionSubclassEntityPersister extends AbstractEntityPersister {
 
 	// the class hierarchy structure
 	private final String subquery;
 	private final String tableName;
 	//private final String rootTableName;
 	private final String[] subclassClosure;
 	private final String[] spaces;
 	private final String[] subclassSpaces;
 	private final Object discriminatorValue;
 	private final String discriminatorSQLValue;
 	private final Map subclassByDiscriminatorValue = new HashMap();
 
 	private final String[] constraintOrderedTableNames;
 	private final String[][] constraintOrderedKeyColumnNames;
 
 	//INITIALIZATION:
 
 	public UnionSubclassEntityPersister(
 			final PersistentClass persistentClass, 
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final PersisterCreationContext creationContext) throws HibernateException {
 
 		super( persistentClass, cacheAccessStrategy, naturalIdRegionAccessStrategy, creationContext );
 
 		final SessionFactoryImplementor factory = creationContext.getSessionFactory();
 
 		if ( getIdentifierGenerator() instanceof IdentityGenerator ) {
 			throw new MappingException(
 					"Cannot use identity column key generation with <union-subclass> mapping for: " + 
 					getEntityName() 
 			);
 		}
 
 		// TABLE
 
 		tableName = persistentClass.getTable().getQualifiedName( 
 				factory.getDialect(), 
 				factory.getSettings().getDefaultCatalogName(), 
 				factory.getSettings().getDefaultSchemaName() 
 		);
 		/*rootTableName = persistentClass.getRootTable().getQualifiedName( 
 				factory.getDialect(), 
 				factory.getDefaultCatalog(), 
 				factory.getDefaultSchema() 
 		);*/
 
 		//Custom SQL
 
 		String sql;
 		boolean callable = false;
 		ExecuteUpdateResultCheckStyle checkStyle = null;
 		sql = persistentClass.getCustomSQLInsert();
 		callable = sql != null && persistentClass.isCustomInsertCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
 	            : persistentClass.getCustomSQLInsertCheckStyle() == null
 						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
 	                    : persistentClass.getCustomSQLInsertCheckStyle();
 		customSQLInsert = new String[] { sql };
 		insertCallable = new boolean[] { callable };
 		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
 
 		sql = persistentClass.getCustomSQLUpdate();
 		callable = sql != null && persistentClass.isCustomUpdateCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
 	            : persistentClass.getCustomSQLUpdateCheckStyle() == null
 						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
 	                    : persistentClass.getCustomSQLUpdateCheckStyle();
 		customSQLUpdate = new String[] { sql };
 		updateCallable = new boolean[] { callable };
 		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
 
 		sql = persistentClass.getCustomSQLDelete();
 		callable = sql != null && persistentClass.isCustomDeleteCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
 	            : persistentClass.getCustomSQLDeleteCheckStyle() == null
 						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
 	                    : persistentClass.getCustomSQLDeleteCheckStyle();
 		customSQLDelete = new String[] { sql };
 		deleteCallable = new boolean[] { callable };
 		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
 
 		discriminatorValue = persistentClass.getSubclassId();
 		discriminatorSQLValue = String.valueOf( persistentClass.getSubclassId() );
 
 		// PROPERTIES
 
 		int subclassSpan = persistentClass.getSubclassSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[0] = getEntityName();
 
 		// SUBCLASSES
 		subclassByDiscriminatorValue.put( 
 				persistentClass.getSubclassId(),
 				persistentClass.getEntityName() 
 		);
 		if ( persistentClass.isPolymorphic() ) {
 			Iterator iter = persistentClass.getSubclassIterator();
 			int k=1;
 			while ( iter.hasNext() ) {
 				Subclass sc = (Subclass) iter.next();
 				subclassClosure[k++] = sc.getEntityName();
 				subclassByDiscriminatorValue.put( sc.getSubclassId(), sc.getEntityName() );
 			}
 		}
 		
 		//SPACES
 		//TODO: i'm not sure, but perhaps we should exclude
 		//      abstract denormalized tables?
 		
 		int spacesSize = 1 + persistentClass.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = tableName;
 		Iterator iter = persistentClass.getSynchronizedTables().iterator();
 		for ( int i=1; i<spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
 		
 		HashSet subclassTables = new HashSet();
 		iter = persistentClass.getSubclassTableClosureIterator();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			subclassTables.add( table.getQualifiedName(
 					factory.getDialect(), 
 					factory.getSettings().getDefaultCatalogName(), 
 					factory.getSettings().getDefaultSchemaName() 
 			) );
 		}
 		subclassSpaces = ArrayHelper.toStringArray(subclassTables);
 
 		subquery = generateSubquery( persistentClass, creationContext.getMetadata() );
 
 		if ( isMultiTable() ) {
 			int idColumnSpan = getIdentifierColumnSpan();
 			ArrayList tableNames = new ArrayList();
 			ArrayList keyColumns = new ArrayList();
 			if ( !isAbstract() ) {
 				tableNames.add( tableName );
 				keyColumns.add( getIdentifierColumnNames() );
 			}
 			iter = persistentClass.getSubclassTableClosureIterator();
 			while ( iter.hasNext() ) {
 				Table tab = ( Table ) iter.next();
 				if ( !tab.isAbstractUnionTable() ) {
 					String tableName = tab.getQualifiedName(
 							factory.getDialect(),
 							factory.getSettings().getDefaultCatalogName(),
 							factory.getSettings().getDefaultSchemaName()
 					);
 					tableNames.add( tableName );
 					String[] key = new String[idColumnSpan];
 					Iterator citer = tab.getPrimaryKey().getColumnIterator();
 					for ( int k=0; k<idColumnSpan; k++ ) {
 						key[k] = ( ( Column ) citer.next() ).getQuotedName( factory.getDialect() );
 					}
 					keyColumns.add( key );
 				}
 			}
 
 			constraintOrderedTableNames = ArrayHelper.toStringArray( tableNames );
 			constraintOrderedKeyColumnNames = ArrayHelper.to2DStringArray( keyColumns );
 		}
 		else {
 			constraintOrderedTableNames = new String[] { tableName };
 			constraintOrderedKeyColumnNames = new String[][] { getIdentifierColumnNames() };
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap( persistentClass );
 		
 		postConstruct( creationContext.getMetadata() );
 
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return subclassSpaces;
 	}
 	
 	public String getTableName() {
 		return subquery;
 	}
 
 	public Type getDiscriminatorType() {
 		return StandardBasicTypes.INTEGER;
 	}
 
 	public Object getDiscriminatorValue() {
 		return discriminatorValue;
 	}
 
 	public String getDiscriminatorSQLValue() {
 		return discriminatorSQLValue;
 	}
 
 	public String[] getSubclassClosure() {
 		return subclassClosure;
 	}
 
 	public String getSubclassForDiscriminatorValue(Object value) {
 		return (String) subclassByDiscriminatorValue.get(value);
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return spaces;
 	}
 
 	protected boolean isDiscriminatorFormula() {
 		return false;
 	}
 
 	/**
 	 * Generate the SQL that selects a row by id
 	 */
 	protected String generateSelectString(LockMode lockMode) {
 		SimpleSelect select = new SimpleSelect( getFactory().getDialect() )
 			.setLockMode(lockMode)
 			.setTableName( getTableName() )
 			.addColumns( getIdentifierColumnNames() )
 			.addColumns( 
 					getSubclassColumnClosure(), 
 					getSubclassColumnAliasClosure(),
 					getSubclassColumnLazyiness()
 			)
 			.addColumns( 
 					getSubclassFormulaClosure(), 
 					getSubclassFormulaAliasClosure(),
 					getSubclassFormulaLazyiness()
 			);
 		//TODO: include the rowids!!!!
 		if ( hasSubclasses() ) {
 			if ( isDiscriminatorFormula() ) {
 				select.addColumn( getDiscriminatorFormula(), getDiscriminatorAlias() );
 			}
 			else {
 				select.addColumn( getDiscriminatorColumnName(), getDiscriminatorAlias() );
 			}
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "load " + getEntityName() );
 		}
 		return select.addCondition( getIdentifierColumnNames(), "=?" ).toStatementString();
 	}
 
 	protected String getDiscriminatorFormula() {
 		return null;
 	}
 
 	protected String getTableName(int j) {
 		return tableName;
 	}
 
 	protected String[] getKeyColumns(int j) {
 		return getIdentifierColumnNames();
 	}
 	
 	protected boolean isTableCascadeDeleteEnabled(int j) {
 		return false;
 	}
 	
 	protected boolean isPropertyOfTable(int property, int j) {
 		return true;
 	}
 
 	// Execute the SQL:
 
 	public String fromTableFragment(String name) {
 		return getTableName() + ' '  + name;
 	}
 
 	@Override
 	public String filterFragment(String name) {
 		return hasWhere()
 				? " and " + getSQLWhereString( name )
 				: "";
 	}
 
 	@Override
 	protected String filterFragment(String alias, Set<String> treatAsDeclarations) {
 		return filterFragment( alias );
 	}
 
 	public String getSubclassPropertyTableName(int i) {
 		return getTableName();//ie. the subquery! yuck!
 	}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
 		select.addColumn( name, getDiscriminatorColumnName(),  getDiscriminatorAlias() );
 	}
 	
 	protected int[] getPropertyTableNumbersInSelect() {
 		return new int[ getPropertySpan() ];
 	}
 
 	protected int getSubclassPropertyTableNumber(int i) {
 		return 0;
 	}
 
 	public int getSubclassPropertyTableNumber(String propertyName) {
 		return 0;
 	}
 
 	public boolean isMultiTable() {
 		// This could also just be true all the time...
 		return isAbstract() || hasSubclasses();
 	}
 
 	public int getTableSpan() {
 		return 1;
 	}
 
 	protected int[] getSubclassColumnTableNumberClosure() {
 		return new int[ getSubclassColumnClosure().length ];
 	}
 
 	protected int[] getSubclassFormulaTableNumberClosure() {
 		return new int[ getSubclassFormulaClosure().length ];
 	}
 
 	protected boolean[] getTableHasColumns() {
 		return new boolean[] { true };
 	}
 
 	protected int[] getPropertyTableNumbers() {
 		return new int[ getPropertySpan() ];
 	}
 
 	protected String generateSubquery(PersistentClass model, Mapping mapping) {
 
 		Dialect dialect = getFactory().getDialect();
 		Settings settings = getFactory().getSettings();
 		
 		if ( !model.hasSubclasses() ) {
 			return model.getTable().getQualifiedName(
 					dialect,
 					settings.getDefaultCatalogName(),
 					settings.getDefaultSchemaName()
 				);
 		}
 
 		HashSet columns = new LinkedHashSet();
 		Iterator titer = model.getSubclassTableClosureIterator();
 		while ( titer.hasNext() ) {
 			Table table = (Table) titer.next();
 			if ( !table.isAbstractUnionTable() ) {
 				Iterator citer = table.getColumnIterator();
-				while ( citer.hasNext() ) columns.add( citer.next() );
+				while ( citer.hasNext() ) {
+					columns.add( citer.next() );
+				}
 			}
 		}
 
 		StringBuilder buf = new StringBuilder()
 			.append("( ");
 
 		Iterator siter = new JoinedIterator(
 			new SingletonIterator(model),
 			model.getSubclassIterator()
 		);
 
 		while ( siter.hasNext() ) {
 			PersistentClass clazz = (PersistentClass) siter.next();
 			Table table = clazz.getTable();
 			if ( !table.isAbstractUnionTable() ) {
 				//TODO: move to .sql package!!
 				buf.append("select ");
 				Iterator citer = columns.iterator();
 				while ( citer.hasNext() ) {
 					Column col = (Column) citer.next();
 					if ( !table.containsColumn(col) ) {
 						int sqlType = col.getSqlTypeCode(mapping);
 						buf.append( dialect.getSelectClauseNullString(sqlType) )
 							.append(" as ");
 					}
 					buf.append( col.getQuotedName(dialect) );
 					buf.append(", ");
 				}
 				buf.append( clazz.getSubclassId() )
 					.append(" as clazz_");
 				buf.append(" from ")
 					.append( table.getQualifiedName(
 							dialect,
 							settings.getDefaultCatalogName(),
 							settings.getDefaultSchemaName()
 					) );
 				buf.append(" union ");
 				if ( dialect.supportsUnionAll() ) {
 					buf.append("all ");
 				}
 			}
 		}
 		
 		if ( buf.length() > 2 ) {
 			//chop the last union (all)
 			buf.setLength( buf.length() - ( dialect.supportsUnionAll() ? 11 : 7 ) );
 		}
 
 		return buf.append(" )").toString();
 	}
 
 	protected String[] getSubclassTableKeyColumns(int j) {
-		if (j!=0) throw new AssertionFailure("only one table");
+		if (j!=0) {
+			throw new AssertionFailure("only one table");
+		}
 		return getIdentifierColumnNames();
 	}
 
 	public String getSubclassTableName(int j) {
-		if (j!=0) throw new AssertionFailure("only one table");
+		if (j!=0) {
+			throw new AssertionFailure("only one table");
+		}
 		return tableName;
 	}
 
 	public int getSubclassTableSpan() {
 		return 1;
 	}
 
 	protected boolean isClassOrSuperclassTable(int j) {
-		if (j!=0) throw new AssertionFailure("only one table");
+		if (j!=0) {
+			throw new AssertionFailure("only one table");
+		}
 		return true;
 	}
 
 	public String getPropertyTableName(String propertyName) {
 		//TODO: check this....
 		return getTableName();
 	}
 
 	public String[] getConstraintOrderedTableNameClosure() {
-			return constraintOrderedTableNames;
+		return constraintOrderedTableNames;
 	}
 
 	public String[][] getContraintOrderedTableKeyColumnClosure() {
 		return constraintOrderedKeyColumnNames;
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
 		return new StaticFilterAliasGenerator(rootAlias);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java b/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
index 31db69bdf7..78eb107b73 100644
--- a/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
@@ -1,378 +1,378 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.property;
 
 import java.beans.Introspector;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Member;
 import java.lang.reflect.Method;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.PropertyAccessException;
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.PropertySetterAccessException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 
 import org.jboss.logging.Logger;
 
 /**
  * Accesses property values via a get/set pair, which may be nonpublic.
  * The default (and recommended strategy).
  *
  * @author Gavin King
  */
 public class BasicPropertyAccessor implements PropertyAccessor {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( BasicPropertyAccessor.class );
 
 	public static final class BasicSetter implements Setter {
 		private Class clazz;
 		private final transient Method method;
 		private final String propertyName;
 
 		private BasicSetter(Class clazz, Method method, String propertyName) {
 			this.clazz=clazz;
 			this.method=method;
 			this.propertyName=propertyName;
 		}
 
 		@Override
 		public void set(Object target, Object value, SessionFactoryImplementor factory)
 		throws HibernateException {
 			try {
 				method.invoke( target, value );
 			}
 			catch (NullPointerException npe) {
 				if ( value==null && method.getParameterTypes()[0].isPrimitive() ) {
 					throw new PropertyAccessException(
 							npe,
 							"Null value was assigned to a property of primitive type",
 							true,
 							clazz,
 							propertyName
-						);
+					);
 				}
 				else {
 					throw new PropertyAccessException(
 							npe,
 							"NullPointerException occurred while calling",
 							true,
 							clazz,
 							propertyName
-						);
+					);
 				}
 			}
 			catch (InvocationTargetException ite) {
 				throw new PropertyAccessException(
 						ite,
 						"Exception occurred inside",
 						true,
 						clazz,
 						propertyName
-					);
+				);
 			}
 			catch (IllegalAccessException iae) {
 				throw new PropertyAccessException(
 						iae,
 						"IllegalAccessException occurred while calling",
 						true,
 						clazz,
 						propertyName
-					);
+				);
 				//cannot occur
 			}
 			catch (IllegalArgumentException iae) {
 				if ( value==null && method.getParameterTypes()[0].isPrimitive() ) {
 					throw new PropertyAccessException(
 							iae,
 							"Null value was assigned to a property of primitive type",
 							true,
 							clazz,
 							propertyName
-						);
+					);
 				}
 				else {
 					final Class expectedType = method.getParameterTypes()[0];
 					LOG.illegalPropertySetterArgument( clazz.getName(), propertyName );
 					LOG.expectedType( expectedType.getName(), value == null ? null : value.getClass().getName() );
 					throw new PropertySetterAccessException(
 							iae,
 							clazz,
 							propertyName,
 							expectedType,
 							target,
 							value
-						);
+					);
 				}
 			}
 		}
 
 		@Override
 		public Method getMethod() {
 			return method;
 		}
 
 		@Override
 		public String getMethodName() {
 			return method.getName();
 		}
 
 		Object readResolve() {
 			return createSetter(clazz, propertyName);
 		}
 
 		@Override
         public String toString() {
 			return "BasicSetter(" + clazz.getName() + '.' + propertyName + ')';
 		}
 	}
 
 	public static final class BasicGetter implements Getter {
 		private Class clazz;
 		private final transient Method method;
 		private final String propertyName;
 
 		private BasicGetter(Class clazz, Method method, String propertyName) {
 			this.clazz=clazz;
 			this.method=method;
 			this.propertyName=propertyName;
 		}
 
 		@Override
 		public Object get(Object target) throws HibernateException {
 			try {
 				return method.invoke( target, (Object[]) null );
 			}
 			catch (InvocationTargetException ite) {
 				throw new PropertyAccessException(
 						ite,
 						"Exception occurred inside",
 						false,
 						clazz,
 						propertyName
-					);
+				);
 			}
 			catch (IllegalAccessException iae) {
 				throw new PropertyAccessException(
 						iae,
 						"IllegalAccessException occurred while calling",
 						false,
 						clazz,
 						propertyName
-					);
+				);
 				//cannot occur
 			}
 			catch (IllegalArgumentException iae) {
                 LOG.illegalPropertyGetterArgument(clazz.getName(), propertyName);
 				throw new PropertyAccessException(
 						iae,
 						"IllegalArgumentException occurred calling",
 						false,
 						clazz,
 						propertyName
-					);
+				);
 			}
 		}
 
 		@Override
 		public Object getForInsert(Object target, Map mergeMap, SessionImplementor session) {
 			return get( target );
 		}
 
 		@Override
 		public Class getReturnType() {
 			return method.getReturnType();
 		}
 
 		@Override
 		public Member getMember() {
 			return method;
 		}
 
 		@Override
 		public Method getMethod() {
 			return method;
 		}
 
 		@Override
 		public String getMethodName() {
 			return method.getName();
 		}
 
 		@Override
         public String toString() {
 			return "BasicGetter(" + clazz.getName() + '.' + propertyName + ')';
 		}
 
 		Object readResolve() {
 			return createGetter(clazz, propertyName);
 		}
 	}
 
 
 	@Override
 	public Setter getSetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		return createSetter(theClass, propertyName);
 	}
 
 	private static Setter createSetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		BasicSetter result = getSetterOrNull(theClass, propertyName);
 		if (result==null) {
 			throw new PropertyNotFoundException(
 					"Could not find a setter for property " +
 					propertyName +
 					" in class " +
 					theClass.getName()
-				);
+			);
 		}
 		return result;
 	}
 
 	private static BasicSetter getSetterOrNull(Class theClass, String propertyName) {
-
-		if (theClass==Object.class || theClass==null) return null;
+		if (theClass==Object.class || theClass==null) {
+			return null;
+		}
 
 		Method method = setterMethod(theClass, propertyName);
 
 		if (method!=null) {
 			method.setAccessible(true);
 			return new BasicSetter(theClass, method, propertyName);
 		}
 		else {
 			BasicSetter setter = getSetterOrNull( theClass.getSuperclass(), propertyName );
 			if (setter==null) {
 				Class[] interfaces = theClass.getInterfaces();
 				for ( int i=0; setter==null && i<interfaces.length; i++ ) {
 					setter=getSetterOrNull( interfaces[i], propertyName );
 				}
 			}
 			return setter;
 		}
 
 	}
 
 	private static Method setterMethod(Class theClass, String propertyName) {
 		BasicGetter getter = getGetterOrNull(theClass, propertyName);
 		Class returnType = (getter==null) ? null : getter.getReturnType();
 
 		Method[] methods = theClass.getDeclaredMethods();
 		Method potentialSetter = null;
 		for ( Method method : methods ) {
 			final String methodName = method.getName();
-
 			if ( method.getParameterTypes().length == 1 && methodName.startsWith( "set" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 3 ) );
 				String testOldMethod = methodName.substring( 3 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					potentialSetter = method;
 					if ( returnType == null || method.getParameterTypes()[0].equals( returnType ) ) {
 						return potentialSetter;
 					}
 				}
 			}
 		}
 		return potentialSetter;
 	}
 
 	@Override
 	public Getter getGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		return createGetter(theClass, propertyName);
 	}
 
 	public static Getter createGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		BasicGetter result = getGetterOrNull(theClass, propertyName);
 		if (result==null) {
 			throw new PropertyNotFoundException(
 					"Could not find a getter for " +
 					propertyName +
 					" in class " +
 					theClass.getName()
 			);
 		}
 		return result;
 	}
 
 	private static BasicGetter getGetterOrNull(Class theClass, String propertyName) {
 		if (theClass==Object.class || theClass==null) {
 			return null;
 		}
 
 		Method method = getterMethod(theClass, propertyName);
 
 		if (method!=null) {
 			method.setAccessible(true);
 			return new BasicGetter(theClass, method, propertyName);
 		}
 		else {
 			BasicGetter getter = getGetterOrNull( theClass.getSuperclass(), propertyName );
 			if (getter==null) {
 				Class[] interfaces = theClass.getInterfaces();
 				for ( int i=0; getter==null && i<interfaces.length; i++ ) {
 					getter=getGetterOrNull( interfaces[i], propertyName );
 				}
 			}
 			return getter;
 		}
 	}
 
 	private static Method getterMethod(Class theClass, String propertyName) {
 		Method[] methods = theClass.getDeclaredMethods();
 		for ( Method method : methods ) {
 			// if the method has parameters, skip it
 			if ( method.getParameterTypes().length != 0 ) {
 				continue;
 			}
 			// if the method is a "bridge", skip it
 			if ( method.isBridge() ) {
 				continue;
 			}
 
 			final String methodName = method.getName();
 
 			// try "get"
 			if ( methodName.startsWith( "get" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 3 ) );
 				String testOldMethod = methodName.substring( 3 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					return method;
 				}
 			}
 
 			// if not "get", then try "is"
 			if ( methodName.startsWith( "is" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 2 ) );
 				String testOldMethod = methodName.substring( 2 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					return method;
 				}
 			}
 		}
 
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/property/PropertyAccessorFactory.java b/hibernate-core/src/main/java/org/hibernate/property/PropertyAccessorFactory.java
index 08b061a3ae..99044e9c80 100644
--- a/hibernate-core/src/main/java/org/hibernate/property/PropertyAccessorFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/property/PropertyAccessorFactory.java
@@ -1,146 +1,157 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.property;
 
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.MappingException;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Property;
 
 /**
  * A factory for building/retrieving PropertyAccessor instances.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public final class PropertyAccessorFactory {
-
 	private static final PropertyAccessor BASIC_PROPERTY_ACCESSOR = new BasicPropertyAccessor();
 	private static final PropertyAccessor DIRECT_PROPERTY_ACCESSOR = new DirectPropertyAccessor();
 	private static final PropertyAccessor MAP_ACCESSOR = new MapAccessor();
 	private static final PropertyAccessor NOOP_ACCESSOR = new NoopAccessor();
 	private static final PropertyAccessor EMBEDDED_PROPERTY_ACCESSOR = new EmbeddedPropertyAccessor();
 
 	//TODO: ideally we need the construction of PropertyAccessor to take the following:
 	//      1) EntityMode
 	//      2) EntityMode-specific data (i.e., the classname for pojo entities)
 	//      3) Property-specific data based on the EntityMode (i.e., property-name or dom4j-node-name)
 	// The easiest way, with the introduction of the new runtime-metamodel classes, would be the
 	// the following predicates:
 	//      1) PropertyAccessorFactory.getPropertyAccessor() takes references to both a
 	//          org.hibernate.metadata.EntityModeMetadata and org.hibernate.metadata.Property
 	//      2) What is now termed a "PropertyAccessor" stores any values needed from those two
 	//          pieces of information
 	//      3) Code can then simply call PropertyAccess.getGetter() with no parameters; likewise with
 	//          PropertyAccessor.getSetter()
 
     /**
      * Retrieves a PropertyAccessor instance based on the given property definition and
      * entity mode.
      *
      * @param property The property for which to retrieve an accessor.
      * @param mode The mode for the resulting entity.
      * @return An appropriate accessor.
      * @throws MappingException
      */
 	public static PropertyAccessor getPropertyAccessor(Property property, EntityMode mode) throws MappingException {
 		//TODO: this is temporary in that the end result will probably not take a Property reference per-se.
 	    if ( null == mode || EntityMode.POJO.equals( mode ) ) {
 		    return getPojoPropertyAccessor( property.getPropertyAccessorName() );
 	    }
 	    else if ( EntityMode.MAP.equals( mode ) ) {
 		    return getDynamicMapPropertyAccessor();
 	    }
 	    else {
 		    throw new MappingException( "Unknown entity mode [" + mode + "]" );
 	    }
 	}
 
 
 	/**
 	 * Retreives a PropertyAccessor specific for a PojoRepresentation with the given access strategy.
 	 *
 	 * @param pojoAccessorStrategy The access strategy.
 	 * @return An appropriate accessor.
 	 */
 	private static PropertyAccessor getPojoPropertyAccessor(String pojoAccessorStrategy) {
 		if ( StringHelper.isEmpty( pojoAccessorStrategy ) || "property".equals( pojoAccessorStrategy ) ) {
 			return BASIC_PROPERTY_ACCESSOR;
 		}
 		else if ( "field".equals( pojoAccessorStrategy ) ) {
 			return DIRECT_PROPERTY_ACCESSOR;
 		}
 		else if ( "embedded".equals( pojoAccessorStrategy ) ) {
 			return EMBEDDED_PROPERTY_ACCESSOR;
 		}
 		else if ( "noop".equals(pojoAccessorStrategy) ) {
 			return NOOP_ACCESSOR;
 		}
 		else {
 			return resolveCustomAccessor( pojoAccessorStrategy );
 		}
 	}
 
 	public static PropertyAccessor getDynamicMapPropertyAccessor() throws MappingException {
 		return MAP_ACCESSOR;
 	}
 
 	private static PropertyAccessor resolveCustomAccessor(String accessorName) {
 		Class accessorClass;
 		try {
 			accessorClass = ReflectHelper.classForName( accessorName );
 		}
 		catch (ClassNotFoundException cnfe) {
 			throw new MappingException("could not find PropertyAccessor class: " + accessorName, cnfe);
 		}
 		try {
 			return (PropertyAccessor) accessorClass.newInstance();
 		}
 		catch (Exception e) {
 			throw new MappingException("could not instantiate PropertyAccessor class: " + accessorName, e);
 		}
 	}
 
 	private PropertyAccessorFactory() {}
 
 	// todo : this eventually needs to be removed
 	public static PropertyAccessor getPropertyAccessor(Class optionalClass, String type) throws MappingException {
-		if ( type==null ) type = optionalClass==null || optionalClass==Map.class ? "map" : "property";
+		if ( type==null ) {
+			type = optionalClass==null || optionalClass==Map.class ? "map" : "property";
+		}
 		return getPropertyAccessor(type);
 	}
 
 	// todo : this eventually needs to be removed
 	public static PropertyAccessor getPropertyAccessor(String type) throws MappingException {
-		if ( type==null || "property".equals(type) ) return BASIC_PROPERTY_ACCESSOR;
-		if ( "field".equals(type) ) return DIRECT_PROPERTY_ACCESSOR;
-		if ( "map".equals(type) ) return MAP_ACCESSOR;
-		if ( "embedded".equals(type) ) return EMBEDDED_PROPERTY_ACCESSOR;
-		if ( "noop".equals(type)) return NOOP_ACCESSOR;
+		if ( type==null || "property".equals(type) ) {
+			return BASIC_PROPERTY_ACCESSOR;
+		}
+		if ( "field".equals(type) ) {
+			return DIRECT_PROPERTY_ACCESSOR;
+		}
+		if ( "map".equals(type) ) {
+			return MAP_ACCESSOR;
+		}
+		if ( "embedded".equals(type) ) {
+			return EMBEDDED_PROPERTY_ACCESSOR;
+		}
+		if ( "noop".equals(type)) {
+			return NOOP_ACCESSOR;
+		}
 
 		return resolveCustomAccessor(type);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/proxy/pojo/BasicLazyInitializer.java b/hibernate-core/src/main/java/org/hibernate/proxy/pojo/BasicLazyInitializer.java
index 4ac2e9eca2..78002d762b 100644
--- a/hibernate-core/src/main/java/org/hibernate/proxy/pojo/BasicLazyInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/proxy/pojo/BasicLazyInitializer.java
@@ -1,137 +1,139 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.proxy.pojo;
 
 import java.io.Serializable;
 import java.lang.reflect.Method;
 
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.proxy.AbstractLazyInitializer;
 import org.hibernate.type.CompositeType;
 
 /**
  * Lazy initializer for POJOs
  *
  * @author Gavin King
  */
 public abstract class BasicLazyInitializer extends AbstractLazyInitializer {
 
 	protected static final Object INVOKE_IMPLEMENTATION = new MarkerObject("INVOKE_IMPLEMENTATION");
 
 	protected final Class persistentClass;
 	protected final Method getIdentifierMethod;
 	protected final Method setIdentifierMethod;
 	protected final boolean overridesEquals;
 	protected final CompositeType componentIdType;
 
 	private Object replacement;
 
 	protected BasicLazyInitializer(
 			String entityName,
 	        Class persistentClass,
 	        Serializable id,
 	        Method getIdentifierMethod,
 	        Method setIdentifierMethod,
 	        CompositeType componentIdType,
 	        SessionImplementor session,
 	        boolean overridesEquals) {
 		super(entityName, id, session);
 		this.persistentClass = persistentClass;
 		this.getIdentifierMethod = getIdentifierMethod;
 		this.setIdentifierMethod = setIdentifierMethod;
 		this.componentIdType = componentIdType;
 		this.overridesEquals = overridesEquals;
 	}
 
 	protected abstract Object serializableProxy();
 
 	protected final Object invoke(Method method, Object[] args, Object proxy) throws Throwable {
 		String methodName = method.getName();
 		int params = args.length;
 
 		if ( params==0 ) {
 			if ( "writeReplace".equals(methodName) ) {
 				return getReplacement();
 			}
 			else if ( !overridesEquals && "hashCode".equals(methodName) ) {
 				return System.identityHashCode(proxy);
 			}
 			else if ( isUninitialized() && method.equals(getIdentifierMethod) ) {
 				return getIdentifier();
 			}
 			else if ( "getHibernateLazyInitializer".equals(methodName) ) {
 				return this;
 			}
 		}
 		else if ( params==1 ) {
 			if ( !overridesEquals && "equals".equals(methodName) ) {
 				return args[0]==proxy;
 			}
 			else if ( method.equals(setIdentifierMethod) ) {
 				initialize();
 				setIdentifier( (Serializable) args[0] );
 				return INVOKE_IMPLEMENTATION;
 			}
 		}
 
 		//if it is a property of an embedded component, invoke on the "identifier"
 		if ( componentIdType!=null && componentIdType.isMethodOf(method) ) {
 			return method.invoke( getIdentifier(), args );
 		}
 
 		// otherwise:
 		return INVOKE_IMPLEMENTATION;
 
 	}
 
 	private Object getReplacement() {
 		final SessionImplementor session = getSession();
 		if ( isUninitialized() && session != null && session.isOpen()) {
 			final EntityKey key = session.generateEntityKey(
 					getIdentifier(),
 					session.getFactory().getEntityPersister( getEntityName() )
 			);
 			final Object entity = session.getPersistenceContext().getEntity(key);
-			if (entity!=null) setImplementation( entity );
+			if (entity!=null) {
+				setImplementation( entity );
+			}
 		}
 
 		if ( isUninitialized() ) {
 			if (replacement==null) {
 				replacement = serializableProxy();
 			}
 			return replacement;
 		}
 		else {
 			return getTarget();
 		}
 
 	}
 
 	public final Class getPersistentClass() {
 		return persistentClass;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/result/internal/OutputsImpl.java b/hibernate-core/src/main/java/org/hibernate/result/internal/OutputsImpl.java
index 9adc2ad53f..3adf88ecad 100644
--- a/hibernate-core/src/main/java/org/hibernate/result/internal/OutputsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/result/internal/OutputsImpl.java
@@ -1,312 +1,313 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.result.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.JDBCException;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.loader.custom.sql.SQLQueryReturnProcessor;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.result.NoMoreReturnsException;
 import org.hibernate.result.Output;
 import org.hibernate.result.Outputs;
 import org.hibernate.result.spi.ResultContext;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Steve Ebersole
  */
 public class OutputsImpl implements Outputs {
 	private static final Logger log = CoreLogging.logger( OutputsImpl.class );
 
 	private final ResultContext context;
 	private final PreparedStatement jdbcStatement;
 	private final CustomLoaderExtension loader;
 
 	private CurrentReturnState currentReturnState;
 
 	public OutputsImpl(ResultContext context, PreparedStatement jdbcStatement) {
 		this.context = context;
 		this.jdbcStatement = jdbcStatement;
 
 		// For now...  but see the LoadPlan work; eventually this should just be a ResultSetProcessor.
 		this.loader = buildSpecializedCustomLoader( context );
 
 		try {
 			final boolean isResultSet = jdbcStatement.execute();
 			currentReturnState = buildCurrentReturnState( isResultSet );
 		}
 		catch (SQLException e) {
 			throw convert( e, "Error calling CallableStatement.getMoreResults" );
 		}
 	}
 
 	private CurrentReturnState buildCurrentReturnState(boolean isResultSet) {
 		int updateCount = -1;
 		if ( ! isResultSet ) {
 			try {
 				updateCount = jdbcStatement.getUpdateCount();
 			}
 			catch (SQLException e) {
 				throw convert( e, "Error calling CallableStatement.getUpdateCount" );
 			}
 		}
 
 		return buildCurrentReturnState( isResultSet, updateCount );
 	}
 
 	protected CurrentReturnState buildCurrentReturnState(boolean isResultSet, int updateCount) {
 		return new CurrentReturnState( isResultSet, updateCount );
 	}
 
 	protected JDBCException convert(SQLException e, String message) {
 		return context.getSession().getFactory().getSQLExceptionHelper().convert(
 				e,
 				message,
 				context.getSql()
 		);
 	}
 
 	@Override
 	public Output getCurrent() {
 		if ( currentReturnState == null ) {
 			return null;
 		}
 		return currentReturnState.getOutput();
 	}
 
 	@Override
 	public boolean goToNext() {
 		if ( currentReturnState == null ) {
 			return false;
 		}
 
-		if ( currentReturnState.indicatesMoreOutputs() )
-		// prepare the next return state
-		try {
-			final boolean isResultSet = jdbcStatement.getMoreResults();
-			currentReturnState = buildCurrentReturnState( isResultSet );
-		}
-		catch (SQLException e) {
-			throw convert( e, "Error calling CallableStatement.getMoreResults" );
+		if ( currentReturnState.indicatesMoreOutputs() ) {
+			// prepare the next return state
+			try {
+				final boolean isResultSet = jdbcStatement.getMoreResults();
+				currentReturnState = buildCurrentReturnState( isResultSet );
+			}
+			catch (SQLException e) {
+				throw convert( e, "Error calling CallableStatement.getMoreResults" );
+			}
 		}
 
 		// and return
 		return currentReturnState != null && currentReturnState.indicatesMoreOutputs();
 	}
 
 	@Override
 	public void release() {
 		try {
 			jdbcStatement.close();
 		}
 		catch (SQLException e) {
 			log.debug( "Unable to close PreparedStatement", e );
 		}
 	}
 
 	private List extractCurrentResults() {
 		try {
 			return extractResults( jdbcStatement.getResultSet() );
 		}
 		catch (SQLException e) {
 			throw convert( e, "Error calling CallableStatement.getResultSet" );
 		}
 	}
 
 	protected List extractResults(ResultSet resultSet) {
 		try {
 			return loader.processResultSet( resultSet );
 		}
 		catch (SQLException e) {
 			throw convert( e, "Error extracting results from CallableStatement" );
 		}
 	}
 
 	/**
 	 * Encapsulates the information needed to interpret the current return within a result
 	 */
 	protected class CurrentReturnState {
 		private final boolean isResultSet;
 		private final int updateCount;
 
 		private Output rtn;
 
 		protected CurrentReturnState(boolean isResultSet, int updateCount) {
 			this.isResultSet = isResultSet;
 			this.updateCount = updateCount;
 		}
 
 		public boolean indicatesMoreOutputs() {
 			return isResultSet() || getUpdateCount() >= 0;
 		}
 
 		public boolean isResultSet() {
 			return isResultSet;
 		}
 
 		public int getUpdateCount() {
 			return updateCount;
 		}
 
 		public Output getOutput() {
 			if ( rtn == null ) {
 				rtn = buildOutput();
 			}
 			return rtn;
 		}
 
 		protected Output buildOutput() {
 			if ( log.isDebugEnabled() ) {
 				log.debugf(
 						"Building Return [isResultSet=%s, updateCount=%s, extendedReturn=%s",
 						isResultSet(),
 						getUpdateCount(),
 						hasExtendedReturns()
 				);
 			}
 
 			if ( isResultSet() ) {
 				return buildResultSetOutput( extractCurrentResults() );
 			}
 			else if ( getUpdateCount() >= 0 ) {
 				return buildUpdateCountOutput( updateCount );
 			}
 			else if ( hasExtendedReturns() ) {
 				return buildExtendedReturn();
 			}
 
 			throw new NoMoreReturnsException();
 		}
 
 		// hooks for stored procedure (out param) processing ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		protected Output buildResultSetOutput(List list) {
 			return new ResultSetOutputImpl( list );
 		}
 
 		protected Output buildUpdateCountOutput(int updateCount) {
 			return new UpdateCountOutputImpl( updateCount );
 		}
 
 		protected boolean hasExtendedReturns() {
 			return false;
 		}
 
 		protected Output buildExtendedReturn() {
 			throw new IllegalStateException( "State does not define extended returns" );
 		}
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Hooks into Hibernate's Loader hierarchy for ResultSet -> Object mapping
 
 	private static CustomLoaderExtension buildSpecializedCustomLoader(final ResultContext context) {
 		// might be better to just manually construct the Return(s).. SQLQueryReturnProcessor does a lot of
 		// work that is really unnecessary here.
 		final SQLQueryReturnProcessor processor = new SQLQueryReturnProcessor(
 				context.getQueryReturns(),
 				context.getSession().getFactory()
 		);
 		processor.process();
 		final List<org.hibernate.loader.custom.Return> customReturns = processor.generateCustomReturns( false );
 
 		CustomQuery customQuery = new CustomQuery() {
 			@Override
 			public String getSQL() {
 				return context.getSql();
 			}
 
 			@Override
 			public Set<String> getQuerySpaces() {
 				return context.getSynchronizedQuerySpaces();
 			}
 
 			@Override
 			public Map getNamedParameterBindPoints() {
 				// no named parameters in terms of embedded in the SQL string
 				return null;
 			}
 
 			@Override
 			public List<org.hibernate.loader.custom.Return> getCustomQueryReturns() {
 				return customReturns;
 			}
 		};
 
 		return new CustomLoaderExtension(
 				customQuery,
 				context.getQueryParameters(),
 				context.getSession()
 		);
 	}
 
 	private static class CustomLoaderExtension extends CustomLoader {
 		private QueryParameters queryParameters;
 		private SessionImplementor session;
 
 		private boolean needsDiscovery = true;
 
 		public CustomLoaderExtension(
 				CustomQuery customQuery,
 				QueryParameters queryParameters,
 				SessionImplementor session) {
 			super( customQuery, session.getFactory() );
 			this.queryParameters = queryParameters;
 			this.session = session;
 		}
 
 		// todo : this would be a great way to add locking to stored procedure support (at least where returning entities).
 
 		public List processResultSet(ResultSet resultSet) throws SQLException {
 			if ( needsDiscovery ) {
 				super.autoDiscoverTypes( resultSet );
 				// todo : EntityAliases discovery
 				needsDiscovery = false;
 			}
 			return super.processResultSet(
 					resultSet,
 					queryParameters,
 					session,
 					true,
 					null,
 					Integer.MAX_VALUE,
 					Collections.<AfterLoadAction>emptyList()
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/ConditionFragment.java b/hibernate-core/src/main/java/org/hibernate/sql/ConditionFragment.java
index 79355660bc..7d66e79e9a 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/ConditionFragment.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/ConditionFragment.java
@@ -1,81 +1,83 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 /**
  * @author Gavin King
  */
 public class ConditionFragment {
 	private String tableAlias;
 	private String[] lhs;
 	private String[] rhs;
 	private String op = "=";
 
 	/**
 	 * Sets the op.
 	 * @param op The op to set
 	 */
 	public ConditionFragment setOp(String op) {
 		this.op = op;
 		return this;
 	}
 
 	/**
 	 * Sets the tableAlias.
 	 * @param tableAlias The tableAlias to set
 	 */
 	public ConditionFragment setTableAlias(String tableAlias) {
 		this.tableAlias = tableAlias;
 		return this;
 	}
 
 	public ConditionFragment setCondition(String[] lhs, String[] rhs) {
 		this.lhs = lhs;
 		this.rhs = rhs;
 		return this;
 	}
 
 	public ConditionFragment setCondition(String[] lhs, String rhs) {
 		this.lhs = lhs;
 		this.rhs = ArrayHelper.fillArray(rhs, lhs.length);
 		return this;
 	}
 
 	public String toFragmentString() {
 		StringBuilder buf = new StringBuilder( lhs.length * 10 );
 		for ( int i=0; i<lhs.length; i++ ) {
 			buf.append(tableAlias)
 				.append('.')
 				.append( lhs[i] )
 				.append(op)
 				.append( rhs[i] );
-			if (i<lhs.length-1) buf.append(" and ");
+			if (i<lhs.length-1) {
+				buf.append(" and ");
+			}
 		}
 		return buf.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/Delete.java b/hibernate-core/src/main/java/org/hibernate/sql/Delete.java
index faec336722..0878f98899 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/Delete.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/Delete.java
@@ -1,141 +1,143 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.Map;
 
 /**
  * An SQL <tt>DELETE</tt> statement
  *
  * @author Gavin King
  */
 public class Delete {
 
 	private String tableName;
 	private String versionColumnName;
 	private String where;
 
 	private Map primaryKeyColumns = new LinkedHashMap();	
 	
 	private String comment;
 	public Delete setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
 
 	public Delete setTableName(String tableName) {
 		this.tableName = tableName;
 		return this;
 	}
 
 	public String toStatementString() {
 		StringBuilder buf = new StringBuilder( tableName.length() + 10 );
 		if ( comment!=null ) {
 			buf.append( "/* " ).append(comment).append( " */ " );
 		}
 		buf.append( "delete from " ).append(tableName);
 		if ( where != null || !primaryKeyColumns.isEmpty() || versionColumnName != null ) {
 			buf.append( " where " );
 		}
 		boolean conditionsAppended = false;
 		Iterator iter = primaryKeyColumns.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry e = (Map.Entry) iter.next();
 			buf.append( e.getKey() ).append( '=' ).append( e.getValue() );
 			if ( iter.hasNext() ) {
 				buf.append( " and " );
 			}
 			conditionsAppended = true;
 		}
 		if ( where!=null ) {
 			if ( conditionsAppended ) {
 				buf.append( " and " );
 			}
 			buf.append( where );
 			conditionsAppended = true;
 		}
 		if ( versionColumnName!=null ) {
 			if ( conditionsAppended ) {
 				buf.append( " and " );
 			}
 			buf.append( versionColumnName ).append( "=?" );
 		}
 		return buf.toString();
 	}
 
 	public Delete setWhere(String where) {
 		this.where=where;
 		return this;
 	}
 
 	public Delete addWhereFragment(String fragment) {
 		if ( where == null ) {
 			where = fragment;
 		}
 		else {
 			where += ( " and " + fragment );
 		}
 		return this;
 	}
 
 	public Delete setPrimaryKeyColumnNames(String[] columnNames) {
 		this.primaryKeyColumns.clear();
 		addPrimaryKeyColumns(columnNames);
 		return this;
 	}	
 
 	public Delete addPrimaryKeyColumns(String[] columnNames) {
-		for ( int i=0; i<columnNames.length; i++ ) {
-			addPrimaryKeyColumn( columnNames[i], "?" );
+		for ( String columnName : columnNames ) {
+			addPrimaryKeyColumn( columnName, "?" );
 		}
 		return this;
 	}
 	
 	public Delete addPrimaryKeyColumns(String[] columnNames, boolean[] includeColumns, String[] valueExpressions) {
 		for ( int i=0; i<columnNames.length; i++ ) {
-			if( includeColumns[i] ) addPrimaryKeyColumn( columnNames[i], valueExpressions[i] );
+			if( includeColumns[i] ) {
+				addPrimaryKeyColumn( columnNames[i], valueExpressions[i] );
+			}
 		}
 		return this;
 	}
 	
 	public Delete addPrimaryKeyColumns(String[] columnNames, String[] valueExpressions) {
 		for ( int i=0; i<columnNames.length; i++ ) {
 			addPrimaryKeyColumn( columnNames[i], valueExpressions[i] );
 		}
 		return this;
 	}	
 
 	public Delete addPrimaryKeyColumn(String columnName, String valueExpression) {
 		this.primaryKeyColumns.put(columnName, valueExpression);
 		return this;
 	}
 
 	public Delete setVersionColumnName(String versionColumnName) {
 		this.versionColumnName = versionColumnName;
 		return this;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/InsertSelect.java b/hibernate-core/src/main/java/org/hibernate/sql/InsertSelect.java
index 37bda6996b..c05ab2e486 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/InsertSelect.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/InsertSelect.java
@@ -1,100 +1,103 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.Dialect;
 
 /**
  * Implementation of InsertSelect.
  *
  * @author Steve Ebersole
  */
 public class InsertSelect {
-
 	private Dialect dialect;
 	private String tableName;
 	private String comment;
 	private List columnNames = new ArrayList();
 	private Select select;
 
 	public InsertSelect(Dialect dialect) {
 		this.dialect = dialect;
 	}
 
 	public InsertSelect setTableName(String tableName) {
 		this.tableName = tableName;
 		return this;
 	}
 
 	public InsertSelect setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
 
 	public InsertSelect addColumn(String columnName) {
 		columnNames.add( columnName );
 		return this;
 	}
 
 	public InsertSelect addColumns(String[] columnNames) {
 		for ( int i = 0; i < columnNames.length; i++ ) {
 			this.columnNames.add( columnNames[i] );
 		}
 		return this;
 	}
 
 	public InsertSelect setSelect(Select select) {
 		this.select = select;
 		return this;
 	}
 
 	public String toStatementString() {
-		if ( tableName == null ) throw new HibernateException( "no table name defined for insert-select" );
-		if ( select == null ) throw new HibernateException( "no select defined for insert-select" );
+		if ( tableName == null ) {
+			throw new HibernateException( "no table name defined for insert-select" );
+		}
+		if ( select == null ) {
+			throw new HibernateException( "no select defined for insert-select" );
+		}
 
 		StringBuilder buf = new StringBuilder( (columnNames.size() * 15) + tableName.length() + 10 );
 		if ( comment!=null ) {
 			buf.append( "/* " ).append( comment ).append( " */ " );
 		}
 		buf.append( "insert into " ).append( tableName );
 		if ( !columnNames.isEmpty() ) {
 			buf.append( " (" );
 			Iterator itr = columnNames.iterator();
 			while ( itr.hasNext() ) {
 				buf.append( itr.next() );
 				if ( itr.hasNext() ) {
 					buf.append( ", " );
 				}
 			}
 			buf.append( ")" );
 		}
 		buf.append( ' ' ).append( select.toStatementString() );
 		return buf.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/OracleJoinFragment.java b/hibernate-core/src/main/java/org/hibernate/sql/OracleJoinFragment.java
index 585d82e081..de0ee921be 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/OracleJoinFragment.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/OracleJoinFragment.java
@@ -1,149 +1,151 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import java.util.HashSet;
 import java.util.Set;
 
 /**
  * An Oracle-style (theta) join
  *
  * @author Jon Lipsky, Gavin King
  */
 public class OracleJoinFragment extends JoinFragment {
 
 	private StringBuilder afterFrom = new StringBuilder();
 	private StringBuilder afterWhere = new StringBuilder();
 
 	public void addJoin(String tableName, String alias, String[] fkColumns, String[] pkColumns, JoinType joinType) {
-
 		addCrossJoin( tableName, alias );
 
 		for ( int j = 0; j < fkColumns.length; j++ ) {
 			setHasThetaJoins( true );
 			afterWhere.append( " and " )
 					.append( fkColumns[j] );
-			if ( joinType == JoinType.RIGHT_OUTER_JOIN || joinType == JoinType.FULL_JOIN ) afterWhere.append( "(+)" );
+			if ( joinType == JoinType.RIGHT_OUTER_JOIN || joinType == JoinType.FULL_JOIN ) {
+				afterWhere.append( "(+)" );
+			}
 			afterWhere.append( '=' )
 					.append( alias )
 					.append( '.' )
 					.append( pkColumns[j] );
-			if ( joinType == JoinType.LEFT_OUTER_JOIN || joinType == JoinType.FULL_JOIN ) afterWhere.append( "(+)" );
+			if ( joinType == JoinType.LEFT_OUTER_JOIN || joinType == JoinType.FULL_JOIN ) {
+				afterWhere.append( "(+)" );
+			}
 		}
-
 	}
 
 	public String toFromFragmentString() {
 		return afterFrom.toString();
 	}
 
 	public String toWhereFragmentString() {
 		return afterWhere.toString();
 	}
 
 	public void addJoins(String fromFragment, String whereFragment) {
 		afterFrom.append( fromFragment );
 		afterWhere.append( whereFragment );
 	}
 
 	public JoinFragment copy() {
 		OracleJoinFragment copy = new OracleJoinFragment();
 		copy.afterFrom = new StringBuilder( afterFrom.toString() );
 		copy.afterWhere = new StringBuilder( afterWhere.toString() );
 		return copy;
 	}
 
 	public void addCondition(String alias, String[] columns, String condition) {
-		for ( int i = 0; i < columns.length; i++ ) {
+		for ( String column : columns ) {
 			afterWhere.append( " and " )
 					.append( alias )
 					.append( '.' )
-					.append( columns[i] )
+					.append( column )
 					.append( condition );
 		}
 	}
 
 	public void addCrossJoin(String tableName, String alias) {
 		afterFrom.append( ", " )
 				.append( tableName )
 				.append( ' ' )
 				.append( alias );
 	}
 
 	public void addCondition(String alias, String[] fkColumns, String[] pkColumns) {
 		throw new UnsupportedOperationException();
 	}
 
 	public boolean addCondition(String condition) {
 		return addCondition( afterWhere, condition );
 	}
 
 	public void addFromFragmentString(String fromFragmentString) {
 		afterFrom.append( fromFragmentString );
 	}
 
 	public void addJoin(String tableName, String alias, String[] fkColumns, String[] pkColumns, JoinType joinType, String on) {
 		//arbitrary on clause ignored!!
 		addJoin( tableName, alias, fkColumns, pkColumns, joinType );
 		if ( joinType == JoinType.INNER_JOIN ) {
 			addCondition( on );
 		}
 		else if ( joinType == JoinType.LEFT_OUTER_JOIN ) {
 			addLeftOuterJoinCondition( on );
 		}
 		else {
 			throw new UnsupportedOperationException( "join type not supported by OracleJoinFragment (use Oracle9iDialect/Oracle10gDialect)" );
 		}
 	}
 
 	/**
 	 * This method is a bit of a hack, and assumes
 	 * that the column on the "right" side of the
 	 * join appears on the "left" side of the
 	 * operator, which is extremely wierd if this
 	 * was a normal join condition, but is natural
 	 * for a filter.
 	 */
 	private void addLeftOuterJoinCondition(String on) {
 		StringBuilder buf = new StringBuilder( on );
 		for ( int i = 0; i < buf.length(); i++ ) {
 			char character = buf.charAt( i );
 			final boolean isInsertPoint = OPERATORS.contains( Character.valueOf( character ) )
 					|| ( character == ' ' && buf.length() > i + 3 && "is ".equals( buf.substring( i + 1, i + 4 ) ) );
 			if ( isInsertPoint ) {
 				buf.insert( i, "(+)" );
 				i += 3;
 			}
 		}
 		addCondition( buf.toString() );
 	}
 
 	private static final Set OPERATORS = new HashSet();
 
 	static {
 		OPERATORS.add( Character.valueOf( '=' ) );
 		OPERATORS.add( Character.valueOf( '<' ) );
 		OPERATORS.add( Character.valueOf( '>' ) );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java b/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
index 9e250256a6..45d5db0aff 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
@@ -1,212 +1,228 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import java.util.HashSet;
 import java.util.Iterator;
 
 import org.hibernate.dialect.Dialect;
 
 /**
  * A translated HQL query
  * @author Gavin King
  */
 public class QuerySelect {
 	private Dialect dialect;
 	private JoinFragment joins;
 	private StringBuilder select = new StringBuilder();
 	private StringBuilder where = new StringBuilder();
 	private StringBuilder groupBy = new StringBuilder();
 	private StringBuilder orderBy = new StringBuilder();
 	private StringBuilder having = new StringBuilder();
 	private String comment;
 	private boolean distinct;
 
-	private static final HashSet DONT_SPACE_TOKENS = new HashSet();
+	private static final HashSet<String> DONT_SPACE_TOKENS = new HashSet<String>();
 	static {
 		//dontSpace.add("'");
 		DONT_SPACE_TOKENS.add(".");
 		DONT_SPACE_TOKENS.add("+");
 		DONT_SPACE_TOKENS.add("-");
 		DONT_SPACE_TOKENS.add("/");
 		DONT_SPACE_TOKENS.add("*");
 		DONT_SPACE_TOKENS.add("<");
 		DONT_SPACE_TOKENS.add(">");
 		DONT_SPACE_TOKENS.add("=");
 		DONT_SPACE_TOKENS.add("#");
 		DONT_SPACE_TOKENS.add("~");
 		DONT_SPACE_TOKENS.add("|");
 		DONT_SPACE_TOKENS.add("&");
 		DONT_SPACE_TOKENS.add("<=");
 		DONT_SPACE_TOKENS.add(">=");
 		DONT_SPACE_TOKENS.add("=>");
 		DONT_SPACE_TOKENS.add("=<");
 		DONT_SPACE_TOKENS.add("!=");
 		DONT_SPACE_TOKENS.add("<>");
 		DONT_SPACE_TOKENS.add("!#");
 		DONT_SPACE_TOKENS.add("!~");
 		DONT_SPACE_TOKENS.add("!<");
 		DONT_SPACE_TOKENS.add("!>");
 		DONT_SPACE_TOKENS.add("("); //for MySQL
 		DONT_SPACE_TOKENS.add(")");
 	}
 
 	public QuerySelect(Dialect dialect) {
 		this.dialect = dialect;
 		joins = new QueryJoinFragment(dialect, false);
 	}
 
 	public JoinFragment getJoinFragment() {
 		return joins;
 	}
 
 	public void addSelectFragmentString(String fragment) {
-		if ( fragment.length()>0 && fragment.charAt(0)==',' ) fragment = fragment.substring(1);
+		if ( fragment.length()>0 && fragment.charAt(0)==',' ) {
+			fragment = fragment.substring(1);
+		}
 		fragment = fragment.trim();
 		if ( fragment.length()>0 ) {
-			if ( select.length()>0 ) select.append(", ");
+			if ( select.length()>0 ) {
+				select.append(", ");
+			}
 			select.append(fragment);
 		}
 	}
 
 	public void addSelectColumn(String columnName, String alias) {
 		addSelectFragmentString(columnName + ' ' + alias);
 	}
 
 	public void setDistinct(boolean distinct) {
 		this.distinct = distinct;
 	}
 
 	public void setWhereTokens(Iterator tokens) {
 		//if ( conjunctiveWhere.length()>0 ) conjunctiveWhere.append(" and ");
 		appendTokens(where, tokens);
 	}
 
 	public void prependWhereConditions(String conditions) {
 		if (where.length() > 0) {
 			where.insert(0, conditions + " and ");
 		}
 		else {
 			where.append(conditions);
 		}
 	}
 
 	public void setGroupByTokens(Iterator tokens) {
 		//if ( groupBy.length()>0 ) groupBy.append(" and ");
 		appendTokens(groupBy, tokens);
 	}
 
 	public void setOrderByTokens(Iterator tokens) {
 		//if ( orderBy.length()>0 ) orderBy.append(" and ");
 		appendTokens(orderBy, tokens);
 	}
 
 	public void setHavingTokens(Iterator tokens) {
 		//if ( having.length()>0 ) having.append(" and ");
 		appendTokens(having, tokens);
 	}
 
 	public void addOrderBy(String orderByString) {
-		if ( orderBy.length() > 0 ) orderBy.append(", ");
+		if ( orderBy.length() > 0 ) {
+			orderBy.append(", ");
+		}
 		orderBy.append(orderByString);
 	}
 
 	public String toQueryString() {
 		StringBuilder buf = new StringBuilder(50);
-		if (comment!=null) buf.append("/* ").append(comment).append(" */ ");
+		if (comment!=null) {
+			buf.append("/* ").append(comment).append(" */ ");
+		}
 		buf.append("select ");
-		if (distinct) buf.append("distinct ");
+		if (distinct) {
+			buf.append("distinct ");
+		}
 		String from = joins.toFromFragmentString();
 		if ( from.startsWith(",") ) {
 			from = from.substring(1);
 		}
 		else if ( from.startsWith(" inner join") ){
 			from = from.substring(11);
 		}
 
 		buf.append( select.toString() )
 			.append(" from")
 			.append(from);
 
 		String outerJoinsAfterWhere = joins.toWhereFragmentString().trim();
 		String whereConditions = where.toString().trim();
 		boolean hasOuterJoinsAfterWhere = outerJoinsAfterWhere.length() > 0;
 		boolean hasWhereConditions = whereConditions.length() > 0;
 		if (hasOuterJoinsAfterWhere || hasWhereConditions) {
 			buf.append(" where ");
 			if (hasOuterJoinsAfterWhere) {
 				buf.append( outerJoinsAfterWhere.substring(4) );
 			}
 			if (hasWhereConditions) {
 				if (hasOuterJoinsAfterWhere) {
 					buf.append(" and (");
 				}
 				buf.append(whereConditions);
 				if (hasOuterJoinsAfterWhere) {
 					buf.append(")");
 				}
 			}
 		}
 
-		if ( groupBy.length() > 0 ) buf.append(" group by ").append( groupBy.toString() );
-		if ( having.length() > 0 ) buf.append(" having ").append( having.toString() );
-		if ( orderBy.length() > 0 ) buf.append(" order by ").append( orderBy.toString() );
+		if ( groupBy.length() > 0 ) {
+			buf.append(" group by ").append( groupBy.toString() );
+		}
+		if ( having.length() > 0 ) {
+			buf.append(" having ").append( having.toString() );
+		}
+		if ( orderBy.length() > 0 ) {
+			buf.append(" order by ").append( orderBy.toString() );
+		}
 
 		return dialect.transformSelectString( buf.toString() );
 	}
 
 	private static void appendTokens(StringBuilder buf, Iterator iter) {
 		boolean lastSpaceable=true;
 		boolean lastQuoted=false;
 		while ( iter.hasNext() ) {
 			String token = (String) iter.next();
 			boolean spaceable = !DONT_SPACE_TOKENS.contains(token);
 			boolean quoted = token.startsWith("'");
 			if (spaceable && lastSpaceable) {
 				if ( !quoted || !lastQuoted ) buf.append(' ');
 			}
 			lastSpaceable = spaceable;
 			buf.append(token);
 			lastQuoted = token.endsWith("'");
 		}
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public QuerySelect copy() {
 		QuerySelect copy = new QuerySelect(dialect);
 		copy.joins = this.joins.copy();
 		copy.select.append( this.select.toString() );
 		copy.where.append( this.where.toString() );
 		copy.groupBy.append( this.groupBy.toString() );
 		copy.orderBy.append( this.orderBy.toString() );
 		copy.having.append( this.having.toString() );
 		copy.comment = this.comment;
 		copy.distinct = this.distinct;
 		return copy;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/Select.java b/hibernate-core/src/main/java/org/hibernate/sql/Select.java
index c3fb086f08..0d8900f4d3 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/Select.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/Select.java
@@ -1,212 +1,214 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.StringHelper;
 
 
 /**
  * A simple SQL <tt>SELECT</tt> statement
  * @author Gavin King
  */
 public class Select {
 
 	private String selectClause;
 	private String fromClause;
 	private String outerJoinsAfterFrom;
 	private String whereClause;
 	private String outerJoinsAfterWhere;
 	private String orderByClause;
 	private String groupByClause;
 	private String comment;
 	private LockOptions lockOptions = new LockOptions();
 	public final Dialect dialect;
 
 	private int guesstimatedBufferSize = 20;
 	
 	public Select(Dialect dialect) {
 		this.dialect = dialect;
 	}
 
 	/**
 	 * Construct an SQL <tt>SELECT</tt> statement from the given clauses
 	 */
 	public String toStatementString() {
 		StringBuilder buf = new StringBuilder(guesstimatedBufferSize);
 		if ( StringHelper.isNotEmpty(comment) ) {
 			buf.append("/* ").append(comment).append(" */ ");
 		}
 		
 		buf.append("select ").append(selectClause)
 				.append(" from ").append(fromClause);
 		
 		if ( StringHelper.isNotEmpty(outerJoinsAfterFrom) ) {
 			buf.append(outerJoinsAfterFrom);
 		}
 		
 		if ( StringHelper.isNotEmpty(whereClause) || StringHelper.isNotEmpty(outerJoinsAfterWhere) ) {
 			buf.append(" where " );
 			// the outerJoinsAfterWhere needs to come before where clause to properly
 			// handle dynamic filters
 			if ( StringHelper.isNotEmpty(outerJoinsAfterWhere) ) {
 				buf.append(outerJoinsAfterWhere);
 				if ( StringHelper.isNotEmpty(whereClause) ) {
 					buf.append( " and " );
 				}
 			}
 			if ( StringHelper.isNotEmpty( whereClause ) ) {
 				buf.append(whereClause);
 			}
 		}
 		
 		if ( StringHelper.isNotEmpty(groupByClause) ) {
 			buf.append(" group by ").append(groupByClause);
 		}
 		
 		if ( StringHelper.isNotEmpty(orderByClause) ) {
 			buf.append(" order by ").append(orderByClause);
 		}
 		
 		if (lockOptions.getLockMode() != LockMode.NONE) {
 			buf.append(dialect.getForUpdateString(lockOptions));
 		}
 		
 		return dialect.transformSelectString( buf.toString() );
 	}
 
 	/**
 	 * Sets the fromClause.
 	 * @param fromClause The fromClause to set
 	 */
 	public Select setFromClause(String fromClause) {
 		this.fromClause = fromClause;
 		this.guesstimatedBufferSize += fromClause.length();
 		return this;
 	}
 
 	public Select setFromClause(String tableName, String alias) {
 		this.fromClause = tableName + ' ' + alias;
 		this.guesstimatedBufferSize += fromClause.length();
 		return this;
 	}
 
 	public Select setOrderByClause(String orderByClause) {
 		this.orderByClause = orderByClause;
 		this.guesstimatedBufferSize += orderByClause.length();
 		return this;
 	}
 
 	public Select setGroupByClause(String groupByClause) {
 		this.groupByClause = groupByClause;
 		this.guesstimatedBufferSize += groupByClause.length();
 		return this;
 	}
 
 	public Select setOuterJoins(String outerJoinsAfterFrom, String outerJoinsAfterWhere) {
 		this.outerJoinsAfterFrom = outerJoinsAfterFrom;
 
 		// strip off any leading 'and' token
 		String tmpOuterJoinsAfterWhere = outerJoinsAfterWhere.trim();
 		if ( tmpOuterJoinsAfterWhere.startsWith("and") ) {
 			tmpOuterJoinsAfterWhere = tmpOuterJoinsAfterWhere.substring(4);
 		}
 		this.outerJoinsAfterWhere = tmpOuterJoinsAfterWhere;
 
 		this.guesstimatedBufferSize += outerJoinsAfterFrom.length() + outerJoinsAfterWhere.length();
 		return this;
 	}
 
 
 	/**
 	 * Sets the selectClause.
 	 * @param selectClause The selectClause to set
 	 */
 	public Select setSelectClause(String selectClause) {
 		this.selectClause = selectClause;
 		this.guesstimatedBufferSize += selectClause.length();
 		return this;
 	}
 
 	public Select setSelectClause(SelectFragment selectFragment) {
 		setSelectClause( selectFragment.toFragmentString().substring( 2 ) );
 		return this;
 	}
 
 	/**
 	 * Sets the whereClause.
 	 * @param whereClause The whereClause to set
 	 */
 	public Select setWhereClause(String whereClause) {
 		this.whereClause = whereClause;
 		this.guesstimatedBufferSize += whereClause.length();
 		return this;
 	}
 
 	public Select setComment(String comment) {
 		this.comment = comment;
 		this.guesstimatedBufferSize += comment.length();
 		return this;
 	}
 
 	/**
 	 * Get the current lock mode
 	 * @return LockMode
 	 * @deprecated Instead use getLockOptions
 	 */
+	@Deprecated
 	public LockMode getLockMode() {
 		return lockOptions.getLockMode();
 	}
 
 	/**
 	 * Set the lock mode
 	 * @param lockMode
 	 * @return this object
 	 * @deprecated Instead use setLockOptions
 	 */
+	@Deprecated
 	public Select setLockMode(LockMode lockMode) {
 		lockOptions.setLockMode(lockMode);
 		return this;
 	}
 
 	/**
 	 * Get the current lock options
 	 * @return LockOptions
 	 */
 	public LockOptions getLockOptions() {
 		return lockOptions;
 	}
 
 	/**
 	 * Set the lock options
 	 * @param lockOptions
 	 * @return this object
 	 */
 	public Select setLockOptions(LockOptions lockOptions) {
 		LockOptions.copy(lockOptions, this.lockOptions);
 		return this;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java b/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
index 9b9393a651..db764b787d 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
@@ -1,169 +1,177 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A fragment of an SQL <tt>SELECT</tt> clause
  *
  * @author Gavin King
  */
 public class SelectFragment {
 	private String suffix;
 	private List columns = new ArrayList();
 	//private List aliases = new ArrayList();
 	private List columnAliases = new ArrayList();
 	private String extraSelectList;
 	private String[] usedAliases;
 
 	public SelectFragment() {}
 
 	public List getColumns() {
 		return columns;
 	}
 
 	public String getExtraSelectList() {
 		return extraSelectList;
 	}
 
 	public SelectFragment setUsedAliases(String[] aliases) {
 		usedAliases = aliases;
 		return this;
 	}
 
 	public SelectFragment setExtraSelectList(String extraSelectList) {
 		this.extraSelectList = extraSelectList;
 		return this;
 	}
 
 	public SelectFragment setExtraSelectList(CaseFragment caseFragment, String fragmentAlias) {
 		setExtraSelectList( caseFragment.setReturnColumnName(fragmentAlias, suffix).toFragmentString() );
 		return this;
 	}
 
 	public SelectFragment setSuffix(String suffix) {
 		this.suffix = suffix;
 		return this;
 	}
 
 	public SelectFragment addColumn(String columnName) {
 		addColumn(null, columnName);
 		return this;
 	}
 
 	public SelectFragment addColumns(String[] columnNames) {
-		for (int i=0; i<columnNames.length; i++) addColumn( columnNames[i] );
+		for ( String columnName : columnNames ) {
+			addColumn( columnName );
+		}
 		return this;
 	}
 
 	public SelectFragment addColumn(String tableAlias, String columnName) {
 		return addColumn(tableAlias, columnName, columnName);
 	}
 
 	public SelectFragment addColumn(String tableAlias, String columnName, String columnAlias) {
 		columns.add( StringHelper.qualify(tableAlias, columnName) );
 		//columns.add(columnName);
 		//aliases.add(tableAlias);
 		columnAliases.add(columnAlias);
 		return this;
 	}
 
 	public SelectFragment addColumns(String tableAlias, String[] columnNames) {
-		for (int i=0; i<columnNames.length; i++) addColumn( tableAlias, columnNames[i] );
+		for ( String columnName : columnNames ) {
+			addColumn( tableAlias, columnName );
+		}
 		return this;
 	}
 
 	public SelectFragment addColumns(String tableAlias, String[] columnNames, String[] columnAliases) {
 		for (int i=0; i<columnNames.length; i++) {
-			if ( columnNames[i]!=null ) addColumn( tableAlias, columnNames[i], columnAliases[i] );
+			if ( columnNames[i]!=null ) {
+				addColumn( tableAlias, columnNames[i], columnAliases[i] );
+			}
 		}
 		return this;
 	}
 
 	public SelectFragment addFormulas(String tableAlias, String[] formulas, String[] formulaAliases) {
 		for ( int i=0; i<formulas.length; i++ ) {
 			if ( formulas[i]!=null ) addFormula( tableAlias, formulas[i], formulaAliases[i] );
 		}
 		return this;
 	}
 
 	public SelectFragment addFormula(String tableAlias, String formula, String formulaAlias) {
 		columns.add( StringHelper.replace( formula, Template.TEMPLATE, tableAlias ) );
 		columnAliases.add(formulaAlias);
 		return this;
 	}
 
 	public SelectFragment addColumnTemplate(String tableAlias, String columnTemplate, String columnAlias) {
 		// In this context, there's no difference between a column template and a formula.
 		return addFormula( tableAlias, columnTemplate, columnAlias );
 	}
 
 	public SelectFragment addColumnTemplates(String tableAlias, String[] columnTemplates, String[] columnAliases) {
 		// In this context, there's no difference between a column template and a formula.
 		return addFormulas( tableAlias, columnTemplates, columnAliases );
 	}
 
 	public String toFragmentString() {
 		StringBuilder buf = new StringBuilder( columns.size() * 10 );
 		Iterator iter = columns.iterator();
 		Iterator columnAliasIter = columnAliases.iterator();
 		//HashMap columnsUnique = new HashMap();
 		HashSet columnsUnique = new HashSet();
-		if (usedAliases!=null) columnsUnique.addAll( Arrays.asList(usedAliases) );
+		if (usedAliases!=null) {
+			columnsUnique.addAll( Arrays.asList(usedAliases) );
+		}
 		while ( iter.hasNext() ) {
 			String column = (String) iter.next();
 			String columnAlias = (String) columnAliasIter.next();
 			//TODO: eventually put this back in, once we think all is fixed
 			//Object otherAlias = columnsUnique.put(qualifiedColumn, columnAlias);
 			/*if ( otherAlias!=null && !columnAlias.equals(otherAlias) ) {
 				throw new AssertionFailure("bug in Hibernate SQL alias generation");
 			}*/
 			if ( columnsUnique.add(columnAlias) ) {
 				buf.append(", ")
 					.append(column)
 					.append(" as ");
 				if (suffix==null) {
 					buf.append(columnAlias);
 				}
 				else {
 					buf.append( new Alias(suffix).toAliasString(columnAlias) );
 				}
 			}
 		}
 		if (extraSelectList!=null) {
 			buf.append(", ")
 				.append(extraSelectList);
 		}
 		return buf.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/SimpleSelect.java b/hibernate-core/src/main/java/org/hibernate/sql/SimpleSelect.java
index 17a4ed4c42..bd81b008d8 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/SimpleSelect.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/SimpleSelect.java
@@ -1,216 +1,224 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.dialect.Dialect;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 /**
  * An SQL <tt>SELECT</tt> statement with no table joins
  *
  * @author Gavin King
  */
 public class SimpleSelect {
 
 	public SimpleSelect(Dialect dialect) {
 		this.dialect = dialect;
 	}
 
 	//private static final Alias DEFAULT_ALIAS = new Alias(10, null);
 
 	private String tableName;
 	private String orderBy;
 	private Dialect dialect;
 	private LockOptions lockOptions = new LockOptions( LockMode.READ);
 	private String comment;
 
 	private List columns = new ArrayList();
 	private Map aliases = new HashMap();
 	private List whereTokens = new ArrayList();
 
 	public SimpleSelect addColumns(String[] columnNames, String[] columnAliases) {
 		for ( int i=0; i<columnNames.length; i++ ) {
 			if ( columnNames[i]!=null  ) {
 				addColumn( columnNames[i], columnAliases[i] );
 			}
 		}
 		return this;
 	}
 
 	public SimpleSelect addColumns(String[] columns, String[] aliases, boolean[] ignore) {
 		for ( int i=0; i<ignore.length; i++ ) {
 			if ( !ignore[i] && columns[i]!=null ) {
 				addColumn( columns[i], aliases[i] );
 			}
 		}
 		return this;
 	}
 
 	public SimpleSelect addColumns(String[] columnNames) {
-		for ( int i=0; i<columnNames.length; i++ ) {
-			if ( columnNames[i]!=null ) addColumn( columnNames[i] );
+		for ( String columnName : columnNames ) {
+			if ( columnName != null ) {
+				addColumn( columnName );
+			}
 		}
 		return this;
 	}
 	public SimpleSelect addColumn(String columnName) {
 		columns.add(columnName);
 		//aliases.put( columnName, DEFAULT_ALIAS.toAliasString(columnName) );
 		return this;
 	}
 
 	public SimpleSelect addColumn(String columnName, String alias) {
 		columns.add(columnName);
 		aliases.put(columnName, alias);
 		return this;
 	}
 
 	public SimpleSelect setTableName(String tableName) {
 		this.tableName = tableName;
 		return this;
 	}
 
 	public SimpleSelect setLockOptions( LockOptions lockOptions ) {
 	   LockOptions.copy(lockOptions, this.lockOptions);
 		return this;
 	}
 
 	public SimpleSelect setLockMode(LockMode lockMode) {
 		this.lockOptions.setLockMode( lockMode );
 		return this;
 	}
 
 	public SimpleSelect addWhereToken(String token) {
 		whereTokens.add(token);
 		return this;
 	}
 	
 	private void and() {
 		if ( whereTokens.size()>0 ) {
 			whereTokens.add("and");
 		}
 	}
 
 	public SimpleSelect addCondition(String lhs, String op, String rhs) {
 		and();
 		whereTokens.add( lhs + ' ' + op + ' ' + rhs );
 		return this;
 	}
 
 	public SimpleSelect addCondition(String lhs, String condition) {
 		and();
 		whereTokens.add( lhs + ' ' + condition );
 		return this;
 	}
 
 	public SimpleSelect addCondition(String[] lhs, String op, String[] rhs) {
 		for ( int i=0; i<lhs.length; i++ ) {
 			addCondition( lhs[i], op, rhs[i] );
 		}
 		return this;
 	}
 
 	public SimpleSelect addCondition(String[] lhs, String condition) {
-		for ( int i=0; i<lhs.length; i++ ) {
-			if ( lhs[i]!=null ) addCondition( lhs[i], condition );
+		for ( String lh : lhs ) {
+			if ( lh != null ) {
+				addCondition( lh, condition );
+			}
 		}
 		return this;
 	}
 
 	public String toStatementString() {
 		StringBuilder buf = new StringBuilder( 
 				columns.size()*10 + 
 				tableName.length() + 
 				whereTokens.size() * 10 + 
 				10 
-			);
+		);
 		
 		if ( comment!=null ) {
 			buf.append("/* ").append(comment).append(" */ ");
 		}
 		
 		buf.append("select ");
 		Set uniqueColumns = new HashSet();
 		Iterator iter = columns.iterator();
 		boolean appendComma = false;
 		while ( iter.hasNext() ) {
 			String col = (String) iter.next();
 			String alias = (String) aliases.get(col);
 			if ( uniqueColumns.add(alias==null ? col : alias) ) {
 				if (appendComma) buf.append(", ");
 				buf.append(col);
 				if ( alias!=null && !alias.equals(col) ) {
 					buf.append(" as ")
 						.append(alias);
 				}
 				appendComma = true;
 			}
 		}
 		
 		buf.append(" from ")
 			.append( dialect.appendLockHint(lockOptions, tableName) );
 		
 		if ( whereTokens.size() > 0 ) {
 			buf.append(" where ")
 				.append( toWhereClause() );
 		}
 		
-		if (orderBy!=null) buf.append(orderBy);
+		if (orderBy!=null) {
+			buf.append(orderBy);
+		}
 		
 		if (lockOptions!=null) {
 			buf.append( dialect.getForUpdateString(lockOptions) );
 		}
 
 		return dialect.transformSelectString( buf.toString() );
 	}
 
 	public String toWhereClause() {
 		StringBuilder buf = new StringBuilder( whereTokens.size() * 5 );
 		Iterator iter = whereTokens.iterator();
 		while ( iter.hasNext() ) {
 			buf.append( iter.next() );
-			if ( iter.hasNext() ) buf.append(' ');
+			if ( iter.hasNext() ) {
+				buf.append(' ');
+			}
 		}
 		return buf.toString();
 	}
 
 	public SimpleSelect setOrderBy(String orderBy) {
 		this.orderBy = orderBy;
 		return this;
 	}
 
 	public SimpleSelect setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/Update.java b/hibernate-core/src/main/java/org/hibernate/sql/Update.java
index d49eb5e690..06ca347b48 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/Update.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/Update.java
@@ -1,241 +1,245 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.Map;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.type.LiteralType;
 
 /**
  * An SQL <tt>UPDATE</tt> statement
  *
  * @author Gavin King
  */
 public class Update {
 
 	private String tableName;
 	private String versionColumnName;
 	private String where;
 	private String assignments;
 	private String comment;
 
 	private Map primaryKeyColumns = new LinkedHashMap();
 	private Map columns = new LinkedHashMap();
 	private Map whereColumns = new LinkedHashMap();
 	
 	private Dialect dialect;
 	
 	public Update(Dialect dialect) {
 		this.dialect = dialect;
 	}
 
 	public String getTableName() {
 		return tableName;
 	}
 
 	public Update appendAssignmentFragment(String fragment) {
 		if ( assignments == null ) {
 			assignments = fragment;
 		}
 		else {
 			assignments += ", " + fragment;
 		}
 		return this;
 	}
 
 	public Update setTableName(String tableName) {
 		this.tableName = tableName;
 		return this;
 	}
 
 	public Update setPrimaryKeyColumnNames(String[] columnNames) {
 		this.primaryKeyColumns.clear();
 		addPrimaryKeyColumns(columnNames);
 		return this;
 	}	
 	
 	public Update addPrimaryKeyColumns(String[] columnNames) {
-		for ( int i=0; i<columnNames.length; i++ ) {
-			addPrimaryKeyColumn( columnNames[i], "?" );
+		for ( String columnName : columnNames ) {
+			addPrimaryKeyColumn( columnName, "?" );
 		}
 		return this;
 	}
 	
 	public Update addPrimaryKeyColumns(String[] columnNames, boolean[] includeColumns, String[] valueExpressions) {
 		for ( int i=0; i<columnNames.length; i++ ) {
-			if( includeColumns[i] ) addPrimaryKeyColumn( columnNames[i], valueExpressions[i] );
+			if( includeColumns[i] ) {
+				addPrimaryKeyColumn( columnNames[i], valueExpressions[i] );
+			}
 		}
 		return this;
 	}
 	
 	public Update addPrimaryKeyColumns(String[] columnNames, String[] valueExpressions) {
 		for ( int i=0; i<columnNames.length; i++ ) {
 			addPrimaryKeyColumn( columnNames[i], valueExpressions[i] );
 		}
 		return this;
 	}	
 
 	public Update addPrimaryKeyColumn(String columnName, String valueExpression) {
 		this.primaryKeyColumns.put(columnName, valueExpression);
 		return this;
 	}
 	
 	public Update setVersionColumnName(String versionColumnName) {
 		this.versionColumnName = versionColumnName;
 		return this;
 	}
 
 
 	public Update setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
 	
 	public Update addColumns(String[] columnNames) {
-		for ( int i=0; i<columnNames.length; i++ ) {
-			addColumn( columnNames[i] );
+		for ( String columnName : columnNames ) {
+			addColumn( columnName );
 		}
 		return this;
 	}
 
 	public Update addColumns(String[] columnNames, boolean[] updateable, String[] valueExpressions) {
 		for ( int i=0; i<columnNames.length; i++ ) {
-			if ( updateable[i] ) addColumn( columnNames[i], valueExpressions[i] );
+			if ( updateable[i] ) {
+				addColumn( columnNames[i], valueExpressions[i] );
+			}
 		}
 		return this;
 	}
 
 	public Update addColumns(String[] columnNames, String valueExpression) {
-		for ( int i=0; i<columnNames.length; i++ ) {
-			addColumn( columnNames[i], valueExpression );
+		for ( String columnName : columnNames ) {
+			addColumn( columnName, valueExpression );
 		}
 		return this;
 	}
 
 	public Update addColumn(String columnName) {
 		return addColumn(columnName, "?");
 	}
 
 	public Update addColumn(String columnName, String valueExpression) {
 		columns.put(columnName, valueExpression);
 		return this;
 	}
 
 	public Update addColumn(String columnName, Object value, LiteralType type) throws Exception {
 		return addColumn( columnName, type.objectToSQLString(value, dialect) );
 	}
 
 	public Update addWhereColumns(String[] columnNames) {
-		for ( int i=0; i<columnNames.length; i++ ) {
-			addWhereColumn( columnNames[i] );
+		for ( String columnName : columnNames ) {
+			addWhereColumn( columnName );
 		}
 		return this;
 	}
 
 	public Update addWhereColumns(String[] columnNames, String valueExpression) {
-		for ( int i=0; i<columnNames.length; i++ ) {
-			addWhereColumn( columnNames[i], valueExpression );
+		for ( String columnName : columnNames ) {
+			addWhereColumn( columnName, valueExpression );
 		}
 		return this;
 	}
 
 	public Update addWhereColumn(String columnName) {
 		return addWhereColumn(columnName, "=?");
 	}
 
 	public Update addWhereColumn(String columnName, String valueExpression) {
 		whereColumns.put(columnName, valueExpression);
 		return this;
 	}
 
 	public Update setWhere(String where) {
 		this.where=where;
 		return this;
 	}
 
 	public String toStatementString() {
 		StringBuilder buf = new StringBuilder( (columns.size() * 15) + tableName.length() + 10 );
 		if ( comment!=null ) {
 			buf.append( "/* " ).append( comment ).append( " */ " );
 		}
 		buf.append( "update " ).append( tableName ).append( " set " );
 		boolean assignmentsAppended = false;
 		Iterator iter = columns.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry e = (Map.Entry) iter.next();
 			buf.append( e.getKey() ).append( '=' ).append( e.getValue() );
 			if ( iter.hasNext() ) {
 				buf.append( ", " );
 			}
 			assignmentsAppended = true;
 		}
 		if ( assignments != null ) {
 			if ( assignmentsAppended ) {
 				buf.append( ", " );
 			}
 			buf.append( assignments );
 		}
 
 		boolean conditionsAppended = false;
 		if ( !primaryKeyColumns.isEmpty() || where != null || !whereColumns.isEmpty() || versionColumnName != null ) {
 			buf.append( " where " );
 		}
 		iter = primaryKeyColumns.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry e = (Map.Entry) iter.next();
 			buf.append( e.getKey() ).append( '=' ).append( e.getValue() );
 			if ( iter.hasNext() ) {
 				buf.append( " and " );
 			}
 			conditionsAppended = true;
 		}
 		if ( where != null ) {
 			if ( conditionsAppended ) {
 				buf.append( " and " );
 			}
 			buf.append( where );
 			conditionsAppended = true;
 		}
 		iter = whereColumns.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			final Map.Entry e = (Map.Entry) iter.next();
 			if ( conditionsAppended ) {
 				buf.append( " and " );
 			}
 			buf.append( e.getKey() ).append( e.getValue() );
 			conditionsAppended = true;
 		}
 		if ( versionColumnName != null ) {
 			if ( conditionsAppended ) {
 				buf.append( " and " );
 			}
 			buf.append( versionColumnName ).append( "=?" );
 		}
 
 		return buf.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentQueryStatisticsImpl.java b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentQueryStatisticsImpl.java
index 1e43188724..204cee0f64 100644
--- a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentQueryStatisticsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentQueryStatisticsImpl.java
@@ -1,179 +1,179 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.stat.internal;
 
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReadWriteLock;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
 import org.hibernate.stat.QueryStatistics;
 
 /**
  * Query statistics (HQL and SQL)
  * <p/>
  * Note that for a cached query, the cache miss is equals to the db count
  *
  * @author Alex Snaps
  */
 public class ConcurrentQueryStatisticsImpl extends CategorizedStatistics implements QueryStatistics {
 	private final AtomicLong cacheHitCount = new AtomicLong();
 	private final AtomicLong cacheMissCount = new AtomicLong();
 	private final AtomicLong cachePutCount = new AtomicLong();
 	private final AtomicLong executionCount = new AtomicLong();
 	private final AtomicLong executionRowCount = new AtomicLong();
 	private final AtomicLong executionMaxTime = new AtomicLong();
 	private final AtomicLong executionMinTime = new AtomicLong(Long.MAX_VALUE);
 	private final AtomicLong totalExecutionTime = new AtomicLong();
 
 	private final Lock readLock;
 	private final Lock writeLock;
 
 	{
 		ReadWriteLock lock = new ReentrantReadWriteLock();
 		readLock = lock.readLock();
 		writeLock = lock.writeLock();
 	}
 
 	ConcurrentQueryStatisticsImpl(String query) {
 		super(query);
 	}
 
 	/**
 	 * queries executed to the DB
 	 */
 	public long getExecutionCount() {
 		return executionCount.get();
 	}
 
 	/**
 	 * Queries retrieved successfully from the cache
 	 */
 	public long getCacheHitCount() {
 		return cacheHitCount.get();
 	}
 
 	public long getCachePutCount() {
 		return cachePutCount.get();
 	}
 
 	public long getCacheMissCount() {
 		return cacheMissCount.get();
 	}
 
 	/**
 	 * Number of lines returned by all the executions of this query (from DB)
 	 * For now, {@link org.hibernate.Query#iterate()}
 	 * and {@link org.hibernate.Query#scroll()()} do not fill this statistic
 	 *
 	 * @return The number of rows cumulatively returned by the given query; iterate
 	 *         and scroll queries do not effect this total as their number of returned rows
 	 *         is not known at execution time.
 	 */
 	public long getExecutionRowCount() {
 		return executionRowCount.get();
 	}
 
 	/**
 	 * average time in ms taken by the excution of this query onto the DB
 	 */
 	public long getExecutionAvgTime() {
 		// We write lock here to be sure that we always calculate the average time
 		// with all updates from the executed applied: executionCount and totalExecutionTime
 		// both used in the calculation
 		writeLock.lock();
 		try {
 			long avgExecutionTime = 0;
 			if (executionCount.get() > 0) {
 				avgExecutionTime = totalExecutionTime.get() / executionCount.get();
 			}
 			return avgExecutionTime;
-		} finally {
+		}
+		finally {
 			writeLock.unlock();
 		}
 	}
 
 	/**
 	 * max time in ms taken by the excution of this query onto the DB
 	 */
 	public long getExecutionMaxTime() {
 		return executionMaxTime.get();
 	}
 
 	/**
 	 * min time in ms taken by the excution of this query onto the DB
 	 */
 	public long getExecutionMinTime() {
 		return executionMinTime.get();
 	}
 
 	/**
 	 * add statistics report of a DB query
 	 *
 	 * @param rows rows count returned
 	 * @param time time taken
 	 */
 	void executed(long rows, long time) {
 		// read lock is enough, concurrent updates are supported by the underlying type AtomicLong
 		// this only guards executed(long, long) to be called, when another thread is executing getExecutionAvgTime()
 		readLock.lock();
 		try {
 			// Less chances for a context switch
-			for (long old = executionMinTime.get(); (time < old) && !executionMinTime.compareAndSet(old, time); old = executionMinTime.get());
-			for (long old = executionMaxTime.get(); (time > old) && !executionMaxTime.compareAndSet(old, time); old = executionMaxTime.get());
+			for (long old = executionMinTime.get(); (time < old) && !executionMinTime.compareAndSet(old, time); old = executionMinTime.get()) {}
+			for (long old = executionMaxTime.get(); (time > old) && !executionMaxTime.compareAndSet(old, time); old = executionMaxTime.get()) {}
 			executionCount.getAndIncrement();
 			executionRowCount.addAndGet(rows);
 			totalExecutionTime.addAndGet(time);
-		} finally {
+		}
+		finally {
 			readLock.unlock();
 		}
 	}
 
 	public String toString() {
-		return new StringBuilder()
-				.append("QueryStatistics")
-				.append("[cacheHitCount=").append(this.cacheHitCount)
-				.append(",cacheMissCount=").append(this.cacheMissCount)
-				.append(",cachePutCount=").append(this.cachePutCount)
-				.append(",executionCount=").append(this.executionCount)
-				.append(",executionRowCount=").append(this.executionRowCount)
-				.append(",executionAvgTime=").append(this.getExecutionAvgTime())
-				.append(",executionMaxTime=").append(this.executionMaxTime)
-				.append(",executionMinTime=").append(this.executionMinTime)
-				.append(']')
-				.toString();
+		return "QueryStatistics"
+				+ "[cacheHitCount=" + this.cacheHitCount
+				+ ",cacheMissCount=" + this.cacheMissCount
+				+ ",cachePutCount=" + this.cachePutCount
+				+ ",executionCount=" + this.executionCount
+				+ ",executionRowCount=" + this.executionRowCount
+				+ ",executionAvgTime=" + this.getExecutionAvgTime()
+				+ ",executionMaxTime=" + this.executionMaxTime
+				+ ",executionMinTime=" + this.executionMinTime
+				+ ']';
 	}
 
 	void incrementCacheHitCount() {
 		cacheHitCount.getAndIncrement();
 	}
 
 	void incrementCacheMissCount() {
 		cacheMissCount.getAndIncrement();
 	}
 
 	void incrementCachePutCount() {
 		cachePutCount.getAndIncrement();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/enhance/EnhancementTask.java b/hibernate-core/src/main/java/org/hibernate/tool/enhance/EnhancementTask.java
index 028021e833..4235f7623e 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/enhance/EnhancementTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/enhance/EnhancementTask.java
@@ -1,232 +1,238 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.enhance;
 
 import javassist.ClassPool;
 import javassist.CtClass;
 import javassist.CtField;
+
 import org.apache.tools.ant.BuildException;
 import org.apache.tools.ant.DirectoryScanner;
 import org.apache.tools.ant.Project;
 import org.apache.tools.ant.Task;
 import org.apache.tools.ant.types.FileSet;
+
 import org.hibernate.bytecode.enhance.spi.EnhancementContext;
 import org.hibernate.bytecode.enhance.spi.Enhancer;
 
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.Entity;
 import javax.persistence.ManyToMany;
 import javax.persistence.OneToMany;
 import javax.persistence.Transient;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 
 /**
  * Ant task for performing build-time enhancement of entities and component/embeddable classes.
  * <p/>
  * IMPL NOTE : currently makes numerous assumptions, the most "horrific" being that all entities are
  * annotated @Entity which precludes {@code hbm.xml} mappings as well as complete {@code orm.xml} mappings.  This is
  * just a PoC though...
  *
  * @author Steve Ebersole
- *
  * @see org.hibernate.engine.spi.Managed
  */
 public class EnhancementTask extends Task implements EnhancementContext {
 	private List<FileSet> filesets = new ArrayList<FileSet>();
 
 	// Enhancer also builds CtClass instances.  Might make sense to share these (ClassPool).
 	private final ClassPool classPool = new ClassPool( false );
 	private final Enhancer enhancer = new Enhancer( this );
 
 	public void addFileset(FileSet set) {
 		this.filesets.add( set );
 	}
 
 	@Override
 	public void execute() throws BuildException {
-		log("Starting Hibernate EnhancementTask execution", Project.MSG_INFO);
+		log( "Starting Hibernate EnhancementTask execution", Project.MSG_INFO );
 
 		// we use the CtClass stuff here just as a simple vehicle for obtaining low level information about
 		// the class(es) contained in a file while still maintaining easy access to the underlying byte[]
 		final Project project = getProject();
 
 		for ( FileSet fileSet : filesets ) {
 			final File fileSetBaseDir = fileSet.getDir( project );
 			final DirectoryScanner directoryScanner = fileSet.getDirectoryScanner( project );
 			for ( String relativeIncludedFileName : directoryScanner.getIncludedFiles() ) {
 				final File javaClassFile = new File( fileSetBaseDir, relativeIncludedFileName );
-				if ( ! javaClassFile.exists() ) {
+				if ( !javaClassFile.exists() ) {
 					continue;
 				}
 
-				processClassFile( javaClassFile);
+				processClassFile( javaClassFile );
 			}
 		}
 
 	}
 
-    /**
-     * Atm only process files annotated with either @Entity or @Embeddable
-     * @param javaClassFile
-     */
-    private void processClassFile(File javaClassFile) {
+	/**
+	 * Atm only process files annotated with either @Entity or @Embeddable
+	 *
+	 * @param javaClassFile
+	 */
+	private void processClassFile(File javaClassFile) {
 		try {
 			final CtClass ctClass = classPool.makeClass( new FileInputStream( javaClassFile ) );
-            if(this.isEntityClass(ctClass))
-                processEntityClassFile(javaClassFile, ctClass);
-            else if(this.isCompositeClass(ctClass))
-                processCompositeClassFile(javaClassFile, ctClass);
-
-        }
-        catch (IOException e) {
-            throw new BuildException(
-                    String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e );
-        }
-    }
-
-    private void processEntityClassFile(File javaClassFile, CtClass ctClass ) {
-        try {
-            byte[] result = enhancer.enhance(ctClass.getName(), ctClass.toBytecode());
-            if(result != null)
-                writeEnhancedClass(javaClassFile, result);
-        }
-        catch (Exception e) {
-            log( "Unable to enhance class [" + ctClass.getName() + "]", e, Project.MSG_WARN );
-            return;
-        }
-    }
-
-    private void processCompositeClassFile(File javaClassFile, CtClass ctClass) {
-        try {
-            byte[] result = enhancer.enhanceComposite(ctClass.getName(), ctClass.toBytecode());
-            if(result != null)
-                writeEnhancedClass(javaClassFile, result);
-        }
-        catch (Exception e) {
-            log( "Unable to enhance class [" + ctClass.getName() + "]", e, Project.MSG_WARN );
-            return;
-        }
-    }
-
-    private void writeEnhancedClass(File javaClassFile, byte[] result) {
-        try {
+			if ( this.isEntityClass( ctClass ) ) {
+				processEntityClassFile( javaClassFile, ctClass );
+			}
+			else if ( this.isCompositeClass( ctClass ) ) {
+				processCompositeClassFile( javaClassFile, ctClass );
+			}
+
+		}
+		catch (IOException e) {
+			throw new BuildException(
+					String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e
+			);
+		}
+	}
+
+	private void processEntityClassFile(File javaClassFile, CtClass ctClass) {
+		try {
+			byte[] result = enhancer.enhance( ctClass.getName(), ctClass.toBytecode() );
+			if ( result != null ) {
+				writeEnhancedClass( javaClassFile, result );
+			}
+		}
+		catch (Exception e) {
+			log( "Unable to enhance class [" + ctClass.getName() + "]", e, Project.MSG_WARN );
+		}
+	}
+
+	private void processCompositeClassFile(File javaClassFile, CtClass ctClass) {
+		try {
+			byte[] result = enhancer.enhanceComposite( ctClass.getName(), ctClass.toBytecode() );
+			if ( result != null ) {
+				writeEnhancedClass( javaClassFile, result );
+			}
+		}
+		catch (Exception e) {
+			log( "Unable to enhance class [" + ctClass.getName() + "]", e, Project.MSG_WARN );
+		}
+	}
+
+	private void writeEnhancedClass(File javaClassFile, byte[] result) {
+		try {
 			if ( javaClassFile.delete() ) {
-                    if ( ! javaClassFile.createNewFile() ) {
-                        log( "Unable to recreate class file [" + javaClassFile.getName() + "]", Project.MSG_INFO );
-                    }
-            }
+				if ( !javaClassFile.createNewFile() ) {
+					log( "Unable to recreate class file [" + javaClassFile.getName() + "]", Project.MSG_INFO );
+				}
+			}
 			else {
 				log( "Unable to delete class file [" + javaClassFile.getName() + "]", Project.MSG_INFO );
 			}
 
 			FileOutputStream outputStream = new FileOutputStream( javaClassFile, false );
 			try {
-				outputStream.write( result);
+				outputStream.write( result );
 				outputStream.flush();
 			}
 			finally {
 				try {
 					outputStream.close();
 				}
-				catch ( IOException ignore) {
+				catch (IOException ignore) {
 				}
 			}
-        }
-        catch (FileNotFoundException ignore) {
-            // should not ever happen because of explicit checks
-        }
-        catch (IOException e) {
-            throw new BuildException(
-                    String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e );
-        }
-    }
+		}
+		catch (FileNotFoundException ignore) {
+			// should not ever happen because of explicit checks
+		}
+		catch (IOException e) {
+			throw new BuildException(
+					String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e
+			);
+		}
+	}
 
 	// EnhancementContext impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	@Override
 	public ClassLoader getLoadingClassLoader() {
 		return getClass().getClassLoader();
 	}
 
 	@Override
 	public boolean isEntityClass(CtClass classDescriptor) {
-        return classDescriptor.hasAnnotation(Entity.class);
-    }
+		return classDescriptor.hasAnnotation( Entity.class );
+	}
 
 	@Override
 	public boolean isCompositeClass(CtClass classDescriptor) {
-        return classDescriptor.hasAnnotation(Embeddable.class);
+		return classDescriptor.hasAnnotation( Embeddable.class );
 	}
 
 	@Override
 	public boolean doBiDirectionalAssociationManagement(CtField field) {
 		return false;
 	}
 
 	@Override
 	public boolean doDirtyCheckingInline(CtClass classDescriptor) {
 		return true;
 	}
 
 	@Override
 	public boolean hasLazyLoadableAttributes(CtClass classDescriptor) {
 		return true;
 	}
 
 	@Override
 	public boolean isLazyLoadable(CtField field) {
 		return true;
 	}
 
 	@Override
 	public boolean isPersistentField(CtField ctField) {
 		// current check is to look for @Transient
-		return ! ctField.hasAnnotation( Transient.class );
-	}
-
-    @Override
-    public boolean isMappedCollection(CtField field) {
-        try {
-            return (field.getAnnotation(OneToMany.class) != null ||
-                    field.getAnnotation(ManyToMany.class) != null ||
-                    field.getAnnotation(ElementCollection.class) != null);
-        }
-        catch (ClassNotFoundException e) {
-            return false;
-        }
-    }
+		return !ctField.hasAnnotation( Transient.class );
+	}
+
+	@Override
+	public boolean isMappedCollection(CtField field) {
+		try {
+			return ( field.getAnnotation( OneToMany.class ) != null ||
+					field.getAnnotation( ManyToMany.class ) != null ||
+					field.getAnnotation( ElementCollection.class ) != null );
+		}
+		catch (ClassNotFoundException e) {
+			return false;
+		}
+	}
 
 	@Override
 	public CtField[] order(CtField[] persistentFields) {
 		// for now...
 		return persistentFields;
 		// eventually needs to consult the Hibernate metamodel for proper ordering
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/IndexMetadata.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/IndexMetadata.java
index f7a34bd99a..4fdb20bf65 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/IndexMetadata.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/IndexMetadata.java
@@ -1,64 +1,66 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.List;
 
 /**
  * JDBC index metadata
  * @author Christoph Sturm
  */
 public class IndexMetadata {
 	private final String name;
 	private final List columns = new ArrayList();
 
 	IndexMetadata(ResultSet rs) throws SQLException {
 		name = rs.getString("INDEX_NAME");
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	void addColumn(ColumnMetadata column) {
-		if (column != null) columns.add(column);
+		if (column != null) {
+			columns.add(column);
+		}
 	}
 
 	public ColumnMetadata[] getColumns() {
 		return (ColumnMetadata[]) columns.toArray(new ColumnMetadata[0]);
 	}
 
 	public String toString() {
 		return "IndexMatadata(" + name + ')';
 	}
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/AbstractAttribute.java b/hibernate-core/src/main/java/org/hibernate/tuple/AbstractAttribute.java
index 4818c33c22..17234663ae 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/AbstractAttribute.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/AbstractAttribute.java
@@ -1,55 +1,54 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 import org.hibernate.type.Type;
 
 /**
  * @author Steve Ebersole
  */
 public abstract class AbstractAttribute implements Attribute, Property {
 	private final String attributeName;
 	private final Type attributeType;
 
 	protected AbstractAttribute(String attributeName, Type attributeType) {
 		this.attributeName = attributeName;
 		this.attributeType = attributeType;
 	}
 
 	@Override
-	@Deprecated
 	public String getNode() {
 		return null;
 	}
 
 	@Override
 	public String getName() {
 		return attributeName;
 	}
 
 	@Override
 	public Type getType() {
 		return attributeType;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/ElementWrapper.java b/hibernate-core/src/main/java/org/hibernate/tuple/ElementWrapper.java
index 0b23b28598..258e1755c8 100755
--- a/hibernate-core/src/main/java/org/hibernate/tuple/ElementWrapper.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/ElementWrapper.java
@@ -1,597 +1,591 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tuple;
 import java.io.IOException;
 import java.io.Serializable;
 import java.io.Writer;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.dom4j.Attribute;
 import org.dom4j.Branch;
 import org.dom4j.CDATA;
 import org.dom4j.Comment;
 import org.dom4j.Document;
 import org.dom4j.Element;
 import org.dom4j.Entity;
 import org.dom4j.InvalidXPathException;
 import org.dom4j.Namespace;
 import org.dom4j.Node;
 import org.dom4j.ProcessingInstruction;
 import org.dom4j.QName;
 import org.dom4j.Text;
 import org.dom4j.Visitor;
 import org.dom4j.XPath;
 
 /**
  * Wraps dom4j elements, allowing them to exist in a 
  * non-hierarchical structure.
  *
  * @author Gavin King
  */
 public class ElementWrapper implements Element, Serializable {
 
 	private Element element;
 	private Element parent;
 	
 	public Element getElement() {
 		return element;
 	}
 
 	public ElementWrapper(Element element) {
 		this.element = element;
 	}
 
 	public QName getQName() {
 		return element.getQName();
 	}
 
 	public QName getQName(String s) {
 		return element.getQName( s );
 	}
 
 	public void setQName(QName qName) {
 		element.setQName( qName );
 	}
 
 	public Namespace getNamespace() {
 		return element.getNamespace();
 	}
 
 	public Namespace getNamespaceForPrefix(String s) {
 		return element.getNamespaceForPrefix( s );
 	}
 
 	public Namespace getNamespaceForURI(String s) {
 		return element.getNamespaceForURI( s );
 	}
 
 	public List getNamespacesForURI(String s) {
 		return element.getNamespacesForURI( s );
 	}
 
 	public String getNamespacePrefix() {
 		return element.getNamespacePrefix();
 	}
 
 	public String getNamespaceURI() {
 		return element.getNamespaceURI();
 	}
 
 	public String getQualifiedName() {
 		return element.getQualifiedName();
 	}
 
 	public List additionalNamespaces() {
 		return element.additionalNamespaces();
 	}
 
 	public List declaredNamespaces() {
 		return element.declaredNamespaces();
 	}
 
 	public Element addAttribute(String attrName, String text) {
 		return element.addAttribute( attrName, text );
 	}
 
 	public Element addAttribute(QName attrName, String text) {
 		return element.addAttribute( attrName, text );
 	}
 
 	public Element addComment(String text) {
 		return element.addComment( text );
 	}
 
 	public Element addCDATA(String text) {
 		return element.addCDATA( text );
 	}
 
 	public Element addEntity(String name, String text) {
 		return element.addEntity( name, text );
 	}
 
 	public Element addNamespace(String prefix, String uri) {
 		return element.addNamespace( prefix, uri );
 	}
 
 	public Element addProcessingInstruction(String target, String text) {
 		return element.addProcessingInstruction( target, text );
 	}
 
 	public Element addProcessingInstruction(String target, Map data) {
 		return element.addProcessingInstruction( target, data );
 	}
 
 	public Element addText(String text) {
 		return element.addText( text );
 	}
 
 	public void add(Attribute attribute) {
 		element.add( attribute );
 	}
 
 	public void add(CDATA cdata) {
 		element.add( cdata );
 	}
 
 	public void add(Entity entity) {
 		element.add( entity );
 	}
 
 	public void add(Text text) {
 		element.add( text );
 	}
 
 	public void add(Namespace namespace) {
 		element.add( namespace );
 	}
 
 	public boolean remove(Attribute attribute) {
 		return element.remove( attribute );
 	}
 
 	public boolean remove(CDATA cdata) {
 		return element.remove( cdata );
 	}
 
 	public boolean remove(Entity entity) {
 		return element.remove( entity );
 	}
 
 	public boolean remove(Namespace namespace) {
 		return element.remove( namespace );
 	}
 
 	public boolean remove(Text text) {
 		return element.remove( text );
 	}
 
 	public boolean supportsParent() {
 		return element.supportsParent();
 	}
 
 	public Element getParent() {
 		return parent==null ? element.getParent() : parent;
 	}
 
 	public void setParent(Element parent) {
 		element.setParent( parent );
 		this.parent = parent;
 	}
 
 	public Document getDocument() {
 		return element.getDocument();
 	}
 
 	public void setDocument(Document document) {
 		element.setDocument( document );
 	}
 
 	public boolean isReadOnly() {
 		return element.isReadOnly();
 	}
 
 	public boolean hasContent() {
 		return element.hasContent();
 	}
 
 	public String getName() {
 		return element.getName();
 	}
 
 	public void setName(String name) {
 		element.setName( name );
 	}
 
 	public String getText() {
 		return element.getText();
 	}
 
 	public void setText(String text) {
 		element.setText( text );
 	}
 
 	public String getTextTrim() {
 		return element.getTextTrim();
 	}
 
 	public String getStringValue() {
 		return element.getStringValue();
 	}
 
 	public String getPath() {
 		return element.getPath();
 	}
 
 	public String getPath(Element element) {
 		return element.getPath( element );
 	}
 
 	public String getUniquePath() {
 		return element.getUniquePath();
 	}
 
 	public String getUniquePath(Element element) {
 		return element.getUniquePath( element );
 	}
 
 	public String asXML() {
 		return element.asXML();
 	}
 
 	public void write(Writer writer) throws IOException {
 		element.write( writer );
 	}
 
 	public short getNodeType() {
 		return element.getNodeType();
 	}
 
 	public String getNodeTypeName() {
 		return element.getNodeTypeName();
 	}
 
 	public Node detach() {
 		if (parent!=null) {
 			parent.remove(this);
 			parent = null;
 		}
 		return element.detach();
 	}
 
 	public List selectNodes(String xpath) {
 		return element.selectNodes( xpath );
 	}
 
 	public Object selectObject(String xpath) {
 		return element.selectObject( xpath );
 	}
 
 	public List selectNodes(String xpath, String comparison) {
 		return element.selectNodes( xpath, comparison );
 	}
 
 	public List selectNodes(String xpath, String comparison, boolean removeDups) {
 		return element.selectNodes( xpath, comparison, removeDups );
 	}
 
 	public Node selectSingleNode(String xpath) {
         return element.selectSingleNode( xpath );
 	}
 
 	public String valueOf(String xpath) {
 		return element.valueOf( xpath );
 	}
 
 	public Number numberValueOf(String xpath) {
 		return element.numberValueOf( xpath );
 	}
 
 	public boolean matches(String xpath) {
 		return element.matches( xpath );
 	}
 
 	public XPath createXPath(String xpath) throws InvalidXPathException {
 		return element.createXPath( xpath );
 	}
 
 	public Node asXPathResult(Element element) {
 		return element.asXPathResult( element );
 	}
 
 	public void accept(Visitor visitor) {
 		element.accept( visitor );
 	}
 
 	public Object clone() {
 		return element.clone();
 	}
 
 	public Object getData() {
 		return element.getData();
 	}
 
 	public void setData(Object data) {
 		element.setData( data );
 	}
 
 	public List attributes() {
 		return element.attributes();
 	}
 
 	public void setAttributes(List list) {
 		element.setAttributes( list );
 	}
 
 	public int attributeCount() {
 		return element.attributeCount();
 	}
 
 	public Iterator attributeIterator() {
 		return element.attributeIterator();
 	}
 
 	public Attribute attribute(int i) {
 		return element.attribute( i );
 	}
 
 	public Attribute attribute(String name) {
 		return element.attribute( name );
 	}
 
 	public Attribute attribute(QName qName) {
 		return element.attribute( qName );
 	}
 
 	public String attributeValue(String name) {
 		return element.attributeValue( name );
 	}
 
 	public String attributeValue(String name, String defaultValue) {
 		return element.attributeValue( name, defaultValue );
 	}
 
 	public String attributeValue(QName qName) {
 		return element.attributeValue( qName );
 	}
 
 	public String attributeValue(QName qName, String defaultValue) {
 		return element.attributeValue( qName, defaultValue );
 	}
 
-	/**
-	 * @deprecated
-	 */
 	public void setAttributeValue(String name, String value) {
 		element.setAttributeValue( name, value );
 	}
 
-	/**
-	 * @deprecated
-	 */
 	public void setAttributeValue(QName qName, String value) {
 		element.setAttributeValue( qName, value );
 	}
 
 	public Element element(String name) {
 		return element.element( name );
 	}
 
 	public Element element(QName qName) {
 		return element.element( qName );
 	}
 
 	public List elements() {
 		return element.elements();
 	}
 
 	public List elements(String name) {
 		return element.elements( name );
 	}
 
 	public List elements(QName qName) {
 		return element.elements( qName );
 	}
 
 	public Iterator elementIterator() {
 		return element.elementIterator();
 	}
 
 	public Iterator elementIterator(String name) {
 		return element.elementIterator( name );
 
 	}
 
 	public Iterator elementIterator(QName qName) {
 		return element.elementIterator( qName );
 	}
 
 	public boolean isRootElement() {
 		return element.isRootElement();
 	}
 
 	public boolean hasMixedContent() {
 		return element.hasMixedContent();
 	}
 
 	public boolean isTextOnly() {
 		return element.isTextOnly();
 	}
 
 	public void appendAttributes(Element element) {
 		element.appendAttributes( element );
 	}
 
 	public Element createCopy() {
 		return element.createCopy();
 	}
 
 	public Element createCopy(String name) {
 		return element.createCopy( name );
 	}
 
 	public Element createCopy(QName qName) {
 		return element.createCopy( qName );
 	}
 
 	public String elementText(String name) {
 		return element.elementText( name );
 	}
 
 	public String elementText(QName qName) {
 		return element.elementText( qName );
 	}
 
 	public String elementTextTrim(String name) {
 		return element.elementTextTrim( name );
 	}
 
 	public String elementTextTrim(QName qName) {
 		return element.elementTextTrim( qName );
 	}
 
 	public Node getXPathResult(int i) {
 		return element.getXPathResult( i );
 	}
 
 	public Node node(int i) {
 		return element.node( i );
 	}
 
 	public int indexOf(Node node) {
 		return element.indexOf( node );
 	}
 
 	public int nodeCount() {
 		return element.nodeCount();
 	}
 
 	public Element elementByID(String id) {
 		return element.elementByID( id );
 	}
 
 	public List content() {
 		return element.content();
 	}
 
 	public Iterator nodeIterator() {
 		return element.nodeIterator();
 	}
 
 	public void setContent(List list) {
 		element.setContent( list );
 	}
 
 	public void appendContent(Branch branch) {
 		element.appendContent( branch );
 	}
 
 	public void clearContent() {
 		element.clearContent();
 	}
 
 	public List processingInstructions() {
 		return element.processingInstructions();
 	}
 
 	public List processingInstructions(String name) {
 		return element.processingInstructions( name );
 	}
 
 	public ProcessingInstruction processingInstruction(String name) {
 		return element.processingInstruction( name );
 	}
 
 	public void setProcessingInstructions(List list) {
 		element.setProcessingInstructions( list );
 	}
 
 	public Element addElement(String name) {
 		return element.addElement( name );
 	}
 
 	public Element addElement(QName qName) {
 		return element.addElement( qName );
 	}
 
 	public Element addElement(String name, String text) {
 		return element.addElement( name, text );
 
 	}
 
 	public boolean removeProcessingInstruction(String name) {
 		return element.removeProcessingInstruction( name );
 	}
 
 	public void add(Node node) {
 		element.add( node );
 	}
 
 	public void add(Comment comment) {
 		element.add( comment );
 	}
 
 	public void add(Element element) {
 		element.add( element );
 	}
 
 	public void add(ProcessingInstruction processingInstruction) {
 		element.add( processingInstruction );
 	}
 
 	public boolean remove(Node node) {
 		return element.remove( node );
 	}
 
 	public boolean remove(Comment comment) {
 		return element.remove( comment );
 	}
 
 	public boolean remove(Element element) {
 		return element.remove( element );
 	}
 
 	public boolean remove(ProcessingInstruction processingInstruction) {
 		return element.remove( processingInstruction );
 	}
 
 	public void normalize() {
 		element.normalize();
 	}
 	
 	public boolean equals(Object other) {
 		return element.equals(other);
 	}
 	
 	public int hashCode() {
 		return element.hashCode();
 	}
 	
 	public String toString() {
 		return element.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/Property.java b/hibernate-core/src/main/java/org/hibernate/tuple/Property.java
index 69ea51cd20..3e2732ee7c 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/Property.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/Property.java
@@ -1,35 +1,38 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 /**
  * Defines the basic contract of a Property within the runtime metamodel.
  *
  * @author Steve Ebersole
  */
 @Deprecated
 public interface Property extends Attribute {
+	/**
+	 * @deprecated DOM4j entity mode is no longer supported
+	 */
 	@Deprecated
 	public String getNode();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java b/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
index 52992816dc..95bd6e631e 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
@@ -1,328 +1,331 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 import java.lang.reflect.Constructor;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.internal.UnsavedValueFactory;
 import org.hibernate.engine.spi.IdentifierValue;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.VersionValue;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.property.Getter;
 import org.hibernate.property.PropertyAccessor;
 import org.hibernate.property.PropertyAccessorFactory;
 import org.hibernate.tuple.entity.EntityBasedAssociationAttribute;
 import org.hibernate.tuple.entity.EntityBasedBasicAttribute;
 import org.hibernate.tuple.entity.EntityBasedCompositionAttribute;
 import org.hibernate.tuple.entity.VersionProperty;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * Responsible for generation of runtime metamodel {@link Property} representations.
  * Makes distinction between identifier, version, and other (standard) properties.
  *
  * @author Steve Ebersole
  */
 public final class PropertyFactory {
 	private PropertyFactory() {
 	}
 
 	/**
 	 * Generates the attribute representation of the identifier for a given entity mapping.
 	 *
 	 * @param mappedEntity The mapping definition of the entity.
 	 * @param generator The identifier value generator to use for this identifier.
 	 * @return The appropriate IdentifierProperty definition.
 	 */
 	public static IdentifierProperty buildIdentifierAttribute(
 			PersistentClass mappedEntity,
 			IdentifierGenerator generator) {
 		String mappedUnsavedValue = mappedEntity.getIdentifier().getNullValue();
 		Type type = mappedEntity.getIdentifier().getType();
 		Property property = mappedEntity.getIdentifierProperty();
 		
 		IdentifierValue unsavedValue = UnsavedValueFactory.getUnsavedIdentifierValue(
 				mappedUnsavedValue,
 				getGetter( property ),
 				type,
 				getConstructor(mappedEntity)
 			);
 
 		if ( property == null ) {
 			// this is a virtual id property...
 			return new IdentifierProperty(
 			        type,
 					mappedEntity.hasEmbeddedIdentifier(),
 					mappedEntity.hasIdentifierMapper(),
 					unsavedValue,
 					generator
 				);
 		}
 		else {
 			return new IdentifierProperty(
 					property.getName(),
 					property.getNodeName(),
 					type,
 					mappedEntity.hasEmbeddedIdentifier(),
 					unsavedValue,
 					generator
 				);
 		}
 	}
 
 	/**
 	 * Generates a VersionProperty representation for an entity mapping given its
 	 * version mapping Property.
 	 *
 	 * @param property The version mapping Property.
 	 * @param lazyAvailable Is property lazy loading currently available.
 	 * @return The appropriate VersionProperty definition.
 	 */
 	public static VersionProperty buildVersionProperty(
 			EntityPersister persister,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			Property property,
 			boolean lazyAvailable) {
 		String mappedUnsavedValue = ( (KeyValue) property.getValue() ).getNullValue();
 		
 		VersionValue unsavedValue = UnsavedValueFactory.getUnsavedVersionValue(
 				mappedUnsavedValue,
 				getGetter( property ),
 				(VersionType) property.getType(),
 				getConstructor( property.getPersistentClass() )
 		);
 
 		boolean lazy = lazyAvailable && property.isLazy();
 
 		return new VersionProperty(
 				persister,
 				sessionFactory,
 				attributeNumber,
 		        property.getName(),
 		        property.getValue().getType(),
 				new BaselineAttributeInformation.Builder()
 						.setLazy( lazy )
 						.setInsertable( property.isInsertable() )
 						.setUpdateable( property.isUpdateable() )
 						.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 						.setNullable( property.isOptional() )
 						.setDirtyCheckable( property.isUpdateable() && !lazy )
 						.setVersionable( property.isOptimisticLocked() )
 						.setCascadeStyle( property.getCascadeStyle() )
 						.createInformation(),
 		        unsavedValue
 			);
 	}
 
 	public static enum NonIdentifierAttributeNature {
 		BASIC,
 		COMPOSITE,
 		ANY,
 		ENTITY,
 		COLLECTION
 	}
 
 	/**
 	 * Generate a non-identifier (and non-version) attribute based on the given mapped property from the given entity
 	 *
 	 * @param property The mapped property.
 	 * @param lazyAvailable Is property lazy loading currently available.
 	 * @return The appropriate NonIdentifierProperty definition.
 	 */
 	public static NonIdentifierAttribute buildEntityBasedAttribute(
 			EntityPersister persister,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			Property property,
 			boolean lazyAvailable) {
 		final Type type = property.getValue().getType();
 
 		final NonIdentifierAttributeNature nature = decode( type );
 
 		// we need to dirty check collections, since they can cause an owner
 		// version number increment
 		
 		// we need to dirty check many-to-ones with not-found="ignore" in order 
 		// to update the cache (not the database), since in this case a null
 		// entity reference can lose information
 		
 		boolean alwaysDirtyCheck = type.isAssociationType() && 
 				( (AssociationType) type ).isAlwaysDirtyChecked(); 
 
 		switch ( nature ) {
 			case BASIC: {
 				return new EntityBasedBasicAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			case COMPOSITE: {
 				return new EntityBasedCompositionAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						(CompositeType) type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			case ENTITY:
 			case ANY:
 			case COLLECTION: {
 				return new EntityBasedAssociationAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						(AssociationType) type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			default: {
 				throw new HibernateException( "Internal error" );
 			}
 		}
 	}
 
 	private static NonIdentifierAttributeNature decode(Type type) {
 		if ( type.isAssociationType() ) {
 			AssociationType associationType = (AssociationType) type;
 
 			if ( type.isComponentType() ) {
 				// an any type is both an association and a composite...
 				return NonIdentifierAttributeNature.ANY;
 			}
 
 			return type.isCollectionType()
 					? NonIdentifierAttributeNature.COLLECTION
 					: NonIdentifierAttributeNature.ENTITY;
 		}
 		else {
 			if ( type.isComponentType() ) {
 				return NonIdentifierAttributeNature.COMPOSITE;
 			}
 
 			return NonIdentifierAttributeNature.BASIC;
 		}
 	}
 
+	/**
+	 * @deprecated See mainly {@link #buildEntityBasedAttribute}
+	 */
 	@Deprecated
 	public static StandardProperty buildStandardProperty(Property property, boolean lazyAvailable) {
 		final Type type = property.getValue().getType();
 
 		// we need to dirty check collections, since they can cause an owner
 		// version number increment
 
 		// we need to dirty check many-to-ones with not-found="ignore" in order
 		// to update the cache (not the database), since in this case a null
 		// entity reference can lose information
 
 		boolean alwaysDirtyCheck = type.isAssociationType() &&
 				( (AssociationType) type ).isAlwaysDirtyChecked();
 
 		return new StandardProperty(
 				property.getName(),
 				type,
 				lazyAvailable && property.isLazy(),
 				property.isInsertable(),
 				property.isUpdateable(),
 				property.getValueGenerationStrategy(),
 				property.isOptional(),
 				alwaysDirtyCheck || property.isUpdateable(),
 				property.isOptimisticLocked(),
 				property.getCascadeStyle(),
 				property.getValue().getFetchMode()
 		);
 	}
 
 
 	private static Constructor getConstructor(PersistentClass persistentClass) {
 		if ( persistentClass == null || !persistentClass.hasPojoRepresentation() ) {
 			return null;
 		}
 
 		try {
 			return ReflectHelper.getDefaultConstructor( persistentClass.getMappedClass() );
 		}
 		catch( Throwable t ) {
 			return null;
 		}
 	}
 
 	private static Getter getGetter(Property mappingProperty) {
 		if ( mappingProperty == null || !mappingProperty.getPersistentClass().hasPojoRepresentation() ) {
 			return null;
 		}
 
 		PropertyAccessor pa = PropertyAccessorFactory.getPropertyAccessor( mappingProperty, EntityMode.POJO );
 		return pa.getGetter( mappingProperty.getPersistentClass().getMappedClass(), mappingProperty.getName() );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/StandardProperty.java b/hibernate-core/src/main/java/org/hibernate/tuple/StandardProperty.java
index 39f20bbb75..5648f27d80 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/StandardProperty.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/StandardProperty.java
@@ -1,85 +1,87 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 import org.hibernate.FetchMode;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.type.Type;
 
 /**
  * Represents a non-identifier property within the Hibernate runtime-metamodel.
  *
  * @author Steve Ebersole
+ *
+ * @deprecated Use one of the {@link org.hibernate.tuple.Attribute}-based impls instead.
  */
 @Deprecated
 public class StandardProperty extends AbstractNonIdentifierAttribute implements NonIdentifierAttribute {
 
 	/**
 	 * Constructs NonIdentifierProperty instances.
 	 *
 	 * @param name The name by which the property can be referenced within
 	 * its owner.
 	 * @param type The Hibernate Type of this property.
 	 * @param lazy Should this property be handled lazily?
 	 * @param insertable Is this property an insertable value?
 	 * @param updateable Is this property an updateable value?
 	 * @param valueGenerationStrategy How (if) values for this attribute are generated
 	 * @param nullable Is this property a nullable value?
 	 * @param checkable Is this property a checkable value?
 	 * @param versionable Is this property a versionable value?
 	 * @param cascadeStyle The cascade style for this property's value.
 	 * @param fetchMode Any fetch mode defined for this property
 	 */
 	public StandardProperty(
 			String name,
 			Type type,
 			boolean lazy,
 			boolean insertable,
 			boolean updateable,
 			ValueGeneration valueGenerationStrategy,
 			boolean nullable,
 			boolean checkable,
 			boolean versionable,
 			CascadeStyle cascadeStyle,
 			FetchMode fetchMode) {
 		super(
 				null,
 				null,
 				-1,
 				name,
 				type,
 				new BaselineAttributeInformation.Builder()
 						.setLazy( lazy )
 						.setInsertable( insertable )
 						.setUpdateable( updateable )
 						.setValueGenerationStrategy( valueGenerationStrategy )
 						.setNullable( nullable )
 						.setDirtyCheckable( checkable )
 						.setVersionable( versionable )
 						.setCascadeStyle( cascadeStyle )
 						.setFetchMode( fetchMode )
 						.createInformation()
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
index dc62d1c2ae..3ecdb23b13 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
@@ -1,1115 +1,1119 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.bytecode.spi.EntityInstrumentationMetadata;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.ValueInclusion;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.persister.entity.AbstractEntityPersister;
 import org.hibernate.tuple.GenerationTiming;
 import org.hibernate.tuple.IdentifierProperty;
 import org.hibernate.tuple.InDatabaseValueGenerationStrategy;
 import org.hibernate.tuple.InMemoryValueGenerationStrategy;
 import org.hibernate.tuple.NonIdentifierAttribute;
 import org.hibernate.tuple.PropertyFactory;
 import org.hibernate.tuple.ValueGeneration;
 import org.hibernate.tuple.ValueGenerator;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Centralizes metamodel information about an entity.
  *
  * @author Steve Ebersole
  */
 public class EntityMetamodel implements Serializable {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityMetamodel.class.getName());
 
 	private static final int NO_VERSION_INDX = -66;
 
 	private final SessionFactoryImplementor sessionFactory;
 	private final AbstractEntityPersister persister;
 
 	private final String name;
 	private final String rootName;
 	private final EntityType entityType;
 
 	private final IdentifierProperty identifierAttribute;
 	private final boolean versioned;
 
 	private final int propertySpan;
 	private final int versionPropertyIndex;
 	private final NonIdentifierAttribute[] properties;
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final String[] propertyNames;
 	private final Type[] propertyTypes;
 	private final boolean[] propertyLaziness;
 	private final boolean[] propertyUpdateability;
 	private final boolean[] nonlazyPropertyUpdateability;
 	private final boolean[] propertyCheckability;
 	private final boolean[] propertyInsertability;
 	private final boolean[] propertyNullability;
 	private final boolean[] propertyVersionability;
 	private final CascadeStyle[] cascadeStyles;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	// value generations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final boolean hasPreInsertGeneratedValues;
 	private final boolean hasPreUpdateGeneratedValues;
 	private final boolean hasInsertGeneratedValues;
 	private final boolean hasUpdateGeneratedValues;
 
 	private final InMemoryValueGenerationStrategy[] inMemoryValueGenerationStrategies;
 	private final InDatabaseValueGenerationStrategy[] inDatabaseValueGenerationStrategies;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private final Map<String, Integer> propertyIndexes = new HashMap<String, Integer>();
 	private final boolean hasCollections;
 	private final boolean hasMutableProperties;
 	private final boolean hasLazyProperties;
 	private final boolean hasNonIdentifierPropertyNamedId;
 
 	private final int[] naturalIdPropertyNumbers;
 	private final boolean hasImmutableNaturalId;
 	private final boolean hasCacheableNaturalId;
 
 	private boolean lazy; //not final because proxy factory creation can fail
 	private final boolean hasCascades;
 	private final boolean mutable;
 	private final boolean isAbstract;
 	private final boolean selectBeforeUpdate;
 	private final boolean dynamicUpdate;
 	private final boolean dynamicInsert;
 	private final OptimisticLockStyle optimisticLockStyle;
 
 	private final boolean polymorphic;
 	private final String superclass;  // superclass entity-name
 	private final boolean explicitPolymorphism;
 	private final boolean inherited;
 	private final boolean hasSubclasses;
 	private final Set subclassEntityNames = new HashSet();
 	private final Map entityNameByInheritenceClassMap = new HashMap();
 
 	private final EntityMode entityMode;
 	private final EntityTuplizer entityTuplizer;
 	private final EntityInstrumentationMetadata instrumentationMetadata;
 
 	public EntityMetamodel(
 			PersistentClass persistentClass,
 			AbstractEntityPersister persister,
 			SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 		this.persister = persister;
 
 		name = persistentClass.getEntityName();
 		rootName = persistentClass.getRootClass().getEntityName();
 		entityType = sessionFactory.getTypeResolver().getTypeFactory().manyToOne( name );
 
 		identifierAttribute = PropertyFactory.buildIdentifierAttribute(
 				persistentClass,
 				sessionFactory.getIdentifierGenerator( rootName )
 		);
 
 		versioned = persistentClass.isVersioned();
 
 		instrumentationMetadata = persistentClass.hasPojoRepresentation()
 				? Environment.getBytecodeProvider().getEntityInstrumentationMetadata( persistentClass.getMappedClass() )
 				: new NonPojoInstrumentationMetadata( persistentClass.getEntityName() );
 
 		boolean hasLazy = false;
 
 		propertySpan = persistentClass.getPropertyClosureSpan();
 		properties = new NonIdentifierAttribute[propertySpan];
 		List<Integer> naturalIdNumbers = new ArrayList<Integer>();
 		// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		propertyNames = new String[propertySpan];
 		propertyTypes = new Type[propertySpan];
 		propertyUpdateability = new boolean[propertySpan];
 		propertyInsertability = new boolean[propertySpan];
 		nonlazyPropertyUpdateability = new boolean[propertySpan];
 		propertyCheckability = new boolean[propertySpan];
 		propertyNullability = new boolean[propertySpan];
 		propertyVersionability = new boolean[propertySpan];
 		propertyLaziness = new boolean[propertySpan];
 		cascadeStyles = new CascadeStyle[propertySpan];
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		// generated value strategies ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		this.inMemoryValueGenerationStrategies = new InMemoryValueGenerationStrategy[propertySpan];
 		this.inDatabaseValueGenerationStrategies = new InDatabaseValueGenerationStrategy[propertySpan];
 
 		boolean foundPreInsertGeneratedValues = false;
 		boolean foundPreUpdateGeneratedValues = false;
 		boolean foundPostInsertGeneratedValues = false;
 		boolean foundPostUpdateGeneratedValues = false;
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		Iterator iter = persistentClass.getPropertyClosureIterator();
 		int i = 0;
 		int tempVersionProperty = NO_VERSION_INDX;
 		boolean foundCascade = false;
 		boolean foundCollection = false;
 		boolean foundMutable = false;
 		boolean foundNonIdentifierPropertyNamedId = false;
 		boolean foundInsertGeneratedValue = false;
 		boolean foundUpdateGeneratedValue = false;
 		boolean foundUpdateableNaturalIdProperty = false;
 
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 
 			if ( prop == persistentClass.getVersion() ) {
 				tempVersionProperty = i;
 				properties[i] = PropertyFactory.buildVersionProperty(
 						persister,
 						sessionFactory,
 						i,
 						prop,
 						instrumentationMetadata.isInstrumented()
 				);
 			}
 			else {
 				properties[i] = PropertyFactory.buildEntityBasedAttribute(
 						persister,
 						sessionFactory,
 						i,
 						prop,
 						instrumentationMetadata.isInstrumented()
 				);
 			}
 
 			if ( prop.isNaturalIdentifier() ) {
 				naturalIdNumbers.add( i );
 				if ( prop.isUpdateable() ) {
 					foundUpdateableNaturalIdProperty = true;
 				}
 			}
 
 			if ( "id".equals( prop.getName() ) ) {
 				foundNonIdentifierPropertyNamedId = true;
 			}
 
 			// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			boolean lazy = prop.isLazy() && instrumentationMetadata.isInstrumented();
-			if ( lazy ) hasLazy = true;
+			if ( lazy ) {
+				hasLazy = true;
+			}
 			propertyLaziness[i] = lazy;
 
 			propertyNames[i] = properties[i].getName();
 			propertyTypes[i] = properties[i].getType();
 			propertyNullability[i] = properties[i].isNullable();
 			propertyUpdateability[i] = properties[i].isUpdateable();
 			propertyInsertability[i] = properties[i].isInsertable();
 			propertyVersionability[i] = properties[i].isVersionable();
 			nonlazyPropertyUpdateability[i] = properties[i].isUpdateable() && !lazy;
 			propertyCheckability[i] = propertyUpdateability[i] ||
 					( propertyTypes[i].isAssociationType() && ( (AssociationType) propertyTypes[i] ).isAlwaysDirtyChecked() );
 
 			cascadeStyles[i] = properties[i].getCascadeStyle();
 			// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 			// generated value strategies ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			GenerationStrategyPair pair = buildGenerationStrategyPair( sessionFactory, prop );
 			inMemoryValueGenerationStrategies[i] = pair.getInMemoryStrategy();
 			inDatabaseValueGenerationStrategies[i] = pair.getInDatabaseStrategy();
 
 			if ( pair.getInMemoryStrategy() != null ) {
 				final GenerationTiming timing = pair.getInMemoryStrategy().getGenerationTiming();
 				if ( timing != GenerationTiming.NEVER ) {
 					final ValueGenerator generator = pair.getInMemoryStrategy().getValueGenerator();
 					if ( generator != null ) {
 						// we have some level of generation indicated
 						if ( timing == GenerationTiming.INSERT ) {
 							foundPreInsertGeneratedValues = true;
 						}
 						else if ( timing == GenerationTiming.ALWAYS ) {
 							foundPreInsertGeneratedValues = true;
 							foundPreUpdateGeneratedValues = true;
 						}
 					}
 				}
 			}
 			if (  pair.getInDatabaseStrategy() != null ) {
 				final GenerationTiming timing =  pair.getInDatabaseStrategy().getGenerationTiming();
 				if ( timing == GenerationTiming.INSERT ) {
 					foundPostInsertGeneratedValues = true;
 				}
 				else if ( timing == GenerationTiming.ALWAYS ) {
 					foundPostInsertGeneratedValues = true;
 					foundPostUpdateGeneratedValues = true;
 				}
 			}
 			// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 			if ( properties[i].isLazy() ) {
 				hasLazy = true;
 			}
 
 			if ( properties[i].getCascadeStyle() != CascadeStyles.NONE ) {
 				foundCascade = true;
 			}
 
 			if ( indicatesCollection( properties[i].getType() ) ) {
 				foundCollection = true;
 			}
 
 			if ( propertyTypes[i].isMutable() && propertyCheckability[i] ) {
 				foundMutable = true;
 			}
 
 			mapPropertyToIndex(prop, i);
 			i++;
 		}
 
 		if (naturalIdNumbers.size()==0) {
 			naturalIdPropertyNumbers = null;
 			hasImmutableNaturalId = false;
 			hasCacheableNaturalId = false;
 		}
 		else {
 			naturalIdPropertyNumbers = ArrayHelper.toIntArray(naturalIdNumbers);
 			hasImmutableNaturalId = !foundUpdateableNaturalIdProperty;
 			hasCacheableNaturalId = persistentClass.getNaturalIdCacheRegionName() != null;
 		}
 
 		this.hasPreInsertGeneratedValues = foundPreInsertGeneratedValues;
 		this.hasPreUpdateGeneratedValues = foundPreUpdateGeneratedValues;
 		this.hasInsertGeneratedValues = foundPostInsertGeneratedValues;
 		this.hasUpdateGeneratedValues = foundPostUpdateGeneratedValues;
 
 		hasCascades = foundCascade;
 		hasNonIdentifierPropertyNamedId = foundNonIdentifierPropertyNamedId;
 		versionPropertyIndex = tempVersionProperty;
 		hasLazyProperties = hasLazy;
-        if (hasLazyProperties) LOG.lazyPropertyFetchingAvailable(name);
+        if (hasLazyProperties) {
+			LOG.lazyPropertyFetchingAvailable(name);
+		}
 
 		lazy = persistentClass.isLazy() && (
 				// TODO: this disables laziness even in non-pojo entity modes:
 				!persistentClass.hasPojoRepresentation() ||
 				!ReflectHelper.isFinalClass( persistentClass.getProxyInterface() )
 		);
 		mutable = persistentClass.isMutable();
 		if ( persistentClass.isAbstract() == null ) {
 			// legacy behavior (with no abstract attribute specified)
 			isAbstract = persistentClass.hasPojoRepresentation() &&
 			             ReflectHelper.isAbstractClass( persistentClass.getMappedClass() );
 		}
 		else {
 			isAbstract = persistentClass.isAbstract().booleanValue();
 			if ( !isAbstract && persistentClass.hasPojoRepresentation() &&
 			     ReflectHelper.isAbstractClass( persistentClass.getMappedClass() ) ) {
                 LOG.entityMappedAsNonAbstract(name);
 			}
 		}
 		selectBeforeUpdate = persistentClass.hasSelectBeforeUpdate();
 		dynamicUpdate = persistentClass.useDynamicUpdate();
 		dynamicInsert = persistentClass.useDynamicInsert();
 
 		polymorphic = persistentClass.isPolymorphic();
 		explicitPolymorphism = persistentClass.isExplicitPolymorphism();
 		inherited = persistentClass.isInherited();
 		superclass = inherited ?
 				persistentClass.getSuperclass().getEntityName() :
 				null;
 		hasSubclasses = persistentClass.hasSubclasses();
 
 		optimisticLockStyle = persistentClass.getOptimisticLockStyle();
 		final boolean isAllOrDirty =
 				optimisticLockStyle == OptimisticLockStyle.ALL
 						|| optimisticLockStyle == OptimisticLockStyle.DIRTY;
 		if ( isAllOrDirty && !dynamicUpdate ) {
 			throw new MappingException( "optimistic-lock=all|dirty requires dynamic-update=\"true\": " + name );
 		}
 		if ( versionPropertyIndex != NO_VERSION_INDX && isAllOrDirty ) {
 			throw new MappingException( "version and optimistic-lock=all|dirty are not a valid combination : " + name );
 		}
 
 		hasCollections = foundCollection;
 		hasMutableProperties = foundMutable;
 
 		iter = persistentClass.getSubclassIterator();
 		while ( iter.hasNext() ) {
 			subclassEntityNames.add( ( (PersistentClass) iter.next() ).getEntityName() );
 		}
 		subclassEntityNames.add( name );
 
 		if ( persistentClass.hasPojoRepresentation() ) {
 			entityNameByInheritenceClassMap.put( persistentClass.getMappedClass(), persistentClass.getEntityName() );
 			iter = persistentClass.getSubclassIterator();
 			while ( iter.hasNext() ) {
 				final PersistentClass pc = ( PersistentClass ) iter.next();
 				entityNameByInheritenceClassMap.put( pc.getMappedClass(), pc.getEntityName() );
 			}
 		}
 
 		entityMode = persistentClass.hasPojoRepresentation() ? EntityMode.POJO : EntityMode.MAP;
 		final EntityTuplizerFactory entityTuplizerFactory = sessionFactory.getSettings().getEntityTuplizerFactory();
 		final String tuplizerClassName = persistentClass.getTuplizerImplClassName( entityMode );
 		if ( tuplizerClassName == null ) {
 			entityTuplizer = entityTuplizerFactory.constructDefaultTuplizer( entityMode, this, persistentClass );
 		}
 		else {
 			entityTuplizer = entityTuplizerFactory.constructTuplizer( tuplizerClassName, this, persistentClass );
 		}
 	}
 
 	private static GenerationStrategyPair buildGenerationStrategyPair(
 			final SessionFactoryImplementor sessionFactory,
 			final Property mappingProperty) {
 		final ValueGeneration valueGeneration = mappingProperty.getValueGenerationStrategy();
 		if ( valueGeneration != null && valueGeneration.getGenerationTiming() != GenerationTiming.NEVER ) {
 			// the property is generated in full. build the generation strategy pair.
 			if ( valueGeneration.getValueGenerator() != null ) {
 				// in-memory generation
 				return new GenerationStrategyPair(
 						FullInMemoryValueGenerationStrategy.create( valueGeneration )
 				);
 			}
 			else {
 				// in-db generation
 				return new GenerationStrategyPair(
 						create(
 								sessionFactory,
 								mappingProperty,
 								valueGeneration
 						)
 				);
 			}
 		}
 		else if ( mappingProperty.getValue() instanceof Component ) {
 			final CompositeGenerationStrategyPairBuilder builder = new CompositeGenerationStrategyPairBuilder( mappingProperty );
 			interpretPartialCompositeValueGeneration( sessionFactory, (Component) mappingProperty.getValue(), builder );
 			return builder.buildPair();
 		}
 
 		return NO_GEN_PAIR;
 	}
 
 	private static final GenerationStrategyPair NO_GEN_PAIR = new GenerationStrategyPair();
 
 	private static void interpretPartialCompositeValueGeneration(
 			SessionFactoryImplementor sessionFactory,
 			Component composite,
 			CompositeGenerationStrategyPairBuilder builder) {
 		Iterator subProperties = composite.getPropertyIterator();
 		while ( subProperties.hasNext() ) {
 			final Property subProperty = (Property) subProperties.next();
 			builder.addPair( buildGenerationStrategyPair( sessionFactory, subProperty ) );
 		}
 	}
 
 	public static InDatabaseValueGenerationStrategyImpl create(
 			SessionFactoryImplementor sessionFactoryImplementor,
 			Property mappingProperty,
 			ValueGeneration valueGeneration) {
 		final int numberOfMappedColumns = mappingProperty.getType().getColumnSpan( sessionFactoryImplementor );
 		if ( numberOfMappedColumns == 1 ) {
 			return new InDatabaseValueGenerationStrategyImpl(
 					valueGeneration.getGenerationTiming(),
 					valueGeneration.referenceColumnInSql(),
 					new String[] { valueGeneration.getDatabaseGeneratedReferencedColumnValue() }
 
 			);
 		}
 		else {
 			if ( valueGeneration.getDatabaseGeneratedReferencedColumnValue() != null ) {
 				LOG.debugf(
 						"Value generator specified column value in reference to multi-column attribute [%s -> %s]; ignoring",
 						mappingProperty.getPersistentClass(),
 						mappingProperty.getName()
 				);
 			}
 			return new InDatabaseValueGenerationStrategyImpl(
 					valueGeneration.getGenerationTiming(),
 					valueGeneration.referenceColumnInSql(),
 					new String[numberOfMappedColumns]
 			);
 		}
 	}
 
 	public static class GenerationStrategyPair {
 		private final InMemoryValueGenerationStrategy inMemoryStrategy;
 		private final InDatabaseValueGenerationStrategy inDatabaseStrategy;
 
 		public GenerationStrategyPair() {
 			this( NoInMemoryValueGenerationStrategy.INSTANCE, NoInDatabaseValueGenerationStrategy.INSTANCE );
 		}
 
 		public GenerationStrategyPair(FullInMemoryValueGenerationStrategy inMemoryStrategy) {
 			this( inMemoryStrategy, NoInDatabaseValueGenerationStrategy.INSTANCE );
 		}
 
 		public GenerationStrategyPair(InDatabaseValueGenerationStrategyImpl inDatabaseStrategy) {
 			this( NoInMemoryValueGenerationStrategy.INSTANCE, inDatabaseStrategy );
 		}
 
 		public GenerationStrategyPair(
 				InMemoryValueGenerationStrategy inMemoryStrategy,
 				InDatabaseValueGenerationStrategy inDatabaseStrategy) {
 			// perform some normalization.  Also check that only one (if any) strategy is specified
 			if ( inMemoryStrategy == null ) {
 				inMemoryStrategy = NoInMemoryValueGenerationStrategy.INSTANCE;
 			}
 			if ( inDatabaseStrategy == null ) {
 				inDatabaseStrategy = NoInDatabaseValueGenerationStrategy.INSTANCE;
 			}
 
 			if ( inMemoryStrategy.getGenerationTiming() != GenerationTiming.NEVER
 					&& inDatabaseStrategy.getGenerationTiming() != GenerationTiming.NEVER ) {
 				throw new ValueGenerationStrategyException(
 						"in-memory and in-database value generation are mutually exclusive"
 				);
 			}
 
 			this.inMemoryStrategy = inMemoryStrategy;
 			this.inDatabaseStrategy = inDatabaseStrategy;
 		}
 
 		public InMemoryValueGenerationStrategy getInMemoryStrategy() {
 			return inMemoryStrategy;
 		}
 
 		public InDatabaseValueGenerationStrategy getInDatabaseStrategy() {
 			return inDatabaseStrategy;
 		}
 	}
 
 	public static class ValueGenerationStrategyException extends HibernateException {
 		public ValueGenerationStrategyException(String message) {
 			super( message );
 		}
 
 		public ValueGenerationStrategyException(String message, Throwable cause) {
 			super( message, cause );
 		}
 	}
 
 	private static class CompositeGenerationStrategyPairBuilder {
 		private final Property mappingProperty;
 
 		private boolean hadInMemoryGeneration;
 		private boolean hadInDatabaseGeneration;
 
 		private List<InMemoryValueGenerationStrategy> inMemoryStrategies;
 		private List<InDatabaseValueGenerationStrategy> inDatabaseStrategies;
 
 		public CompositeGenerationStrategyPairBuilder(Property mappingProperty) {
 			this.mappingProperty = mappingProperty;
 		}
 
 		public void addPair(GenerationStrategyPair generationStrategyPair) {
 			add( generationStrategyPair.getInMemoryStrategy() );
 			add( generationStrategyPair.getInDatabaseStrategy() );
 		}
 
 		private void add(InMemoryValueGenerationStrategy inMemoryStrategy) {
 			if ( inMemoryStrategies == null ) {
 				inMemoryStrategies = new ArrayList<InMemoryValueGenerationStrategy>();
 			}
 			inMemoryStrategies.add( inMemoryStrategy );
 
 			if ( inMemoryStrategy.getGenerationTiming() != GenerationTiming.NEVER ) {
 				hadInMemoryGeneration = true;
 			}
 		}
 
 		private void add(InDatabaseValueGenerationStrategy inDatabaseStrategy) {
 			if ( inDatabaseStrategies == null ) {
 				inDatabaseStrategies = new ArrayList<InDatabaseValueGenerationStrategy>();
 			}
 			inDatabaseStrategies.add( inDatabaseStrategy );
 
 			if ( inDatabaseStrategy.getGenerationTiming() != GenerationTiming.NEVER ) {
 				hadInDatabaseGeneration = true;
 			}
 		}
 
 		public GenerationStrategyPair buildPair() {
 			if ( hadInMemoryGeneration && hadInDatabaseGeneration ) {
 				throw new ValueGenerationStrategyException(
 						"Composite attribute [" + mappingProperty.getName() + "] contained both in-memory"
 								+ " and in-database value generation"
 				);
 			}
 			else if ( hadInMemoryGeneration ) {
 				throw new NotYetImplementedException( "Still need to wire in composite in-memory value generation" );
 
 			}
 			else if ( hadInDatabaseGeneration ) {
 				final Component composite = (Component) mappingProperty.getValue();
 
 				// we need the numbers to match up so we can properly handle 'referenced sql column values'
 				if ( inDatabaseStrategies.size() != composite.getPropertySpan() ) {
 					throw new ValueGenerationStrategyException(
 							"Internal error : mismatch between number of collected in-db generation strategies" +
 									" and number of attributes for composite attribute : " + mappingProperty.getName()
 					);
 				}
 
 				// the base-line values for the aggregated InDatabaseValueGenerationStrategy we will build here.
 				GenerationTiming timing = GenerationTiming.INSERT;
 				boolean referenceColumns = false;
 				String[] columnValues = new String[ composite.getColumnSpan() ];
 
 				// start building the aggregate values
 				int propertyIndex = -1;
 				int columnIndex = 0;
 				Iterator subProperties = composite.getPropertyIterator();
 				while ( subProperties.hasNext() ) {
 					propertyIndex++;
 					final Property subProperty = (Property) subProperties.next();
 					final InDatabaseValueGenerationStrategy subStrategy = inDatabaseStrategies.get( propertyIndex );
 
 					if ( subStrategy.getGenerationTiming() == GenerationTiming.ALWAYS ) {
 						// override the base-line to the more often "ALWAYS"...
 						timing = GenerationTiming.ALWAYS;
 
 					}
 					if ( subStrategy.referenceColumnsInSql() ) {
 						// override base-line value
 						referenceColumns = true;
 					}
 					if ( subStrategy.getReferencedColumnValues() != null ) {
 						if ( subStrategy.getReferencedColumnValues().length != subProperty.getColumnSpan() ) {
 							throw new ValueGenerationStrategyException(
 									"Internal error : mismatch between number of collected 'referenced column values'" +
 											" and number of columns for composite attribute : " + mappingProperty.getName() +
 											'.' + subProperty.getName()
 							);
 						}
 						System.arraycopy(
 								subStrategy.getReferencedColumnValues(),
 								0,
 								columnValues,
 								columnIndex,
 								subProperty.getColumnSpan()
 						);
 					}
 				}
 
 				// then use the aggregated values to build the InDatabaseValueGenerationStrategy
 				return new GenerationStrategyPair(
 						new InDatabaseValueGenerationStrategyImpl( timing, referenceColumns, columnValues )
 				);
 			}
 			else {
 				return NO_GEN_PAIR;
 			}
 		}
 	}
 
 	private static class NoInMemoryValueGenerationStrategy implements InMemoryValueGenerationStrategy {
 		/**
 		 * Singleton access
 		 */
 		public static final NoInMemoryValueGenerationStrategy INSTANCE = new NoInMemoryValueGenerationStrategy();
 
 		@Override
 		public GenerationTiming getGenerationTiming() {
 			return GenerationTiming.NEVER;
 		}
 
 		@Override
 		public ValueGenerator getValueGenerator() {
 			return null;
 		}
 	}
 
 	private static class FullInMemoryValueGenerationStrategy implements InMemoryValueGenerationStrategy {
 		private final GenerationTiming timing;
 		private final ValueGenerator generator;
 
 		private FullInMemoryValueGenerationStrategy(GenerationTiming timing, ValueGenerator generator) {
 			this.timing = timing;
 			this.generator = generator;
 		}
 
 		public static FullInMemoryValueGenerationStrategy create(ValueGeneration valueGeneration) {
 			return new FullInMemoryValueGenerationStrategy(
 					valueGeneration.getGenerationTiming(),
 					valueGeneration.getValueGenerator()
 			);
 		}
 
 		@Override
 		public GenerationTiming getGenerationTiming() {
 			return timing;
 		}
 
 		@Override
 		public ValueGenerator getValueGenerator() {
 			return generator;
 		}
 	}
 
 	private static class NoInDatabaseValueGenerationStrategy implements InDatabaseValueGenerationStrategy {
 		/**
 		 * Singleton access
 		 */
 		public static final NoInDatabaseValueGenerationStrategy INSTANCE = new NoInDatabaseValueGenerationStrategy();
 
 		@Override
 		public GenerationTiming getGenerationTiming() {
 			return GenerationTiming.NEVER;
 		}
 
 		@Override
 		public boolean referenceColumnsInSql() {
 			return true;
 		}
 
 		@Override
 		public String[] getReferencedColumnValues() {
 			return null;
 		}
 	}
 
 	private static class InDatabaseValueGenerationStrategyImpl implements InDatabaseValueGenerationStrategy {
 		private final GenerationTiming timing;
 		private final boolean referenceColumnInSql;
 		private final String[] referencedColumnValues;
 
 		private InDatabaseValueGenerationStrategyImpl(
 				GenerationTiming timing,
 				boolean referenceColumnInSql,
 				String[] referencedColumnValues) {
 			this.timing = timing;
 			this.referenceColumnInSql = referenceColumnInSql;
 			this.referencedColumnValues = referencedColumnValues;
 		}
 
 		@Override
 		public GenerationTiming getGenerationTiming() {
 			return timing;
 		}
 
 		@Override
 		public boolean referenceColumnsInSql() {
 			return referenceColumnInSql;
 		}
 
 		@Override
 		public String[] getReferencedColumnValues() {
 			return referencedColumnValues;
 		}
 	}
 
 	private ValueInclusion determineInsertValueGenerationType(Property mappingProperty, NonIdentifierAttribute runtimeProperty) {
 		if ( isInsertGenerated( runtimeProperty ) ) {
 			return ValueInclusion.FULL;
 		}
 		else if ( mappingProperty.getValue() instanceof Component ) {
 			if ( hasPartialInsertComponentGeneration( ( Component ) mappingProperty.getValue() ) ) {
 				return ValueInclusion.PARTIAL;
 			}
 		}
 		return ValueInclusion.NONE;
 	}
 
 	private boolean isInsertGenerated(NonIdentifierAttribute property) {
 		return property.getValueGenerationStrategy() != null
 				&& property.getValueGenerationStrategy().getGenerationTiming() != GenerationTiming.NEVER;
 	}
 
 	private boolean isInsertGenerated(Property property) {
 		return property.getValueGenerationStrategy() != null
 				&& property.getValueGenerationStrategy().getGenerationTiming() != GenerationTiming.NEVER;
 	}
 
 	private boolean hasPartialInsertComponentGeneration(Component component) {
 		Iterator subProperties = component.getPropertyIterator();
 		while ( subProperties.hasNext() ) {
 			final Property prop = ( Property ) subProperties.next();
 			if ( isInsertGenerated( prop ) ) {
 				return true;
 			}
 			else if ( prop.getValue() instanceof Component ) {
 				if ( hasPartialInsertComponentGeneration( (Component) prop.getValue() ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	private ValueInclusion determineUpdateValueGenerationType(Property mappingProperty, NonIdentifierAttribute runtimeProperty) {
 		if ( isUpdateGenerated( runtimeProperty ) ) {
 			return ValueInclusion.FULL;
 		}
 		else if ( mappingProperty.getValue() instanceof Component ) {
 			if ( hasPartialUpdateComponentGeneration( ( Component ) mappingProperty.getValue() ) ) {
 				return ValueInclusion.PARTIAL;
 			}
 		}
 		return ValueInclusion.NONE;
 	}
 
 	private static boolean isUpdateGenerated(Property property) {
 		return property.getValueGenerationStrategy() != null
 				&& property.getValueGenerationStrategy().getGenerationTiming() == GenerationTiming.ALWAYS;
 	}
 
 	private static boolean isUpdateGenerated(NonIdentifierAttribute property) {
 		return property.getValueGenerationStrategy() != null
 				&& property.getValueGenerationStrategy().getGenerationTiming() == GenerationTiming.ALWAYS;
 	}
 
 	private boolean hasPartialUpdateComponentGeneration(Component component) {
 		Iterator subProperties = component.getPropertyIterator();
 		while ( subProperties.hasNext() ) {
 			Property prop = (Property) subProperties.next();
 			if ( isUpdateGenerated( prop ) ) {
 				return true;
 			}
 			else if ( prop.getValue() instanceof Component ) {
 				if ( hasPartialUpdateComponentGeneration( ( Component ) prop.getValue() ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	private void mapPropertyToIndex(Property prop, int i) {
 		propertyIndexes.put( prop.getName(), i );
 		if ( prop.getValue() instanceof Component ) {
 			Iterator iter = ( (Component) prop.getValue() ).getPropertyIterator();
 			while ( iter.hasNext() ) {
 				Property subprop = (Property) iter.next();
 				propertyIndexes.put(
 						prop.getName() + '.' + subprop.getName(),
 						i
 					);
 			}
 		}
 	}
 
 	public EntityTuplizer getTuplizer() {
 		return entityTuplizer;
 	}
 
 	public boolean isNaturalIdentifierInsertGenerated() {
 		// the intention is for this call to replace the usage of the old ValueInclusion stuff (as exposed from
 		// persister) in SelectGenerator to determine if it is safe to use the natural identifier to find the
 		// insert-generated identifier.  That wont work if the natural-id is also insert-generated.
 		//
 		// Assumptions:
 		//		* That code checks that there is a natural identifier before making this call, so we assume the same here
 		// 		* That code assumes a non-composite natural-id, so we assume the same here
 		final InDatabaseValueGenerationStrategy strategy = inDatabaseValueGenerationStrategies[ naturalIdPropertyNumbers[0] ];
 		return strategy != null && strategy.getGenerationTiming() != GenerationTiming.NEVER;
 	}
 
 	public boolean isVersionGenerated() {
 		final InDatabaseValueGenerationStrategy strategy = inDatabaseValueGenerationStrategies[ versionPropertyIndex ];
 		return strategy != null && strategy.getGenerationTiming() != GenerationTiming.NEVER;
 	}
 
 	public int[] getNaturalIdentifierProperties() {
 		return naturalIdPropertyNumbers;
 	}
 
 	public boolean hasNaturalIdentifier() {
 		return naturalIdPropertyNumbers!=null;
 	}
 	
 	public boolean isNaturalIdentifierCached() {
 		return hasNaturalIdentifier() && hasCacheableNaturalId;
 	}
 
 	public boolean hasImmutableNaturalId() {
 		return hasImmutableNaturalId;
 	}
 
 	public Set getSubclassEntityNames() {
 		return subclassEntityNames;
 	}
 
 	private boolean indicatesCollection(Type type) {
 		if ( type.isCollectionType() ) {
 			return true;
 		}
 		else if ( type.isComponentType() ) {
 			Type[] subtypes = ( (CompositeType) type ).getSubtypes();
 			for ( int i = 0; i < subtypes.length; i++ ) {
 				if ( indicatesCollection( subtypes[i] ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	public SessionFactoryImplementor getSessionFactory() {
 		return sessionFactory;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public String getRootName() {
 		return rootName;
 	}
 
 	public EntityType getEntityType() {
 		return entityType;
 	}
 
 	public IdentifierProperty getIdentifierProperty() {
 		return identifierAttribute;
 	}
 
 	public int getPropertySpan() {
 		return propertySpan;
 	}
 
 	public int getVersionPropertyIndex() {
 		return versionPropertyIndex;
 	}
 
 	public VersionProperty getVersionProperty() {
 		if ( NO_VERSION_INDX == versionPropertyIndex ) {
 			return null;
 		}
 		else {
 			return ( VersionProperty ) properties[ versionPropertyIndex ];
 		}
 	}
 
 	public NonIdentifierAttribute[] getProperties() {
 		return properties;
 	}
 
 	public int getPropertyIndex(String propertyName) {
 		Integer index = getPropertyIndexOrNull(propertyName);
 		if ( index == null ) {
 			throw new HibernateException("Unable to resolve property: " + propertyName);
 		}
 		return index;
 	}
 
 	public Integer getPropertyIndexOrNull(String propertyName) {
 		return propertyIndexes.get( propertyName );
 	}
 
 	public boolean hasCollections() {
 		return hasCollections;
 	}
 
 	public boolean hasMutableProperties() {
 		return hasMutableProperties;
 	}
 
 	public boolean hasNonIdentifierPropertyNamedId() {
 		return hasNonIdentifierPropertyNamedId;
 	}
 
 	public boolean hasLazyProperties() {
 		return hasLazyProperties;
 	}
 
 	public boolean hasCascades() {
 		return hasCascades;
 	}
 
 	public boolean isMutable() {
 		return mutable;
 	}
 
 	public boolean isSelectBeforeUpdate() {
 		return selectBeforeUpdate;
 	}
 
 	public boolean isDynamicUpdate() {
 		return dynamicUpdate;
 	}
 
 	public boolean isDynamicInsert() {
 		return dynamicInsert;
 	}
 
 	public OptimisticLockStyle getOptimisticLockStyle() {
 		return optimisticLockStyle;
 	}
 
 	public boolean isPolymorphic() {
 		return polymorphic;
 	}
 
 	public String getSuperclass() {
 		return superclass;
 	}
 
 	public boolean isExplicitPolymorphism() {
 		return explicitPolymorphism;
 	}
 
 	public boolean isInherited() {
 		return inherited;
 	}
 
 	public boolean hasSubclasses() {
 		return hasSubclasses;
 	}
 
 	public boolean isLazy() {
 		return lazy;
 	}
 
 	public void setLazy(boolean lazy) {
 		this.lazy = lazy;
 	}
 
 	public boolean isVersioned() {
 		return versioned;
 	}
 
 	public boolean isAbstract() {
 		return isAbstract;
 	}
 
 	/**
 	 * Return the entity-name mapped to the given class within our inheritance hierarchy, if any.
 	 *
 	 * @param inheritenceClass The class for which to resolve the entity-name.
 	 * @return The mapped entity-name, or null if no such mapping was found.
 	 */
 	public String findEntityNameByEntityClass(Class inheritenceClass) {
 		return ( String ) entityNameByInheritenceClassMap.get( inheritenceClass );
 	}
 
 	@Override
     public String toString() {
 		return "EntityMetamodel(" + name + ':' + ArrayHelper.toString(properties) + ')';
 	}
 
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public String[] getPropertyNames() {
 		return propertyNames;
 	}
 
 	public Type[] getPropertyTypes() {
 		return propertyTypes;
 	}
 
 	public boolean[] getPropertyLaziness() {
 		return propertyLaziness;
 	}
 
 	public boolean[] getPropertyUpdateability() {
 		return propertyUpdateability;
 	}
 
 	public boolean[] getPropertyCheckability() {
 		return propertyCheckability;
 	}
 
 	public boolean[] getNonlazyPropertyUpdateability() {
 		return nonlazyPropertyUpdateability;
 	}
 
 	public boolean[] getPropertyInsertability() {
 		return propertyInsertability;
 	}
 
 	public boolean[] getPropertyNullability() {
 		return propertyNullability;
 	}
 
 	public boolean[] getPropertyVersionability() {
 		return propertyVersionability;
 	}
 
 	public CascadeStyle[] getCascadeStyles() {
 		return cascadeStyles;
 	}
 
 	public boolean hasPreInsertGeneratedValues() {
 		return hasPreInsertGeneratedValues;
 	}
 
 	public boolean hasPreUpdateGeneratedValues() {
 		return hasPreUpdateGeneratedValues;
 	}
 
 	public boolean hasInsertGeneratedValues() {
 		return hasInsertGeneratedValues;
 	}
 
 	public boolean hasUpdateGeneratedValues() {
 		return hasUpdateGeneratedValues;
 	}
 
 	public InMemoryValueGenerationStrategy[] getInMemoryValueGenerationStrategies() {
 		return inMemoryValueGenerationStrategies;
 	}
 
 	public InDatabaseValueGenerationStrategy[] getInDatabaseValueGenerationStrategies() {
 		return inDatabaseValueGenerationStrategies;
 	}
 
 	public EntityMode getEntityMode() {
 		return entityMode;
 	}
 
 	/**
 	 * Whether or not this class can be lazy (ie intercepted)
 	 */
 	public boolean isInstrumented() {
 		return instrumentationMetadata.isInstrumented();
 	}
 
 	public EntityInstrumentationMetadata getInstrumentationMetadata() {
 		return instrumentationMetadata;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityTuplizer.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityTuplizer.java
index 229656949b..399ab7852d 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityTuplizer.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityTuplizer.java
@@ -1,305 +1,309 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tuple.entity;
 import java.io.Serializable;
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.property.Getter;
 import org.hibernate.tuple.Tuplizer;
 
 /**
  * Defines further responsibilities reagarding tuplization based on
  * a mapped entity.
  * <p/>
  * EntityTuplizer implementations should have the following constructor signatures:
  *      (org.hibernate.tuple.entity.EntityMetamodel, org.hibernate.mapping.PersistentClass)
  *      (org.hibernate.tuple.entity.EntityMetamodel, org.hibernate.metamodel.binding.EntityBinding)
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public interface EntityTuplizer extends Tuplizer {
 	/**
 	 * Return the entity-mode handled by this tuplizer instance.
 	 *
 	 * @return The entity-mode
 	 */
-	public EntityMode getEntityMode();
+	EntityMode getEntityMode();
 
     /**
      * Create an entity instance initialized with the given identifier.
      *
      * @param id The identifier value for the entity to be instantiated.
      * @return The instantiated entity.
      * @throws HibernateException
 	 *
 	 * @deprecated Use {@link #instantiate(Serializable, SessionImplementor)} instead.
      */
+	@Deprecated
 	@SuppressWarnings( {"JavaDoc"})
-	public Object instantiate(Serializable id) throws HibernateException;
+	Object instantiate(Serializable id) throws HibernateException;
 
     /**
      * Create an entity instance initialized with the given identifier.
      *
      * @param id The identifier value for the entity to be instantiated.
 	 * @param session The session from which is requests originates
 	 *
      * @return The instantiated entity.
      */
-	public Object instantiate(Serializable id, SessionImplementor session);
+	Object instantiate(Serializable id, SessionImplementor session);
 
     /**
      * Extract the identifier value from the given entity.
      *
      * @param entity The entity from which to extract the identifier value.
 	 *
      * @return The identifier value.
 	 *
      * @throws HibernateException If the entity does not define an identifier property, or an
      * error occurs accessing its value.
 	 *
 	 * @deprecated Use {@link #getIdentifier(Object,SessionImplementor)} instead.
      */
-	public Serializable getIdentifier(Object entity) throws HibernateException;
+	@Deprecated
+	Serializable getIdentifier(Object entity) throws HibernateException;
 
     /**
      * Extract the identifier value from the given entity.
      *
      * @param entity The entity from which to extract the identifier value.
 	 * @param session The session from which is requests originates
 	 *
      * @return The identifier value.
      */
-	public Serializable getIdentifier(Object entity, SessionImplementor session);
+	Serializable getIdentifier(Object entity, SessionImplementor session);
 
     /**
      * Inject the identifier value into the given entity.
      * </p>
      * Has no effect if the entity does not define an identifier property
      *
      * @param entity The entity to inject with the identifier value.
      * @param id The value to be injected as the identifier.
 	 *
 	 * @deprecated Use {@link #setIdentifier(Object, Serializable, SessionImplementor)} instead.
      */
+	@Deprecated
 	@SuppressWarnings( {"JavaDoc"})
-	public void setIdentifier(Object entity, Serializable id) throws HibernateException;
+	void setIdentifier(Object entity, Serializable id) throws HibernateException;
 
     /**
      * Inject the identifier value into the given entity.
      * </p>
      * Has no effect if the entity does not define an identifier property
      *
      * @param entity The entity to inject with the identifier value.
      * @param id The value to be injected as the identifier.
 	 * @param session The session from which is requests originates
      */
-	public void setIdentifier(Object entity, Serializable id, SessionImplementor session);
+	void setIdentifier(Object entity, Serializable id, SessionImplementor session);
 
 	/**
 	 * Inject the given identifier and version into the entity, in order to
 	 * "roll back" to their original values.
 	 *
 	 * @param entity The entity for which to reset the id/version values
 	 * @param currentId The identifier value to inject into the entity.
 	 * @param currentVersion The version value to inject into the entity.
 	 *
 	 * @deprecated Use {@link #resetIdentifier(Object, Serializable, Object, SessionImplementor)} instead
 	 */
+	@Deprecated
 	@SuppressWarnings( {"UnusedDeclaration"})
-	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion);
+	void resetIdentifier(Object entity, Serializable currentId, Object currentVersion);
 
 	/**
 	 * Inject the given identifier and version into the entity, in order to
 	 * "roll back" to their original values.
 	 *
 	 * @param entity The entity for which to reset the id/version values
 	 * @param currentId The identifier value to inject into the entity.
 	 * @param currentVersion The version value to inject into the entity.
 	 * @param session The session from which the request originated
 	 */
-	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session);
+	void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session);
 
     /**
      * Extract the value of the version property from the given entity.
      *
      * @param entity The entity from which to extract the version value.
      * @return The value of the version property, or null if not versioned.
 	 * @throws HibernateException Indicates a problem accessing the version property
      */
-	public Object getVersion(Object entity) throws HibernateException;
+	Object getVersion(Object entity) throws HibernateException;
 
 	/**
 	 * Inject the value of a particular property.
 	 *
 	 * @param entity The entity into which to inject the value.
 	 * @param i The property's index.
 	 * @param value The property value to inject.
 	 * @throws HibernateException Indicates a problem access the property
 	 */
-	public void setPropertyValue(Object entity, int i, Object value) throws HibernateException;
+	void setPropertyValue(Object entity, int i, Object value) throws HibernateException;
 
 	/**
 	 * Inject the value of a particular property.
 	 *
 	 * @param entity The entity into which to inject the value.
 	 * @param propertyName The name of the property.
 	 * @param value The property value to inject.
 	 * @throws HibernateException Indicates a problem access the property
 	 */
-	public void setPropertyValue(Object entity, String propertyName, Object value) throws HibernateException;
+	void setPropertyValue(Object entity, String propertyName, Object value) throws HibernateException;
 
 	/**
 	 * Extract the values of the insertable properties of the entity (including backrefs)
 	 *
 	 * @param entity The entity from which to extract.
 	 * @param mergeMap a map of instances being merged to merged instances
 	 * @param session The session in which the resuest is being made.
 	 * @return The insertable property values.
 	 * @throws HibernateException Indicates a problem access the properties
 	 */
-	public Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session)
+	Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Extract the value of a particular property from the given entity.
 	 *
 	 * @param entity The entity from which to extract the property value.
 	 * @param propertyName The name of the property for which to extract the value.
 	 * @return The current value of the given property on the given entity.
 	 * @throws HibernateException Indicates a problem access the property
 	 */
-	public Object getPropertyValue(Object entity, String propertyName) throws HibernateException;
+	Object getPropertyValue(Object entity, String propertyName) throws HibernateException;
 
     /**
      * Called just after the entities properties have been initialized.
      *
      * @param entity The entity being initialized.
      * @param lazyPropertiesAreUnfetched Are defined lazy properties currently unfecthed
      * @param session The session initializing this entity.
      */
-	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session);
+	void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session);
 
 	/**
 	 * Does this entity, for this mode, present a possibility for proxying?
 	 *
 	 * @return True if this tuplizer can generate proxies for this entity.
 	 */
-	public boolean hasProxy();
+	boolean hasProxy();
 
 	/**
 	 * Generates an appropriate proxy representation of this entity for this
 	 * entity-mode.
 	 *
 	 * @param id The id of the instance for which to generate a proxy.
 	 * @param session The session to which the proxy should be bound.
 	 * @return The generate proxies.
 	 * @throws HibernateException Indicates an error generating the proxy.
 	 */
-	public Object createProxy(Serializable id, SessionImplementor session) throws HibernateException;
+	Object createProxy(Serializable id, SessionImplementor session) throws HibernateException;
 
 	/**
 	 * Does the {@link #getMappedClass() class} managed by this tuplizer implement
 	 * the {@link org.hibernate.classic.Lifecycle} interface.
 	 *
 	 * @return True if the Lifecycle interface is implemented; false otherwise.
 	 */
-	public boolean isLifecycleImplementor();
+	boolean isLifecycleImplementor();
 
 	/**
 	 * Returns the java class to which generated proxies will be typed.
 	 * <p/>
 	 * todo : look at fully encapsulating {@link org.hibernate.engine.spi.PersistenceContext#narrowProxy} here,
 	 * since that is the only external use of this method
 	 *
 	 * @return The java class to which generated proxies will be typed
 	 */
-	public Class getConcreteProxyClass();
+	Class getConcreteProxyClass();
 	
     /**
      * Does the given entity instance have any currently uninitialized lazy properties?
      *
      * @param entity The entity to be check for uninitialized lazy properties.
      * @return True if uninitialized lazy properties were found; false otherwise.
      */
-	public boolean hasUninitializedLazyProperties(Object entity);
+	boolean hasUninitializedLazyProperties(Object entity);
 	
 	/**
 	 * Is it an instrumented POJO?
 	 *
 	 * @return {@code true} if the entity class is instrumented; {@code false} otherwise.
 	 */
-	public boolean isInstrumented();
+	boolean isInstrumented();
 
 	/**
 	 * Get any {@link EntityNameResolver EntityNameResolvers} associated with this {@link Tuplizer}.
 	 *
 	 * @return The associated resolvers.  May be null or empty.
 	 */
-	public EntityNameResolver[] getEntityNameResolvers();
+	EntityNameResolver[] getEntityNameResolvers();
 
 	/**
 	 * Given an entity instance, determine the most appropriate (most targeted) entity-name which represents it.
 	 * This is called in situations where we already know an entity name for the given entityInstance; we are being
 	 * asked to determine if there is a more appropriate entity-name to use, specifically within an inheritence
 	 * hierarchy.
 	 * <p/>
 	 * For example, consider a case where a user calls <tt>session.update( "Animal", cat );</tt>.  Here, the
 	 * user has explicitly provided <tt>Animal</tt> as the entity-name.  However, they have passed in an instance
 	 * of <tt>Cat</tt> which is a subclass of <tt>Animal</tt>.  In this case, we would return <tt>Cat</tt> as the
 	 * entity-name.
 	 * <p/>
 	 * <tt>null</tt> may be returned from calls to this method.  The meaining of <tt>null</tt> in that case is assumed
 	 * to be that we should use whatever explicit entity-name the user provided (<tt>Animal</tt> rather than <tt>Cat</tt>
 	 * in the example above).
 	 *
 	 * @param entityInstance The entity instance.
 	 * @param factory Reference to the SessionFactory.
 	 *
 	 * @return The most appropriate entity name to use.
 	 *
 	 * @throws HibernateException If we are unable to determine an entity-name within the inheritence hierarchy.
 	 */
-	public String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory);
+	String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory);
 
 	/**
 	 * Retrieve the getter for the identifier property.  May return null.
 	 *
 	 * @return The getter for the identifier property.
 	 */
-	public Getter getIdentifierGetter();
+	Getter getIdentifierGetter();
 
 	/**
 	 * Retrieve the getter for the version property.  May return null.
 	 *
 	 * @return The getter for the version property.
 	 */
-	public Getter getVersionGetter();
+	Getter getVersionGetter();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AbstractBynaryType.java b/hibernate-core/src/main/java/org/hibernate/type/AbstractBynaryType.java
deleted file mode 100644
index 05344d15c8..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/AbstractBynaryType.java
+++ /dev/null
@@ -1,186 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.sql.Types;
-import java.util.Comparator;
-
-import org.hibernate.HibernateException;
-import org.hibernate.cfg.Environment;
-import org.hibernate.engine.spi.SessionImplementor;
-
-/**
- * Logic to bind stream of byte into a VARBINARY
- *
- * @author Gavin King
- * @author Emmanuel Bernard
- *
- * @deprecated Use the {@link AbstractStandardBasicType} approach instead
- */
-public abstract class AbstractBynaryType extends MutableType implements VersionType, Comparator {
-
-	/**
-	 * Convert the byte[] into the expected object type
-	 */
-	abstract protected Object toExternalFormat(byte[] bytes);
-
-	/**
-	 * Convert the object into the internal byte[] representation
-	 */
-	abstract protected byte[] toInternalFormat(Object bytes);
-
-	public void set(PreparedStatement st, Object value, int index) throws HibernateException, SQLException {
-		byte[] internalValue = toInternalFormat( value );
-		if ( Environment.useStreamsForBinary() ) {
-			st.setBinaryStream( index, new ByteArrayInputStream( internalValue ), internalValue.length );
-		}
-		else {
-			st.setBytes( index, internalValue );
-		}
-	}
-
-	public Object get(ResultSet rs, String name) throws HibernateException, SQLException {
-
-		if ( Environment.useStreamsForBinary() ) {
-
-			InputStream inputStream = rs.getBinaryStream(name);
-
-			if (inputStream==null) return toExternalFormat( null ); // is this really necessary?
-
-			ByteArrayOutputStream outputStream = new ByteArrayOutputStream(2048);
-			byte[] buffer = new byte[2048];
-
-			try {
-				while (true) {
-					int amountRead = inputStream.read(buffer);
-					if (amountRead == -1) {
-						break;
-					}
-					outputStream.write(buffer, 0, amountRead);
-				}
-
-				inputStream.close();
-				outputStream.close();
-			}
-			catch (IOException ioe) {
-				throw new HibernateException( "IOException occurred reading a binary value", ioe );
-			}
-
-			return toExternalFormat( outputStream.toByteArray() );
-
-		}
-		else {
-			return toExternalFormat( rs.getBytes(name) );
-		}
-	}
-
-	public int sqlType() {
-		return Types.VARBINARY;
-	}
-
-	// VersionType impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-	//      Note : simply returns null for seed() and next() as the only known
-	//      application of binary types for versioning is for use with the
-	//      TIMESTAMP datatype supported by Sybase and SQL Server, which
-	//      are completely db-generated values...
-	public Object seed(SessionImplementor session) {
-		return null;
-	}
-
-	public Object next(Object current, SessionImplementor session) {
-		return current;
-	}
-
-	public Comparator getComparator() {
-		return this;
-	}
-
-
-	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-	public boolean isEqual(Object x, Object y) {
-		return x==y || ( x!=null && y!=null && java.util.Arrays.equals( toInternalFormat(x), toInternalFormat(y) ) );
-	}
-
-	public int getHashCode(Object x) {
-		byte[] bytes = toInternalFormat(x);
-		int hashCode = 1;
-		for ( int j=0; j<bytes.length; j++ ) {
-			hashCode = 31 * hashCode + bytes[j];
-		}
-		return hashCode;
-	}
-
-	public int compare(Object x, Object y) {
-		byte[] xbytes = toInternalFormat(x);
-		byte[] ybytes = toInternalFormat(y);
-		if ( xbytes.length < ybytes.length ) return -1;
-		if ( xbytes.length > ybytes.length ) return 1;
-		for ( int i=0; i<xbytes.length; i++ ) {
-			if ( xbytes[i] < ybytes[i] ) return -1;
-			if ( xbytes[i] > ybytes[i] ) return 1;
-		}
-		return 0;
-	}
-
-	public abstract String getName();
-
-	public String toString(Object val) {
-		byte[] bytes = toInternalFormat(val);
-		StringBuilder buf = new StringBuilder();
-		for ( int i=0; i<bytes.length; i++ ) {
-			String hexStr = Integer.toHexString( bytes[i] - Byte.MIN_VALUE );
-			if ( hexStr.length()==1 ) buf.append('0');
-			buf.append(hexStr);
-		}
-		return buf.toString();
-	}
-
-	public Object deepCopyNotNull(Object value) {
-		byte[] bytes = toInternalFormat(value);
-		byte[] result = new byte[bytes.length];
-		System.arraycopy(bytes, 0, result, 0, bytes.length);
-		return toExternalFormat(result);
-	}
-
-	public Object fromStringValue(String xml) throws HibernateException {
-		if (xml == null)
-			return null;
-		if (xml.length() % 2 != 0)
-			throw new IllegalArgumentException("The string is not a valid xml representation of a binary content.");
-		byte[] bytes = new byte[xml.length() / 2];
-		for (int i = 0; i < bytes.length; i++) {
-			String hexStr = xml.substring(i * 2, (i + 1) * 2);
-			bytes[i] = (byte) (Integer.parseInt(hexStr, 16) + Byte.MIN_VALUE);
-		}
-		return toExternalFormat(bytes);
-	}
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AbstractCharArrayType.java b/hibernate-core/src/main/java/org/hibernate/type/AbstractCharArrayType.java
deleted file mode 100644
index 7c7880c7dc..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/AbstractCharArrayType.java
+++ /dev/null
@@ -1,120 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-import java.io.CharArrayReader;
-import java.io.CharArrayWriter;
-import java.io.IOException;
-import java.io.Reader;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.sql.Types;
-
-import org.hibernate.HibernateException;
-import org.hibernate.dialect.Dialect;
-
-/**
- * Logic to bind stream of char into a VARCHAR
- *
- * @author Emmanuel Bernard
- *
- * @deprecated Use the {@link AbstractStandardBasicType} approach instead
- */
-public abstract class AbstractCharArrayType extends MutableType {
-
-	/**
-	 * Convert the char[] into the expected object type
-	 */
-	abstract protected Object toExternalFormat(char[] chars);
-
-	/**
-	 * Convert the object into the internal char[] representation
-	 */
-	abstract protected char[] toInternalFormat(Object chars);
-
-	public Object get(ResultSet rs, String name) throws SQLException {
-		Reader stream = rs.getCharacterStream(name);
-		if ( stream == null ) return toExternalFormat( null );
-		CharArrayWriter writer = new CharArrayWriter();
-		for(;;) {
-			try {
-				int c = stream.read();
-				if ( c == -1) return toExternalFormat( writer.toCharArray() );
-				writer.write( c );
-			}
-			catch (IOException e) {
-				throw new HibernateException("Unable to read character stream from rs");
-			}
-		}
-	}
-
-	public abstract Class getReturnedClass();
-
-	public void set(PreparedStatement st, Object value, int index) throws SQLException {
-		char[] chars = toInternalFormat( value );
-		st.setCharacterStream(index, new CharArrayReader(chars), chars.length);
-	}
-
-	public int sqlType() {
-		return Types.VARCHAR;
-	}
-
-	public String objectToSQLString(Object value, Dialect dialect) throws Exception {
-
-		return '\'' + new String( toInternalFormat( value ) ) + '\'';
-	}
-
-	public Object stringToObject(String xml) throws Exception {
-		if (xml == null) return toExternalFormat( null );
-		int length = xml.length();
-		char[] chars = new char[length];
-		for (int index = 0 ; index < length ; index++ ) {
-			chars[index] = xml.charAt( index );
-		}
-		return toExternalFormat( chars );
-	}
-
-	public String toString(Object value) {
-		if (value == null) return null;
-		return new String( toInternalFormat( value ) );
-	}
-
-	public Object fromStringValue(String xml) {
-		if (xml == null) return null;
-		int length = xml.length();
-		char[] chars = new char[length];
-		for (int index = 0 ; index < length ; index++ ) {
-			chars[index] = xml.charAt( index );
-		}
-		return toExternalFormat( chars );
-	}
-
-	protected Object deepCopyNotNull(Object value) throws HibernateException {
-		char[] chars = toInternalFormat(value);
-		char[] result = new char[chars.length];
-		System.arraycopy(chars, 0, result, 0, chars.length);
-		return toExternalFormat(result);
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AbstractComponentType.java b/hibernate-core/src/main/java/org/hibernate/type/AbstractComponentType.java
deleted file mode 100644
index 8f1ba37228..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/AbstractComponentType.java
+++ /dev/null
@@ -1,37 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-
-/**
- * Enables other Component-like types to hold collections and have cascades, etc.
- *
- * @see ComponentType
- * @see AnyType
- * @author Gavin King
- *
- * @deprecated in favor of {@link org.hibernate.type.CompositeType}
- */
-public interface AbstractComponentType extends CompositeType {
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AbstractLobType.java b/hibernate-core/src/main/java/org/hibernate/type/AbstractLobType.java
deleted file mode 100644
index d039e82a28..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/AbstractLobType.java
+++ /dev/null
@@ -1,100 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-import java.io.Serializable;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-
-import org.hibernate.HibernateException;
-import org.hibernate.MappingException;
-import org.hibernate.engine.spi.Mapping;
-import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.jdbc.Size;
-
-/**
- * @author Emmanuel Bernard
- * @deprecated
- */
-@Deprecated
-public abstract class AbstractLobType extends AbstractType implements Serializable {
-	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session)
-			throws HibernateException {
-		return checkable[0] ? ! isEqual( old, current ) : false;
-	}
-
-	@Override
-	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
-		return new Size[] { LEGACY_DICTATED_SIZE };
-	}
-
-	@Override
-	public Size[] defaultSizes(Mapping mapping) throws MappingException {
-		return new Size[] { LEGACY_DEFAULT_SIZE };
-	}
-
-	@Override
-	public boolean isEqual(Object x, Object y) {
-		return isEqual( x, y, null );
-	}
-
-	@Override
-	public int getHashCode(Object x) {
-		return getHashCode( x, null );
-	}
-
-	public String getName() {
-		return this.getClass().getName();
-	}
-
-	public int getColumnSpan(Mapping mapping) throws MappingException {
-		return 1;
-	}
-
-	protected abstract Object get(ResultSet rs, String name) throws SQLException;
-
-	public Object nullSafeGet(ResultSet rs, String[] names, SessionImplementor session, Object owner)
-			throws HibernateException, SQLException {
-		return get( rs, names[0] );
-	}
-
-	public Object nullSafeGet(ResultSet rs, String name, SessionImplementor session, Object owner)
-			throws HibernateException, SQLException {
-		return get( rs, name );
-	}
-
-	public void nullSafeSet(
-			PreparedStatement st, Object value, int index, boolean[] settable, SessionImplementor session
-	) throws HibernateException, SQLException {
-		if ( settable[0] ) set( st, value, index, session );
-	}
-
-	protected abstract void set(PreparedStatement st, Object value, int index, SessionImplementor session)
-			throws SQLException;
-
-	public void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session)
-			throws HibernateException, SQLException {
-		set( st, value, index, session );
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AbstractLongBinaryType.java b/hibernate-core/src/main/java/org/hibernate/type/AbstractLongBinaryType.java
deleted file mode 100644
index 1c6927fc19..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/AbstractLongBinaryType.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-
-/**
- * An abstract type for mapping long binary SQL types to Java byte[].
- *
- * @author Gail Badner
- *
- * @deprecated Use the {@link AbstractStandardBasicType} approach instead
- */
-public abstract class AbstractLongBinaryType extends AbstractBynaryType {
-
-	public Class getReturnedClass() {
-		return byte[].class;
-	}
-
-	protected Object toExternalFormat(byte[] bytes) {
-		return bytes;
-	}
-
-	protected byte[] toInternalFormat(Object bytes) {
-		return ( byte[] ) bytes;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AbstractLongStringType.java b/hibernate-core/src/main/java/org/hibernate/type/AbstractLongStringType.java
deleted file mode 100644
index 0c4ec658a6..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/AbstractLongStringType.java
+++ /dev/null
@@ -1,94 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-
-import org.hibernate.HibernateException;
-
-/**
- * An abstract type for mapping long string SQL types to a Java String.
- * @author Gavin King, Bertrand Renuart (from TextType)
- *
- * @deprecated Use the {@link AbstractStandardBasicType} approach instead
- */
-public abstract class AbstractLongStringType extends ImmutableType {
-
-	public void set(PreparedStatement st, Object value, int index) throws HibernateException, SQLException {
-		String str = (String) value;
-		st.setCharacterStream( index, new StringReader(str), str.length() );
-	}
-
-	public Object get(ResultSet rs, String name) throws HibernateException, SQLException {
-
-			// Retrieve the value of the designated column in the current row of this
-			// ResultSet object as a java.io.Reader object
-			Reader charReader = rs.getCharacterStream(name);
-
-			// if the corresponding SQL value is NULL, the reader we got is NULL as well
-			if (charReader==null) return null;
-
-			// Fetch Reader content up to the end - and put characters in a StringBuilder
-			StringBuilder sb = new StringBuilder();
-			try {
-				char[] buffer = new char[2048];
-				while (true) {
-					int amountRead = charReader.read(buffer, 0, buffer.length);
-					if ( amountRead == -1 ) break;
-					sb.append(buffer, 0, amountRead);
-				}
-			}
-			catch (IOException ioe) {
-				throw new HibernateException( "IOException occurred reading text", ioe );
-			}
-			finally {
-				try {
-					charReader.close();
-				}
-				catch (IOException e) {
-					throw new HibernateException( "IOException occurred closing stream", e );
-				}
-			}
-
-			// Return StringBuilder content as a large String
-			return sb.toString();
-	}
-
-	public Class getReturnedClass() {
-		return String.class;
-	}
-
-	public String toString(Object val) {
-		return (String) val;
-	}
-	public Object fromStringValue(String xml) {
-		return xml;
-	}
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AbstractStandardBasicType.java b/hibernate-core/src/main/java/org/hibernate/type/AbstractStandardBasicType.java
index 6ec39a6438..88624d31f1 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/AbstractStandardBasicType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/AbstractStandardBasicType.java
@@ -1,412 +1,404 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Map;
 
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.Size;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 import org.hibernate.type.descriptor.java.MutabilityPlan;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 import org.dom4j.Node;
 
 /**
  * Convenience base class for {@link BasicType} implementations
  *
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public abstract class AbstractStandardBasicType<T>
-		implements BasicType, StringRepresentableType<T>, XmlRepresentableType<T>, ProcedureParameterExtractionAware<T> {
+		implements BasicType, StringRepresentableType<T>, ProcedureParameterExtractionAware<T> {
 
 	private static final Size DEFAULT_SIZE = new Size( 19, 2, 255, Size.LobMultiplier.NONE ); // to match legacy behavior
 	private final Size dictatedSize = new Size();
 
 	// Don't use final here.  Need to initialize after-the-fact
 	// by DynamicParameterizedTypes.
 	private SqlTypeDescriptor sqlTypeDescriptor;
 	private JavaTypeDescriptor<T> javaTypeDescriptor;
 	// sqlTypes need always to be in sync with sqlTypeDescriptor
 	private int[] sqlTypes;
 
 	public AbstractStandardBasicType(SqlTypeDescriptor sqlTypeDescriptor, JavaTypeDescriptor<T> javaTypeDescriptor) {
 		this.sqlTypeDescriptor = sqlTypeDescriptor;
 		this.sqlTypes = new int[] { sqlTypeDescriptor.getSqlType() };
 		this.javaTypeDescriptor = javaTypeDescriptor;
 	}
 
 	public T fromString(String string) {
 		return javaTypeDescriptor.fromString( string );
 	}
 
 	public String toString(T value) {
 		return javaTypeDescriptor.toString( value );
 	}
 
 	public T fromStringValue(String xml) throws HibernateException {
 		return fromString( xml );
 	}
 
-	public String toXMLString(T value, SessionFactoryImplementor factory) throws HibernateException {
-		return toString( value );
-	}
-
-	public T fromXMLString(String xml, Mapping factory) throws HibernateException {
-		return StringHelper.isEmpty( xml ) ? null : fromStringValue( xml );
-	}
-
 	protected MutabilityPlan<T> getMutabilityPlan() {
 		return javaTypeDescriptor.getMutabilityPlan();
 	}
 
 	protected T getReplacement(T original, T target, SessionImplementor session) {
 		if ( !isMutable() ) {
 			return original;
 		}
 		else if ( isEqual( original, target ) ) {
 			return original;
 		}
 		else {
 			return deepCopy( original );
 		}
 	}
 
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
 		return value == null ? ArrayHelper.FALSE : ArrayHelper.TRUE;
 	}
 
 	public String[] getRegistrationKeys() {
 		return registerUnderJavaType()
 				? new String[] { getName(), javaTypeDescriptor.getJavaTypeClass().getName() }
 				: new String[] { getName() };
 	}
 
 	protected boolean registerUnderJavaType() {
 		return false;
 	}
 
 	protected static Size getDefaultSize() {
 		return DEFAULT_SIZE;
 	}
 
 	protected Size getDictatedSize() {
 		return dictatedSize;
 	}
 	
 	// final implementations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public final JavaTypeDescriptor<T> getJavaTypeDescriptor() {
 		return javaTypeDescriptor;
 	}
 	
 	public final void setJavaTypeDescriptor( JavaTypeDescriptor<T> javaTypeDescriptor ) {
 		this.javaTypeDescriptor = javaTypeDescriptor;
 	}
 
 	public final SqlTypeDescriptor getSqlTypeDescriptor() {
 		return sqlTypeDescriptor;
 	}
 
 	public final void setSqlTypeDescriptor( SqlTypeDescriptor sqlTypeDescriptor ) {
 		this.sqlTypeDescriptor = sqlTypeDescriptor;
 		this.sqlTypes = new int[] { sqlTypeDescriptor.getSqlType() };
 	}
 
 	public final Class getReturnedClass() {
 		return javaTypeDescriptor.getJavaTypeClass();
 	}
 
 	public final int getColumnSpan(Mapping mapping) throws MappingException {
 		return 1;
 	}
 
 	public final int[] sqlTypes(Mapping mapping) throws MappingException {
 		return sqlTypes;
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		return new Size[] { getDictatedSize() };
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		return new Size[] { getDefaultSize() };
 	}
 
 	public final boolean isAssociationType() {
 		return false;
 	}
 
 	public final boolean isCollectionType() {
 		return false;
 	}
 
 	public final boolean isComponentType() {
 		return false;
 	}
 
 	public final boolean isEntityType() {
 		return false;
 	}
 
 	public final boolean isAnyType() {
 		return false;
 	}
 
 	public final boolean isXMLElement() {
 		return false;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final boolean isSame(Object x, Object y) {
 		return isEqual( x, y );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final boolean isEqual(Object x, Object y, SessionFactoryImplementor factory) {
 		return isEqual( x, y );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final boolean isEqual(Object one, Object another) {
 		return javaTypeDescriptor.areEqual( (T) one, (T) another );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final int getHashCode(Object x) {
 		return javaTypeDescriptor.extractHashCode( (T) x );
 	}
 
 	public final int getHashCode(Object x, SessionFactoryImplementor factory) {
 		return getHashCode( x );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final int compare(Object x, Object y) {
 		return javaTypeDescriptor.getComparator().compare( (T) x, (T) y );
 	}
 
 	public final boolean isDirty(Object old, Object current, SessionImplementor session) {
 		return isDirty( old, current );
 	}
 
 	public final boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session) {
 		return checkable[0] && isDirty( old, current );
 	}
 
 	protected final boolean isDirty(Object old, Object current) {
 		return !isSame( old, current );
 	}
 
 	public final boolean isModified(
 			Object oldHydratedState,
 			Object currentState,
 			boolean[] checkable,
 			SessionImplementor session) {
 		return isDirty( oldHydratedState, currentState );
 	}
 
 	public final Object nullSafeGet(
 			ResultSet rs,
 			String[] names,
 			SessionImplementor session,
 			Object owner) throws SQLException {
 		return nullSafeGet( rs, names[0], session );
 	}
 
 	public final Object nullSafeGet(ResultSet rs, String name, SessionImplementor session, Object owner)
 			throws SQLException {
 		return nullSafeGet( rs, name, session );
 	}
 
 	public final T nullSafeGet(ResultSet rs, String name, final SessionImplementor session) throws SQLException {
 		final WrapperOptions options = getOptions(session);
 		return nullSafeGet( rs, name, options );
 	}
 
 	protected final T nullSafeGet(ResultSet rs, String name, WrapperOptions options) throws SQLException {
 		return remapSqlTypeDescriptor( options ).getExtractor( javaTypeDescriptor ).extract( rs, name, options );
 	}
 
 	public Object get(ResultSet rs, String name, SessionImplementor session) throws HibernateException, SQLException {
 		return nullSafeGet( rs, name, session );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final void nullSafeSet(
 			PreparedStatement st,
 			Object value,
 			int index,
 			final SessionImplementor session) throws SQLException {
 		final WrapperOptions options = getOptions(session);
 		nullSafeSet( st, value, index, options );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected final void nullSafeSet(PreparedStatement st, Object value, int index, WrapperOptions options) throws SQLException {
 		remapSqlTypeDescriptor( options ).getBinder( javaTypeDescriptor ).bind( st, ( T ) value, index, options );
 	}
 
 	protected SqlTypeDescriptor remapSqlTypeDescriptor(WrapperOptions options) {
 		return options.remapSqlTypeDescriptor( sqlTypeDescriptor );
 	}
 
 	public void set(PreparedStatement st, T value, int index, SessionImplementor session) throws HibernateException, SQLException {
 		nullSafeSet( st, value, index, session );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final String toLoggableString(Object value, SessionFactoryImplementor factory) {
 		return javaTypeDescriptor.extractLoggableRepresentation( (T) value );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory) {
 		node.setText( toString( (T) value ) );
 	}
 
 	public final Object fromXMLNode(Node xml, Mapping factory) {
 		return fromString( xml.getText() );
 	}
 
 	public final boolean isMutable() {
 		return getMutabilityPlan().isMutable();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final Object deepCopy(Object value, SessionFactoryImplementor factory) {
 		return deepCopy( (T) value );
 	}
 
 	protected final T deepCopy(T value) {
 		return getMutabilityPlan().deepCopy( value );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final Serializable disassemble(Object value, SessionImplementor session, Object owner) throws HibernateException {
 		return getMutabilityPlan().disassemble( (T) value );
 	}
 
 	public final Object assemble(Serializable cached, SessionImplementor session, Object owner) throws HibernateException {
 		return getMutabilityPlan().assemble( cached );
 	}
 
 	public final void beforeAssemble(Serializable cached, SessionImplementor session) {
 	}
 
 	public final Object hydrate(ResultSet rs, String[] names, SessionImplementor session, Object owner)
 			throws HibernateException, SQLException {
 		return nullSafeGet(rs, names, session, owner);
 	}
 
 	public final Object resolve(Object value, SessionImplementor session, Object owner) throws HibernateException {
 		return value;
 	}
 
 	public final Object semiResolve(Object value, SessionImplementor session, Object owner) throws HibernateException {
 		return value;
 	}
 
 	public final Type getSemiResolvedType(SessionFactoryImplementor factory) {
 		return this;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final Object replace(Object original, Object target, SessionImplementor session, Object owner, Map copyCache) {
 		return getReplacement( (T) original, (T) target, session );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public Object replace(
 			Object original,
 			Object target,
 			SessionImplementor session,
 			Object owner,
 			Map copyCache,
 			ForeignKeyDirection foreignKeyDirection) {
 		return ForeignKeyDirection.FROM_PARENT == foreignKeyDirection
 				? getReplacement( (T) original, (T) target, session )
 				: target;
 	}
 
 	@Override
 	public boolean canDoExtraction() {
 		return true;
 	}
 
 	@Override
 	public T extract(CallableStatement statement, int startIndex, final SessionImplementor session) throws SQLException {
 		final WrapperOptions options = getOptions(session);
 		return remapSqlTypeDescriptor( options ).getExtractor( javaTypeDescriptor ).extract(
 				statement,
 				startIndex,
 				options
 		);
 	}
 
 	@Override
 	public T extract(CallableStatement statement, String[] paramNames, final SessionImplementor session) throws SQLException {
 		final WrapperOptions options = getOptions(session);
 		return remapSqlTypeDescriptor( options ).getExtractor( javaTypeDescriptor ).extract( statement, paramNames, options );
 	}
 	
 	// TODO : have SessionImplementor extend WrapperOptions
 	private WrapperOptions getOptions(final SessionImplementor session) {
 		return new WrapperOptions() {
 			public boolean useStreamForLobBinding() {
 				return Environment.useStreamsForBinary()
 						|| session.getFactory().getDialect().useInputStreamToInsertBlob();
 			}
 
 			public LobCreator getLobCreator() {
 				return Hibernate.getLobCreator( session );
 			}
 
 			public SqlTypeDescriptor remapSqlTypeDescriptor(SqlTypeDescriptor sqlTypeDescriptor) {
 				final SqlTypeDescriptor remapped = sqlTypeDescriptor.canBeRemapped()
 						? session.getFactory().getDialect().remapSqlTypeDescriptor( sqlTypeDescriptor )
 						: sqlTypeDescriptor;
 				return remapped == null ? sqlTypeDescriptor : remapped;
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/ArrayType.java b/hibernate-core/src/main/java/org/hibernate/type/ArrayType.java
index 893518f3c4..d890b771a7 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/ArrayType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/ArrayType.java
@@ -1,154 +1,156 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.lang.reflect.Array;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.collection.internal.PersistentArrayHolder;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 
 /**
  * A type for persistent arrays.
  * @author Gavin King
  */
 public class ArrayType extends CollectionType {
 
 	private final Class elementClass;
 	private final Class arrayClass;
 
 	/**
 	 * @deprecated Use {@link #ArrayType(TypeFactory.TypeScope, String, String, Class )} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public ArrayType(TypeFactory.TypeScope typeScope, String role, String propertyRef, Class elementClass, boolean isEmbeddedInXML) {
 		super( typeScope, role, propertyRef, isEmbeddedInXML );
 		this.elementClass = elementClass;
 		arrayClass = Array.newInstance(elementClass, 0).getClass();
 	}
 
 	public ArrayType(TypeFactory.TypeScope typeScope, String role, String propertyRef, Class elementClass) {
 		super( typeScope, role, propertyRef );
 		this.elementClass = elementClass;
 		arrayClass = Array.newInstance(elementClass, 0).getClass();
 	}
 
 	public Class getReturnedClass() {
 		return arrayClass;
 	}
 
 	public PersistentCollection instantiate(SessionImplementor session, CollectionPersister persister, Serializable key)
 	throws HibernateException {
 		return new PersistentArrayHolder(session, persister);
 	}
 
 	/**
 	 * Not defined for collections of primitive type
 	 */
 	public Iterator getElementsIterator(Object collection) {
 		return Arrays.asList( (Object[]) collection ).iterator();
 	}
 
 	public PersistentCollection wrap(SessionImplementor session, Object array) {
 		return new PersistentArrayHolder(session, array);
 	}
 
 	public boolean isArrayType() {
 		return true;
 	}
 
 	public String toLoggableString(Object value, SessionFactoryImplementor factory) throws HibernateException {
 		if ( value == null ) {
 			return "null";
 		}
 		int length = Array.getLength(value);
 		List list = new ArrayList(length);
 		Type elemType = getElementType(factory);
 		for ( int i=0; i<length; i++ ) {
 			list.add( elemType.toLoggableString( Array.get(value, i), factory ) );
 		}
 		return list.toString();
 	}
 	
 	public Object instantiateResult(Object original) {
 		return Array.newInstance( elementClass, Array.getLength(original) );
 	}
 
 	public Object replaceElements(
 		Object original,
 		Object target,
 		Object owner, 
 		Map copyCache, 
 		SessionImplementor session)
 	throws HibernateException {
 		
 		int length = Array.getLength(original);
 		if ( length!=Array.getLength(target) ) {
 			//note: this affects the return value!
 			target=instantiateResult(original);
 		}
 		
 		Type elemType = getElementType( session.getFactory() );
 		for ( int i=0; i<length; i++ ) {
 			Array.set( target, i, elemType.replace( Array.get(original, i), null, session, owner, copyCache ) );
 		}
 		
 		return target;
 	
 	}
 
 	public Object instantiate(int anticipatedSize) {
 		throw new UnsupportedOperationException();
 	}
 
 	public Object indexOf(Object array, Object element) {
 		int length = Array.getLength(array);
 		for ( int i=0; i<length; i++ ) {
 			//TODO: proxies!
-			if ( Array.get(array, i)==element ) return i;
+			if ( Array.get(array, i)==element ) {
+				return i;
+			}
 		}
 		return null;
 	}
 
 	@Override
 	protected boolean initializeImmediately() {
 		return true;
 	}
 
 	@Override
 	public boolean hasHolder() {
 		return true;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java b/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
index c2d5859c5a..1ffafd539b 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
@@ -1,170 +1,174 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import org.hibernate.HibernateException;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
 import org.jboss.logging.Logger;
 
 import java.io.Serializable;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
 /**
  * A registry of {@link BasicType} instances
  *
  * @author Steve Ebersole
  */
 public class BasicTypeRegistry implements Serializable {
     private static final CoreMessageLogger LOG = CoreLogging.messageLogger( BasicTypeRegistry.class );
 
 	// TODO : analyze these sizing params; unfortunately this seems to be the only way to give a "concurrencyLevel"
 	private Map<String,BasicType> registry = new ConcurrentHashMap<String, BasicType>( 100, .75f, 1 );
 	private boolean locked;
 
 	public BasicTypeRegistry() {
 		register( BooleanType.INSTANCE );
 		register( NumericBooleanType.INSTANCE );
 		register( TrueFalseType.INSTANCE );
 		register( YesNoType.INSTANCE );
 
 		register( ByteType.INSTANCE );
 		register( CharacterType.INSTANCE );
 		register( ShortType.INSTANCE );
 		register( IntegerType.INSTANCE );
 		register( LongType.INSTANCE );
 		register( FloatType.INSTANCE );
 		register( DoubleType.INSTANCE );
 		register( BigDecimalType.INSTANCE );
 		register( BigIntegerType.INSTANCE );
 
 		register( StringType.INSTANCE );
 		register( StringNVarcharType.INSTANCE );
 		register( CharacterNCharType.INSTANCE );
 		register( UrlType.INSTANCE );
 
 		register( DateType.INSTANCE );
 		register( TimeType.INSTANCE );
 		register( TimestampType.INSTANCE );
 		register( DbTimestampType.INSTANCE );
 		register( CalendarType.INSTANCE );
 		register( CalendarDateType.INSTANCE );
 
 		register( LocaleType.INSTANCE );
 		register( CurrencyType.INSTANCE );
 		register( TimeZoneType.INSTANCE );
 		register( ClassType.INSTANCE );
 		register( UUIDBinaryType.INSTANCE );
 		register( UUIDCharType.INSTANCE );
 
 		register( BinaryType.INSTANCE );
 		register( WrapperBinaryType.INSTANCE );
 		register( ImageType.INSTANCE );
 		register( CharArrayType.INSTANCE );
 		register( CharacterArrayType.INSTANCE );
 		register( TextType.INSTANCE );
 		register( NTextType.INSTANCE );
 		register( BlobType.INSTANCE );
 		register( MaterializedBlobType.INSTANCE );
 		register( ClobType.INSTANCE );
 		register( NClobType.INSTANCE );
 		register( MaterializedClobType.INSTANCE );
 		register( MaterializedNClobType.INSTANCE );
 		register( SerializableType.INSTANCE );
 
 		register( ObjectType.INSTANCE );
 
 		//noinspection unchecked
 		register( new AdaptedImmutableType( DateType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( TimeType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( TimestampType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( DbTimestampType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( CalendarType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( CalendarDateType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( BinaryType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( SerializableType.INSTANCE ) );
 	}
 
 	/**
 	 * Constructor version used during shallow copy
 	 *
 	 * @param registeredTypes The type map to copy over
 	 */
 	@SuppressWarnings({ "UnusedDeclaration" })
 	private BasicTypeRegistry(Map<String, BasicType> registeredTypes) {
 		registry.putAll( registeredTypes );
 		locked = true;
 	}
 
 	public void register(BasicType type) {
 		if ( locked ) {
 			throw new HibernateException( "Can not alter TypeRegistry at this time" );
 		}
 
 		if ( type == null ) {
 			throw new HibernateException( "Type to register cannot be null" );
 		}
 
 		if ( type.getRegistrationKeys() == null || type.getRegistrationKeys().length == 0 ) {
 			LOG.typeDefinedNoRegistrationKeys( type );
 		}
 
 		for ( String key : type.getRegistrationKeys() ) {
 			// be safe...
-            if (key == null) continue;
+            if (key == null) {
+				continue;
+			}
             LOG.debugf("Adding type registration %s -> %s", key, type);
 			final Type old = registry.put( key, type );
-            if (old != null && old != type) LOG.typeRegistrationOverridesPrevious(key, old);
+            if (old != null && old != type) {
+				LOG.typeRegistrationOverridesPrevious(key, old);
+			}
 		}
 	}
 
 	public void register(UserType type, String[] keys) {
 		register( new CustomType( type, keys ) );
 	}
 
 	public void register(CompositeUserType type, String[] keys) {
 		register( new CompositeCustomType( type, keys ) );
 	}
 
 	public BasicType getRegisteredType(String key) {
 		return registry.get( key );
 	}
 
 	public BasicTypeRegistry shallowCopy() {
 		return new BasicTypeRegistry( this.registry );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/ByteArrayBlobType.java b/hibernate-core/src/main/java/org/hibernate/type/ByteArrayBlobType.java
deleted file mode 100644
index d404591db2..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/ByteArrayBlobType.java
+++ /dev/null
@@ -1,219 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-import java.io.ByteArrayInputStream;
-import java.sql.Blob;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.sql.Types;
-import java.util.Map;
-
-import org.hibernate.Hibernate;
-import org.hibernate.HibernateException;
-import org.hibernate.engine.spi.Mapping;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.internal.util.collections.ArrayHelper;
-
-import org.dom4j.Node;
-
-/**
- * Map a Byte[] into a Blob
- * Experimental
- *
- * @author Emmanuel Bernard
- * @deprecated replaced by {@link org.hibernate.type.WrappedMaterializedBlobType}
- */
-@Deprecated
-public class ByteArrayBlobType extends AbstractLobType {
-	private static final int[] TYPES = new int[] { Types.BLOB };
-
-	public int[] sqlTypes(Mapping mapping) {
-		return TYPES;
-	}
-
-	@Override
-	public boolean isEqual(Object x, Object y, SessionFactoryImplementor factory) {
-		if ( x == y ) return true;
-		if ( x == null || y == null ) return false;
-		if ( x instanceof Byte[] ) {
-			Object[] o1 = (Object[]) x;
-			Object[] o2 = (Object[]) y;
-			return ArrayHelper.isEquals( o1, o2 );
-		}
-		else {
-			byte[] c1 = (byte[]) x;
-			byte[] c2 = (byte[]) y;
-			return ArrayHelper.isEquals( c1, c2 );
-		}
-	}
-
-	public int getHashCode(Object x, SessionFactoryImplementor factory) {
-		if ( x instanceof Character[] ) {
-			Object[] o = (Object[]) x;
-			return ArrayHelper.hash( o );
-		}
-		else {
-			byte[] c = (byte[]) x;
-			return ArrayHelper.hash( c );
-		}
-	}
-
-	public Object deepCopy(Object value, SessionFactoryImplementor factory)
-			throws HibernateException {
-		if ( value == null ) return null;
-		if ( value instanceof Byte[] ) {
-			Byte[] array = (Byte[]) value;
-			int length = array.length;
-			Byte[] copy = new Byte[length];
-			for ( int index = 0; index < length ; index++ ) {
-				copy[index] = Byte.valueOf( array[index].byteValue() );
-			}
-			return copy;
-		}
-		else {
-			byte[] array = (byte[]) value;
-			int length = array.length;
-			byte[] copy = new byte[length];
-			System.arraycopy( array, 0, copy, 0, length );
-			return copy;
-		}
-	}
-
-	public Class getReturnedClass() {
-		return Byte[].class;
-	}
-
-	protected Object get(ResultSet rs, String name) throws SQLException {
-		Blob blob = rs.getBlob( name );
-		if ( rs.wasNull() ) return null;
-		int length = (int) blob.length();
-		byte[] primaryResult = blob.getBytes( 1, length );
-		return wrap( primaryResult );
-	}
-
-	protected void set(PreparedStatement st, Object value, int index, SessionImplementor session) throws SQLException {
-		if ( value == null ) {
-			st.setNull( index, sqlTypes( null )[0] );
-		}
-		else {
-			byte[] toSet = unWrap( value );
-			final boolean useInputStream = session.getFactory().getDialect().useInputStreamToInsertBlob();
-
-			if ( useInputStream ) {
-				st.setBinaryStream( index, new ByteArrayInputStream( toSet ), toSet.length );
-			}
-			else {
-				st.setBlob( index, Hibernate.getLobCreator( session ).createBlob( toSet ) );
-			}
-		}
-	}
-
-	public void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory) throws HibernateException {
-		node.setText( toString( value ) );
-	}
-
-	public String toString(Object val) {
-		byte[] bytes = unWrap( val );
-		StringBuilder buf = new StringBuilder( 2 * bytes.length );
-		for ( int i = 0; i < bytes.length ; i++ ) {
-			String hexStr = Integer.toHexString( bytes[i] - Byte.MIN_VALUE );
-			if ( hexStr.length() == 1 ) buf.append( '0' );
-			buf.append( hexStr );
-		}
-		return buf.toString();
-	}
-
-	public String toLoggableString(Object value, SessionFactoryImplementor factory) {
-		return value == null ? "null" : toString( value );
-	}
-
-	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
-		String xmlText = xml.getText();
-		return xmlText == null || xmlText.length() == 0 ? null : fromString( xmlText );
-	}
-
-	private Object fromString(String xmlText) {
-		if ( xmlText == null ) {
-			return null;
-		}
-		if ( xmlText.length() % 2 != 0 ) {
-			throw new IllegalArgumentException( "The string is not a valid xml representation of a binary content." );
-		}
-		byte[] bytes = new byte[xmlText.length() / 2];
-		for ( int i = 0; i < bytes.length ; i++ ) {
-			String hexStr = xmlText.substring( i * 2, ( i + 1 ) * 2 );
-			bytes[i] = (byte) ( Integer.parseInt( hexStr, 16 ) + Byte.MIN_VALUE );
-		}
-		return wrap( bytes );
-	}
-
-	protected Object wrap(byte[] bytes) {
-		return wrapPrimitive( bytes );
-	}
-
-	protected byte[] unWrap(Object bytes) {
-		return unwrapNonPrimitive( (Byte[]) bytes );
-	}
-
-	private byte[] unwrapNonPrimitive(Byte[] bytes) {
-		int length = bytes.length;
-		byte[] result = new byte[length];
-		for ( int i = 0; i < length ; i++ ) {
-			result[i] = bytes[i].byteValue();
-		}
-		return result;
-	}
-
-	private Byte[] wrapPrimitive(byte[] bytes) {
-		int length = bytes.length;
-		Byte[] result = new Byte[length];
-		for ( int index = 0; index < length ; index++ ) {
-			result[index] = Byte.valueOf( bytes[index] );
-		}
-		return result;
-	}
-
-	public boolean isMutable() {
-		return true;
-	}
-
-	public Object replace(
-			Object original,
-			Object target,
-			SessionImplementor session,
-			Object owner,
-			Map copyCache
-	)
-			throws HibernateException {
-		if ( isEqual( original, target ) ) return original;
-		return deepCopy( original, session.getFactory() );
-	}
-
-	public boolean[] toColumnNullness(Object value, Mapping mapping) {
-		return value == null ? ArrayHelper.FALSE : ArrayHelper.TRUE;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/CharBooleanType.java b/hibernate-core/src/main/java/org/hibernate/type/CharBooleanType.java
deleted file mode 100644
index a50de62c14..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/CharBooleanType.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-import org.hibernate.type.descriptor.java.BooleanTypeDescriptor;
-import org.hibernate.type.descriptor.sql.CharTypeDescriptor;
-
-/**
- * Superclass for types that map Java boolean to SQL CHAR(1).
- *
- * @author Gavin King
- *
- * @deprecated Use the {@link AbstractStandardBasicType} approach instead
- */
-public abstract class CharBooleanType extends BooleanType {
-	private final String stringValueTrue;
-	private final String stringValueFalse;
-
-	protected CharBooleanType(char characterValueTrue, char characterValueFalse) {
-		super( CharTypeDescriptor.INSTANCE, new BooleanTypeDescriptor( characterValueTrue, characterValueFalse ) );
-
-		stringValueTrue = String.valueOf( characterValueTrue );
-		stringValueFalse = String.valueOf( characterValueFalse );
-	}
-
-	/**
-	 * @deprecated Pass the true/false values into constructor instead.
-	 */
-	protected final String getTrueString() {
-		return stringValueTrue;
-	}
-
-	/**
-	 * @deprecated Pass the true/false values into constructor instead.
-	 */
-	protected final String getFalseString() {
-		return stringValueFalse;
-	}
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/CollectionType.java b/hibernate-core/src/main/java/org/hibernate/type/CollectionType.java
index 073e81f25d..6ce45fb7e8 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/CollectionType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/CollectionType.java
@@ -1,843 +1,850 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.SortedMap;
 import java.util.TreeMap;
 
 import org.hibernate.EntityMode;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.Size;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.CollectionKey;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 
 import org.jboss.logging.Logger;
 
 import org.dom4j.Element;
 import org.dom4j.Node;
 
 /**
  * A type that handles Hibernate <tt>PersistentCollection</tt>s (including arrays).
  * 
  * @author Gavin King
  */
 public abstract class CollectionType extends AbstractType implements AssociationType {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CollectionType.class.getName());
 
 	private static final Object NOT_NULL_COLLECTION = new MarkerObject( "NOT NULL COLLECTION" );
 	public static final Object UNFETCHED_COLLECTION = new MarkerObject( "UNFETCHED COLLECTION" );
 
 	private final TypeFactory.TypeScope typeScope;
 	private final String role;
 	private final String foreignKeyPropertyName;
 	private final boolean isEmbeddedInXML;
 
 	/**
 	 * @deprecated Use {@link #CollectionType(TypeFactory.TypeScope, String, String)} instead
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType(TypeFactory.TypeScope typeScope, String role, String foreignKeyPropertyName, boolean isEmbeddedInXML) {
 		this.typeScope = typeScope;
 		this.role = role;
 		this.foreignKeyPropertyName = foreignKeyPropertyName;
 		this.isEmbeddedInXML = isEmbeddedInXML;
 	}
 
 	public CollectionType(TypeFactory.TypeScope typeScope, String role, String foreignKeyPropertyName) {
 		this.typeScope = typeScope;
 		this.role = role;
 		this.foreignKeyPropertyName = foreignKeyPropertyName;
 		this.isEmbeddedInXML = true;
 	}
 
 	@Override
 	public boolean isEmbeddedInXML() {
 		return isEmbeddedInXML;
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public Object indexOf(Object collection, Object element) {
 		throw new UnsupportedOperationException( "generic collections don't have indexes" );
 	}
 
 	public boolean contains(Object collection, Object childObject, SessionImplementor session) {
 		// we do not have to worry about queued additions to uninitialized
 		// collections, since they can only occur for inverse collections!
 		Iterator elems = getElementsIterator( collection, session );
 		while ( elems.hasNext() ) {
 			Object element = elems.next();
 			// worrying about proxies is perhaps a little bit of overkill here...
 			if ( element instanceof HibernateProxy ) {
 				LazyInitializer li = ( (HibernateProxy) element ).getHibernateLazyInitializer();
-				if ( !li.isUninitialized() ) element = li.getImplementation();
+				if ( !li.isUninitialized() ) {
+					element = li.getImplementation();
+				}
+			}
+			if ( element == childObject ) {
+				return true;
 			}
-			if ( element == childObject ) return true;
 		}
 		return false;
 	}
 
 	@Override
 	public boolean isCollectionType() {
 		return true;
 	}
 
 	@Override
 	public final boolean isEqual(Object x, Object y) {
 		return x == y
 			|| ( x instanceof PersistentCollection && ( (PersistentCollection) x ).isWrapper( y ) )
 			|| ( y instanceof PersistentCollection && ( (PersistentCollection) y ).isWrapper( x ) );
 	}
 
 	@Override
 	public int compare(Object x, Object y) {
 		return 0; // collections cannot be compared
 	}
 
 	@Override
 	public int getHashCode(Object x) {
 		throw new UnsupportedOperationException( "cannot doAfterTransactionCompletion lookups on collections" );
 	}
 
 	/**
 	 * Instantiate an uninitialized collection wrapper or holder. Callers MUST add the holder to the
 	 * persistence context!
 	 *
 	 * @param session The session from which the request is originating.
 	 * @param persister The underlying collection persister (metadata)
 	 * @param key The owner key.
 	 * @return The instantiated collection.
 	 */
 	public abstract PersistentCollection instantiate(SessionImplementor session, CollectionPersister persister, Serializable key);
 
 	@Override
 	public Object nullSafeGet(ResultSet rs, String name, SessionImplementor session, Object owner) throws SQLException {
-		return nullSafeGet( rs, new String[] { name }, session, owner );
+		return nullSafeGet( rs, new String[] {name}, session, owner );
 	}
 
 	@Override
 	public Object nullSafeGet(ResultSet rs, String[] name, SessionImplementor session, Object owner)
 			throws HibernateException, SQLException {
 		return resolve( null, session, owner );
 	}
 
 	@Override
 	public final void nullSafeSet(PreparedStatement st, Object value, int index, boolean[] settable,
 			SessionImplementor session) throws HibernateException, SQLException {
 		//NOOP
 	}
 
 	@Override
 	public void nullSafeSet(PreparedStatement st, Object value, int index,
 			SessionImplementor session) throws HibernateException, SQLException {
 	}
 
 	@Override
 	public int[] sqlTypes(Mapping session) throws MappingException {
 		return ArrayHelper.EMPTY_INT_ARRAY;
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		return new Size[] { LEGACY_DICTATED_SIZE };
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		return new Size[] { LEGACY_DEFAULT_SIZE };
 	}
 
 	@Override
 	public int getColumnSpan(Mapping session) throws MappingException {
 		return 0;
 	}
 
 	@Override
 	public String toLoggableString(Object value, SessionFactoryImplementor factory)
 			throws HibernateException {
 		if ( value == null ) {
 			return "null";
 		}
 		else if ( !Hibernate.isInitialized( value ) ) {
 			return "<uninitialized>";
 		}
 		else {
 			return renderLoggableString( value, factory );
 		}
 	}
 
 	protected String renderLoggableString(Object value, SessionFactoryImplementor factory) throws HibernateException {
 		final List<String> list = new ArrayList<String>();
 		Type elemType = getElementType( factory );
 		Iterator itr = getElementsIterator( value );
 		while ( itr.hasNext() ) {
 			list.add( elemType.toLoggableString( itr.next(), factory ) );
 		}
 		return list.toString();
 	}
 
 	@Override
 	public Object deepCopy(Object value, SessionFactoryImplementor factory)
 			throws HibernateException {
 		return value;
 	}
 
 	@Override
 	public String getName() {
 		return getReturnedClass().getName() + '(' + getRole() + ')';
 	}
 
 	/**
 	 * Get an iterator over the element set of the collection, which may not yet be wrapped
 	 *
 	 * @param collection The collection to be iterated
 	 * @param session The session from which the request is originating.
 	 * @return The iterator.
 	 */
 	public Iterator getElementsIterator(Object collection, SessionImplementor session) {
-		return getElementsIterator(collection);
+		return getElementsIterator( collection );
 	}
 
 	/**
 	 * Get an iterator over the element set of the collection in POJO mode
 	 *
 	 * @param collection The collection to be iterated
 	 * @return The iterator.
 	 */
 	protected Iterator getElementsIterator(Object collection) {
 		return ( (Collection) collection ).iterator();
 	}
 
 	@Override
 	public boolean isMutable() {
 		return false;
 	}
 
 	@Override
 	public Serializable disassemble(Object value, SessionImplementor session, Object owner)
 			throws HibernateException {
 		//remember the uk value
 		
 		//This solution would allow us to eliminate the owner arg to disassemble(), but
 		//what if the collection was null, and then later had elements added? seems unsafe
 		//session.getPersistenceContext().getCollectionEntry( (PersistentCollection) value ).getKey();
 		
 		final Serializable key = getKeyOfOwner(owner, session);
 		if (key==null) {
 			return null;
 		}
 		else {
 			return getPersister(session)
 					.getKeyType()
 					.disassemble( key, session, owner );
 		}
 	}
 
 	@Override
 	public Object assemble(Serializable cached, SessionImplementor session, Object owner)
 			throws HibernateException {
 		//we must use the "remembered" uk value, since it is 
 		//not available from the EntityEntry during assembly
 		if (cached==null) {
 			return null;
 		}
 		else {
 			final Serializable key = (Serializable) getPersister(session)
 					.getKeyType()
 					.assemble( cached, session, owner);
 			return resolveKey( key, session, owner );
 		}
 	}
 
 	/**
 	 * Is the owning entity versioned?
 	 *
 	 * @param session The session from which the request is originating.
 	 * @return True if the collection owner is versioned; false otherwise.
 	 * @throws org.hibernate.MappingException Indicates our persister could not be located.
 	 */
 	private boolean isOwnerVersioned(SessionImplementor session) throws MappingException {
 		return getPersister( session ).getOwnerEntityPersister().isVersioned();
 	}
 
 	/**
 	 * Get our underlying collection persister (using the session to access the
 	 * factory).
 	 *
 	 * @param session The session from which the request is originating.
 	 * @return The underlying collection persister
 	 */
 	private CollectionPersister getPersister(SessionImplementor session) {
 		return session.getFactory().getCollectionPersister( role );
 	}
 
 	@Override
 	public boolean isDirty(Object old, Object current, SessionImplementor session)
 			throws HibernateException {
 
 		// collections don't dirty an unversioned parent entity
 
 		// TODO: I don't really like this implementation; it would be better if
 		// this was handled by searchForDirtyCollections()
 		return isOwnerVersioned( session ) && super.isDirty( old, current, session );
 		// return false;
 
 	}
 
 	@Override
 	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session)
 			throws HibernateException {
 		return isDirty(old, current, session);
 	}
 
 	/**
 	 * Wrap the naked collection instance in a wrapper, or instantiate a
 	 * holder. Callers <b>MUST</b> add the holder to the persistence context!
 	 *
 	 * @param session The session from which the request is originating.
 	 * @param collection The bare collection to be wrapped.
 	 * @return The wrapped collection.
 	 */
 	public abstract PersistentCollection wrap(SessionImplementor session, Object collection);
 
 	/**
 	 * Note: return true because this type is castable to <tt>AssociationType</tt>. Not because
 	 * all collections are associations.
 	 */
 	@Override
 	public boolean isAssociationType() {
 		return true;
 	}
 
 	@Override
 	public ForeignKeyDirection getForeignKeyDirection() {
 		return ForeignKeyDirection.TO_PARENT;
 	}
 
 	/**
 	 * Get the key value from the owning entity instance, usually the identifier, but might be some
 	 * other unique key, in the case of property-ref
 	 *
 	 * @param owner The collection owner
 	 * @param session The session from which the request is originating.
 	 * @return The collection owner's key
 	 */
 	public Serializable getKeyOfOwner(Object owner, SessionImplementor session) {
 		
 		EntityEntry entityEntry = session.getPersistenceContext().getEntry( owner );
-		if ( entityEntry == null ) return null; // This just handles a particular case of component
-									  // projection, perhaps get rid of it and throw an exception
+		if ( entityEntry == null ) {
+			// This just handles a particular case of component
+			// projection, perhaps get rid of it and throw an exception
+			return null;
+		}
 		
 		if ( foreignKeyPropertyName == null ) {
 			return entityEntry.getId();
 		}
 		else {
 			// TODO: at the point where we are resolving collection references, we don't
 			// know if the uk value has been resolved (depends if it was earlier or
 			// later in the mapping document) - now, we could try and use e.getStatus()
 			// to decide to semiResolve(), trouble is that initializeEntity() reuses
 			// the same array for resolved and hydrated values
 			Object id;
 			if ( entityEntry.getLoadedState() != null ) {
 				id = entityEntry.getLoadedValue( foreignKeyPropertyName );
 			}
 			else {
 				id = entityEntry.getPersister().getPropertyValue( owner, foreignKeyPropertyName );
 			}
 
 			// NOTE VERY HACKISH WORKAROUND!!
 			// TODO: Fix this so it will work for non-POJO entity mode
 			Type keyType = getPersister( session ).getKeyType();
 			if ( !keyType.getReturnedClass().isInstance( id ) ) {
 				id = keyType.semiResolve(
 						entityEntry.getLoadedValue( foreignKeyPropertyName ),
 						session,
 						owner 
-					);
+				);
 			}
 
 			return (Serializable) id;
 		}
 	}
 
 	/**
 	 * Get the id value from the owning entity key, usually the same as the key, but might be some
 	 * other property, in the case of property-ref
 	 *
 	 * @param key The collection owner key
 	 * @param session The session from which the request is originating.
 	 * @return The collection owner's id, if it can be obtained from the key;
 	 * otherwise, null is returned
 	 */
 	public Serializable getIdOfOwnerOrNull(Serializable key, SessionImplementor session) {
 		Serializable ownerId = null;
 		if ( foreignKeyPropertyName == null ) {
 			ownerId = key;
 		}
 		else {
 			Type keyType = getPersister( session ).getKeyType();
 			EntityPersister ownerPersister = getPersister( session ).getOwnerEntityPersister();
 			// TODO: Fix this so it will work for non-POJO entity mode
 			Class ownerMappedClass = ownerPersister.getMappedClass();
 			if ( ownerMappedClass.isAssignableFrom( keyType.getReturnedClass() ) &&
 					keyType.getReturnedClass().isInstance( key ) ) {
 				// the key is the owning entity itself, so get the ID from the key
 				ownerId = ownerPersister.getIdentifier( key, session );
 			}
 			else {
 				// TODO: check if key contains the owner ID
 			}
 		}
 		return ownerId;
 	}
 
 	@Override
 	public Object hydrate(ResultSet rs, String[] name, SessionImplementor session, Object owner) {
 		// can't just return null here, since that would
 		// cause an owning component to become null
 		return NOT_NULL_COLLECTION;
 	}
 
 	@Override
 	public Object resolve(Object value, SessionImplementor session, Object owner)
 			throws HibernateException {
 		
 		return resolveKey( getKeyOfOwner( owner, session ), session, owner );
 	}
 	
 	private Object resolveKey(Serializable key, SessionImplementor session, Object owner) {
 		// if (key==null) throw new AssertionFailure("owner identifier unknown when re-assembling
 		// collection reference");
 		return key == null ? null : // TODO: can this case really occur??
 			getCollection( key, session, owner );
 	}
 
 	@Override
 	public Object semiResolve(Object value, SessionImplementor session, Object owner)
 			throws HibernateException {
 		throw new UnsupportedOperationException(
 			"collection mappings may not form part of a property-ref" );
 	}
 
 	public boolean isArrayType() {
 		return false;
 	}
 
 	@Override
 	public boolean useLHSPrimaryKey() {
 		return foreignKeyPropertyName == null;
 	}
 
 	@Override
 	public String getRHSUniqueKeyPropertyName() {
 		return null;
 	}
 
 	@Override
 	public Joinable getAssociatedJoinable(SessionFactoryImplementor factory)
 			throws MappingException {
 		return (Joinable) factory.getCollectionPersister( role );
 	}
 
 	@Override
 	public boolean isModified(Object old, Object current, boolean[] checkable, SessionImplementor session) throws HibernateException {
 		return false;
 	}
 
 	@Override
 	public String getAssociatedEntityName(SessionFactoryImplementor factory)
 			throws MappingException {
 		try {
 			
 			QueryableCollection collectionPersister = (QueryableCollection) factory
 					.getCollectionPersister( role );
 			
 			if ( !collectionPersister.getElementType().isEntityType() ) {
 				throw new MappingException( 
 						"collection was not an association: " + 
 						collectionPersister.getRole() 
-					);
+				);
 			}
 			
 			return collectionPersister.getElementPersister().getEntityName();
 			
 		}
 		catch (ClassCastException cce) {
 			throw new MappingException( "collection role is not queryable " + role );
 		}
 	}
 
 	/**
 	 * Replace the elements of a collection with the elements of another collection.
 	 *
 	 * @param original The 'source' of the replacement elements (where we copy from)
 	 * @param target The target of the replacement elements (where we copy to)
 	 * @param owner The owner of the collection being merged
 	 * @param copyCache The map of elements already replaced.
 	 * @param session The session from which the merge event originated.
 	 * @return The merged collection.
 	 */
 	public Object replaceElements(
 			Object original,
 			Object target,
 			Object owner,
 			Map copyCache,
 			SessionImplementor session) {
 		// TODO: does not work for EntityMode.DOM4J yet!
 		java.util.Collection result = ( java.util.Collection ) target;
 		result.clear();
 
 		// copy elements into newly empty target collection
 		Type elemType = getElementType( session.getFactory() );
 		Iterator iter = ( (java.util.Collection) original ).iterator();
 		while ( iter.hasNext() ) {
 			result.add( elemType.replace( iter.next(), null, session, owner, copyCache ) );
 		}
 
 		// if the original is a PersistentCollection, and that original
 		// was not flagged as dirty, then reset the target's dirty flag
 		// here after the copy operation.
 		// </p>
 		// One thing to be careful of here is a "bare" original collection
 		// in which case we should never ever ever reset the dirty flag
 		// on the target because we simply do not know...
 		if ( original instanceof PersistentCollection ) {
 			if ( result instanceof PersistentCollection ) {
 				final PersistentCollection originalPersistentCollection = (PersistentCollection) original;
 				final PersistentCollection resultPersistentCollection = (PersistentCollection) result;
 
 				preserveSnapshot( originalPersistentCollection, resultPersistentCollection, elemType, owner, copyCache, session );
 
 				if ( ! originalPersistentCollection.isDirty() ) {
 					resultPersistentCollection.clearDirty();
 				}
 			}
 		}
 
 		return result;
 	}
 
 	private void preserveSnapshot(
 			PersistentCollection original,
 			PersistentCollection result,
 			Type elemType,
 			Object owner,
 			Map copyCache,
 			SessionImplementor session) {
 		Serializable originalSnapshot = original.getStoredSnapshot();
 		Serializable resultSnapshot = result.getStoredSnapshot();
 		Serializable targetSnapshot;
 
 		if ( originalSnapshot instanceof List ) {
 			targetSnapshot = new ArrayList(
 					( (List) originalSnapshot ).size() );
 			for ( Object obj : (List) originalSnapshot ) {
 				( (List) targetSnapshot ).add( elemType.replace( obj, null, session, owner, copyCache ) );
 			}
 
 		}
 		else if ( originalSnapshot instanceof Map ) {
 			if ( originalSnapshot instanceof SortedMap ) {
 				targetSnapshot = new TreeMap( ( (SortedMap) originalSnapshot ).comparator() );
 			}
 			else {
 				targetSnapshot = new HashMap(
 						CollectionHelper.determineProperSizing( ( (Map) originalSnapshot ).size() ),
 						CollectionHelper.LOAD_FACTOR
 				);
 			}
 
 			for ( Map.Entry<Object, Object> entry : ( (Map<Object, Object>) originalSnapshot ).entrySet() ) {
 				Object key = entry.getKey();
 				Object value = entry.getValue();
 				Object resultSnapshotValue = ( resultSnapshot == null )
 						? null
 						: ( (Map<Object, Object>) resultSnapshot ).get( key );
 
 				Object newValue = elemType.replace( value, resultSnapshotValue, session, owner, copyCache );
 
 				if ( key == value ) {
 					( (Map) targetSnapshot ).put( newValue, newValue );
 
 				}
 				else {
 					( (Map) targetSnapshot ).put( key, newValue );
 				}
 
 			}
 
 		}
 		else if ( originalSnapshot instanceof Object[] ) {
 			Object[] arr = (Object[]) originalSnapshot;
 			for ( int i = 0; i < arr.length; i++ ) {
 				arr[i] = elemType.replace( arr[i], null, session, owner, copyCache );
 			}
 			targetSnapshot = originalSnapshot;
 
 		}
 		else {
 			// retain the same snapshot
 			targetSnapshot = resultSnapshot;
 
 		}
 
 		CollectionEntry ce = session.getPersistenceContext().getCollectionEntry( result );
 		if ( ce != null ) {
 			ce.resetStoredSnapshot( result, targetSnapshot );
 		}
 
 	}
 
 	/**
 	 * Instantiate a new "underlying" collection exhibiting the same capacity
 	 * charactersitcs and the passed "original".
 	 *
 	 * @param original The original collection.
 	 * @return The newly instantiated collection.
 	 */
 	protected Object instantiateResult(Object original) {
 		// by default just use an unanticipated capacity since we don't
 		// know how to extract the capacity to use from original here...
 		return instantiate( -1 );
 	}
 
 	/**
 	 * Instantiate an empty instance of the "underlying" collection (not a wrapper),
 	 * but with the given anticipated size (i.e. accounting for initial capacity
 	 * and perhaps load factor).
 	 *
 	 * @param anticipatedSize The anticipated size of the instaniated collection
 	 * after we are done populating it.
 	 * @return A newly instantiated collection to be wrapped.
 	 */
 	public abstract Object instantiate(int anticipatedSize);
 
 	@Override
 	public Object replace(
 			final Object original,
 			final Object target,
 			final SessionImplementor session,
 			final Object owner,
 			final Map copyCache) throws HibernateException {
 		if ( original == null ) {
 			return null;
 		}
 		if ( !Hibernate.isInitialized( original ) ) {
 			return target;
 		}
 
 		// for a null target, or a target which is the same as the original, we
 		// need to put the merged elements in a new collection
 		Object result = target == null || target == original ? instantiateResult( original ) : target;
 		
 		//for arrays, replaceElements() may return a different reference, since
 		//the array length might not match
 		result = replaceElements( original, result, owner, copyCache, session );
 
 		if ( original == target ) {
 			// get the elements back into the target making sure to handle dirty flag
 			boolean wasClean = PersistentCollection.class.isInstance( target ) && !( ( PersistentCollection ) target ).isDirty();
 			//TODO: this is a little inefficient, don't need to do a whole
 			//      deep replaceElements() call
 			replaceElements( result, target, owner, copyCache, session );
 			if ( wasClean ) {
 				( ( PersistentCollection ) target ).clearDirty();
 			}
 			result = target;
 		}
 
 		return result;
 	}
 
 	/**
 	 * Get the Hibernate type of the collection elements
 	 *
 	 * @param factory The session factory.
 	 * @return The type of the collection elements
 	 * @throws MappingException Indicates the underlying persister could not be located.
 	 */
 	public final Type getElementType(SessionFactoryImplementor factory) throws MappingException {
 		return factory.getCollectionPersister( getRole() ).getElementType();
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getRole() + ')';
 	}
 
 	@Override
 	public String getOnCondition(String alias, SessionFactoryImplementor factory, Map enabledFilters)
 			throws MappingException {
 		return getAssociatedJoinable( factory ).filterFragment( alias, enabledFilters );
 	}
 
 	@Override
 	public String getOnCondition(
 			String alias,
 			SessionFactoryImplementor factory,
 			Map enabledFilters,
 			Set<String> treatAsDeclarations) {
 		return getAssociatedJoinable( factory ).filterFragment( alias, enabledFilters, treatAsDeclarations );
 	}
 
 	/**
 	 * instantiate a collection wrapper (called when loading an object)
 	 *
 	 * @param key The collection owner key
 	 * @param session The session from which the request is originating.
 	 * @param owner The collection owner
 	 * @return The collection
 	 */
 	public Object getCollection(Serializable key, SessionImplementor session, Object owner) {
 
 		CollectionPersister persister = getPersister( session );
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		final EntityMode entityMode = persister.getOwnerEntityPersister().getEntityMode();
 
 		// check if collection is currently being loaded
 		PersistentCollection collection = persistenceContext.getLoadContexts().locateLoadingCollection( persister, key );
 		
 		if ( collection == null ) {
 			
 			// check if it is already completely loaded, but unowned
 			collection = persistenceContext.useUnownedCollection( new CollectionKey(persister, key, entityMode) );
 			
 			if ( collection == null ) {
 				// create a new collection wrapper, to be initialized later
 				collection = instantiate( session, persister, key );
 				
 				collection.setOwner(owner);
 	
 				persistenceContext.addUninitializedCollection( persister, collection, key );
 	
 				// some collections are not lazy:
 				if ( initializeImmediately() ) {
 					session.initializeCollection( collection, false );
 				}
 				else if ( !persister.isLazy() ) {
 					persistenceContext.addNonLazyCollection( collection );
 				}
 	
 				if ( hasHolder() ) {
 					session.getPersistenceContext().addCollectionHolder( collection );
 				}
 				
 			}
 			
 			if ( LOG.isTraceEnabled() ) {
 				LOG.tracef( "Created collection wrapper: %s",
 						MessageHelper.collectionInfoString( persister, collection,
 								key, session ) );
 			}
 			
 		}
 		
 		collection.setOwner(owner);
 
 		return collection.getValue();
 	}
 
 	public boolean hasHolder() {
 		return false;
 	}
 
 	protected boolean initializeImmediately() {
 		return false;
 	}
 
 	@Override
 	public String getLHSPropertyName() {
 		return foreignKeyPropertyName;
 	}
 
 	@Override
 	public boolean isXMLElement() {
 		return true;
 	}
 
 	@Override
 	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
 		return xml;
 	}
 
 	@Override
 	public void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory)
 			throws HibernateException {
 		if ( !isEmbeddedInXML ) {
 			node.detach();
 		}
 		else {
 			replaceNode( node, (Element) value );
 		}
 	}
 	
 	/**
 	 * We always need to dirty check the collection because we sometimes 
 	 * need to incremement version number of owner and also because of 
 	 * how assemble/disassemble is implemented for uks
 	 */
 	@Override
 	public boolean isAlwaysDirtyChecked() {
 		return true; 
 	}
 
 	@Override
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
 		return ArrayHelper.EMPTY_BOOLEAN_ARRAY;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/CompositeCustomType.java b/hibernate-core/src/main/java/org/hibernate/type/CompositeCustomType.java
index 958d43ad80..177884da42 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/CompositeCustomType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/CompositeCustomType.java
@@ -1,320 +1,307 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.lang.reflect.Method;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.engine.jdbc.Size;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.LoggableUserType;
 
 import org.dom4j.Element;
 import org.dom4j.Node;
 
 /**
  * Adapts {@link CompositeUserType} to the {@link Type} interface
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class CompositeCustomType extends AbstractType implements CompositeType, BasicType {
 	private final CompositeUserType userType;
 	private final String[] registrationKeys;
 	private final String name;
 	private final boolean customLogging;
 
 	public CompositeCustomType(CompositeUserType userType) {
 		this( userType, ArrayHelper.EMPTY_STRING_ARRAY );
 	}
 
 	public CompositeCustomType(CompositeUserType userType, String[] registrationKeys) {
 		this.userType = userType;
 		this.name = userType.getClass().getName();
 		this.customLogging = LoggableUserType.class.isInstance( userType );
 		this.registrationKeys = registrationKeys;
 	}
 
 	public String[] getRegistrationKeys() {
 		return registrationKeys;
 	}
 
 	public CompositeUserType getUserType() {
 		return userType;
 	}
 
 	public boolean isMethodOf(Method method) {
 		return false;
 	}
 
 	public Type[] getSubtypes() {
 		return userType.getPropertyTypes();
 	}
 
 	public String[] getPropertyNames() {
 		return userType.getPropertyNames();
 	}
 
 	public Object[] getPropertyValues(Object component, SessionImplementor session) throws HibernateException {
 		return getPropertyValues( component, EntityMode.POJO );
 	}
 
 	public Object[] getPropertyValues(Object component, EntityMode entityMode) throws HibernateException {
-
 		int len = getSubtypes().length;
 		Object[] result = new Object[len];
-		for ( int i=0; i<len; i++ ) {
-			result[i] = getPropertyValue(component, i);
+		for ( int i = 0; i < len; i++ ) {
+			result[i] = getPropertyValue( component, i );
 		}
 		return result;
 	}
 
-	public void setPropertyValues(Object component, Object[] values, EntityMode entityMode)
-		throws HibernateException {
-
-		for (int i=0; i<values.length; i++) {
+	public void setPropertyValues(Object component, Object[] values, EntityMode entityMode) throws HibernateException {
+		for ( int i = 0; i < values.length; i++ ) {
 			userType.setPropertyValue( component, i, values[i] );
 		}
 	}
 
-	public Object getPropertyValue(Object component, int i, SessionImplementor session)
-		throws HibernateException {
-		return getPropertyValue(component, i);
+	public Object getPropertyValue(Object component, int i, SessionImplementor session) throws HibernateException {
+		return getPropertyValue( component, i );
 	}
 
 	public Object getPropertyValue(Object component, int i) throws HibernateException {
 		return userType.getPropertyValue( component, i );
 	}
 
 	public CascadeStyle getCascadeStyle(int i) {
 		return CascadeStyles.NONE;
 	}
 
 	public FetchMode getFetchMode(int i) {
 		return FetchMode.DEFAULT;
 	}
 
 	public boolean isComponentType() {
 		return true;
 	}
 
 	public Object deepCopy(Object value, SessionFactoryImplementor factory)
-	throws HibernateException {
+			throws HibernateException {
 		return userType.deepCopy( value );
 	}
 
 	public Object assemble(
-		Serializable cached,
-		SessionImplementor session,
-		Object owner)
-		throws HibernateException {
-
+			Serializable cached,
+			SessionImplementor session,
+			Object owner) throws HibernateException {
 		return userType.assemble( cached, session, owner );
 	}
 
-	public Serializable disassemble(Object value, SessionImplementor session, Object owner)
-	throws HibernateException {
-		return userType.disassemble(value, session);
+	public Serializable disassemble(Object value, SessionImplementor session, Object owner) throws HibernateException {
+		return userType.disassemble( value, session );
 	}
 
 	public Object replace(
-			Object original, 
+			Object original,
 			Object target,
-			SessionImplementor session, 
-			Object owner, 
+			SessionImplementor session,
+			Object owner,
 			Map copyCache)
-	throws HibernateException {
-		return userType.replace(original, target, session, owner);
+			throws HibernateException {
+		return userType.replace( original, target, session, owner );
 	}
-	
+
 	public boolean isEqual(Object x, Object y)
-	throws HibernateException {
-		return userType.equals(x, y);
+			throws HibernateException {
+		return userType.equals( x, y );
 	}
 
 	public int getHashCode(Object x) {
-		return userType.hashCode(x);
+		return userType.hashCode( x );
 	}
-	
+
 	public int getColumnSpan(Mapping mapping) throws MappingException {
 		Type[] types = userType.getPropertyTypes();
-		int n=0;
+		int n = 0;
 		for ( Type type : types ) {
 			n += type.getColumnSpan( mapping );
 		}
 		return n;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public Class getReturnedClass() {
 		return userType.returnedClass();
 	}
 
 	public boolean isMutable() {
 		return userType.isMutable();
 	}
 
 	public Object nullSafeGet(
-		ResultSet rs,
-		String columnName,
-		SessionImplementor session,
-		Object owner)
-		throws HibernateException, SQLException {
-
+			ResultSet rs,
+			String columnName,
+			SessionImplementor session,
+			Object owner) throws HibernateException, SQLException {
 		return userType.nullSafeGet( rs, new String[] {columnName}, session, owner );
 	}
 
 	public Object nullSafeGet(
-		ResultSet rs,
-		String[] names,
-		SessionImplementor session,
-		Object owner)
-		throws HibernateException, SQLException {
-
-		return userType.nullSafeGet(rs, names, session, owner);
+			ResultSet rs,
+			String[] names,
+			SessionImplementor session,
+			Object owner) throws HibernateException, SQLException {
+		return userType.nullSafeGet( rs, names, session, owner );
 	}
 
 	public void nullSafeSet(
-		PreparedStatement st,
-		Object value,
-		int index,
-		SessionImplementor session)
-		throws HibernateException, SQLException {
-
-		userType.nullSafeSet(st, value, index, session);
-
+			PreparedStatement st,
+			Object value,
+			int index,
+			SessionImplementor session) throws HibernateException, SQLException {
+		userType.nullSafeSet( st, value, index, session );
 	}
 
 	public void nullSafeSet(
-		PreparedStatement st,
-		Object value,
-		int index,
-		boolean[] settable, 
-		SessionImplementor session)
-		throws HibernateException, SQLException {
-
-		userType.nullSafeSet(st, value, index, session);
+			PreparedStatement st,
+			Object value,
+			int index,
+			boolean[] settable,
+			SessionImplementor session) throws HibernateException, SQLException {
+		userType.nullSafeSet( st, value, index, session );
 	}
 
 	public int[] sqlTypes(Mapping mapping) throws MappingException {
-		int[] result = new int[ getColumnSpan(mapping) ];
-		int n=0;
+		int[] result = new int[getColumnSpan( mapping )];
+		int n = 0;
 		for ( Type type : userType.getPropertyTypes() ) {
 			for ( int sqlType : type.sqlTypes( mapping ) ) {
 				result[n++] = sqlType;
 			}
 		}
 		return result;
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		//Not called at runtime so doesn't matter if its slow :)
-		final Size[] sizes = new Size[ getColumnSpan( mapping ) ];
+		final Size[] sizes = new Size[getColumnSpan( mapping )];
 		int soFar = 0;
 		for ( Type propertyType : userType.getPropertyTypes() ) {
 			final Size[] propertySizes = propertyType.dictatedSizes( mapping );
 			System.arraycopy( propertySizes, 0, sizes, soFar, propertySizes.length );
 			soFar += propertySizes.length;
 		}
 		return sizes;
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		//Not called at runtime so doesn't matter if its slow :)
-		final Size[] sizes = new Size[ getColumnSpan( mapping ) ];
+		final Size[] sizes = new Size[getColumnSpan( mapping )];
 		int soFar = 0;
 		for ( Type propertyType : userType.getPropertyTypes() ) {
 			final Size[] propertySizes = propertyType.defaultSizes( mapping );
 			System.arraycopy( propertySizes, 0, sizes, soFar, propertySizes.length );
 			soFar += propertySizes.length;
 		}
 		return sizes;
 	}
-	
+
 	public String toLoggableString(Object value, SessionFactoryImplementor factory) throws HibernateException {
 		if ( value == null ) {
 			return "null";
 		}
 		else if ( customLogging ) {
 			return ( (LoggableUserType) userType ).toLoggableString( value, factory );
 		}
 		else {
 			return value.toString();
 		}
 	}
 
 	public boolean[] getPropertyNullability() {
 		return null;
 	}
 
 	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
 		return xml;
 	}
 
 	public void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory)
-	throws HibernateException {
+			throws HibernateException {
 		replaceNode( node, (Element) value );
 	}
 
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
-		boolean[] result = new boolean[ getColumnSpan(mapping) ];
-		if (value==null) return result;
-		Object[] values = getPropertyValues(value, EntityMode.POJO); //TODO!!!!!!!
+		boolean[] result = new boolean[getColumnSpan( mapping )];
+		if ( value == null ) {
+			return result;
+		}
+		Object[] values = getPropertyValues( value, EntityMode.POJO ); //TODO!!!!!!!
 		int loc = 0;
 		Type[] propertyTypes = getSubtypes();
-		for ( int i=0; i<propertyTypes.length; i++ ) {
+		for ( int i = 0; i < propertyTypes.length; i++ ) {
 			boolean[] propertyNullness = propertyTypes[i].toColumnNullness( values[i], mapping );
-			System.arraycopy(propertyNullness, 0, result, loc, propertyNullness.length);
+			System.arraycopy( propertyNullness, 0, result, loc, propertyNullness.length );
 			loc += propertyNullness.length;
 		}
 		return result;
 	}
 
-	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session) throws HibernateException {
-		return isDirty(old, current, session);
+	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session)
+			throws HibernateException {
+		return isDirty( old, current, session );
 	}
-	
+
 	public boolean isEmbedded() {
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java b/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
index 8263427bf3..8471e32ffb 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
@@ -1,146 +1,161 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Timestamp;
 import java.util.Date;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * <tt>dbtimestamp</tt>: An extension of {@link TimestampType} which
  * maps to the database's current timestamp, rather than the jvm's
  * current timestamp.
  * <p/>
  * Note: May/may-not cause issues on dialects which do not properly support
  * a true notion of timestamp (Oracle < 8, for example, where only its DATE
  * datatype is supported).  Depends on the frequency of DML operations...
  *
  * @author Steve Ebersole
  */
 public class DbTimestampType extends TimestampType {
 	public static final DbTimestampType INSTANCE = new DbTimestampType();
 
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, DbTimestampType.class.getName() );
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
+			CoreMessageLogger.class,
+			DbTimestampType.class.getName()
+	);
 
 	@Override
 	public String getName() {
 		return "dbtimestamp";
 	}
 
 	@Override
 	public String[] getRegistrationKeys() {
-		return new String[] { getName() };
+		return new String[] {getName()};
 	}
 
 	@Override
 	public Date seed(SessionImplementor session) {
 		if ( session == null ) {
 			LOG.trace( "Incoming session was null; using current jvm time" );
 			return super.seed( session );
 		}
 		else if ( !session.getFactory().getDialect().supportsCurrentTimestampSelection() ) {
 			LOG.debug( "Falling back to vm-based timestamp, as dialect does not support current timestamp selection" );
 			return super.seed( session );
 		}
 		else {
 			return getCurrentTimestamp( session );
 		}
 	}
 
 	private Date getCurrentTimestamp(SessionImplementor session) {
 		Dialect dialect = session.getFactory().getDialect();
 		String timestampSelectString = dialect.getCurrentTimestampSelectString();
-        if (dialect.isCurrentTimestampSelectStringCallable()) return useCallableStatement(timestampSelectString, session);
-        return usePreparedStatement(timestampSelectString, session);
+		if ( dialect.isCurrentTimestampSelectStringCallable() ) {
+			return useCallableStatement( timestampSelectString, session );
+		}
+		return usePreparedStatement( timestampSelectString, session );
 	}
 
 	private Timestamp usePreparedStatement(String timestampSelectString, SessionImplementor session) {
 		PreparedStatement ps = null;
 		try {
 			ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( timestampSelectString, false );
 			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 			rs.next();
 			Timestamp ts = rs.getTimestamp( 1 );
 			if ( LOG.isTraceEnabled() ) {
-				LOG.tracev( "Current timestamp retreived from db : {0} (nanos={1}, time={2})", ts, ts.getNanos(), ts.getTime() );
+				LOG.tracev(
+						"Current timestamp retreived from db : {0} (nanos={1}, time={2})",
+						ts,
+						ts.getNanos(),
+						ts.getTime()
+				);
 			}
 			return ts;
 		}
-		catch( SQLException e ) {
+		catch (SQLException e) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
-			        e,
-			        "could not select current db timestamp",
-			        timestampSelectString
+					e,
+					"could not select current db timestamp",
+					timestampSelectString
 			);
 		}
 		finally {
 			if ( ps != null ) {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 	}
 
 	private Timestamp useCallableStatement(String callString, SessionImplementor session) {
 		CallableStatement cs = null;
 		try {
 			cs = (CallableStatement) session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( callString, true );
 			cs.registerOutParameter( 1, java.sql.Types.TIMESTAMP );
 			session.getJdbcCoordinator().getResultSetReturn().execute( cs );
 			Timestamp ts = cs.getTimestamp( 1 );
 			if ( LOG.isTraceEnabled() ) {
-				LOG.tracev( "Current timestamp retreived from db : {0} (nanos={1}, time={2})", ts, ts.getNanos(), ts.getTime() );
+				LOG.tracev(
+						"Current timestamp retreived from db : {0} (nanos={1}, time={2})",
+						ts,
+						ts.getNanos(),
+						ts.getTime()
+				);
 			}
 			return ts;
 		}
-		catch( SQLException e ) {
+		catch (SQLException e) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
-			        e,
-			        "could not call current db timestamp function",
-			        callString
+					e,
+					"could not call current db timestamp function",
+					callString
 			);
 		}
 		finally {
 			if ( cs != null ) {
 				session.getJdbcCoordinator().getResourceRegistry().release( cs );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/ImmutableType.java b/hibernate-core/src/main/java/org/hibernate/type/ImmutableType.java
deleted file mode 100644
index 7dfcdcc0a7..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/ImmutableType.java
+++ /dev/null
@@ -1,58 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-import java.util.Map;
-
-import org.hibernate.HibernateException;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.spi.SessionImplementor;
-
-/**
- * Superclass of nullable immutable types.
- * @author Gavin King
- *
- * @deprecated Use the {@link AbstractStandardBasicType} approach instead
- */
-public abstract class ImmutableType extends NullableType {
-
-	public final Object deepCopy(Object value, SessionFactoryImplementor factory) {
-		return value;
-	}
-
-	public final boolean isMutable() {
-		return false;
-	}
-
-	public Object replace(
-		Object original,
-		Object target,
-		SessionImplementor session,
-		Object owner, 
-		Map copyCache)
-	throws HibernateException {
-		return original;
-	}
-
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/ListType.java b/hibernate-core/src/main/java/org/hibernate/type/ListType.java
index b7d9824b4c..052ca3e264 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/ListType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/ListType.java
@@ -1,80 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.collection.internal.PersistentList;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 
 public class ListType extends CollectionType {
 
 	/**
 	 * @deprecated Use {@link #ListType(org.hibernate.type.TypeFactory.TypeScope, String, String)}
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public ListType(TypeFactory.TypeScope typeScope, String role, String propertyRef, boolean isEmbeddedInXML) {
 		super( typeScope, role, propertyRef, isEmbeddedInXML );
 	}
 
 	public ListType(TypeFactory.TypeScope typeScope, String role, String propertyRef) {
 		super( typeScope, role, propertyRef );
 	}
 
 	public PersistentCollection instantiate(SessionImplementor session, CollectionPersister persister, Serializable key) {
 		return new PersistentList(session);
 	}
 
 	public Class getReturnedClass() {
 		return List.class;
 	}
 
 	public PersistentCollection wrap(SessionImplementor session, Object collection) {
 		return new PersistentList( session, (List) collection );
 	}
 
 	public Object instantiate(int anticipatedSize) {
 		return anticipatedSize <= 0 ? new ArrayList() : new ArrayList( anticipatedSize + 1 );
 	}
 	
 	public Object indexOf(Object collection, Object element) {
 		List list = (List) collection;
 		for ( int i=0; i<list.size(); i++ ) {
 			//TODO: proxies!
-			if ( list.get(i)==element ) return i;
+			if ( list.get(i)==element ) {
+				return i;
+			}
 		}
 		return null;
 	}
 	
 }
 
-
-
-
-
diff --git a/hibernate-core/src/main/java/org/hibernate/type/MapType.java b/hibernate-core/src/main/java/org/hibernate/type/MapType.java
index f0aa1d1447..7edbbee271 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/MapType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/MapType.java
@@ -1,110 +1,112 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.collection.internal.PersistentMap;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 
 
 public class MapType extends CollectionType {
 
 	/**
-	 * @deprecated Use {@link #MapType(TypeFactory.TypeScope, String, String ) } instead.
+	 * @deprecated Use {@link #MapType(TypeFactory.TypeScope, String, String) } instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public MapType(TypeFactory.TypeScope typeScope, String role, String propertyRef, boolean isEmbeddedInXML) {
 		super( typeScope, role, propertyRef, isEmbeddedInXML );
 	}
 
 	public MapType(TypeFactory.TypeScope typeScope, String role, String propertyRef) {
 		super( typeScope, role, propertyRef );
 	}
 
-	public PersistentCollection instantiate(SessionImplementor session, CollectionPersister persister, Serializable key) {
-		return new PersistentMap(session);
+	public PersistentCollection instantiate(
+			SessionImplementor session,
+			CollectionPersister persister,
+			Serializable key) {
+		return new PersistentMap( session );
 	}
 
 	public Class getReturnedClass() {
 		return Map.class;
 	}
 
 	public Iterator getElementsIterator(Object collection) {
 		return ( (java.util.Map) collection ).values().iterator();
 	}
 
 	public PersistentCollection wrap(SessionImplementor session, Object collection) {
 		return new PersistentMap( session, (java.util.Map) collection );
 	}
-	
+
 	public Object instantiate(int anticipatedSize) {
-		return anticipatedSize <= 0 
-		       ? new HashMap()
-		       : new HashMap( anticipatedSize + (int)( anticipatedSize * .75f ), .75f );
+		return anticipatedSize <= 0
+				? new HashMap()
+				: new HashMap( anticipatedSize + (int) ( anticipatedSize * .75f ), .75f );
 	}
 
 	public Object replaceElements(
-		final Object original,
-		final Object target,
-		final Object owner, 
-		final java.util.Map copyCache, 
-		final SessionImplementor session)
-		throws HibernateException {
-
+			final Object original,
+			final Object target,
+			final Object owner,
+			final java.util.Map copyCache,
+			final SessionImplementor session) throws HibernateException {
 		CollectionPersister cp = session.getFactory().getCollectionPersister( getRole() );
-		
+
 		java.util.Map result = (java.util.Map) target;
 		result.clear();
-		
-		Iterator iter = ( (java.util.Map) original ).entrySet().iterator();
-		while ( iter.hasNext() ) {
-			java.util.Map.Entry me = (java.util.Map.Entry) iter.next();
+
+		for ( Object o : ( (Map) original ).entrySet() ) {
+			Map.Entry me = (Map.Entry) o;
 			Object key = cp.getIndexType().replace( me.getKey(), null, session, owner, copyCache );
 			Object value = cp.getElementType().replace( me.getValue(), null, session, owner, copyCache );
-			result.put(key, value);
+			result.put( key, value );
 		}
-		
+
 		return result;
-		
+
 	}
-	
+
 	public Object indexOf(Object collection, Object element) {
 		Iterator iter = ( (Map) collection ).entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = (Map.Entry) iter.next();
 			//TODO: proxies!
-			if ( me.getValue()==element ) return me.getKey();
+			if ( me.getValue() == element ) {
+				return me.getKey();
+			}
 		}
 		return null;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/MetaType.java b/hibernate-core/src/main/java/org/hibernate/type/MetaType.java
index 4f25c20eae..ec41311e1d 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/MetaType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/MetaType.java
@@ -1,178 +1,178 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.jdbc.Size;
 
 import org.dom4j.Node;
 
 /**
  * @author Gavin King
  */
 public class MetaType extends AbstractType {
 	public static final String[] REGISTRATION_KEYS = new String[0];
 
 	private final Type baseType;
 	private final Map<Object,String> discriminatorValuesToEntityNameMap;
 	private final Map<String,Object> entityNameToDiscriminatorValueMap;
 
 	public MetaType(Map<Object,String> discriminatorValuesToEntityNameMap, Type baseType) {
 		this.baseType = baseType;
 		this.discriminatorValuesToEntityNameMap = discriminatorValuesToEntityNameMap;
 		this.entityNameToDiscriminatorValueMap = new HashMap<String,Object>();
 		for ( Map.Entry<Object,String> entry : discriminatorValuesToEntityNameMap.entrySet() ) {
 			entityNameToDiscriminatorValueMap.put( entry.getValue(), entry.getKey() );
 		}
 	}
 
 	public String[] getRegistrationKeys() {
 		return REGISTRATION_KEYS;
 	}
 
 	public Map<Object, String> getDiscriminatorValuesToEntityNameMap() {
 		return discriminatorValuesToEntityNameMap;
 	}
 
 	public int[] sqlTypes(Mapping mapping) throws MappingException {
 		return baseType.sqlTypes(mapping);
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		return baseType.dictatedSizes( mapping );
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		return baseType.defaultSizes( mapping );
 	}
 
 	public int getColumnSpan(Mapping mapping) throws MappingException {
 		return baseType.getColumnSpan(mapping);
 	}
 
 	public Class getReturnedClass() {
 		return String.class;
 	}
 
 	public Object nullSafeGet(
 		ResultSet rs,
 		String[] names,
 		SessionImplementor session,
 		Object owner)
 	throws HibernateException, SQLException {
 		Object key = baseType.nullSafeGet(rs, names, session, owner);
 		return key==null ? null : discriminatorValuesToEntityNameMap.get(key);
 	}
 
 	public Object nullSafeGet(
 		ResultSet rs,
 		String name,
 		SessionImplementor session,
 		Object owner)
 	throws HibernateException, SQLException {
 		Object key = baseType.nullSafeGet(rs, name, session, owner);
 		return key==null ? null : discriminatorValuesToEntityNameMap.get(key);
 	}
 
 	public void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session)
 	throws HibernateException, SQLException {
 		baseType.nullSafeSet(st, value==null ? null : entityNameToDiscriminatorValueMap.get(value), index, session);
 	}
 	
 	public void nullSafeSet(
 			PreparedStatement st,
 			Object value,
 			int index,
 			boolean[] settable, 
-			SessionImplementor session)
-	throws HibernateException, SQLException {
-		if ( settable[0] ) nullSafeSet(st, value, index, session);
+			SessionImplementor session) throws HibernateException, SQLException {
+		if ( settable[0] ) {
+			nullSafeSet(st, value, index, session);
+		}
 	}
 
 	public String toLoggableString(Object value, SessionFactoryImplementor factory) throws HibernateException {
 		return toXMLString(value, factory);
 	}
 	
 	public String toXMLString(Object value, SessionFactoryImplementor factory)
 		throws HibernateException {
 		return (String) value; //value is the entity name
 	}
 
 	public Object fromXMLString(String xml, Mapping factory)
 		throws HibernateException {
 		return xml; //xml is the entity name
 	}
 
 	public String getName() {
 		return baseType.getName(); //TODO!
 	}
 
 	public Object deepCopy(Object value, SessionFactoryImplementor factory)
 	throws HibernateException {
 		return value;
 	}
 
 	public Object replace(
 			Object original, 
 			Object target,
 			SessionImplementor session, 
 			Object owner, 
-			Map copyCache
-	) {
+			Map copyCache) {
 		return original;
 	}
 	
 	public boolean isMutable() {
 		return false;
 	}
 
 	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
 		return fromXMLString( xml.getText(), factory );
 	}
 
 	public void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory) throws HibernateException {
 		node.setText( toXMLString(value, factory) );
 	}
 
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
 		throw new UnsupportedOperationException();
 	}
 
 	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session) throws HibernateException {
 		return checkable[0] && isDirty(old, current, session);
 	}
 	
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/MutableType.java b/hibernate-core/src/main/java/org/hibernate/type/MutableType.java
deleted file mode 100644
index f9f7abf213..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/MutableType.java
+++ /dev/null
@@ -1,61 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-import java.util.Map;
-
-import org.hibernate.HibernateException;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.spi.SessionImplementor;
-
-/**
- * Superclass for mutable nullable types
- * @author Gavin King
- *
- * @deprecated Use the {@link AbstractStandardBasicType} approach instead
- */
-public abstract class MutableType extends NullableType {
-
-	public final boolean isMutable() {
-		return true;
-	}
-
-	protected abstract Object deepCopyNotNull(Object value) throws HibernateException;
-
-	public final Object deepCopy(Object value, SessionFactoryImplementor factory) throws HibernateException {
-		return (value==null) ? null : deepCopyNotNull(value);
-	}
-
-	public Object replace(
-			Object original,
-			Object target,
-			SessionImplementor session,
-			Object owner,
-			Map copyCache) throws HibernateException {
-		if ( isEqual( original, target ) ) {
-			return original;
-		}
-		return deepCopy( original, session.getFactory() );
-	}
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/NullableType.java b/hibernate-core/src/main/java/org/hibernate/type/NullableType.java
deleted file mode 100644
index 70eabb6a6f..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/NullableType.java
+++ /dev/null
@@ -1,264 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-
-import org.hibernate.HibernateException;
-import org.hibernate.MappingException;
-import org.hibernate.engine.spi.Mapping;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.internal.util.collections.ArrayHelper;
-import org.hibernate.internal.util.compare.EqualsHelper;
-import org.hibernate.engine.jdbc.Size;
-
-import org.jboss.logging.Logger;
-
-import org.dom4j.Node;
-
-/**
- * Superclass of single-column nullable types.
- *
- * @author Gavin King
- *
- * @deprecated Use the {@link AbstractStandardBasicType} approach instead
- */
-@Deprecated
-public abstract class NullableType extends AbstractType implements StringRepresentableType, XmlRepresentableType {
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, NullableType.class.getName());
-
-	private final Size dictatedSize = new Size();
-
-	/**
-	 * A convenience form of {@link #sqlTypes(org.hibernate.engine.spi.Mapping)}, returning
-	 * just a single type value since these are explicitly dealing with single column
-	 * mappings.
-	 *
-	 * @return The {@link java.sql.Types} mapping value.
-	 */
-	public abstract int sqlType();
-
-	/**
-	 * A convenience form of {@link #dictatedSizes}, returning just a single size since we are explicitly dealing with
-	 * single column mappings here.
-	 *
-	 * @return The {@link java.sql.Types} mapping value.
-	 */
-	public Size dictatedSize() {
-		return dictatedSize;
-	}
-
-	/**
-	 * A convenience form of {@link #defaultSizes}, returning just a single size since we are explicitly dealing with
-	 * single column mappings here.
-	 *
-	 * @return The {@link java.sql.Types} mapping value.
-	 */
-	public Size defaultSize() {
-		return LEGACY_DEFAULT_SIZE;
-	}
-
-	/**
-	 * Get a column value from a result set, without worrying about the
-	 * possibility of null values.  Called from {@link #nullSafeGet} after
-	 * nullness checks have been performed.
-	 *
-	 * @param rs The result set from which to extract the value.
-	 * @param name The name of the value to extract.
-	 *
-	 * @return The extracted value.
-	 *
-	 * @throws org.hibernate.HibernateException Generally some form of mismatch error.
-	 * @throws java.sql.SQLException Indicates problem making the JDBC call(s).
-	 */
-	public abstract Object get(ResultSet rs, String name) throws HibernateException, SQLException;
-
-	/**
-	 * Set a parameter value without worrying about the possibility of null
-	 * values.  Called from {@link #nullSafeSet} after nullness checks have
-	 * been performed.
-	 *
-	 * @param st The statement into which to bind the parameter value.
-	 * @param value The parameter value to bind.
-	 * @param index The position or index at which to bind the param value.
-	 *
-	 * @throws org.hibernate.HibernateException Generally some form of mismatch error.
-	 * @throws java.sql.SQLException Indicates problem making the JDBC call(s).
-	 */
-	public abstract void set(PreparedStatement st, Object value, int index) throws HibernateException, SQLException;
-
-	/**
-	 * A null-safe version of {@link #toString(Object)}.  Specifically we are
-	 * worried about null safeness in regards to the incoming value parameter,
-	 * not the return.
-	 *
-	 * @param value The value to convert to a string representation; may be null.
-	 * @return The string representation; may be null.
-	 * @throws HibernateException Thrown by {@link #toString(Object)}, which this calls.
-	 */
-	public String nullSafeToString(Object value) throws HibernateException {
-		return value == null ? null : toString( value );
-	}
-
-	public abstract String toString(Object value) throws HibernateException;
-
-	public abstract Object fromStringValue(String xml) throws HibernateException;
-
-	public final void nullSafeSet(
-			PreparedStatement st,
-			Object value,
-			int index,
-			boolean[] settable,
-			SessionImplementor session)
-	throws HibernateException, SQLException {
-		if ( settable[0] ) nullSafeSet(st, value, index);
-	}
-
-	public final void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session)
-	throws HibernateException, SQLException {
-		nullSafeSet(st, value, index);
-	}
-
-	public final void nullSafeSet(PreparedStatement st, Object value, int index)
-	throws HibernateException, SQLException {
-		try {
-			if ( value == null ) {
-				LOG.tracev("Binding null to parameter: {0}", index);
-
-				st.setNull( index, sqlType() );
-			}
-			else {
-				if (LOG.isTraceEnabled()) LOG.tracev("Binding '{0}' to parameter: {1}", toString(value), index);
-
-				set( st, value, index );
-			}
-		}
-		catch ( RuntimeException re ) {
-			LOG.unableToBindValueToParameter( nullSafeToString( value ), index, re.getMessage() );
-			throw re;
-		}
-		catch ( SQLException se ) {
-			LOG.unableToBindValueToParameter( nullSafeToString( value ), index, se.getMessage() );
-			throw se;
-		}
-	}
-
-	public final Object nullSafeGet(
-			ResultSet rs,
-			String[] names,
-			SessionImplementor session,
-			Object owner)
-	throws HibernateException, SQLException {
-		return nullSafeGet(rs, names[0]);
-	}
-
-	public final Object nullSafeGet(ResultSet rs, String[] names)
-	throws HibernateException, SQLException {
-		return nullSafeGet(rs, names[0]);
-	}
-
-	public final Object nullSafeGet(ResultSet rs, String name)
-	throws HibernateException, SQLException {
-		try {
-			Object value = get(rs, name);
-			if ( value == null || rs.wasNull() ) {
-				LOG.tracev( "Returning null as column {0}", name );
-				return null;
-			}
-			if ( LOG.isTraceEnabled() ) LOG.trace( "Returning '" + toString( value ) + "' as column " + name );
-			return value;
-		}
-		catch ( RuntimeException re ) {
-			LOG.unableToReadColumnValueFromResultSet( name, re.getMessage() );
-			throw re;
-		}
-		catch ( SQLException se ) {
-			LOG.unableToReadColumnValueFromResultSet( name, se.getMessage() );
-			throw se;
-		}
-	}
-
-	public final Object nullSafeGet(ResultSet rs, String name, SessionImplementor session, Object owner)
-	throws HibernateException, SQLException {
-		return nullSafeGet( rs, name );
-	}
-
-	public final String toXMLString(Object value, SessionFactoryImplementor pc)
-	throws HibernateException {
-		return toString(value);
-	}
-
-	public final Object fromXMLString(String xml, Mapping factory) throws HibernateException {
-		return xml==null || xml.length()==0 ? null : fromStringValue(xml);
-	}
-
-	public final int getColumnSpan(Mapping session) {
-		return 1;
-	}
-
-	public final int[] sqlTypes(Mapping session) {
-		return new int[] { sqlType() };
-	}
-
-	@Override
-	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
-		return new Size[] { dictatedSize() };
-	}
-
-	@Override
-	public Size[] defaultSizes(Mapping mapping) throws MappingException {
-		return new Size[] { defaultSize() };
-	}
-
-	@Override
-	public boolean isEqual(Object x, Object y) {
-		return EqualsHelper.equals(x, y);
-	}
-
-	public String toLoggableString(Object value, SessionFactoryImplementor factory) {
-		return value == null ? "null" : toString(value);
-	}
-
-	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
-		return fromXMLString( xml.getText(), factory );
-	}
-
-	public void setToXMLNode(Node xml, Object value, SessionFactoryImplementor factory)
-	throws HibernateException {
-		xml.setText( toXMLString(value, factory) );
-	}
-
-	public boolean[] toColumnNullness(Object value, Mapping mapping) {
-		return value==null ? ArrayHelper.FALSE : ArrayHelper.TRUE;
-	}
-
-	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session)
-	throws HibernateException {
-		return checkable[0] && isDirty(old, current, session);
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/PrimitiveByteArrayBlobType.java b/hibernate-core/src/main/java/org/hibernate/type/PrimitiveByteArrayBlobType.java
deleted file mode 100644
index 651e4841a6..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/PrimitiveByteArrayBlobType.java
+++ /dev/null
@@ -1,46 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-
-/**
- * Map a byte[] to a Blob
- *
- * @author Emmanuel Bernard
- * @deprecated replaced by {@link org.hibernate.type.MaterializedBlobType}
- */
-@Deprecated
-public class PrimitiveByteArrayBlobType extends ByteArrayBlobType {
-	public Class getReturnedClass() {
-		return byte[].class;
-	}
-
-	protected Object wrap(byte[] bytes) {
-		return bytes;
-	}
-
-	protected byte[] unWrap(Object bytes) {
-		return (byte[]) bytes;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/SingleColumnType.java b/hibernate-core/src/main/java/org/hibernate/type/SingleColumnType.java
index 530fa058d6..01dffc655a 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/SingleColumnType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/SingleColumnType.java
@@ -1,91 +1,88 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
 
 /**
- * Provide convenient methods for binding and extracting values for use with {@link BasicType}.  Most of this
- * is copied from the (now deprecated) {@link NullableType}.
- * <p/>
- * Glaring omission are the forms that do not take
+ * Provide convenient methods for binding and extracting values for use with {@link BasicType}.
  *
  * @author Steve Ebersole
  */
 public interface SingleColumnType<T> extends Type {
 
-	public int sqlType();
+	int sqlType();
 
-	public String toString(T value) throws HibernateException;
+	String toString(T value) throws HibernateException;
 
-	public T fromStringValue(String xml) throws HibernateException;
+	T fromStringValue(String xml) throws HibernateException;
 
 	/**
 	 * Get a column value from a result set by name.
 	 *
 	 * @param rs The result set from which to extract the value.
 	 * @param name The name of the value to extract.
 	 * @param session The session from which the request originates
 	 *
 	 * @return The extracted value.
 	 *
 	 * @throws org.hibernate.HibernateException Generally some form of mismatch error.
 	 * @throws java.sql.SQLException Indicates problem making the JDBC call(s).
 	 */
-	public T nullSafeGet(ResultSet rs, String name, SessionImplementor session) throws HibernateException, SQLException;
+	T nullSafeGet(ResultSet rs, String name, SessionImplementor session) throws HibernateException, SQLException;
 
 	/**
 	 * Get a column value from a result set, without worrying about the possibility of null values.
 	 *
 	 * @param rs The result set from which to extract the value.
 	 * @param name The name of the value to extract.
 	 * @param session The session from which the request originates
 	 *
 	 * @return The extracted value.
 	 *
 	 * @throws org.hibernate.HibernateException Generally some form of mismatch error.
 	 * @throws java.sql.SQLException Indicates problem making the JDBC call(s).
 	 */
-	public Object get(ResultSet rs, String name, SessionImplementor session) throws HibernateException, SQLException;
+	Object get(ResultSet rs, String name, SessionImplementor session) throws HibernateException, SQLException;
 
 	/**
 	 * Set a parameter value without worrying about the possibility of null
 	 * values.  Called from {@link #nullSafeSet} after nullness checks have
 	 * been performed.
 	 *
 	 * @param st The statement into which to bind the parameter value.
 	 * @param value The parameter value to bind.
 	 * @param index The position or index at which to bind the param value.
 	 * @param session The session from which the request originates
 	 *
 	 * @throws org.hibernate.HibernateException Generally some form of mismatch error.
 	 * @throws java.sql.SQLException Indicates problem making the JDBC call(s).
 	 */
-	public void set(PreparedStatement st, T value, int index, SessionImplementor session) throws HibernateException, SQLException;
+	void set(PreparedStatement st, T value, int index, SessionImplementor session) throws HibernateException, SQLException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/SpecialOneToOneType.java b/hibernate-core/src/main/java/org/hibernate/type/SpecialOneToOneType.java
index 26b777e844..4eb1506b94 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/SpecialOneToOneType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/SpecialOneToOneType.java
@@ -1,157 +1,159 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.engine.internal.ForeignKeys;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.jdbc.Size;
 
 /**
  * A one-to-one association that maps to specific formula(s)
  * instead of the primary key column of the owning entity.
  * 
  * @author Gavin King
  */
 public class SpecialOneToOneType extends OneToOneType {
 	
 	/**
 	 * @deprecated Use {@link #SpecialOneToOneType(org.hibernate.type.TypeFactory.TypeScope, String, ForeignKeyDirection, boolean, String, boolean, boolean, String, String)} instead.
 	 */
 	@Deprecated
 	public SpecialOneToOneType(
 			TypeFactory.TypeScope scope,
 			String referencedEntityName,
 			ForeignKeyDirection foreignKeyType, 
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
 		this( scope, referencedEntityName, foreignKeyType, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, entityName, propertyName );
 	}
 	
 	public SpecialOneToOneType(
 			TypeFactory.TypeScope scope,
 			String referencedEntityName,
 			ForeignKeyDirection foreignKeyType,
 			boolean referenceToPrimaryKey, 
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
 		super(
 				scope,
 				referencedEntityName, 
 				foreignKeyType,
 				referenceToPrimaryKey, 
 				uniqueKeyPropertyName, 
 				lazy,
 				unwrapProxy,
 				entityName, 
 				propertyName
 			);
 	}
 	
 	public int getColumnSpan(Mapping mapping) throws MappingException {
 		return super.getIdentifierOrUniqueKeyType( mapping ).getColumnSpan( mapping );
 	}
 	
 	public int[] sqlTypes(Mapping mapping) throws MappingException {
 		return super.getIdentifierOrUniqueKeyType( mapping ).sqlTypes( mapping );
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		return super.getIdentifierOrUniqueKeyType( mapping ).dictatedSizes( mapping );
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		return super.getIdentifierOrUniqueKeyType( mapping ).defaultSizes( mapping );
 	}
 
 	public boolean useLHSPrimaryKey() {
 		return false;
 	}
 	
 	public Object hydrate(ResultSet rs, String[] names, SessionImplementor session, Object owner)
 	throws HibernateException, SQLException {
 		return super.getIdentifierOrUniqueKeyType( session.getFactory() )
 			.nullSafeGet(rs, names, session, owner);
 	}
 	
 	// TODO: copy/paste from ManyToOneType
 
 	public Serializable disassemble(Object value, SessionImplementor session, Object owner)
 	throws HibernateException {
 
 		if ( isNotEmbedded(session) ) {
 			return getIdentifierType(session).disassemble(value, session, owner);
 		}
 		
 		if (value==null) {
 			return null;
 		}
 		else {
 			// cache the actual id of the object, not the value of the
 			// property-ref, which might not be initialized
 			Object id = ForeignKeys.getEntityIdentifierIfNotUnsaved( getAssociatedEntityName(), value, session );
 			if (id==null) {
 				throw new AssertionFailure(
 						"cannot cache a reference to an object with a null id: " + 
 						getAssociatedEntityName() 
 				);
 			}
 			return getIdentifierType(session).disassemble(id, session, owner);
 		}
 	}
 
 	public Object assemble(Serializable oid, SessionImplementor session, Object owner)
 	throws HibernateException {
 		//TODO: currently broken for unique-key references (does not detect
 		//      change to unique key property of the associated object)
 		Serializable id = (Serializable) getIdentifierType(session).assemble(oid, session, null); //the owner of the association is not the owner of the id
 
-		if ( isNotEmbedded(session) ) return id;
+		if ( isNotEmbedded(session) ) {
+			return id;
+		}
 		
 		if (id==null) {
 			return null;
 		}
 		else {
 			return resolveIdentifier(id, session);
 		}
 	}
 	
 
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/StringClobType.java b/hibernate-core/src/main/java/org/hibernate/type/StringClobType.java
deleted file mode 100644
index e0d05891be..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/StringClobType.java
+++ /dev/null
@@ -1,110 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.Serializable;
-import java.io.StringReader;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.sql.Types;
-
-import org.hibernate.HibernateException;
-import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.usertype.UserType;
-
-/**
- * Map a String to a Clob
- *
- * @author Emmanuel Bernard
- * @deprecated replaced by {@link org.hibernate.type.MaterializedClobType}
- */
-@Deprecated
-public class StringClobType implements UserType, Serializable {
-	public int[] sqlTypes() {
-		return new int[]{Types.CLOB};
-	}
-
-	public Class returnedClass() {
-		return String.class;
-	}
-
-	public boolean equals(Object x, Object y) throws HibernateException {
-		return ( x == y ) || ( x != null && x.equals( y ) );
-	}
-
-	public int hashCode(Object x) throws HibernateException {
-		return x.hashCode();
-	}
-
-	public Object nullSafeGet(ResultSet rs, String[] names, SessionImplementor session, Object owner) throws HibernateException, SQLException {
-		Reader reader = rs.getCharacterStream( names[0] );
-		if ( reader == null ) return null;
-		StringBuilder result = new StringBuilder( 4096 );
-		try {
-			char[] charbuf = new char[4096];
-			for ( int i = reader.read( charbuf ); i > 0 ; i = reader.read( charbuf ) ) {
-				result.append( charbuf, 0, i );
-			}
-		}
-		catch (IOException e) {
-			throw new SQLException( e.getMessage() );
-		}
-		return result.toString();
-	}
-
-	public void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session) throws HibernateException, SQLException {
-		if ( value != null ) {
-			String string = (String) value;
-			StringReader reader = new StringReader( string );
-			st.setCharacterStream( index, reader, string.length() );
-		}
-		else {
-			st.setNull( index, sqlTypes()[0] );
-		}
-	}
-
-	public Object deepCopy(Object value) throws HibernateException {
-		//returning value should be OK since String are immutable
-		return value;
-	}
-
-	public boolean isMutable() {
-		return false;
-	}
-
-	public Serializable disassemble(Object value) throws HibernateException {
-		return (Serializable) value;
-	}
-
-	public Object assemble(Serializable cached, Object owner) throws HibernateException {
-		return cached;
-	}
-
-	public Object replace(Object original, Object target, Object owner) throws HibernateException {
-		return original;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/StringRepresentableType.java b/hibernate-core/src/main/java/org/hibernate/type/StringRepresentableType.java
index f5cfbcd187..a599dc3a0b 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/StringRepresentableType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/StringRepresentableType.java
@@ -1,55 +1,55 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import org.hibernate.HibernateException;
 
 /**
  * Additional, optional contract for types capable of rendering and consuming their values to/from strings.
  *
  * @author Steve Ebersole
  */
 public interface StringRepresentableType<T> {
 	/**
 	 * Render the value to the string representation.
 	 *
 	 * @param value The value to render to string.
 	 *
 	 * @return The string representation
 	 *
 	 * @throws HibernateException Problem rendering
 	 */
-	public abstract String toString(T value) throws HibernateException;
+	String toString(T value) throws HibernateException;
 
 	/**
 	 * Consume the given string representation back into this types java form.
 	 *
 	 * @param string The string representation to be consumed.
 	 *
 	 * @return The java type representation
 	 *
 	 * @throws HibernateException Problem consuming
 	 */
-	public abstract T fromStringValue(String string) throws HibernateException;
+	T fromStringValue(String string) throws HibernateException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/XmlRepresentableType.java b/hibernate-core/src/main/java/org/hibernate/type/XmlRepresentableType.java
deleted file mode 100644
index 6fab12d070..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/type/XmlRepresentableType.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.type;
-
-import org.hibernate.HibernateException;
-import org.hibernate.engine.spi.Mapping;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-
-/**
- * Additional, optional contract for types whose values can be represented as XML text (either as attribute or
- * element value).
- *
- * @author Steve Ebersole
- *
- * @deprecated To be removed in 5.  Use {@link StringRepresentableType} instead.  See Jira issues
- * <a href="https://hibernate.onjira.com/browse/HHH-7777">HHH-7777</a> and
- * <a href="https://hibernate.onjira.com/browse/HHH-7776">HHH-7776</a> for details.
- *
- * @see StringRepresentableType
- */
-@Deprecated
-public interface XmlRepresentableType<T> {
-	public String toXMLString(T value, SessionFactoryImplementor factory) throws HibernateException;
-
-	public T fromXMLString(String xml, Mapping factory) throws HibernateException;
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/BlobTypeDescriptor.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/BlobTypeDescriptor.java
index 5305067547..ba01a9e953 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/BlobTypeDescriptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/BlobTypeDescriptor.java
@@ -1,180 +1,182 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.java;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.Serializable;
 import java.sql.Blob;
 import java.sql.SQLException;
 import java.util.Comparator;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.BinaryStream;
 import org.hibernate.engine.jdbc.BlobImplementer;
 import org.hibernate.engine.jdbc.BlobProxy;
 import org.hibernate.engine.jdbc.WrappedBlob;
 import org.hibernate.engine.jdbc.internal.BinaryStreamImpl;
 import org.hibernate.type.descriptor.WrapperOptions;
 
 /**
  * Descriptor for {@link Blob} handling.
  * <p/>
  * Note, {@link Blob blobs} really are mutable (their internal state can in fact be mutated).  We simply
  * treat them as immutable because we cannot properly check them for changes nor deep copy them.
  *
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public class BlobTypeDescriptor extends AbstractTypeDescriptor<Blob> {
 	public static final BlobTypeDescriptor INSTANCE = new BlobTypeDescriptor();
 
 	public static class BlobMutabilityPlan implements MutabilityPlan<Blob> {
 		public static final BlobMutabilityPlan INSTANCE = new BlobMutabilityPlan();
 
+		@Override
 		public boolean isMutable() {
 			return false;
 		}
 
+		@Override
 		public Blob deepCopy(Blob value) {
 			return value;
 		}
 
+		@Override
 		public Serializable disassemble(Blob value) {
 			throw new UnsupportedOperationException( "Blobs are not cacheable" );
 		}
 
+		@Override
 		public Blob assemble(Serializable cached) {
 			throw new UnsupportedOperationException( "Blobs are not cacheable" );
 		}
 	}
 
 	public BlobTypeDescriptor() {
 		super( Blob.class, BlobMutabilityPlan.INSTANCE );
 	}
 
-	/**
-	 * {@inheritDoc}
-	 */
+	@Override
 	public String toString(Blob value) {
 		final byte[] bytes;
 		try {
 			bytes = DataHelper.extractBytes( value.getBinaryStream() );
 		}
 		catch ( SQLException e ) {
 			throw new HibernateException( "Unable to access blob stream", e );
 		}
 		return PrimitiveByteArrayTypeDescriptor.INSTANCE.toString( bytes );
 	}
 
-	/**
-	 * {@inheritDoc}
-	 */
+	@Override
 	public Blob fromString(String string) {
 		return BlobProxy.generateProxy( PrimitiveByteArrayTypeDescriptor.INSTANCE.fromString( string ) );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public Comparator<Blob> getComparator() {
 		return IncomparableComparator.INSTANCE;
 	}
 
 	@Override
 	public int extractHashCode(Blob value) {
 		return System.identityHashCode( value );
 	}
 
 	@Override
 	public boolean areEqual(Blob one, Blob another) {
 		return one == another;
 	}
 
+	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <X> X unwrap(Blob value, Class<X> type, WrapperOptions options) {
 		if ( value == null ) {
 			return null;
 		}
 
 		try {
 			if ( BinaryStream.class.isAssignableFrom( type ) ) {
 				if ( BlobImplementer.class.isInstance( value ) ) {
 					// if the incoming Blob is a wrapper, just pass along its BinaryStream
 					return (X) ( (BlobImplementer) value ).getUnderlyingStream();
 				}
 				else {
 					// otherwise we need to build a BinaryStream...
 					return (X) new BinaryStreamImpl( DataHelper.extractBytes( value.getBinaryStream() ) );
 				}
 			}
 			else if ( byte[].class.isAssignableFrom( type )) {
 				if ( BlobImplementer.class.isInstance( value ) ) {
 					// if the incoming Blob is a wrapper, just grab the bytes from its BinaryStream
 					return (X) ( (BlobImplementer) value ).getUnderlyingStream().getBytes();
 				}
 				else {
 					// otherwise extract the bytes from the stream manually
 					return (X) DataHelper.extractBytes( value.getBinaryStream() );
 				}
 			}
 			else if (Blob.class.isAssignableFrom( type )) {
 				final Blob blob =  WrappedBlob.class.isInstance( value )
 						? ( (WrappedBlob) value ).getWrappedBlob()
 						: value;
 				return (X) blob;
 			}
 		}
 		catch ( SQLException e ) {
 			throw new HibernateException( "Unable to access blob stream", e );
 		}
 		
 		throw unknownUnwrap( type );
 	}
 
+	@Override
 	public <X> Blob wrap(X value, WrapperOptions options) {
 		if ( value == null ) {
 			return null;
 		}
 
 		// Support multiple return types from
 		// org.hibernate.type.descriptor.sql.BlobTypeDescriptor
 		if ( Blob.class.isAssignableFrom( value.getClass() ) ) {
 			return options.getLobCreator().wrap( (Blob) value );
 		}
 		else if ( byte[].class.isAssignableFrom( value.getClass() ) ) {
 			return options.getLobCreator().createBlob( ( byte[] ) value);
 		}
 		else if ( InputStream.class.isAssignableFrom( value.getClass() ) ) {
 			InputStream inputStream = ( InputStream ) value;
 			try {
 				return options.getLobCreator().createBlob( inputStream, inputStream.available() );
 			}
 			catch ( IOException e ) {
 				throw unknownWrap( value.getClass() );
 			}
 		}
 
 		throw unknownWrap( value.getClass() );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/loadplans/plans/LoadPlanStructureAssertionHelper.java b/hibernate-core/src/test/java/org/hibernate/test/loadplans/plans/LoadPlanStructureAssertionHelper.java
index 24dc217526..743c85f6d7 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/loadplans/plans/LoadPlanStructureAssertionHelper.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/loadplans/plans/LoadPlanStructureAssertionHelper.java
@@ -1,141 +1,141 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.loadplans.plans;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.loader.JoinWalker;
 import org.hibernate.loader.entity.EntityJoinWalker;
 import org.hibernate.loader.plan.build.internal.FetchStyleLoadPlanBuildingAssociationVisitationStrategy;
 import org.hibernate.loader.plan.build.spi.MetamodelDrivenLoadPlanBuilder;
 import org.hibernate.loader.plan.exec.internal.BatchingLoadQueryDetailsFactory;
 import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
 import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 
 /**
  * Perform assertions based on a LoadPlan, specifically against the outputs/expectations of the legacy Loader approach.
  * <p/>
  * Mainly this is intended to be a transitory set of help since it is expected that Loader will go away replaced by
  * LoadPlans, QueryBuilders and ResultSetProcessors.  For now I want to make sure that the outputs (e.g., the SQL,
  * the extraction aliases) are the same given the same input.  That makes sure we have the best possibility of success
  * in designing and implementing the "replacement parts".
  *
  * @author Steve Ebersole
  */
 public class LoadPlanStructureAssertionHelper {
 	/**
 	 * Singleton access to the helper
 	 */
 	public static final LoadPlanStructureAssertionHelper INSTANCE = new LoadPlanStructureAssertionHelper();
 
 	/**
 	 * Performs a basic comparison.  Builds a LoadPlan for the given persister and compares it against the
 	 * expectations according to the Loader/Walker corollary.
 	 *
 	 * @param sf The SessionFactory
 	 * @param persister The entity persister for which to build a LoadPlan and compare against the Loader/Walker
 	 * expectations.
 	 */
 	public void performBasicComparison(SessionFactoryImplementor sf, OuterJoinLoadable persister) {
 		// todo : allow these to be passed in by tests?
 		final LoadQueryInfluencers influencers = LoadQueryInfluencers.NONE;
 		final LockMode lockMode = LockMode.NONE;
 		final int batchSize = 1;
 
 		// legacy Loader-based contracts...
 		final EntityJoinWalker walker = new EntityJoinWalker(
 				persister,
 				persister.getKeyColumnNames(),
 				batchSize,
 				lockMode,
 				sf,
 				influencers
 		);
 //		final EntityLoader loader = new EntityLoader( persister, lockMode, sf, influencers );
 
 		LoadPlan plan = buildLoadPlan( sf, persister, influencers, lockMode );
-		LoadQueryDetails details = BatchingLoadQueryDetailsFactory.makeEntityLoadQueryDetails(
+		LoadQueryDetails details = BatchingLoadQueryDetailsFactory.INSTANCE.makeEntityLoadQueryDetails(
 				plan,
 				persister.getKeyColumnNames(),
 				new QueryBuildingParameters() {
 					@Override
 					public LoadQueryInfluencers getQueryInfluencers() {
 						return influencers;
 					}
 
 					@Override
 					public int getBatchSize() {
 						return batchSize;
 					}
 
 					@Override
 					public LockMode getLockMode() {
 						return lockMode;
 					}
 
 					@Override
 					public LockOptions getLockOptions() {
 						return null;
 					}
 				}, sf
 		);
 
 		compare( walker, details );
 	}
 
 	public LoadPlan buildLoadPlan(
 			SessionFactoryImplementor sf,
 			OuterJoinLoadable persister,
 			LoadQueryInfluencers influencers,
 			LockMode lockMode) {
 		FetchStyleLoadPlanBuildingAssociationVisitationStrategy strategy = new FetchStyleLoadPlanBuildingAssociationVisitationStrategy(
 				sf,
 				influencers,
 				lockMode
 				);
 		return MetamodelDrivenLoadPlanBuilder.buildRootEntityLoadPlan( strategy, persister );
 	}
 
 	public LoadPlan buildLoadPlan(SessionFactoryImplementor sf, OuterJoinLoadable persister) {
 		return buildLoadPlan( sf, persister, LoadQueryInfluencers.NONE, LockMode.NONE );
 	}
 
 	private void compare(JoinWalker walker, LoadQueryDetails details) {
 		System.out.println( "------ SQL -----------------------------------------------------------------" );
 		System.out.println( "WALKER    : " + walker.getSQLString() );
 		System.out.println( "LOAD-PLAN : " + details.getSqlStatement() );
 		System.out.println( "----------------------------------------------------------------------------" );
 		System.out.println( );
 		System.out.println( "------ SUFFIXES ------------------------------------------------------------" );
 		System.out.println( "WALKER    : " + StringHelper.join( ", ",  walker.getSuffixes() ) + " : "
 									+ StringHelper.join( ", ", walker.getCollectionSuffixes() ) );
 		System.out.println( "----------------------------------------------------------------------------" );
 		System.out.println( );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/loadplans/process/Helper.java b/hibernate-core/src/test/java/org/hibernate/test/loadplans/process/Helper.java
index 3a1f2e9bb7..a76ebe3ac3 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/loadplans/process/Helper.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/loadplans/process/Helper.java
@@ -1,94 +1,94 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.loadplans.process;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.plan.build.internal.FetchStyleLoadPlanBuildingAssociationVisitationStrategy;
 import org.hibernate.loader.plan.build.spi.MetamodelDrivenLoadPlanBuilder;
 import org.hibernate.loader.plan.exec.internal.BatchingLoadQueryDetailsFactory;
 import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
 import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * @author Steve Ebersole
  */
 public class Helper implements QueryBuildingParameters {
 	/**
 	 * Singleton access
 	 */
 	public static final Helper INSTANCE = new Helper();
 
 	private Helper() {
 	}
 
 	public LoadPlan buildLoadPlan(SessionFactoryImplementor sf, EntityPersister entityPersister) {
 		final FetchStyleLoadPlanBuildingAssociationVisitationStrategy strategy = new FetchStyleLoadPlanBuildingAssociationVisitationStrategy(
 				sf,
 				LoadQueryInfluencers.NONE,
 				LockMode.NONE
 		);
 		return MetamodelDrivenLoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
 	}
 
 	public LoadQueryDetails buildLoadQueryDetails(EntityPersister entityPersister, SessionFactoryImplementor sf) {
 		return buildLoadQueryDetails(
 				buildLoadPlan( sf, entityPersister ),
 				sf
 		);
 	}
 
 	public LoadQueryDetails buildLoadQueryDetails(LoadPlan loadPlan, SessionFactoryImplementor sf) {
-		return BatchingLoadQueryDetailsFactory.makeEntityLoadQueryDetails(
+		return BatchingLoadQueryDetailsFactory.INSTANCE.makeEntityLoadQueryDetails(
 				loadPlan,
 				null,
 				this,
 				sf
 		);
 	}
 
 	@Override
 	public LoadQueryInfluencers getQueryInfluencers() {
 		return LoadQueryInfluencers.NONE;
 	}
 
 	@Override
 	public int getBatchSize() {
 		return 1;
 	}
 
 	@Override
 	public LockMode getLockMode() {
 		return null;
 	}
 
 	@Override
 	public LockOptions getLockOptions() {
 		return null;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractEntityManagerImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractEntityManagerImpl.java
index ec0f8eda6d..e9b5d8b23d 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractEntityManagerImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractEntityManagerImpl.java
@@ -1,50 +1,51 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb;
 
 import java.io.Serializable;
 import java.util.Map;
 import javax.persistence.PersistenceContextType;
 import javax.persistence.SynchronizationType;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 
 import org.hibernate.jpa.internal.EntityManagerFactoryImpl;
 
 /**
  * @deprecated Use {@link org.hibernate.jpa.spi.AbstractEntityManagerImpl} instead
  */
+@Deprecated
 @SuppressWarnings("unchecked")
 public abstract class AbstractEntityManagerImpl
 		extends org.hibernate.jpa.spi.AbstractEntityManagerImpl
 		implements HibernateEntityManagerImplementor, Serializable {
 
 	protected AbstractEntityManagerImpl(
 			EntityManagerFactoryImpl entityManagerFactory,
 			PersistenceContextType type,
 			SynchronizationType synchronizationType,
 			PersistenceUnitTransactionType transactionType,
 			Map properties) {
 		super( entityManagerFactory, type, synchronizationType, transactionType, properties );
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/AvailableSettings.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/AvailableSettings.java
index 7986ada208..ea401ab94c 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/AvailableSettings.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/AvailableSettings.java
@@ -1,556 +1,557 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa;
 
 /**
  * Defines the available HEM settings, both JPA-defined as well as Hibernate-specific
  * <p/>
  * NOTE : Does *not* include {@link org.hibernate.cfg.Environment} values.
  *
  * @author Steve Ebersole
  */
 public interface AvailableSettings {
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// JPA defined settings
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * THe name of the {@link javax.persistence.spi.PersistenceProvider} implementor
 	 * <p/>
 	 * See JPA 2 sections 9.4.3 and 8.2.1.4
 	 */
 	String PROVIDER = "javax.persistence.provider";
 
 	/**
 	 * The type of transactions supported by the entity managers.
 	 * <p/>
 	 * See JPA 2 sections 9.4.3 and 8.2.1.2
 	 */
 	String TRANSACTION_TYPE = "javax.persistence.transactionType";
 
 	/**
 	 * The JNDI name of a JTA {@link javax.sql.DataSource}.
 	 * <p/>
 	 * See JPA 2 sections 9.4.3 and 8.2.1.5
 	 */
 	String JTA_DATASOURCE = "javax.persistence.jtaDataSource";
 
 	/**
 	 * The JNDI name of a non-JTA {@link javax.sql.DataSource}.
 	 * <p/>
 	 * See JPA 2 sections 9.4.3 and 8.2.1.5
 	 */
 	String NON_JTA_DATASOURCE = "javax.persistence.nonJtaDataSource";
 
 	/**
 	 * The name of a JDBC driver to use to connect to the database.
 	 * <p/>
 	 * Used in conjunction with {@link #JDBC_URL}, {@link #JDBC_USER} and {@link #JDBC_PASSWORD}
 	 * to define how to make connections to the database in lieu of
 	 * a datasource (either {@link #JTA_DATASOURCE} or {@link #NON_JTA_DATASOURCE}).
 	 * <p/>
 	 * See section 8.2.1.9
 	 */
 	String JDBC_DRIVER = "javax.persistence.jdbc.driver";
 
 	/**
 	 * The JDBC connection url to use to connect to the database.
 	 * <p/>
 	 * Used in conjunction with {@link #JDBC_DRIVER}, {@link #JDBC_USER} and {@link #JDBC_PASSWORD}
 	 * to define how to make connections to the database in lieu of
 	 * a datasource (either {@link #JTA_DATASOURCE} or {@link #NON_JTA_DATASOURCE}).
 	 * <p/>
 	 * See section 8.2.1.9
 	 */
 	String JDBC_URL = "javax.persistence.jdbc.url";
 
 	/**
 	 * The JDBC connection user name.
 	 * <p/>
 	 * Used in conjunction with {@link #JDBC_DRIVER}, {@link #JDBC_URL} and {@link #JDBC_PASSWORD}
 	 * to define how to make connections to the database in lieu of
 	 * a datasource (either {@link #JTA_DATASOURCE} or {@link #NON_JTA_DATASOURCE}).
 	 * <p/>
 	 * See section 8.2.1.9
 	 */
 	String JDBC_USER = "javax.persistence.jdbc.user";
 
 	/**
 	 * The JDBC connection password.
 	 * <p/>
 	 * Used in conjunction with {@link #JDBC_DRIVER}, {@link #JDBC_URL} and {@link #JDBC_USER}
 	 * to define how to make connections to the database in lieu of
 	 * a datasource (either {@link #JTA_DATASOURCE} or {@link #NON_JTA_DATASOURCE}).
 	 * <p/>
 	 * See JPA 2 section 8.2.1.9
 	 */
 	String JDBC_PASSWORD = "javax.persistence.jdbc.password";
 
 	/**
 	 * Used to indicate whether second-level (what JPA terms shared cache) caching is
 	 * enabled as per the rules defined in JPA 2 section 3.1.7.
 	 * <p/>
 	 * See JPA 2 sections 9.4.3 and 8.2.1.7
 	 * @see javax.persistence.SharedCacheMode
 	 */
 	String SHARED_CACHE_MODE = "javax.persistence.sharedCache.mode";
 
 	/**
 	 * NOTE : Not a valid EMF property...
 	 * <p/>
 	 * Used to indicate if the provider should attempt to retrieve requested data
 	 * in the shared cache.
 	 *
 	 * @see javax.persistence.CacheRetrieveMode
 	 */
 	String SHARED_CACHE_RETRIEVE_MODE ="javax.persistence.cache.retrieveMode";
 
 	/**
 	 * NOTE : Not a valid EMF property...
 	 * <p/>
 	 * Used to indicate if the provider should attempt to store data loaded from the database
 	 * in the shared cache.
 	 *
 	 * @see javax.persistence.CacheStoreMode
 	 */
 	String SHARED_CACHE_STORE_MODE ="javax.persistence.cache.storeMode";
 
 	/**
 	 * Used to indicate what form of automatic validation is in effect as per rules defined
 	 * in JPA 2 section 3.6.1.1
 	 * <p/>
 	 * See JPA 2 sections 9.4.3 and 8.2.1.8
 	 * @see javax.persistence.ValidationMode
 	 */
 	String VALIDATION_MODE = "javax.persistence.validation.mode";
 
 	/**
 	 * Used to pass along any discovered validator factory.
 	 */
 	String VALIDATION_FACTORY = "javax.persistence.validation.factory";
 
 	/**
 	 * Used to request (hint) a pessimistic lock scope.
 	 * <p/>
 	 * See JPA 2 sections 8.2.1.9 and 3.4.4.3
 	 */
 	String LOCK_SCOPE = "javax.persistence.lock.scope";
 
 	/**
 	 * Used to request (hint) a pessimistic lock timeout (in milliseconds).
 	 * <p/>
 	 * See JPA 2 sections 8.2.1.9 and 3.4.4.3
 	 */
 	String LOCK_TIMEOUT = "javax.persistence.lock.timeout";
 
 	/**
 	 * Used to coordinate with bean validators
 	 * <p/>
 	 * See JPA 2 section 8.2.1.9
 	 */
 	String PERSIST_VALIDATION_GROUP = "javax.persistence.validation.group.pre-persist";
 
 	/**
 	 * Used to coordinate with bean validators
 	 * <p/>
 	 * See JPA 2 section 8.2.1.9
 	 */
 	String UPDATE_VALIDATION_GROUP = "javax.persistence.validation.group.pre-update";
 
 	/**
 	 * Used to coordinate with bean validators
 	 * <p/>
 	 * See JPA 2 section 8.2.1.9
 	 */
 	String REMOVE_VALIDATION_GROUP = "javax.persistence.validation.group.pre-remove";
 
 	/**
 	 * Used to pass along the CDI BeanManager, if any, to be used.
 	 */
 	String CDI_BEAN_MANAGER = "javax.persistence.bean.manager";
 
 	/**
 	 * Specifies whether schema generation commands for schema creation are to be determine based on object/relational
 	 * mapping metadata, DDL scripts, or a combination of the two.  See {@link SchemaGenSource} for valid set of values.
 	 * If no value is specified, a default is assumed as follows:<ul>
 	 *     <li>
 	 *         if source scripts are specified (per {@value #SCHEMA_GEN_CREATE_SCRIPT_SOURCE}),then "scripts" is assumed
 	 *     </li>
 	 *     <li>
 	 *         otherwise, "metadata" is assumed
 	 *     </li>
 	 * </ul>
 	 *
 	 * @see SchemaGenSource
 	 */
 	String SCHEMA_GEN_CREATE_SOURCE = "javax.persistence.schema-generation.create-source";
 
 	/**
 	 * Specifies whether schema generation commands for schema dropping are to be determine based on object/relational
 	 * mapping metadata, DDL scripts, or a combination of the two.  See {@link SchemaGenSource} for valid set of values.
 	 * If no value is specified, a default is assumed as follows:<ul>
 	 *     <li>
 	 *         if source scripts are specified (per {@value #SCHEMA_GEN_DROP_SCRIPT_SOURCE}),then "scripts" is assumed
 	 *     </li>
 	 *     <li>
 	 *         otherwise, "metadata" is assumed
 	 *     </li>
 	 * </ul>
 	 *
 	 * @see SchemaGenSource
 	 */
 	String SCHEMA_GEN_DROP_SOURCE = "javax.persistence.schema-generation.drop-source";
 
 	/**
 	 * Specifies the CREATE script file as either a {@link java.io.Reader} configured for reading of the DDL script
 	 * file or a string designating a file {@link java.net.URL} for the DDL script.
 	 *
 	 * @see #SCHEMA_GEN_CREATE_SOURCE
 	 * @see #SCHEMA_GEN_DROP_SCRIPT_SOURCE
 	 */
 	String SCHEMA_GEN_CREATE_SCRIPT_SOURCE = "javax.persistence.schema-generation.create-script-source";
 
 	/**
 	 * Specifies the DROP script file as either a {@link java.io.Reader} configured for reading of the DDL script
 	 * file or a string designating a file {@link java.net.URL} for the DDL script.
 	 *
 	 * @see #SCHEMA_GEN_DROP_SOURCE
 	 * @see #SCHEMA_GEN_CREATE_SCRIPT_SOURCE
 	 */
 	String SCHEMA_GEN_DROP_SCRIPT_SOURCE = "javax.persistence.schema-generation.drop-script-source";
 
 	/**
 	 * Specifies the type of schema generation action to be taken by the persistence provider in regards to sending
 	 * commands directly to the database via JDBC.  See {@link SchemaGenAction} for the set of possible values.
 	 * <p/>
 	 * If no value is specified, the default is "none".
 	 *
 	 * @see SchemaGenAction
 	 */
 	String SCHEMA_GEN_DATABASE_ACTION = "javax.persistence.schema-generation.database.action";
 
 	/**
 	 * Specifies the type of schema generation action to be taken by the persistence provider in regards to writing
 	 * commands to DDL script files.  See {@link SchemaGenAction} for the set of possible values.
 	 * <p/>
 	 * If no value is specified, the default is "none".
 	 *
 	 * @see SchemaGenAction
 	 */
 	String SCHEMA_GEN_SCRIPTS_ACTION = "javax.persistence.schema-generation.scripts.action";
 
 	/**
 	 * For cases where the {@value #SCHEMA_GEN_SCRIPTS_ACTION} value indicates that schema creation commands should
 	 * be written to DDL script file, {@value #SCHEMA_GEN_SCRIPTS_CREATE_TARGET} specifies either a
 	 * {@link java.io.Writer} configured for output of the DDL script or a string specifying the file URL for the DDL
 	 * script.
 	 *
 	 * @see #SCHEMA_GEN_SCRIPTS_ACTION
 	 */
 	@SuppressWarnings("JavaDoc")
 	String SCHEMA_GEN_SCRIPTS_CREATE_TARGET = "javax.persistence.schema-generation.scripts.create-target";
 
 	/**
 	 * For cases where the {@value #SCHEMA_GEN_SCRIPTS_ACTION} value indicates that schema drop commands should
 	 * be written to DDL script file, {@value #SCHEMA_GEN_SCRIPTS_DROP_TARGET} specifies either a
 	 * {@link java.io.Writer} configured for output of the DDL script or a string specifying the file URL for the DDL
 	 * script.
 	 *
 	 * @see #SCHEMA_GEN_SCRIPTS_ACTION
 	 */
 	@SuppressWarnings("JavaDoc")
 	String SCHEMA_GEN_SCRIPTS_DROP_TARGET = "javax.persistence.schema-generation.scripts.drop-target";
 
 	/**
 	 * Specifies whether the persistence provider is to create the database schema(s) in addition to creating
 	 * database objects (tables, sequences, constraints, etc).  The value of this boolean property should be set
 	 * to {@code true} if the persistence provider is to create schemas in the database or to generate DDL that
 	 * contains "CREATE SCHEMA" commands.  If this property is not supplied (or is explicitly {@code false}), the
 	 * provider should not attempt to create database schemas.
 	 */
 	String SCHEMA_GEN_CREATE_SCHEMAS = "javax.persistence.create-database-schemas";
 
 	/**
 	 * Allows passing the specific {@link java.sql.Connection} instance to be used for performing schema generation
 	 * where the target is "database".
 	 * <p/>
 	 * May also be used to determine the values for {@value #SCHEMA_GEN_DB_NAME},
 	 * {@value #SCHEMA_GEN_DB_MAJOR_VERSION} and {@value #SCHEMA_GEN_DB_MINOR_VERSION}.
 	 */
 	String SCHEMA_GEN_CONNECTION = "javax.persistence.schema-generation-connection";
 
 	/**
 	 * Specifies the name of the database provider in cases where a Connection to the underlying database is
 	 * not available (aka, mainly in generating scripts).  In such cases, a value for
 	 * {@value #SCHEMA_GEN_DB_NAME} *must* be specified.
 	 * <p/>
 	 * The value of this setting is expected to match the value returned by
 	 * {@link java.sql.DatabaseMetaData#getDatabaseProductName()} for the target database.
 	 * <p/>
 	 * Additionally specifying {@value #SCHEMA_GEN_DB_MAJOR_VERSION} and/or {@value #SCHEMA_GEN_DB_MINOR_VERSION}
 	 * may be required to understand exactly how to generate the required schema commands.
 	 *
 	 * @see #SCHEMA_GEN_DB_MAJOR_VERSION
 	 * @see #SCHEMA_GEN_DB_MINOR_VERSION
 	 */
 	@SuppressWarnings("JavaDoc")
 	String SCHEMA_GEN_DB_NAME = "javax.persistence.database-product-name";
 
 	/**
 	 * Specifies the major version of the underlying database, as would be returned by
 	 * {@link java.sql.DatabaseMetaData#getDatabaseMajorVersion} for the target database.  This value is used to
 	 * help more precisely determine how to perform schema generation tasks for the underlying database in cases
 	 * where {@value #SCHEMA_GEN_DB_NAME} does not provide enough distinction.
 
 	 * @see #SCHEMA_GEN_DB_NAME
 	 * @see #SCHEMA_GEN_DB_MINOR_VERSION
 	 */
 	String SCHEMA_GEN_DB_MAJOR_VERSION = "javax.persistence.database-major-version";
 
 	/**
 	 * Specifies the minor version of the underlying database, as would be returned by
 	 * {@link java.sql.DatabaseMetaData#getDatabaseMinorVersion} for the target database.  This value is used to
 	 * help more precisely determine how to perform schema generation tasks for the underlying database in cases
 	 * where te combination of {@value #SCHEMA_GEN_DB_NAME} and {@value #SCHEMA_GEN_DB_MAJOR_VERSION} does not provide
 	 * enough distinction.
 	 *
 	 * @see #SCHEMA_GEN_DB_NAME
 	 * @see #SCHEMA_GEN_DB_MAJOR_VERSION
 	 */
 	String SCHEMA_GEN_DB_MINOR_VERSION = "javax.persistence.database-minor-version";
 
 	/**
 	 * Specifies a {@link java.io.Reader} configured for reading of the SQL load script or a string designating the
 	 * file {@link java.net.URL} for the SQL load script.
 	 * <p/>
 	 * A "SQL load script" is a script that performs some database initialization (INSERT, etc).
 	 */
 	String SCHEMA_GEN_LOAD_SCRIPT_SOURCE = "javax.persistence.sql-load-script-source";
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Hibernate specific settings
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Query hint (aka {@link javax.persistence.Query#setHint}) for applying
 	 * an alias specific lock mode (aka {@link org.hibernate.Query#setLockMode}).
 	 * <p/>
 	 * Either {@link org.hibernate.LockMode} or {@link javax.persistence.LockModeType}
 	 * are accepted.  Also the String names of either are accepted as well.  <tt>null</tt>
 	 * is additionally accepted as meaning {@link org.hibernate.LockMode#NONE}.
 	 * <p/>
 	 * Usage is to concatenate this setting name and the alias name together, separated
 	 * by a dot.  For example<code>Query.setHint( "org.hibernate.lockMode.a", someLockMode )</code>
 	 * would apply <code>someLockMode</code> to the alias <code>"a"</code>.
 	 */
 	//Use the org.hibernate prefix. instead of hibernate. as it is a query hint se QueryHints
 	String ALIAS_SPECIFIC_LOCK_MODE = "org.hibernate.lockMode";
 
 	/**
 	 * JAR autodetection artifacts class, hbm
 	 *
 	 * @deprecated Use {@link org.hibernate.cfg.AvailableSettings#SCANNER_DISCOVERY} instead
 	 */
 	@Deprecated
 	String AUTODETECTION = org.hibernate.cfg.AvailableSettings.SCANNER_DISCOVERY;
 
 	/**
 	 * cfg.xml configuration file used
 	 */
 	String CFG_FILE = "hibernate.ejb.cfgfile";
 
 	/**
 	 * Caching configuration should follow the following pattern
 	 * hibernate.ejb.classcache.<fully.qualified.Classname> usage[, region]
 	 * where usage is the cache strategy used and region the cache region name
 	 */
 	String CLASS_CACHE_PREFIX = "hibernate.ejb.classcache";
 
 	/**
 	 * Caching configuration should follow the following pattern
 	 * hibernate.ejb.collectioncache.<fully.qualified.Classname>.<role> usage[, region]
 	 * where usage is the cache strategy used and region the cache region name
 	 */
 	String COLLECTION_CACHE_PREFIX = "hibernate.ejb.collectioncache";
 
 	/**
 	 * Interceptor class name, the class has to have a no-arg constructor
 	 * the interceptor instance is shared amongst all EntityManager of a given EntityManagerFactory
 	 */
 	String INTERCEPTOR = "hibernate.ejb.interceptor";
 
 	/**
 	 * Interceptor class name, the class has to have a no-arg constructor
 	 */
 	String SESSION_INTERCEPTOR = "hibernate.ejb.interceptor.session_scoped";
 
 	/**
 	 * SessionFactoryObserver class name, the class must have a no-arg constructor
 	 */
 	String SESSION_FACTORY_OBSERVER = "hibernate.ejb.session_factory_observer";
 
 	/**
 	 * Naming strategy class name, the class has to have a no-arg constructor
 	 *
 	 * @deprecated Use {@link org.hibernate.cfg.AvailableSettings#IMPLICIT_NAMING_STRATEGY}
 	 * or {@link org.hibernate.cfg.AvailableSettings#PHYSICAL_NAMING_STRATEGY} instead
 	 */
 	@Deprecated
 	String NAMING_STRATEGY = "hibernate.ejb.naming_strategy";
 
 	/**
 	 * IdentifierGeneratorStrategyProvider class name, the class must have a no-arg constructor
 	 * @deprecated if possible wait of Hibernate 4.1 and theService registry (MutableIdentifierGeneratorStrategy service)
 	 */
+	@Deprecated
 	String IDENTIFIER_GENERATOR_STRATEGY_PROVIDER = "hibernate.ejb.identifier_generator_strategy_provider";
 
 	/**
 	 * Event configuration should follow the following pattern
 	 * hibernate.ejb.event.[eventType] f.q.c.n.EventListener1, f.q.c.n.EventListener12 ...
 	 */
 	String EVENT_LISTENER_PREFIX = "hibernate.ejb.event";
 
 	/**
 	 * Enable the class file enhancement
 	 */
 	String USE_CLASS_ENHANCER = "hibernate.ejb.use_class_enhancer";
 
 	/**
 	 * Whether or not discard persistent context on entityManager.close()
 	 * The EJB3 compliant and default choice is false
 	 */
 	String DISCARD_PC_ON_CLOSE = "hibernate.ejb.discard_pc_on_close";
 
 	/**
 	 * Consider this as experimental
 	 * It is not recommended to set up this property, the configuration is stored
 	 * in the JNDI in a serialized form
 	 *
 	 * @deprecated Configuration going away.
 	 */
 	@Deprecated
 	String CONFIGURATION_JNDI_NAME = "hibernate.ejb.configuration_jndi_name";
 
 	/**
 	 * Used to determine flush mode.
 	 */
 	//Use the org.hibernate prefix. instead of hibernate. as it is a query hint se QueryHints
 	String FLUSH_MODE = "org.hibernate.flushMode";
 
 	/**
 	 * @deprecated Prefer {@link org.hibernate.cfg.AvailableSettings#SCANNER} instead
 	 */
 	@Deprecated
 	@SuppressWarnings("UnusedDeclaration")
 	String SCANNER = org.hibernate.cfg.AvailableSettings.SCANNER_DEPRECATED;
 
 	/**
 	 * List of classes names
 	 * Internal use only
 	 *
 	 * @deprecated Was never intended for external use
 	 */
 	@Deprecated
 	@SuppressWarnings("UnusedDeclaration")
 	String CLASS_NAMES = "hibernate.ejb.classes";
 
 	/**
 	 * List of annotated packages
 	 * Internal use only
 	 *
 	 * @deprecated Was never intended for external use
 	 */
 	@Deprecated
 	@SuppressWarnings("UnusedDeclaration")
 	String PACKAGE_NAMES = "hibernate.ejb.packages";
 
 	/**
 	 * EntityManagerFactory name
 	 */
 	String ENTITY_MANAGER_FACTORY_NAME = "hibernate.ejb.entitymanager_factory_name";
 
 	/**
 	 * @deprecated use {@link #JPA_METAMODEL_POPULATION} instead.
 	 */
 	@Deprecated
 	String JPA_METAMODEL_GENERATION = "hibernate.ejb.metamodel.generation";
 
 	/**
 	 * Setting that controls whether we seek out JPA "static metamodel" classes and populate them.  Accepts
 	 * 3 values:<ul>
 	 *     <li>
 	 *         <b>enabled</b> - Do the population
 	 *     </li>
 	 *     <li>
 	 *         <b>disabled</b> - Do not do the population
 	 *     </li>
 	 *     <li>
 	 *         <b>ignoreUnsupported</b> - Do the population, but ignore any non-JPA features that would otherwise
 	 *         result in the population failing.
 	 *     </li>
 	 * </ul>
 	 *
 	 */
 	String JPA_METAMODEL_POPULATION = "hibernate.ejb.metamodel.population";
 
 
 	/**
 	 * List of classes names
 	 * Internal use only
 	 */
 	String XML_FILE_NAMES = "hibernate.ejb.xml_files";
 	String HBXML_FILES = "hibernate.hbmxml.files";
 	String LOADED_CLASSES = "hibernate.ejb.loaded.classes";
 
 	/**
 	 * Deprecated
 	 *
 	 * @deprecated Use {@link org.hibernate.cfg.AvailableSettings#JACC_CONTEXT_ID} instead
 	 */
 	@Deprecated
 	String JACC_CONTEXT_ID = org.hibernate.cfg.AvailableSettings.JACC_CONTEXT_ID;
 
 	/**
 	 * Deprecated
 	 *
 	 * @deprecated Use {@link org.hibernate.cfg.AvailableSettings#JACC_PREFIX} instead
 	 */
 	@Deprecated
 	String JACC_PREFIX = org.hibernate.cfg.AvailableSettings.JACC_PREFIX;
 
 	/**
 	 * Deprecated
 	 *
 	 * @deprecated Use {@link org.hibernate.cfg.AvailableSettings#JACC_ENABLED} instead
 	 */
 	@Deprecated
 	String JACC_ENABLED = org.hibernate.cfg.AvailableSettings.JACC_ENABLED;
 
 	/**
 	 * Used to pass along the name of the persistence unit.
 	 */
 	String PERSISTENCE_UNIT_NAME = "hibernate.ejb.persistenceUnitName";
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/LegacyCallbackProcessor.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/LegacyCallbackProcessor.java
index 546e1a71eb..7cb98f3d53 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/LegacyCallbackProcessor.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/LegacyCallbackProcessor.java
@@ -1,240 +1,244 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.event.internal.jpa;
 
 import org.hibernate.MappingException;
 import org.hibernate.annotations.common.reflection.ClassLoadingException;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XMethod;
 import org.hibernate.jpa.event.spi.jpa.Callback;
 import org.hibernate.jpa.event.spi.jpa.ListenerFactory;
 import org.jboss.logging.Logger;
 
 import javax.persistence.Entity;
 import javax.persistence.EntityListeners;
 import javax.persistence.ExcludeDefaultListeners;
 import javax.persistence.ExcludeSuperclassListeners;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.PersistenceException;
 import java.lang.annotation.Annotation;
 import java.lang.annotation.ElementType;
 import java.lang.annotation.Target;
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.List;
 
 /**
  * @author <a href="mailto:kabir.khan@jboss.org">Kabir Khan</a>
  * @author Steve Ebersole
  */
 public class LegacyCallbackProcessor implements CallbackProcessor {
 	private static final Logger log = Logger.getLogger( LegacyCallbackProcessor.class );
 
 	private final ListenerFactory jpaListenerFactory;
 	private final ReflectionManager reflectionManager;
 
 	public LegacyCallbackProcessor(ListenerFactory jpaListenerFactory, ReflectionManager reflectionManager) {
 		this.jpaListenerFactory = jpaListenerFactory;
 		this.reflectionManager = reflectionManager;
 	}
 
 	@Override
 	public void processCallbacksForEntity(Object entityObject, CallbackRegistryImpl callbackRegistry) {
 		final String entityClassName = (String) entityObject;
 		try {
 			final XClass entityXClass = reflectionManager.classForName( entityClassName );
 			final Class entityClass = reflectionManager.toClass( entityXClass );
 			for ( Class annotationClass : CALLBACK_ANNOTATION_CLASSES ) {
 				final Callback[] callbacks = resolveCallbacks( entityXClass, annotationClass, reflectionManager );
 				callbackRegistry.addEntityCallbacks( entityClass, annotationClass, callbacks );
 			}
 		}
 		catch (ClassLoadingException e) {
 			throw new MappingException( "entity class not found: " + entityClassName, e );
 		}
 	}
 
 	public Callback[] resolveCallbacks(XClass beanClass, Class annotation, ReflectionManager reflectionManager) {
 		List<Callback> callbacks = new ArrayList<Callback>();
 		List<String> callbacksMethodNames = new ArrayList<String>(); //used to track overridden methods
 		List<Class> orderedListeners = new ArrayList<Class>();
 		XClass currentClazz = beanClass;
 		boolean stopListeners = false;
 		boolean stopDefaultListeners = false;
 		do {
 			Callback callback = null;
 			List<XMethod> methods = currentClazz.getDeclaredMethods();
 			final int size = methods.size();
 			for ( int i = 0; i < size ; i++ ) {
 				final XMethod xMethod = methods.get( i );
 				if ( xMethod.isAnnotationPresent( annotation ) ) {
 					Method method = reflectionManager.toMethod( xMethod );
 					final String methodName = method.getName();
 					if ( ! callbacksMethodNames.contains( methodName ) ) {
 						//overridden method, remove the superclass overridden method
 						if ( callback == null ) {
 							callback = new EntityCallback( method );
 							Class returnType = method.getReturnType();
 							Class[] args = method.getParameterTypes();
 							if ( returnType != Void.TYPE || args.length != 0 ) {
 								throw new RuntimeException(
 										"Callback methods annotated on the bean class must return void and take no arguments: " + annotation
 												.getName() + " - " + xMethod
 								);
 							}
 							method.setAccessible(true);
 							log.debugf("Adding %s as %s callback for entity %s",
 									   methodName,
 									   annotation.getSimpleName(),
 									   beanClass.getName());
 							callbacks.add( 0, callback ); //superclass first
 							callbacksMethodNames.add( 0, methodName );
 						}
 						else {
 							throw new PersistenceException(
 									"You can only annotate one callback method with "
 											+ annotation.getName() + " in bean class: " + beanClass.getName()
 							);
 						}
 					}
 				}
 			}
 			if ( !stopListeners ) {
 				getListeners( currentClazz, orderedListeners );
 				stopListeners = currentClazz.isAnnotationPresent( ExcludeSuperclassListeners.class );
 				stopDefaultListeners = currentClazz.isAnnotationPresent( ExcludeDefaultListeners.class );
 			}
 
 			do {
 				currentClazz = currentClazz.getSuperclass();
 			}
 			while ( currentClazz != null
 					&& ! ( currentClazz.isAnnotationPresent( Entity.class )
 					|| currentClazz.isAnnotationPresent( MappedSuperclass.class ) )
 					);
 		}
 		while ( currentClazz != null );
 
 		//handle default listeners
 		if ( ! stopDefaultListeners ) {
 			List<Class> defaultListeners = (List<Class>) reflectionManager.getDefaults().get( EntityListeners.class );
 
 			if ( defaultListeners != null ) {
 				int defaultListenerSize = defaultListeners.size();
 				for ( int i = defaultListenerSize - 1; i >= 0 ; i-- ) {
 					orderedListeners.add( defaultListeners.get( i ) );
 				}
 			}
 		}
 
 		for ( Class listener : orderedListeners ) {
 			Callback callback = null;
 			if ( listener != null ) {
 				XClass xListener = reflectionManager.toXClass( listener );
 				callbacksMethodNames = new ArrayList<String>();
 				List<XMethod> methods = xListener.getDeclaredMethods();
 				final int size = methods.size();
 				for ( int i = 0; i < size ; i++ ) {
 					final XMethod xMethod = methods.get( i );
 					if ( xMethod.isAnnotationPresent( annotation ) ) {
 						final Method method = reflectionManager.toMethod( xMethod );
 						final String methodName = method.getName();
 						if ( ! callbacksMethodNames.contains( methodName ) ) {
 							//overridden method, remove the superclass overridden method
 							if ( callback == null ) {
 								callback = new ListenerCallback( jpaListenerFactory.buildListener( listener ), method );
 
 								Class returnType = method.getReturnType();
 								Class[] args = method.getParameterTypes();
 								if ( returnType != Void.TYPE || args.length != 1 ) {
 									throw new PersistenceException(
 											"Callback methods annotated in a listener bean class must return void and take one argument: " + annotation
 													.getName() + " - " + method
 									);
 								}
-								if (!method.isAccessible()) method.setAccessible(true);
+								if (!method.isAccessible()) {
+									method.setAccessible(true);
+								}
 								log.debugf("Adding %s as %s callback for entity %s",
 										   methodName,
 										   annotation.getSimpleName(),
 										   beanClass.getName());
 								callbacks.add( 0, callback ); // listeners first
 							}
 							else {
 								throw new PersistenceException(
 										"You can only annotate one callback method with "
 												+ annotation.getName() + " in bean class: " + beanClass.getName() + " and callback listener: "
 												+ listener.getName()
 								);
 							}
 						}
 					}
 				}
 			}
 		}
 		return callbacks.toArray( new Callback[ callbacks.size() ] );
 	}
 
 	private static boolean useAnnotationAnnotatedByListener;
 
 	static {
 		//check whether reading annotations of annotations is useful or not
 		useAnnotationAnnotatedByListener = false;
 		Target target = EntityListeners.class.getAnnotation( Target.class );
 		if ( target != null ) {
 			for ( ElementType type : target.value() ) {
-				if ( type.equals( ElementType.ANNOTATION_TYPE ) ) useAnnotationAnnotatedByListener = true;
+				if ( type.equals( ElementType.ANNOTATION_TYPE ) ) {
+					useAnnotationAnnotatedByListener = true;
+				}
 			}
 		}
 	}
 
 	private static void getListeners(XClass currentClazz, List<Class> orderedListeners) {
 		EntityListeners entityListeners = currentClazz.getAnnotation( EntityListeners.class );
 		if ( entityListeners != null ) {
 			Class[] classes = entityListeners.value();
 			int size = classes.length;
 			for ( int index = size - 1; index >= 0 ; index-- ) {
 				orderedListeners.add( classes[index] );
 			}
 		}
 		if ( useAnnotationAnnotatedByListener ) {
 			Annotation[] annotations = currentClazz.getAnnotations();
 			for ( Annotation annot : annotations ) {
 				entityListeners = annot.getClass().getAnnotation( EntityListeners.class );
 				if ( entityListeners != null ) {
 					Class[] classes = entityListeners.value();
 					int size = classes.length;
 					for ( int index = size - 1; index >= 0 ; index-- ) {
 						orderedListeners.add( classes[index] );
 					}
 				}
 			}
 		}
 	}
 
 	@Override
 	public void release() {
 		// nothing to do here
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/QueryImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/QueryImpl.java
index 0a95568e88..4ad57895cd 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/QueryImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/QueryImpl.java
@@ -1,581 +1,583 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal;
 
 import java.util.Calendar;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Date;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 import javax.persistence.ParameterMode;
 import javax.persistence.PersistenceException;
 import javax.persistence.Query;
 import javax.persistence.TemporalType;
 import javax.persistence.TypedQuery;
 
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.SQLQuery;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NamedParameterDescriptor;
 import org.hibernate.engine.query.spi.OrdinalParameterDescriptor;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.QueryExecutionRequestException;
 import org.hibernate.internal.SQLQueryImpl;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.HibernateQuery;
 import org.hibernate.jpa.internal.util.ConfigurationHelper;
 import org.hibernate.jpa.internal.util.LockModeTypeHelper;
 import org.hibernate.jpa.spi.AbstractEntityManagerImpl;
 import org.hibernate.jpa.spi.AbstractQueryImpl;
 import org.hibernate.jpa.spi.ParameterBind;
 import org.hibernate.jpa.spi.ParameterRegistration;
 import org.hibernate.type.CompositeCustomType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 import static javax.persistence.TemporalType.DATE;
 import static javax.persistence.TemporalType.TIME;
 import static javax.persistence.TemporalType.TIMESTAMP;
 
 /**
  * Hibernate implementation of both the {@link Query} and {@link TypedQuery} contracts.
  *
  * @author <a href="mailto:gavin@hibernate.org">Gavin King</a>
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  */
 public class QueryImpl<X> extends AbstractQueryImpl<X> implements TypedQuery<X>, HibernateQuery, org.hibernate.ejb.HibernateQuery {
 
     public static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class, QueryImpl.class.getName());
 
 	private org.hibernate.Query query;
 
 	public QueryImpl(org.hibernate.Query query, AbstractEntityManagerImpl em) {
 		this( query, em, Collections.<String, Class>emptyMap() );
 	}
 
 	public QueryImpl(
 			org.hibernate.Query query,
 			AbstractEntityManagerImpl em,
 			Map<String,Class> namedParameterTypeRedefinitions) {
 		super( em );
 		this.query = query;
 		extractParameterInfo( namedParameterTypeRedefinitions );
 	}
 
 	@Override
 	protected boolean isNativeSqlQuery() {
 		return SQLQuery.class.isInstance( query );
 	}
 
 	@Override
 	protected boolean isSelectQuery() {
 		if ( isNativeSqlQuery() ) {
 			throw new IllegalStateException( "Cannot tell if native SQL query is SELECT query" );
 		}
 
 		return org.hibernate.internal.QueryImpl.class.cast( query ).isSelect();
 	}
 
 	@SuppressWarnings({ "unchecked", "RedundantCast" })
 	private void extractParameterInfo(Map<String,Class> namedParameterTypeRedefinition) {
 		if ( ! org.hibernate.internal.AbstractQueryImpl.class.isInstance( query ) ) {
 			throw new IllegalStateException( "Unknown query type for parameter extraction" );
 		}
 
 		boolean hadJpaPositionalParameters = false;
 
 		final ParameterMetadata parameterMetadata = org.hibernate.internal.AbstractQueryImpl.class.cast( query ).getParameterMetadata();
 
 		// extract named params
 		for ( String name : (Set<String>) parameterMetadata.getNamedParameterNames() ) {
 			final NamedParameterDescriptor descriptor = parameterMetadata.getNamedParameterDescriptor( name );
 			Class javaType = namedParameterTypeRedefinition.get( name );
 			if ( javaType != null && mightNeedRedefinition( javaType, descriptor.getExpectedType() ) ) {
 				descriptor.resetExpectedType(
 						sfi().getTypeResolver().heuristicType( javaType.getName() )
 				);
 			}
 			else if ( descriptor.getExpectedType() != null ) {
 				javaType = descriptor.getExpectedType().getReturnedClass();
 			}
 
 			if ( descriptor.isJpaStyle() ) {
 				hadJpaPositionalParameters = true;
 				final Integer position = Integer.valueOf( name );
 				registerParameter( new JpaPositionalParameterRegistrationImpl( this, query, position, javaType ) );
 			}
 			else {
 				registerParameter( new ParameterRegistrationImpl( this, query, name, javaType ) );
 			}
 		}
 
 		if ( hadJpaPositionalParameters ) {
 			if ( parameterMetadata.getOrdinalParameterCount() > 0 ) {
 				throw new IllegalArgumentException(
 						"Cannot mix JPA positional parameters and native Hibernate positional/ordinal parameters"
 				);
 			}
 		}
 
 		// extract Hibernate native positional parameters
 		for ( int i = 0, max = parameterMetadata.getOrdinalParameterCount(); i < max; i++ ) {
 			final OrdinalParameterDescriptor descriptor = parameterMetadata.getOrdinalParameterDescriptor( i + 1 );
 			Class javaType = descriptor.getExpectedType() == null ? null : descriptor.getExpectedType().getReturnedClass();
 			registerParameter( new ParameterRegistrationImpl( this, query, i+1, javaType ) );
 		}
 	}
 
 	private SessionFactoryImplementor sfi() {
 		return (SessionFactoryImplementor) getEntityManager().getFactory().getSessionFactory();
 	}
 
 	private boolean mightNeedRedefinition(Class javaType, Type expectedType) {
 		// only redefine dates/times/timestamps that are not wrapped in a CompositeCustomType
-		if ( expectedType == null )
+		if ( expectedType == null ) {
 			return java.util.Date.class.isAssignableFrom( javaType );
-		else
+		}
+		else {
 			return java.util.Date.class.isAssignableFrom( javaType )
 					&& !CompositeCustomType.class.isAssignableFrom( expectedType.getClass() );
+		}
 	}
 
 	private static class ParameterRegistrationImpl<T> implements ParameterRegistration<T> {
 		private final Query jpaQuery;
 		private final org.hibernate.Query nativeQuery;
 
 		private final String name;
 		private final Integer position;
 		private final Class<T> javaType;
 
 		private ParameterBind<T> bind;
 
 		protected ParameterRegistrationImpl(
 				Query jpaQuery,
 				org.hibernate.Query nativeQuery,
 				String name,
 				Class<T> javaType) {
 			this.jpaQuery = jpaQuery;
 			this.nativeQuery = nativeQuery;
 			this.name = name;
 			this.javaType = javaType;
 			this.position = null;
 		}
 
 		protected ParameterRegistrationImpl(
 				Query jpaQuery,
 				org.hibernate.Query nativeQuery,
 				Integer position,
 				Class<T> javaType) {
 			this.jpaQuery = jpaQuery;
 			this.nativeQuery = nativeQuery;
 			this.position = position;
 			this.javaType = javaType;
 			this.name = null;
 		}
 
 		@Override
 		public boolean isJpaPositionalParameter() {
 			return false;
 		}
 
 		@Override
 		public Query getQuery() {
 			return jpaQuery;
 		}
 
 		@Override
 		public String getName() {
 			return name;
 		}
 
 		@Override
 		public Integer getPosition() {
 			return position;
 		}
 
 		@Override
 		public Class<T> getParameterType() {
 			return javaType;
 		}
 
 		@Override
 		public ParameterMode getMode() {
 			// implicitly
 			return ParameterMode.IN;
 		}
 
 		@Override
 		public boolean isBindable() {
 			// again, implicitly
 			return true;
 		}
 
 		@Override
 		public void bindValue(T value) {
 			validateBinding( getParameterType(), value, null );
 
 			if ( name != null ) {
 				if ( value instanceof Collection ) {
 					nativeQuery.setParameterList( name, (Collection) value );
 				}
 				else {
 					nativeQuery.setParameter( name, value );
 				}
 			}
 			else {
 				nativeQuery.setParameter( position - 1, value );
 			}
 
 			bind = new ParameterBindImpl<T>( value, null );
 		}
 
 		@Override
 		public void bindValue(T value, TemporalType specifiedTemporalType) {
 			validateBinding( getParameterType(), value, specifiedTemporalType );
 
 			if ( Date.class.isInstance( value ) ) {
 				if ( name != null ) {
 					if ( specifiedTemporalType == DATE ) {
 						nativeQuery.setDate( name, (Date) value );
 					}
 					else if ( specifiedTemporalType == TIME ) {
 						nativeQuery.setTime( name, (Date) value );
 					}
 					else if ( specifiedTemporalType == TIMESTAMP ) {
 						nativeQuery.setTimestamp( name, (Date) value );
 					}
 				}
 				else {
 					if ( specifiedTemporalType == DATE ) {
 						nativeQuery.setDate( position - 1, (Date) value );
 					}
 					else if ( specifiedTemporalType == TIME ) {
 						nativeQuery.setTime( position - 1, (Date) value );
 					}
 					else if ( specifiedTemporalType == TIMESTAMP ) {
 						nativeQuery.setTimestamp( position - 1, (Date) value );
 					}
 				}
 			}
 			else if ( Calendar.class.isInstance( value ) ) {
 				if ( name != null ) {
 					if ( specifiedTemporalType == DATE ) {
 						nativeQuery.setCalendarDate( name, (Calendar) value );
 					}
 					else if ( specifiedTemporalType == TIME ) {
 						throw new IllegalArgumentException( "not yet implemented" );
 					}
 					else if ( specifiedTemporalType == TIMESTAMP ) {
 						nativeQuery.setCalendar( name, (Calendar) value );
 					}
 				}
 				else {
 					if ( specifiedTemporalType == DATE ) {
 						nativeQuery.setCalendarDate( position - 1, (Calendar) value );
 					}
 					else if ( specifiedTemporalType == TIME ) {
 						throw new IllegalArgumentException( "not yet implemented" );
 					}
 					else if ( specifiedTemporalType == TIMESTAMP ) {
 						nativeQuery.setCalendar( position - 1, (Calendar) value );
 					}
 				}
 			}
 			else {
 				throw new IllegalArgumentException(
 						"Unexpected type [" + value + "] passed with TemporalType; expecting Date or Calendar"
 				);
 			}
 
 			bind = new ParameterBindImpl<T>( value, specifiedTemporalType );
 		}
 
 		@Override
 		public ParameterBind<T> getBind() {
 			return bind;
 		}
 	}
 
 	/**
 	 * Specialized handling for JPA "positional parameters".
 	 *
 	 * @param <T> The parameter type type.
 	 */
 	public static class JpaPositionalParameterRegistrationImpl<T> extends ParameterRegistrationImpl<T> {
 		final Integer position;
 
 		protected JpaPositionalParameterRegistrationImpl(
 				Query jpaQuery,
 				org.hibernate.Query nativeQuery,
 				Integer position,
 				Class<T> javaType) {
 			super( jpaQuery, nativeQuery, position.toString(), javaType );
 			this.position = position;
 		}
 
 		@Override
 		public String getName() {
 			return null;
 		}
 
 		@Override
 		public Integer getPosition() {
 			return position;
 		}
 
 		@Override
 		public boolean isJpaPositionalParameter() {
 			return true;
 		}
 	}
 
 	public org.hibernate.Query getHibernateQuery() {
 		return query;
 	}
 
 	@Override
     protected int internalExecuteUpdate() {
 		return query.executeUpdate();
 	}
 
 	@Override
     protected void applyMaxResults(int maxResults) {
 		query.setMaxResults( maxResults );
 	}
 
 	@Override
     protected void applyFirstResult(int firstResult) {
 		query.setFirstResult( firstResult );
 	}
 
 	@Override
     protected boolean applyTimeoutHint(int timeout) {
 		query.setTimeout( timeout );
 		return true;
 	}
 
 	@Override
     protected boolean applyCommentHint(String comment) {
 		query.setComment( comment );
 		return true;
 	}
 
 	@Override
     protected boolean applyFetchSizeHint(int fetchSize) {
 		query.setFetchSize( fetchSize );
 		return true;
 	}
 
 	@Override
     protected boolean applyCacheableHint(boolean isCacheable) {
 		query.setCacheable( isCacheable );
 		return true;
 	}
 
 	@Override
     protected boolean applyCacheRegionHint(String regionName) {
 		query.setCacheRegion( regionName );
 		return true;
 	}
 
 	@Override
     protected boolean applyReadOnlyHint(boolean isReadOnly) {
 		query.setReadOnly( isReadOnly );
 		return true;
 	}
 
 	@Override
     protected boolean applyCacheModeHint(CacheMode cacheMode) {
 		query.setCacheMode( cacheMode );
 		return true;
 	}
 
 	@Override
     protected boolean applyFlushModeHint(FlushMode flushMode) {
 		query.setFlushMode( flushMode );
 		return true;
 	}
 
 	@Override
 	protected boolean canApplyAliasSpecificLockModeHints() {
 		return org.hibernate.internal.QueryImpl.class.isInstance( query ) || SQLQueryImpl.class.isInstance( query );
 	}
 
 	@Override
 	protected void applyAliasSpecificLockModeHint(String alias, LockMode lockMode) {
 		query.getLockOptions().setAliasSpecificLockMode( alias, lockMode );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked", "RedundantCast" })
 	public List<X> getResultList() {
 		getEntityManager().checkOpen( true );
 		checkTransaction();
 		beforeQuery();
 		try {
 			return list();
 		}
 		catch (QueryExecutionRequestException he) {
 			throw new IllegalStateException(he);
 		}
 		catch( TypeMismatchException e ) {
 			throw new IllegalArgumentException(e);
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	/**
 	 * For JPA native SQL queries, we may need to perform a flush before executing the query.
 	 */
 	private void beforeQuery() {
 		final org.hibernate.Query query = getHibernateQuery();
 		if ( ! SQLQuery.class.isInstance( query ) ) {
 			// this need only exists for native SQL queries, not JPQL or Criteria queries (both of which do
 			// partial auto flushing already).
 			return;
 		}
 
 		final SQLQuery sqlQuery = (SQLQuery) query;
 		if ( sqlQuery.getSynchronizedQuerySpaces() != null && ! sqlQuery.getSynchronizedQuerySpaces().isEmpty() ) {
 			// The application defined query spaces on the Hibernate native SQLQuery which means the query will already
 			// perform a partial flush according to the defined query spaces, no need to do a full flush.
 			return;
 		}
 
 		// otherwise we need to flush.  the query itself is not required to execute in a transaction; if there is
 		// no transaction, the flush would throw a TransactionRequiredException which would potentially break existing
 		// apps, so we only do the flush if a transaction is in progress.
 		if ( getEntityManager().isTransactionInProgress() ) {
 			getEntityManager().flush();
 		}
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked", "RedundantCast" })
 	public X getSingleResult() {
 		getEntityManager().checkOpen( true );
 		checkTransaction();
 		beforeQuery();
 		try {
 			final List<X> result = list();
 
 			if ( result.size() == 0 ) {
 				NoResultException nre = new NoResultException( "No entity found for query" );
 				getEntityManager().handlePersistenceException( nre );
 				throw nre;
 			}
 			else if ( result.size() > 1 ) {
 				final Set<X> uniqueResult = new HashSet<X>(result);
 				if ( uniqueResult.size() > 1 ) {
 					NonUniqueResultException nure = new NonUniqueResultException( "result returns more than one elements" );
 					getEntityManager().handlePersistenceException( nure );
 					throw nure;
 				}
 				else {
 					return uniqueResult.iterator().next();
 				}
 			}
 			else {
 				return result.get( 0 );
 			}
 		}
 		catch (QueryExecutionRequestException he) {
 			throw new IllegalStateException(he);
 		}
 		catch( TypeMismatchException e ) {
 			throw new IllegalArgumentException(e);
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <T> T unwrap(Class<T> tClass) {
 		if ( org.hibernate.Query.class.isAssignableFrom( tClass ) ) {
 			return (T) query;
 		}
 		if ( QueryImpl.class.isAssignableFrom( tClass ) ) {
 			return (T) this;
 		}
 		if ( HibernateQuery.class.isAssignableFrom( tClass ) ) {
 			return (T) this;
 		}
 
 		throw new PersistenceException(
 				String.format(
 						"Unsure how to unwrap %s impl [%s] as requested type [%s]",
 						Query.class.getSimpleName(),
 						this.getClass().getName(),
 						tClass.getName()
 				)
 		);
 	}
 
 	@Override
 	protected void internalApplyLockMode(javax.persistence.LockModeType lockModeType) {
 		query.getLockOptions().setLockMode( LockModeTypeHelper.getLockMode( lockModeType ) );
 		if ( getHints() != null && getHints().containsKey( AvailableSettings.LOCK_TIMEOUT ) ) {
 			applyLockTimeoutHint( ConfigurationHelper.getInteger( getHints().get( AvailableSettings.LOCK_TIMEOUT ) ) );
 		}
 	}
 
 	@Override
 	protected boolean applyLockTimeoutHint(int timeout) {
 		query.getLockOptions().setTimeOut( timeout );
 		return true;
 	}
 
 	private List<X> list() {
 		if (getEntityGraphQueryHint() != null) {
 			SessionImplementor sessionImpl = (SessionImplementor) getEntityManager().getSession();
 			HQLQueryPlan entityGraphQueryPlan = new HQLQueryPlan(
 					getHibernateQuery().getQueryString(),
 					false,
 					sessionImpl.getLoadQueryInfluencers().getEnabledFilters(),
 					sessionImpl.getFactory(),
 					getEntityGraphQueryHint()
 			);
 			// Safe to assume QueryImpl at this point.
 			unwrap( org.hibernate.internal.QueryImpl.class ).setQueryPlan( entityGraphQueryPlan );
 		}
 		return query.list();
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/TransactionImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/TransactionImpl.java
index 091048550c..b2c4eb1696 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/TransactionImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/TransactionImpl.java
@@ -1,155 +1,161 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal;
 
 import javax.persistence.EntityTransaction;
 import javax.persistence.PersistenceException;
 import javax.persistence.RollbackException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.jpa.spi.AbstractEntityManagerImpl;
 import org.hibernate.jpa.spi.HibernateEntityManagerImplementor;
 import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 /**
  * @author Gavin King
  * @author Emmanuel Bernard
  */
 public class TransactionImpl implements EntityTransaction {
 
 	private HibernateEntityManagerImplementor entityManager;
 	private Transaction tx;
 	private boolean rollbackOnly;
 
 	public TransactionImpl(AbstractEntityManagerImpl entityManager) {
 		this.entityManager = entityManager;
 	}
 
 	private Session getSession() {
 		return entityManager.getSession();
 	}
 
 	public void begin() {
 		try {
 			rollbackOnly = false;
 			if ( tx != null && tx.getStatus() == TransactionStatus.ACTIVE ) {
 				throw new IllegalStateException( "Transaction already active" );
 			}
 			//entityManager.adjustFlushMode();
 			tx = getSession().beginTransaction();
 		}
 		catch (HibernateException he) {
 			entityManager.throwPersistenceException( he );
 		}
 	}
 
 	public void commit() {
 		if ( tx == null || tx.getStatus() != TransactionStatus.ACTIVE ) {
 			throw new IllegalStateException( "Transaction not active" );
 		}
 		if ( rollbackOnly ) {
 			tx.rollback();
 			throw new RollbackException( "Transaction marked as rollbackOnly" );
 		}
 		try {
 			tx.commit();
 		}
 		catch (Exception e) {
 			Throwable wrappedException;
 			if ( e instanceof PersistenceException ) {
 				if ( e.getCause() instanceof HibernateException ) {
 					wrappedException = entityManager.convert( (HibernateException) e.getCause() );
 				}
 				else {
 					wrappedException = e.getCause();
 				}
 			}
 			else if ( e instanceof HibernateException ) {
 				wrappedException = entityManager.convert( (HibernateException) e );
 			}
 			else {
 				wrappedException = e;
 			}
 			try {
 				//as per the spec we should rollback if commit fails
 				tx.rollback();
 			}
 			catch (Exception re) {
 				//swallow
 			}
 			throw new RollbackException( "Error while committing the transaction", wrappedException );
 		}
 		finally {
 			rollbackOnly = false;
 		}
 		//if closed and we commit, the mode should have been adjusted already
 		//if ( entityManager.isOpen() ) entityManager.adjustFlushMode();
 	}
 
 	public void rollback() {
 		if ( tx == null || tx.getStatus() != TransactionStatus.ACTIVE ) {
 			throw new IllegalStateException( "Transaction not active" );
 		}
 		try {
 			tx.rollback();
 		}
 		catch (Exception e) {
 			throw new PersistenceException( "unexpected error when rollbacking", e );
 		}
 		finally {
 			try {
-				if (entityManager !=  null) {
+				if ( entityManager != null ) {
 					Session session = getSession();
-					if ( session != null && session.isOpen() ) session.clear();
+					if ( session != null && session.isOpen() ) {
+						session.clear();
+					}
 				}
 			}
 			catch (Throwable t) {
 				//we don't really care here since it's only for safety purpose
 			}
 			rollbackOnly = false;
 		}
 	}
 
 	public void setRollbackOnly() {
-		if ( ! isActive() ) throw new IllegalStateException( "Transaction not active" );
+		if ( !isActive() ) {
+			throw new IllegalStateException( "Transaction not active" );
+		}
 		this.rollbackOnly = true;
 	}
 
 	public boolean getRollbackOnly() {
-		if ( ! isActive() ) throw new IllegalStateException( "Transaction not active" );
+		if ( !isActive() ) {
+			throw new IllegalStateException( "Transaction not active" );
+		}
 		return rollbackOnly;
 	}
 
 	public boolean isActive() {
 		try {
 			return tx != null && tx.getStatus() == TransactionStatus.ACTIVE;
 		}
 		catch (RuntimeException e) {
 			throw new PersistenceException( "unexpected error when checking transaction status", e );
 		}
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/XmlHelper.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/XmlHelper.java
index af6046cd8d..1f3589b611 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/XmlHelper.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/XmlHelper.java
@@ -1,203 +1,205 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.util;
 
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.Locale;
 
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
 /**
  * A utility class to cover up the rough bits of xml parsing
  *
  * @author <a href="mailto:chris@kimptoc.net">Chris Kimpton</a>
  */
 public final class XmlHelper {
 	private XmlHelper() {
 	}
 
 	/**
 	 * Returns an iterator over the children of the given element with
 	 * the given tag name.
 	 *
 	 * @param element The parent element
 	 * @param tagName The name of the desired child
 	 * @return An interator of children or null if element is null.
 	 */
 	public static Iterator getChildrenByTagName(
 			Element element,
 			String tagName) {
-		if ( element == null ) return null;
+		if ( element == null ) {
+			return null;
+		}
 		// getElementsByTagName gives the corresponding elements in the whole
 		// descendance. We want only children
 
 		NodeList children = element.getChildNodes();
 		ArrayList goodChildren = new ArrayList();
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			Node currentChild = children.item( i );
 			if ( currentChild.getNodeType() == Node.ELEMENT_NODE &&
 					( (Element) currentChild ).getTagName().equals( tagName ) ) {
 				goodChildren.add( currentChild );
 			}
 		}
 		return goodChildren.iterator();
 	}
 
 	/**
 	 * Gets the child of the specified element having the specified unique
 	 * name.  If there are more than one children elements with the same name
 	 * and exception is thrown.
 	 *
 	 * @param element The parent element
 	 * @param tagName The name of the desired child
 	 * @return The named child.
 	 * @throws Exception Child was not found or was not unique.
 	 */
 	public static Element getUniqueChild(Element element, String tagName) throws Exception {
 		final Iterator goodChildren = getChildrenByTagName( element, tagName );
 
 		if ( goodChildren != null && goodChildren.hasNext() ) {
 			final Element child = (Element) goodChildren.next();
 			if ( goodChildren.hasNext() ) {
 				throw new Exception( "expected only one " + tagName + " tag" );
 			}
 			return child;
 		}
 		else {
 			throw new Exception( "expected one " + tagName + " tag" );
 		}
 	}
 
 	/**
 	 * Gets the child of the specified element having the
 	 * specified name. If the child with this name doesn't exist
 	 * then null is returned instead.
 	 *
 	 * @param element the parent element
 	 * @param tagName the name of the desired child
 	 * @return either the named child or null
 	 */
 	public static Element getOptionalChild(Element element, String tagName) throws Exception {
 		return getOptionalChild( element, tagName, null );
 	}
 
 	/**
 	 * Gets the child of the specified element having the
 	 * specified name. If the child with this name doesn't exist
 	 * then the supplied default element is returned instead.
 	 *
 	 * @param element		the parent element
 	 * @param tagName		the name of the desired child
 	 * @param defaultElement the element to return if the child
 	 *                       doesn't exist
 	 * @return either the named child or the supplied default
 	 */
 	public static Element getOptionalChild(
 			Element element,
 			String tagName,
 			Element defaultElement) throws Exception {
 		final Iterator goodChildren = getChildrenByTagName( element, tagName );
 
 		if ( goodChildren != null && goodChildren.hasNext() ) {
 			final Element child = (Element) goodChildren.next();
 			if ( goodChildren.hasNext() ) {
 				throw new Exception( "expected only one " + tagName + " tag" );
 			}
 			return child;
 		}
 		else {
 			return defaultElement;
 		}
 	}
 
 	/**
 	 * Get the content of the given element.
 	 *
 	 * @param element The element to get the content for.
 	 * @return The content of the element or null.
 	 */
 	public static String getElementContent(final Element element) throws Exception {
 		return getElementContent( element, null );
 	}
 
 	/**
 	 * Get the content of the given element.
 	 *
 	 * @param element	The element to get the content for.
 	 * @param defaultStr The default to return when there is no content.
 	 * @return The content of the element or the default.
 	 */
 	public static String getElementContent(Element element, String defaultStr) throws Exception {
 		if ( element == null ) {
 			return defaultStr;
 		}
 
 		final NodeList children = element.getChildNodes();
 		final StringBuilder result = new StringBuilder("");
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			if ( children.item( i ).getNodeType() == Node.TEXT_NODE
 					|| children.item( i ).getNodeType() == Node.CDATA_SECTION_NODE ) {
 				result.append( children.item( i ).getNodeValue() );
 			}
 //			else if ( children.item( i ).getNodeType() == Node.COMMENT_NODE ) {
 //				// Ignore comment nodes
 //			}
 		}
 		return result.toString().trim();
 	}
 
 	/**
 	 * Macro to get the content of a unique child element.
 	 *
 	 * @param element The parent element.
 	 * @param tagName The name of the desired child.
 	 * @return The element content or null.
 	 */
 	public static String getUniqueChildContent(Element element, String tagName) throws Exception {
 		return getElementContent( getUniqueChild( element, tagName ) );
 	}
 
 	/**
 	 * Macro to get the content of an optional child element.
 	 *
 	 * @param element The parent element.
 	 * @param tagName The name of the desired child.
 	 * @return The element content or null.
 	 */
 	public static String getOptionalChildContent(Element element, String tagName) throws Exception {
 		return getElementContent( getOptionalChild( element, tagName ) );
 	}
 
 	public static boolean getOptionalChildBooleanContent(Element element, String name) throws Exception {
 		Element child = getOptionalChild( element, name );
 		if ( child != null ) {
 			String value = getElementContent( child ).toLowerCase(Locale.ROOT);
 			return value.equals( "true" ) || value.equals( "yes" );
 		}
 
 		return false;
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
index 00e0c97ab8..0abfcc0be7 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
@@ -1,1105 +1,1103 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.spi;
 
+import java.io.IOException;
+import java.io.ObjectInputStream;
+import java.io.ObjectOutputStream;
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
 import javax.persistence.CacheRetrieveMode;
 import javax.persistence.CacheStoreMode;
 import javax.persistence.EntityExistsException;
 import javax.persistence.EntityGraph;
 import javax.persistence.EntityManager;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.EntityTransaction;
 import javax.persistence.FlushModeType;
 import javax.persistence.LockModeType;
 import javax.persistence.LockTimeoutException;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 import javax.persistence.OptimisticLockException;
 import javax.persistence.PersistenceContextType;
 import javax.persistence.PersistenceException;
 import javax.persistence.PessimisticLockException;
 import javax.persistence.PessimisticLockScope;
 import javax.persistence.Query;
 import javax.persistence.QueryTimeoutException;
 import javax.persistence.StoredProcedureQuery;
 import javax.persistence.SynchronizationType;
 import javax.persistence.TransactionRequiredException;
 import javax.persistence.Tuple;
 import javax.persistence.TupleElement;
 import javax.persistence.TypedQuery;
 import javax.persistence.criteria.CriteriaBuilder;
 import javax.persistence.criteria.CriteriaDelete;
 import javax.persistence.criteria.CriteriaQuery;
 import javax.persistence.criteria.CriteriaUpdate;
 import javax.persistence.criteria.Selection;
 import javax.persistence.metamodel.Metamodel;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.transaction.Status;
 import javax.transaction.SystemException;
 import javax.transaction.TransactionManager;
-import java.io.IOException;
-import java.io.ObjectInputStream;
-import java.io.ObjectOutputStream;
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.SQLQuery;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.TransactionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.dialect.lock.LockingStrategyException;
 import org.hibernate.dialect.lock.OptimisticEntityLockException;
 import org.hibernate.dialect.lock.PessimisticEntityLockException;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryConstructorReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.internal.SessionImpl;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.HibernateEntityManagerFactory;
 import org.hibernate.jpa.QueryHints;
 import org.hibernate.jpa.criteria.ValueHandlerFactory;
 import org.hibernate.jpa.criteria.compile.CompilableCriteria;
 import org.hibernate.jpa.criteria.compile.CriteriaCompiler;
 import org.hibernate.jpa.criteria.expression.CompoundSelectionImpl;
 import org.hibernate.jpa.internal.EntityManagerFactoryImpl;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.HEMLogging;
 import org.hibernate.jpa.internal.QueryImpl;
 import org.hibernate.jpa.internal.StoredProcedureQueryImpl;
 import org.hibernate.jpa.internal.TransactionImpl;
 import org.hibernate.jpa.internal.util.CacheModeHelper;
 import org.hibernate.jpa.internal.util.ConfigurationHelper;
 import org.hibernate.jpa.internal.util.LockModeTypeHelper;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.procedure.UnknownSqlResultSetMappingException;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.transform.BasicTransformerAdapter;
 import org.hibernate.type.Type;
 
 /**
  * @author <a href="mailto:gavin@hibernate.org">Gavin King</a>
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public abstract class AbstractEntityManagerImpl implements HibernateEntityManagerImplementor, Serializable {
 	private static final long serialVersionUID = 78818181L;
 
     private static final EntityManagerMessageLogger LOG = HEMLogging.messageLogger( AbstractEntityManagerImpl.class );
 
 	private static final List<String> ENTITY_MANAGER_SPECIFIC_PROPERTIES = new ArrayList<String>();
 
 	static {
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.LOCK_SCOPE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.LOCK_TIMEOUT );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.FLUSH_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.SHARED_CACHE_STORE_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( QueryHints.SPEC_HINT_TIMEOUT );
 	}
 
 	private EntityManagerFactoryImpl entityManagerFactory;
 	protected transient TransactionImpl tx = new TransactionImpl( this );
 	private SynchronizationType synchronizationType;
 	private PersistenceUnitTransactionType transactionType;
 	private Map<String, Object> properties;
 	private LockOptions lockOptions;
 
 	protected AbstractEntityManagerImpl(
 			EntityManagerFactoryImpl entityManagerFactory,
 			PersistenceContextType type,  // TODO:  remove as no longer used
 			SynchronizationType synchronizationType,
 			PersistenceUnitTransactionType transactionType,
 			Map properties) {
 		this.entityManagerFactory = entityManagerFactory;
 		this.synchronizationType = synchronizationType;
 		this.transactionType = transactionType;
 
 		this.lockOptions = new LockOptions();
 		this.properties = new HashMap<String, Object>();
 		for ( String key : ENTITY_MANAGER_SPECIFIC_PROPERTIES ) {
 			if ( entityManagerFactory.getProperties().containsKey( key ) ) {
 				this.properties.put( key, entityManagerFactory.getProperties().get( key ) );
 			}
 			if ( properties != null && properties.containsKey( key ) ) {
 				this.properties.put( key, properties.get( key ) );
 			}
 		}
 	}
 
 //	protected PersistenceUnitTransactionType transactionType() {
 //		return transactionType;
 //	}
 //
 //	protected SynchronizationType synchronizationType() {
 //		return synchronizationType;
 //	}
 //
 //	public boolean shouldAutoJoinTransactions() {
 //		// the Session should auto join only if using non-JTA transactions or if the synchronization type
 //		// was specified as SYNCHRONIZED
 //		return transactionType != PersistenceUnitTransactionType.JTA
 //				|| synchronizationType == SynchronizationType.SYNCHRONIZED;
 //	}
 
 	public PersistenceUnitTransactionType getTransactionType() {
 		return transactionType;
 	}
 
 	protected void postInit() {
 		//register in Sync if needed
 		if ( transactionType == PersistenceUnitTransactionType.JTA
 				&& synchronizationType == SynchronizationType.SYNCHRONIZED ) {
 			joinTransaction( false );
 		}
 
 		setDefaultProperties();
 		applyProperties();
 	}
 
 	private void applyProperties() {
 		getSession().setFlushMode( ConfigurationHelper.getFlushMode( properties.get( AvailableSettings.FLUSH_MODE ) ) );
 		setLockOptions( this.properties, this.lockOptions );
 		getSession().setCacheMode(
 				CacheModeHelper.interpretCacheMode(
 						currentCacheStoreMode(),
 						currentCacheRetrieveMode()
 				)
 		);
 	}
 
 	private Query applyProperties(Query query) {
 		if ( lockOptions.getLockMode() != LockMode.NONE ) {
 			query.setLockMode( getLockMode(lockOptions.getLockMode()));
 		}
 		Object queryTimeout;
 		if ( (queryTimeout = getProperties().get(QueryHints.SPEC_HINT_TIMEOUT)) != null ) {
 			query.setHint( QueryHints.SPEC_HINT_TIMEOUT, queryTimeout );
 		}
 		Object lockTimeout;
 		if( (lockTimeout = getProperties().get( AvailableSettings.LOCK_TIMEOUT ))!=null){
 			query.setHint( AvailableSettings.LOCK_TIMEOUT, lockTimeout );
 		}
 		return query;
 	}
 
 	private CacheRetrieveMode currentCacheRetrieveMode() {
 		return determineCacheRetrieveMode( properties );
 	}
 
 	private CacheRetrieveMode determineCacheRetrieveMode(Map<String, Object> settings) {
 		return ( CacheRetrieveMode ) settings.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 	}
 
 	private CacheStoreMode currentCacheStoreMode() {
 		return determineCacheStoreMode( properties );
 	}
 
 	private CacheStoreMode determineCacheStoreMode(Map<String, Object> settings) {
 		return ( CacheStoreMode ) settings.get( AvailableSettings.SHARED_CACHE_STORE_MODE );
 	}
 
 	private void setLockOptions(Map<String, Object> props, LockOptions options) {
 		Object lockScope = props.get( AvailableSettings.LOCK_SCOPE );
 		if ( lockScope instanceof String && PessimisticLockScope.valueOf( ( String ) lockScope ) == PessimisticLockScope.EXTENDED ) {
 			options.setScope( true );
 		}
 		else if ( lockScope instanceof PessimisticLockScope ) {
 			boolean extended = PessimisticLockScope.EXTENDED.equals( lockScope );
 			options.setScope( extended );
 		}
 		else if ( lockScope != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_SCOPE + ": " + lockScope );
 		}
 
 		Object lockTimeout = props.get( AvailableSettings.LOCK_TIMEOUT );
 		int timeout = 0;
 		boolean timeoutSet = false;
 		if ( lockTimeout instanceof String ) {
 			timeout = Integer.parseInt( ( String ) lockTimeout );
 			timeoutSet = true;
 		}
 		else if ( lockTimeout instanceof Number ) {
 			timeout = ( (Number) lockTimeout ).intValue();
 			timeoutSet = true;
 		}
 		else if ( lockTimeout != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_TIMEOUT + ": " + lockTimeout );
 		}
 		if ( timeoutSet ) {
             if ( timeout == LockOptions.SKIP_LOCKED ) {
                 options.setTimeOut( LockOptions.SKIP_LOCKED );
             }
 			else if ( timeout < 0 ) {
 				options.setTimeOut( LockOptions.WAIT_FOREVER );
 			}
 			else if ( timeout == 0 ) {
 				options.setTimeOut( LockOptions.NO_WAIT );
 			}
 			else {
 				options.setTimeOut( timeout );
 			}
 		}
 	}
 
 	/**
 	 * Sets the default property values for the properties the entity manager supports and which are not already explicitly
 	 * set.
 	 */
 	private void setDefaultProperties() {
 		if ( properties.get( AvailableSettings.FLUSH_MODE ) == null ) {
 			properties.put( AvailableSettings.FLUSH_MODE, getSession().getFlushMode().toString() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_SCOPE ) == null ) {
 			this.properties.put( AvailableSettings.LOCK_SCOPE, PessimisticLockScope.EXTENDED.name() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_TIMEOUT ) == null ) {
 			properties.put( AvailableSettings.LOCK_TIMEOUT, LockOptions.WAIT_FOREVER );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE, CacheModeHelper.DEFAULT_RETRIEVE_MODE );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_STORE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_STORE_MODE, CacheModeHelper.DEFAULT_STORE_MODE );
 		}
 	}
 
 	@Override
 	public Query createQuery(String jpaqlString) {
 		checkOpen();
 		try {
 			return applyProperties( new QueryImpl<Object>( internalGetSession().createQuery( jpaqlString ), this ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected abstract void checkOpen();
 
 	@Override
 	public <T> TypedQuery<T> createQuery(String jpaqlString, Class<T> resultClass) {
 		checkOpen();
 		try {
 			// do the translation
 			org.hibernate.Query hqlQuery = internalGetSession().createQuery( jpaqlString );
 
 			resultClassChecking( resultClass, hqlQuery );
 
 			// finally, build/return the query instance
 			return new QueryImpl<T>( hqlQuery, this );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected void resultClassChecking(Class resultClass, org.hibernate.Query hqlQuery) {
 		// make sure the query is a select -> HHH-7192
 		final SessionImplementor session = unwrap( SessionImplementor.class );
 		final HQLQueryPlan queryPlan = session.getFactory().getQueryPlanCache().getHQLQueryPlan(
 				hqlQuery.getQueryString(),
 				false,
 				session.getLoadQueryInfluencers().getEnabledFilters()
 		);
 		if ( queryPlan.getTranslators()[0].isManipulationStatement() ) {
 			throw new IllegalArgumentException( "Update/delete queries cannot be typed" );
 		}
 
 		// do some return type validation checking
 		if ( Object[].class.equals( resultClass ) ) {
 			// no validation needed
 		}
 		else if ( Tuple.class.equals( resultClass ) ) {
 			TupleBuilderTransformer tupleTransformer = new TupleBuilderTransformer( hqlQuery );
 			hqlQuery.setResultTransformer( tupleTransformer  );
 		}
 		else {
 			final Class dynamicInstantiationClass = queryPlan.getDynamicInstantiationResultType();
 			if ( dynamicInstantiationClass != null ) {
 				if ( ! resultClass.isAssignableFrom( dynamicInstantiationClass ) ) {
 					throw new IllegalArgumentException(
 							"Mismatch in requested result type [" + resultClass.getName() +
 									"] and actual result type [" + dynamicInstantiationClass.getName() + "]"
 					);
 				}
 			}
 			else if ( hqlQuery.getReturnTypes().length == 1 ) {
 				// if we have only a single return expression, its java type should match with the requested type
 				if ( !resultClass.isAssignableFrom( hqlQuery.getReturnTypes()[0].getReturnedClass() ) ) {
 					throw new IllegalArgumentException(
 							"Type specified for TypedQuery [" +
 									resultClass.getName() +
 									"] is incompatible with query return type [" +
 									hqlQuery.getReturnTypes()[0].getReturnedClass() + "]"
 					);
 				}
 			}
 			else {
 				throw new IllegalArgumentException(
 						"Cannot create TypedQuery for query with more than one return using requested result type [" +
 								resultClass.getName() + "]"
 				);
 			}
 		}
 	}
 
 	public static class TupleBuilderTransformer extends BasicTransformerAdapter {
 		private List<TupleElement<?>> tupleElements;
 		private Map<String,HqlTupleElementImpl> tupleElementsByAlias;
 
 		public TupleBuilderTransformer(org.hibernate.Query hqlQuery) {
 			final Type[] resultTypes = hqlQuery.getReturnTypes();
 			final int tupleSize = resultTypes.length;
 
 			this.tupleElements = CollectionHelper.arrayList( tupleSize );
 
 			final String[] aliases = hqlQuery.getReturnAliases();
 			final boolean hasAliases = aliases != null && aliases.length > 0;
 			this.tupleElementsByAlias = hasAliases
 					? CollectionHelper.<String, HqlTupleElementImpl>mapOfSize( tupleSize )
 					: Collections.<String, HqlTupleElementImpl>emptyMap();
 
 			for ( int i = 0; i < tupleSize; i++ ) {
 				final HqlTupleElementImpl tupleElement = new HqlTupleElementImpl(
 						i,
 						aliases == null ? null : aliases[i],
 						resultTypes[i]
 				);
 				tupleElements.add( tupleElement );
 				if ( hasAliases ) {
 					final String alias = aliases[i];
 					if ( alias != null ) {
 						tupleElementsByAlias.put( alias, tupleElement );
 					}
 				}
 			}
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			if ( tuple.length != tupleElements.size() ) {
 				throw new IllegalArgumentException(
 						"Size mismatch between tuple result [" + tuple.length + "] and expected tuple elements [" +
 								tupleElements.size() + "]"
 				);
 			}
 			return new HqlTupleImpl( tuple );
 		}
 
 		public static class HqlTupleElementImpl<X> implements TupleElement<X> {
 			private final int position;
 			private final String alias;
 			private final Type hibernateType;
 
 			public HqlTupleElementImpl(int position, String alias, Type hibernateType) {
 				this.position = position;
 				this.alias = alias;
 				this.hibernateType = hibernateType;
 			}
 
 			@Override
 			public Class getJavaType() {
 				return hibernateType.getReturnedClass();
 			}
 
 			@Override
 			public String getAlias() {
 				return alias;
 			}
 
 			public int getPosition() {
 				return position;
 			}
 
 			public Type getHibernateType() {
 				return hibernateType;
 			}
 		}
 
 		public class HqlTupleImpl implements Tuple {
 			private Object[] tuple;
 
 			public HqlTupleImpl(Object[] tuple) {
 				this.tuple = tuple;
 			}
 
 			@Override
 			public <X> X get(String alias, Class<X> type) {
 				final Object untyped = get( alias );
 				if ( untyped != null ) {
 					if ( ! type.isInstance( untyped ) ) {
 						throw new IllegalArgumentException(
 								String.format(
 										"Requested tuple value [alias=%s, value=%s] cannot be assigned to requested type [%s]",
 										alias,
 										untyped,
 										type.getName()
 								)
 						);
 					}
 				}
 				return (X) untyped;
 			}
 
 			@Override
 			public Object get(String alias) {
 				HqlTupleElementImpl tupleElement = tupleElementsByAlias.get( alias );
 				if ( tupleElement == null ) {
 					throw new IllegalArgumentException( "Unknown alias [" + alias + "]" );
 				}
 				return tuple[ tupleElement.getPosition() ];
 			}
 
 			@Override
 			public <X> X get(int i, Class<X> type) {
 				final Object result = get( i );
 				if ( result != null && ! type.isInstance( result ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Requested tuple value [index=%s, realType=%s] cannot be assigned to requested type [%s]",
 									i,
 									result.getClass().getName(),
 									type.getName()
 							)
 					);
 				}
 				return ( X ) result;
 			}
 
 			@Override
 			public Object get(int i) {
 				if ( i < 0 ) {
 					throw new IllegalArgumentException( "requested tuple index must be greater than zero" );
 				}
 				if ( i > tuple.length ) {
 					throw new IllegalArgumentException( "requested tuple index exceeds actual tuple size" );
 				}
 				return tuple[i];
 			}
 
 			@Override
 			public Object[] toArray() {
 				// todo : make a copy?
 				return tuple;
 			}
 
 			@Override
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 
 			@Override
 			public <X> X get(TupleElement<X> tupleElement) {
 				if ( HqlTupleElementImpl.class.isInstance( tupleElement ) ) {
 					return get( ( (HqlTupleElementImpl) tupleElement ).getPosition(), tupleElement.getJavaType() );
 				}
 				else {
 					return get( tupleElement.getAlias(), tupleElement.getJavaType() );
 				}
 			}
 		}
 	}
 
 	@Override
 	public <T> QueryImpl<T> createQuery(
 			String jpaqlString,
 			Class<T> resultClass,
 			Selection selection,
 			QueryOptions queryOptions) {
 		try {
 			org.hibernate.Query hqlQuery = internalGetSession().createQuery( jpaqlString );
 
 			if ( queryOptions.getValueHandlers() == null ) {
 				if ( queryOptions.getResultMetadataValidator() != null ) {
 					queryOptions.getResultMetadataValidator().validate( hqlQuery.getReturnTypes() );
 				}
 			}
 
 			// determine if we need a result transformer
 			List tupleElements = Tuple.class.equals( resultClass )
 					? ( ( CompoundSelectionImpl<Tuple> ) selection ).getCompoundSelectionItems()
 					: null;
 			if ( queryOptions.getValueHandlers() != null || tupleElements != null ) {
 				hqlQuery.setResultTransformer(
 						new CriteriaQueryTransformer( queryOptions.getValueHandlers(), tupleElements )
 				);
 			}
 			return new QueryImpl<T>( hqlQuery, this, queryOptions.getNamedParameterExplicitTypes() );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	private static class CriteriaQueryTransformer extends BasicTransformerAdapter {
 		private final List<ValueHandlerFactory.ValueHandler> valueHandlers;
 		private final List tupleElements;
 
 		private CriteriaQueryTransformer(List<ValueHandlerFactory.ValueHandler> valueHandlers, List tupleElements) {
 			// todo : should these 2 sizes match *always*?
 			this.valueHandlers = valueHandlers;
 			this.tupleElements = tupleElements;
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			final Object[] valueHandlerResult;
 			if ( valueHandlers == null ) {
 				valueHandlerResult = tuple;
 			}
 			else {
 				valueHandlerResult = new Object[tuple.length];
 				for ( int i = 0; i < tuple.length; i++ ) {
 					ValueHandlerFactory.ValueHandler valueHandler = valueHandlers.get( i );
 					valueHandlerResult[i] = valueHandler == null
 							? tuple[i]
 							: valueHandler.convert( tuple[i] );
 				}
 			}
 
 			return tupleElements == null
 					? valueHandlerResult.length == 1 ? valueHandlerResult[0] : valueHandlerResult
 					: new TupleImpl( tuple );
 
 		}
 
 		private class TupleImpl implements Tuple {
 			private final Object[] tuples;
 
 			private TupleImpl(Object[] tuples) {
 				if ( tuples.length != tupleElements.size() ) {
 					throw new IllegalArgumentException(
 							"Size mismatch between tuple result [" + tuples.length
 									+ "] and expected tuple elements [" + tupleElements.size() + "]"
 					);
 				}
 				this.tuples = tuples;
 			}
 
 			public <X> X get(TupleElement<X> tupleElement) {
 				int index = tupleElements.indexOf( tupleElement );
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Requested tuple element did not correspond to element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return ( X ) tuples[index];
 			}
 
 			public Object get(String alias) {
 				int index = -1;
 				if ( alias != null ) {
 					alias = alias.trim();
 					if ( alias.length() > 0 ) {
 						int i = 0;
 						for ( TupleElement selection : ( List<TupleElement> ) tupleElements ) {
 							if ( alias.equals( selection.getAlias() ) ) {
 								index = i;
 								break;
 							}
 							i++;
 						}
 					}
 				}
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Given alias [" + alias + "] did not correspond to an element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return tuples[index];
 			}
 
 			public <X> X get(String alias, Class<X> type) {
 				final Object untyped = get( alias );
 				if ( untyped != null ) {
 					if ( ! type.isInstance( untyped ) ) {
 						throw new IllegalArgumentException(
 								String.format(
 										"Requested tuple value [alias=%s, value=%s] cannot be assigned to requested type [%s]",
 										alias,
 										untyped,
 										type.getName()
 								)
 						);
 					}
 				}
 				return (X) untyped;
 			}
 
 			public Object get(int i) {
 				if ( i >= tuples.length ) {
 					throw new IllegalArgumentException(
 							"Given index [" + i + "] was outside the range of result tuple size [" + tuples.length + "] "
 					);
 				}
 				return tuples[i];
 			}
 
 			public <X> X get(int i, Class<X> type) {
 				final Object result = get( i );
 				if ( result != null && ! type.isInstance( result ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Requested tuple value [index=%s, realType=%s] cannot be assigned to requested type [%s]",
 									i,
 									result.getClass().getName(),
 									type.getName()
 							)
 					);
 				}
 				return ( X ) result;
 			}
 
 			public Object[] toArray() {
 				return tuples;
 			}
 
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 		}
 	}
 
 	private CriteriaCompiler criteriaCompiler;
 
 	protected CriteriaCompiler criteriaCompiler() {
 		if ( criteriaCompiler == null ) {
 			criteriaCompiler = new CriteriaCompiler( this );
 		}
 		return criteriaCompiler;
 	}
 
 	@Override
 	public <T> TypedQuery<T> createQuery(CriteriaQuery<T> criteriaQuery) {
 		checkOpen();
 		try {
 			return (TypedQuery<T>) criteriaCompiler().compile( (CompilableCriteria) criteriaQuery );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createQuery(CriteriaUpdate criteriaUpdate) {
 		checkOpen();
 		try {
 			return criteriaCompiler().compile( (CompilableCriteria) criteriaUpdate );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createQuery(CriteriaDelete criteriaDelete) {
 		checkOpen();
 		try {
 			return criteriaCompiler().compile( (CompilableCriteria) criteriaDelete );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createNamedQuery(String name) {
 		return buildQueryFromName( name, null );
 	}
 
 	private QueryImpl buildQueryFromName(String name, Class resultType) {
 		checkOpen();
 
 		// we can't just call Session#getNamedQuery because we need to apply stored setting at the JPA Query
 		// level too
 
 		final SessionFactoryImplementor sfi = entityManagerFactory.getSessionFactory();
 
 		final NamedQueryDefinition jpqlDefinition = sfi.getNamedQueryRepository().getNamedQueryDefinition( name );
 		if ( jpqlDefinition != null ) {
 			return createNamedJpqlQuery( jpqlDefinition, resultType );
 		}
 
 		final NamedSQLQueryDefinition nativeQueryDefinition = sfi.getNamedQueryRepository().getNamedSQLQueryDefinition(	name );
 		if ( nativeQueryDefinition != null ) {
 			return createNamedSqlQuery( nativeQueryDefinition, resultType );
 		}
 
 		throw convert( new IllegalArgumentException( "No query defined for that name [" + name + "]" ) );
 	}
 
 	protected QueryImpl createNamedJpqlQuery(NamedQueryDefinition namedQueryDefinition, Class resultType) {
 		final org.hibernate.Query hibQuery = ( (SessionImplementor) internalGetSession() ).createQuery( namedQueryDefinition );
 		if ( resultType != null ) {
 			resultClassChecking( resultType, hibQuery );
 		}
 
 		return wrapAsJpaQuery( namedQueryDefinition, hibQuery );
 	}
 
 	protected QueryImpl wrapAsJpaQuery(NamedQueryDefinition namedQueryDefinition, org.hibernate.Query hibQuery) {
 		try {
 			final QueryImpl jpaQuery = new QueryImpl( hibQuery, this );
 			applySavedSettings( namedQueryDefinition, jpaQuery );
 			return jpaQuery;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected void applySavedSettings(NamedQueryDefinition namedQueryDefinition, QueryImpl jpaQuery) {
 		if ( namedQueryDefinition.isCacheable() ) {
 			jpaQuery.setHint( QueryHints.HINT_CACHEABLE, true );
 			if ( namedQueryDefinition.getCacheRegion() != null ) {
 				jpaQuery.setHint( QueryHints.HINT_CACHE_REGION, namedQueryDefinition.getCacheRegion() );
 			}
 		}
 
 		if ( namedQueryDefinition.getCacheMode() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_CACHE_MODE, namedQueryDefinition.getCacheMode() );
 		}
 
 		if ( namedQueryDefinition.isReadOnly() ) {
 			jpaQuery.setHint( QueryHints.HINT_READONLY, true );
 		}
 
 		if ( namedQueryDefinition.getTimeout() != null ) {
 			jpaQuery.setHint( QueryHints.SPEC_HINT_TIMEOUT, namedQueryDefinition.getTimeout() * 1000 );
 		}
 
 		if ( namedQueryDefinition.getFetchSize() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_FETCH_SIZE, namedQueryDefinition.getFetchSize() );
 		}
 
 		if ( namedQueryDefinition.getComment() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_COMMENT, namedQueryDefinition.getComment() );
 		}
 
 		if ( namedQueryDefinition.getFirstResult() != null ) {
 			jpaQuery.setFirstResult( namedQueryDefinition.getFirstResult() );
 		}
 
 		if ( namedQueryDefinition.getMaxResults() != null ) {
 			jpaQuery.setMaxResults( namedQueryDefinition.getMaxResults() );
 		}
 
 		if ( namedQueryDefinition.getLockOptions() != null ) {
 			if ( namedQueryDefinition.getLockOptions().getLockMode() != null ) {
 				jpaQuery.setLockMode(
 						LockModeTypeHelper.getLockModeType( namedQueryDefinition.getLockOptions().getLockMode() )
 				);
 			}
 		}
 
 		if ( namedQueryDefinition.getFlushMode() != null ) {
 			if ( namedQueryDefinition.getFlushMode() == FlushMode.COMMIT ) {
 				jpaQuery.setFlushMode( FlushModeType.COMMIT );
 			}
 			else {
 				jpaQuery.setFlushMode( FlushModeType.AUTO );
 			}
 		}
 	}
 
 	protected QueryImpl createNamedSqlQuery(NamedSQLQueryDefinition namedQueryDefinition, Class resultType) {
 		if ( resultType != null ) {
 			resultClassChecking( resultType, namedQueryDefinition );
 		}
 		return wrapAsJpaQuery(
 				namedQueryDefinition,
 				( (SessionImplementor) internalGetSession() ).createSQLQuery( namedQueryDefinition )
 		);
 	}
 
 	protected void resultClassChecking(Class resultType, NamedSQLQueryDefinition namedQueryDefinition) {
 		final SessionFactoryImplementor sfi = entityManagerFactory.getSessionFactory();
 
 		final NativeSQLQueryReturn[] queryReturns;
 		if ( namedQueryDefinition.getQueryReturns() != null ) {
 			queryReturns = namedQueryDefinition.getQueryReturns();
 		}
 		else if ( namedQueryDefinition.getResultSetRef() != null ) {
 			final ResultSetMappingDefinition rsMapping = sfi.getResultSetMapping( namedQueryDefinition.getResultSetRef() );
 			queryReturns = rsMapping.getQueryReturns();
 		}
 		else {
 			throw new AssertionFailure( "Unsupported named query model. Please report the bug in Hibernate EntityManager");
 		}
 
 		if ( queryReturns.length > 1 ) {
 			throw new IllegalArgumentException( "Cannot create TypedQuery for query with more than one return" );
 		}
 
 		final NativeSQLQueryReturn nativeSQLQueryReturn = queryReturns[0];
 
 		if ( nativeSQLQueryReturn instanceof NativeSQLQueryRootReturn ) {
 			final Class<?> actualReturnedClass;
 			final String entityClassName = ( (NativeSQLQueryRootReturn) nativeSQLQueryReturn ).getReturnEntityName();
 			try {
 				actualReturnedClass = sfi.getServiceRegistry().getService( ClassLoaderService.class ).classForName( entityClassName );
 			}
 			catch ( ClassLoadingException e ) {
 				throw new AssertionFailure(
 						"Unable to load class [" + entityClassName + "] declared on named native query [" +
 								namedQueryDefinition.getName() + "]"
 				);
 			}
 			if ( !resultType.isAssignableFrom( actualReturnedClass ) ) {
 				throw buildIncompatibleException( resultType, actualReturnedClass );
 			}
 		}
 		else if ( nativeSQLQueryReturn instanceof NativeSQLQueryConstructorReturn ) {
 			final NativeSQLQueryConstructorReturn ctorRtn = (NativeSQLQueryConstructorReturn) nativeSQLQueryReturn;
 			if ( !resultType.isAssignableFrom( ctorRtn.getTargetClass() ) ) {
 				throw buildIncompatibleException( resultType, ctorRtn.getTargetClass() );
 			}
 		}
 		else {
 			//TODO support other NativeSQLQueryReturn type. For now let it go.
 		}
 	}
 
 	@Override
 	public <T> TypedQuery<T> createNamedQuery(String name, Class<T> resultClass) {
 		return buildQueryFromName( name, resultClass );
 	}
 
 	private IllegalArgumentException buildIncompatibleException(Class<?> resultClass, Class<?> actualResultClass) {
 		return new IllegalArgumentException(
 				"Type specified for TypedQuery [" + resultClass.getName() +
 						"] is incompatible with query return type [" + actualResultClass + "]"
 		);
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString) {
 		checkOpen();
 		try {
 			SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString, Class resultClass) {
 		checkOpen();
 		try {
 			SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			q.addEntity( "alias1", resultClass.getName(), LockMode.READ );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString, String resultSetMapping) {
 		checkOpen();
 		try {
 			final SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			q.setResultSetMapping( resultSetMapping );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createNamedStoredProcedureQuery(String name) {
 		checkOpen();
 		try {
 			final ProcedureCallMemento memento = ( (SessionImplementor) internalGetSession() ).getFactory()
 					.getNamedQueryRepository().getNamedProcedureCallMemento( name );
 			if ( memento == null ) {
 				throw new IllegalArgumentException( "No @NamedStoredProcedureQuery was found with that name : " + name );
 			}
 			final StoredProcedureQueryImpl jpaImpl = new StoredProcedureQueryImpl( memento, this );
 			// apply hints
 			if ( memento.getHintsMap() != null ) {
 				for ( Map.Entry<String,Object> hintEntry : memento.getHintsMap().entrySet() ) {
 					jpaImpl.setHint( hintEntry.getKey(), hintEntry.getValue() );
 				}
 			}
 			return jpaImpl;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName) {
 		checkOpen();
 		try {
 			return new StoredProcedureQueryImpl(
 					internalGetSession().createStoredProcedureCall( procedureName ),
 					this
 			);
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName, Class... resultClasses) {
 		checkOpen();
 		try {
 			return new StoredProcedureQueryImpl(
 					internalGetSession().createStoredProcedureCall( procedureName, resultClasses ),
 					this
 			);
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName, String... resultSetMappings) {
 		checkOpen();
 		try {
 			try {
 				return new StoredProcedureQueryImpl(
 						internalGetSession().createStoredProcedureCall( procedureName, resultSetMappings ),
 						this
 				);
 			}
 			catch (UnknownSqlResultSetMappingException unknownResultSetMapping) {
 				throw new IllegalArgumentException( unknownResultSetMapping.getMessage(), unknownResultSetMapping );
 			}
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> T getReference(Class<T> entityClass, Object primaryKey) {
 		checkOpen();
 		try {
 			return ( T ) internalGetSession().load( entityClass, ( Serializable ) primaryKey );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( TypeMismatchException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( ClassCastException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey) {
 		checkOpen();
 		return find( entityClass, primaryKey, null, null );
 	}
 
 	@Override
 	public <T> T find(Class<T> entityClass, Object primaryKey, Map<String, Object> properties) {
 		checkOpen();
 		return find( entityClass, primaryKey, null, properties );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType) {
 		checkOpen();
 		return find( entityClass, primaryKey, lockModeType, null );
 	}
 
 	@Override
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 		Session session = internalGetSession();
 		CacheMode previousCacheMode = session.getCacheMode();
 		CacheMode cacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			if ( properties != null && !properties.isEmpty() ) {
 				( (SessionImplementor) session ).getLoadQueryInfluencers()
 						.setFetchGraph( (EntityGraph) properties.get( QueryHints.HINT_FETCHGRAPH ) );
 				( (SessionImplementor) session ).getLoadQueryInfluencers()
 						.setLoadGraph( (EntityGraph) properties.get( QueryHints.HINT_LOADGRAPH ) );
 			}
 			session.setCacheMode( cacheMode );
 			if ( lockModeType != null ) {
 				lockOptions = getLockRequest( lockModeType, properties );
 				if ( !LockModeType.NONE.equals( lockModeType) ) {
 					checkTransactionNeeded();
 				}
 				return ( A ) session.get(
 						entityClass, ( Serializable ) primaryKey, 
 						lockOptions
 				);
 			}
 			else {
 				return ( A ) session.get( entityClass, ( Serializable ) primaryKey );
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/BaseQueryImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/BaseQueryImpl.java
index d57136386e..e7f4fe1025 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/BaseQueryImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/BaseQueryImpl.java
@@ -1,979 +1,979 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.spi;
 
 import java.util.Calendar;
 import java.util.Collection;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.CacheRetrieveMode;
 import javax.persistence.CacheStoreMode;
 import javax.persistence.FlushModeType;
 import javax.persistence.LockModeType;
 import javax.persistence.Parameter;
 import javax.persistence.Query;
 import javax.persistence.TemporalType;
 
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.QueryParameterException;
 import org.hibernate.engine.query.spi.EntityGraphQueryHint;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.QueryHints;
 import org.hibernate.jpa.graph.internal.EntityGraphImpl;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.util.CacheModeHelper;
 import org.hibernate.jpa.internal.util.ConfigurationHelper;
 import org.hibernate.jpa.internal.util.LockModeTypeHelper;
 import org.hibernate.jpa.internal.util.PessimisticNumberParser;
 import org.hibernate.procedure.NoSuchParameterException;
 import org.hibernate.procedure.ParameterStrategyException;
 
 import org.jboss.logging.Logger;
 
 import static org.hibernate.jpa.QueryHints.HINT_CACHEABLE;
 import static org.hibernate.jpa.QueryHints.HINT_CACHE_MODE;
 import static org.hibernate.jpa.QueryHints.HINT_CACHE_REGION;
 import static org.hibernate.jpa.QueryHints.HINT_COMMENT;
 import static org.hibernate.jpa.QueryHints.HINT_FETCHGRAPH;
 import static org.hibernate.jpa.QueryHints.HINT_FETCH_SIZE;
 import static org.hibernate.jpa.QueryHints.HINT_FLUSH_MODE;
 import static org.hibernate.jpa.QueryHints.HINT_LOADGRAPH;
 import static org.hibernate.jpa.QueryHints.HINT_NATIVE_LOCKMODE;
 import static org.hibernate.jpa.QueryHints.HINT_READONLY;
 import static org.hibernate.jpa.QueryHints.HINT_TIMEOUT;
 import static org.hibernate.jpa.QueryHints.SPEC_HINT_TIMEOUT;
 
 /**
  * Intended as the base class for all {@link javax.persistence.Query} implementations, including
  * {@link javax.persistence.TypedQuery} and {@link javax.persistence.StoredProcedureQuery}.  Care should be taken
  * that all changes here fit with all those usages.
  *
  * @author Steve Ebersole
  */
 public abstract class BaseQueryImpl implements Query {
 	private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(
 			EntityManagerMessageLogger.class,
 			AbstractQueryImpl.class.getName()
 	);
 
 	private final HibernateEntityManagerImplementor entityManager;
 
 	private int firstResult;
 	private int maxResults = -1;
 	private Map<String, Object> hints;
 
 	private EntityGraphQueryHint entityGraphQueryHint;
 
 	public BaseQueryImpl(HibernateEntityManagerImplementor entityManager) {
 		this.entityManager = entityManager;
 	}
 
 	protected HibernateEntityManagerImplementor entityManager() {
 		return entityManager;
 	}
 
 	protected void checkOpen(boolean markForRollbackIfClosed) {
 		entityManager.checkOpen( markForRollbackIfClosed );
 	}
 
 
 	// Limits (first and max results) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Apply the given first-result value.
 	 *
 	 * @param firstResult The specified first-result value.
 	 */
 	protected abstract void applyFirstResult(int firstResult);
 
 	@Override
 	public BaseQueryImpl setFirstResult(int firstResult) {
 		checkOpen( true );
 
 		if ( firstResult < 0 ) {
 			throw new IllegalArgumentException(
 					"Negative value (" + firstResult + ") passed to setFirstResult"
 			);
 		}
 		this.firstResult = firstResult;
 		applyFirstResult( firstResult );
 		return this;
 	}
 
 	@Override
 	public int getFirstResult() {
 		checkOpen( false ); // technically should rollback
 		return firstResult;
 	}
 
 	/**
 	 * Apply the given max results value.
 	 *
 	 * @param maxResults The specified max results
 	 */
 	protected abstract void applyMaxResults(int maxResults);
 
 	@Override
 	public BaseQueryImpl setMaxResults(int maxResult) {
 		checkOpen( true );
 		if ( maxResult < 0 ) {
 			throw new IllegalArgumentException(
 					"Negative value (" + maxResult + ") passed to setMaxResults"
 			);
 		}
 		this.maxResults = maxResult;
 		applyMaxResults( maxResult );
 		return this;
 	}
 
 	public int getSpecifiedMaxResults() {
 		return maxResults;
 	}
 
 	@Override
 	public int getMaxResults() {
 		checkOpen( false ); // technically should rollback
 		return maxResults == -1
 				? Integer.MAX_VALUE // stupid spec... MAX_VALUE??
 				: maxResults;
 	}
 
 
 	// Hints ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public Set<String> getSupportedHints() {
 		return QueryHints.getDefinedHints();
 	}
 
 	@Override
 	public Map<String, Object> getHints() {
 		checkOpen( false ); // technically should rollback
 		return hints;
 	}
 
 	/**
 	 * Apply the query timeout hint.
 	 *
 	 * @param timeout The timeout (in seconds!) specified as a hint
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyTimeoutHint(int timeout);
 
 	/**
 	 * Apply the lock timeout (in seconds!) hint
 	 *
 	 * @param timeout The timeout (in seconds!) specified as a hint
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyLockTimeoutHint(int timeout);
 
 	/**
 	 * Apply the comment hint.
 	 *
 	 * @param comment The comment specified as a hint
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyCommentHint(String comment);
 
 	/**
 	 * Apply the fetch size hint
 	 *
 	 * @param fetchSize The fetch size specified as a hint
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyFetchSizeHint(int fetchSize);
 
 	/**
 	 * Apply the cacheable (true/false) hint.
 	 *
 	 * @param isCacheable The value specified as hint
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyCacheableHint(boolean isCacheable);
 
 	/**
 	 * Apply the cache region hint
 	 *
 	 * @param regionName The name of the cache region specified as a hint
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyCacheRegionHint(String regionName);
 
 	/**
 	 * Apply the read-only (true/false) hint.
 	 *
 	 * @param isReadOnly The value specified as hint
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyReadOnlyHint(boolean isReadOnly);
 
 	/**
 	 * Apply the CacheMode hint.
 	 *
 	 * @param cacheMode The CacheMode value specified as a hint.
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyCacheModeHint(CacheMode cacheMode);
 
 	/**
 	 * Apply the FlushMode hint.
 	 *
 	 * @param flushMode The FlushMode value specified as hint
 	 *
 	 * @return {@code true} if the hint was "applied"
 	 */
 	protected abstract boolean applyFlushModeHint(FlushMode flushMode);
 
 	/**
 	 * Can alias-specific lock modes be applied?
 	 *
 	 * @return {@code true} indicates they can be applied, {@code false} otherwise.
 	 */
 	protected abstract boolean canApplyAliasSpecificLockModeHints();
 
 	/**
 	 * Apply the alias specific lock modes.  Assumes {@link #canApplyAliasSpecificLockModeHints()} has already been
 	 * called and returned {@code true}.
 	 *
 	 * @param alias The alias to apply the 'lockMode' to.
 	 * @param lockMode The LockMode to apply.
 	 */
 	protected abstract void applyAliasSpecificLockModeHint(String alias, LockMode lockMode);
 
 	@Override
 	@SuppressWarnings( {"deprecation"})
 	public BaseQueryImpl setHint(String hintName, Object value) {
 		checkOpen( true );
 		boolean applied = false;
 		try {
 			if ( HINT_TIMEOUT.equals( hintName ) ) {
 				applied = applyTimeoutHint( ConfigurationHelper.getInteger( value ) );
 			}
 			else if ( SPEC_HINT_TIMEOUT.equals( hintName ) ) {
 				// convert milliseconds to seconds
 				int timeout = (int)Math.round(ConfigurationHelper.getInteger( value ).doubleValue() / 1000.0 );
 				applied = applyTimeoutHint( timeout );
 			}
 			else if ( AvailableSettings.LOCK_TIMEOUT.equals( hintName ) ) {
 				applied = applyLockTimeoutHint( ConfigurationHelper.getInteger( value ) );
 			}
 			else if ( HINT_COMMENT.equals( hintName ) ) {
 				applied = applyCommentHint( (String) value );
 			}
 			else if ( HINT_FETCH_SIZE.equals( hintName ) ) {
 				applied = applyFetchSizeHint( ConfigurationHelper.getInteger( value ) );
 			}
 			else if ( HINT_CACHEABLE.equals( hintName ) ) {
 				applied = applyCacheableHint( ConfigurationHelper.getBoolean( value ) );
 			}
 			else if ( HINT_CACHE_REGION.equals( hintName ) ) {
 				applied = applyCacheRegionHint( (String) value );
 			}
 			else if ( HINT_READONLY.equals( hintName ) ) {
 				applied = applyReadOnlyHint( ConfigurationHelper.getBoolean( value ) );
 			}
 			else if ( HINT_CACHE_MODE.equals( hintName ) ) {
 				applied = applyCacheModeHint( ConfigurationHelper.getCacheMode( value ) );
 			}
 			else if ( HINT_FLUSH_MODE.equals( hintName ) ) {
 				applied = applyFlushModeHint( ConfigurationHelper.getFlushMode( value ) );
 			}
 			else if ( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE.equals( hintName ) ) {
 				final CacheRetrieveMode retrieveMode = value != null ? CacheRetrieveMode.valueOf( value.toString() ) : null;
 				final CacheStoreMode storeMode = getHint( AvailableSettings.SHARED_CACHE_STORE_MODE, CacheStoreMode.class );
 				applied = applyCacheModeHint( CacheModeHelper.interpretCacheMode( storeMode, retrieveMode ) );
 			}
 			else if ( AvailableSettings.SHARED_CACHE_STORE_MODE.equals( hintName ) ) {
-				final CacheStoreMode storeMode = value != null ? CacheStoreMode.valueOf( value.toString () ) : null;
+				final CacheStoreMode storeMode = value != null ? CacheStoreMode.valueOf( value.toString() ) : null;
 				final CacheRetrieveMode retrieveMode = getHint( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE, CacheRetrieveMode.class );
 				applied = applyCacheModeHint( CacheModeHelper.interpretCacheMode( storeMode, retrieveMode ) );
 			}
 			else if ( QueryHints.HINT_NATIVE_LOCKMODE.equals( hintName ) ) {
 				if ( !isNativeSqlQuery() ) {
 					throw new IllegalStateException(
 							"Illegal attempt to set lock mode on non-native query via hint; use Query#setLockMode instead"
 					);
 				}
 				if ( LockMode.class.isInstance( value ) ) {
 					internalApplyLockMode( LockModeTypeHelper.getLockModeType( (LockMode) value ) );
 				}
 				else if ( LockModeType.class.isInstance( value ) ) {
 					internalApplyLockMode( (LockModeType) value );
 				}
 				else {
 					throw new IllegalArgumentException(
 							String.format(
 									"Native lock-mode hint [%s] must specify %s or %s.  Encountered type : %s",
 									HINT_NATIVE_LOCKMODE,
 									LockMode.class.getName(),
 									LockModeType.class.getName(),
 									value.getClass().getName()
 							)
 					);
 				}
 				applied = true;
 			}
 			else if ( hintName.startsWith( AvailableSettings.ALIAS_SPECIFIC_LOCK_MODE ) ) {
 				if ( canApplyAliasSpecificLockModeHints() ) {
 					// extract the alias
 					final String alias = hintName.substring( AvailableSettings.ALIAS_SPECIFIC_LOCK_MODE.length() + 1 );
 					// determine the LockMode
 					try {
 						final LockMode lockMode = LockModeTypeHelper.interpretLockMode( value );
 						applyAliasSpecificLockModeHint( alias, lockMode );
 					}
 					catch ( Exception e ) {
 						LOG.unableToDetermineLockModeValue( hintName, value );
 						applied = false;
 					}
 				}
 				else {
 					applied = false;
 				}
 			}
 			else if ( HINT_FETCHGRAPH.equals( hintName ) || HINT_LOADGRAPH.equals( hintName ) ) {
 				if (value instanceof EntityGraphImpl) {
 					entityGraphQueryHint = new EntityGraphQueryHint( (EntityGraphImpl) value );
 				}
 				else {
 					LOG.warnf( "The %s hint was set, but the value was not an EntityGraph!", hintName );
 				}
 				applied = true;
 			}
 			else {
 				LOG.ignoringUnrecognizedQueryHint( hintName );
 			}
 		}
 		catch ( ClassCastException e ) {
 			throw new IllegalArgumentException( "Value for hint" );
 		}
 
 		if ( applied ) {
 			if ( hints == null ) {
 				hints = new HashMap<String,Object>();
 			}
 			hints.put( hintName, value );
 		}
 		else {
 			LOG.debugf( "Skipping unsupported query hint [%s]", hintName );
 		}
 
 		return this;
 	}
 
 	private <T extends Enum<T>> T getHint(String key, Class<T> hintClass) {
 		Object hint = hints != null ? hints.get( key ) : null;
 
 		if ( hint == null ) {
 			hint = entityManager.getProperties().get( key );
 		}
 
 		return hint != null ? Enum.valueOf( hintClass, hint.toString() ) : null;
 	}
 
 	/**
 	 * Is the query represented here a native SQL query?
 	 *
 	 * @return {@code true} if it is a native SQL query; {@code false} otherwise
 	 */
 	protected abstract boolean isNativeSqlQuery();
 
 	/**
 	 * Is the query represented here a SELECT query?
 	 *
 	 * @return {@code true} if the query is a SELECT; {@code false} otherwise.
 	 */
 	protected abstract boolean isSelectQuery();
 
 	protected abstract void internalApplyLockMode(javax.persistence.LockModeType lockModeType);
 
 	// FlushMode ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private FlushModeType jpaFlushMode;
 
 	@Override
 	public BaseQueryImpl setFlushMode(FlushModeType jpaFlushMode) {
 		checkOpen( true );
 		this.jpaFlushMode = jpaFlushMode;
 		// TODO : treat as hint?
 		if ( jpaFlushMode == FlushModeType.AUTO ) {
 			applyFlushModeHint( FlushMode.AUTO );
 		}
 		else if ( jpaFlushMode == FlushModeType.COMMIT ) {
 			applyFlushModeHint( FlushMode.COMMIT );
 		}
 		return this;
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected FlushModeType getSpecifiedFlushMode() {
 		return jpaFlushMode;
 	}
 
 	@Override
 	public FlushModeType getFlushMode() {
 		checkOpen( false );
 		return jpaFlushMode != null
 				? jpaFlushMode
 				: entityManager.getFlushMode();
 	}
 
 
 	// Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private Set<ParameterRegistration<?>> parameterRegistrations;
 
 	protected <X> ParameterRegistration<X> findParameterRegistration(Parameter<X> parameter) {
 		if ( ParameterRegistration.class.isInstance( parameter ) ) {
 			final ParameterRegistration<X> reg = (ParameterRegistration<X>) parameter;
 			// validate the parameter source
 			if ( reg.getQuery() != this ) {
 				throw new IllegalArgumentException( "Passed Parameter was from different Query" );
 			}
 			return reg;
 		}
 		else {
 			if ( parameter.getName() != null ) {
 				return findParameterRegistration( parameter.getName() );
 			}
 			else if ( parameter.getPosition() != null ) {
 				return findParameterRegistration( parameter.getPosition() );
 			}
 		}
 
 		throw new IllegalArgumentException( "Unable to resolve incoming parameter [" + parameter + "] to registration" );
 	}
 
 	@SuppressWarnings("unchecked")
 	protected <X> ParameterRegistration<X> findParameterRegistration(String parameterName) {
 		if ( parameterRegistrations != null ) {
 			for ( ParameterRegistration<?> param : parameterRegistrations ) {
 				if ( parameterName.equals( param.getName() ) ) {
 					return (ParameterRegistration<X>) param;
 				}
 			}
 
 			// legacy allowance of the application to access the parameter using the position as a String
 			final Integer jpaPositionalParameter = PessimisticNumberParser.toNumberOrNull( parameterName );
 			if ( jpaPositionalParameter != null ) {
 				for ( ParameterRegistration<?> param : parameterRegistrations ) {
 					if ( param.isJpaPositionalParameter() && jpaPositionalParameter.equals( param.getPosition() ) ) {
 						LOG.deprecatedJpaPositionalParameterAccess( jpaPositionalParameter );
 						return (ParameterRegistration<X>) param;
 					}
 				}
 			}
 		}
 		throw new IllegalArgumentException( "Parameter with that name [" + parameterName + "] did not exist" );
 	}
 
 	@SuppressWarnings("unchecked")
 	protected <X> ParameterRegistration<X> findParameterRegistration(int parameterPosition) {
 		if ( parameterRegistrations != null ) {
 			for ( ParameterRegistration<?> param : parameterRegistrations ) {
 				if ( param.getPosition() == null ) {
 					continue;
 				}
 				if ( parameterPosition == param.getPosition() ) {
 					return (ParameterRegistration<X>) param;
 				}
 			}
 		}
 		throw new IllegalArgumentException( "Parameter with that position [" + parameterPosition + "] did not exist" );
 	}
 
 	protected static class ParameterBindImpl<T> implements ParameterBind<T> {
 		private final T value;
 		private final TemporalType specifiedTemporalType;
 
 		public ParameterBindImpl(T value, TemporalType specifiedTemporalType) {
 			this.value = value;
 			this.specifiedTemporalType = specifiedTemporalType;
 		}
 
 		public T getValue() {
 			return value;
 		}
 
 		public TemporalType getSpecifiedTemporalType() {
 			return specifiedTemporalType;
 		}
 	}
 
 	private Set<ParameterRegistration<?>> parameterRegistrations() {
 		if ( parameterRegistrations == null ) {
 			// todo : could se use an identity set here?
 			parameterRegistrations = new HashSet<ParameterRegistration<?>>();
 		}
 		return parameterRegistrations;
 	}
 
 	protected void registerParameter(ParameterRegistration parameter) {
 		if ( parameter == null ) {
 			throw new IllegalArgumentException( "parameter cannot be null" );
 		}
 
 		if ( parameterRegistrations().contains( parameter ) ) {
 			LOG.debug( "Parameter registered multiple times : " + parameter );
 			return;
 		}
 
 		parameterRegistrations().add( parameter );
 	}
 
 	@Override
 	public <T> BaseQueryImpl setParameter(Parameter<T> param, T value) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( param ).bindValue( value );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	public BaseQueryImpl setParameter(Parameter<Calendar> param, Calendar value, TemporalType temporalType) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( param ).bindValue( value, temporalType );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	public BaseQueryImpl setParameter(Parameter<Date> param, Date value, TemporalType temporalType) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( param ).bindValue( value, temporalType );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public BaseQueryImpl setParameter(String name, Object value) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( name ).bindValue( value );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	public BaseQueryImpl setParameter(String name, Calendar value, TemporalType temporalType) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( name ).bindValue( value, temporalType );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	public BaseQueryImpl setParameter(String name, Date value, TemporalType temporalType) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( name ).bindValue( value, temporalType );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	public BaseQueryImpl setParameter(int position, Object value) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( position ).bindValue( value );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	public BaseQueryImpl setParameter(int position, Calendar value, TemporalType temporalType) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( position ).bindValue( value, temporalType );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	public BaseQueryImpl setParameter(int position, Date value, TemporalType temporalType) {
 		checkOpen( true );
 
 		try {
 			findParameterRegistration( position ).bindValue( value, temporalType );
 		}
 		catch (ParameterStrategyException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( "Invalid mix of named and positional parameters", e );
 		}
 		catch (NoSuchParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (QueryParameterException e) {
 			entityManager().markForRollbackOnly();
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (HibernateException he) {
 			throw entityManager.convert( he );
 		}
 
 		return this;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public Set getParameters() {
 		checkOpen( false );
 		return parameterRegistrations();
 	}
 
 	@Override
 	public Parameter<?> getParameter(String name) {
 		checkOpen( false );
 		return findParameterRegistration( name );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> Parameter<T> getParameter(String name, Class<T> type) {
 		checkOpen( false );
 		Parameter param = findParameterRegistration( name );
 
 		if ( param.getParameterType() != null ) {
 			// we were able to determine the expected type during analysis, so validate it here
 			if ( ! param.getParameterType().isAssignableFrom( type ) ) {
 				throw new IllegalArgumentException(
 						String.format(
 								"Parameter type [%s] is not assignment compatible with requested type [%s] for parameter named [%s]",
 								param.getParameterType().getName(),
 								type.getName(),
 								name
 						)
 				);
 			}
 		}
 		return (Parameter<T>) param;
 	}
 
 	@Override
 	public Parameter<?> getParameter(int position) {
 		checkOpen( false );
 		return findParameterRegistration( position );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> Parameter<T> getParameter(int position, Class<T> type) {
 		checkOpen( false );
 
 		Parameter param = findParameterRegistration( position );
 
 		if ( param.getParameterType() != null ) {
 			// we were able to determine the expected type during analysis, so validate it here
 			if ( ! param.getParameterType().isAssignableFrom( type ) ) {
 				throw new IllegalArgumentException(
 						String.format(
 								"Parameter type [%s] is not assignment compatible with requested type [%s] for parameter at position [%s]",
 								param.getParameterType().getName(),
 								type.getName(),
 								position
 						)
 				);
 			}
 		}
 		return (Parameter<T>) param;
 	}
 
 	@Override
 	public boolean isBound(Parameter<?> param) {
 		checkOpen( false );
 		final ParameterRegistration registration = findParameterRegistration( param );
 		return registration != null && registration.isBindable() && registration.getBind() != null;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> T getParameterValue(Parameter<T> param) {
 		checkOpen( false );
 
 		final ParameterRegistration<T> registration = findParameterRegistration( param );
 		if ( registration == null ) {
 			throw new IllegalArgumentException( "Passed parameter [" + param + "] is not a (registered) parameter of this query" );
 		}
 
 		if ( ! registration.isBindable() ) {
 			throw new IllegalStateException( "Passed parameter [" + param + "] is not bindable" );
 		}
 
 		final ParameterBind<T> bind = registration.getBind();
 		if ( bind == null ) {
 			throw new IllegalStateException( "Parameter [" + param + "] has not yet been bound" );
 		}
 
 		return bind.getValue();
 	}
 
 	@Override
 	public Object getParameterValue(String name) {
 		checkOpen( false );
 		return getParameterValue( getParameter( name ) );
 	}
 
 	@Override
 	public Object getParameterValue(int position) {
 		checkOpen( false );
 		return getParameterValue( getParameter( position ) );
 	}
 	
 	protected EntityGraphQueryHint getEntityGraphQueryHint() {
 		return entityGraphQueryHint;
 	}
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 	protected static void validateBinding(Class parameterType, Object bind, TemporalType temporalType) {
 		if ( bind == null || parameterType == null ) {
 			// nothing we can check
 			return;
 		}
 
 		if ( Collection.class.isInstance( bind ) && ! Collection.class.isAssignableFrom( parameterType ) ) {
 			// we have a collection passed in where we are expecting a non-collection.
 			// 		NOTE : this can happen in Hibernate's notion of "parameter list" binding
 			// 		NOTE2 : the case of a collection value and an expected collection (if that can even happen)
 			//			will fall through to the main check.
 			validateCollectionValuedParameterBinding( parameterType, (Collection) bind, temporalType );
 		}
 		else if ( bind.getClass().isArray() ) {
 			validateArrayValuedParameterBinding( parameterType, bind, temporalType );
 		}
 		else {
 			if ( ! isValidBindValue( parameterType, bind, temporalType ) ) {
 				throw new IllegalArgumentException(
 						String.format(
 								"Parameter value [%s] did not match expected type [%s (%s)]",
 								bind,
 								parameterType.getName(),
 								extractName( temporalType )
 						)
 				);
 			}
 		}
 	}
 
 	private static String extractName(TemporalType temporalType) {
 		return temporalType == null ? "n/a" : temporalType.name();
 	}
 
 	private static void validateCollectionValuedParameterBinding(
 			Class parameterType,
 			Collection value,
 			TemporalType temporalType) {
 		// validate the elements...
 		for ( Object element : value ) {
 			if ( ! isValidBindValue( parameterType, element, temporalType ) ) {
 				throw new IllegalArgumentException(
 						String.format(
 								"Parameter value element [%s] did not match expected type [%s (%s)]",
 								element,
 								parameterType.getName(),
 								extractName( temporalType )
 						)
 				);
 			}
 		}
 	}
 
 	private static void validateArrayValuedParameterBinding(
 			Class parameterType,
 			Object value,
 			TemporalType temporalType) {
 		if ( ! parameterType.isArray() ) {
 			throw new IllegalArgumentException(
 					String.format(
 							"Encountered array-valued parameter binding, but was expecting [%s (%s)]",
 							parameterType.getName(),
 							extractName( temporalType )
 					)
 			);
 		}
 
 		if ( value.getClass().getComponentType().isPrimitive() ) {
 			// we have a primitive array.  we validate that the actual array has the component type (type of elements)
 			// we expect based on the component type of the parameter specification
 			if ( ! parameterType.getComponentType().isAssignableFrom( value.getClass().getComponentType() ) ) {
 				throw new IllegalArgumentException(
 						String.format(
 								"Primitive array-valued parameter bind value type [%s] did not match expected type [%s (%s)]",
 								value.getClass().getComponentType().getName(),
 								parameterType.getName(),
 								extractName( temporalType )
 						)
 				);
 			}
 		}
 		else {
 			// we have an object array.  Here we loop over the array and physically check each element against
 			// the type we expect based on the component type of the parameter specification
 			final Object[] array = (Object[]) value;
 			for ( Object element : array ) {
 				if ( ! isValidBindValue( parameterType.getComponentType(), element, temporalType ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Array-valued parameter value element [%s] did not match expected type [%s (%s)]",
 									element,
 									parameterType.getName(),
 									extractName( temporalType )
 							)
 					);
 				}
 			}
 		}
 	}
 
 
 	private static boolean isValidBindValue(Class expectedType, Object value, TemporalType temporalType) {
 		if ( expectedType.isInstance( value ) ) {
 			return true;
 		}
 
 		if ( temporalType != null ) {
 			final boolean parameterDeclarationIsTemporal = Date.class.isAssignableFrom( expectedType )
 					|| Calendar.class.isAssignableFrom( expectedType );
 			final boolean bindIsTemporal = Date.class.isInstance( value )
 					|| Calendar.class.isInstance( value );
 
 			if ( parameterDeclarationIsTemporal && bindIsTemporal ) {
 				return true;
 			}
 		}
 
 		return false;
 	}
 
 
 
 
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
index 8be9162be2..d3573055ed 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
@@ -1,86 +1,75 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria;
 
 import org.hibernate.envers.query.criteria.internal.IdentifierEqAuditExpression;
 import org.hibernate.envers.query.internal.property.EntityPropertyName;
 import org.hibernate.envers.query.internal.property.OriginalIdPropertyName;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 import org.hibernate.envers.query.projection.AuditProjection;
 import org.hibernate.envers.query.projection.internal.PropertyAuditProjection;
 
 /**
  * Create restrictions and projections for the id of an audited entity.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 @SuppressWarnings({"JavaDoc"})
 public class AuditId<T> extends AuditProperty<T> {
 	public static final String IDENTIFIER_PLACEHOLDER = "$$id$$";
 	private static final PropertyNameGetter IDENTIFIER_PROPERTY_GETTER = new EntityPropertyName( IDENTIFIER_PLACEHOLDER );
 
 	public AuditId() {
 		super( IDENTIFIER_PROPERTY_GETTER );
 	}
 
 	/**
 	 * Apply an "equal" constraint
 	 */
 	@Override
 	public AuditCriterion eq(Object id) {
 		return new IdentifierEqAuditExpression( id, true );
 	}
 
 	/**
 	 * Apply a "not equal" constraint
 	 */
 	@Override
 	public AuditCriterion ne(Object id) {
 		return new IdentifierEqAuditExpression( id, false );
 	}
 
 	// Projections
 
-	/**
-	 * Projection counting the values
-	 *
-	 * @param idPropertyName Name of the identifier property
-	 *
-	 * @deprecated Use {@link #count()}.
-	 */
-	public AuditProjection count(String idPropertyName) {
-		return new PropertyAuditProjection( new OriginalIdPropertyName( idPropertyName ), "count", false );
-	}
-
 	@Override
 	public AuditCriterion hasChanged() {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public AuditCriterion hasNotChanged() {
 		throw new UnsupportedOperationException();
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/impl/AbstractAuditQuery.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/impl/AbstractAuditQuery.java
index 8dcc536e3d..900504eace 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/impl/AbstractAuditQuery.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/impl/AbstractAuditQuery.java
@@ -1,267 +1,268 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.internal.impl;
 
 import java.util.ArrayList;
 import java.util.List;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.Query;
 import org.hibernate.envers.boot.internal.EnversService;
 import org.hibernate.envers.exception.AuditException;
 import org.hibernate.envers.internal.entities.EntityInstantiator;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.internal.tools.Triple;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.envers.query.AuditQuery;
 import org.hibernate.envers.query.criteria.AuditCriterion;
 import org.hibernate.envers.query.criteria.internal.CriteriaTools;
 import org.hibernate.envers.query.order.AuditOrder;
 import org.hibernate.envers.query.projection.AuditProjection;
 import org.hibernate.envers.tools.Pair;
 
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REFERENCED_ENTITY_ALIAS;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author HernпїЅn Chanfreau
  */
 public abstract class AbstractAuditQuery implements AuditQuery {
 	protected EntityInstantiator entityInstantiator;
 	protected List<AuditCriterion> criterions;
 
 	protected String entityName;
 	protected String entityClassName;
 	protected String versionsEntityName;
 	protected QueryBuilder qb;
 
 	protected boolean hasProjection;
 	protected boolean hasOrder;
 
 	protected final EnversService enversService;
 	protected final AuditReaderImplementor versionsReader;
 
 	protected AbstractAuditQuery(
 			EnversService enversService,
 			AuditReaderImplementor versionsReader,
 			Class<?> cls) {
 		this( enversService, versionsReader, cls, cls.getName() );
 	}
 
 	protected AbstractAuditQuery(
 			EnversService enversService,
 			AuditReaderImplementor versionsReader,
 			Class<?> cls,
 			String entityName) {
 		this.enversService = enversService;
 		this.versionsReader = versionsReader;
 
 		criterions = new ArrayList<AuditCriterion>();
 		entityInstantiator = new EntityInstantiator( enversService, versionsReader );
 
 		entityClassName = cls.getName();
 		this.entityName = entityName;
 		versionsEntityName = enversService.getAuditEntitiesConfiguration().getAuditEntityName( entityName );
 
 		qb = new QueryBuilder( versionsEntityName, REFERENCED_ENTITY_ALIAS );
 	}
 
 	protected Query buildQuery() {
 		Query query = qb.toQuery( versionsReader.getSession() );
 		setQueryProperties( query );
 		return query;
 	}
 
 	protected List buildAndExecuteQuery() {
 		Query query = buildQuery();
 
 		return query.list();
 	}
 
 	public abstract List list() throws AuditException;
 
 	public List getResultList() throws AuditException {
 		return list();
 	}
 
 	public Object getSingleResult() throws AuditException, NonUniqueResultException, NoResultException {
 		List result = list();
 
 		if ( result == null || result.size() == 0 ) {
 			throw new NoResultException();
 		}
 
 		if ( result.size() > 1 ) {
 			throw new NonUniqueResultException();
 		}
 
 		return result.get( 0 );
 	}
 
 	public AuditQuery add(AuditCriterion criterion) {
 		criterions.add( criterion );
 		return this;
 	}
 
 	// Projection and order
 
 	public AuditQuery addProjection(AuditProjection projection) {
 		Triple<String, String, Boolean> projectionData = projection.getData( enversService );
 		hasProjection = true;
 		String propertyName = CriteriaTools.determinePropertyName(
 				enversService,
 				versionsReader,
 				entityName,
 				projectionData.getSecond()
 		);
 		qb.addProjection( projectionData.getFirst(), propertyName, projectionData.getThird() );
 		return this;
 	}
 
 	public AuditQuery addOrder(AuditOrder order) {
 		hasOrder = true;
 		Pair<String, Boolean> orderData = order.getData( enversService );
 		String propertyName = CriteriaTools.determinePropertyName(
 				enversService,
 				versionsReader,
 				entityName,
 				orderData.getFirst()
 		);
 		qb.addOrder( propertyName, orderData.getSecond() );
 		return this;
 	}
 
 	// Query properties
 
 	private Integer maxResults;
 	private Integer firstResult;
 	private Boolean cacheable;
 	private String cacheRegion;
 	private String comment;
 	private FlushMode flushMode;
 	private CacheMode cacheMode;
 	private Integer timeout;
 	private LockOptions lockOptions = new LockOptions( LockMode.NONE );
 
 	public AuditQuery setMaxResults(int maxResults) {
 		this.maxResults = maxResults;
 		return this;
 	}
 
 	public AuditQuery setFirstResult(int firstResult) {
 		this.firstResult = firstResult;
 		return this;
 	}
 
 	public AuditQuery setCacheable(boolean cacheable) {
 		this.cacheable = cacheable;
 		return this;
 	}
 
 	public AuditQuery setCacheRegion(String cacheRegion) {
 		this.cacheRegion = cacheRegion;
 		return this;
 	}
 
 	public AuditQuery setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
 
 	public AuditQuery setFlushMode(FlushMode flushMode) {
 		this.flushMode = flushMode;
 		return this;
 	}
 
 	public AuditQuery setCacheMode(CacheMode cacheMode) {
 		this.cacheMode = cacheMode;
 		return this;
 	}
 
 	public AuditQuery setTimeout(int timeout) {
 		this.timeout = timeout;
 		return this;
 	}
 
 	/**
 	 * Set lock mode
 	 *
 	 * @param lockMode The {@link LockMode} used for this query.
 	 *
 	 * @return this object
 	 *
 	 * @deprecated Instead use setLockOptions
 	 */
+	@Deprecated
 	public AuditQuery setLockMode(LockMode lockMode) {
 		lockOptions.setLockMode( lockMode );
 		return this;
 	}
 
 	/**
 	 * Set lock options
 	 *
 	 * @param lockOptions The @{link LockOptions} used for this query.
 	 *
 	 * @return this object
 	 */
 	public AuditQuery setLockOptions(LockOptions lockOptions) {
 		LockOptions.copy( lockOptions, this.lockOptions );
 		return this;
 	}
 
 	protected void setQueryProperties(Query query) {
 		if ( maxResults != null ) {
 			query.setMaxResults( maxResults );
 		}
 		if ( firstResult != null ) {
 			query.setFirstResult( firstResult );
 		}
 		if ( cacheable != null ) {
 			query.setCacheable( cacheable );
 		}
 		if ( cacheRegion != null ) {
 			query.setCacheRegion( cacheRegion );
 		}
 		if ( comment != null ) {
 			query.setComment( comment );
 		}
 		if ( flushMode != null ) {
 			query.setFlushMode( flushMode );
 		}
 		if ( cacheMode != null ) {
 			query.setCacheMode( cacheMode );
 		}
 		if ( timeout != null ) {
 			query.setTimeout( timeout );
 		}
 		if ( lockOptions != null && lockOptions.getLockMode() != LockMode.NONE ) {
 			query.setLockMode( REFERENCED_ENTITY_ALIAS, lockOptions.getLockMode() );
 		}
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/OriginalIdPropertyName.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/OriginalIdPropertyName.java
index fad9d8c77d..4de05c2068 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/OriginalIdPropertyName.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/OriginalIdPropertyName.java
@@ -1,46 +1,44 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.internal.property;
 
 import org.hibernate.envers.boot.internal.EnversService;
-import org.hibernate.envers.query.criteria.AuditId;
 
 /**
  * Used for specifying restrictions on the identifier.
  *
  * @author Adam Warski (adam at warski dot org)
- * @deprecated To be removed together with {@link AuditId#count(String)} in version 5.0.
  */
 public class OriginalIdPropertyName implements PropertyNameGetter {
 	private final String idPropertyName;
 
 	public OriginalIdPropertyName(String idPropertyName) {
 		this.idPropertyName = idPropertyName;
 	}
 
 	@Override
 	public String get(EnversService enversService) {
 		return enversService.getAuditEntitiesConfiguration().getOriginalIdPropName() + "." + idPropertyName;
 	}
 }
diff --git a/hibernate-envers/src/test/java/org/hibernate/envers/test/integration/query/DeletedEntities.java b/hibernate-envers/src/test/java/org/hibernate/envers/test/integration/query/DeletedEntities.java
index 333676aa3d..4f0735fb27 100644
--- a/hibernate-envers/src/test/java/org/hibernate/envers/test/integration/query/DeletedEntities.java
+++ b/hibernate-envers/src/test/java/org/hibernate/envers/test/integration/query/DeletedEntities.java
@@ -1,101 +1,101 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.test.integration.query;
 
 import java.util.List;
 import javax.persistence.EntityManager;
 
 import org.hibernate.envers.RevisionType;
 import org.hibernate.envers.enhanced.SequenceIdRevisionEntity;
 import org.hibernate.envers.query.AuditEntity;
 import org.hibernate.envers.test.BaseEnversJPAFunctionalTestCase;
 import org.hibernate.envers.test.Priority;
 import org.hibernate.envers.test.entities.StrIntTestEntity;
 
 import org.junit.Test;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class DeletedEntities extends BaseEnversJPAFunctionalTestCase {
 	private Integer id2;
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] {StrIntTestEntity.class};
 	}
 
 	@Test
 	@Priority(10)
 	public void initData() {
 		// Revision 1
 		EntityManager em = getEntityManager();
 		em.getTransaction().begin();
 
 		StrIntTestEntity site1 = new StrIntTestEntity( "a", 10 );
 		StrIntTestEntity site2 = new StrIntTestEntity( "b", 11 );
 
 		em.persist( site1 );
 		em.persist( site2 );
 
 		id2 = site2.getId();
 
 		em.getTransaction().commit();
 
 		// Revision 2
 		em.getTransaction().begin();
 
 		site2 = em.find( StrIntTestEntity.class, id2 );
 		em.remove( site2 );
 
 		em.getTransaction().commit();
 	}
 
 	@Test
 	public void testProjectionsInEntitiesAtRevision() {
 		assert getAuditReader().createQuery().forEntitiesAtRevision( StrIntTestEntity.class, 1 )
 				.getResultList().size() == 2;
 		assert getAuditReader().createQuery().forEntitiesAtRevision( StrIntTestEntity.class, 2 )
 				.getResultList().size() == 1;
 
 		assert (Long) getAuditReader().createQuery().forEntitiesAtRevision( StrIntTestEntity.class, 1 )
-				.addProjection( AuditEntity.id().count( "id" ) ).getResultList().get( 0 ) == 2;
+				.addProjection( AuditEntity.id().count() ).getResultList().get( 0 ) == 2;
 		assert (Long) getAuditReader().createQuery().forEntitiesAtRevision( StrIntTestEntity.class, 2 )
 				.addProjection( AuditEntity.id().count() ).getResultList().get( 0 ) == 1;
 	}
 
 	@Test
 	public void testRevisionsOfEntityWithoutDelete() {
 		List result = getAuditReader().createQuery()
 				.forRevisionsOfEntity( StrIntTestEntity.class, false, false )
 				.add( AuditEntity.id().eq( id2 ) )
 				.getResultList();
 
 		assert result.size() == 1;
 
 		assert ((Object[]) result.get( 0 ))[0].equals( new StrIntTestEntity( "b", 11, id2 ) );
 		assert ((SequenceIdRevisionEntity) ((Object[]) result.get( 0 ))[1]).getId() == 1;
 		assert ((Object[]) result.get( 0 ))[2].equals( RevisionType.ADD );
 	}
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/access/TransactionalAccessDelegate.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/access/TransactionalAccessDelegate.java
index facc57d233..626d64a3f2 100755
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/access/TransactionalAccessDelegate.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/access/TransactionalAccessDelegate.java
@@ -1,258 +1,260 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cache.infinispan.access;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.infinispan.impl.BaseRegion;
 import org.hibernate.cache.infinispan.util.Caches;
 
 import org.infinispan.AdvancedCache;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * Defines the strategy for transactional access to entity or collection data in a Infinispan instance.
  * <p/>
  * The intent of this class is to encapsulate common code and serve as a delegate for
  * {@link org.hibernate.cache.spi.access.EntityRegionAccessStrategy}
  * and {@link org.hibernate.cache.spi.access.CollectionRegionAccessStrategy} implementations.
  *
  * @author Brian Stansberry
  * @author Galder Zamarreño
  * @since 3.5
  */
 public class TransactionalAccessDelegate {
 	private static final Log log = LogFactory.getLog( TransactionalAccessDelegate.class );
 	private static final boolean TRACE_ENABLED = log.isTraceEnabled();
 	private final AdvancedCache cache;
 	private final BaseRegion region;
 	private final PutFromLoadValidator putValidator;
 	private final AdvancedCache<Object, Object> writeCache;
 
    /**
     * Create a new transactional access delegate instance.
     *
     * @param region to control access to
     * @param validator put from load validator
     */
 	@SuppressWarnings("unchecked")
 	public TransactionalAccessDelegate(BaseRegion region, PutFromLoadValidator validator) {
 		this.region = region;
 		this.cache = region.getCache();
 		this.putValidator = validator;
 		this.writeCache = Caches.ignoreReturnValuesCache( cache );
 	}
 
    /**
     * Attempt to retrieve an object from the cache.
     *
     * @param key The key of the item to be retrieved
     * @param txTimestamp a timestamp prior to the transaction start time
     * @return the cached object or <tt>null</tt>
     * @throws CacheException if the cache retrieval failed
     */
 	@SuppressWarnings("UnusedParameters")
 	public Object get(Object key, long txTimestamp) throws CacheException {
 		if ( !region.checkValid() ) {
 			return null;
 		}
 		final Object val = cache.get( key );
 		if ( val == null ) {
 			putValidator.registerPendingPut( key );
 		}
 		return val;
 	}
 
    /**
     * Attempt to cache an object, after loading from the database.
     *
     * @param key The item key
     * @param value The item
     * @param txTimestamp a timestamp prior to the transaction start time
     * @param version the item version number
     * @return <tt>true</tt> if the object was successfully cached
     */
 	public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) {
 		return putFromLoad( key, value, txTimestamp, version, false );
 	}
 
    /**
     * Attempt to cache an object, after loading from the database, explicitly
     * specifying the minimalPut behavior.
     *
     * @param key The item key
     * @param value The item
     * @param txTimestamp a timestamp prior to the transaction start time
     * @param version the item version number
     * @param minimalPutOverride Explicit minimalPut flag
     * @return <tt>true</tt> if the object was successfully cached
     * @throws CacheException if storing the object failed
     */
 	@SuppressWarnings("UnusedParameters")
 	public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version, boolean minimalPutOverride)
 			throws CacheException {
 		if ( !region.checkValid() ) {
 			if ( TRACE_ENABLED ) {
 				log.tracef( "Region %s not valid", region.getName() );
 			}
 			return false;
 		}
 
 		// In theory, since putForExternalRead is already as minimal as it can
 		// get, we shouldn't be need this check. However, without the check and
 		// without https://issues.jboss.org/browse/ISPN-1986, it's impossible to
 		// know whether the put actually occurred. Knowing this is crucial so
 		// that Hibernate can expose accurate statistics.
 		if ( minimalPutOverride && cache.containsKey( key ) ) {
 			return false;
 		}
 
 		if ( !putValidator.acquirePutFromLoadLock( key ) ) {
 			if ( TRACE_ENABLED ) {
 				log.tracef( "Put from load lock not acquired for key %s", key );
 			}
 			return false;
 		}
 
 		try {
 			// Conditional put/putForExternalRead. If the region has been
 			// evicted in the current transaction, do a put instead of a
 			// putForExternalRead to make it stick, otherwise the current
 			// transaction won't see it.
-			if ( region.isRegionInvalidatedInCurrentTx() )
+			if ( region.isRegionInvalidatedInCurrentTx() ) {
 				writeCache.put( key, value );
-			else
+			}
+			else {
 				writeCache.putForExternalRead( key, value );
+			}
 		}
 		finally {
 			putValidator.releasePutFromLoadLock( key );
 		}
 
 		return true;
 	}
 
    /**
     * Called after an item has been inserted (before the transaction completes),
     * instead of calling evict().
     *
     * @param key The item key
     * @param value The item
     * @param version The item's version value
     * @return Were the contents of the cache actual changed by this operation?
     * @throws CacheException if the insert fails
     */
 	@SuppressWarnings("UnusedParameters")
 	public boolean insert(Object key, Object value, Object version) throws CacheException {
 		if ( !region.checkValid() ) {
 			return false;
 		}
 
 		writeCache.put( key, value );
 		return true;
 	}
 
    /**
     * Called after an item has been updated (before the transaction completes),
     * instead of calling evict().
     *
     * @param key The item key
     * @param value The item
     * @param currentVersion The item's current version value
     * @param previousVersion The item's previous version value
     * @return Whether the contents of the cache actual changed by this operation
     * @throws CacheException if the update fails
     */
 	@SuppressWarnings("UnusedParameters")
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion)
 			throws CacheException {
 		// We update whether or not the region is valid. Other nodes
 		// may have already restored the region so they need to
 		// be informed of the change.
 		writeCache.put( key, value );
 		return true;
 	}
 
    /**
     * Called after an item has become stale (before the transaction completes).
     *
     * @param key The key of the item to remove
     * @throws CacheException if removing the cached item fails
     */
 	public void remove(Object key) throws CacheException {
 		if ( !putValidator.invalidateKey( key ) ) {
 			throw new CacheException(
 					"Failed to invalidate pending putFromLoad calls for key " + key + " from region " + region.getName()
 			);
 		}
 		// We update whether or not the region is valid. Other nodes
 		// may have already restored the region so they need to
 		// be informed of the change.
 		writeCache.remove( key );
 	}
 
    /**
     * Called to evict data from the entire region
     *
     * @throws CacheException if eviction the region fails
     */
 	public void removeAll() throws CacheException {
 		if ( !putValidator.invalidateRegion() ) {
 			throw new CacheException( "Failed to invalidate pending putFromLoad calls for region " + region.getName() );
 		}
 		Caches.removeAll(cache);
 	}
 
    /**
     * Forcibly evict an item from the cache immediately without regard for transaction
     * isolation.
     *
     * @param key The key of the item to remove
     * @throws CacheException if evicting the item fails
     */
 	public void evict(Object key) throws CacheException {
 		if ( !putValidator.invalidateKey( key ) ) {
 			throw new CacheException(
 					"Failed to invalidate pending putFromLoad calls for key " + key + " from region " + region.getName()
 			);
 		}
 		writeCache.remove( key );
 	}
 
    /**
     * Forcibly evict all items from the cache immediately without regard for transaction
     * isolation.
     *
     * @throws CacheException if evicting items fails
     */
 	public void evictAll() throws CacheException {
 		if ( !putValidator.invalidateRegion() ) {
 			throw new CacheException( "Failed to invalidate pending putFromLoad calls for region " + region.getName() );
 		}
 
 		// Invalidate the local region and then go remote
 		region.invalidateRegion();
 		Caches.broadcastEvictAll( cache );
 	}
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/logger/Log4DelegatingLogger.java b/hibernate-testing/src/main/java/org/hibernate/testing/logger/Log4DelegatingLogger.java
index 2199360317..efe01d7168 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/logger/Log4DelegatingLogger.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/logger/Log4DelegatingLogger.java
@@ -1,119 +1,138 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.logger;
 
 import org.jboss.logging.Logger;
 
 import java.text.MessageFormat;
 import java.util.LinkedList;
 import java.util.List;
 
 /**
  * A {@code Logger} implementation which delegates to Log4J but makes it possible
  * to test for events being logged (not logged).
  *
  * @author Sanne Grinovero <sanne@hibernate.org> (C) 2015 Red Hat Inc.
  */
 public final class Log4DelegatingLogger extends Logger {
 
 	private final org.apache.log4j.Logger logger;
 
 	// Synchronize access on the field
 	private final List<LogListener> enabledListeners = new LinkedList<LogListener>();
 
 	Log4DelegatingLogger(final String name) {
 		super( name );
 		logger = org.apache.log4j.Logger.getLogger( name );
 	}
 
 	void registerListener(LogListener newListener) {
 		synchronized ( enabledListeners ) {
 			if ( newListener != null ) {
 				enabledListeners.add( newListener );
 			}
 		}
 	}
 
 	void clearAllListeners() {
 		synchronized ( enabledListeners ) {
 			enabledListeners.clear();
 		}
 	}
 
 	public boolean isEnabled(final Level level) {
 		final org.apache.log4j.Level l = translate( level );
 		return logger.isEnabledFor( l ) && l.isGreaterOrEqual( logger.getEffectiveLevel() );
 	}
 
 	protected void doLog(final Level level, final String loggerClassName, final Object message, final Object[] parameters, final Throwable thrown) {
 		final org.apache.log4j.Level translatedLevel = translate( level );
 		intercept( level, parameters == null || parameters.length == 0 ? String.valueOf( message ) : MessageFormat.format( String.valueOf( message ), parameters ), thrown );
-		if ( logger.isEnabledFor( translatedLevel ) )
-			try {
-				logger.log( loggerClassName, translatedLevel,
-						parameters == null || parameters.length == 0 ? String.valueOf( message ) : MessageFormat.format( String.valueOf( message ), parameters ), thrown );
-			}
-			catch (Throwable ignored) {
-			}
+		if ( !logger.isEnabledFor( translatedLevel ) ) {
+			return;
+		}
+		try {
+			logger.log(
+					loggerClassName,
+					translatedLevel,
+					parameters == null || parameters.length == 0
+							? String.valueOf( message )
+							: MessageFormat.format(String.valueOf( message ), parameters ),
+					thrown
+			);
+		}
+		catch (Throwable ignored) {
+		}
 	}
 
 	private void intercept(Level level, String renderedMessage, Throwable thrown) {
 		synchronized ( enabledListeners ) {
 			for ( LogListener listener : enabledListeners ) {
 				listener.loggedEvent( level, renderedMessage, thrown );
 			}
 		}
 	}
 
 	protected void doLogf(final Level level, final String loggerClassName, final String format, final Object[] parameters, final Throwable thrown) {
 		final org.apache.log4j.Level translatedLevel = translate( level );
-		intercept( level, parameters == null ? String.format( format ) : String.format( format, parameters ), thrown );
-		if ( logger.isEnabledFor( translatedLevel ) )
-			try {
-				logger.log( loggerClassName, translatedLevel, parameters == null ? String.format( format ) : String.format( format, parameters ), thrown );
-			}
-			catch (Throwable ignored) {
-			}
+		intercept( level, parameters == null ? format : String.format( format, parameters ), thrown );
+		if ( !logger.isEnabledFor( translatedLevel ) ) {
+			return;
+		}
+		try {
+			logger.log(
+					loggerClassName,
+					translatedLevel,
+					parameters == null ? format : String.format( format, parameters ),
+					thrown
+			);
+		}
+		catch (Throwable ignored) {
+		}
 	}
 
 	private static org.apache.log4j.Level translate(final Level level) {
-		if ( level != null )
-			switch ( level ) {
-				case FATAL:
-					return org.apache.log4j.Level.FATAL;
-				case ERROR:
-					return org.apache.log4j.Level.ERROR;
-				case WARN:
-					return org.apache.log4j.Level.WARN;
-				case INFO:
-					return org.apache.log4j.Level.INFO;
-				case DEBUG:
-					return org.apache.log4j.Level.DEBUG;
-				case TRACE:
-					return org.apache.log4j.Level.TRACE;
-			}
+		if ( level == null ) {
+			return org.apache.log4j.Level.ALL;
+		}
+
+		switch ( level ) {
+			case FATAL:
+				return org.apache.log4j.Level.FATAL;
+			case ERROR:
+				return org.apache.log4j.Level.ERROR;
+			case WARN:
+				return org.apache.log4j.Level.WARN;
+			case INFO:
+				return org.apache.log4j.Level.INFO;
+			case DEBUG:
+				return org.apache.log4j.Level.DEBUG;
+			case TRACE:
+				return org.apache.log4j.Level.TRACE;
+		}
+
 		return org.apache.log4j.Level.ALL;
 	}
 
 }
diff --git a/shared/config/checkstyle/checkstyle.xml b/shared/config/checkstyle/checkstyle.xml
index 7191c470ef..b8e9f6501b 100644
--- a/shared/config/checkstyle/checkstyle.xml
+++ b/shared/config/checkstyle/checkstyle.xml
@@ -1,236 +1,239 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2013, Red Hat Inc. or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Inc.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 <!DOCTYPE module PUBLIC "-//Puppy Crawl//DTD Check Configuration 1.1//EN" "http://www.puppycrawl.com/dtds/configuration_1_2.dtd">
 <module name="Checker">
 
     <module name="TreeWalker">
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             General regex checks as part of the TreeWalker
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="RegexpSinglelineJava">
             <property name="ignoreComments" value="true" />
             <property name="format" value="^\t* +\t*\S" />
             <property name="message" value="Line has leading space characters; indentation should be performed with tabs only." />
         </module>
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Annotation checks
 
             See http://checkstyle.sourceforge.net/config_annotation.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="MissingDeprecated" />
         <module name="MissingOverride" />
         <module name="PackageAnnotation" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Block checks
 
             See http://checkstyle.sourceforge.net/config_blocks.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="AvoidNestedBlocks">
             <property name="allowInSwitchCase" value="true" />
             <property name="severity" value="warning" />
         </module>
         <module name="NeedBraces" />
         <module name="LeftCurly">
             <property name="option" value="eol" />
         </module>
         <module name="RightCurly">
             <property name="option" value="alone" />
         </module>
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Design checks
 
             See http://checkstyle.sourceforge.net/config_design.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="HideUtilityClassConstructor">
             <!-- Some classes in o.h.metamodel on master do this -->
             <property name="severity" value="warning" />
         </module>
         <module name="MutableException" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Coding checks
 
             See http://checkstyle.sourceforge.net/config_coding.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="EmptyStatement">
             <property name="severity" value="warning" />
         </module>
         <module name="EqualsHashCode" />
+<!--
         <module name="FinalLocalVariable">
             <property name="severity" value="warning" />
         </module>
+-->
         <module name="MissingSwitchDefault">
             <property name="severity" value="warning" />
         </module>
         <module name="DefaultComesLast" />
         <module name="ModifiedControlVariable">
             <property name="severity" value="warning" />
         </module>
         <module name="SimplifyBooleanExpression" />
         <module name="SimplifyBooleanReturn" />
         <module name="StringLiteralEquality" />
         <module name="NoFinalizer" />
         <module name="ExplicitInitialization">
             <property name="severity" value="warning" />
         </module>
         <module name="FallThrough" />
         <module name="OneStatementPerLine" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Import checks
 
             See http://checkstyle.sourceforge.net/config_imports.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="AvoidStarImport" />
         <module name="RedundantImport" />
         <module name="UnusedImports" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Misc checks
 
             See http://checkstyle.sourceforge.net/config_misc.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="UpperEll" />
         <module name="ArrayTypeStyle">
             <!-- Some classes in o.h.metamodel on master do this -->
             <property name="severity" value="warning" />
         </module>
         <module name="TrailingComment">
             <property name="severity" value="warning" />
         </module>
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Modifier checks
 
             See http://checkstyle.sourceforge.net/config_modifier.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="ModifierOrder"/>
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Naming checks
 
             See http://checkstyle.sourceforge.net/config_naming.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="AbstractClassName">
             <!-- we are just using this to make sure that classes matching the pattern (Abstract*) have the abstract modifier -->
             <property name="format" value="^Abstract.*$" />
             <property name="ignoreName" value="true" />
         </module>
         <module name="ClassTypeParameterName">
             <property name="format" value="^[A-Z][A-Z0-9]*$" />
         </module>
         <module name="ConstantName">
             <property name="format" value="^[A-Z](_?[A-Z0-9]+)*$|log" />
             <!-- Some classes in o.h.metamodel on master violate this -->
             <property name="severity" value="warning" />
         </module>
         <module name="LocalFinalVariableName" />
         <module name="LocalVariableName">
             <!-- Some classes in o.h.metamodel on master violate this -->
             <property name="severity" value="warning" />
         </module>
         <module name="MemberName" />
         <!--
         The org.hibernate.engine.spi.ManagedEntity method names (prefixed with '&&_') muck with this
         <module name="MethodName" />
         -->
         <module name="MethodTypeParameterName">
             <property name="format" value="^[A-Z][A-Z0-9]*$" />
         </module>
         <module name="PackageName" />
         <module name="ParameterName" />
         <module name="StaticVariableName" />
         <module name="TypeName" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Whitespace checks
 
             See http://checkstyle.sourceforge.net/config_whitespace.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="MethodParamPad" />
         <module name="TypecastParenPad" />
         <module name="ParenPad">
             <property name="tokens" value="CTOR_CALL, METHOD_CALL, SUPER_CTOR_CALL" />
             <property name="option" value="space" />
         </module>
 
     </module>
 
 
     <!--
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         Javadoc checks
 
         See http://checkstyle.sourceforge.net/config_javadoc.html
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     -->
+<!--
     <module name="JavadocPackage">
         <property name="allowLegacy" value="true" />
     </module>
-
+-->
 
     <!--
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         Misc checks
 
         See http://checkstyle.sourceforge.net/config_misc.html
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     -->
     <module name="NewlineAtEndOfFile" />
 
 </module>
diff --git a/tooling/hibernate-enhance-maven-plugin/src/main/java/org/hibernate/bytecode/enhance/plugins/MavenEnhancePlugin.java b/tooling/hibernate-enhance-maven-plugin/src/main/java/org/hibernate/bytecode/enhance/plugins/MavenEnhancePlugin.java
index dc8317305a..05e5d2bb6a 100644
--- a/tooling/hibernate-enhance-maven-plugin/src/main/java/org/hibernate/bytecode/enhance/plugins/MavenEnhancePlugin.java
+++ b/tooling/hibernate-enhance-maven-plugin/src/main/java/org/hibernate/bytecode/enhance/plugins/MavenEnhancePlugin.java
@@ -1,273 +1,274 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.bytecode.enhance.plugins;
 
 import javassist.ClassPool;
 import javassist.CtClass;
 import javassist.CtField;
+
 import org.apache.maven.plugin.AbstractMojo;
 import org.apache.maven.plugin.MojoExecutionException;
 import org.apache.maven.plugin.MojoFailureException;
 import org.apache.maven.plugins.annotations.Execute;
 import org.apache.maven.plugins.annotations.LifecyclePhase;
 import org.apache.maven.plugins.annotations.Mojo;
 import org.apache.maven.plugins.annotations.Parameter;
+
 import org.hibernate.bytecode.enhance.spi.EnhancementContext;
 import org.hibernate.bytecode.enhance.spi.Enhancer;
 
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.Entity;
 import javax.persistence.ManyToMany;
 import javax.persistence.OneToMany;
 import javax.persistence.Transient;
 import java.io.File;
 import java.io.FileFilter;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.List;
 
 /**
  * This plugin will enhance Entity objects.
- * 
+ *
  * @author Jeremy Whiting
  * @phase "compile"
  */
-@Mojo ( name="enhance", defaultPhase = LifecyclePhase.COMPILE )
-@Execute ( goal ="enhance" , phase = LifecyclePhase.COMPILE )
+@Mojo(name = "enhance", defaultPhase = LifecyclePhase.COMPILE)
+@Execute(goal = "enhance", phase = LifecyclePhase.COMPILE)
 public class MavenEnhancePlugin extends AbstractMojo implements EnhancementContext {
 
 	/**
 	 * The contexts to use during enhancement.
 	 */
 	private List<File> classes = new ArrayList<File>();
 	private ClassPool pool = new ClassPool( false );
-    private final Enhancer enhancer = new Enhancer( this);
+	private final Enhancer enhancer = new Enhancer( this );
 
 	private static final String CLASS_EXTENSION = ".class";
 
-	@Parameter(property="dir", defaultValue="${project.build.outputDirectory}")
+	@Parameter(property = "dir", defaultValue = "${project.build.outputDirectory}")
 	private String dir = null;
 
 	public void execute() throws MojoExecutionException, MojoFailureException {
 		getLog().info( "Started enhance plugin....." );
 		/** Perform a depth first search for files. */
-		File root = new File( this.dir ); 
+		File root = new File( this.dir );
 		walkDir( root );
 
 		if ( 0 < classes.size() ) {
 			for ( File file : classes ) {
-				processClassFile(file);
+				processClassFile( file );
 			}
 		}
 
 		getLog().info( "Enhance plugin completed." );
 	}
 
 	/**
 	 * Expects a directory.
 	 */
 	private void walkDir(File dir) {
+		walkDir(
+				dir,
+				new FileFilter() {
+					@Override
+					public boolean accept(File pathname) {
+						return ( pathname.isFile() && pathname.getName().endsWith( CLASS_EXTENSION ) );
+					}
+				},
+				new FileFilter() {
+					@Override
+					public boolean accept(File pathname) {
+						return ( pathname.isDirectory() );
+					}
+				}
+		);
+	}
 
-		walkDir( dir, new FileFilter() {
+	private void walkDir(File dir, FileFilter classesFilter, FileFilter dirFilter) {
+		File[] dirs = dir.listFiles( dirFilter );
+		for ( File dir1 : dirs ) {
+			walkDir( dir1, classesFilter, dirFilter );
+		}
+		File[] files = dir.listFiles( classesFilter );
+		Collections.addAll( this.classes, files );
+	}
 
-			@Override
-			public boolean accept(File pathname) {
-				return ( pathname.isFile() && pathname.getName().endsWith( CLASS_EXTENSION ) );
-			}
-		}, new FileFilter() {
 
-			@Override
-			public boolean accept(File pathname) {
-				return ( pathname.isDirectory() );
+	/**
+	 * Atm only process files annotated with either @Entity or @Embeddable
+	 */
+	private void processClassFile(File javaClassFile) throws MojoExecutionException {
+		try {
+			final CtClass ctClass = getClassPool().makeClass( new FileInputStream( javaClassFile ) );
+			if ( this.isEntityClass( ctClass ) ) {
+				processEntityClassFile( javaClassFile, ctClass );
+			}
+			else if ( this.isCompositeClass( ctClass ) ) {
+				processCompositeClassFile( javaClassFile, ctClass );
 			}
-		} );
-	}
 
-	private void walkDir(File dir, FileFilter classesFilter, FileFilter dirFilter) {
+		}
+		catch (IOException e) {
+			throw new MojoExecutionException(
+					String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e
+			);
+		}
+	}
 
-		File[] dirs = dir.listFiles( dirFilter );
-		for ( int i = 0; i < dirs.length; i++ ) {
-			walkDir( dirs[i], classesFilter, dirFilter );
+	private void processEntityClassFile(File javaClassFile, CtClass ctClass) {
+		try {
+			getLog().info( String.format( "Processing Entity class file [%1$s].", ctClass.getName() ) );
+			byte[] result = enhancer.enhance( ctClass.getName(), ctClass.toBytecode() );
+			if ( result != null ) {
+				writeEnhancedClass( javaClassFile, result );
+			}
 		}
-		dirs = null;
-		File[] files = dir.listFiles( classesFilter );
-		for ( int i = 0; i < files.length; i++ ) {
-			this.classes.add( files[i] );
+		catch (Exception e) {
+			getLog().error( "Unable to enhance class [" + ctClass.getName() + "]", e );
 		}
 	}
 
+	private void processCompositeClassFile(File javaClassFile, CtClass ctClass) {
+		try {
+			getLog().info( String.format( "Processing Composite class file [%1$s].", ctClass.getName() ) );
+			byte[] result = enhancer.enhanceComposite( ctClass.getName(), ctClass.toBytecode() );
+			if ( result != null ) {
+				writeEnhancedClass( javaClassFile, result );
+			}
+		}
+		catch (Exception e) {
+			getLog().error( "Unable to enhance class [" + ctClass.getName() + "]", e );
+		}
+	}
 
-    /**
-     * Atm only process files annotated with either @Entity or @Embeddable
-     * @param javaClassFile
-     */
-    private void processClassFile(File javaClassFile)
-            throws MojoExecutionException {
+	private void writeEnhancedClass(File javaClassFile, byte[] result) throws MojoExecutionException {
 		try {
-			final CtClass ctClass = getClassPool().makeClass( new FileInputStream( javaClassFile ) );
-            if(this.isEntityClass(ctClass))
-                processEntityClassFile(javaClassFile, ctClass);
-            else if(this.isCompositeClass(ctClass))
-                processCompositeClassFile(javaClassFile, ctClass);
-
-        }
-        catch (IOException e) {
-            throw new MojoExecutionException(
-                    String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e );
-        }
-    }
-
-    private void processEntityClassFile(File javaClassFile, CtClass ctClass ) {
-        try {
-            getLog().info( String.format("Processing Entity class file [%1$s].", ctClass.getName()) );
-            byte[] result = enhancer.enhance( ctClass.getName(), ctClass.toBytecode() );
-            if(result != null)
-                writeEnhancedClass(javaClassFile, result);
-        }
-        catch (Exception e) {
-            getLog().error( "Unable to enhance class [" + ctClass.getName() + "]", e);
-            return;
-        }
-    }
-
-    private void processCompositeClassFile(File javaClassFile, CtClass ctClass) {
-        try {
-            getLog().info( String.format("Processing Composite class file [%1$s].", ctClass.getName()) );
-            byte[] result = enhancer.enhanceComposite(ctClass.getName(), ctClass.toBytecode());
-            if(result != null)
-                writeEnhancedClass(javaClassFile, result);
-        }
-        catch (Exception e) {
-            getLog().error( "Unable to enhance class [" + ctClass.getName() + "]", e);
-            return;
-        }
-    }
-
-    private void writeEnhancedClass(File javaClassFile, byte[] result)
-            throws MojoExecutionException {
-        try {
 			if ( javaClassFile.delete() ) {
-                    if ( ! javaClassFile.createNewFile() ) {
-                        getLog().error( "Unable to recreate class file [" + javaClassFile.getName() + "]");
-                    }
-            }
+				if ( !javaClassFile.createNewFile() ) {
+					getLog().error( "Unable to recreate class file [" + javaClassFile.getName() + "]" );
+				}
+			}
 			else {
-				getLog().error( "Unable to delete class file [" + javaClassFile.getName() + "]");
+				getLog().error( "Unable to delete class file [" + javaClassFile.getName() + "]" );
 			}
 
 			FileOutputStream outputStream = new FileOutputStream( javaClassFile, false );
 			try {
-				outputStream.write( result);
+				outputStream.write( result );
 				outputStream.flush();
 			}
 			finally {
 				try {
 					outputStream.close();
 				}
-				catch ( IOException ignore) {
+				catch (IOException ignore) {
 				}
 			}
-        }
-        catch (FileNotFoundException ignore) {
-            // should not ever happen because of explicit checks
-        }
-        catch (IOException e) {
-            throw new MojoExecutionException(
-                    String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e );
-        }
-    }
+		}
+		catch (FileNotFoundException ignore) {
+			// should not ever happen because of explicit checks
+		}
+		catch (IOException e) {
+			throw new MojoExecutionException(
+					String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e
+			);
+		}
+	}
 
 	private ClassPool getClassPool() {
 		return this.pool;
 	}
 
-    private boolean shouldInclude(CtClass ctClass) {
+	private boolean shouldInclude(CtClass ctClass) {
 		// we currently only handle entity enhancement
 		return ctClass.hasAnnotation( Entity.class );
 	}
 
 	@Override
 	public ClassLoader getLoadingClassLoader() {
 		return getClass().getClassLoader();
 	}
 
 	@Override
 	public boolean isEntityClass(CtClass classDescriptor) {
-        return classDescriptor.hasAnnotation(Entity.class);
-    }
+		return classDescriptor.hasAnnotation( Entity.class );
+	}
 
 	@Override
 	public boolean isCompositeClass(CtClass classDescriptor) {
-        return classDescriptor.hasAnnotation(Embeddable.class);
+		return classDescriptor.hasAnnotation( Embeddable.class );
 	}
 
 	@Override
 	public boolean doBiDirectionalAssociationManagement(CtField field) {
 		return false;
 	}
 
 	@Override
 	public boolean doDirtyCheckingInline(CtClass classDescriptor) {
 		return true;
 	}
 
 	@Override
 	public boolean hasLazyLoadableAttributes(CtClass classDescriptor) {
 		return true;
 	}
 
 	@Override
 	public boolean isLazyLoadable(CtField field) {
 		return true;
 	}
 
 	@Override
 	public boolean isPersistentField(CtField ctField) {
 		// current check is to look for @Transient
-		return ! ctField.hasAnnotation( Transient.class );
+		return !ctField.hasAnnotation( Transient.class );
 	}
 
-    @Override
-    public boolean isMappedCollection(CtField field) {
-        try {
-            return (field.getAnnotation(OneToMany.class) != null ||
-                    field.getAnnotation(ManyToMany.class) != null ||
-                    field.getAnnotation(ElementCollection.class) != null);
-        }
-        catch (ClassNotFoundException e) {
-            return false;
-        }
-    }
+	@Override
+	public boolean isMappedCollection(CtField field) {
+		try {
+			return ( field.getAnnotation( OneToMany.class ) != null ||
+					field.getAnnotation( ManyToMany.class ) != null ||
+					field.getAnnotation( ElementCollection.class ) != null );
+		}
+		catch (ClassNotFoundException e) {
+			return false;
+		}
+	}
 
 	@Override
 	public CtField[] order(CtField[] persistentFields) {
 		// for now...
 		return persistentFields;
 		// eventually needs to consult the Hibernate metamodel for proper ordering
 	}
 }
