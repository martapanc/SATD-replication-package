diff --git a/documentation/src/main/docbook/manual/en-US/content/configuration.xml b/documentation/src/main/docbook/manual/en-US/content/configuration.xml
index 533661690d..da4d58fa4d 100644
--- a/documentation/src/main/docbook/manual/en-US/content/configuration.xml
+++ b/documentation/src/main/docbook/manual/en-US/content/configuration.xml
@@ -777,1026 +777,1026 @@ hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect</programlisting>
             <entry>Purpose</entry>
           </row>
         </thead>
 
         <tbody>
           <row>
             <entry><literal>hibernate.transaction.factory_class</literal></entry>
 
             <entry>The classname of a <literal>TransactionFactory</literal> to
             use with Hibernate <literal>Transaction</literal> API (defaults to
             <literal>JDBCTransactionFactory</literal>). <para> <emphasis
             role="strong">e.g.</emphasis>
             <literal>classname.of.TransactionFactory</literal> </para></entry>
           </row>
 
           <row>
             <entry><literal>jta.UserTransaction</literal></entry>
 
             <entry>A JNDI name used by
             <literal>JTATransactionFactory</literal> to obtain the JTA
             <literal>UserTransaction</literal> from the application server.
             <para> <emphasis role="strong">e.g.</emphasis>
             <literal>jndi/composite/name</literal> </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.transaction.manager_lookup_class</literal></entry>
 
             <entry>The classname of a
             <literal>TransactionManagerLookup</literal>. It is required when
             JVM-level caching is enabled or when using hilo generator in a JTA
             environment. <para> <emphasis role="strong">e.g.</emphasis>
             <literal>classname.of.TransactionManagerLookup</literal>
             </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.transaction.flush_before_completion</literal></entry>
 
             <entry>If enabled, the session will be automatically flushed
             during the before completion phase of the transaction. Built-in
             and automatic session context management is preferred, see <xref
             linkend="architecture-current-session" />. <para> <emphasis
             role="strong">e.g.</emphasis> <literal>true</literal> |
             <literal>false</literal> </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.transaction.auto_close_session</literal></entry>
 
             <entry>If enabled, the session will be automatically closed during
             the after completion phase of the transaction. Built-in and
             automatic session context management is preferred, see <xref
             linkend="architecture-current-session" />. <para> <emphasis
             role="strong">e.g.</emphasis> <literal>true</literal> |
             <literal>false</literal> </para></entry>
           </row>
         </tbody>
       </tgroup>
     </table>
 
     <table frame="topbot" id="configuration-misc-properties" revision="11">
       <title>Miscellaneous Properties</title>
 
       <tgroup cols="2">
         <colspec colname="c1" colwidth="1*" />
 
         <colspec colname="c2" colwidth="1*" />
 
         <thead>
           <row>
             <entry>Property name</entry>
 
             <entry>Purpose</entry>
           </row>
         </thead>
 
         <tbody>
           <row>
             <entry><literal>hibernate.current_session_context_class</literal></entry>
 
             <entry>Supply a custom strategy for the scoping of the "current"
             <literal>Session</literal>. See <xref
             linkend="architecture-current-session" /> for more information
             about the built-in strategies. <para> <emphasis
             role="strong">e.g.</emphasis> <literal>jta</literal> |
             <literal>thread</literal> | <literal>managed</literal> |
             <literal>custom.Class</literal> </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.query.factory_class</literal></entry>
 
             <entry>Chooses the HQL parser implementation. <para> <emphasis
             role="strong">e.g.</emphasis>
             <literal>org.hibernate.hql.ast.ASTQueryTranslatorFactory</literal>
             or
             <literal>org.hibernate.hql.classic.ClassicQueryTranslatorFactory</literal>
             </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.query.substitutions</literal></entry>
 
             <entry>Is used to map from tokens in Hibernate queries to SQL
             tokens (tokens might be function or literal names, for example).
             <para> <emphasis role="strong">e.g.</emphasis>
             <literal>hqlLiteral=SQL_LITERAL, hqlFunction=SQLFUNC</literal>
             </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.hbm2ddl.auto</literal></entry>
 
             <entry>Automatically validates or exports schema DDL to the
             database when the <literal>SessionFactory</literal> is created.
             With <literal>create-drop</literal>, the database schema will be
             dropped when the <literal>SessionFactory</literal> is closed
             explicitly. <para> <emphasis role="strong">e.g.</emphasis>
             <literal>validate</literal> | <literal>update</literal> |
             <literal>create</literal> | <literal>create-drop</literal>
             </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.hbm2ddl.import_file</literal></entry>
 
             <entry><para>Comma-separated names of the optional files
             containing SQL DML statements executed during the
             <classname>SessionFactory</classname> creation. This is useful for
             testing or demoing: by adding INSERT statements for example you
             can populate your database with a minimal set of data when it is
             deployed.</para><para>File order matters, the statements of a give
             file are executed before the statements of the following files.
             These statements are only executed if the schema is created ie if
             <literal>hibernate.hbm2ddl.auto</literal> is set to
             <literal>create</literal> or
             <literal>create-drop</literal>.</para><para> <emphasis
             role="strong">e.g.</emphasis>
             <literal>/humans.sql,/dogs.sql</literal> </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.bytecode.use_reflection_optimizer</literal></entry>
 
             <entry><para>Enables the use of bytecode manipulation instead of
             runtime reflection. This is a System-level property and cannot be
             set in <literal>hibernate.cfg.xml</literal>. Reflection can
             sometimes be useful when troubleshooting. Hibernate always
             requires either CGLIB or javassist even if you turn off the
             optimizer.</para><para> <emphasis role="strong">e.g.</emphasis>
             <literal>true</literal> | <literal>false</literal> </para></entry>
           </row>
 
           <row>
             <entry><literal>hibernate.bytecode.provider</literal></entry>
 
             <entry><para>Both javassist or cglib can be used as byte
             manipulation engines; the default is
             <literal>javassist</literal>.</para><para> <emphasis
             role="strong">e.g.</emphasis> <literal>javassist</literal> |
             <literal>cglib</literal> </para></entry>
           </row>
         </tbody>
       </tgroup>
     </table>
 
     <section id="configuration-optional-dialects" revision="1">
       <title>SQL Dialects</title>
 
       <para>Always set the <literal>hibernate.dialect</literal> property to
       the correct <literal>org.hibernate.dialect.Dialect</literal> subclass
       for your database. If you specify a dialect, Hibernate will use sensible
       defaults for some of the other properties listed above. This means that
       you will not have to specify them manually.</para>
 
       <table frame="topbot" id="sql-dialects" revision="3">
         <title>Hibernate SQL Dialects
         (<literal>hibernate.dialect</literal>)</title>
 
         <tgroup cols="2">
           <!--
                     <colspec colwidth="1*"/>
                     <colspec colwidth="2.5*"/>
 -->
 
           <thead>
             <row>
               <entry>RDBMS</entry>
 
               <entry>Dialect</entry>
             </row>
           </thead>
 
           <tbody>
             <row>
               <entry>DB2</entry>
 
               <entry><literal>org.hibernate.dialect.DB2Dialect</literal></entry>
             </row>
 
             <row>
               <entry>DB2 AS/400</entry>
 
               <entry><literal>org.hibernate.dialect.DB2400Dialect</literal></entry>
             </row>
 
             <row>
               <entry>DB2 OS390</entry>
 
               <entry><literal>org.hibernate.dialect.DB2390Dialect</literal></entry>
             </row>
 
             <row>
               <entry>PostgreSQL</entry>
 
               <entry><literal>org.hibernate.dialect.PostgreSQLDialect</literal></entry>
             </row>
 
             <row>
               <entry>MySQL5</entry>
 
               <entry><literal>org.hibernate.dialect.MySQL5Dialect</literal></entry>
             </row>
 
             <row>
               <entry>MySQL5 with InnoDB</entry>
 
               <entry><literal>org.hibernate.dialect.MySQL5InnoDBDialect</literal></entry>
             </row>
 
             <row>
               <entry>MySQL with MyISAM</entry>
 
               <entry><literal>org.hibernate.dialect.MySQLMyISAMDialect</literal></entry>
             </row>
 
             <row>
               <entry>Oracle (any version)</entry>
 
               <entry><literal>org.hibernate.dialect.OracleDialect</literal></entry>
             </row>
 
             <row>
               <entry>Oracle 9i</entry>
 
               <entry><literal>org.hibernate.dialect.Oracle9iDialect</literal></entry>
             </row>
 
             <row>
               <entry>Oracle 10g</entry>
 
               <entry><literal>org.hibernate.dialect.Oracle10gDialect</literal></entry>
             </row>
 
             <row>
               <entry>Oracle 11g</entry>
 
               <entry><literal>org.hibernate.dialect.Oracle10gDialect</literal></entry>
             </row>
 
             <row>
               <entry>Sybase</entry>
 
               <entry><literal>org.hibernate.dialect.SybaseASE15Dialect</literal></entry>
             </row>
 
             <row>
               <entry>Sybase Anywhere</entry>
 
               <entry><literal>org.hibernate.dialect.SybaseAnywhereDialect</literal></entry>
             </row>
 
             <row>
               <entry>Microsoft SQL Server 2000</entry>
 
               <entry><literal>org.hibernate.dialect.SQLServerDialect</literal></entry>
             </row>
 
             <row>
               <entry>Microsoft SQL Server 2005</entry>
 
               <entry><literal>org.hibernate.dialect.SQLServer2005Dialect</literal></entry>
             </row>
 
             <row>
               <entry>Microsoft SQL Server 2008</entry>
 
               <entry><literal>org.hibernate.dialect.SQLServer2008Dialect</literal></entry>
             </row>
 
             <row>
               <entry>SAP DB</entry>
 
               <entry><literal>org.hibernate.dialect.SAPDBDialect</literal></entry>
             </row>
 
             <row>
               <entry>Informix</entry>
 
               <entry><literal>org.hibernate.dialect.InformixDialect</literal></entry>
             </row>
 
             <row>
               <entry>HypersonicSQL</entry>
 
               <entry><literal>org.hibernate.dialect.HSQLDialect</literal></entry>
             </row>
 
             <row>
               <entry>H2 Database</entry>
 
               <entry><literal>org.hibernate.dialect.H2Dialect</literal></entry>
             </row>
 
             <row>
               <entry>Ingres</entry>
 
               <entry><literal>org.hibernate.dialect.IngresDialect</literal></entry>
             </row>
 
             <row>
               <entry>Progress</entry>
 
               <entry><literal>org.hibernate.dialect.ProgressDialect</literal></entry>
             </row>
 
             <row>
               <entry>Mckoi SQL</entry>
 
               <entry><literal>org.hibernate.dialect.MckoiDialect</literal></entry>
             </row>
 
             <row>
               <entry>Interbase</entry>
 
               <entry><literal>org.hibernate.dialect.InterbaseDialect</literal></entry>
             </row>
 
             <row>
               <entry>Pointbase</entry>
 
               <entry><literal>org.hibernate.dialect.PointbaseDialect</literal></entry>
             </row>
 
             <row>
               <entry>FrontBase</entry>
 
               <entry><literal>org.hibernate.dialect.FrontbaseDialect</literal></entry>
             </row>
 
             <row>
               <entry>Firebird</entry>
 
               <entry><literal>org.hibernate.dialect.FirebirdDialect</literal></entry>
             </row>
           </tbody>
         </tgroup>
       </table>
     </section>
 
     <section id="configuration-optional-outerjoin" revision="4">
       <title>Outer Join Fetching</title>
 
       <para>If your database supports ANSI, Oracle or Sybase style outer
       joins, <emphasis>outer join fetching</emphasis> will often increase
       performance by limiting the number of round trips to and from the
       database. This is, however, at the cost of possibly more work performed
       by the database itself. Outer join fetching allows a whole graph of
       objects connected by many-to-one, one-to-many, many-to-many and
       one-to-one associations to be retrieved in a single SQL
       <literal>SELECT</literal>.</para>
 
       <para>Outer join fetching can be disabled <emphasis>globally</emphasis>
       by setting the property <literal>hibernate.max_fetch_depth</literal> to
       <literal>0</literal>. A setting of <literal>1</literal> or higher
       enables outer join fetching for one-to-one and many-to-one associations
       that have been mapped with <literal>fetch="join"</literal>.</para>
 
       <para>See <xref linkend="performance-fetching" /> for more
       information.</para>
     </section>
 
     <section id="configuration-optional-binarystreams" revision="1">
       <title>Binary Streams</title>
 
       <para>Oracle limits the size of <literal>byte</literal> arrays that can
       be passed to and/or from its JDBC driver. If you wish to use large
       instances of <literal>binary</literal> or
       <literal>serializable</literal> type, you should enable
       <literal>hibernate.jdbc.use_streams_for_binary</literal>. <emphasis>This
       is a system-level setting only.</emphasis></para>
     </section>
 
     <section id="configuration-optional-cacheprovider" revision="2">
       <title>Second-level and query cache</title>
 
       <para>The properties prefixed by <literal>hibernate.cache</literal>
       allow you to use a process or cluster scoped second-level cache system
       with Hibernate. See the <xref linkend="performance-cache" /> for more
       information.</para>
     </section>
 
     <section id="configuration-optional-querysubstitution">
       <title>Query Language Substitution</title>
 
       <para>You can define new Hibernate query tokens using
       <literal>hibernate.query.substitutions</literal>. For example:</para>
 
       <programlisting>hibernate.query.substitutions true=1, false=0</programlisting>
 
       <para>This would cause the tokens <literal>true</literal> and
       <literal>false</literal> to be translated to integer literals in the
       generated SQL.</para>
 
       <programlisting>hibernate.query.substitutions toLowercase=LOWER</programlisting>
 
       <para>This would allow you to rename the SQL <literal>LOWER</literal>
       function.</para>
     </section>
 
     <section id="configuration-optional-statistics" revision="2">
       <title>Hibernate statistics</title>
 
       <para>If you enable <literal>hibernate.generate_statistics</literal>,
       Hibernate exposes a number of metrics that are useful when tuning a
       running system via <literal>SessionFactory.getStatistics()</literal>.
       Hibernate can even be configured to expose these statistics via JMX.
       Read the Javadoc of the interfaces in
       <literal>org.hibernate.stats</literal> for more information.</para>
     </section>
   </section>
 
   <section id="configuration-logging">
     <title>Logging</title>
 
     <para>Hibernate utilizes <ulink url="http://www.slf4j.org/">Simple Logging
     Facade for Java</ulink> (SLF4J) in order to log various system events.
     SLF4J can direct your logging output to several logging frameworks (NOP,
     Simple, log4j version 1.2, JDK 1.4 logging, JCL or logback) depending on
     your chosen binding. In order to setup logging you will need
     <filename>slf4j-api.jar</filename> in your classpath together with the jar
     file for your preferred binding - <filename>slf4j-log4j12.jar</filename>
     in the case of Log4J. See the SLF4J <ulink
     url="http://www.slf4j.org/manual.html">documentation</ulink> for more
     detail. To use Log4j you will also need to place a
     <filename>log4j.properties</filename> file in your classpath. An example
     properties file is distributed with Hibernate in the
     <literal>src/</literal> directory.</para>
 
     <para>It is recommended that you familiarize yourself with Hibernate's log
     messages. A lot of work has been put into making the Hibernate log as
     detailed as possible, without making it unreadable. It is an essential
     troubleshooting device. The most interesting log categories are the
     following:</para>
 
     <table frame="topbot" id="log-categories" revision="2">
       <title>Hibernate Log Categories</title>
 
       <tgroup cols="2">
         <colspec colwidth="1*" />
 
         <colspec colwidth="2.5*" />
 
         <thead>
           <row>
             <entry>Category</entry>
 
             <entry>Function</entry>
           </row>
         </thead>
 
         <tbody>
           <row>
             <entry><literal>org.hibernate.SQL</literal></entry>
 
             <entry>Log all SQL DML statements as they are executed</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate.type</literal></entry>
 
             <entry>Log all JDBC parameters</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate.tool.hbm2ddl</literal></entry>
 
             <entry>Log all SQL DDL statements as they are executed</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate.pretty</literal></entry>
 
             <entry>Log the state of all entities (max 20 entities) associated
             with the session at flush time</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate.cache</literal></entry>
 
             <entry>Log all second-level cache activity</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate.transaction</literal></entry>
 
             <entry>Log transaction related activity</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate.jdbc</literal></entry>
 
             <entry>Log all JDBC resource acquisition</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate.hql.ast.AST</literal></entry>
 
             <entry>Log HQL and SQL ASTs during query parsing</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate.secure</literal></entry>
 
             <entry>Log all JAAS authorization requests</entry>
           </row>
 
           <row>
             <entry><literal>org.hibernate</literal></entry>
 
             <entry>Log everything. This is a lot of information but it is
             useful for troubleshooting</entry>
           </row>
         </tbody>
       </tgroup>
     </table>
 
     <para>When developing applications with Hibernate, you should almost
     always work with <literal>debug</literal> enabled for the category
     <literal>org.hibernate.SQL</literal>, or, alternatively, the property
     <literal>hibernate.show_sql</literal> enabled.</para>
   </section>
 
   <section id="configuration-namingstrategy">
     <title>Implementing a <literal>NamingStrategy</literal></title>
 
     <para>The interface <literal>org.hibernate.cfg.NamingStrategy</literal>
     allows you to specify a "naming standard" for database objects and schema
     elements.</para>
 
     <para>You can provide rules for automatically generating database
     identifiers from Java identifiers or for processing "logical" column and
     table names given in the mapping file into "physical" table and column
     names. This feature helps reduce the verbosity of the mapping document,
     eliminating repetitive noise (<literal>TBL_</literal> prefixes, for
     example). The default strategy used by Hibernate is quite minimal.</para>
 
     <para>You can specify a different strategy by calling
     <literal>Configuration.setNamingStrategy()</literal> before adding
     mappings:</para>
 
     <programlisting role="JAVA">SessionFactory sf = new Configuration()
     .setNamingStrategy(ImprovedNamingStrategy.INSTANCE)
     .addFile("Item.hbm.xml")
     .addFile("Bid.hbm.xml")
     .buildSessionFactory();</programlisting>
 
     <para><literal>org.hibernate.cfg.ImprovedNamingStrategy</literal> is a
     built-in strategy that might be a useful starting point for some
     applications.</para>
   </section>
 
   <section>
     <title>Implementing a PersisterClassProvider</title>
 
     <para>You can configure the persister implementation used to persist your
     entities and collections:</para>
 
     <itemizedlist>
       <listitem>
         <para>by default, Hibernate uses persisters that make sense in a
         relational model and follow Java Persistence's specification</para>
       </listitem>
 
       <listitem>
         <para>you can define a <classname>PersisterClassProvider</classname>
         implementation that provides the persister class used of a given
         entity or collection</para>
       </listitem>
 
       <listitem>
         <para>finally, you can override them on a per entity and collection
         basis in the mapping using <classname>@Persister</classname> or its
         XML equivalent</para>
       </listitem>
     </itemizedlist>
 
     <para>The latter in the list the higher in priority.</para>
 
     <para>You can pass the <classname>PersisterClassProvider</classname>
     instance to the <classname>Configuration</classname> object.</para>
 
     <programlisting role="JAVA">SessionFactory sf = new Configuration()
     .setPersisterClassProvider(customPersisterClassProvider)
     .addAnnotatedClass(Order.class)
     .buildSessionFactory();</programlisting>
 
     <para>The persister class provider methods, when returning a non null
     persister class, override the default Hibernate persisters. The entity
     name or the collection role are passed to the methods. It is a nice way to
     centralize the overriding logic of the persisters instead of spreading
     them on each entity or collection mapping. </para>
   </section>
 
   <section id="configuration-xmlconfig" revision="2">
     <title>XML configuration file</title>
 
     <para>An alternative approach to configuration is to specify a full
     configuration in a file named <literal>hibernate.cfg.xml</literal>. This
     file can be used as a replacement for the
     <literal>hibernate.properties</literal> file or, if both are present, to
     override properties.</para>
 
     <para>The XML configuration file is by default expected to be in the root
     of your <literal>CLASSPATH</literal>. Here is an example:</para>
 
     <programlisting role="XML">&lt;?xml version='1.0' encoding='utf-8'?&gt;
 &lt;!DOCTYPE hibernate-configuration PUBLIC
     "-//Hibernate/Hibernate Configuration DTD//EN"
     "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;
 
 &lt;hibernate-configuration&gt;
 
     &lt;!-- a SessionFactory instance listed as /jndi/name --&gt;
     &lt;session-factory
         name="java:hibernate/SessionFactory"&gt;
 
         &lt;!-- properties --&gt;
         &lt;property name="connection.datasource"&gt;java:/comp/env/jdbc/MyDB&lt;/property&gt;
         &lt;property name="dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt;
         &lt;property name="show_sql"&gt;false&lt;/property&gt;
         &lt;property name="transaction.factory_class"&gt;
             org.hibernate.transaction.JTATransactionFactory
         &lt;/property&gt;
         &lt;property name="jta.UserTransaction"&gt;java:comp/UserTransaction&lt;/property&gt;
 
         &lt;!-- mapping files --&gt;
         &lt;mapping resource="org/hibernate/auction/Item.hbm.xml"/&gt;
         &lt;mapping resource="org/hibernate/auction/Bid.hbm.xml"/&gt;
 
         &lt;!-- cache settings --&gt;
         &lt;class-cache class="org.hibernate.auction.Item" usage="read-write"/&gt;
         &lt;class-cache class="org.hibernate.auction.Bid" usage="read-only"/&gt;
         &lt;collection-cache collection="org.hibernate.auction.Item.bids" usage="read-write"/&gt;
 
     &lt;/session-factory&gt;
 
 &lt;/hibernate-configuration&gt;</programlisting>
 
     <para>The advantage of this approach is the externalization of the mapping
     file names to configuration. The <literal>hibernate.cfg.xml</literal> is
     also more convenient once you have to tune the Hibernate cache. It is your
     choice to use either <literal>hibernate.properties</literal> or
     <literal>hibernate.cfg.xml</literal>. Both are equivalent, except for the
     above mentioned benefits of using the XML syntax.</para>
 
     <para>With the XML configuration, starting Hibernate is then as simple
     as:</para>
 
     <programlisting role="JAVA">SessionFactory sf = new Configuration().configure().buildSessionFactory();</programlisting>
 
     <para>You can select a different XML configuration file using:</para>
 
     <programlisting role="JAVA">SessionFactory sf = new Configuration()
     .configure("catdb.cfg.xml")
     .buildSessionFactory();</programlisting>
   </section>
 
   <section id="configuration-j2ee" revision="1">
     <title>Java EE Application Server integration</title>
 
     <para>Hibernate has the following integration points for J2EE
     infrastructure:</para>
 
     <itemizedlist>
       <listitem>
         <para><emphasis>Container-managed datasources</emphasis>: Hibernate
         can use JDBC connections managed by the container and provided through
         JNDI. Usually, a JTA compatible <literal>TransactionManager</literal>
         and a <literal>ResourceManager</literal> take care of transaction
         management (CMT), especially distributed transaction handling across
         several datasources. You can also demarcate transaction boundaries
         programmatically (BMT), or you might want to use the optional
         Hibernate <literal>Transaction</literal> API for this to keep your
         code portable.</para>
       </listitem>
     </itemizedlist>
 
     <itemizedlist>
       <listitem>
         <para><emphasis>Automatic JNDI binding</emphasis>: Hibernate can bind
         its <literal>SessionFactory</literal> to JNDI after startup.</para>
       </listitem>
     </itemizedlist>
 
     <itemizedlist>
       <listitem>
         <para><emphasis>JTA Session binding:</emphasis> the Hibernate
         <literal>Session</literal> can be automatically bound to the scope of
         JTA transactions. Simply lookup the <literal>SessionFactory</literal>
         from JNDI and get the current <literal>Session</literal>. Let
         Hibernate manage flushing and closing the <literal>Session</literal>
         when your JTA transaction completes. Transaction demarcation is either
         declarative (CMT) or programmatic (BMT/UserTransaction).</para>
       </listitem>
     </itemizedlist>
 
     <itemizedlist>
       <listitem>
         <para><emphasis>JMX deployment:</emphasis> if you have a JMX capable
         application server (e.g. JBoss AS), you can choose to deploy Hibernate
         as a managed MBean. This saves you the one line startup code to build
         your <literal>SessionFactory</literal> from a
         <literal>Configuration</literal>. The container will startup your
         <literal>HibernateService</literal> and also take care of service
         dependencies (datasource has to be available before Hibernate starts,
         etc).</para>
       </listitem>
     </itemizedlist>
 
     <para>Depending on your environment, you might have to set the
     configuration option
     <literal>hibernate.connection.aggressive_release</literal> to true if your
     application server shows "connection containment" exceptions.</para>
 
     <section id="configuration-optional-transactionstrategy" revision="3">
       <title>Transaction strategy configuration</title>
 
       <para>The Hibernate <literal>Session</literal> API is independent of any
       transaction demarcation system in your architecture. If you let
       Hibernate use JDBC directly through a connection pool, you can begin and
       end your transactions by calling the JDBC API. If you run in a J2EE
       application server, you might want to use bean-managed transactions and
       call the JTA API and <literal>UserTransaction</literal> when
       needed.</para>
 
       <para>To keep your code portable between these two (and other)
       environments we recommend the optional Hibernate
       <literal>Transaction</literal> API, which wraps and hides the underlying
       system. You have to specify a factory class for
       <literal>Transaction</literal> instances by setting the Hibernate
       configuration property
       <literal>hibernate.transaction.factory_class</literal>.</para>
 
       <para>There are three standard, or built-in, choices:</para>
 
       <variablelist spacing="compact">
         <varlistentry>
           <term><literal>org.hibernate.transaction.JDBCTransactionFactory</literal></term>
 
           <listitem>
             <para>delegates to database (JDBC) transactions (default)</para>
           </listitem>
         </varlistentry>
 
         <varlistentry>
           <term><literal>org.hibernate.transaction.JTATransactionFactory</literal></term>
 
           <listitem>
             <para>delegates to container-managed transactions if an existing
             transaction is underway in this context (for example, EJB session
             bean method). Otherwise, a new transaction is started and
             bean-managed transactions are used.</para>
           </listitem>
         </varlistentry>
 
         <varlistentry>
           <term><literal>org.hibernate.transaction.CMTTransactionFactory</literal></term>
 
           <listitem>
             <para>delegates to container-managed JTA transactions</para>
           </listitem>
         </varlistentry>
       </variablelist>
 
       <para>You can also define your own transaction strategies (for a CORBA
       transaction service, for example).</para>
 
       <para>Some features in Hibernate (i.e., the second level cache,
       Contextual Sessions with JTA, etc.) require access to the JTA
       <literal>TransactionManager</literal> in a managed environment. In an
       application server, since J2EE does not standardize a single mechanism,
       you have to specify how Hibernate should obtain a reference to the
       <literal>TransactionManager</literal>:</para>
 
       <table frame="topbot" id="jtamanagerlookup" revision="1">
         <title>JTA TransactionManagers</title>
 
         <tgroup cols="2">
           <colspec colwidth="2.5*" />
 
           <colspec colwidth="1*" />
 
           <thead>
             <row>
               <entry>Transaction Factory</entry>
 
               <entry align="center">Application Server</entry>
             </row>
           </thead>
 
           <tbody>
             <row>
               <entry><literal>org.hibernate.transaction.JBossTransactionManagerLookup</literal></entry>
 
               <entry align="center">JBoss AS</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.WeblogicTransactionManagerLookup</literal></entry>
 
               <entry align="center">Weblogic</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.WebSphereTransactionManagerLookup</literal></entry>
 
               <entry align="center">WebSphere</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.WebSphereExtendedJTATransactionLookup</literal></entry>
 
               <entry align="center">WebSphere 6</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.OrionTransactionManagerLookup</literal></entry>
 
               <entry align="center">Orion</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.ResinTransactionManagerLookup</literal></entry>
 
               <entry align="center">Resin</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.JOTMTransactionManagerLookup</literal></entry>
 
               <entry align="center">JOTM</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.JOnASTransactionManagerLookup</literal></entry>
 
               <entry align="center">JOnAS</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.JRun4TransactionManagerLookup</literal></entry>
 
               <entry align="center">JRun4</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.BESTransactionManagerLookup</literal></entry>
 
               <entry align="center">Borland ES</entry>
             </row>
 
             <row>
               <entry><literal>org.hibernate.transaction.JBossTSStandaloneTransactionManagerLookup</literal></entry>
 
               <entry align="center">JBoss TS used standalone (ie. outside
               JBoss AS and a JNDI environment generally). Known to work for
               <literal>org.jboss.jbossts:jbossjta:4.11.0.Final</literal></entry>
             </row>
           </tbody>
         </tgroup>
       </table>
     </section>
 
     <section id="configuration-optional-jndi" revision="3">
       <title>JNDI-bound <literal>SessionFactory</literal></title>
 
       <para>A JNDI-bound Hibernate <literal>SessionFactory</literal> can
       simplify the lookup function of the factory and create new
       <literal>Session</literal>s. This is not, however, related to a JNDI
       bound <literal>Datasource</literal>; both simply use the same
       registry.</para>
 
       <para>If you wish to have the <literal>SessionFactory</literal> bound to
       a JNDI namespace, specify a name (e.g.
       <literal>java:hibernate/SessionFactory</literal>) using the property
       <literal>hibernate.session_factory_name</literal>. If this property is
       omitted, the <literal>SessionFactory</literal> will not be bound to
       JNDI. This is especially useful in environments with a read-only JNDI
       default implementation (in Tomcat, for example).</para>
 
       <para>When binding the <literal>SessionFactory</literal> to JNDI,
       Hibernate will use the values of <literal>hibernate.jndi.url</literal>,
       <literal>hibernate.jndi.class</literal> to instantiate an initial
       context. If they are not specified, the default
       <literal>InitialContext</literal> will be used.</para>
 
       <para>Hibernate will automatically place the
       <literal>SessionFactory</literal> in JNDI after you call
       <literal>cfg.buildSessionFactory()</literal>. This means you will have
       this call in some startup code, or utility class in your application,
       unless you use JMX deployment with the
       <literal>HibernateService</literal> (this is discussed later in greater
       detail).</para>
 
       <para>If you use a JNDI <literal>SessionFactory</literal>, an EJB or any
       other class, you can obtain the <literal>SessionFactory</literal> using
       a JNDI lookup.</para>
 
       <para>It is recommended that you bind the
       <literal>SessionFactory</literal> to JNDI in a managed environment and
       use a <literal>static</literal> singleton otherwise. To shield your
       application code from these details, we also recommend to hide the
       actual lookup code for a <literal>SessionFactory</literal> in a helper
       class, such as <literal>HibernateUtil.getSessionFactory()</literal>.
       Note that such a class is also a convenient way to startup Hibernate—see
       chapter 1.</para>
     </section>
 
     <section id="configuration-j2ee-currentsession" revision="4">
       <title>Current Session context management with JTA</title>
 
       <para>The easiest way to handle <literal>Sessions</literal> and
       transactions is Hibernate's automatic "current"
       <literal>Session</literal> management. For a discussion of contextual
       sessions see <xref linkend="architecture-current-session" />. Using the
       <literal>"jta"</literal> session context, if there is no Hibernate
       <literal>Session</literal> associated with the current JTA transaction,
       one will be started and associated with that JTA transaction the first
       time you call <literal>sessionFactory.getCurrentSession()</literal>. The
       <literal>Session</literal>s retrieved via
       <literal>getCurrentSession()</literal> in the <literal>"jta"</literal>
       context are set to automatically flush before the transaction completes,
       close after the transaction completes, and aggressively release JDBC
       connections after each statement. This allows the
       <literal>Session</literal>s to be managed by the life cycle of the JTA
       transaction to which it is associated, keeping user code clean of such
       management concerns. Your code can either use JTA programmatically
       through <literal>UserTransaction</literal>, or (recommended for portable
       code) use the Hibernate <literal>Transaction</literal> API to set
       transaction boundaries. If you run in an EJB container, declarative
       transaction demarcation with CMT is preferred.</para>
     </section>
 
     <section id="configuration-j2ee-jmx" revision="1">
       <title>JMX deployment</title>
 
       <para>The line <literal>cfg.buildSessionFactory()</literal> still has to
       be executed somewhere to get a <literal>SessionFactory</literal> into
       JNDI. You can do this either in a <literal>static</literal> initializer
       block, like the one in <literal>HibernateUtil</literal>, or you can
       deploy Hibernate as a <emphasis>managed service</emphasis>.</para>
 
       <para>Hibernate is distributed with
       <literal>org.hibernate.jmx.HibernateService</literal> for deployment on
       an application server with JMX capabilities, such as JBoss AS. The
       actual deployment and configuration is vendor-specific. Here is an
       example <literal>jboss-service.xml</literal> for JBoss 4.0.x:</para>
 
       <programlisting role="XML">&lt;?xml version="1.0"?&gt;
 &lt;server&gt;
 
 &lt;mbean code="org.hibernate.jmx.HibernateService"
     name="jboss.jca:service=HibernateFactory,name=HibernateFactory"&gt;
 
     &lt;!-- Required services --&gt;
     &lt;depends&gt;jboss.jca:service=RARDeployer&lt;/depends&gt;
     &lt;depends&gt;jboss.jca:service=LocalTxCM,name=HsqlDS&lt;/depends&gt;
 
     &lt;!-- Bind the Hibernate service to JNDI --&gt;
     &lt;attribute name="JndiName"&gt;java:/hibernate/SessionFactory&lt;/attribute&gt;
 
     &lt;!-- Datasource settings --&gt;
     &lt;attribute name="Datasource"&gt;java:HsqlDS&lt;/attribute&gt;
     &lt;attribute name="Dialect"&gt;org.hibernate.dialect.HSQLDialect&lt;/attribute&gt;
 
     &lt;!-- Transaction integration --&gt;
     &lt;attribute name="TransactionStrategy"&gt;
         org.hibernate.transaction.JTATransactionFactory&lt;/attribute&gt;
     &lt;attribute name="TransactionManagerLookupStrategy"&gt;
         org.hibernate.transaction.JBossTransactionManagerLookup&lt;/attribute&gt;
     &lt;attribute name="FlushBeforeCompletionEnabled"&gt;true&lt;/attribute&gt;
     &lt;attribute name="AutoCloseSessionEnabled"&gt;true&lt;/attribute&gt;
 
     &lt;!-- Fetching options --&gt;
     &lt;attribute name="MaximumFetchDepth"&gt;5&lt;/attribute&gt;
 
     &lt;!-- Second-level caching --&gt;
     &lt;attribute name="SecondLevelCacheEnabled"&gt;true&lt;/attribute&gt;
-    &lt;attribute name="CacheProviderClass"&gt;org.hibernate.cache.EhCacheProvider&lt;/attribute&gt;
+    &lt;attribute name="CacheProviderClass"&gt;org.hibernate.cache.internal.EhCacheProvider&lt;/attribute&gt;
     &lt;attribute name="QueryCacheEnabled"&gt;true&lt;/attribute&gt;
 
     &lt;!-- Logging --&gt;
     &lt;attribute name="ShowSqlEnabled"&gt;true&lt;/attribute&gt;
 
     &lt;!-- Mapping files --&gt;
     &lt;attribute name="MapResources"&gt;auction/Item.hbm.xml,auction/Category.hbm.xml&lt;/attribute&gt;
 
 &lt;/mbean&gt;
 
 &lt;/server&gt;</programlisting>
 
       <para>This file is deployed in a directory called
       <literal>META-INF</literal> and packaged in a JAR file with the
       extension <literal>.sar</literal> (service archive). You also need to
       package Hibernate, its required third-party libraries, your compiled
       persistent classes, as well as your mapping files in the same archive.
       Your enterprise beans (usually session beans) can be kept in their own
       JAR file, but you can include this EJB JAR file in the main service
       archive to get a single (hot-)deployable unit. Consult the JBoss AS
       documentation for more information about JMX service and EJB
       deployment.</para>
     </section>
   </section>
 </chapter>
diff --git a/documentation/src/main/docbook/manual/en-US/content/performance.xml b/documentation/src/main/docbook/manual/en-US/content/performance.xml
index b16e248b14..2582f7f402 100644
--- a/documentation/src/main/docbook/manual/en-US/content/performance.xml
+++ b/documentation/src/main/docbook/manual/en-US/content/performance.xml
@@ -1,1693 +1,1693 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Middleware LLC.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 <!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
 "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
 <!ENTITY % BOOK_ENTITIES SYSTEM "../HIBERNATE_-_Relational_Persistence_for_Idiomatic_Java.ent">
 %BOOK_ENTITIES;
 ]>
 <chapter id="performance">
   <title>Improving performance</title>
 
   <section id="performance-fetching" revision="2">
     <title>Fetching strategies</title>
 
     <para>Hibernate uses a <emphasis>fetching strategy</emphasis> to retrieve
     associated objects if the application needs to navigate the association.
     Fetch strategies can be declared in the O/R mapping metadata, or
     over-ridden by a particular HQL or <literal>Criteria</literal>
     query.</para>
 
     <para>Hibernate3 defines the following fetching strategies:</para>
 
     <itemizedlist>
       <listitem>
         <para><emphasis>Join fetching</emphasis>: Hibernate retrieves the
         associated instance or collection in the same
         <literal>SELECT</literal>, using an <literal>OUTER
         JOIN</literal>.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Select fetching</emphasis>: a second
         <literal>SELECT</literal> is used to retrieve the associated entity or
         collection. Unless you explicitly disable lazy fetching by specifying
         <literal>lazy="false"</literal>, this second select will only be
         executed when you access the association.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Subselect fetching</emphasis>: a second
         <literal>SELECT</literal> is used to retrieve the associated
         collections for all entities retrieved in a previous query or fetch.
         Unless you explicitly disable lazy fetching by specifying
         <literal>lazy="false"</literal>, this second select will only be
         executed when you access the association.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Batch fetching</emphasis>: an optimization strategy
         for select fetching. Hibernate retrieves a batch of entity instances
         or collections in a single <literal>SELECT</literal> by specifying a
         list of primary or foreign keys.</para>
       </listitem>
     </itemizedlist>
 
     <para>Hibernate also distinguishes between:</para>
 
     <itemizedlist>
       <listitem>
         <para><emphasis>Immediate fetching</emphasis>: an association,
         collection or attribute is fetched immediately when the owner is
         loaded.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Lazy collection fetching</emphasis>: a collection is
         fetched when the application invokes an operation upon that
         collection. This is the default for collections.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>"Extra-lazy" collection fetching</emphasis>:
         individual elements of the collection are accessed from the database
         as needed. Hibernate tries not to fetch the whole collection into
         memory unless absolutely needed. It is suitable for large
         collections.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Proxy fetching</emphasis>: a single-valued association
         is fetched when a method other than the identifier getter is invoked
         upon the associated object.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>"No-proxy" fetching</emphasis>: a single-valued
         association is fetched when the instance variable is accessed.
         Compared to proxy fetching, this approach is less lazy; the
         association is fetched even when only the identifier is accessed. It
         is also more transparent, since no proxy is visible to the
         application. This approach requires buildtime bytecode instrumentation
         and is rarely necessary.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Lazy attribute fetching</emphasis>: an attribute or
         single valued association is fetched when the instance variable is
         accessed. This approach requires buildtime bytecode instrumentation
         and is rarely necessary.</para>
       </listitem>
     </itemizedlist>
 
     <para>We have two orthogonal notions here: <emphasis>when</emphasis> is
     the association fetched and <emphasis>how</emphasis> is it fetched. It is
     important that you do not confuse them. We use <literal>fetch</literal> to
     tune performance. We can use <literal>lazy</literal> to define a contract
     for what data is always available in any detached instance of a particular
     class.</para>
 
     <section id="performance-fetching-lazy">
       <title>Working with lazy associations</title>
 
       <para>By default, Hibernate3 uses lazy select fetching for collections
       and lazy proxy fetching for single-valued associations. These defaults
       make sense for most associations in the majority of applications.</para>
 
       <para>If you set <literal>hibernate.default_batch_fetch_size</literal>,
       Hibernate will use the batch fetch optimization for lazy fetching. This
       optimization can also be enabled at a more granular level.</para>
 
       <para>Please be aware that access to a lazy association outside of the
       context of an open Hibernate session will result in an exception. For
       example:</para>
 
       <programlisting role="JAVA">s = sessions.openSession();
 Transaction tx = s.beginTransaction();
             
 User u = (User) s.createQuery("from User u where u.name=:userName")
     .setString("userName", userName).uniqueResult();
 Map permissions = u.getPermissions();
 
 tx.commit();
 s.close();
 
 Integer accessLevel = (Integer) permissions.get("accounts");  // Error!</programlisting>
 
       <para>Since the permissions collection was not initialized when the
       <literal>Session</literal> was closed, the collection will not be able
       to load its state. <emphasis>Hibernate does not support lazy
       initialization for detached objects</emphasis>. This can be fixed by
       moving the code that reads from the collection to just before the
       transaction is committed.</para>
 
       <para>Alternatively, you can use a non-lazy collection or association,
       by specifying <literal>lazy="false"</literal> for the association
       mapping. However, it is intended that lazy initialization be used for
       almost all collections and associations. If you define too many non-lazy
       associations in your object model, Hibernate will fetch the entire
       database into memory in every transaction.</para>
 
       <para>On the other hand, you can use join fetching, which is non-lazy by
       nature, instead of select fetching in a particular transaction. We will
       now explain how to customize the fetching strategy. In Hibernate3, the
       mechanisms for choosing a fetch strategy are identical for single-valued
       associations and collections.</para>
     </section>
 
     <section id="performance-fetching-custom" revision="4">
       <title>Tuning fetch strategies</title>
 
       <para>Select fetching (the default) is extremely vulnerable to N+1
       selects problems, so we might want to enable join fetching in the
       mapping document:</para>
 
       <programlisting role="XML">&lt;set name="permissions"
             fetch="join"&gt;
     &lt;key column="userId"/&gt;
     &lt;one-to-many class="Permission"/&gt;
 &lt;/set</programlisting>
 
       <programlisting role="XML">&lt;many-to-one name="mother" class="Cat" fetch="join"/&gt;</programlisting>
 
       <para>The <literal>fetch</literal> strategy defined in the mapping
       document affects:</para>
 
       <itemizedlist>
         <listitem>
           <para>retrieval via <literal>get()</literal> or
           <literal>load()</literal></para>
         </listitem>
 
         <listitem>
           <para>retrieval that happens implicitly when an association is
           navigated</para>
         </listitem>
 
         <listitem>
           <para><literal>Criteria</literal> queries</para>
         </listitem>
 
         <listitem>
           <para>HQL queries if <literal>subselect</literal> fetching is
           used</para>
         </listitem>
       </itemizedlist>
 
       <para>Irrespective of the fetching strategy you use, the defined
       non-lazy graph is guaranteed to be loaded into memory. This might,
       however, result in several immediate selects being used to execute a
       particular HQL query.</para>
 
       <para>Usually, the mapping document is not used to customize fetching.
       Instead, we keep the default behavior, and override it for a particular
       transaction, using <literal>left join fetch</literal> in HQL. This tells
       Hibernate to fetch the association eagerly in the first select, using an
       outer join. In the <literal>Criteria</literal> query API, you would use
       <literal>setFetchMode(FetchMode.JOIN)</literal>.</para>
 
       <para>If you want to change the fetching strategy used by
       <literal>get()</literal> or <literal>load()</literal>, you can use a
       <literal>Criteria</literal> query. For example:</para>
 
       <programlisting role="JAVA">User user = (User) session.createCriteria(User.class)
                 .setFetchMode("permissions", FetchMode.JOIN)
                 .add( Restrictions.idEq(userId) )
                 .uniqueResult();</programlisting>
 
       <para>This is Hibernate's equivalent of what some ORM solutions call a
       "fetch plan".</para>
 
       <para>A completely different approach to problems with N+1 selects is to
       use the second-level cache.</para>
     </section>
 
     <section id="performance-fetching-proxies" revision="2">
       <title>Single-ended association proxies</title>
 
       <para>Lazy fetching for collections is implemented using Hibernate's own
       implementation of persistent collections. However, a different mechanism
       is needed for lazy behavior in single-ended associations. The target
       entity of the association must be proxied. Hibernate implements lazy
       initializing proxies for persistent objects using runtime bytecode
       enhancement which is accessed via the CGLIB library.</para>
 
       <para>At startup, Hibernate3 generates proxies by default for all
       persistent classes and uses them to enable lazy fetching of
       <literal>many-to-one</literal> and <literal>one-to-one</literal>
       associations.</para>
 
       <para>The mapping file may declare an interface to use as the proxy
       interface for that class, with the <literal>proxy</literal> attribute.
       By default, Hibernate uses a subclass of the class. <emphasis>The
       proxied class must implement a default constructor with at least package
       visibility. This constructor is recommended for all persistent
       classes</emphasis>.</para>
 
       <para>There are potential problems to note when extending this approach
       to polymorphic classes.For example:</para>
 
       <programlisting role="XML">&lt;class name="Cat" proxy="Cat"&gt;
     ......
     &lt;subclass name="DomesticCat"&gt;
         .....
     &lt;/subclass&gt;
 &lt;/class&gt;</programlisting>
 
       <para>Firstly, instances of <literal>Cat</literal> will never be
       castable to <literal>DomesticCat</literal>, even if the underlying
       instance is an instance of <literal>DomesticCat</literal>:</para>
 
       <programlisting role="JAVA">Cat cat = (Cat) session.load(Cat.class, id);  // instantiate a proxy (does not hit the db)
 if ( cat.isDomesticCat() ) {                  // hit the db to initialize the proxy
     DomesticCat dc = (DomesticCat) cat;       // Error!
     ....
 }</programlisting>
 
       <para>Secondly, it is possible to break proxy
       <literal>==</literal>:</para>
 
       <programlisting role="JAVA">Cat cat = (Cat) session.load(Cat.class, id);            // instantiate a Cat proxy
 DomesticCat dc = 
         (DomesticCat) session.load(DomesticCat.class, id);  // acquire new DomesticCat proxy!
 System.out.println(cat==dc);                            // false</programlisting>
 
       <para>However, the situation is not quite as bad as it looks. Even
       though we now have two references to different proxy objects, the
       underlying instance will still be the same object:</para>
 
       <programlisting role="JAVA">cat.setWeight(11.0);  // hit the db to initialize the proxy
 System.out.println( dc.getWeight() );  // 11.0</programlisting>
 
       <para>Third, you cannot use a CGLIB proxy for a <literal>final</literal>
       class or a class with any <literal>final</literal> methods.</para>
 
       <para>Finally, if your persistent object acquires any resources upon
       instantiation (e.g. in initializers or default constructor), then those
       resources will also be acquired by the proxy. The proxy class is an
       actual subclass of the persistent class.</para>
 
       <para>These problems are all due to fundamental limitations in Java's
       single inheritance model. To avoid these problems your persistent
       classes must each implement an interface that declares its business
       methods. You should specify these interfaces in the mapping file where
       <literal>CatImpl</literal> implements the interface
       <literal>Cat</literal> and <literal>DomesticCatImpl</literal> implements
       the interface <literal>DomesticCat</literal>. For example:</para>
 
       <programlisting role="XML">&lt;class name="CatImpl" proxy="Cat"&gt;
     ......
     &lt;subclass name="DomesticCatImpl" proxy="DomesticCat"&gt;
         .....
     &lt;/subclass&gt;
 &lt;/class&gt;</programlisting>
 
       <para>Then proxies for instances of <literal>Cat</literal> and
       <literal>DomesticCat</literal> can be returned by
       <literal>load()</literal> or <literal>iterate()</literal>.</para>
 
       <programlisting role="JAVA">Cat cat = (Cat) session.load(CatImpl.class, catid);
 Iterator iter = session.createQuery("from CatImpl as cat where cat.name='fritz'").iterate();
 Cat fritz = (Cat) iter.next();</programlisting>
 
       <note>
         <title>Note</title>
 
         <para><literal>list()</literal> does not usually return
         proxies.</para>
       </note>
 
       <para>Relationships are also lazily initialized. This means you must
       declare any properties to be of type <literal>Cat</literal>, not
       <literal>CatImpl</literal>.</para>
 
       <para>Certain operations do <emphasis>not</emphasis> require proxy
       initialization:</para>
 
       <itemizedlist spacing="compact">
         <listitem>
           <para><literal>equals()</literal>: if the persistent class does not
           override <literal>equals()</literal></para>
         </listitem>
 
         <listitem>
           <para><literal>hashCode()</literal>: if the persistent class does
           not override <literal>hashCode()</literal></para>
         </listitem>
 
         <listitem>
           <para>The identifier getter method</para>
         </listitem>
       </itemizedlist>
 
       <para>Hibernate will detect persistent classes that override
       <literal>equals()</literal> or <literal>hashCode()</literal>.</para>
 
       <para>By choosing <literal>lazy="no-proxy"</literal> instead of the
       default <literal>lazy="proxy"</literal>, you can avoid problems
       associated with typecasting. However, buildtime bytecode instrumentation
       is required, and all operations will result in immediate proxy
       initialization.</para>
     </section>
 
     <section id="performance-fetching-initialization" revision="1">
       <title>Initializing collections and proxies</title>
 
       <para>A <literal>LazyInitializationException</literal> will be thrown by
       Hibernate if an uninitialized collection or proxy is accessed outside of
       the scope of the <literal>Session</literal>, i.e., when the entity
       owning the collection or having the reference to the proxy is in the
       detached state.</para>
 
       <para>Sometimes a proxy or collection needs to be initialized before
       closing the <literal>Session</literal>. You can force initialization by
       calling <literal>cat.getSex()</literal> or
       <literal>cat.getKittens().size()</literal>, for example. However, this
       can be confusing to readers of the code and it is not convenient for
       generic code.</para>
 
       <para>The static methods <literal>Hibernate.initialize()</literal> and
       <literal>Hibernate.isInitialized()</literal>, provide the application
       with a convenient way of working with lazily initialized collections or
       proxies. <literal>Hibernate.initialize(cat)</literal> will force the
       initialization of a proxy, <literal>cat</literal>, as long as its
       <literal>Session</literal> is still open. <literal>Hibernate.initialize(
       cat.getKittens() )</literal> has a similar effect for the collection of
       kittens.</para>
 
       <para>Another option is to keep the <literal>Session</literal> open
       until all required collections and proxies have been loaded. In some
       application architectures, particularly where the code that accesses
       data using Hibernate, and the code that uses it are in different
       application layers or different physical processes, it can be a problem
       to ensure that the <literal>Session</literal> is open when a collection
       is initialized. There are two basic ways to deal with this issue:</para>
 
       <itemizedlist>
         <listitem>
           <para>In a web-based application, a servlet filter can be used to
           close the <literal>Session</literal> only at the end of a user
           request, once the rendering of the view is complete (the
           <emphasis>Open Session in View</emphasis> pattern). Of course, this
           places heavy demands on the correctness of the exception handling of
           your application infrastructure. It is vitally important that the
           <literal>Session</literal> is closed and the transaction ended
           before returning to the user, even when an exception occurs during
           rendering of the view. See the Hibernate Wiki for examples of this
           "Open Session in View" pattern.</para>
         </listitem>
 
         <listitem>
           <para>In an application with a separate business tier, the business
           logic must "prepare" all collections that the web tier needs before
           returning. This means that the business tier should load all the
           data and return all the data already initialized to the
           presentation/web tier that is required for a particular use case.
           Usually, the application calls
           <literal>Hibernate.initialize()</literal> for each collection that
           will be needed in the web tier (this call must occur before the
           session is closed) or retrieves the collection eagerly using a
           Hibernate query with a <literal>FETCH</literal> clause or a
           <literal>FetchMode.JOIN</literal> in <literal>Criteria</literal>.
           This is usually easier if you adopt the <emphasis>Command</emphasis>
           pattern instead of a <emphasis>Session Facade</emphasis>.</para>
         </listitem>
 
         <listitem>
           <para>You can also attach a previously loaded object to a new
           <literal>Session</literal> with <literal>merge()</literal> or
           <literal>lock()</literal> before accessing uninitialized collections
           or other proxies. Hibernate does not, and certainly
           <emphasis>should</emphasis> not, do this automatically since it
           would introduce impromptu transaction semantics.</para>
         </listitem>
       </itemizedlist>
 
       <para>Sometimes you do not want to initialize a large collection, but
       still need some information about it, like its size, for example, or a
       subset of the data.</para>
 
       <para>You can use a collection filter to get the size of a collection
       without initializing it:</para>
 
       <programlisting role="JAVA">( (Integer) s.createFilter( collection, "select count(*)" ).list().get(0) ).intValue()</programlisting>
 
       <para>The <literal>createFilter()</literal> method is also used to
       efficiently retrieve subsets of a collection without needing to
       initialize the whole collection:</para>
 
       <programlisting role="JAVA">s.createFilter( lazyCollection, "").setFirstResult(0).setMaxResults(10).list();</programlisting>
     </section>
 
     <section id="performance-fetching-batch">
       <title>Using batch fetching</title>
 
       <para>Using batch fetching, Hibernate can load several uninitialized
       proxies if one proxy is accessed. Batch fetching is an optimization of
       the lazy select fetching strategy. There are two ways you can configure
       batch fetching: on the class level and the collection level.</para>
 
       <para>Batch fetching for classes/entities is easier to understand.
       Consider the following example: at runtime you have 25
       <literal>Cat</literal> instances loaded in a <literal>Session</literal>,
       and each <literal>Cat</literal> has a reference to its
       <literal>owner</literal>, a <literal>Person</literal>. The
       <literal>Person</literal> class is mapped with a proxy,
       <literal>lazy="true"</literal>. If you now iterate through all cats and
       call <literal>getOwner()</literal> on each, Hibernate will, by default,
       execute 25 <literal>SELECT</literal> statements to retrieve the proxied
       owners. You can tune this behavior by specifying a
       <literal>batch-size</literal> in the mapping of
       <literal>Person</literal>:</para>
 
       <programlisting role="XML">&lt;class name="Person" batch-size="10"&gt;...&lt;/class&gt;</programlisting>
 
       <para>Hibernate will now execute only three queries: the pattern is 10,
       10, 5.</para>
 
       <para>You can also enable batch fetching of collections. For example, if
       each <literal>Person</literal> has a lazy collection of
       <literal>Cat</literal>s, and 10 persons are currently loaded in the
       <literal>Session</literal>, iterating through all persons will generate
       10 <literal>SELECT</literal>s, one for every call to
       <literal>getCats()</literal>. If you enable batch fetching for the
       <literal>cats</literal> collection in the mapping of
       <literal>Person</literal>, Hibernate can pre-fetch collections:</para>
 
       <programlisting role="XML">&lt;class name="Person"&gt;
     &lt;set name="cats" batch-size="3"&gt;
         ...
     &lt;/set&gt;
 &lt;/class&gt;</programlisting>
 
       <para>With a <literal>batch-size</literal> of 3, Hibernate will load 3,
       3, 3, 1 collections in four <literal>SELECT</literal>s. Again, the value
       of the attribute depends on the expected number of uninitialized
       collections in a particular <literal>Session</literal>.</para>
 
       <para>Batch fetching of collections is particularly useful if you have a
       nested tree of items, i.e. the typical bill-of-materials pattern.
       However, a <emphasis>nested set</emphasis> or a <emphasis>materialized
       path</emphasis> might be a better option for read-mostly trees.</para>
     </section>
 
     <section id="performance-fetching-subselect">
       <title>Using subselect fetching</title>
 
       <para>If one lazy collection or single-valued proxy has to be fetched,
       Hibernate will load all of them, re-running the original query in a
       subselect. This works in the same way as batch-fetching but without the
       piecemeal loading.</para>
 
       <!-- TODO: Write more about this -->
     </section>
 
     <section id="performance-fetching-profiles">
       <title>Fetch profiles</title>
 
       <para>Another way to affect the fetching strategy for loading associated
       objects is through something called a fetch profile, which is a named
       configuration associated with the
       <interfacename>org.hibernate.SessionFactory</interfacename> but enabled,
       by name, on the <interfacename>org.hibernate.Session</interfacename>.
       Once enabled on a <interfacename>org.hibernate.Session</interfacename>,
       the fetch profile will be in affect for that
       <interfacename>org.hibernate.Session</interfacename> until it is
       explicitly disabled.</para>
 
       <para>So what does that mean? Well lets explain that by way of an
       example which show the different available approaches to configure a
       fetch profile:</para>
 
       <example>
         <title>Specifying a fetch profile using
         <classname>@FetchProfile</classname></title>
 
         <programlisting role="XML">@Entity
 @FetchProfile(name = "customer-with-orders", fetchOverrides = {
    @FetchProfile.FetchOverride(entity = Customer.class, association = "orders", mode = FetchMode.JOIN)
 })
 public class Customer {
    @Id
    @GeneratedValue
    private long id;
 
    private String name;
 
    private long customerNumber;
 
    @OneToMany
    private Set&lt;Order&gt; orders;
 
    // standard getter/setter
    ...
 }</programlisting>
       </example>
 
       <example>
         <title>Specifying a fetch profile using
         <literal>&lt;fetch-profile&gt;</literal> outside
         <literal>&lt;class&gt;</literal> node</title>
 
         <programlisting role="XML">&lt;hibernate-mapping&gt;
     &lt;class name="Customer"&gt;
         ...
         &lt;set name="orders" inverse="true"&gt;
             &lt;key column="cust_id"/&gt;
             &lt;one-to-many class="Order"/&gt;
         &lt;/set&gt;
     &lt;/class&gt;
     &lt;class name="Order"&gt;
         ...
     &lt;/class&gt;
     &lt;fetch-profile name="customer-with-orders"&gt;
         &lt;fetch entity="Customer" association="orders" style="join"/&gt;
     &lt;/fetch-profile&gt;
 &lt;/hibernate-mapping&gt;
 </programlisting>
       </example>
 
       <example>
         <title>Specifying a fetch profile using
         <literal>&lt;fetch-profile&gt;</literal> inside
         <literal>&lt;class&gt;</literal> node</title>
 
         <programlisting role="XML">&lt;hibernate-mapping&gt;
     &lt;class name="Customer"&gt;
         ...
         &lt;set name="orders" inverse="true"&gt;
             &lt;key column="cust_id"/&gt;
             &lt;one-to-many class="Order"/&gt;
         &lt;/set&gt;
         &lt;fetch-profile name="customer-with-orders"&gt;
             &lt;fetch association="orders" style="join"/&gt;
         &lt;/fetch-profile&gt;
     &lt;/class&gt;
     &lt;class name="Order"&gt;
         ...
     &lt;/class&gt;
 &lt;/hibernate-mapping&gt;
 </programlisting>
       </example>
 
       <para>Now normally when you get a reference to a particular customer,
       that customer's set of orders will be lazy meaning we will not yet have
       loaded those orders from the database. Normally this is a good thing.
       Now lets say that you have a certain use case where it is more efficient
       to load the customer and their orders together. One way certainly is to
       use "dynamic fetching" strategies via an HQL or criteria queries. But
       another option is to use a fetch profile to achieve that. The following
       code will load both the customer <emphasis>and</emphasis>their
       orders:</para>
 
       <example>
         <title>Activating a fetch profile for a given
         <classname>Session</classname></title>
 
         <programlisting role="JAVA">Session session = ...;
 session.enableFetchProfile( "customer-with-orders" );  // name matches from mapping
 Customer customer = (Customer) session.get( Customer.class, customerId );
 </programlisting>
       </example>
 
       <note>
         <para><classname>@FetchProfile </classname>definitions are global and
         it does not matter on which class you place them. You can place the
         <classname>@FetchProfile</classname> annotation either onto a class or
         package (package-info.java). In order to define multiple fetch
         profiles for the same class or package
         <classname>@FetchProfiles</classname> can be used.</para>
       </note>
 
       <para>Currently only join style fetch profiles are supported, but they
       plan is to support additional styles. See <ulink
       url="http://opensource.atlassian.com/projects/hibernate/browse/HHH-3414">HHH-3414</ulink>
       for details.</para>
     </section>
 
     <section id="performance-fetching-lazyproperties">
       <title>Using lazy property fetching</title>
 
       <para>Hibernate3 supports the lazy fetching of individual properties.
       This optimization technique is also known as <emphasis>fetch
       groups</emphasis>. Please note that this is mostly a marketing feature;
       optimizing row reads is much more important than optimization of column
       reads. However, only loading some properties of a class could be useful
       in extreme cases. For example, when legacy tables have hundreds of
       columns and the data model cannot be improved.</para>
 
       <para>To enable lazy property loading, set the <literal>lazy</literal>
       attribute on your particular property mappings:</para>
 
       <programlisting role="XML">&lt;class name="Document"&gt;
        &lt;id name="id"&gt;
         &lt;generator class="native"/&gt;
     &lt;/id&gt;
     &lt;property name="name" not-null="true" length="50"/&gt;
     &lt;property name="summary" not-null="true" length="200" lazy="true"/&gt;
     &lt;property name="text" not-null="true" length="2000" lazy="true"/&gt;
 &lt;/class&gt;</programlisting>
 
       <para>Lazy property loading requires buildtime bytecode instrumentation.
       If your persistent classes are not enhanced, Hibernate will ignore lazy
       property settings and return to immediate fetching.</para>
 
       <para>For bytecode instrumentation, use the following Ant task:</para>
 
       <programlisting role="XML">&lt;target name="instrument" depends="compile"&gt;
     &lt;taskdef name="instrument" classname="org.hibernate.tool.instrument.InstrumentTask"&gt;
         &lt;classpath path="${jar.path}"/&gt;
         &lt;classpath path="${classes.dir}"/&gt;
         &lt;classpath refid="lib.class.path"/&gt;
     &lt;/taskdef&gt;
 
     &lt;instrument verbose="true"&gt;
         &lt;fileset dir="${testclasses.dir}/org/hibernate/auction/model"&gt;
             &lt;include name="*.class"/&gt;
         &lt;/fileset&gt;
     &lt;/instrument&gt;
 &lt;/target&gt;</programlisting>
 
       <para>A different way of avoiding unnecessary column reads, at least for
       read-only transactions, is to use the projection features of HQL or
       Criteria queries. This avoids the need for buildtime bytecode processing
       and is certainly a preferred solution.</para>
 
       <para>You can force the usual eager fetching of properties using
       <literal>fetch all properties</literal> in HQL.</para>
     </section>
   </section>
 
   <section id="performance-cache" revision="1">
     <title>The Second Level Cache</title>
 
     <para>A Hibernate <literal>Session</literal> is a transaction-level cache
     of persistent data. It is possible to configure a cluster or JVM-level
     (<literal>SessionFactory</literal>-level) cache on a class-by-class and
     collection-by-collection basis. You can even plug in a clustered cache. Be
     aware that caches are not aware of changes made to the persistent store by
     another application. They can, however, be configured to regularly expire
     cached data.</para>
 
     <para revision="1">You have the option to tell Hibernate which caching
     implementation to use by specifying the name of a class that implements
     <literal>org.hibernate.cache.CacheProvider</literal> using the property
     <literal>hibernate.cache.provider_class</literal>. Hibernate is bundled
     with a number of built-in integrations with the open-source cache
     providers that are listed in <xref linkend="cacheproviders" />. You can
     also implement your own and plug it in as outlined above. Note that
     versions prior to Hibernate 3.2 use EhCache as the default cache
     provider.</para>
 
     <table frame="topbot" id="cacheproviders" revision="1">
       <title>Cache Providers</title>
 
       <tgroup align="left" cols="5" colsep="1" rowsep="1">
         <colspec colname="c1" colwidth="1*" />
 
         <colspec colname="c2" colwidth="3*" />
 
         <colspec colname="c3" colwidth="1*" />
 
         <colspec colname="c4" colwidth="1*" />
 
         <colspec colname="c5" colwidth="1*" />
 
         <thead>
           <row>
             <entry>Cache</entry>
 
             <entry>Provider class</entry>
 
             <entry>Type</entry>
 
             <entry>Cluster Safe</entry>
 
             <entry>Query Cache Supported</entry>
           </row>
         </thead>
 
         <tbody>
           <row>
             <entry>Hashtable (not intended for production use)</entry>
 
             <entry><literal>org.hibernate.cache.HashtableCacheProvider</literal></entry>
 
             <entry>memory</entry>
 
             <entry></entry>
 
             <entry>yes</entry>
           </row>
 
           <row>
             <entry>EHCache</entry>
 
-            <entry><literal>org.hibernate.cache.EhCacheProvider</literal></entry>
+            <entry><literal>org.hibernate.cache.internal.EhCacheProvider</literal></entry>
 
             <entry>memory, disk</entry>
 
             <entry></entry>
 
             <entry>yes</entry>
           </row>
 
           <row>
             <entry>OSCache</entry>
 
             <entry><literal>org.hibernate.cache.OSCacheProvider</literal></entry>
 
             <entry>memory, disk</entry>
 
             <entry></entry>
 
             <entry>yes</entry>
           </row>
 
           <row>
             <entry>SwarmCache</entry>
 
             <entry><literal>org.hibernate.cache.SwarmCacheProvider</literal></entry>
 
             <entry>clustered (ip multicast)</entry>
 
             <entry>yes (clustered invalidation)</entry>
 
             <entry></entry>
           </row>
 
           <row>
             <entry>JBoss Cache 1.x</entry>
 
             <entry><literal>org.hibernate.cache.TreeCacheProvider</literal></entry>
 
             <entry>clustered (ip multicast), transactional</entry>
 
             <entry>yes (replication)</entry>
 
             <entry>yes (clock sync req.)</entry>
           </row>
 
           <row>
             <entry>JBoss Cache 2</entry>
 
             <entry><literal>org.hibernate.cache.jbc.JBossCacheRegionFactory</literal></entry>
 
             <entry>clustered (ip multicast), transactional</entry>
 
             <entry>yes (replication or invalidation)</entry>
 
             <entry>yes (clock sync req.)</entry>
           </row>
         </tbody>
       </tgroup>
     </table>
 
     <section id="performance-cache-mapping" revision="2">
       <title>Cache mappings</title>
 
       <para>As we have done in previous chapters we are looking at the two
       different possibiltites to configure caching. First configuration via
       annotations and then via Hibernate mapping files.</para>
 
       <para>By default, entities are not part of the second level cache and we
       recommend you to stick to this setting. However, you can override this
       by setting the <literal>shared-cache-mode</literal> element in your
       <filename>persistence.xml</filename> file or by using the
       <literal>javax.persistence.sharedCache.mode </literal>property in your
       configuration. The following values are possible:</para>
 
       <itemizedlist>
         <listitem>
           <para><literal>ENABLE_SELECTIVE</literal> (Default and recommended
           value): entities are not cached unless explicitly marked as
           cacheable.</para>
         </listitem>
 
         <listitem>
           <para><literal>DISABLE_SELECTIVE</literal>: entities are cached
           unless explicitly marked as not cacheable.</para>
         </listitem>
 
         <listitem>
           <para><literal>ALL</literal>: all entities are always cached even if
           marked as non cacheable.</para>
         </listitem>
 
         <listitem>
           <para><literal>NONE</literal>: no entity are cached even if marked
           as cacheable. This option can make sense to disable second-level
           cache altogether.</para>
         </listitem>
       </itemizedlist>
 
       <para>The cache concurrency strategy used by default can be set globaly
       via the
       <literal>hibernate.cache.default_cache_concurrency_strategy</literal>
       configuration property. The values for this property are:</para>
 
       <itemizedlist>
         <listitem>
           <para><literal>read-only</literal></para>
         </listitem>
 
         <listitem>
           <para><literal>read-write</literal></para>
         </listitem>
 
         <listitem>
           <para><literal>nonstrict-read-write</literal></para>
         </listitem>
 
         <listitem>
           <para><literal>transactional</literal></para>
         </listitem>
       </itemizedlist>
 
       <note>
         <para>It is recommended to define the cache concurrency strategy per
         entity rather than using a global one. Use the
         <classname>@org.hibernate.annotations.Cache</classname> annotation for
         that.</para>
       </note>
 
       <example id="example-cache-concurrency-with-cache-annotation">
         <title>Definition of cache concurrency strategy via
         <classname>@Cache</classname></title>
 
         <programlisting language="JAVA" role="JAVA">@Entity 
 @Cacheable
 @Cache(usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
 public class Forest { ... }</programlisting>
       </example>
 
       <para>Hibernate also let's you cache the content of a collection or the
       identifiers if the collection contains other entities. Use the
       <classname>@Cache</classname> annotation on the collection
       property.</para>
 
       <example>
         <title>Caching collections using annotations</title>
 
         <programlisting language="JAVA" role="JAVA">@OneToMany(cascade=CascadeType.ALL, fetch=FetchType.EAGER)
 @JoinColumn(name="CUST_ID")
 @Cache(usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
 public SortedSet&lt;Ticket&gt; getTickets() {
     return tickets;
 }</programlisting>
       </example>
 
       <para><xref linkend="example-cache-annotation-with-attributes" />shows
       the<literal> @org.hibernate.annotations.Cache</literal> annotations with
       its attributes. It allows you to define the caching strategy and region
       of a given second level cache.</para>
 
       <example id="example-cache-annotation-with-attributes">
         <title><classname>@Cache</classname> annotation with
         attributes</title>
 
         <programlistingco>
           <areaspec>
             <area coords="2" id="cache-hm1" />
 
             <area coords="3" id="cache-hm2" />
 
             <area coords="4" id="cache-hm3" />
           </areaspec>
 
           <programlisting>@Cache(
     CacheConcurrencyStrategy usage();
     String region() default "";
     String include() default "all";
 )</programlisting>
 
           <calloutlist>
             <callout arearefs="cache-hm1">
               <para>usage: the given cache concurrency strategy (NONE,
               READ_ONLY, NONSTRICT_READ_WRITE, READ_WRITE,
               TRANSACTIONAL)</para>
             </callout>
 
             <callout arearefs="cache-hm2">
               <para>region (optional): the cache region (default to the fqcn
               of the class or the fq role name of the collection)</para>
             </callout>
 
             <callout arearefs="cache-hm3">
               <para><literal>include</literal> (optional): all to include all
               properties, non-lazy to only include non lazy properties
               (default all).</para>
             </callout>
           </calloutlist>
         </programlistingco>
       </example>
 
       <para>Let's now take a look at Hibernate mapping files. There the
       <literal>&lt;cache&gt;</literal> element of a class or collection
       mapping is used to configure the second level cache. Looking at <xref
       linkend="example-hibernate-cache-mapping-element" /> the parallels to
       anotations is obvious.</para>
 
       <example id="example-hibernate-cache-mapping-element">
         <title>The Hibernate <literal>&lt;cache&gt;</literal> mapping
         element</title>
 
         <programlistingco>
           <areaspec>
             <area coords="2" id="cache1" />
 
             <area coords="3" id="cache2" />
 
             <area coords="4" id="cache3" />
           </areaspec>
 
           <programlisting>&lt;cache
     usage="transactional|read-write|nonstrict-read-write|read-only"
     region="RegionName"
     include="all|non-lazy"
 /&gt;</programlisting>
 
           <calloutlist>
             <callout arearefs="cache1">
               <para><literal>usage</literal> (required) specifies the caching
               strategy: <literal>transactional</literal>,
               <literal>read-write</literal>,
               <literal>nonstrict-read-write</literal> or
               <literal>read-only</literal></para>
             </callout>
 
             <callout arearefs="cache2">
               <para><literal>region</literal> (optional: defaults to the class
               or collection role name): specifies the name of the second level
               cache region</para>
             </callout>
 
             <callout arearefs="cache3">
               <para><literal>include</literal> (optional: defaults to
               <literal>all</literal>) <literal>non-lazy</literal>: specifies
               that properties of the entity mapped with
               <literal>lazy="true"</literal> cannot be cached when
               attribute-level lazy fetching is enabled</para>
             </callout>
           </calloutlist>
         </programlistingco>
       </example>
 
       <para>Alternatively to <literal>&lt;cache&gt;</literal>, you can use
       <literal>&lt;class-cache&gt;</literal> and
       <literal>&lt;collection-cache&gt;</literal> elements in
       <literal>hibernate.cfg.xml</literal>.</para>
 
       <para>Let's now have a closer look at the different usage
       strategies</para>
     </section>
 
     <section id="performance-cache-readonly">
       <title>Strategy: read only</title>
 
       <para>If your application needs to read, but not modify, instances of a
       persistent class, a <literal>read-only</literal> cache can be used. This
       is the simplest and optimal performing strategy. It is even safe for use
       in a cluster.</para>
     </section>
 
     <section id="performance-cache-readwrite">
       <title>Strategy: read/write</title>
 
       <para>If the application needs to update data, a
       <literal>read-write</literal> cache might be appropriate. This cache
       strategy should never be used if serializable transaction isolation
       level is required. If the cache is used in a JTA environment, you must
       specify the property
       <literal>hibernate.transaction.manager_lookup_class</literal> and naming
       a strategy for obtaining the JTA <literal>TransactionManager</literal>.
       In other environments, you should ensure that the transaction is
       completed when <literal>Session.close()</literal> or
       <literal>Session.disconnect()</literal> is called. If you want to use
       this strategy in a cluster, you should ensure that the underlying cache
       implementation supports locking. The built-in cache providers
       <emphasis>do not</emphasis> support locking.</para>
     </section>
 
     <section id="performance-cache-nonstrict">
       <title>Strategy: nonstrict read/write</title>
 
       <para>If the application only occasionally needs to update data (i.e. if
       it is extremely unlikely that two transactions would try to update the
       same item simultaneously), and strict transaction isolation is not
       required, a <literal>nonstrict-read-write</literal> cache might be
       appropriate. If the cache is used in a JTA environment, you must specify
       <literal>hibernate.transaction.manager_lookup_class</literal>. In other
       environments, you should ensure that the transaction is completed when
       <literal>Session.close()</literal> or
       <literal>Session.disconnect()</literal> is called.</para>
     </section>
 
     <section id="performance-cache-transactional">
       <title>Strategy: transactional</title>
 
       <para>The <literal>transactional</literal> cache strategy provides
       support for fully transactional cache providers such as JBoss TreeCache.
       Such a cache can only be used in a JTA environment and you must specify
       <literal>hibernate.transaction.manager_lookup_class</literal>.</para>
     </section>
 
     <section id="performance-cache-compat-matrix">
       <title>Cache-provider/concurrency-strategy compatibility</title>
 
       <important>
         <para>None of the cache providers support all of the cache concurrency
         strategies.</para>
       </important>
 
       <para>The following table shows which providers are compatible with
       which concurrency strategies.</para>
 
       <table frame="topbot">
         <title>Cache Concurrency Strategy Support</title>
 
         <tgroup align="left" cols="5" colsep="1" rowsep="1">
           <colspec colname="c1" colwidth="1*" />
 
           <colspec colname="c2" colwidth="1*" />
 
           <colspec colname="c3" colwidth="1*" />
 
           <colspec colname="c4" colwidth="1*" />
 
           <colspec colname="c5" colwidth="1*" />
 
           <thead>
             <row>
               <entry>Cache</entry>
 
               <entry>read-only</entry>
 
               <entry>nonstrict-read-write</entry>
 
               <entry>read-write</entry>
 
               <entry>transactional</entry>
             </row>
           </thead>
 
           <tbody>
             <row>
               <entry>Hashtable (not intended for production use)</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
             </row>
 
             <row>
               <entry>EHCache</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
             </row>
 
             <row>
               <entry>OSCache</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
             </row>
 
             <row>
               <entry>SwarmCache</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
 
               <entry></entry>
             </row>
 
             <row>
               <entry>JBoss Cache 1.x</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
 
               <entry></entry>
 
               <entry>yes</entry>
             </row>
 
             <row>
               <entry>JBoss Cache 2</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
 
               <entry></entry>
 
               <entry>yes</entry>
             </row>
           </tbody>
         </tgroup>
       </table>
     </section>
   </section>
 
   <section id="performance-sessioncache" revision="2">
     <title>Managing the caches</title>
 
     <para>Whenever you pass an object to <literal>save()</literal>,
     <literal>update()</literal> or <literal>saveOrUpdate()</literal>, and
     whenever you retrieve an object using <literal>load()</literal>,
     <literal>get()</literal>, <literal>list()</literal>,
     <literal>iterate()</literal> or <literal>scroll()</literal>, that object
     is added to the internal cache of the <literal>Session</literal>.</para>
 
     <para>When <literal>flush()</literal> is subsequently called, the state of
     that object will be synchronized with the database. If you do not want
     this synchronization to occur, or if you are processing a huge number of
     objects and need to manage memory efficiently, the
     <literal>evict()</literal> method can be used to remove the object and its
     collections from the first-level cache.</para>
 
     <example>
       <title>Explcitly evicting a cached instance from the first level cache
       using <methodname>Session.evict()</methodname></title>
 
       <programlisting role="JAVA">ScrollableResult cats = sess.createQuery("from Cat as cat").scroll(); //a huge result set
 while ( cats.next() ) {
     Cat cat = (Cat) cats.get(0);
     doSomethingWithACat(cat);
     sess.evict(cat);
 }</programlisting>
     </example>
 
     <para>The <literal>Session</literal> also provides a
     <literal>contains()</literal> method to determine if an instance belongs
     to the session cache.</para>
 
     <para>To evict all objects from the session cache, call
     <literal>Session.clear()</literal></para>
 
     <para>For the second-level cache, there are methods defined on
     <literal>SessionFactory</literal> for evicting the cached state of an
     instance, entire class, collection instance or entire collection
     role.</para>
 
     <example>
       <title>Second-level cache eviction via
       <methodname>SessionFactoty.evict() </methodname>and
       <methodname>SessionFacyory.evictCollection()</methodname></title>
 
       <programlisting role="JAVA">sessionFactory.evict(Cat.class, catId); //evict a particular Cat
 sessionFactory.evict(Cat.class);  //evict all Cats
 sessionFactory.evictCollection("Cat.kittens", catId); //evict a particular collection of kittens
 sessionFactory.evictCollection("Cat.kittens"); //evict all kitten collections</programlisting>
     </example>
 
     <para>The <literal>CacheMode</literal> controls how a particular session
     interacts with the second-level cache:</para>
 
     <itemizedlist>
       <listitem>
         <para><literal>CacheMode.NORMAL</literal>: will read items from and
         write items to the second-level cache</para>
       </listitem>
 
       <listitem>
         <para><literal>CacheMode.GET</literal>: will read items from the
         second-level cache. Do not write to the second-level cache except when
         updating data</para>
       </listitem>
 
       <listitem>
         <para><literal>CacheMode.PUT</literal>: will write items to the
         second-level cache. Do not read from the second-level cache</para>
       </listitem>
 
       <listitem>
         <para><literal>CacheMode.REFRESH</literal>: will write items to the
         second-level cache. Do not read from the second-level cache. Bypass
         the effect of <literal>hibernate.cache.use_minimal_puts</literal>
         forcing a refresh of the second-level cache for all items read from
         the database</para>
       </listitem>
     </itemizedlist>
 
     <para>To browse the contents of a second-level or query cache region, use
     the <literal>Statistics</literal> API:</para>
 
     <example>
       <title>Browsing the second-level cache entries via the
       <classname>Statistics</classname> API</title>
 
       <programlisting role="JAVA">Map cacheEntries = sessionFactory.getStatistics()
         .getSecondLevelCacheStatistics(regionName)
         .getEntries();</programlisting>
     </example>
 
     <para>You will need to enable statistics and, optionally, force Hibernate
     to keep the cache entries in a more readable format:</para>
 
     <example>
       <title>Enabling Hibernate statistics</title>
 
       <programlisting>hibernate.generate_statistics true
 hibernate.cache.use_structured_entries true</programlisting>
     </example>
   </section>
 
   <section id="performance-querycache" revision="1">
     <title>The Query Cache</title>
 
     <para>Query result sets can also be cached. This is only useful for
     queries that are run frequently with the same parameters.</para>
 
     <section id="performance-querycache-enable">
       <title>Enabling query caching</title>
 
       <para>Caching of query results introduces some overhead in terms of your
       applications normal transactional processing. For example, if you cache
       results of a query against Person Hibernate will need to keep track of
       when those results should be invalidated because changes have been
       committed against Person. That, coupled with the fact that most
       applications simply gain no benefit from caching query results, leads
       Hibernate to disable caching of query results by default. To use query
       caching, you will first need to enable the query cache:</para>
 
       <programlisting>hibernate.cache.use_query_cache true</programlisting>
 
       <para>This setting creates two new cache regions: <itemizedlist>
           <listitem>
             <para><classname>org.hibernate.cache.StandardQueryCache</classname>,
             holding the cached query results</para>
           </listitem>
 
           <listitem>
             <para><classname>org.hibernate.cache.UpdateTimestampsCache</classname>,
             holding timestamps of the most recent updates to queryable tables.
             These are used to validate the results as they are served from the
             query cache.</para>
           </listitem>
         </itemizedlist></para>
 
       <important>
         <para>If you configure your underlying cache implementation to use
         expiry or timeouts is very important that the cache timeout of the
         underlying cache region for the UpdateTimestampsCache be set to a
         higher value than the timeouts of any of the query caches. In fact, we
         recommend that the the UpdateTimestampsCache region not be configured
         for expiry at all. Note, in particular, that an LRU cache expiry
         policy is never appropriate.</para>
       </important>
 
       <para>As mentioned above, most queries do not benefit from caching or
       their results. So by default, individual queries are not cached even
       after enabling query caching. To enable results caching for a particular
       query, call <literal>org.hibernate.Query.setCacheable(true)</literal>.
       This call allows the query to look for existing cache results or add its
       results to the cache when it is executed.</para>
 
       <note>
         <para>The query cache does not cache the state of the actual entities
         in the cache; it caches only identifier values and results of value
         type. For this reaso, the query cache should always be used in
         conjunction with the second-level cache for those entities expected to
         be cached as part of a query result cache (just as with collection
         caching).</para>
       </note>
     </section>
 
     <section id="performance-querycache-regions">
       <title>Query cache regions</title>
 
       <para>If you require fine-grained control over query cache expiration
       policies, you can specify a named cache region for a particular query by
       calling <literal>Query.setCacheRegion()</literal>.</para>
 
       <programlisting role="JAVA">List blogs = sess.createQuery("from Blog blog where blog.blogger = :blogger")
         .setEntity("blogger", blogger)
         .setMaxResults(15)
         .setCacheable(true)
         .setCacheRegion("frontpages")
         .list();</programlisting>
 
       <para>If you want to force the query cache to refresh one of its regions
       (disregard any cached results it finds there) you can use
       <literal>org.hibernate.Query.setCacheMode(CacheMode.REFRESH)</literal>.
       In conjunction with the region you have defined for the given query,
       Hibernate will selectively force the results cached in that particular
       region to be refreshed. This is particularly useful in cases where
       underlying data may have been updated via a separate process and is a
       far more efficient alternative to bulk eviction of the region via
       <literal>org.hibernate.SessionFactory.evictQueries()</literal>.</para>
     </section>
   </section>
 
   <section id="performance-collections">
     <title>Understanding Collection performance</title>
 
     <para>In the previous sections we have covered collections and their
     applications. In this section we explore some more issues in relation to
     collections at runtime.</para>
 
     <section id="performance-collections-taxonomy">
       <title>Taxonomy</title>
 
       <para>Hibernate defines three basic kinds of collections:</para>
 
       <itemizedlist>
         <listitem>
           <para>collections of values</para>
         </listitem>
 
         <listitem>
           <para>one-to-many associations</para>
         </listitem>
 
         <listitem>
           <para>many-to-many associations</para>
         </listitem>
       </itemizedlist>
 
       <para>This classification distinguishes the various table and foreign
       key relationships but does not tell us quite everything we need to know
       about the relational model. To fully understand the relational structure
       and performance characteristics, we must also consider the structure of
       the primary key that is used by Hibernate to update or delete collection
       rows. This suggests the following classification:</para>
 
       <itemizedlist>
         <listitem>
           <para>indexed collections</para>
         </listitem>
 
         <listitem>
           <para>sets</para>
         </listitem>
 
         <listitem>
           <para>bags</para>
         </listitem>
       </itemizedlist>
 
       <para>All indexed collections (maps, lists, and arrays) have a primary
       key consisting of the <literal>&lt;key&gt;</literal> and
       <literal>&lt;index&gt;</literal> columns. In this case, collection
       updates are extremely efficient. The primary key can be efficiently
       indexed and a particular row can be efficiently located when Hibernate
       tries to update or delete it.</para>
 
       <para>Sets have a primary key consisting of
       <literal>&lt;key&gt;</literal> and element columns. This can be less
       efficient for some types of collection element, particularly composite
       elements or large text or binary fields, as the database may not be able
       to index a complex primary key as efficiently. However, for one-to-many
       or many-to-many associations, particularly in the case of synthetic
       identifiers, it is likely to be just as efficient. If you want
       <literal>SchemaExport</literal> to actually create the primary key of a
       <literal>&lt;set&gt;</literal>, you must declare all columns as
       <literal>not-null="true"</literal>.</para>
 
       <para><literal>&lt;idbag&gt;</literal> mappings define a surrogate key,
       so they are efficient to update. In fact, they are the best case.</para>
 
       <para>Bags are the worst case since they permit duplicate element values
       and, as they have no index column, no primary key can be defined.
       Hibernate has no way of distinguishing between duplicate rows. Hibernate
       resolves this problem by completely removing in a single
       <literal>DELETE</literal> and recreating the collection whenever it
       changes. This can be inefficient.</para>
 
       <para>For a one-to-many association, the "primary key" may not be the
       physical primary key of the database table. Even in this case, the above
       classification is still useful. It reflects how Hibernate "locates"
       individual rows of the collection.</para>
     </section>
 
     <section id="performance-collections-mostefficientupdate">
       <title>Lists, maps, idbags and sets are the most efficient collections
       to update</title>
 
       <para>From the discussion above, it should be clear that indexed
       collections and sets allow the most efficient operation in terms of
       adding, removing and updating elements.</para>
 
       <para>There is, arguably, one more advantage that indexed collections
       have over sets for many-to-many associations or collections of values.
       Because of the structure of a <literal>Set</literal>, Hibernate does not
       <literal>UPDATE</literal> a row when an element is "changed". Changes to
       a <literal>Set</literal> always work via <literal>INSERT</literal> and
       <literal>DELETE</literal> of individual rows. Once again, this
       consideration does not apply to one-to-many associations.</para>
 
       <para>After observing that arrays cannot be lazy, you can conclude that
       lists, maps and idbags are the most performant (non-inverse) collection
       types, with sets not far behind. You can expect sets to be the most
       common kind of collection in Hibernate applications. This is because the
       "set" semantics are most natural in the relational model.</para>
 
       <para>However, in well-designed Hibernate domain models, most
       collections are in fact one-to-many associations with
       <literal>inverse="true"</literal>. For these associations, the update is
       handled by the many-to-one end of the association, and so considerations
       of collection update performance simply do not apply.</para>
     </section>
 
     <section id="performance-collections-mostefficentinverse">
       <title>Bags and lists are the most efficient inverse collections</title>
 
       <para>There is a particular case, however, in which bags, and also
       lists, are much more performant than sets. For a collection with
       <literal>inverse="true"</literal>, the standard bidirectional
       one-to-many relationship idiom, for example, we can add elements to a
       bag or list without needing to initialize (fetch) the bag elements. This
       is because, unlike a <literal>set</literal>,
       <literal>Collection.add()</literal> or
       <literal>Collection.addAll()</literal> must always return true for a bag
       or <literal>List</literal>. This can make the following common code much
       faster:</para>
 
       <programlisting role="JAVA">Parent p = (Parent) sess.load(Parent.class, id);
 Child c = new Child();
 c.setParent(p);
 p.getChildren().add(c);  //no need to fetch the collection!
 sess.flush();</programlisting>
     </section>
 
     <section id="performance-collections-oneshotdelete">
       <title>One shot delete</title>
 
       <para>Deleting collection elements one by one can sometimes be extremely
       inefficient. Hibernate knows not to do that in the case of an
       newly-empty collection (if you called <literal>list.clear()</literal>,
       for example). In this case, Hibernate will issue a single
       <literal>DELETE</literal>.</para>
 
       <para>Suppose you added a single element to a collection of size twenty
       and then remove two elements. Hibernate will issue one
       <literal>INSERT</literal> statement and two <literal>DELETE</literal>
       statements, unless the collection is a bag. This is certainly
       desirable.</para>
 
       <para>However, suppose that we remove eighteen elements, leaving two and
       then add thee new elements. There are two possible ways to
       proceed</para>
 
       <itemizedlist>
         <listitem>
           <para>delete eighteen rows one by one and then insert three
           rows</para>
         </listitem>
 
         <listitem>
           <para>remove the whole collection in one SQL
           <literal>DELETE</literal> and insert all five current elements one
           by one</para>
         </listitem>
       </itemizedlist>
 
       <para>Hibernate cannot know that the second option is probably quicker.
       It would probably be undesirable for Hibernate to be that intuitive as
       such behavior might confuse database triggers, etc.</para>
 
       <para>Fortunately, you can force this behavior (i.e. the second
       strategy) at any time by discarding (i.e. dereferencing) the original
       collection and returning a newly instantiated collection with all the
       current elements.</para>
 
       <para>One-shot-delete does not apply to collections mapped
       <literal>inverse="true"</literal>.</para>
     </section>
   </section>
 
   <section id="performance-monitoring" revision="1">
     <title>Monitoring performance</title>
 
     <para>Optimization is not much use without monitoring and access to
     performance numbers. Hibernate provides a full range of figures about its
     internal operations. Statistics in Hibernate are available per
     <literal>SessionFactory</literal>.</para>
 
     <section id="performance-monitoring-sf" revision="2">
       <title>Monitoring a SessionFactory</title>
 
       <para>You can access <literal>SessionFactory</literal> metrics in two
       ways. Your first option is to call
       <literal>sessionFactory.getStatistics()</literal> and read or display
       the <literal>Statistics</literal> yourself.</para>
 
       <para>Hibernate can also use JMX to publish metrics if you enable the
       <literal>StatisticsService</literal> MBean. You can enable a single
       MBean for all your <literal>SessionFactory</literal> or one per factory.
       See the following code for minimalistic configuration examples:</para>
 
       <programlisting role="JAVA">// MBean service registration for a specific SessionFactory
 Hashtable tb = new Hashtable();
 tb.put("type", "statistics");
 tb.put("sessionFactory", "myFinancialApp");
 ObjectName on = new ObjectName("hibernate", tb); // MBean object name
 
 StatisticsService stats = new StatisticsService(); // MBean implementation
 stats.setSessionFactory(sessionFactory); // Bind the stats to a SessionFactory
 server.registerMBean(stats, on); // Register the Mbean on the server</programlisting>
 
       <programlisting role="JAVA">// MBean service registration for all SessionFactory's
 Hashtable tb = new Hashtable();
 tb.put("type", "statistics");
 tb.put("sessionFactory", "all");
 ObjectName on = new ObjectName("hibernate", tb); // MBean object name
 
 StatisticsService stats = new StatisticsService(); // MBean implementation
 server.registerMBean(stats, on); // Register the MBean on the server</programlisting>
 
       <para>You can activate and deactivate the monitoring for a
       <literal>SessionFactory</literal>:</para>
 
       <itemizedlist>
         <listitem>
           <para>at configuration time, set
           <literal>hibernate.generate_statistics</literal> to
           <literal>false</literal></para>
         </listitem>
       </itemizedlist>
 
       <itemizedlist>
         <listitem>
           <para>at runtime:
           <literal>sf.getStatistics().setStatisticsEnabled(true)</literal> or
           <literal>hibernateStatsBean.setStatisticsEnabled(true)</literal></para>
         </listitem>
       </itemizedlist>
 
       <para>Statistics can be reset programmatically using the
       <literal>clear()</literal> method. A summary can be sent to a logger
       (info level) using the <literal>logSummary()</literal> method.</para>
     </section>
 
     <section id="performance-monitoring-metrics" revision="1">
       <title>Metrics</title>
 
       <para>Hibernate provides a number of metrics, from basic information to
       more specialized information that is only relevant in certain scenarios.
       All available counters are described in the
       <literal>Statistics</literal> interface API, in three categories:</para>
 
       <itemizedlist>
         <listitem>
           <para>Metrics related to the general <literal>Session</literal>
           usage, such as number of open sessions, retrieved JDBC connections,
           etc.</para>
         </listitem>
 
         <listitem>
           <para>Metrics related to the entities, collections, queries, and
           caches as a whole (aka global metrics).</para>
         </listitem>
 
         <listitem>
           <para>Detailed metrics related to a particular entity, collection,
           query or cache region.</para>
         </listitem>
       </itemizedlist>
 
       <para>For example, you can check the cache hit, miss, and put ratio of
       entities, collections and queries, and the average time a query needs.
       Be aware that the number of milliseconds is subject to approximation in
       Java. Hibernate is tied to the JVM precision and on some platforms this
       might only be accurate to 10 seconds.</para>
 
       <para>Simple getters are used to access the global metrics (i.e. not
       tied to a particular entity, collection, cache region, etc.). You can
       access the metrics of a particular entity, collection or cache region
       through its name, and through its HQL or SQL representation for queries.
       Please refer to the <literal>Statistics</literal>,
       <literal>EntityStatistics</literal>,
       <literal>CollectionStatistics</literal>,
       <literal>SecondLevelCacheStatistics</literal>, and
       <literal>QueryStatistics</literal> API Javadoc for more information. The
       following code is a simple example:</para>
 
       <programlisting role="JAVA">Statistics stats = HibernateUtil.sessionFactory.getStatistics();
 
 double queryCacheHitCount  = stats.getQueryCacheHitCount();
 double queryCacheMissCount = stats.getQueryCacheMissCount();
 double queryCacheHitRatio =
   queryCacheHitCount / (queryCacheHitCount + queryCacheMissCount);
 
 log.info("Query Hit ratio:" + queryCacheHitRatio);
 
 EntityStatistics entityStats =
   stats.getEntityStatistics( Cat.class.getName() );
 long changes =
         entityStats.getInsertCount()
         + entityStats.getUpdateCount()
         + entityStats.getDeleteCount();
 log.info(Cat.class.getName() + " changed " + changes + "times"  );</programlisting>
 
       <para>You can work on all entities, collections, queries and region
       caches, by retrieving the list of names of entities, collections,
       queries and region caches using the following methods:
       <literal>getQueries()</literal>, <literal>getEntityNames()</literal>,
       <literal>getCollectionRoleNames()</literal>, and
       <literal>getSecondLevelCacheRegionNames()</literal>.</para>
     </section>
   </section>
 </chapter>
diff --git a/hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0ConnectionProvider.java b/hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0ConnectionProvider.java
index d946835a6e..c45c20197c 100644
--- a/hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0ConnectionProvider.java
+++ b/hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0ConnectionProvider.java
@@ -1,249 +1,249 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.connections.internal;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Properties;
 import javax.sql.DataSource;
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.UnknownUnwrapTypeException;
 import org.jboss.logging.Logger;
 import com.mchange.v2.c3p0.DataSources;
 
 /**
  * A connection provider that uses a C3P0 connection pool. Hibernate will use this by
  * default if the <tt>hibernate.c3p0.*</tt> properties are set.
  *
  * @author various people
  * @see ConnectionProvider
  */
 public class C3P0ConnectionProvider implements ConnectionProvider {
 
-    private static final C3P0Logger LOG = Logger.getMessageLogger(C3P0Logger.class, C3P0ConnectionProvider.class.getName());
+    private static final C3P0MessageLogger LOG = Logger.getMessageLogger(C3P0MessageLogger.class, C3P0ConnectionProvider.class.getName());
 
 	//swaldman 2006-08-28: define c3p0-style configuration parameters for properties with
 	//                     hibernate-specific overrides to detect and warn about conflicting
 	//                     declarations
 	private final static String C3P0_STYLE_MIN_POOL_SIZE = "c3p0.minPoolSize";
 	private final static String C3P0_STYLE_MAX_POOL_SIZE = "c3p0.maxPoolSize";
 	private final static String C3P0_STYLE_MAX_IDLE_TIME = "c3p0.maxIdleTime";
 	private final static String C3P0_STYLE_MAX_STATEMENTS = "c3p0.maxStatements";
 	private final static String C3P0_STYLE_ACQUIRE_INCREMENT = "c3p0.acquireIncrement";
 	private final static String C3P0_STYLE_IDLE_CONNECTION_TEST_PERIOD = "c3p0.idleConnectionTestPeriod";
     // private final static String C3P0_STYLE_TEST_CONNECTION_ON_CHECKOUT = "c3p0.testConnectionOnCheckout";
 
 	//swaldman 2006-08-28: define c3p0-style configuration parameters for initialPoolSize, which
 	//                     hibernate sensibly lets default to minPoolSize, but we'll let users
 	//                     override it with the c3p0-style property if they want.
 	private final static String C3P0_STYLE_INITIAL_POOL_SIZE = "c3p0.initialPoolSize";
 
 	private DataSource ds;
 	private Integer isolation;
 	private boolean autocommit;
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Connection getConnection() throws SQLException {
 		final Connection c = ds.getConnection();
 		if ( isolation != null ) {
 			c.setTransactionIsolation( isolation.intValue() );
 		}
 		if ( c.getAutoCommit() != autocommit ) {
 			c.setAutoCommit( autocommit );
 		}
 		return c;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void closeConnection(Connection conn) throws SQLException {
 		conn.close();
 	}
 
 	@Override
 	public boolean isUnwrappableAs(Class unwrapType) {
 		return ConnectionProvider.class.equals( unwrapType ) ||
 				C3P0ConnectionProvider.class.isAssignableFrom( unwrapType ) ||
 				DataSource.class.isAssignableFrom( unwrapType );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public <T> T unwrap(Class<T> unwrapType) {
 		if ( ConnectionProvider.class.equals( unwrapType ) ||
 				C3P0ConnectionProvider.class.isAssignableFrom( unwrapType ) ) {
 			return (T) this;
 		}
 		else if ( DataSource.class.isAssignableFrom( unwrapType ) ) {
 			return (T) ds;
 		}
 		else {
 			throw new UnknownUnwrapTypeException( unwrapType );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void configure(Properties props) throws HibernateException {
 		String jdbcDriverClass = props.getProperty( Environment.DRIVER );
 		String jdbcUrl = props.getProperty( Environment.URL );
 		Properties connectionProps = ConnectionProviderInitiator.getConnectionProperties( props );
 
         LOG.c3p0UsingDriver(jdbcDriverClass, jdbcUrl);
         LOG.connectionProperties(ConfigurationHelper.maskOut(connectionProps, "password"));
 
 		autocommit = ConfigurationHelper.getBoolean( Environment.AUTOCOMMIT, props );
-        LOG.autoCommitMode(autocommit);
+        LOG.autoCommitMode( autocommit );
 
         if (jdbcDriverClass == null) LOG.jdbcDriverNotSpecified(Environment.DRIVER);
 		else {
 			try {
 				Class.forName( jdbcDriverClass );
 			}
 			catch ( ClassNotFoundException cnfe ) {
 				try {
 					ReflectHelper.classForName( jdbcDriverClass );
 				}
 				catch ( ClassNotFoundException e ) {
                     String msg = LOG.jdbcDriverNotFound(jdbcDriverClass);
                     LOG.error(msg, e);
 					throw new HibernateException( msg, e );
 				}
 			}
 		}
 
 		try {
 
 			//swaldman 2004-02-07: modify to allow null values to signify fall through to c3p0 PoolConfig defaults
 			Integer minPoolSize = ConfigurationHelper.getInteger( Environment.C3P0_MIN_SIZE, props );
 			Integer maxPoolSize = ConfigurationHelper.getInteger( Environment.C3P0_MAX_SIZE, props );
 			Integer maxIdleTime = ConfigurationHelper.getInteger( Environment.C3P0_TIMEOUT, props );
 			Integer maxStatements = ConfigurationHelper.getInteger( Environment.C3P0_MAX_STATEMENTS, props );
 			Integer acquireIncrement = ConfigurationHelper.getInteger( Environment.C3P0_ACQUIRE_INCREMENT, props );
 			Integer idleTestPeriod = ConfigurationHelper.getInteger( Environment.C3P0_IDLE_TEST_PERIOD, props );
 
 			Properties c3props = new Properties();
 
 			// turn hibernate.c3p0.* into c3p0.*, so c3p0
 			// gets a chance to see all hibernate.c3p0.*
 			for ( Iterator ii = props.keySet().iterator(); ii.hasNext(); ) {
 				String key = ( String ) ii.next();
 				if ( key.startsWith( "hibernate.c3p0." ) ) {
 					String newKey = key.substring( 10 );
 					if ( props.containsKey( newKey ) ) {
 						warnPropertyConflict( key, newKey );
 					}
 					c3props.put( newKey, props.get( key ) );
 				}
 			}
 
 			setOverwriteProperty( Environment.C3P0_MIN_SIZE, C3P0_STYLE_MIN_POOL_SIZE, props, c3props, minPoolSize );
 			setOverwriteProperty( Environment.C3P0_MAX_SIZE, C3P0_STYLE_MAX_POOL_SIZE, props, c3props, maxPoolSize );
 			setOverwriteProperty( Environment.C3P0_TIMEOUT, C3P0_STYLE_MAX_IDLE_TIME, props, c3props, maxIdleTime );
 			setOverwriteProperty(
 					Environment.C3P0_MAX_STATEMENTS, C3P0_STYLE_MAX_STATEMENTS, props, c3props, maxStatements
 			);
 			setOverwriteProperty(
 					Environment.C3P0_ACQUIRE_INCREMENT, C3P0_STYLE_ACQUIRE_INCREMENT, props, c3props, acquireIncrement
 			);
 			setOverwriteProperty(
 					Environment.C3P0_IDLE_TEST_PERIOD, C3P0_STYLE_IDLE_CONNECTION_TEST_PERIOD, props, c3props, idleTestPeriod
 			);
 
 			// revert to traditional hibernate behavior of setting initialPoolSize to minPoolSize
 			// unless otherwise specified with a c3p0.*-style parameter.
 			Integer initialPoolSize = ConfigurationHelper.getInteger( C3P0_STYLE_INITIAL_POOL_SIZE, props );
 			if ( initialPoolSize == null && minPoolSize != null ) {
 				c3props.put( C3P0_STYLE_INITIAL_POOL_SIZE, String.valueOf( minPoolSize ).trim() );
 			}
 
 			/*DataSource unpooled = DataSources.unpooledDataSource(
 				jdbcUrl, props.getProperty(Environment.USER), props.getProperty(Environment.PASS)
 			);*/
 			DataSource unpooled = DataSources.unpooledDataSource( jdbcUrl, connectionProps );
 
 			Properties allProps = ( Properties ) props.clone();
 			allProps.putAll( c3props );
 
 			ds = DataSources.pooledDataSource( unpooled, allProps );
 		}
 		catch ( Exception e ) {
             LOG.error(LOG.unableToInstantiateC3p0ConnectionPool(), e);
             throw new HibernateException(LOG.unableToInstantiateC3p0ConnectionPool(), e);
 		}
 
 		String i = props.getProperty( Environment.ISOLATION );
         if (i == null) isolation = null;
 		else {
 			isolation = new Integer( i );
             LOG.jdbcIsolationLevel(Environment.isolationLevelToString(isolation.intValue()));
 		}
 
 	}
 
     /**
 	 *
 	 */
 	public void close() {
 		try {
 			DataSources.destroy( ds );
 		}
 		catch ( SQLException sqle ) {
             LOG.unableToDestroyC3p0ConnectionPool(sqle);
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public boolean supportsAggressiveRelease() {
 		return false;
 	}
 
 	private void setOverwriteProperty(String hibernateStyleKey, String c3p0StyleKey, Properties hibp, Properties c3p, Integer value) {
 		if ( value != null ) {
 			c3p.put( c3p0StyleKey, String.valueOf( value ).trim() );
 			if ( hibp.getProperty( c3p0StyleKey ) != null ) {
 				warnPropertyConflict( hibernateStyleKey, c3p0StyleKey );
 			}
 			String longC3p0StyleKey = "hibernate." + c3p0StyleKey;
 			if ( hibp.getProperty( longC3p0StyleKey ) != null ) {
 				warnPropertyConflict( hibernateStyleKey, longC3p0StyleKey );
 			}
 		}
 	}
 
 	private void warnPropertyConflict(String hibernateStyle, String c3p0Style) {
         LOG.bothHibernateAndC3p0StylesSet(hibernateStyle, c3p0Style, hibernateStyle, c3p0Style);
 	}
 }
diff --git a/hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0Logger.java b/hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0MessageLogger.java
similarity index 87%
rename from hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0Logger.java
rename to hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0MessageLogger.java
index a215337b60..71adefc452 100644
--- a/hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0Logger.java
+++ b/hibernate-c3p0/src/main/java/org/hibernate/service/jdbc/connections/internal/C3P0MessageLogger.java
@@ -1,64 +1,68 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.connections.internal;
 
 import static org.jboss.logging.Logger.Level.INFO;
 import static org.jboss.logging.Logger.Level.WARN;
 import java.sql.SQLException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Cause;
 import org.jboss.logging.LogMessage;
 import org.jboss.logging.Message;
 import org.jboss.logging.MessageLogger;
 
 /**
- * Defines internationalized messages for this hibernate-c3p0, with IDs ranging from 10001 to 15000 inclusively. New messages must
- * be added after the last message defined to ensure message codes are unique.
+ * The jboss-logging {@link MessageLogger} for the hibernate-c3p0 module.  It reserves message ids ranging from
+ * 10001 to 15000 inclusively.
+ * <p/>
+ * New messages must be added after the last message defined to ensure message codes are unique.
  */
 @MessageLogger( projectCode = "HHH" )
-public interface C3P0Logger extends HibernateLogger {
+public interface C3P0MessageLogger extends CoreMessageLogger {
 
     @LogMessage( level = WARN )
     @Message( value = "Both hibernate-style property '%s' and c3p0-style property '%s' have been set in hibernate.properties. "
                       + "Hibernate-style property '%s' will be used and c3p0-style property '%s' will be ignored!", id = 10001 )
     void bothHibernateAndC3p0StylesSet( String hibernateStyle,
                                         String c3p0Style,
                                         String hibernateStyle2,
                                         String c3p0Style2 );
 
     @LogMessage( level = INFO )
     @Message( value = "C3P0 using driver: %s at URL: %s", id = 10002 )
     void c3p0UsingDriver( String jdbcDriverClass,
                           String jdbcUrl );
 
     @Message( value = "JDBC Driver class not found: %s", id = 10003 )
     String jdbcDriverNotFound( String jdbcDriverClass );
 
     @LogMessage( level = WARN )
     @Message( value = "Could not destroy C3P0 connection pool", id = 10004 )
     void unableToDestroyC3p0ConnectionPool( @Cause SQLException e );
 
     @Message( value = "Could not instantiate C3P0 connection pool", id = 10005 )
     String unableToInstantiateC3p0ConnectionPool();
 }
diff --git a/hibernate-core/src/main/antlr/hql-sql.g b/hibernate-core/src/main/antlr/hql-sql.g
index 23e23b10e6..01a64e4849 100644
--- a/hibernate-core/src/main/antlr/hql-sql.g
+++ b/hibernate-core/src/main/antlr/hql-sql.g
@@ -1,742 +1,741 @@
 header
 {
-// $Id: hql-sql.g 10001 2006-06-08 21:08:04Z steve.ebersole@jboss.com $
 package org.hibernate.hql.antlr;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.jboss.logging.Logger;
 }
 
 /**
  * Hibernate Query Language to SQL Tree Transform.<br>
  * This is a tree grammar that transforms an HQL AST into a intermediate SQL AST
  * with bindings to Hibernate interfaces (Queryable, etc.).  The Hibernate specific methods
  * are all implemented in the HqlSqlWalker subclass, allowing the ANTLR-generated class
  * to have only the minimum dependencies on the Hibernate code base.   This will also allow
  * the sub-class to be easily edited using an IDE (most IDE's don't support ANTLR).
  * <br>
  * <i>NOTE:</i> The java class is generated from hql-sql.g by ANTLR.
  * <i>DO NOT EDIT THE GENERATED JAVA SOURCE CODE.</i>
  * @author Joshua Davis (joshua@hibernate.org)
  */
 class HqlSqlBaseWalker extends TreeParser;
 
 options
 {
 	// Note: importVocab and exportVocab cause ANTLR to share the token type numbers between the
 	// two grammars.  This means that the token type constants from the source tree are the same
 	// as those in the target tree.  If this is not the case, tree translation can result in
 	// token types from the *source* tree being present in the target tree.
 	importVocab=Hql;        // import definitions from "Hql"
 	exportVocab=HqlSql;     // Call the resulting definitions "HqlSql"
 	buildAST=true;
 }
 
 tokens
 {
 	FROM_FRAGMENT;	// A fragment of SQL that represents a table reference in a FROM clause.
 	IMPLIED_FROM;	// An implied FROM element.
 	JOIN_FRAGMENT;	// A JOIN fragment.
 	SELECT_CLAUSE;
 	LEFT_OUTER;
 	RIGHT_OUTER;
 	ALIAS_REF;      // An IDENT that is a reference to an entity via it's alias.
 	PROPERTY_REF;   // A DOT that is a reference to a property in an entity.
 	SQL_TOKEN;      // A chunk of SQL that is 'rendered' already.
 	SELECT_COLUMNS; // A chunk of SQL representing a bunch of select columns.
 	SELECT_EXPR;    // A select expression, generated from a FROM element.
 	THETA_JOINS;	// Root of theta join condition subtree.
 	FILTERS;		// Root of the filters condition subtree.
 	METHOD_NAME;    // An IDENT that is a method name.
 	NAMED_PARAM;    // A named parameter (:foo).
 	BOGUS;          // Used for error state detection, etc.
 	RESULT_VARIABLE_REF;   // An IDENT that refers to result variable
 	                       // (i.e, an alias for a select expression) 
 }
 
 // -- Declarations --
 {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, HqlSqlBaseWalker.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HqlSqlBaseWalker.class.getName());
 
 	private int level = 0;
 	private boolean inSelect = false;
 	private boolean inFunctionCall = false;
 	private boolean inCase = false;
 	private boolean inFrom = false;
 	private int statementType;
 	private String statementTypeName;
 	// Note: currentClauseType tracks the current clause within the current
 	// statement, regardless of level; currentTopLevelClauseType, on the other
 	// hand, tracks the current clause within the top (or primary) statement.
 	// Thus, currentTopLevelClauseType ignores the clauses from any subqueries.
 	private int currentClauseType;
 	private int currentTopLevelClauseType;
 	private int currentStatementType;
 
 	public final boolean isSubQuery() {
 		return level > 1;
 	}
 
 	public final boolean isInFrom() {
 		return inFrom;
 	}
 
 	public final boolean isInFunctionCall() {
 		return inFunctionCall;
 	}
 	
 	public final boolean isInSelect() {
 		return inSelect;
 	}
 
 	public final boolean isInCase() {
 		return inCase;
 	}
 
 	public final int getStatementType() {
 		return statementType;
 	}
 
 	public final int getCurrentClauseType() {
 		return currentClauseType;
 	}
 
 	public final int getCurrentTopLevelClauseType() {
 		return currentTopLevelClauseType;
 	}
 
 	public final int getCurrentStatementType() {
 		return currentStatementType;
 	}
 
 	public final boolean isComparativeExpressionClause() {
 		// Note: once we add support for "JOIN ... ON ...",
 		// the ON clause needs to get included here
 	    return getCurrentClauseType() == WHERE ||
 	            getCurrentClauseType() == WITH ||
 	            isInCase();
 	}
 
 	public final boolean isSelectStatement() {
 		return statementType == SELECT;
 	}
 
 	private void beforeStatement(String statementName, int statementType) {
 		inFunctionCall = false;
 		level++;
 		if ( level == 1 ) {
 			this.statementTypeName = statementName;
 			this.statementType = statementType;
 		}
 		currentStatementType = statementType;
 		LOG.debugf("%s << begin [level=%s, statement=%s]", statementName, level, this.statementTypeName);
 	}
 
 	private void beforeStatementCompletion(String statementName) {
         LOG.debugf("%s : finishing up [level=%s, statement=%s]", statementName, level, this.statementTypeName);
 	}
 
 	private void afterStatementCompletion(String statementName) {
         LOG.debugf("%s >> end [level=%s, statement=%s]", statementName, level, this.statementTypeName);
 		level--;
 	}
 
 	private void handleClauseStart(int clauseType) {
 		currentClauseType = clauseType;
 		if ( level == 1 ) {
 			currentTopLevelClauseType = clauseType;
 		}
 	}
 
 	///////////////////////////////////////////////////////////////////////////
 	// NOTE: The real implementations for the following are in the subclass.
 
 	protected void evaluateAssignment(AST eq) throws SemanticException { }
 	
 	/** Pre-process the from clause input tree. **/
 	protected void prepareFromClauseInputTree(AST fromClauseInput) {}
 
 	/** Sets the current 'FROM' context. **/
 	protected void pushFromClause(AST fromClause,AST inputFromNode) {}
 
 	protected AST createFromElement(String path,AST alias,AST propertyFetch) throws SemanticException {
 		return null;
 	}
 
 	protected void createFromJoinElement(AST path,AST alias,int joinType,AST fetch,AST propertyFetch,AST with) throws SemanticException {}
 
 	protected AST createFromFilterElement(AST filterEntity,AST alias) throws SemanticException	{
 		return null;
 	}
 
 	protected void processQuery(AST select,AST query) throws SemanticException { }
 
 	protected void postProcessUpdate(AST update) throws SemanticException { }
 
 	protected void postProcessDelete(AST delete) throws SemanticException { }
 
 	protected void postProcessInsert(AST insert) throws SemanticException { }
 
 	protected void beforeSelectClause() throws SemanticException { }
 
 	protected void processIndex(AST indexOp) throws SemanticException { }
 
 	protected void processConstant(AST constant) throws SemanticException { }
 
 	protected void processBoolean(AST constant) throws SemanticException { }
 
 	protected void processNumericLiteral(AST literal) throws SemanticException { }
 
 	protected void resolve(AST node) throws SemanticException { }
 
 	protected void resolveSelectExpression(AST dotNode) throws SemanticException { }
 
 	protected void processFunction(AST functionCall,boolean inSelect) throws SemanticException { }
 
 	protected void processAggregation(AST node, boolean inSelect) throws SemanticException { }
 
 	protected void processConstructor(AST constructor) throws SemanticException { }
 
 	protected AST generateNamedParameter(AST delimiterNode, AST nameNode) throws SemanticException {
 		return #( [NAMED_PARAM, nameNode.getText()] );
 	}
 
 	protected AST generatePositionalParameter(AST inputNode) throws SemanticException {
 		return #( [PARAM, "?"] );
 	}
 
 	protected void lookupAlias(AST ident) throws SemanticException { }
 
 	protected void setAlias(AST selectExpr, AST ident) { }
 
 	protected boolean isOrderExpressionResultVariableRef(AST ident) throws SemanticException {
 		return false;
 	}
 
 	protected void handleResultVariableRef(AST resultVariableRef) throws SemanticException {
 	}
 
 	protected AST lookupProperty(AST dot,boolean root,boolean inSelect) throws SemanticException {
 		return dot;
 	}
 
 	protected boolean isNonQualifiedPropertyRef(AST ident) { return false; }
 
 	protected AST lookupNonQualifiedProperty(AST property) throws SemanticException { return property; }
 
 	protected void setImpliedJoinType(int joinType) { }
 
 	protected AST createIntoClause(String path, AST propertySpec) throws SemanticException {
 		return null;
 	};
 
 	protected void prepareVersioned(AST updateNode, AST versionedNode) throws SemanticException {}
 
 	protected void prepareLogicOperator(AST operator) throws SemanticException { }
 
 	protected void prepareArithmeticOperator(AST operator) throws SemanticException { }
 
     protected void processMapComponentReference(AST node) throws SemanticException { }
 
 	protected void validateMapPropertyExpression(AST node) throws SemanticException { }
 }
 
 // The main statement rule.
 statement
 	: selectStatement | updateStatement | deleteStatement | insertStatement
 	;
 
 selectStatement
 	: query
 	;
 
 // Cannot use just the fromElement rule here in the update and delete queries
 // because fromElement essentially relies on a FromClause already having been
 // built :(
 updateStatement!
 	: #( u:UPDATE { beforeStatement( "update", UPDATE ); } (v:VERSIONED)? f:fromClause s:setClause (w:whereClause)? ) {
 		#updateStatement = #(#u, #f, #s, #w);
 		beforeStatementCompletion( "update" );
 		prepareVersioned( #updateStatement, #v );
 		postProcessUpdate( #updateStatement );
 		afterStatementCompletion( "update" );
 	}
 	;
 
 deleteStatement
 	: #( DELETE { beforeStatement( "delete", DELETE ); } fromClause (whereClause)? ) {
 		beforeStatementCompletion( "delete" );
 		postProcessDelete( #deleteStatement );
 		afterStatementCompletion( "delete" );
 	}
 	;
 
 insertStatement
 	// currently only "INSERT ... SELECT ..." statements supported;
 	// do we also need support for "INSERT ... VALUES ..."?
 	//
 	: #( INSERT { beforeStatement( "insert", INSERT ); } intoClause query ) {
 		beforeStatementCompletion( "insert" );
 		postProcessInsert( #insertStatement );
 		afterStatementCompletion( "insert" );
 	}
 	;
 
 intoClause! {
 		String p = null;
 	}
 	: #( INTO { handleClauseStart( INTO ); } (p=path) ps:insertablePropertySpec ) {
 		#intoClause = createIntoClause(p, ps);
 	}
 	;
 
 insertablePropertySpec
 	: #( RANGE (IDENT)+ )
 	;
 
 setClause
 	: #( SET { handleClauseStart( SET ); } (assignment)* )
 	;
 
 assignment
 	// Note: the propertyRef here needs to be resolved
 	// *before* we evaluate the newValue rule...
 	: #( EQ (p:propertyRef) { resolve(#p); } (newValue) ) {
 		evaluateAssignment( #assignment );
 	}
 	;
 
 // For now, just use expr.  Revisit after ejb3 solidifies this.
 newValue
 	: expr | query
 	;
 
 // The query / subquery rule. Pops the current 'from node' context 
 // (list of aliases).
 query!
 	: #( QUERY { beforeStatement( "select", SELECT ); }
 			// The first phase places the FROM first to make processing the SELECT simpler.
 			#(SELECT_FROM
 				f:fromClause
 				(s:selectClause)?
 			)
 			(w:whereClause)?
 			(g:groupClause)?
 			(o:orderClause)?
 		) {
 		// Antlr note: #x_in refers to the input AST, #x refers to the output AST
 		#query = #([SELECT,"SELECT"], #s, #f, #w, #g, #o);
 		beforeStatementCompletion( "select" );
 		processQuery( #s, #query );
 		afterStatementCompletion( "select" );
 	}
 	;
 
 orderClause
 	: #(ORDER { handleClauseStart( ORDER ); } orderExprs)
 	;
 
 orderExprs
 	: orderExpr ( ASCENDING | DESCENDING )? (orderExprs)?
 	;
 
 orderExpr
 	: { isOrderExpressionResultVariableRef( _t ) }? resultVariableRef
 	| expr
 	;
 
 resultVariableRef!
 	: i:identifier {
 		// Create a RESULT_VARIABLE_REF node instead of an IDENT node.
 		#resultVariableRef = #([RESULT_VARIABLE_REF, i.getText()]);
 		handleResultVariableRef(#resultVariableRef);
 	}
 	;
 
 groupClause
 	: #(GROUP { handleClauseStart( GROUP ); } (expr)+ ( #(HAVING logicalExpr) )? )
 	;
 
 selectClause!
 	: #(SELECT { handleClauseStart( SELECT ); beforeSelectClause(); } (d:DISTINCT)? x:selectExprList ) {
 		#selectClause = #([SELECT_CLAUSE,"{select clause}"], #d, #x);
 	}
 	;
 
 selectExprList {
 		boolean oldInSelect = inSelect;
 		inSelect = true;
 	}
 	: ( selectExpr | aliasedSelectExpr )+ {
 		inSelect = oldInSelect;
 	}
 	;
 
 aliasedSelectExpr!
 	: #(AS se:selectExpr i:identifier) {
 		setAlias(#se,#i);
 		#aliasedSelectExpr = #se;
 	}
 	;
 
 selectExpr
 	: p:propertyRef					{ resolveSelectExpression(#p); }
 	| #(ALL ar2:aliasRef) 			{ resolveSelectExpression(#ar2); #selectExpr = #ar2; }
 	| #(OBJECT ar3:aliasRef)		{ resolveSelectExpression(#ar3); #selectExpr = #ar3; }
 	| con:constructor 				{ processConstructor(#con); }
 	| functionCall
 	| count
 	| collectionFunction			// elements() or indices()
 	| literal
 	| arithmeticExpr
 	| query
 	;
 
 count
 	: #(COUNT ( DISTINCT | ALL )? ( aggregateExpr | ROW_STAR ) )
 	;
 
 constructor
 	{ String className = null; }
 	: #(CONSTRUCTOR className=path ( selectExpr | aliasedSelectExpr )* )
 	;
 
 aggregateExpr
 	: expr //p:propertyRef { resolve(#p); }
 	| collectionFunction
 	;
 
 // Establishes the list of aliases being used by this query.
 fromClause {
 		// NOTE: This references the INPUT AST! (see http://www.antlr.org/doc/trees.html#Action%20Translation)
 		// the ouput AST (#fromClause) has not been built yet.
 		prepareFromClauseInputTree(#fromClause_in);
 	}
 	: #(f:FROM { pushFromClause(#fromClause,f); handleClauseStart( FROM ); } fromElementList )
 	;
 
 fromElementList {
 		boolean oldInFrom = inFrom;
 		inFrom = true;
 		}
 	: (fromElement)+ {
 		inFrom = oldInFrom;
 		}
 	;
 
 fromElement! {
 	String p = null;
 	}
 	// A simple class name, alias element.
 	: #(RANGE p=path (a:ALIAS)? (pf:FETCH)? ) {
 		#fromElement = createFromElement(p,a, pf);
 	}
 	| je:joinElement {
 		#fromElement = #je;
 	}
 	// A from element created due to filter compilation
 	| fe:FILTER_ENTITY a3:ALIAS {
 		#fromElement = createFromFilterElement(fe,a3);
 	}
 	;
 
 joinElement! {
 		int j = INNER;
 	}
 	// A from element with a join.  This time, the 'path' should be treated as an AST
 	// and resolved (like any path in a WHERE clause).   Make sure all implied joins
 	// generated by the property ref use the join type, if it was specified.
 	: #(JOIN (j=joinType { setImpliedJoinType(j); } )? (f:FETCH)? ref:propertyRef (a:ALIAS)? (pf:FETCH)? (with:WITH)? ) {
 		//createFromJoinElement(#ref,a,j,f, pf);
 		createFromJoinElement(#ref,a,j,f, pf, with);
 		setImpliedJoinType(INNER);	// Reset the implied join type.
 	}
 	;
 
 // Returns an node type integer that represents the join type
 // tokens.
 joinType returns [int j] {
 	j = INNER;
 	}
 	: ( (left:LEFT | right:RIGHT) (outer:OUTER)? ) {
 		if (left != null)       j = LEFT_OUTER;
 		else if (right != null) j = RIGHT_OUTER;
 		else if (outer != null) j = RIGHT_OUTER;
 	}
 	| FULL {
 		j = FULL;
 	}
 	| INNER {
 		j = INNER;
 	}
 	;
 
 // Matches a path and returns the normalized string for the path (usually
 // fully qualified a class name).
 path returns [String p] {
 	p = "???";
 	String x = "?x?";
 	}
 	: a:identifier { p = a.getText(); }
 	| #(DOT x=path y:identifier) {
 			StringBuffer buf = new StringBuffer();
 			buf.append(x).append(".").append(y.getText());
 			p = buf.toString();
 		}
 	;
 
 // Returns a path as a single identifier node.
 pathAsIdent {
     String text = "?text?";
     }
     : text=path {
         #pathAsIdent = #([IDENT,text]);
     }
     ;
 
 withClause
 	// Note : this is used internally from the HqlSqlWalker to
 	// parse the node recognized with the with keyword earlier.
 	// Done this way because it relies on the join it "qualifies"
 	// already having been processed, which would not be the case
 	// if withClause was simply referenced from the joinElement
 	// rule during recognition...
 	: #(w:WITH { handleClauseStart( WITH ); } b:logicalExpr ) {
 		#withClause = #(w , #b);
 	}
 	;
 
 whereClause
 	: #(w:WHERE { handleClauseStart( WHERE ); } b:logicalExpr ) {
 		// Use the *output* AST for the boolean expression!
 		#whereClause = #(w , #b);
 	}
 	;
 
 logicalExpr
 	: #(AND logicalExpr logicalExpr)
 	| #(OR logicalExpr logicalExpr)
 	| #(NOT logicalExpr)
 	| comparisonExpr
 	;
 
 // TODO: Add any other comparison operators here.
 comparisonExpr
 	:
 	( #(EQ exprOrSubquery exprOrSubquery)
 	| #(NE exprOrSubquery exprOrSubquery)
 	| #(LT exprOrSubquery exprOrSubquery)
 	| #(GT exprOrSubquery exprOrSubquery)
 	| #(LE exprOrSubquery exprOrSubquery)
 	| #(GE exprOrSubquery exprOrSubquery)
 	| #(LIKE exprOrSubquery expr ( #(ESCAPE expr) )? )
 	| #(NOT_LIKE exprOrSubquery expr ( #(ESCAPE expr) )? )
 	| #(BETWEEN exprOrSubquery exprOrSubquery exprOrSubquery)
 	| #(NOT_BETWEEN exprOrSubquery exprOrSubquery exprOrSubquery)
 	| #(IN exprOrSubquery inRhs )
 	| #(NOT_IN exprOrSubquery inRhs )
 	| #(IS_NULL exprOrSubquery)
 	| #(IS_NOT_NULL exprOrSubquery)
 //	| #(IS_TRUE expr)
 //	| #(IS_FALSE expr)
 	| #(EXISTS ( expr | collectionFunctionOrSubselect ) )
 	) {
 	    prepareLogicOperator( #comparisonExpr );
 	}
 	;
 
 inRhs
 	: #(IN_LIST ( collectionFunctionOrSubselect | ( (expr)* ) ) )
 	;
 
 exprOrSubquery
 	: expr
 	| query
 	| #(ANY collectionFunctionOrSubselect)
 	| #(ALL collectionFunctionOrSubselect)
 	| #(SOME collectionFunctionOrSubselect)
 	;
 	
 collectionFunctionOrSubselect
 	: collectionFunction
 	| query
 	;
 	
 expr
 	: ae:addrExpr [ true ] { resolve(#ae); }	// Resolve the top level 'address expression'
 	| #( VECTOR_EXPR (expr)* )
 	| constant
 	| arithmeticExpr
 	| functionCall							// Function call, not in the SELECT clause.
 	| parameter
 	| count										// Count, not in the SELECT clause.
 	;
 
 arithmeticExpr
     : #(PLUS exprOrSubquery exprOrSubquery)         { prepareArithmeticOperator( #arithmeticExpr ); }
     | #(MINUS exprOrSubquery exprOrSubquery)        { prepareArithmeticOperator( #arithmeticExpr ); }
     | #(DIV exprOrSubquery exprOrSubquery)          { prepareArithmeticOperator( #arithmeticExpr ); }
     | #(MOD exprOrSubquery exprOrSubquery)          { prepareArithmeticOperator( #arithmeticExpr ); }
     | #(STAR exprOrSubquery exprOrSubquery)         { prepareArithmeticOperator( #arithmeticExpr ); }
 //	| #(CONCAT expr (expr)+ )   { prepareArithmeticOperator( #arithmeticExpr ); }
 	| #(UNARY_MINUS expr)       { prepareArithmeticOperator( #arithmeticExpr ); }
 	| caseExpr
 	;
 
 caseExpr
 	: #(CASE { inCase = true; } (#(WHEN logicalExpr expr))+ (#(ELSE expr))?) { inCase = false; }
 	| #(CASE2 { inCase = true; } expr (#(WHEN expr expr))+ (#(ELSE expr))?) { inCase = false; }
 	;
 
 //TODO: I don't think we need this anymore .. how is it different to 
 //      maxelements, etc, which are handled by functionCall
 collectionFunction
 	: #(e:ELEMENTS {inFunctionCall=true;} p1:propertyRef { resolve(#p1); } ) 
 		{ processFunction(#e,inSelect); } {inFunctionCall=false;}
 	| #(i:INDICES {inFunctionCall=true;} p2:propertyRef { resolve(#p2); } ) 
 		{ processFunction(#i,inSelect); } {inFunctionCall=false;}
 	;
 
 functionCall
 	: #(METHOD_CALL  {inFunctionCall=true;} pathAsIdent ( #(EXPR_LIST (exprOrSubquery)* ) )? ) {
         processFunction( #functionCall, inSelect );
         inFunctionCall=false;
     }
 	| #(AGGREGATE aggregateExpr )
 	;
 
 constant
 	: literal
 	| NULL
 	| TRUE { processBoolean(#constant); } 
 	| FALSE { processBoolean(#constant); }
 	| JAVA_CONSTANT
 	;
 
 literal
 	: NUM_INT { processNumericLiteral( #literal ); }
 	| NUM_LONG { processNumericLiteral( #literal ); }
 	| NUM_FLOAT { processNumericLiteral( #literal ); }
 	| NUM_DOUBLE { processNumericLiteral( #literal ); }
 	| NUM_BIG_INTEGER { processNumericLiteral( #literal ); }
 	| NUM_BIG_DECIMAL { processNumericLiteral( #literal ); }
 	| QUOTED_STRING
 	;
 
 identifier
 	: (IDENT | WEIRD_IDENT)
 	;
 
 addrExpr! [ boolean root ]
 	: #(d:DOT lhs:addrExprLhs rhs:propertyName )	{
 		// This gives lookupProperty() a chance to transform the tree 
 		// to process collection properties (.elements, etc).
 		#addrExpr = #(#d, #lhs, #rhs);
 		#addrExpr = lookupProperty(#addrExpr,root,false);
 	}
 	| #(i:INDEX_OP lhs2:addrExprLhs rhs2:expr)	{
 		#addrExpr = #(#i, #lhs2, #rhs2);
 		processIndex(#addrExpr);
 	}
 	| p:identifier {
 //		#addrExpr = #p;
 //		resolve(#addrExpr);
 		// In many cases, things other than property-refs are recognized
 		// by this addrExpr rule.  Some of those I have seen:
 		//  1) select-clause from-aliases
 		//  2) sql-functions
 		if ( isNonQualifiedPropertyRef(#p) ) {
 			#addrExpr = lookupNonQualifiedProperty(#p);
 		}
 		else {
 			resolve(#p);
 			#addrExpr = #p;
 		}
 	}
 	;
 
 addrExprLhs
 	: addrExpr [ false ]
 	;
 
 propertyName
 	: identifier
 	| CLASS
 	| ELEMENTS
 	| INDICES
 	;
 
 propertyRef!
 	: mcr:mapComponentReference {
 	    resolve( #mcr );
 	    #propertyRef = #mcr;
 	}
 	| #(d:DOT lhs:propertyRefLhs rhs:propertyName )	{
 		// This gives lookupProperty() a chance to transform the tree to process collection properties (.elements, etc).
 		#propertyRef = #(#d, #lhs, #rhs);
 		#propertyRef = lookupProperty(#propertyRef,false,true);
 	}
 	|
 	p:identifier {
 		// In many cases, things other than property-refs are recognized
 		// by this propertyRef rule.  Some of those I have seen:
 		//  1) select-clause from-aliases
 		//  2) sql-functions
 		if ( isNonQualifiedPropertyRef(#p) ) {
 			#propertyRef = lookupNonQualifiedProperty(#p);
 		}
 		else {
 			resolve(#p);
 			#propertyRef = #p;
 		}
 	}
 	;
 
 propertyRefLhs
 	: propertyRef
 	;
 
 aliasRef!
 	: i:identifier {
 		#aliasRef = #([ALIAS_REF,i.getText()]);	// Create an ALIAS_REF node instead of an IDENT node.
 		lookupAlias(#aliasRef);
 		}
 	;
 
 mapComponentReference
     : #( KEY mapPropertyExpression )
     | #( VALUE mapPropertyExpression )
     | #( ENTRY mapPropertyExpression )
     ;
 
 mapPropertyExpression
     : e:expr {
         validateMapPropertyExpression( #e );
     }
     ;
 
 parameter!
 	: #(c:COLON a:identifier) {
 			// Create a NAMED_PARAM node instead of (COLON IDENT).
 			#parameter = generateNamedParameter( c, a );
 //			#parameter = #([NAMED_PARAM,a.getText()]);
 //			namedParameter(#parameter);
 		}
 	| #(p:PARAM (n:NUM_INT)?) {
 			if ( n != null ) {
 				// An ejb3-style "positional parameter", which we handle internally as a named-param
 				#parameter = generateNamedParameter( p, n );
 //				#parameter = #([NAMED_PARAM,n.getText()]);
 //				namedParameter(#parameter);
 			}
 			else {
 				#parameter = generatePositionalParameter( p );
 //				#parameter = #([PARAM,"?"]);
 //				positionalParameter(#parameter);
 			}
 		}
 	;
 
 numericInteger
 	: NUM_INT
 	;
diff --git a/hibernate-core/src/main/java/org/hibernate/AssertionFailure.java b/hibernate-core/src/main/java/org/hibernate/AssertionFailure.java
index 931c524709..cf0ee1a7e7 100644
--- a/hibernate-core/src/main/java/org/hibernate/AssertionFailure.java
+++ b/hibernate-core/src/main/java/org/hibernate/AssertionFailure.java
@@ -1,49 +1,51 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate;
+
 import org.jboss.logging.Logger;
 
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
  * Indicates failure of an assertion: a possible bug in Hibernate.
  *
  * @author Gavin King
  */
 public class AssertionFailure extends RuntimeException {
 
     private static final long serialVersionUID = 1L;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, AssertionFailure.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, AssertionFailure.class.getName());
 
     public AssertionFailure( String s ) {
         super(s);
         LOG.failed(this);
     }
 
     public AssertionFailure( String s,
                              Throwable t ) {
         super(s, t);
         LOG.failed(t);
     }
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/LazyInitializationException.java b/hibernate-core/src/main/java/org/hibernate/LazyInitializationException.java
index 5238066dfd..b2f1436559 100644
--- a/hibernate-core/src/main/java/org/hibernate/LazyInitializationException.java
+++ b/hibernate-core/src/main/java/org/hibernate/LazyInitializationException.java
@@ -1,53 +1,55 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate;
 import org.jboss.logging.Logger;
 
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
  * Indicates access to unfetched data outside of a session context.
  * For example, when an uninitialized proxy or collection is accessed
  * after the session was closed.
  *
  * @see Hibernate#initialize(java.lang.Object)
  * @see Hibernate#isInitialized(java.lang.Object)
  * @author Gavin King
  */
 public class LazyInitializationException extends HibernateException {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        LazyInitializationException.class.getName());
 
 	public LazyInitializationException(String msg) {
 		super(msg);
         LOG.error(msg, this);
 	}
 
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/bytecode/internal/javassist/BytecodeProviderImpl.java b/hibernate-core/src/main/java/org/hibernate/bytecode/internal/javassist/BytecodeProviderImpl.java
index 9238dc9749..a913c43765 100644
--- a/hibernate-core/src/main/java/org/hibernate/bytecode/internal/javassist/BytecodeProviderImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/bytecode/internal/javassist/BytecodeProviderImpl.java
@@ -1,103 +1,103 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.bytecode.internal.javassist;
 
 import java.lang.reflect.Modifier;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.bytecode.buildtime.spi.ClassFilter;
 import org.hibernate.bytecode.buildtime.spi.FieldFilter;
 import org.hibernate.bytecode.spi.BytecodeProvider;
 import org.hibernate.bytecode.spi.ClassTransformer;
 import org.hibernate.bytecode.spi.ProxyFactoryFactory;
 import org.hibernate.bytecode.spi.ReflectionOptimizer;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * Bytecode provider implementation for Javassist.
  *
  * @author Steve Ebersole
  */
 public class BytecodeProviderImpl implements BytecodeProvider {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BytecodeProviderImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BytecodeProviderImpl.class.getName());
 
 	public ProxyFactoryFactory getProxyFactoryFactory() {
 		return new ProxyFactoryFactoryImpl();
 	}
 
 	public ReflectionOptimizer getReflectionOptimizer(
 			Class clazz,
 	        String[] getterNames,
 	        String[] setterNames,
 	        Class[] types) {
 		FastClass fastClass;
 		BulkAccessor bulkAccessor;
 		try {
 			fastClass = FastClass.create( clazz );
 			bulkAccessor = BulkAccessor.create( clazz, getterNames, setterNames, types );
 			if ( !clazz.isInterface() && !Modifier.isAbstract( clazz.getModifiers() ) ) {
 				if ( fastClass == null ) {
 					bulkAccessor = null;
 				}
 				else {
 					//test out the optimizer:
 					Object instance = fastClass.newInstance();
 					bulkAccessor.setPropertyValues( instance, bulkAccessor.getPropertyValues( instance ) );
 				}
 			}
 		}
 		catch ( Throwable t ) {
 			fastClass = null;
 			bulkAccessor = null;
             if (LOG.isDebugEnabled()) {
                 int index = 0;
                 if (t instanceof BulkAccessorException) index = ((BulkAccessorException)t).getIndex();
                 if (index >= 0) LOG.debugf("Reflection optimizer disabled for: %s [%s: %s (property %s)",
                                            clazz.getName(),
                                            StringHelper.unqualify(t.getClass().getName()),
                                            t.getMessage(),
                                            setterNames[index]);
                 else LOG.debugf("Reflection optimizer disabled for: %s [%s: %s",
                                 clazz.getName(),
                                 StringHelper.unqualify(t.getClass().getName()),
                                 t.getMessage());
             }
 		}
 
 		if ( fastClass != null && bulkAccessor != null ) {
 			return new ReflectionOptimizerImpl(
 					new InstantiationOptimizerAdapter( fastClass ),
 			        new AccessOptimizerAdapter( bulkAccessor, clazz )
 			);
 		}
         return null;
 	}
 
 	public ClassTransformer getTransformer(ClassFilter classFilter, FieldFilter fieldFilter) {
 		return new JavassistClassTransformer( classFilter, fieldFilter );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/bytecode/internal/javassist/JavassistClassTransformer.java b/hibernate-core/src/main/java/org/hibernate/bytecode/internal/javassist/JavassistClassTransformer.java
index 5334b24786..8d4e1b7e7e 100644
--- a/hibernate-core/src/main/java/org/hibernate/bytecode/internal/javassist/JavassistClassTransformer.java
+++ b/hibernate-core/src/main/java/org/hibernate/bytecode/internal/javassist/JavassistClassTransformer.java
@@ -1,134 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.bytecode.internal.javassist;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.DataInputStream;
 import java.io.DataOutputStream;
 import java.io.IOException;
 import java.security.ProtectionDomain;
 
 import javassist.bytecode.ClassFile;
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.bytecode.buildtime.spi.ClassFilter;
 import org.hibernate.bytecode.spi.AbstractClassTransformerImpl;
 
 /**
  * Enhance the classes allowing them to implements InterceptFieldEnabled
  * This interface is then used by Hibernate for some optimizations.
  *
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  */
 public class JavassistClassTransformer extends AbstractClassTransformerImpl {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        JavassistClassTransformer.class.getName());
 
 	public JavassistClassTransformer(ClassFilter classFilter, org.hibernate.bytecode.buildtime.spi.FieldFilter fieldFilter) {
 		super( classFilter, fieldFilter );
 	}
 
 	@Override
     protected byte[] doTransform(
 			ClassLoader loader,
 			String className,
 			Class classBeingRedefined,
 			ProtectionDomain protectionDomain,
 			byte[] classfileBuffer) {
 		ClassFile classfile;
 		try {
 			// WARNING: classfile only
 			classfile = new ClassFile( new DataInputStream( new ByteArrayInputStream( classfileBuffer ) ) );
 		}
 		catch (IOException e) {
             LOG.unableToBuildEnhancementMetamodel(className);
 			return classfileBuffer;
 		}
 		FieldTransformer transformer = getFieldTransformer( classfile );
 		if ( transformer != null ) {
             LOG.debugf("Enhancing %s", className);
 			DataOutputStream out = null;
 			try {
 				transformer.transform( classfile );
 				ByteArrayOutputStream byteStream = new ByteArrayOutputStream();
 				out = new DataOutputStream( byteStream );
 				classfile.write( out );
 				return byteStream.toByteArray();
 			}
 			catch (Exception e) {
                 LOG.unableToTransformClass(e.getMessage());
 				throw new HibernateException( "Unable to transform class: " + e.getMessage() );
 			}
 			finally {
 				try {
 					if ( out != null ) out.close();
 				}
 				catch (IOException e) {
 					//swallow
 				}
 			}
 		}
 		return classfileBuffer;
 	}
 
 	protected FieldTransformer getFieldTransformer(final ClassFile classfile) {
 		if ( alreadyInstrumented( classfile ) ) {
 			return null;
 		}
 		return new FieldTransformer(
 				new FieldFilter() {
 					public boolean handleRead(String desc, String name) {
 						return fieldFilter.shouldInstrumentField( classfile.getName(), name );
 					}
 
 					public boolean handleWrite(String desc, String name) {
 						return fieldFilter.shouldInstrumentField( classfile.getName(), name );
 					}
 
 					public boolean handleReadAccess(String fieldOwnerClassName, String fieldName) {
 						return fieldFilter.shouldTransformFieldAccess( classfile.getName(), fieldOwnerClassName, fieldName );
 					}
 
 					public boolean handleWriteAccess(String fieldOwnerClassName, String fieldName) {
 						return fieldFilter.shouldTransformFieldAccess( classfile.getName(), fieldOwnerClassName, fieldName );
 					}
 				}
 		);
 	}
 
 	private boolean alreadyInstrumented(ClassFile classfile) {
 		String[] intfs = classfile.getInterfaces();
 		for ( int i = 0; i < intfs.length; i++ ) {
 			if ( FieldHandled.class.getName().equals( intfs[i] ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/AbstractJndiBoundCacheProvider.java b/hibernate-core/src/main/java/org/hibernate/cache/AbstractJndiBoundCacheProvider.java
index 37c951e1db..6dacd4b163 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/AbstractJndiBoundCacheProvider.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/AbstractJndiBoundCacheProvider.java
@@ -1,109 +1,111 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.cache;
 
 import java.util.Properties;
 import javax.naming.Context;
 import javax.naming.InitialContext;
 import javax.naming.NamingException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.jndi.JndiHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * Support for CacheProvider implementations which are backed by caches bound
  * into JNDI namespace.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractJndiBoundCacheProvider implements CacheProvider {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractJndiBoundCacheProvider.class.getName());
 
 	private Object cache;
 
 	protected void prepare(Properties properties) {
 		// Do nothing; subclasses may override.
 	}
 
 	protected void release() {
 		// Do nothing; subclasses may override.
 	}
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation during SessionFactory
 	 * construction.
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public final void start(Properties properties) throws CacheException {
 		String jndiNamespace = properties.getProperty( Environment.CACHE_NAMESPACE );
 		if ( StringHelper.isEmpty( jndiNamespace ) ) {
 			throw new CacheException( "No JNDI namespace specified for cache" );
 		}
 		cache = locateCache( jndiNamespace, JndiHelper.extractJndiProperties( properties ) );
 		prepare( properties );
 	}
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache
 	 * implementation during SessionFactory.close().
 	 */
 	public final void stop() {
 		release();
 		cache = null;
 	}
 
 	private Object locateCache(String jndiNamespace, Properties jndiProperties) {
 
 		Context ctx = null;
 		try {
 			ctx = new InitialContext( jndiProperties );
 			return ctx.lookup( jndiNamespace );
 		}
 		catch (NamingException ne) {
 			String msg = "Unable to retreive Cache from JNDI [" + jndiNamespace + "]";
             LOG.unableToRetrieveCache(jndiNamespace, ne.getMessage());
 			throw new CacheException( msg );
 		}
 		finally {
 			if ( ctx != null ) {
 				try {
 					ctx.close();
 				}
 				catch( NamingException ne ) {
                     LOG.unableToReleaseContext(ne.getMessage());
 				}
 			}
 		}
 	}
 
 	public Object getCache() {
 		return cache;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/NonstrictReadWriteCache.java b/hibernate-core/src/main/java/org/hibernate/cache/NonstrictReadWriteCache.java
index f23f7f8e81..f81ffa52d0 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/NonstrictReadWriteCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/NonstrictReadWriteCache.java
@@ -1,174 +1,176 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.cache;
 import java.util.Comparator;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cache.access.SoftLock;
+
 import org.jboss.logging.Logger;
 
 /**
  * Caches data that is sometimes updated without ever locking the cache.
  * If concurrent access to an item is possible, this concurrency strategy
  * makes no guarantee that the item returned from the cache is the latest
  * version available in the database. Configure your cache timeout accordingly!
  * This is an "asynchronous" concurrency strategy.
  *
  * @author Gavin King
  * @see ReadWriteCache for a much stricter algorithm
  */
 public class NonstrictReadWriteCache implements CacheConcurrencyStrategy {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        NonstrictReadWriteCache.class.getName());
 
 	private Cache cache;
 
 	public NonstrictReadWriteCache() {
 	}
 
 	public void setCache(Cache cache) {
 		this.cache = cache;
 	}
 
 	public Cache getCache() {
 		return cache;
 	}
 
 	/**
 	 * Get the most recent version, if available.
 	 */
 	public Object get(Object key, long txTimestamp) throws CacheException {
         LOG.debugf("Cache lookup: %s", key);
 
 		Object result = cache.get( key );
         if (result != null) LOG.debugf("Cache hit: %s", key);
         else LOG.debugf("Cache miss: %s", key);
 		return result;
 	}
 
 	/**
 	 * Add an item to the cache.
 	 */
 	public boolean put(
 			Object key,
 	        Object value,
 	        long txTimestamp,
 	        Object version,
 	        Comparator versionComparator,
 	        boolean minimalPut) throws CacheException {
 		if ( minimalPut && cache.get( key ) != null ) {
             LOG.debugf("Item already cached: %s", key);
 			return false;
 		}
         LOG.debugf("Caching: %s", key);
 
 		cache.put( key, value );
 		return true;
 
 	}
 
 	/**
 	 * Do nothing.
 	 *
 	 * @return null, no lock
 	 */
 	public SoftLock lock(Object key, Object version) throws CacheException {
 		return null;
 	}
 
 	public void remove(Object key) throws CacheException {
         LOG.debugf("Removing: %s", key);
 		cache.remove( key );
 	}
 
 	public void clear() throws CacheException {
         LOG.debugf("Clearing");
 		cache.clear();
 	}
 
 	public void destroy() {
 		try {
 			cache.destroy();
 		}
 		catch ( Exception e ) {
             LOG.unableToDestroyCache(e.getMessage());
 		}
 	}
 
 	/**
 	 * Invalidate the item
 	 */
 	public void evict(Object key) throws CacheException {
         LOG.debugf("Invalidating: %s", key);
 		cache.remove( key );
 	}
 
 	/**
 	 * Invalidate the item
 	 */
 	public boolean insert(Object key, Object value, Object currentVersion) {
 		return false;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) {
 		evict( key );
 		return false;
 	}
 
 	/**
 	 * Invalidate the item (again, for safety).
 	 */
 	public void release(Object key, SoftLock lock) throws CacheException {
         LOG.debugf("Invalidating: %s", key);
 		cache.remove( key );
 	}
 
 	/**
 	 * Invalidate the item (again, for safety).
 	 */
 	public boolean afterUpdate(Object key, Object value, Object version, SoftLock lock) throws CacheException {
 		release( key, lock );
 		return false;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
 		return false;
 	}
 
 	public String getRegionName() {
 		return cache.getRegionName();
 	}
 
 	@Override
     public String toString() {
 		return cache + "(nonstrict-read-write)";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/ReadOnlyCache.java b/hibernate-core/src/main/java/org/hibernate/cache/ReadOnlyCache.java
index b1b6ac37d2..8c0fbc35cb 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/ReadOnlyCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/ReadOnlyCache.java
@@ -1,161 +1,162 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.cache;
 import java.util.Comparator;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cache.access.SoftLock;
+
 import org.jboss.logging.Logger;
 
 /**
  * Caches data that is never updated.
  * @see CacheConcurrencyStrategy
  */
 public class ReadOnlyCache implements CacheConcurrencyStrategy {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ReadOnlyCache.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ReadOnlyCache.class.getName());
 
 	private Cache cache;
 
 	public ReadOnlyCache() {}
 
 	public void setCache(Cache cache) {
 		this.cache=cache;
 	}
 
 	public Cache getCache() {
 		return cache;
 	}
 
 	public String getRegionName() {
 		return cache.getRegionName();
 	}
 
 	public synchronized Object get(Object key, long timestamp) throws CacheException {
 		Object result = cache.get(key);
         if (result != null) LOG.debugf("Cache hit: %s", key);
 		return result;
 	}
 
 	/**
 	 * Unsupported!
 	 */
 	public SoftLock lock(Object key, Object version) {
         LOG.invalidEditOfReadOnlyItem(key);
 		throw new UnsupportedOperationException("Can't write to a readonly object");
 	}
 
 	public synchronized boolean put(
 			Object key,
 			Object value,
 			long timestamp,
 			Object version,
 			Comparator versionComparator,
 			boolean minimalPut)
 	throws CacheException {
 		if ( minimalPut && cache.get(key)!=null ) {
             LOG.debugf("Item already cached: %s", key);
 			return false;
 		}
         LOG.debugf("Caching: %s", key);
 		cache.put(key, value);
 		return true;
 	}
 
 	/**
 	 * Unsupported!
 	 */
 	public void release(Object key, SoftLock lock) {
         LOG.invalidEditOfReadOnlyItem(key);
 		//throw new UnsupportedOperationException("Can't write to a readonly object");
 	}
 
 	public void clear() throws CacheException {
 		cache.clear();
 	}
 
 	public void remove(Object key) throws CacheException {
 		cache.remove(key);
 	}
 
 	public void destroy() {
 		try {
 			cache.destroy();
 		}
 		catch (Exception e) {
             LOG.unableToDestroyCache(e.getMessage());
 		}
 	}
 
 	/**
 	 * Unsupported!
 	 */
 	public boolean afterUpdate(Object key, Object value, Object version, SoftLock lock) throws CacheException {
         LOG.invalidEditOfReadOnlyItem(key);
 		throw new UnsupportedOperationException("Can't write to a readonly object");
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
         LOG.debugf("Caching after insert: %s", key);
 		cache.update(key, value);
 		return true;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public void evict(Object key) throws CacheException {
 		// noop
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean insert(Object key, Object value, Object currentVersion) {
 		return false;
 	}
 
 	/**
 	 * Unsupported!
 	 */
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) {
         LOG.invalidEditOfReadOnlyItem(key);
 		throw new UnsupportedOperationException("Can't write to a readonly object");
 	}
 
 	@Override
     public String toString() {
 		return cache + "(read-only)";
 	}
 
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/ReadWriteCache.java b/hibernate-core/src/main/java/org/hibernate/cache/ReadWriteCache.java
index f2b6bf2486..552afb9b4a 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/ReadWriteCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/ReadWriteCache.java
@@ -1,496 +1,498 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.cache;
 import java.io.Serializable;
 import java.util.Comparator;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cache.access.SoftLock;
+
 import org.jboss.logging.Logger;
 
 /**
  * Caches data that is sometimes updated while maintaining the semantics of
  * "read committed" isolation level. If the database is set to "repeatable
  * read", this concurrency strategy <em>almost</em> maintains the semantics.
  * Repeatable read isolation is compromised in the case of concurrent writes.
  * This is an "asynchronous" concurrency strategy.<br>
  * <br>
  * If this strategy is used in a cluster, the underlying cache implementation
  * must support distributed hard locks (which are held only momentarily). This
  * strategy also assumes that the underlying cache implementation does not do
  * asynchronous replication and that state has been fully replicated as soon
  * as the lock is released.
  *
  * @see NonstrictReadWriteCache for a faster algorithm
  * @see CacheConcurrencyStrategy
  */
 public class ReadWriteCache implements CacheConcurrencyStrategy {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ReadWriteCache.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ReadWriteCache.class.getName());
 
 	private Cache cache;
 	private int nextLockId;
 
 	public ReadWriteCache() {}
 
 	public void setCache(Cache cache) {
 		this.cache=cache;
 	}
 
 	public Cache getCache() {
 		return cache;
 	}
 
 	public String getRegionName() {
 		return cache.getRegionName();
 	}
 
 	/**
 	 * Generate an id for a new lock. Uniqueness per cache instance is very
 	 * desirable but not absolutely critical. Must be called from one of the
 	 * synchronized methods of this class.
 	 */
 	private int nextLockId() {
 		if (nextLockId==Integer.MAX_VALUE) nextLockId = Integer.MIN_VALUE;
 		return nextLockId++;
 	}
 
 	/**
 	 * Do not return an item whose timestamp is later than the current
 	 * transaction timestamp. (Otherwise we might compromise repeatable
 	 * read unnecessarily.) Do not return an item which is soft-locked.
 	 * Always go straight to the database instead.<br>
 	 * <br>
 	 * Note that since reading an item from that cache does not actually
 	 * go to the database, it is possible to see a kind of phantom read
 	 * due to the underlying row being updated after we have read it
 	 * from the cache. This would not be possible in a lock-based
 	 * implementation of repeatable read isolation. It is also possible
 	 * to overwrite changes made and committed by another transaction
 	 * after the current transaction read the item from the cache. This
 	 * problem would be caught by the update-time version-checking, if
 	 * the data is versioned or timestamped.
 	 */
 	public synchronized Object get(Object key, long txTimestamp) throws CacheException {
         LOG.debugf("Cache lookup: %s", key);
 		Lockable lockable = (Lockable)cache.get(key);
 		boolean gettable = lockable != null && lockable.isGettable(txTimestamp);
 		if (gettable) {
             LOG.debugf("Cache hit: %s", key);
             return ((Item)lockable).getValue();
         }
         if (lockable == null) LOG.debugf("Cache miss: %s", key);
         else LOG.debugf("Cached item was locked: %s", key);
         return null;
 	}
 
 	/**
 	 * Stop any other transactions reading or writing this item to/from
 	 * the cache. Send them straight to the database instead. (The lock
 	 * does time out eventually.) This implementation tracks concurrent
 	 * locks of transactions which simultaneously attempt to write to an
 	 * item.
 	 */
 	public synchronized SoftLock lock(Object key, Object version) throws CacheException {
         LOG.debugf("Invalidating: %s", key);
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 			long timeout = cache.nextTimestamp() + cache.getTimeout();
 			final Lock lock = (lockable==null) ?
 				new Lock( timeout, nextLockId(), version ) :
 				lockable.lock( timeout, nextLockId() );
 			cache.update(key, lock);
 			return lock;
 		}
 		finally {
 			cache.unlock(key);
 		}
 
 	}
 
 	/**
 	 * Do not add an item to the cache unless the current transaction
 	 * timestamp is later than the timestamp at which the item was
 	 * invalidated. (Otherwise, a stale item might be re-added if the
 	 * database is operating in repeatable read isolation mode.)
 	 * For versioned data, don't add the item unless it is the later
 	 * version.
 	 */
 	public synchronized boolean put(
 			Object key,
 			Object value,
 			long txTimestamp,
 			Object version,
 			Comparator versionComparator,
 			boolean minimalPut)
 	throws CacheException {
         LOG.debugf("Caching: %s", key);
 
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 
 			boolean puttable = lockable==null ||
 				lockable.isPuttable(txTimestamp, version, versionComparator);
 
 			if (puttable) {
 				cache.put( key, new Item( value, version, cache.nextTimestamp() ) );
                 LOG.debugf("Cached: %s", key);
 				return true;
 			}
             if (lockable.isLock()) LOG.debugf("Cached item was locked: %s", key);
             else LOG.debugf("Item already cached: %s", key);
             return false;
 		}
 		finally {
 			cache.unlock(key);
 		}
 	}
 
 	/**
 	 * decrement a lock and put it back in the cache
 	 */
 	private void decrementLock(Object key, Lock lock) throws CacheException {
 		//decrement the lock
 		lock.unlock( cache.nextTimestamp() );
 		cache.update(key, lock);
 	}
 
 	/**
 	 * Release the soft lock on the item. Other transactions may now
 	 * re-cache the item (assuming that no other transaction holds a
 	 * simultaneous lock).
 	 */
 	public synchronized void release(Object key, SoftLock clientLock) throws CacheException {
         LOG.debugf("Releasing: %s", key);
 
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 			if ( isUnlockable(clientLock, lockable) ) {
 				decrementLock(key, (Lock) lockable);
 			}
 			else {
 				handleLockExpiry(key);
 			}
 		}
 		finally {
 			cache.unlock(key);
 		}
 	}
 
 	void handleLockExpiry(Object key) throws CacheException {
         LOG.expired(key);
 		long ts = cache.nextTimestamp() + cache.getTimeout();
 		// create new lock that times out immediately
 		Lock lock = new Lock( ts, nextLockId(), null );
 		lock.unlock(ts);
 		cache.update(key, lock);
 	}
 
 	public void clear() throws CacheException {
 		cache.clear();
 	}
 
 	public void remove(Object key) throws CacheException {
 		cache.remove(key);
 	}
 
 	public void destroy() {
 		try {
 			cache.destroy();
 		}
 		catch (Exception e) {
             LOG.unableToDestroyCache(e.getMessage());
 		}
 	}
 
 	/**
 	 * Re-cache the updated state, if and only if there there are
 	 * no other concurrent soft locks. Release our lock.
 	 */
 	public synchronized boolean afterUpdate(Object key, Object value, Object version, SoftLock clientLock)
 	throws CacheException {
 
         LOG.debugf("Updating: %s", key);
 
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 			if ( isUnlockable(clientLock, lockable) ) {
 				Lock lock = (Lock) lockable;
 				if ( lock.wasLockedConcurrently() ) {
 					// just decrement the lock, don't recache
 					// (we don't know which transaction won)
 					decrementLock(key, lock);
 					return false;
 				}
                 // recache the updated state
                 cache.update(key, new Item(value, version, cache.nextTimestamp()));
                 LOG.debugf("Updated: %s", key);
                 return true;
 			}
             handleLockExpiry(key);
             return false;
 		}
 		finally {
 			cache.unlock(key);
 		}
 	}
 
 	/**
 	 * Add the new item to the cache, checking that no other transaction has
 	 * accessed the item.
 	 */
 	public synchronized boolean afterInsert(Object key, Object value, Object version)
 	throws CacheException {
 
         LOG.debugf("Inserting: %s", key);
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 			if (lockable==null) {
 				cache.update( key, new Item( value, version, cache.nextTimestamp() ) );
                 LOG.debugf("Inserted: %s", key);
 				return true;
 			}
             return false;
 		}
 		finally {
 			cache.unlock(key);
 		}
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public void evict(Object key) throws CacheException {
 		// noop
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean insert(Object key, Object value, Object currentVersion) {
 		return false;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) {
 		return false;
 	}
 
 	/**
 	 * Is the client's lock commensurate with the item in the cache?
 	 * If it is not, we know that the cache expired the original
 	 * lock.
 	 */
 	private boolean isUnlockable(SoftLock clientLock, Lockable myLock)
 	throws CacheException {
 		//null clientLock is remotely possible but will never happen in practice
 		return myLock!=null &&
 			myLock.isLock() &&
 			clientLock!=null &&
 			( (Lock) clientLock ).getId()==( (Lock) myLock ).getId();
 	}
 
 	public static interface Lockable {
 		public Lock lock(long timeout, int id);
 		public boolean isLock();
 		public boolean isGettable(long txTimestamp);
 		public boolean isPuttable(long txTimestamp, Object newVersion, Comparator comparator);
 	}
 
 	/**
 	 * An item of cached data, timestamped with the time it was cached,.
 	 * @see ReadWriteCache
 	 */
 	public static final class Item implements Serializable, Lockable {
 
 		private final long freshTimestamp;
 		private final Object value;
 		private final Object version;
 
 		public Item(Object value, Object version, long currentTimestamp) {
 			this.value = value;
 			this.version = version;
 			freshTimestamp = currentTimestamp;
 		}
 		/**
 		 * The timestamp on the cached data
 		 */
 		public long getFreshTimestamp() {
 			return freshTimestamp;
 		}
 		/**
 		 * The actual cached data
 		 */
 		public Object getValue() {
 			return value;
 		}
 
 		/**
 		 * Lock the item
 		 */
 		public Lock lock(long timeout, int id) {
 			return new Lock(timeout, id, version);
 		}
 		/**
 		 * Not a lock!
 		 */
 		public boolean isLock() {
 			return false;
 		}
 		/**
 		 * Is this item visible to the timestamped
 		 * transaction?
 		 */
 		public boolean isGettable(long txTimestamp) {
 			return freshTimestamp < txTimestamp;
 		}
 
 		/**
 		 * Don't overwite already cached items
 		 */
 		public boolean isPuttable(long txTimestamp, Object newVersion, Comparator comparator) {
 			// we really could refresh the item if it
 			// is not a lock, but it might be slower
 			//return freshTimestamp < txTimestamp
 			return version!=null && comparator.compare(version, newVersion) < 0;
 		}
 
 		@Override
         public String toString() {
 			return "Item{version=" + version +
 				",freshTimestamp=" + freshTimestamp;
 		}
 	}
 
 	/**
 	 * A soft lock which supports concurrent locking,
 	 * timestamped with the time it was released
 	 * @author Gavin King
 	 */
 	public static final class Lock implements Serializable, Lockable, SoftLock {
 		private long unlockTimestamp = -1;
 		private int multiplicity = 1;
 		private boolean concurrentLock = false;
 		private long timeout;
 		private final int id;
 		private final Object version;
 
 		public Lock(long timeout, int id, Object version) {
 			this.timeout = timeout;
 			this.id = id;
 			this.version = version;
 		}
 
 		public long getUnlockTimestamp() {
 			return unlockTimestamp;
 		}
 		/**
 		 * Increment the lock, setting the
 		 * new lock timeout
 		 */
 		public Lock lock(long timeout, int id) {
 			concurrentLock = true;
 			multiplicity++;
 			this.timeout = timeout;
 			return this;
 		}
 		/**
 		 * Decrement the lock, setting the unlock
 		 * timestamp if now unlocked
 		 * @param currentTimestamp
 		 */
 		public void unlock(long currentTimestamp) {
 			if ( --multiplicity == 0 ) {
 				unlockTimestamp = currentTimestamp;
 			}
 		}
 
 		/**
 		 * Can the timestamped transaction re-cache this
 		 * locked item now?
 		 */
 		public boolean isPuttable(long txTimestamp, Object newVersion, Comparator comparator) {
 			if (timeout < txTimestamp) return true;
 			if (multiplicity>0) return false;
 			return version==null ?
 				unlockTimestamp < txTimestamp :
 				comparator.compare(version, newVersion) < 0; //by requiring <, we rely on lock timeout in the case of an unsuccessful update!
 		}
 
 		/**
 		 * Was this lock held concurrently by multiple
 		 * transactions?
 		 */
 		public boolean wasLockedConcurrently() {
 			return concurrentLock;
 		}
 		/**
 		 * Yes, this is a lock
 		 */
 		public boolean isLock() {
 			return true;
 		}
 		/**
 		 * locks are not returned to the client!
 		 */
 		public boolean isGettable(long txTimestamp) {
 			return false;
 		}
 
 		public int getId() { return id; }
 
 		@Override
         public String toString() {
 			return "Lock{id=" + id +
 				",version=" + version +
 				",multiplicity=" + multiplicity +
 				",unlockTimestamp=" + unlockTimestamp;
 		}
 
 	}
 
 	@Override
     public String toString() {
 		return cache + "(read-write)";
 	}
 
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCache.java b/hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCache.java
index dcb0bc402d..ebdc3c18a7 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCache.java
@@ -1,237 +1,237 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cache;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 import java.util.Set;
 import javax.persistence.EntityNotFoundException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.cfg.Settings;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 import org.jboss.logging.Logger;
 
 /**
  * The standard implementation of the Hibernate QueryCache interface.  This
  * implementation is very good at recognizing stale query results and
  * and re-running queries when it detects this condition, recaching the new
  * results.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class StandardQueryCache implements QueryCache {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, StandardQueryCache.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, StandardQueryCache.class.getName());
 
 	private QueryResultsRegion cacheRegion;
 	private UpdateTimestampsCache updateTimestampsCache;
 
 	public void clear() throws CacheException {
 		cacheRegion.evictAll();
 	}
 
 	public StandardQueryCache(
 			final Settings settings,
 			final Properties props,
 			final UpdateTimestampsCache updateTimestampsCache,
 			String regionName) throws HibernateException {
 		if ( regionName == null ) {
 			regionName = StandardQueryCache.class.getName();
 		}
 		String prefix = settings.getCacheRegionPrefix();
 		if ( prefix != null ) {
 			regionName = prefix + '.' + regionName;
 		}
         LOG.startingQueryCache(regionName);
 
 		this.cacheRegion = settings.getRegionFactory().buildQueryResultsRegion( regionName, props );
 		this.updateTimestampsCache = updateTimestampsCache;
 	}
 
 	@SuppressWarnings({ "UnnecessaryBoxing", "unchecked" })
 	public boolean put(
 			QueryKey key,
 			Type[] returnTypes,
 			List result,
 			boolean isNaturalKeyLookup,
 			SessionImplementor session) throws HibernateException {
         if (isNaturalKeyLookup && result.size() == 0) return false;
         Long ts = new Long(session.getFactory().getSettings().getRegionFactory().nextTimestamp());
 
         LOG.debugf("Caching query results in region: %s; timestamp=%s", cacheRegion.getName(), ts);
 
 		List cacheable = new ArrayList(result.size() + 1);
         logCachedResultDetails(key, null, returnTypes, cacheable);
         cacheable.add(ts);
         for (Object aResult : result) {
             if (returnTypes.length == 1) cacheable.add(returnTypes[0].disassemble(aResult, session, null));
             else cacheable.add(TypeHelper.disassemble((Object[])aResult, returnTypes, null, session, null));
             logCachedResultRowDetails(returnTypes, aResult);
         }
 
 		cacheRegion.put(key, cacheable);
         return true;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public List get(
 			QueryKey key,
 			Type[] returnTypes,
 			boolean isNaturalKeyLookup,
 			Set spaces,
 			SessionImplementor session) throws HibernateException {
         LOG.debugf("Checking cached query results in region: %s", cacheRegion.getName());
 
 		List cacheable = ( List ) cacheRegion.get( key );
         logCachedResultDetails(key, spaces, returnTypes, cacheable);
 
 		if ( cacheable == null ) {
             LOG.debugf("Query results were not found in cache");
 			return null;
 		}
 
 		Long timestamp = ( Long ) cacheable.get( 0 );
 		if ( !isNaturalKeyLookup && !isUpToDate( spaces, timestamp ) ) {
             LOG.debugf("Cached query results were not up-to-date");
 			return null;
 		}
 
         LOG.debugf("Returning cached query results");
 		for ( int i = 1; i < cacheable.size(); i++ ) {
 			if ( returnTypes.length == 1 ) {
 				returnTypes[0].beforeAssemble( ( Serializable ) cacheable.get( i ), session );
 			}
 			else {
 				TypeHelper.beforeAssemble( ( Serializable[] ) cacheable.get( i ), returnTypes, session );
 			}
 		}
 		List result = new ArrayList( cacheable.size() - 1 );
 		for ( int i = 1; i < cacheable.size(); i++ ) {
 			try {
 				if ( returnTypes.length == 1 ) {
 					result.add( returnTypes[0].assemble( ( Serializable ) cacheable.get( i ), session, null ) );
 				}
 				else {
 					result.add(
 							TypeHelper.assemble( ( Serializable[] ) cacheable.get( i ), returnTypes, session, null )
 					);
 				}
                 logCachedResultRowDetails(returnTypes, result.get(i - 1));
 			}
 			catch ( RuntimeException ex ) {
 				if ( isNaturalKeyLookup &&
 						( UnresolvableObjectException.class.isInstance( ex ) ||
 						EntityNotFoundException.class.isInstance( ex ) ) ) {
 					//TODO: not really completely correct, since
 					//      the uoe could occur while resolving
 					//      associations, leaving the PC in an
 					//      inconsistent state
                     LOG.debugf("Unable to reassemble cached result set");
 					cacheRegion.evict( key );
 					return null;
 				}
                 throw ex;
 			}
 		}
 		return result;
 	}
 
 	protected boolean isUpToDate(Set spaces, Long timestamp) {
         LOG.debugf("Checking query spaces are up-to-date: %s", spaces);
 		return updateTimestampsCache.isUpToDate( spaces, timestamp );
 	}
 
 	public void destroy() {
 		try {
 			cacheRegion.destroy();
 		}
 		catch ( Exception e ) {
             LOG.unableToDestroyQueryCache(cacheRegion.getName(), e.getMessage());
 		}
 	}
 
 	public QueryResultsRegion getRegion() {
 		return cacheRegion;
 	}
 
 	@Override
     public String toString() {
 		return "StandardQueryCache(" + cacheRegion.getName() + ')';
 	}
 
 	private static void logCachedResultDetails(QueryKey key, Set querySpaces, Type[] returnTypes, List result) {
         if (!LOG.isTraceEnabled()) return;
         LOG.trace("key.hashCode=" + key.hashCode());
         LOG.trace("querySpaces=" + querySpaces);
         if (returnTypes == null || returnTypes.length == 0) LOG.trace("Unexpected returnTypes is "
                                                                       + (returnTypes == null ? "null" : "empty") + "! result"
                                                                       + (result == null ? " is null" : ".size()=" + result.size()));
 		else {
 			StringBuffer returnTypeInfo = new StringBuffer();
 			for ( int i=0; i<returnTypes.length; i++ ) {
 				returnTypeInfo.append( "typename=" )
 						.append( returnTypes[ i ].getName() )
 						.append(" class=" )
 						.append( returnTypes[ i ].getReturnedClass().getName() ).append(' ');
 			}
             LOG.trace("unexpected returnTypes is " + returnTypeInfo.toString() + "! result");
 		}
 	}
 
 	private static void logCachedResultRowDetails(Type[] returnTypes, Object result) {
         if (!LOG.isTraceEnabled()) return;
 		logCachedResultRowDetails(
 				returnTypes,
 				( result instanceof Object[] ? ( Object[] ) result : new Object[] { result } )
 		);
 	}
 
 	private static void logCachedResultRowDetails(Type[] returnTypes, Object[] tuple) {
         if (!LOG.isTraceEnabled()) return;
 		if ( tuple == null ) {
             LOG.trace(" tuple is null; returnTypes is " + returnTypes == null ? "null" : "Type[" + returnTypes.length + "]");
             if (returnTypes != null && returnTypes.length > 1) LOG.trace("Unexpected result tuple! tuple is null; should be Object["
                                                                          + returnTypes.length + "]!");
 		}
 		else {
             if (returnTypes == null || returnTypes.length == 0) LOG.trace("Unexpected result tuple! tuple is null; returnTypes is "
                                                                           + (returnTypes == null ? "null" : "empty"));
             LOG.trace(" tuple is Object[" + tuple.length + "]; returnTypes is Type[" + returnTypes.length + "]");
             if (tuple.length != returnTypes.length) LOG.trace("Unexpected tuple length! transformer= expected="
                                                               + returnTypes.length + " got=" + tuple.length);
             else for (int j = 0; j < tuple.length; j++) {
                 if (tuple[j] != null && !returnTypes[j].getReturnedClass().isInstance(tuple[j])) LOG.trace("Unexpected tuple value type! transformer= expected="
                                                                                                            + returnTypes[j].getReturnedClass().getName()
                                                                                                            + " got="
                                                                                                            + tuple[j].getClass().getName());
             }
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/TransactionalCache.java b/hibernate-core/src/main/java/org/hibernate/cache/TransactionalCache.java
index a09ae64939..d1268901d3 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/TransactionalCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/TransactionalCache.java
@@ -1,179 +1,181 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.cache;
 import java.util.Comparator;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cache.access.SoftLock;
+
 import org.jboss.logging.Logger;
 
 /**
  * Support for fully transactional cache implementations like
  * JBoss TreeCache. Note that this might be a less scalable
  * concurrency strategy than <tt>ReadWriteCache</tt>. This is
  * a "synchronous" concurrency strategy.
  *
  * @author Gavin King
  */
 public class TransactionalCache implements CacheConcurrencyStrategy {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TransactionalCache.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TransactionalCache.class.getName());
 
 	private Cache cache;
 
 	public String getRegionName() {
 		return cache.getRegionName();
 	}
 
 	public Object get(Object key, long txTimestamp) throws CacheException {
         LOG.debugf("Cache lookup: %s", key);
 		Object result = cache.read( key );
         if (result == null) LOG.debugf("Cache miss: %s", key);
         else LOG.debugf("Cache hit: %s", key);
 		return result;
 	}
 
 	public boolean put(
 			Object key,
 	        Object value,
 	        long txTimestamp,
 	        Object version,
 	        Comparator versionComparator,
 	        boolean minimalPut) throws CacheException {
 		if ( minimalPut && cache.read( key ) != null ) {
             LOG.debugf("Item already cached: %s", key);
 			return false;
 		}
         LOG.debugf("Caching: %s", key);
 		if ( cache instanceof OptimisticCache ) {
 			( ( OptimisticCache ) cache ).writeLoad( key, value, version );
 		}
 		else {
 			cache.put( key, value );
 		}
 		return true;
 	}
 
 	/**
 	 * Do nothing, returning null.
 	 */
 	public SoftLock lock(Object key, Object version) throws CacheException {
 		//noop
 		return null;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public void release(Object key, SoftLock clientLock) throws CacheException {
 		//noop
 	}
 
 	public boolean update(
 			Object key,
 	        Object value,
 	        Object currentVersion,
 	        Object previousVersion) throws CacheException {
         LOG.debugf("Updating: %s", key);
 		if ( cache instanceof OptimisticCache ) {
 			( ( OptimisticCache ) cache ).writeUpdate( key, value, currentVersion, previousVersion );
 		}
 		else {
 			cache.update( key, value );
 		}
 		return true;
 	}
 
 	public boolean insert(
 			Object key,
 	        Object value,
 	        Object currentVersion) throws CacheException {
         LOG.debugf("Inserting: %s", key);
 		if ( cache instanceof OptimisticCache ) {
 			( ( OptimisticCache ) cache ).writeInsert( key, value, currentVersion );
 		}
 		else {
 			cache.update( key, value );
 		}
 		return true;
 	}
 
 	public void evict(Object key) throws CacheException {
 		cache.remove( key );
 	}
 
 	public void remove(Object key) throws CacheException {
         LOG.debugf("Removing: %s", key);
 		cache.remove( key );
 	}
 
 	public void clear() throws CacheException {
         LOG.debugf("Clearing");
 		cache.clear();
 	}
 
 	public void destroy() {
 		try {
 			cache.destroy();
 		}
 		catch ( Exception e ) {
             LOG.unableToDestroyCache(e.getMessage());
 		}
 	}
 
 	public void setCache(Cache cache) {
 		this.cache = cache;
 	}
 
 	public Cache getCache() {
 		return cache;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean afterInsert(
 			Object key,
 	        Object value,
 	        Object version) throws CacheException {
 		return false;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean afterUpdate(
 			Object key,
 	        Object value,
 	        Object version,
 	        SoftLock clientLock) throws CacheException {
 		return false;
 	}
 
 	@Override
     public String toString() {
 		return cache + "(transactional)";
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/UpdateTimestampsCache.java b/hibernate-core/src/main/java/org/hibernate/cache/UpdateTimestampsCache.java
index 126186a5a8..f40b9a9ac1 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/UpdateTimestampsCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/UpdateTimestampsCache.java
@@ -1,149 +1,150 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cache;
 import java.io.Serializable;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Settings;
+
 import org.jboss.logging.Logger;
 
 /**
  * Tracks the timestamps of the most recent updates to particular tables. It is
  * important that the cache timeout of the underlying cache implementation be set
  * to a higher value than the timeouts of any of the query caches. In fact, we
  * recommend that the the underlying cache not be configured for expiry at all.
  * Note, in particular, that an LRU cache expiry policy is never appropriate.
  *
  * @author Gavin King
  * @author Mikheil Kapanadze
  */
 public class UpdateTimestampsCache {
 
 	public static final String REGION_NAME = UpdateTimestampsCache.class.getName();
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                                 UpdateTimestampsCache.class.getName());
 
 	private ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();
 	private final TimestampsRegion region;
 
 	public UpdateTimestampsCache(Settings settings, Properties props) throws HibernateException {
 		String prefix = settings.getCacheRegionPrefix();
 		String regionName = prefix == null ? REGION_NAME : prefix + '.' + REGION_NAME;
         LOG.startingUpdateTimestampsCache(regionName);
 		this.region = settings.getRegionFactory().buildTimestampsRegion( regionName, props );
 	}
 
 	@SuppressWarnings({"UnnecessaryBoxing"})
 	public void preinvalidate(Serializable[] spaces) throws CacheException {
 		// TODO: to handle concurrent writes correctly, this should return a Lock to the client
 
 		readWriteLock.writeLock().lock();
 
 		try {
 			Long ts = new Long( region.nextTimestamp() + region.getTimeout() );
 			for ( Serializable space : spaces ) {
 	            LOG.debugf("Pre-invalidating space [%s]", space);
 				//put() has nowait semantics, is this really appropriate?
 				//note that it needs to be async replication, never local or sync
 				region.put( space, ts );
 			}
 			//TODO: return new Lock(ts);
 		}
 		finally {
 			readWriteLock.writeLock().unlock();
 		}
 	}
 
 	 @SuppressWarnings({"UnnecessaryBoxing"})
 	public void invalidate(Serializable[] spaces) throws CacheException {
 		//TODO: to handle concurrent writes correctly, the client should pass in a Lock
 
 		readWriteLock.writeLock().lock();
 
 		try {
 			Long ts = new Long( region.nextTimestamp() );
 			//TODO: if lock.getTimestamp().equals(ts)
 			for (Serializable space : spaces) {
 		        LOG.debugf("Invalidating space [%s], timestamp: %s", space, ts);
 		        //put() has nowait semantics, is this really appropriate?
 				//note that it needs to be async replication, never local or sync
 				region.put( space, ts );
 			}
 		}
 		finally {
 		    readWriteLock.writeLock().unlock();
 		}
 	}
 
 	@SuppressWarnings({"unchecked", "UnnecessaryUnboxing"})
 	public boolean isUpToDate(Set spaces, Long timestamp) throws HibernateException {
 		readWriteLock.readLock().lock();
 
 		try {
 			for ( Serializable space : (Set<Serializable>) spaces ) {
 				Long lastUpdate = (Long) region.get( space );
 				if ( lastUpdate == null ) {
 					//the last update timestamp was lost from the cache
 					//(or there were no updates since startup!)
 					//updateTimestamps.put( space, new Long( updateTimestamps.nextTimestamp() ) );
 					//result = false; // safer
 				}
 				else {
 	                LOG.debugf("[%s] last update timestamp: %s", space, lastUpdate + ", result set timestamp: " + timestamp);
 					if ( lastUpdate.longValue() >= timestamp.longValue() ) return false;
 				}
 			}
 			return true;
 		}
 		finally {
 			readWriteLock.readLock().unlock();
 		}
 	}
 
 	public void clear() throws CacheException {
 		region.evictAll();
 	}
 
 	public void destroy() {
 		try {
 			region.destroy();
 		}
 		catch (Exception e) {
             LOG.unableToDestroyUpdateTimestampsCache(region.getName(), e.getMessage());
 		}
 	}
 
 	public TimestampsRegion getRegion() {
 		return region;
 	}
 
 	@Override
     public String toString() {
         return "UpdateTimestampsCache";
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionRegionAdapter.java
index 6c20420dd5..82a327d21c 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionRegionAdapter.java
@@ -1,80 +1,81 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ *
+ */
 package org.hibernate.cache.impl.bridge;
-import org.hibernate.HibernateLogger;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.CacheConcurrencyStrategy;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.NonstrictReadWriteCache;
-import org.hibernate.cache.OptimisticCache;
-import org.hibernate.cache.ReadOnlyCache;
-import org.hibernate.cache.ReadWriteCache;
-import org.hibernate.cache.TransactionalCache;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cfg.Settings;
-import org.jboss.logging.Logger;
-
-/**
- * Adapter specifically bridging {@link CollectionRegion} to {@link Cache}.
- *
- * @author Steve Ebersole
- */
-public class CollectionRegionAdapter extends BaseTransactionalDataRegionAdapter implements CollectionRegion {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
-                                                                       CollectionRegionAdapter.class.getName());
-
-	public CollectionRegionAdapter(Cache underlyingCache, Settings settings, CacheDataDescription metadata) {
-		super( underlyingCache, settings, metadata );
-		if ( underlyingCache instanceof OptimisticCache ) {
-			( ( OptimisticCache ) underlyingCache ).setSource( new OptimisticCacheSourceAdapter( metadata ) );
-		}
-	}
-
-	public CollectionRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
-		CacheConcurrencyStrategy ccs;
-		if ( AccessType.READ_ONLY.equals( accessType ) ) {
-            if (metadata.isMutable()) LOG.readOnlyCacheConfiguredForMutableCollection(getName());
-			ccs = new ReadOnlyCache();
-		}
-		else if ( AccessType.READ_WRITE.equals( accessType ) ) {
-			ccs = new ReadWriteCache();
-		}
-		else if ( AccessType.NONSTRICT_READ_WRITE.equals( accessType ) ) {
-			ccs = new NonstrictReadWriteCache();
-		}
-		else if ( AccessType.TRANSACTIONAL.equals( accessType ) ) {
-			ccs = new TransactionalCache();
-		}
-		else {
-			throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
-		}
-		ccs.setCache( underlyingCache );
-		return new CollectionAccessStrategyAdapter( this, ccs, settings );
-	}
-}
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.cache.Cache;
+import org.hibernate.cache.CacheConcurrencyStrategy;
+import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.CollectionRegion;
+import org.hibernate.cache.NonstrictReadWriteCache;
+import org.hibernate.cache.OptimisticCache;
+import org.hibernate.cache.ReadOnlyCache;
+import org.hibernate.cache.ReadWriteCache;
+import org.hibernate.cache.TransactionalCache;
+import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.access.CollectionRegionAccessStrategy;
+import org.hibernate.cfg.Settings;
+
+import org.jboss.logging.Logger;
+
+/**
+ * Adapter specifically bridging {@link CollectionRegion} to {@link Cache}.
+ *
+ * @author Steve Ebersole
+ */
+public class CollectionRegionAdapter extends BaseTransactionalDataRegionAdapter implements CollectionRegion {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
+                                                                       CollectionRegionAdapter.class.getName());
+
+	public CollectionRegionAdapter(Cache underlyingCache, Settings settings, CacheDataDescription metadata) {
+		super( underlyingCache, settings, metadata );
+		if ( underlyingCache instanceof OptimisticCache ) {
+			( ( OptimisticCache ) underlyingCache ).setSource( new OptimisticCacheSourceAdapter( metadata ) );
+		}
+	}
+
+	public CollectionRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
+		CacheConcurrencyStrategy ccs;
+		if ( AccessType.READ_ONLY.equals( accessType ) ) {
+            if (metadata.isMutable()) LOG.readOnlyCacheConfiguredForMutableCollection(getName());
+			ccs = new ReadOnlyCache();
+		}
+		else if ( AccessType.READ_WRITE.equals( accessType ) ) {
+			ccs = new ReadWriteCache();
+		}
+		else if ( AccessType.NONSTRICT_READ_WRITE.equals( accessType ) ) {
+			ccs = new NonstrictReadWriteCache();
+		}
+		else if ( AccessType.TRANSACTIONAL.equals( accessType ) ) {
+			ccs = new TransactionalCache();
+		}
+		else {
+			throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
+		}
+		ccs.setCache( underlyingCache );
+		return new CollectionAccessStrategyAdapter( this, ccs, settings );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityRegionAdapter.java
index 6930d42209..d43e9b02c4 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityRegionAdapter.java
@@ -1,79 +1,80 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ *
+ */
 package org.hibernate.cache.impl.bridge;
-import org.hibernate.HibernateLogger;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.CacheConcurrencyStrategy;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.NonstrictReadWriteCache;
-import org.hibernate.cache.OptimisticCache;
-import org.hibernate.cache.ReadOnlyCache;
-import org.hibernate.cache.ReadWriteCache;
-import org.hibernate.cache.TransactionalCache;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cfg.Settings;
-import org.jboss.logging.Logger;
-
-/**
- * Adapter specifically bridging {@link EntityRegion} to {@link Cache}.
- *
- * @author Steve Ebersole
- */
-public class EntityRegionAdapter extends BaseTransactionalDataRegionAdapter implements EntityRegion {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, EntityRegionAdapter.class.getName());
-
-	public EntityRegionAdapter(Cache underlyingCache, Settings settings, CacheDataDescription metadata) {
-		super( underlyingCache, settings, metadata );
-		if ( underlyingCache instanceof OptimisticCache ) {
-			( ( OptimisticCache ) underlyingCache ).setSource( new OptimisticCacheSourceAdapter( metadata ) );
-		}
-	}
-
-	public EntityRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
-		CacheConcurrencyStrategy ccs;
-		if ( AccessType.READ_ONLY.equals( accessType ) ) {
-            if (metadata.isMutable()) LOG.readOnlyCacheConfiguredForMutableCollection(getName());
-			ccs = new ReadOnlyCache();
-		}
-		else if ( AccessType.READ_WRITE.equals( accessType ) ) {
-			ccs = new ReadWriteCache();
-		}
-		else if ( AccessType.NONSTRICT_READ_WRITE.equals( accessType ) ) {
-			ccs = new NonstrictReadWriteCache();
-		}
-		else if ( AccessType.TRANSACTIONAL.equals( accessType ) ) {
-			ccs = new TransactionalCache();
-		}
-		else {
-			throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
-		}
-		ccs.setCache( underlyingCache );
-		return new EntityAccessStrategyAdapter( this, ccs, settings );
-	}
-}
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.cache.Cache;
+import org.hibernate.cache.CacheConcurrencyStrategy;
+import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.EntityRegion;
+import org.hibernate.cache.NonstrictReadWriteCache;
+import org.hibernate.cache.OptimisticCache;
+import org.hibernate.cache.ReadOnlyCache;
+import org.hibernate.cache.ReadWriteCache;
+import org.hibernate.cache.TransactionalCache;
+import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.access.EntityRegionAccessStrategy;
+import org.hibernate.cfg.Settings;
+
+import org.jboss.logging.Logger;
+
+/**
+ * Adapter specifically bridging {@link EntityRegion} to {@link Cache}.
+ *
+ * @author Steve Ebersole
+ */
+public class EntityRegionAdapter extends BaseTransactionalDataRegionAdapter implements EntityRegion {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityRegionAdapter.class.getName());
+
+	public EntityRegionAdapter(Cache underlyingCache, Settings settings, CacheDataDescription metadata) {
+		super( underlyingCache, settings, metadata );
+		if ( underlyingCache instanceof OptimisticCache ) {
+			( ( OptimisticCache ) underlyingCache ).setSource( new OptimisticCacheSourceAdapter( metadata ) );
+		}
+	}
+
+	public EntityRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
+		CacheConcurrencyStrategy ccs;
+		if ( AccessType.READ_ONLY.equals( accessType ) ) {
+            if (metadata.isMutable()) LOG.readOnlyCacheConfiguredForMutableCollection(getName());
+			ccs = new ReadOnlyCache();
+		}
+		else if ( AccessType.READ_WRITE.equals( accessType ) ) {
+			ccs = new ReadWriteCache();
+		}
+		else if ( AccessType.NONSTRICT_READ_WRITE.equals( accessType ) ) {
+			ccs = new NonstrictReadWriteCache();
+		}
+		else if ( AccessType.TRANSACTIONAL.equals( accessType ) ) {
+			ccs = new TransactionalCache();
+		}
+		else {
+			throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
+		}
+		ccs.setCache( underlyingCache );
+		return new EntityAccessStrategyAdapter( this, ccs, settings );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/RegionFactoryCacheProviderBridge.java b/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/RegionFactoryCacheProviderBridge.java
index 873be8a035..2ac014dd2b 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/RegionFactoryCacheProviderBridge.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/RegionFactoryCacheProviderBridge.java
@@ -1,123 +1,124 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cache.impl.bridge;
 
 import java.util.Properties;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.CacheProvider;
 import org.hibernate.cache.CollectionRegion;
 import org.hibernate.cache.EntityRegion;
 import org.hibernate.cache.NoCacheProvider;
 import org.hibernate.cache.QueryResultsRegion;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.TimestampsRegion;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.jboss.logging.Logger;
 
 /**
  * Acts as a bridge between the {@link RegionFactory} contract and the older
  * {@link CacheProvider} contract.
  *
  * @author Steve Ebersole
  */
 public class RegionFactoryCacheProviderBridge implements RegionFactory {
 	public static final String DEF_PROVIDER = NoCacheProvider.class.getName();
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        RegionFactoryCacheProviderBridge.class.getName());
 
 	private CacheProvider cacheProvider;
 	private Settings settings;
 
 	public RegionFactoryCacheProviderBridge(Properties properties) {
 		String providerClassName = ConfigurationHelper.getString( Environment.CACHE_PROVIDER, properties, DEF_PROVIDER );
         LOG.cacheProvider(providerClassName);
 		try {
 			cacheProvider = ( CacheProvider ) ReflectHelper.classForName( providerClassName ).newInstance();
 		}
 		catch ( Exception cnfe ) {
 			throw new CacheException( "could not instantiate CacheProvider [" + providerClassName + "]", cnfe );
 		}
 	}
 
 	public void start(Settings settings, Properties properties) throws CacheException {
 		this.settings = settings;
 		cacheProvider.start( properties );
 	}
 
 	public void stop() {
 		cacheProvider.stop();
 		cacheProvider = null;
 	}
 
 	public boolean isMinimalPutsEnabledByDefault() {
 		return cacheProvider.isMinimalPutsEnabledByDefault();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public AccessType getDefaultAccessType() {
 		// we really have no idea
 		return null;
 	}
 
 	public long nextTimestamp() {
 		return cacheProvider.nextTimestamp();
 	}
 
 	public CacheProvider getCacheProvider() {
 		return cacheProvider;
 	}
 
 	public EntityRegion buildEntityRegion(
 			String regionName,
 			Properties properties,
 			CacheDataDescription metadata) throws CacheException {
 		return new EntityRegionAdapter( cacheProvider.buildCache( regionName, properties ), settings, metadata );
 	}
 
 	public CollectionRegion buildCollectionRegion(
 			String regionName,
 			Properties properties,
 			CacheDataDescription metadata) throws CacheException {
 		return new CollectionRegionAdapter( cacheProvider.buildCache( regionName, properties ), settings, metadata );
 	}
 
 	public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties) throws CacheException {
 		return new QueryResultsRegionAdapter( cacheProvider.buildCache( regionName, properties ), settings );
 	}
 
 	public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties) throws CacheException {
 		return new TimestampsRegionAdapter( cacheProvider.buildCache( regionName, properties ), settings );
 	}
 
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationBinder.java
index 2568423dc3..9ca34a3a67 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationBinder.java
@@ -1,2297 +1,2297 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 import java.lang.annotation.Annotation;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.EnumSet;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import javax.persistence.Basic;
 import javax.persistence.Cacheable;
 import javax.persistence.CollectionTable;
 import javax.persistence.Column;
 import javax.persistence.DiscriminatorType;
 import javax.persistence.DiscriminatorValue;
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.Embedded;
 import javax.persistence.EmbeddedId;
 import javax.persistence.Entity;
 import javax.persistence.FetchType;
 import javax.persistence.GeneratedValue;
 import javax.persistence.GenerationType;
 import javax.persistence.Id;
 import javax.persistence.IdClass;
 import javax.persistence.InheritanceType;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinTable;
 import javax.persistence.ManyToMany;
 import javax.persistence.ManyToOne;
 import javax.persistence.MapKey;
 import javax.persistence.MapKeyColumn;
 import javax.persistence.MapKeyJoinColumn;
 import javax.persistence.MapKeyJoinColumns;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.MapsId;
 import javax.persistence.NamedNativeQueries;
 import javax.persistence.NamedNativeQuery;
 import javax.persistence.NamedQueries;
 import javax.persistence.NamedQuery;
 import javax.persistence.OneToMany;
 import javax.persistence.OneToOne;
 import javax.persistence.OrderColumn;
 import javax.persistence.PrimaryKeyJoinColumn;
 import javax.persistence.PrimaryKeyJoinColumns;
 import javax.persistence.SequenceGenerator;
 import javax.persistence.SharedCacheMode;
 import javax.persistence.SqlResultSetMapping;
 import javax.persistence.SqlResultSetMappings;
 import javax.persistence.Table;
 import javax.persistence.TableGenerator;
 import javax.persistence.UniqueConstraint;
 import javax.persistence.Version;
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.BatchSize;
 import org.hibernate.annotations.Cache;
 import org.hibernate.annotations.CacheConcurrencyStrategy;
 import org.hibernate.annotations.Cascade;
 import org.hibernate.annotations.CascadeType;
 import org.hibernate.annotations.Check;
 import org.hibernate.annotations.CollectionId;
 import org.hibernate.annotations.CollectionOfElements;
 import org.hibernate.annotations.Columns;
 import org.hibernate.annotations.DiscriminatorOptions;
 import org.hibernate.annotations.Fetch;
 import org.hibernate.annotations.FetchProfile;
 import org.hibernate.annotations.FetchProfiles;
 import org.hibernate.annotations.Filter;
 import org.hibernate.annotations.FilterDef;
 import org.hibernate.annotations.FilterDefs;
 import org.hibernate.annotations.Filters;
 import org.hibernate.annotations.ForceDiscriminator;
 import org.hibernate.annotations.ForeignKey;
 import org.hibernate.annotations.Formula;
 import org.hibernate.annotations.GenericGenerator;
 import org.hibernate.annotations.GenericGenerators;
 import org.hibernate.annotations.Index;
 import org.hibernate.annotations.LazyToOne;
 import org.hibernate.annotations.LazyToOneOption;
 import org.hibernate.annotations.ManyToAny;
 import org.hibernate.annotations.MapKeyType;
 import org.hibernate.annotations.NaturalId;
 import org.hibernate.annotations.NotFound;
 import org.hibernate.annotations.NotFoundAction;
 import org.hibernate.annotations.OnDelete;
 import org.hibernate.annotations.OnDeleteAction;
 import org.hibernate.annotations.OrderBy;
 import org.hibernate.annotations.ParamDef;
 import org.hibernate.annotations.Parameter;
 import org.hibernate.annotations.Parent;
 import org.hibernate.annotations.Proxy;
 import org.hibernate.annotations.Sort;
 import org.hibernate.annotations.Source;
 import org.hibernate.annotations.Tuplizer;
 import org.hibernate.annotations.Tuplizers;
 import org.hibernate.annotations.TypeDef;
 import org.hibernate.annotations.TypeDefs;
 import org.hibernate.annotations.Where;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XAnnotatedElement;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XMethod;
 import org.hibernate.annotations.common.reflection.XPackage;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cfg.annotations.CollectionBinder;
 import org.hibernate.cfg.annotations.EntityBinder;
 import org.hibernate.cfg.annotations.MapKeyColumnDelegator;
 import org.hibernate.cfg.annotations.MapKeyJoinColumnDelegator;
 import org.hibernate.cfg.annotations.Nullability;
 import org.hibernate.cfg.annotations.PropertyBinder;
 import org.hibernate.cfg.annotations.QueryBinder;
 import org.hibernate.cfg.annotations.SimpleValueBinder;
 import org.hibernate.cfg.annotations.TableBinder;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Versioning;
 import org.hibernate.id.MultipleHiLoPerTableGenerator;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.id.SequenceHiLoGenerator;
 import org.hibernate.id.TableHiLoGenerator;
 import org.hibernate.id.enhanced.SequenceStyleGenerator;
 import org.hibernate.mapping.Any;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.IdGenerator;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.JoinedSubclass;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.SingleTableSubclass;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.ToOne;
 import org.hibernate.mapping.UnionSubclass;
 import org.hibernate.persister.entity.JoinedSubclassEntityPersister;
 import org.hibernate.persister.entity.SingleTableEntityPersister;
 import org.hibernate.persister.entity.UnionSubclassEntityPersister;
 import org.jboss.logging.Logger;
 
 /**
  * JSR 175 annotation binder which reads the annotations from classes, applies the
  * principles of the EJB3 spec and produces the Hibernate configuration-time metamodel
  * (the classes in the {@code org.hibernate.mapping} package)
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public final class AnnotationBinder {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, AnnotationBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, AnnotationBinder.class.getName());
 
     /*
      * Some design description
      * I tried to remove any link to annotation except from the 2 first level of
      * method call.
      * It'll enable to:
      *   - facilitate annotation overriding
      *   - mutualize one day xml and annotation binder (probably a dream though)
      *   - split this huge class in smaller mapping oriented classes
      *
      * bindSomething usually create the mapping container and is accessed by one of the 2 first level method
      * makeSomething usually create the mapping container and is accessed by bindSomething[else]
      * fillSomething take the container into parameter and fill it.
      */
 
 	private AnnotationBinder() {
 	}
 
 	public static void bindDefaults(Mappings mappings) {
 		Map defaults = mappings.getReflectionManager().getDefaults();
 		{
 			List<SequenceGenerator> anns = ( List<SequenceGenerator> ) defaults.get( SequenceGenerator.class );
 			if ( anns != null ) {
 				for ( SequenceGenerator ann : anns ) {
 					IdGenerator idGen = buildIdGenerator( ann, mappings );
 					if ( idGen != null ) {
 						mappings.addDefaultGenerator( idGen );
 					}
 				}
 			}
 		}
 		{
 			List<TableGenerator> anns = ( List<TableGenerator> ) defaults.get( TableGenerator.class );
 			if ( anns != null ) {
 				for ( TableGenerator ann : anns ) {
 					IdGenerator idGen = buildIdGenerator( ann, mappings );
 					if ( idGen != null ) {
 						mappings.addDefaultGenerator( idGen );
 					}
 				}
 			}
 		}
 		{
 			List<NamedQuery> anns = ( List<NamedQuery> ) defaults.get( NamedQuery.class );
 			if ( anns != null ) {
 				for ( NamedQuery ann : anns ) {
 					QueryBinder.bindQuery( ann, mappings, true );
 				}
 			}
 		}
 		{
 			List<NamedNativeQuery> anns = ( List<NamedNativeQuery> ) defaults.get( NamedNativeQuery.class );
 			if ( anns != null ) {
 				for ( NamedNativeQuery ann : anns ) {
 					QueryBinder.bindNativeQuery( ann, mappings, true );
 				}
 			}
 		}
 		{
 			List<SqlResultSetMapping> anns = ( List<SqlResultSetMapping> ) defaults.get( SqlResultSetMapping.class );
 			if ( anns != null ) {
 				for ( SqlResultSetMapping ann : anns ) {
 					QueryBinder.bindSqlResultsetMapping( ann, mappings, true );
 				}
 			}
 		}
 	}
 
 	public static void bindPackage(String packageName, Mappings mappings) {
 		XPackage pckg;
 		try {
 			pckg = mappings.getReflectionManager().packageForName( packageName );
 		}
 		catch ( ClassNotFoundException cnf ) {
             LOG.packageNotFound(packageName);
 			return;
 		}
 		if ( pckg.isAnnotationPresent( SequenceGenerator.class ) ) {
 			SequenceGenerator ann = pckg.getAnnotation( SequenceGenerator.class );
 			IdGenerator idGen = buildIdGenerator( ann, mappings );
 			mappings.addGenerator( idGen );
             LOG.trace("Add sequence generator with name: " + idGen.getName());
 		}
 		if ( pckg.isAnnotationPresent( TableGenerator.class ) ) {
 			TableGenerator ann = pckg.getAnnotation( TableGenerator.class );
 			IdGenerator idGen = buildIdGenerator( ann, mappings );
 			mappings.addGenerator( idGen );
 
 		}
 		bindGenericGenerators( pckg, mappings );
 		bindQueries( pckg, mappings );
 		bindFilterDefs( pckg, mappings );
 		bindTypeDefs( pckg, mappings );
 		bindFetchProfiles( pckg, mappings );
 		BinderHelper.bindAnyMetaDefs( pckg, mappings );
 	}
 
 	private static void bindGenericGenerators(XAnnotatedElement annotatedElement, Mappings mappings) {
 		GenericGenerator defAnn = annotatedElement.getAnnotation( GenericGenerator.class );
 		GenericGenerators defsAnn = annotatedElement.getAnnotation( GenericGenerators.class );
 		if ( defAnn != null ) {
 			bindGenericGenerator( defAnn, mappings );
 		}
 		if ( defsAnn != null ) {
 			for ( GenericGenerator def : defsAnn.value() ) {
 				bindGenericGenerator( def, mappings );
 			}
 		}
 	}
 
 	private static void bindGenericGenerator(GenericGenerator def, Mappings mappings) {
 		IdGenerator idGen = buildIdGenerator( def, mappings );
 		mappings.addGenerator( idGen );
 	}
 
 	private static void bindQueries(XAnnotatedElement annotatedElement, Mappings mappings) {
 		{
 			SqlResultSetMapping ann = annotatedElement.getAnnotation( SqlResultSetMapping.class );
 			QueryBinder.bindSqlResultsetMapping( ann, mappings, false );
 		}
 		{
 			SqlResultSetMappings ann = annotatedElement.getAnnotation( SqlResultSetMappings.class );
 			if ( ann != null ) {
 				for ( SqlResultSetMapping current : ann.value() ) {
 					QueryBinder.bindSqlResultsetMapping( current, mappings, false );
 				}
 			}
 		}
 		{
 			NamedQuery ann = annotatedElement.getAnnotation( NamedQuery.class );
 			QueryBinder.bindQuery( ann, mappings, false );
 		}
 		{
 			org.hibernate.annotations.NamedQuery ann = annotatedElement.getAnnotation(
 					org.hibernate.annotations.NamedQuery.class
 			);
 			QueryBinder.bindQuery( ann, mappings );
 		}
 		{
 			NamedQueries ann = annotatedElement.getAnnotation( NamedQueries.class );
 			QueryBinder.bindQueries( ann, mappings, false );
 		}
 		{
 			org.hibernate.annotations.NamedQueries ann = annotatedElement.getAnnotation(
 					org.hibernate.annotations.NamedQueries.class
 			);
 			QueryBinder.bindQueries( ann, mappings );
 		}
 		{
 			NamedNativeQuery ann = annotatedElement.getAnnotation( NamedNativeQuery.class );
 			QueryBinder.bindNativeQuery( ann, mappings, false );
 		}
 		{
 			org.hibernate.annotations.NamedNativeQuery ann = annotatedElement.getAnnotation(
 					org.hibernate.annotations.NamedNativeQuery.class
 			);
 			QueryBinder.bindNativeQuery( ann, mappings );
 		}
 		{
 			NamedNativeQueries ann = annotatedElement.getAnnotation( NamedNativeQueries.class );
 			QueryBinder.bindNativeQueries( ann, mappings, false );
 		}
 		{
 			org.hibernate.annotations.NamedNativeQueries ann = annotatedElement.getAnnotation(
 					org.hibernate.annotations.NamedNativeQueries.class
 			);
 			QueryBinder.bindNativeQueries( ann, mappings );
 		}
 	}
 
 	private static IdGenerator buildIdGenerator(java.lang.annotation.Annotation ann, Mappings mappings) {
 		IdGenerator idGen = new IdGenerator();
 		if ( mappings.getSchemaName() != null ) {
 			idGen.addParam( PersistentIdentifierGenerator.SCHEMA, mappings.getSchemaName() );
 		}
 		if ( mappings.getCatalogName() != null ) {
 			idGen.addParam( PersistentIdentifierGenerator.CATALOG, mappings.getCatalogName() );
 		}
 		final boolean useNewGeneratorMappings = mappings.useNewGeneratorMappings();
 		if ( ann == null ) {
 			idGen = null;
 		}
 		else if ( ann instanceof TableGenerator ) {
 			TableGenerator tabGen = ( TableGenerator ) ann;
 			idGen.setName( tabGen.name() );
 			if ( useNewGeneratorMappings ) {
 				idGen.setIdentifierGeneratorStrategy( org.hibernate.id.enhanced.TableGenerator.class.getName() );
 				idGen.addParam( org.hibernate.id.enhanced.TableGenerator.CONFIG_PREFER_SEGMENT_PER_ENTITY, "true" );
 
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.catalog() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.CATALOG, tabGen.catalog() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.schema() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.SCHEMA, tabGen.schema() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.table() ) ) {
 					idGen.addParam( org.hibernate.id.enhanced.TableGenerator.TABLE_PARAM, tabGen.table() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.pkColumnName() ) ) {
 					idGen.addParam(
 							org.hibernate.id.enhanced.TableGenerator.SEGMENT_COLUMN_PARAM, tabGen.pkColumnName()
 					);
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.pkColumnValue() ) ) {
 					idGen.addParam(
 							org.hibernate.id.enhanced.TableGenerator.SEGMENT_VALUE_PARAM, tabGen.pkColumnValue()
 					);
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.valueColumnName() ) ) {
 					idGen.addParam(
 							org.hibernate.id.enhanced.TableGenerator.VALUE_COLUMN_PARAM, tabGen.valueColumnName()
 					);
 				}
 				idGen.addParam(
 						org.hibernate.id.enhanced.TableGenerator.INCREMENT_PARAM,
 						String.valueOf( tabGen.allocationSize() )
 				);
 				// See comment on HHH-4884 wrt initialValue.  Basically initialValue is really the stated value + 1
 				idGen.addParam(
 						org.hibernate.id.enhanced.TableGenerator.INITIAL_PARAM,
 						String.valueOf( tabGen.initialValue() + 1 )
 				);
                 if (tabGen.uniqueConstraints() != null && tabGen.uniqueConstraints().length > 0) LOG.warn(tabGen.name());
 			}
 			else {
 				idGen.setIdentifierGeneratorStrategy( MultipleHiLoPerTableGenerator.class.getName() );
 
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.table() ) ) {
 					idGen.addParam( MultipleHiLoPerTableGenerator.ID_TABLE, tabGen.table() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.catalog() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.CATALOG, tabGen.catalog() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.schema() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.SCHEMA, tabGen.schema() );
 				}
 				//FIXME implement uniqueconstrains
                 if (tabGen.uniqueConstraints() != null && tabGen.uniqueConstraints().length > 0) LOG.ignoringTableGeneratorConstraints(tabGen.name());
 
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.pkColumnName() ) ) {
 					idGen.addParam( MultipleHiLoPerTableGenerator.PK_COLUMN_NAME, tabGen.pkColumnName() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.valueColumnName() ) ) {
 					idGen.addParam( MultipleHiLoPerTableGenerator.VALUE_COLUMN_NAME, tabGen.valueColumnName() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.pkColumnValue() ) ) {
 					idGen.addParam( MultipleHiLoPerTableGenerator.PK_VALUE_NAME, tabGen.pkColumnValue() );
 				}
 				idGen.addParam( TableHiLoGenerator.MAX_LO, String.valueOf( tabGen.allocationSize() - 1 ) );
 			}
             LOG.trace("Add table generator with name: " + idGen.getName());
 		}
 		else if ( ann instanceof SequenceGenerator ) {
 			SequenceGenerator seqGen = ( SequenceGenerator ) ann;
 			idGen.setName( seqGen.name() );
 			if ( useNewGeneratorMappings ) {
 				idGen.setIdentifierGeneratorStrategy( SequenceStyleGenerator.class.getName() );
 
 				if ( !BinderHelper.isEmptyAnnotationValue( seqGen.catalog() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.CATALOG, seqGen.catalog() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( seqGen.schema() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.SCHEMA, seqGen.schema() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( seqGen.sequenceName() ) ) {
 					idGen.addParam( SequenceStyleGenerator.SEQUENCE_PARAM, seqGen.sequenceName() );
 				}
 				idGen.addParam( SequenceStyleGenerator.INCREMENT_PARAM, String.valueOf( seqGen.allocationSize() ) );
 				idGen.addParam( SequenceStyleGenerator.INITIAL_PARAM, String.valueOf( seqGen.initialValue() ) );
 			}
 			else {
 				idGen.setIdentifierGeneratorStrategy( "seqhilo" );
 
 				if ( !BinderHelper.isEmptyAnnotationValue( seqGen.sequenceName() ) ) {
 					idGen.addParam( org.hibernate.id.SequenceGenerator.SEQUENCE, seqGen.sequenceName() );
 				}
 				//FIXME: work on initialValue() through SequenceGenerator.PARAMETERS
 				//		steve : or just use o.h.id.enhanced.SequenceStyleGenerator
                 if (seqGen.initialValue() != 1) LOG.unsupportedInitialValue(Configuration.USE_NEW_ID_GENERATOR_MAPPINGS);
 				idGen.addParam( SequenceHiLoGenerator.MAX_LO, String.valueOf( seqGen.allocationSize() - 1 ) );
                 LOG.trace("Add sequence generator with name: " + idGen.getName());
 			}
 		}
 		else if ( ann instanceof GenericGenerator ) {
 			GenericGenerator genGen = ( GenericGenerator ) ann;
 			idGen.setName( genGen.name() );
 			idGen.setIdentifierGeneratorStrategy( genGen.strategy() );
 			Parameter[] params = genGen.parameters();
 			for ( Parameter parameter : params ) {
 				idGen.addParam( parameter.name(), parameter.value() );
 			}
             LOG.trace("Add generic generator with name: " + idGen.getName());
 		}
 		else {
 			throw new AssertionFailure( "Unknown Generator annotation: " + ann );
 		}
 		return idGen;
 	}
 
 	/**
 	 * Bind a class having JSR175 annotations. Subclasses <b>have to</b> be bound after its parent class.
 	 *
 	 * @param clazzToProcess entity to bind as {@code XClass} instance
 	 * @param inheritanceStatePerClass Meta data about the inheritance relationships for all mapped classes
 	 * @param mappings Mapping meta data
 	 *
 	 * @throws MappingException in case there is an configuration error
 	 */
 	public static void bindClass(
 			XClass clazzToProcess,
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			Mappings mappings) throws MappingException {
 		//@Entity and @MappedSuperclass on the same class leads to a NPE down the road
 		if ( clazzToProcess.isAnnotationPresent( Entity.class )
 				&&  clazzToProcess.isAnnotationPresent( MappedSuperclass.class ) ) {
 			throw new AnnotationException( "An entity cannot be annotated with both @Entity and @MappedSuperclass: "
 					+ clazzToProcess.getName() );
 		}
 
 		//TODO: be more strict with secondarytable allowance (not for ids, not for secondary table join columns etc)
 		InheritanceState inheritanceState = inheritanceStatePerClass.get( clazzToProcess );
 		AnnotatedClassType classType = mappings.getClassType( clazzToProcess );
 
 		//Queries declared in MappedSuperclass should be usable in Subclasses
 		if ( AnnotatedClassType.EMBEDDABLE_SUPERCLASS.equals( classType ) ) {
 			bindQueries( clazzToProcess, mappings );
 			bindTypeDefs( clazzToProcess, mappings );
 			bindFilterDefs( clazzToProcess, mappings );
 		}
 
 		if ( !isEntityClassType( clazzToProcess, classType ) ) {
 			return;
 		}
 
-        LOG.bindingEntityFromClass(clazzToProcess.getName());
+        LOG.bindingEntityFromClass( clazzToProcess.getName() );
 
 		PersistentClass superEntity = getSuperEntity(
 				clazzToProcess, inheritanceStatePerClass, mappings, inheritanceState
 		);
 
 		PersistentClass persistentClass = makePersistentClass( inheritanceState, superEntity );
 		Entity entityAnn = clazzToProcess.getAnnotation( Entity.class );
 		org.hibernate.annotations.Entity hibEntityAnn = clazzToProcess.getAnnotation(
 				org.hibernate.annotations.Entity.class
 		);
 		EntityBinder entityBinder = new EntityBinder(
 				entityAnn, hibEntityAnn, clazzToProcess, persistentClass, mappings
 		);
 		entityBinder.setInheritanceState( inheritanceState );
 
 		bindQueries( clazzToProcess, mappings );
 		bindFilterDefs( clazzToProcess, mappings );
 		bindTypeDefs( clazzToProcess, mappings );
 		bindFetchProfiles( clazzToProcess, mappings );
 		BinderHelper.bindAnyMetaDefs( clazzToProcess, mappings );
 
 		String schema = "";
 		String table = ""; //might be no @Table annotation on the annotated class
 		String catalog = "";
 		List<UniqueConstraintHolder> uniqueConstraints = new ArrayList<UniqueConstraintHolder>();
 		if ( clazzToProcess.isAnnotationPresent( javax.persistence.Table.class ) ) {
 			javax.persistence.Table tabAnn = clazzToProcess.getAnnotation( javax.persistence.Table.class );
 			table = tabAnn.name();
 			schema = tabAnn.schema();
 			catalog = tabAnn.catalog();
 			uniqueConstraints = TableBinder.buildUniqueConstraintHolders( tabAnn.uniqueConstraints() );
 		}
 
 		Ejb3JoinColumn[] inheritanceJoinedColumns = makeInheritanceJoinColumns(
 				clazzToProcess, mappings, inheritanceState, superEntity
 		);
 		Ejb3DiscriminatorColumn discriminatorColumn = null;
 		if ( InheritanceType.SINGLE_TABLE.equals( inheritanceState.getType() ) ) {
 			discriminatorColumn = processDiscriminatorProperties(
 					clazzToProcess, mappings, inheritanceState, entityBinder
 			);
 		}
 
 		entityBinder.setProxy( clazzToProcess.getAnnotation( Proxy.class ) );
 		entityBinder.setBatchSize( clazzToProcess.getAnnotation( BatchSize.class ) );
 		entityBinder.setWhere( clazzToProcess.getAnnotation( Where.class ) );
 	    entityBinder.setCache( determineCacheSettings( clazzToProcess, mappings ) );
 
 		//Filters are not allowed on subclasses
 		if ( !inheritanceState.hasParents() ) {
 			bindFilters( clazzToProcess, entityBinder, mappings );
 		}
 
 		entityBinder.bindEntity();
 
 		if ( inheritanceState.hasTable() ) {
 			Check checkAnn = clazzToProcess.getAnnotation( Check.class );
 			String constraints = checkAnn == null ?
 					null :
 					checkAnn.constraints();
 			entityBinder.bindTable(
 					schema, catalog, table, uniqueConstraints,
 					constraints, inheritanceState.hasDenormalizedTable() ?
 							superEntity.getTable() :
 							null
 			);
         } else if (clazzToProcess.isAnnotationPresent(Table.class)) LOG.invalidTableAnnotation(clazzToProcess.getName());
 
 
 		PropertyHolder propertyHolder = PropertyHolderBuilder.buildPropertyHolder(
 				clazzToProcess,
 				persistentClass,
 				entityBinder, mappings, inheritanceStatePerClass
 		);
 
 		javax.persistence.SecondaryTable secTabAnn = clazzToProcess.getAnnotation(
 				javax.persistence.SecondaryTable.class
 		);
 		javax.persistence.SecondaryTables secTabsAnn = clazzToProcess.getAnnotation(
 				javax.persistence.SecondaryTables.class
 		);
 		entityBinder.firstLevelSecondaryTablesBinding( secTabAnn, secTabsAnn );
 
 		OnDelete onDeleteAnn = clazzToProcess.getAnnotation( OnDelete.class );
 		boolean onDeleteAppropriate = false;
 		if ( InheritanceType.JOINED.equals( inheritanceState.getType() ) && inheritanceState.hasParents() ) {
 			onDeleteAppropriate = true;
 			final JoinedSubclass jsc = ( JoinedSubclass ) persistentClass;
 			if ( persistentClass.getEntityPersisterClass() == null ) {
 				persistentClass.getRootClass().setEntityPersisterClass( JoinedSubclassEntityPersister.class );
 			}
 			SimpleValue key = new DependantValue( mappings, jsc.getTable(), jsc.getIdentifier() );
 			jsc.setKey( key );
 			ForeignKey fk = clazzToProcess.getAnnotation( ForeignKey.class );
 			if ( fk != null && !BinderHelper.isEmptyAnnotationValue( fk.name() ) ) {
 				key.setForeignKeyName( fk.name() );
 			}
 			if ( onDeleteAnn != null ) {
 				key.setCascadeDeleteEnabled( OnDeleteAction.CASCADE.equals( onDeleteAnn.action() ) );
 			}
 			else {
 				key.setCascadeDeleteEnabled( false );
 			}
 			//we are never in a second pass at that stage, so queue it
 			SecondPass sp = new JoinedSubclassFkSecondPass( jsc, inheritanceJoinedColumns, key, mappings );
 			mappings.addSecondPass( sp );
 			mappings.addSecondPass( new CreateKeySecondPass( jsc ) );
 
 		}
 		else if ( InheritanceType.SINGLE_TABLE.equals( inheritanceState.getType() ) ) {
 			if ( inheritanceState.hasParents() ) {
 				if ( persistentClass.getEntityPersisterClass() == null ) {
 					persistentClass.getRootClass().setEntityPersisterClass( SingleTableEntityPersister.class );
 				}
 			}
 			else {
 				if ( inheritanceState.hasSiblings() || !discriminatorColumn.isImplicit() ) {
 					//need a discriminator column
 					bindDiscriminatorToPersistentClass(
 							( RootClass ) persistentClass,
 							discriminatorColumn,
 							entityBinder.getSecondaryTables(),
 							propertyHolder,
 							mappings
 					);
 					entityBinder.bindDiscriminatorValue();//bind it again since the type might have changed
 				}
 			}
 		}
 		else if ( InheritanceType.TABLE_PER_CLASS.equals( inheritanceState.getType() ) ) {
 			if ( inheritanceState.hasParents() ) {
 				if ( persistentClass.getEntityPersisterClass() == null ) {
 					persistentClass.getRootClass().setEntityPersisterClass( UnionSubclassEntityPersister.class );
 				}
 			}
 		}
         if (onDeleteAnn != null && !onDeleteAppropriate) LOG.invalidOnDeleteAnnotation(propertyHolder.getEntityName());
 
 		// try to find class level generators
 		HashMap<String, IdGenerator> classGenerators = buildLocalGenerators( clazzToProcess, mappings );
 
 		// check properties
 		final InheritanceState.ElementsToProcess elementsToProcess = inheritanceState.getElementsToProcess();
 		inheritanceState.postProcess( persistentClass, entityBinder );
 
 		final boolean subclassAndSingleTableStrategy = inheritanceState.getType() == InheritanceType.SINGLE_TABLE
 				&& inheritanceState.hasParents();
 		Set<String> idPropertiesIfIdClass = new HashSet<String>();
 		boolean isIdClass = mapAsIdClass(
 				inheritanceStatePerClass,
 				inheritanceState,
 				persistentClass,
 				entityBinder,
 				propertyHolder,
 				elementsToProcess,
 				idPropertiesIfIdClass,
 				mappings
 		);
 
 		if ( !isIdClass ) {
 			entityBinder.setWrapIdsInEmbeddedComponents( elementsToProcess.getIdPropertyCount() > 1 );
 		}
 
 		processIdPropertiesIfNotAlready(
 				inheritanceStatePerClass,
 				mappings,
 				persistentClass,
 				entityBinder,
 				propertyHolder,
 				classGenerators,
 				elementsToProcess,
 				subclassAndSingleTableStrategy,
 				idPropertiesIfIdClass
 		);
 
 		if ( !inheritanceState.hasParents() ) {
 			final RootClass rootClass = ( RootClass ) persistentClass;
 			mappings.addSecondPass( new CreateKeySecondPass( rootClass ) );
 		}
 		else {
 			superEntity.addSubclass( ( Subclass ) persistentClass );
 		}
 
 		mappings.addClass( persistentClass );
 
 		//Process secondary tables and complementary definitions (ie o.h.a.Table)
 		mappings.addSecondPass( new SecondaryTableSecondPass( entityBinder, propertyHolder, clazzToProcess ) );
 
 		//add process complementary Table definition (index & all)
 		entityBinder.processComplementaryTableDefinitions( clazzToProcess.getAnnotation( org.hibernate.annotations.Table.class ) );
 		entityBinder.processComplementaryTableDefinitions( clazzToProcess.getAnnotation( org.hibernate.annotations.Tables.class ) );
 
 	}
 
 	// parse everything discriminator column relevant in case of single table inheritance
 	private static Ejb3DiscriminatorColumn processDiscriminatorProperties(XClass clazzToProcess, Mappings mappings, InheritanceState inheritanceState, EntityBinder entityBinder) {
 		Ejb3DiscriminatorColumn discriminatorColumn = null;
 		javax.persistence.DiscriminatorColumn discAnn = clazzToProcess.getAnnotation(
 				javax.persistence.DiscriminatorColumn.class
 		);
 		DiscriminatorType discriminatorType = discAnn != null ?
 				discAnn.discriminatorType() :
 				DiscriminatorType.STRING;
 
 		org.hibernate.annotations.DiscriminatorFormula discFormulaAnn = clazzToProcess.getAnnotation(
 				org.hibernate.annotations.DiscriminatorFormula.class
 		);
 		if ( !inheritanceState.hasParents() ) {
 			discriminatorColumn = Ejb3DiscriminatorColumn.buildDiscriminatorColumn(
 					discriminatorType, discAnn, discFormulaAnn, mappings
 			);
 		}
         if (discAnn != null && inheritanceState.hasParents()) LOG.invalidDescriminatorAnnotation(clazzToProcess.getName());
 
 		String discrimValue = clazzToProcess.isAnnotationPresent( DiscriminatorValue.class ) ?
 				clazzToProcess.getAnnotation( DiscriminatorValue.class ).value() :
 				null;
 		entityBinder.setDiscriminatorValue( discrimValue );
 
 		if ( clazzToProcess.isAnnotationPresent( ForceDiscriminator.class ) ) {
             LOG.deprecatedForceDescriminatorAnnotation();
 			entityBinder.setForceDiscriminator( true );
 		}
 
 		DiscriminatorOptions discriminatorOptions = clazzToProcess.getAnnotation( DiscriminatorOptions.class );
 		if ( discriminatorOptions != null) {
 			entityBinder.setForceDiscriminator( discriminatorOptions.force() );
 			entityBinder.setInsertableDiscriminator( discriminatorOptions.insert() );
 		}
 
 		return discriminatorColumn;
 	}
 
 	private static void processIdPropertiesIfNotAlready(
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			Mappings mappings,
 			PersistentClass persistentClass,
 			EntityBinder entityBinder,
 			PropertyHolder propertyHolder,
 			HashMap<String, IdGenerator> classGenerators,
 			InheritanceState.ElementsToProcess elementsToProcess,
 			boolean subclassAndSingleTableStrategy,
 			Set<String> idPropertiesIfIdClass) {
 		Set<String> missingIdProperties = new HashSet<String>( idPropertiesIfIdClass );
 		for ( PropertyData propertyAnnotatedElement : elementsToProcess.getElements() ) {
 			String propertyName = propertyAnnotatedElement.getPropertyName();
 			if ( !idPropertiesIfIdClass.contains( propertyName ) ) {
 				processElementAnnotations(
 						propertyHolder,
 						subclassAndSingleTableStrategy ?
 								Nullability.FORCED_NULL :
 								Nullability.NO_CONSTRAINT,
 						propertyAnnotatedElement, classGenerators, entityBinder,
 						false, false, false, mappings, inheritanceStatePerClass
 				);
 			}
 			else {
 				missingIdProperties.remove( propertyName );
 			}
 		}
 
 		if ( missingIdProperties.size() != 0 ) {
 			StringBuilder missings = new StringBuilder();
 			for ( String property : missingIdProperties ) {
 				missings.append( property ).append( ", " );
 			}
 			throw new AnnotationException(
 					"Unable to find properties ("
 							+ missings.substring( 0, missings.length() - 2 )
 							+ ") in entity annotated with @IdClass:" + persistentClass.getEntityName()
 			);
 		}
 	}
 
 	private static boolean mapAsIdClass(
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			InheritanceState inheritanceState,
 			PersistentClass persistentClass,
 			EntityBinder entityBinder,
 			PropertyHolder propertyHolder,
 			InheritanceState.ElementsToProcess elementsToProcess,
 			Set<String> idPropertiesIfIdClass,
 			Mappings mappings) {
 		/*
 		 * We are looking for @IdClass
 		 * In general we map the id class as identifier using the mapping metadata of the main entity's properties
 		 * and we create an identifier mapper containing the id properties of the main entity
 		 *
 		 * In JPA 2, there is a shortcut if the id class is the Pk of the associated class pointed to by the id
 		 * it ought to be treated as an embedded and not a real IdClass (at least in the Hibernate's internal way
 		 */
 		XClass classWithIdClass = inheritanceState.getClassWithIdClass( false );
 		if ( classWithIdClass != null ) {
 			IdClass idClass = classWithIdClass.getAnnotation( IdClass.class );
 			XClass compositeClass = mappings.getReflectionManager().toXClass( idClass.value() );
 			PropertyData inferredData = new PropertyPreloadedData(
 					entityBinder.getPropertyAccessType(), "id", compositeClass
 			);
 			PropertyData baseInferredData = new PropertyPreloadedData(
 					entityBinder.getPropertyAccessType(), "id", classWithIdClass
 			);
 			AccessType propertyAccessor = entityBinder.getPropertyAccessor( compositeClass );
 			//In JPA 2, there is a shortcut if the IdClass is the Pk of the associated class pointed to by the id
 			//it ought to be treated as an embedded and not a real IdClass (at least in the Hibernate's internal way
 			final boolean isFakeIdClass = isIdClassPkOfTheAssociatedEntity(
 					elementsToProcess,
 					compositeClass,
 					inferredData,
 					baseInferredData,
 					propertyAccessor,
 					inheritanceStatePerClass,
 					mappings
 			);
 
 			if ( isFakeIdClass ) {
 				return false;
 			}
 
 			boolean isComponent = true;
 			String generatorType = "assigned";
 			String generator = BinderHelper.ANNOTATION_STRING_DEFAULT;
 
 			boolean ignoreIdAnnotations = entityBinder.isIgnoreIdAnnotations();
 			entityBinder.setIgnoreIdAnnotations( true );
 			propertyHolder.setInIdClass( true );
 			bindIdClass(
 					generatorType,
 					generator,
 					inferredData,
 					baseInferredData,
 					null,
 					propertyHolder,
 					isComponent,
 					propertyAccessor,
 					entityBinder,
 					true,
 					false,
 					mappings,
 					inheritanceStatePerClass
 			);
 			propertyHolder.setInIdClass( null );
 			inferredData = new PropertyPreloadedData(
 					propertyAccessor, "_identifierMapper", compositeClass
 			);
 			Component mapper = fillComponent(
 					propertyHolder,
 					inferredData,
 					baseInferredData,
 					propertyAccessor,
 					false,
 					entityBinder,
 					true,
 					true,
 					false,
 					mappings,
 					inheritanceStatePerClass
 			);
 			entityBinder.setIgnoreIdAnnotations( ignoreIdAnnotations );
 			persistentClass.setIdentifierMapper( mapper );
 
 			//If id definition is on a mapped superclass, update the mapping
 			final org.hibernate.mapping.MappedSuperclass superclass =
 					BinderHelper.getMappedSuperclassOrNull(
 							inferredData.getDeclaringClass(),
 							inheritanceStatePerClass,
 							mappings
 					);
 			if ( superclass != null ) {
 				superclass.setDeclaredIdentifierMapper( mapper );
 			}
 			else {
 				//we are for sure on the entity
 				persistentClass.setDeclaredIdentifierMapper( mapper );
 			}
 
 			Property property = new Property();
 			property.setName( "_identifierMapper" );
 			property.setNodeName( "id" );
 			property.setUpdateable( false );
 			property.setInsertable( false );
 			property.setValue( mapper );
 			property.setPropertyAccessorName( "embedded" );
 			persistentClass.addProperty( property );
 			entityBinder.setIgnoreIdAnnotations( true );
 
 			Iterator properties = mapper.getPropertyIterator();
 			while ( properties.hasNext() ) {
 				idPropertiesIfIdClass.add( ( ( Property ) properties.next() ).getName() );
 			}
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	private static boolean isIdClassPkOfTheAssociatedEntity(
 			InheritanceState.ElementsToProcess elementsToProcess,
 			XClass compositeClass,
 			PropertyData inferredData,
 			PropertyData baseInferredData,
 			AccessType propertyAccessor,
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			Mappings mappings) {
 		if ( elementsToProcess.getIdPropertyCount() == 1 ) {
 			final PropertyData idPropertyOnBaseClass = getUniqueIdPropertyFromBaseClass(
 					inferredData, baseInferredData, propertyAccessor, mappings
 			);
 			final InheritanceState state = inheritanceStatePerClass.get( idPropertyOnBaseClass.getClassOrElement() );
 			if ( state == null ) {
 				return false; //while it is likely a user error, let's consider it is something that might happen
 			}
 			final XClass associatedClassWithIdClass = state.getClassWithIdClass( true );
 			if ( associatedClassWithIdClass == null ) {
 				//we cannot know for sure here unless we try and find the @EmbeddedId
 				//Let's not do this thorough checking but do some extra validation
 				final XProperty property = idPropertyOnBaseClass.getProperty();
 				return property.isAnnotationPresent( ManyToOne.class )
 						|| property.isAnnotationPresent( OneToOne.class );
 
 			}
 			else {
 				final XClass idClass = mappings.getReflectionManager().toXClass(
 						associatedClassWithIdClass.getAnnotation( IdClass.class ).value()
 				);
 				return idClass.equals( compositeClass );
 			}
 		}
 		else {
 			return false;
 		}
 	}
 
 	private static Cache determineCacheSettings(XClass clazzToProcess, Mappings mappings) {
 		Cache cacheAnn = clazzToProcess.getAnnotation( Cache.class );
 		if ( cacheAnn != null ) {
 			return cacheAnn;
 		}
 
 		Cacheable cacheableAnn = clazzToProcess.getAnnotation( Cacheable.class );
 		SharedCacheMode mode = determineSharedCacheMode( mappings );
 		switch ( mode ) {
 			case ALL: {
 				cacheAnn = buildCacheMock( clazzToProcess.getName(), mappings );
 				break;
 			}
 			case ENABLE_SELECTIVE: {
 				if ( cacheableAnn != null && cacheableAnn.value() ) {
 					cacheAnn = buildCacheMock( clazzToProcess.getName(), mappings );
 				}
 				break;
 			}
 			case DISABLE_SELECTIVE: {
 				if ( cacheableAnn == null || cacheableAnn.value() ) {
 					cacheAnn = buildCacheMock( clazzToProcess.getName(), mappings );
 				}
 				break;
 			}
 			default: {
 				// treat both NONE and UNSPECIFIED the same
 				break;
 			}
 		}
 		return cacheAnn;
 	}
 
 	private static SharedCacheMode determineSharedCacheMode(Mappings mappings) {
 		SharedCacheMode mode;
 		final Object value = mappings.getConfigurationProperties().get( "javax.persistence.sharedCache.mode" );
 		if ( value == null ) {
             LOG.debugf("No value specified for 'javax.persistence.sharedCache.mode'; using UNSPECIFIED");
 			mode = SharedCacheMode.UNSPECIFIED;
 		}
 		else {
 			if ( SharedCacheMode.class.isInstance( value ) ) {
 				mode = ( SharedCacheMode ) value;
 			}
 			else {
 				try {
 					mode = SharedCacheMode.valueOf( value.toString() );
 				}
 				catch ( Exception e ) {
                     LOG.debugf("Unable to resolve given mode name [%s]; using UNSPECIFIED : %s", value, e);
 					mode = SharedCacheMode.UNSPECIFIED;
 				}
 			}
 		}
 		return mode;
 	}
 
 	private static Cache buildCacheMock(String region, Mappings mappings) {
 		return new LocalCacheAnnotationImpl( region, determineCacheConcurrencyStrategy( mappings ) );
 	}
 
 	private static CacheConcurrencyStrategy DEFAULT_CACHE_CONCURRENCY_STRATEGY;
 
 	static void prepareDefaultCacheConcurrencyStrategy(Properties properties) {
 		if ( DEFAULT_CACHE_CONCURRENCY_STRATEGY != null ) {
             LOG.trace("Default cache concurrency strategy already defined");
 			return;
 		}
 
 		if ( !properties.containsKey( Configuration.DEFAULT_CACHE_CONCURRENCY_STRATEGY ) ) {
             LOG.trace("Given properties did not contain any default cache concurrency strategy setting");
 			return;
 		}
 
 		final String strategyName = properties.getProperty( Configuration.DEFAULT_CACHE_CONCURRENCY_STRATEGY );
         LOG.trace("Discovered default cache concurrency strategy via config [" + strategyName + "]");
 		CacheConcurrencyStrategy strategy = CacheConcurrencyStrategy.parse( strategyName );
 		if ( strategy == null ) {
             LOG.trace("Discovered default cache concurrency strategy specified nothing");
 			return;
 		}
 
         LOG.debugf("Setting default cache concurrency strategy via config [%s]", strategy.name());
 		DEFAULT_CACHE_CONCURRENCY_STRATEGY = strategy;
 	}
 
 	private static CacheConcurrencyStrategy determineCacheConcurrencyStrategy(Mappings mappings) {
 		if ( DEFAULT_CACHE_CONCURRENCY_STRATEGY == null ) {
 			final RegionFactory cacheRegionFactory = SettingsFactory.createRegionFactory(
 					mappings.getConfigurationProperties(), true
 			);
 			DEFAULT_CACHE_CONCURRENCY_STRATEGY = CacheConcurrencyStrategy.fromAccessType( cacheRegionFactory.getDefaultAccessType() );
 		}
 		return DEFAULT_CACHE_CONCURRENCY_STRATEGY;
 	}
 
 	@SuppressWarnings({ "ClassExplicitlyAnnotation" })
 	private static class LocalCacheAnnotationImpl implements Cache {
 		private final String region;
 		private final CacheConcurrencyStrategy usage;
 
 		private LocalCacheAnnotationImpl(String region, CacheConcurrencyStrategy usage) {
 			this.region = region;
 			this.usage = usage;
 		}
 
 		public CacheConcurrencyStrategy usage() {
 			return usage;
 		}
 
 		public String region() {
 			return region;
 		}
 
 		public String include() {
 			return "all";
 		}
 
 		public Class<? extends Annotation> annotationType() {
 			return Cache.class;
 		}
 	}
 
 	private static PersistentClass makePersistentClass(InheritanceState inheritanceState, PersistentClass superEntity) {
 		//we now know what kind of persistent entity it is
 		PersistentClass persistentClass;
 		//create persistent class
 		if ( !inheritanceState.hasParents() ) {
 			persistentClass = new RootClass();
 		}
 		else if ( InheritanceType.SINGLE_TABLE.equals( inheritanceState.getType() ) ) {
 			persistentClass = new SingleTableSubclass( superEntity );
 		}
 		else if ( InheritanceType.JOINED.equals( inheritanceState.getType() ) ) {
 			persistentClass = new JoinedSubclass( superEntity );
 		}
 		else if ( InheritanceType.TABLE_PER_CLASS.equals( inheritanceState.getType() ) ) {
 			persistentClass = new UnionSubclass( superEntity );
 		}
 		else {
 			throw new AssertionFailure( "Unknown inheritance type: " + inheritanceState.getType() );
 		}
 		return persistentClass;
 	}
 
 	private static Ejb3JoinColumn[] makeInheritanceJoinColumns(
 			XClass clazzToProcess,
 			Mappings mappings,
 			InheritanceState inheritanceState,
 			PersistentClass superEntity) {
 		Ejb3JoinColumn[] inheritanceJoinedColumns = null;
 		final boolean hasJoinedColumns = inheritanceState.hasParents()
 				&& InheritanceType.JOINED.equals( inheritanceState.getType() );
 		if ( hasJoinedColumns ) {
 			//@Inheritance(JOINED) subclass need to link back to the super entity
 			PrimaryKeyJoinColumns jcsAnn = clazzToProcess.getAnnotation( PrimaryKeyJoinColumns.class );
 			boolean explicitInheritanceJoinedColumns = jcsAnn != null && jcsAnn.value().length != 0;
 			if ( explicitInheritanceJoinedColumns ) {
 				int nbrOfInhJoinedColumns = jcsAnn.value().length;
 				PrimaryKeyJoinColumn jcAnn;
 				inheritanceJoinedColumns = new Ejb3JoinColumn[nbrOfInhJoinedColumns];
 				for ( int colIndex = 0; colIndex < nbrOfInhJoinedColumns; colIndex++ ) {
 					jcAnn = jcsAnn.value()[colIndex];
 					inheritanceJoinedColumns[colIndex] = Ejb3JoinColumn.buildJoinColumn(
 							jcAnn, null, superEntity.getIdentifier(),
 							( Map<String, Join> ) null, ( PropertyHolder ) null, mappings
 					);
 				}
 			}
 			else {
 				PrimaryKeyJoinColumn jcAnn = clazzToProcess.getAnnotation( PrimaryKeyJoinColumn.class );
 				inheritanceJoinedColumns = new Ejb3JoinColumn[1];
 				inheritanceJoinedColumns[0] = Ejb3JoinColumn.buildJoinColumn(
 						jcAnn, null, superEntity.getIdentifier(),
 						( Map<String, Join> ) null, ( PropertyHolder ) null, mappings
 				);
 			}
             LOG.trace("Subclass joined column(s) created");
 		}
 		else {
             if (clazzToProcess.isAnnotationPresent(PrimaryKeyJoinColumns.class)
                 || clazzToProcess.isAnnotationPresent(PrimaryKeyJoinColumn.class)) LOG.invalidPrimaryKeyJoinColumnAnnotation();
 		}
 		return inheritanceJoinedColumns;
 	}
 
 	private static PersistentClass getSuperEntity(XClass clazzToProcess, Map<XClass, InheritanceState> inheritanceStatePerClass, Mappings mappings, InheritanceState inheritanceState) {
 		InheritanceState superEntityState = InheritanceState.getInheritanceStateOfSuperEntity(
 				clazzToProcess, inheritanceStatePerClass
 		);
 		PersistentClass superEntity = superEntityState != null ?
 				mappings.getClass(
 						superEntityState.getClazz().getName()
 				) :
 				null;
 		if ( superEntity == null ) {
 			//check if superclass is not a potential persistent class
 			if ( inheritanceState.hasParents() ) {
 				throw new AssertionFailure(
 						"Subclass has to be binded after it's mother class: "
 								+ superEntityState.getClazz().getName()
 				);
 			}
 		}
 		return superEntity;
 	}
 
 	private static boolean isEntityClassType(XClass clazzToProcess, AnnotatedClassType classType) {
 		if ( AnnotatedClassType.EMBEDDABLE_SUPERCLASS.equals( classType ) //will be processed by their subentities
 				|| AnnotatedClassType.NONE.equals( classType ) //to be ignored
 				|| AnnotatedClassType.EMBEDDABLE.equals( classType ) //allow embeddable element declaration
 				) {
             if (AnnotatedClassType.NONE.equals(classType)
                 && clazzToProcess.isAnnotationPresent(org.hibernate.annotations.Entity.class))
                 LOG.missingEntityAnnotation(clazzToProcess.getName());
 			return false;
 		}
 
 		if ( !classType.equals( AnnotatedClassType.ENTITY ) ) {
 			throw new AnnotationException(
 					"Annotated class should have a @javax.persistence.Entity, @javax.persistence.Embeddable or @javax.persistence.EmbeddedSuperclass annotation: " + clazzToProcess
 							.getName()
 			);
 		}
 
 		return true;
 	}
 
 	/*
 	 * Process the filters defined on the given class, as well as all filters defined
 	 * on the MappedSuperclass(s) in the inheritance hierarchy
 	 */
 
 	private static void bindFilters(XClass annotatedClass, EntityBinder entityBinder,
 									Mappings mappings) {
 
 		bindFilters( annotatedClass, entityBinder );
 
 		XClass classToProcess = annotatedClass.getSuperclass();
 		while ( classToProcess != null ) {
 			AnnotatedClassType classType = mappings.getClassType( classToProcess );
 			if ( AnnotatedClassType.EMBEDDABLE_SUPERCLASS.equals( classType ) ) {
 				bindFilters( classToProcess, entityBinder );
 			}
 			classToProcess = classToProcess.getSuperclass();
 		}
 
 	}
 
 	private static void bindFilters(XAnnotatedElement annotatedElement, EntityBinder entityBinder) {
 
 		Filters filtersAnn = annotatedElement.getAnnotation( Filters.class );
 		if ( filtersAnn != null ) {
 			for ( Filter filter : filtersAnn.value() ) {
 				entityBinder.addFilter( filter.name(), filter.condition() );
 			}
 		}
 
 		Filter filterAnn = annotatedElement.getAnnotation( Filter.class );
 		if ( filterAnn != null ) {
 			entityBinder.addFilter( filterAnn.name(), filterAnn.condition() );
 		}
 	}
 
 	private static void bindFilterDefs(XAnnotatedElement annotatedElement, Mappings mappings) {
 		FilterDef defAnn = annotatedElement.getAnnotation( FilterDef.class );
 		FilterDefs defsAnn = annotatedElement.getAnnotation( FilterDefs.class );
 		if ( defAnn != null ) {
 			bindFilterDef( defAnn, mappings );
 		}
 		if ( defsAnn != null ) {
 			for ( FilterDef def : defsAnn.value() ) {
 				bindFilterDef( def, mappings );
 			}
 		}
 	}
 
 	private static void bindFilterDef(FilterDef defAnn, Mappings mappings) {
 		Map<String, org.hibernate.type.Type> params = new HashMap<String, org.hibernate.type.Type>();
 		for ( ParamDef param : defAnn.parameters() ) {
 			params.put( param.name(), mappings.getTypeResolver().heuristicType( param.type() ) );
 		}
 		FilterDefinition def = new FilterDefinition( defAnn.name(), defAnn.defaultCondition(), params );
-        LOG.bindingFilterDefinition(def.getFilterName());
+        LOG.bindingFilterDefinition( def.getFilterName() );
 		mappings.addFilterDefinition( def );
 	}
 
 	private static void bindTypeDefs(XAnnotatedElement annotatedElement, Mappings mappings) {
 		TypeDef defAnn = annotatedElement.getAnnotation( TypeDef.class );
 		TypeDefs defsAnn = annotatedElement.getAnnotation( TypeDefs.class );
 		if ( defAnn != null ) {
 			bindTypeDef( defAnn, mappings );
 		}
 		if ( defsAnn != null ) {
 			for ( TypeDef def : defsAnn.value() ) {
 				bindTypeDef( def, mappings );
 			}
 		}
 	}
 
 	private static void bindFetchProfiles(XAnnotatedElement annotatedElement, Mappings mappings) {
 		FetchProfile fetchProfileAnnotation = annotatedElement.getAnnotation( FetchProfile.class );
 		FetchProfiles fetchProfileAnnotations = annotatedElement.getAnnotation( FetchProfiles.class );
 		if ( fetchProfileAnnotation != null ) {
 			bindFetchProfile( fetchProfileAnnotation, mappings );
 		}
 		if ( fetchProfileAnnotations != null ) {
 			for ( FetchProfile profile : fetchProfileAnnotations.value() ) {
 				bindFetchProfile( profile, mappings );
 			}
 		}
 	}
 
 	private static void bindFetchProfile(FetchProfile fetchProfileAnnotation, Mappings mappings) {
 		for ( FetchProfile.FetchOverride fetch : fetchProfileAnnotation.fetchOverrides() ) {
 			org.hibernate.annotations.FetchMode mode = fetch.mode();
 			if ( !mode.equals( org.hibernate.annotations.FetchMode.JOIN ) ) {
 				throw new MappingException( "Only FetchMode.JOIN is currently supported" );
 			}
 
 			SecondPass sp = new VerifyFetchProfileReferenceSecondPass( fetchProfileAnnotation.name(), fetch, mappings );
 			mappings.addSecondPass( sp );
 		}
 	}
 
 	private static void bindTypeDef(TypeDef defAnn, Mappings mappings) {
 		Properties params = new Properties();
 		for ( Parameter param : defAnn.parameters() ) {
 			params.setProperty( param.name(), param.value() );
 		}
 
 		if ( BinderHelper.isEmptyAnnotationValue( defAnn.name() ) && defAnn.defaultForType().equals( void.class ) ) {
 			throw new AnnotationException(
 					"Either name or defaultForType (or both) attribute should be set in TypeDef having typeClass " +
 							defAnn.typeClass().getName()
 			);
 		}
 
 		if ( !BinderHelper.isEmptyAnnotationValue( defAnn.name() ) ) {
-            LOG.bindingTypeDefinition(defAnn.name());
+            LOG.bindingTypeDefinition( defAnn.name() );
 			mappings.addTypeDef( defAnn.name(), defAnn.typeClass().getName(), params );
 		}
 		if ( !defAnn.defaultForType().equals( void.class ) ) {
-            LOG.bindingTypeDefinition(defAnn.defaultForType().getName());
+            LOG.bindingTypeDefinition( defAnn.defaultForType().getName() );
 			mappings.addTypeDef( defAnn.defaultForType().getName(), defAnn.typeClass().getName(), params );
 		}
 
 	}
 
 
 	private static void bindDiscriminatorToPersistentClass(
 			RootClass rootClass,
 			Ejb3DiscriminatorColumn discriminatorColumn,
 			Map<String, Join> secondaryTables,
 			PropertyHolder propertyHolder,
 			Mappings mappings) {
 		if ( rootClass.getDiscriminator() == null ) {
 			if ( discriminatorColumn == null ) {
 				throw new AssertionFailure( "discriminator column should have been built" );
 			}
 			discriminatorColumn.setJoins( secondaryTables );
 			discriminatorColumn.setPropertyHolder( propertyHolder );
 			SimpleValue discrim = new SimpleValue( mappings, rootClass.getTable() );
 			rootClass.setDiscriminator( discrim );
 			discriminatorColumn.linkWithValue( discrim );
 			discrim.setTypeName( discriminatorColumn.getDiscriminatorTypeName() );
 			rootClass.setPolymorphic( true );
             LOG.trace("Setting discriminator for entity " + rootClass.getEntityName());
 		}
 	}
 
 	/**
 	 * @param elements List of {@code ProperyData} instances
 	 * @param defaultAccessType The default value access strategy which has to be used in case no explicit local access
 	 * strategy is used
 	 * @param propertyContainer Metadata about a class and its properties
 	 * @param mappings Mapping meta data
 	 *
 	 * @return the number of id properties found while iterating the elements of {@code annotatedClass} using
 	 *         the determined access strategy, {@code false} otherwise.
 	 */
 	static int addElementsOfClass(
 			List<PropertyData> elements,
 			AccessType defaultAccessType,
 			PropertyContainer propertyContainer,
 			Mappings mappings) {
 		int idPropertyCounter = 0;
 		AccessType accessType = defaultAccessType;
 
 		if ( propertyContainer.hasExplicitAccessStrategy() ) {
 			accessType = propertyContainer.getExplicitAccessStrategy();
 		}
 
 		Collection<XProperty> properties = propertyContainer.getProperties( accessType );
 		for ( XProperty p : properties ) {
 			final int currentIdPropertyCounter = addProperty(
 					propertyContainer, p, elements, accessType.getType(), mappings
 			);
 			idPropertyCounter += currentIdPropertyCounter;
 		}
 		return idPropertyCounter;
 	}
 
 	private static int addProperty(
 			PropertyContainer propertyContainer,
 			XProperty property,
 			List<PropertyData> annElts,
 			String propertyAccessor,
 			Mappings mappings) {
 		final XClass declaringClass = propertyContainer.getDeclaringClass();
 		final XClass entity = propertyContainer.getEntityAtStake();
 		int idPropertyCounter = 0;
 		PropertyData propertyAnnotatedElement = new PropertyInferredData(
 				declaringClass, property, propertyAccessor,
 				mappings.getReflectionManager()
 		);
 
 		/*
 		 * put element annotated by @Id in front
 		 * since it has to be parsed before any association by Hibernate
 		 */
 		final XAnnotatedElement element = propertyAnnotatedElement.getProperty();
 		if ( element.isAnnotationPresent( Id.class ) || element.isAnnotationPresent( EmbeddedId.class ) ) {
 			annElts.add( 0, propertyAnnotatedElement );
 			/**
 			 * The property must be put in hibernate.properties as it's a system wide property. Fixable?
 			 * TODO support true/false/default on the property instead of present / not present
 			 * TODO is @Column mandatory?
 			 * TODO add method support
 			 */
 			if ( mappings.isSpecjProprietarySyntaxEnabled() ) {
 				if ( element.isAnnotationPresent( Id.class ) && element.isAnnotationPresent( Column.class ) ) {
 					String columnName = element.getAnnotation( Column.class ).name();
 					for ( XProperty prop : declaringClass.getDeclaredProperties( AccessType.FIELD.getType() ) ) {
 						if ( prop.isAnnotationPresent( JoinColumn.class )
 								&& prop.getAnnotation( JoinColumn.class ).name().equals( columnName )
 								&& !prop.isAnnotationPresent( MapsId.class ) ) {
 							//create a PropertyData fpr the specJ property holding the mapping
 							PropertyData specJPropertyData = new PropertyInferredData(
 									declaringClass,  //same dec
 									prop, // the actual @XToOne property
 									propertyAccessor, //TODO we should get the right accessor but the same as id would do
 									mappings.getReflectionManager()
 							);
 							mappings.addPropertyAnnotatedWithMapsIdSpecj( entity, specJPropertyData, element.toString() );
 						}
 					}
 				}
 			}
 
 			if ( element.isAnnotationPresent( ManyToOne.class ) || element.isAnnotationPresent( OneToOne.class ) ) {
 				mappings.addToOneAndIdProperty( entity, propertyAnnotatedElement );
 			}
 			idPropertyCounter++;
 		}
 		else {
 			annElts.add( propertyAnnotatedElement );
 		}
 		if ( element.isAnnotationPresent( MapsId.class ) ) {
 			mappings.addPropertyAnnotatedWithMapsId( entity, propertyAnnotatedElement );
 		}
 
 		return idPropertyCounter;
 	}
 
 	/*
 	 * Process annotation of a particular property
 	 */
 
 	private static void processElementAnnotations(
 			PropertyHolder propertyHolder,
 			Nullability nullability,
 			PropertyData inferredData,
 			HashMap<String, IdGenerator> classGenerators,
 			EntityBinder entityBinder,
 			boolean isIdentifierMapper,
 			boolean isComponentEmbedded,
 			boolean inSecondPass,
 			Mappings mappings,
 			Map<XClass, InheritanceState> inheritanceStatePerClass) throws MappingException {
 		/**
 		 * inSecondPass can only be used to apply right away the second pass of a composite-element
 		 * Because it's a value type, there is no bidirectional association, hence second pass
 		 * ordering does not matter
 		 */
 
         LOG.trace("Processing annotations of " + propertyHolder.getEntityName() + "." + inferredData.getPropertyName());
 
 		final XProperty property = inferredData.getProperty();
 		if ( property.isAnnotationPresent( Parent.class ) ) {
 			if ( propertyHolder.isComponent() ) {
 				propertyHolder.setParentProperty( property.getName() );
 			}
 			else {
 				throw new AnnotationException(
 						"@Parent cannot be applied outside an embeddable object: "
 								+ BinderHelper.getPath( propertyHolder, inferredData )
 				);
 			}
 			return;
 		}
 
 		ColumnsBuilder columnsBuilder = new ColumnsBuilder(
 				propertyHolder, nullability, property, inferredData, entityBinder, mappings
 		).extractMetadata();
 		Ejb3Column[] columns = columnsBuilder.getColumns();
 		Ejb3JoinColumn[] joinColumns = columnsBuilder.getJoinColumns();
 
 		final XClass returnedClass = inferredData.getClassOrElement();
 
 		//prepare PropertyBinder
 		PropertyBinder propertyBinder = new PropertyBinder();
 		propertyBinder.setName( inferredData.getPropertyName() );
 		propertyBinder.setReturnedClassName( inferredData.getTypeName() );
 		propertyBinder.setAccessType( inferredData.getDefaultAccess() );
 		propertyBinder.setHolder( propertyHolder );
 		propertyBinder.setProperty( property );
 		propertyBinder.setReturnedClass( inferredData.getPropertyClass() );
 		propertyBinder.setMappings( mappings );
 		if ( isIdentifierMapper ) {
 			propertyBinder.setInsertable( false );
 			propertyBinder.setUpdatable( false );
 		}
 		propertyBinder.setDeclaringClass( inferredData.getDeclaringClass() );
 		propertyBinder.setEntityBinder( entityBinder );
 		propertyBinder.setInheritanceStatePerClass( inheritanceStatePerClass );
 
 		boolean isId = !entityBinder.isIgnoreIdAnnotations() &&
 				( property.isAnnotationPresent( Id.class )
 						|| property.isAnnotationPresent( EmbeddedId.class ) );
 		propertyBinder.setId( isId );
 
 		if ( property.isAnnotationPresent( Version.class ) ) {
 			if ( isIdentifierMapper ) {
 				throw new AnnotationException(
 						"@IdClass class should not have @Version property"
 				);
 			}
 			if ( !( propertyHolder.getPersistentClass() instanceof RootClass ) ) {
 				throw new AnnotationException(
 						"Unable to define/override @Version on a subclass: "
 								+ propertyHolder.getEntityName()
 				);
 			}
 			if ( !propertyHolder.isEntity() ) {
 				throw new AnnotationException(
 						"Unable to define @Version on an embedded class: "
 								+ propertyHolder.getEntityName()
 				);
 			}
             LOG.trace(inferredData.getPropertyName() + " is a version property");
 			RootClass rootClass = ( RootClass ) propertyHolder.getPersistentClass();
 			propertyBinder.setColumns( columns );
 			Property prop = propertyBinder.makePropertyValueAndBind();
 			setVersionInformation( property, propertyBinder );
 			rootClass.setVersion( prop );
 
 			//If version is on a mapped superclass, update the mapping
 			final org.hibernate.mapping.MappedSuperclass superclass = BinderHelper.getMappedSuperclassOrNull(
 					inferredData.getDeclaringClass(),
 					inheritanceStatePerClass,
 					mappings
 			);
 			if ( superclass != null ) {
 				superclass.setDeclaredVersion( prop );
 			}
 			else {
 				//we know the property is on the actual entity
 				rootClass.setDeclaredVersion( prop );
 			}
 
 			SimpleValue simpleValue = ( SimpleValue ) prop.getValue();
 			simpleValue.setNullValue( "undefined" );
 			rootClass.setOptimisticLockMode( Versioning.OPTIMISTIC_LOCK_VERSION );
             LOG.trace("Version name: " + rootClass.getVersion().getName() + ", unsavedValue: "
                       + ((SimpleValue)rootClass.getVersion().getValue()).getNullValue());
 		}
 		else {
 			final boolean forcePersist = property.isAnnotationPresent( MapsId.class )
 					|| property.isAnnotationPresent( Id.class );
 			if ( property.isAnnotationPresent( ManyToOne.class ) ) {
 				ManyToOne ann = property.getAnnotation( ManyToOne.class );
 
 				//check validity
 				if ( property.isAnnotationPresent( Column.class )
 						|| property.isAnnotationPresent( Columns.class ) ) {
 					throw new AnnotationException(
 							"@Column(s) not allowed on a @ManyToOne property: "
 									+ BinderHelper.getPath( propertyHolder, inferredData )
 					);
 				}
 
 				Cascade hibernateCascade = property.getAnnotation( Cascade.class );
 				NotFound notFound = property.getAnnotation( NotFound.class );
 				boolean ignoreNotFound = notFound != null && notFound.action().equals( NotFoundAction.IGNORE );
 				OnDelete onDeleteAnn = property.getAnnotation( OnDelete.class );
 				boolean onDeleteCascade = onDeleteAnn != null && OnDeleteAction.CASCADE.equals( onDeleteAnn.action() );
 				JoinTable assocTable = propertyHolder.getJoinTable( property );
 				if ( assocTable != null ) {
 					Join join = propertyHolder.addJoin( assocTable, false );
 					for ( Ejb3JoinColumn joinColumn : joinColumns ) {
 						joinColumn.setSecondaryTableName( join.getTable().getName() );
 					}
 				}
 				final boolean mandatory = !ann.optional() || forcePersist;
 				bindManyToOne(
 						getCascadeStrategy( ann.cascade(), hibernateCascade, false, forcePersist ),
 						joinColumns,
 						!mandatory,
 						ignoreNotFound, onDeleteCascade,
 						ToOneBinder.getTargetEntity( inferredData, mappings ),
 						propertyHolder,
 						inferredData, false, isIdentifierMapper,
 						inSecondPass, propertyBinder, mappings
 				);
 			}
 			else if ( property.isAnnotationPresent( OneToOne.class ) ) {
 				OneToOne ann = property.getAnnotation( OneToOne.class );
 
 				//check validity
 				if ( property.isAnnotationPresent( Column.class )
 						|| property.isAnnotationPresent( Columns.class ) ) {
 					throw new AnnotationException(
 							"@Column(s) not allowed on a @OneToOne property: "
 									+ BinderHelper.getPath( propertyHolder, inferredData )
 					);
 				}
 
 				//FIXME support a proper PKJCs
 				boolean trueOneToOne = property.isAnnotationPresent( PrimaryKeyJoinColumn.class )
 						|| property.isAnnotationPresent( PrimaryKeyJoinColumns.class );
 				Cascade hibernateCascade = property.getAnnotation( Cascade.class );
 				NotFound notFound = property.getAnnotation( NotFound.class );
 				boolean ignoreNotFound = notFound != null && notFound.action().equals( NotFoundAction.IGNORE );
 				OnDelete onDeleteAnn = property.getAnnotation( OnDelete.class );
 				boolean onDeleteCascade = onDeleteAnn != null && OnDeleteAction.CASCADE.equals( onDeleteAnn.action() );
 				JoinTable assocTable = propertyHolder.getJoinTable( property );
 				if ( assocTable != null ) {
 					Join join = propertyHolder.addJoin( assocTable, false );
 					for ( Ejb3JoinColumn joinColumn : joinColumns ) {
 						joinColumn.setSecondaryTableName( join.getTable().getName() );
 					}
 				}
 				//MapsId means the columns belong to the pk => not null
 				//@PKJC must be constrained
 				final boolean mandatory = !ann.optional() || forcePersist || trueOneToOne;
 				bindOneToOne(
 						getCascadeStrategy( ann.cascade(), hibernateCascade, ann.orphanRemoval(), forcePersist ),
 						joinColumns,
 						!mandatory,
 						getFetchMode( ann.fetch() ),
 						ignoreNotFound, onDeleteCascade,
 						ToOneBinder.getTargetEntity( inferredData, mappings ),
 						propertyHolder,
 						inferredData,
 						ann.mappedBy(),
 						trueOneToOne,
 						isIdentifierMapper,
 						inSecondPass,
 						propertyBinder,
 						mappings
 				);
 			}
 			else if ( property.isAnnotationPresent( org.hibernate.annotations.Any.class ) ) {
 
 				//check validity
 				if ( property.isAnnotationPresent( Column.class )
 						|| property.isAnnotationPresent( Columns.class ) ) {
 					throw new AnnotationException(
 							"@Column(s) not allowed on a @Any property: "
 									+ BinderHelper.getPath( propertyHolder, inferredData )
 					);
 				}
 
 				Cascade hibernateCascade = property.getAnnotation( Cascade.class );
 				OnDelete onDeleteAnn = property.getAnnotation( OnDelete.class );
 				boolean onDeleteCascade = onDeleteAnn != null && OnDeleteAction.CASCADE.equals( onDeleteAnn.action() );
 				JoinTable assocTable = propertyHolder.getJoinTable( property );
 				if ( assocTable != null ) {
 					Join join = propertyHolder.addJoin( assocTable, false );
 					for ( Ejb3JoinColumn joinColumn : joinColumns ) {
 						joinColumn.setSecondaryTableName( join.getTable().getName() );
 					}
 				}
 				bindAny(
 						getCascadeStrategy( null, hibernateCascade, false, forcePersist ),
 						//@Any has not cascade attribute
 						joinColumns,
 						onDeleteCascade,
 						nullability,
 						propertyHolder,
 						inferredData,
 						entityBinder,
 						isIdentifierMapper,
 						mappings
 				);
 			}
 			else if ( property.isAnnotationPresent( OneToMany.class )
 					|| property.isAnnotationPresent( ManyToMany.class )
 					|| property.isAnnotationPresent( CollectionOfElements.class ) //legacy Hibernate
 					|| property.isAnnotationPresent( ElementCollection.class )
 					|| property.isAnnotationPresent( ManyToAny.class ) ) {
 				OneToMany oneToManyAnn = property.getAnnotation( OneToMany.class );
 				ManyToMany manyToManyAnn = property.getAnnotation( ManyToMany.class );
 				ElementCollection elementCollectionAnn = property.getAnnotation( ElementCollection.class );
 				CollectionOfElements collectionOfElementsAnn = property.getAnnotation( CollectionOfElements.class ); //legacy hibernate
 
 				final IndexColumn indexColumn;
 
 				if ( property.isAnnotationPresent( OrderColumn.class ) ) {
 					indexColumn = IndexColumn.buildColumnFromAnnotation(
 							property.getAnnotation( OrderColumn.class ),
 							propertyHolder,
 							inferredData,
 							entityBinder.getSecondaryTables(),
 							mappings
 					);
 				}
 				else {
 					//if @IndexColumn is not there, the generated IndexColumn is an implicit column and not used.
 					//so we can leave the legacy processing as the default
 					indexColumn = IndexColumn.buildColumnFromAnnotation(
 							property.getAnnotation( org.hibernate.annotations.IndexColumn.class ),
 							propertyHolder,
 							inferredData,
 							mappings
 					);
 				}
 				CollectionBinder collectionBinder = CollectionBinder.getCollectionBinder(
 						propertyHolder.getEntityName(),
 						property,
 						!indexColumn.isImplicit(),
 						property.isAnnotationPresent( CollectionOfElements.class )
 								|| property.isAnnotationPresent( org.hibernate.annotations.MapKey.class )
 								|| property.isAnnotationPresent( MapKeyType.class )
 
 						// || property.isAnnotationPresent( ManyToAny.class )
 				);
 				collectionBinder.setIndexColumn( indexColumn );
 				collectionBinder.setMapKey( property.getAnnotation( MapKey.class ) );
 				collectionBinder.setPropertyName( inferredData.getPropertyName() );
 				BatchSize batchAnn = property.getAnnotation( BatchSize.class );
 				collectionBinder.setBatchSize( batchAnn );
 				javax.persistence.OrderBy ejb3OrderByAnn = property.getAnnotation( javax.persistence.OrderBy.class );
 				OrderBy orderByAnn = property.getAnnotation( OrderBy.class );
 				collectionBinder.setEjb3OrderBy( ejb3OrderByAnn );
 				collectionBinder.setSqlOrderBy( orderByAnn );
 				Sort sortAnn = property.getAnnotation( Sort.class );
 				collectionBinder.setSort( sortAnn );
 				Cache cachAnn = property.getAnnotation( Cache.class );
 				collectionBinder.setCache( cachAnn );
 				collectionBinder.setPropertyHolder( propertyHolder );
 				Cascade hibernateCascade = property.getAnnotation( Cascade.class );
 				NotFound notFound = property.getAnnotation( NotFound.class );
 				boolean ignoreNotFound = notFound != null && notFound.action().equals( NotFoundAction.IGNORE );
 				collectionBinder.setIgnoreNotFound( ignoreNotFound );
 				collectionBinder.setCollectionType( inferredData.getProperty().getElementClass() );
 				collectionBinder.setMappings( mappings );
 				collectionBinder.setAccessType( inferredData.getDefaultAccess() );
 
 				Ejb3Column[] elementColumns;
 				//do not use "element" if you are a JPA 2 @ElementCollection only for legacy Hibernate mappings
 				boolean isJPA2ForValueMapping = property.isAnnotationPresent( ElementCollection.class );
 				PropertyData virtualProperty = isJPA2ForValueMapping ? inferredData : new WrappedInferredData(
 						inferredData, "element"
 				);
 				if ( property.isAnnotationPresent( Column.class ) || property.isAnnotationPresent(
 						Formula.class
 				) ) {
 					Column ann = property.getAnnotation( Column.class );
 					Formula formulaAnn = property.getAnnotation( Formula.class );
 					elementColumns = Ejb3Column.buildColumnFromAnnotation(
 							new Column[] { ann },
 							formulaAnn,
 							nullability,
 							propertyHolder,
 							virtualProperty,
 							entityBinder.getSecondaryTables(),
 							mappings
 					);
 				}
 				else if ( property.isAnnotationPresent( Columns.class ) ) {
 					Columns anns = property.getAnnotation( Columns.class );
 					elementColumns = Ejb3Column.buildColumnFromAnnotation(
 							anns.columns(), null, nullability, propertyHolder, virtualProperty,
 							entityBinder.getSecondaryTables(), mappings
 					);
 				}
 				else {
 					elementColumns = Ejb3Column.buildColumnFromAnnotation(
 							null,
 							null,
 							nullability,
 							propertyHolder,
 							virtualProperty,
 							entityBinder.getSecondaryTables(),
 							mappings
 					);
 				}
 				{
 					Column[] keyColumns = null;
 					//JPA 2 has priority and has different default column values, differenciate legacy from JPA 2
 					Boolean isJPA2 = null;
 					if ( property.isAnnotationPresent( MapKeyColumn.class ) ) {
 						isJPA2 = Boolean.TRUE;
 						keyColumns = new Column[] { new MapKeyColumnDelegator( property.getAnnotation( MapKeyColumn.class ) ) };
 					}
 					else if ( property.isAnnotationPresent( org.hibernate.annotations.MapKey.class ) ) {
 						if ( isJPA2 == null ) {
 							isJPA2 = Boolean.FALSE;
 						}
 						keyColumns = property.getAnnotation( org.hibernate.annotations.MapKey.class ).columns();
 					}
 
 					//not explicitly legacy
 					if ( isJPA2 == null ) {
 						isJPA2 = Boolean.TRUE;
 					}
 
 					//nullify empty array
 					keyColumns = keyColumns != null && keyColumns.length > 0 ? keyColumns : null;
 
 					//"mapkey" is the legacy column name of the key column pre JPA 2
 					PropertyData mapKeyVirtualProperty = new WrappedInferredData( inferredData, "mapkey" );
 					Ejb3Column[] mapColumns = Ejb3Column.buildColumnFromAnnotation(
 							keyColumns,
 							null,
 							Nullability.FORCED_NOT_NULL,
 							propertyHolder,
 							isJPA2 ? inferredData : mapKeyVirtualProperty,
 							isJPA2 ? "_KEY" : null,
 							entityBinder.getSecondaryTables(),
 							mappings
 					);
 					collectionBinder.setMapKeyColumns( mapColumns );
 				}
 				{
 					JoinColumn[] joinKeyColumns = null;
 					//JPA 2 has priority and has different default column values, differenciate legacy from JPA 2
 					Boolean isJPA2 = null;
 					if ( property.isAnnotationPresent( MapKeyJoinColumns.class ) ) {
 						isJPA2 = Boolean.TRUE;
 						final MapKeyJoinColumn[] mapKeyJoinColumns = property.getAnnotation( MapKeyJoinColumns.class )
 								.value();
 						joinKeyColumns = new JoinColumn[mapKeyJoinColumns.length];
 						int index = 0;
 						for ( MapKeyJoinColumn joinColumn : mapKeyJoinColumns ) {
 							joinKeyColumns[index] = new MapKeyJoinColumnDelegator( joinColumn );
 							index++;
 						}
 						if ( property.isAnnotationPresent( MapKeyJoinColumn.class ) ) {
 							throw new AnnotationException(
 									"@MapKeyJoinColumn and @MapKeyJoinColumns used on the same property: "
 											+ BinderHelper.getPath( propertyHolder, inferredData )
 							);
 						}
 					}
 					else if ( property.isAnnotationPresent( MapKeyJoinColumn.class ) ) {
 						isJPA2 = Boolean.TRUE;
 						joinKeyColumns = new JoinColumn[] {
 								new MapKeyJoinColumnDelegator(
 										property.getAnnotation(
 												MapKeyJoinColumn.class
 										)
 								)
 						};
 					}
 					else if ( property.isAnnotationPresent( org.hibernate.annotations.MapKeyManyToMany.class ) ) {
 						if ( isJPA2 == null ) {
 							isJPA2 = Boolean.FALSE;
 						}
 						joinKeyColumns = property.getAnnotation( org.hibernate.annotations.MapKeyManyToMany.class )
 								.joinColumns();
 					}
 
 					//not explicitly legacy
 					if ( isJPA2 == null ) {
 						isJPA2 = Boolean.TRUE;
 					}
 
 					PropertyData mapKeyVirtualProperty = new WrappedInferredData( inferredData, "mapkey" );
 					Ejb3JoinColumn[] mapJoinColumns = Ejb3JoinColumn.buildJoinColumnsWithDefaultColumnSuffix(
 							joinKeyColumns,
 							null,
 							entityBinder.getSecondaryTables(),
 							propertyHolder,
 							isJPA2 ? inferredData.getPropertyName() : mapKeyVirtualProperty.getPropertyName(),
 							isJPA2 ? "_KEY" : null,
 							mappings
 					);
 					collectionBinder.setMapKeyManyToManyColumns( mapJoinColumns );
 				}
 
 				//potential element
 				collectionBinder.setEmbedded( property.isAnnotationPresent( Embedded.class ) );
 				collectionBinder.setElementColumns( elementColumns );
 				collectionBinder.setProperty( property );
 
 				//TODO enhance exception with @ManyToAny and @CollectionOfElements
 				if ( oneToManyAnn != null && manyToManyAnn != null ) {
 					throw new AnnotationException(
 							"@OneToMany and @ManyToMany on the same property is not allowed: "
 									+ propertyHolder.getEntityName() + "." + inferredData.getPropertyName()
 					);
 				}
 				String mappedBy = null;
 				if ( oneToManyAnn != null ) {
 					for ( Ejb3JoinColumn column : joinColumns ) {
 						if ( column.isSecondary() ) {
 							throw new NotYetImplementedException( "Collections having FK in secondary table" );
 						}
 					}
 					collectionBinder.setFkJoinColumns( joinColumns );
 					mappedBy = oneToManyAnn.mappedBy();
 					collectionBinder.setTargetEntity(
 							mappings.getReflectionManager().toXClass( oneToManyAnn.targetEntity() )
 					);
 					collectionBinder.setCascadeStrategy(
 							getCascadeStrategy(
 									oneToManyAnn.cascade(), hibernateCascade, oneToManyAnn.orphanRemoval(), false
 							)
 					);
 					collectionBinder.setOneToMany( true );
 				}
 				else if ( elementCollectionAnn != null
 						|| collectionOfElementsAnn != null //Hibernate legacy
 						) {
 					for ( Ejb3JoinColumn column : joinColumns ) {
 						if ( column.isSecondary() ) {
 							throw new NotYetImplementedException( "Collections having FK in secondary table" );
 						}
 					}
 					collectionBinder.setFkJoinColumns( joinColumns );
 					mappedBy = "";
 					final Class<?> targetElement = elementCollectionAnn != null ?
 							elementCollectionAnn.targetClass() :
 							collectionOfElementsAnn.targetElement();
 					collectionBinder.setTargetEntity(
 							mappings.getReflectionManager().toXClass( targetElement )
 					);
 					//collectionBinder.setCascadeStrategy( getCascadeStrategy( embeddedCollectionAnn.cascade(), hibernateCascade ) );
 					collectionBinder.setOneToMany( true );
 				}
 				else if ( manyToManyAnn != null ) {
 					mappedBy = manyToManyAnn.mappedBy();
 					collectionBinder.setTargetEntity(
 							mappings.getReflectionManager().toXClass( manyToManyAnn.targetEntity() )
 					);
 					collectionBinder.setCascadeStrategy(
 							getCascadeStrategy(
 									manyToManyAnn.cascade(), hibernateCascade, false, false
 							)
 					);
 					collectionBinder.setOneToMany( false );
 				}
 				else if ( property.isAnnotationPresent( ManyToAny.class ) ) {
 					mappedBy = "";
 					collectionBinder.setTargetEntity(
 							mappings.getReflectionManager().toXClass( void.class )
 					);
 					collectionBinder.setCascadeStrategy( getCascadeStrategy( null, hibernateCascade, false, false ) );
 					collectionBinder.setOneToMany( false );
 				}
 				collectionBinder.setMappedBy( mappedBy );
 
 				bindJoinedTableAssociation(
 						property, mappings, entityBinder, collectionBinder, propertyHolder, inferredData, mappedBy
 				);
 
 				OnDelete onDeleteAnn = property.getAnnotation( OnDelete.class );
 				boolean onDeleteCascade = onDeleteAnn != null && OnDeleteAction.CASCADE.equals( onDeleteAnn.action() );
 				collectionBinder.setCascadeDeleteEnabled( onDeleteCascade );
 				if ( isIdentifierMapper ) {
 					collectionBinder.setInsertable( false );
 					collectionBinder.setUpdatable( false );
 				}
 				if ( property.isAnnotationPresent( CollectionId.class ) ) { //do not compute the generators unless necessary
 					HashMap<String, IdGenerator> localGenerators = ( HashMap<String, IdGenerator> ) classGenerators.clone();
 					localGenerators.putAll( buildLocalGenerators( property, mappings ) );
 					collectionBinder.setLocalGenerators( localGenerators );
 
 				}
 				collectionBinder.setInheritanceStatePerClass( inheritanceStatePerClass );
 				collectionBinder.setDeclaringClass( inferredData.getDeclaringClass() );
 				collectionBinder.bind();
 
 			}
 			//Either a regular property or a basic @Id or @EmbeddedId while not ignoring id annotations
 			else if ( !isId || !entityBinder.isIgnoreIdAnnotations() ) {
 				//define whether the type is a component or not
 
 				boolean isComponent = false;
 
 				//Overrides from @MapsId if needed
 				boolean isOverridden = false;
 				if ( isId || propertyHolder.isOrWithinEmbeddedId() || propertyHolder.isInIdClass() ) {
 					//the associated entity could be using an @IdClass making the overridden property a component
 					final PropertyData overridingProperty = BinderHelper.getPropertyOverriddenByMapperOrMapsId(
 							isId, propertyHolder, property.getName(), mappings
 					);
 					if ( overridingProperty != null ) {
 						isOverridden = true;
 						final InheritanceState state = inheritanceStatePerClass.get( overridingProperty.getClassOrElement() );
 						if ( state != null ) {
 							isComponent = isComponent || state.hasIdClassOrEmbeddedId();
 						}
 						//Get the new column
 						columns = columnsBuilder.overrideColumnFromMapperOrMapsIdProperty( isId );
 					}
 				}
 
 				isComponent = isComponent
 						|| property.isAnnotationPresent( Embedded.class )
 						|| property.isAnnotationPresent( EmbeddedId.class )
 						|| returnedClass.isAnnotationPresent( Embeddable.class );
 
 
 				if ( isComponent ) {
 					String referencedEntityName = null;
 					if ( isOverridden ) {
 						final PropertyData mapsIdProperty = BinderHelper.getPropertyOverriddenByMapperOrMapsId(
 								isId, propertyHolder, property.getName(), mappings
 						);
 						referencedEntityName = mapsIdProperty.getClassOrElementName();
 					}
 					AccessType propertyAccessor = entityBinder.getPropertyAccessor( property );
 					propertyBinder = bindComponent(
 							inferredData,
 							propertyHolder,
 							propertyAccessor,
 							entityBinder,
 							isIdentifierMapper,
 							mappings,
 							isComponentEmbedded,
 							isId,
 							inheritanceStatePerClass,
 							referencedEntityName,
 							isOverridden ? ( Ejb3JoinColumn[] ) columns : null
 					);
 				}
 				else {
 					//provide the basic property mapping
 					boolean optional = true;
 					boolean lazy = false;
 					if ( property.isAnnotationPresent( Basic.class ) ) {
 						Basic ann = property.getAnnotation( Basic.class );
 						optional = ann.optional();
 						lazy = ann.fetch() == FetchType.LAZY;
 					}
 					//implicit type will check basic types and Serializable classes
 					if ( isId || ( !optional && nullability != Nullability.FORCED_NULL ) ) {
 						//force columns to not null
 						for ( Ejb3Column col : columns ) {
 							col.forceNotNull();
 						}
 					}
 
 					propertyBinder.setLazy( lazy );
 					propertyBinder.setColumns( columns );
 					if ( isOverridden ) {
 						final PropertyData mapsIdProperty = BinderHelper.getPropertyOverriddenByMapperOrMapsId(
 								isId, propertyHolder, property.getName(), mappings
 						);
 						propertyBinder.setReferencedEntityName( mapsIdProperty.getClassOrElementName() );
 					}
 
 					propertyBinder.makePropertyValueAndBind();
 
 				}
 				if ( isOverridden ) {
 					final PropertyData mapsIdProperty = BinderHelper.getPropertyOverriddenByMapperOrMapsId(
 							isId, propertyHolder, property.getName(), mappings
 					);
 					Map<String, IdGenerator> localGenerators = ( HashMap<String, IdGenerator> ) classGenerators.clone();
 					final IdGenerator foreignGenerator = new IdGenerator();
 					foreignGenerator.setIdentifierGeneratorStrategy( "assigned" );
 					foreignGenerator.setName( "Hibernate-local--foreign generator" );
 					foreignGenerator.setIdentifierGeneratorStrategy( "foreign" );
 					foreignGenerator.addParam( "property", mapsIdProperty.getPropertyName() );
 					localGenerators.put( foreignGenerator.getName(), foreignGenerator );
 
 					BinderHelper.makeIdGenerator(
 							( SimpleValue ) propertyBinder.getValue(),
 							foreignGenerator.getIdentifierGeneratorStrategy(),
 							foreignGenerator.getName(),
 							mappings,
 							localGenerators
 					);
 				}
 				if ( isId ) {
 					//components and regular basic types create SimpleValue objects
 					final SimpleValue value = ( SimpleValue ) propertyBinder.getValue();
 					if ( !isOverridden ) {
 						processId(
 								propertyHolder,
 								inferredData,
 								value,
 								classGenerators,
 								isIdentifierMapper,
 								mappings
 						);
 					}
 				}
 			}
 		}
 		//init index
 		//process indexes after everything: in second pass, many to one has to be done before indexes
 		Index index = property.getAnnotation( Index.class );
 		if ( index != null ) {
 			if ( joinColumns != null ) {
 
 				for ( Ejb3Column column : joinColumns ) {
 					column.addIndex( index, inSecondPass );
 				}
 			}
 			else {
 				if ( columns != null ) {
 					for ( Ejb3Column column : columns ) {
 						column.addIndex( index, inSecondPass );
 					}
 				}
 			}
 		}
 
 		NaturalId naturalIdAnn = property.getAnnotation( NaturalId.class );
 		if ( naturalIdAnn != null ) {
 			if ( joinColumns != null ) {
 				for ( Ejb3Column column : joinColumns ) {
 					column.addUniqueKey( "_UniqueKey", inSecondPass );
 				}
 			}
 			else {
 				for ( Ejb3Column column : columns ) {
 					column.addUniqueKey( "_UniqueKey", inSecondPass );
 				}
 			}
 		}
 	}
 
 	private static void setVersionInformation(XProperty property, PropertyBinder propertyBinder) {
 		propertyBinder.getSimpleValueBinder().setVersion( true );
 		if(property.isAnnotationPresent( Source.class )) {
 			Source source = property.getAnnotation( Source.class );
 			propertyBinder.getSimpleValueBinder().setTimestampVersionType( source.value().typeName() );
 		}
 	}
 
 	private static void processId(
 			PropertyHolder propertyHolder,
 			PropertyData inferredData,
 			SimpleValue idValue,
 			HashMap<String, IdGenerator> classGenerators,
 			boolean isIdentifierMapper,
 			Mappings mappings) {
 		if ( isIdentifierMapper ) {
 			throw new AnnotationException(
 					"@IdClass class should not have @Id nor @EmbeddedId properties: "
 							+ BinderHelper.getPath( propertyHolder, inferredData )
 			);
 		}
 		XClass returnedClass = inferredData.getClassOrElement();
 		XProperty property = inferredData.getProperty();
 		//clone classGenerator and override with local values
 		HashMap<String, IdGenerator> localGenerators = ( HashMap<String, IdGenerator> ) classGenerators.clone();
 		localGenerators.putAll( buildLocalGenerators( property, mappings ) );
 
 		//manage composite related metadata
 		//guess if its a component and find id data access (property, field etc)
 		final boolean isComponent = returnedClass.isAnnotationPresent( Embeddable.class )
 				|| property.isAnnotationPresent( EmbeddedId.class );
 
 		GeneratedValue generatedValue = property.getAnnotation( GeneratedValue.class );
 		String generatorType = generatedValue != null ?
 				generatorType( generatedValue.strategy(), mappings ) :
 				"assigned";
 		String generatorName = generatedValue != null ?
 				generatedValue.generator() :
 				BinderHelper.ANNOTATION_STRING_DEFAULT;
 		if ( isComponent ) {
 			generatorType = "assigned";
 		} //a component must not have any generator
 		BinderHelper.makeIdGenerator( idValue, generatorType, generatorName, mappings, localGenerators );
 
         LOG.trace("Bind " + (isComponent ? "@EmbeddedId" : "@Id") + " on " + inferredData.getPropertyName());
 	}
 
 	//TODO move that to collection binder?
 
 	private static void bindJoinedTableAssociation(
 			XProperty property,
 			Mappings mappings,
 			EntityBinder entityBinder,
 			CollectionBinder collectionBinder,
 			PropertyHolder propertyHolder,
 			PropertyData inferredData,
 			String mappedBy) {
 		TableBinder associationTableBinder = new TableBinder();
 		JoinColumn[] annJoins;
 		JoinColumn[] annInverseJoins;
 		JoinTable assocTable = propertyHolder.getJoinTable( property );
 		CollectionTable collectionTable = property.getAnnotation( CollectionTable.class );
 
 		if ( assocTable != null || collectionTable != null ) {
 
 			final String catalog;
 			final String schema;
 			final String tableName;
 			final UniqueConstraint[] uniqueConstraints;
 			final JoinColumn[] joins;
 			final JoinColumn[] inverseJoins;
 
 			//JPA 2 has priority
 			if ( collectionTable != null ) {
 				catalog = collectionTable.catalog();
 				schema = collectionTable.schema();
 				tableName = collectionTable.name();
 				uniqueConstraints = collectionTable.uniqueConstraints();
 				joins = collectionTable.joinColumns();
 				inverseJoins = null;
 			}
 			else {
 				catalog = assocTable.catalog();
 				schema = assocTable.schema();
 				tableName = assocTable.name();
 				uniqueConstraints = assocTable.uniqueConstraints();
 				joins = assocTable.joinColumns();
 				inverseJoins = assocTable.inverseJoinColumns();
 			}
 
 			collectionBinder.setExplicitAssociationTable( true );
 
 			if ( !BinderHelper.isEmptyAnnotationValue( schema ) ) {
 				associationTableBinder.setSchema( schema );
 			}
 			if ( !BinderHelper.isEmptyAnnotationValue( catalog ) ) {
 				associationTableBinder.setCatalog( catalog );
 			}
 			if ( !BinderHelper.isEmptyAnnotationValue( tableName ) ) {
 				associationTableBinder.setName( tableName );
 			}
 			associationTableBinder.setUniqueConstraints( uniqueConstraints );
 
 			//set check constaint in the second pass
 			annJoins = joins.length == 0 ? null : joins;
 			annInverseJoins = inverseJoins == null || inverseJoins.length == 0 ? null : inverseJoins;
 		}
 		else {
 			annJoins = null;
 			annInverseJoins = null;
 		}
 		Ejb3JoinColumn[] joinColumns = Ejb3JoinColumn.buildJoinTableJoinColumns(
 				annJoins, entityBinder.getSecondaryTables(), propertyHolder, inferredData.getPropertyName(), mappedBy,
 				mappings
 		);
 		Ejb3JoinColumn[] inverseJoinColumns = Ejb3JoinColumn.buildJoinTableJoinColumns(
 				annInverseJoins, entityBinder.getSecondaryTables(), propertyHolder, inferredData.getPropertyName(),
 				mappedBy, mappings
 		);
 		associationTableBinder.setMappings( mappings );
 		collectionBinder.setTableBinder( associationTableBinder );
 		collectionBinder.setJoinColumns( joinColumns );
 		collectionBinder.setInverseJoinColumns( inverseJoinColumns );
 	}
 
 	private static PropertyBinder bindComponent(
 			PropertyData inferredData,
 			PropertyHolder propertyHolder,
 			AccessType propertyAccessor,
 			EntityBinder entityBinder,
 			boolean isIdentifierMapper,
 			Mappings mappings,
 			boolean isComponentEmbedded,
 			boolean isId, //is a identifier
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			String referencedEntityName, //is a component who is overridden by a @MapsId
 			Ejb3JoinColumn[] columns) {
 		Component comp;
 		if ( referencedEntityName != null ) {
 			comp = createComponent( propertyHolder, inferredData, isComponentEmbedded, isIdentifierMapper, mappings );
 			SecondPass sp = new CopyIdentifierComponentSecondPass(
 					comp,
 					referencedEntityName,
 					columns,
 					mappings
 			);
 			mappings.addSecondPass( sp );
 		}
 		else {
 			comp = fillComponent(
 					propertyHolder, inferredData, propertyAccessor, !isId, entityBinder,
 					isComponentEmbedded, isIdentifierMapper,
 					false, mappings, inheritanceStatePerClass
 			);
 		}
 		if ( isId ) {
 			comp.setKey( true );
 			if ( propertyHolder.getPersistentClass().getIdentifier() != null ) {
 				throw new AnnotationException(
 						comp.getComponentClassName()
 								+ " must not have @Id properties when used as an @EmbeddedId: "
 								+ BinderHelper.getPath( propertyHolder, inferredData )
 				);
 			}
 			if ( referencedEntityName == null && comp.getPropertySpan() == 0 ) {
 				throw new AnnotationException(
 						comp.getComponentClassName()
 								+ " has no persistent id property: "
 								+ BinderHelper.getPath( propertyHolder, inferredData )
 				);
 			}
 		}
 		XProperty property = inferredData.getProperty();
 		setupComponentTuplizer( property, comp );
 		PropertyBinder binder = new PropertyBinder();
 		binder.setName( inferredData.getPropertyName() );
 		binder.setValue( comp );
 		binder.setProperty( inferredData.getProperty() );
 		binder.setAccessType( inferredData.getDefaultAccess() );
 		binder.setEmbedded( isComponentEmbedded );
 		binder.setHolder( propertyHolder );
 		binder.setId( isId );
 		binder.setEntityBinder( entityBinder );
 		binder.setInheritanceStatePerClass( inheritanceStatePerClass );
 		binder.setMappings( mappings );
 		binder.makePropertyAndBind();
 		return binder;
 	}
 
 	public static Component fillComponent(
 			PropertyHolder propertyHolder,
 			PropertyData inferredData,
 			AccessType propertyAccessor,
 			boolean isNullable,
 			EntityBinder entityBinder,
 			boolean isComponentEmbedded,
 			boolean isIdentifierMapper,
 			boolean inSecondPass,
 			Mappings mappings,
 			Map<XClass, InheritanceState> inheritanceStatePerClass) {
 		return fillComponent(
 				propertyHolder, inferredData, null, propertyAccessor,
 				isNullable, entityBinder, isComponentEmbedded, isIdentifierMapper, inSecondPass, mappings,
 				inheritanceStatePerClass
 		);
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/BinderHelper.java b/hibernate-core/src/main/java/org/hibernate/cfg/BinderHelper.java
index 71d3471468..df3a594c40 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/BinderHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/BinderHelper.java
@@ -1,692 +1,693 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.StringTokenizer;
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.AnyMetaDef;
 import org.hibernate.annotations.AnyMetaDefs;
 import org.hibernate.annotations.MetaValue;
 import org.hibernate.annotations.common.reflection.XAnnotatedElement;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XPackage;
 import org.hibernate.cfg.annotations.EntityBinder;
 import org.hibernate.cfg.annotations.Nullability;
 import org.hibernate.cfg.annotations.TableBinder;
 import org.hibernate.id.MultipleHiLoPerTableGenerator;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Any;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.IdGenerator;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.MappedSuperclass;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.SyntheticProperty;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.ToOne;
 import org.hibernate.mapping.Value;
+
 import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 public class BinderHelper {
 
 	public static final String ANNOTATION_STRING_DEFAULT = "";
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BinderHelper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BinderHelper.class.getName());
 
 	private BinderHelper() {
 	}
 
 	static {
 		Set<String> primitiveNames = new HashSet<String>();
 		primitiveNames.add( byte.class.getName() );
 		primitiveNames.add( short.class.getName() );
 		primitiveNames.add( int.class.getName() );
 		primitiveNames.add( long.class.getName() );
 		primitiveNames.add( float.class.getName() );
 		primitiveNames.add( double.class.getName() );
 		primitiveNames.add( char.class.getName() );
 		primitiveNames.add( boolean.class.getName() );
 		PRIMITIVE_NAMES = Collections.unmodifiableSet( primitiveNames );
 	}
 
 	public static final Set<String> PRIMITIVE_NAMES;
 
 	/**
 	 * create a property copy reusing the same value
 	 */
 	public static Property shallowCopy(Property property) {
 		Property clone = new Property();
 		clone.setCascade( property.getCascade() );
 		clone.setInsertable( property.isInsertable() );
 		clone.setLazy( property.isLazy() );
 		clone.setName( property.getName() );
 		clone.setNodeName( property.getNodeName() );
 		clone.setNaturalIdentifier( property.isNaturalIdentifier() );
 		clone.setOptimisticLocked( property.isOptimisticLocked() );
 		clone.setOptional( property.isOptional() );
 		clone.setPersistentClass( property.getPersistentClass() );
 		clone.setPropertyAccessorName( property.getPropertyAccessorName() );
 		clone.setSelectable( property.isSelectable() );
 		clone.setUpdateable( property.isUpdateable() );
 		clone.setValue( property.getValue() );
 		return clone;
 	}
 
 	public static void createSyntheticPropertyReference(
 			Ejb3JoinColumn[] columns,
 			PersistentClass ownerEntity,
 			PersistentClass associatedEntity,
 			Value value,
 			boolean inverse,
 			Mappings mappings) {
 		//associated entity only used for more precise exception, yuk!
 		if ( columns[0].isImplicit() || StringHelper.isNotEmpty( columns[0].getMappedBy() ) ) return;
 		int fkEnum = Ejb3JoinColumn.checkReferencedColumnsType( columns, ownerEntity, mappings );
 		PersistentClass associatedClass = columns[0].getPropertyHolder() != null ?
 				columns[0].getPropertyHolder().getPersistentClass() :
 				null;
 		if ( Ejb3JoinColumn.NON_PK_REFERENCE == fkEnum ) {
 			/**
 			 * Create a synthetic property to refer to including an
 			 * embedded component value containing all the properties
 			 * mapped to the referenced columns
 			 * We need to shallow copy those properties to mark them
 			 * as non insertable / non updatable
 			 */
 			StringBuilder propertyNameBuffer = new StringBuilder( "_" );
 			propertyNameBuffer.append( associatedClass.getEntityName().replace( '.', '_' ) );
 			propertyNameBuffer.append( "_" ).append( columns[0].getPropertyName() );
 			String syntheticPropertyName = propertyNameBuffer.toString();
 			//find properties associated to a certain column
 			Object columnOwner = findColumnOwner( ownerEntity, columns[0].getReferencedColumn(), mappings );
 			List<Property> properties = findPropertiesByColumns( columnOwner, columns, mappings );
 			//create an embeddable component
 			Property synthProp = null;
 			if ( properties != null ) {
 				//todo how about properties.size() == 1, this should be much simpler
 				Component embeddedComp = columnOwner instanceof PersistentClass ?
 						new Component( mappings, (PersistentClass) columnOwner ) :
 						new Component( mappings, (Join) columnOwner );
 				embeddedComp.setEmbedded( true );
 				embeddedComp.setNodeName( syntheticPropertyName );
 				embeddedComp.setComponentClassName( embeddedComp.getOwner().getClassName() );
 				for (Property property : properties) {
 					Property clone = BinderHelper.shallowCopy( property );
 					clone.setInsertable( false );
 					clone.setUpdateable( false );
 					clone.setNaturalIdentifier( false );
 					clone.setGeneration( property.getGeneration() );
 					embeddedComp.addProperty( clone );
 				}
 				synthProp = new SyntheticProperty();
 				synthProp.setName( syntheticPropertyName );
 				synthProp.setNodeName( syntheticPropertyName );
 				synthProp.setPersistentClass( ownerEntity );
 				synthProp.setUpdateable( false );
 				synthProp.setInsertable( false );
 				synthProp.setValue( embeddedComp );
 				synthProp.setPropertyAccessorName( "embedded" );
 				ownerEntity.addProperty( synthProp );
 				//make it unique
 				TableBinder.createUniqueConstraint( embeddedComp );
 			}
 			else {
 				//TODO use a ToOne type doing a second select
 				StringBuilder columnsList = new StringBuilder();
 				columnsList.append( "referencedColumnNames(" );
 				for (Ejb3JoinColumn column : columns) {
 					columnsList.append( column.getReferencedColumn() ).append( ", " );
 				}
 				columnsList.setLength( columnsList.length() - 2 );
 				columnsList.append( ") " );
 
 				if ( associatedEntity != null ) {
 					//overidden destination
 					columnsList.append( "of " )
 							.append( associatedEntity.getEntityName() )
 							.append( "." )
 							.append( columns[0].getPropertyName() )
 							.append( " " );
 				}
 				else {
 					if ( columns[0].getPropertyHolder() != null ) {
 						columnsList.append( "of " )
 								.append( columns[0].getPropertyHolder().getEntityName() )
 								.append( "." )
 								.append( columns[0].getPropertyName() )
 								.append( " " );
 					}
 				}
 				columnsList.append( "referencing " )
 						.append( ownerEntity.getEntityName() )
 						.append( " not mapped to a single property" );
 				throw new AnnotationException( columnsList.toString() );
 			}
 
 			/**
 			 * creating the property ref to the new synthetic property
 			 */
 			if ( value instanceof ToOne ) {
 				( (ToOne) value ).setReferencedPropertyName( syntheticPropertyName );
 				mappings.addUniquePropertyReference( ownerEntity.getEntityName(), syntheticPropertyName );
 			}
 			else if ( value instanceof Collection ) {
 				( (Collection) value ).setReferencedPropertyName( syntheticPropertyName );
 				//not unique because we could create a mtm wo association table
 				mappings.addPropertyReference( ownerEntity.getEntityName(), syntheticPropertyName );
 			}
 			else {
 				throw new AssertionFailure(
 						"Do a property ref on an unexpected Value type: "
 								+ value.getClass().getName()
 				);
 			}
 			mappings.addPropertyReferencedAssociation(
 					( inverse ? "inverse__" : "" ) + associatedClass.getEntityName(),
 					columns[0].getPropertyName(),
 					syntheticPropertyName
 			);
 		}
 	}
 
 
 	private static List<Property> findPropertiesByColumns(
 			Object columnOwner,
 			Ejb3JoinColumn[] columns,
 			Mappings mappings) {
 		Map<Column, Set<Property>> columnsToProperty = new HashMap<Column, Set<Property>>();
 		List<Column> orderedColumns = new ArrayList<Column>( columns.length );
 		Table referencedTable = null;
 		if ( columnOwner instanceof PersistentClass ) {
 			referencedTable = ( (PersistentClass) columnOwner ).getTable();
 		}
 		else if ( columnOwner instanceof Join ) {
 			referencedTable = ( (Join) columnOwner ).getTable();
 		}
 		else {
 			throw new AssertionFailure(
 					columnOwner == null ?
 							"columnOwner is null" :
 							"columnOwner neither PersistentClass nor Join: " + columnOwner.getClass()
 			);
 		}
 		//build the list of column names
 		for (Ejb3JoinColumn column1 : columns) {
 			Column column = new Column(
 					mappings.getPhysicalColumnName( column1.getReferencedColumn(), referencedTable )
 			);
 			orderedColumns.add( column );
 			columnsToProperty.put( column, new HashSet<Property>() );
 		}
 		boolean isPersistentClass = columnOwner instanceof PersistentClass;
 		Iterator it = isPersistentClass ?
 				( (PersistentClass) columnOwner ).getPropertyIterator() :
 				( (Join) columnOwner ).getPropertyIterator();
 		while ( it.hasNext() ) {
 			matchColumnsByProperty( (Property) it.next(), columnsToProperty );
 		}
 		if ( isPersistentClass ) {
 			matchColumnsByProperty( ( (PersistentClass) columnOwner ).getIdentifierProperty(), columnsToProperty );
 		}
 
 		//first naive implementation
 		//only check 1 columns properties
 		//TODO make it smarter by checking correctly ordered multi column properties
 		List<Property> orderedProperties = new ArrayList<Property>();
 		for (Column column : orderedColumns) {
 			boolean found = false;
 			for (Property property : columnsToProperty.get( column ) ) {
 				if ( property.getColumnSpan() == 1 ) {
 					orderedProperties.add( property );
 					found = true;
 					break;
 				}
 			}
 			if ( !found ) return null; //have to find it the hard way
 		}
 		return orderedProperties;
 	}
 
 	private static void matchColumnsByProperty(Property property, Map<Column, Set<Property>> columnsToProperty) {
 		if ( property == null ) return;
 		if ( "noop".equals( property.getPropertyAccessorName() )
 				|| "embedded".equals( property.getPropertyAccessorName() ) ) {
 			return;
 		}
 // FIXME cannot use subproperties becasue the caller needs top level properties
 //		if ( property.isComposite() ) {
 //			Iterator subProperties = ( (Component) property.getValue() ).getPropertyIterator();
 //			while ( subProperties.hasNext() ) {
 //				matchColumnsByProperty( (Property) subProperties.next(), columnsToProperty );
 //			}
 //		}
 		else {
 			Iterator columnIt = property.getColumnIterator();
 			while ( columnIt.hasNext() ) {
 				Object column = columnIt.next(); //can be a Formula so we don't cast
 				//noinspection SuspiciousMethodCalls
 				if ( columnsToProperty.containsKey( column ) ) {
 					columnsToProperty.get( column ).add( property );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Retrieve the property by path in a recursive way, including IndetifierProperty in the loop
 	 * If propertyName is null or empty, the IdentifierProperty is returned
 	 */
 	public static Property findPropertyByName(PersistentClass associatedClass, String propertyName) {
 		Property property = null;
 		Property idProperty = associatedClass.getIdentifierProperty();
 		String idName = idProperty != null ? idProperty.getName() : null;
 		try {
 			if ( propertyName == null
 					|| propertyName.length() == 0
 					|| propertyName.equals( idName ) ) {
 				//default to id
 				property = idProperty;
 			}
 			else {
 				if ( propertyName.indexOf( idName + "." ) == 0 ) {
 					property = idProperty;
 					propertyName = propertyName.substring( idName.length() + 1 );
 				}
 				StringTokenizer st = new StringTokenizer( propertyName, ".", false );
 				while ( st.hasMoreElements() ) {
 					String element = (String) st.nextElement();
 					if ( property == null ) {
 						property = associatedClass.getProperty( element );
 					}
 					else {
 						if ( !property.isComposite() ) return null;
 						property = ( (Component) property.getValue() ).getProperty( element );
 					}
 				}
 			}
 		}
 		catch (MappingException e) {
 			try {
 				//if we do not find it try to check the identifier mapper
 				if ( associatedClass.getIdentifierMapper() == null ) return null;
 				StringTokenizer st = new StringTokenizer( propertyName, ".", false );
 				while ( st.hasMoreElements() ) {
 					String element = (String) st.nextElement();
 					if ( property == null ) {
 						property = associatedClass.getIdentifierMapper().getProperty( element );
 					}
 					else {
 						if ( !property.isComposite() ) return null;
 						property = ( (Component) property.getValue() ).getProperty( element );
 					}
 				}
 			}
 			catch (MappingException ee) {
 				return null;
 			}
 		}
 		return property;
 	}
 
 	/**
 	 * Retrieve the property by path in a recursive way
 	 */
 	public static Property findPropertyByName(Component component, String propertyName) {
 		Property property = null;
 		try {
 			if ( propertyName == null
 					|| propertyName.length() == 0) {
 				// Do not expect to use a primary key for this case
 				return null;
 			}
 			else {
 				StringTokenizer st = new StringTokenizer( propertyName, ".", false );
 				while ( st.hasMoreElements() ) {
 					String element = (String) st.nextElement();
 					if ( property == null ) {
 						property = component.getProperty( element );
 					}
 					else {
 						if ( !property.isComposite() ) return null;
 						property = ( (Component) property.getValue() ).getProperty( element );
 					}
 				}
 			}
 		}
 		catch (MappingException e) {
 			try {
 				//if we do not find it try to check the identifier mapper
 				if ( component.getOwner().getIdentifierMapper() == null ) return null;
 				StringTokenizer st = new StringTokenizer( propertyName, ".", false );
 				while ( st.hasMoreElements() ) {
 					String element = (String) st.nextElement();
 					if ( property == null ) {
 						property = component.getOwner().getIdentifierMapper().getProperty( element );
 					}
 					else {
 						if ( !property.isComposite() ) return null;
 						property = ( (Component) property.getValue() ).getProperty( element );
 					}
 				}
 			}
 			catch (MappingException ee) {
 				return null;
 			}
 		}
 		return property;
 	}
 
 	public static String getRelativePath(PropertyHolder propertyHolder, String propertyName) {
 		if ( propertyHolder == null ) return propertyName;
 		String path = propertyHolder.getPath();
 		String entityName = propertyHolder.getPersistentClass().getEntityName();
 		if ( path.length() == entityName.length() ) {
 			return propertyName;
 		}
 		else {
 			return StringHelper.qualify( path.substring( entityName.length() + 1 ), propertyName );
 		}
 	}
 
 	/**
 	 * Find the column owner (ie PersistentClass or Join) of columnName.
 	 * If columnName is null or empty, persistentClass is returned
 	 */
 	public static Object findColumnOwner(
 			PersistentClass persistentClass,
 			String columnName,
 			Mappings mappings) {
 		if ( StringHelper.isEmpty( columnName ) ) {
 			return persistentClass; //shortcut for implicit referenced column names
 		}
 		PersistentClass current = persistentClass;
 		Object result;
 		boolean found = false;
 		do {
 			result = current;
 			Table currentTable = current.getTable();
 			try {
 				mappings.getPhysicalColumnName( columnName, currentTable );
 				found = true;
 			}
 			catch (MappingException me) {
 				//swallow it
 			}
 			Iterator joins = current.getJoinIterator();
 			while ( !found && joins.hasNext() ) {
 				result = joins.next();
 				currentTable = ( (Join) result ).getTable();
 				try {
 					mappings.getPhysicalColumnName( columnName, currentTable );
 					found = true;
 				}
 				catch (MappingException me) {
 					//swallow it
 				}
 			}
 			current = current.getSuperclass();
 		}
 		while ( !found && current != null );
 		return found ? result : null;
 	}
 
 	/**
 	 * apply an id generator to a SimpleValue
 	 */
 	public static void makeIdGenerator(
 			SimpleValue id,
 			String generatorType,
 			String generatorName,
 			Mappings mappings,
 			Map<String, IdGenerator> localGenerators) {
 		Table table = id.getTable();
 		table.setIdentifierValue( id );
 		//generator settings
 		id.setIdentifierGeneratorStrategy( generatorType );
 		Properties params = new Properties();
 		//always settable
 		params.setProperty(
 				PersistentIdentifierGenerator.TABLE, table.getName()
 		);
 
 		if ( id.getColumnSpan() == 1 ) {
 			params.setProperty(
 					PersistentIdentifierGenerator.PK,
 					( (org.hibernate.mapping.Column) id.getColumnIterator().next() ).getName()
 			);
 		}
 		// YUCK!  but cannot think of a clean way to do this given the string-config based scheme
 		params.put( PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER, mappings.getObjectNameNormalizer() );
 
 		if ( !isEmptyAnnotationValue( generatorName ) ) {
 			//we have a named generator
 			IdGenerator gen = mappings.getGenerator( generatorName, localGenerators );
 			if ( gen == null ) {
 				throw new AnnotationException( "Unknown Id.generator: " + generatorName );
 			}
 			//This is quite vague in the spec but a generator could override the generate choice
 			String identifierGeneratorStrategy = gen.getIdentifierGeneratorStrategy();
 			//yuk! this is a hack not to override 'AUTO' even if generator is set
 			final boolean avoidOverriding =
 					identifierGeneratorStrategy.equals( "identity" )
 							|| identifierGeneratorStrategy.equals( "seqhilo" )
 							|| identifierGeneratorStrategy.equals( MultipleHiLoPerTableGenerator.class.getName() );
 			if ( generatorType == null || !avoidOverriding ) {
 				id.setIdentifierGeneratorStrategy( identifierGeneratorStrategy );
 			}
 			//checkIfMatchingGenerator(gen, generatorType, generatorName);
 			Iterator genParams = gen.getParams().entrySet().iterator();
 			while ( genParams.hasNext() ) {
 				Map.Entry elt = (Map.Entry) genParams.next();
 				params.setProperty( (String) elt.getKey(), (String) elt.getValue() );
 			}
 		}
 		if ( "assigned".equals( generatorType ) ) id.setNullValue( "undefined" );
 		id.setIdentifierGeneratorProperties( params );
 	}
 
 	public static boolean isEmptyAnnotationValue(String annotationString) {
 		return annotationString != null && annotationString.length() == 0;
 		//equivalent to (but faster) ANNOTATION_STRING_DEFAULT.equals( annotationString );
 	}
 
 	public static Any buildAnyValue(
 			String anyMetaDefName,
 			Ejb3JoinColumn[] columns,
 			javax.persistence.Column metaColumn,
 			PropertyData inferredData,
 			boolean cascadeOnDelete,
 			Nullability nullability,
 			PropertyHolder propertyHolder,
 			EntityBinder entityBinder,
 			boolean optional,
 			Mappings mappings) {
 		//All FK columns should be in the same table
 		Any value = new Any( mappings, columns[0].getTable() );
 		AnyMetaDef metaAnnDef = inferredData.getProperty().getAnnotation( AnyMetaDef.class );
 
 		if ( metaAnnDef != null ) {
 			//local has precedence over general and can be mapped for future reference if named
 			bindAnyMetaDefs( inferredData.getProperty(), mappings );
 		}
 		else {
 			metaAnnDef = mappings.getAnyMetaDef( anyMetaDefName );
 		}
 		if ( metaAnnDef != null ) {
 			value.setIdentifierType( metaAnnDef.idType() );
 			value.setMetaType( metaAnnDef.metaType() );
 
 			HashMap values = new HashMap();
 			org.hibernate.type.Type metaType = mappings.getTypeResolver().heuristicType( value.getMetaType() );
 			for (MetaValue metaValue : metaAnnDef.metaValues()) {
 				try {
 					Object discrim = ( (org.hibernate.type.DiscriminatorType) metaType ).stringToObject( metaValue
 							.value() );
 					String entityName = metaValue.targetEntity().getName();
 					values.put( discrim, entityName );
 				}
 				catch (ClassCastException cce) {
 					throw new MappingException( "metaType was not a DiscriminatorType: "
 							+ metaType.getName() );
 				}
 				catch (Exception e) {
 					throw new MappingException( "could not interpret metaValue", e );
 				}
 			}
 			if ( !values.isEmpty() ) value.setMetaValues( values );
 		}
 		else {
 			throw new AnnotationException( "Unable to find @AnyMetaDef for an @(ManyTo)Any mapping: "
 					+ StringHelper.qualify( propertyHolder.getPath(), inferredData.getPropertyName() ) );
 		}
 
 		value.setCascadeDeleteEnabled( cascadeOnDelete );
 		if ( !optional ) {
 			for (Ejb3JoinColumn column : columns) {
 				column.setNullable( false );
 			}
 		}
 
 		Ejb3Column[] metaColumns = Ejb3Column.buildColumnFromAnnotation(
 				new javax.persistence.Column[] { metaColumn }, null,
 				nullability, propertyHolder, inferredData, entityBinder.getSecondaryTables(), mappings
 		);
 		//set metaColumn to the right table
 		for (Ejb3Column column : metaColumns) {
 			column.setTable( value.getTable() );
 		}
 		//meta column
 		for (Ejb3Column column : metaColumns) {
 			column.linkWithValue( value );
 		}
 
 		//id columns
 		final String propertyName = inferredData.getPropertyName();
 		Ejb3Column.checkPropertyConsistency( columns, propertyHolder.getEntityName() + propertyName );
 		for (Ejb3JoinColumn column : columns) {
 			column.linkWithValue( value );
 		}
 		return value;
 	}
 
 	public static void bindAnyMetaDefs(XAnnotatedElement annotatedElement, Mappings mappings) {
 		AnyMetaDef defAnn = annotatedElement.getAnnotation( AnyMetaDef.class );
 		AnyMetaDefs defsAnn = annotatedElement.getAnnotation( AnyMetaDefs.class );
 		boolean mustHaveName = XClass.class.isAssignableFrom( annotatedElement.getClass() )
 				|| XPackage.class.isAssignableFrom( annotatedElement.getClass() );
 		if ( defAnn != null ) {
 			checkAnyMetaDefValidity( mustHaveName, defAnn, annotatedElement );
 			bindAnyMetaDef( defAnn, mappings );
 		}
 		if ( defsAnn != null ) {
 			for (AnyMetaDef def : defsAnn.value()) {
 				checkAnyMetaDefValidity( mustHaveName, def, annotatedElement );
 				bindAnyMetaDef( def, mappings );
 			}
 		}
 	}
 
 	private static void checkAnyMetaDefValidity(boolean mustHaveName, AnyMetaDef defAnn, XAnnotatedElement annotatedElement) {
 		if ( mustHaveName && isEmptyAnnotationValue( defAnn.name() ) ) {
 			String name = XClass.class.isAssignableFrom( annotatedElement.getClass() ) ?
 					( (XClass) annotatedElement ).getName() :
 					( (XPackage) annotatedElement ).getName();
 			throw new AnnotationException( "@AnyMetaDef.name cannot be null on an entity or a package: " + name );
 		}
 	}
 
 	private static void bindAnyMetaDef(AnyMetaDef defAnn, Mappings mappings) {
 		if ( isEmptyAnnotationValue( defAnn.name() ) ) return; //don't map not named definitions
-        LOG.bindingAnyMetaDefinition(defAnn.name());
+        LOG.bindingAnyMetaDefinition( defAnn.name() );
 		mappings.addAnyMetaDef( defAnn );
 	}
 
 	public static MappedSuperclass getMappedSuperclassOrNull(
 			XClass declaringClass,
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			Mappings mappings) {
 		boolean retrieve = false;
 		if ( declaringClass != null ) {
 			final InheritanceState inheritanceState = inheritanceStatePerClass.get( declaringClass );
 			if ( inheritanceState == null ) {
 				throw new org.hibernate.annotations.common.AssertionFailure(
 						"Declaring class is not found in the inheritance state hierarchy: " + declaringClass
 				);
 			}
 			if ( inheritanceState.isEmbeddableSuperclass() ) {
 				retrieve = true;
 			}
 		}
 		return retrieve ?
 				mappings.getMappedSuperclass( mappings.getReflectionManager().toClass( declaringClass ) ) :
 		        null;
 	}
 
 	public static String getPath(PropertyHolder holder, PropertyData property) {
 		return StringHelper.qualify( holder.getPath(), property.getPropertyName() );
 	}
 
 	static PropertyData getPropertyOverriddenByMapperOrMapsId(
 			boolean isId,
 			PropertyHolder propertyHolder,
 			String propertyName,
 			Mappings mappings) {
 		final XClass persistentXClass;
 		try {
 			 persistentXClass = mappings.getReflectionManager()
 					.classForName( propertyHolder.getPersistentClass().getClassName(), AnnotationBinder.class );
 		}
 		catch ( ClassNotFoundException e ) {
 			throw new AssertionFailure( "PersistentClass name cannot be converted into a Class", e);
 		}
 		if ( propertyHolder.isInIdClass() ) {
 			PropertyData pd = mappings.getPropertyAnnotatedWithIdAndToOne( persistentXClass, propertyName );
 			if ( pd == null && mappings.isSpecjProprietarySyntaxEnabled() ) {
 				pd = mappings.getPropertyAnnotatedWithMapsId( persistentXClass, propertyName );
 			}
 			return pd;
 		}
         String propertyPath = isId ? "" : propertyName;
         return mappings.getPropertyAnnotatedWithMapsId(persistentXClass, propertyPath);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/CollectionSecondPass.java b/hibernate-core/src/main/java/org/hibernate/cfg/CollectionSecondPass.java
index 9d587da714..d5b8e61c0f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/CollectionSecondPass.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/CollectionSecondPass.java
@@ -1,94 +1,95 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.OneToMany;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Value;
 import org.jboss.logging.Logger;
 
 /**
  * Collection second pass
  *
  * @author Emmanuel Bernard
  */
 public abstract class CollectionSecondPass implements SecondPass {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, CollectionSecondPass.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CollectionSecondPass.class.getName());
 
 	Mappings mappings;
 	Collection collection;
 	private Map localInheritedMetas;
 
 	public CollectionSecondPass(Mappings mappings, Collection collection, java.util.Map inheritedMetas) {
 		this.collection = collection;
 		this.mappings = mappings;
 		this.localInheritedMetas = inheritedMetas;
 	}
 
 	public CollectionSecondPass(Mappings mappings, Collection collection) {
 		this(mappings, collection, Collections.EMPTY_MAP);
 	}
 
 	public void doSecondPass(java.util.Map persistentClasses)
 			throws MappingException {
         LOG.debugf("Second pass for collection: %s", collection.getRole());
 
 		secondPass( persistentClasses, localInheritedMetas ); // using local since the inheritedMetas at this point is not the correct map since it is always the empty map
 		collection.createAllKeys();
 
         if (LOG.isDebugEnabled()) {
 			String msg = "Mapped collection key: " + columns( collection.getKey() );
 			if ( collection.isIndexed() )
 				msg += ", index: " + columns( ( (IndexedCollection) collection ).getIndex() );
 			if ( collection.isOneToMany() ) {
 				msg += ", one-to-many: "
 					+ ( (OneToMany) collection.getElement() ).getReferencedEntityName();
 			}
 			else {
 				msg += ", element: " + columns( collection.getElement() );
 			}
             LOG.debugf(msg);
 		}
 	}
 
 	abstract public void secondPass(java.util.Map persistentClasses, java.util.Map inheritedMetas)
 			throws MappingException;
 
 	private static String columns(Value val) {
 		StringBuffer columns = new StringBuffer();
 		Iterator iter = val.getColumnIterator();
 		while ( iter.hasNext() ) {
 			columns.append( ( (Selectable) iter.next() ).getText() );
 			if ( iter.hasNext() ) columns.append( ", " );
 		}
 		return columns.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Configuration.java b/hibernate-core/src/main/java/org/hibernate/cfg/Configuration.java
index 744867c731..a8591cd6aa 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Configuration.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Configuration.java
@@ -1,1529 +1,1529 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import javax.persistence.Embeddable;
 import javax.persistence.Entity;
 import javax.persistence.MapsId;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.Serializable;
 import java.io.StringReader;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Enumeration;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.ListIterator;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.StringTokenizer;
 import java.util.TreeMap;
 import java.util.jar.JarFile;
 import java.util.zip.ZipEntry;
 
 import org.dom4j.Attribute;
 import org.dom4j.Document;
 import org.dom4j.DocumentException;
 import org.dom4j.Element;
 import org.jboss.logging.Logger;
 import org.xml.sax.EntityResolver;
 import org.xml.sax.InputSource;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.DuplicateMappingException;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.Interceptor;
 import org.hibernate.InvalidMappingException;
 import org.hibernate.MappingException;
 import org.hibernate.MappingNotFoundException;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.annotations.AnyMetaDef;
 import org.hibernate.annotations.common.reflection.MetadataProvider;
 import org.hibernate.annotations.common.reflection.MetadataProviderInjector;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.java.JavaReflectionManager;
 import org.hibernate.cfg.annotations.reflection.JPAMetadataProvider;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.IdentifierGeneratorAggregator;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.id.factory.DefaultIdentifierGeneratorFactory;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.impl.SessionFactoryImpl;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.SerializationHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.internal.util.xml.MappingReader;
 import org.hibernate.internal.util.xml.Origin;
 import org.hibernate.internal.util.xml.OriginImpl;
 import org.hibernate.internal.util.xml.XMLHelper;
 import org.hibernate.internal.util.xml.XmlDocument;
 import org.hibernate.internal.util.xml.XmlDocumentImpl;
 import org.hibernate.mapping.AuxiliaryDatabaseObject;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.DenormalizedTable;
 import org.hibernate.mapping.FetchProfile;
 import org.hibernate.mapping.ForeignKey;
 import org.hibernate.mapping.IdGenerator;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.Index;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.MappedSuperclass;
 import org.hibernate.mapping.MetadataSource;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.TypeDef;
 import org.hibernate.mapping.UniqueKey;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.secure.JACCConfiguration;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 import org.hibernate.tool.hbm2ddl.DatabaseMetadata;
 import org.hibernate.tool.hbm2ddl.IndexMetadata;
 import org.hibernate.tool.hbm2ddl.TableMetadata;
 import org.hibernate.tuple.entity.EntityTuplizerFactory;
 import org.hibernate.type.BasicType;
 import org.hibernate.type.SerializationException;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
 
 /**
  * An instance of <tt>Configuration</tt> allows the application
  * to specify properties and mapping documents to be used when
  * creating a <tt>SessionFactory</tt>. Usually an application will create
  * a single <tt>Configuration</tt>, build a single instance of
  * <tt>SessionFactory</tt> and then instantiate <tt>Session</tt>s in
  * threads servicing client requests. The <tt>Configuration</tt> is meant
  * only as an initialization-time object. <tt>SessionFactory</tt>s are
  * immutable and do not retain any association back to the
  * <tt>Configuration</tt>.<br>
  * <br>
  * A new <tt>Configuration</tt> will use the properties specified in
  * <tt>hibernate.properties</tt> by default.
  *
  * @author Gavin King
  * @see org.hibernate.SessionFactory
  */
 public class Configuration implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Configuration.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Configuration.class.getName());
 
 	/**
 	 * Setting used to give the name of the default {@link org.hibernate.annotations.CacheConcurrencyStrategy}
 	 * to use when either {@link javax.persistence.Cacheable @Cacheable} or
 	 * {@link org.hibernate.annotations.Cache @Cache} is used.  {@link org.hibernate.annotations.Cache @Cache(strategy="..")} is used to override.
 	 */
 	public static final String DEFAULT_CACHE_CONCURRENCY_STRATEGY = "hibernate.cache.default_cache_concurrency_strategy";
 
 	/**
 	 * Setting which indicates whether or not the new {@link org.hibernate.id.IdentifierGenerator} are used
 	 * for AUTO, TABLE and SEQUENCE.
 	 * Default to false to keep backward compatibility.
 	 */
 	public static final String USE_NEW_ID_GENERATOR_MAPPINGS = "hibernate.id.new_generator_mappings";
 
 	public static final String ARTEFACT_PROCESSING_ORDER = "hibernate.mapping.precedence";
 
 	/**
 	 * Class name of the class needed to enable Search.
 	 */
 	private static final String SEARCH_STARTUP_CLASS = "org.hibernate.search.event.EventListenerRegister";
 
 	/**
 	 * Method to call to enable Search.
 	 */
 	private static final String SEARCH_STARTUP_METHOD = "enableHibernateSearch";
 
 	protected MetadataSourceQueue metadataSourceQueue;
 	private transient ReflectionManager reflectionManager;
 
 	protected Map<String, PersistentClass> classes;
 	protected Map<String, String> imports;
 	protected Map<String, Collection> collections;
 	protected Map<String, Table> tables;
 	protected List<AuxiliaryDatabaseObject> auxiliaryDatabaseObjects;
 
 	protected Map<String, NamedQueryDefinition> namedQueries;
 	protected Map<String, NamedSQLQueryDefinition> namedSqlQueries;
 	protected Map<String, ResultSetMappingDefinition> sqlResultSetMappings;
 
 	protected Map<String, TypeDef> typeDefs;
 	protected Map<String, FilterDefinition> filterDefinitions;
 	protected Map<String, FetchProfile> fetchProfiles;
 
 	protected Map tableNameBinding;
 	protected Map columnNameBindingPerTable;
 
 	protected List<SecondPass> secondPasses;
 	protected List<Mappings.PropertyReference> propertyReferences;
 	protected Map<ExtendsQueueEntry, ?> extendsQueue;
 
 	protected Map<String, SQLFunction> sqlFunctions;
 	private TypeResolver typeResolver = new TypeResolver();
 
 	private EntityTuplizerFactory entityTuplizerFactory;
 //	private ComponentTuplizerFactory componentTuplizerFactory; todo : HHH-3517 and HHH-1907
 
 	private Interceptor interceptor;
 	private Properties properties;
 	private EntityResolver entityResolver;
 	private EntityNotFoundDelegate entityNotFoundDelegate;
 
 	protected transient XMLHelper xmlHelper;
 	protected NamingStrategy namingStrategy;
 	private SessionFactoryObserver sessionFactoryObserver;
 
 	protected final SettingsFactory settingsFactory;
 
 	private transient Mapping mapping = buildMapping();
 
 	private DefaultIdentifierGeneratorFactory identifierGeneratorFactory;
 
 	private Map<Class<?>, org.hibernate.mapping.MappedSuperclass> mappedSuperClasses;
 
 	private Map<String, IdGenerator> namedGenerators;
 	private Map<String, Map<String, Join>> joins;
 	private Map<String, AnnotatedClassType> classTypes;
 	private Set<String> defaultNamedQueryNames;
 	private Set<String> defaultNamedNativeQueryNames;
 	private Set<String> defaultSqlResultSetMappingNames;
 	private Set<String> defaultNamedGenerators;
 	private Map<String, Properties> generatorTables;
 	private Map<Table, List<UniqueConstraintHolder>> uniqueConstraintHoldersByTable;
 	private Map<String, String> mappedByResolver;
 	private Map<String, String> propertyRefResolver;
 	private Map<String, AnyMetaDef> anyMetaDefs;
 	private List<CacheHolder> caches;
 	private boolean inSecondPass = false;
 	private boolean isDefaultProcessed = false;
 	private boolean isValidatorNotPresentLogged;
 	private Map<XClass, Map<String, PropertyData>> propertiesAnnotatedWithMapsId;
 	private Map<XClass, Map<String, PropertyData>> propertiesAnnotatedWithIdAndToOne;
 	private boolean specjProprietarySyntaxEnabled;
 
 
 	protected Configuration(SettingsFactory settingsFactory) {
 		this.settingsFactory = settingsFactory;
 		reset();
 	}
 
 	public Configuration() {
 		this( new SettingsFactory() );
 	}
 
 	protected void reset() {
 		metadataSourceQueue = new MetadataSourceQueue();
 		createReflectionManager();
 
 		classes = new HashMap<String,PersistentClass>();
 		imports = new HashMap<String,String>();
 		collections = new HashMap<String,Collection>();
 		tables = new TreeMap<String,Table>();
 
 		namedQueries = new HashMap<String,NamedQueryDefinition>();
 		namedSqlQueries = new HashMap<String,NamedSQLQueryDefinition>();
 		sqlResultSetMappings = new HashMap<String, ResultSetMappingDefinition>();
 
 		typeDefs = new HashMap<String,TypeDef>();
 		filterDefinitions = new HashMap<String, FilterDefinition>();
 		fetchProfiles = new HashMap<String, FetchProfile>();
 		auxiliaryDatabaseObjects = new ArrayList<AuxiliaryDatabaseObject>();
 
 		tableNameBinding = new HashMap();
 		columnNameBindingPerTable = new HashMap();
 
 		secondPasses = new ArrayList<SecondPass>();
 		propertyReferences = new ArrayList<Mappings.PropertyReference>();
 		extendsQueue = new HashMap<ExtendsQueueEntry, String>();
 
 		xmlHelper = new XMLHelper();
 		interceptor = EmptyInterceptor.INSTANCE;
 		properties = Environment.getProperties();
 		entityResolver = XMLHelper.DEFAULT_DTD_RESOLVER;
 
 		sqlFunctions = new HashMap<String, SQLFunction>();
 
 		entityTuplizerFactory = new EntityTuplizerFactory();
 //		componentTuplizerFactory = new ComponentTuplizerFactory();
 
 		identifierGeneratorFactory = new DefaultIdentifierGeneratorFactory();
 
 		mappedSuperClasses = new HashMap<Class<?>, MappedSuperclass>();
 
 		metadataSourcePrecedence = Collections.emptyList();
 
 		namedGenerators = new HashMap<String, IdGenerator>();
 		joins = new HashMap<String, Map<String, Join>>();
 		classTypes = new HashMap<String, AnnotatedClassType>();
 		generatorTables = new HashMap<String, Properties>();
 		defaultNamedQueryNames = new HashSet<String>();
 		defaultNamedNativeQueryNames = new HashSet<String>();
 		defaultSqlResultSetMappingNames = new HashSet<String>();
 		defaultNamedGenerators = new HashSet<String>();
 		uniqueConstraintHoldersByTable = new HashMap<Table, List<UniqueConstraintHolder>>();
 		mappedByResolver = new HashMap<String, String>();
 		propertyRefResolver = new HashMap<String, String>();
 		caches = new ArrayList<CacheHolder>();
 		namingStrategy = EJB3NamingStrategy.INSTANCE;
 		setEntityResolver( new EJB3DTDEntityResolver() );
 		anyMetaDefs = new HashMap<String, AnyMetaDef>();
 		propertiesAnnotatedWithMapsId = new HashMap<XClass, Map<String, PropertyData>>();
 		propertiesAnnotatedWithIdAndToOne = new HashMap<XClass, Map<String, PropertyData>>();
 		specjProprietarySyntaxEnabled = System.getProperty( "hibernate.enable_specj_proprietary_syntax" ) != null;
 	}
 
 	public EntityTuplizerFactory getEntityTuplizerFactory() {
 		return entityTuplizerFactory;
 	}
 
 	public ReflectionManager getReflectionManager() {
 		return reflectionManager;
 	}
 
 //	public ComponentTuplizerFactory getComponentTuplizerFactory() {
 //		return componentTuplizerFactory;
 //	}
 
 	/**
 	 * Iterate the entity mappings
 	 *
 	 * @return Iterator of the entity mappings currently contained in the configuration.
 	 */
 	public Iterator<PersistentClass> getClassMappings() {
 		return classes.values().iterator();
 	}
 
 	/**
 	 * Iterate the collection mappings
 	 *
 	 * @return Iterator of the collection mappings currently contained in the configuration.
 	 */
 	public Iterator getCollectionMappings() {
 		return collections.values().iterator();
 	}
 
 	/**
 	 * Iterate the table mappings
 	 *
 	 * @return Iterator of the table mappings currently contained in the configuration.
 	 */
 	public Iterator<Table> getTableMappings() {
 		return tables.values().iterator();
 	}
 
 	/**
 	 * Iterate the mapped super class mappings
 	 * EXPERIMENTAL Consider this API as PRIVATE
 	 *
 	 * @return iterator over the MappedSuperclass mapping currently contained in the configuration.
 	 */
 	public Iterator<MappedSuperclass> getMappedSuperclassMappings() {
 		return mappedSuperClasses.values().iterator();
 	}
 
 	/**
 	 * Get the mapping for a particular entity
 	 *
 	 * @param entityName An entity name.
 	 * @return the entity mapping information
 	 */
 	public PersistentClass getClassMapping(String entityName) {
 		return classes.get( entityName );
 	}
 
 	/**
 	 * Get the mapping for a particular collection role
 	 *
 	 * @param role a collection role
 	 * @return The collection mapping information
 	 */
 	public Collection getCollectionMapping(String role) {
 		return collections.get( role );
 	}
 
 	/**
 	 * Set a custom entity resolver. This entity resolver must be
 	 * set before addXXX(misc) call.
 	 * Default value is {@link org.hibernate.internal.util.xml.DTDEntityResolver}
 	 *
 	 * @param entityResolver entity resolver to use
 	 */
 	public void setEntityResolver(EntityResolver entityResolver) {
 		this.entityResolver = entityResolver;
 	}
 
 	public EntityResolver getEntityResolver() {
 		return entityResolver;
 	}
 
 	/**
 	 * Retrieve the user-supplied delegate to handle non-existent entity
 	 * scenarios.  May be null.
 	 *
 	 * @return The user-supplied delegate
 	 */
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return entityNotFoundDelegate;
 	}
 
 	/**
 	 * Specify a user-supplied delegate to be used to handle scenarios where an entity could not be
 	 * located by specified id.  This is mainly intended for EJB3 implementations to be able to
 	 * control how proxy initialization errors should be handled...
 	 *
 	 * @param entityNotFoundDelegate The delegate to use
 	 */
 	public void setEntityNotFoundDelegate(EntityNotFoundDelegate entityNotFoundDelegate) {
 		this.entityNotFoundDelegate = entityNotFoundDelegate;
 	}
 
 	/**
 	 * Read mappings from a particular XML file
 	 *
 	 * @param xmlFile a path to a file
 	 * @return this (for method chaining purposes)
 	 * @throws org.hibernate.MappingException Indicates inability to locate or parse
 	 * the specified mapping file.
 	 * @see #addFile(java.io.File)
 	 */
 	public Configuration addFile(String xmlFile) throws MappingException {
 		return addFile( new File( xmlFile ) );
 	}
 
 	/**
 	 * Read mappings from a particular XML file
 	 *
 	 * @param xmlFile a path to a file
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates inability to locate the specified mapping file.  Historically this could
 	 * have indicated a problem parsing the XML document, but that is now delayed until after {@link #buildMappings}
 	 */
 	public Configuration addFile(final File xmlFile) throws MappingException {
         LOG.readingMappingsFromFile(xmlFile.getPath());
 		final String name =  xmlFile.getAbsolutePath();
 		final InputSource inputSource;
 		try {
 			inputSource = new InputSource( new FileInputStream( xmlFile ) );
 		}
 		catch ( FileNotFoundException e ) {
 			throw new MappingNotFoundException( "file", xmlFile.toString() );
 		}
 		add( inputSource, "file", name );
 		return this;
 	}
 
 	private XmlDocument add(InputSource inputSource, String originType, String originName) {
 		return add( inputSource, new OriginImpl( originType, originName ) );
 	}
 
 	private XmlDocument add(InputSource inputSource, Origin origin) {
 		XmlDocument metadataXml = MappingReader.INSTANCE.readMappingDocument( entityResolver, inputSource, origin );
 		add( metadataXml );
 		return metadataXml;
 	}
 
 	public void add(XmlDocument metadataXml) {
 		if ( inSecondPass || !isOrmXml( metadataXml ) ) {
 			metadataSourceQueue.add( metadataXml );
 		}
 		else {
 			final MetadataProvider metadataProvider = ( (MetadataProviderInjector) reflectionManager ).getMetadataProvider();
 			JPAMetadataProvider jpaMetadataProvider = ( JPAMetadataProvider ) metadataProvider;
 			List<String> classNames = jpaMetadataProvider.getXMLContext().addDocument( metadataXml.getDocumentTree() );
 			for ( String className : classNames ) {
 				try {
 					metadataSourceQueue.add( reflectionManager.classForName( className, this.getClass() ) );
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException( "Unable to load class defined in XML: " + className, e );
 				}
 			}
 		}
 	}
 
 	private static boolean isOrmXml(XmlDocument xmlDocument) {
 		return "entity-mappings".equals( xmlDocument.getDocumentTree().getRootElement().getName() );
 	}
 
 	/**
 	 * Add a cached mapping file.  A cached file is a serialized representation
 	 * of the DOM structure of a particular mapping.  It is saved from a previous
 	 * call as a file with the name <tt>xmlFile + ".bin"</tt> where xmlFile is
 	 * the name of the original mapping file.
 	 * </p>
 	 * If a cached <tt>xmlFile + ".bin"</tt> exists and is newer than
 	 * <tt>xmlFile</tt> the <tt>".bin"</tt> file will be read directly. Otherwise
 	 * xmlFile is read and then serialized to <tt>xmlFile + ".bin"</tt> for use
 	 * the next time.
 	 *
 	 * @param xmlFile The cacheable mapping file to be added.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the cached file or processing
 	 * the non-cached file.
 	 */
 	public Configuration addCacheableFile(File xmlFile) throws MappingException {
 		File cachedFile = determineCachedDomFile( xmlFile );
 
 		try {
 			return addCacheableFileStrictly( xmlFile );
 		}
 		catch ( SerializationException e ) {
             LOG.unableToDeserializeCache(cachedFile.getPath(), e);
 		}
 		catch ( FileNotFoundException e ) {
-            LOG.cachedFileNotFound(cachedFile.getPath(), e);
+            LOG.cachedFileNotFound( cachedFile.getPath(), e );
 		}
 
 		final String name = xmlFile.getAbsolutePath();
 		final InputSource inputSource;
 		try {
 			inputSource = new InputSource( new FileInputStream( xmlFile ) );
 		}
 		catch ( FileNotFoundException e ) {
 			throw new MappingNotFoundException( "file", xmlFile.toString() );
 		}
 
         LOG.readingMappingsFromFile(xmlFile.getPath());
 		XmlDocument metadataXml = add( inputSource, "file", name );
 
 		try {
             LOG.debugf("Writing cache file for: %s to: %s", xmlFile, cachedFile);
 			SerializationHelper.serialize( ( Serializable ) metadataXml.getDocumentTree(), new FileOutputStream( cachedFile ) );
         } catch (Exception e) {
             LOG.unableToWriteCachedFile(cachedFile.getPath(), e.getMessage());
 		}
 
 		return this;
 	}
 
 	private File determineCachedDomFile(File xmlFile) {
 		return new File( xmlFile.getAbsolutePath() + ".bin" );
 	}
 
 	/**
 	 * <b>INTENDED FOR TESTSUITE USE ONLY!</b>
 	 * <p/>
 	 * Much like {@link #addCacheableFile(File)} except that here we will fail immediately if
 	 * the cache version cannot be found or used for whatever reason
 	 *
 	 * @param xmlFile The xml file, not the bin!
 	 *
 	 * @return The dom "deserialized" from the cached file.
 	 *
 	 * @throws SerializationException Indicates a problem deserializing the cached dom tree
 	 * @throws FileNotFoundException Indicates that the cached file was not found or was not usable.
 	 */
 	public Configuration addCacheableFileStrictly(File xmlFile) throws SerializationException, FileNotFoundException {
 		final File cachedFile = determineCachedDomFile( xmlFile );
 
 		final boolean useCachedFile = xmlFile.exists()
 				&& cachedFile.exists()
 				&& xmlFile.lastModified() < cachedFile.lastModified();
 
 		if ( ! useCachedFile ) {
 			throw new FileNotFoundException( "Cached file could not be found or could not be used" );
 		}
 
         LOG.readingCachedMappings(cachedFile);
 		Document document = ( Document ) SerializationHelper.deserialize( new FileInputStream( cachedFile ) );
 		add( new XmlDocumentImpl( document, "file", xmlFile.getAbsolutePath() ) );
 		return this;
 	}
 
 	/**
 	 * Add a cacheable mapping file.
 	 *
 	 * @param xmlFile The name of the file to be added.  This must be in a form
 	 * useable to simply construct a {@link java.io.File} instance.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the cached file or processing
 	 * the non-cached file.
 	 * @see #addCacheableFile(java.io.File)
 	 */
 	public Configuration addCacheableFile(String xmlFile) throws MappingException {
 		return addCacheableFile( new File( xmlFile ) );
 	}
 
 
 	/**
 	 * Read mappings from a <tt>String</tt>
 	 *
 	 * @param xml an XML string
 	 * @return this (for method chaining purposes)
 	 * @throws org.hibernate.MappingException Indicates problems parsing the
 	 * given XML string
 	 */
 	public Configuration addXML(String xml) throws MappingException {
         LOG.debugf("Mapping XML:\n%s", xml);
 		final InputSource inputSource = new InputSource( new StringReader( xml ) );
 		add( inputSource, "string", "XML String" );
 		return this;
 	}
 
 	/**
 	 * Read mappings from a <tt>URL</tt>
 	 *
 	 * @param url The url for the mapping document to be read.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the URL or processing
 	 * the mapping document.
 	 */
 	public Configuration addURL(URL url) throws MappingException {
 		final String urlExternalForm = url.toExternalForm();
 
         LOG.debugf("Reading mapping document from URL : %s", urlExternalForm);
 
 		try {
 			add( url.openStream(), "URL", urlExternalForm );
 		}
 		catch ( IOException e ) {
 			throw new InvalidMappingException( "Unable to open url stream [" + urlExternalForm + "]", "URL", urlExternalForm, e );
 		}
 		return this;
 	}
 
 	private XmlDocument add(InputStream inputStream, final String type, final String name) {
 		final InputSource inputSource = new InputSource( inputStream );
 		try {
 			return add( inputSource, type, name );
 		}
 		finally {
 			try {
 				inputStream.close();
 			}
 			catch ( IOException ignore ) {
                 LOG.trace("Was unable to close input stream");
 			}
 		}
 	}
 
 	/**
 	 * Read mappings from a DOM <tt>Document</tt>
 	 *
 	 * @param doc The DOM document
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the DOM or processing
 	 * the mapping document.
 	 */
 	public Configuration addDocument(org.w3c.dom.Document doc) throws MappingException {
         LOG.debugf("Mapping Document:\n%s", doc);
 
 		final Document document = xmlHelper.createDOMReader().read( doc );
 		add( new XmlDocumentImpl( document, "unknown", null ) );
 
 		return this;
 	}
 
 	/**
 	 * Read mappings from an {@link java.io.InputStream}.
 	 *
 	 * @param xmlInputStream The input stream containing a DOM.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the stream, or
 	 * processing the contained mapping document.
 	 */
 	public Configuration addInputStream(InputStream xmlInputStream) throws MappingException {
 		add( xmlInputStream, "input stream", null );
 		return this;
 	}
 
 	/**
 	 * Read mappings as a application resource (i.e. classpath lookup).
 	 *
 	 * @param resourceName The resource name
 	 * @param classLoader The class loader to use.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems locating the resource or
 	 * processing the contained mapping document.
 	 */
 	public Configuration addResource(String resourceName, ClassLoader classLoader) throws MappingException {
         LOG.readingMappingsFromResource(resourceName);
 		InputStream resourceInputStream = classLoader.getResourceAsStream( resourceName );
 		if ( resourceInputStream == null ) {
 			throw new MappingNotFoundException( "resource", resourceName );
 		}
 		add( resourceInputStream, "resource", resourceName );
 		return this;
 	}
 
 	/**
 	 * Read mappings as a application resourceName (i.e. classpath lookup)
 	 * trying different class loaders.
 	 *
 	 * @param resourceName The resource name
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems locating the resource or
 	 * processing the contained mapping document.
 	 */
 	public Configuration addResource(String resourceName) throws MappingException {
         LOG.readingMappingsFromResource(resourceName);
 		ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();
 		InputStream resourceInputStream = null;
 		if ( contextClassLoader != null ) {
 			resourceInputStream = contextClassLoader.getResourceAsStream( resourceName );
 		}
 		if ( resourceInputStream == null ) {
 			resourceInputStream = Environment.class.getClassLoader().getResourceAsStream( resourceName );
 		}
 		if ( resourceInputStream == null ) {
 			throw new MappingNotFoundException( "resource", resourceName );
 		}
 		add( resourceInputStream, "resource", resourceName );
 		return this;
 	}
 
 	/**
 	 * Read a mapping as an application resource using the convention that a class
 	 * named <tt>foo.bar.Foo</tt> is mapped by a file <tt>foo/bar/Foo.hbm.xml</tt>
 	 * which can be resolved as a classpath resource.
 	 *
 	 * @param persistentClass The mapped class
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems locating the resource or
 	 * processing the contained mapping document.
 	 */
 	public Configuration addClass(Class persistentClass) throws MappingException {
 		String mappingResourceName = persistentClass.getName().replace( '.', '/' ) + ".hbm.xml";
         LOG.readingMappingsFromResource(mappingResourceName);
 		return addResource( mappingResourceName, persistentClass.getClassLoader() );
 	}
 
 	/**
 	 * Read metadata from the annotations associated with this class.
 	 *
 	 * @param annotatedClass The class containing annotations
 	 *
 	 * @return this (for method chaining)
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public Configuration addAnnotatedClass(Class annotatedClass) {
 		XClass xClass = reflectionManager.toXClass( annotatedClass );
 		metadataSourceQueue.add( xClass );
 		return this;
 	}
 
 	/**
 	 * Read package-level metadata.
 	 *
 	 * @param packageName java package name
 	 *
 	 * @return this (for method chaining)
 	 *
 	 * @throws MappingException in case there is an error in the mapping data
 	 */
 	public Configuration addPackage(String packageName) throws MappingException {
         LOG.mappingPackage(packageName);
 		try {
 			AnnotationBinder.bindPackage( packageName, createMappings() );
 			return this;
 		}
 		catch ( MappingException me ) {
             LOG.unableToParseMetadata(packageName);
 			throw me;
 		}
 	}
 
 	/**
 	 * Read all mappings from a jar file
 	 * <p/>
 	 * Assumes that any file named <tt>*.hbm.xml</tt> is a mapping document.
 	 *
 	 * @param jar a jar file
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the jar file or
 	 * processing the contained mapping documents.
 	 */
 	public Configuration addJar(File jar) throws MappingException {
         LOG.searchingForMappingDocuments(jar.getName());
 		JarFile jarFile = null;
 		try {
 			try {
 				jarFile = new JarFile( jar );
 			}
 			catch (IOException ioe) {
 				throw new InvalidMappingException(
 						"Could not read mapping documents from jar: " + jar.getName(), "jar", jar.getName(),
 						ioe
 				);
 			}
 			Enumeration jarEntries = jarFile.entries();
 			while ( jarEntries.hasMoreElements() ) {
 				ZipEntry ze = (ZipEntry) jarEntries.nextElement();
 				if ( ze.getName().endsWith( ".hbm.xml" ) ) {
                     LOG.foundMappingDocument(ze.getName());
 					try {
 						addInputStream( jarFile.getInputStream( ze ) );
 					}
 					catch (Exception e) {
 						throw new InvalidMappingException(
 								"Could not read mapping documents from jar: " + jar.getName(),
 								"jar",
 								jar.getName(),
 								e
 						);
 					}
 				}
 			}
 		}
 		finally {
 			try {
 				if ( jarFile != null ) {
 					jarFile.close();
 				}
 			}
 			catch (IOException ioe) {
                 LOG.unableToCloseJar(ioe.getMessage());
 			}
 		}
 
 		return this;
 	}
 
 	/**
 	 * Read all mapping documents from a directory tree.
 	 * <p/>
 	 * Assumes that any file named <tt>*.hbm.xml</tt> is a mapping document.
 	 *
 	 * @param dir The directory
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the jar file or
 	 * processing the contained mapping documents.
 	 */
 	public Configuration addDirectory(File dir) throws MappingException {
 		File[] files = dir.listFiles();
 		for ( File file : files ) {
 			if ( file.isDirectory() ) {
 				addDirectory( file );
 			}
 			else if ( file.getName().endsWith( ".hbm.xml" ) ) {
 				addFile( file );
 			}
 		}
 		return this;
 	}
 
 	/**
 	 * Create a new <tt>Mappings</tt> to add class and collection mappings to.
 	 *
 	 * @return The created mappings
 	 */
 	public Mappings createMappings() {
 		return new MappingsImpl();
 	}
 
 
 	@SuppressWarnings({ "unchecked" })
 	private Iterator<IdentifierGenerator> iterateGenerators(Dialect dialect) throws MappingException {
 
 		TreeMap generators = new TreeMap();
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		for ( PersistentClass pc : classes.values() ) {
 			if ( !pc.isInherited() ) {
 				IdentifierGenerator ig = pc.getIdentifier().createIdentifierGenerator(
 						getIdentifierGeneratorFactory(),
 						dialect,
 						defaultCatalog,
 						defaultSchema,
 						(RootClass) pc
 				);
 
 				if ( ig instanceof PersistentIdentifierGenerator ) {
 					generators.put( ( (PersistentIdentifierGenerator) ig ).generatorKey(), ig );
 				}
 				else if ( ig instanceof IdentifierGeneratorAggregator ) {
 					( (IdentifierGeneratorAggregator) ig ).registerPersistentGenerators( generators );
 				}
 			}
 		}
 
 		for ( Collection collection : collections.values() ) {
 			if ( collection.isIdentified() ) {
 				IdentifierGenerator ig = ( ( IdentifierCollection ) collection ).getIdentifier().createIdentifierGenerator(
 						getIdentifierGeneratorFactory(),
 						dialect,
 						defaultCatalog,
 						defaultSchema,
 						null
 				);
 
 				if ( ig instanceof PersistentIdentifierGenerator ) {
 					generators.put( ( (PersistentIdentifierGenerator) ig ).generatorKey(), ig );
 				}
 			}
 		}
 
 		return generators.values().iterator();
 	}
 
 	/**
 	 * Generate DDL for dropping tables
 	 *
 	 * @param dialect The dialect for which to generate the drop script
 
 	 * @return The sequence of DDL commands to drop the schema objects
 
 	 * @throws HibernateException Generally indicates a problem calling {@link #buildMappings()}
 
 	 * @see org.hibernate.tool.hbm2ddl.SchemaExport
 	 */
 	public String[] generateDropSchemaScript(Dialect dialect) throws HibernateException {
 		secondPassCompile();
 
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		ArrayList<String> script = new ArrayList<String>( 50 );
 
 		// drop them in reverse order in case db needs it done that way...
 		{
 			ListIterator itr = auxiliaryDatabaseObjects.listIterator( auxiliaryDatabaseObjects.size() );
 			while ( itr.hasPrevious() ) {
 				AuxiliaryDatabaseObject object = (AuxiliaryDatabaseObject) itr.previous();
 				if ( object.appliesToDialect( dialect ) ) {
 					script.add( object.sqlDropString( dialect, defaultCatalog, defaultSchema ) );
 				}
 			}
 		}
 
 		if ( dialect.dropConstraints() ) {
 			Iterator itr = getTableMappings();
 			while ( itr.hasNext() ) {
 				Table table = (Table) itr.next();
 				if ( table.isPhysicalTable() ) {
 					Iterator subItr = table.getForeignKeyIterator();
 					while ( subItr.hasNext() ) {
 						ForeignKey fk = (ForeignKey) subItr.next();
 						if ( fk.isPhysicalConstraint() ) {
 							script.add(
 									fk.sqlDropString(
 											dialect,
 											defaultCatalog,
 											defaultSchema
 										)
 								);
 						}
 					}
 				}
 			}
 		}
 
 
 		Iterator itr = getTableMappings();
 		while ( itr.hasNext() ) {
 
 			Table table = (Table) itr.next();
 			if ( table.isPhysicalTable() ) {
 
 				/*Iterator subIter = table.getIndexIterator();
 				while ( subIter.hasNext() ) {
 					Index index = (Index) subIter.next();
 					if ( !index.isForeignKey() || !dialect.hasImplicitIndexForForeignKey() ) {
 						script.add( index.sqlDropString(dialect) );
 					}
 				}*/
 
 				script.add(
 						table.sqlDropString(
 								dialect,
 								defaultCatalog,
 								defaultSchema
 							)
 					);
 
 			}
 
 		}
 
 		itr = iterateGenerators( dialect );
 		while ( itr.hasNext() ) {
 			String[] lines = ( (PersistentIdentifierGenerator) itr.next() ).sqlDropStrings( dialect );
 			script.addAll( Arrays.asList( lines ) );
 		}
 
 		return ArrayHelper.toStringArray( script );
 	}
 
 	/**
 	 * @param dialect The dialect for which to generate the creation script
 	 *
 	 * @return The sequence of DDL commands to create the schema objects
 	 *
 	 * @throws HibernateException Generally indicates a problem calling {@link #buildMappings()}
 	 *
 	 * @see org.hibernate.tool.hbm2ddl.SchemaExport
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public String[] generateSchemaCreationScript(Dialect dialect) throws HibernateException {
 		secondPassCompile();
 
 		ArrayList<String> script = new ArrayList<String>( 50 );
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		Iterator iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 				script.add(
 						table.sqlCreateString(
 								dialect,
 								mapping,
 								defaultCatalog,
 								defaultSchema
 							)
 					);
 				Iterator<String> comments = table.sqlCommentStrings( dialect, defaultCatalog, defaultSchema );
 				while ( comments.hasNext() ) {
 					script.add( comments.next() );
 				}
 			}
 		}
 
 		iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 
 				if ( !dialect.supportsUniqueConstraintInCreateAlterTable() ) {
 					Iterator subIter = table.getUniqueKeyIterator();
 					while ( subIter.hasNext() ) {
 						UniqueKey uk = (UniqueKey) subIter.next();
 						String constraintString = uk.sqlCreateString( dialect, mapping, defaultCatalog, defaultSchema );
 						if (constraintString != null) script.add( constraintString );
 					}
 				}
 
 
 				Iterator subIter = table.getIndexIterator();
 				while ( subIter.hasNext() ) {
 					Index index = (Index) subIter.next();
 					script.add(
 							index.sqlCreateString(
 									dialect,
 									mapping,
 									defaultCatalog,
 									defaultSchema
 								)
 						);
 				}
 
 				if ( dialect.hasAlterTable() ) {
 					subIter = table.getForeignKeyIterator();
 					while ( subIter.hasNext() ) {
 						ForeignKey fk = (ForeignKey) subIter.next();
 						if ( fk.isPhysicalConstraint() ) {
 							script.add(
 									fk.sqlCreateString(
 											dialect, mapping,
 											defaultCatalog,
 											defaultSchema
 										)
 								);
 						}
 					}
 				}
 
 			}
 		}
 
 		iter = iterateGenerators( dialect );
 		while ( iter.hasNext() ) {
 			String[] lines = ( (PersistentIdentifierGenerator) iter.next() ).sqlCreateStrings( dialect );
 			script.addAll( Arrays.asList( lines ) );
 		}
 
 		for ( AuxiliaryDatabaseObject auxiliaryDatabaseObject : auxiliaryDatabaseObjects ) {
 			if ( auxiliaryDatabaseObject.appliesToDialect( dialect ) ) {
 				script.add( auxiliaryDatabaseObject.sqlCreateString( dialect, mapping, defaultCatalog, defaultSchema ) );
 			}
 		}
 
 		return ArrayHelper.toStringArray( script );
 	}
 
 	/**
 	 * @param dialect The dialect for which to generate the creation script
 	 * @param databaseMetadata The database catalog information for the database to be updated; needed to work out what
 	 * should be created/altered
 	 *
 	 * @return The sequence of DDL commands to apply the schema objects
 	 *
 	 * @throws HibernateException Generally indicates a problem calling {@link #buildMappings()}
 	 *
 	 * @see org.hibernate.tool.hbm2ddl.SchemaExport
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public String[] generateSchemaUpdateScript(Dialect dialect, DatabaseMetadata databaseMetadata)
 			throws HibernateException {
 		secondPassCompile();
 
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		ArrayList<String> script = new ArrayList<String>( 50 );
 
 		Iterator iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 
 				TableMetadata tableInfo = databaseMetadata.getTableMetadata(
 						table.getName(),
 						( table.getSchema() == null ) ? defaultSchema : table.getSchema(),
 						( table.getCatalog() == null ) ? defaultCatalog : table.getCatalog(),
 								table.isQuoted()
 
 					);
 				if ( tableInfo == null ) {
 					script.add(
 							table.sqlCreateString(
 									dialect,
 									mapping,
 									defaultCatalog,
 									defaultSchema
 								)
 						);
 				}
 				else {
 					Iterator<String> subiter = table.sqlAlterStrings(
 							dialect,
 							mapping,
 							tableInfo,
 							defaultCatalog,
 							defaultSchema
 						);
 					while ( subiter.hasNext() ) {
 						script.add( subiter.next() );
 					}
 				}
 
 				Iterator<String> comments = table.sqlCommentStrings( dialect, defaultCatalog, defaultSchema );
 				while ( comments.hasNext() ) {
 					script.add( comments.next() );
 				}
 
 			}
 		}
 
 		iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 
 				TableMetadata tableInfo = databaseMetadata.getTableMetadata(
 						table.getName(),
 						table.getSchema(),
 						table.getCatalog(),
 						table.isQuoted()
 					);
 
 				if ( dialect.hasAlterTable() ) {
 					Iterator subIter = table.getForeignKeyIterator();
 					while ( subIter.hasNext() ) {
 						ForeignKey fk = (ForeignKey) subIter.next();
 						if ( fk.isPhysicalConstraint() ) {
 							boolean create = tableInfo == null || (
 									tableInfo.getForeignKeyMetadata( fk ) == null && (
 											//Icky workaround for MySQL bug:
 											!( dialect instanceof MySQLDialect ) ||
 													tableInfo.getIndexMetadata( fk.getName() ) == null
 										)
 								);
 							if ( create ) {
 								script.add(
 										fk.sqlCreateString(
 												dialect,
 												mapping,
 												defaultCatalog,
 												defaultSchema
 											)
 									);
 							}
 						}
 					}
 				}
 
 				Iterator subIter = table.getIndexIterator();
 				while ( subIter.hasNext() ) {
 					final Index index = (Index) subIter.next();
 					// Skip if index already exists
 					if ( tableInfo != null && StringHelper.isNotEmpty( index.getName() ) ) {
 						final IndexMetadata meta = tableInfo.getIndexMetadata( index.getName() );
 						if ( meta != null ) {
 							continue;
 						}
 					}
 					script.add(
 							index.sqlCreateString(
 									dialect,
 									mapping,
 									defaultCatalog,
 									defaultSchema
 							)
 					);
 				}
 
 //broken, 'cos we don't generate these with names in SchemaExport
 //				subIter = table.getUniqueKeyIterator();
 //				while ( subIter.hasNext() ) {
 //					UniqueKey uk = (UniqueKey) subIter.next();
 //					if ( tableInfo==null || tableInfo.getIndexMetadata( uk.getFilterName() ) == null ) {
 //						script.add( uk.sqlCreateString(dialect, mapping) );
 //					}
 //				}
 			}
 		}
 
 		iter = iterateGenerators( dialect );
 		while ( iter.hasNext() ) {
 			PersistentIdentifierGenerator generator = (PersistentIdentifierGenerator) iter.next();
 			Object key = generator.generatorKey();
 			if ( !databaseMetadata.isSequence( key ) && !databaseMetadata.isTable( key ) ) {
 				String[] lines = generator.sqlCreateStrings( dialect );
 				script.addAll( Arrays.asList( lines ) );
 			}
 		}
 
 		return ArrayHelper.toStringArray( script );
 	}
 
 	public void validateSchema(Dialect dialect, DatabaseMetadata databaseMetadata)throws HibernateException {
 		secondPassCompile();
 
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		Iterator iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 
 
 				TableMetadata tableInfo = databaseMetadata.getTableMetadata(
 						table.getName(),
 						( table.getSchema() == null ) ? defaultSchema : table.getSchema(),
 						( table.getCatalog() == null ) ? defaultCatalog : table.getCatalog(),
 								table.isQuoted());
 				if ( tableInfo == null ) {
 					throw new HibernateException( "Missing table: " + table.getName() );
 				}
 				else {
 					table.validateColumns( dialect, mapping, tableInfo );
 				}
 
 			}
 		}
 
 		iter = iterateGenerators( dialect );
 		while ( iter.hasNext() ) {
 			PersistentIdentifierGenerator generator = (PersistentIdentifierGenerator) iter.next();
 			Object key = generator.generatorKey();
 			if ( !databaseMetadata.isSequence( key ) && !databaseMetadata.isTable( key ) ) {
 				throw new HibernateException( "Missing sequence or table: " + key );
 			}
 		}
 	}
 
 	private void validate() throws MappingException {
 		Iterator iter = classes.values().iterator();
 		while ( iter.hasNext() ) {
 			( (PersistentClass) iter.next() ).validate( mapping );
 		}
 		iter = collections.values().iterator();
 		while ( iter.hasNext() ) {
 			( (Collection) iter.next() ).validate( mapping );
 		}
 	}
 
 	/**
 	 * Call this to ensure the mappings are fully compiled/built. Usefull to ensure getting
 	 * access to all information in the metamodel when calling e.g. getClassMappings().
 	 */
 	public void buildMappings() {
 		secondPassCompile();
 	}
 
 	protected void secondPassCompile() throws MappingException {
         LOG.trace("Starting secondPassCompile() processing");
 
 		//process default values first
 		{
 			if ( !isDefaultProcessed ) {
 				//use global delimiters if orm.xml declare it
 				final Object isDelimited = reflectionManager.getDefaults().get( "delimited-identifier" );
 				if ( isDelimited != null && isDelimited == Boolean.TRUE ) {
 					getProperties().put( Environment.GLOBALLY_QUOTED_IDENTIFIERS, "true" );
 				}
 
 				AnnotationBinder.bindDefaults( createMappings() );
 				isDefaultProcessed = true;
 			}
 		}
 
 		// process metadata queue
 		{
 			metadataSourceQueue.syncAnnotatedClasses();
 			metadataSourceQueue.processMetadata( determineMetadataSourcePrecedence() );
 		}
 
 		// process cache queue
 		{
 			for ( CacheHolder holder : caches ) {
 				if ( holder.isClass ) {
 					applyCacheConcurrencyStrategy( holder );
 				}
 				else {
 					applyCollectionCacheConcurrencyStrategy( holder );
 				}
 			}
 			caches.clear();
 		}
 
 		try {
 			inSecondPass = true;
 			processSecondPassesOfType( PkDrivenByDefaultMapsIdSecondPass.class );
 			processSecondPassesOfType( SetSimpleValueTypeSecondPass.class );
 			processSecondPassesOfType( CopyIdentifierComponentSecondPass.class );
 			processFkSecondPassInOrder();
 			processSecondPassesOfType( CreateKeySecondPass.class );
 			processSecondPassesOfType( SecondaryTableSecondPass.class );
 
 			originalSecondPassCompile();
 
 			inSecondPass = false;
 		}
 		catch ( RecoverableException e ) {
 			//the exception was not recoverable after all
 			throw ( RuntimeException ) e.getCause();
 		}
 
 		for ( Map.Entry<Table, List<UniqueConstraintHolder>> tableListEntry : uniqueConstraintHoldersByTable.entrySet() ) {
 			final Table table = tableListEntry.getKey();
 			final List<UniqueConstraintHolder> uniqueConstraints = tableListEntry.getValue();
 			int uniqueIndexPerTable = 0;
 			for ( UniqueConstraintHolder holder : uniqueConstraints ) {
 				uniqueIndexPerTable++;
 				final String keyName = StringHelper.isEmpty( holder.getName() )
 						? "key" + uniqueIndexPerTable
 						: holder.getName();
 				buildUniqueKeyFromColumnNames( table, keyName, holder.getColumns() );
 			}
 		}
 	}
 
 	private void processSecondPassesOfType(Class<? extends SecondPass> type) {
 		Iterator iter = secondPasses.iterator();
 		while ( iter.hasNext() ) {
 			SecondPass sp = ( SecondPass ) iter.next();
 			//do the second pass of simple value types first and remove them
 			if ( type.isInstance( sp ) ) {
 				sp.doSecondPass( classes );
 				iter.remove();
 			}
 		}
 	}
 
 	/**
 	 * Processes FKSecondPass instances trying to resolve any
 	 * graph circularity (ie PK made of a many to one linking to
 	 * an entity having a PK made of a ManyToOne ...).
 	 */
 	private void processFkSecondPassInOrder() {
         LOG.debugf("Processing fk mappings (*ToOne and JoinedSubclass)");
 		List<FkSecondPass> fkSecondPasses = getFKSecondPassesOnly();
 
 		if ( fkSecondPasses.size() == 0 ) {
 			return; // nothing to do here
 		}
 
 		// split FkSecondPass instances into primary key and non primary key FKs.
 		// While doing so build a map of class names to FkSecondPass instances depending on this class.
 		Map<String, Set<FkSecondPass>> isADependencyOf = new HashMap<String, Set<FkSecondPass>>();
 		List<FkSecondPass> endOfQueueFkSecondPasses = new ArrayList<FkSecondPass>( fkSecondPasses.size() );
 		for ( FkSecondPass sp : fkSecondPasses ) {
 			if ( sp.isInPrimaryKey() ) {
 				String referenceEntityName = sp.getReferencedEntityName();
 				PersistentClass classMapping = getClassMapping( referenceEntityName );
 				String dependentTable = classMapping.getTable().getQuotedName();
 				if ( !isADependencyOf.containsKey( dependentTable ) ) {
 					isADependencyOf.put( dependentTable, new HashSet<FkSecondPass>() );
 				}
 				isADependencyOf.get( dependentTable ).add( sp );
 			}
 			else {
 				endOfQueueFkSecondPasses.add( sp );
 			}
 		}
 
 		// using the isADependencyOf map we order the FkSecondPass recursively instances into the right order for processing
 		List<FkSecondPass> orderedFkSecondPasses = new ArrayList<FkSecondPass>( fkSecondPasses.size() );
 		for ( String tableName : isADependencyOf.keySet() ) {
 			buildRecursiveOrderedFkSecondPasses( orderedFkSecondPasses, isADependencyOf, tableName, tableName );
 		}
 
 		// process the ordered FkSecondPasses
 		for ( FkSecondPass sp : orderedFkSecondPasses ) {
 			sp.doSecondPass( classes );
 		}
 
 		processEndOfQueue( endOfQueueFkSecondPasses );
 	}
 
 	/**
 	 * @return Returns a list of all <code>secondPasses</code> instances which are a instance of
 	 *         <code>FkSecondPass</code>.
 	 */
 	private List<FkSecondPass> getFKSecondPassesOnly() {
 		Iterator iter = secondPasses.iterator();
 		List<FkSecondPass> fkSecondPasses = new ArrayList<FkSecondPass>( secondPasses.size() );
 		while ( iter.hasNext() ) {
 			SecondPass sp = ( SecondPass ) iter.next();
 			//do the second pass of fk before the others and remove them
 			if ( sp instanceof FkSecondPass ) {
 				fkSecondPasses.add( ( FkSecondPass ) sp );
 				iter.remove();
 			}
 		}
 		return fkSecondPasses;
 	}
 
 	/**
 	 * Recursively builds a list of FkSecondPass instances ready to be processed in this order.
 	 * Checking all dependencies recursively seems quite expensive, but the original code just relied
 	 * on some sort of table name sorting which failed in certain circumstances.
 	 * <p/>
 	 * See <tt>ANN-722</tt> and <tt>ANN-730</tt>
 	 *
 	 * @param orderedFkSecondPasses The list containing the <code>FkSecondPass<code> instances ready
 	 * for processing.
 	 * @param isADependencyOf Our lookup data structure to determine dependencies between tables
 	 * @param startTable Table name to start recursive algorithm.
 	 * @param currentTable The current table name used to check for 'new' dependencies.
 	 */
 	private void buildRecursiveOrderedFkSecondPasses(
 			List<FkSecondPass> orderedFkSecondPasses,
 			Map<String, Set<FkSecondPass>> isADependencyOf,
 			String startTable,
 			String currentTable) {
 
 		Set<FkSecondPass> dependencies = isADependencyOf.get( currentTable );
 
 		// bottom out
 		if ( dependencies == null || dependencies.size() == 0 ) {
 			return;
 		}
 
 		for ( FkSecondPass sp : dependencies ) {
 			String dependentTable = sp.getValue().getTable().getQuotedName();
 			if ( dependentTable.compareTo( startTable ) == 0 ) {
 				StringBuilder sb = new StringBuilder(
 						"Foreign key circularity dependency involving the following tables: "
 				);
 				throw new AnnotationException( sb.toString() );
 			}
 			buildRecursiveOrderedFkSecondPasses( orderedFkSecondPasses, isADependencyOf, startTable, dependentTable );
 			if ( !orderedFkSecondPasses.contains( sp ) ) {
 				orderedFkSecondPasses.add( 0, sp );
 			}
 		}
 	}
 
 	private void processEndOfQueue(List<FkSecondPass> endOfQueueFkSecondPasses) {
 		/*
 		 * If a second pass raises a recoverableException, queue it for next round
 		 * stop of no pass has to be processed or if the number of pass to processes
 		 * does not diminish between two rounds.
 		 * If some failing pass remain, raise the original exception
 		 */
 		boolean stopProcess = false;
 		RuntimeException originalException = null;
 		while ( !stopProcess ) {
 			List<FkSecondPass> failingSecondPasses = new ArrayList<FkSecondPass>();
 			Iterator<FkSecondPass> it = endOfQueueFkSecondPasses.listIterator();
 			while ( it.hasNext() ) {
 				final FkSecondPass pass = it.next();
 				try {
 					pass.doSecondPass( classes );
 				}
 				catch ( RecoverableException e ) {
 					failingSecondPasses.add( pass );
 					if ( originalException == null ) {
 						originalException = ( RuntimeException ) e.getCause();
 					}
 				}
 			}
 			stopProcess = failingSecondPasses.size() == 0 || failingSecondPasses.size() == endOfQueueFkSecondPasses.size();
 			endOfQueueFkSecondPasses = failingSecondPasses;
 		}
 		if ( endOfQueueFkSecondPasses.size() > 0 ) {
 			throw originalException;
 		}
 	}
 
 	private void buildUniqueKeyFromColumnNames(Table table, String keyName, String[] columnNames) {
 		keyName = normalizer.normalizeIdentifierQuoting( keyName );
 
 		UniqueKey uc;
 		int size = columnNames.length;
 		Column[] columns = new Column[size];
 		Set<Column> unbound = new HashSet<Column>();
 		Set<Column> unboundNoLogical = new HashSet<Column>();
 		for ( int index = 0; index < size; index++ ) {
 			final String logicalColumnName = normalizer.normalizeIdentifierQuoting( columnNames[index] );
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/EJB3DTDEntityResolver.java b/hibernate-core/src/main/java/org/hibernate/cfg/EJB3DTDEntityResolver.java
index dbed1e611f..85f9cee33e 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/EJB3DTDEntityResolver.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/EJB3DTDEntityResolver.java
@@ -1,109 +1,111 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
 package org.hibernate.cfg;
-
-import java.io.InputStream;
-import org.hibernate.HibernateLogger;
-import org.hibernate.internal.util.xml.DTDEntityResolver;
-import org.jboss.logging.Logger;
-import org.xml.sax.EntityResolver;
-import org.xml.sax.InputSource;
-
-/**
- * Resolve JPA xsd files locally
- * Hibernate OGM uses this class, consider this some kind of exposed service at the SPI level
- *
- * @author Emmanuel Bernard
- */
-public class EJB3DTDEntityResolver extends DTDEntityResolver {
-	public static final EntityResolver INSTANCE = new EJB3DTDEntityResolver();
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, EJB3DTDEntityResolver.class.getName());
-
-	boolean resolved = false;
-
-	/**
-	 * Persistence.xml has been resolved locally
-	 * @return true if it has
-	 */
-	public boolean isResolved() {
-		return resolved;
-	}
-
-	@Override
-    public InputSource resolveEntity(String publicId, String systemId) {
-        LOG.trace("Resolving XML entity " + publicId + " : " + systemId);
-		InputSource is = super.resolveEntity( publicId, systemId );
-		if ( is == null ) {
-			if ( systemId != null ) {
-				if ( systemId.endsWith( "orm_1_0.xsd" ) ) {
-					InputStream dtdStream = getStreamFromClasspath( "orm_1_0.xsd" );
-					final InputSource source = buildInputSource( publicId, systemId, dtdStream, false );
-					if (source != null) return source;
-				}
-				else if ( systemId.endsWith( "orm_2_0.xsd" ) ) {
-					InputStream dtdStream = getStreamFromClasspath( "orm_2_0.xsd" );
-					final InputSource source = buildInputSource( publicId, systemId, dtdStream, false );
-					if (source != null) return source;
-				}
-				else if ( systemId.endsWith( "persistence_1_0.xsd" ) ) {
-					InputStream dtdStream = getStreamFromClasspath( "persistence_1_0.xsd" );
-					final InputSource source = buildInputSource( publicId, systemId, dtdStream, true );
-					if (source != null) return source;
-				}
-				else if ( systemId.endsWith( "persistence_2_0.xsd" ) ) {
-					InputStream dtdStream = getStreamFromClasspath( "persistence_2_0.xsd" );
-					final InputSource source = buildInputSource( publicId, systemId, dtdStream, true );
-					if (source != null) return source;
-				}
-			}
-		}
-		else {
-			resolved = true;
-			return is;
-		}
-		//use the default behavior
-		return null;
-	}
-
-	private InputSource buildInputSource(String publicId, String systemId, InputStream dtdStream, boolean resolved) {
-		if ( dtdStream == null ) {
-            LOG.trace("Unable to locate [" + systemId + "] on classpath");
-			return null;
-		}
-        LOG.trace("Located [" + systemId + "] in classpath");
-        InputSource source = new InputSource(dtdStream);
-        source.setPublicId(publicId);
-        source.setSystemId(systemId);
-        this.resolved = resolved;
-        return source;
-	}
-
-	private InputStream getStreamFromClasspath(String fileName) {
-        LOG.trace("Recognized JPA ORM namespace; attempting to resolve on classpath under org/hibernate/ejb");
-		String path = "org/hibernate/ejb/" + fileName;
-		InputStream dtdStream = resolveInHibernateNamespace( path );
-		return dtdStream;
-	}
-}
+
+import java.io.InputStream;
+
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.internal.util.xml.DTDEntityResolver;
+
+import org.jboss.logging.Logger;
+import org.xml.sax.EntityResolver;
+import org.xml.sax.InputSource;
+
+/**
+ * Resolve JPA xsd files locally
+ * Hibernate OGM uses this class, consider this some kind of exposed service at the SPI level
+ *
+ * @author Emmanuel Bernard
+ */
+public class EJB3DTDEntityResolver extends DTDEntityResolver {
+	public static final EntityResolver INSTANCE = new EJB3DTDEntityResolver();
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EJB3DTDEntityResolver.class.getName());
+
+	boolean resolved = false;
+
+	/**
+	 * Persistence.xml has been resolved locally
+	 * @return true if it has
+	 */
+	public boolean isResolved() {
+		return resolved;
+	}
+
+	@Override
+    public InputSource resolveEntity(String publicId, String systemId) {
+        LOG.trace("Resolving XML entity " + publicId + " : " + systemId);
+		InputSource is = super.resolveEntity( publicId, systemId );
+		if ( is == null ) {
+			if ( systemId != null ) {
+				if ( systemId.endsWith( "orm_1_0.xsd" ) ) {
+					InputStream dtdStream = getStreamFromClasspath( "orm_1_0.xsd" );
+					final InputSource source = buildInputSource( publicId, systemId, dtdStream, false );
+					if (source != null) return source;
+				}
+				else if ( systemId.endsWith( "orm_2_0.xsd" ) ) {
+					InputStream dtdStream = getStreamFromClasspath( "orm_2_0.xsd" );
+					final InputSource source = buildInputSource( publicId, systemId, dtdStream, false );
+					if (source != null) return source;
+				}
+				else if ( systemId.endsWith( "persistence_1_0.xsd" ) ) {
+					InputStream dtdStream = getStreamFromClasspath( "persistence_1_0.xsd" );
+					final InputSource source = buildInputSource( publicId, systemId, dtdStream, true );
+					if (source != null) return source;
+				}
+				else if ( systemId.endsWith( "persistence_2_0.xsd" ) ) {
+					InputStream dtdStream = getStreamFromClasspath( "persistence_2_0.xsd" );
+					final InputSource source = buildInputSource( publicId, systemId, dtdStream, true );
+					if (source != null) return source;
+				}
+			}
+		}
+		else {
+			resolved = true;
+			return is;
+		}
+		//use the default behavior
+		return null;
+	}
+
+	private InputSource buildInputSource(String publicId, String systemId, InputStream dtdStream, boolean resolved) {
+		if ( dtdStream == null ) {
+            LOG.trace("Unable to locate [" + systemId + "] on classpath");
+			return null;
+		}
+        LOG.trace("Located [" + systemId + "] in classpath");
+        InputSource source = new InputSource(dtdStream);
+        source.setPublicId(publicId);
+        source.setSystemId(systemId);
+        this.resolved = resolved;
+        return source;
+	}
+
+	private InputStream getStreamFromClasspath(String fileName) {
+        LOG.trace("Recognized JPA ORM namespace; attempting to resolve on classpath under org/hibernate/ejb");
+		String path = "org/hibernate/ejb/" + fileName;
+		InputStream dtdStream = resolveInHibernateNamespace( path );
+		return dtdStream;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Ejb3Column.java b/hibernate-core/src/main/java/org/hibernate/cfg/Ejb3Column.java
index 585a078af8..46f708b18c 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Ejb3Column.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Ejb3Column.java
@@ -1,630 +1,631 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat, Inc. and/or its affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.util.Map;
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.annotations.ColumnTransformer;
 import org.hibernate.annotations.ColumnTransformers;
 import org.hibernate.annotations.Index;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.cfg.annotations.Nullability;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Table;
+
 import org.jboss.logging.Logger;
 
 /**
  * Wrap state of an EJB3 @Column annotation
  * and build the Hibernate column mapping element
  *
  * @author Emmanuel Bernard
  */
 public class Ejb3Column {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Ejb3Column.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Ejb3Column.class.getName());
 
 	private Column mappingColumn;
 	private boolean insertable = true;
 	private boolean updatable = true;
 	private String secondaryTableName;
 	protected Map<String, Join> joins;
 	protected PropertyHolder propertyHolder;
 	private Mappings mappings;
 	private boolean isImplicit;
 	public static final int DEFAULT_COLUMN_LENGTH = 255;
 	public String sqlType;
 	private int length = DEFAULT_COLUMN_LENGTH;
 	private int precision;
 	private int scale;
 	private String logicalColumnName;
 	private String propertyName;
 	private boolean unique;
 	private boolean nullable = true;
 	private String formulaString;
 	private Formula formula;
 	private Table table;
 	private String readExpression;
 	private String writeExpression;
 
 	public void setTable(Table table) {
 		this.table = table;
 	}
 
 	public String getLogicalColumnName() {
 		return logicalColumnName;
 	}
 
 	public String getSqlType() {
 		return sqlType;
 	}
 
 	public int getLength() {
 		return length;
 	}
 
 	public int getPrecision() {
 		return precision;
 	}
 
 	public int getScale() {
 		return scale;
 	}
 
 	public boolean isUnique() {
 		return unique;
 	}
 
 	public boolean isFormula() {
 		return StringHelper.isNotEmpty( formulaString );
 	}
 
 	public String getFormulaString() {
 		return formulaString;
 	}
 
 	public String getSecondaryTableName() {
 		return secondaryTableName;
 	}
 
 	public void setFormula(String formula) {
 		this.formulaString = formula;
 	}
 
 	public boolean isImplicit() {
 		return isImplicit;
 	}
 
 	public void setInsertable(boolean insertable) {
 		this.insertable = insertable;
 	}
 
 	public void setUpdatable(boolean updatable) {
 		this.updatable = updatable;
 	}
 
 	protected Mappings getMappings() {
 		return mappings;
 	}
 
 	public void setMappings(Mappings mappings) {
 		this.mappings = mappings;
 	}
 
 	public void setImplicit(boolean implicit) {
 		isImplicit = implicit;
 	}
 
 	public void setSqlType(String sqlType) {
 		this.sqlType = sqlType;
 	}
 
 	public void setLength(int length) {
 		this.length = length;
 	}
 
 	public void setPrecision(int precision) {
 		this.precision = precision;
 	}
 
 	public void setScale(int scale) {
 		this.scale = scale;
 	}
 
 	public void setLogicalColumnName(String logicalColumnName) {
 		this.logicalColumnName = logicalColumnName;
 	}
 
 	public void setPropertyName(String propertyName) {
 		this.propertyName = propertyName;
 	}
 
 	public String getPropertyName() {
 		return propertyName;
 	}
 
 	public void setUnique(boolean unique) {
 		this.unique = unique;
 	}
 
 	public boolean isNullable() {
 		return mappingColumn.isNullable();
 	}
 
 	public Ejb3Column() {
 	}
 
 	public void bind() {
 		if ( StringHelper.isNotEmpty( formulaString ) ) {
             LOG.debugf("Binding formula %s", formulaString);
 			formula = new Formula();
 			formula.setFormula( formulaString );
 		}
 		else {
 			initMappingColumn(
 					logicalColumnName, propertyName, length, precision, scale, nullable, sqlType, unique, true
 			);
             LOG.debugf("Binding column: %s", toString());
 		}
 	}
 
 	protected void initMappingColumn(
 			String columnName,
 			String propertyName,
 			int length,
 			int precision,
 			int scale,
 			boolean nullable,
 			String sqlType,
 			boolean unique,
 			boolean applyNamingStrategy) {
 		if ( StringHelper.isNotEmpty( formulaString ) ) {
 			this.formula = new Formula();
 			this.formula.setFormula( formulaString );
 		}
 		else {
 			this.mappingColumn = new Column();
 			redefineColumnName( columnName, propertyName, applyNamingStrategy );
 			this.mappingColumn.setLength( length );
 			if ( precision > 0 ) {  //revelent precision
 				this.mappingColumn.setPrecision( precision );
 				this.mappingColumn.setScale( scale );
 			}
 			this.mappingColumn.setNullable( nullable );
 			this.mappingColumn.setSqlType( sqlType );
 			this.mappingColumn.setUnique( unique );
 
 			if(writeExpression != null && !writeExpression.matches("[^?]*\\?[^?]*")) {
 				throw new AnnotationException(
 						"@WriteExpression must contain exactly one value placeholder ('?') character: property ["
 								+ propertyName + "] and column [" + logicalColumnName + "]"
 				);
 			}
 			if ( readExpression != null) {
 				this.mappingColumn.setCustomRead( readExpression );
 			}
 			if ( writeExpression != null) {
 				this.mappingColumn.setCustomWrite( writeExpression );
 			}
 		}
 	}
 
 	public boolean isNameDeferred() {
 		return mappingColumn == null || StringHelper.isEmpty( mappingColumn.getName() );
 	}
 
 	public void redefineColumnName(String columnName, String propertyName, boolean applyNamingStrategy) {
 		if ( applyNamingStrategy ) {
 			if ( StringHelper.isEmpty( columnName ) ) {
 				if ( propertyName != null ) {
 					mappingColumn.setName(
 							mappings.getObjectNameNormalizer().normalizeIdentifierQuoting(
 									mappings.getNamingStrategy().propertyToColumnName( propertyName )
 							)
 					);
 				}
 				//Do nothing otherwise
 			}
 			else {
 				columnName = mappings.getObjectNameNormalizer().normalizeIdentifierQuoting( columnName );
 				columnName = mappings.getNamingStrategy().columnName( columnName );
 				columnName = mappings.getObjectNameNormalizer().normalizeIdentifierQuoting( columnName );
 				mappingColumn.setName( columnName );
 			}
 		}
 		else {
 			if ( StringHelper.isNotEmpty( columnName ) ) {
 				mappingColumn.setName( mappings.getObjectNameNormalizer().normalizeIdentifierQuoting( columnName ) );
 			}
 		}
 	}
 
 	public String getName() {
 		return mappingColumn.getName();
 	}
 
 	public Column getMappingColumn() {
 		return mappingColumn;
 	}
 
 	public boolean isInsertable() {
 		return insertable;
 	}
 
 	public boolean isUpdatable() {
 		return updatable;
 	}
 
 	public void setNullable(boolean nullable) {
 		if ( mappingColumn != null ) {
 			mappingColumn.setNullable( nullable );
 		}
 		else {
 			this.nullable = nullable;
 		}
 	}
 
 	public void setJoins(Map<String, Join> joins) {
 		this.joins = joins;
 	}
 
 	public PropertyHolder getPropertyHolder() {
 		return propertyHolder;
 	}
 
 	public void setPropertyHolder(PropertyHolder propertyHolder) {
 		this.propertyHolder = propertyHolder;
 	}
 
 	protected void setMappingColumn(Column mappingColumn) {
 		this.mappingColumn = mappingColumn;
 	}
 
 	public void linkWithValue(SimpleValue value) {
 		if ( formula != null ) {
 			value.addFormula( formula );
 		}
 		else {
 			getMappingColumn().setValue( value );
 			value.addColumn( getMappingColumn() );
 			value.getTable().addColumn( getMappingColumn() );
 			addColumnBinding( value );
 			table = value.getTable();
 		}
 	}
 
 	protected void addColumnBinding(SimpleValue value) {
 		String logicalColumnName = mappings.getNamingStrategy()
 				.logicalColumnName( this.logicalColumnName, propertyName );
 		mappings.addColumnBinding( logicalColumnName, getMappingColumn(), value.getTable() );
 	}
 
 	/**
 	 * Find appropriate table of the column.
 	 * It can come from a secondary table or from the main table of the persistent class
 	 *
 	 * @return appropriate table
 	 * @throws AnnotationException missing secondary table
 	 */
 	public Table getTable() {
 		if ( table != null ) return table; //association table
 		if ( isSecondary() ) {
 			return getJoin().getTable();
 		}
 		else {
 			return propertyHolder.getTable();
 		}
 	}
 
 	public boolean isSecondary() {
 		if ( propertyHolder == null ) {
 			throw new AssertionFailure( "Should not call getTable() on column wo persistent class defined" );
 		}
 		if ( StringHelper.isNotEmpty( secondaryTableName ) ) {
 			return true;
 		}
 		// else {
 		return false;
 	}
 
 	public Join getJoin() {
 		Join join = joins.get( secondaryTableName );
 		if ( join == null ) {
 			throw new AnnotationException(
 					"Cannot find the expected secondary table: no "
 							+ secondaryTableName + " available for " + propertyHolder.getClassName()
 			);
 		}
 		else {
 			return join;
 		}
 	}
 
 	public void forceNotNull() {
 		mappingColumn.setNullable( false );
 	}
 
 	public void setSecondaryTableName(String secondaryTableName) {
 		if ( "``".equals( secondaryTableName ) ) {
 			this.secondaryTableName = "";
 		}
 		else {
 			this.secondaryTableName = secondaryTableName;
 		}
 	}
 
 	public static Ejb3Column[] buildColumnFromAnnotation(
 			javax.persistence.Column[] anns,
 			org.hibernate.annotations.Formula formulaAnn,
 			Nullability nullability,
 			PropertyHolder propertyHolder,
 			PropertyData inferredData,
 			Map<String, Join> secondaryTables,
 			Mappings mappings){
 		return buildColumnFromAnnotation(
 				anns, formulaAnn, nullability, propertyHolder, inferredData, null, secondaryTables, mappings
 		);
 	}
 	public static Ejb3Column[] buildColumnFromAnnotation(
 			javax.persistence.Column[] anns,
 			org.hibernate.annotations.Formula formulaAnn,
 			Nullability nullability,
 			PropertyHolder propertyHolder,
 			PropertyData inferredData,
 			String suffixForDefaultColumnName,
 			Map<String, Join> secondaryTables,
 			Mappings mappings) {
 		Ejb3Column[] columns;
 		if ( formulaAnn != null ) {
 			Ejb3Column formulaColumn = new Ejb3Column();
 			formulaColumn.setFormula( formulaAnn.value() );
 			formulaColumn.setImplicit( false );
 			formulaColumn.setMappings( mappings );
 			formulaColumn.setPropertyHolder( propertyHolder );
 			formulaColumn.bind();
 			columns = new Ejb3Column[] { formulaColumn };
 		}
 		else {
 			javax.persistence.Column[] actualCols = anns;
 			javax.persistence.Column[] overriddenCols = propertyHolder.getOverriddenColumn(
 					StringHelper.qualify( propertyHolder.getPath(), inferredData.getPropertyName() )
 			);
 			if ( overriddenCols != null ) {
 				//check for overridden first
 				if ( anns != null && overriddenCols.length != anns.length ) {
 					throw new AnnotationException( "AttributeOverride.column() should override all columns for now" );
 				}
 				actualCols = overriddenCols.length == 0 ? null : overriddenCols;
                 LOG.debugf("Column(s) overridden for property %s", inferredData.getPropertyName());
 			}
 			if ( actualCols == null ) {
 				columns = buildImplicitColumn(
 						inferredData,
 						suffixForDefaultColumnName,
 						secondaryTables,
 						propertyHolder,
 						nullability,
 						mappings
 				);
 			}
 			else {
 				final int length = actualCols.length;
 				columns = new Ejb3Column[length];
 				for (int index = 0; index < length; index++) {
 					final ObjectNameNormalizer nameNormalizer = mappings.getObjectNameNormalizer();
 					javax.persistence.Column col = actualCols[index];
 					final String sqlType = col.columnDefinition().equals( "" )
 							? null
 							: nameNormalizer.normalizeIdentifierQuoting( col.columnDefinition() );
 					final String tableName = nameNormalizer.normalizeIdentifierQuoting( col.table() );
 					final String columnName = nameNormalizer.normalizeIdentifierQuoting( col.name() );
 					Ejb3Column column = new Ejb3Column();
 					column.setImplicit( false );
 					column.setSqlType( sqlType );
 					column.setLength( col.length() );
 					column.setPrecision( col.precision() );
 					column.setScale( col.scale() );
 					if ( StringHelper.isEmpty( columnName ) && ! StringHelper.isEmpty( suffixForDefaultColumnName ) ) {
 						column.setLogicalColumnName( inferredData.getPropertyName() + suffixForDefaultColumnName );
 					}
 					else {
 						column.setLogicalColumnName( columnName );
 					}
 
 					column.setPropertyName(
 							BinderHelper.getRelativePath( propertyHolder, inferredData.getPropertyName() )
 					);
 			 		column.setNullable(
 						col.nullable()
 					); //TODO force to not null if available? This is a (bad) user choice.
 					column.setUnique( col.unique() );
 					column.setInsertable( col.insertable() );
 					column.setUpdatable( col.updatable() );
 					column.setSecondaryTableName( tableName );
 					column.setPropertyHolder( propertyHolder );
 					column.setJoins( secondaryTables );
 					column.setMappings( mappings );
 					column.extractDataFromPropertyData(inferredData);
 					column.bind();
 					columns[index] = column;
 				}
 			}
 		}
 		return columns;
 	}
 
 	//must only be called after all setters are defined and before bind
 	private void extractDataFromPropertyData(PropertyData inferredData) {
 		if ( inferredData != null ) {
 			XProperty property = inferredData.getProperty();
 			if ( property != null ) {
 				processExpression( property.getAnnotation( ColumnTransformer.class ) );
 				ColumnTransformers annotations = property.getAnnotation( ColumnTransformers.class );
 				if (annotations != null) {
 					for ( ColumnTransformer annotation : annotations.value() ) {
 						processExpression( annotation );
 					}
 				}
 			}
 		}
 	}
 
 	private void processExpression(ColumnTransformer annotation) {
 		String nonNullLogicalColumnName = logicalColumnName != null ? logicalColumnName : ""; //use the default for annotations
 		if ( annotation != null &&
 				( StringHelper.isEmpty( annotation.forColumn() )
 						|| annotation.forColumn().equals( nonNullLogicalColumnName ) ) ) {
 			readExpression = annotation.read();
 			if ( StringHelper.isEmpty( readExpression ) ) {
 				readExpression = null;
 			}
 			writeExpression = annotation.write();
 			if ( StringHelper.isEmpty( writeExpression ) ) {
 				writeExpression = null;
 			}
 		}
 	}
 
 	private static Ejb3Column[] buildImplicitColumn(
 			PropertyData inferredData,
 			String suffixForDefaultColumnName,
 			Map<String, Join> secondaryTables,
 			PropertyHolder propertyHolder,
 			Nullability nullability,
 			Mappings mappings) {
 		Ejb3Column column = new Ejb3Column();
 		Ejb3Column[] columns = new Ejb3Column[1];
 		columns[0] = column;
 
 		//not following the spec but more clean
 		if ( nullability != Nullability.FORCED_NULL
 				&& inferredData.getClassOrElement().isPrimitive()
 				&& !inferredData.getProperty().isArray() ) {
 			column.setNullable( false );
 		}
 		column.setLength( DEFAULT_COLUMN_LENGTH );
 		final String propertyName = inferredData.getPropertyName();
 		column.setPropertyName(
 				BinderHelper.getRelativePath( propertyHolder, propertyName )
 		);
 		column.setPropertyHolder( propertyHolder );
 		column.setJoins( secondaryTables );
 		column.setMappings( mappings );
 
 		// property name + suffix is an "explicit" column name
 		if ( !StringHelper.isEmpty( suffixForDefaultColumnName ) ) {
 			column.setLogicalColumnName( propertyName + suffixForDefaultColumnName );
 			column.setImplicit( false );
 		}
 		else {
 			column.setImplicit( true );
 		}
 		column.extractDataFromPropertyData( inferredData );
 		column.bind();
 		return columns;
 	}
 
 	public static void checkPropertyConsistency(Ejb3Column[] columns, String propertyName) {
 		int nbrOfColumns = columns.length;
 
 		if ( nbrOfColumns > 1 ) {
 			for (int currentIndex = 1; currentIndex < nbrOfColumns; currentIndex++) {
 
 				if (columns[currentIndex].isFormula() || columns[currentIndex - 1].isFormula()) {
 					continue;
 				}
 
 				if ( columns[currentIndex].isInsertable() != columns[currentIndex - 1].isInsertable() ) {
 					throw new AnnotationException(
 							"Mixing insertable and non insertable columns in a property is not allowed: " + propertyName
 					);
 				}
 				if ( columns[currentIndex].isNullable() != columns[currentIndex - 1].isNullable() ) {
 					throw new AnnotationException(
 							"Mixing nullable and non nullable columns in a property is not allowed: " + propertyName
 					);
 				}
 				if ( columns[currentIndex].isUpdatable() != columns[currentIndex - 1].isUpdatable() ) {
 					throw new AnnotationException(
 							"Mixing updatable and non updatable columns in a property is not allowed: " + propertyName
 					);
 				}
 				if ( !columns[currentIndex].getTable().equals( columns[currentIndex - 1].getTable() ) ) {
 					throw new AnnotationException(
 							"Mixing different tables in a property is not allowed: " + propertyName
 					);
 				}
 			}
 		}
 
 	}
 
 	public void addIndex(Index index, boolean inSecondPass) {
 		if ( index == null ) return;
 		String indexName = index.name();
 		addIndex( indexName, inSecondPass );
 	}
 
 	void addIndex(String indexName, boolean inSecondPass) {
 		IndexOrUniqueKeySecondPass secondPass = new IndexOrUniqueKeySecondPass( indexName, this, mappings, false );
 		if ( inSecondPass ) {
 			secondPass.doSecondPass( mappings.getClasses() );
 		}
 		else {
 			mappings.addSecondPass(
 					secondPass
 			);
 		}
 	}
 
 	void addUniqueKey(String uniqueKeyName, boolean inSecondPass) {
 		IndexOrUniqueKeySecondPass secondPass = new IndexOrUniqueKeySecondPass( uniqueKeyName, this, mappings, true );
 		if ( inSecondPass ) {
 			secondPass.doSecondPass( mappings.getClasses() );
 		}
 		else {
 			mappings.addSecondPass(
 					secondPass
 			);
 		}
 	}
 
 	@Override
 	public String toString() {
 		final StringBuilder sb = new StringBuilder();
 		sb.append( "Ejb3Column" );
 		sb.append( "{table=" ).append( getTable() );
 		sb.append( ", mappingColumn=" ).append( mappingColumn.getName() );
 		sb.append( ", insertable=" ).append( insertable );
 		sb.append( ", updatable=" ).append( updatable );
 		sb.append( ", unique=" ).append( unique );
 		sb.append( '}' );
 		return sb.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java b/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
index a1b03f455b..62e17c22cb 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
@@ -1,810 +1,811 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.sql.Connection;
 import java.sql.Statement;
 import java.sql.Timestamp;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.Version;
 import org.hibernate.bytecode.spi.BytecodeProvider;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
+
 import org.jboss.logging.Logger;
 
 
 /**
  * Provides access to configuration info passed in <tt>Properties</tt> objects.
  * <br><br>
  * Hibernate has two property scopes:
  * <ul>
  * <li><b>Factory-level</b> properties may be passed to the <tt>SessionFactory</tt> when it
  * instantiated. Each instance might have different property values. If no
  * properties are specified, the factory calls <tt>Environment.getProperties()</tt>.
  * <li><b>System-level</b> properties are shared by all factory instances and are always
  * determined by the <tt>Environment</tt> properties.
  * </ul>
  * The only system-level properties are
  * <ul>
  * <li><tt>hibernate.jdbc.use_streams_for_binary</tt>
  * <li><tt>hibernate.cglib.use_reflection_optimizer</tt>
  * </ul>
  * <tt>Environment</tt> properties are populated by calling <tt>System.getProperties()</tt>
  * and then from a resource named <tt>/hibernate.properties</tt> if it exists. System
  * properties override properties specified in <tt>hibernate.properties</tt>.<br>
  * <br>
  * The <tt>SessionFactory</tt> is controlled by the following properties.
  * Properties may be either be <tt>System</tt> properties, properties
  * defined in a resource named <tt>/hibernate.properties</tt> or an instance of
  * <tt>java.util.Properties</tt> passed to
  * <tt>Configuration.buildSessionFactory()</tt><br>
  * <br>
  * <table>
  * <tr><td><b>property</b></td><td><b>meaning</b></td></tr>
  * <tr>
  *   <td><tt>hibernate.dialect</tt></td>
  *   <td>classname of <tt>org.hibernate.dialect.Dialect</tt> subclass</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.cache.provider_class</tt></td>
  *   <td>classname of <tt>org.hibernate.cache.CacheProvider</tt>
  *   subclass (if not specified EHCache is used)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.provider_class</tt></td>
  *   <td>classname of <tt>org.hibernate.service.jdbc.connections.spi.ConnectionProvider</tt>
  *   subclass (if not specified hueristics are used)</td>
  * </tr>
  * <tr><td><tt>hibernate.connection.username</tt></td><td>database username</td></tr>
  * <tr><td><tt>hibernate.connection.password</tt></td><td>database password</td></tr>
  * <tr>
  *   <td><tt>hibernate.connection.url</tt></td>
  *   <td>JDBC URL (when using <tt>java.sql.DriverManager</tt>)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.driver_class</tt></td>
  *   <td>classname of JDBC driver</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.isolation</tt></td>
  *   <td>JDBC transaction isolation level (only when using
  *     <tt>java.sql.DriverManager</tt>)
  *   </td>
  * </tr>
  *   <td><tt>hibernate.connection.pool_size</tt></td>
  *   <td>the maximum size of the connection pool (only when using
  *     <tt>java.sql.DriverManager</tt>)
  *   </td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.datasource</tt></td>
  *   <td>databasource JNDI name (when using <tt>javax.sql.Datasource</tt>)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jndi.url</tt></td><td>JNDI <tt>InitialContext</tt> URL</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jndi.class</tt></td><td>JNDI <tt>InitialContext</tt> classname</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.max_fetch_depth</tt></td>
  *   <td>maximum depth of outer join fetching</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.batch_size</tt></td>
  *   <td>enable use of JDBC2 batch API for drivers which support it</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.fetch_size</tt></td>
  *   <td>set the JDBC fetch size</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.use_scrollable_resultset</tt></td>
  *   <td>enable use of JDBC2 scrollable resultsets (you only need this specify
  *   this property when using user supplied connections)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.use_getGeneratedKeys</tt></td>
  *   <td>enable use of JDBC3 PreparedStatement.getGeneratedKeys() to retrieve
  *   natively generated keys after insert. Requires JDBC3+ driver and JRE1.4+</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.hbm2ddl.auto</tt></td>
  *   <td>enable auto DDL export</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.default_schema</tt></td>
  *   <td>use given schema name for unqualified tables (always optional)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.default_catalog</tt></td>
  *   <td>use given catalog name for unqualified tables (always optional)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.session_factory_name</tt></td>
  *   <td>If set, the factory attempts to bind this name to itself in the
  *   JNDI context. This name is also used to support cross JVM <tt>
  *   Session</tt> (de)serialization.</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.transaction.manager_lookup_class</tt></td>
  *   <td>classname of <tt>org.hibernate.transaction.TransactionManagerLookup</tt>
  *   implementor</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.transaction.factory_class</tt></td>
  *   <td>the factory to use for instantiating <tt>Transaction</tt>s.
  *   (Defaults to <tt>JdbcTransactionFactory</tt>.)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.query.substitutions</tt></td><td>query language token substitutions</td>
  * </tr>
  * </table>
  *
  * @see org.hibernate.SessionFactory
  * @author Gavin King
  */
 public final class Environment {
 	/**
 	 * <tt>ConnectionProvider</tt> implementor to use when obtaining connections
 	 */
 	public static final String CONNECTION_PROVIDER ="hibernate.connection.provider_class";
 	/**
 	 * JDBC driver class
 	 */
 	public static final String DRIVER ="hibernate.connection.driver_class";
 	/**
 	 * JDBC transaction isolation level
 	 */
 	public static final String ISOLATION ="hibernate.connection.isolation";
 	/**
 	 * JDBC URL
 	 */
 	public static final String URL ="hibernate.connection.url";
 	/**
 	 * JDBC user
 	 */
 	public static final String USER ="hibernate.connection.username";
 	/**
 	 * JDBC password
 	 */
 	public static final String PASS ="hibernate.connection.password";
 	/**
 	 * JDBC autocommit mode
 	 */
 	public static final String AUTOCOMMIT ="hibernate.connection.autocommit";
 	/**
 	 * Maximum number of inactive connections for Hibernate's connection pool
 	 */
 	public static final String POOL_SIZE ="hibernate.connection.pool_size";
 	/**
 	 * <tt>java.sql.Datasource</tt> JNDI name
 	 */
 	public static final String DATASOURCE ="hibernate.connection.datasource";
 	/**
 	 * prefix for arbitrary JDBC connection properties
 	 */
 	public static final String CONNECTION_PREFIX = "hibernate.connection";
 
 	/**
 	 * JNDI initial context class, <tt>Context.INITIAL_CONTEXT_FACTORY</tt>
 	 */
 	public static final String JNDI_CLASS ="hibernate.jndi.class";
 	/**
 	 * JNDI provider URL, <tt>Context.PROVIDER_URL</tt>
 	 */
 	public static final String JNDI_URL ="hibernate.jndi.url";
 	/**
 	 * prefix for arbitrary JNDI <tt>InitialContext</tt> properties
 	 */
 	public static final String JNDI_PREFIX = "hibernate.jndi";
 	/**
 	 * JNDI name to bind to <tt>SessionFactory</tt>
 	 */
 	public static final String SESSION_FACTORY_NAME = "hibernate.session_factory_name";
 
 	/**
 	 * Hibernate SQL {@link org.hibernate.dialect.Dialect} class
 	 */
 	public static final String DIALECT ="hibernate.dialect";
 
 	/**
 	 * {@link org.hibernate.service.jdbc.dialect.spi.DialectResolver} classes to register with the
 	 * {@link org.hibernate.service.jdbc.dialect.spi.DialectFactory}
 	 */
 	public static final String DIALECT_RESOLVERS = "hibernate.dialect_resolvers";
 
 	/**
 	 * A default database schema (owner) name to use for unqualified tablenames
 	 */
 	public static final String DEFAULT_SCHEMA = "hibernate.default_schema";
 	/**
 	 * A default database catalog name to use for unqualified tablenames
 	 */
 	public static final String DEFAULT_CATALOG = "hibernate.default_catalog";
 
 	/**
 	 * Enable logging of generated SQL to the console
 	 */
 	public static final String SHOW_SQL ="hibernate.show_sql";
 	/**
 	 * Enable formatting of SQL logged to the console
 	 */
 	public static final String FORMAT_SQL ="hibernate.format_sql";
 	/**
 	 * Add comments to the generated SQL
 	 */
 	public static final String USE_SQL_COMMENTS ="hibernate.use_sql_comments";
 	/**
 	 * Maximum depth of outer join fetching
 	 */
 	public static final String MAX_FETCH_DEPTH = "hibernate.max_fetch_depth";
 	/**
 	 * The default batch size for batch fetching
 	 */
 	public static final String DEFAULT_BATCH_FETCH_SIZE = "hibernate.default_batch_fetch_size";
 	/**
 	 * Use <tt>java.io</tt> streams to read / write binary data from / to JDBC
 	 */
 	public static final String USE_STREAMS_FOR_BINARY = "hibernate.jdbc.use_streams_for_binary";
 	/**
 	 * Use JDBC scrollable <tt>ResultSet</tt>s. This property is only necessary when there is
 	 * no <tt>ConnectionProvider</tt>, ie. the user is supplying JDBC connections.
 	 */
 	public static final String USE_SCROLLABLE_RESULTSET = "hibernate.jdbc.use_scrollable_resultset";
 	/**
 	 * Tells the JDBC driver to attempt to retrieve row Id with the JDBC 3.0 PreparedStatement.getGeneratedKeys()
 	 * method. In general, performance will be better if this property is set to true and the underlying
 	 * JDBC driver supports getGeneratedKeys().
 	 */
 	public static final String USE_GET_GENERATED_KEYS = "hibernate.jdbc.use_get_generated_keys";
 	/**
 	 * Gives the JDBC driver a hint as to the number of rows that should be fetched from the database
 	 * when more rows are needed. If <tt>0</tt>, JDBC driver default settings will be used.
 	 */
 	public static final String STATEMENT_FETCH_SIZE = "hibernate.jdbc.fetch_size";
 	/**
 	 * Maximum JDBC batch size. A nonzero value enables batch updates.
 	 */
 	public static final String STATEMENT_BATCH_SIZE = "hibernate.jdbc.batch_size";
 	/**
 	 * Select a custom batcher.
 	 */
 	public static final String BATCH_STRATEGY = "hibernate.jdbc.factory_class";
 	/**
 	 * Should versioned data be included in batching?
 	 */
 	public static final String BATCH_VERSIONED_DATA = "hibernate.jdbc.batch_versioned_data";
 	/**
 	 * An XSLT resource used to generate "custom" XML
 	 */
 	public static final String OUTPUT_STYLESHEET ="hibernate.xml.output_stylesheet";
 
 	/**
 	 * Maximum size of C3P0 connection pool
 	 */
 	public static final String C3P0_MAX_SIZE = "hibernate.c3p0.max_size";
 	/**
 	 * Minimum size of C3P0 connection pool
 	 */
 	public static final String C3P0_MIN_SIZE = "hibernate.c3p0.min_size";
 
 	/**
 	 * Maximum idle time for C3P0 connection pool
 	 */
 	public static final String C3P0_TIMEOUT = "hibernate.c3p0.timeout";
 	/**
 	 * Maximum size of C3P0 statement cache
 	 */
 	public static final String C3P0_MAX_STATEMENTS = "hibernate.c3p0.max_statements";
 	/**
 	 * Number of connections acquired when pool is exhausted
 	 */
 	public static final String C3P0_ACQUIRE_INCREMENT = "hibernate.c3p0.acquire_increment";
 	/**
 	 * Idle time before a C3P0 pooled connection is validated
 	 */
 	public static final String C3P0_IDLE_TEST_PERIOD = "hibernate.c3p0.idle_test_period";
 
 	/**
 	 * Proxool/Hibernate property prefix
 	 */
 	public static final String PROXOOL_PREFIX = "hibernate.proxool";
 	/**
 	 * Proxool property to configure the Proxool Provider using an XML (<tt>/path/to/file.xml</tt>)
 	 */
 	public static final String PROXOOL_XML = "hibernate.proxool.xml";
 	/**
 	 * Proxool property to configure the Proxool Provider  using a properties file (<tt>/path/to/proxool.properties</tt>)
 	 */
 	public static final String PROXOOL_PROPERTIES = "hibernate.proxool.properties";
 	/**
 	 * Proxool property to configure the Proxool Provider from an already existing pool (<tt>true</tt> / <tt>false</tt>)
 	 */
 	public static final String PROXOOL_EXISTING_POOL = "hibernate.proxool.existing_pool";
 	/**
 	 * Proxool property with the Proxool pool alias to use
 	 * (Required for <tt>PROXOOL_EXISTING_POOL</tt>, <tt>PROXOOL_PROPERTIES</tt>, or
 	 * <tt>PROXOOL_XML</tt>)
 	 */
 	public static final String PROXOOL_POOL_ALIAS = "hibernate.proxool.pool_alias";
 
 	/**
 	 * Enable automatic session close at end of transaction
 	 */
 	public static final String AUTO_CLOSE_SESSION = "hibernate.transaction.auto_close_session";
 	/**
 	 * Enable automatic flush during the JTA <tt>beforeCompletion()</tt> callback
 	 */
 	public static final String FLUSH_BEFORE_COMPLETION = "hibernate.transaction.flush_before_completion";
 	/**
 	 * Specifies how Hibernate should release JDBC connections.
 	 */
 	public static final String RELEASE_CONNECTIONS = "hibernate.connection.release_mode";
 	/**
 	 * Context scoping impl for {@link org.hibernate.SessionFactory#getCurrentSession()} processing.
 	 */
 	public static final String CURRENT_SESSION_CONTEXT_CLASS = "hibernate.current_session_context_class";
 	/**
 	 * Names the implementation of {@link org.hibernate.engine.transaction.spi.TransactionContext} to use for
 	 * creating {@link org.hibernate.Transaction} instances
 	 */
 	public static final String TRANSACTION_STRATEGY = "hibernate.transaction.factory_class";
 	/**
 	 * <tt>TransactionManagerLookup</tt> implementor to use for obtaining the <tt>TransactionManager</tt>
 	 */
 	public static final String TRANSACTION_MANAGER_STRATEGY = "hibernate.transaction.manager_lookup_class";
 	/**
 	 * JNDI name of JTA <tt>UserTransaction</tt> object
 	 */
 	public static final String USER_TRANSACTION = "jta.UserTransaction";
 
 	/**
 	 * The <tt>CacheProvider</tt> implementation class
 	 */
 	public static final String CACHE_PROVIDER = "hibernate.cache.provider_class";
 
 	/**
 	 * The {@link org.hibernate.cache.RegionFactory} implementation class
 	 */
 	public static final String CACHE_REGION_FACTORY = "hibernate.cache.region.factory_class";
 
 	/**
 	 * The <tt>CacheProvider</tt> implementation class
 	 */
 	public static final String CACHE_PROVIDER_CONFIG = "hibernate.cache.provider_configuration_file_resource_path";
 	/**
 	 * The <tt>CacheProvider</tt> JNDI namespace, if pre-bound to JNDI.
 	 */
 	public static final String CACHE_NAMESPACE = "hibernate.cache.jndi";
 	/**
 	 * Enable the query cache (disabled by default)
 	 */
 	public static final String USE_QUERY_CACHE = "hibernate.cache.use_query_cache";
 	/**
 	 * The <tt>QueryCacheFactory</tt> implementation class.
 	 */
 	public static final String QUERY_CACHE_FACTORY = "hibernate.cache.query_cache_factory";
 	/**
 	 * Enable the second-level cache (enabled by default)
 	 */
 	public static final String USE_SECOND_LEVEL_CACHE = "hibernate.cache.use_second_level_cache";
 	/**
 	 * Optimize the cache for minimal puts instead of minimal gets
 	 */
 	public static final String USE_MINIMAL_PUTS = "hibernate.cache.use_minimal_puts";
 	/**
 	 * The <tt>CacheProvider</tt> region name prefix
 	 */
 	public static final String CACHE_REGION_PREFIX = "hibernate.cache.region_prefix";
 	/**
 	 * Enable use of structured second-level cache entries
 	 */
 	public static final String USE_STRUCTURED_CACHE = "hibernate.cache.use_structured_entries";
 
 	/**
 	 * Enable statistics collection
 	 */
 	public static final String GENERATE_STATISTICS = "hibernate.generate_statistics";
 
 	public static final String USE_IDENTIFIER_ROLLBACK = "hibernate.use_identifier_rollback";
 
 	/**
 	 * Use bytecode libraries optimized property access
 	 */
 	public static final String USE_REFLECTION_OPTIMIZER = "hibernate.bytecode.use_reflection_optimizer";
 
 	/**
 	 * The classname of the HQL query parser factory
 	 */
 	public static final String QUERY_TRANSLATOR = "hibernate.query.factory_class";
 
 	/**
 	 * A comma-separated list of token substitutions to use when translating a Hibernate
 	 * query to SQL
 	 */
 	public static final String QUERY_SUBSTITUTIONS = "hibernate.query.substitutions";
 
 	/**
 	 * Should named queries be checked during startup (the default is enabled).
 	 * <p/>
 	 * Mainly intended for test environments.
 	 */
 	public static final String QUERY_STARTUP_CHECKING = "hibernate.query.startup_check";
 
 	/**
 	 * Auto export/update schema using hbm2ddl tool. Valid values are <tt>update</tt>,
 	 * <tt>create</tt>, <tt>create-drop</tt> and <tt>validate</tt>.
 	 */
 	public static final String HBM2DDL_AUTO = "hibernate.hbm2ddl.auto";
 
 	/**
 	 * Comma-separated names of the optional files containing SQL DML statements executed
 	 * during the SessionFactory creation.
 	 * File order matters, the statements of a give file are executed before the statements of the
 	 * following files.
 	 *
 	 * These statements are only executed if the schema is created ie if <tt>hibernate.hbm2ddl.auto</tt>
 	 * is set to <tt>create</tt> or <tt>create-drop</tt>.
 	 *
 	 * The default value is <tt>/import.sql</tt>
 	 */
 	public static final String HBM2DDL_IMPORT_FILES = "hibernate.hbm2ddl.import_files";
 
 	/**
 	 * The {@link org.hibernate.exception.SQLExceptionConverter} to use for converting SQLExceptions
 	 * to Hibernate's JDBCException hierarchy.  The default is to use the configured
 	 * {@link org.hibernate.dialect.Dialect}'s preferred SQLExceptionConverter.
 	 */
 	public static final String SQL_EXCEPTION_CONVERTER = "hibernate.jdbc.sql_exception_converter";
 
 	/**
 	 * Enable wrapping of JDBC result sets in order to speed up column name lookups for
 	 * broken JDBC drivers
 	 */
 	public static final String WRAP_RESULT_SETS = "hibernate.jdbc.wrap_result_sets";
 
 	/**
 	 * Enable ordering of update statements by primary key value
 	 */
 	public static final String ORDER_UPDATES = "hibernate.order_updates";
 
 	/**
 	 * Enable ordering of insert statements for the purpose of more efficient JDBC batching.
 	 */
 	public static final String ORDER_INSERTS = "hibernate.order_inserts";
 
 	/**
 	 * The EntityMode in which set the Session opened from the SessionFactory.
 	 */
     public static final String DEFAULT_ENTITY_MODE = "hibernate.default_entity_mode";
 
     /**
      * The jacc context id of the deployment
      */
     public static final String JACC_CONTEXTID = "hibernate.jacc_context_id";
 
 	/**
 	 * Should all database identifiers be quoted.
 	 */
 	public static final String GLOBALLY_QUOTED_IDENTIFIERS = "hibernate.globally_quoted_identifiers";
 
 	/**
 	 * Enable nullability checking.
 	 * Raises an exception if a property marked as not-null is null.
 	 * Default to false if Bean Validation is present in the classpath and Hibernate Annotations is used,
 	 * true otherwise.
 	 */
 	public static final String CHECK_NULLABILITY = "hibernate.check_nullability";
 
 
 	public static final String BYTECODE_PROVIDER = "hibernate.bytecode.provider";
 
 	public static final String JPAQL_STRICT_COMPLIANCE= "hibernate.query.jpaql_strict_compliance";
 
 	/**
 	 * When using pooled {@link org.hibernate.id.enhanced.Optimizer optimizers}, prefer interpreting the
 	 * database value as the lower (lo) boundary.  The default is to interpret it as the high boundary.
 	 */
 	public static final String PREFER_POOLED_VALUES_LO = "hibernate.id.optimizer.pooled.prefer_lo";
 
 	/**
 	 * The maximum number of strong references maintained by {@link org.hibernate.internal.util.collections.SoftLimitMRUCache}. Default is 128.
 	 */
 	public static final String QUERY_PLAN_CACHE_MAX_STRONG_REFERENCES = "hibernate.query.plan_cache_max_strong_references";
 
 	/**
 	 * The maximum number of soft references maintained by {@link org.hibernate.internal.util.collections.SoftLimitMRUCache}. Default is 2048.
 	 */
 	public static final String QUERY_PLAN_CACHE_MAX_SOFT_REFERENCES = "hibernate.query.plan_cache_max_soft_references";
 
 	/**
 	 * Should we not use contextual LOB creation (aka based on {@link java.sql.Connection#createBlob()} et al).
 	 */
 	public static final String NON_CONTEXTUAL_LOB_CREATION = "hibernate.jdbc.lob.non_contextual_creation";
 
 	/**
 	 * Strategy for multi-tenancy.
 	 * @see org.hibernate.MultiTenancyStrategy
 	 */
 	public static final String MULTI_TENANT = "hibernate.multiTenancy";
 
 	private static final BytecodeProvider BYTECODE_PROVIDER_INSTANCE;
 	private static final boolean ENABLE_BINARY_STREAMS;
 	private static final boolean ENABLE_REFLECTION_OPTIMIZER;
 	private static final boolean JVM_SUPPORTS_LINKED_HASH_COLLECTIONS;
 	private static final boolean JVM_HAS_TIMESTAMP_BUG;
 	private static final boolean JVM_HAS_JDK14_TIMESTAMP;
 	private static final boolean JVM_SUPPORTS_GET_GENERATED_KEYS;
 
 	private static final Properties GLOBAL_PROPERTIES;
 	private static final HashMap ISOLATION_LEVELS = new HashMap();
 	private static final Map OBSOLETE_PROPERTIES = new HashMap();
 	private static final Map RENAMED_PROPERTIES = new HashMap();
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Environment.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Environment.class.getName());
 
 	/**
 	 * Issues warnings to the user when any obsolete or renamed property names are used.
 	 *
 	 * @param props The specified properties.
 	 */
 	public static void verifyProperties(Properties props) {
 		Iterator iter = props.keySet().iterator();
 		Map propertiesToAdd = new HashMap();
 		while ( iter.hasNext() ) {
 			final Object propertyName = iter.next();
 			Object newPropertyName = OBSOLETE_PROPERTIES.get( propertyName );
             if (newPropertyName != null) LOG.unsupportedProperty(propertyName, newPropertyName);
 			newPropertyName = RENAMED_PROPERTIES.get( propertyName );
 			if ( newPropertyName != null ) {
                 LOG.renamedProperty(propertyName, newPropertyName);
 				if ( ! props.containsKey( newPropertyName ) ) {
 					propertiesToAdd.put( newPropertyName, props.get( propertyName ) );
 				}
 			}
 		}
 		props.putAll(propertiesToAdd);
 	}
 
 	static {
 
         LOG.version(Version.getVersionString());
 
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_NONE), "NONE" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_READ_UNCOMMITTED), "READ_UNCOMMITTED" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_READ_COMMITTED), "READ_COMMITTED" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_REPEATABLE_READ), "REPEATABLE_READ" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_SERIALIZABLE), "SERIALIZABLE" );
 
 		GLOBAL_PROPERTIES = new Properties();
 		//Set USE_REFLECTION_OPTIMIZER to false to fix HHH-227
 		GLOBAL_PROPERTIES.setProperty( USE_REFLECTION_OPTIMIZER, Boolean.FALSE.toString() );
 
 		try {
 			InputStream stream = ConfigHelper.getResourceAsStream( "/hibernate.properties" );
 			try {
 				GLOBAL_PROPERTIES.load(stream);
                 LOG.propertiesLoaded(ConfigurationHelper.maskOut(GLOBAL_PROPERTIES, PASS));
 			}
 			catch (Exception e) {
                 LOG.unableToloadProperties();
 			}
 			finally {
 				try{
 					stream.close();
 				}
 				catch (IOException ioe){
                     LOG.unableToCloseStreamError(ioe);
 				}
 			}
 		}
 		catch (HibernateException he) {
             LOG.propertiesNotFound();
 		}
 
 		try {
 			GLOBAL_PROPERTIES.putAll( System.getProperties() );
 		}
 		catch (SecurityException se) {
             LOG.unableToCopySystemProperties();
 		}
 
 		verifyProperties(GLOBAL_PROPERTIES);
 
 		ENABLE_BINARY_STREAMS = ConfigurationHelper.getBoolean(USE_STREAMS_FOR_BINARY, GLOBAL_PROPERTIES);
 		ENABLE_REFLECTION_OPTIMIZER = ConfigurationHelper.getBoolean(USE_REFLECTION_OPTIMIZER, GLOBAL_PROPERTIES);
 
         if (ENABLE_BINARY_STREAMS) LOG.usingStreams();
         if (ENABLE_REFLECTION_OPTIMIZER) LOG.usingReflectionOptimizer();
 		BYTECODE_PROVIDER_INSTANCE = buildBytecodeProvider( GLOBAL_PROPERTIES );
 
 		boolean getGeneratedKeysSupport;
 		try {
 			Statement.class.getMethod("getGeneratedKeys", (Class[])null);
 			getGeneratedKeysSupport = true;
 		}
 		catch (NoSuchMethodException nsme) {
 			getGeneratedKeysSupport = false;
 		}
 		JVM_SUPPORTS_GET_GENERATED_KEYS = getGeneratedKeysSupport;
         if (!JVM_SUPPORTS_GET_GENERATED_KEYS) LOG.generatedKeysNotSupported();
 
 		boolean linkedHashSupport;
 		try {
 			Class.forName("java.util.LinkedHashSet");
 			linkedHashSupport = true;
 		}
 		catch (ClassNotFoundException cnfe) {
 			linkedHashSupport = false;
 		}
 		JVM_SUPPORTS_LINKED_HASH_COLLECTIONS = linkedHashSupport;
         if (!JVM_SUPPORTS_LINKED_HASH_COLLECTIONS) LOG.linkedMapsAndSetsNotSupported();
 
 		long x = 123456789;
 		JVM_HAS_TIMESTAMP_BUG = new Timestamp(x).getTime() != x;
         if (JVM_HAS_TIMESTAMP_BUG) LOG.usingTimestampWorkaround();
 
 		Timestamp t = new Timestamp(0);
 		t.setNanos(5 * 1000000);
 		JVM_HAS_JDK14_TIMESTAMP = t.getTime() == 5;
         if (JVM_HAS_JDK14_TIMESTAMP) LOG.usingJdk14TimestampHandling();
         else LOG.usingPreJdk14TimestampHandling();
 	}
 
 	public static BytecodeProvider getBytecodeProvider() {
 		return BYTECODE_PROVIDER_INSTANCE;
 	}
 
 	/**
 	 * Does this JVM's implementation of {@link java.sql.Timestamp} have a bug in which the following is true:<code>
 	 * new java.sql.Timestamp( x ).getTime() != x
 	 * </code>
 	 * <p/>
 	 * NOTE : IBM JDK 1.3.1 the only known JVM to exhibit this behavior.
 	 *
 	 * @return True if the JVM's {@link Timestamp} implementa
 	 */
 	public static boolean jvmHasTimestampBug() {
 		return JVM_HAS_TIMESTAMP_BUG;
 	}
 
 	/**
 	 * Does this JVM handle {@link java.sql.Timestamp} in the JDK 1.4 compliant way wrt to nano rolling>
 	 *
 	 * @return True if the JDK 1.4 (JDBC3) specification for {@link java.sql.Timestamp} nano rolling is adhered to.
 	 *
 	 * @deprecated Starting with 3.3 Hibernate requires JDK 1.4 or higher
 	 */
 	@Deprecated
     public static boolean jvmHasJDK14Timestamp() {
 		return JVM_HAS_JDK14_TIMESTAMP;
 	}
 
 	/**
 	 * Does this JVM support {@link java.util.LinkedHashSet} and {@link java.util.LinkedHashMap}?
 	 * <p/>
 	 * Note, this is true for JDK 1.4 and above; hence the deprecation.
 	 *
 	 * @return True if {@link java.util.LinkedHashSet} and {@link java.util.LinkedHashMap} are available.
 	 *
 	 * @deprecated Starting with 3.3 Hibernate requires JDK 1.4 or higher
 	 * @see java.util.LinkedHashSet
 	 * @see java.util.LinkedHashMap
 	 */
 	@Deprecated
     public static boolean jvmSupportsLinkedHashCollections() {
 		return JVM_SUPPORTS_LINKED_HASH_COLLECTIONS;
 	}
 
 	/**
 	 * Does this JDK/JVM define the JDBC {@link Statement} interface with a 'getGeneratedKeys' method?
 	 * <p/>
 	 * Note, this is true for JDK 1.4 and above; hence the deprecation.
 	 *
 	 * @return True if generated keys can be retrieved via Statement; false otherwise.
 	 *
 	 * @see Statement
 	 * @deprecated Starting with 3.3 Hibernate requires JDK 1.4 or higher
 	 */
 	@Deprecated
     public static boolean jvmSupportsGetGeneratedKeys() {
 		return JVM_SUPPORTS_GET_GENERATED_KEYS;
 	}
 
 	/**
 	 * Should we use streams to bind binary types to JDBC IN parameters?
 	 *
 	 * @return True if streams should be used for binary data handling; false otherwise.
 	 *
 	 * @see #USE_STREAMS_FOR_BINARY
 	 */
 	public static boolean useStreamsForBinary() {
 		return ENABLE_BINARY_STREAMS;
 	}
 
 	/**
 	 * Should we use reflection optimization?
 	 *
 	 * @return True if reflection optimization should be used; false otherwise.
 	 *
 	 * @see #USE_REFLECTION_OPTIMIZER
 	 * @see #getBytecodeProvider()
 	 * @see BytecodeProvider#getReflectionOptimizer
 	 */
 	public static boolean useReflectionOptimizer() {
 		return ENABLE_REFLECTION_OPTIMIZER;
 	}
 
 	/**
 	 * Disallow instantiation
 	 */
 	private Environment() {
 		throw new UnsupportedOperationException();
 	}
 
 	/**
 	 * Return <tt>System</tt> properties, extended by any properties specified
 	 * in <tt>hibernate.properties</tt>.
 	 * @return Properties
 	 */
 	public static Properties getProperties() {
 		Properties copy = new Properties();
 		copy.putAll(GLOBAL_PROPERTIES);
 		return copy;
 	}
 
 	/**
 	 * Get the name of a JDBC transaction isolation level
 	 *
 	 * @see java.sql.Connection
 	 * @param isolation as defined by <tt>java.sql.Connection</tt>
 	 * @return a human-readable name
 	 */
 	public static String isolationLevelToString(int isolation) {
 		return (String) ISOLATION_LEVELS.get( new Integer(isolation) );
 	}
 
 	public static BytecodeProvider buildBytecodeProvider(Properties properties) {
 		String provider = ConfigurationHelper.getString( BYTECODE_PROVIDER, properties, "javassist" );
         LOG.bytecodeProvider(provider);
 		return buildBytecodeProvider( provider );
 	}
 
 	private static BytecodeProvider buildBytecodeProvider(String providerName) {
 		if ( "javassist".equals( providerName ) ) {
 			return new org.hibernate.bytecode.internal.javassist.BytecodeProviderImpl();
 		}
 
         LOG.unknownBytecodeProvider( providerName );
 		return new org.hibernate.bytecode.internal.javassist.BytecodeProviderImpl();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/HbmBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/HbmBinder.java
index dd0e14a27b..1ad46426c9 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/HbmBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/HbmBinder.java
@@ -1,1110 +1,1110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Properties;
 import java.util.StringTokenizer;
 import org.dom4j.Attribute;
 import org.dom4j.Document;
 import org.dom4j.Element;
 import org.hibernate.CacheMode;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.FlushMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.Versioning;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.internal.util.xml.XmlDocument;
 import org.hibernate.mapping.Any;
 import org.hibernate.mapping.Array;
 import org.hibernate.mapping.AuxiliaryDatabaseObject;
 import org.hibernate.mapping.Backref;
 import org.hibernate.mapping.Bag;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.FetchProfile;
 import org.hibernate.mapping.Fetchable;
 import org.hibernate.mapping.Filterable;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.IdentifierBag;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.IndexBackref;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.JoinedSubclass;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.List;
 import org.hibernate.mapping.ManyToOne;
 import org.hibernate.mapping.Map;
 import org.hibernate.mapping.MetaAttribute;
 import org.hibernate.mapping.MetadataSource;
 import org.hibernate.mapping.OneToMany;
 import org.hibernate.mapping.OneToOne;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.PrimitiveArray;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.PropertyGeneration;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Set;
 import org.hibernate.mapping.SimpleAuxiliaryDatabaseObject;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.SingleTableSubclass;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.ToOne;
 import org.hibernate.mapping.TypeDef;
 import org.hibernate.mapping.UnionSubclass;
 import org.hibernate.mapping.UniqueKey;
 import org.hibernate.mapping.Value;
 import org.hibernate.persister.entity.JoinedSubclassEntityPersister;
 import org.hibernate.persister.entity.SingleTableEntityPersister;
 import org.hibernate.persister.entity.UnionSubclassEntityPersister;
 import org.hibernate.type.DiscriminatorType;
 import org.hibernate.type.ForeignKeyDirection;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Walks an XML mapping document and produces the Hibernate configuration-time metamodel (the
  * classes in the <tt>mapping</tt> package)
  *
  * @author Gavin King
  */
 public final class HbmBinder {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, HbmBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HbmBinder.class.getName());
 
 	/**
 	 * Private constructor to disallow instantiation.
 	 */
 	private HbmBinder() {
 	}
 
 	/**
 	 * The main contract into the hbm.xml-based binder. Performs necessary binding operations
 	 * represented by the given DOM.
 	 *
 	 * @param metadataXml The DOM to be parsed and bound.
 	 * @param mappings Current bind state.
 	 * @param inheritedMetas Any inherited meta-tag information.
 	 * @param entityNames Any state
 	 *
 	 * @throws MappingException
 	 */
 	public static void bindRoot(
 			XmlDocument metadataXml,
 			Mappings mappings,
 			java.util.Map inheritedMetas,
 			java.util.Set<String> entityNames) throws MappingException {
 
 		final Document doc = metadataXml.getDocumentTree();
 		final Element hibernateMappingElement = doc.getRootElement();
 
 		java.util.List<String> names = HbmBinder.getExtendsNeeded( metadataXml, mappings );
 		if ( !names.isEmpty() ) {
 			// classes mentioned in extends not available - so put it in queue
 			Attribute packageAttribute = hibernateMappingElement.attribute( "package" );
 			String packageName = packageAttribute == null ? null : packageAttribute.getValue();
 			for ( String name : names ) {
 				mappings.addToExtendsQueue( new ExtendsQueueEntry( name, packageName, metadataXml, entityNames ) );
 			}
 			return;
 		}
 
 		// get meta's from <hibernate-mapping>
 		inheritedMetas = getMetas( hibernateMappingElement, inheritedMetas, true );
 		extractRootAttributes( hibernateMappingElement, mappings );
 
 		Iterator rootChildren = hibernateMappingElement.elementIterator();
 		while ( rootChildren.hasNext() ) {
 			final Element element = (Element) rootChildren.next();
 			final String elementName = element.getName();
 
 			if ( "filter-def".equals( elementName ) ) {
 				parseFilterDef( element, mappings );
 			}
 			else if ( "fetch-profile".equals( elementName ) ) {
 				parseFetchProfile( element, mappings, null );
 			}
 			else if ( "identifier-generator".equals( elementName ) ) {
 				parseIdentifierGeneratorRegistration( element, mappings );
 			}
 			else if ( "typedef".equals( elementName ) ) {
 				bindTypeDef( element, mappings );
 			}
 			else if ( "class".equals( elementName ) ) {
 				RootClass rootclass = new RootClass();
 				bindRootClass( element, rootclass, mappings, inheritedMetas );
 				mappings.addClass( rootclass );
 			}
 			else if ( "subclass".equals( elementName ) ) {
 				PersistentClass superModel = getSuperclass( mappings, element );
 				handleSubclass( superModel, mappings, element, inheritedMetas );
 			}
 			else if ( "joined-subclass".equals( elementName ) ) {
 				PersistentClass superModel = getSuperclass( mappings, element );
 				handleJoinedSubclass( superModel, mappings, element, inheritedMetas );
 			}
 			else if ( "union-subclass".equals( elementName ) ) {
 				PersistentClass superModel = getSuperclass( mappings, element );
 				handleUnionSubclass( superModel, mappings, element, inheritedMetas );
 			}
 			else if ( "query".equals( elementName ) ) {
 				bindNamedQuery( element, null, mappings );
 			}
 			else if ( "sql-query".equals( elementName ) ) {
 				bindNamedSQLQuery( element, null, mappings );
 			}
 			else if ( "resultset".equals( elementName ) ) {
 				bindResultSetMappingDefinition( element, null, mappings );
 			}
 			else if ( "import".equals( elementName ) ) {
 				bindImport( element, mappings );
 			}
 			else if ( "database-object".equals( elementName ) ) {
 				bindAuxiliaryDatabaseObject( element, mappings );
 			}
 		}
 	}
 
 	private static void parseIdentifierGeneratorRegistration(Element element, Mappings mappings) {
 		String strategy = element.attributeValue( "name" );
 		if ( StringHelper.isEmpty( strategy ) ) {
 			throw new MappingException( "'name' attribute expected for identifier-generator elements" );
 		}
 		String generatorClassName = element.attributeValue( "class" );
 		if ( StringHelper.isEmpty( generatorClassName ) ) {
 			throw new MappingException( "'class' attribute expected for identifier-generator [identifier-generator@name=" + strategy + "]" );
 		}
 
 		try {
 			Class generatorClass = ReflectHelper.classForName( generatorClassName );
 			mappings.getIdentifierGeneratorFactory().register( strategy, generatorClass );
 		}
 		catch ( ClassNotFoundException e ) {
 			throw new MappingException( "Unable to locate identifier-generator class [name=" + strategy + ", class=" + generatorClassName + "]" );
 		}
 
 	}
 
 	private static void bindImport(Element importNode, Mappings mappings) {
 		String className = getClassName( importNode.attribute( "class" ), mappings );
 		Attribute renameNode = importNode.attribute( "rename" );
 		String rename = ( renameNode == null ) ?
 						StringHelper.unqualify( className ) :
 						renameNode.getValue();
         LOG.debugf("Import: %s -> %s", rename, className);
 		mappings.addImport( className, rename );
 	}
 
 	private static void bindTypeDef(Element typedefNode, Mappings mappings) {
 		String typeClass = typedefNode.attributeValue( "class" );
 		String typeName = typedefNode.attributeValue( "name" );
 		Iterator paramIter = typedefNode.elementIterator( "param" );
 		Properties parameters = new Properties();
 		while ( paramIter.hasNext() ) {
 			Element param = (Element) paramIter.next();
 			parameters.setProperty( param.attributeValue( "name" ), param.getTextTrim() );
 		}
 		mappings.addTypeDef( typeName, typeClass, parameters );
 	}
 
 	private static void bindAuxiliaryDatabaseObject(Element auxDbObjectNode, Mappings mappings) {
 		AuxiliaryDatabaseObject auxDbObject = null;
 		Element definitionNode = auxDbObjectNode.element( "definition" );
 		if ( definitionNode != null ) {
 			try {
 				auxDbObject = ( AuxiliaryDatabaseObject ) ReflectHelper
 						.classForName( definitionNode.attributeValue( "class" ) )
 						.newInstance();
 			}
 			catch( ClassNotFoundException e ) {
 				throw new MappingException(
 						"could not locate custom database object class [" +
 						definitionNode.attributeValue( "class" ) + "]"
 					);
 			}
 			catch( Throwable t ) {
 				throw new MappingException(
 						"could not instantiate custom database object class [" +
 						definitionNode.attributeValue( "class" ) + "]"
 					);
 			}
 		}
 		else {
 			auxDbObject = new SimpleAuxiliaryDatabaseObject(
 					auxDbObjectNode.elementTextTrim( "create" ),
 					auxDbObjectNode.elementTextTrim( "drop" )
 				);
 		}
 
 		Iterator dialectScopings = auxDbObjectNode.elementIterator( "dialect-scope" );
 		while ( dialectScopings.hasNext() ) {
 			Element dialectScoping = ( Element ) dialectScopings.next();
 			auxDbObject.addDialectScope( dialectScoping.attributeValue( "name" ) );
 		}
 
 		mappings.addAuxiliaryDatabaseObject( auxDbObject );
 	}
 
 	private static void extractRootAttributes(Element hmNode, Mappings mappings) {
 		Attribute schemaNode = hmNode.attribute( "schema" );
 		mappings.setSchemaName( ( schemaNode == null ) ? null : schemaNode.getValue() );
 
 		Attribute catalogNode = hmNode.attribute( "catalog" );
 		mappings.setCatalogName( ( catalogNode == null ) ? null : catalogNode.getValue() );
 
 		Attribute dcNode = hmNode.attribute( "default-cascade" );
 		mappings.setDefaultCascade( ( dcNode == null ) ? "none" : dcNode.getValue() );
 
 		Attribute daNode = hmNode.attribute( "default-access" );
 		mappings.setDefaultAccess( ( daNode == null ) ? "property" : daNode.getValue() );
 
 		Attribute dlNode = hmNode.attribute( "default-lazy" );
 		mappings.setDefaultLazy( dlNode == null || dlNode.getValue().equals( "true" ) );
 
 		Attribute aiNode = hmNode.attribute( "auto-import" );
 		mappings.setAutoImport( ( aiNode == null ) || "true".equals( aiNode.getValue() ) );
 
 		Attribute packNode = hmNode.attribute( "package" );
 		if ( packNode != null ) mappings.setDefaultPackage( packNode.getValue() );
 	}
 
 	/**
 	 * Responsible for perfoming the bind operation related to an &lt;class/&gt; mapping element.
 	 *
 	 * @param node The DOM Element for the &lt;class/&gt; element.
 	 * @param rootClass The mapping instance to which to bind the information.
 	 * @param mappings The current bind state.
 	 * @param inheritedMetas Any inherited meta-tag information.
 	 * @throws MappingException
 	 */
 	public static void bindRootClass(Element node, RootClass rootClass, Mappings mappings,
 			java.util.Map inheritedMetas) throws MappingException {
 		bindClass( node, rootClass, mappings, inheritedMetas );
 		inheritedMetas = getMetas( node, inheritedMetas, true ); // get meta's from <class>
 		bindRootPersistentClassCommonValues( node, inheritedMetas, mappings, rootClass );
 	}
 
 	private static void bindRootPersistentClassCommonValues(Element node,
 			java.util.Map inheritedMetas, Mappings mappings, RootClass entity)
 			throws MappingException {
 
 		// DB-OBJECTNAME
 
 		Attribute schemaNode = node.attribute( "schema" );
 		String schema = schemaNode == null ?
 				mappings.getSchemaName() : schemaNode.getValue();
 
 		Attribute catalogNode = node.attribute( "catalog" );
 		String catalog = catalogNode == null ?
 				mappings.getCatalogName() : catalogNode.getValue();
 
 		Table table = mappings.addTable(
 				schema,
 				catalog,
 				getClassTableName( entity, node, schema, catalog, null, mappings ),
 				getSubselect( node ),
 		        entity.isAbstract() != null && entity.isAbstract().booleanValue()
 			);
 		entity.setTable( table );
 		bindComment(table, node);
 
         LOG.mappingClass(entity.getEntityName(), entity.getTable().getName());
 
 		// MUTABLE
 		Attribute mutableNode = node.attribute( "mutable" );
 		entity.setMutable( ( mutableNode == null ) || mutableNode.getValue().equals( "true" ) );
 
 		// WHERE
 		Attribute whereNode = node.attribute( "where" );
 		if ( whereNode != null ) entity.setWhere( whereNode.getValue() );
 
 		// CHECK
 		Attribute chNode = node.attribute( "check" );
 		if ( chNode != null ) table.addCheckConstraint( chNode.getValue() );
 
 		// POLYMORPHISM
 		Attribute polyNode = node.attribute( "polymorphism" );
 		entity.setExplicitPolymorphism( ( polyNode != null )
 			&& polyNode.getValue().equals( "explicit" ) );
 
 		// ROW ID
 		Attribute rowidNode = node.attribute( "rowid" );
 		if ( rowidNode != null ) table.setRowId( rowidNode.getValue() );
 
 		Iterator subnodes = node.elementIterator();
 		while ( subnodes.hasNext() ) {
 
 			Element subnode = (Element) subnodes.next();
 			String name = subnode.getName();
 
 			if ( "id".equals( name ) ) {
 				// ID
 				bindSimpleId( subnode, entity, mappings, inheritedMetas );
 			}
 			else if ( "composite-id".equals( name ) ) {
 				// COMPOSITE-ID
 				bindCompositeId( subnode, entity, mappings, inheritedMetas );
 			}
 			else if ( "version".equals( name ) || "timestamp".equals( name ) ) {
 				// VERSION / TIMESTAMP
 				bindVersioningProperty( table, subnode, mappings, name, entity, inheritedMetas );
 			}
 			else if ( "discriminator".equals( name ) ) {
 				// DISCRIMINATOR
 				bindDiscriminatorProperty( table, entity, subnode, mappings );
 			}
 			else if ( "cache".equals( name ) ) {
 				entity.setCacheConcurrencyStrategy( subnode.attributeValue( "usage" ) );
 				entity.setCacheRegionName( subnode.attributeValue( "region" ) );
 				entity.setLazyPropertiesCacheable( !"non-lazy".equals( subnode.attributeValue( "include" ) ) );
 			}
 
 		}
 
 		// Primary key constraint
 		entity.createPrimaryKey();
 
 		createClassProperties( node, entity, mappings, inheritedMetas );
 	}
 
 	private static void bindSimpleId(Element idNode, RootClass entity, Mappings mappings,
 			java.util.Map inheritedMetas) throws MappingException {
 		String propertyName = idNode.attributeValue( "name" );
 
 		SimpleValue id = new SimpleValue( mappings, entity.getTable() );
 		entity.setIdentifier( id );
 
 		// if ( propertyName == null || entity.getPojoRepresentation() == null ) {
 		// bindSimpleValue( idNode, id, false, RootClass.DEFAULT_IDENTIFIER_COLUMN_NAME, mappings );
 		// if ( !id.isTypeSpecified() ) {
 		// throw new MappingException( "must specify an identifier type: " + entity.getEntityName()
 		// );
 		// }
 		// }
 		// else {
 		// bindSimpleValue( idNode, id, false, propertyName, mappings );
 		// PojoRepresentation pojo = entity.getPojoRepresentation();
 		// id.setTypeUsingReflection( pojo.getClassName(), propertyName );
 		//
 		// Property prop = new Property();
 		// prop.setValue( id );
 		// bindProperty( idNode, prop, mappings, inheritedMetas );
 		// entity.setIdentifierProperty( prop );
 		// }
 
 		if ( propertyName == null ) {
 			bindSimpleValue( idNode, id, false, RootClass.DEFAULT_IDENTIFIER_COLUMN_NAME, mappings );
 		}
 		else {
 			bindSimpleValue( idNode, id, false, propertyName, mappings );
 		}
 
 		if ( propertyName == null || !entity.hasPojoRepresentation() ) {
 			if ( !id.isTypeSpecified() ) {
 				throw new MappingException( "must specify an identifier type: "
 					+ entity.getEntityName() );
 			}
 		}
 		else {
 			id.setTypeUsingReflection( entity.getClassName(), propertyName );
 		}
 
 		if ( propertyName != null ) {
 			Property prop = new Property();
 			prop.setValue( id );
 			bindProperty( idNode, prop, mappings, inheritedMetas );
 			entity.setIdentifierProperty( prop );
 		}
 
 		// TODO:
 		/*
 		 * if ( id.getHibernateType().getReturnedClass().isArray() ) throw new MappingException(
 		 * "illegal use of an array as an identifier (arrays don't reimplement equals)" );
 		 */
 		makeIdentifier( idNode, id, mappings );
 	}
 
 	private static void bindCompositeId(Element idNode, RootClass entity, Mappings mappings,
 			java.util.Map inheritedMetas) throws MappingException {
 		String propertyName = idNode.attributeValue( "name" );
 		Component id = new Component( mappings, entity );
 		entity.setIdentifier( id );
 		bindCompositeId( idNode, id, entity, propertyName, mappings, inheritedMetas );
 		if ( propertyName == null ) {
 			entity.setEmbeddedIdentifier( id.isEmbedded() );
 			if ( id.isEmbedded() ) {
 				// todo : what is the implication of this?
 				id.setDynamic( !entity.hasPojoRepresentation() );
 				/*
 				 * Property prop = new Property(); prop.setName("id");
 				 * prop.setPropertyAccessorName("embedded"); prop.setValue(id);
 				 * entity.setIdentifierProperty(prop);
 				 */
 			}
 		}
 		else {
 			Property prop = new Property();
 			prop.setValue( id );
 			bindProperty( idNode, prop, mappings, inheritedMetas );
 			entity.setIdentifierProperty( prop );
 		}
 
 		makeIdentifier( idNode, id, mappings );
 
 	}
 
 	private static void bindVersioningProperty(Table table, Element subnode, Mappings mappings,
 			String name, RootClass entity, java.util.Map inheritedMetas) {
 
 		String propertyName = subnode.attributeValue( "name" );
 		SimpleValue val = new SimpleValue( mappings, table );
 		bindSimpleValue( subnode, val, false, propertyName, mappings );
 		if ( !val.isTypeSpecified() ) {
 			// this is either a <version/> tag with no type attribute,
 			// or a <timestamp/> tag
 			if ( "version".equals( name ) ) {
 				val.setTypeName( "integer" );
 			}
 			else {
 				if ( "db".equals( subnode.attributeValue( "source" ) ) ) {
 					val.setTypeName( "dbtimestamp" );
 				}
 				else {
 					val.setTypeName( "timestamp" );
 				}
 			}
 		}
 		Property prop = new Property();
 		prop.setValue( val );
 		bindProperty( subnode, prop, mappings, inheritedMetas );
 		// for version properties marked as being generated, make sure they are "always"
 		// generated; aka, "insert" is invalid; this is dis-allowed by the DTD,
 		// but just to make sure...
 		if ( prop.getGeneration() == PropertyGeneration.INSERT ) {
 			throw new MappingException( "'generated' attribute cannot be 'insert' for versioning property" );
 		}
 		makeVersion( subnode, val );
 		entity.setVersion( prop );
 		entity.addProperty( prop );
 	}
 
 	private static void bindDiscriminatorProperty(Table table, RootClass entity, Element subnode,
 			Mappings mappings) {
 		SimpleValue discrim = new SimpleValue( mappings, table );
 		entity.setDiscriminator( discrim );
 		bindSimpleValue(
 				subnode,
 				discrim,
 				false,
 				RootClass.DEFAULT_DISCRIMINATOR_COLUMN_NAME,
 				mappings
 			);
 		if ( !discrim.isTypeSpecified() ) {
 			discrim.setTypeName( "string" );
 			// ( (Column) discrim.getColumnIterator().next() ).setType(type);
 		}
 		entity.setPolymorphic( true );
 		if ( "true".equals( subnode.attributeValue( "force" ) ) )
 			entity.setForceDiscriminator( true );
 		if ( "false".equals( subnode.attributeValue( "insert" ) ) )
 			entity.setDiscriminatorInsertable( false );
 	}
 
 	public static void bindClass(Element node, PersistentClass persistentClass, Mappings mappings,
 			java.util.Map inheritedMetas) throws MappingException {
 		// transfer an explicitly defined entity name
 		// handle the lazy attribute
 		Attribute lazyNode = node.attribute( "lazy" );
 		boolean lazy = lazyNode == null ?
 				mappings.isDefaultLazy() :
 				"true".equals( lazyNode.getValue() );
 		// go ahead and set the lazy here, since pojo.proxy can override it.
 		persistentClass.setLazy( lazy );
 
 		String entityName = node.attributeValue( "entity-name" );
 		if ( entityName == null ) entityName = getClassName( node.attribute("name"), mappings );
 		if ( entityName==null ) {
 			throw new MappingException( "Unable to determine entity name" );
 		}
 		persistentClass.setEntityName( entityName );
 
 		bindPojoRepresentation( node, persistentClass, mappings, inheritedMetas );
 		bindDom4jRepresentation( node, persistentClass, mappings, inheritedMetas );
 		bindMapRepresentation( node, persistentClass, mappings, inheritedMetas );
 
 		Iterator itr = node.elementIterator( "fetch-profile" );
 		while ( itr.hasNext() ) {
 			final Element profileElement = ( Element ) itr.next();
 			parseFetchProfile( profileElement, mappings, entityName );
 		}
 
 		bindPersistentClassCommonValues( node, persistentClass, mappings, inheritedMetas );
 	}
 
 	private static void bindPojoRepresentation(Element node, PersistentClass entity,
 			Mappings mappings, java.util.Map metaTags) {
 
 		String className = getClassName( node.attribute( "name" ), mappings );
 		String proxyName = getClassName( node.attribute( "proxy" ), mappings );
 
 		entity.setClassName( className );
 
 		if ( proxyName != null ) {
 			entity.setProxyInterfaceName( proxyName );
 			entity.setLazy( true );
 		}
 		else if ( entity.isLazy() ) {
 			entity.setProxyInterfaceName( className );
 		}
 
 		Element tuplizer = locateTuplizerDefinition( node, EntityMode.POJO );
 		if ( tuplizer != null ) {
 			entity.addTuplizer( EntityMode.POJO, tuplizer.attributeValue( "class" ) );
 		}
 	}
 
 	private static void bindDom4jRepresentation(Element node, PersistentClass entity,
 			Mappings mappings, java.util.Map inheritedMetas) {
 		String nodeName = node.attributeValue( "node" );
 		if (nodeName==null) nodeName = StringHelper.unqualify( entity.getEntityName() );
 		entity.setNodeName(nodeName);
 
 		Element tuplizer = locateTuplizerDefinition( node, EntityMode.DOM4J );
 		if ( tuplizer != null ) {
 			entity.addTuplizer( EntityMode.DOM4J, tuplizer.attributeValue( "class" ) );
 		}
 	}
 
 	private static void bindMapRepresentation(Element node, PersistentClass entity,
 			Mappings mappings, java.util.Map inheritedMetas) {
 		Element tuplizer = locateTuplizerDefinition( node, EntityMode.MAP );
 		if ( tuplizer != null ) {
 			entity.addTuplizer( EntityMode.MAP, tuplizer.attributeValue( "class" ) );
 		}
 	}
 
 	/**
 	 * Locate any explicit tuplizer definition in the metadata, for the given entity-mode.
 	 *
 	 * @param container The containing element (representing the entity/component)
 	 * @param entityMode The entity-mode for which to locate the tuplizer element
 	 * @return The tuplizer element, or null.
 	 */
 	private static Element locateTuplizerDefinition(Element container, EntityMode entityMode) {
 		Iterator itr = container.elements( "tuplizer" ).iterator();
 		while( itr.hasNext() ) {
 			final Element tuplizerElem = ( Element ) itr.next();
 			if ( entityMode.toString().equals( tuplizerElem.attributeValue( "entity-mode") ) ) {
 				return tuplizerElem;
 			}
 		}
 		return null;
 	}
 
 	private static void bindPersistentClassCommonValues(Element node, PersistentClass entity,
 			Mappings mappings, java.util.Map inheritedMetas) throws MappingException {
 		// DISCRIMINATOR
 		Attribute discriminatorNode = node.attribute( "discriminator-value" );
 		entity.setDiscriminatorValue( ( discriminatorNode == null )
 			? entity.getEntityName()
 			: discriminatorNode.getValue() );
 
 		// DYNAMIC UPDATE
 		Attribute dynamicNode = node.attribute( "dynamic-update" );
 		entity.setDynamicUpdate(
 				dynamicNode != null && "true".equals( dynamicNode.getValue() )
 		);
 
 		// DYNAMIC INSERT
 		Attribute insertNode = node.attribute( "dynamic-insert" );
 		entity.setDynamicInsert(
 				insertNode != null && "true".equals( insertNode.getValue() )
 		);
 
 		// IMPORT
 		mappings.addImport( entity.getEntityName(), entity.getEntityName() );
 		if ( mappings.isAutoImport() && entity.getEntityName().indexOf( '.' ) > 0 ) {
 			mappings.addImport(
 					entity.getEntityName(),
 					StringHelper.unqualify( entity.getEntityName() )
 				);
 		}
 
 		// BATCH SIZE
 		Attribute batchNode = node.attribute( "batch-size" );
 		if ( batchNode != null ) entity.setBatchSize( Integer.parseInt( batchNode.getValue() ) );
 
 		// SELECT BEFORE UPDATE
 		Attribute sbuNode = node.attribute( "select-before-update" );
 		if ( sbuNode != null ) entity.setSelectBeforeUpdate( "true".equals( sbuNode.getValue() ) );
 
 		// OPTIMISTIC LOCK MODE
 		Attribute olNode = node.attribute( "optimistic-lock" );
 		entity.setOptimisticLockMode( getOptimisticLockMode( olNode ) );
 
 		entity.setMetaAttributes( getMetas( node, inheritedMetas ) );
 
 		// PERSISTER
 		Attribute persisterNode = node.attribute( "persister" );
 		if ( persisterNode != null ) {
 			try {
 				entity.setEntityPersisterClass( ReflectHelper.classForName(
 						persisterNode
 								.getValue()
 				) );
 			}
 			catch (ClassNotFoundException cnfe) {
 				throw new MappingException( "Could not find persister class: "
 					+ persisterNode.getValue() );
 			}
 		}
 
 		// CUSTOM SQL
 		handleCustomSQL( node, entity );
 
 		Iterator tables = node.elementIterator( "synchronize" );
 		while ( tables.hasNext() ) {
 			entity.addSynchronizedTable( ( (Element) tables.next() ).attributeValue( "table" ) );
 		}
 
 		Attribute abstractNode = node.attribute( "abstract" );
 		Boolean isAbstract = abstractNode == null
 				? null
 		        : "true".equals( abstractNode.getValue() )
 						? Boolean.TRUE
 	                    : "false".equals( abstractNode.getValue() )
 								? Boolean.FALSE
 	                            : null;
 		entity.setAbstract( isAbstract );
 	}
 
 	private static void handleCustomSQL(Element node, PersistentClass model)
 			throws MappingException {
 		Element element = node.element( "sql-insert" );
 		if ( element != null ) {
 			boolean callable = isCallable( element );
 			model.setCustomSQLInsert( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 
 		element = node.element( "sql-delete" );
 		if ( element != null ) {
 			boolean callable = isCallable( element );
 			model.setCustomSQLDelete( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 
 		element = node.element( "sql-update" );
 		if ( element != null ) {
 			boolean callable = isCallable( element );
 			model.setCustomSQLUpdate( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 
 		element = node.element( "loader" );
 		if ( element != null ) {
 			model.setLoaderName( element.attributeValue( "query-ref" ) );
 		}
 	}
 
 	private static void handleCustomSQL(Element node, Join model) throws MappingException {
 		Element element = node.element( "sql-insert" );
 		if ( element != null ) {
 			boolean callable = isCallable( element );
 			model.setCustomSQLInsert( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 
 		element = node.element( "sql-delete" );
 		if ( element != null ) {
 			boolean callable = isCallable( element );
 			model.setCustomSQLDelete( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 
 		element = node.element( "sql-update" );
 		if ( element != null ) {
 			boolean callable = isCallable( element );
 			model.setCustomSQLUpdate( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 	}
 
 	private static void handleCustomSQL(Element node, Collection model) throws MappingException {
 		Element element = node.element( "sql-insert" );
 		if ( element != null ) {
 			boolean callable = isCallable( element, true );
 			model.setCustomSQLInsert( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 
 		element = node.element( "sql-delete" );
 		if ( element != null ) {
 			boolean callable = isCallable( element, true );
 			model.setCustomSQLDelete( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 
 		element = node.element( "sql-update" );
 		if ( element != null ) {
 			boolean callable = isCallable( element, true );
 			model.setCustomSQLUpdate( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 
 		element = node.element( "sql-delete-all" );
 		if ( element != null ) {
 			boolean callable = isCallable( element, true );
 			model.setCustomSQLDeleteAll( element.getTextTrim(), callable, getResultCheckStyle( element, callable ) );
 		}
 	}
 
 	private static boolean isCallable(Element e) throws MappingException {
 		return isCallable( e, true );
 	}
 
 	private static boolean isCallable(Element element, boolean supportsCallable)
 			throws MappingException {
 		Attribute attrib = element.attribute( "callable" );
 		if ( attrib != null && "true".equals( attrib.getValue() ) ) {
 			if ( !supportsCallable ) {
 				throw new MappingException( "callable attribute not supported yet!" );
 			}
 			return true;
 		}
 		return false;
 	}
 
 	private static ExecuteUpdateResultCheckStyle getResultCheckStyle(Element element, boolean callable) throws MappingException {
 		Attribute attr = element.attribute( "check" );
 		if ( attr == null ) {
 			// use COUNT as the default.  This mimics the old behavior, although
 			// NONE might be a better option moving forward in the case of callable
 			return ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		return ExecuteUpdateResultCheckStyle.parse( attr.getValue() );
 	}
 
 	public static void bindUnionSubclass(Element node, UnionSubclass unionSubclass,
 			Mappings mappings, java.util.Map inheritedMetas) throws MappingException {
 
 		bindClass( node, unionSubclass, mappings, inheritedMetas );
 		inheritedMetas = getMetas( node, inheritedMetas, true ); // get meta's from <subclass>
 
 		if ( unionSubclass.getEntityPersisterClass() == null ) {
 			unionSubclass.getRootClass().setEntityPersisterClass(
 				UnionSubclassEntityPersister.class );
 		}
 
 		Attribute schemaNode = node.attribute( "schema" );
 		String schema = schemaNode == null ?
 				mappings.getSchemaName() : schemaNode.getValue();
 
 		Attribute catalogNode = node.attribute( "catalog" );
 		String catalog = catalogNode == null ?
 				mappings.getCatalogName() : catalogNode.getValue();
 
 		Table denormalizedSuperTable = unionSubclass.getSuperclass().getTable();
 		Table mytable = mappings.addDenormalizedTable(
 				schema,
 				catalog,
 				getClassTableName(unionSubclass, node, schema, catalog, denormalizedSuperTable, mappings ),
 		        unionSubclass.isAbstract() != null && unionSubclass.isAbstract().booleanValue(),
 				getSubselect( node ),
 				denormalizedSuperTable
 			);
 		unionSubclass.setTable( mytable );
 
         LOG.mappingUnionSubclass(unionSubclass.getEntityName(), unionSubclass.getTable().getName());
 
 		createClassProperties( node, unionSubclass, mappings, inheritedMetas );
 
 	}
 
 	public static void bindSubclass(Element node, Subclass subclass, Mappings mappings,
 			java.util.Map inheritedMetas) throws MappingException {
 
 		bindClass( node, subclass, mappings, inheritedMetas );
 		inheritedMetas = getMetas( node, inheritedMetas, true ); // get meta's from <subclass>
 
 		if ( subclass.getEntityPersisterClass() == null ) {
 			subclass.getRootClass()
 					.setEntityPersisterClass( SingleTableEntityPersister.class );
 		}
 
         LOG.mappingSubclass(subclass.getEntityName(), subclass.getTable().getName());
 
 		// properties
 		createClassProperties( node, subclass, mappings, inheritedMetas );
 	}
 
 	private static String getClassTableName(
 			PersistentClass model, Element node, String schema, String catalog, Table denormalizedSuperTable,
 			Mappings mappings
 	) {
 		Attribute tableNameNode = node.attribute( "table" );
 		String logicalTableName;
 		String physicalTableName;
 		if ( tableNameNode == null ) {
 			logicalTableName = StringHelper.unqualify( model.getEntityName() );
 			physicalTableName = mappings.getNamingStrategy().classToTableName( model.getEntityName() );
 		}
 		else {
 			logicalTableName = tableNameNode.getValue();
 			physicalTableName = mappings.getNamingStrategy().tableName( logicalTableName );
 		}
 		mappings.addTableBinding( schema, catalog, logicalTableName, physicalTableName, denormalizedSuperTable );
 		return physicalTableName;
 	}
 
 	public static void bindJoinedSubclass(Element node, JoinedSubclass joinedSubclass,
 			Mappings mappings, java.util.Map inheritedMetas) throws MappingException {
 
 		bindClass( node, joinedSubclass, mappings, inheritedMetas );
 		inheritedMetas = getMetas( node, inheritedMetas, true ); // get meta's from
 																	// <joined-subclass>
 
 		// joined subclasses
 		if ( joinedSubclass.getEntityPersisterClass() == null ) {
 			joinedSubclass.getRootClass()
 				.setEntityPersisterClass( JoinedSubclassEntityPersister.class );
 		}
 
 		Attribute schemaNode = node.attribute( "schema" );
 		String schema = schemaNode == null ?
 				mappings.getSchemaName() : schemaNode.getValue();
 
 		Attribute catalogNode = node.attribute( "catalog" );
 		String catalog = catalogNode == null ?
 				mappings.getCatalogName() : catalogNode.getValue();
 
 		Table mytable = mappings.addTable(
 				schema,
 				catalog,
 				getClassTableName( joinedSubclass, node, schema, catalog, null, mappings ),
 				getSubselect( node ),
 				false
 			);
 		joinedSubclass.setTable( mytable );
 		bindComment(mytable, node);
 
         LOG.mappingJoinedSubclass(joinedSubclass.getEntityName(), joinedSubclass.getTable().getName());
 
 		// KEY
 		Element keyNode = node.element( "key" );
 		SimpleValue key = new DependantValue( mappings, mytable, joinedSubclass.getIdentifier() );
 		joinedSubclass.setKey( key );
 		key.setCascadeDeleteEnabled( "cascade".equals( keyNode.attributeValue( "on-delete" ) ) );
 		bindSimpleValue( keyNode, key, false, joinedSubclass.getEntityName(), mappings );
 
 		// model.getKey().setType( new Type( model.getIdentifier() ) );
 		joinedSubclass.createPrimaryKey();
 		joinedSubclass.createForeignKey();
 
 		// CHECK
 		Attribute chNode = node.attribute( "check" );
 		if ( chNode != null ) mytable.addCheckConstraint( chNode.getValue() );
 
 		// properties
 		createClassProperties( node, joinedSubclass, mappings, inheritedMetas );
 
 	}
 
 	private static void bindJoin(Element node, Join join, Mappings mappings,
 			java.util.Map inheritedMetas) throws MappingException {
 
 		PersistentClass persistentClass = join.getPersistentClass();
 		String path = persistentClass.getEntityName();
 
 		// TABLENAME
 
 		Attribute schemaNode = node.attribute( "schema" );
 		String schema = schemaNode == null ?
 				mappings.getSchemaName() : schemaNode.getValue();
 		Attribute catalogNode = node.attribute( "catalog" );
 		String catalog = catalogNode == null ?
 				mappings.getCatalogName() : catalogNode.getValue();
 		Table primaryTable = persistentClass.getTable();
 		Table table = mappings.addTable(
 				schema,
 				catalog,
 				getClassTableName( persistentClass, node, schema, catalog, primaryTable, mappings ),
 				getSubselect( node ),
 				false
 			);
 		join.setTable( table );
 		bindComment(table, node);
 
 		Attribute fetchNode = node.attribute( "fetch" );
 		if ( fetchNode != null ) {
 			join.setSequentialSelect( "select".equals( fetchNode.getValue() ) );
 		}
 
 		Attribute invNode = node.attribute( "inverse" );
 		if ( invNode != null ) {
 			join.setInverse( "true".equals( invNode.getValue() ) );
 		}
 
 		Attribute nullNode = node.attribute( "optional" );
 		if ( nullNode != null ) {
 			join.setOptional( "true".equals( nullNode.getValue() ) );
 		}
 
 
         LOG.mappingClassJoin(persistentClass.getEntityName(), join.getTable().getName());
 
 		// KEY
 		Element keyNode = node.element( "key" );
 		SimpleValue key = new DependantValue( mappings, table, persistentClass.getIdentifier() );
 		join.setKey( key );
 		key.setCascadeDeleteEnabled( "cascade".equals( keyNode.attributeValue( "on-delete" ) ) );
 		bindSimpleValue( keyNode, key, false, persistentClass.getEntityName(), mappings );
 
 		// join.getKey().setType( new Type( lazz.getIdentifier() ) );
 		join.createPrimaryKey();
 		join.createForeignKey();
 
 		// PROPERTIES
 		Iterator iter = node.elementIterator();
 		while ( iter.hasNext() ) {
 			Element subnode = (Element) iter.next();
 			String name = subnode.getName();
 			String propertyName = subnode.attributeValue( "name" );
 
 			Value value = null;
 			if ( "many-to-one".equals( name ) ) {
 				value = new ManyToOne( mappings, table );
 				bindManyToOne( subnode, (ManyToOne) value, propertyName, true, mappings );
 			}
 			else if ( "any".equals( name ) ) {
 				value = new Any( mappings, table );
 				bindAny( subnode, (Any) value, true, mappings );
 			}
 			else if ( "property".equals( name ) ) {
 				value = new SimpleValue( mappings, table );
 				bindSimpleValue( subnode, (SimpleValue) value, true, propertyName, mappings );
 			}
 			else if ( "component".equals( name ) || "dynamic-component".equals( name ) ) {
 				String subpath = StringHelper.qualify( path, propertyName );
 				value = new Component( mappings, join );
 				bindComponent(
 						subnode,
 						(Component) value,
 						join.getPersistentClass().getClassName(),
 						propertyName,
 						subpath,
 						true,
 						false,
 						mappings,
 						inheritedMetas,
 						false
 					);
 			}
 
 			if ( value != null ) {
 				Property prop = createProperty( value, propertyName, persistentClass
 					.getEntityName(), subnode, mappings, inheritedMetas );
 				prop.setOptional( join.isOptional() );
 				join.addProperty( prop );
 			}
 
 		}
 
 		// CUSTOM SQL
 		handleCustomSQL( node, join );
 
 	}
 
 	public static void bindColumns(final Element node, final SimpleValue simpleValue,
 			final boolean isNullable, final boolean autoColumn, final String propertyPath,
 			final Mappings mappings) throws MappingException {
 
 		Table table = simpleValue.getTable();
 
 		// COLUMN(S)
 		Attribute columnAttribute = node.attribute( "column" );
 		if ( columnAttribute == null ) {
 			Iterator itr = node.elementIterator();
 			int count = 0;
 			while ( itr.hasNext() ) {
 				Element columnElement = (Element) itr.next();
 				if ( columnElement.getName().equals( "column" ) ) {
 					Column column = new Column();
 					column.setValue( simpleValue );
 					column.setTypeIndex( count++ );
 					bindColumn( columnElement, column, isNullable );
 					final String columnName = columnElement.attributeValue( "name" );
 					String logicalColumnName = mappings.getNamingStrategy().logicalColumnName(
 							columnName, propertyPath
 					);
 					column.setName( mappings.getNamingStrategy().columnName(
 						columnName ) );
 					if ( table != null ) {
 						table.addColumn( column ); // table=null -> an association
 						                           // - fill it in later
 						//TODO fill in the mappings for table == null
 						mappings.addColumnBinding( logicalColumnName, column, table );
 					}
 
 
 					simpleValue.addColumn( column );
 					// column index
 					bindIndex( columnElement.attribute( "index" ), table, column, mappings );
 					bindIndex( node.attribute( "index" ), table, column, mappings );
 					//column unique-key
 					bindUniqueKey( columnElement.attribute( "unique-key" ), table, column, mappings );
 					bindUniqueKey( node.attribute( "unique-key" ), table, column, mappings );
 				}
 				else if ( columnElement.getName().equals( "formula" ) ) {
 					Formula formula = new Formula();
 					formula.setFormula( columnElement.getText() );
 					simpleValue.addFormula( formula );
 				}
 			}
 
 			// todo : another GoodThing would be to go back after all parsing and see if all the columns
 			// (and no formulas) are contained in a defined unique key that only contains these columns.
 			// That too would mark this as a logical one-to-one
 			final Attribute uniqueAttribute = node.attribute( "unique" );
 			if ( uniqueAttribute != null
 					&& "true".equals( uniqueAttribute.getValue() )
 					&& ManyToOne.class.isInstance( simpleValue ) ) {
 				( (ManyToOne) simpleValue ).markAsLogicalOneToOne();
 			}
 		}
 		else {
 			if ( node.elementIterator( "column" ).hasNext() ) {
 				throw new MappingException(
 					"column attribute may not be used together with <column> subelement" );
 			}
 			if ( node.elementIterator( "formula" ).hasNext() ) {
 				throw new MappingException(
 					"column attribute may not be used together with <formula> subelement" );
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/NamedSQLQuerySecondPass.java b/hibernate-core/src/main/java/org/hibernate/cfg/NamedSQLQuerySecondPass.java
index c0e0d2cccd..b3fc4f5252 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/NamedSQLQuerySecondPass.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/NamedSQLQuerySecondPass.java
@@ -1,123 +1,125 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.Map;
 import org.dom4j.Attribute;
 import org.dom4j.Element;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.internal.util.StringHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 public class NamedSQLQuerySecondPass extends ResultSetMappingBinder implements QuerySecondPass {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        NamedSQLQuerySecondPass.class.getName());
 
 	private Element queryElem;
 	private String path;
 	private Mappings mappings;
 
 	public NamedSQLQuerySecondPass(Element queryElem, String path, Mappings mappings) {
 		this.queryElem = queryElem;
 		this.path = path;
 		this.mappings = mappings;
 	}
 
 	public void doSecondPass(Map persistentClasses) throws MappingException {
 		String queryName = queryElem.attribute( "name" ).getValue();
 		if (path!=null) queryName = path + '.' + queryName;
 
 		boolean cacheable = "true".equals( queryElem.attributeValue( "cacheable" ) );
 		String region = queryElem.attributeValue( "cache-region" );
 		Attribute tAtt = queryElem.attribute( "timeout" );
 		Integer timeout = tAtt == null ? null : new Integer( tAtt.getValue() );
 		Attribute fsAtt = queryElem.attribute( "fetch-size" );
 		Integer fetchSize = fsAtt == null ? null : new Integer( fsAtt.getValue() );
 		Attribute roAttr = queryElem.attribute( "read-only" );
 		boolean readOnly = roAttr != null && "true".equals( roAttr.getValue() );
 		Attribute cacheModeAtt = queryElem.attribute( "cache-mode" );
 		String cacheMode = cacheModeAtt == null ? null : cacheModeAtt.getValue();
 		Attribute cmAtt = queryElem.attribute( "comment" );
 		String comment = cmAtt == null ? null : cmAtt.getValue();
 
 		java.util.List<String> synchronizedTables = new ArrayList<String>();
 		Iterator tables = queryElem.elementIterator( "synchronize" );
 		while ( tables.hasNext() ) {
 			synchronizedTables.add( ( (Element) tables.next() ).attributeValue( "table" ) );
 		}
 		boolean callable = "true".equals( queryElem.attributeValue( "callable" ) );
 
 		NamedSQLQueryDefinition namedQuery;
 		Attribute ref = queryElem.attribute( "resultset-ref" );
 		String resultSetRef = ref == null ? null : ref.getValue();
 		if ( StringHelper.isNotEmpty( resultSetRef ) ) {
 			namedQuery = new NamedSQLQueryDefinition(
 					queryElem.getText(),
 					resultSetRef,
 					synchronizedTables,
 					cacheable,
 					region,
 					timeout,
 					fetchSize,
 					HbmBinder.getFlushMode( queryElem.attributeValue( "flush-mode" ) ),
 					HbmBinder.getCacheMode( cacheMode ),
 					readOnly,
 					comment,
 					HbmBinder.getParameterTypes( queryElem ),
 					callable
 			);
 			//TODO check there is no actual definition elemnents when a ref is defined
 		}
 		else {
 			ResultSetMappingDefinition definition = buildResultSetMappingDefinition( queryElem, path, mappings );
 			namedQuery = new NamedSQLQueryDefinition(
 					queryElem.getText(),
 					definition.getQueryReturns(),
 					synchronizedTables,
 					cacheable,
 					region,
 					timeout,
 					fetchSize,
 					HbmBinder.getFlushMode( queryElem.attributeValue( "flush-mode" ) ),
 					HbmBinder.getCacheMode( cacheMode ),
 					readOnly,
 					comment,
 					HbmBinder.getParameterTypes( queryElem ),
 					callable
 			);
 		}
 
         LOG.debugf("Named SQL query: %s -> %s", queryName, namedQuery.getQueryString());
 		mappings.addSQLQuery( queryName, namedQuery );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/PropertyContainer.java b/hibernate-core/src/main/java/org/hibernate/cfg/PropertyContainer.java
index 99c6b2f3cc..b0d652f2b8 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/PropertyContainer.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/PropertyContainer.java
@@ -1,279 +1,280 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 
 // $Id$
 
 package org.hibernate.cfg;
 
 import java.util.Collection;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 import java.util.TreeMap;
 import javax.persistence.Access;
 import javax.persistence.ManyToMany;
 import javax.persistence.ManyToOne;
 import javax.persistence.OneToMany;
 import javax.persistence.OneToOne;
 import javax.persistence.Transient;
 import org.hibernate.AnnotationException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.ManyToAny;
 import org.hibernate.annotations.Target;
 import org.hibernate.annotations.Type;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.internal.util.StringHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * A helper class to keep the {@code XProperty}s of a class ordered by access type.
  *
  * @author Hardy Ferentschik
  */
 class PropertyContainer {
 
     static {
         System.setProperty("jboss.i18n.generate-proxies", "true");
     }
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, PropertyContainer.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, PropertyContainer.class.getName());
 
 	private final AccessType explicitClassDefinedAccessType;
 
 	/**
 	 * Constains the properties which must be returned in case the class is accessed via {@code AccessType.FIELD}. Note,
 	 * this does not mean that all {@code XProperty}s in this map are fields. Due to JPA access rules single properties
 	 * can have different access type than the overall class access type.
 	 */
 	private final TreeMap<String, XProperty> fieldAccessMap;
 
 	/**
 	 * Constains the properties which must be returned in case the class is accessed via {@code AccessType.Property}. Note,
 	 * this does not mean that all {@code XProperty}s in this map are properties/methods. Due to JPA access rules single properties
 	 * can have different access type than the overall class access type.
 	 */
 	private final TreeMap<String, XProperty> propertyAccessMap;
 
 	/**
 	 * The class for which this container is created.
 	 */
 	private final XClass xClass;
 	private final XClass entityAtStake;
 
 	PropertyContainer(XClass clazz, XClass entityAtStake) {
 		this.xClass = clazz;
 		this.entityAtStake = entityAtStake;
 
 		explicitClassDefinedAccessType = determineClassDefinedAccessStrategy();
 
 		// first add all properties to field and property map
 		fieldAccessMap = initProperties( AccessType.FIELD );
 		propertyAccessMap = initProperties( AccessType.PROPERTY );
 
 		considerExplicitFieldAndPropertyAccess();
 	}
 
 	public XClass getEntityAtStake() {
 		return entityAtStake;
 	}
 
 	public XClass getDeclaringClass() {
 		return xClass;
 	}
 
 	public AccessType getExplicitAccessStrategy() {
 		return explicitClassDefinedAccessType;
 	}
 
 	public boolean hasExplicitAccessStrategy() {
 		return !explicitClassDefinedAccessType.equals( AccessType.DEFAULT );
 	}
 
 	public Collection<XProperty> getProperties(AccessType accessType) {
 		assertTypesAreResolvable( accessType );
 		if ( AccessType.DEFAULT == accessType || AccessType.PROPERTY == accessType ) {
 			return Collections.unmodifiableCollection( propertyAccessMap.values() );
 		}
 		else {
 			return Collections.unmodifiableCollection( fieldAccessMap.values() );
 		}
 	}
 
 	private void assertTypesAreResolvable(AccessType access) {
 		Map<String, XProperty> xprops;
 		if ( AccessType.PROPERTY.equals( access ) || AccessType.DEFAULT.equals( access ) ) {
 			xprops = propertyAccessMap;
 		}
 		else {
 			xprops = fieldAccessMap;
 		}
 		for ( XProperty property : xprops.values() ) {
 			if ( !property.isTypeResolved() && !discoverTypeWithoutReflection( property ) ) {
 				String msg = "Property " + StringHelper.qualify( xClass.getName(), property.getName() ) +
 						" has an unbound type and no explicit target entity. Resolve this Generic usage issue" +
 						" or set an explicit target attribute (eg @OneToMany(target=) or use an explicit @Type";
 				throw new AnnotationException( msg );
 			}
 		}
 	}
 
 	private void considerExplicitFieldAndPropertyAccess() {
 		for ( XProperty property : fieldAccessMap.values() ) {
 			Access access = property.getAnnotation( Access.class );
 			if ( access == null ) {
 				continue;
 			}
 
 			// see "2.3.2 Explicit Access Type" of JPA 2 spec
 			// the access type for this property is explicitly set to AccessType.FIELD, hence we have to
 			// use field access for this property even if the default access type for the class is AccessType.PROPERTY
 			AccessType accessType = AccessType.getAccessStrategy( access.value() );
             if (accessType == AccessType.FIELD) propertyAccessMap.put(property.getName(), property);
             else LOG.annotationHasNoEffect(AccessType.FIELD);
 		}
 
 		for ( XProperty property : propertyAccessMap.values() ) {
 			Access access = property.getAnnotation( Access.class );
 			if ( access == null ) {
 				continue;
 			}
 
 			AccessType accessType = AccessType.getAccessStrategy( access.value() );
 
 			// see "2.3.2 Explicit Access Type" of JPA 2 spec
 			// the access type for this property is explicitly set to AccessType.PROPERTY, hence we have to
 			// return use method access even if the default class access type is AccessType.FIELD
             if (accessType == AccessType.PROPERTY) fieldAccessMap.put(property.getName(), property);
             else LOG.annotationHasNoEffect(AccessType.PROPERTY);
 		}
 	}
 
 	/**
 	 * Retrieves all properties from the {@code xClass} with the specified access type. This method does not take
 	 * any jpa access rules/annotations into account yet.
 	 *
 	 * @param access The access type - {@code AccessType.FIELD}  or {@code AccessType.Property}
 	 *
 	 * @return A maps of the properties with the given access type keyed against their property name
 	 */
 	private TreeMap<String, XProperty> initProperties(AccessType access) {
 		if ( !( AccessType.PROPERTY.equals( access ) || AccessType.FIELD.equals( access ) ) ) {
 			throw new IllegalArgumentException( "Acces type has to be AccessType.FIELD or AccessType.Property" );
 		}
 
 		//order so that property are used in the same order when binding native query
 		TreeMap<String, XProperty> propertiesMap = new TreeMap<String, XProperty>();
 		List<XProperty> properties = xClass.getDeclaredProperties( access.getType() );
 		for ( XProperty property : properties ) {
 			if ( mustBeSkipped( property ) ) {
 				continue;
 			}
 			propertiesMap.put( property.getName(), property );
 		}
 		return propertiesMap;
 	}
 
 	private AccessType determineClassDefinedAccessStrategy() {
 		AccessType classDefinedAccessType;
 
 		AccessType hibernateDefinedAccessType = AccessType.DEFAULT;
 		AccessType jpaDefinedAccessType = AccessType.DEFAULT;
 
 		org.hibernate.annotations.AccessType accessType = xClass.getAnnotation( org.hibernate.annotations.AccessType.class );
 		if ( accessType != null ) {
 			hibernateDefinedAccessType = AccessType.getAccessStrategy( accessType.value() );
 		}
 
 		Access access = xClass.getAnnotation( Access.class );
 		if ( access != null ) {
 			jpaDefinedAccessType = AccessType.getAccessStrategy( access.value() );
 		}
 
 		if ( hibernateDefinedAccessType != AccessType.DEFAULT
 				&& jpaDefinedAccessType != AccessType.DEFAULT
 				&& hibernateDefinedAccessType != jpaDefinedAccessType ) {
 			throw new MappingException(
 					"@AccessType and @Access specified with contradicting values. Use of @Access only is recommended. "
 			);
 		}
 
 		if ( hibernateDefinedAccessType != AccessType.DEFAULT ) {
 			classDefinedAccessType = hibernateDefinedAccessType;
 		}
 		else {
 			classDefinedAccessType = jpaDefinedAccessType;
 		}
 		return classDefinedAccessType;
 	}
 
 	private static boolean discoverTypeWithoutReflection(XProperty p) {
 		if ( p.isAnnotationPresent( OneToOne.class ) && !p.getAnnotation( OneToOne.class )
 				.targetEntity()
 				.equals( void.class ) ) {
 			return true;
 		}
 		else if ( p.isAnnotationPresent( OneToMany.class ) && !p.getAnnotation( OneToMany.class )
 				.targetEntity()
 				.equals( void.class ) ) {
 			return true;
 		}
 		else if ( p.isAnnotationPresent( ManyToOne.class ) && !p.getAnnotation( ManyToOne.class )
 				.targetEntity()
 				.equals( void.class ) ) {
 			return true;
 		}
 		else if ( p.isAnnotationPresent( ManyToMany.class ) && !p.getAnnotation( ManyToMany.class )
 				.targetEntity()
 				.equals( void.class ) ) {
 			return true;
 		}
 		else if ( p.isAnnotationPresent( org.hibernate.annotations.Any.class ) ) {
 			return true;
 		}
 		else if ( p.isAnnotationPresent( ManyToAny.class ) ) {
 			if ( !p.isCollection() && !p.isArray() ) {
 				throw new AnnotationException( "@ManyToAny used on a non collection non array property: " + p.getName() );
 			}
 			return true;
 		}
 		else if ( p.isAnnotationPresent( Type.class ) ) {
 			return true;
 		}
 		else if ( p.isAnnotationPresent( Target.class ) ) {
 			return true;
 		}
 		return false;
 	}
 
 	private static boolean mustBeSkipped(XProperty property) {
 		//TODO make those hardcoded tests more portable (through the bytecode provider?)
 		return property.isAnnotationPresent( Transient.class )
 				|| "net.sf.cglib.transform.impl.InterceptFieldCallback".equals( property.getType().getName() )
 				|| "org.hibernate.bytecode.internal.javassist.FieldHandler".equals( property.getType().getName() );
 	}
 }
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java b/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
index efcfec4ccf..5a475ccc43 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
@@ -1,329 +1,330 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.Serializable;
 import java.util.Map;
 import java.util.Properties;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.cache.QueryCacheFactory;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.impl.NoCachingRegionFactory;
 import org.hibernate.cache.impl.bridge.RegionFactoryCacheProviderBridge;
 import org.hibernate.engine.jdbc.spi.ExtractedDatabaseMetaData;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.hql.QueryTranslatorFactory;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.hibernate.service.ServiceRegistry;
+
 import org.jboss.logging.Logger;
 
 /**
  * Reads configuration properties and builds a {@link Settings} instance.
  *
  * @author Gavin King
  */
 public class SettingsFactory implements Serializable {
 
     private static final long serialVersionUID = -1194386144994524825L;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SettingsFactory.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SettingsFactory.class.getName());
 
 	public static final String DEF_CACHE_REG_FACTORY = NoCachingRegionFactory.class.getName();
 
 	protected SettingsFactory() {
 	}
 
 	public Settings buildSettings(Properties props, ServiceRegistry serviceRegistry) {
 		final JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 		Settings settings = new Settings();
 
 		//SessionFactory name:
 
 		String sessionFactoryName = props.getProperty(Environment.SESSION_FACTORY_NAME);
 		settings.setSessionFactoryName(sessionFactoryName);
 
 		//JDBC and connection settings:
 
 		//Interrogate JDBC metadata
 		ExtractedDatabaseMetaData meta = jdbcServices.getExtractedMetaDataSupport();
 
 		settings.setDataDefinitionImplicitCommit( meta.doesDataDefinitionCauseTransactionCommit() );
 		settings.setDataDefinitionInTransactionSupported( meta.supportsDataDefinitionInTransaction() );
 
 		//use dialect default properties
 		final Properties properties = new Properties();
 		properties.putAll( jdbcServices.getDialect().getDefaultProperties() );
 		properties.putAll( props );
 
 		// Transaction settings:
 		settings.setJtaPlatform( serviceRegistry.getService( JtaPlatform.class ) );
 
 		boolean flushBeforeCompletion = ConfigurationHelper.getBoolean(Environment.FLUSH_BEFORE_COMPLETION, properties);
         LOG.autoFlush(enabledDisabled(flushBeforeCompletion));
 		settings.setFlushBeforeCompletionEnabled(flushBeforeCompletion);
 
 		boolean autoCloseSession = ConfigurationHelper.getBoolean(Environment.AUTO_CLOSE_SESSION, properties);
         LOG.autoSessionClose(enabledDisabled(autoCloseSession));
 		settings.setAutoCloseSessionEnabled(autoCloseSession);
 
 		//JDBC and connection settings:
 
 		int batchSize = ConfigurationHelper.getInt(Environment.STATEMENT_BATCH_SIZE, properties, 0);
 		if ( !meta.supportsBatchUpdates() ) batchSize = 0;
 		if (batchSize>0) LOG.jdbcBatchSize(batchSize);
 		settings.setJdbcBatchSize(batchSize);
 		boolean jdbcBatchVersionedData = ConfigurationHelper.getBoolean(Environment.BATCH_VERSIONED_DATA, properties, false);
         if (batchSize > 0) LOG.jdbcBatchUpdates(enabledDisabled(jdbcBatchVersionedData));
 		settings.setJdbcBatchVersionedData(jdbcBatchVersionedData);
 
 		boolean useScrollableResultSets = ConfigurationHelper.getBoolean(Environment.USE_SCROLLABLE_RESULTSET, properties, meta.supportsScrollableResults());
         LOG.scrollabelResultSets(enabledDisabled(useScrollableResultSets));
 		settings.setScrollableResultSetsEnabled(useScrollableResultSets);
 
 		boolean wrapResultSets = ConfigurationHelper.getBoolean(Environment.WRAP_RESULT_SETS, properties, false);
         LOG.wrapResultSets(enabledDisabled(wrapResultSets));
 		settings.setWrapResultSetsEnabled(wrapResultSets);
 
 		boolean useGetGeneratedKeys = ConfigurationHelper.getBoolean(Environment.USE_GET_GENERATED_KEYS, properties, meta.supportsGetGeneratedKeys());
         LOG.jdbc3GeneratedKeys(enabledDisabled(useGetGeneratedKeys));
 		settings.setGetGeneratedKeysEnabled(useGetGeneratedKeys);
 
 		Integer statementFetchSize = ConfigurationHelper.getInteger(Environment.STATEMENT_FETCH_SIZE, properties);
         if (statementFetchSize != null) LOG.jdbcResultSetFetchSize(statementFetchSize);
 		settings.setJdbcFetchSize(statementFetchSize);
 
 		String releaseModeName = ConfigurationHelper.getString( Environment.RELEASE_CONNECTIONS, properties, "auto" );
         LOG.connectionReleaseMode(releaseModeName);
 		ConnectionReleaseMode releaseMode;
 		if ( "auto".equals(releaseModeName) ) {
 			releaseMode = serviceRegistry.getService( TransactionFactory.class ).getDefaultReleaseMode();
 		}
 		else {
 			releaseMode = ConnectionReleaseMode.parse( releaseModeName );
 			if ( releaseMode == ConnectionReleaseMode.AFTER_STATEMENT &&
 					! jdbcServices.getConnectionProvider().supportsAggressiveRelease() ) {
                 LOG.unsupportedAfterStatement();
 				releaseMode = ConnectionReleaseMode.AFTER_TRANSACTION;
 			}
 		}
 		settings.setConnectionReleaseMode( releaseMode );
 
 		//SQL Generation settings:
 
 		String defaultSchema = properties.getProperty(Environment.DEFAULT_SCHEMA);
 		String defaultCatalog = properties.getProperty(Environment.DEFAULT_CATALOG);
         if (defaultSchema != null) LOG.defaultSchema(defaultSchema);
         if (defaultCatalog != null) LOG.defaultCatalog(defaultCatalog);
 		settings.setDefaultSchemaName(defaultSchema);
 		settings.setDefaultCatalogName(defaultCatalog);
 
 		Integer maxFetchDepth = ConfigurationHelper.getInteger(Environment.MAX_FETCH_DEPTH, properties);
         if (maxFetchDepth != null) LOG.maxOuterJoinFetchDepth(maxFetchDepth);
 		settings.setMaximumFetchDepth(maxFetchDepth);
 		int batchFetchSize = ConfigurationHelper.getInt(Environment.DEFAULT_BATCH_FETCH_SIZE, properties, 1);
         LOG.defaultBatchFetchSize(batchFetchSize);
 		settings.setDefaultBatchFetchSize(batchFetchSize);
 
 		boolean comments = ConfigurationHelper.getBoolean(Environment.USE_SQL_COMMENTS, properties);
         LOG.generateSqlWithComments(enabledDisabled(comments));
 		settings.setCommentsEnabled(comments);
 
 		boolean orderUpdates = ConfigurationHelper.getBoolean(Environment.ORDER_UPDATES, properties);
         LOG.orderSqlUpdatesByPrimaryKey(enabledDisabled(orderUpdates));
 		settings.setOrderUpdatesEnabled(orderUpdates);
 
 		boolean orderInserts = ConfigurationHelper.getBoolean(Environment.ORDER_INSERTS, properties);
         LOG.orderSqlInsertsForBatching(enabledDisabled(orderInserts));
 		settings.setOrderInsertsEnabled( orderInserts );
 
 		//Query parser settings:
 
 		settings.setQueryTranslatorFactory( createQueryTranslatorFactory(properties) );
 
         Map querySubstitutions = ConfigurationHelper.toMap(Environment.QUERY_SUBSTITUTIONS, " ,=;:\n\t\r\f", properties);
         LOG.queryLanguageSubstitutions(querySubstitutions);
 		settings.setQuerySubstitutions(querySubstitutions);
 
 		boolean jpaqlCompliance = ConfigurationHelper.getBoolean( Environment.JPAQL_STRICT_COMPLIANCE, properties, false );
 		settings.setStrictJPAQLCompliance( jpaqlCompliance );
         LOG.jpaQlStrictCompliance(enabledDisabled(jpaqlCompliance));
 
 		// Second-level / query cache:
 
 		boolean useSecondLevelCache = ConfigurationHelper.getBoolean(Environment.USE_SECOND_LEVEL_CACHE, properties, true);
         LOG.secondLevelCache(enabledDisabled(useSecondLevelCache));
 		settings.setSecondLevelCacheEnabled(useSecondLevelCache);
 
 		boolean useQueryCache = ConfigurationHelper.getBoolean(Environment.USE_QUERY_CACHE, properties);
         LOG.queryCache(enabledDisabled(useQueryCache));
 		settings.setQueryCacheEnabled(useQueryCache);
 
 		// The cache provider is needed when we either have second-level cache enabled
 		// or query cache enabled.  Note that useSecondLevelCache is enabled by default
 		settings.setRegionFactory( createRegionFactory( properties, ( useSecondLevelCache || useQueryCache ) ) );
 
 		boolean useMinimalPuts = ConfigurationHelper.getBoolean(
 				Environment.USE_MINIMAL_PUTS, properties, settings.getRegionFactory().isMinimalPutsEnabledByDefault()
 		);
         LOG.optimizeCacheForMinimalInputs(enabledDisabled(useMinimalPuts));
 		settings.setMinimalPutsEnabled(useMinimalPuts);
 
 		String prefix = properties.getProperty(Environment.CACHE_REGION_PREFIX);
 		if ( StringHelper.isEmpty(prefix) ) prefix=null;
         if (prefix != null) LOG.cacheRegionPrefix(prefix);
 		settings.setCacheRegionPrefix(prefix);
 
 		boolean useStructuredCacheEntries = ConfigurationHelper.getBoolean(Environment.USE_STRUCTURED_CACHE, properties, false);
         LOG.structuredSecondLevelCacheEntries(enabledDisabled(useStructuredCacheEntries));
 		settings.setStructuredCacheEntriesEnabled(useStructuredCacheEntries);
 
 		if (useQueryCache) settings.setQueryCacheFactory( createQueryCacheFactory(properties) );
 
 		//Statistics and logging:
 
 		boolean useStatistics = ConfigurationHelper.getBoolean(Environment.GENERATE_STATISTICS, properties);
 		LOG.statistics( enabledDisabled(useStatistics) );
 		settings.setStatisticsEnabled(useStatistics);
 
 		boolean useIdentifierRollback = ConfigurationHelper.getBoolean(Environment.USE_IDENTIFIER_ROLLBACK, properties);
         LOG.deletedEntitySyntheticIdentifierRollback(enabledDisabled(useIdentifierRollback));
 		settings.setIdentifierRollbackEnabled(useIdentifierRollback);
 
 		//Schema export:
 
 		String autoSchemaExport = properties.getProperty(Environment.HBM2DDL_AUTO);
 		if ( "validate".equals(autoSchemaExport) ) settings.setAutoValidateSchema(true);
 		if ( "update".equals(autoSchemaExport) ) settings.setAutoUpdateSchema(true);
 		if ( "create".equals(autoSchemaExport) ) settings.setAutoCreateSchema(true);
 		if ( "create-drop".equals(autoSchemaExport) ) {
 			settings.setAutoCreateSchema(true);
 			settings.setAutoDropSchema(true);
 		}
 		settings.setImportFiles( properties.getProperty( Environment.HBM2DDL_IMPORT_FILES ) );
 
 		EntityMode defaultEntityMode = EntityMode.parse( properties.getProperty( Environment.DEFAULT_ENTITY_MODE ) );
         LOG.defaultEntityMode(defaultEntityMode);
 		settings.setDefaultEntityMode( defaultEntityMode );
 
 		boolean namedQueryChecking = ConfigurationHelper.getBoolean( Environment.QUERY_STARTUP_CHECKING, properties, true );
         LOG.namedQueryChecking(enabledDisabled(namedQueryChecking));
 		settings.setNamedQueryStartupCheckingEnabled( namedQueryChecking );
 
 		boolean checkNullability = ConfigurationHelper.getBoolean(Environment.CHECK_NULLABILITY, properties, true);
         LOG.checkNullability(enabledDisabled(checkNullability));
 		settings.setCheckNullability(checkNullability);
 
 		MultiTenancyStrategy multiTenancyStrategy = MultiTenancyStrategy.determineMultiTenancyStrategy( properties );
 		LOG.debug( "multi-tenancy strategy : " + multiTenancyStrategy );
 		settings.setMultiTenancyStrategy( multiTenancyStrategy );
 
 //		String provider = properties.getProperty( Environment.BYTECODE_PROVIDER );
 //		log.info( "Bytecode provider name : " + provider );
 //		BytecodeProvider bytecodeProvider = buildBytecodeProvider( provider );
 //		settings.setBytecodeProvider( bytecodeProvider );
 
 		return settings;
 
 	}
 
 //	protected BytecodeProvider buildBytecodeProvider(String providerName) {
 //		if ( "javassist".equals( providerName ) ) {
 //			return new org.hibernate.bytecode.internal.javassist.BytecodeProviderImpl();
 //		}
 //		else {
 //            LOG.debugf("Using javassist as bytecode provider by default");
 //			return new org.hibernate.bytecode.internal.javassist.BytecodeProviderImpl();
 //		}
 //	}
 
 	private static String enabledDisabled(boolean value) {
 		return value ? "enabled" : "disabled";
 	}
 
 	protected QueryCacheFactory createQueryCacheFactory(Properties properties) {
 		String queryCacheFactoryClassName = ConfigurationHelper.getString(
 				Environment.QUERY_CACHE_FACTORY, properties, "org.hibernate.cache.StandardQueryCacheFactory"
 		);
         LOG.queryCacheFactory(queryCacheFactoryClassName);
 		try {
 			return (QueryCacheFactory) ReflectHelper.classForName(queryCacheFactoryClassName).newInstance();
 		}
 		catch (Exception cnfe) {
 			throw new HibernateException("could not instantiate QueryCacheFactory: " + queryCacheFactoryClassName, cnfe);
 		}
 	}
 
 	public static RegionFactory createRegionFactory(Properties properties, boolean cachingEnabled) {
 		String regionFactoryClassName = ConfigurationHelper.getString(
 				Environment.CACHE_REGION_FACTORY, properties, null
 		);
 		if ( regionFactoryClassName == null && cachingEnabled ) {
 			String providerClassName = ConfigurationHelper.getString( Environment.CACHE_PROVIDER, properties, null );
 			if ( providerClassName != null ) {
 				// legacy behavior, apply the bridge...
 				regionFactoryClassName = RegionFactoryCacheProviderBridge.class.getName();
 			}
 		}
 		if ( regionFactoryClassName == null ) {
 			regionFactoryClassName = DEF_CACHE_REG_FACTORY;
 		}
         LOG.cacheRegionFactory( regionFactoryClassName );
 		try {
 			try {
 				return (RegionFactory) ReflectHelper.classForName( regionFactoryClassName )
 						.getConstructor( Properties.class )
 						.newInstance( properties );
 			}
 			catch ( NoSuchMethodException nsme ) {
 				// no constructor accepting Properties found, try no arg constructor
                 LOG.constructorWithPropertiesNotFound(regionFactoryClassName);
 				return (RegionFactory) ReflectHelper.classForName( regionFactoryClassName ).newInstance();
 			}
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "could not instantiate RegionFactory [" + regionFactoryClassName + "]", e );
 		}
 	}
 
 	protected QueryTranslatorFactory createQueryTranslatorFactory(Properties properties) {
 		String className = ConfigurationHelper.getString(
 				Environment.QUERY_TRANSLATOR, properties, "org.hibernate.hql.ast.ASTQueryTranslatorFactory"
 		);
         LOG.queryTranslator( className );
 		try {
 			return (QueryTranslatorFactory) ReflectHelper.classForName(className).newInstance();
 		}
 		catch (Exception cnfe) {
 			throw new HibernateException("could not instantiate QueryTranslatorFactory: " + className, cnfe);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/CollectionBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/CollectionBinder.java
index 1ac62a7174..f63dc3ebb6 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/CollectionBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/CollectionBinder.java
@@ -1,1122 +1,1123 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import java.util.ArrayList;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.StringTokenizer;
 import javax.persistence.AttributeOverride;
 import javax.persistence.AttributeOverrides;
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.FetchType;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinColumns;
 import javax.persistence.JoinTable;
 import javax.persistence.ManyToMany;
 import javax.persistence.MapKey;
 import javax.persistence.MapKeyColumn;
 import javax.persistence.OneToMany;
 import org.hibernate.AnnotationException;
 import org.hibernate.FetchMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.BatchSize;
 import org.hibernate.annotations.Cache;
 import org.hibernate.annotations.CollectionId;
 import org.hibernate.annotations.CollectionOfElements;
 import org.hibernate.annotations.Fetch;
 import org.hibernate.annotations.Filter;
 import org.hibernate.annotations.FilterJoinTable;
 import org.hibernate.annotations.FilterJoinTables;
 import org.hibernate.annotations.Filters;
 import org.hibernate.annotations.ForeignKey;
 import org.hibernate.annotations.Immutable;
 import org.hibernate.annotations.LazyCollection;
 import org.hibernate.annotations.LazyCollectionOption;
 import org.hibernate.annotations.Loader;
 import org.hibernate.annotations.ManyToAny;
 import org.hibernate.annotations.OptimisticLock;
 import org.hibernate.annotations.OrderBy;
 import org.hibernate.annotations.Persister;
 import org.hibernate.annotations.SQLDelete;
 import org.hibernate.annotations.SQLDeleteAll;
 import org.hibernate.annotations.SQLInsert;
 import org.hibernate.annotations.SQLUpdate;
 import org.hibernate.annotations.Sort;
 import org.hibernate.annotations.SortType;
 import org.hibernate.annotations.Where;
 import org.hibernate.annotations.WhereJoinTable;
 import org.hibernate.annotations.common.AssertionFailure;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.cfg.AccessType;
 import org.hibernate.cfg.AnnotatedClassType;
 import org.hibernate.cfg.AnnotationBinder;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.CollectionSecondPass;
 import org.hibernate.cfg.Ejb3Column;
 import org.hibernate.cfg.Ejb3JoinColumn;
 import org.hibernate.cfg.IndexColumn;
 import org.hibernate.cfg.InheritanceState;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.PropertyData;
 import org.hibernate.cfg.PropertyHolder;
 import org.hibernate.cfg.PropertyHolderBuilder;
 import org.hibernate.cfg.PropertyInferredData;
 import org.hibernate.cfg.PropertyPreloadedData;
 import org.hibernate.cfg.SecondPass;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Any;
 import org.hibernate.mapping.Backref;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.IdGenerator;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.ManyToOne;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.SingleTableSubclass;
 import org.hibernate.mapping.Table;
+
 import org.jboss.logging.Logger;
 
 /**
  * Base class for binding different types of collections to Hibernate configuration objects.
  *
  * @author inger
  * @author Emmanuel Bernard
  */
 @SuppressWarnings({"unchecked", "serial"})
 public abstract class CollectionBinder {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, CollectionBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CollectionBinder.class.getName());
 
 	protected Collection collection;
 	protected String propertyName;
 	PropertyHolder propertyHolder;
 	int batchSize;
 	private String mappedBy;
 	private XClass collectionType;
 	private XClass targetEntity;
 	private Mappings mappings;
 	private Ejb3JoinColumn[] inverseJoinColumns;
 	private String cascadeStrategy;
 	String cacheConcurrencyStrategy;
 	String cacheRegionName;
 	private boolean oneToMany;
 	protected IndexColumn indexColumn;
 	private String orderBy;
 	protected String hqlOrderBy;
 	private boolean isSorted;
 	private Class comparator;
 	private boolean hasToBeSorted;
 	protected boolean cascadeDeleteEnabled;
 	protected String mapKeyPropertyName;
 	private boolean insertable = true;
 	private boolean updatable = true;
 	private Ejb3JoinColumn[] fkJoinColumns;
 	private boolean isExplicitAssociationTable;
 	private Ejb3Column[] elementColumns;
 	private boolean isEmbedded;
 	private XProperty property;
 	private boolean ignoreNotFound;
 	private TableBinder tableBinder;
 	private Ejb3Column[] mapKeyColumns;
 	private Ejb3JoinColumn[] mapKeyManyToManyColumns;
 	protected HashMap<String, IdGenerator> localGenerators;
 	protected Map<XClass, InheritanceState> inheritanceStatePerClass;
 	private XClass declaringClass;
 	private boolean declaringClassSet;
 	private AccessType accessType;
 	private boolean hibernateExtensionMapping;
 
 	protected Mappings getMappings() {
 		return mappings;
 	}
 
 	public boolean isMap() {
 		return false;
 	}
 
 	public void setIsHibernateExtensionMapping(boolean hibernateExtensionMapping) {
 		this.hibernateExtensionMapping = hibernateExtensionMapping;
 	}
 
 	protected boolean isHibernateExtensionMapping() {
 		return hibernateExtensionMapping;
 	}
 
 	public void setUpdatable(boolean updatable) {
 		this.updatable = updatable;
 	}
 
 	public void setInheritanceStatePerClass(Map<XClass, InheritanceState> inheritanceStatePerClass) {
 		this.inheritanceStatePerClass = inheritanceStatePerClass;
 	}
 
 	public void setInsertable(boolean insertable) {
 		this.insertable = insertable;
 	}
 
 	public void setCascadeStrategy(String cascadeStrategy) {
 		this.cascadeStrategy = cascadeStrategy;
 	}
 
 	public void setAccessType(AccessType accessType) {
 		this.accessType = accessType;
 	}
 
 	public void setInverseJoinColumns(Ejb3JoinColumn[] inverseJoinColumns) {
 		this.inverseJoinColumns = inverseJoinColumns;
 	}
 
 	public void setJoinColumns(Ejb3JoinColumn[] joinColumns) {
 		this.joinColumns = joinColumns;
 	}
 
 	private Ejb3JoinColumn[] joinColumns;
 
 	public void setPropertyHolder(PropertyHolder propertyHolder) {
 		this.propertyHolder = propertyHolder;
 	}
 
 	public void setBatchSize(BatchSize batchSize) {
 		this.batchSize = batchSize == null ? -1 : batchSize.size();
 	}
 
 	public void setEjb3OrderBy(javax.persistence.OrderBy orderByAnn) {
 		if ( orderByAnn != null ) {
 			hqlOrderBy = orderByAnn.value();
 		}
 	}
 
 	public void setSqlOrderBy(OrderBy orderByAnn) {
 		if ( orderByAnn != null ) {
 			if ( !BinderHelper.isEmptyAnnotationValue( orderByAnn.clause() ) ) {
 				orderBy = orderByAnn.clause();
 			}
 		}
 	}
 
 	public void setSort(Sort sortAnn) {
 		if ( sortAnn != null ) {
 			isSorted = !SortType.UNSORTED.equals( sortAnn.type() );
 			if ( isSorted && SortType.COMPARATOR.equals( sortAnn.type() ) ) {
 				comparator = sortAnn.comparator();
 			}
 		}
 	}
 
 	/**
 	 * collection binder factory
 	 */
 	public static CollectionBinder getCollectionBinder(
 			String entityName,
 			XProperty property,
 			boolean isIndexed,
 			boolean isHibernateExtensionMapping) {
 		CollectionBinder result;
 		if ( property.isArray() ) {
 			if ( property.getElementClass().isPrimitive() ) {
 				result = new PrimitiveArrayBinder();
 			}
 			else {
 				result = new ArrayBinder();
 			}
 		}
 		else if ( property.isCollection() ) {
 			//TODO consider using an XClass
 			Class returnedClass = property.getCollectionClass();
 			if ( java.util.Set.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					throw new AnnotationException( "Set do not support @CollectionId: "
 							+ StringHelper.qualify( entityName, property.getName() ) );
 				}
 				result = new SetBinder();
 			}
 			else if ( java.util.SortedSet.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					throw new AnnotationException( "Set do not support @CollectionId: "
 							+ StringHelper.qualify( entityName, property.getName() ) );
 				}
 				result = new SetBinder( true );
 			}
 			else if ( java.util.Map.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					throw new AnnotationException( "Map do not support @CollectionId: "
 							+ StringHelper.qualify( entityName, property.getName() ) );
 				}
 				result = new MapBinder();
 			}
 			else if ( java.util.SortedMap.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					throw new AnnotationException( "Map do not support @CollectionId: "
 							+ StringHelper.qualify( entityName, property.getName() ) );
 				}
 				result = new MapBinder( true );
 			}
 			else if ( java.util.Collection.class.equals( returnedClass ) ) {
 				if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					result = new IdBagBinder();
 				}
 				else {
 					result = new BagBinder();
 				}
 			}
 			else if ( java.util.List.class.equals( returnedClass ) ) {
 				if ( isIndexed ) {
 					if ( property.isAnnotationPresent( CollectionId.class ) ) {
 						throw new AnnotationException(
 								"List do not support @CollectionId and @OrderColumn (or @IndexColumn) at the same time: "
 								+ StringHelper.qualify( entityName, property.getName() ) );
 					}
 					result = new ListBinder();
 				}
 				else if ( property.isAnnotationPresent( CollectionId.class ) ) {
 					result = new IdBagBinder();
 				}
 				else {
 					result = new BagBinder();
 				}
 			}
 			else {
 				throw new AnnotationException(
 						returnedClass.getName() + " collection not yet supported: "
 								+ StringHelper.qualify( entityName, property.getName() )
 				);
 			}
 		}
 		else {
 			throw new AnnotationException(
 					"Illegal attempt to map a non collection as a @OneToMany, @ManyToMany or @CollectionOfElements: "
 							+ StringHelper.qualify( entityName, property.getName() )
 			);
 		}
 		result.setIsHibernateExtensionMapping( isHibernateExtensionMapping );
 		return result;
 	}
 
 	protected CollectionBinder() {
 	}
 
 	protected CollectionBinder(boolean sorted) {
 		this.hasToBeSorted = sorted;
 	}
 
 	public void setMappedBy(String mappedBy) {
 		this.mappedBy = mappedBy;
 	}
 
 	public void setTableBinder(TableBinder tableBinder) {
 		this.tableBinder = tableBinder;
 	}
 
 	public void setCollectionType(XClass collectionType) {
 		this.collectionType = collectionType;
 	}
 
 	public void setTargetEntity(XClass targetEntity) {
 		this.targetEntity = targetEntity;
 	}
 
 	public void setMappings(Mappings mappings) {
 		this.mappings = mappings;
 	}
 
 	protected abstract Collection createCollection(PersistentClass persistentClass);
 
 	public Collection getCollection() {
 		return collection;
 	}
 
 	public void setPropertyName(String propertyName) {
 		this.propertyName = propertyName;
 	}
 
 	public void setDeclaringClass(XClass declaringClass) {
 		this.declaringClass = declaringClass;
 		this.declaringClassSet = true;
 	}
 
 	public void bind() {
 		this.collection = createCollection( propertyHolder.getPersistentClass() );
         String role = StringHelper.qualify(propertyHolder.getPath(), propertyName);
         LOG.debugf("Collection role: %s", role);
         collection.setRole(role);
 		collection.setNodeName( propertyName );
 
 		if ( (property.isAnnotationPresent( org.hibernate.annotations.MapKey.class )
 				|| property.isAnnotationPresent( MapKeyColumn.class ) )
 			&& mapKeyPropertyName != null ) {
 			throw new AnnotationException(
 					"Cannot mix @javax.persistence.MapKey and @MapKeyColumn or @org.hibernate.annotations.MapKey "
 							+ "on the same collection: " + StringHelper.qualify(
 							propertyHolder.getPath(), propertyName
 					)
 			);
 		}
 
 		//set laziness
 		defineFetchingStrategy();
 		collection.setBatchSize( batchSize );
 		if ( orderBy != null && hqlOrderBy != null ) {
 			throw new AnnotationException(
 					"Cannot use sql order by clause in conjunction of EJB3 order by clause: " + safeCollectionRole()
 			);
 		}
 
 		collection.setMutable( !property.isAnnotationPresent( Immutable.class ) );
 		OptimisticLock lockAnn = property.getAnnotation( OptimisticLock.class );
 		if ( lockAnn != null ) collection.setOptimisticLocked( !lockAnn.excluded() );
 
 		Persister persisterAnn = property.getAnnotation( Persister.class );
 		if ( persisterAnn != null ) {
 			collection.setCollectionPersisterClass( persisterAnn.impl() );
 		}
 
 		// set ordering
 		if ( orderBy != null ) collection.setOrderBy( orderBy );
 		if ( isSorted ) {
 			collection.setSorted( true );
 			if ( comparator != null ) {
 				try {
 					collection.setComparator( (Comparator) comparator.newInstance() );
 				}
 				catch (ClassCastException e) {
 					throw new AnnotationException(
 							"Comparator not implementing java.util.Comparator class: "
 									+ comparator.getName() + "(" + safeCollectionRole() + ")"
 					);
 				}
 				catch (Exception e) {
 					throw new AnnotationException(
 							"Could not instantiate comparator class: "
 									+ comparator.getName() + "(" + safeCollectionRole() + ")"
 					);
 				}
 			}
 		}
 		else {
 			if ( hasToBeSorted ) {
 				throw new AnnotationException(
 						"A sorted collection has to define @Sort: "
 								+ safeCollectionRole()
 				);
 			}
 		}
 
 		//set cache
 		if ( StringHelper.isNotEmpty( cacheConcurrencyStrategy ) ) {
 			collection.setCacheConcurrencyStrategy( cacheConcurrencyStrategy );
 			collection.setCacheRegionName( cacheRegionName );
 		}
 
 		//SQL overriding
 		SQLInsert sqlInsert = property.getAnnotation( SQLInsert.class );
 		SQLUpdate sqlUpdate = property.getAnnotation( SQLUpdate.class );
 		SQLDelete sqlDelete = property.getAnnotation( SQLDelete.class );
 		SQLDeleteAll sqlDeleteAll = property.getAnnotation( SQLDeleteAll.class );
 		Loader loader = property.getAnnotation( Loader.class );
 		if ( sqlInsert != null ) {
 			collection.setCustomSQLInsert( sqlInsert.sql().trim(), sqlInsert.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlInsert.check().toString().toLowerCase() )
 			);
 
 		}
 		if ( sqlUpdate != null ) {
 			collection.setCustomSQLUpdate( sqlUpdate.sql(), sqlUpdate.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlUpdate.check().toString().toLowerCase() )
 			);
 		}
 		if ( sqlDelete != null ) {
 			collection.setCustomSQLDelete( sqlDelete.sql(), sqlDelete.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlDelete.check().toString().toLowerCase() )
 			);
 		}
 		if ( sqlDeleteAll != null ) {
 			collection.setCustomSQLDeleteAll( sqlDeleteAll.sql(), sqlDeleteAll.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlDeleteAll.check().toString().toLowerCase() )
 			);
 		}
 		if ( loader != null ) {
 			collection.setLoaderName( loader.namedQuery() );
 		}
 
 		//work on association
 		boolean isMappedBy = !BinderHelper.isEmptyAnnotationValue( mappedBy );
 
 		if (isMappedBy
 				&& (property.isAnnotationPresent( JoinColumn.class )
 					|| property.isAnnotationPresent( JoinColumns.class )
 					|| propertyHolder.getJoinTable( property ) != null ) ) {
 			String message = "Associations marked as mappedBy must not define database mappings like @JoinTable or @JoinColumn: ";
 			message += StringHelper.qualify( propertyHolder.getPath(), propertyName );
 			throw new AnnotationException( message );
 		}
 
 		collection.setInverse( isMappedBy );
 
 		//many to many may need some second pass informations
 		if ( !oneToMany && isMappedBy ) {
 			mappings.addMappedBy( getCollectionType().getName(), mappedBy, propertyName );
 		}
 		//TODO reducce tableBinder != null and oneToMany
 		XClass collectionType = getCollectionType();
 		if ( inheritanceStatePerClass == null) throw new AssertionFailure( "inheritanceStatePerClass not set" );
 		SecondPass sp = getSecondPass(
 				fkJoinColumns,
 				joinColumns,
 				inverseJoinColumns,
 				elementColumns,
 				mapKeyColumns, mapKeyManyToManyColumns, isEmbedded,
 				property, collectionType,
 				ignoreNotFound, oneToMany,
 				tableBinder, mappings
 		);
 		if ( collectionType.isAnnotationPresent( Embeddable.class )
 				|| property.isAnnotationPresent( CollectionOfElements.class ) //legacy hibernate
 				|| property.isAnnotationPresent( ElementCollection.class ) //JPA 2
 				) {
 			// do it right away, otherwise @ManyToOne on composite element call addSecondPass
 			// and raise a ConcurrentModificationException
 			//sp.doSecondPass( CollectionHelper.EMPTY_MAP );
 			mappings.addSecondPass( sp, !isMappedBy );
 		}
 		else {
 			mappings.addSecondPass( sp, !isMappedBy );
 		}
 
 		mappings.addCollection( collection );
 
 		//property building
 		PropertyBinder binder = new PropertyBinder();
 		binder.setName( propertyName );
 		binder.setValue( collection );
 		binder.setCascade( cascadeStrategy );
 		if ( cascadeStrategy != null && cascadeStrategy.indexOf( "delete-orphan" ) >= 0 ) {
 			collection.setOrphanDelete( true );
 		}
 		binder.setAccessType( accessType );
 		binder.setProperty( property );
 		binder.setInsertable( insertable );
 		binder.setUpdatable( updatable );
 		Property prop = binder.makeProperty();
 		//we don't care about the join stuffs because the column is on the association table.
 		if (! declaringClassSet) throw new AssertionFailure( "DeclaringClass is not set in CollectionBinder while binding" );
 		propertyHolder.addProperty( prop, declaringClass );
 	}
 
 	private void defineFetchingStrategy() {
 		LazyCollection lazy = property.getAnnotation( LazyCollection.class );
 		Fetch fetch = property.getAnnotation( Fetch.class );
 		OneToMany oneToMany = property.getAnnotation( OneToMany.class );
 		ManyToMany manyToMany = property.getAnnotation( ManyToMany.class );
 		CollectionOfElements collectionOfElements = property.getAnnotation( CollectionOfElements.class ); //legacy hibernate
 		ElementCollection elementCollection = property.getAnnotation( ElementCollection.class ); //jpa 2
 		ManyToAny manyToAny = property.getAnnotation( ManyToAny.class );
 		FetchType fetchType;
 		if ( oneToMany != null ) {
 			fetchType = oneToMany.fetch();
 		}
 		else if ( manyToMany != null ) {
 			fetchType = manyToMany.fetch();
 		}
 		else if ( elementCollection != null ) {
 			fetchType = elementCollection.fetch();
 		}
 		else if ( collectionOfElements != null ) {
 			fetchType = collectionOfElements.fetch();
 		}
 		else if ( manyToAny != null ) {
 			fetchType = FetchType.LAZY;
 		}
 		else {
 			throw new AssertionFailure(
 					"Define fetch strategy on a property not annotated with @ManyToOne nor @OneToMany nor @CollectionOfElements"
 			);
 		}
 		if ( lazy != null ) {
 			collection.setLazy( !( lazy.value() == LazyCollectionOption.FALSE ) );
 			collection.setExtraLazy( lazy.value() == LazyCollectionOption.EXTRA );
 		}
 		else {
 			collection.setLazy( fetchType == FetchType.LAZY );
 			collection.setExtraLazy( false );
 		}
 		if ( fetch != null ) {
 			if ( fetch.value() == org.hibernate.annotations.FetchMode.JOIN ) {
 				collection.setFetchMode( FetchMode.JOIN );
 				collection.setLazy( false );
 			}
 			else if ( fetch.value() == org.hibernate.annotations.FetchMode.SELECT ) {
 				collection.setFetchMode( FetchMode.SELECT );
 			}
 			else if ( fetch.value() == org.hibernate.annotations.FetchMode.SUBSELECT ) {
 				collection.setFetchMode( FetchMode.SELECT );
 				collection.setSubselectLoadable( true );
 				collection.getOwner().setSubselectLoadableCollections( true );
 			}
 			else {
 				throw new AssertionFailure( "Unknown FetchMode: " + fetch.value() );
 			}
 		}
 		else {
 			collection.setFetchMode( AnnotationBinder.getFetchMode( fetchType ) );
 		}
 	}
 
 	private XClass getCollectionType() {
 		if ( AnnotationBinder.isDefault( targetEntity, mappings ) ) {
 			if ( collectionType != null ) {
 				return collectionType;
 			}
 			else {
 				String errorMsg = "Collection has neither generic type or OneToMany.targetEntity() defined: "
 						+ safeCollectionRole();
 				throw new AnnotationException( errorMsg );
 			}
 		}
 		else {
 			return targetEntity;
 		}
 	}
 
 	public SecondPass getSecondPass(
 			final Ejb3JoinColumn[] fkJoinColumns,
 			final Ejb3JoinColumn[] keyColumns,
 			final Ejb3JoinColumn[] inverseColumns,
 			final Ejb3Column[] elementColumns,
 			final Ejb3Column[] mapKeyColumns,
 			final Ejb3JoinColumn[] mapKeyManyToManyColumns,
 			final boolean isEmbedded,
 			final XProperty property,
 			final XClass collType,
 			final boolean ignoreNotFound,
 			final boolean unique,
 			final TableBinder assocTableBinder,
 			final Mappings mappings) {
 		return new CollectionSecondPass( mappings, collection ) {
 			@Override
             public void secondPass(java.util.Map persistentClasses, java.util.Map inheritedMetas) throws MappingException {
 				bindStarToManySecondPass(
 						persistentClasses, collType, fkJoinColumns, keyColumns, inverseColumns, elementColumns,
 						isEmbedded, property, unique, assocTableBinder, ignoreNotFound, mappings
 				);
 			}
 		};
 	}
 
 	/**
 	 * return true if it's a Fk, false if it's an association table
 	 */
 	protected boolean bindStarToManySecondPass(
 			Map persistentClasses,
 			XClass collType,
 			Ejb3JoinColumn[] fkJoinColumns,
 			Ejb3JoinColumn[] keyColumns,
 			Ejb3JoinColumn[] inverseColumns,
 			Ejb3Column[] elementColumns,
 			boolean isEmbedded,
 			XProperty property,
 			boolean unique,
 			TableBinder associationTableBinder,
 			boolean ignoreNotFound,
 			Mappings mappings) {
 		PersistentClass persistentClass = (PersistentClass) persistentClasses.get( collType.getName() );
 		boolean reversePropertyInJoin = false;
 		if ( persistentClass != null && StringHelper.isNotEmpty( this.mappedBy ) ) {
 			try {
 				reversePropertyInJoin = 0 != persistentClass.getJoinNumber(
 						persistentClass.getRecursiveProperty( this.mappedBy )
 				);
 			}
 			catch (MappingException e) {
 				StringBuilder error = new StringBuilder( 80 );
 				error.append( "mappedBy reference an unknown target entity property: " )
 						.append( collType ).append( "." ).append( this.mappedBy )
 						.append( " in " )
 						.append( collection.getOwnerEntityName() )
 						.append( "." )
 						.append( property.getName() );
 				throw new AnnotationException( error.toString() );
 			}
 		}
 		if ( persistentClass != null
 				&& !reversePropertyInJoin
 				&& oneToMany
 				&& !this.isExplicitAssociationTable
 				&& ( joinColumns[0].isImplicit() && !BinderHelper.isEmptyAnnotationValue( this.mappedBy ) //implicit @JoinColumn
 				|| !fkJoinColumns[0].isImplicit() ) //this is an explicit @JoinColumn
 				) {
 			//this is a Foreign key
 			bindOneToManySecondPass(
 					getCollection(),
 					persistentClasses,
 					fkJoinColumns,
 					collType,
 					cascadeDeleteEnabled,
 					ignoreNotFound, hqlOrderBy,
 					mappings,
 					inheritanceStatePerClass
 			);
 			return true;
 		}
 		else {
 			//this is an association table
 			bindManyToManySecondPass(
 					this.collection,
 					persistentClasses,
 					keyColumns,
 					inverseColumns,
 					elementColumns,
 					isEmbedded, collType,
 					ignoreNotFound, unique,
 					cascadeDeleteEnabled,
 					associationTableBinder, property, propertyHolder, hqlOrderBy, mappings
 			);
 			return false;
 		}
 	}
 
 	protected void bindOneToManySecondPass(
 			Collection collection,
 			Map persistentClasses,
 			Ejb3JoinColumn[] fkJoinColumns,
 			XClass collectionType,
 			boolean cascadeDeleteEnabled,
 			boolean ignoreNotFound,
 			String hqlOrderBy,
 			Mappings mappings,
 			Map<XClass, InheritanceState> inheritanceStatePerClass) {
         LOG.debugf("Binding a OneToMany: %s.%s through a foreign key", propertyHolder.getEntityName(), propertyName);
 		org.hibernate.mapping.OneToMany oneToMany = new org.hibernate.mapping.OneToMany( mappings, collection.getOwner() );
 		collection.setElement( oneToMany );
 		oneToMany.setReferencedEntityName( collectionType.getName() );
 		oneToMany.setIgnoreNotFound( ignoreNotFound );
 
 		String assocClass = oneToMany.getReferencedEntityName();
 		PersistentClass associatedClass = (PersistentClass) persistentClasses.get( assocClass );
 		String orderBy = buildOrderByClauseFromHql( hqlOrderBy, associatedClass, collection.getRole() );
 		if ( orderBy != null ) collection.setOrderBy( orderBy );
 		if ( mappings == null ) {
 			throw new AssertionFailure(
 					"CollectionSecondPass for oneToMany should not be called with null mappings"
 			);
 		}
 		Map<String, Join> joins = mappings.getJoins( assocClass );
 		if ( associatedClass == null ) {
 			throw new MappingException(
 					"Association references unmapped class: " + assocClass
 			);
 		}
 		oneToMany.setAssociatedClass( associatedClass );
 		for (Ejb3JoinColumn column : fkJoinColumns) {
 			column.setPersistentClass( associatedClass, joins, inheritanceStatePerClass );
 			column.setJoins( joins );
 			collection.setCollectionTable( column.getTable() );
 		}
         LOG.mappingCollection(collection.getRole(), collection.getCollectionTable().getName());
 		bindFilters( false );
 		bindCollectionSecondPass( collection, null, fkJoinColumns, cascadeDeleteEnabled, property, mappings );
 		if ( !collection.isInverse()
 				&& !collection.getKey().isNullable() ) {
 			// for non-inverse one-to-many, with a not-null fk, add a backref!
 			String entityName = oneToMany.getReferencedEntityName();
 			PersistentClass referenced = mappings.getClass( entityName );
 			Backref prop = new Backref();
 			prop.setName( '_' + fkJoinColumns[0].getPropertyName() + "Backref" );
 			prop.setUpdateable( false );
 			prop.setSelectable( false );
 			prop.setCollectionRole( collection.getRole() );
 			prop.setEntityName( collection.getOwner().getEntityName() );
 			prop.setValue( collection.getKey() );
 			referenced.addProperty( prop );
 		}
 	}
 
 
 	private void bindFilters(boolean hasAssociationTable) {
 		Filter simpleFilter = property.getAnnotation( Filter.class );
 		//set filtering
 		//test incompatible choices
 		//if ( StringHelper.isNotEmpty( where ) ) collection.setWhere( where );
 		if ( simpleFilter != null ) {
 			if ( hasAssociationTable ) {
 				collection.addManyToManyFilter( simpleFilter.name(), getCondition( simpleFilter ) );
 			}
 			else {
 				collection.addFilter( simpleFilter.name(), getCondition( simpleFilter ) );
 			}
 		}
 		Filters filters = property.getAnnotation( Filters.class );
 		if ( filters != null ) {
 			for (Filter filter : filters.value()) {
 				if ( hasAssociationTable ) {
 					collection.addManyToManyFilter( filter.name(), getCondition( filter ) );
 				}
 				else {
 					collection.addFilter( filter.name(), getCondition( filter ) );
 				}
 			}
 		}
 		FilterJoinTable simpleFilterJoinTable = property.getAnnotation( FilterJoinTable.class );
 		if ( simpleFilterJoinTable != null ) {
 			if ( hasAssociationTable ) {
 				collection.addFilter( simpleFilterJoinTable.name(), getCondition( simpleFilterJoinTable ) );
 			}
 			else {
 				throw new AnnotationException(
 						"Illegal use of @FilterJoinTable on an association without join table:"
 								+ StringHelper.qualify( propertyHolder.getPath(), propertyName )
 				);
 			}
 		}
 		FilterJoinTables filterJoinTables = property.getAnnotation( FilterJoinTables.class );
 		if ( filterJoinTables != null ) {
 			for (FilterJoinTable filter : filterJoinTables.value()) {
 				if ( hasAssociationTable ) {
 					collection.addFilter( filter.name(), getCondition( filter ) );
 				}
 				else {
 					throw new AnnotationException(
 							"Illegal use of @FilterJoinTable on an association without join table:"
 									+ StringHelper.qualify( propertyHolder.getPath(), propertyName )
 					);
 				}
 			}
 		}
 
 		Where where = property.getAnnotation( Where.class );
 		String whereClause = where == null ? null : where.clause();
 		if ( StringHelper.isNotEmpty( whereClause ) ) {
 			if ( hasAssociationTable ) {
 				collection.setManyToManyWhere( whereClause );
 			}
 			else {
 				collection.setWhere( whereClause );
 			}
 		}
 
 		WhereJoinTable whereJoinTable = property.getAnnotation( WhereJoinTable.class );
 		String whereJoinTableClause = whereJoinTable == null ? null : whereJoinTable.clause();
 		if ( StringHelper.isNotEmpty( whereJoinTableClause ) ) {
 			if ( hasAssociationTable ) {
 				collection.setWhere( whereJoinTableClause );
 			}
 			else {
 				throw new AnnotationException(
 						"Illegal use of @WhereJoinTable on an association without join table:"
 								+ StringHelper.qualify( propertyHolder.getPath(), propertyName )
 				);
 			}
 		}
 //		This cannot happen in annotations since the second fetch is hardcoded to join
 //		if ( ( ! collection.getManyToManyFilterMap().isEmpty() || collection.getManyToManyWhere() != null ) &&
 //		        collection.getFetchMode() == FetchMode.JOIN &&
 //		        collection.getElement().getFetchMode() != FetchMode.JOIN ) {
 //			throw new MappingException(
 //			        "association with join table  defining filter or where without join fetching " +
 //			        "not valid within collection using join fetching [" + collection.getRole() + "]"
 //				);
 //		}
 	}
 
 	private String getCondition(FilterJoinTable filter) {
 		//set filtering
 		String name = filter.name();
 		String cond = filter.condition();
 		return getCondition( cond, name );
 	}
 
 	private String getCondition(Filter filter) {
 		//set filtering
 		String name = filter.name();
 		String cond = filter.condition();
 		return getCondition( cond, name );
 	}
 
 	private String getCondition(String cond, String name) {
 		if ( BinderHelper.isEmptyAnnotationValue( cond ) ) {
 			cond = mappings.getFilterDefinition( name ).getDefaultFilterCondition();
 			if ( StringHelper.isEmpty( cond ) ) {
 				throw new AnnotationException(
 						"no filter condition found for filter " + name + " in "
 								+ StringHelper.qualify( propertyHolder.getPath(), propertyName )
 				);
 			}
 		}
 		return cond;
 	}
 
 	public void setCache(Cache cacheAnn) {
 		if ( cacheAnn != null ) {
 			cacheRegionName = BinderHelper.isEmptyAnnotationValue( cacheAnn.region() ) ? null : cacheAnn.region();
 			cacheConcurrencyStrategy = EntityBinder.getCacheConcurrencyStrategy( cacheAnn.usage() );
 		}
 		else {
 			cacheConcurrencyStrategy = null;
 			cacheRegionName = null;
 		}
 	}
 
 	public void setOneToMany(boolean oneToMany) {
 		this.oneToMany = oneToMany;
 	}
 
 	public void setIndexColumn(IndexColumn indexColumn) {
 		this.indexColumn = indexColumn;
 	}
 
 	public void setMapKey(MapKey key) {
 		if ( key != null ) {
 			mapKeyPropertyName = key.name();
 		}
 	}
 
 	private static String buildOrderByClauseFromHql(String hqlOrderBy, PersistentClass associatedClass, String role) {
 		String orderByString = null;
 		if ( hqlOrderBy != null ) {
 			List<String> properties = new ArrayList<String>();
 			List<String> ordering = new ArrayList<String>();
 			StringBuilder orderByBuffer = new StringBuilder();
 			if ( hqlOrderBy.length() == 0 ) {
 				//order by id
 				Iterator it = associatedClass.getIdentifier().getColumnIterator();
 				while ( it.hasNext() ) {
 					Selectable col = (Selectable) it.next();
 					orderByBuffer.append( col.getText() ).append( " asc" ).append( ", " );
 				}
 			}
 			else {
 				StringTokenizer st = new StringTokenizer( hqlOrderBy, " ,", false );
 				String currentOrdering = null;
 				//FIXME make this code decent
 				while ( st.hasMoreTokens() ) {
 					String token = st.nextToken();
 					if ( isNonPropertyToken( token ) ) {
 						if ( currentOrdering != null ) {
 							throw new AnnotationException(
 									"Error while parsing HQL orderBy clause: " + hqlOrderBy
 											+ " (" + role + ")"
 							);
 						}
 						currentOrdering = token;
 					}
 					else {
 						//Add ordering of the previous
 						if ( currentOrdering == null ) {
 							//default ordering
 							ordering.add( "asc" );
 						}
 						else {
 							ordering.add( currentOrdering );
 							currentOrdering = null;
 						}
 						properties.add( token );
 					}
 				}
 				ordering.remove( 0 ); //first one is the algorithm starter
 				// add last one ordering
 				if ( currentOrdering == null ) {
 					//default ordering
 					ordering.add( "asc" );
 				}
 				else {
 					ordering.add( currentOrdering );
 					currentOrdering = null;
 				}
 				int index = 0;
 
 				for (String property : properties) {
 					Property p = BinderHelper.findPropertyByName( associatedClass, property );
 					if ( p == null ) {
 						throw new AnnotationException(
 								"property from @OrderBy clause not found: "
 										+ associatedClass.getEntityName() + "." + property
 						);
 					}
 					PersistentClass pc = p.getPersistentClass();
 					String table;
 					if ( pc == null ) {
 						//we are touching a @IdClass property, the pc is not set
 						//this means pc == associatedClass
 						//TODO check whether @ManyToOne @JoinTable in @IdClass used for @OrderBy works: doh!
 						table = "";
 					}
 
 					else if (pc == associatedClass
 							|| (associatedClass instanceof SingleTableSubclass && pc
 									.getMappedClass().isAssignableFrom(
 											associatedClass.getMappedClass()))) {
 						table = "";
 					} else {
 						table = pc.getTable().getQuotedName() + ".";
 					}
 
 					Iterator propertyColumns = p.getColumnIterator();
 					while ( propertyColumns.hasNext() ) {
 						Selectable column = (Selectable) propertyColumns.next();
 						orderByBuffer.append( table )
 								.append( column.getText() )
 								.append( " " )
 								.append( ordering.get( index ) )
 								.append( ", " );
 					}
 					index++;
 				}
 			}
 			orderByString = orderByBuffer.substring( 0, orderByBuffer.length() - 2 );
 		}
 		return orderByString;
 	}
 
 	private static String buildOrderByClauseFromHql(String hqlOrderBy, Component component, String role) {
 		String orderByString = null;
 		if ( hqlOrderBy != null ) {
 			List<String> properties = new ArrayList<String>();
 			List<String> ordering = new ArrayList<String>();
 			StringBuilder orderByBuffer = new StringBuilder();
 			if ( hqlOrderBy.length() == 0 ) {
 				//TODO : Check that. Maybe order by key for maps
 			}
 			else {
 				StringTokenizer st = new StringTokenizer( hqlOrderBy, " ,", false );
 				String currentOrdering = null;
 				//FIXME make this code decent
 				while ( st.hasMoreTokens() ) {
 					String token = st.nextToken();
 					if ( isNonPropertyToken( token ) ) {
 						if ( currentOrdering != null ) {
 							throw new AnnotationException(
 									"Error while parsing HQL orderBy clause: " + hqlOrderBy
 											+ " (" + role + ")"
 							);
 						}
 						currentOrdering = token;
 					}
 					else {
 						//Add ordering of the previous
 						if ( currentOrdering == null ) {
 							//default ordering
 							ordering.add( "asc" );
 						}
 						else {
 							ordering.add( currentOrdering );
 							currentOrdering = null;
 						}
 						properties.add( token );
 					}
 				}
 				ordering.remove( 0 ); //first one is the algorithm starter
 				// add last one ordering
 				if ( currentOrdering == null ) {
 					//default ordering
 					ordering.add( "asc" );
 				}
 				else {
 					ordering.add( currentOrdering );
 					currentOrdering = null;
 				}
 				int index = 0;
 
 				for (String property : properties) {
 					Property p = BinderHelper.findPropertyByName( component, property );
 					if ( p == null ) {
 						throw new AnnotationException(
 								"property from @OrderBy clause not found: "
 										+ role + "." + property
 						);
 					}
 
 					Iterator propertyColumns = p.getColumnIterator();
 					while ( propertyColumns.hasNext() ) {
 						Selectable column = (Selectable) propertyColumns.next();
 						orderByBuffer.append( column.getText() )
 								.append( " " )
 								.append( ordering.get( index ) )
 								.append( ", " );
 					}
 					index++;
 				}
 
 				if ( orderByBuffer.length() >= 2 ) {
 					orderByString = orderByBuffer.substring( 0, orderByBuffer.length() - 2 );
 				}
 			}
 		}
 		return orderByString;
 	}
 
 	private static boolean isNonPropertyToken(String token) {
 		if ( " ".equals( token ) ) return true;
 		if ( ",".equals( token ) ) return true;
 		if ( token.equalsIgnoreCase( "desc" ) ) return true;
 		if ( token.equalsIgnoreCase( "asc" ) ) return true;
 		return false;
 	}
 
 	private static SimpleValue buildCollectionKey(
 			Collection collValue, Ejb3JoinColumn[] joinColumns, boolean cascadeDeleteEnabled,
 			XProperty property, Mappings mappings
 	) {
 		//binding key reference using column
 		KeyValue keyVal;
 		//give a chance to override the referenced property name
 		//has to do that here because the referencedProperty creation happens in a FKSecondPass for Many to one yuk!
 		if ( joinColumns.length > 0 && StringHelper.isNotEmpty( joinColumns[0].getMappedBy() ) ) {
 			String entityName = joinColumns[0].getManyToManyOwnerSideEntityName() != null ?
 					"inverse__" + joinColumns[0].getManyToManyOwnerSideEntityName() :
 					joinColumns[0].getPropertyHolder().getEntityName();
 			String propRef = mappings.getPropertyReferencedAssociation(
 					entityName,
 					joinColumns[0].getMappedBy()
 			);
 			if ( propRef != null ) {
 				collValue.setReferencedPropertyName( propRef );
 				mappings.addPropertyReference( collValue.getOwnerEntityName(), propRef );
 			}
 		}
 		String propRef = collValue.getReferencedPropertyName();
 		if ( propRef == null ) {
 			keyVal = collValue.getOwner().getIdentifier();
 		}
 		else {
 			keyVal = (KeyValue) collValue.getOwner()
 					.getRecursiveProperty( propRef )
 					.getValue();
 		}
 		DependantValue key = new DependantValue( mappings, collValue.getCollectionTable(), keyVal );
 		key.setTypeName( null );
 		Ejb3Column.checkPropertyConsistency( joinColumns, collValue.getOwnerEntityName() );
 		key.setNullable( joinColumns.length == 0 || joinColumns[0].isNullable() );
 		key.setUpdateable( joinColumns.length == 0 || joinColumns[0].isUpdatable() );
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
index 77048b41eb..335fdffdec 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
@@ -1,930 +1,930 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import javax.persistence.Access;
 import javax.persistence.Entity;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinTable;
 import javax.persistence.PrimaryKeyJoinColumn;
 import javax.persistence.SecondaryTable;
 import javax.persistence.SecondaryTables;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.BatchSize;
 import org.hibernate.annotations.Cache;
 import org.hibernate.annotations.CacheConcurrencyStrategy;
 import org.hibernate.annotations.FetchMode;
 import org.hibernate.annotations.Immutable;
 import org.hibernate.annotations.Loader;
 import org.hibernate.annotations.OptimisticLockType;
 import org.hibernate.annotations.Persister;
 import org.hibernate.annotations.PolymorphismType;
 import org.hibernate.annotations.Proxy;
 import org.hibernate.annotations.RowId;
 import org.hibernate.annotations.SQLDelete;
 import org.hibernate.annotations.SQLDeleteAll;
 import org.hibernate.annotations.SQLInsert;
 import org.hibernate.annotations.SQLUpdate;
 import org.hibernate.annotations.Subselect;
 import org.hibernate.annotations.Synchronize;
 import org.hibernate.annotations.Tables;
 import org.hibernate.annotations.Tuplizer;
 import org.hibernate.annotations.Tuplizers;
 import org.hibernate.annotations.Where;
 import org.hibernate.annotations.common.reflection.XAnnotatedElement;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.cfg.AccessType;
 import org.hibernate.cfg.AnnotationBinder;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.Ejb3JoinColumn;
 import org.hibernate.cfg.InheritanceState;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.cfg.ObjectNameSource;
 import org.hibernate.cfg.PropertyHolder;
 import org.hibernate.cfg.UniqueConstraintHolder;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Versioning;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.TableOwner;
 import org.hibernate.mapping.Value;
 
 /**
  * Stateful holder and processor for binding Entity information
  *
  * @author Emmanuel Bernard
  */
 public class EntityBinder {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, EntityBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityBinder.class.getName());
 
 	private String name;
 	private XClass annotatedClass;
 	private PersistentClass persistentClass;
 	private Mappings mappings;
 	private String discriminatorValue = "";
 	private Boolean forceDiscriminator;
 	private Boolean insertableDiscriminator;
 	private boolean dynamicInsert;
 	private boolean dynamicUpdate;
 	private boolean explicitHibernateEntityAnnotation;
 	private OptimisticLockType optimisticLockType;
 	private PolymorphismType polymorphismType;
 	private boolean selectBeforeUpdate;
 	private int batchSize;
 	private boolean lazy;
 	private XClass proxyClass;
 	private String where;
 	private java.util.Map<String, Join> secondaryTables = new HashMap<String, Join>();
 	private java.util.Map<String, Object> secondaryTableJoins = new HashMap<String, Object>();
 	private String cacheConcurrentStrategy;
 	private String cacheRegion;
 	private java.util.Map<String, String> filters = new HashMap<String, String>();
 	private InheritanceState inheritanceState;
 	private boolean ignoreIdAnnotations;
 	private boolean cacheLazyProperty;
 	private AccessType propertyAccessType = AccessType.DEFAULT;
 	private boolean wrapIdsInEmbeddedComponents;
 	private String subselect;
 
 	public boolean wrapIdsInEmbeddedComponents() {
 		return wrapIdsInEmbeddedComponents;
 	}
 
 	/**
 	 * Use as a fake one for Collection of elements
 	 */
 	public EntityBinder() {
 	}
 
 	public EntityBinder(
 			Entity ejb3Ann,
 			org.hibernate.annotations.Entity hibAnn,
 			XClass annotatedClass,
 			PersistentClass persistentClass,
 			Mappings mappings) {
 		this.mappings = mappings;
 		this.persistentClass = persistentClass;
 		this.annotatedClass = annotatedClass;
 		bindEjb3Annotation( ejb3Ann );
 		bindHibernateAnnotation( hibAnn );
 	}
 
 	private void bindHibernateAnnotation(org.hibernate.annotations.Entity hibAnn) {
 		if ( hibAnn != null ) {
 			dynamicInsert = hibAnn.dynamicInsert();
 			dynamicUpdate = hibAnn.dynamicUpdate();
 			optimisticLockType = hibAnn.optimisticLock();
 			selectBeforeUpdate = hibAnn.selectBeforeUpdate();
 			polymorphismType = hibAnn.polymorphism();
 			explicitHibernateEntityAnnotation = true;
 			//persister handled in bind
 		}
 		else {
 			//default values when the annotation is not there
 			dynamicInsert = false;
 			dynamicUpdate = false;
 			optimisticLockType = OptimisticLockType.VERSION;
 			polymorphismType = PolymorphismType.IMPLICIT;
 			selectBeforeUpdate = false;
 		}
 	}
 
 	private void bindEjb3Annotation(Entity ejb3Ann) {
 		if ( ejb3Ann == null ) throw new AssertionFailure( "@Entity should always be not null" );
 		if ( BinderHelper.isEmptyAnnotationValue( ejb3Ann.name() ) ) {
 			name = StringHelper.unqualify( annotatedClass.getName() );
 		}
 		else {
 			name = ejb3Ann.name();
 		}
 	}
 
 	public void setDiscriminatorValue(String discriminatorValue) {
 		this.discriminatorValue = discriminatorValue;
 	}
 
 	public void setForceDiscriminator(boolean forceDiscriminator) {
 		this.forceDiscriminator = forceDiscriminator;
 	}
 
 	public void setInsertableDiscriminator(boolean insertableDiscriminator) {
 		this.insertableDiscriminator = insertableDiscriminator;
 	}
 
 	public void bindEntity() {
 		persistentClass.setAbstract( annotatedClass.isAbstract() );
 		persistentClass.setClassName( annotatedClass.getName() );
 		persistentClass.setNodeName( name );
 		persistentClass.setJpaEntityName(name);
 		//persistentClass.setDynamic(false); //no longer needed with the Entity name refactoring?
 		persistentClass.setEntityName( annotatedClass.getName() );
 		bindDiscriminatorValue();
 
 		persistentClass.setLazy( lazy );
 		if ( proxyClass != null ) {
 			persistentClass.setProxyInterfaceName( proxyClass.getName() );
 		}
 		persistentClass.setDynamicInsert( dynamicInsert );
 		persistentClass.setDynamicUpdate( dynamicUpdate );
 
 		if ( persistentClass instanceof RootClass ) {
 			RootClass rootClass = (RootClass) persistentClass;
 			boolean mutable = true;
 			//priority on @Immutable, then @Entity.mutable()
 			if ( annotatedClass.isAnnotationPresent( Immutable.class ) ) {
 				mutable = false;
 			}
 			else {
 				org.hibernate.annotations.Entity entityAnn =
 						annotatedClass.getAnnotation( org.hibernate.annotations.Entity.class );
 				if ( entityAnn != null ) {
 					mutable = entityAnn.mutable();
 				}
 			}
 			rootClass.setMutable( mutable );
 			rootClass.setExplicitPolymorphism( isExplicitPolymorphism( polymorphismType ) );
 			if ( StringHelper.isNotEmpty( where ) ) rootClass.setWhere( where );
 			if ( cacheConcurrentStrategy != null ) {
 				rootClass.setCacheConcurrencyStrategy( cacheConcurrentStrategy );
 				rootClass.setCacheRegionName( cacheRegion );
 				rootClass.setLazyPropertiesCacheable( cacheLazyProperty );
 			}
 			if(forceDiscriminator != null) {
 				rootClass.setForceDiscriminator( forceDiscriminator );
 			}
 			if( insertableDiscriminator != null) {
 				rootClass.setDiscriminatorInsertable( insertableDiscriminator );
 			}
 		}
 		else {
             if (explicitHibernateEntityAnnotation) {
 				LOG.entityAnnotationOnNonRoot(annotatedClass.getName());
 			}
             if (annotatedClass.isAnnotationPresent(Immutable.class)) {
 				LOG.immutableAnnotationOnNonRoot(annotatedClass.getName());
 			}
 		}
 		persistentClass.setOptimisticLockMode( getVersioning( optimisticLockType ) );
 		persistentClass.setSelectBeforeUpdate( selectBeforeUpdate );
 
 		//set persister if needed
 		Persister persisterAnn = annotatedClass.getAnnotation( Persister.class );
 		Class persister = null;
 		if ( persisterAnn != null ) {
 			persister = persisterAnn.impl();
 		}
 		else {
 			org.hibernate.annotations.Entity entityAnn = annotatedClass.getAnnotation( org.hibernate.annotations.Entity.class );
 			if ( entityAnn != null && !BinderHelper.isEmptyAnnotationValue( entityAnn.persister() ) ) {
 				try {
 					persister = ReflectHelper.classForName( entityAnn.persister() );
 				}
 				catch (ClassNotFoundException cnfe) {
 					throw new AnnotationException( "Could not find persister class: " + persister );
 				}
 			}
 		}
 		if ( persister != null ) {
 			persistentClass.setEntityPersisterClass( persister );
 		}
 
 		persistentClass.setBatchSize( batchSize );
 
 		//SQL overriding
 		SQLInsert sqlInsert = annotatedClass.getAnnotation( SQLInsert.class );
 		SQLUpdate sqlUpdate = annotatedClass.getAnnotation( SQLUpdate.class );
 		SQLDelete sqlDelete = annotatedClass.getAnnotation( SQLDelete.class );
 		SQLDeleteAll sqlDeleteAll = annotatedClass.getAnnotation( SQLDeleteAll.class );
 		Loader loader = annotatedClass.getAnnotation( Loader.class );
 
 		if ( sqlInsert != null ) {
 			persistentClass.setCustomSQLInsert( sqlInsert.sql().trim(), sqlInsert.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlInsert.check().toString().toLowerCase() )
 			);
 
 		}
 		if ( sqlUpdate != null ) {
 			persistentClass.setCustomSQLUpdate( sqlUpdate.sql(), sqlUpdate.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlUpdate.check().toString().toLowerCase() )
 			);
 		}
 		if ( sqlDelete != null ) {
 			persistentClass.setCustomSQLDelete( sqlDelete.sql(), sqlDelete.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlDelete.check().toString().toLowerCase() )
 			);
 		}
 		if ( sqlDeleteAll != null ) {
 			persistentClass.setCustomSQLDelete( sqlDeleteAll.sql(), sqlDeleteAll.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlDeleteAll.check().toString().toLowerCase() )
 			);
 		}
 		if ( loader != null ) {
 			persistentClass.setLoaderName( loader.namedQuery() );
 		}
 
 		if ( annotatedClass.isAnnotationPresent( Synchronize.class )) {
 			Synchronize synchronizedWith = annotatedClass.getAnnotation(Synchronize.class);
 
 			String [] tables = synchronizedWith.value();
 			for (String table : tables) {
 				persistentClass.addSynchronizedTable(table);
 			}
 		}
 
 		if ( annotatedClass.isAnnotationPresent(Subselect.class )) {
 			Subselect subselect = annotatedClass.getAnnotation(Subselect.class);
 			this.subselect = subselect.value();
 		}
 
 		//tuplizers
 		if ( annotatedClass.isAnnotationPresent( Tuplizers.class ) ) {
 			for (Tuplizer tuplizer : annotatedClass.getAnnotation( Tuplizers.class ).value()) {
 				EntityMode mode = EntityMode.parse( tuplizer.entityMode() );
 				persistentClass.addTuplizer( mode, tuplizer.impl().getName() );
 			}
 		}
 		if ( annotatedClass.isAnnotationPresent( Tuplizer.class ) ) {
 			Tuplizer tuplizer = annotatedClass.getAnnotation( Tuplizer.class );
 			EntityMode mode = EntityMode.parse( tuplizer.entityMode() );
 			persistentClass.addTuplizer( mode, tuplizer.impl().getName() );
 		}
 
 		if ( !inheritanceState.hasParents() ) {
 			for ( Map.Entry<String, String> filter : filters.entrySet() ) {
 				String filterName = filter.getKey();
 				String cond = filter.getValue();
 				if ( BinderHelper.isEmptyAnnotationValue( cond ) ) {
 					FilterDefinition definition = mappings.getFilterDefinition( filterName );
 					cond = definition == null ? null : definition.getDefaultFilterCondition();
 					if ( StringHelper.isEmpty( cond ) ) {
 						throw new AnnotationException(
 								"no filter condition found for filter " + filterName + " in " + this.name
 						);
 					}
 				}
 				persistentClass.addFilter( filterName, cond );
 			}
         } else if (filters.size() > 0) LOG.filterAnnotationOnSubclass(persistentClass.getEntityName());
         LOG.debugf("Import with entity name %s", name);
 		try {
 			mappings.addImport( persistentClass.getEntityName(), name );
 			String entityName = persistentClass.getEntityName();
 			if ( !entityName.equals( name ) ) {
 				mappings.addImport( entityName, entityName );
 			}
 		}
 		catch (MappingException me) {
 			throw new AnnotationException( "Use of the same entity name twice: " + name, me );
 		}
 	}
 
 	public void bindDiscriminatorValue() {
 		if ( StringHelper.isEmpty( discriminatorValue ) ) {
 			Value discriminator = persistentClass.getDiscriminator();
 			if ( discriminator == null ) {
 				persistentClass.setDiscriminatorValue( name );
 			}
 			else if ( "character".equals( discriminator.getType().getName() ) ) {
 				throw new AnnotationException(
 						"Using default @DiscriminatorValue for a discriminator of type CHAR is not safe"
 				);
 			}
 			else if ( "integer".equals( discriminator.getType().getName() ) ) {
 				persistentClass.setDiscriminatorValue( String.valueOf( name.hashCode() ) );
 			}
 			else {
 				persistentClass.setDiscriminatorValue( name ); //Spec compliant
 			}
 		}
 		else {
 			//persistentClass.getDiscriminator()
 			persistentClass.setDiscriminatorValue( discriminatorValue );
 		}
 	}
 
 	int getVersioning(OptimisticLockType type) {
 		switch ( type ) {
 			case VERSION:
 				return Versioning.OPTIMISTIC_LOCK_VERSION;
 			case NONE:
 				return Versioning.OPTIMISTIC_LOCK_NONE;
 			case DIRTY:
 				return Versioning.OPTIMISTIC_LOCK_DIRTY;
 			case ALL:
 				return Versioning.OPTIMISTIC_LOCK_ALL;
 			default:
 				throw new AssertionFailure( "optimistic locking not supported: " + type );
 		}
 	}
 
 	private boolean isExplicitPolymorphism(PolymorphismType type) {
 		switch ( type ) {
 			case IMPLICIT:
 				return false;
 			case EXPLICIT:
 				return true;
 			default:
 				throw new AssertionFailure( "Unknown polymorphism type: " + type );
 		}
 	}
 
 	public void setBatchSize(BatchSize sizeAnn) {
 		if ( sizeAnn != null ) {
 			batchSize = sizeAnn.size();
 		}
 		else {
 			batchSize = -1;
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void setProxy(Proxy proxy) {
 		if ( proxy != null ) {
 			lazy = proxy.lazy();
 			if ( !lazy ) {
 				proxyClass = null;
 			}
 			else {
 				if ( AnnotationBinder.isDefault(
 						mappings.getReflectionManager().toXClass( proxy.proxyClass() ), mappings
 				) ) {
 					proxyClass = annotatedClass;
 				}
 				else {
 					proxyClass = mappings.getReflectionManager().toXClass( proxy.proxyClass() );
 				}
 			}
 		}
 		else {
 			lazy = true; //needed to allow association lazy loading.
 			proxyClass = annotatedClass;
 		}
 	}
 
 	public void setWhere(Where whereAnn) {
 		if ( whereAnn != null ) {
 			where = whereAnn.clause();
 		}
 	}
 
 	public void setWrapIdsInEmbeddedComponents(boolean wrapIdsInEmbeddedComponents) {
 		this.wrapIdsInEmbeddedComponents = wrapIdsInEmbeddedComponents;
 	}
 
 
 	private static class EntityTableObjectNameSource implements ObjectNameSource {
 		private final String explicitName;
 		private final String logicalName;
 
 		private EntityTableObjectNameSource(String explicitName, String entityName) {
 			this.explicitName = explicitName;
 			this.logicalName = StringHelper.isNotEmpty( explicitName )
 					? explicitName
 					: StringHelper.unqualify( entityName );
 		}
 
 		public String getExplicitName() {
 			return explicitName;
 		}
 
 		public String getLogicalName() {
 			return logicalName;
 		}
 	}
 
 	private static class EntityTableNamingStrategyHelper implements ObjectNameNormalizer.NamingStrategyHelper {
 		private final String entityName;
 
 		private EntityTableNamingStrategyHelper(String entityName) {
 			this.entityName = entityName;
 		}
 
 		public String determineImplicitName(NamingStrategy strategy) {
 			return strategy.classToTableName( entityName );
 		}
 
 		public String handleExplicitName(NamingStrategy strategy, String name) {
 			return strategy.tableName( name );
 		}
 	}
 
 	public void bindTable(
 			String schema,
 			String catalog,
 			String tableName,
 			List<UniqueConstraintHolder> uniqueConstraints,
 			String constraints,
 			Table denormalizedSuperclassTable) {
 		EntityTableObjectNameSource tableNameContext = new EntityTableObjectNameSource( tableName, name );
 		EntityTableNamingStrategyHelper namingStrategyHelper = new EntityTableNamingStrategyHelper( name );
 		final Table table = TableBinder.buildAndFillTable(
 				schema,
 				catalog,
 				tableNameContext,
 				namingStrategyHelper,
 				persistentClass.isAbstract(),
 				uniqueConstraints,
 				constraints,
 				denormalizedSuperclassTable,
 				mappings,
 				this.subselect
 		);
 		final RowId rowId = annotatedClass.getAnnotation( RowId.class );
 		if ( rowId != null ) {
 			table.setRowId( rowId.value() );
 		}
 
 		if ( persistentClass instanceof TableOwner ) {
-            LOG.bindEntityOnTable(persistentClass.getEntityName(), table.getName());
+            LOG.bindEntityOnTable( persistentClass.getEntityName(), table.getName() );
 			( (TableOwner) persistentClass ).setTable( table );
 		}
 		else {
 			throw new AssertionFailure( "binding a table for a subclass" );
 		}
 	}
 
 	public void finalSecondaryTableBinding(PropertyHolder propertyHolder) {
 		/*
 		 * Those operations has to be done after the id definition of the persistence class.
 		 * ie after the properties parsing
 		 */
 		Iterator joins = secondaryTables.values().iterator();
 		Iterator joinColumns = secondaryTableJoins.values().iterator();
 
 		while ( joins.hasNext() ) {
 			Object uncastedColumn = joinColumns.next();
 			Join join = (Join) joins.next();
 			createPrimaryColumnsToSecondaryTable( uncastedColumn, propertyHolder, join );
 		}
 		mappings.addJoins( persistentClass, secondaryTables );
 	}
 
 	private void createPrimaryColumnsToSecondaryTable(Object uncastedColumn, PropertyHolder propertyHolder, Join join) {
 		Ejb3JoinColumn[] ejb3JoinColumns;
 		PrimaryKeyJoinColumn[] pkColumnsAnn = null;
 		JoinColumn[] joinColumnsAnn = null;
 		if ( uncastedColumn instanceof PrimaryKeyJoinColumn[] ) {
 			pkColumnsAnn = (PrimaryKeyJoinColumn[]) uncastedColumn;
 		}
 		if ( uncastedColumn instanceof JoinColumn[] ) {
 			joinColumnsAnn = (JoinColumn[]) uncastedColumn;
 		}
 		if ( pkColumnsAnn == null && joinColumnsAnn == null ) {
 			ejb3JoinColumns = new Ejb3JoinColumn[1];
 			ejb3JoinColumns[0] = Ejb3JoinColumn.buildJoinColumn(
 					null,
 					null,
 					persistentClass.getIdentifier(),
 					secondaryTables,
 					propertyHolder, mappings
 			);
 		}
 		else {
 			int nbrOfJoinColumns = pkColumnsAnn != null ?
 					pkColumnsAnn.length :
 					joinColumnsAnn.length;
 			if ( nbrOfJoinColumns == 0 ) {
 				ejb3JoinColumns = new Ejb3JoinColumn[1];
 				ejb3JoinColumns[0] = Ejb3JoinColumn.buildJoinColumn(
 						null,
 						null,
 						persistentClass.getIdentifier(),
 						secondaryTables,
 						propertyHolder, mappings
 				);
 			}
 			else {
 				ejb3JoinColumns = new Ejb3JoinColumn[nbrOfJoinColumns];
 				if ( pkColumnsAnn != null ) {
 					for (int colIndex = 0; colIndex < nbrOfJoinColumns; colIndex++) {
 						ejb3JoinColumns[colIndex] = Ejb3JoinColumn.buildJoinColumn(
 								pkColumnsAnn[colIndex],
 								null,
 								persistentClass.getIdentifier(),
 								secondaryTables,
 								propertyHolder, mappings
 						);
 					}
 				}
 				else {
 					for (int colIndex = 0; colIndex < nbrOfJoinColumns; colIndex++) {
 						ejb3JoinColumns[colIndex] = Ejb3JoinColumn.buildJoinColumn(
 								null,
 								joinColumnsAnn[colIndex],
 								persistentClass.getIdentifier(),
 								secondaryTables,
 								propertyHolder, mappings
 						);
 					}
 				}
 			}
 		}
 
 		for (Ejb3JoinColumn joinColumn : ejb3JoinColumns) {
 			joinColumn.forceNotNull();
 		}
 		bindJoinToPersistentClass( join, ejb3JoinColumns, mappings );
 	}
 
 	private void bindJoinToPersistentClass(Join join, Ejb3JoinColumn[] ejb3JoinColumns, Mappings mappings) {
 		SimpleValue key = new DependantValue( mappings, join.getTable(), persistentClass.getIdentifier() );
 		join.setKey( key );
 		setFKNameIfDefined( join );
 		key.setCascadeDeleteEnabled( false );
 		TableBinder.bindFk( persistentClass, null, ejb3JoinColumns, key, false, mappings );
 		join.createPrimaryKey();
 		join.createForeignKey();
 		persistentClass.addJoin( join );
 	}
 
 	private void setFKNameIfDefined(Join join) {
 		org.hibernate.annotations.Table matchingTable = findMatchingComplimentTableAnnotation( join );
 		if ( matchingTable != null && !BinderHelper.isEmptyAnnotationValue( matchingTable.foreignKey().name() ) ) {
 			( (SimpleValue) join.getKey() ).setForeignKeyName( matchingTable.foreignKey().name() );
 		}
 	}
 
 	private org.hibernate.annotations.Table findMatchingComplimentTableAnnotation(Join join) {
 		String tableName = join.getTable().getQuotedName();
 		org.hibernate.annotations.Table table = annotatedClass.getAnnotation( org.hibernate.annotations.Table.class );
 		org.hibernate.annotations.Table matchingTable = null;
 		if ( table != null && tableName.equals( table.appliesTo() ) ) {
 			matchingTable = table;
 		}
 		else {
 			Tables tables = annotatedClass.getAnnotation( Tables.class );
 			if ( tables != null ) {
 				for (org.hibernate.annotations.Table current : tables.value()) {
 					if ( tableName.equals( current.appliesTo() ) ) {
 						matchingTable = current;
 						break;
 					}
 				}
 			}
 		}
 		return matchingTable;
 	}
 
 	public void firstLevelSecondaryTablesBinding(
 			SecondaryTable secTable, SecondaryTables secTables
 	) {
 		if ( secTables != null ) {
 			//loop through it
 			for (SecondaryTable tab : secTables.value()) {
 				addJoin( tab, null, null, false );
 			}
 		}
 		else {
 			if ( secTable != null ) addJoin( secTable, null, null, false );
 		}
 	}
 
 	//Used for @*ToMany @JoinTable
 	public Join addJoin(JoinTable joinTable, PropertyHolder holder, boolean noDelayInPkColumnCreation) {
 		return addJoin( null, joinTable, holder, noDelayInPkColumnCreation );
 	}
 
 	private static class SecondaryTableNameSource implements ObjectNameSource {
 		// always has an explicit name
 		private final String explicitName;
 
 		private SecondaryTableNameSource(String explicitName) {
 			this.explicitName = explicitName;
 		}
 
 		public String getExplicitName() {
 			return explicitName;
 		}
 
 		public String getLogicalName() {
 			return explicitName;
 		}
 	}
 
 	private static class SecondaryTableNamingStrategyHelper implements ObjectNameNormalizer.NamingStrategyHelper {
 		public String determineImplicitName(NamingStrategy strategy) {
 			// todo : throw an error?
 			return null;
 		}
 
 		public String handleExplicitName(NamingStrategy strategy, String name) {
 			return strategy.tableName( name );
 		}
 	}
 
 	private static SecondaryTableNamingStrategyHelper SEC_TBL_NS_HELPER = new SecondaryTableNamingStrategyHelper();
 
 	private Join addJoin(
 			SecondaryTable secondaryTable,
 			JoinTable joinTable,
 			PropertyHolder propertyHolder,
 			boolean noDelayInPkColumnCreation) {
 		// A non null propertyHolder means than we process the Pk creation without delay
 		Join join = new Join();
 		join.setPersistentClass( persistentClass );
 
 		final String schema;
 		final String catalog;
 		final SecondaryTableNameSource secondaryTableNameContext;
 		final Object joinColumns;
 		final List<UniqueConstraintHolder> uniqueConstraintHolders;
 
 		if ( secondaryTable != null ) {
 			schema = secondaryTable.schema();
 			catalog = secondaryTable.catalog();
 			secondaryTableNameContext = new SecondaryTableNameSource( secondaryTable.name() );
 			joinColumns = secondaryTable.pkJoinColumns();
 			uniqueConstraintHolders = TableBinder.buildUniqueConstraintHolders( secondaryTable.uniqueConstraints() );
 		}
 		else if ( joinTable != null ) {
 			schema = joinTable.schema();
 			catalog = joinTable.catalog();
 			secondaryTableNameContext = new SecondaryTableNameSource( joinTable.name() );
 			joinColumns = joinTable.joinColumns();
 			uniqueConstraintHolders = TableBinder.buildUniqueConstraintHolders( joinTable.uniqueConstraints() );
 		}
 		else {
 			throw new AssertionFailure( "Both JoinTable and SecondaryTable are null" );
 		}
 
 		final Table table = TableBinder.buildAndFillTable(
 				schema,
 				catalog,
 				secondaryTableNameContext,
 				SEC_TBL_NS_HELPER,
 				false,
 				uniqueConstraintHolders,
 				null,
 				null,
 				mappings,
 				null
 		);
 
 		//no check constraints available on joins
 		join.setTable( table );
 
 		//somehow keep joins() for later.
 		//Has to do the work later because it needs persistentClass id!
-        LOG.addingSecondaryTableToEntity(persistentClass.getEntityName(), join.getTable().getName());
+        LOG.addingSecondaryTableToEntity( persistentClass.getEntityName(), join.getTable().getName() );
 		org.hibernate.annotations.Table matchingTable = findMatchingComplimentTableAnnotation( join );
 		if ( matchingTable != null ) {
 			join.setSequentialSelect( FetchMode.JOIN != matchingTable.fetch() );
 			join.setInverse( matchingTable.inverse() );
 			join.setOptional( matchingTable.optional() );
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlInsert().sql() ) ) {
 				join.setCustomSQLInsert( matchingTable.sqlInsert().sql().trim(),
 						matchingTable.sqlInsert().callable(),
 						ExecuteUpdateResultCheckStyle.parse( matchingTable.sqlInsert().check().toString().toLowerCase() )
 				);
 			}
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlUpdate().sql() ) ) {
 				join.setCustomSQLUpdate( matchingTable.sqlUpdate().sql().trim(),
 						matchingTable.sqlUpdate().callable(),
 						ExecuteUpdateResultCheckStyle.parse( matchingTable.sqlUpdate().check().toString().toLowerCase() )
 				);
 			}
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlDelete().sql() ) ) {
 				join.setCustomSQLDelete( matchingTable.sqlDelete().sql().trim(),
 						matchingTable.sqlDelete().callable(),
 						ExecuteUpdateResultCheckStyle.parse( matchingTable.sqlDelete().check().toString().toLowerCase() )
 				);
 			}
 		}
 		else {
 			//default
 			join.setSequentialSelect( false );
 			join.setInverse( false );
 			join.setOptional( true ); //perhaps not quite per-spec, but a Good Thing anyway
 		}
 
 		if ( noDelayInPkColumnCreation ) {
 			createPrimaryColumnsToSecondaryTable( joinColumns, propertyHolder, join );
 		}
 		else {
 			secondaryTables.put( table.getQuotedName(), join );
 			secondaryTableJoins.put( table.getQuotedName(), joinColumns );
 		}
 		return join;
 	}
 
 	public java.util.Map<String, Join> getSecondaryTables() {
 		return secondaryTables;
 	}
 
 	public void setCache(Cache cacheAnn) {
 		if ( cacheAnn != null ) {
 			cacheRegion = BinderHelper.isEmptyAnnotationValue( cacheAnn.region() ) ?
 					null :
 					cacheAnn.region();
 			cacheConcurrentStrategy = getCacheConcurrencyStrategy( cacheAnn.usage() );
 			if ( "all".equalsIgnoreCase( cacheAnn.include() ) ) {
 				cacheLazyProperty = true;
 			}
 			else if ( "non-lazy".equalsIgnoreCase( cacheAnn.include() ) ) {
 				cacheLazyProperty = false;
 			}
 			else {
 				throw new AnnotationException( "Unknown lazy property annotations: " + cacheAnn.include() );
 			}
 		}
 		else {
 			cacheConcurrentStrategy = null;
 			cacheRegion = null;
 			cacheLazyProperty = true;
 		}
 	}
 
 	public static String getCacheConcurrencyStrategy(CacheConcurrencyStrategy strategy) {
 		org.hibernate.cache.access.AccessType accessType = strategy.toAccessType();
 		return accessType == null ? null : accessType.getName();
 	}
 
 	public void addFilter(String name, String condition) {
 		filters.put( name, condition );
 	}
 
 	public void setInheritanceState(InheritanceState inheritanceState) {
 		this.inheritanceState = inheritanceState;
 	}
 
 	public boolean isIgnoreIdAnnotations() {
 		return ignoreIdAnnotations;
 	}
 
 	public void setIgnoreIdAnnotations(boolean ignoreIdAnnotations) {
 		this.ignoreIdAnnotations = ignoreIdAnnotations;
 	}
 
 	public void processComplementaryTableDefinitions(org.hibernate.annotations.Table table) {
 		//comment and index are processed here
 		if ( table == null ) return;
 		String appliedTable = table.appliesTo();
 		Iterator tables = persistentClass.getTableClosureIterator();
 		Table hibTable = null;
 		while ( tables.hasNext() ) {
 			Table pcTable = (Table) tables.next();
 			if ( pcTable.getQuotedName().equals( appliedTable ) ) {
 				//we are in the correct table to find columns
 				hibTable = pcTable;
 				break;
 			}
 			hibTable = null;
 		}
 		if ( hibTable == null ) {
 			//maybe a join/secondary table
 			for ( Join join : secondaryTables.values() ) {
 				if ( join.getTable().getQuotedName().equals( appliedTable ) ) {
 					hibTable = join.getTable();
 					break;
 				}
 			}
 		}
 		if ( hibTable == null ) {
 			throw new AnnotationException(
 					"@org.hibernate.annotations.Table references an unknown table: " + appliedTable
 			);
 		}
 		if ( !BinderHelper.isEmptyAnnotationValue( table.comment() ) ) hibTable.setComment( table.comment() );
 		TableBinder.addIndexes( hibTable, table.indexes(), mappings );
 	}
 
 	public void processComplementaryTableDefinitions(Tables tables) {
 		if ( tables == null ) return;
 		for (org.hibernate.annotations.Table table : tables.value()) {
 			processComplementaryTableDefinitions( table );
 		}
 	}
 
 	public AccessType getPropertyAccessType() {
 		return propertyAccessType;
 	}
 
 	public void setPropertyAccessType(AccessType propertyAccessor) {
 		this.propertyAccessType = getExplicitAccessType( annotatedClass );
 		// only set the access type if there is no explicit access type for this class
 		if( this.propertyAccessType == null ) {
 			this.propertyAccessType = propertyAccessor;
 		}
 	}
 
 	public AccessType getPropertyAccessor(XAnnotatedElement element) {
 		AccessType accessType = getExplicitAccessType( element );
 		if ( accessType == null ) {
 		   accessType = propertyAccessType;
 		}
 		return accessType;
 	}
 
 	public AccessType getExplicitAccessType(XAnnotatedElement element) {
 		AccessType accessType = null;
 
 		AccessType hibernateAccessType = null;
 		AccessType jpaAccessType = null;
 
 		org.hibernate.annotations.AccessType accessTypeAnnotation = element.getAnnotation( org.hibernate.annotations.AccessType.class );
 		if ( accessTypeAnnotation != null ) {
 			hibernateAccessType = AccessType.getAccessStrategy( accessTypeAnnotation.value() );
 		}
 
 		Access access = element.getAnnotation( Access.class );
 		if ( access != null ) {
 			jpaAccessType = AccessType.getAccessStrategy( access.value() );
 		}
 
 		if ( hibernateAccessType != null && jpaAccessType != null && hibernateAccessType != jpaAccessType ) {
 			throw new MappingException(
 					"Found @Access and @AccessType with conflicting values on a property in class " + annotatedClass.toString()
 			);
 		}
 
 		if ( hibernateAccessType != null ) {
 			accessType = hibernateAccessType;
 		}
 		else if ( jpaAccessType != null ) {
 			accessType = jpaAccessType;
 		}
 
 		return accessType;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/ListBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/ListBinder.java
index 52f15c475b..676516ee69 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/ListBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/ListBinder.java
@@ -1,146 +1,146 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import java.util.Map;
 import org.hibernate.AnnotationException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.OrderBy;
 import org.hibernate.annotations.Sort;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.cfg.CollectionSecondPass;
 import org.hibernate.cfg.Ejb3Column;
 import org.hibernate.cfg.Ejb3JoinColumn;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.PropertyHolder;
 import org.hibernate.cfg.PropertyHolderBuilder;
 import org.hibernate.cfg.SecondPass;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.IndexBackref;
 import org.hibernate.mapping.List;
 import org.hibernate.mapping.OneToMany;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.SimpleValue;
 import org.jboss.logging.Logger;
 
 /**
  * Bind a list to the underlying Hibernate configuration
  *
  * @author Matthew Inger
  * @author Emmanuel Bernard
  */
 @SuppressWarnings({"unchecked", "serial"})
 public class ListBinder extends CollectionBinder {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ListBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ListBinder.class.getName());
 
 	public ListBinder() {
 	}
 
 	@Override
     protected Collection createCollection(PersistentClass persistentClass) {
 		return new org.hibernate.mapping.List( getMappings(), persistentClass );
 	}
 
 	@Override
     public void setSqlOrderBy(OrderBy orderByAnn) {
         if (orderByAnn != null) LOG.orderByAnnotationIndexedCollection();
 	}
 
 	@Override
     public void setSort(Sort sortAnn) {
         if (sortAnn != null) LOG.sortAnnotationIndexedCollection();
 	}
 
 	@Override
 	public SecondPass getSecondPass(
 			final Ejb3JoinColumn[] fkJoinColumns,
 			final Ejb3JoinColumn[] keyColumns,
 			final Ejb3JoinColumn[] inverseColumns,
 			final Ejb3Column[] elementColumns,
 			Ejb3Column[] mapKeyColumns,
 			final Ejb3JoinColumn[] mapKeyManyToManyColumns,
 			final boolean isEmbedded,
 			final XProperty property,
 			final XClass collType,
 			final boolean ignoreNotFound,
 			final boolean unique,
 			final TableBinder assocTableBinder,
 			final Mappings mappings) {
 		return new CollectionSecondPass( mappings, ListBinder.this.collection ) {
 			@Override
             public void secondPass(Map persistentClasses, Map inheritedMetas)
 					throws MappingException {
 				bindStarToManySecondPass(
 						persistentClasses, collType, fkJoinColumns, keyColumns, inverseColumns, elementColumns,
 						isEmbedded, property, unique, assocTableBinder, ignoreNotFound, mappings
 				);
 				bindIndex( mappings );
 			}
 		};
 	}
 
 	private void bindIndex(final Mappings mappings) {
 		if ( !indexColumn.isImplicit() ) {
 			PropertyHolder valueHolder = PropertyHolderBuilder.buildPropertyHolder(
 					this.collection,
 					StringHelper.qualify( this.collection.getRole(), "key" ),
 					(XClass) null,
 					(XProperty) null, propertyHolder, mappings
 			);
 			List list = (List) this.collection;
 			if ( !list.isOneToMany() ) indexColumn.forceNotNull();
 			indexColumn.setPropertyHolder( valueHolder );
 			SimpleValueBinder value = new SimpleValueBinder();
 			value.setColumns( new Ejb3Column[] { indexColumn } );
 			value.setExplicitType( "integer" );
 			value.setMappings( mappings );
 			SimpleValue indexValue = value.make();
 			indexColumn.linkWithValue( indexValue );
 			list.setIndex( indexValue );
 			list.setBaseIndex( indexColumn.getBase() );
 			if ( list.isOneToMany() && !list.getKey().isNullable() && !list.isInverse() ) {
 				String entityName = ( (OneToMany) list.getElement() ).getReferencedEntityName();
 				PersistentClass referenced = mappings.getClass( entityName );
 				IndexBackref ib = new IndexBackref();
 				ib.setName( '_' + propertyName + "IndexBackref" );
 				ib.setUpdateable( false );
 				ib.setSelectable( false );
 				ib.setCollectionRole( list.getRole() );
 				ib.setEntityName( list.getOwner().getEntityName() );
 				ib.setValue( list.getIndex() );
 				referenced.addProperty( ib );
 			}
 		}
 		else {
 			Collection coll = this.collection;
 			throw new AnnotationException(
 					"List/array has to be annotated with an @OrderColumn (or @IndexColumn): "
 							+ coll.getRole()
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/PropertyBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/PropertyBinder.java
index 5a6e8acfac..b0cf0ec6a6 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/PropertyBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/PropertyBinder.java
@@ -1,339 +1,340 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import java.util.Map;
 import javax.persistence.EmbeddedId;
 import javax.persistence.Id;
 import org.hibernate.AnnotationException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.annotations.Generated;
 import org.hibernate.annotations.GenerationTime;
 import org.hibernate.annotations.Immutable;
 import org.hibernate.annotations.NaturalId;
 import org.hibernate.annotations.OptimisticLock;
 import org.hibernate.annotations.common.AssertionFailure;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.cfg.AccessType;
 import org.hibernate.cfg.AnnotationBinder;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.Ejb3Column;
 import org.hibernate.cfg.InheritanceState;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.PropertyHolder;
 import org.hibernate.cfg.PropertyPreloadedData;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.PropertyGeneration;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Value;
+
 import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 public class PropertyBinder {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, PropertyBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, PropertyBinder.class.getName());
 
 	private String name;
 	private String returnedClassName;
 	private boolean lazy;
 	private AccessType accessType;
 	private Ejb3Column[] columns;
 	private PropertyHolder holder;
 	private Mappings mappings;
 	private Value value;
 	private boolean insertable = true;
 	private boolean updatable = true;
 	private String cascade;
 	private SimpleValueBinder simpleValueBinder;
 	private XClass declaringClass;
 	private boolean declaringClassSet;
 	private boolean embedded;
 	private EntityBinder entityBinder;
 	private boolean isXToMany;
 	private String referencedEntityName;
 
 	public void setReferencedEntityName(String referencedEntityName) {
 		this.referencedEntityName = referencedEntityName;
 	}
 
 	public void setEmbedded(boolean embedded) {
 		this.embedded = embedded;
 	}
 
 	public void setEntityBinder(EntityBinder entityBinder) {
 		this.entityBinder = entityBinder;
 	}
 
 	/*
 			 * property can be null
 			 * prefer propertyName to property.getName() since some are overloaded
 			 */
 	private XProperty property;
 	private XClass returnedClass;
 	private boolean isId;
 	private Map<XClass, InheritanceState> inheritanceStatePerClass;
 	private Property mappingProperty;
 
 	public void setInsertable(boolean insertable) {
 		this.insertable = insertable;
 	}
 
 	public void setUpdatable(boolean updatable) {
 		this.updatable = updatable;
 	}
 
 	public void setName(String name) {
 		this.name = name;
 	}
 
 	public void setReturnedClassName(String returnedClassName) {
 		this.returnedClassName = returnedClassName;
 	}
 
 	public void setLazy(boolean lazy) {
 		this.lazy = lazy;
 	}
 
 	public void setAccessType(AccessType accessType) {
 		this.accessType = accessType;
 	}
 
 	public void setColumns(Ejb3Column[] columns) {
 		insertable = columns[0].isInsertable();
 		updatable = columns[0].isUpdatable();
 		//consistency is checked later when we know the property name
 		this.columns = columns;
 	}
 
 	public void setHolder(PropertyHolder holder) {
 		this.holder = holder;
 	}
 
 	public void setValue(Value value) {
 		this.value = value;
 	}
 
 	public void setCascade(String cascadeStrategy) {
 		this.cascade = cascadeStrategy;
 	}
 
 	public void setMappings(Mappings mappings) {
 		this.mappings = mappings;
 	}
 
 	public void setDeclaringClass(XClass declaringClass) {
 		this.declaringClass = declaringClass;
 		this.declaringClassSet = true;
 	}
 
 	private void validateBind() {
 		if ( property.isAnnotationPresent( Immutable.class ) ) {
 			throw new AnnotationException(
 					"@Immutable on property not allowed. " +
 							"Only allowed on entity level or on a collection."
 			);
 		}
 		if ( !declaringClassSet ) {
 			throw new AssertionFailure( "declaringClass has not been set before a bind" );
 		}
 	}
 
 	private void validateMake() {
 		//TODO check necessary params for a make
 	}
 
 	private Property makePropertyAndValue() {
 		validateBind();
         LOG.debugf("Binder property %s with lazy=%s", name, lazy);
 		String containerClassName = holder == null ?
 				null :
 				holder.getClassName();
 		simpleValueBinder = new SimpleValueBinder();
 		simpleValueBinder.setMappings( mappings );
 		simpleValueBinder.setPropertyName( name );
 		simpleValueBinder.setReturnedClassName( returnedClassName );
 		simpleValueBinder.setColumns( columns );
 		simpleValueBinder.setPersistentClassName( containerClassName );
 		simpleValueBinder.setType( property, returnedClass );
 		simpleValueBinder.setMappings( mappings );
 		simpleValueBinder.setReferencedEntityName( referencedEntityName );
 		SimpleValue propertyValue = simpleValueBinder.make();
 		setValue( propertyValue );
 		return makeProperty();
 	}
 
 	//used when value is provided
 	public Property makePropertyAndBind() {
 		return bind( makeProperty() );
 	}
 
 	//used to build everything from scratch
 	public Property makePropertyValueAndBind() {
 		return bind( makePropertyAndValue() );
 	}
 
 	public void setXToMany(boolean xToMany) {
 		this.isXToMany = xToMany;
 	}
 
 	private Property bind(Property prop) {
 		if (isId) {
 			final RootClass rootClass = ( RootClass ) holder.getPersistentClass();
 			//if an xToMany, it as to be wrapped today.
 			//FIXME this pose a problem as the PK is the class instead of the associated class which is not really compliant with the spec
 			if ( isXToMany || entityBinder.wrapIdsInEmbeddedComponents() ) {
 				Component identifier = (Component) rootClass.getIdentifier();
 				if (identifier == null) {
 					identifier = AnnotationBinder.createComponent( holder, new PropertyPreloadedData(null, null, null), true, false, mappings );
 					rootClass.setIdentifier( identifier );
 					identifier.setNullValue( "undefined" );
 					rootClass.setEmbeddedIdentifier( true );
 					rootClass.setIdentifierMapper( identifier );
 				}
 				//FIXME is it good enough?
 				identifier.addProperty( prop );
 			}
 			else {
 				rootClass.setIdentifier( ( KeyValue ) getValue() );
 				if (embedded) {
 					rootClass.setEmbeddedIdentifier( true );
 				}
 				else {
 					rootClass.setIdentifierProperty( prop );
 					final org.hibernate.mapping.MappedSuperclass superclass = BinderHelper.getMappedSuperclassOrNull(
 							declaringClass,
 							inheritanceStatePerClass,
 							mappings
 					);
 					if (superclass != null) {
 						superclass.setDeclaredIdentifierProperty(prop);
 					}
 					else {
 						//we know the property is on the actual entity
 						rootClass.setDeclaredIdentifierProperty( prop );
 					}
 				}
 			}
 		}
 		else {
 			holder.addProperty( prop, columns, declaringClass );
 		}
 		return prop;
 	}
 
 	//used when the value is provided and the binding is done elsewhere
 	public Property makeProperty() {
 		validateMake();
         LOG.debugf("Building property %s", name);
 		Property prop = new Property();
 		prop.setName( name );
 		prop.setNodeName( name );
 		prop.setValue( value );
 		prop.setLazy( lazy );
 		prop.setCascade( cascade );
 		prop.setPropertyAccessorName( accessType.getType() );
 		Generated ann = property != null ?
 				property.getAnnotation( Generated.class ) :
 				null;
 		GenerationTime generated = ann != null ?
 				ann.value() :
 				null;
 		if ( generated != null ) {
 			if ( !GenerationTime.NEVER.equals( generated ) ) {
 				if ( property.isAnnotationPresent( javax.persistence.Version.class )
 						&& GenerationTime.INSERT.equals( generated ) ) {
 					throw new AnnotationException(
 							"@Generated(INSERT) on a @Version property not allowed, use ALWAYS: "
 									+ StringHelper.qualify( holder.getPath(), name )
 					);
 				}
 				insertable = false;
 				if ( GenerationTime.ALWAYS.equals( generated ) ) {
 					updatable = false;
 				}
 				prop.setGeneration( PropertyGeneration.parse( generated.toString().toLowerCase() ) );
 			}
 		}
 		NaturalId naturalId = property != null ?
 				property.getAnnotation( NaturalId.class ) :
 				null;
 		if ( naturalId != null ) {
 			if ( !naturalId.mutable() ) {
 				updatable = false;
 			}
 			prop.setNaturalIdentifier( true );
 		}
 		prop.setInsertable( insertable );
 		prop.setUpdateable( updatable );
 		OptimisticLock lockAnn = property != null ?
 				property.getAnnotation( OptimisticLock.class ) :
 				null;
 		if ( lockAnn != null ) {
 			prop.setOptimisticLocked( !lockAnn.excluded() );
 			//TODO this should go to the core as a mapping validation checking
 			if ( lockAnn.excluded() && (
 					property.isAnnotationPresent( javax.persistence.Version.class )
 							|| property.isAnnotationPresent( Id.class )
 							|| property.isAnnotationPresent( EmbeddedId.class ) ) ) {
 				throw new AnnotationException(
 						"@OptimisticLock.exclude=true incompatible with @Id, @EmbeddedId and @Version: "
 								+ StringHelper.qualify( holder.getPath(), name )
 				);
 			}
 		}
         LOG.trace("Cascading " + name + " with " + cascade);
 		this.mappingProperty = prop;
 		return prop;
 	}
 
 	public void setProperty(XProperty property) {
 		this.property = property;
 	}
 
 	public void setReturnedClass(XClass returnedClass) {
 		this.returnedClass = returnedClass;
 	}
 
 	public SimpleValueBinder getSimpleValueBinder() {
 		return simpleValueBinder;
 	}
 
 	public Value getValue() {
 		return value;
 	}
 
 	public void setId(boolean id) {
 		this.isId = id;
 	}
 
 	public void setInheritanceStatePerClass(Map<XClass, InheritanceState> inheritanceStatePerClass) {
 		this.inheritanceStatePerClass = inheritanceStatePerClass;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/QueryBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/QueryBinder.java
index 7f63db2f74..c0ed9a5142 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/QueryBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/QueryBinder.java
@@ -1,417 +1,418 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 import java.util.HashMap;
 import javax.persistence.NamedNativeQueries;
 import javax.persistence.NamedNativeQuery;
 import javax.persistence.NamedQueries;
 import javax.persistence.NamedQuery;
 import javax.persistence.QueryHint;
 import javax.persistence.SqlResultSetMapping;
 import javax.persistence.SqlResultSetMappings;
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.annotations.CacheModeType;
 import org.hibernate.annotations.FlushModeType;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.query.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.sql.NativeSQLQueryRootReturn;
+
 import org.jboss.logging.Logger;
 
 /**
  * Query binder
  *
  * @author Emmanuel Bernard
  */
 public abstract class QueryBinder {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, QueryBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QueryBinder.class.getName());
 
 	public static void bindQuery(NamedQuery queryAnn, Mappings mappings, boolean isDefault) {
 		if ( queryAnn == null ) return;
         if (BinderHelper.isEmptyAnnotationValue(queryAnn.name())) throw new AnnotationException(
                                                                                                 "A named query must have a name when used in class or package level");
 		//EJBQL Query
 		QueryHint[] hints = queryAnn.hints();
 		String queryName = queryAnn.query();
 		NamedQueryDefinition query = new NamedQueryDefinition(
 				queryName,
 				getBoolean( queryName, "org.hibernate.cacheable", hints ),
 				getString( queryName, "org.hibernate.cacheRegion", hints ),
 				getTimeout( queryName, hints ),
 				getInteger( queryName, "org.hibernate.fetchSize", hints ),
 				getFlushMode( queryName, hints ),
 				getCacheMode( queryName, hints ),
 				getBoolean( queryName, "org.hibernate.readOnly", hints ),
 				getString( queryName, "org.hibernate.comment", hints ),
 				null
 		);
 		if ( isDefault ) {
 			mappings.addDefaultQuery( queryAnn.name(), query );
 		}
 		else {
 			mappings.addQuery( queryAnn.name(), query );
 		}
-        LOG.bindingNamedQuery(queryAnn.name(), queryAnn.query());
+        LOG.bindingNamedQuery( queryAnn.name(), queryAnn.query() );
 	}
 
 
 	public static void bindNativeQuery(NamedNativeQuery queryAnn, Mappings mappings, boolean isDefault) {
 		if ( queryAnn == null ) return;
 		//ResultSetMappingDefinition mappingDefinition = mappings.getResultSetMapping( queryAnn.resultSetMapping() );
         if (BinderHelper.isEmptyAnnotationValue(queryAnn.name())) throw new AnnotationException(
                                                                                                 "A named query must have a name when used in class or package level");
 		NamedSQLQueryDefinition query;
 		String resultSetMapping = queryAnn.resultSetMapping();
 		QueryHint[] hints = queryAnn.hints();
 		String queryName = queryAnn.query();
 		if ( !BinderHelper.isEmptyAnnotationValue( resultSetMapping ) ) {
 			//sql result set usage
 			query = new NamedSQLQueryDefinition(
 					queryName,
 					resultSetMapping,
 					null,
 					getBoolean( queryName, "org.hibernate.cacheable", hints ),
 					getString( queryName, "org.hibernate.cacheRegion", hints ),
 					getTimeout( queryName, hints ),
 					getInteger( queryName, "org.hibernate.fetchSize", hints ),
 					getFlushMode( queryName, hints ),
 					getCacheMode( queryName, hints ),
 					getBoolean( queryName, "org.hibernate.readOnly", hints ),
 					getString( queryName, "org.hibernate.comment", hints ),
 					null,
 					getBoolean( queryName, "org.hibernate.callable", hints )
 			);
 		}
 		else if ( !void.class.equals( queryAnn.resultClass() ) ) {
 			//class mapping usage
 			//FIXME should be done in a second pass due to entity name?
 			final NativeSQLQueryRootReturn entityQueryReturn =
 					new NativeSQLQueryRootReturn( "alias1", queryAnn.resultClass().getName(), new HashMap(), LockMode.READ );
 			query = new NamedSQLQueryDefinition(
 					queryName,
 					new NativeSQLQueryReturn[] { entityQueryReturn },
 					null,
 					getBoolean( queryName, "org.hibernate.cacheable", hints ),
 					getString( queryName, "org.hibernate.cacheRegion", hints ),
 					getTimeout( queryName, hints ),
 					getInteger( queryName, "org.hibernate.fetchSize", hints ),
 					getFlushMode( queryName, hints ),
 					getCacheMode( queryName, hints ),
 					getBoolean( queryName, "org.hibernate.readOnly", hints ),
 					getString( queryName, "org.hibernate.comment", hints ),
 					null,
 					getBoolean( queryName, "org.hibernate.callable", hints )
 			);
 		}
 		else {
 			throw new NotYetImplementedException( "Pure native scalar queries are not yet supported" );
 		}
 		if ( isDefault ) {
 			mappings.addDefaultSQLQuery( queryAnn.name(), query );
 		}
 		else {
 			mappings.addSQLQuery( queryAnn.name(), query );
 		}
-        LOG.bindingNamedNativeQuery(queryAnn.name(), queryAnn.query());
+        LOG.bindingNamedNativeQuery( queryAnn.name(), queryAnn.query() );
 	}
 
 	public static void bindNativeQuery(org.hibernate.annotations.NamedNativeQuery queryAnn, Mappings mappings) {
 		if ( queryAnn == null ) return;
 		//ResultSetMappingDefinition mappingDefinition = mappings.getResultSetMapping( queryAnn.resultSetMapping() );
         if (BinderHelper.isEmptyAnnotationValue(queryAnn.name())) throw new AnnotationException(
                                                                                                 "A named query must have a name when used in class or package level");
         NamedSQLQueryDefinition query;
 		String resultSetMapping = queryAnn.resultSetMapping();
 		if ( !BinderHelper.isEmptyAnnotationValue( resultSetMapping ) ) {
 			//sql result set usage
 			query = new NamedSQLQueryDefinition(
 					queryAnn.query(),
 					resultSetMapping,
 					null,
 					queryAnn.cacheable(),
 					BinderHelper.isEmptyAnnotationValue( queryAnn.cacheRegion() ) ? null : queryAnn.cacheRegion(),
 					queryAnn.timeout() < 0 ? null : queryAnn.timeout(),
 					queryAnn.fetchSize() < 0 ? null : queryAnn.fetchSize(),
 					getFlushMode( queryAnn.flushMode() ),
 					getCacheMode( queryAnn.cacheMode() ),
 					queryAnn.readOnly(),
 					BinderHelper.isEmptyAnnotationValue( queryAnn.comment() ) ? null : queryAnn.comment(),
 					null,
 					queryAnn.callable()
 			);
 		}
 		else if ( !void.class.equals( queryAnn.resultClass() ) ) {
 			//class mapping usage
 			//FIXME should be done in a second pass due to entity name?
 			final NativeSQLQueryRootReturn entityQueryReturn =
 					new NativeSQLQueryRootReturn( "alias1", queryAnn.resultClass().getName(), new HashMap(), LockMode.READ );
 			query = new NamedSQLQueryDefinition(
 					queryAnn.query(),
 					new NativeSQLQueryReturn[] { entityQueryReturn },
 					null,
 					queryAnn.cacheable(),
 					BinderHelper.isEmptyAnnotationValue( queryAnn.cacheRegion() ) ? null : queryAnn.cacheRegion(),
 					queryAnn.timeout() < 0 ? null : queryAnn.timeout(),
 					queryAnn.fetchSize() < 0 ? null : queryAnn.fetchSize(),
 					getFlushMode( queryAnn.flushMode() ),
 					getCacheMode( queryAnn.cacheMode() ),
 					queryAnn.readOnly(),
 					BinderHelper.isEmptyAnnotationValue( queryAnn.comment() ) ? null : queryAnn.comment(),
 					null,
 					queryAnn.callable()
 			);
 		}
 		else {
 			throw new NotYetImplementedException( "Pure native scalar queries are not yet supported" );
 		}
 		mappings.addSQLQuery( queryAnn.name(), query );
-        LOG.bindingNamedNativeQuery(queryAnn.name(), queryAnn.query());
+        LOG.bindingNamedNativeQuery( queryAnn.name(), queryAnn.query() );
 	}
 
 	public static void bindQueries(NamedQueries queriesAnn, Mappings mappings, boolean isDefault) {
 		if ( queriesAnn == null ) return;
 		for (NamedQuery q : queriesAnn.value()) {
 			bindQuery( q, mappings, isDefault );
 		}
 	}
 
 	public static void bindNativeQueries(NamedNativeQueries queriesAnn, Mappings mappings, boolean isDefault) {
 		if ( queriesAnn == null ) return;
 		for (NamedNativeQuery q : queriesAnn.value()) {
 			bindNativeQuery( q, mappings, isDefault );
 		}
 	}
 
 	public static void bindNativeQueries(
 			org.hibernate.annotations.NamedNativeQueries queriesAnn, Mappings mappings
 	) {
 		if ( queriesAnn == null ) return;
 		for (org.hibernate.annotations.NamedNativeQuery q : queriesAnn.value()) {
 			bindNativeQuery( q, mappings );
 		}
 	}
 
 	public static void bindQuery(org.hibernate.annotations.NamedQuery queryAnn, Mappings mappings) {
 		if ( queryAnn == null ) return;
         if (BinderHelper.isEmptyAnnotationValue(queryAnn.name())) throw new AnnotationException(
                                                                                                 "A named query must have a name when used in class or package level");
 		FlushMode flushMode;
 		flushMode = getFlushMode( queryAnn.flushMode() );
 
 		NamedQueryDefinition query = new NamedQueryDefinition(
 				queryAnn.query(),
 				queryAnn.cacheable(),
 				BinderHelper.isEmptyAnnotationValue( queryAnn.cacheRegion() ) ? null : queryAnn.cacheRegion(),
 				queryAnn.timeout() < 0 ? null : queryAnn.timeout(),
 				queryAnn.fetchSize() < 0 ? null : queryAnn.fetchSize(),
 				flushMode,
 				getCacheMode( queryAnn.cacheMode() ),
 				queryAnn.readOnly(),
 				BinderHelper.isEmptyAnnotationValue( queryAnn.comment() ) ? null : queryAnn.comment(),
 				null
 		);
 
 		mappings.addQuery( queryAnn.name(), query );
-        LOG.bindingNamedQuery(queryAnn.name(), queryAnn.query());
+        LOG.bindingNamedQuery( queryAnn.name(), queryAnn.query() );
 	}
 
 	private static FlushMode getFlushMode(FlushModeType flushModeType) {
 		FlushMode flushMode;
 		switch ( flushModeType ) {
 			case ALWAYS:
 				flushMode = FlushMode.ALWAYS;
 				break;
 			case AUTO:
 				flushMode = FlushMode.AUTO;
 				break;
 			case COMMIT:
 				flushMode = FlushMode.COMMIT;
 				break;
 			case NEVER:
 				flushMode = FlushMode.MANUAL;
 				break;
 			case MANUAL:
 				flushMode = FlushMode.MANUAL;
 				break;
 			case PERSISTENCE_CONTEXT:
 				flushMode = null;
 				break;
 			default:
 				throw new AssertionFailure( "Unknown flushModeType: " + flushModeType );
 		}
 		return flushMode;
 	}
 
 	private static CacheMode getCacheMode(CacheModeType cacheModeType) {
 		switch ( cacheModeType ) {
 			case GET:
 				return CacheMode.GET;
 			case IGNORE:
 				return CacheMode.IGNORE;
 			case NORMAL:
 				return CacheMode.NORMAL;
 			case PUT:
 				return CacheMode.PUT;
 			case REFRESH:
 				return CacheMode.REFRESH;
 			default:
 				throw new AssertionFailure( "Unknown cacheModeType: " + cacheModeType );
 		}
 	}
 
 
 	public static void bindQueries(org.hibernate.annotations.NamedQueries queriesAnn, Mappings mappings) {
 		if ( queriesAnn == null ) return;
 		for (org.hibernate.annotations.NamedQuery q : queriesAnn.value()) {
 			bindQuery( q, mappings );
 		}
 	}
 
 	public static void bindSqlResultsetMappings(SqlResultSetMappings ann, Mappings mappings, boolean isDefault) {
 		if ( ann == null ) return;
 		for (SqlResultSetMapping rs : ann.value()) {
 			//no need to handle inSecondPass
 			mappings.addSecondPass( new ResultsetMappingSecondPass( rs, mappings, true ) );
 		}
 	}
 
 	public static void bindSqlResultsetMapping(SqlResultSetMapping ann, Mappings mappings, boolean isDefault) {
 		//no need to handle inSecondPass
 		mappings.addSecondPass( new ResultsetMappingSecondPass( ann, mappings, isDefault ) );
 	}
 
 	private static CacheMode getCacheMode(String query, QueryHint[] hints) {
 		for (QueryHint hint : hints) {
 			if ( "org.hibernate.cacheMode".equals( hint.name() ) ) {
 				if ( hint.value().equalsIgnoreCase( CacheMode.GET.toString() ) ) {
 					return CacheMode.GET;
 				}
 				else if ( hint.value().equalsIgnoreCase( CacheMode.IGNORE.toString() ) ) {
 					return CacheMode.IGNORE;
 				}
 				else if ( hint.value().equalsIgnoreCase( CacheMode.NORMAL.toString() ) ) {
 					return CacheMode.NORMAL;
 				}
 				else if ( hint.value().equalsIgnoreCase( CacheMode.PUT.toString() ) ) {
 					return CacheMode.PUT;
 				}
 				else if ( hint.value().equalsIgnoreCase( CacheMode.REFRESH.toString() ) ) {
 					return CacheMode.REFRESH;
 				}
 				else {
 					throw new AnnotationException( "Unknown CacheMode in hint: " + query + ":" + hint.name() );
 				}
 			}
 		}
 		return null;
 	}
 
 	private static FlushMode getFlushMode(String query, QueryHint[] hints) {
 		for (QueryHint hint : hints) {
 			if ( "org.hibernate.flushMode".equals( hint.name() ) ) {
 				if ( hint.value().equalsIgnoreCase( FlushMode.ALWAYS.toString() ) ) {
 					return FlushMode.ALWAYS;
 				}
 				else if ( hint.value().equalsIgnoreCase( FlushMode.AUTO.toString() ) ) {
 					return FlushMode.AUTO;
 				}
 				else if ( hint.value().equalsIgnoreCase( FlushMode.COMMIT.toString() ) ) {
 					return FlushMode.COMMIT;
 				}
 				else if ( hint.value().equalsIgnoreCase( FlushMode.NEVER.toString() ) ) {
 					return FlushMode.MANUAL;
 				}
 				else if ( hint.value().equalsIgnoreCase( FlushMode.MANUAL.toString() ) ) {
 					return FlushMode.MANUAL;
 				}
 				else {
 					throw new AnnotationException( "Unknown FlushMode in hint: " + query + ":" + hint.name() );
 				}
 			}
 		}
 		return null;
 	}
 
 	private static boolean getBoolean(String query, String hintName, QueryHint[] hints) {
 		for (QueryHint hint : hints) {
 			if ( hintName.equals( hint.name() ) ) {
 				if ( hint.value().equalsIgnoreCase( "true" ) ) {
 					return true;
 				}
 				else if ( hint.value().equalsIgnoreCase( "false" ) ) {
 					return false;
 				}
 				else {
 					throw new AnnotationException( "Not a boolean in hint: " + query + ":" + hint.name() );
 				}
 			}
 		}
 		return false;
 	}
 
 	private static String getString(String query, String hintName, QueryHint[] hints) {
 		for (QueryHint hint : hints) {
 			if ( hintName.equals( hint.name() ) ) {
 				return hint.value();
 			}
 		}
 		return null;
 	}
 
 	private static Integer getInteger(String query, String hintName, QueryHint[] hints) {
 		for (QueryHint hint : hints) {
 			if ( hintName.equals( hint.name() ) ) {
 				try {
 					return Integer.decode( hint.value() );
 				}
 				catch (NumberFormatException nfe) {
 					throw new AnnotationException( "Not an integer in hint: " + query + ":" + hint.name(), nfe );
 				}
 			}
 		}
 		return null;
 	}
 
 	private static Integer getTimeout(String queryName, QueryHint[] hints) {
 		Integer timeout = getInteger( queryName, "javax.persistence.query.timeout", hints );
 
 		if ( timeout != null ) {
 			// convert milliseconds to seconds
 			timeout = new Integer ((int)Math.round(timeout.doubleValue() / 1000.0 ) );
 		}
 		else {
 			// timeout is already in seconds
 			timeout = getInteger( queryName, "org.hibernate.timeout", hints );
 		}
 		return timeout;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/ResultsetMappingSecondPass.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/ResultsetMappingSecondPass.java
index cc1433bb2d..acb979b64f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/ResultsetMappingSecondPass.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/ResultsetMappingSecondPass.java
@@ -1,269 +1,270 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.ColumnResult;
 import javax.persistence.EntityResult;
 import javax.persistence.FieldResult;
 import javax.persistence.SqlResultSetMapping;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.QuerySecondPass;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.query.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.query.sql.NativeSQLQueryScalarReturn;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.ToOne;
 import org.hibernate.mapping.Value;
 import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 public class ResultsetMappingSecondPass implements QuerySecondPass {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        ResultsetMappingSecondPass.class.getName());
 
 	private SqlResultSetMapping ann;
 	private Mappings mappings;
 	private boolean isDefault;
 
 	public ResultsetMappingSecondPass(SqlResultSetMapping ann, Mappings mappings, boolean isDefault) {
 		this.ann = ann;
 		this.mappings = mappings;
 		this.isDefault = isDefault;
 	}
 
 	public void doSecondPass(Map persistentClasses) throws MappingException {
 		//TODO add parameters checkings
 		if ( ann == null ) return;
 		ResultSetMappingDefinition definition = new ResultSetMappingDefinition( ann.name() );
-        LOG.bindingResultSetMapping(definition.getName());
+        LOG.bindingResultSetMapping( definition.getName() );
 
 		int entityAliasIndex = 0;
 
 		for (EntityResult entity : ann.entities()) {
 			//TODO parameterize lock mode?
 			List<FieldResult> properties = new ArrayList<FieldResult>();
 			List<String> propertyNames = new ArrayList<String>();
 			for (FieldResult field : entity.fields()) {
 				//use an ArrayList cause we might have several columns per root property
 				String name = field.name();
 				if ( name.indexOf( '.' ) == -1 ) {
 					//regular property
 					properties.add( field );
 					propertyNames.add( name );
 				}
 				else {
 					/**
 					 * Reorder properties
 					 * 1. get the parent property
 					 * 2. list all the properties following the expected one in the parent property
 					 * 3. calculate the lowest index and insert the property
 					 */
 					PersistentClass pc = mappings.getClass( entity.entityClass().getName() );
 					if ( pc == null ) {
 						throw new MappingException(
 								"Entity not found " + entity.entityClass().getName()
 										+ " in SqlResultsetMapping " + ann.name()
 						);
 					}
 					int dotIndex = name.lastIndexOf( '.' );
 					String reducedName = name.substring( 0, dotIndex );
 					Iterator parentPropIter = getSubPropertyIterator( pc, reducedName );
 					List followers = getFollowers( parentPropIter, reducedName, name );
 
 					int index = propertyNames.size();
 					int followersSize = followers.size();
 					for (int loop = 0; loop < followersSize; loop++) {
 						String follower = (String) followers.get( loop );
 						int currentIndex = getIndexOfFirstMatchingProperty( propertyNames, follower );
 						index = currentIndex != -1 && currentIndex < index ? currentIndex : index;
 					}
 					propertyNames.add( index, name );
 					properties.add( index, field );
 				}
 			}
 
 			Set<String> uniqueReturnProperty = new HashSet<String>();
 			Map<String, ArrayList<String>> propertyResultsTmp = new HashMap<String, ArrayList<String>>();
 			for ( Object property : properties ) {
 				final FieldResult propertyresult = ( FieldResult ) property;
 				final String name = propertyresult.name();
 				if ( "class".equals( name ) ) {
 					throw new MappingException(
 							"class is not a valid property name to use in a @FieldResult, use @Entity(discriminatorColumn) instead"
 					);
 				}
 
 				if ( uniqueReturnProperty.contains( name ) ) {
 					throw new MappingException(
 							"duplicate @FieldResult for property " + name +
 									" on @Entity " + entity.entityClass().getName() + " in " + ann.name()
 					);
 				}
 				uniqueReturnProperty.add( name );
 
 				final String quotingNormalizedColumnName = mappings.getObjectNameNormalizer()
 						.normalizeIdentifierQuoting( propertyresult.column() );
 
 				String key = StringHelper.root( name );
 				ArrayList<String> intermediateResults = propertyResultsTmp.get( key );
 				if ( intermediateResults == null ) {
 					intermediateResults = new ArrayList<String>();
 					propertyResultsTmp.put( key, intermediateResults );
 				}
 				intermediateResults.add( quotingNormalizedColumnName );
 			}
 
 			Map<String, String[]> propertyResults = new HashMap<String,String[]>();
 			for ( Map.Entry<String, ArrayList<String>> entry : propertyResultsTmp.entrySet() ) {
 				propertyResults.put(
 						entry.getKey(),
 						entry.getValue().toArray( new String[ entry.getValue().size() ] )
 				);
 			}
 
 			if ( !BinderHelper.isEmptyAnnotationValue( entity.discriminatorColumn() ) ) {
 				final String quotingNormalizedName = mappings.getObjectNameNormalizer().normalizeIdentifierQuoting(
 						entity.discriminatorColumn()
 				);
 				propertyResults.put( "class", new String[] { quotingNormalizedName } );
 			}
 
 			if ( propertyResults.isEmpty() ) {
 				propertyResults = java.util.Collections.emptyMap();
 			}
 
 			NativeSQLQueryRootReturn result = new NativeSQLQueryRootReturn(
 					"alias" + entityAliasIndex++,
 					entity.entityClass().getName(),
 					propertyResults,
 					LockMode.READ
 			);
 			definition.addQueryReturn( result );
 		}
 
 		for ( ColumnResult column : ann.columns() ) {
 			definition.addQueryReturn(
 					new NativeSQLQueryScalarReturn(
 							mappings.getObjectNameNormalizer().normalizeIdentifierQuoting(
 									column.name()
 							),
 							null
 					)
 			);
 		}
 
 		if ( isDefault ) {
 			mappings.addDefaultResultSetMapping( definition );
 		}
 		else {
 			mappings.addResultSetMapping( definition );
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private List getFollowers(Iterator parentPropIter, String reducedName, String name) {
 		boolean hasFollowers = false;
 		List followers = new ArrayList();
 		while ( parentPropIter.hasNext() ) {
 			String currentPropertyName = ( (Property) parentPropIter.next() ).getName();
 			String currentName = reducedName + '.' + currentPropertyName;
 			if ( hasFollowers ) {
 				followers.add( currentName );
 			}
 			if ( name.equals( currentName ) ) hasFollowers = true;
 		}
 		return followers;
 	}
 
 	private Iterator getSubPropertyIterator(PersistentClass pc, String reducedName) {
 		Value value = pc.getRecursiveProperty( reducedName ).getValue();
 		Iterator parentPropIter;
 		if ( value instanceof Component ) {
 			Component comp = (Component) value;
 			parentPropIter = comp.getPropertyIterator();
 		}
 		else if ( value instanceof ToOne ) {
 			ToOne toOne = (ToOne) value;
 			PersistentClass referencedPc = mappings.getClass( toOne.getReferencedEntityName() );
 			if ( toOne.getReferencedPropertyName() != null ) {
 				try {
 					parentPropIter = ( (Component) referencedPc.getRecursiveProperty(
 							toOne.getReferencedPropertyName()
 					).getValue() ).getPropertyIterator();
 				}
 				catch (ClassCastException e) {
 					throw new MappingException(
 							"dotted notation reference neither a component nor a many/one to one", e
 					);
 				}
 			}
 			else {
 				try {
 					if ( referencedPc.getIdentifierMapper() == null ) {
 						parentPropIter = ( (Component) referencedPc.getIdentifierProperty()
 								.getValue() ).getPropertyIterator();
 					}
 					else {
 						parentPropIter = referencedPc.getIdentifierMapper().getPropertyIterator();
 					}
 				}
 				catch (ClassCastException e) {
 					throw new MappingException(
 							"dotted notation reference neither a component nor a many/one to one", e
 					);
 				}
 			}
 		}
 		else {
 			throw new MappingException( "dotted notation reference neither a component nor a many/one to one" );
 		}
 		return parentPropIter;
 	}
 
 	private static int getIndexOfFirstMatchingProperty(List propertyNames, String follower) {
 		int propertySize = propertyNames.size();
 		for (int propIndex = 0; propIndex < propertySize; propIndex++) {
 			if ( ( (String) propertyNames.get( propIndex ) ).startsWith( follower ) ) {
 				return propIndex;
 			}
 		}
 		return -1;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/SetBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/SetBinder.java
index ccb5083e7c..9d3b568790 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/SetBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/SetBinder.java
@@ -1,60 +1,61 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.annotations.OrderBy;
 import org.hibernate.cfg.Environment;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
+
 import org.jboss.logging.Logger;
 
 /**
  * Bind a set.
  *
  * @author Matthew Inger
  */
 public class SetBinder extends CollectionBinder {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SetBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SetBinder.class.getName());
 
 	public SetBinder() {
 	}
 
 	public SetBinder(boolean sorted) {
 		super( sorted );
 	}
 
 	@Override
     protected Collection createCollection(PersistentClass persistentClass) {
 		return new org.hibernate.mapping.Set( getMappings(), persistentClass );
 	}
 
 	@Override
     public void setSqlOrderBy(OrderBy orderByAnn) {
 		// *annotation* binder, jdk 1.5, ... am i missing something?
 		if ( orderByAnn != null ) {
             if (Environment.jvmSupportsLinkedHashCollections()) super.setSqlOrderBy(orderByAnn);
             else LOG.orderByAttributeIgnored();
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/SimpleValueBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/SimpleValueBinder.java
index 8b4bf4608d..0a63b62b59 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/SimpleValueBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/SimpleValueBinder.java
@@ -1,370 +1,370 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import java.io.Serializable;
 import java.sql.Types;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.Properties;
 import javax.persistence.Enumerated;
 import javax.persistence.Lob;
 import javax.persistence.MapKeyEnumerated;
 import javax.persistence.MapKeyTemporal;
 import javax.persistence.Temporal;
 import javax.persistence.TemporalType;
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
 import org.hibernate.Hibernate;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.annotations.Parameter;
 import org.hibernate.annotations.Type;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.Ejb3Column;
 import org.hibernate.cfg.Ejb3JoinColumn;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.cfg.PkDrivenByDefaultMapsIdSecondPass;
 import org.hibernate.cfg.SetSimpleValueTypeSecondPass;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.CharacterArrayClobType;
 import org.hibernate.type.EnumType;
 import org.hibernate.type.PrimitiveCharacterArrayClobType;
 import org.hibernate.type.SerializableToBlobType;
 import org.hibernate.type.WrappedMaterializedBlobType;
 import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 public class SimpleValueBinder {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SimpleValueBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SimpleValueBinder.class.getName());
 
 	private String propertyName;
 	private String returnedClassName;
 	private Ejb3Column[] columns;
 	private String persistentClassName;
 	private String explicitType = "";
 	private Properties typeParameters = new Properties();
 	private Mappings mappings;
 	private Table table;
 	private SimpleValue simpleValue;
 	private boolean isVersion;
 	private String timeStampVersionType;
 	//is a Map key
 	private boolean key;
 	private String referencedEntityName;
 
 	public void setReferencedEntityName(String referencedEntityName) {
 		this.referencedEntityName = referencedEntityName;
 	}
 
 	public boolean isVersion() {
 		return isVersion;
 	}
 
 	public void setVersion(boolean isVersion) {
 		this.isVersion = isVersion;
 	}
 
 	public void setTimestampVersionType(String versionType) {
 		this.timeStampVersionType = versionType;
 	}
 
 	public void setPropertyName(String propertyName) {
 		this.propertyName = propertyName;
 	}
 
 	public void setReturnedClassName(String returnedClassName) {
 		this.returnedClassName = returnedClassName;
 	}
 
 	public void setTable(Table table) {
 		this.table = table;
 	}
 
 	public void setColumns(Ejb3Column[] columns) {
 		this.columns = columns;
 	}
 
 
 	public void setPersistentClassName(String persistentClassName) {
 		this.persistentClassName = persistentClassName;
 	}
 
 	//TODO execute it lazily to be order safe
 
 	public void setType(XProperty property, XClass returnedClass) {
 		if ( returnedClass == null ) {
 			return;
 		} //we cannot guess anything
 		XClass returnedClassOrElement = returnedClass;
 		boolean isArray = false;
 		if ( property.isArray() ) {
 			returnedClassOrElement = property.getElementClass();
 			isArray = true;
 		}
 		Properties typeParameters = this.typeParameters;
 		typeParameters.clear();
 		String type = BinderHelper.ANNOTATION_STRING_DEFAULT;
 		if ( ( !key && property.isAnnotationPresent( Temporal.class ) )
 				|| ( key && property.isAnnotationPresent( MapKeyTemporal.class ) ) ) {
 
 			boolean isDate;
 			if ( mappings.getReflectionManager().equals( returnedClassOrElement, Date.class ) ) {
 				isDate = true;
 			}
 			else if ( mappings.getReflectionManager().equals( returnedClassOrElement, Calendar.class ) ) {
 				isDate = false;
 			}
 			else {
 				throw new AnnotationException(
 						"@Temporal should only be set on a java.util.Date or java.util.Calendar property: "
 								+ StringHelper.qualify( persistentClassName, propertyName )
 				);
 			}
 			final TemporalType temporalType = getTemporalType( property );
 			switch ( temporalType ) {
 				case DATE:
 					type = isDate ? "date" : "calendar_date";
 					break;
 				case TIME:
 					type = "time";
 					if ( !isDate ) {
 						throw new NotYetImplementedException(
 								"Calendar cannot persist TIME only"
 										+ StringHelper.qualify( persistentClassName, propertyName )
 						);
 					}
 					break;
 				case TIMESTAMP:
 					type = isDate ? "timestamp" : "calendar";
 					break;
 				default:
 					throw new AssertionFailure( "Unknown temporal type: " + temporalType );
 			}
 		}
 		else if ( property.isAnnotationPresent( Lob.class ) ) {
 
 			if ( mappings.getReflectionManager().equals( returnedClassOrElement, java.sql.Clob.class ) ) {
 				type = "clob";
 			}
 			else if ( mappings.getReflectionManager().equals( returnedClassOrElement, java.sql.Blob.class ) ) {
 				type = "blob";
 			}
 			else if ( mappings.getReflectionManager().equals( returnedClassOrElement, String.class ) ) {
 				type = Hibernate.MATERIALIZED_CLOB.getName();
 			}
 			else if ( mappings.getReflectionManager().equals( returnedClassOrElement, Character.class ) && isArray ) {
 				type = CharacterArrayClobType.class.getName();
 			}
 			else if ( mappings.getReflectionManager().equals( returnedClassOrElement, char.class ) && isArray ) {
 				type = PrimitiveCharacterArrayClobType.class.getName();
 			}
 			else if ( mappings.getReflectionManager().equals( returnedClassOrElement, Byte.class ) && isArray ) {
 				type = WrappedMaterializedBlobType.class.getName();
 			}
 			else if ( mappings.getReflectionManager().equals( returnedClassOrElement, byte.class ) && isArray ) {
 				type = Hibernate.MATERIALIZED_BLOB.getName();
 			}
 			else if ( mappings.getReflectionManager()
 					.toXClass( Serializable.class )
 					.isAssignableFrom( returnedClassOrElement ) ) {
 				type = SerializableToBlobType.class.getName();
 				//typeParameters = new Properties();
 				typeParameters.setProperty(
 						SerializableToBlobType.CLASS_NAME,
 						returnedClassOrElement.getName()
 				);
 			}
 			else {
 				type = "blob";
 			}
 		}
 		//implicit type will check basic types and Serializable classes
 		if ( columns == null ) {
 			throw new AssertionFailure( "SimpleValueBinder.setColumns should be set before SimpleValueBinder.setType" );
 		}
 		if ( BinderHelper.ANNOTATION_STRING_DEFAULT.equals( type ) ) {
 			if ( returnedClassOrElement.isEnum() ) {
 				type = EnumType.class.getName();
 				typeParameters = new Properties();
 				typeParameters.setProperty( EnumType.ENUM, returnedClassOrElement.getName() );
 				String schema = columns[0].getTable().getSchema();
 				schema = schema == null ? "" : schema;
 				String catalog = columns[0].getTable().getCatalog();
 				catalog = catalog == null ? "" : catalog;
 				typeParameters.setProperty( EnumType.SCHEMA, schema );
 				typeParameters.setProperty( EnumType.CATALOG, catalog );
 				typeParameters.setProperty( EnumType.TABLE, columns[0].getTable().getName() );
 				typeParameters.setProperty( EnumType.COLUMN, columns[0].getName() );
 				javax.persistence.EnumType enumType = getEnumType( property );
 				if ( enumType != null ) {
 					if ( javax.persistence.EnumType.ORDINAL.equals( enumType ) ) {
 						typeParameters.setProperty( EnumType.TYPE, String.valueOf( Types.INTEGER ) );
 					}
 					else if ( javax.persistence.EnumType.STRING.equals( enumType ) ) {
 						typeParameters.setProperty( EnumType.TYPE, String.valueOf( Types.VARCHAR ) );
 					}
 					else {
 						throw new AssertionFailure( "Unknown EnumType: " + enumType );
 					}
 				}
 			}
 		}
 		explicitType = type;
 		this.typeParameters = typeParameters;
 		Type annType = property.getAnnotation( Type.class );
 		setExplicitType( annType );
 	}
 
 	private javax.persistence.EnumType getEnumType(XProperty property) {
 		javax.persistence.EnumType enumType = null;
 		if ( key ) {
 			MapKeyEnumerated enumAnn = property.getAnnotation( MapKeyEnumerated.class );
 			if ( enumAnn != null ) {
 				enumType = enumAnn.value();
 			}
 		}
 		else {
 			Enumerated enumAnn = property.getAnnotation( Enumerated.class );
 			if ( enumAnn != null ) {
 				enumType = enumAnn.value();
 			}
 		}
 		return enumType;
 	}
 
 	private TemporalType getTemporalType(XProperty property) {
 		if ( key ) {
 			MapKeyTemporal ann = property.getAnnotation( MapKeyTemporal.class );
 			return ann.value();
 		}
 		else {
 			Temporal ann = property.getAnnotation( Temporal.class );
 			return ann.value();
 		}
 	}
 
 	public void setExplicitType(String explicitType) {
 		this.explicitType = explicitType;
 	}
 
 	//FIXME raise an assertion failure  if setExplicitType(String) and setExplicitType(Type) are use at the same time
 
 	public void setExplicitType(Type typeAnn) {
 		if ( typeAnn != null ) {
 			explicitType = typeAnn.type();
 			typeParameters.clear();
 			for ( Parameter param : typeAnn.parameters() ) {
 				typeParameters.setProperty( param.name(), param.value() );
 			}
 		}
 	}
 
 	public void setMappings(Mappings mappings) {
 		this.mappings = mappings;
 	}
 
 	private void validate() {
 		//TODO check necessary params
 		Ejb3Column.checkPropertyConsistency( columns, propertyName );
 	}
 
 	public SimpleValue make() {
 
 		validate();
         LOG.debugf("building SimpleValue for %s", propertyName);
 		if ( table == null ) {
 			table = columns[0].getTable();
 		}
 		simpleValue = new SimpleValue( mappings, table );
 
 		linkWithValue();
 
 		boolean isInSecondPass = mappings.isInSecondPass();
 		SetSimpleValueTypeSecondPass secondPass = new SetSimpleValueTypeSecondPass( this );
 		if ( !isInSecondPass ) {
 			//Defer this to the second pass
 			mappings.addSecondPass( secondPass );
 		}
 		else {
 			//We are already in second pass
 			fillSimpleValue();
 		}
 		return simpleValue;
 	}
 
 	public void linkWithValue() {
 		if ( columns[0].isNameDeferred() && !mappings.isInSecondPass() && referencedEntityName != null ) {
 			mappings.addSecondPass(
 					new PkDrivenByDefaultMapsIdSecondPass(
 							referencedEntityName, ( Ejb3JoinColumn[] ) columns, simpleValue
 					)
 			);
 		}
 		else {
 			for ( Ejb3Column column : columns ) {
 				column.linkWithValue( simpleValue );
 			}
 		}
 	}
 
 	public void fillSimpleValue() {
 
         LOG.debugf("Setting SimpleValue typeName for %s", propertyName);
 
 		String type = BinderHelper.isEmptyAnnotationValue( explicitType ) ? returnedClassName : explicitType;
 		org.hibernate.mapping.TypeDef typeDef = mappings.getTypeDef( type );
 		if ( typeDef != null ) {
 			type = typeDef.getTypeClass();
 			simpleValue.setTypeParameters( typeDef.getParameters() );
 		}
 		if ( typeParameters != null && typeParameters.size() != 0 ) {
 			//explicit type params takes precedence over type def params
 			simpleValue.setTypeParameters( typeParameters );
 		}
 		simpleValue.setTypeName( type );
 		if ( persistentClassName != null ) {
 			simpleValue.setTypeUsingReflection( persistentClassName, propertyName );
 		}
 
 		if ( !simpleValue.isTypeSpecified() && isVersion() ) {
 			simpleValue.setTypeName( "integer" );
 		}
 
 		// HHH-5205
 		if ( timeStampVersionType != null ) {
 			simpleValue.setTypeName( timeStampVersionType );
 		}
 	}
 
 	public void setKey(boolean key) {
 		this.key = key;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/TableBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/TableBinder.java
index 872e142bd4..a735559b90 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/TableBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/TableBinder.java
@@ -1,577 +1,578 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import javax.persistence.UniqueConstraint;
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.annotations.Index;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.Ejb3JoinColumn;
 import org.hibernate.cfg.IndexOrUniqueKeySecondPass;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.cfg.ObjectNameSource;
 import org.hibernate.cfg.UniqueConstraintHolder;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.JoinedSubclass;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.ToOne;
 import org.hibernate.mapping.Value;
+
 import org.jboss.logging.Logger;
 
 /**
  * Table related operations
  *
  * @author Emmanuel Bernard
  */
 @SuppressWarnings("unchecked")
 public class TableBinder {
 	//TODO move it to a getter/setter strategy
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TableBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TableBinder.class.getName());
 
 	private String schema;
 	private String catalog;
 	private String name;
 	private boolean isAbstract;
 	private List<UniqueConstraintHolder> uniqueConstraints;
 //	private List<String[]> uniqueConstraints;
 	String constraints;
 	Table denormalizedSuperTable;
 	Mappings mappings;
 	private String ownerEntityTable;
 	private String associatedEntityTable;
 	private String propertyName;
 	private String ownerEntity;
 	private String associatedEntity;
 	private boolean isJPA2ElementCollection;
 
 	public void setSchema(String schema) {
 		this.schema = schema;
 	}
 
 	public void setCatalog(String catalog) {
 		this.catalog = catalog;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public void setName(String name) {
 		this.name = name;
 	}
 
 	public void setAbstract(boolean anAbstract) {
 		isAbstract = anAbstract;
 	}
 
 	public void setUniqueConstraints(UniqueConstraint[] uniqueConstraints) {
 		this.uniqueConstraints = TableBinder.buildUniqueConstraintHolders( uniqueConstraints );
 	}
 
 	public void setConstraints(String constraints) {
 		this.constraints = constraints;
 	}
 
 	public void setDenormalizedSuperTable(Table denormalizedSuperTable) {
 		this.denormalizedSuperTable = denormalizedSuperTable;
 	}
 
 	public void setMappings(Mappings mappings) {
 		this.mappings = mappings;
 	}
 
 	public void setJPA2ElementCollection(boolean isJPA2ElementCollection) {
 		this.isJPA2ElementCollection = isJPA2ElementCollection;
 	}
 
 	private static class AssociationTableNameSource implements ObjectNameSource {
 		private final String explicitName;
 		private final String logicalName;
 
 		private AssociationTableNameSource(String explicitName, String logicalName) {
 			this.explicitName = explicitName;
 			this.logicalName = logicalName;
 		}
 
 		public String getExplicitName() {
 			return explicitName;
 		}
 
 		public String getLogicalName() {
 			return logicalName;
 		}
 	}
 
 	// only bind association table currently
 	public Table bind() {
 		//logicalName only accurate for assoc table...
 		final String unquotedOwnerTable = StringHelper.unquote( ownerEntityTable );
 		final String unquotedAssocTable = StringHelper.unquote( associatedEntityTable );
 
 		//@ElementCollection use ownerEntity_property instead of the cleaner ownerTableName_property
 		// ownerEntity can be null when the table name is explicitly set
 		final String ownerObjectName = isJPA2ElementCollection && ownerEntity != null ?
 				StringHelper.unqualify( ownerEntity ) : unquotedOwnerTable;
 		final ObjectNameSource nameSource = buildNameContext(
 				ownerObjectName,
 				unquotedAssocTable );
 
 		final boolean ownerEntityTableQuoted = StringHelper.isQuoted( ownerEntityTable );
 		final boolean associatedEntityTableQuoted = StringHelper.isQuoted( associatedEntityTable );
 		final ObjectNameNormalizer.NamingStrategyHelper namingStrategyHelper = new ObjectNameNormalizer.NamingStrategyHelper() {
 			public String determineImplicitName(NamingStrategy strategy) {
 
 				final String strategyResult = strategy.collectionTableName(
 						ownerEntity,
 						ownerObjectName,
 						associatedEntity,
 						unquotedAssocTable,
 						propertyName
 
 				);
 				return ownerEntityTableQuoted || associatedEntityTableQuoted
 						? StringHelper.quote( strategyResult )
 						: strategyResult;
 			}
 
 			public String handleExplicitName(NamingStrategy strategy, String name) {
 				return strategy.tableName( name );
 			}
 		};
 
 		return buildAndFillTable(
 				schema,
 				catalog,
 				nameSource,
 				namingStrategyHelper,
 				isAbstract,
 				uniqueConstraints,
 				constraints,
 				denormalizedSuperTable,
 				mappings,
 				null
 		);
 	}
 
 	private ObjectNameSource buildNameContext(String unquotedOwnerTable, String unquotedAssocTable) {
 		String logicalName = mappings.getNamingStrategy().logicalCollectionTableName(
 				name,
 				unquotedOwnerTable,
 				unquotedAssocTable,
 				propertyName
 		);
 		if ( StringHelper.isQuoted( ownerEntityTable ) || StringHelper.isQuoted( associatedEntityTable ) ) {
 			logicalName = StringHelper.quote( logicalName );
 		}
 
 		return new AssociationTableNameSource( name, logicalName );
 	}
 
 	public static Table buildAndFillTable(
 			String schema,
 			String catalog,
 			ObjectNameSource nameSource,
 			ObjectNameNormalizer.NamingStrategyHelper namingStrategyHelper,
 			boolean isAbstract,
 			List<UniqueConstraintHolder> uniqueConstraints,
 			String constraints,
 			Table denormalizedSuperTable,
 			Mappings mappings,
 			String subselect) {
 		schema = BinderHelper.isEmptyAnnotationValue( schema ) ? mappings.getSchemaName() : schema;
 		catalog = BinderHelper.isEmptyAnnotationValue( catalog ) ? mappings.getCatalogName() : catalog;
 
 		String realTableName = mappings.getObjectNameNormalizer().normalizeDatabaseIdentifier(
 				nameSource.getExplicitName(),
 				namingStrategyHelper
 		);
 
 		final Table table;
 		if ( denormalizedSuperTable != null ) {
 			table = mappings.addDenormalizedTable(
 					schema,
 					catalog,
 					realTableName,
 					isAbstract,
 					subselect,
 					denormalizedSuperTable
 			);
 		}
 		else {
 			table = mappings.addTable(
 					schema,
 					catalog,
 					realTableName,
 					subselect,
 					isAbstract
 			);
 		}
 
 		if ( uniqueConstraints != null && uniqueConstraints.size() > 0 ) {
 			mappings.addUniqueConstraintHolders( table, uniqueConstraints );
 		}
 
 		if ( constraints != null ) table.addCheckConstraint( constraints );
 
 		// logicalName is null if we are in the second pass
 		final String logicalName = nameSource.getLogicalName();
 		if ( logicalName != null ) {
 			mappings.addTableBinding( schema, catalog, logicalName, realTableName, denormalizedSuperTable );
 		}
 		return table;
 	}
 
 	/**
 	 *
 	 * @param schema
 	 * @param catalog
 	 * @param realTableName
 	 * @param logicalName
 	 * @param isAbstract
 	 * @param uniqueConstraints
 	 * @param constraints
 	 * @param denormalizedSuperTable
 	 * @param mappings
 	 * @return
 	 *
 	 * @deprecated Use {@link #buildAndFillTable} instead.
 	 */
 	@Deprecated
     @SuppressWarnings({ "JavaDoc" })
 	public static Table fillTable(
 			String schema,
 			String catalog,
 			String realTableName,
 			String logicalName,
 			boolean isAbstract,
 			List uniqueConstraints,
 			String constraints,
 			Table denormalizedSuperTable,
 			Mappings mappings) {
 		schema = BinderHelper.isEmptyAnnotationValue( schema ) ? mappings.getSchemaName() : schema;
 		catalog = BinderHelper.isEmptyAnnotationValue( catalog ) ? mappings.getCatalogName() : catalog;
 		Table table;
 		if ( denormalizedSuperTable != null ) {
 			table = mappings.addDenormalizedTable(
 					schema,
 					catalog,
 					realTableName,
 					isAbstract,
 					null, //subselect
 					denormalizedSuperTable
 			);
 		}
 		else {
 			table = mappings.addTable(
 					schema,
 					catalog,
 					realTableName,
 					null, //subselect
 					isAbstract
 			);
 		}
 		if ( uniqueConstraints != null && uniqueConstraints.size() > 0 ) {
 			mappings.addUniqueConstraints( table, uniqueConstraints );
 		}
 		if ( constraints != null ) table.addCheckConstraint( constraints );
 		//logicalName is null if we are in the second pass
 		if ( logicalName != null ) {
 			mappings.addTableBinding( schema, catalog, logicalName, realTableName, denormalizedSuperTable );
 		}
 		return table;
 	}
 
 	public static void bindFk(
 			PersistentClass referencedEntity,
 			PersistentClass destinationEntity,
 			Ejb3JoinColumn[] columns,
 			SimpleValue value,
 			boolean unique,
 			Mappings mappings) {
 		PersistentClass associatedClass;
 		if ( destinationEntity != null ) {
 			//overridden destination
 			associatedClass = destinationEntity;
 		}
 		else {
 			associatedClass = columns[0].getPropertyHolder() == null
 					? null
 					: columns[0].getPropertyHolder().getPersistentClass();
 		}
 		final String mappedByProperty = columns[0].getMappedBy();
 		if ( StringHelper.isNotEmpty( mappedByProperty ) ) {
 			/**
 			 * Get the columns of the mapped-by property
 			 * copy them and link the copy to the actual value
 			 */
             LOG.debugf("Retrieving property %s.%s", associatedClass.getEntityName(), mappedByProperty);
 
 			final Property property = associatedClass.getRecursiveProperty( columns[0].getMappedBy() );
 			Iterator mappedByColumns;
 			if ( property.getValue() instanceof Collection ) {
 				Collection collection = ( (Collection) property.getValue() );
 				Value element = collection.getElement();
 				if ( element == null ) {
 					throw new AnnotationException(
 							"Illegal use of mappedBy on both sides of the relationship: "
 									+ associatedClass.getEntityName() + "." + mappedByProperty
 					);
 				}
 				mappedByColumns = element.getColumnIterator();
 			}
 			else {
 				mappedByColumns = property.getValue().getColumnIterator();
 			}
 			while ( mappedByColumns.hasNext() ) {
 				Column column = (Column) mappedByColumns.next();
 				columns[0].overrideFromReferencedColumnIfNecessary( column );
 				columns[0].linkValueUsingAColumnCopy( column, value );
 			}
 		}
 		else if ( columns[0].isImplicit() ) {
 			/**
 			 * if columns are implicit, then create the columns based on the
 			 * referenced entity id columns
 			 */
 			Iterator idColumns;
 			if ( referencedEntity instanceof JoinedSubclass ) {
 				idColumns = referencedEntity.getKey().getColumnIterator();
 			}
 			else {
 				idColumns = referencedEntity.getIdentifier().getColumnIterator();
 			}
 			while ( idColumns.hasNext() ) {
 				Column column = (Column) idColumns.next();
 				columns[0].overrideFromReferencedColumnIfNecessary( column );
 				columns[0].linkValueUsingDefaultColumnNaming( column, referencedEntity, value );
 			}
 		}
 		else {
 			int fkEnum = Ejb3JoinColumn.checkReferencedColumnsType( columns, referencedEntity, mappings );
 
 			if ( Ejb3JoinColumn.NON_PK_REFERENCE == fkEnum ) {
 				String referencedPropertyName;
 				if ( value instanceof ToOne ) {
 					referencedPropertyName = ( (ToOne) value ).getReferencedPropertyName();
 				}
 				else if ( value instanceof DependantValue ) {
 					String propertyName = columns[0].getPropertyName();
 					if ( propertyName != null ) {
 						Collection collection = (Collection) referencedEntity.getRecursiveProperty( propertyName )
 								.getValue();
 						referencedPropertyName = collection.getReferencedPropertyName();
 					}
 					else {
 						throw new AnnotationException( "SecondaryTable JoinColumn cannot reference a non primary key" );
 					}
 
 				}
 				else {
 					throw new AssertionFailure(
 							"Do a property ref on an unexpected Value type: "
 									+ value.getClass().getName()
 					);
 				}
 				if ( referencedPropertyName == null ) {
 					throw new AssertionFailure(
 							"No property ref found while expected"
 					);
 				}
 				Property synthProp = referencedEntity.getRecursiveProperty( referencedPropertyName );
 				if ( synthProp == null ) {
 					throw new AssertionFailure(
 							"Cannot find synthProp: " + referencedEntity.getEntityName() + "." + referencedPropertyName
 					);
 				}
 				linkJoinColumnWithValueOverridingNameIfImplicit(
 						referencedEntity, synthProp.getColumnIterator(), columns, value
 				);
 
 			}
 			else {
 				if ( Ejb3JoinColumn.NO_REFERENCE == fkEnum ) {
 					//implicit case, we hope PK and FK columns are in the same order
 					if ( columns.length != referencedEntity.getIdentifier().getColumnSpan() ) {
 						throw new AnnotationException(
 								"A Foreign key refering " + referencedEntity.getEntityName()
 										+ " from " + associatedClass.getEntityName()
 										+ " has the wrong number of column. should be " + referencedEntity.getIdentifier()
 										.getColumnSpan()
 						);
 					}
 					linkJoinColumnWithValueOverridingNameIfImplicit(
 							referencedEntity,
 							referencedEntity.getIdentifier().getColumnIterator(),
 							columns,
 							value
 					);
 				}
 				else {
 					//explicit referencedColumnName
 					Iterator idColItr = referencedEntity.getKey().getColumnIterator();
 					org.hibernate.mapping.Column col;
 					Table table = referencedEntity.getTable(); //works cause the pk has to be on the primary table
                     if (!idColItr.hasNext()) LOG.debugf("No column in the identifier!");
 					while ( idColItr.hasNext() ) {
 						boolean match = false;
 						//for each PK column, find the associated FK column.
 						col = (org.hibernate.mapping.Column) idColItr.next();
 						for (Ejb3JoinColumn joinCol : columns) {
 							String referencedColumn = joinCol.getReferencedColumn();
 							referencedColumn = mappings.getPhysicalColumnName( referencedColumn, table );
 							//In JPA 2 referencedColumnName is case insensitive
 							if ( referencedColumn.equalsIgnoreCase( col.getQuotedName() ) ) {
 								//proper join column
 								if ( joinCol.isNameDeferred() ) {
 									joinCol.linkValueUsingDefaultColumnNaming(
 											col, referencedEntity, value
 									);
 								}
 								else {
 									joinCol.linkWithValue( value );
 								}
 								joinCol.overrideFromReferencedColumnIfNecessary( col );
 								match = true;
 								break;
 							}
 						}
 						if ( !match ) {
 							throw new AnnotationException(
 									"Column name " + col.getName() + " of "
 											+ referencedEntity.getEntityName() + " not found in JoinColumns.referencedColumnName"
 							);
 						}
 					}
 				}
 			}
 		}
 		value.createForeignKey();
 		if ( unique ) {
 			createUniqueConstraint( value );
 		}
 	}
 
 	public static void linkJoinColumnWithValueOverridingNameIfImplicit(
 			PersistentClass referencedEntity,
 			Iterator columnIterator,
 			Ejb3JoinColumn[] columns,
 			SimpleValue value) {
 		for (Ejb3JoinColumn joinCol : columns) {
 			Column synthCol = (Column) columnIterator.next();
 			if ( joinCol.isNameDeferred() ) {
 				//this has to be the default value
 				joinCol.linkValueUsingDefaultColumnNaming( synthCol, referencedEntity, value );
 			}
 			else {
 				joinCol.linkWithValue( value );
 				joinCol.overrideFromReferencedColumnIfNecessary( synthCol );
 			}
 		}
 	}
 
 	public static void createUniqueConstraint(Value value) {
 		Iterator iter = value.getColumnIterator();
 		ArrayList cols = new ArrayList();
 		while ( iter.hasNext() ) {
 			cols.add( iter.next() );
 		}
 		value.getTable().createUniqueKey( cols );
 	}
 
 	public static void addIndexes(Table hibTable, Index[] indexes, Mappings mappings) {
 		for (Index index : indexes) {
 			//no need to handle inSecondPass here since it is only called from EntityBinder
 			mappings.addSecondPass(
 					new IndexOrUniqueKeySecondPass( hibTable, index.name(), index.columnNames(), mappings )
 			);
 		}
 	}
 
 	/**
 	 * @deprecated Use {@link #buildUniqueConstraintHolders} instead
 	 */
 	@Deprecated
     @SuppressWarnings({ "JavaDoc" })
 	public static List<String[]> buildUniqueConstraints(UniqueConstraint[] constraintsArray) {
 		List<String[]> result = new ArrayList<String[]>();
 		if ( constraintsArray.length != 0 ) {
 			for (UniqueConstraint uc : constraintsArray) {
 				result.add( uc.columnNames() );
 			}
 		}
 		return result;
 	}
 
 	/**
 	 * Build a list of {@link org.hibernate.cfg.UniqueConstraintHolder} instances given a list of
 	 * {@link UniqueConstraint} annotations.
 	 *
 	 * @param annotations The {@link UniqueConstraint} annotations.
 	 *
 	 * @return The built {@link org.hibernate.cfg.UniqueConstraintHolder} instances.
 	 */
 	public static List<UniqueConstraintHolder> buildUniqueConstraintHolders(UniqueConstraint[] annotations) {
 		List<UniqueConstraintHolder> result;
 		if ( annotations == null || annotations.length == 0 ) {
 			result = java.util.Collections.emptyList();
 		}
 		else {
 			result = new ArrayList<UniqueConstraintHolder>( CollectionHelper.determineProperSizing( annotations.length ) );
 			for ( UniqueConstraint uc : annotations ) {
 				result.add(
 						new UniqueConstraintHolder()
 								.setName( uc.name() )
 								.setColumns( uc.columnNames() )
 				);
 			}
 		}
 		return result;
 	}
 
 	public void setDefaultName(
 			String ownerEntity, String ownerEntityTable, String associatedEntity, String associatedEntityTable,
 			String propertyName
 	) {
 		this.ownerEntity = ownerEntity;
 		this.ownerEntityTable = ownerEntityTable;
 		this.associatedEntity = associatedEntity;
 		this.associatedEntityTable = associatedEntityTable;
 		this.propertyName = propertyName;
 		this.name = null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/JPAOverridenAnnotationReader.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/JPAOverridenAnnotationReader.java
index 2f4b03e017..dc90390d0f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/JPAOverridenAnnotationReader.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/JPAOverridenAnnotationReader.java
@@ -1,1145 +1,1145 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 
 package org.hibernate.cfg.annotations.reflection;
 
 import java.beans.Introspector;
 import java.lang.annotation.Annotation;
 import java.lang.reflect.AccessibleObject;
 import java.lang.reflect.AnnotatedElement;
 import java.lang.reflect.Field;
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.Access;
 import javax.persistence.AccessType;
 import javax.persistence.AssociationOverride;
 import javax.persistence.AssociationOverrides;
 import javax.persistence.AttributeOverride;
 import javax.persistence.AttributeOverrides;
 import javax.persistence.Basic;
 import javax.persistence.CascadeType;
 import javax.persistence.CollectionTable;
 import javax.persistence.Column;
 import javax.persistence.ColumnResult;
 import javax.persistence.DiscriminatorColumn;
 import javax.persistence.DiscriminatorType;
 import javax.persistence.DiscriminatorValue;
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.Embedded;
 import javax.persistence.EmbeddedId;
 import javax.persistence.Entity;
 import javax.persistence.EntityListeners;
 import javax.persistence.EntityResult;
 import javax.persistence.EnumType;
 import javax.persistence.Enumerated;
 import javax.persistence.ExcludeDefaultListeners;
 import javax.persistence.ExcludeSuperclassListeners;
 import javax.persistence.FetchType;
 import javax.persistence.FieldResult;
 import javax.persistence.GeneratedValue;
 import javax.persistence.GenerationType;
 import javax.persistence.Id;
 import javax.persistence.IdClass;
 import javax.persistence.Inheritance;
 import javax.persistence.InheritanceType;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinColumns;
 import javax.persistence.JoinTable;
 import javax.persistence.Lob;
 import javax.persistence.ManyToMany;
 import javax.persistence.ManyToOne;
 import javax.persistence.MapKey;
 import javax.persistence.MapKeyClass;
 import javax.persistence.MapKeyColumn;
 import javax.persistence.MapKeyEnumerated;
 import javax.persistence.MapKeyJoinColumn;
 import javax.persistence.MapKeyJoinColumns;
 import javax.persistence.MapKeyTemporal;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.MapsId;
 import javax.persistence.NamedNativeQueries;
 import javax.persistence.NamedNativeQuery;
 import javax.persistence.NamedQueries;
 import javax.persistence.NamedQuery;
 import javax.persistence.OneToMany;
 import javax.persistence.OneToOne;
 import javax.persistence.OrderBy;
 import javax.persistence.OrderColumn;
 import javax.persistence.PostLoad;
 import javax.persistence.PostPersist;
 import javax.persistence.PostRemove;
 import javax.persistence.PostUpdate;
 import javax.persistence.PrePersist;
 import javax.persistence.PreRemove;
 import javax.persistence.PreUpdate;
 import javax.persistence.PrimaryKeyJoinColumn;
 import javax.persistence.PrimaryKeyJoinColumns;
 import javax.persistence.QueryHint;
 import javax.persistence.SecondaryTable;
 import javax.persistence.SecondaryTables;
 import javax.persistence.SequenceGenerator;
 import javax.persistence.SqlResultSetMapping;
 import javax.persistence.SqlResultSetMappings;
 import javax.persistence.Table;
 import javax.persistence.TableGenerator;
 import javax.persistence.Temporal;
 import javax.persistence.TemporalType;
 import javax.persistence.Transient;
 import javax.persistence.UniqueConstraint;
 import javax.persistence.Version;
 import org.dom4j.Attribute;
 import org.dom4j.Element;
 import org.hibernate.AnnotationException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.annotations.Cascade;
 import org.hibernate.annotations.CollectionOfElements;
 import org.hibernate.annotations.Columns;
 import org.hibernate.annotations.common.annotationfactory.AnnotationDescriptor;
 import org.hibernate.annotations.common.annotationfactory.AnnotationFactory;
 import org.hibernate.annotations.common.reflection.AnnotationReader;
 import org.hibernate.annotations.common.reflection.Filter;
 import org.hibernate.annotations.common.reflection.ReflectionUtil;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.jboss.logging.Logger;
 
 /**
  * Encapsulates the overriding of Java annotations from an EJB 3.0 descriptor.
  *
  * @author Paolo Perrotta
  * @author Davide Marchignoli
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class JPAOverridenAnnotationReader implements AnnotationReader {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        JPAOverridenAnnotationReader.class.getName());
 	private static final Map<Class, String> annotationToXml;
 	private static final String SCHEMA_VALIDATION = "Activate schema validation for more information";
 	private static final Filter FILTER = new Filter() {
 		public boolean returnStatic() {
 			return false;
 		}
 
 		public boolean returnTransient() {
 			return false;
 		}
 	};
 
 	static {
 		annotationToXml = new HashMap<Class, String>();
 		annotationToXml.put( Entity.class, "entity" );
 		annotationToXml.put( MappedSuperclass.class, "mapped-superclass" );
 		annotationToXml.put( Embeddable.class, "embeddable" );
 		annotationToXml.put( Table.class, "table" );
 		annotationToXml.put( SecondaryTable.class, "secondary-table" );
 		annotationToXml.put( SecondaryTables.class, "secondary-table" );
 		annotationToXml.put( PrimaryKeyJoinColumn.class, "primary-key-join-column" );
 		annotationToXml.put( PrimaryKeyJoinColumns.class, "primary-key-join-column" );
 		annotationToXml.put( IdClass.class, "id-class" );
 		annotationToXml.put( Inheritance.class, "inheritance" );
 		annotationToXml.put( DiscriminatorValue.class, "discriminator-value" );
 		annotationToXml.put( DiscriminatorColumn.class, "discriminator-column" );
 		annotationToXml.put( SequenceGenerator.class, "sequence-generator" );
 		annotationToXml.put( TableGenerator.class, "table-generator" );
 		annotationToXml.put( NamedQuery.class, "named-query" );
 		annotationToXml.put( NamedQueries.class, "named-query" );
 		annotationToXml.put( NamedNativeQuery.class, "named-native-query" );
 		annotationToXml.put( NamedNativeQueries.class, "named-native-query" );
 		annotationToXml.put( SqlResultSetMapping.class, "sql-result-set-mapping" );
 		annotationToXml.put( SqlResultSetMappings.class, "sql-result-set-mapping" );
 		annotationToXml.put( ExcludeDefaultListeners.class, "exclude-default-listeners" );
 		annotationToXml.put( ExcludeSuperclassListeners.class, "exclude-superclass-listeners" );
 		annotationToXml.put( AccessType.class, "access" );
 		annotationToXml.put( AttributeOverride.class, "attribute-override" );
 		annotationToXml.put( AttributeOverrides.class, "attribute-override" );
 		annotationToXml.put( AttributeOverride.class, "association-override" );
 		annotationToXml.put( AttributeOverrides.class, "association-override" );
 		annotationToXml.put( AttributeOverride.class, "map-key-attribute-override" );
 		annotationToXml.put( AttributeOverrides.class, "map-key-attribute-override" );
 		annotationToXml.put( Id.class, "id" );
 		annotationToXml.put( EmbeddedId.class, "embedded-id" );
 		annotationToXml.put( GeneratedValue.class, "generated-value" );
 		annotationToXml.put( Column.class, "column" );
 		annotationToXml.put( Columns.class, "column" );
 		annotationToXml.put( Temporal.class, "temporal" );
 		annotationToXml.put( Lob.class, "lob" );
 		annotationToXml.put( Enumerated.class, "enumerated" );
 		annotationToXml.put( Version.class, "version" );
 		annotationToXml.put( Transient.class, "transient" );
 		annotationToXml.put( Basic.class, "basic" );
 		annotationToXml.put( Embedded.class, "embedded" );
 		annotationToXml.put( ManyToOne.class, "many-to-one" );
 		annotationToXml.put( OneToOne.class, "one-to-one" );
 		annotationToXml.put( OneToMany.class, "one-to-many" );
 		annotationToXml.put( ManyToMany.class, "many-to-many" );
 		annotationToXml.put( JoinTable.class, "join-table" );
 		annotationToXml.put( JoinColumn.class, "join-column" );
 		annotationToXml.put( JoinColumns.class, "join-column" );
 		annotationToXml.put( MapKey.class, "map-key" );
 		annotationToXml.put( OrderBy.class, "order-by" );
 		annotationToXml.put( EntityListeners.class, "entity-listeners" );
 		annotationToXml.put( PrePersist.class, "pre-persist" );
 		annotationToXml.put( PreRemove.class, "pre-remove" );
 		annotationToXml.put( PreUpdate.class, "pre-update" );
 		annotationToXml.put( PostPersist.class, "post-persist" );
 		annotationToXml.put( PostRemove.class, "post-remove" );
 		annotationToXml.put( PostUpdate.class, "post-update" );
 		annotationToXml.put( PostLoad.class, "post-load" );
 		annotationToXml.put( CollectionTable.class, "collection-table" );
 		annotationToXml.put( MapKeyClass.class, "map-key-class" );
 		annotationToXml.put( MapKeyTemporal.class, "map-key-temporal" );
 		annotationToXml.put( MapKeyEnumerated.class, "map-key-enumerated" );
 		annotationToXml.put( MapKeyColumn.class, "map-key-column" );
 		annotationToXml.put( MapKeyJoinColumn.class, "map-key-join-column" );
 		annotationToXml.put( MapKeyJoinColumns.class, "map-key-join-column" );
 		annotationToXml.put( OrderColumn.class, "order-column" );
 	}
 
 	private XMLContext xmlContext;
 	private String className;
 	private String propertyName;
 	private PropertyType propertyType;
 	private transient Annotation[] annotations;
 	private transient Map<Class, Annotation> annotationsMap;
 	private static final String WORD_SEPARATOR = "-";
 	private transient List<Element> elementsForProperty;
 	private AccessibleObject mirroredAttribute;
 	private final AnnotatedElement element;
 
 	private enum PropertyType {
 		PROPERTY,
 		FIELD,
 		METHOD
 	}
 
 	public JPAOverridenAnnotationReader(AnnotatedElement el, XMLContext xmlContext) {
 		this.element = el;
 		this.xmlContext = xmlContext;
 		if ( el instanceof Class ) {
 			Class clazz = (Class) el;
 			className = clazz.getName();
 		}
 		else if ( el instanceof Field ) {
 			Field field = (Field) el;
 			className = field.getDeclaringClass().getName();
 			propertyName = field.getName();
 			propertyType = PropertyType.FIELD;
 			String expectedGetter = "get" + Character.toUpperCase( propertyName.charAt( 0 ) ) + propertyName.substring(
 					1
 			);
 			try {
 				mirroredAttribute = field.getDeclaringClass().getDeclaredMethod( expectedGetter );
 			}
 			catch ( NoSuchMethodException e ) {
 				//no method
 			}
 		}
 		else if ( el instanceof Method ) {
 			Method method = (Method) el;
 			className = method.getDeclaringClass().getName();
 			propertyName = method.getName();
 			if ( ReflectionUtil.isProperty(
 					method,
 					null, //this is yukky!! we'd rather get the TypeEnvironment()
 					FILTER
 			) ) {
 				if ( propertyName.startsWith( "get" ) ) {
 					propertyName = Introspector.decapitalize( propertyName.substring( "get".length() ) );
 				}
 				else if ( propertyName.startsWith( "is" ) ) {
 					propertyName = Introspector.decapitalize( propertyName.substring( "is".length() ) );
 				}
 				else {
 					throw new RuntimeException( "Method " + propertyName + " is not a property getter" );
 				}
 				propertyType = PropertyType.PROPERTY;
 				try {
 					mirroredAttribute = method.getDeclaringClass().getDeclaredField( propertyName );
 				}
 				catch ( NoSuchFieldException e ) {
 					//no method
 				}
 			}
 			else {
 				propertyType = PropertyType.METHOD;
 			}
 		}
 		else {
 			className = null;
 			propertyName = null;
 		}
 	}
 
 	public <T extends Annotation> T getAnnotation(Class<T> annotationType) {
 		initAnnotations();
 		return (T) annotationsMap.get( annotationType );
 	}
 
 	public <T extends Annotation> boolean isAnnotationPresent(Class<T> annotationType) {
 		initAnnotations();
 		return (T) annotationsMap.get( annotationType ) != null;
 	}
 
 	public Annotation[] getAnnotations() {
 		initAnnotations();
 		return annotations;
 	}
 
 	/*
 	 * The idea is to create annotation proxies for the xml configuration elements. Using this proxy annotations together
 	 * with the {@code JPAMetadataprovider} allows to handle xml configuration the same way as annotation configuration.
 	 */
 	private void initAnnotations() {
 		if ( annotations == null ) {
 			XMLContext.Default defaults = xmlContext.getDefault( className );
 			if ( className != null && propertyName == null ) {
 				//is a class
 				Element tree = xmlContext.getXMLTree( className );
 				Annotation[] annotations = getJavaAnnotations();
 				List<Annotation> annotationList = new ArrayList<Annotation>( annotations.length + 5 );
 				annotationsMap = new HashMap<Class, Annotation>( annotations.length + 5 );
 				for ( Annotation annotation : annotations ) {
 					if ( !annotationToXml.containsKey( annotation.annotationType() ) ) {
 						//unknown annotations are left over
 						annotationList.add( annotation );
 					}
 				}
 				addIfNotNull( annotationList, getEntity( tree, defaults ) );
 				addIfNotNull( annotationList, getMappedSuperclass( tree, defaults ) );
 				addIfNotNull( annotationList, getEmbeddable( tree, defaults ) );
 				addIfNotNull( annotationList, getTable( tree, defaults ) );
 				addIfNotNull( annotationList, getSecondaryTables( tree, defaults ) );
 				addIfNotNull( annotationList, getPrimaryKeyJoinColumns( tree, defaults, true ) );
 				addIfNotNull( annotationList, getIdClass( tree, defaults ) );
 				addIfNotNull( annotationList, getInheritance( tree, defaults ) );
 				addIfNotNull( annotationList, getDiscriminatorValue( tree, defaults ) );
 				addIfNotNull( annotationList, getDiscriminatorColumn( tree, defaults ) );
 				addIfNotNull( annotationList, getSequenceGenerator( tree, defaults ) );
 				addIfNotNull( annotationList, getTableGenerator( tree, defaults ) );
 				addIfNotNull( annotationList, getNamedQueries( tree, defaults ) );
 				addIfNotNull( annotationList, getNamedNativeQueries( tree, defaults ) );
 				addIfNotNull( annotationList, getSqlResultSetMappings( tree, defaults ) );
 				addIfNotNull( annotationList, getExcludeDefaultListeners( tree, defaults ) );
 				addIfNotNull( annotationList, getExcludeSuperclassListeners( tree, defaults ) );
 				addIfNotNull( annotationList, getAccessType( tree, defaults ) );
 				addIfNotNull( annotationList, getAttributeOverrides( tree, defaults, true ) );
 				addIfNotNull( annotationList, getAssociationOverrides( tree, defaults, true ) );
 				addIfNotNull( annotationList, getEntityListeners( tree, defaults ) );
 				this.annotations = annotationList.toArray( new Annotation[annotationList.size()] );
 				for ( Annotation ann : this.annotations ) {
 					annotationsMap.put( ann.annotationType(), ann );
 				}
 				checkForOrphanProperties( tree );
 			}
 			else if ( className != null ) { //&& propertyName != null ) { //always true but less confusing
 				Element tree = xmlContext.getXMLTree( className );
 				Annotation[] annotations = getJavaAnnotations();
 				List<Annotation> annotationList = new ArrayList<Annotation>( annotations.length + 5 );
 				annotationsMap = new HashMap<Class, Annotation>( annotations.length + 5 );
 				for ( Annotation annotation : annotations ) {
 					if ( !annotationToXml.containsKey( annotation.annotationType() ) ) {
 						//unknown annotations are left over
 						annotationList.add( annotation );
 					}
 				}
 				preCalculateElementsForProperty( tree );
 				Transient transientAnn = getTransient( defaults );
 				if ( transientAnn != null ) {
 					annotationList.add( transientAnn );
 				}
 				else {
 					if ( defaults.canUseJavaAnnotations() ) {
 						Annotation annotation = getJavaAnnotation( Access.class );
 						addIfNotNull( annotationList, annotation );
 					}
 					getId( annotationList, defaults );
 					getEmbeddedId( annotationList, defaults );
 					getEmbedded( annotationList, defaults );
 					getBasic( annotationList, defaults );
 					getVersion( annotationList, defaults );
 					getAssociation( ManyToOne.class, annotationList, defaults );
 					getAssociation( OneToOne.class, annotationList, defaults );
 					getAssociation( OneToMany.class, annotationList, defaults );
 					getAssociation( ManyToMany.class, annotationList, defaults );
 					getElementCollection( annotationList, defaults );
 					addIfNotNull( annotationList, getSequenceGenerator( elementsForProperty, defaults ) );
 					addIfNotNull( annotationList, getTableGenerator( elementsForProperty, defaults ) );
 				}
 				processEventAnnotations( annotationList, defaults );
 				//FIXME use annotationsMap rather than annotationList this will be faster since the annotation type is usually known at put() time
 				this.annotations = annotationList.toArray( new Annotation[annotationList.size()] );
 				for ( Annotation ann : this.annotations ) {
 					annotationsMap.put( ann.annotationType(), ann );
 				}
 			}
 			else {
 				this.annotations = getJavaAnnotations();
 				annotationsMap = new HashMap<Class, Annotation>( annotations.length + 5 );
 				for ( Annotation ann : this.annotations ) {
 					annotationsMap.put( ann.annotationType(), ann );
 				}
 			}
 		}
 	}
 
 	private void checkForOrphanProperties(Element tree) {
 		Class clazz;
 		try {
 			clazz = ReflectHelper.classForName( className, this.getClass() );
 		}
 		catch ( ClassNotFoundException e ) {
 			return; //a primitive type most likely
 		}
 		Element element = tree != null ? tree.element( "attributes" ) : null;
 		//put entity.attributes elements
 		if ( element != null ) {
 			//precompute the list of properties
 			//TODO is it really useful...
 			Set<String> properties = new HashSet<String>();
 			for ( Field field : clazz.getFields() ) {
 				properties.add( field.getName() );
 			}
 			for ( Method method : clazz.getMethods() ) {
 				String name = method.getName();
 				if ( name.startsWith( "get" ) ) {
 					properties.add( Introspector.decapitalize( name.substring( "get".length() ) ) );
 				}
 				else if ( name.startsWith( "is" ) ) {
 					properties.add( Introspector.decapitalize( name.substring( "is".length() ) ) );
 				}
 			}
 			for ( Element subelement : (List<Element>) element.elements() ) {
 				String propertyName = subelement.attributeValue( "name" );
                 if (!properties.contains(propertyName)) LOG.propertyNotFound(StringHelper.qualify(className, propertyName));
 			}
 		}
 	}
 
 	/**
 	 * Adds {@code annotation} to the list (only if it's not null) and then returns it.
 	 *
 	 * @param annotationList The list of annotations.
 	 * @param annotation The annotation to add to the list.
 	 *
 	 * @return The annotation which was added to the list or {@code null}.
 	 */
 	private Annotation addIfNotNull(List<Annotation> annotationList, Annotation annotation) {
 		if ( annotation != null ) {
 			annotationList.add( annotation );
 		}
 		return annotation;
 	}
 
 	//TODO mutualize the next 2 methods
 	private Annotation getTableGenerator(List<Element> elementsForProperty, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			Element subelement = element != null ? element.element( annotationToXml.get( TableGenerator.class ) ) : null;
 			if ( subelement != null ) {
 				return buildTableGeneratorAnnotation( subelement, defaults );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			return getJavaAnnotation( TableGenerator.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private Annotation getSequenceGenerator(List<Element> elementsForProperty, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			Element subelement = element != null ? element.element( annotationToXml.get( SequenceGenerator.class ) ) : null;
 			if ( subelement != null ) {
 				return buildSequenceGeneratorAnnotation( subelement );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			return getJavaAnnotation( SequenceGenerator.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void processEventAnnotations(List<Annotation> annotationList, XMLContext.Default defaults) {
 		boolean eventElement = false;
 		for ( Element element : elementsForProperty ) {
 			String elementName = element.getName();
 			if ( "pre-persist".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PrePersist.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "pre-remove".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PreRemove.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "pre-update".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PreUpdate.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "post-persist".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PostPersist.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "post-remove".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PostRemove.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "post-update".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PostUpdate.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 			else if ( "post-load".equals( elementName ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( PostLoad.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				eventElement = true;
 			}
 		}
 		if ( !eventElement && defaults.canUseJavaAnnotations() ) {
 			Annotation ann = getJavaAnnotation( PrePersist.class );
 			addIfNotNull( annotationList, ann );
 			ann = getJavaAnnotation( PreRemove.class );
 			addIfNotNull( annotationList, ann );
 			ann = getJavaAnnotation( PreUpdate.class );
 			addIfNotNull( annotationList, ann );
 			ann = getJavaAnnotation( PostPersist.class );
 			addIfNotNull( annotationList, ann );
 			ann = getJavaAnnotation( PostRemove.class );
 			addIfNotNull( annotationList, ann );
 			ann = getJavaAnnotation( PostUpdate.class );
 			addIfNotNull( annotationList, ann );
 			ann = getJavaAnnotation( PostLoad.class );
 			addIfNotNull( annotationList, ann );
 		}
 	}
 
 	private EntityListeners getEntityListeners(Element tree, XMLContext.Default defaults) {
 		Element element = tree != null ? tree.element( "entity-listeners" ) : null;
 		if ( element != null ) {
 			List<Class> entityListenerClasses = new ArrayList<Class>();
 			for ( Element subelement : (List<Element>) element.elements( "entity-listener" ) ) {
 				String className = subelement.attributeValue( "class" );
 				try {
 					entityListenerClasses.add(
 							ReflectHelper.classForName(
 									XMLContext.buildSafeClassName( className, defaults ),
 									this.getClass()
 							)
 					);
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException(
 							"Unable to find " + element.getPath() + ".class: " + className, e
 					);
 				}
 			}
 			AnnotationDescriptor ad = new AnnotationDescriptor( EntityListeners.class );
 			ad.setValue( "value", entityListenerClasses.toArray( new Class[entityListenerClasses.size()] ) );
 			return AnnotationFactory.create( ad );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getJavaAnnotation( EntityListeners.class );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private JoinTable overridesDefaultsInJoinTable(Annotation annotation, XMLContext.Default defaults) {
 		//no element but might have some default or some annotation
 		boolean defaultToJoinTable = !( isJavaAnnotationPresent( JoinColumn.class )
 				|| isJavaAnnotationPresent( JoinColumns.class ) );
 		final Class<? extends Annotation> annotationClass = annotation.annotationType();
 		defaultToJoinTable = defaultToJoinTable &&
 				( ( annotationClass == ManyToMany.class && StringHelper.isEmpty( ( (ManyToMany) annotation ).mappedBy() ) )
 						|| ( annotationClass == OneToMany.class && StringHelper.isEmpty( ( (OneToMany) annotation ).mappedBy() ) )
 						|| ( annotationClass == CollectionOfElements.class ) //legacy Hibernate
 						|| ( annotationClass == ElementCollection.class )
 				);
 		final Class<JoinTable> annotationType = JoinTable.class;
 		if ( defaultToJoinTable
 				&& ( StringHelper.isNotEmpty( defaults.getCatalog() )
 				|| StringHelper.isNotEmpty( defaults.getSchema() ) ) ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( annotationType );
 			if ( defaults.canUseJavaAnnotations() ) {
 				JoinTable table = getJavaAnnotation( annotationType );
 				if ( table != null ) {
 					ad.setValue( "name", table.name() );
 					ad.setValue( "schema", table.schema() );
 					ad.setValue( "catalog", table.catalog() );
 					ad.setValue( "uniqueConstraints", table.uniqueConstraints() );
 					ad.setValue( "joinColumns", table.joinColumns() );
 					ad.setValue( "inverseJoinColumns", table.inverseJoinColumns() );
 				}
 			}
 			if ( StringHelper.isEmpty( (String) ad.valueOf( "schema" ) )
 					&& StringHelper.isNotEmpty( defaults.getSchema() ) ) {
 				ad.setValue( "schema", defaults.getSchema() );
 			}
 			if ( StringHelper.isEmpty( (String) ad.valueOf( "catalog" ) )
 					&& StringHelper.isNotEmpty( defaults.getCatalog() ) ) {
 				ad.setValue( "catalog", defaults.getCatalog() );
 			}
 			return AnnotationFactory.create( ad );
 		}
 		else if ( defaults.canUseJavaAnnotations() ) {
 			return getJavaAnnotation( annotationType );
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void getJoinTable(List<Annotation> annotationList, Element tree, XMLContext.Default defaults) {
 		addIfNotNull( annotationList, buildJoinTable( tree, defaults ) );
 	}
 
 	/*
 	 * no partial overriding possible
 	 */
 	private JoinTable buildJoinTable(Element tree, XMLContext.Default defaults) {
 		Element subelement = tree == null ? null : tree.element( "join-table" );
 		final Class<JoinTable> annotationType = JoinTable.class;
 		if ( subelement == null ) {
 			return null;
 		}
 		//ignore java annotation, an element is defined
 		AnnotationDescriptor annotation = new AnnotationDescriptor( annotationType );
 		copyStringAttribute( annotation, subelement, "name", false );
 		copyStringAttribute( annotation, subelement, "catalog", false );
 		if ( StringHelper.isNotEmpty( defaults.getCatalog() )
 				&& StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) ) ) {
 			annotation.setValue( "catalog", defaults.getCatalog() );
 		}
 		copyStringAttribute( annotation, subelement, "schema", false );
 		if ( StringHelper.isNotEmpty( defaults.getSchema() )
 				&& StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) ) ) {
 			annotation.setValue( "schema", defaults.getSchema() );
 		}
 		buildUniqueConstraints( annotation, subelement );
 		annotation.setValue( "joinColumns", getJoinColumns( subelement, false ) );
 		annotation.setValue( "inverseJoinColumns", getJoinColumns( subelement, true ) );
 		return AnnotationFactory.create( annotation );
 	}
 
 	/**
 	 * As per section 12.2 of the JPA 2.0 specification, the association
 	 * subelements (many-to-one, one-to-many, one-to-one, many-to-many,
 	 * element-collection) completely override the mapping for the specified
 	 * field or property.  Thus, any methods which might in some contexts merge
 	 * with annotations must not do so in this context.
 	 *
 	 * @see #getElementCollection(List, org.hibernate.cfg.annotations.reflection.XMLContext.Default)
 	 */
 	private void getAssociation(
 			Class<? extends Annotation> annotationType, List<Annotation> annotationList, XMLContext.Default defaults
 	) {
 		String xmlName = annotationToXml.get( annotationType );
 		for ( Element element : elementsForProperty ) {
 			if ( xmlName.equals( element.getName() ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( annotationType );
 				addTargetClass( element, ad, "target-entity", defaults );
 				getFetchType( ad, element );
 				getCascades( ad, element, defaults );
 				getJoinTable( annotationList, element, defaults );
 				buildJoinColumns( annotationList, element );
 				Annotation annotation = getPrimaryKeyJoinColumns( element, defaults, false );
 				addIfNotNull( annotationList, annotation );
 				copyBooleanAttribute( ad, element, "optional" );
 				copyBooleanAttribute( ad, element, "orphan-removal" );
 				copyStringAttribute( ad, element, "mapped-by", false );
 				getOrderBy( annotationList, element );
 				getMapKey( annotationList, element );
 				getMapKeyClass( annotationList, element, defaults );
 				getMapKeyColumn( annotationList, element );
 				getOrderColumn( annotationList, element );
 				getMapKeyTemporal( annotationList, element );
 				getMapKeyEnumerated( annotationList, element );
 				annotation = getMapKeyAttributeOverrides( element, defaults );
 				addIfNotNull( annotationList, annotation );
 				buildMapKeyJoinColumns( annotationList, element );
 				getAssociationId( annotationList, element );
 				getMapsId( annotationList, element );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				getAccessType( annotationList, element );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			Annotation annotation = getJavaAnnotation( annotationType );
 			if ( annotation != null ) {
 				annotationList.add( annotation );
 				annotation = overridesDefaultsInJoinTable( annotation, defaults );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( JoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( JoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( PrimaryKeyJoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( PrimaryKeyJoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKey.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( OrderBy.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AttributeOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AttributeOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AssociationOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AssociationOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Lob.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Enumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Temporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Column.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Columns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyClass.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyTemporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyEnumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyJoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyJoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( OrderColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Cascade.class );
 				addIfNotNull( annotationList, annotation );
 			}
 			else if ( isJavaAnnotationPresent( ElementCollection.class ) ) { //JPA2
 				annotation = overridesDefaultsInJoinTable( getJavaAnnotation( ElementCollection.class ), defaults );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKey.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( OrderBy.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AttributeOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AttributeOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AssociationOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AssociationOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Lob.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Enumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Temporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Column.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( OrderColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyClass.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyTemporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyEnumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyJoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKeyJoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( CollectionTable.class );
 				addIfNotNull( annotationList, annotation );
 			}
 			else if ( isJavaAnnotationPresent( CollectionOfElements.class ) ) { //legacy Hibernate
 				annotation = overridesDefaultsInJoinTable( getJavaAnnotation( CollectionOfElements.class ), defaults );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( JoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( JoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( PrimaryKeyJoinColumn.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( PrimaryKeyJoinColumns.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( MapKey.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( OrderBy.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AttributeOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AttributeOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AssociationOverride.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( AssociationOverrides.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Lob.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Enumerated.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Temporal.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Column.class );
 				addIfNotNull( annotationList, annotation );
 				annotation = getJavaAnnotation( Columns.class );
 				addIfNotNull( annotationList, annotation );
 			}
 		}
 	}
 
 	private void buildMapKeyJoinColumns(List<Annotation> annotationList, Element element) {
 		MapKeyJoinColumn[] joinColumns = getMapKeyJoinColumns( element );
 		if ( joinColumns.length > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyJoinColumns.class );
 			ad.setValue( "value", joinColumns );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private MapKeyJoinColumn[] getMapKeyJoinColumns(Element element) {
 		List<Element> subelements = element != null ? element.elements( "map-key-join-column" ) : null;
 		List<MapKeyJoinColumn> joinColumns = new ArrayList<MapKeyJoinColumn>();
 		if ( subelements != null ) {
 			for ( Element subelement : subelements ) {
 				AnnotationDescriptor column = new AnnotationDescriptor( MapKeyJoinColumn.class );
 				copyStringAttribute( column, subelement, "name", false );
 				copyStringAttribute( column, subelement, "referenced-column-name", false );
 				copyBooleanAttribute( column, subelement, "unique" );
 				copyBooleanAttribute( column, subelement, "nullable" );
 				copyBooleanAttribute( column, subelement, "insertable" );
 				copyBooleanAttribute( column, subelement, "updatable" );
 				copyStringAttribute( column, subelement, "column-definition", false );
 				copyStringAttribute( column, subelement, "table", false );
 				joinColumns.add( (MapKeyJoinColumn) AnnotationFactory.create( column ) );
 			}
 		}
 		return joinColumns.toArray( new MapKeyJoinColumn[joinColumns.size()] );
 	}
 
 	private AttributeOverrides getMapKeyAttributeOverrides(Element tree, XMLContext.Default defaults) {
 		List<AttributeOverride> attributes = buildAttributeOverrides( tree, "map-key-attribute-override" );
 		return mergeAttributeOverrides( defaults, attributes, false );
 	}
 
 	/**
 	 * Adds a @MapKeyEnumerated annotation to the specified annotationList if the specified element
 	 * contains a map-key-enumerated sub-element. This should only be the case for
 	 * element-collection, many-to-many, or one-to-many associations.
 	 */
 	private void getMapKeyEnumerated(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "map-key-enumerated" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyEnumerated.class );
 			EnumType value = EnumType.valueOf( subelement.getTextTrim() );
 			ad.setValue( "value", value );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * Adds a @MapKeyTemporal annotation to the specified annotationList if the specified element
 	 * contains a map-key-temporal sub-element. This should only be the case for element-collection,
 	 * many-to-many, or one-to-many associations.
 	 */
 	private void getMapKeyTemporal(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "map-key-temporal" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyTemporal.class );
 			TemporalType value = TemporalType.valueOf( subelement.getTextTrim() );
 			ad.setValue( "value", value );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * Adds an @OrderColumn annotation to the specified annotationList if the specified element
 	 * contains an order-column sub-element. This should only be the case for element-collection,
 	 * many-to-many, or one-to-many associations.
 	 */
 	private void getOrderColumn(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "order-column" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( OrderColumn.class );
 			copyStringAttribute( ad, subelement, "name", false );
 			copyBooleanAttribute( ad, subelement, "nullable" );
 			copyBooleanAttribute( ad, subelement, "insertable" );
 			copyBooleanAttribute( ad, subelement, "updatable" );
 			copyStringAttribute( ad, subelement, "column-definition", false );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * Adds a @MapsId annotation to the specified annotationList if the specified element has the
 	 * maps-id attribute set. This should only be the case for many-to-one or one-to-one
 	 * associations.
 	 */
 	private void getMapsId(List<Annotation> annotationList, Element element) {
 		String attrVal = element.attributeValue( "maps-id" );
 		if ( attrVal != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapsId.class );
 			ad.setValue( "value", attrVal );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	/**
 	 * Adds an @Id annotation to the specified annotationList if the specified element has the id
 	 * attribute set to true. This should only be the case for many-to-one or one-to-one
 	 * associations.
 	 */
 	private void getAssociationId(List<Annotation> annotationList, Element element) {
 		String attrVal = element.attributeValue( "id" );
 		if ( "true".equals( attrVal ) ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( Id.class );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void addTargetClass(Element element, AnnotationDescriptor ad, String nodeName, XMLContext.Default defaults) {
 		String className = element.attributeValue( nodeName );
 		if ( className != null ) {
 			Class clazz;
 			try {
 				clazz = ReflectHelper.classForName(
 						XMLContext.buildSafeClassName( className, defaults ), this.getClass()
 				);
 			}
 			catch ( ClassNotFoundException e ) {
 				throw new AnnotationException(
 						"Unable to find " + element.getPath() + " " + nodeName + ": " + className, e
 				);
 			}
 			ad.setValue( getJavaAttributeNameFromXMLOne( nodeName ), clazz );
 		}
 	}
 
 	/**
 	 * As per sections 12.2.3.23.9, 12.2.4.8.9 and 12.2.5.3.6 of the JPA 2.0
 	 * specification, the element-collection subelement completely overrides the
 	 * mapping for the specified field or property.  Thus, any methods which
 	 * might in some contexts merge with annotations must not do so in this
 	 * context.
 	 */
 	private void getElementCollection(List<Annotation> annotationList, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "element-collection".equals( element.getName() ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( ElementCollection.class );
 				addTargetClass( element, ad, "target-class", defaults );
 				getFetchType( ad, element );
 				getOrderBy( annotationList, element );
 				getOrderColumn( annotationList, element );
 				getMapKey( annotationList, element );
 				getMapKeyClass( annotationList, element, defaults );
 				getMapKeyTemporal( annotationList, element );
 				getMapKeyEnumerated( annotationList, element );
 				getMapKeyColumn( annotationList, element );
 				buildMapKeyJoinColumns( annotationList, element );
 				Annotation annotation = getColumn( element.element( "column" ), false, element );
 				addIfNotNull( annotationList, annotation );
 				getTemporal( annotationList, element );
 				getEnumerated( annotationList, element );
 				getLob( annotationList, element );
 				//Both map-key-attribute-overrides and attribute-overrides
 				//translate into AttributeOverride annotations, which need
 				//need to be wrapped in the same AttributeOverrides annotation.
 				List<AttributeOverride> attributes = new ArrayList<AttributeOverride>();
 				attributes.addAll( buildAttributeOverrides( element, "map-key-attribute-override" ) );
 				attributes.addAll( buildAttributeOverrides( element, "attribute-override" ) );
 				annotation = mergeAttributeOverrides( defaults, attributes, false );
 				addIfNotNull( annotationList, annotation );
 				annotation = getAssociationOverrides( element, defaults, false );
 				addIfNotNull( annotationList, annotation );
 				getCollectionTable( annotationList, element, defaults );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				getAccessType( annotationList, element );
 			}
 		}
 	}
 
 	private void getOrderBy(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "order-by" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( OrderBy.class );
 			copyStringElement( subelement, ad, "value" );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getMapKey(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "map-key" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKey.class );
 			copyStringAttribute( ad, subelement, "name", false );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getMapKeyColumn(List<Annotation> annotationList, Element element) {
 		Element subelement = element != null ? element.element( "map-key-column" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyColumn.class );
 			copyStringAttribute( ad, subelement, "name", false );
 			copyBooleanAttribute( ad, subelement, "unique" );
 			copyBooleanAttribute( ad, subelement, "nullable" );
 			copyBooleanAttribute( ad, subelement, "insertable" );
 			copyBooleanAttribute( ad, subelement, "updatable" );
 			copyStringAttribute( ad, subelement, "column-definition", false );
 			copyStringAttribute( ad, subelement, "table", false );
 			copyIntegerAttribute( ad, subelement, "length" );
 			copyIntegerAttribute( ad, subelement, "precision" );
 			copyIntegerAttribute( ad, subelement, "scale" );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getMapKeyClass(List<Annotation> annotationList, Element element, XMLContext.Default defaults) {
 		String nodeName = "map-key-class";
 		Element subelement = element != null ? element.element( nodeName ) : null;
 		if ( subelement != null ) {
 			String mapKeyClassName = subelement.attributeValue( "class" );
 			AnnotationDescriptor ad = new AnnotationDescriptor( MapKeyClass.class );
 			if ( StringHelper.isNotEmpty( mapKeyClassName ) ) {
 				Class clazz;
 				try {
 					clazz = ReflectHelper.classForName(
 							XMLContext.buildSafeClassName( mapKeyClassName, defaults ),
 							this.getClass()
 					);
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException(
 							"Unable to find " + element.getPath() + " " + nodeName + ": " + mapKeyClassName, e
 					);
 				}
 				ad.setValue( "value", clazz );
 			}
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getCollectionTable(List<Annotation> annotationList, Element element, XMLContext.Default defaults) {
 		Element subelement = element != null ? element.element( "collection-table" ) : null;
 		if ( subelement != null ) {
 			AnnotationDescriptor annotation = new AnnotationDescriptor( CollectionTable.class );
 			copyStringAttribute( annotation, subelement, "name", false );
 			copyStringAttribute( annotation, subelement, "catalog", false );
 			if ( StringHelper.isNotEmpty( defaults.getCatalog() )
 					&& StringHelper.isEmpty( (String) annotation.valueOf( "catalog" ) ) ) {
 				annotation.setValue( "catalog", defaults.getCatalog() );
 			}
 			copyStringAttribute( annotation, subelement, "schema", false );
 			if ( StringHelper.isNotEmpty( defaults.getSchema() )
 					&& StringHelper.isEmpty( (String) annotation.valueOf( "schema" ) ) ) {
 				annotation.setValue( "schema", defaults.getSchema() );
 			}
 			JoinColumn[] joinColumns = getJoinColumns( subelement, false );
 			if ( joinColumns.length > 0 ) {
 				annotation.setValue( "joinColumns", joinColumns );
 			}
 			buildUniqueConstraints( annotation, subelement );
 			annotationList.add( AnnotationFactory.create( annotation ) );
 		}
 	}
 
 	private void buildJoinColumns(List<Annotation> annotationList, Element element) {
 		JoinColumn[] joinColumns = getJoinColumns( element, false );
 		if ( joinColumns.length > 0 ) {
 			AnnotationDescriptor ad = new AnnotationDescriptor( JoinColumns.class );
 			ad.setValue( "value", joinColumns );
 			annotationList.add( AnnotationFactory.create( ad ) );
 		}
 	}
 
 	private void getCascades(AnnotationDescriptor ad, Element element, XMLContext.Default defaults) {
 		List<Element> elements = element != null ? element.elements( "cascade" ) : new ArrayList<Element>( 0 );
 		List<CascadeType> cascades = new ArrayList<CascadeType>();
 		for ( Element subelement : elements ) {
 			if ( subelement.element( "cascade-all" ) != null ) {
 				cascades.add( CascadeType.ALL );
 			}
 			if ( subelement.element( "cascade-persist" ) != null ) {
 				cascades.add( CascadeType.PERSIST );
 			}
 			if ( subelement.element( "cascade-merge" ) != null ) {
 				cascades.add( CascadeType.MERGE );
 			}
 			if ( subelement.element( "cascade-remove" ) != null ) {
 				cascades.add( CascadeType.REMOVE );
 			}
 			if ( subelement.element( "cascade-refresh" ) != null ) {
 				cascades.add( CascadeType.REFRESH );
 			}
 			if ( subelement.element( "cascade-detach" ) != null ) {
 				cascades.add( CascadeType.DETACH );
 			}
 		}
 		if ( Boolean.TRUE.equals( defaults.getCascadePersist() )
 				&& !cascades.contains( CascadeType.ALL ) && !cascades.contains( CascadeType.PERSIST ) ) {
 			cascades.add( CascadeType.PERSIST );
 		}
 		if ( cascades.size() > 0 ) {
 			ad.setValue( "cascade", cascades.toArray( new CascadeType[cascades.size()] ) );
 		}
 	}
 
 	private void getEmbedded(List<Annotation> annotationList, XMLContext.Default defaults) {
 		for ( Element element : elementsForProperty ) {
 			if ( "embedded".equals( element.getName() ) ) {
 				AnnotationDescriptor ad = new AnnotationDescriptor( Embedded.class );
 				annotationList.add( AnnotationFactory.create( ad ) );
 				Annotation annotation = getAttributeOverrides( element, defaults, false );
 				addIfNotNull( annotationList, annotation );
 				annotation = getAssociationOverrides( element, defaults, false );
 				addIfNotNull( annotationList, annotation );
 				getAccessType( annotationList, element );
 			}
 		}
 		if ( elementsForProperty.size() == 0 && defaults.canUseJavaAnnotations() ) {
 			Annotation annotation = getJavaAnnotation( Embedded.class );
 			if ( annotation != null ) {
 				annotationList.add( annotation );
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/XMLContext.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/XMLContext.java
index f8006c678a..91eea38229 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/XMLContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/reflection/XMLContext.java
@@ -1,307 +1,307 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-
-// $Id$
-
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+
+// $Id$
+
 package org.hibernate.cfg.annotations.reflection;
-
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import javax.persistence.AccessType;
-import org.dom4j.Document;
-import org.dom4j.Element;
-import org.hibernate.AnnotationException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.internal.util.StringHelper;
-import org.jboss.logging.Logger;
-
-/**
- * @author Emmanuel Bernard
- */
-public class XMLContext implements Serializable {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, XMLContext.class.getName());
-	private Default globalDefaults;
-	private Map<String, Element> classOverriding = new HashMap<String, Element>();
-	private Map<String, Default> defaultsOverriding = new HashMap<String, Default>();
-	private List<Element> defaultElements = new ArrayList<Element>();
-	private List<String> defaultEntityListeners = new ArrayList<String>();
-	private boolean hasContext = false;
-
-	/**
-	 * @param doc The xml document to add
-	 * @return Add a xml document to this context and return the list of added class names.
-	 */
-	@SuppressWarnings( "unchecked" )
-	public List<String> addDocument(Document doc) {
-		hasContext = true;
-		List<String> addedClasses = new ArrayList<String>();
-		Element root = doc.getRootElement();
-		//global defaults
-		Element metadata = root.element( "persistence-unit-metadata" );
-		if ( metadata != null ) {
-			if ( globalDefaults == null ) {
-				globalDefaults = new Default();
-				globalDefaults.setMetadataComplete(
-						metadata.element( "xml-mapping-metadata-complete" ) != null ?
-								Boolean.TRUE :
-								null
-				);
-				Element defaultElement = metadata.element( "persistence-unit-defaults" );
-				if ( defaultElement != null ) {
-					Element unitElement = defaultElement.element( "schema" );
-					globalDefaults.setSchema( unitElement != null ? unitElement.getTextTrim() : null );
-					unitElement = defaultElement.element( "catalog" );
-					globalDefaults.setCatalog( unitElement != null ? unitElement.getTextTrim() : null );
-					unitElement = defaultElement.element( "access" );
-					setAccess( unitElement, globalDefaults );
-					unitElement = defaultElement.element( "cascade-persist" );
-					globalDefaults.setCascadePersist( unitElement != null ? Boolean.TRUE : null );
-					unitElement = defaultElement.element( "delimited-identifiers" );
-					globalDefaults.setDelimitedIdentifiers( unitElement != null ? Boolean.TRUE : null );
-					defaultEntityListeners.addAll( addEntityListenerClasses( defaultElement, null, addedClasses ) );
-				}
-			}
-			else {
-                LOG.duplicateMetadata();
-			}
-		}
-
-		//entity mapping default
-		Default entityMappingDefault = new Default();
-		Element unitElement = root.element( "package" );
-		String packageName = unitElement != null ? unitElement.getTextTrim() : null;
-		entityMappingDefault.setPackageName( packageName );
-		unitElement = root.element( "schema" );
-		entityMappingDefault.setSchema( unitElement != null ? unitElement.getTextTrim() : null );
-		unitElement = root.element( "catalog" );
-		entityMappingDefault.setCatalog( unitElement != null ? unitElement.getTextTrim() : null );
-		unitElement = root.element( "access" );
-		setAccess( unitElement, entityMappingDefault );
-		defaultElements.add( root );
-
-		List<Element> entities = root.elements( "entity" );
-		addClass( entities, packageName, entityMappingDefault, addedClasses );
-
-		entities = root.elements( "mapped-superclass" );
-		addClass( entities, packageName, entityMappingDefault, addedClasses );
-
-		entities = root.elements( "embeddable" );
-		addClass( entities, packageName, entityMappingDefault, addedClasses );
-		return addedClasses;
-	}
-
-	private void setAccess(Element unitElement, Default defaultType) {
-		if ( unitElement != null ) {
-			String access = unitElement.getTextTrim();
-			setAccess( access, defaultType );
-		}
-	}
-
-	private void setAccess( String access, Default defaultType) {
-		AccessType type;
-		if ( access != null ) {
-			try {
-				type = AccessType.valueOf( access );
-			}
-			catch ( IllegalArgumentException e ) {
-				throw new AnnotationException( "Invalid access type " + access + " (check your xml configuration)" );
-			}
-			defaultType.setAccess( type );
-		}
-	}
-
-	private void addClass(List<Element> entities, String packageName, Default defaults, List<String> addedClasses) {
-		for (Element element : entities) {
-			String className = buildSafeClassName( element.attributeValue( "class" ), packageName );
-			if ( classOverriding.containsKey( className ) ) {
-				//maybe switch it to warn?
-				throw new IllegalStateException( "Duplicate XML entry for " + className );
-			}
-			addedClasses.add( className );
-			classOverriding.put( className, element );
-			Default localDefault = new Default();
-			localDefault.override( defaults );
-			String metadataCompleteString = element.attributeValue( "metadata-complete" );
-			if ( metadataCompleteString != null ) {
-				localDefault.setMetadataComplete( Boolean.parseBoolean( metadataCompleteString ) );
-			}
-			String access = element.attributeValue( "access" );
-			setAccess( access, localDefault );
-			defaultsOverriding.put( className, localDefault );
-
-            LOG.debugf("Adding XML overriding information for %s", className);
-			addEntityListenerClasses( element, packageName, addedClasses );
-		}
-	}
-
-	private List<String> addEntityListenerClasses(Element element, String packageName, List<String> addedClasses) {
-		List<String> localAddedClasses = new ArrayList<String>();
-		Element listeners = element.element( "entity-listeners" );
-		if ( listeners != null ) {
-			@SuppressWarnings( "unchecked" )
-			List<Element> elements = listeners.elements( "entity-listener" );
-			for (Element listener : elements) {
-				String listenerClassName = buildSafeClassName( listener.attributeValue( "class" ), packageName );
-				if ( classOverriding.containsKey( listenerClassName ) ) {
-					//maybe switch it to warn?
-					if ( "entity-listener".equals( classOverriding.get( listenerClassName ).getName() ) ) {
-                        LOG.duplicateListener(listenerClassName);
-						continue;
-					}
-                    throw new IllegalStateException("Duplicate XML entry for " + listenerClassName);
-				}
-				localAddedClasses.add( listenerClassName );
-				classOverriding.put( listenerClassName, listener );
-			}
-		}
-        LOG.debugf("Adding XML overriding information for listeners: %s", localAddedClasses);
-		addedClasses.addAll( localAddedClasses );
-		return localAddedClasses;
-	}
-
-	public static String buildSafeClassName(String className, String defaultPackageName) {
-		if ( className.indexOf( '.' ) < 0 && StringHelper.isNotEmpty( defaultPackageName ) ) {
-			className = StringHelper.qualify( defaultPackageName, className );
-		}
-		return className;
-	}
-
-	public static String buildSafeClassName(String className, XMLContext.Default defaults) {
-		return buildSafeClassName( className, defaults.getPackageName() );
-	}
-
-	public Default getDefault(String className) {
-		Default xmlDefault = new Default();
-		xmlDefault.override( globalDefaults );
-		if ( className != null ) {
-			Default entityMappingOverriding = defaultsOverriding.get( className );
-			xmlDefault.override( entityMappingOverriding );
-		}
-		return xmlDefault;
-	}
-
-	public Element getXMLTree(String className ) {
-		return classOverriding.get( className );
-	}
-
-	public List<Element> getAllDocuments() {
-		return defaultElements;
-	}
-
-	public boolean hasContext() {
-		return hasContext;
-	}
-
-	public static class Default implements Serializable {
-		private AccessType access;
-		private String packageName;
-		private String schema;
-		private String catalog;
-		private Boolean metadataComplete;
-		private Boolean cascadePersist;
-		private Boolean delimitedIdentifier;
-
-		public AccessType getAccess() {
-			return access;
-		}
-
-		protected void setAccess(AccessType access) {
-			this.access = access;
-		}
-
-		public String getCatalog() {
-			return catalog;
-		}
-
-		protected void setCatalog(String catalog) {
-			this.catalog = catalog;
-		}
-
-		public String getPackageName() {
-			return packageName;
-		}
-
-		protected void setPackageName(String packageName) {
-			this.packageName = packageName;
-		}
-
-		public String getSchema() {
-			return schema;
-		}
-
-		protected void setSchema(String schema) {
-			this.schema = schema;
-		}
-
-		public Boolean getMetadataComplete() {
-			return metadataComplete;
-		}
-
-		public boolean canUseJavaAnnotations() {
-			return metadataComplete == null || !metadataComplete;
-		}
-
-		protected void setMetadataComplete(Boolean metadataComplete) {
-			this.metadataComplete = metadataComplete;
-		}
-
-		public Boolean getCascadePersist() {
-			return cascadePersist;
-		}
-
-		void setCascadePersist(Boolean cascadePersist) {
-			this.cascadePersist = cascadePersist;
-		}
-
-		public void override(Default globalDefault) {
-			if ( globalDefault != null ) {
-				if ( globalDefault.getAccess() != null ) access = globalDefault.getAccess();
-				if ( globalDefault.getPackageName() != null ) packageName = globalDefault.getPackageName();
-				if ( globalDefault.getSchema() != null ) schema = globalDefault.getSchema();
-				if ( globalDefault.getCatalog() != null ) catalog = globalDefault.getCatalog();
-				if ( globalDefault.getDelimitedIdentifier() != null ) delimitedIdentifier = globalDefault.getDelimitedIdentifier();
-				if ( globalDefault.getMetadataComplete() != null ) {
-					metadataComplete = globalDefault.getMetadataComplete();
-				}
-				//TODO fix that in stone if cascade-persist is set already?
-				if ( globalDefault.getCascadePersist() != null ) cascadePersist = globalDefault.getCascadePersist();
-			}
-		}
-
-		public void setDelimitedIdentifiers(Boolean delimitedIdentifier) {
-			this.delimitedIdentifier = delimitedIdentifier;
-		}
-
-		public Boolean getDelimitedIdentifier() {
-			return delimitedIdentifier;
-		}
-	}
-
-	public List<String> getDefaultEntityListeners() {
-		return defaultEntityListeners;
-	}
-}
+
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import javax.persistence.AccessType;
+import org.dom4j.Document;
+import org.dom4j.Element;
+import org.hibernate.AnnotationException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.internal.util.StringHelper;
+import org.jboss.logging.Logger;
+
+/**
+ * @author Emmanuel Bernard
+ */
+public class XMLContext implements Serializable {
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, XMLContext.class.getName());
+	private Default globalDefaults;
+	private Map<String, Element> classOverriding = new HashMap<String, Element>();
+	private Map<String, Default> defaultsOverriding = new HashMap<String, Default>();
+	private List<Element> defaultElements = new ArrayList<Element>();
+	private List<String> defaultEntityListeners = new ArrayList<String>();
+	private boolean hasContext = false;
+
+	/**
+	 * @param doc The xml document to add
+	 * @return Add a xml document to this context and return the list of added class names.
+	 */
+	@SuppressWarnings( "unchecked" )
+	public List<String> addDocument(Document doc) {
+		hasContext = true;
+		List<String> addedClasses = new ArrayList<String>();
+		Element root = doc.getRootElement();
+		//global defaults
+		Element metadata = root.element( "persistence-unit-metadata" );
+		if ( metadata != null ) {
+			if ( globalDefaults == null ) {
+				globalDefaults = new Default();
+				globalDefaults.setMetadataComplete(
+						metadata.element( "xml-mapping-metadata-complete" ) != null ?
+								Boolean.TRUE :
+								null
+				);
+				Element defaultElement = metadata.element( "persistence-unit-defaults" );
+				if ( defaultElement != null ) {
+					Element unitElement = defaultElement.element( "schema" );
+					globalDefaults.setSchema( unitElement != null ? unitElement.getTextTrim() : null );
+					unitElement = defaultElement.element( "catalog" );
+					globalDefaults.setCatalog( unitElement != null ? unitElement.getTextTrim() : null );
+					unitElement = defaultElement.element( "access" );
+					setAccess( unitElement, globalDefaults );
+					unitElement = defaultElement.element( "cascade-persist" );
+					globalDefaults.setCascadePersist( unitElement != null ? Boolean.TRUE : null );
+					unitElement = defaultElement.element( "delimited-identifiers" );
+					globalDefaults.setDelimitedIdentifiers( unitElement != null ? Boolean.TRUE : null );
+					defaultEntityListeners.addAll( addEntityListenerClasses( defaultElement, null, addedClasses ) );
+				}
+			}
+			else {
+                LOG.duplicateMetadata();
+			}
+		}
+
+		//entity mapping default
+		Default entityMappingDefault = new Default();
+		Element unitElement = root.element( "package" );
+		String packageName = unitElement != null ? unitElement.getTextTrim() : null;
+		entityMappingDefault.setPackageName( packageName );
+		unitElement = root.element( "schema" );
+		entityMappingDefault.setSchema( unitElement != null ? unitElement.getTextTrim() : null );
+		unitElement = root.element( "catalog" );
+		entityMappingDefault.setCatalog( unitElement != null ? unitElement.getTextTrim() : null );
+		unitElement = root.element( "access" );
+		setAccess( unitElement, entityMappingDefault );
+		defaultElements.add( root );
+
+		List<Element> entities = root.elements( "entity" );
+		addClass( entities, packageName, entityMappingDefault, addedClasses );
+
+		entities = root.elements( "mapped-superclass" );
+		addClass( entities, packageName, entityMappingDefault, addedClasses );
+
+		entities = root.elements( "embeddable" );
+		addClass( entities, packageName, entityMappingDefault, addedClasses );
+		return addedClasses;
+	}
+
+	private void setAccess(Element unitElement, Default defaultType) {
+		if ( unitElement != null ) {
+			String access = unitElement.getTextTrim();
+			setAccess( access, defaultType );
+		}
+	}
+
+	private void setAccess( String access, Default defaultType) {
+		AccessType type;
+		if ( access != null ) {
+			try {
+				type = AccessType.valueOf( access );
+			}
+			catch ( IllegalArgumentException e ) {
+				throw new AnnotationException( "Invalid access type " + access + " (check your xml configuration)" );
+			}
+			defaultType.setAccess( type );
+		}
+	}
+
+	private void addClass(List<Element> entities, String packageName, Default defaults, List<String> addedClasses) {
+		for (Element element : entities) {
+			String className = buildSafeClassName( element.attributeValue( "class" ), packageName );
+			if ( classOverriding.containsKey( className ) ) {
+				//maybe switch it to warn?
+				throw new IllegalStateException( "Duplicate XML entry for " + className );
+			}
+			addedClasses.add( className );
+			classOverriding.put( className, element );
+			Default localDefault = new Default();
+			localDefault.override( defaults );
+			String metadataCompleteString = element.attributeValue( "metadata-complete" );
+			if ( metadataCompleteString != null ) {
+				localDefault.setMetadataComplete( Boolean.parseBoolean( metadataCompleteString ) );
+			}
+			String access = element.attributeValue( "access" );
+			setAccess( access, localDefault );
+			defaultsOverriding.put( className, localDefault );
+
+            LOG.debugf("Adding XML overriding information for %s", className);
+			addEntityListenerClasses( element, packageName, addedClasses );
+		}
+	}
+
+	private List<String> addEntityListenerClasses(Element element, String packageName, List<String> addedClasses) {
+		List<String> localAddedClasses = new ArrayList<String>();
+		Element listeners = element.element( "entity-listeners" );
+		if ( listeners != null ) {
+			@SuppressWarnings( "unchecked" )
+			List<Element> elements = listeners.elements( "entity-listener" );
+			for (Element listener : elements) {
+				String listenerClassName = buildSafeClassName( listener.attributeValue( "class" ), packageName );
+				if ( classOverriding.containsKey( listenerClassName ) ) {
+					//maybe switch it to warn?
+					if ( "entity-listener".equals( classOverriding.get( listenerClassName ).getName() ) ) {
+                        LOG.duplicateListener(listenerClassName);
+						continue;
+					}
+                    throw new IllegalStateException("Duplicate XML entry for " + listenerClassName);
+				}
+				localAddedClasses.add( listenerClassName );
+				classOverriding.put( listenerClassName, listener );
+			}
+		}
+        LOG.debugf("Adding XML overriding information for listeners: %s", localAddedClasses);
+		addedClasses.addAll( localAddedClasses );
+		return localAddedClasses;
+	}
+
+	public static String buildSafeClassName(String className, String defaultPackageName) {
+		if ( className.indexOf( '.' ) < 0 && StringHelper.isNotEmpty( defaultPackageName ) ) {
+			className = StringHelper.qualify( defaultPackageName, className );
+		}
+		return className;
+	}
+
+	public static String buildSafeClassName(String className, XMLContext.Default defaults) {
+		return buildSafeClassName( className, defaults.getPackageName() );
+	}
+
+	public Default getDefault(String className) {
+		Default xmlDefault = new Default();
+		xmlDefault.override( globalDefaults );
+		if ( className != null ) {
+			Default entityMappingOverriding = defaultsOverriding.get( className );
+			xmlDefault.override( entityMappingOverriding );
+		}
+		return xmlDefault;
+	}
+
+	public Element getXMLTree(String className ) {
+		return classOverriding.get( className );
+	}
+
+	public List<Element> getAllDocuments() {
+		return defaultElements;
+	}
+
+	public boolean hasContext() {
+		return hasContext;
+	}
+
+	public static class Default implements Serializable {
+		private AccessType access;
+		private String packageName;
+		private String schema;
+		private String catalog;
+		private Boolean metadataComplete;
+		private Boolean cascadePersist;
+		private Boolean delimitedIdentifier;
+
+		public AccessType getAccess() {
+			return access;
+		}
+
+		protected void setAccess(AccessType access) {
+			this.access = access;
+		}
+
+		public String getCatalog() {
+			return catalog;
+		}
+
+		protected void setCatalog(String catalog) {
+			this.catalog = catalog;
+		}
+
+		public String getPackageName() {
+			return packageName;
+		}
+
+		protected void setPackageName(String packageName) {
+			this.packageName = packageName;
+		}
+
+		public String getSchema() {
+			return schema;
+		}
+
+		protected void setSchema(String schema) {
+			this.schema = schema;
+		}
+
+		public Boolean getMetadataComplete() {
+			return metadataComplete;
+		}
+
+		public boolean canUseJavaAnnotations() {
+			return metadataComplete == null || !metadataComplete;
+		}
+
+		protected void setMetadataComplete(Boolean metadataComplete) {
+			this.metadataComplete = metadataComplete;
+		}
+
+		public Boolean getCascadePersist() {
+			return cascadePersist;
+		}
+
+		void setCascadePersist(Boolean cascadePersist) {
+			this.cascadePersist = cascadePersist;
+		}
+
+		public void override(Default globalDefault) {
+			if ( globalDefault != null ) {
+				if ( globalDefault.getAccess() != null ) access = globalDefault.getAccess();
+				if ( globalDefault.getPackageName() != null ) packageName = globalDefault.getPackageName();
+				if ( globalDefault.getSchema() != null ) schema = globalDefault.getSchema();
+				if ( globalDefault.getCatalog() != null ) catalog = globalDefault.getCatalog();
+				if ( globalDefault.getDelimitedIdentifier() != null ) delimitedIdentifier = globalDefault.getDelimitedIdentifier();
+				if ( globalDefault.getMetadataComplete() != null ) {
+					metadataComplete = globalDefault.getMetadataComplete();
+				}
+				//TODO fix that in stone if cascade-persist is set already?
+				if ( globalDefault.getCascadePersist() != null ) cascadePersist = globalDefault.getCascadePersist();
+			}
+		}
+
+		public void setDelimitedIdentifiers(Boolean delimitedIdentifier) {
+			this.delimitedIdentifier = delimitedIdentifier;
+		}
+
+		public Boolean getDelimitedIdentifier() {
+			return delimitedIdentifier;
+		}
+	}
+
+	public List<String> getDefaultEntityListeners() {
+		return defaultEntityListeners;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/BeanValidationEventListener.java b/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/BeanValidationEventListener.java
index ba3330c353..658586f300 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/BeanValidationEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/BeanValidationEventListener.java
@@ -1,173 +1,174 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.beanvalidation;
 import java.util.HashSet;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 import javax.validation.ConstraintViolation;
 import javax.validation.ConstraintViolationException;
 import javax.validation.TraversableResolver;
 import javax.validation.Validation;
 import javax.validation.Validator;
 import javax.validation.ValidatorFactory;
 import org.hibernate.EntityMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.event.Initializable;
 import org.hibernate.event.PreDeleteEvent;
 import org.hibernate.event.PreDeleteEventListener;
 import org.hibernate.event.PreInsertEvent;
 import org.hibernate.event.PreInsertEventListener;
 import org.hibernate.event.PreUpdateEvent;
 import org.hibernate.event.PreUpdateEventListener;
 import org.hibernate.persister.entity.EntityPersister;
+
 import org.jboss.logging.Logger;
 
 /**
  * Event listener used to enable Bean Validation for insert/update/delete events.
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 //FIXME review exception model
 public class BeanValidationEventListener implements
 		PreInsertEventListener, PreUpdateEventListener, PreDeleteEventListener, Initializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        BeanValidationEventListener.class.getName());
 
 	private ValidatorFactory factory;
 	private ConcurrentHashMap<EntityPersister, Set<String>> associationsPerEntityPersister =
 			new ConcurrentHashMap<EntityPersister, Set<String>>();
 	private GroupsPerOperation groupsPerOperation;
 	boolean initialized;
 
 	/**
 	 * No-arg constructor used when listener is configured via configuration file
 	 */
 	public BeanValidationEventListener() {
 	}
 
 	/**
 	 * Constructor used in an environment where validator factory is injected (JPA2).
 	 *
 	 * @param factory The {@code ValidatorFactory} to use to create {@code Validator} instance(s)
 	 * @param properties Configued properties
 	 */
 	public BeanValidationEventListener(ValidatorFactory factory, Properties properties) {
 		init( factory, properties );
 	}
 
 	public void initialize(Configuration cfg) {
 		if ( !initialized ) {
 			ValidatorFactory factory = Validation.buildDefaultValidatorFactory();
 			Properties props = cfg.getProperties();
 			init( factory, props );
 		}
 	}
 
 	public boolean onPreInsert(PreInsertEvent event) {
 		validate(
 				event.getEntity(), event.getSession().getEntityMode(), event.getPersister(),
 				event.getSession().getFactory(), GroupsPerOperation.Operation.INSERT
 		);
 		return false;
 	}
 
 	public boolean onPreUpdate(PreUpdateEvent event) {
 		validate(
 				event.getEntity(), event.getSession().getEntityMode(), event.getPersister(),
 				event.getSession().getFactory(), GroupsPerOperation.Operation.UPDATE
 		);
 		return false;
 	}
 
 	public boolean onPreDelete(PreDeleteEvent event) {
 		validate(
 				event.getEntity(), event.getSession().getEntityMode(), event.getPersister(),
 				event.getSession().getFactory(), GroupsPerOperation.Operation.DELETE
 		);
 		return false;
 	}
 
 	private void init(ValidatorFactory factory, Properties properties) {
 		this.factory = factory;
 		groupsPerOperation = new GroupsPerOperation( properties );
 		initialized = true;
 	}
 
 	private <T> void validate(T object, EntityMode mode, EntityPersister persister,
 							  SessionFactoryImplementor sessionFactory, GroupsPerOperation.Operation operation) {
 		if ( object == null || mode != EntityMode.POJO ) {
 			return;
 		}
 		TraversableResolver tr = new HibernateTraversableResolver(
 				persister, associationsPerEntityPersister, sessionFactory
 		);
 		Validator validator = factory.usingContext()
 				.traversableResolver( tr )
 				.getValidator();
 		final Class<?>[] groups = groupsPerOperation.get( operation );
 		if ( groups.length > 0 ) {
 			final Set<ConstraintViolation<T>> constraintViolations = validator.validate( object, groups );
 			if ( constraintViolations.size() > 0 ) {
 				Set<ConstraintViolation<?>> propagatedViolations =
 						new HashSet<ConstraintViolation<?>>( constraintViolations.size() );
 				Set<String> classNames = new HashSet<String>();
 				for ( ConstraintViolation<?> violation : constraintViolations ) {
                     LOG.trace(violation);
 					propagatedViolations.add( violation );
 					classNames.add( violation.getLeafBean().getClass().getName() );
 				}
 				StringBuilder builder = new StringBuilder();
 				builder.append( "Validation failed for classes " );
 				builder.append( classNames );
 				builder.append( " during " );
 				builder.append( operation.getName() );
 				builder.append( " time for groups " );
 				builder.append( toString( groups ) );
 				builder.append( "\nList of constraint violations:[\n" );
 				for (ConstraintViolation<?> violation : constraintViolations) {
 					builder.append( "\t" ).append( violation.toString() ).append("\n");
 				}
 				builder.append( "]" );
 
 				throw new ConstraintViolationException(
 						builder.toString(), propagatedViolations
 				);
 			}
 		}
 	}
 
 	private String toString(Class<?>[] groups) {
 		StringBuilder toString = new StringBuilder( "[" );
 		for ( Class<?> group : groups ) {
 			toString.append( group.getName() ).append( ", " );
 		}
 		toString.append( "]" );
 		return toString.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/BeanValidationIntegrator.java b/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/BeanValidationIntegrator.java
index 8630194f16..aaca83f799 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/BeanValidationIntegrator.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/BeanValidationIntegrator.java
@@ -1,296 +1,296 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.beanvalidation;
 
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Properties;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.spi.Integrator;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.classloading.spi.ClassLoaderService;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 
 /**
  * @author Steve Ebersole
  */
 public class BeanValidationIntegrator implements Integrator {
-	private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BeanValidationIntegrator.class.getName());
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BeanValidationIntegrator.class.getName());
 
 	public static final String APPLY_CONSTRAINTS = "hibernate.validator.apply_to_ddl";
 
 	public static final String BV_CHECK_CLASS = "javax.validation.Validation";
 
 	public static final String MODE_PROPERTY = "javax.persistence.validation.mode";
 
 	private static final String ACTIVATOR_CLASS = "org.hibernate.cfg.beanvalidation.TypeSafeActivator";
 	private static final String DDL_METHOD = "applyDDL";
 	private static final String ACTIVATE_METHOD = "activateBeanValidation";
 	private static final String VALIDATE_METHOD = "validateFactory";
 
 	public static void validateFactory(Object object) {
 		try {
 			final Class activatorClass = BeanValidationIntegrator.class.getClassLoader().loadClass( ACTIVATOR_CLASS );
 			try {
 				final Method validateMethod = activatorClass.getMethod( VALIDATE_METHOD, Object.class );
 				if ( ! validateMethod.isAccessible() ) {
 					validateMethod.setAccessible( true );
 				}
 				try {
 					validateMethod.invoke( null, object );
 				}
 				catch (InvocationTargetException e) {
 					if ( e.getTargetException() instanceof HibernateException ) {
 						throw (HibernateException) e.getTargetException();
 					}
 					throw new HibernateException( "Unable to check validity of passed ValidatorFactory", e );
 				}
 				catch (IllegalAccessException e) {
 					throw new HibernateException( "Unable to check validity of passed ValidatorFactory", e );
 				}
 			}
 			catch (HibernateException e) {
 				throw e;
 			}
 			catch (Exception e) {
 				throw new HibernateException( "Could not locate method needed for ValidatorFactory validation", e );
 			}
 		}
 		catch (HibernateException e) {
 			throw e;
 		}
 		catch (Exception e) {
 			throw new HibernateException( "Could not locate TypeSafeActivator class", e );
 		}
 	}
 
 	@Override
 	public void integrate(
 			Configuration configuration,
 			SessionFactoryImplementor sessionFactory,
 			SessionFactoryServiceRegistry serviceRegistry) {
 		// determine requested validation modes.
 		final Set<ValidationMode> modes = ValidationMode.getModes( configuration.getProperties().get( MODE_PROPERTY ) );
 
 		final ClassLoaderService classLoaderService = serviceRegistry.getService( ClassLoaderService.class );
 
 		// try to locate a BV class to see if it is available on the classpath
 		boolean isBeanValidationAvailable;
 		try {
 			classLoaderService.classForName( BV_CHECK_CLASS );
 			isBeanValidationAvailable = true;
 		}
 		catch ( Exception e ) {
 			isBeanValidationAvailable = false;
 		}
 
 		// locate the type safe activator class
 		final Class typeSafeActivatorClass = loadTypeSafeActivatorClass( serviceRegistry );
 
 		// todo : if this works out, probably better to simply alter TypeSafeActivator into a single method...
 
 		applyRelationalConstraints(
 				modes,
 				isBeanValidationAvailable,
 				typeSafeActivatorClass,
 				configuration
 		);
 		applyHibernateListeners(
 				modes,
 				isBeanValidationAvailable,
 				typeSafeActivatorClass,
 				configuration,
 				sessionFactory,
 				serviceRegistry
 		);
 	}
 
 	private Class loadTypeSafeActivatorClass(SessionFactoryServiceRegistry serviceRegistry) {
 		try {
 			return serviceRegistry.getService( ClassLoaderService.class ).classForName( ACTIVATOR_CLASS );
 		}
 		catch (Exception e) {
 			return null;
 		}
 	}
 
 	private void applyRelationalConstraints(
 			Set<ValidationMode> modes,
 			boolean beanValidationAvailable,
 			Class typeSafeActivatorClass,
 			Configuration configuration) {
 		if ( ! ConfigurationHelper.getBoolean( APPLY_CONSTRAINTS, configuration.getProperties(), true ) ){
 			LOG.debug( "Skipping application of relational constraints from legacy Hibernate Validator" );
 			return;
 		}
 
 		if ( ! ( modes.contains( ValidationMode.DDL ) || modes.contains( ValidationMode.AUTO ) ) ) {
 			return;
 		}
 
 		if ( ! beanValidationAvailable ) {
 			if ( modes.contains( ValidationMode.DDL ) ) {
 				throw new HibernateException( "Bean Validation not available in the class path but required in " + MODE_PROPERTY );
 			}
 			else if (modes.contains( ValidationMode.AUTO ) ) {
 				//nothing to activate
 				return;
 			}
 		}
 
 		try {
 			Method applyDDLMethod = typeSafeActivatorClass.getMethod( DDL_METHOD, Collection.class, Properties.class );
 			try {
 				applyDDLMethod.invoke(
 						null,
 						configuration.createMappings().getClasses().values(),
 						configuration.getProperties()
 				);
 			}
 			catch (HibernateException e) {
 				throw e;
 			}
 			catch (Exception e) {
 				throw new HibernateException( "Error applying BeanValidation relational constraints", e );
 			}
 		}
 		catch (HibernateException e) {
 			throw e;
 		}
 		catch (Exception e) {
 			throw new HibernateException( "Unable to locate TypeSafeActivator#applyDDL method", e );
 		}
 	}
 
 	private void applyHibernateListeners(
 			Set<ValidationMode> modes,
 			boolean beanValidationAvailable,
 			Class typeSafeActivatorClass,
 			Configuration configuration,
 			SessionFactoryImplementor sessionFactory,
 			SessionFactoryServiceRegistry serviceRegistry) {
 		// de-activate not-null tracking at the core level when Bean Validation is present unless the user explicitly
 		// asks for it
 		if ( configuration.getProperty( Environment.CHECK_NULLABILITY ) == null ) {
 			sessionFactory.getSettings().setCheckNullability( false );
 		}
 
 		if ( ! ( modes.contains( ValidationMode.CALLBACK ) || modes.contains( ValidationMode.AUTO ) ) ) {
 			return;
 		}
 
 		if ( ! beanValidationAvailable ) {
 			if ( modes.contains( ValidationMode.CALLBACK ) ) {
 				throw new HibernateException( "Bean Validation not available in the class path but required in " + MODE_PROPERTY );
 			}
 			else if (modes.contains( ValidationMode.AUTO ) ) {
 				//nothing to activate
 				return;
 			}
 		}
 
 		try {
 			Method activateMethod = typeSafeActivatorClass.getMethod( ACTIVATE_METHOD, EventListenerRegistry.class, Properties.class );
 			try {
 				activateMethod.invoke(
 						null,
 						serviceRegistry.getService( EventListenerRegistry.class ),
 						configuration.getProperties()
 				);
 			}
 			catch (HibernateException e) {
 				throw e;
 			}
 			catch (Exception e) {
 				throw new HibernateException( "Error applying BeanValidation relational constraints", e );
 			}
 		}
 		catch (HibernateException e) {
 			throw e;
 		}
 		catch (Exception e) {
 			throw new HibernateException( "Unable to locate TypeSafeActivator#applyDDL method", e );
 		}
 	}
 
 
 	// Because the javax validation classes might not be on the runtime classpath
 	private static enum ValidationMode {
 		AUTO,
 		CALLBACK,
 		NONE,
 		DDL;
 
 		public static Set<ValidationMode> getModes(Object modeProperty) {
 			Set<ValidationMode> modes = new HashSet<ValidationMode>(3);
 			if (modeProperty == null) {
 				modes.add(ValidationMode.AUTO);
 			}
 			else {
 				final String[] modesInString = modeProperty.toString().split( "," );
 				for ( String modeInString : modesInString ) {
 					modes.add( getMode(modeInString) );
 				}
 			}
 			if ( modes.size() > 1 && ( modes.contains( ValidationMode.AUTO ) || modes.contains( ValidationMode.NONE ) ) ) {
 				StringBuilder message = new StringBuilder( "Incompatible validation modes mixed: " );
 				for (ValidationMode mode : modes) {
 					message.append( mode ).append( ", " );
 				}
 				throw new HibernateException( message.substring( 0, message.length() - 2 ) );
 			}
 			return modes;
 		}
 
 		private static ValidationMode getMode(String modeProperty) {
 			if (modeProperty == null || modeProperty.length() == 0) {
 				return AUTO;
 			}
 			else {
 				try {
 					return valueOf( modeProperty.trim().toUpperCase() );
 				}
 				catch ( IllegalArgumentException e ) {
 					throw new HibernateException( "Unknown validation mode in " + MODE_PROPERTY + ": " + modeProperty );
 				}
 			}
 		}
 	}
 
 	@Override
 	public void disintegrate(SessionFactoryImplementor sessionFactory, SessionFactoryServiceRegistry serviceRegistry) {
 		// nothing to do here afaik
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/TypeSafeActivator.java b/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/TypeSafeActivator.java
index 73573ae3e0..ae49adadde 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/TypeSafeActivator.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/beanvalidation/TypeSafeActivator.java
@@ -1,377 +1,377 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.beanvalidation;
 
 import javax.validation.Validation;
 import javax.validation.ValidatorFactory;
 import javax.validation.constraints.Digits;
 import javax.validation.constraints.Max;
 import javax.validation.constraints.Min;
 import javax.validation.constraints.NotNull;
 import javax.validation.constraints.Size;
 import javax.validation.metadata.BeanDescriptor;
 import javax.validation.metadata.ConstraintDescriptor;
 import javax.validation.metadata.PropertyDescriptor;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.event.EventType;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.SingleTableSubclass;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 
 /**
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 class TypeSafeActivator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TypeSafeActivator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TypeSafeActivator.class.getName());
 
 	private static final String FACTORY_PROPERTY = "javax.persistence.validation.factory";
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public static void validateFactory(Object object) {
 		if ( ! ValidatorFactory.class.isInstance( object ) ) {
 			throw new HibernateException(
 					"Given object was not an instance of " + ValidatorFactory.class.getName()
 							+ "[" + object.getClass().getName() + "]"
 			);
 		}
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public static void activateBeanValidation(EventListenerRegistry listenerRegistry, Properties properties) {
 		ValidatorFactory factory = getValidatorFactory( properties );
 		BeanValidationEventListener listener = new BeanValidationEventListener(
 				factory, properties
 		);
 
 		listenerRegistry.addDuplicationStrategy( DuplicationStrategyImpl.INSTANCE );
 
 		listenerRegistry.appendListeners( EventType.PRE_INSERT, listener );
 		listenerRegistry.appendListeners( EventType.PRE_UPDATE, listener );
 		listenerRegistry.appendListeners( EventType.PRE_DELETE, listener );
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public static void applyDDL(Collection<PersistentClass> persistentClasses, Properties properties) {
 		ValidatorFactory factory = getValidatorFactory( properties );
 		Class<?>[] groupsArray = new GroupsPerOperation( properties ).get( GroupsPerOperation.Operation.DDL );
 		Set<Class<?>> groups = new HashSet<Class<?>>( Arrays.asList( groupsArray ) );
 
 		for ( PersistentClass persistentClass : persistentClasses ) {
 			final String className = persistentClass.getClassName();
 
 			if ( className == null || className.length() == 0 ) {
 				continue;
 			}
 			Class<?> clazz;
 			try {
 				clazz = ReflectHelper.classForName( className, TypeSafeActivator.class );
 			}
 			catch ( ClassNotFoundException e ) {
 				throw new AssertionFailure( "Entity class not found", e );
 			}
 
 			try {
 				applyDDL( "", persistentClass, clazz, factory, groups, true );
 			}
 			catch (Exception e) {
                 LOG.unableToApplyConstraints(className, e);
 			}
 		}
 	}
 
 	private static void applyDDL(String prefix,
 								 PersistentClass persistentClass,
 								 Class<?> clazz,
 								 ValidatorFactory factory,
 								 Set<Class<?>> groups,
 								 boolean activateNotNull) {
 		final BeanDescriptor descriptor = factory.getValidator().getConstraintsForClass( clazz );
 		//no bean level constraints can be applied, go to the properties
 
 		for ( PropertyDescriptor propertyDesc : descriptor.getConstrainedProperties() ) {
 			Property property = findPropertyByName( persistentClass, prefix + propertyDesc.getPropertyName() );
 			boolean hasNotNull;
 			if ( property != null ) {
 				hasNotNull = applyConstraints(
 						propertyDesc.getConstraintDescriptors(), property, propertyDesc, groups, activateNotNull
 				);
 				if ( property.isComposite() && propertyDesc.isCascaded() ) {
 					Class<?> componentClass = ( (Component) property.getValue() ).getComponentClass();
 
 					/*
 					 * we can apply not null if the upper component let's us activate not null
 					 * and if the property is not null.
 					 * Otherwise, all sub columns should be left nullable
 					 */
 					final boolean canSetNotNullOnColumns = activateNotNull && hasNotNull;
 					applyDDL(
 							prefix + propertyDesc.getPropertyName() + ".",
 							persistentClass, componentClass, factory, groups,
 							canSetNotNullOnColumns
 					);
 				}
 				//FIXME add collection of components
 			}
 		}
 	}
 
 	private static boolean applyConstraints(Set<ConstraintDescriptor<?>> constraintDescriptors,
 											Property property,
 											PropertyDescriptor propertyDesc,
 											Set<Class<?>> groups,
 											boolean canApplyNotNull
 	) {
 		boolean hasNotNull = false;
 		for ( ConstraintDescriptor<?> descriptor : constraintDescriptors ) {
 			if ( groups != null && Collections.disjoint( descriptor.getGroups(), groups ) ) {
 				continue;
 			}
 
 			if ( canApplyNotNull ) {
 				hasNotNull = hasNotNull || applyNotNull( property, descriptor );
 			}
 
 			// apply bean validation specific constraints
 			applyDigits( property, descriptor );
 			applySize( property, descriptor, propertyDesc );
 			applyMin( property, descriptor );
 			applyMax( property, descriptor );
 
 			// apply hibernate validator specific constraints - we cannot import any HV specific classes though!
 			// no need to check explicitly for @Range. @Range is a composed constraint using @Min and @Max which
 			// will be taken care later
 			applyLength( property, descriptor, propertyDesc );
 
 			// pass an empty set as composing constraints inherit the main constraint and thus are matching already
 			hasNotNull = hasNotNull || applyConstraints(
 					descriptor.getComposingConstraints(),
 					property, propertyDesc, null,
 					canApplyNotNull
 			);
 		}
 		return hasNotNull;
 	}
 
 	private static void applyMin(Property property, ConstraintDescriptor<?> descriptor) {
 		if ( Min.class.equals( descriptor.getAnnotation().annotationType() ) ) {
 			@SuppressWarnings("unchecked")
 			ConstraintDescriptor<Min> minConstraint = (ConstraintDescriptor<Min>) descriptor;
 			long min = minConstraint.getAnnotation().value();
 
 			Column col = (Column) property.getColumnIterator().next();
 			String checkConstraint = col.getName() + ">=" + min;
 			applySQLCheck( col, checkConstraint );
 		}
 	}
 
 	private static void applyMax(Property property, ConstraintDescriptor<?> descriptor) {
 		if ( Max.class.equals( descriptor.getAnnotation().annotationType() ) ) {
 			@SuppressWarnings("unchecked")
 			ConstraintDescriptor<Max> maxConstraint = (ConstraintDescriptor<Max>) descriptor;
 			long max = maxConstraint.getAnnotation().value();
 			Column col = (Column) property.getColumnIterator().next();
 			String checkConstraint = col.getName() + "<=" + max;
 			applySQLCheck( col, checkConstraint );
 		}
 	}
 
 	private static void applySQLCheck(Column col, String checkConstraint) {
 		String existingCheck = col.getCheckConstraint();
 		// need to check whether the new check is already part of the existing check, because applyDDL can be called
 		// multiple times
 		if ( StringHelper.isNotEmpty( existingCheck ) && !existingCheck.contains( checkConstraint ) ) {
 			checkConstraint = col.getCheckConstraint() + " AND " + checkConstraint;
 		}
 		col.setCheckConstraint( checkConstraint );
 	}
 
 	private static boolean applyNotNull(Property property, ConstraintDescriptor<?> descriptor) {
 		boolean hasNotNull = false;
 		if ( NotNull.class.equals( descriptor.getAnnotation().annotationType() ) ) {
 			if ( !( property.getPersistentClass() instanceof SingleTableSubclass ) ) {
 				//single table should not be forced to null
 				if ( !property.isComposite() ) { //composite should not add not-null on all columns
 					@SuppressWarnings( "unchecked" )
 					Iterator<Column> iter = property.getColumnIterator();
 					while ( iter.hasNext() ) {
 						iter.next().setNullable( false );
 						hasNotNull = true;
 					}
 				}
 			}
 			hasNotNull = true;
 		}
 		return hasNotNull;
 	}
 
 	private static void applyDigits(Property property, ConstraintDescriptor<?> descriptor) {
 		if ( Digits.class.equals( descriptor.getAnnotation().annotationType() ) ) {
 			@SuppressWarnings("unchecked")
 			ConstraintDescriptor<Digits> digitsConstraint = (ConstraintDescriptor<Digits>) descriptor;
 			int integerDigits = digitsConstraint.getAnnotation().integer();
 			int fractionalDigits = digitsConstraint.getAnnotation().fraction();
 			Column col = (Column) property.getColumnIterator().next();
 			col.setPrecision( integerDigits + fractionalDigits );
 			col.setScale( fractionalDigits );
 		}
 	}
 
 	private static void applySize(Property property, ConstraintDescriptor<?> descriptor, PropertyDescriptor propertyDescriptor) {
 		if ( Size.class.equals( descriptor.getAnnotation().annotationType() )
 				&& String.class.equals( propertyDescriptor.getElementClass() ) ) {
 			@SuppressWarnings("unchecked")
 			ConstraintDescriptor<Size> sizeConstraint = (ConstraintDescriptor<Size>) descriptor;
 			int max = sizeConstraint.getAnnotation().max();
 			Column col = (Column) property.getColumnIterator().next();
 			if ( max < Integer.MAX_VALUE ) {
 				col.setLength( max );
 			}
 		}
 	}
 
 	private static void applyLength(Property property, ConstraintDescriptor<?> descriptor, PropertyDescriptor propertyDescriptor) {
 		if ( "org.hibernate.validator.constraints.Length".equals(
 				descriptor.getAnnotation().annotationType().getName()
 		)
 				&& String.class.equals( propertyDescriptor.getElementClass() ) ) {
 			@SuppressWarnings("unchecked")
 			int max = (Integer) descriptor.getAttributes().get( "max" );
 			Column col = (Column) property.getColumnIterator().next();
 			if ( max < Integer.MAX_VALUE ) {
 				col.setLength( max );
 			}
 		}
 	}
 
 	/**
 	 * Retrieve the property by path in a recursive way, including IndentifierProperty in the loop
 	 * If propertyName is null or empty, the IdentifierProperty is returned
 	 */
 	private static Property findPropertyByName(PersistentClass associatedClass, String propertyName) {
 		Property property = null;
 		Property idProperty = associatedClass.getIdentifierProperty();
 		String idName = idProperty != null ? idProperty.getName() : null;
 		try {
 			if ( propertyName == null
 					|| propertyName.length() == 0
 					|| propertyName.equals( idName ) ) {
 				//default to id
 				property = idProperty;
 			}
 			else {
 				if ( propertyName.indexOf( idName + "." ) == 0 ) {
 					property = idProperty;
 					propertyName = propertyName.substring( idName.length() + 1 );
 				}
 				StringTokenizer st = new StringTokenizer( propertyName, ".", false );
 				while ( st.hasMoreElements() ) {
 					String element = (String) st.nextElement();
 					if ( property == null ) {
 						property = associatedClass.getProperty( element );
 					}
 					else {
 						if ( !property.isComposite() ) {
 							return null;
 						}
 						property = ( (Component) property.getValue() ).getProperty( element );
 					}
 				}
 			}
 		}
 		catch ( MappingException e ) {
 			try {
 				//if we do not find it try to check the identifier mapper
 				if ( associatedClass.getIdentifierMapper() == null ) {
 					return null;
 				}
 				StringTokenizer st = new StringTokenizer( propertyName, ".", false );
 				while ( st.hasMoreElements() ) {
 					String element = (String) st.nextElement();
 					if ( property == null ) {
 						property = associatedClass.getIdentifierMapper().getProperty( element );
 					}
 					else {
 						if ( !property.isComposite() ) {
 							return null;
 						}
 						property = ( (Component) property.getValue() ).getProperty( element );
 					}
 				}
 			}
 			catch ( MappingException ee ) {
 				return null;
 			}
 		}
 		return property;
 	}
 
 	private static ValidatorFactory getValidatorFactory(Map<Object, Object> properties) {
 		ValidatorFactory factory = null;
 		if ( properties != null ) {
 			Object unsafeProperty = properties.get( FACTORY_PROPERTY );
 			if ( unsafeProperty != null ) {
 				try {
 					factory = ValidatorFactory.class.cast( unsafeProperty );
 				}
 				catch ( ClassCastException e ) {
 					throw new HibernateException(
 							"Property " + FACTORY_PROPERTY
 									+ " should contain an object of type " + ValidatorFactory.class.getName()
 					);
 				}
 			}
 		}
 		if ( factory == null ) {
 			try {
 				factory = Validation.buildDefaultValidatorFactory();
 			}
 			catch ( Exception e ) {
 				throw new HibernateException( "Unable to build the default ValidatorFactory", e );
 			}
 		}
 		return factory;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/search/HibernateSearchIntegrator.java b/hibernate-core/src/main/java/org/hibernate/cfg/search/HibernateSearchIntegrator.java
index a3dabdc764..0116060bad 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/search/HibernateSearchIntegrator.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/search/HibernateSearchIntegrator.java
@@ -1,134 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.search;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AnnotationException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.event.EventType;
 import org.hibernate.event.PostCollectionRecreateEventListener;
 import org.hibernate.event.PostCollectionRemoveEventListener;
 import org.hibernate.event.PostCollectionUpdateEventListener;
 import org.hibernate.event.PostDeleteEventListener;
 import org.hibernate.event.PostInsertEventListener;
 import org.hibernate.event.PostUpdateEventListener;
 import org.hibernate.spi.Integrator;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.classloading.spi.ClassLoaderService;
 import org.hibernate.service.event.spi.DuplicationStrategy;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 
 /**
  * Integrates Hibernate Search into Hibernate Core by registering its needed listeners
  * <p/>
  * The note on the original (now removed) org.hibernate.cfg.search.HibernateSearchEventListenerRegister class indicated
  * that Search now uses a new means for this.  However that signature is relying on removed classes...
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  * @author Steve Ebersole
  */
 public class HibernateSearchIntegrator implements Integrator {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, HibernateSearchIntegrator.class.getName() );
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HibernateSearchIntegrator.class.getName() );
 
 	public static final String AUTO_REGISTER = "hibernate.search.autoregister_listeners";
 	public static final String LISTENER_CLASS = "org.hibernate.search.event.FullTextIndexEventListener";
 
 	@Override
 	public void integrate(
 			Configuration configuration,
 			SessionFactoryImplementor sessionFactory,
 			SessionFactoryServiceRegistry serviceRegistry) {
 		final boolean registerListeners = ConfigurationHelper.getBoolean( AUTO_REGISTER, configuration.getProperties(), false );
 		if ( !registerListeners ) {
 			LOG.debug( "Skipping search event listener auto registration" );
 			return;
 		}
 
 		final Class listenerClass = loadSearchEventListener( serviceRegistry );
 		if ( listenerClass == null ) {
 			LOG.debug( "Skipping search event listener auto registration - could not fid listener class" );
 			return;
 		}
 
 		final Object listener = instantiateListener( listenerClass );
 
 		EventListenerRegistry listenerRegistry = serviceRegistry.getService( EventListenerRegistry.class );
 
 		listenerRegistry.addDuplicationStrategy( new DuplicationStrategyImpl( listenerClass ) );
 
 		listenerRegistry.getEventListenerGroup( EventType.POST_INSERT ).appendListener( (PostInsertEventListener) listener );
 		listenerRegistry.getEventListenerGroup( EventType.POST_UPDATE ).appendListener( (PostUpdateEventListener) listener );
 		listenerRegistry.getEventListenerGroup( EventType.POST_DELETE ).appendListener( (PostDeleteEventListener) listener );
 		listenerRegistry.getEventListenerGroup( EventType.POST_COLLECTION_RECREATE ).appendListener( (PostCollectionRecreateEventListener) listener );
 		listenerRegistry.getEventListenerGroup( EventType.POST_COLLECTION_REMOVE ).appendListener( (PostCollectionRemoveEventListener) listener );
 		listenerRegistry.getEventListenerGroup( EventType.POST_COLLECTION_UPDATE ).appendListener( (PostCollectionUpdateEventListener) listener );
 	}
 
 	private Class loadSearchEventListener(SessionFactoryServiceRegistry serviceRegistry) {
 		try {
 			return serviceRegistry.getService( ClassLoaderService.class ).classForName( LISTENER_CLASS );
 		}
 		catch (Exception e) {
 			return null;
 		}
 	}
 
 	private Object instantiateListener(Class listenerClass) {
 		try {
 			return listenerClass.newInstance();
 		}
 		catch (Exception e) {
 			throw new AnnotationException( "Unable to instantiate Search event listener", e );
 		}
 	}
 
 	public static class DuplicationStrategyImpl implements DuplicationStrategy {
 		private final Class checkClass;
 
 		public DuplicationStrategyImpl(Class checkClass) {
 			this.checkClass = checkClass;
 		}
 
 		@Override
 		public boolean areMatch(Object listener, Object original) {
 			// not isAssignableFrom since the user could subclass
 			return checkClass == original.getClass() && checkClass == listener.getClass();
 		}
 
 		@Override
 		public Action getAction() {
 			return Action.KEEP_ORIGINAL;
 		}
 	}
 
 	@Override
 	public void disintegrate(SessionFactoryImplementor sessionFactory, SessionFactoryServiceRegistry serviceRegistry) {
 		// nothing to do here afaik
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/collection/PersistentArrayHolder.java b/hibernate-core/src/main/java/org/hibernate/collection/PersistentArrayHolder.java
index c9035613b6..9086e57b12 100644
--- a/hibernate-core/src/main/java/org/hibernate/collection/PersistentArrayHolder.java
+++ b/hibernate-core/src/main/java/org/hibernate/collection/PersistentArrayHolder.java
@@ -1,255 +1,255 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.collection;
 import java.io.Serializable;
 import java.lang.reflect.Array;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Iterator;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * A persistent wrapper for an array. Lazy initialization
  * is NOT supported. Use of Hibernate arrays is not really
  * recommended.
  *
  * @author Gavin King
  */
 public class PersistentArrayHolder extends AbstractPersistentCollection {
 	protected Object array;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, PersistentArrayHolder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, PersistentArrayHolder.class.getName());
 
 	//just to help out during the load (ugly, i know)
 	private transient Class elementClass;
 	private transient java.util.List tempList;
 
 	public PersistentArrayHolder(SessionImplementor session, Object array) {
 		super(session);
 		this.array = array;
 		setInitialized();
 	}
 
 	public Serializable getSnapshot(CollectionPersister persister) throws HibernateException {
 		EntityMode entityMode = getSession().getEntityMode();
 		int length = /*(array==null) ? tempList.size() :*/ Array.getLength(array);
 		Serializable result = (Serializable) Array.newInstance( persister.getElementClass(), length );
 		for ( int i=0; i<length; i++ ) {
 			Object elt = /*(array==null) ? tempList.get(i) :*/ Array.get(array, i);
 			try {
 				Array.set( result, i, persister.getElementType().deepCopy(elt, entityMode, persister.getFactory()) );
 			}
 			catch (IllegalArgumentException iae) {
                 LOG.invalidArrayElementType(iae.getMessage());
 				throw new HibernateException( "Array element type error", iae );
 			}
 		}
 		return result;
 	}
 
 	public boolean isSnapshotEmpty(Serializable snapshot) {
 		return Array.getLength( snapshot ) == 0;
 	}
 
 	@Override
     public Collection getOrphans(Serializable snapshot, String entityName) throws HibernateException {
 		Object[] sn = (Object[]) snapshot;
 		Object[] arr = (Object[]) array;
 		ArrayList result = new ArrayList();
 		for (int i=0; i<sn.length; i++) result.add( sn[i] );
 		for (int i=0; i<sn.length; i++) identityRemove( result, arr[i], entityName, getSession() );
 		return result;
 	}
 
 	public PersistentArrayHolder(SessionImplementor session, CollectionPersister persister) throws HibernateException {
 		super(session);
 		elementClass = persister.getElementClass();
 	}
 
 	public Object getArray() {
 		return array;
 	}
 
 	public boolean isWrapper(Object collection) {
 		return array==collection;
 	}
 
 	public boolean equalsSnapshot(CollectionPersister persister) throws HibernateException {
 		Type elementType = persister.getElementType();
 		Serializable snapshot = getSnapshot();
 		int xlen = Array.getLength(snapshot);
 		if ( xlen!= Array.getLength(array) ) return false;
 		for ( int i=0; i<xlen; i++) {
 			if ( elementType.isDirty( Array.get(snapshot, i), Array.get(array, i), getSession() ) ) return false;
 		}
 		return true;
 	}
 
 	public Iterator elements() {
 		//if (array==null) return tempList.iterator();
 		int length = Array.getLength(array);
 		java.util.List list = new ArrayList(length);
 		for (int i=0; i<length; i++) {
 			list.add( Array.get(array, i) );
 		}
 		return list.iterator();
 	}
 	@Override
     public boolean empty() {
 		return false;
 	}
 
 	public Object readFrom(ResultSet rs, CollectionPersister persister, CollectionAliases descriptor, Object owner)
 	throws HibernateException, SQLException {
 
 		Object element = persister.readElement( rs, owner, descriptor.getSuffixedElementAliases(), getSession() );
 		int index = ( (Integer) persister.readIndex( rs, descriptor.getSuffixedIndexAliases(), getSession() ) ).intValue();
 		for ( int i = tempList.size(); i<=index; i++) {
 			tempList.add(i, null);
 		}
 		tempList.set(index, element);
 		return element;
 	}
 
 	public Iterator entries(CollectionPersister persister) {
 		return elements();
 	}
 
 	@Override
     public void beginRead() {
 		super.beginRead();
 		tempList = new ArrayList();
 	}
 	@Override
     public boolean endRead() {
 		setInitialized();
 		array = Array.newInstance( elementClass, tempList.size() );
 		for ( int i=0; i<tempList.size(); i++) {
 			Array.set(array, i, tempList.get(i) );
 		}
 		tempList=null;
 		return true;
 	}
 
 	public void beforeInitialize(CollectionPersister persister, int anticipatedSize) {
 		//if (tempList==null) throw new UnsupportedOperationException("Can't lazily initialize arrays");
 	}
 
 	@Override
     public boolean isDirectlyAccessible() {
 		return true;
 	}
 
 	public void initializeFromCache(CollectionPersister persister, Serializable disassembled, Object owner)
 	throws HibernateException {
 		Serializable[] cached = (Serializable[]) disassembled;
 
 		array = Array.newInstance( persister.getElementClass(), cached.length );
 
 		for ( int i=0; i<cached.length; i++ ) {
 			Array.set( array, i, persister.getElementType().assemble( cached[i], getSession(), owner ) );
 		}
 	}
 
 	public Serializable disassemble(CollectionPersister persister) throws HibernateException {
 		int length = Array.getLength(array);
 		Serializable[] result = new Serializable[length];
 		for ( int i=0; i<length; i++ ) {
 			result[i] = persister.getElementType().disassemble( Array.get(array,i), getSession(), null );
 		}
 
 		/*int length = tempList.size();
 		Serializable[] result = new Serializable[length];
 		for ( int i=0; i<length; i++ ) {
 			result[i] = persister.getElementType().disassemble( tempList.get(i), session );
 		}*/
 
 		return result;
 
 	}
 
 	@Override
     public Object getValue() {
 		return array;
 	}
 
 	public Iterator getDeletes(CollectionPersister persister, boolean indexIsFormula) throws HibernateException {
 		java.util.List deletes = new ArrayList();
 		Serializable sn = getSnapshot();
 		int snSize = Array.getLength(sn);
 		int arraySize = Array.getLength(array);
 		int end;
 		if ( snSize > arraySize ) {
 			for ( int i=arraySize; i<snSize; i++ ) deletes.add( new Integer(i) );
 			end = arraySize;
 		}
 		else {
 			end = snSize;
 		}
 		for ( int i=0; i<end; i++ ) {
 			if ( Array.get(array, i)==null && Array.get(sn, i)!=null ) deletes.add( new Integer(i) );
 		}
 		return deletes.iterator();
 	}
 
 	public boolean needsInserting(Object entry, int i, Type elemType) throws HibernateException {
 		Serializable sn = getSnapshot();
 		return Array.get(array, i)!=null && ( i >= Array.getLength(sn) || Array.get(sn, i)==null );
 	}
 
 	public boolean needsUpdating(Object entry, int i, Type elemType) throws HibernateException {
 		Serializable sn = getSnapshot();
 		return i<Array.getLength(sn) &&
 				Array.get(sn, i)!=null &&
 				Array.get(array, i)!=null &&
 				elemType.isDirty( Array.get(array, i), Array.get(sn, i), getSession() );
 	}
 
 	public Object getIndex(Object entry, int i, CollectionPersister persister) {
 		return new Integer(i);
 	}
 
 	public Object getElement(Object entry) {
 		return entry;
 	}
 
 	public Object getSnapshotElement(Object entry, int i) {
 		Serializable sn = getSnapshot();
 		return Array.get(sn, i);
 	}
 
 	public boolean entryExists(Object entry, int i) {
 		return entry!=null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/context/JTASessionContext.java b/hibernate-core/src/main/java/org/hibernate/context/JTASessionContext.java
index d6bddefdca..d875048519 100644
--- a/hibernate-core/src/main/java/org/hibernate/context/JTASessionContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/context/JTASessionContext.java
@@ -1,208 +1,208 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.context;
 
 import javax.transaction.Synchronization;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import java.util.Hashtable;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.Session;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 
 /**
  * An implementation of {@link CurrentSessionContext} which scopes the notion
  * of a current session to a JTA transaction.  Because JTA gives us a nice
  * tie-in to clean up after ourselves, this implementation will generate
  * Sessions as needed provided a JTA transaction is in effect.  If a session
  * is not already associated with the current JTA transaction at the time
  * {@link #currentSession()} is called, a new session will be opened and it
  * will be associated with that JTA transaction.
  * <p/>
  * Note that the sessions returned from this method are automatically configured with
  * both the {@link org.hibernate.cfg.Environment#FLUSH_BEFORE_COMPLETION auto-flush} and
  * {@link org.hibernate.cfg.Environment#AUTO_CLOSE_SESSION auto-close} attributes set to
  * true, meaning that the Session will be automatically flushed and closed
  * as part of the lifecycle for the JTA transaction to which it is associated.
  * Additionally, it will also be configured to aggressively release JDBC
  * connections after each statement is executed.  These settings are governed
  * by the {@link #isAutoFlushEnabled()}, {@link #isAutoCloseEnabled()}, and
  * {@link #getConnectionReleaseMode()} methods; these are provided (along with
  * the {@link #buildOrObtainSession()} method) for easier subclassing for custom
  * JTA-based session tracking logic (like maybe long-session semantics).
  *
  * @author Steve Ebersole
  */
 public class JTASessionContext implements CurrentSessionContext {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JTASessionContext.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JTASessionContext.class.getName());
 
 	protected final SessionFactoryImplementor factory;
 	private transient Map currentSessionMap = new Hashtable();
 
 	public JTASessionContext(SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 
 	@Override
 	public Session currentSession() throws HibernateException {
 		final JtaPlatform jtaPlatform = factory.getServiceRegistry().getService( JtaPlatform.class );
 		final TransactionManager transactionManager = jtaPlatform.retrieveTransactionManager();
 		if ( transactionManager == null ) {
 			throw new HibernateException( "No TransactionManagerLookup specified" );
 		}
 
 		Transaction txn;
 		try {
 			txn = transactionManager.getTransaction();
 			if ( txn == null ) {
 				throw new HibernateException( "Unable to locate current JTA transaction" );
 			}
 			if ( !JtaStatusHelper.isActive( txn.getStatus() ) ) {
 				// We could register the session against the transaction even though it is
 				// not started, but we'd have no guarantee of ever getting the map
 				// entries cleaned up (aside from spawning threads).
 				throw new HibernateException( "Current transaction is not in progress" );
 			}
 		}
 		catch ( HibernateException e ) {
 			throw e;
 		}
 		catch ( Throwable t ) {
 			throw new HibernateException( "Problem locating/validating JTA transaction", t );
 		}
 
 		final Object txnIdentifier = jtaPlatform.getTransactionIdentifier( txn );
 
 		Session currentSession = ( Session ) currentSessionMap.get( txnIdentifier );
 
 		if ( currentSession == null ) {
 			currentSession = buildOrObtainSession();
 
 			try {
 				txn.registerSynchronization( buildCleanupSynch( txnIdentifier ) );
 			}
 			catch ( Throwable t ) {
 				try {
 					currentSession.close();
 				}
 				catch ( Throwable ignore ) {
                     LOG.debug("Unable to release generated current-session on failed synch registration", ignore);
 				}
 				throw new HibernateException( "Unable to register cleanup Synchronization with TransactionManager" );
 			}
 
 			currentSessionMap.put( txnIdentifier, currentSession );
 		}
 
 		return currentSession;
 	}
 
 	/**
 	 * Builds a {@link CleanupSynch} capable of cleaning up the the current session map as an after transaction
 	 * callback.
 	 *
 	 * @param transactionIdentifier The transaction identifier under which the current session is registered.
 	 * @return The cleanup synch.
 	 */
 	private CleanupSynch buildCleanupSynch(Object transactionIdentifier) {
 		return new CleanupSynch( transactionIdentifier, this );
 	}
 
 	/**
 	 * Strictly provided for subclassing purposes; specifically to allow long-session
 	 * support.
 	 * <p/>
 	 * This implementation always just opens a new session.
 	 *
 	 * @return the built or (re)obtained session.
 	 */
 	protected Session buildOrObtainSession() {
 		return factory.withOptions()
 				.autoClose( isAutoCloseEnabled() )
 				.connectionReleaseMode( getConnectionReleaseMode() )
 				.flushBeforeCompletion( isAutoFlushEnabled() )
 				.openSession();
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns true.
 	 *
 	 * @return Whether or not the the session should be closed by transaction completion.
 	 */
 	protected boolean isAutoCloseEnabled() {
 		return true;
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns true.
 	 *
 	 * @return Whether or not the the session should be flushed prior transaction completion.
 	 */
 	protected boolean isAutoFlushEnabled() {
 		return true;
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns after_statement.
 	 *
 	 * @return The connection release mode for any built sessions.
 	 */
 	protected ConnectionReleaseMode getConnectionReleaseMode() {
 		return ConnectionReleaseMode.AFTER_STATEMENT;
 	}
 
 	/**
 	 * JTA transaction synch used for cleanup of the internal session map.
 	 */
 	protected static class CleanupSynch implements Synchronization {
 		private Object transactionIdentifier;
 		private JTASessionContext context;
 
 		public CleanupSynch(Object transactionIdentifier, JTASessionContext context) {
 			this.transactionIdentifier = transactionIdentifier;
 			this.context = context;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public void beforeCompletion() {
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public void afterCompletion(int i) {
 			context.currentSessionMap.remove( transactionIdentifier );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/context/ThreadLocalSessionContext.java b/hibernate-core/src/main/java/org/hibernate/context/ThreadLocalSessionContext.java
index c0555a2721..2322bb297e 100644
--- a/hibernate-core/src/main/java/org/hibernate/context/ThreadLocalSessionContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/context/ThreadLocalSessionContext.java
@@ -1,386 +1,386 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.context;
 
 import javax.transaction.Synchronization;
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.reflect.InvocationHandler;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.lang.reflect.Proxy;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.event.EventSource;
 
 /**
  * A {@link CurrentSessionContext} impl which scopes the notion of current
  * session by the current thread of execution.  Unlike the JTA counterpart,
  * threads do not give us a nice hook to perform any type of cleanup making
  * it questionable for this impl to actually generate Session instances.  In
  * the interest of usability, it was decided to have this default impl
  * actually generate a session upon first request and then clean it up
  * after the {@link org.hibernate.Transaction} associated with that session
  * is committed/rolled-back.  In order for ensuring that happens, the sessions
  * generated here are unusable until after {@link Session#beginTransaction()}
  * has been called. If <tt>close()</tt> is called on a session managed by
  * this class, it will be automatically unbound.
  * <p/>
  * Additionally, the static {@link #bind} and {@link #unbind} methods are
  * provided to allow application code to explicitly control opening and
  * closing of these sessions.  This, with some from of interception,
  * is the preferred approach.  It also allows easy framework integration
  * and one possible approach for implementing long-sessions.
  * <p/>
  * The {@link #buildOrObtainSession}, {@link #isAutoCloseEnabled},
  * {@link #isAutoFlushEnabled}, {@link #getConnectionReleaseMode}, and
  * {@link #buildCleanupSynch} methods are all provided to allow easy
  * subclassing (for long-running session scenarios, for example).
  *
  * @author Steve Ebersole
  */
 public class ThreadLocalSessionContext implements CurrentSessionContext {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        ThreadLocalSessionContext.class.getName());
 	private static final Class[] SESSION_PROXY_INTERFACES = new Class[] {
 			Session.class,
 	        SessionImplementor.class,
 	        EventSource.class,
 			TransactionContext.class,
 			LobCreationContext.class
 	};
 
 	/**
 	 * A ThreadLocal maintaining current sessions for the given execution thread.
 	 * The actual ThreadLocal variable is a java.util.Map to account for
 	 * the possibility for multiple SessionFactorys being used during execution
 	 * of the given thread.
 	 */
 	private static final ThreadLocal<Map> context = new ThreadLocal<Map>();
 
 	protected final SessionFactoryImplementor factory;
 
 	public ThreadLocalSessionContext(SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final Session currentSession() throws HibernateException {
 		Session current = existingSession( factory );
 		if (current == null) {
 			current = buildOrObtainSession();
 			// register a cleanup sync
 			current.getTransaction().registerSynchronization( buildCleanupSynch() );
 			// wrap the session in the transaction-protection proxy
 			if ( needsWrapping( current ) ) {
 				current = wrap( current );
 			}
 			// then bind it
 			doBind( current, factory );
 		}
 		return current;
 	}
 
 	private boolean needsWrapping(Session session) {
 		// try to make sure we don't wrap and already wrapped session
 		return session != null
 		       && ! Proxy.isProxyClass( session.getClass() )
 		       || ( Proxy.getInvocationHandler( session ) != null
 		       && ! ( Proxy.getInvocationHandler( session ) instanceof TransactionProtectionWrapper ) );
 	}
 
 	/**
 	 * Getter for property 'factory'.
 	 *
 	 * @return Value for property 'factory'.
 	 */
 	protected SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	/**
 	 * Strictly provided for subclassing purposes; specifically to allow long-session
 	 * support.
 	 * <p/>
 	 * This implementation always just opens a new session.
 	 *
 	 * @return the built or (re)obtained session.
 	 */
 	protected Session buildOrObtainSession() {
 		return factory.withOptions()
 				.autoClose( isAutoCloseEnabled() )
 				.connectionReleaseMode( getConnectionReleaseMode() )
 				.flushBeforeCompletion( isAutoFlushEnabled() )
 				.openSession();
 	}
 
 	protected CleanupSynch buildCleanupSynch() {
 		return new CleanupSynch( factory );
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns true.
 	 *
 	 * @return Whether or not the the session should be closed by transaction completion.
 	 */
 	protected boolean isAutoCloseEnabled() {
 		return true;
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns true.
 	 *
 	 * @return Whether or not the the session should be flushed prior transaction completion.
 	 */
 	protected boolean isAutoFlushEnabled() {
 		return true;
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns after_transaction.
 	 *
 	 * @return The connection release mode for any built sessions.
 	 */
 	protected ConnectionReleaseMode getConnectionReleaseMode() {
 		return factory.getSettings().getConnectionReleaseMode();
 	}
 
 	protected Session wrap(Session session) {
 		TransactionProtectionWrapper wrapper = new TransactionProtectionWrapper( session );
 		Session wrapped = ( Session ) Proxy.newProxyInstance(
 				Session.class.getClassLoader(),
 				SESSION_PROXY_INTERFACES,
 		        wrapper
 			);
 		// yick!  need this for proper serialization/deserialization handling...
 		wrapper.setWrapped( wrapped );
 		return wrapped;
 	}
 
 	/**
 	 * Associates the given session with the current thread of execution.
 	 *
 	 * @param session The session to bind.
 	 */
 	public static void bind(org.hibernate.Session session) {
 		SessionFactory factory = session.getSessionFactory();
 		cleanupAnyOrphanedSession( factory );
 		doBind( session, factory );
 	}
 
 	private static void cleanupAnyOrphanedSession(SessionFactory factory) {
 		Session orphan = doUnbind( factory, false );
 		if ( orphan != null ) {
             LOG.alreadySessionBound();
 			try {
 				if ( orphan.getTransaction() != null && orphan.getTransaction().isActive() ) {
 					try {
 						orphan.getTransaction().rollback();
 					}
 					catch( Throwable t ) {
                         LOG.debug("Unable to rollback transaction for orphaned session", t);
 					}
 				}
 				orphan.close();
 			}
 			catch( Throwable t ) {
                 LOG.debug("Unable to close orphaned session", t);
 			}
 		}
 	}
 
 	/**
 	 * Disassociates a previously bound session from the current thread of execution.
 	 *
 	 * @param factory The factory for which the session should be unbound.
 	 * @return The session which was unbound.
 	 */
 	public static Session unbind(SessionFactory factory) {
 		return doUnbind( factory, true );
 	}
 
 	private static Session existingSession(SessionFactory factory) {
 		Map sessionMap = sessionMap();
         if (sessionMap == null) return null;
         return (Session)sessionMap.get(factory);
 	}
 
 	protected static Map sessionMap() {
 		return context.get();
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private static void doBind(org.hibernate.Session session, SessionFactory factory) {
 		Map sessionMap = sessionMap();
 		if ( sessionMap == null ) {
 			sessionMap = new HashMap();
 			context.set( sessionMap );
 		}
 		sessionMap.put( factory, session );
 	}
 
 	private static Session doUnbind(SessionFactory factory, boolean releaseMapIfEmpty) {
 		Map sessionMap = sessionMap();
 		Session session = null;
 		if ( sessionMap != null ) {
 			session = ( Session ) sessionMap.remove( factory );
 			if ( releaseMapIfEmpty && sessionMap.isEmpty() ) {
 				context.set( null );
 			}
 		}
 		return session;
 	}
 
 	/**
 	 * JTA transaction synch used for cleanup of the internal session map.
 	 */
 	protected static class CleanupSynch implements Synchronization, Serializable {
 		protected final SessionFactory factory;
 
 		public CleanupSynch(SessionFactory factory) {
 			this.factory = factory;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public void beforeCompletion() {
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public void afterCompletion(int i) {
 			unbind( factory );
 		}
 	}
 
 	private class TransactionProtectionWrapper implements InvocationHandler, Serializable {
 		private final Session realSession;
 		private Session wrappedSession;
 
 		public TransactionProtectionWrapper(Session realSession) {
 			this.realSession = realSession;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
 			try {
 				// If close() is called, guarantee unbind()
 				if ( "close".equals( method.getName()) ) {
 					unbind( realSession.getSessionFactory() );
 				}
 				else if ( "toString".equals( method.getName() )
 					     || "equals".equals( method.getName() )
 					     || "hashCode".equals( method.getName() )
 				         || "getStatistics".equals( method.getName() )
 					     || "isOpen".equals( method.getName() )
 						 || "getListeners".equals( method.getName() ) //useful for HSearch in particular
 						) {
 					// allow these to go through the the real session no matter what
 				}
 				else if ( !realSession.isOpen() ) {
 					// essentially, if the real session is closed allow any
 					// method call to pass through since the real session
 					// will complain by throwing an appropriate exception;
 					// NOTE that allowing close() above has the same basic effect,
 					//   but we capture that there simply to doAfterTransactionCompletion the unbind...
 				}
 				else if ( !realSession.getTransaction().isActive() ) {
 					// limit the methods available if no transaction is active
 					if ( "beginTransaction".equals( method.getName() )
 					     || "getTransaction".equals( method.getName() )
 					     || "isTransactionInProgress".equals( method.getName() )
 					     || "setFlushMode".equals( method.getName() )
 					     || "getSessionFactory".equals( method.getName() ) ) {
                         LOG.trace("Allowing method [" + method.getName() + "] in non-transacted context");
 					}
 					else if ( "reconnect".equals( method.getName() )
 					          || "disconnect".equals( method.getName() ) ) {
 						// allow these (deprecated) methods to pass through
 					}
 					else {
 						throw new HibernateException( method.getName() + " is not valid without active transaction" );
 					}
 				}
                 LOG.trace("Allowing proxied method [" + method.getName() + "] to proceed to real session");
 				return method.invoke( realSession, args );
 			}
 			catch ( InvocationTargetException e ) {
                 if (e.getTargetException() instanceof RuntimeException) throw (RuntimeException)e.getTargetException();
                 throw e;
 			}
 		}
 
 		/**
 		 * Setter for property 'wrapped'.
 		 *
 		 * @param wrapped Value to set for property 'wrapped'.
 		 */
 		public void setWrapped(Session wrapped) {
 			this.wrappedSession = wrapped;
 		}
 
 
 		// serialization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		private void writeObject(ObjectOutputStream oos) throws IOException {
 			// if a ThreadLocalSessionContext-bound session happens to get
 			// serialized, to be completely correct, we need to make sure
 			// that unbinding of that session occurs.
 			oos.defaultWriteObject();
 			if ( existingSession( factory ) == wrappedSession ) {
 				unbind( factory );
 			}
 		}
 
 		private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 			// on the inverse, it makes sense that if a ThreadLocalSessionContext-
 			// bound session then gets deserialized to go ahead and re-bind it to
 			// the ThreadLocalSessionContext session map.
 			ois.defaultReadObject();
 			realSession.getTransaction().registerSynchronization( buildCleanupSynch() );
 			doBind( wrappedSession, factory );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/DerbyDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/DerbyDialect.java
index 1f3983d131..a29b1ff99d 100755
--- a/hibernate-core/src/main/java/org/hibernate/dialect/DerbyDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/DerbyDialect.java
@@ -1,246 +1,247 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.lang.reflect.Method;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.function.AnsiTrimFunction;
 import org.hibernate.dialect.function.DerbyConcatFunction;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.DerbyCaseFragment;
 import org.jboss.logging.Logger;
 
 /**
  * Hibernate Dialect for Cloudscape 10 - aka Derby. This implements both an
  * override for the identity column generator as well as for the case statement
  * issue documented at:
  * http://www.jroller.com/comments/kenlars99/Weblog/cloudscape_soon_to_be_derby
  *
  * @author Simon Johnston
  *
  * @deprecated HHH-6073
  */
 @Deprecated
 public class DerbyDialect extends DB2Dialect {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, DerbyDialect.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DerbyDialect.class.getName());
 
 	private int driverVersionMajor;
 	private int driverVersionMinor;
 
 	public DerbyDialect() {
 		super();
 		LOG.deprecatedDerbyDialect();
 		registerFunction( "concat", new DerbyConcatFunction() );
 		registerFunction( "trim", new AnsiTrimFunction() );
 		determineDriverVersion();
 	}
 
 	@SuppressWarnings({ "UnnecessaryUnboxing" })
 	private void determineDriverVersion() {
 		try {
 			// locate the derby sysinfo class and query its version info
 			final Class sysinfoClass = ReflectHelper.classForName( "org.apache.derby.tools.sysinfo", this.getClass() );
 			final Method majorVersionGetter = sysinfoClass.getMethod( "getMajorVersion", ReflectHelper.NO_PARAM_SIGNATURE );
 			final Method minorVersionGetter = sysinfoClass.getMethod( "getMinorVersion", ReflectHelper.NO_PARAM_SIGNATURE );
 			driverVersionMajor = ( (Integer) majorVersionGetter.invoke( null, ReflectHelper.NO_PARAMS ) ).intValue();
 			driverVersionMinor = ( (Integer) minorVersionGetter.invoke( null, ReflectHelper.NO_PARAMS ) ).intValue();
 		}
 		catch ( Exception e ) {
             LOG.unableToLoadDerbyDriver(e.getMessage());
 			driverVersionMajor = -1;
 			driverVersionMinor = -1;
 		}
 	}
 
 	private boolean isTenPointFiveReleaseOrNewer() {
 		return driverVersionMajor > 10 || ( driverVersionMajor == 10 && driverVersionMinor >= 5 );
 	}
 
 	@Override
     public String getCrossJoinSeparator() {
 		return ", ";
 	}
 
 	/**
 	 * Return the case statement modified for Cloudscape.
 	 */
 	@Override
     public CaseFragment createCaseFragment() {
 		return new DerbyCaseFragment();
 	}
 
 	@Override
     public boolean dropConstraints() {
 	      return true;
 	}
 
 	@Override
     public boolean supportsSequences() {
 		// technically sequence support was added in 10.6.1.0...
 		//
 		// The problem though is that I am not exactly sure how to differentiate 10.6.1.0 from any other 10.6.x release.
 		//
 		// http://db.apache.org/derby/docs/10.0/publishedapi/org/apache/derby/tools/sysinfo.html seems incorrect.  It
 		// states that derby's versioning scheme is major.minor.maintenance, but obviously 10.6.1.0 has 4 components
 		// to it, not 3.
 		//
 		// Let alone the fact that it states that versions with the matching major.minor are 'feature
 		// compatible' which is clearly not the case here (sequence support is a new feature...)
 		return driverVersionMajor > 10 || ( driverVersionMajor == 10 && driverVersionMinor >= 6 );
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		if ( supportsSequences() ) {
 			return "values next value for " + sequenceName;
 		}
 		else {
 			throw new MappingException( "Derby does not support sequence prior to release 10.6.1.0" );
 		}
 	}
 
 	@Override
     public boolean supportsLimit() {
 		return isTenPointFiveReleaseOrNewer();
 	}
 
 	//HHH-4531
 	@Override
     public boolean supportsCommentOn() {
 		return false;
 	}
 
 	@Override
     public boolean supportsLimitOffset() {
 		return isTenPointFiveReleaseOrNewer();
 	}
 
    @Override
 public String getForUpdateString() {
 		return " for update with rs";
    }
 
 	@Override
     public String getWriteLockString(int timeout) {
 		return " for update with rs";
 	}
 
 	@Override
     public String getReadLockString(int timeout) {
 		return " for read only with rs";
 	}
 
 
 	/**
 	 * {@inheritDoc}
 	 * <p/>
 	 * From Derby 10.5 Docs:
 	 * <pre>
 	 * Query
 	 * [ORDER BY clause]
 	 * [result offset clause]
 	 * [fetch first clause]
 	 * [FOR UPDATE clause]
 	 * [WITH {RR|RS|CS|UR}]
 	 * </pre>
 	 */
 	@Override
     public String getLimitString(String query, final int offset, final int limit) {
 		StringBuffer sb = new StringBuffer(query.length() + 50);
 
 		final String normalizedSelect = query.toLowerCase().trim();
 		final int forUpdateIndex = normalizedSelect.lastIndexOf( "for update") ;
 
 		if ( hasForUpdateClause( forUpdateIndex ) ) {
 			sb.append( query.substring( 0, forUpdateIndex-1 ) );
 		}
 		else if ( hasWithClause( normalizedSelect ) ) {
 			sb.append( query.substring( 0, getWithIndex( query ) - 1 ) );
 		}
 		else {
 			sb.append( query );
 		}
 
 		if ( offset == 0 ) {
 			sb.append( " fetch first " );
 		}
 		else {
 			sb.append( " offset " ).append( offset ).append( " rows fetch next " );
 		}
 
 		sb.append( limit ).append( " rows only" );
 
 		if ( hasForUpdateClause( forUpdateIndex ) ) {
 			sb.append(' ');
 			sb.append( query.substring( forUpdateIndex ) );
 		}
 		else if ( hasWithClause( normalizedSelect ) ) {
 			sb.append( ' ' ).append( query.substring( getWithIndex( query ) ) );
 		}
 		return sb.toString();
 	}
 
 	@Override
     public boolean supportsVariableLimit() {
 		// we bind the limit and offset values directly into the sql...
 		return false;
 	}
 
 	private boolean hasForUpdateClause(int forUpdateIndex) {
 		return forUpdateIndex >= 0;
 	}
 
 	private boolean hasWithClause(String normalizedSelect){
 		return normalizedSelect.startsWith( "with ", normalizedSelect.length()-7 );
 	}
 
 	private int getWithIndex(String querySelect) {
 		int i = querySelect.lastIndexOf( "with " );
 		if ( i < 0 ) {
 			i = querySelect.lastIndexOf( "WITH " );
 		}
 		return i;
 	}
 
 	@Override
     public String getQuerySequencesString() {
 	   return null ;
 	}
 
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
     public boolean supportsLobValueChangePropogation() {
 		return false;
 	}
 
 	@Override
     public boolean supportsUnboundedLobLocatorMaterialization() {
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Dialect.java
index 4a9bf170d5..d7bea821a0 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Dialect.java
@@ -1,1096 +1,1096 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.io.InputStream;
 import java.io.OutputStream;
 import java.sql.Blob;
 import java.sql.CallableStatement;
 import java.sql.Clob;
 import java.sql.NClob;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.CastFunction;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardAnsiSqlAggregationFunctions;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.dialect.lock.OptimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.OptimisticLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticReadSelectLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticWriteSelectLockingStrategy;
 import org.hibernate.dialect.lock.SelectLockingStrategy;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.exception.SQLStateConverter;
 import org.hibernate.exception.ViolatedConstraintNameExtracter;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.id.SequenceGenerator;
 import org.hibernate.id.TableHiLoGenerator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.io.StreamCopier;
 import org.hibernate.mapping.Column;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.sql.ANSICaseFragment;
 import org.hibernate.sql.ANSIJoinFragment;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.ForUpdateFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.descriptor.sql.BlobTypeDescriptor;
 import org.hibernate.type.descriptor.sql.ClobTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 import org.jboss.logging.Logger;
 
 /**
  * Represents a dialect of SQL implemented by a particular RDBMS.
  * Subclasses implement Hibernate compatibility with different systems.<br>
  * <br>
  * Subclasses should provide a public default constructor that <tt>register()</tt>
  * a set of type mappings and default Hibernate properties.<br>
  * <br>
  * Subclasses should be immutable.
  *
  * @author Gavin King, David Channon
  */
 public abstract class Dialect {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Dialect.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Dialect.class.getName());
 
 	public static final String DEFAULT_BATCH_SIZE = "15";
 	public static final String NO_BATCH = "0";
 
 	/**
 	 * Characters used for quoting SQL identifiers
 	 */
 	public static final String QUOTE = "`\"[";
 	public static final String CLOSED_QUOTE = "`\"]";
 
 	private final TypeNames typeNames = new TypeNames();
 	private final TypeNames hibernateTypeNames = new TypeNames();
 
 	private final Properties properties = new Properties();
 	private final Map<String, SQLFunction> sqlFunctions = new HashMap<String, SQLFunction>();
 	private final Set<String> sqlKeywords = new HashSet<String>();
 
 
 	// constructors and factory methods ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	protected Dialect() {
         LOG.usingDialect(this);
 		StandardAnsiSqlAggregationFunctions.primeFunctionMap( sqlFunctions );
 
 		// standard sql92 functions (can be overridden by subclasses)
 		registerFunction( "substring", new SQLFunctionTemplate( StandardBasicTypes.STRING, "substring(?1, ?2, ?3)" ) );
 		registerFunction( "locate", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "locate(?1, ?2, ?3)" ) );
 		registerFunction( "trim", new SQLFunctionTemplate( StandardBasicTypes.STRING, "trim(?1 ?2 ?3 ?4)" ) );
 		registerFunction( "length", new StandardSQLFunction( "length", StandardBasicTypes.INTEGER ) );
 		registerFunction( "bit_length", new StandardSQLFunction( "bit_length", StandardBasicTypes.INTEGER ) );
 		registerFunction( "coalesce", new StandardSQLFunction( "coalesce" ) );
 		registerFunction( "nullif", new StandardSQLFunction( "nullif" ) );
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "mod", new StandardSQLFunction( "mod", StandardBasicTypes.INTEGER) );
 		registerFunction( "sqrt", new StandardSQLFunction( "sqrt", StandardBasicTypes.DOUBLE) );
 		registerFunction( "upper", new StandardSQLFunction("upper") );
 		registerFunction( "lower", new StandardSQLFunction("lower") );
 		registerFunction( "cast", new CastFunction() );
 		registerFunction( "extract", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(?1 ?2 ?3)") );
 
 		//map second/minute/hour/day/month/year to ANSI extract(), override on subclasses
 		registerFunction( "second", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(second from ?1)") );
 		registerFunction( "minute", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(minute from ?1)") );
 		registerFunction( "hour", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(hour from ?1)") );
 		registerFunction( "day", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(day from ?1)") );
 		registerFunction( "month", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(month from ?1)") );
 		registerFunction( "year", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "extract(year from ?1)") );
 
 		registerFunction( "str", new SQLFunctionTemplate(StandardBasicTypes.STRING, "cast(?1 as char)") );
 
         // register hibernate types for default use in scalar sqlquery type auto detection
 		registerHibernateType( Types.BIGINT, StandardBasicTypes.BIG_INTEGER.getName() );
 		registerHibernateType( Types.BINARY, StandardBasicTypes.BINARY.getName() );
 		registerHibernateType( Types.BIT, StandardBasicTypes.BOOLEAN.getName() );
 		registerHibernateType( Types.CHAR, StandardBasicTypes.CHARACTER.getName() );
 		registerHibernateType( Types.DATE, StandardBasicTypes.DATE.getName() );
 		registerHibernateType( Types.DOUBLE, StandardBasicTypes.DOUBLE.getName() );
 		registerHibernateType( Types.FLOAT, StandardBasicTypes.FLOAT.getName() );
 		registerHibernateType( Types.INTEGER, StandardBasicTypes.INTEGER.getName() );
 		registerHibernateType( Types.SMALLINT, StandardBasicTypes.SHORT.getName() );
 		registerHibernateType( Types.TINYINT, StandardBasicTypes.BYTE.getName() );
 		registerHibernateType( Types.TIME, StandardBasicTypes.TIME.getName() );
 		registerHibernateType( Types.TIMESTAMP, StandardBasicTypes.TIMESTAMP.getName() );
 		registerHibernateType( Types.VARCHAR, StandardBasicTypes.STRING.getName() );
 		registerHibernateType( Types.VARBINARY, StandardBasicTypes.BINARY.getName() );
 		registerHibernateType( Types.LONGVARCHAR, StandardBasicTypes.TEXT.getName() );
 		registerHibernateType( Types.LONGVARBINARY, StandardBasicTypes.IMAGE.getName() );
 		registerHibernateType( Types.NUMERIC, StandardBasicTypes.BIG_DECIMAL.getName() );
 		registerHibernateType( Types.DECIMAL, StandardBasicTypes.BIG_DECIMAL.getName() );
 		registerHibernateType( Types.BLOB, StandardBasicTypes.BLOB.getName() );
 		registerHibernateType( Types.CLOB, StandardBasicTypes.CLOB.getName() );
 		registerHibernateType( Types.REAL, StandardBasicTypes.FLOAT.getName() );
 	}
 
 	/**
 	 * Get an instance of the dialect specified by the current <tt>System</tt> properties.
 	 *
 	 * @return The specified Dialect
 	 * @throws HibernateException If no dialect was specified, or if it could not be instantiated.
 	 */
 	public static Dialect getDialect() throws HibernateException {
 		String dialectName = Environment.getProperties().getProperty( Environment.DIALECT );
 		return instantiateDialect( dialectName );
 	}
 
 
 	/**
 	 * Get an instance of the dialect specified by the given properties or by
 	 * the current <tt>System</tt> properties.
 	 *
 	 * @param props The properties to use for finding the dialect class to use.
 	 * @return The specified Dialect
 	 * @throws HibernateException If no dialect was specified, or if it could not be instantiated.
 	 */
 	public static Dialect getDialect(Properties props) throws HibernateException {
 		String dialectName = props.getProperty( Environment.DIALECT );
 		if ( dialectName == null ) {
 			return getDialect();
 		}
 		return instantiateDialect( dialectName );
 	}
 
 	private static Dialect instantiateDialect(String dialectName) throws HibernateException {
 		if ( dialectName == null ) {
 			throw new HibernateException( "The dialect was not set. Set the property hibernate.dialect." );
 		}
 		try {
 			return ( Dialect ) ReflectHelper.classForName( dialectName ).newInstance();
 		}
 		catch ( ClassNotFoundException cnfe ) {
 			throw new HibernateException( "Dialect class not found: " + dialectName );
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Could not instantiate given dialect class: " + dialectName, e );
 		}
 	}
 
 	/**
 	 * Retrieve a set of default Hibernate properties for this database.
 	 *
 	 * @return a set of Hibernate properties
 	 */
 	public final Properties getDefaultProperties() {
 		return properties;
 	}
 
 	@Override
     public String toString() {
 		return getClass().getName();
 	}
 
 
 	// database type mapping support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Get the name of the database type associated with the given
 	 * {@link java.sql.Types} typecode.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @return the database type name
 	 * @throws HibernateException If no mapping was specified for that type.
 	 */
 	public String getTypeName(int code) throws HibernateException {
 		String result = typeNames.get( code );
 		if ( result == null ) {
 			throw new HibernateException( "No default type mapping for (java.sql.Types) " + code );
 		}
 		return result;
 	}
 
 	/**
 	 * Get the name of the database type associated with the given
 	 * {@link java.sql.Types} typecode with the given storage specification
 	 * parameters.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param length The datatype length
 	 * @param precision The datatype precision
 	 * @param scale The datatype scale
 	 * @return the database type name
 	 * @throws HibernateException If no mapping was specified for that type.
 	 */
 	public String getTypeName(int code, int length, int precision, int scale) throws HibernateException {
 		String result = typeNames.get( code, length, precision, scale );
 		if ( result == null ) {
 			throw new HibernateException(
 					"No type mapping for java.sql.Types code: " +
 					code +
 					", length: " +
 					length
 			);
 		}
 		return result;
 	}
 
 	/**
 	 * Get the name of the database type appropriate for casting operations
 	 * (via the CAST() SQL function) for the given {@link java.sql.Types} typecode.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @return The database type name
 	 */
 	public String getCastTypeName(int code) {
 		return getTypeName( code, Column.DEFAULT_LENGTH, Column.DEFAULT_PRECISION, Column.DEFAULT_SCALE );
 	}
 
 	/**
 	 * Subclasses register a type name for the given type code and maximum
 	 * column length. <tt>$l</tt> in the type name with be replaced by the
 	 * column length (if appropriate).
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param capacity The maximum length of database type
 	 * @param name The database type name
 	 */
 	protected void registerColumnType(int code, int capacity, String name) {
 		typeNames.put( code, capacity, name );
 	}
 
 	/**
 	 * Subclasses register a type name for the given type code. <tt>$l</tt> in
 	 * the type name with be replaced by the column length (if appropriate).
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param name The database type name
 	 */
 	protected void registerColumnType(int code, String name) {
 		typeNames.put( code, name );
 	}
 
 	/**
 	 * Allows the dialect to override a {@link SqlTypeDescriptor}.
 	 * <p/>
 	 * If <code>sqlTypeDescriptor</code> is a "standard basic" SQL type
 	 * descriptor, then this method uses {@link #getSqlTypeDescriptorOverride}
 	 * to get an optional override based on the SQL code returned by
 	 * {@link SqlTypeDescriptor#getSqlType()}.
 	 * <p/>
 	 * If this dialect does not provide an override, then this method
 	 * simply returns <code>sqlTypeDescriptor</code>
 	 *
 	 * @param sqlTypeDescriptor The {@link SqlTypeDescriptor} to override
 	 * @return The {@link SqlTypeDescriptor} that should be used for this dialect;
 	 *         if there is no override, then <code>sqlTypeDescriptor</code> is returned.
 	 * @throws IllegalArgumentException if <code>sqlTypeDescriptor</code> is null.
 	 *
 	 * @see {@link SqlTypeDescriptor}
 	 * @see {@link #getSqlTypeDescriptorOverride}
 	 * @see {@link StandardBasicTypes#isStandardBasicSqlTypeDescriptor(org.hibernate.type.descriptor.sql.SqlTypeDescriptor)}
 	 */
 	public SqlTypeDescriptor remapSqlTypeDescriptor(SqlTypeDescriptor sqlTypeDescriptor) {
 		if ( sqlTypeDescriptor == null ) {
 			throw new IllegalArgumentException( "sqlTypeDescriptor is null" );
 		}
 		if ( ! sqlTypeDescriptor.canBeRemapped() ) {
 			return sqlTypeDescriptor;
 		}
 
 		final SqlTypeDescriptor overridden = getSqlTypeDescriptorOverride( sqlTypeDescriptor.getSqlType() );
 		return overridden == null ? sqlTypeDescriptor : overridden;
 	}
 
 	/**
 	 * Returns the {@link SqlTypeDescriptor} that should override the
 	 * "standard basic" SQL type descriptor for values of the specified
 	 * column type, or null, if there is no override.
 	 *
 	 * @param sqlCode A {@link Types} constant indicating the SQL column type
 	 * @return The {@link SqlTypeDescriptor} that should override the
 	 * "standard basic" SQL type descriptor, or null, if there is no override.
 	 *
 	 * @see {@link SqlTypeDescriptor}
 	 * @see {@link StandardBasicTypes#isStandardBasicSqlTypeDescriptor(org.hibernate.type.descriptor.sql.SqlTypeDescriptor)}
 	 */
 	protected SqlTypeDescriptor getSqlTypeDescriptorOverride(int sqlCode) {
 		SqlTypeDescriptor descriptor;
 		switch ( sqlCode ) {
 			case Types.BLOB: {
 				descriptor = useInputStreamToInsertBlob() ? BlobTypeDescriptor.STREAM_BINDING : null;
 				break;
 			}
 			case Types.CLOB: {
 				descriptor = useInputStreamToInsertBlob() ? ClobTypeDescriptor.STREAM_BINDING : null;
 				break;
 			}
 			default: {
 				descriptor = null;
 				break;
 			}
 		}
 		return descriptor;
 	}
 
 	/**
 	 * The legacy behavior of Hibernate.  LOBs are not processed by merge
 	 */
 	protected static final LobMergeStrategy LEGACY_LOB_MERGE_STRATEGY = new LobMergeStrategy() {
 		@Override
 		public Blob mergeBlob(Blob original, Blob target, SessionImplementor session) {
 			return target;
 		}
 
 		@Override
 		public Clob mergeClob(Clob original, Clob target, SessionImplementor session) {
 			return target;
 		}
 
 		@Override
 		public NClob mergeNClob(NClob original, NClob target, SessionImplementor session) {
 			return target;
 		}
 	};
 
 	/**
 	 * Merge strategy based on transferring contents based on streams.
 	 */
 	protected static final LobMergeStrategy STREAM_XFER_LOB_MERGE_STRATEGY = new LobMergeStrategy() {
 		@Override
 		public Blob mergeBlob(Blob original, Blob target, SessionImplementor session) {
 			if ( original != target ) {
 				try {
 					OutputStream connectedStream = target.setBinaryStream( 1L );  // the BLOB just read during the load phase of merge
 					InputStream detachedStream = original.getBinaryStream();      // the BLOB from the detached state
 					StreamCopier.copy( detachedStream, connectedStream );
 					return target;
 				}
 				catch (SQLException e ) {
 					throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge BLOB data" );
 				}
 			}
 			else {
 				return NEW_LOCATOR_LOB_MERGE_STRATEGY.mergeBlob( original, target, session );
 			}
 		}
 
 		@Override
 		public Clob mergeClob(Clob original, Clob target, SessionImplementor session) {
 			if ( original != target ) {
 				try {
 					OutputStream connectedStream = target.setAsciiStream( 1L );  // the CLOB just read during the load phase of merge
 					InputStream detachedStream = original.getAsciiStream();      // the CLOB from the detached state
 					StreamCopier.copy( detachedStream, connectedStream );
 					return target;
 				}
 				catch (SQLException e ) {
 					throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge CLOB data" );
 				}
 			}
 			else {
 				return NEW_LOCATOR_LOB_MERGE_STRATEGY.mergeClob( original, target, session );
 			}
 		}
 
 		@Override
 		public NClob mergeNClob(NClob original, NClob target, SessionImplementor session) {
 			if ( original != target ) {
 				try {
 					OutputStream connectedStream = target.setAsciiStream( 1L );  // the NCLOB just read during the load phase of merge
 					InputStream detachedStream = original.getAsciiStream();      // the NCLOB from the detached state
 					StreamCopier.copy( detachedStream, connectedStream );
 					return target;
 				}
 				catch (SQLException e ) {
 					throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge NCLOB data" );
 				}
 			}
 			else {
 				return NEW_LOCATOR_LOB_MERGE_STRATEGY.mergeNClob( original, target, session );
 			}
 		}
 	};
 
 	/**
 	 * Merge strategy based on creating a new LOB locator.
 	 */
 	protected static final LobMergeStrategy NEW_LOCATOR_LOB_MERGE_STRATEGY = new LobMergeStrategy() {
 		@Override
 		public Blob mergeBlob(Blob original, Blob target, SessionImplementor session) {
 			if ( original == null && target == null ) {
 				return null;
 			}
 			try {
 				LobCreator lobCreator = session.getFactory().getJdbcServices().getLobCreator( session );
 				return original == null 
 						? lobCreator.createBlob( ArrayHelper.EMPTY_BYTE_ARRAY )
 						: lobCreator.createBlob( original.getBinaryStream(), original.length() );
 			}
 			catch (SQLException e) {
 				throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge BLOB data" );
 			}
 		}
 
 		@Override
 		public Clob mergeClob(Clob original, Clob target, SessionImplementor session) {
 			if ( original == null && target == null ) {
 				return null;
 			}
 			try {
 				LobCreator lobCreator = session.getFactory().getJdbcServices().getLobCreator( session );
 				return original == null
 						? lobCreator.createClob( "" )
 						: lobCreator.createClob( original.getCharacterStream(), original.length() );
 			}
 			catch (SQLException e) {
 				throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge CLOB data" );
 			}
 		}
 
 		@Override
 		public NClob mergeNClob(NClob original, NClob target, SessionImplementor session) {
 			if ( original == null && target == null ) {
 				return null;
 			}
 			try {
 				LobCreator lobCreator = session.getFactory().getJdbcServices().getLobCreator( session );
 				return original == null
 						? lobCreator.createNClob( "" )
 						: lobCreator.createNClob( original.getCharacterStream(), original.length() );
 			}
 			catch (SQLException e) {
 				throw session.getFactory().getSQLExceptionHelper().convert( e, "unable to merge NCLOB data" );
 			}
 		}
 	};
 
 	public LobMergeStrategy getLobMergeStrategy() {
 		return NEW_LOCATOR_LOB_MERGE_STRATEGY;
 	}
 
 
 	// hibernate type mapping support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Get the name of the Hibernate {@link org.hibernate.type.Type} associated with the given
 	 * {@link java.sql.Types} typecode.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @return The Hibernate {@link org.hibernate.type.Type} name.
 	 * @throws HibernateException If no mapping was specified for that type.
 	 */
 	public String getHibernateTypeName(int code) throws HibernateException {
 		String result = hibernateTypeNames.get( code );
 		if ( result == null ) {
 			throw new HibernateException( "No Hibernate type mapping for java.sql.Types code: " + code );
 		}
 		return result;
 	}
 
 	/**
 	 * Get the name of the Hibernate {@link org.hibernate.type.Type} associated
 	 * with the given {@link java.sql.Types} typecode with the given storage
 	 * specification parameters.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param length The datatype length
 	 * @param precision The datatype precision
 	 * @param scale The datatype scale
 	 * @return The Hibernate {@link org.hibernate.type.Type} name.
 	 * @throws HibernateException If no mapping was specified for that type.
 	 */
 	public String getHibernateTypeName(int code, int length, int precision, int scale) throws HibernateException {
 		String result = hibernateTypeNames.get( code, length, precision, scale );
 		if ( result == null ) {
 			throw new HibernateException(
 					"No Hibernate type mapping for java.sql.Types code: " +
 					code +
 					", length: " +
 					length
 			);
 		}
 		return result;
 	}
 
 	/**
 	 * Registers a Hibernate {@link org.hibernate.type.Type} name for the given
 	 * {@link java.sql.Types} type code and maximum column length.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param capacity The maximum length of database type
 	 * @param name The Hibernate {@link org.hibernate.type.Type} name
 	 */
 	protected void registerHibernateType(int code, int capacity, String name) {
 		hibernateTypeNames.put( code, capacity, name);
 	}
 
 	/**
 	 * Registers a Hibernate {@link org.hibernate.type.Type} name for the given
 	 * {@link java.sql.Types} type code.
 	 *
 	 * @param code The {@link java.sql.Types} typecode
 	 * @param name The Hibernate {@link org.hibernate.type.Type} name
 	 */
 	protected void registerHibernateType(int code, String name) {
 		hibernateTypeNames.put( code, name);
 	}
 
 
 	// function support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	protected void registerFunction(String name, SQLFunction function) {
 		sqlFunctions.put( name, function );
 	}
 
 	/**
 	 * Retrieves a map of the dialect's registered functions
 	 * (functionName => {@link org.hibernate.dialect.function.SQLFunction}).
 	 *
 	 * @return The map of registered functions.
 	 */
 	public final Map<String, SQLFunction> getFunctions() {
 		return sqlFunctions;
 	}
 
 
 	// keyword support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	protected void registerKeyword(String word) {
 		sqlKeywords.add(word);
 	}
 
 	public Set<String> getKeywords() {
 		return sqlKeywords;
 	}
 
 
 	// native identifier generation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * The class (which implements {@link org.hibernate.id.IdentifierGenerator})
 	 * which acts as this dialects native generation strategy.
 	 * <p/>
 	 * Comes into play whenever the user specifies the native generator.
 	 *
 	 * @return The native generator class.
 	 */
 	public Class getNativeIdentifierGeneratorClass() {
 		if ( supportsIdentityColumns() ) {
 			return IdentityGenerator.class;
 		}
 		else if ( supportsSequences() ) {
 			return SequenceGenerator.class;
 		}
 		else {
 			return TableHiLoGenerator.class;
 		}
 	}
 
 
 	// IDENTITY support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Does this dialect support identity column key generation?
 	 *
 	 * @return True if IDENTITY columns are supported; false otherwise.
 	 */
 	public boolean supportsIdentityColumns() {
 		return false;
 	}
 
 	/**
 	 * Does the dialect support some form of inserting and selecting
 	 * the generated IDENTITY value all in the same statement.
 	 *
 	 * @return True if the dialect supports selecting the just
 	 * generated IDENTITY in the insert statement.
 	 */
 	public boolean supportsInsertSelectIdentity() {
 		return false;
 	}
 
 	/**
 	 * Whether this dialect have an Identity clause added to the data type or a
 	 * completely separate identity data type
 	 *
 	 * @return boolean
 	 */
 	public boolean hasDataTypeInIdentityColumn() {
 		return true;
 	}
 
 	/**
 	 * Provided we {@link #supportsInsertSelectIdentity}, then attach the
 	 * "select identity" clause to the  insert statement.
 	 *  <p/>
 	 * Note, if {@link #supportsInsertSelectIdentity} == false then
 	 * the insert-string should be returned without modification.
 	 *
 	 * @param insertString The insert command
 	 * @return The insert command with any necessary identity select
 	 * clause attached.
 	 */
 	public String appendIdentitySelectToInsert(String insertString) {
 		return insertString;
 	}
 
 	/**
 	 * Get the select command to use to retrieve the last generated IDENTITY
 	 * value for a particular table
 	 *
 	 * @param table The table into which the insert was done
 	 * @param column The PK column.
 	 * @param type The {@link java.sql.Types} type code.
 	 * @return The appropriate select command
 	 * @throws MappingException If IDENTITY generation is not supported.
 	 */
 	public String getIdentitySelectString(String table, String column, int type) throws MappingException {
 		return getIdentitySelectString();
 	}
 
 	/**
 	 * Get the select command to use to retrieve the last generated IDENTITY
 	 * value.
 	 *
 	 * @return The appropriate select command
 	 * @throws MappingException If IDENTITY generation is not supported.
 	 */
 	protected String getIdentitySelectString() throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support identity key generation" );
 	}
 
 	/**
 	 * The syntax used during DDL to define a column as being an IDENTITY of
 	 * a particular type.
 	 *
 	 * @param type The {@link java.sql.Types} type code.
 	 * @return The appropriate DDL fragment.
 	 * @throws MappingException If IDENTITY generation is not supported.
 	 */
 	public String getIdentityColumnString(int type) throws MappingException {
 		return getIdentityColumnString();
 	}
 
 	/**
 	 * The syntax used during DDL to define a column as being an IDENTITY.
 	 *
 	 * @return The appropriate DDL fragment.
 	 * @throws MappingException If IDENTITY generation is not supported.
 	 */
 	protected String getIdentityColumnString() throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support identity key generation" );
 	}
 
 	/**
 	 * The keyword used to insert a generated value into an identity column (or null).
 	 * Need if the dialect does not support inserts that specify no column values.
 	 *
 	 * @return The appropriate keyword.
 	 */
 	public String getIdentityInsertString() {
 		return null;
 	}
 
 
 	// SEQUENCE support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Does this dialect support sequences?
 	 *
 	 * @return True if sequences supported; false otherwise.
 	 */
 	public boolean supportsSequences() {
 		return false;
 	}
 
 	/**
 	 * Does this dialect support "pooled" sequences.  Not aware of a better
 	 * name for this.  Essentially can we specify the initial and increment values?
 	 *
 	 * @return True if such "pooled" sequences are supported; false otherwise.
 	 * @see #getCreateSequenceStrings(String, int, int)
 	 * @see #getCreateSequenceString(String, int, int)
 	 */
 	public boolean supportsPooledSequences() {
 		return false;
 	}
 
 	/**
 	 * Generate the appropriate select statement to to retrieve the next value
 	 * of a sequence.
 	 * <p/>
 	 * This should be a "stand alone" select statement.
 	 *
 	 * @param sequenceName the name of the sequence
 	 * @return String The "nextval" select string.
 	 * @throws MappingException If sequences are not supported.
 	 */
 	public String getSequenceNextValString(String sequenceName) throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support sequences" );
 	}
 
 	/**
 	 * Generate the select expression fragment that will retrieve the next
 	 * value of a sequence as part of another (typically DML) statement.
 	 * <p/>
 	 * This differs from {@link #getSequenceNextValString(String)} in that this
 	 * should return an expression usable within another statement.
 	 *
 	 * @param sequenceName the name of the sequence
 	 * @return The "nextval" fragment.
 	 * @throws MappingException If sequences are not supported.
 	 */
 	public String getSelectSequenceNextValString(String sequenceName) throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support sequences" );
 	}
 
 	/**
 	 * The multiline script used to create a sequence.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @return The sequence creation commands
 	 * @throws MappingException If sequences are not supported.
 	 * @deprecated Use {@link #getCreateSequenceString(String, int, int)} instead
 	 */
 	@Deprecated
     public String[] getCreateSequenceStrings(String sequenceName) throws MappingException {
 		return new String[] { getCreateSequenceString( sequenceName ) };
 	}
 
 	/**
 	 * An optional multi-line form for databases which {@link #supportsPooledSequences()}.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @param initialValue The initial value to apply to 'create sequence' statement
 	 * @param incrementSize The increment value to apply to 'create sequence' statement
 	 * @return The sequence creation commands
 	 * @throws MappingException If sequences are not supported.
 	 */
 	public String[] getCreateSequenceStrings(String sequenceName, int initialValue, int incrementSize) throws MappingException {
 		return new String[] { getCreateSequenceString( sequenceName, initialValue, incrementSize ) };
 	}
 
 	/**
 	 * Typically dialects which support sequences can create a sequence
 	 * with a single command.  This is convenience form of
 	 * {@link #getCreateSequenceStrings} to help facilitate that.
 	 * <p/>
 	 * Dialects which support sequences and can create a sequence in a
 	 * single command need *only* override this method.  Dialects
 	 * which support sequences but require multiple commands to create
 	 * a sequence should instead override {@link #getCreateSequenceStrings}.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @return The sequence creation command
 	 * @throws MappingException If sequences are not supported.
 	 */
 	protected String getCreateSequenceString(String sequenceName) throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support sequences" );
 	}
 
 	/**
 	 * Overloaded form of {@link #getCreateSequenceString(String)}, additionally
 	 * taking the initial value and increment size to be applied to the sequence
 	 * definition.
 	 * </p>
 	 * The default definition is to suffix {@link #getCreateSequenceString(String)}
 	 * with the string: " start with {initialValue} increment by {incrementSize}" where
 	 * {initialValue} and {incrementSize} are replacement placeholders.  Generally
 	 * dialects should only need to override this method if different key phrases
 	 * are used to apply the allocation information.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @param initialValue The initial value to apply to 'create sequence' statement
 	 * @param incrementSize The increment value to apply to 'create sequence' statement
 	 * @return The sequence creation command
 	 * @throws MappingException If sequences are not supported.
 	 */
 	protected String getCreateSequenceString(String sequenceName, int initialValue, int incrementSize) throws MappingException {
 		if ( supportsPooledSequences() ) {
 			return getCreateSequenceString( sequenceName ) + " start with " + initialValue + " increment by " + incrementSize;
 		}
 		throw new MappingException( getClass().getName() + " does not support pooled sequences" );
 	}
 
 	/**
 	 * The multiline script used to drop a sequence.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @return The sequence drop commands
 	 * @throws MappingException If sequences are not supported.
 	 */
 	public String[] getDropSequenceStrings(String sequenceName) throws MappingException {
 		return new String[]{getDropSequenceString( sequenceName )};
 	}
 
 	/**
 	 * Typically dialects which support sequences can drop a sequence
 	 * with a single command.  This is convenience form of
 	 * {@link #getDropSequenceStrings} to help facilitate that.
 	 * <p/>
 	 * Dialects which support sequences and can drop a sequence in a
 	 * single command need *only* override this method.  Dialects
 	 * which support sequences but require multiple commands to drop
 	 * a sequence should instead override {@link #getDropSequenceStrings}.
 	 *
 	 * @param sequenceName The name of the sequence
 	 * @return The sequence drop commands
 	 * @throws MappingException If sequences are not supported.
 	 */
 	protected String getDropSequenceString(String sequenceName) throws MappingException {
 		throw new MappingException( getClass().getName() + " does not support sequences" );
 	}
 
 	/**
 	 * Get the select command used retrieve the names of all sequences.
 	 *
 	 * @return The select command; or null if sequences are not supported.
 	 * @see org.hibernate.tool.hbm2ddl.SchemaUpdate
 	 */
 	public String getQuerySequencesString() {
 		return null;
 	}
 
 
 	// GUID support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Get the command used to select a GUID from the underlying database.
 	 * <p/>
 	 * Optional operation.
 	 *
 	 * @return The appropriate command.
 	 */
 	public String getSelectGUIDString() {
 		throw new UnsupportedOperationException( getClass().getName() + " does not support GUIDs" );
 	}
 
 
 	// limit/offset support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Does this dialect support some form of limiting query results
 	 * via a SQL clause?
 	 *
 	 * @return True if this dialect supports some form of LIMIT.
 	 */
 	public boolean supportsLimit() {
 		return false;
 	}
 
 	/**
 	 * Does this dialect's LIMIT support (if any) additionally
 	 * support specifying an offset?
 	 *
 	 * @return True if the dialect supports an offset within the limit support.
 	 */
 	public boolean supportsLimitOffset() {
 		return supportsLimit();
 	}
 
 	/**
 	 * Does this dialect support bind variables (i.e., prepared statement
 	 * parameters) for its limit/offset?
 	 *
 	 * @return True if bind variables can be used; false otherwise.
 	 */
 	public boolean supportsVariableLimit() {
 		return supportsLimit();
 	}
 
 	/**
 	 * ANSI SQL defines the LIMIT clause to be in the form LIMIT offset, limit.
 	 * Does this dialect require us to bind the parameters in reverse order?
 	 *
 	 * @return true if the correct order is limit, offset
 	 */
 	public boolean bindLimitParametersInReverseOrder() {
 		return false;
 	}
 
 	/**
 	 * Does the <tt>LIMIT</tt> clause come at the start of the
 	 * <tt>SELECT</tt> statement, rather than at the end?
 	 *
 	 * @return true if limit parameters should come before other parameters
 	 */
 	public boolean bindLimitParametersFirst() {
 		return false;
 	}
 
 	/**
 	 * Does the <tt>LIMIT</tt> clause take a "maximum" row number instead
 	 * of a total number of returned rows?
 	 * <p/>
 	 * This is easiest understood via an example.  Consider you have a table
 	 * with 20 rows, but you only want to retrieve rows number 11 through 20.
 	 * Generally, a limit with offset would say that the offset = 11 and the
 	 * limit = 10 (we only want 10 rows at a time); this is specifying the
 	 * total number of returned rows.  Some dialects require that we instead
 	 * specify offset = 11 and limit = 20, where 20 is the "last" row we want
 	 * relative to offset (i.e. total number of rows = 20 - 11 = 9)
 	 * <p/>
 	 * So essentially, is limit relative from offset?  Or is limit absolute?
 	 *
 	 * @return True if limit is relative from offset; false otherwise.
 	 */
 	public boolean useMaxForLimit() {
 		return false;
 	}
 
 	/**
 	 * Generally, if there is no limit applied to a Hibernate query we do not apply any limits
 	 * to the SQL query.  This option forces that the limit be written to the SQL query.
 	 *
 	 * @return True to force limit into SQL query even if none specified in Hibernate query; false otherwise.
 	 */
 	public boolean forceLimitUsage() {
 		return false;
 	}
 
 	/**
 	 * Given a limit and an offset, apply the limit clause to the query.
 	 *
 	 * @param query The query to which to apply the limit.
 	 * @param offset The offset of the limit
 	 * @param limit The limit of the limit ;)
 	 * @return The modified query statement with the limit applied.
 	 */
 	public String getLimitString(String query, int offset, int limit) {
 		return getLimitString( query, ( offset > 0 || forceLimitUsage() )  );
 	}
 
 	/**
 	 * Apply s limit clause to the query.
 	 * <p/>
 	 * Typically dialects utilize {@link #supportsVariableLimit() variable}
 	 * limit clauses when they support limits.  Thus, when building the
 	 * select command we do not actually need to know the limit or the offest
 	 * since we will just be using placeholders.
 	 * <p/>
 	 * Here we do still pass along whether or not an offset was specified
 	 * so that dialects not supporting offsets can generate proper exceptions.
 	 * In general, dialects will override one or the other of this method and
 	 * {@link #getLimitString(String, int, int)}.
 	 *
 	 * @param query The query to which to apply the limit.
 	 * @param hasOffset Is the query requesting an offset?
 	 * @return the modified SQL
 	 */
 	protected String getLimitString(String query, boolean hasOffset) {
 		throw new UnsupportedOperationException( "Paged queries not supported by " + getClass().getName());
 	}
 
 	/**
 	 * Hibernate APIs explicitly state that setFirstResult() should be a zero-based offset. Here we allow the
 	 * Dialect a chance to convert that value based on what the underlying db or driver will expect.
 	 * <p/>
 	 * NOTE: what gets passed into {@link #getLimitString(String,int,int)} is the zero-based offset.  Dialects which
 	 * do not {@link #supportsVariableLimit} should take care to perform any needed {@link #convertToFirstRowValue}
 	 * calls prior to injecting the limit values into the SQL string.
 	 *
 	 * @param zeroBasedFirstResult The user-supplied, zero-based first row offset.
 	 *
 	 * @return The corresponding db/dialect specific offset.
 	 *
 	 * @see org.hibernate.Query#setFirstResult
 	 * @see org.hibernate.Criteria#setFirstResult
 	 */
 	public int convertToFirstRowValue(int zeroBasedFirstResult) {
 		return zeroBasedFirstResult;
 	}
 
 
 	// lock acquisition support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Informational metadata about whether this dialect is known to support
 	 * specifying timeouts for requested lock acquisitions.
 	 *
 	 * @return True is this dialect supports specifying lock timeouts.
 	 */
 	public boolean supportsLockTimeouts() {
 		return true;
 
 	}
 
 	/**
 	 * If this dialect supports specifying lock timeouts, are those timeouts
 	 * rendered into the <tt>SQL</tt> string as parameters.  The implication
 	 * is that Hibernate will need to bind the timeout value as a parameter
 	 * in the {@link java.sql.PreparedStatement}.  If true, the param position
 	 * is always handled as the last parameter; if the dialect specifies the
 	 * lock timeout elsewhere in the <tt>SQL</tt> statement then the timeout
 	 * value should be directly rendered into the statement and this method
 	 * should return false.
 	 *
 	 * @return True if the lock timeout is rendered into the <tt>SQL</tt>
 	 * string as a parameter; false otherwise.
 	 */
 	public boolean isLockTimeoutParameterized() {
 		return false;
 	}
 
 	/**
 	 * Get a strategy instance which knows how to acquire a database-level lock
 	 * of the specified mode for this dialect.
 	 *
 	 * @param lockable The persister for the entity to be locked.
 	 * @param lockMode The type of lock to be acquired.
 	 * @return The appropriate locking strategy.
 	 * @since 3.2
 	 */
 	public LockingStrategy getLockingStrategy(Lockable lockable, LockMode lockMode) {
 		if ( lockMode==LockMode.PESSIMISTIC_FORCE_INCREMENT) {
 			return new PessimisticForceIncrementLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode==LockMode.PESSIMISTIC_WRITE) {
 			return new PessimisticWriteSelectLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode==LockMode.PESSIMISTIC_READ) {
 			return new PessimisticReadSelectLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode==LockMode.OPTIMISTIC) {
 			return new OptimisticLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode==LockMode.OPTIMISTIC_FORCE_INCREMENT) {
 			return new OptimisticForceIncrementLockingStrategy( lockable, lockMode);
 		}
 		return new SelectLockingStrategy( lockable, lockMode );
 	}
 
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/H2Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/H2Dialect.java
index 0bfda11376..fbfd49b007 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/H2Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/H2Dialect.java
@@ -1,357 +1,357 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.SQLException;
 import java.sql.Types;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.AvgWithArgumentCastFunction;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.exception.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.StandardBasicTypes;
 import org.jboss.logging.Logger;
 
 /**
  * A dialect compatible with the H2 database.
  *
  * @author Thomas Mueller
  */
 public class H2Dialect extends Dialect {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, H2Dialect.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, H2Dialect.class.getName());
 
 	private final String querySequenceString;
 
 	public H2Dialect() {
 		super();
 
 		String querySequenceString = "select sequence_name from information_schema.sequences";
 		try {
 			// HHH-2300
 			final Class h2ConstantsClass = ReflectHelper.classForName( "org.h2.engine.Constants" );
 			final int majorVersion = ( Integer ) h2ConstantsClass.getDeclaredField( "VERSION_MAJOR" ).get( null );
 			final int minorVersion = ( Integer ) h2ConstantsClass.getDeclaredField( "VERSION_MINOR" ).get( null );
 			final int buildId = ( Integer ) h2ConstantsClass.getDeclaredField( "BUILD_ID" ).get( null );
 			if ( buildId < 32 ) {
 				querySequenceString = "select name from information_schema.sequences";
 			}
             if ( ! ( majorVersion > 1 || minorVersion > 2 || buildId >= 139 ) ) {
 				LOG.unsupportedMultiTableBulkHqlJpaql( majorVersion, minorVersion, buildId );
 			}
 		}
 		catch ( Exception e ) {
 			// probably H2 not in the classpath, though in certain app server environments it might just mean we are
 			// not using the correct classloader
 			LOG.undeterminedH2Version();
 		}
 
 		this.querySequenceString = querySequenceString;
 
 		registerColumnType( Types.BOOLEAN, "boolean" );
 		registerColumnType( Types.BIGINT, "bigint" );
 		registerColumnType( Types.BINARY, "binary" );
 		registerColumnType( Types.BIT, "boolean" );
 		registerColumnType( Types.CHAR, "char($l)" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.DECIMAL, "decimal($p,$s)" );
 		registerColumnType( Types.NUMERIC, "decimal($p,$s)" );
 		registerColumnType( Types.DOUBLE, "double" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.INTEGER, "integer" );
 		registerColumnType( Types.LONGVARBINARY, "longvarbinary" );
 		registerColumnType( Types.LONGVARCHAR, "longvarchar" );
 		registerColumnType( Types.REAL, "real" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.TINYINT, "tinyint" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.VARBINARY, "binary($l)" );
 		registerColumnType( Types.BLOB, "blob" );
 		registerColumnType( Types.CLOB, "clob" );
 
 		// Aggregations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		registerFunction( "avg", new AvgWithArgumentCastFunction( "double" ) );
 
 		// select topic, syntax from information_schema.help
 		// where section like 'Function%' order by section, topic
 		//
 		// see also ->  http://www.h2database.com/html/functions.html
 
 		// Numeric Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		registerFunction( "acos", new StandardSQLFunction( "acos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "asin", new StandardSQLFunction( "asin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan", new StandardSQLFunction( "atan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan2", new StandardSQLFunction( "atan2", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "bitand", new StandardSQLFunction( "bitand", StandardBasicTypes.INTEGER ) );
 		registerFunction( "bitor", new StandardSQLFunction( "bitor", StandardBasicTypes.INTEGER ) );
 		registerFunction( "bitxor", new StandardSQLFunction( "bitxor", StandardBasicTypes.INTEGER ) );
 		registerFunction( "ceiling", new StandardSQLFunction( "ceiling", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cos", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "compress", new StandardSQLFunction( "compress", StandardBasicTypes.BINARY ) );
 		registerFunction( "cot", new StandardSQLFunction( "cot", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "decrypt", new StandardSQLFunction( "decrypt", StandardBasicTypes.BINARY ) );
 		registerFunction( "degrees", new StandardSQLFunction( "degrees", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "encrypt", new StandardSQLFunction( "encrypt", StandardBasicTypes.BINARY ) );
 		registerFunction( "exp", new StandardSQLFunction( "exp", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "expand", new StandardSQLFunction( "compress", StandardBasicTypes.BINARY ) );
 		registerFunction( "floor", new StandardSQLFunction( "floor", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "hash", new StandardSQLFunction( "hash", StandardBasicTypes.BINARY ) );
 		registerFunction( "log", new StandardSQLFunction( "log", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log10", new StandardSQLFunction( "log10", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "pi", new NoArgSQLFunction( "pi", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "power", new StandardSQLFunction( "power", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "radians", new StandardSQLFunction( "radians", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "rand", new NoArgSQLFunction( "rand", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "round", new StandardSQLFunction( "round", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "roundmagic", new StandardSQLFunction( "roundmagic", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sign", new StandardSQLFunction( "sign", StandardBasicTypes.INTEGER ) );
 		registerFunction( "sin", new StandardSQLFunction( "sin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tan", new StandardSQLFunction( "tan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "truncate", new StandardSQLFunction( "truncate", StandardBasicTypes.DOUBLE ) );
 
 		// String Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		registerFunction( "ascii", new StandardSQLFunction( "ascii", StandardBasicTypes.INTEGER ) );
 		registerFunction( "char", new StandardSQLFunction( "char", StandardBasicTypes.CHARACTER ) );
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(", "||", ")" ) );
 		registerFunction( "difference", new StandardSQLFunction( "difference", StandardBasicTypes.INTEGER ) );
 		registerFunction( "hextoraw", new StandardSQLFunction( "hextoraw", StandardBasicTypes.STRING ) );
 		registerFunction( "insert", new StandardSQLFunction( "lower", StandardBasicTypes.STRING ) );
 		registerFunction( "left", new StandardSQLFunction( "left", StandardBasicTypes.STRING ) );
 		registerFunction( "lcase", new StandardSQLFunction( "lcase", StandardBasicTypes.STRING ) );
 		registerFunction( "ltrim", new StandardSQLFunction( "ltrim", StandardBasicTypes.STRING ) );
 		registerFunction( "octet_length", new StandardSQLFunction( "octet_length", StandardBasicTypes.INTEGER ) );
 		registerFunction( "position", new StandardSQLFunction( "position", StandardBasicTypes.INTEGER ) );
 		registerFunction( "rawtohex", new StandardSQLFunction( "rawtohex", StandardBasicTypes.STRING ) );
 		registerFunction( "repeat", new StandardSQLFunction( "repeat", StandardBasicTypes.STRING ) );
 		registerFunction( "replace", new StandardSQLFunction( "replace", StandardBasicTypes.STRING ) );
 		registerFunction( "right", new StandardSQLFunction( "right", StandardBasicTypes.STRING ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim", StandardBasicTypes.STRING ) );
 		registerFunction( "soundex", new StandardSQLFunction( "soundex", StandardBasicTypes.STRING ) );
 		registerFunction( "space", new StandardSQLFunction( "space", StandardBasicTypes.STRING ) );
 		registerFunction( "stringencode", new StandardSQLFunction( "stringencode", StandardBasicTypes.STRING ) );
 		registerFunction( "stringdecode", new StandardSQLFunction( "stringdecode", StandardBasicTypes.STRING ) );
 		registerFunction( "stringtoutf8", new StandardSQLFunction( "stringtoutf8", StandardBasicTypes.BINARY ) );
 		registerFunction( "ucase", new StandardSQLFunction( "ucase", StandardBasicTypes.STRING ) );
 		registerFunction( "utf8tostring", new StandardSQLFunction( "utf8tostring", StandardBasicTypes.STRING ) );
 
 		// Time and Date Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		registerFunction( "curdate", new NoArgSQLFunction( "curdate", StandardBasicTypes.DATE ) );
 		registerFunction( "curtime", new NoArgSQLFunction( "curtime", StandardBasicTypes.TIME ) );
 		registerFunction( "curtimestamp", new NoArgSQLFunction( "curtimestamp", StandardBasicTypes.TIME ) );
 		registerFunction( "current_date", new NoArgSQLFunction( "current_date", StandardBasicTypes.DATE ) );
 		registerFunction( "current_time", new NoArgSQLFunction( "current_time", StandardBasicTypes.TIME ) );
 		registerFunction( "current_timestamp", new NoArgSQLFunction( "current_timestamp", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "datediff", new StandardSQLFunction( "datediff", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayname", new StandardSQLFunction( "dayname", StandardBasicTypes.STRING ) );
 		registerFunction( "dayofmonth", new StandardSQLFunction( "dayofmonth", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofweek", new StandardSQLFunction( "dayofweek", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofyear", new StandardSQLFunction( "dayofyear", StandardBasicTypes.INTEGER ) );
 		registerFunction( "monthname", new StandardSQLFunction( "monthname", StandardBasicTypes.STRING ) );
 		registerFunction( "now", new NoArgSQLFunction( "now", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "quarter", new StandardSQLFunction( "quarter", StandardBasicTypes.INTEGER ) );
 		registerFunction( "week", new StandardSQLFunction( "week", StandardBasicTypes.INTEGER ) );
 
 		// System Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		registerFunction( "database", new NoArgSQLFunction( "database", StandardBasicTypes.STRING ) );
 		registerFunction( "user", new NoArgSQLFunction( "user", StandardBasicTypes.STRING ) );
 
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 		getDefaultProperties().setProperty( Environment.NON_CONTEXTUAL_LOB_CREATION, "true" );  // http://code.google.com/p/h2database/issues/detail?id=235
 	}
 
 	public String getAddColumnString() {
 		return "add column";
 	}
 
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	public String getIdentityColumnString() {
 		return "generated by default as identity"; // not null is implicit
 	}
 
 	public String getIdentitySelectString() {
 		return "call identity()";
 	}
 
 	public String getIdentityInsertString() {
 		return "null";
 	}
 
 	public String getForUpdateString() {
 		return " for update";
 	}
 
 	public boolean supportsUnique() {
 		return true;
 	}
 
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	public String getLimitString(String sql, boolean hasOffset) {
 		return new StringBuffer( sql.length() + 20 )
 				.append( sql )
 				.append( hasOffset ? " limit ? offset ?" : " limit ?" )
 				.toString();
 	}
 
 	public boolean bindLimitParametersInReverseOrder() {
 		return true;
 	}
 
 	public boolean bindLimitParametersFirst() {
 		return false;
 	}
 
 	public boolean supportsIfExistsAfterTableName() {
 		return true;
 	}
 
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	public String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName;
 	}
 
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return "next value for " + sequenceName;
 	}
 
 	public String getSequenceNextValString(String sequenceName) {
 		return "call next value for " + sequenceName;
 	}
 
 	public String getQuerySequencesString() {
 		return querySequenceString;
 	}
 
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 	private static ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 		/**
 		 * Extract the name of the violated constraint from the given SQLException.
 		 *
 		 * @param sqle The exception that was the result of the constraint violation.
 		 * @return The extracted constraint name.
 		 */
 		public String extractConstraintName(SQLException sqle) {
 			String constraintName = null;
 			// 23000: Check constraint violation: {0}
 			// 23001: Unique index or primary key violation: {0}
 			if ( sqle.getSQLState().startsWith( "23" ) ) {
 				final String message = sqle.getMessage();
 				int idx = message.indexOf( "violation: " );
 				if ( idx > 0 ) {
 					constraintName = message.substring( idx + "violation: ".length() );
 				}
 			}
 			return constraintName;
 		}
 	};
 
 	@Override
 	public boolean supportsTemporaryTables() {
 		return true;
 	}
 
 	@Override
 	public String getCreateTemporaryTableString() {
 		return "create local temporary table if not exists";
 	}
 
 	@Override
 	public String getCreateTemporaryTablePostfix() {
 		// actually 2 different options are specified here:
 		//		1) [on commit drop] - says to drop the table on transaction commit
 		//		2) [transactional] - says to not perform an implicit commit of any current transaction
 		return "on commit drop transactional";
 	}
 
 	@Override
 	public Boolean performTemporaryTableDDLInIsolation() {
 		// explicitly create the table using the same connection and transaction
 		return Boolean.FALSE;
 	}
 
 	@Override
 	public boolean dropTemporaryTableAfterUse() {
 		return false;
 	}
 
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	public String getCurrentTimestampSelectString() {
 		return "call current_timestamp()";
 	}
 
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean supportsLobValueChangePropogation() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsTupleDistinctCounts() {
 		return false;
 	}
 
 	@Override
 	public boolean doesReadCommittedCauseWritersToBlockReaders() {
 		// see http://groups.google.com/group/h2-database/browse_thread/thread/562d8a49e2dabe99?hl=en
 		return true;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/HSQLDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/HSQLDialect.java
index 2a7a5b0ee1..c3a58a2241 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/HSQLDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/HSQLDialect.java
@@ -1,665 +1,666 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.io.Serializable;
 import java.sql.SQLException;
 import java.sql.Types;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.AvgWithArgumentCastFunction;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.dialect.lock.OptimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.OptimisticLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticReadSelectLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticWriteSelectLockingStrategy;
 import org.hibernate.dialect.lock.SelectLockingStrategy;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.exception.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.type.StandardBasicTypes;
 import org.jboss.logging.Logger;
 
 /**
  * An SQL dialect compatible with HSQLDB (HyperSQL).
  * <p/>
  * Note this version supports HSQLDB version 1.8 and higher, only.
  * <p/>
  * Enhancements to version 3.5.0 GA to provide basic support for both HSQLDB 1.8.x and 2.0
  * Should work with Hibernate 3.2 and later
  *
  * @author Christoph Sturm
  * @author Phillip Baird
  * @author Fred Toussi
  */
 public class HSQLDialect extends Dialect {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, HSQLDialect.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HSQLDialect.class.getName());
 
 	/**
 	 * version is 18 for 1.8 or 20 for 2.0
 	 */
 	private int hsqldbVersion = 18;
 
 
 	public HSQLDialect() {
 		super();
 
 		try {
 			Class props = ReflectHelper.classForName( "org.hsqldb.persist.HsqlDatabaseProperties" );
 			String versionString = (String) props.getDeclaredField( "THIS_VERSION" ).get( null );
 
 			hsqldbVersion = Integer.parseInt( versionString.substring( 0, 1 ) ) * 10;
 			hsqldbVersion += Integer.parseInt( versionString.substring( 2, 3 ) );
 		}
 		catch ( Throwable e ) {
 			// must be a very old version
 		}
 
 		registerColumnType( Types.BIGINT, "bigint" );
 		registerColumnType( Types.BINARY, "binary($l)" );
 		registerColumnType( Types.BIT, "bit" );
         registerColumnType( Types.BOOLEAN, "boolean" );
 		registerColumnType( Types.CHAR, "char($l)" );
 		registerColumnType( Types.DATE, "date" );
 
 		registerColumnType( Types.DECIMAL, "decimal($p,$s)" );
 		registerColumnType( Types.DOUBLE, "double" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.INTEGER, "integer" );
 		registerColumnType( Types.LONGVARBINARY, "longvarbinary" );
 		registerColumnType( Types.LONGVARCHAR, "longvarchar" );
 		registerColumnType( Types.SMALLINT, "smallint" );
 		registerColumnType( Types.TINYINT, "tinyint" );
 		registerColumnType( Types.TIME, "time" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.VARCHAR, "varchar($l)" );
 		registerColumnType( Types.VARBINARY, "varbinary($l)" );
 
 		if ( hsqldbVersion < 20 ) {
 			registerColumnType( Types.NUMERIC, "numeric" );
 		}
 		else {
 			registerColumnType( Types.NUMERIC, "numeric($p,$s)" );
 		}
 
 		//HSQL has no Blob/Clob support .... but just put these here for now!
 		if ( hsqldbVersion < 20 ) {
 			registerColumnType( Types.BLOB, "longvarbinary" );
 			registerColumnType( Types.CLOB, "longvarchar" );
 		}
 		else {
 			registerColumnType( Types.BLOB, "blob" );
 			registerColumnType( Types.CLOB, "clob" );
 		}
 
 		registerFunction( "avg", new AvgWithArgumentCastFunction( "double" ) );
 
 		registerFunction( "ascii", new StandardSQLFunction( "ascii", StandardBasicTypes.INTEGER ) );
 		registerFunction( "char", new StandardSQLFunction( "char", StandardBasicTypes.CHARACTER ) );
 		registerFunction( "lower", new StandardSQLFunction( "lower" ) );
 		registerFunction( "upper", new StandardSQLFunction( "upper" ) );
 		registerFunction( "lcase", new StandardSQLFunction( "lcase" ) );
 		registerFunction( "ucase", new StandardSQLFunction( "ucase" ) );
 		registerFunction( "soundex", new StandardSQLFunction( "soundex", StandardBasicTypes.STRING ) );
 		registerFunction( "ltrim", new StandardSQLFunction( "ltrim" ) );
 		registerFunction( "rtrim", new StandardSQLFunction( "rtrim" ) );
 		registerFunction( "reverse", new StandardSQLFunction( "reverse" ) );
 		registerFunction( "space", new StandardSQLFunction( "space", StandardBasicTypes.STRING ) );
 		registerFunction( "rawtohex", new StandardSQLFunction( "rawtohex" ) );
 		registerFunction( "hextoraw", new StandardSQLFunction( "hextoraw" ) );
 		registerFunction( "str", new SQLFunctionTemplate( StandardBasicTypes.STRING, "cast(?1 as varchar(24))" ) );
 		registerFunction( "user", new NoArgSQLFunction( "user", StandardBasicTypes.STRING ) );
 		registerFunction( "database", new NoArgSQLFunction( "database", StandardBasicTypes.STRING ) );
 
 		registerFunction( "sysdate", new NoArgSQLFunction( "sysdate", StandardBasicTypes.DATE, false ) );
 		registerFunction( "current_date", new NoArgSQLFunction( "current_date", StandardBasicTypes.DATE, false ) );
 		registerFunction( "curdate", new NoArgSQLFunction( "curdate", StandardBasicTypes.DATE ) );
 		registerFunction(
 				"current_timestamp", new NoArgSQLFunction( "current_timestamp", StandardBasicTypes.TIMESTAMP, false )
 		);
 		registerFunction( "now", new NoArgSQLFunction( "now", StandardBasicTypes.TIMESTAMP ) );
 		registerFunction( "current_time", new NoArgSQLFunction( "current_time", StandardBasicTypes.TIME, false ) );
 		registerFunction( "curtime", new NoArgSQLFunction( "curtime", StandardBasicTypes.TIME ) );
 		registerFunction( "day", new StandardSQLFunction( "day", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofweek", new StandardSQLFunction( "dayofweek", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofyear", new StandardSQLFunction( "dayofyear", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayofmonth", new StandardSQLFunction( "dayofmonth", StandardBasicTypes.INTEGER ) );
 		registerFunction( "month", new StandardSQLFunction( "month", StandardBasicTypes.INTEGER ) );
 		registerFunction( "year", new StandardSQLFunction( "year", StandardBasicTypes.INTEGER ) );
 		registerFunction( "week", new StandardSQLFunction( "week", StandardBasicTypes.INTEGER ) );
 		registerFunction( "quarter", new StandardSQLFunction( "quarter", StandardBasicTypes.INTEGER ) );
 		registerFunction( "hour", new StandardSQLFunction( "hour", StandardBasicTypes.INTEGER ) );
 		registerFunction( "minute", new StandardSQLFunction( "minute", StandardBasicTypes.INTEGER ) );
 		registerFunction( "second", new StandardSQLFunction( "second", StandardBasicTypes.INTEGER ) );
 		registerFunction( "dayname", new StandardSQLFunction( "dayname", StandardBasicTypes.STRING ) );
 		registerFunction( "monthname", new StandardSQLFunction( "monthname", StandardBasicTypes.STRING ) );
 
 		registerFunction( "abs", new StandardSQLFunction( "abs" ) );
 		registerFunction( "sign", new StandardSQLFunction( "sign", StandardBasicTypes.INTEGER ) );
 
 		registerFunction( "acos", new StandardSQLFunction( "acos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "asin", new StandardSQLFunction( "asin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "atan", new StandardSQLFunction( "atan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cos", new StandardSQLFunction( "cos", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "cot", new StandardSQLFunction( "cot", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "exp", new StandardSQLFunction( "exp", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log", new StandardSQLFunction( "log", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "log10", new StandardSQLFunction( "log10", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sin", new StandardSQLFunction( "sin", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "sqrt", new StandardSQLFunction( "sqrt", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "tan", new StandardSQLFunction( "tan", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "pi", new NoArgSQLFunction( "pi", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "rand", new StandardSQLFunction( "rand", StandardBasicTypes.FLOAT ) );
 
 		registerFunction( "radians", new StandardSQLFunction( "radians", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "degrees", new StandardSQLFunction( "degrees", StandardBasicTypes.DOUBLE ) );
 		registerFunction( "roundmagic", new StandardSQLFunction( "roundmagic" ) );
 
 		registerFunction( "ceiling", new StandardSQLFunction( "ceiling" ) );
 		registerFunction( "floor", new StandardSQLFunction( "floor" ) );
 
 		// Multi-param dialect functions...
 		registerFunction( "mod", new StandardSQLFunction( "mod", StandardBasicTypes.INTEGER ) );
 
 		// function templates
 		registerFunction( "concat", new VarArgsSQLFunction( StandardBasicTypes.STRING, "(", "||", ")" ) );
 
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 	}
 
 	public String getAddColumnString() {
 		return "add column";
 	}
 
 	public boolean supportsIdentityColumns() {
 		return true;
 	}
 
 	public String getIdentityColumnString() {
 		return "generated by default as identity (start with 1)"; //not null is implicit
 	}
 
 	public String getIdentitySelectString() {
 		return "call identity()";
 	}
 
 	public String getIdentityInsertString() {
 		return hsqldbVersion < 20 ? "null" : "default";
 	}
 
 	public boolean supportsLockTimeouts() {
 		return false;
 	}
 
 	public String getForUpdateString() {
 		return "";
 	}
 
 	public boolean supportsUnique() {
 		return false;
 	}
 
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	public String getLimitString(String sql, boolean hasOffset) {
 		if ( hsqldbVersion < 20 ) {
 			return new StringBuffer( sql.length() + 10 )
 					.append( sql )
 					.insert(
 							sql.toLowerCase().indexOf( "select" ) + 6,
 							hasOffset ? " limit ? ?" : " top ?"
 					)
 					.toString();
 		}
 		else {
 			return new StringBuffer( sql.length() + 20 )
 					.append( sql )
 					.append( hasOffset ? " offset ? limit ?" : " limit ?" )
 					.toString();
 		}
 	}
 
 	public boolean bindLimitParametersFirst() {
 		return hsqldbVersion < 20;
 	}
 
 	public boolean supportsIfExistsAfterTableName() {
 		return true;
 	}
 
 	public boolean supportsColumnCheck() {
 		return hsqldbVersion >= 20;
 	}
 
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	protected String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName;
 	}
 
 	protected String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return "next value for " + sequenceName;
 	}
 
 	public String getSequenceNextValString(String sequenceName) {
 		return "call next value for " + sequenceName;
 	}
 
 	public String getQuerySequencesString() {
 		// this assumes schema support, which is present in 1.8.0 and later...
 		return "select sequence_name from information_schema.system_sequences";
 	}
 
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return hsqldbVersion < 20 ? EXTRACTER_18 : EXTRACTER_20;
 	}
 
 	private static ViolatedConstraintNameExtracter EXTRACTER_18 = new TemplatedViolatedConstraintNameExtracter() {
 
 		/**
 		 * Extract the name of the violated constraint from the given SQLException.
 		 *
 		 * @param sqle The exception that was the result of the constraint violation.
 		 * @return The extracted constraint name.
 		 */
 		public String extractConstraintName(SQLException sqle) {
 			String constraintName = null;
 
 			int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 
 			if ( errorCode == -8 ) {
 				constraintName = extractUsingTemplate(
 						"Integrity constraint violation ", " table:", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -9 ) {
 				constraintName = extractUsingTemplate(
 						"Violation of unique index: ", " in statement [", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -104 ) {
 				constraintName = extractUsingTemplate(
 						"Unique constraint violation: ", " in statement [", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -177 ) {
 				constraintName = extractUsingTemplate(
 						"Integrity constraint violation - no parent ", " table:",
 						sqle.getMessage()
 				);
 			}
 			return constraintName;
 		}
 
 	};
 
 	/**
 	 * HSQLDB 2.0 messages have changed
 	 * messages may be localized - therefore use the common, non-locale element " table: "
 	 */
 	private static ViolatedConstraintNameExtracter EXTRACTER_20 = new TemplatedViolatedConstraintNameExtracter() {
 
 		public String extractConstraintName(SQLException sqle) {
 			String constraintName = null;
 
 			int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 
 			if ( errorCode == -8 ) {
 				constraintName = extractUsingTemplate(
 						"; ", " table: ", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -9 ) {
 				constraintName = extractUsingTemplate(
 						"; ", " table: ", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -104 ) {
 				constraintName = extractUsingTemplate(
 						"; ", " table: ", sqle.getMessage()
 				);
 			}
 			else if ( errorCode == -177 ) {
 				constraintName = extractUsingTemplate(
 						"; ", " table: ", sqle.getMessage()
 				);
 			}
 			return constraintName;
 		}
 	};
 
 	public String getSelectClauseNullString(int sqlType) {
 		String literal;
 		switch ( sqlType ) {
 			case Types.VARCHAR:
 			case Types.CHAR:
 				literal = "cast(null as varchar(100))";
 				break;
 			case Types.DATE:
 				literal = "cast(null as date)";
 				break;
 			case Types.TIMESTAMP:
 				literal = "cast(null as timestamp)";
 				break;
 			case Types.TIME:
 				literal = "cast(null as time)";
 				break;
 			default:
 				literal = "cast(null as int)";
 		}
 		return literal;
 	}
 
     public boolean supportsUnionAll() {
         return true;
     }
 
 	// temporary table support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Hibernate uses this information for temporary tables that it uses for its own operations
 	// therefore the appropriate strategy is taken with different versions of HSQLDB
 
 	// All versions of HSQLDB support GLOBAL TEMPORARY tables where the table
 	// definition is shared by all users but data is private to the session
 	// HSQLDB 2.0 also supports session-based LOCAL TEMPORARY tables where
 	// the definition and data is private to the session and table declaration
 	// can happen in the middle of a transaction
 
 	/**
 	 * Does this dialect support temporary tables?
 	 *
 	 * @return True if temp tables are supported; false otherwise.
 	 */
 	public boolean supportsTemporaryTables() {
 		return true;
 	}
 
 	/**
 	 * With HSQLDB 2.0, the table name is qualified with MODULE to assist the drop
 	 * statement (in-case there is a global name beginning with HT_)
 	 *
 	 * @param baseTableName The table name from which to base the temp table name.
 	 *
 	 * @return The generated temp table name.
 	 */
 	public String generateTemporaryTableName(String baseTableName) {
 		if ( hsqldbVersion < 20 ) {
 			return "HT_" + baseTableName;
 		}
 		else {
 			return "MODULE.HT_" + baseTableName;
 		}
 	}
 
 	/**
 	 * Command used to create a temporary table.
 	 *
 	 * @return The command used to create a temporary table.
 	 */
 	public String getCreateTemporaryTableString() {
 		if ( hsqldbVersion < 20 ) {
 			return "create global temporary table";
 		}
 		else {
 			return "declare local temporary table";
 		}
 	}
 
 	/**
 	 * No fragment is needed if data is not needed beyond commit, otherwise
 	 * should add "on commit preserve rows"
 	 *
 	 * @return Any required postfix.
 	 */
 	public String getCreateTemporaryTablePostfix() {
 		return "";
 	}
 
 	/**
 	 * Command used to drop a temporary table.
 	 *
 	 * @return The command used to drop a temporary table.
 	 */
 	public String getDropTemporaryTableString() {
 		return "drop table";
 	}
 
 	/**
 	 * Different behavior for GLOBAL TEMPORARY (1.8) and LOCAL TEMPORARY (2.0)
 	 * <p/>
 	 * Possible return values and their meanings:<ul>
 	 * <li>{@link Boolean#TRUE} - Unequivocally, perform the temporary table DDL
 	 * in isolation.</li>
 	 * <li>{@link Boolean#FALSE} - Unequivocally, do <b>not</b> perform the
 	 * temporary table DDL in isolation.</li>
 	 * <li><i>null</i> - defer to the JDBC driver response in regards to
 	 * {@link java.sql.DatabaseMetaData#dataDefinitionCausesTransactionCommit()}</li>
 	 * </ul>
 	 *
 	 * @return see the result matrix above.
 	 */
 	public Boolean performTemporaryTableDDLInIsolation() {
 		if ( hsqldbVersion < 20 ) {
 			return Boolean.TRUE;
 		}
 		else {
 			return Boolean.FALSE;
 		}
 	}
 
 	/**
 	 * Do we need to drop the temporary table after use?
 	 *
 	 * todo - clarify usage by Hibernate
 	 * Version 1.8 GLOBAL TEMPORARY table definitions persist beyond the end
 	 * of the session (data is cleared). If there are not too many such tables,
 	 * perhaps we can avoid dropping them and reuse the table next time?
 	 *
 	 * @return True if the table should be dropped.
 	 */
 	public boolean dropTemporaryTableAfterUse() {
 		return true;
 	}
 
 	// current timestamp support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * HSQLDB 1.8.x requires CALL CURRENT_TIMESTAMP but this should not
 	 * be treated as a callable statement. It is equivalent to
 	 * "select current_timestamp from dual" in some databases.
 	 * HSQLDB 2.0 also supports VALUES CURRENT_TIMESTAMP
 	 *
 	 * @return True if the current timestamp can be retrieved; false otherwise.
 	 */
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	/**
 	 * Should the value returned by {@link #getCurrentTimestampSelectString}
 	 * be treated as callable.  Typically this indicates that JDBC escape
 	 * syntax is being used...
 	 *
 	 * @return True if the {@link #getCurrentTimestampSelectString} return
 	 *         is callable; false otherwise.
 	 */
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	/**
 	 * Retrieve the command used to retrieve the current timestamp from the
 	 * database.
 	 *
 	 * @return The command.
 	 */
 	public String getCurrentTimestampSelectString() {
 		return "call current_timestamp";
 	}
 
 	/**
 	 * The name of the database-specific SQL function for retrieving the
 	 * current timestamp.
 	 *
 	 * @return The function name.
 	 */
 	public String getCurrentTimestampSQLFunctionName() {
 		// the standard SQL function name is current_timestamp...
 		return "current_timestamp";
 	}
 
 	/**
 	 * For HSQLDB 2.0, this is a copy of the base class implementation.
 	 * For HSQLDB 1.8, only READ_UNCOMMITTED is supported.
 	 *
 	 * @param lockable The persister for the entity to be locked.
 	 * @param lockMode The type of lock to be acquired.
 	 *
 	 * @return The appropriate locking strategy.
 	 *
 	 * @since 3.2
 	 */
 	public LockingStrategy getLockingStrategy(Lockable lockable, LockMode lockMode) {
 		if ( lockMode == LockMode.PESSIMISTIC_FORCE_INCREMENT ) {
 			return new PessimisticForceIncrementLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_WRITE ) {
 			return new PessimisticWriteSelectLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_READ ) {
 			return new PessimisticReadSelectLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC ) {
 			return new OptimisticLockingStrategy( lockable, lockMode );
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC_FORCE_INCREMENT ) {
 			return new OptimisticForceIncrementLockingStrategy( lockable, lockMode );
 		}
 
 		if ( hsqldbVersion < 20 ) {
 			return new ReadUncommittedLockingStrategy( lockable, lockMode );
 		}
 		else {
 			return new SelectLockingStrategy( lockable, lockMode );
 		}
 	}
 
 	public static class ReadUncommittedLockingStrategy extends SelectLockingStrategy {
 		public ReadUncommittedLockingStrategy(Lockable lockable, LockMode lockMode) {
 			super( lockable, lockMode );
 		}
 
 		public void lock(Serializable id, Object version, Object object, int timeout, SessionImplementor session)
 				throws StaleObjectStateException, JDBCException {
             if (getLockMode().greaterThan(LockMode.READ)) LOG.hsqldbSupportsOnlyReadCommittedIsolation();
 			super.lock( id, version, object, timeout, session );
 		}
 	}
 
 	public boolean supportsCommentOn() {
 		return true;
 	}
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	/**
 	 * todo - needs usage clarification
 	 *
 	 * If the SELECT statement is always part of a UNION, then the type of
 	 * parameter is resolved by v. 2.0, but not v. 1.8 (assuming the other
 	 * SELECT in the UNION has a column reference in the same position and
 	 * can be type-resolved).
 	 *
 	 * On the other hand if the SELECT statement is isolated, all versions of
 	 * HSQLDB require casting for "select ? from .." to work.
 	 *
 	 * @return True if select clause parameter must be cast()ed
 	 *
 	 * @since 3.2
 	 */
 	public boolean requiresCastingOfParametersInSelectClause() {
 		return true;
 	}
 
 	/**
 	 * For the underlying database, is READ_COMMITTED isolation implemented by
 	 * forcing readers to wait for write locks to be released?
 	 *
 	 * @return True if writers block readers to achieve READ_COMMITTED; false otherwise.
 	 */
 	public boolean doesReadCommittedCauseWritersToBlockReaders() {
 		return hsqldbVersion >= 20;
 	}
 
 	/**
 	 * For the underlying database, is REPEATABLE_READ isolation implemented by
 	 * forcing writers to wait for read locks to be released?
 	 *
 	 * @return True if readers block writers to achieve REPEATABLE_READ; false otherwise.
 	 */
 	public boolean doesRepeatableReadCauseReadersToBlockWriters() {
 		return hsqldbVersion >= 20;
 	}
 
 
 	public boolean supportsLobValueChangePropogation() {
 		return false;
 	}
 
     public String toBooleanValueString(boolean bool) {
         return String.valueOf( bool );
     }
 
 	public boolean supportsTupleDistinctCounts() {
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9Dialect.java
index 666cbe3fdd..8c6f6bc04d 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle9Dialect.java
@@ -1,371 +1,371 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.CallableStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.NvlFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.exception.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.StandardBasicTypes;
 import org.jboss.logging.Logger;
 
 /**
  * An SQL dialect for Oracle 9 (uses ANSI-style syntax where possible).
  *
  * @deprecated Use either Oracle9iDialect or Oracle10gDialect instead
  * @author Gavin King, David Channon
  */
 @Deprecated
 public class Oracle9Dialect extends Dialect {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Oracle9Dialect.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Oracle9Dialect.class.getName());
 
 	public Oracle9Dialect() {
 		super();
         LOG.deprecatedOracle9Dialect();
 		registerColumnType( Types.BIT, "number(1,0)" );
 		registerColumnType( Types.BIGINT, "number(19,0)" );
 		registerColumnType( Types.SMALLINT, "number(5,0)" );
 		registerColumnType( Types.TINYINT, "number(3,0)" );
 		registerColumnType( Types.INTEGER, "number(10,0)" );
 		registerColumnType( Types.CHAR, "char(1 char)" );
 		registerColumnType( Types.VARCHAR, 4000, "varchar2($l char)" );
 		registerColumnType( Types.VARCHAR, "long" );
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.DOUBLE, "double precision" );
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "date" );
 		registerColumnType( Types.TIMESTAMP, "timestamp" );
 		registerColumnType( Types.VARBINARY, 2000, "raw($l)" );
 		registerColumnType( Types.VARBINARY, "long raw" );
 		registerColumnType( Types.NUMERIC, "number($p,$s)" );
 		registerColumnType( Types.DECIMAL, "number($p,$s)" );
 		registerColumnType( Types.BLOB, "blob" );
 		registerColumnType( Types.CLOB, "clob" );
 
 		// Oracle driver reports to support getGeneratedKeys(), but they only
 		// support the version taking an array of the names of the columns to
 		// be returned (via its RETURNING clause).  No other driver seems to
 		// support this overloaded version.
 		getDefaultProperties().setProperty(Environment.USE_GET_GENERATED_KEYS, "false");
 		getDefaultProperties().setProperty(Environment.USE_STREAMS_FOR_BINARY, "true");
 		getDefaultProperties().setProperty(Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE);
 
 		registerFunction( "abs", new StandardSQLFunction("abs") );
 		registerFunction( "sign", new StandardSQLFunction("sign", StandardBasicTypes.INTEGER) );
 
 		registerFunction( "acos", new StandardSQLFunction("acos", StandardBasicTypes.DOUBLE) );
 		registerFunction( "asin", new StandardSQLFunction("asin", StandardBasicTypes.DOUBLE) );
 		registerFunction( "atan", new StandardSQLFunction("atan", StandardBasicTypes.DOUBLE) );
 		registerFunction( "cos", new StandardSQLFunction("cos", StandardBasicTypes.DOUBLE) );
 		registerFunction( "cosh", new StandardSQLFunction("cosh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "exp", new StandardSQLFunction("exp", StandardBasicTypes.DOUBLE) );
 		registerFunction( "ln", new StandardSQLFunction("ln", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sin", new StandardSQLFunction("sin", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sinh", new StandardSQLFunction("sinh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "stddev", new StandardSQLFunction("stddev", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sqrt", new StandardSQLFunction("sqrt", StandardBasicTypes.DOUBLE) );
 		registerFunction( "tan", new StandardSQLFunction("tan", StandardBasicTypes.DOUBLE) );
 		registerFunction( "tanh", new StandardSQLFunction("tanh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "variance", new StandardSQLFunction("variance", StandardBasicTypes.DOUBLE) );
 
 		registerFunction( "round", new StandardSQLFunction("round") );
 		registerFunction( "trunc", new StandardSQLFunction("trunc") );
 		registerFunction( "ceil", new StandardSQLFunction("ceil") );
 		registerFunction( "floor", new StandardSQLFunction("floor") );
 
 		registerFunction( "chr", new StandardSQLFunction("chr", StandardBasicTypes.CHARACTER) );
 		registerFunction( "initcap", new StandardSQLFunction("initcap") );
 		registerFunction( "lower", new StandardSQLFunction("lower") );
 		registerFunction( "ltrim", new StandardSQLFunction("ltrim") );
 		registerFunction( "rtrim", new StandardSQLFunction("rtrim") );
 		registerFunction( "soundex", new StandardSQLFunction("soundex") );
 		registerFunction( "upper", new StandardSQLFunction("upper") );
 		registerFunction( "ascii", new StandardSQLFunction("ascii", StandardBasicTypes.INTEGER) );
 
 		registerFunction( "to_char", new StandardSQLFunction("to_char", StandardBasicTypes.STRING) );
 		registerFunction( "to_date", new StandardSQLFunction("to_date", StandardBasicTypes.TIMESTAMP) );
 
 		registerFunction( "current_date", new NoArgSQLFunction("current_date", StandardBasicTypes.DATE, false) );
 		registerFunction( "current_time", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIME, false) );
 		registerFunction( "current_timestamp", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIMESTAMP, false) );
 
 		registerFunction( "last_day", new StandardSQLFunction("last_day", StandardBasicTypes.DATE) );
 		registerFunction( "sysdate", new NoArgSQLFunction("sysdate", StandardBasicTypes.DATE, false) );
 		registerFunction( "systimestamp", new NoArgSQLFunction("systimestamp", StandardBasicTypes.TIMESTAMP, false) );
 		registerFunction( "uid", new NoArgSQLFunction("uid", StandardBasicTypes.INTEGER, false) );
 		registerFunction( "user", new NoArgSQLFunction("user", StandardBasicTypes.STRING, false) );
 
 		registerFunction( "rowid", new NoArgSQLFunction("rowid", StandardBasicTypes.LONG, false) );
 		registerFunction( "rownum", new NoArgSQLFunction("rownum", StandardBasicTypes.LONG, false) );
 
 		// Multi-param string dialect functions...
 		registerFunction( "concat", new VarArgsSQLFunction(StandardBasicTypes.STRING, "", "||", "") );
 		registerFunction( "instr", new StandardSQLFunction("instr", StandardBasicTypes.INTEGER) );
 		registerFunction( "instrb", new StandardSQLFunction("instrb", StandardBasicTypes.INTEGER) );
 		registerFunction( "lpad", new StandardSQLFunction("lpad", StandardBasicTypes.STRING) );
 		registerFunction( "replace", new StandardSQLFunction("replace", StandardBasicTypes.STRING) );
 		registerFunction( "rpad", new StandardSQLFunction("rpad", StandardBasicTypes.STRING) );
 		registerFunction( "substr", new StandardSQLFunction("substr", StandardBasicTypes.STRING) );
 		registerFunction( "substrb", new StandardSQLFunction("substrb", StandardBasicTypes.STRING) );
 		registerFunction( "translate", new StandardSQLFunction("translate", StandardBasicTypes.STRING) );
 
 		registerFunction( "substring", new StandardSQLFunction( "substr", StandardBasicTypes.STRING ) );
 		registerFunction( "locate", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "instr(?2,?1)" ) );
 		registerFunction( "bit_length", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "vsize(?1)*8" ) );
 		registerFunction( "coalesce", new NvlFunction() );
 
 		// Multi-param numeric dialect functions...
 		registerFunction( "atan2", new StandardSQLFunction("atan2", StandardBasicTypes.FLOAT) );
 		registerFunction( "log", new StandardSQLFunction("log", StandardBasicTypes.INTEGER) );
 		registerFunction( "mod", new StandardSQLFunction("mod", StandardBasicTypes.INTEGER) );
 		registerFunction( "nvl", new StandardSQLFunction("nvl") );
 		registerFunction( "nvl2", new StandardSQLFunction("nvl2") );
 		registerFunction( "power", new StandardSQLFunction("power", StandardBasicTypes.FLOAT) );
 
 		// Multi-param date dialect functions...
 		registerFunction( "add_months", new StandardSQLFunction("add_months", StandardBasicTypes.DATE) );
 		registerFunction( "months_between", new StandardSQLFunction("months_between", StandardBasicTypes.FLOAT) );
 		registerFunction( "next_day", new StandardSQLFunction("next_day", StandardBasicTypes.DATE) );
 
 		registerFunction( "str", new StandardSQLFunction("to_char", StandardBasicTypes.STRING) );
 	}
 
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from dual";
 	}
 
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	public String getCreateSequenceString(String sequenceName) {
 		return "create sequence " + sequenceName; //starts with 1, implicitly
 	}
 
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	public String getCascadeConstraintsString() {
 		return " cascade constraints";
 	}
 
 	public boolean dropConstraints() {
 		return false;
 	}
 
 	public String getForUpdateNowaitString() {
 		return " for update nowait";
 	}
 
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	public String getLimitString(String sql, boolean hasOffset) {
 
 		sql = sql.trim();
 		boolean isForUpdate = false;
 		if ( sql.toLowerCase().endsWith(" for update") ) {
 			sql = sql.substring( 0, sql.length()-11 );
 			isForUpdate = true;
 		}
 
 		StringBuffer pagingSelect = new StringBuffer( sql.length()+100 );
 		if (hasOffset) {
 			pagingSelect.append("select * from ( select row_.*, rownum rownum_ from ( ");
 		}
 		else {
 			pagingSelect.append("select * from ( ");
 		}
 		pagingSelect.append(sql);
 		if (hasOffset) {
 			pagingSelect.append(" ) row_ where rownum <= ?) where rownum_ > ?");
 		}
 		else {
 			pagingSelect.append(" ) where rownum <= ?");
 		}
 
 		if ( isForUpdate ) {
 			pagingSelect.append( " for update" );
 		}
 
 		return pagingSelect.toString();
 	}
 
 	public String getForUpdateString(String aliases) {
 		return getForUpdateString() + " of " + aliases;
 	}
 
 	public String getForUpdateNowaitString(String aliases) {
 		return getForUpdateString() + " of " + aliases + " nowait";
 	}
 
 	public boolean bindLimitParametersInReverseOrder() {
 		return true;
 	}
 
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	public boolean forUpdateOfColumns() {
 		return true;
 	}
 
 	public String getQuerySequencesString() {
 		return "select sequence_name from user_sequences";
 	}
 
 	public String getSelectGUIDString() {
 		return "select rawtohex(sys_guid()) from dual";
 	}
 
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
         return EXTRACTER;
 	}
 
 	private static ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 
 		/**
 		 * Extract the name of the violated constraint from the given SQLException.
 		 *
 		 * @param sqle The exception that was the result of the constraint violation.
 		 * @return The extracted constraint name.
 		 */
 		public String extractConstraintName(SQLException sqle) {
 			int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 			if ( errorCode == 1 || errorCode == 2291 || errorCode == 2292 ) {
 				return extractUsingTemplate( "constraint (", ") violated", sqle.getMessage() );
 			}
 			else if ( errorCode == 1400 ) {
 				// simple nullability constraint
 				return null;
 			}
 			else {
 				return null;
 			}
 		}
 
 	};
 
 	// not final-static to avoid possible classcast exceptions if using different oracle drivers.
 	int oracletypes_cursor_value = 0;
 	public int registerResultSetOutParameter(java.sql.CallableStatement statement,int col) throws SQLException {
 		if(oracletypes_cursor_value==0) {
 			try {
 				Class types = ReflectHelper.classForName("oracle.jdbc.driver.OracleTypes");
 				oracletypes_cursor_value = types.getField("CURSOR").getInt(types.newInstance());
 			} catch (Exception se) {
 				throw new HibernateException("Problem while trying to load or access OracleTypes.CURSOR value",se);
 			}
 		}
 		//	register the type of the out param - an Oracle specific type
 		statement.registerOutParameter(col, oracletypes_cursor_value);
 		col++;
 		return col;
 	}
 
 	public ResultSet getResultSet(CallableStatement ps) throws SQLException {
 		ps.execute();
 		return ( ResultSet ) ps.getObject( 1 );
 	}
 
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 	public boolean supportsCommentOn() {
 		return true;
 	}
 
 	public boolean supportsTemporaryTables() {
 		return true;
 	}
 
 	public String generateTemporaryTableName(String baseTableName) {
 		String name = super.generateTemporaryTableName(baseTableName);
 		return name.length() > 30 ? name.substring( 1, 30 ) : name;
 	}
 
 	public String getCreateTemporaryTableString() {
 		return "create global temporary table";
 	}
 
 	public String getCreateTemporaryTablePostfix() {
 		return "on commit delete rows";
 	}
 
 	public boolean dropTemporaryTableAfterUse() {
 		return false;
 	}
 
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	public String getCurrentTimestampSelectString() {
 		return "select systimestamp from dual";
 	}
 
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 
 	// Overridden informational metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 
 	public boolean supportsExistsInSelect() {
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/OracleDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/OracleDialect.java
index 12dc76023d..199940e880 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/OracleDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/OracleDialect.java
@@ -1,119 +1,120 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 import java.sql.Types;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.DecodeCaseFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.OracleJoinFragment;
 import org.jboss.logging.Logger;
 
 /**
  * An SQL dialect for Oracle, compatible with Oracle 8.
  *
  * @deprecated Use Oracle8iDialect instead.
  * @author Gavin King
  */
 @Deprecated
 public class OracleDialect extends Oracle9Dialect {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, OracleDialect.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, OracleDialect.class.getName());
 
 	public OracleDialect() {
 		super();
         LOG.deprecatedOracleDialect();
 		// Oracle8 and previous define only a "DATE" type which
 		//      is used to represent all aspects of date/time
 		registerColumnType( Types.TIMESTAMP, "date" );
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.VARCHAR, 4000, "varchar2($l)" );
 	}
 
 	@Override
     public JoinFragment createOuterJoinFragment() {
 		return new OracleJoinFragment();
 	}
 	@Override
     public CaseFragment createCaseFragment() {
 		return new DecodeCaseFragment();
 	}
 
 	@Override
     public String getLimitString(String sql, boolean hasOffset) {
 
 		sql = sql.trim();
 		boolean isForUpdate = false;
 		if ( sql.toLowerCase().endsWith(" for update") ) {
 			sql = sql.substring( 0, sql.length()-11 );
 			isForUpdate = true;
 		}
 
 		StringBuffer pagingSelect = new StringBuffer( sql.length()+100 );
 		if (hasOffset) {
 			pagingSelect.append("select * from ( select row_.*, rownum rownum_ from ( ");
 		}
 		else {
 			pagingSelect.append("select * from ( ");
 		}
 		pagingSelect.append(sql);
 		if (hasOffset) {
 			pagingSelect.append(" ) row_ ) where rownum_ <= ? and rownum_ > ?");
 		}
 		else {
 			pagingSelect.append(" ) where rownum <= ?");
 		}
 
 		if ( isForUpdate ) {
 			pagingSelect.append( " for update" );
 		}
 
 		return pagingSelect.toString();
 	}
 
 	@Override
     public String getSelectClauseNullString(int sqlType) {
 		switch(sqlType) {
 			case Types.VARCHAR:
 			case Types.CHAR:
 				return "to_char(null)";
 			case Types.DATE:
 			case Types.TIMESTAMP:
 			case Types.TIME:
 				return "to_date(null)";
 			default:
 				return "to_number(null)";
 		}
 	}
 
 	@Override
     public String getCurrentTimestampSelectString() {
 		return "select sysdate from dual";
 	}
 
 	@Override
     public String getCurrentTimestampSQLFunctionName() {
 		return "sysdate";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/RDMSOS2200Dialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/RDMSOS2200Dialect.java
index f3c5df4ac1..7f8ceaab3a 100755
--- a/hibernate-core/src/main/java/org/hibernate/dialect/RDMSOS2200Dialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/RDMSOS2200Dialect.java
@@ -1,363 +1,364 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 import java.sql.Types;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.dialect.lock.OptimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.OptimisticLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticForceIncrementLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticReadUpdateLockingStrategy;
 import org.hibernate.dialect.lock.PessimisticWriteUpdateLockingStrategy;
 import org.hibernate.dialect.lock.SelectLockingStrategy;
 import org.hibernate.dialect.lock.UpdateLockingStrategy;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.DecodeCaseFragment;
 import org.hibernate.type.StandardBasicTypes;
 import org.jboss.logging.Logger;
 
 /**
  * This is the Hibernate dialect for the Unisys 2200 Relational Database (RDMS).
  * This dialect was developed for use with Hibernate 3.0.5. Other versions may
  * require modifications to the dialect.
  *
  * Version History:
  * Also change the version displayed below in the constructor
  * 1.1
  * 1.0  2005-10-24  CDH - First dated version for use with CP 11
  *
  * @author Ploski and Hanson
  */
 public class RDMSOS2200Dialect extends Dialect {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, RDMSOS2200Dialect.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, RDMSOS2200Dialect.class.getName());
 
 	public RDMSOS2200Dialect() {
 		super();
         // Display the dialect version.
         LOG.rdmsOs2200Dialect();
 
         /**
          * This section registers RDMS Biult-in Functions (BIFs) with Hibernate.
          * The first parameter is the 'register' function name with Hibernate.
          * The second parameter is the defined RDMS SQL Function and it's
          * characteristics. If StandardSQLFunction(...) is used, the RDMS BIF
          * name and the return type (if any) is specified.  If
          * SQLFunctionTemplate(...) is used, the return type and a template
          * string is provided, plus an optional hasParenthesesIfNoArgs flag.
          */
 		registerFunction( "abs", new StandardSQLFunction("abs") );
 		registerFunction( "sign", new StandardSQLFunction("sign", StandardBasicTypes.INTEGER) );
 
 		registerFunction("ascii", new StandardSQLFunction("ascii", StandardBasicTypes.INTEGER) );
 		registerFunction("char_length", new StandardSQLFunction("char_length", StandardBasicTypes.INTEGER) );
 		registerFunction("character_length", new StandardSQLFunction("character_length", StandardBasicTypes.INTEGER) );
 
 		// The RDMS concat() function only supports 2 parameters
 		registerFunction( "concat", new SQLFunctionTemplate(StandardBasicTypes.STRING, "concat(?1, ?2)") );
 		registerFunction( "instr", new StandardSQLFunction("instr", StandardBasicTypes.STRING) );
 		registerFunction( "lpad", new StandardSQLFunction("lpad", StandardBasicTypes.STRING) );
 		registerFunction( "replace", new StandardSQLFunction("replace", StandardBasicTypes.STRING) );
 		registerFunction( "rpad", new StandardSQLFunction("rpad", StandardBasicTypes.STRING) );
 		registerFunction( "substr", new StandardSQLFunction("substr", StandardBasicTypes.STRING) );
 
 		registerFunction("lcase", new StandardSQLFunction("lcase") );
 		registerFunction("lower", new StandardSQLFunction("lower") );
 		registerFunction("ltrim", new StandardSQLFunction("ltrim") );
 		registerFunction("reverse", new StandardSQLFunction("reverse") );
 		registerFunction("rtrim", new StandardSQLFunction("rtrim") );
 
 		// RDMS does not directly support the trim() function, we use rtrim() and ltrim()
 		registerFunction("trim", new SQLFunctionTemplate(StandardBasicTypes.INTEGER, "ltrim(rtrim(?1))" ) );
 		registerFunction("soundex", new StandardSQLFunction("soundex") );
 		registerFunction("space", new StandardSQLFunction("space", StandardBasicTypes.STRING) );
 		registerFunction("ucase", new StandardSQLFunction("ucase") );
 		registerFunction("upper", new StandardSQLFunction("upper") );
 
 		registerFunction("acos", new StandardSQLFunction("acos", StandardBasicTypes.DOUBLE) );
 		registerFunction("asin", new StandardSQLFunction("asin", StandardBasicTypes.DOUBLE) );
 		registerFunction("atan", new StandardSQLFunction("atan", StandardBasicTypes.DOUBLE) );
 		registerFunction("cos", new StandardSQLFunction("cos", StandardBasicTypes.DOUBLE) );
 		registerFunction("cosh", new StandardSQLFunction("cosh", StandardBasicTypes.DOUBLE) );
 		registerFunction("cot", new StandardSQLFunction("cot", StandardBasicTypes.DOUBLE) );
 		registerFunction("exp", new StandardSQLFunction("exp", StandardBasicTypes.DOUBLE) );
 		registerFunction("ln", new StandardSQLFunction("ln", StandardBasicTypes.DOUBLE) );
 		registerFunction("log", new StandardSQLFunction("log", StandardBasicTypes.DOUBLE) );
 		registerFunction("log10", new StandardSQLFunction("log10", StandardBasicTypes.DOUBLE) );
 		registerFunction("pi", new NoArgSQLFunction("pi", StandardBasicTypes.DOUBLE) );
 		registerFunction("rand", new NoArgSQLFunction("rand", StandardBasicTypes.DOUBLE) );
 		registerFunction("sin", new StandardSQLFunction("sin", StandardBasicTypes.DOUBLE) );
 		registerFunction("sinh", new StandardSQLFunction("sinh", StandardBasicTypes.DOUBLE) );
 		registerFunction("sqrt", new StandardSQLFunction("sqrt", StandardBasicTypes.DOUBLE) );
 		registerFunction("tan", new StandardSQLFunction("tan", StandardBasicTypes.DOUBLE) );
 		registerFunction("tanh", new StandardSQLFunction("tanh", StandardBasicTypes.DOUBLE) );
 
 		registerFunction( "round", new StandardSQLFunction("round") );
 		registerFunction( "trunc", new StandardSQLFunction("trunc") );
 		registerFunction( "ceil", new StandardSQLFunction("ceil") );
 		registerFunction( "floor", new StandardSQLFunction("floor") );
 
 		registerFunction( "chr", new StandardSQLFunction("chr", StandardBasicTypes.CHARACTER) );
 		registerFunction( "initcap", new StandardSQLFunction("initcap") );
 
 		registerFunction( "user", new NoArgSQLFunction("user", StandardBasicTypes.STRING, false) );
 
 		registerFunction( "current_date", new NoArgSQLFunction("current_date", StandardBasicTypes.DATE, false) );
 		registerFunction( "current_time", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIME, false) );
 		registerFunction( "current_timestamp", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIMESTAMP, false) );
 		registerFunction("curdate", new NoArgSQLFunction("curdate",StandardBasicTypes.DATE) );
 		registerFunction("curtime", new NoArgSQLFunction("curtime",StandardBasicTypes.TIME) );
 		registerFunction("days", new StandardSQLFunction("days",StandardBasicTypes.INTEGER) );
 		registerFunction("dayofmonth", new StandardSQLFunction("dayofmonth",StandardBasicTypes.INTEGER) );
 		registerFunction("dayname", new StandardSQLFunction("dayname",StandardBasicTypes.STRING) );
 		registerFunction("dayofweek", new StandardSQLFunction("dayofweek",StandardBasicTypes.INTEGER) );
 		registerFunction("dayofyear", new StandardSQLFunction("dayofyear",StandardBasicTypes.INTEGER) );
 		registerFunction("hour", new StandardSQLFunction("hour",StandardBasicTypes.INTEGER) );
 		registerFunction("last_day", new StandardSQLFunction("last_day",StandardBasicTypes.DATE) );
 		registerFunction("microsecond", new StandardSQLFunction("microsecond",StandardBasicTypes.INTEGER) );
 		registerFunction("minute", new StandardSQLFunction("minute",StandardBasicTypes.INTEGER) );
 		registerFunction("month", new StandardSQLFunction("month",StandardBasicTypes.INTEGER) );
 		registerFunction("monthname", new StandardSQLFunction("monthname",StandardBasicTypes.STRING) );
 		registerFunction("now", new NoArgSQLFunction("now",StandardBasicTypes.TIMESTAMP) );
 		registerFunction("quarter", new StandardSQLFunction("quarter",StandardBasicTypes.INTEGER) );
 		registerFunction("second", new StandardSQLFunction("second",StandardBasicTypes.INTEGER) );
 		registerFunction("time", new StandardSQLFunction("time",StandardBasicTypes.TIME) );
 		registerFunction("timestamp", new StandardSQLFunction("timestamp",StandardBasicTypes.TIMESTAMP) );
 		registerFunction("week", new StandardSQLFunction("week",StandardBasicTypes.INTEGER) );
 		registerFunction("year", new StandardSQLFunction("year",StandardBasicTypes.INTEGER) );
 
 		registerFunction("atan2", new StandardSQLFunction("atan2",StandardBasicTypes.DOUBLE) );
 		registerFunction( "mod", new StandardSQLFunction("mod",StandardBasicTypes.INTEGER) );
 		registerFunction( "nvl", new StandardSQLFunction("nvl") );
 		registerFunction( "power", new StandardSQLFunction("power", StandardBasicTypes.DOUBLE) );
 
 		/**
 		 * For a list of column types to register, see section A-1
 		 * in 7862 7395, the Unisys JDBC manual.
 		 *
 		 * Here are column sizes as documented in Table A-1 of
 		 * 7831 0760, "Enterprise Relational Database Server
 		 * for ClearPath OS2200 Administration Guide"
 		 * Numeric - 21
 		 * Decimal - 22 (21 digits plus one for sign)
 		 * Float   - 60 bits
 		 * Char    - 28000
 		 * NChar   - 14000
 		 * BLOB+   - 4294967296 (4 Gb)
 		 * + RDMS JDBC driver does not support BLOBs
 		 *
 		 * DATE, TIME and TIMESTAMP literal formats are
 		 * are all described in section 2.3.4 DATE Literal Format
 		 * in 7830 8160.
 		 * The DATE literal format is: YYYY-MM-DD
 		 * The TIME literal format is: HH:MM:SS[.[FFFFFF]]
 		 * The TIMESTAMP literal format is: YYYY-MM-DD HH:MM:SS[.[FFFFFF]]
 		 *
 		 * Note that $l (dollar-L) will use the length value if provided.
 		 * Also new for Hibernate3 is the $p percision and $s (scale) parameters
 		 */
 		registerColumnType(Types.BIT, "SMALLINT");
 		registerColumnType(Types.TINYINT, "SMALLINT");
 		registerColumnType(Types.BIGINT, "NUMERIC(21,0)");
 		registerColumnType(Types.SMALLINT, "SMALLINT");
 		registerColumnType(Types.CHAR, "CHARACTER(1)");
 		registerColumnType(Types.DOUBLE, "DOUBLE PRECISION");
 		registerColumnType(Types.FLOAT, "FLOAT");
 		registerColumnType(Types.REAL, "REAL");
 		registerColumnType(Types.INTEGER, "INTEGER");
 		registerColumnType(Types.NUMERIC, "NUMERIC(21,$l)");
 		registerColumnType(Types.DECIMAL, "NUMERIC(21,$l)");
 		registerColumnType(Types.DATE, "DATE");
 		registerColumnType(Types.TIME, "TIME");
 		registerColumnType(Types.TIMESTAMP, "TIMESTAMP");
 		registerColumnType(Types.VARCHAR, "CHARACTER($l)");
         registerColumnType(Types.BLOB, "BLOB($l)" );
         /*
          * The following types are not supported in RDMS/JDBC and therefore commented out.
          * However, in some cases, mapping them to CHARACTER columns works
          * for many applications, but does not work for all cases.
          */
         // registerColumnType(Types.VARBINARY, "CHARACTER($l)");
         // registerColumnType(Types.BLOB, "CHARACTER($l)" );  // For use prior to CP 11.0
         // registerColumnType(Types.CLOB, "CHARACTER($l)" );
 	}
 
 
 	// Dialect method overrides ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
     /**
      * RDMS does not support qualifing index names with the schema name.
      */
 	public boolean qualifyIndexName() {
 		return false;
 	}
 
 	/**
 	 * The RDMS DB supports the 'FOR UPDATE OF' clause. However, the RDMS-JDBC
      * driver does not support this feature, so a false is return.
      * The base dialect also returns a false, but we will leave this over-ride
      * in to make sure it stays false.
 	 */
 	public boolean forUpdateOfColumns() {
 		return false;
 	}
 
 	/**
 	 * Since the RDMS-JDBC driver does not support for updates, this string is
      * set to an empty string. Whenever, the driver does support this feature,
      * the returned string should be " FOR UPDATE OF". Note that RDMS does not
      * support the string 'FOR UPDATE' string.
 	 */
 	public String getForUpdateString() {
 		return ""; // Original Dialect.java returns " for update";
 	}
 
     /**
      * RDMS does not support adding Unique constraints via create and alter table.
      */
 	public boolean supportsUniqueConstraintInCreateAlterTable() {
 	    return true;
 	}
 
 	// Verify the state of this new method in Hibernate 3.0 Dialect.java
     /**
      * RDMS does not support Cascade Deletes.
      * Need to review this in the future when support is provided.
      */
 	public boolean supportsCascadeDelete() {
 		return false; // Origial Dialect.java returns true;
 	}
 
 	/**
      * Currently, RDMS-JDBC does not support ForUpdate.
      * Need to review this in the future when support is provided.
 	 */
     public boolean supportsOuterJoinForUpdate() {
 		return false;
 	}
 
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	public String getNullColumnString() {
 		// The keyword used to specify a nullable column.
 		return " null";
 	}
 
     // *** Sequence methods - start. The RDMS dialect needs these
 
     // methods to make it possible to use the Native Id generator
 
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	public String getSequenceNextValString(String sequenceName) {
 	    // The where clause was added to eliminate this statement from Brute Force Searches.
         return  "select permuted_id('NEXT',31) from rdms.rdms_dummy where key_col = 1 ";
 	}
 
 	public String getCreateSequenceString(String sequenceName) {
         // We must return a valid RDMS/RSA command from this method to
         // prevent RDMS/RSA from issuing *ERROR 400
         return "";
 	}
 
 	public String getDropSequenceString(String sequenceName) {
         // We must return a valid RDMS/RSA command from this method to
         // prevent RDMS/RSA from issuing *ERROR 400
         return "";
 	}
 
 	// *** Sequence methods - end
 
     public String getCascadeConstraintsString() {
         // Used with DROP TABLE to delete all records in the table.
         return " including contents";
     }
 
 	public CaseFragment createCaseFragment() {
 		return new DecodeCaseFragment();
 	}
 
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	public boolean supportsLimitOffset() {
 		return false;
 	}
 
     public String getLimitString(String sql, int offset, int limit) {
 		if ( offset > 0 ) {
 			throw new UnsupportedOperationException( "query result offset is not supported" );
 		}
 		return new StringBuffer( sql.length() + 40 )
 				.append( sql )
 				.append( " fetch first " )
 				.append( limit )
 				.append( " rows only " )
 				.toString();
 	}
 
 	public boolean supportsVariableLimit() {
 		return false;
 	}
 
 	public boolean supportsUnionAll() {
 		// RDMS supports the UNION ALL clause.
           return true;
 	}
 
 	public LockingStrategy getLockingStrategy(Lockable lockable, LockMode lockMode) {
 		// RDMS has no known variation of a "SELECT ... FOR UPDATE" syntax...
 		if ( lockMode==LockMode.PESSIMISTIC_FORCE_INCREMENT) {
 			return new PessimisticForceIncrementLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode==LockMode.PESSIMISTIC_WRITE) {
 			return new PessimisticWriteUpdateLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode==LockMode.PESSIMISTIC_READ) {
 			return new PessimisticReadUpdateLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode==LockMode.OPTIMISTIC) {
 			return new OptimisticLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode==LockMode.OPTIMISTIC_FORCE_INCREMENT) {
 			return new OptimisticForceIncrementLockingStrategy( lockable, lockMode);
 		}
 		else if ( lockMode.greaterThan( LockMode.READ ) ) {
 			return new UpdateLockingStrategy( lockable, lockMode );
 		}
 		else {
 			return new SelectLockingStrategy( lockable, lockMode );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/function/TemplateRenderer.java b/hibernate-core/src/main/java/org/hibernate/dialect/function/TemplateRenderer.java
index b9a57fdb31..6168070c69 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/function/TemplateRenderer.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/function/TemplateRenderer.java
@@ -1,117 +1,119 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.function;
 import java.util.ArrayList;
 import java.util.List;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionFactoryImplementor;
+
 import org.jboss.logging.Logger;
 
 /**
  * Delegate for handling function "templates".
  *
  * @author Steve Ebersole
  */
 public class TemplateRenderer {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TemplateRenderer.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TemplateRenderer.class.getName());
 
 	private final String template;
 	private final String[] chunks;
 	private final int[] paramIndexes;
 
 	@SuppressWarnings({ "UnnecessaryUnboxing" })
 	public TemplateRenderer(String template) {
 		this.template = template;
 
 		List<String> chunkList = new ArrayList<String>();
 		List<Integer> paramList = new ArrayList<Integer>();
 		StringBuffer chunk = new StringBuffer( 10 );
 		StringBuffer index = new StringBuffer( 2 );
 
 		for ( int i = 0; i < template.length(); ++i ) {
 			char c = template.charAt( i );
 			if ( c == '?' ) {
 				chunkList.add( chunk.toString() );
 				chunk.delete( 0, chunk.length() );
 
 				while ( ++i < template.length() ) {
 					c = template.charAt( i );
 					if ( Character.isDigit( c ) ) {
 						index.append( c );
 					}
 					else {
 						chunk.append( c );
 						break;
 					}
 				}
 
 				paramList.add( Integer.valueOf( index.toString() ) );
 				index.delete( 0, index.length() );
 			}
 			else {
 				chunk.append( c );
 			}
 		}
 
 		if ( chunk.length() > 0 ) {
 			chunkList.add( chunk.toString() );
 		}
 
 		chunks = chunkList.toArray( new String[chunkList.size()] );
 		paramIndexes = new int[paramList.size()];
 		for ( int i = 0; i < paramIndexes.length; ++i ) {
 			paramIndexes[i] = paramList.get( i ).intValue();
 		}
 	}
 
 	public String getTemplate() {
 		return template;
 	}
 
 	public int getAnticipatedNumberOfArguments() {
 		return paramIndexes.length;
 	}
 
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public String render(List args, SessionFactoryImplementor factory) {
 		int numberOfArguments = args.size();
         if (getAnticipatedNumberOfArguments() > 0 && numberOfArguments != getAnticipatedNumberOfArguments()) LOG.missingArguments(getAnticipatedNumberOfArguments(),
                                                                                                                                   numberOfArguments);
 		StringBuffer buf = new StringBuffer();
 		for ( int i = 0; i < chunks.length; ++i ) {
 			if ( i < paramIndexes.length ) {
 				final int index = paramIndexes[i] - 1;
 				final Object arg =  index < numberOfArguments ? args.get( index ) : null;
 				if ( arg != null ) {
 					buf.append( chunks[i] ).append( arg );
 				}
 			}
 			else {
 				buf.append( chunks[i] );
 			}
 		}
 		return buf.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadUpdateLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadUpdateLockingStrategy.java
index 8de9693faa..8f0d1cafbe 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadUpdateLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadUpdateLockingStrategy.java
@@ -1,147 +1,147 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.PessimisticLockException;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 import org.jboss.logging.Logger;
 
 /**
  * A pessimistic locking strategy where the locks are obtained through update statements.
  * <p/>
  * This strategy is valid for LockMode.PESSIMISTIC_READ
  *
  * This class is a clone of UpdateLockingStrategy.
  *
  * @since 3.5
  *
  * @author Steve Ebersole
  * @author Scott Marlow
  */
 public class PessimisticReadUpdateLockingStrategy implements LockingStrategy {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        PessimisticReadUpdateLockingStrategy.class.getName());
 
 	private final Lockable lockable;
 	private final LockMode lockMode;
 	private final String sql;
 
 	/**
 	 * Construct a locking strategy based on SQL UPDATE statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indictates the type of lock to be acquired.  Note that
 	 * read-locks are not valid for this strategy.
 	 */
 	public PessimisticReadUpdateLockingStrategy(Lockable lockable, LockMode lockMode) {
 		this.lockable = lockable;
 		this.lockMode = lockMode;
 		if ( lockMode.lessThan( LockMode.PESSIMISTIC_READ ) ) {
 			throw new HibernateException( "[" + lockMode + "] not valid for update statement" );
 		}
 		if ( !lockable.isVersioned() ) {
             LOG.writeLocksNotSupported(lockable.getEntityName());
 			this.sql = null;
 		}
 		else {
 			this.sql = generateLockString();
 		}
 	}
 
    /**
 	 * @see org.hibernate.dialect.lock.LockingStrategy#lock
 	 */
 	public void lock(
       Serializable id,
       Object version,
       Object object,
       int timeout, SessionImplementor session) throws StaleObjectStateException, JDBCException {
 		if ( !lockable.isVersioned() ) {
 			throw new HibernateException( "write locks via update not supported for non-versioned entities [" + lockable.getEntityName() + "]" );
 		}
 		SessionFactoryImplementor factory = session.getFactory();
 		try {
 			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				lockable.getVersionType().nullSafeSet( st, version, 1, session );
 				int offset = 2;
 
 				lockable.getIdentifierType().nullSafeSet( st, id, offset, session );
 				offset += lockable.getIdentifierType().getColumnSpan( factory );
 
 				if ( lockable.isVersioned() ) {
 					lockable.getVersionType().nullSafeSet( st, version, offset, session );
 				}
 
 				int affected = st.executeUpdate();
 				if ( affected < 0 ) {  // todo:  should this instead check for exactly one row modified?
 					factory.getStatisticsImplementor().optimisticFailure( lockable.getEntityName() );
 					throw new StaleObjectStateException( lockable.getEntityName(), id );
 				}
 
 			}
 			finally {
 				st.close();
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			JDBCException e = session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not lock: " + MessageHelper.infoString( lockable, id, session.getFactory() ),
 					sql
 				);
 			throw new PessimisticLockException("could not obtain pessimistic lock", e, object);
 		}
 	}
 
 	protected String generateLockString() {
 		SessionFactoryImplementor factory = lockable.getFactory();
 		Update update = new Update( factory.getDialect() );
 		update.setTableName( lockable.getRootTableName() );
 		update.addPrimaryKeyColumns( lockable.getRootTableIdentifierColumnNames() );
 		update.setVersionColumnName( lockable.getVersionColumnName() );
 		update.addColumn( lockable.getVersionColumnName() );
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			update.setComment( lockMode + " lock " + lockable.getEntityName() );
 		}
 		return update.toStatementString();
 	}
 
 	protected LockMode getLockMode() {
 		return lockMode;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteUpdateLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteUpdateLockingStrategy.java
index c880c2f6e9..e97b03fc5b 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteUpdateLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteUpdateLockingStrategy.java
@@ -1,147 +1,147 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.PessimisticLockException;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 import org.jboss.logging.Logger;
 
 /**
  * A pessimistic locking strategy where the locks are obtained through update statements.
  * <p/>
  * This strategy is valid for LockMode.PESSIMISTIC_WRITE
  *
  * This class is a clone of UpdateLockingStrategy.
  *
  * @since 3.5
  *
  * @author Steve Ebersole
  * @author Scott Marlow
  */
 public class PessimisticWriteUpdateLockingStrategy implements LockingStrategy {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        PessimisticWriteUpdateLockingStrategy.class.getName());
 
 	private final Lockable lockable;
 	private final LockMode lockMode;
 	private final String sql;
 
 	/**
 	 * Construct a locking strategy based on SQL UPDATE statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indictates the type of lock to be acquired.  Note that
 	 * read-locks are not valid for this strategy.
 	 */
 	public PessimisticWriteUpdateLockingStrategy(Lockable lockable, LockMode lockMode) {
 		this.lockable = lockable;
 		this.lockMode = lockMode;
 		if ( lockMode.lessThan( LockMode.PESSIMISTIC_READ ) ) {
 			throw new HibernateException( "[" + lockMode + "] not valid for update statement" );
 		}
 		if ( !lockable.isVersioned() ) {
             LOG.writeLocksNotSupported(lockable.getEntityName());
 			this.sql = null;
 		}
 		else {
 			this.sql = generateLockString();
 		}
 	}
 
    /**
 	 * @see LockingStrategy#lock
 	 */
 	public void lock(
       Serializable id,
       Object version,
       Object object,
       int timeout, SessionImplementor session) throws StaleObjectStateException, JDBCException {
 		if ( !lockable.isVersioned() ) {
 			throw new HibernateException( "write locks via update not supported for non-versioned entities [" + lockable.getEntityName() + "]" );
 		}
 		SessionFactoryImplementor factory = session.getFactory();
 		try {
 			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				lockable.getVersionType().nullSafeSet( st, version, 1, session );
 				int offset = 2;
 
 				lockable.getIdentifierType().nullSafeSet( st, id, offset, session );
 				offset += lockable.getIdentifierType().getColumnSpan( factory );
 
 				if ( lockable.isVersioned() ) {
 					lockable.getVersionType().nullSafeSet( st, version, offset, session );
 				}
 
 				int affected = st.executeUpdate();
 				if ( affected < 0 ) {  // todo:  should this instead check for exactly one row modified?
 					factory.getStatisticsImplementor().optimisticFailure( lockable.getEntityName() );
 					throw new StaleObjectStateException( lockable.getEntityName(), id );
 				}
 
 			}
 			finally {
 				st.close();
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			JDBCException e = session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not lock: " + MessageHelper.infoString( lockable, id, session.getFactory() ),
 					sql
 				);
 			throw new PessimisticLockException("could not obtain pessimistic lock", e, object);
 		}
 	}
 
 	protected String generateLockString() {
 		SessionFactoryImplementor factory = lockable.getFactory();
 		Update update = new Update( factory.getDialect() );
 		update.setTableName( lockable.getRootTableName() );
 		update.addPrimaryKeyColumns( lockable.getRootTableIdentifierColumnNames() );
 		update.setVersionColumnName( lockable.getVersionColumnName() );
 		update.addColumn( lockable.getVersionColumnName() );
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			update.setComment( lockMode + " lock " + lockable.getEntityName() );
 		}
 		return update.toStatementString();
 	}
 
 	protected LockMode getLockMode() {
 		return lockMode;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/UpdateLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/UpdateLockingStrategy.java
index 14b512acdd..d728f681d1 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/UpdateLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/UpdateLockingStrategy.java
@@ -1,143 +1,143 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 import org.jboss.logging.Logger;
 
 /**
  * A locking strategy where the locks are obtained through update statements.
  * <p/>
  * This strategy is not valid for read style locks.
  *
  * @since 3.2
  *
  * @author Steve Ebersole
  */
 public class UpdateLockingStrategy implements LockingStrategy {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, UpdateLockingStrategy.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, UpdateLockingStrategy.class.getName());
 
 	private final Lockable lockable;
 	private final LockMode lockMode;
 	private final String sql;
 
 	/**
 	 * Construct a locking strategy based on SQL UPDATE statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indictates the type of lock to be acquired.  Note that
 	 * read-locks are not valid for this strategy.
 	 */
 	public UpdateLockingStrategy(Lockable lockable, LockMode lockMode) {
 		this.lockable = lockable;
 		this.lockMode = lockMode;
 		if ( lockMode.lessThan( LockMode.UPGRADE ) ) {
 			throw new HibernateException( "[" + lockMode + "] not valid for update statement" );
 		}
 		if ( !lockable.isVersioned() ) {
             LOG.writeLocksNotSupported(lockable.getEntityName());
 			this.sql = null;
 		}
 		else {
 			this.sql = generateLockString();
 		}
 	}
 
 	/**
 	 * @see LockingStrategy#lock
 	 */
 	public void lock(
 	        Serializable id,
 	        Object version,
 	        Object object,
 	        int timeout,
 	        SessionImplementor session) throws StaleObjectStateException, JDBCException {
 		if ( !lockable.isVersioned() ) {
 			throw new HibernateException( "write locks via update not supported for non-versioned entities [" + lockable.getEntityName() + "]" );
 		}
 		// todo : should we additionally check the current isolation mode explicitly?
 		SessionFactoryImplementor factory = session.getFactory();
 		try {
 			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				lockable.getVersionType().nullSafeSet( st, version, 1, session );
 				int offset = 2;
 
 				lockable.getIdentifierType().nullSafeSet( st, id, offset, session );
 				offset += lockable.getIdentifierType().getColumnSpan( factory );
 
 				if ( lockable.isVersioned() ) {
 					lockable.getVersionType().nullSafeSet( st, version, offset, session );
 				}
 
 				int affected = st.executeUpdate();
 				if ( affected < 0 ) {
 					factory.getStatisticsImplementor().optimisticFailure( lockable.getEntityName() );
 					throw new StaleObjectStateException( lockable.getEntityName(), id );
 				}
 
 			}
 			finally {
 				st.close();
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not lock: " + MessageHelper.infoString( lockable, id, session.getFactory() ),
 			        sql
 			);
 		}
 	}
 
 	protected String generateLockString() {
 		SessionFactoryImplementor factory = lockable.getFactory();
 		Update update = new Update( factory.getDialect() );
 		update.setTableName( lockable.getRootTableName() );
 		update.addPrimaryKeyColumns( lockable.getRootTableIdentifierColumnNames() );
 		update.setVersionColumnName( lockable.getVersionColumnName() );
 		update.addColumn( lockable.getVersionColumnName() );
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			update.setComment( lockMode + " lock " + lockable.getEntityName() );
 		}
 		return update.toStatementString();
 	}
 
 	protected LockMode getLockMode() {
 		return lockMode;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/resolver/BasicSQLExceptionConverter.java b/hibernate-core/src/main/java/org/hibernate/dialect/resolver/BasicSQLExceptionConverter.java
index 786cc0de81..5cfada1f50 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/resolver/BasicSQLExceptionConverter.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/resolver/BasicSQLExceptionConverter.java
@@ -1,64 +1,66 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.resolver;
 import java.sql.SQLException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.exception.SQLStateConverter;
 import org.hibernate.exception.ViolatedConstraintNameExtracter;
+
 import org.jboss.logging.Logger;
 
 /**
  * A helper to centralize conversion of {@link java.sql.SQLException}s to {@link org.hibernate.JDBCException}s.
  *
  * @author Steve Ebersole
  */
 public class BasicSQLExceptionConverter {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        BasicSQLExceptionConverter.class.getName());
 	public static final BasicSQLExceptionConverter INSTANCE = new BasicSQLExceptionConverter();
     public static final String MSG = LOG.unableToQueryDatabaseMetadata();
 
 	private static final SQLStateConverter CONVERTER = new SQLStateConverter( new ConstraintNameExtracter() );
 
 	/**
 	 * Perform a conversion.
 	 *
 	 * @param sqlException The exception to convert.
 	 * @return The converted exception.
 	 */
 	public JDBCException convert(SQLException sqlException) {
 		return CONVERTER.convert( sqlException, MSG, null );
 	}
 
 	private static class ConstraintNameExtracter implements ViolatedConstraintNameExtracter {
 		/**
 		 * {@inheritDoc}
 		 */
 		public String extractConstraintName(SQLException sqle) {
 			return "???";
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/ActionQueue.java b/hibernate-core/src/main/java/org/hibernate/engine/ActionQueue.java
index 3880a9baed..175b4a49ce 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/ActionQueue.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/ActionQueue.java
@@ -1,742 +1,742 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Set;
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.action.internal.BulkOperationCleanupAction;
 import org.hibernate.action.internal.CollectionAction;
 import org.hibernate.action.internal.CollectionRecreateAction;
 import org.hibernate.action.internal.EntityAction;
 import org.hibernate.action.internal.EntityInsertAction;
 import org.hibernate.action.internal.EntityUpdateAction;
 import org.hibernate.action.spi.AfterTransactionCompletionProcess;
 import org.hibernate.action.spi.BeforeTransactionCompletionProcess;
 import org.hibernate.action.internal.CollectionRemoveAction;
 import org.hibernate.action.internal.CollectionUpdateAction;
 import org.hibernate.action.internal.EntityDeleteAction;
 import org.hibernate.action.internal.EntityIdentityInsertAction;
 import org.hibernate.action.spi.Executable;
 import org.hibernate.cache.CacheException;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Responsible for maintaining the queue of actions related to events.
  * </p>
  * The ActionQueue holds the DML operations queued as part of a session's
  * transactional-write-behind semantics.  DML operations are queued here
  * until a flush forces them to be executed against the database.
  *
  * @author Steve Ebersole
  */
 public class ActionQueue {
 
-    static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ActionQueue.class.getName());
+    static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ActionQueue.class.getName());
 	private static final int INIT_QUEUE_LIST_SIZE = 5;
 
 	private SessionImplementor session;
 
 	// Object insertions, updates, and deletions have list semantics because
 	// they must happen in the right order so as to respect referential
 	// integrity
 	private ArrayList insertions;
 	private ArrayList deletions;
 	private ArrayList updates;
 	// Actually the semantics of the next three are really "Bag"
 	// Note that, unlike objects, collection insertions, updates,
 	// deletions are not really remembered between flushes. We
 	// just re-use the same Lists for convenience.
 	private ArrayList collectionCreations;
 	private ArrayList collectionUpdates;
 	private ArrayList collectionRemovals;
 
 	private AfterTransactionCompletionProcessQueue afterTransactionProcesses;
 	private BeforeTransactionCompletionProcessQueue beforeTransactionProcesses;
 
 	/**
 	 * Constructs an action queue bound to the given session.
 	 *
 	 * @param session The session "owning" this queue.
 	 */
 	public ActionQueue(SessionImplementor session) {
 		this.session = session;
 		init();
 	}
 
 	private void init() {
 		insertions = new ArrayList( INIT_QUEUE_LIST_SIZE );
 		deletions = new ArrayList( INIT_QUEUE_LIST_SIZE );
 		updates = new ArrayList( INIT_QUEUE_LIST_SIZE );
 
 		collectionCreations = new ArrayList( INIT_QUEUE_LIST_SIZE );
 		collectionRemovals = new ArrayList( INIT_QUEUE_LIST_SIZE );
 		collectionUpdates = new ArrayList( INIT_QUEUE_LIST_SIZE );
 
 		afterTransactionProcesses = new AfterTransactionCompletionProcessQueue( session );
 		beforeTransactionProcesses = new BeforeTransactionCompletionProcessQueue( session );
 	}
 
 	public void clear() {
 		updates.clear();
 		insertions.clear();
 		deletions.clear();
 
 		collectionCreations.clear();
 		collectionRemovals.clear();
 		collectionUpdates.clear();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void addAction(EntityInsertAction action) {
 		insertions.add( action );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void addAction(EntityDeleteAction action) {
 		deletions.add( action );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void addAction(EntityUpdateAction action) {
 		updates.add( action );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void addAction(CollectionRecreateAction action) {
 		collectionCreations.add( action );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void addAction(CollectionRemoveAction action) {
 		collectionRemovals.add( action );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void addAction(CollectionUpdateAction action) {
 		collectionUpdates.add( action );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void addAction(EntityIdentityInsertAction insert) {
 		insertions.add( insert );
 	}
 
 	public void addAction(BulkOperationCleanupAction cleanupAction) {
 		registerCleanupActions( cleanupAction );
 	}
 
 	public void registerProcess(AfterTransactionCompletionProcess process) {
 		afterTransactionProcesses.register( process );
 	}
 
 	public void registerProcess(BeforeTransactionCompletionProcess process) {
 		beforeTransactionProcesses.register( process );
 	}
 
 	/**
 	 * Perform all currently queued entity-insertion actions.
 	 *
 	 * @throws HibernateException error executing queued insertion actions.
 	 */
 	public void executeInserts() throws HibernateException {
 		executeActions( insertions );
 	}
 
 	/**
 	 * Perform all currently queued actions.
 	 *
 	 * @throws HibernateException error executing queued actions.
 	 */
 	public void executeActions() throws HibernateException {
 		executeActions( insertions );
 		executeActions( updates );
 		executeActions( collectionRemovals );
 		executeActions( collectionUpdates );
 		executeActions( collectionCreations );
 		executeActions( deletions );
 	}
 
 	/**
 	 * Prepares the internal action queues for execution.
 	 *
 	 * @throws HibernateException error preparing actions.
 	 */
 	public void prepareActions() throws HibernateException {
 		prepareActions( collectionRemovals );
 		prepareActions( collectionUpdates );
 		prepareActions( collectionCreations );
 	}
 
 	/**
 	 * Performs cleanup of any held cache softlocks.
 	 *
 	 * @param success Was the transaction successful.
 	 */
 	public void afterTransactionCompletion(boolean success) {
 		afterTransactionProcesses.afterTransactionCompletion( success );
 	}
 
 	/**
 	 * Execute any registered {@link org.hibernate.action.spi.BeforeTransactionCompletionProcess}
 	 */
 	public void beforeTransactionCompletion() {
 		beforeTransactionProcesses.beforeTransactionCompletion();
 	}
 
 	/**
 	 * Check whether the given tables/query-spaces are to be executed against
 	 * given the currently queued actions.
 	 *
 	 * @param tables The table/query-spaces to check.
 	 *
 	 * @return True if we contain pending actions against any of the given
 	 *         tables; false otherwise.
 	 */
 	public boolean areTablesToBeUpdated(Set tables) {
 		return areTablesToUpdated( updates, tables ) ||
 				areTablesToUpdated( insertions, tables ) ||
 				areTablesToUpdated( deletions, tables ) ||
 				areTablesToUpdated( collectionUpdates, tables ) ||
 				areTablesToUpdated( collectionCreations, tables ) ||
 				areTablesToUpdated( collectionRemovals, tables );
 	}
 
 	/**
 	 * Check whether any insertion or deletion actions are currently queued.
 	 *
 	 * @return True if insertions or deletions are currently queued; false otherwise.
 	 */
 	public boolean areInsertionsOrDeletionsQueued() {
 		return ( insertions.size() > 0 || deletions.size() > 0 );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private static boolean areTablesToUpdated(List actions, Set tableSpaces) {
 		for ( Executable action : (List<Executable>) actions ) {
 			final Serializable[] spaces = action.getPropertySpaces();
 			for ( Serializable space : spaces ) {
 				if ( tableSpaces.contains( space ) ) {
                     LOG.debugf("Changes must be flushed to space: %s", space);
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	private void executeActions(List list) throws HibernateException {
 		int size = list.size();
 		for ( int i = 0; i < size; i++ ) {
 			execute( (Executable) list.get( i ) );
 		}
 		list.clear();
 		session.getTransactionCoordinator().getJdbcCoordinator().executeBatch();
 	}
 
 	public void execute(Executable executable) {
 		try {
 			executable.execute();
 		}
 		finally {
 			registerCleanupActions( executable );
 		}
 	}
 
 	private void registerCleanupActions(Executable executable) {
 		beforeTransactionProcesses.register( executable.getBeforeTransactionCompletionProcess() );
 		if ( session.getFactory().getSettings().isQueryCacheEnabled() ) {
 			final String[] spaces = (String[]) executable.getPropertySpaces();
 			afterTransactionProcesses.addSpacesToInvalidate( spaces );
 			session.getFactory().getUpdateTimestampsCache().preinvalidate( spaces );
 		}
 		afterTransactionProcesses.register( executable.getAfterTransactionCompletionProcess() );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private void prepareActions(List queue) throws HibernateException {
 		for ( Executable executable : (List<Executable>) queue ) {
 			executable.beforeExecutions();
 		}
 	}
 
 	/**
 	 * Returns a string representation of the object.
 	 *
 	 * @return a string representation of the object.
 	 */
 	@Override
     public String toString() {
 		return new StringBuffer()
 				.append( "ActionQueue[insertions=" ).append( insertions )
 				.append( " updates=" ).append( updates )
 				.append( " deletions=" ).append( deletions )
 				.append( " collectionCreations=" ).append( collectionCreations )
 				.append( " collectionRemovals=" ).append( collectionRemovals )
 				.append( " collectionUpdates=" ).append( collectionUpdates )
 				.append( "]" )
 				.toString();
 	}
 
 	public int numberOfCollectionRemovals() {
 		return collectionRemovals.size();
 	}
 
 	public int numberOfCollectionUpdates() {
 		return collectionUpdates.size();
 	}
 
 	public int numberOfCollectionCreations() {
 		return collectionCreations.size();
 	}
 
 	public int numberOfDeletions() {
 		return deletions.size();
 	}
 
 	public int numberOfUpdates() {
 		return updates.size();
 	}
 
 	public int numberOfInsertions() {
 		return insertions.size();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void sortCollectionActions() {
 		if ( session.getFactory().getSettings().isOrderUpdatesEnabled() ) {
 			//sort the updates by fk
 			java.util.Collections.sort( collectionCreations );
 			java.util.Collections.sort( collectionUpdates );
 			java.util.Collections.sort( collectionRemovals );
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void sortActions() {
 		if ( session.getFactory().getSettings().isOrderUpdatesEnabled() ) {
 			//sort the updates by pk
 			java.util.Collections.sort( updates );
 		}
 		if ( session.getFactory().getSettings().isOrderInsertsEnabled() ) {
 			sortInsertActions();
 		}
 	}
 
 	/**
 	 * Order the {@link #insertions} queue such that we group inserts
 	 * against the same entity together (without violating constraints).  The
 	 * original order is generated by cascade order, which in turn is based on
 	 * the directionality of foreign-keys.  So even though we will be changing
 	 * the ordering here, we need to make absolutely certain that we do not
 	 * circumvent this FK ordering to the extent of causing constraint
 	 * violations
 	 */
 	private void sortInsertActions() {
 		new InsertActionSorter().sort();
 	}
 
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public ArrayList cloneDeletions() {
 		return ( ArrayList ) deletions.clone();
 	}
 
 	public void clearFromFlushNeededCheck(int previousCollectionRemovalSize) {
 		collectionCreations.clear();
 		collectionUpdates.clear();
 		updates.clear();
 		// collection deletions are a special case since update() can add
 		// deletions of collections not loaded by the session.
 		for ( int i = collectionRemovals.size() - 1; i >= previousCollectionRemovalSize; i-- ) {
 			collectionRemovals.remove( i );
 		}
 	}
 
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public boolean hasAfterTransactionActions() {
 		return afterTransactionProcesses.processes.size() > 0;
 	}
 
 	public boolean hasBeforeTransactionActions() {
 		return beforeTransactionProcesses.processes.size() > 0;
 	}
 
 	public boolean hasAnyQueuedActions() {
 		return updates.size() > 0 ||
 				insertions.size() > 0 ||
 				deletions.size() > 0 ||
 				collectionUpdates.size() > 0 ||
 				collectionRemovals.size() > 0 ||
 				collectionCreations.size() > 0;
 	}
 
 	/**
 	 * Used by the owning session to explicitly control serialization of the
 	 * action queue
 	 *
 	 * @param oos The stream to which the action queue should get written
 	 *
 	 * @throws IOException Indicates an error writing to the stream
 	 */
 	public void serialize(ObjectOutputStream oos) throws IOException {
         LOG.trace("Serializing action-queue");
 
 		int queueSize = insertions.size();
         LOG.trace("Starting serialization of [" + queueSize + "] insertions entries");
 		oos.writeInt( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			oos.writeObject( insertions.get( i ) );
 		}
 
 		queueSize = deletions.size();
         LOG.trace("Starting serialization of [" + queueSize + "] deletions entries");
 		oos.writeInt( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			oos.writeObject( deletions.get( i ) );
 		}
 
 		queueSize = updates.size();
         LOG.trace("Starting serialization of [" + queueSize + "] updates entries");
 		oos.writeInt( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			oos.writeObject( updates.get( i ) );
 		}
 
 		queueSize = collectionUpdates.size();
         LOG.trace("Starting serialization of [" + queueSize + "] collectionUpdates entries");
 		oos.writeInt( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			oos.writeObject( collectionUpdates.get( i ) );
 		}
 
 		queueSize = collectionRemovals.size();
         LOG.trace("Starting serialization of [" + queueSize + "] collectionRemovals entries");
 		oos.writeInt( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			oos.writeObject( collectionRemovals.get( i ) );
 		}
 
 		queueSize = collectionCreations.size();
         LOG.trace("Starting serialization of [" + queueSize + "] collectionCreations entries");
 		oos.writeInt( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			oos.writeObject( collectionCreations.get( i ) );
 		}
 	}
 
 	/**
 	 * Used by the owning session to explicitly control deserialization of the
 	 * action queue
 	 *
 	 * @param ois The stream from which to read the action queue
 	 * @param session The session to which the action queue belongs
 	 *
 	 * @return The deserialized action queue
 	 *
 	 * @throws IOException indicates a problem reading from the stream
 	 * @throws ClassNotFoundException Generally means we were unable to locate user classes.
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public static ActionQueue deserialize(
 			ObjectInputStream ois,
 			SessionImplementor session) throws IOException, ClassNotFoundException {
         LOG.trace("Dedeserializing action-queue");
 		ActionQueue rtn = new ActionQueue( session );
 
 		int queueSize = ois.readInt();
         LOG.trace("Starting deserialization of [" + queueSize + "] insertions entries");
 		rtn.insertions = new ArrayList<Executable>( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			EntityAction action = ( EntityAction ) ois.readObject();
 			action.afterDeserialize( session );
 			rtn.insertions.add( action );
 		}
 
 		queueSize = ois.readInt();
         LOG.trace("Starting deserialization of [" + queueSize + "] deletions entries");
 		rtn.deletions = new ArrayList<Executable>( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			EntityAction action = ( EntityAction ) ois.readObject();
 			action.afterDeserialize( session );
 			rtn.deletions.add( action );
 		}
 
 		queueSize = ois.readInt();
         LOG.trace("Starting deserialization of [" + queueSize + "] updates entries");
 		rtn.updates = new ArrayList<Executable>( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			EntityAction action = ( EntityAction ) ois.readObject();
 			action.afterDeserialize( session );
 			rtn.updates.add( action );
 		}
 
 		queueSize = ois.readInt();
         LOG.trace("Starting deserialization of [" + queueSize + "] collectionUpdates entries");
 		rtn.collectionUpdates = new ArrayList<Executable>( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			CollectionAction action = (CollectionAction) ois.readObject();
 			action.afterDeserialize( session );
 			rtn.collectionUpdates.add( action );
 		}
 
 		queueSize = ois.readInt();
         LOG.trace("Starting deserialization of [" + queueSize + "] collectionRemovals entries");
 		rtn.collectionRemovals = new ArrayList<Executable>( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			CollectionAction action = ( CollectionAction ) ois.readObject();
 			action.afterDeserialize( session );
 			rtn.collectionRemovals.add( action );
 		}
 
 		queueSize = ois.readInt();
         LOG.trace("Starting deserialization of [" + queueSize + "] collectionCreations entries");
 		rtn.collectionCreations = new ArrayList<Executable>( queueSize );
 		for ( int i = 0; i < queueSize; i++ ) {
 			CollectionAction action = ( CollectionAction ) ois.readObject();
 			action.afterDeserialize( session );
 			rtn.collectionCreations.add( action );
 		}
 		return rtn;
 	}
 
 	private static class BeforeTransactionCompletionProcessQueue {
 		private SessionImplementor session;
 		private List<BeforeTransactionCompletionProcess> processes = new ArrayList<BeforeTransactionCompletionProcess>();
 
 		private BeforeTransactionCompletionProcessQueue(SessionImplementor session) {
 			this.session = session;
 		}
 
 		public void register(BeforeTransactionCompletionProcess process) {
 			if ( process == null ) {
 				return;
 			}
 			processes.add( process );
 		}
 
 		public void beforeTransactionCompletion() {
 			final int size = processes.size();
 			for ( int i = 0; i < size; i++ ) {
 				try {
 					BeforeTransactionCompletionProcess process = processes.get( i );
 					process.doBeforeTransactionCompletion( session );
 				}
 				catch ( HibernateException he ) {
 					throw he;
 				}
 				catch ( Exception e ) {
 					throw new AssertionFailure( "Unable to perform beforeTransactionCompletion callback", e );
 				}
 			}
 			processes.clear();
 		}
 	}
 
 	private static class AfterTransactionCompletionProcessQueue {
 		private SessionImplementor session;
 		private Set<String> querySpacesToInvalidate = new HashSet<String>();
 		private List<AfterTransactionCompletionProcess> processes
 				= new ArrayList<AfterTransactionCompletionProcess>( INIT_QUEUE_LIST_SIZE * 3 );
 
 		private AfterTransactionCompletionProcessQueue(SessionImplementor session) {
 			this.session = session;
 		}
 
 		public void addSpacesToInvalidate(String[] spaces) {
 			if ( spaces == null ) {
 				return;
 			}
 			for ( int i = 0, max = spaces.length; i < max; i++ ) {
 				addSpaceToInvalidate( spaces[i] );
 			}
 		}
 
 		public void addSpaceToInvalidate(String space) {
 			querySpacesToInvalidate.add( space );
 		}
 
 		public void register(AfterTransactionCompletionProcess process) {
 			if ( process == null ) {
 				return;
 			}
 			processes.add( process );
 		}
 
 		public void afterTransactionCompletion(boolean success) {
 			final int size = processes.size();
 			for ( int i = 0; i < size; i++ ) {
 				try {
 					AfterTransactionCompletionProcess process = processes.get( i );
 					process.doAfterTransactionCompletion( success, session );
 				}
 				catch ( CacheException ce ) {
                     LOG.unableToReleaseCacheLock(ce);
 					// continue loop
 				}
 				catch ( Exception e ) {
 					throw new AssertionFailure( "Exception releasing cache locks", e );
 				}
 			}
 			processes.clear();
 
 			if ( session.getFactory().getSettings().isQueryCacheEnabled() ) {
 				session.getFactory().getUpdateTimestampsCache().invalidate(
 						querySpacesToInvalidate.toArray( new String[ querySpacesToInvalidate.size()] )
 				);
 			}
 			querySpacesToInvalidate.clear();
 		}
 	}
 
 	/**
 	 * Sorts the insert actions using more hashes.
 	 *
 	 * @author Jay Erb
 	 */
 	private class InsertActionSorter {
 		// the mapping of entity names to their latest batch numbers.
 		private HashMap latestBatches = new HashMap();
 		private HashMap entityBatchNumber;
 
 		// the map of batch numbers to EntityInsertAction lists
 		private HashMap actionBatches = new HashMap();
 
 		public InsertActionSorter() {
 			//optimize the hash size to eliminate a rehash.
 			entityBatchNumber = new HashMap( insertions.size() + 1, 1.0f );
 		}
 
 		/**
 		 * Sort the insert actions.
 		 */
 		@SuppressWarnings({ "unchecked", "UnnecessaryBoxing" })
 		public void sort() {
 			// the list of entity names that indicate the batch number
 			for ( EntityInsertAction action : (List<EntityInsertAction>) insertions ) {
 				// remove the current element from insertions. It will be added back later.
 				String entityName = action.getEntityName();
 
 				// the entity associated with the current action.
 				Object currentEntity = action.getInstance();
 
 				Integer batchNumber;
 				if ( latestBatches.containsKey( entityName ) ) {
 					// There is already an existing batch for this type of entity.
 					// Check to see if the latest batch is acceptable.
 					batchNumber = findBatchNumber( action, entityName );
 				}
 				else {
 					// add an entry for this type of entity.
 					// we can be assured that all referenced entities have already
 					// been processed,
 					// so specify that this entity is with the latest batch.
 					// doing the batch number before adding the name to the list is
 					// a faster way to get an accurate number.
 
 					batchNumber = Integer.valueOf( actionBatches.size() );
 					latestBatches.put( entityName, batchNumber );
 				}
 				entityBatchNumber.put( currentEntity, batchNumber );
 				addToBatch( batchNumber, action );
 			}
 			insertions.clear();
 
 			// now rebuild the insertions list. There is a batch for each entry in the name list.
 			for ( int i = 0; i < actionBatches.size(); i++ ) {
 				List batch = ( List ) actionBatches.get( new Integer( i ) );
 				for ( Object aBatch : batch ) {
 					EntityInsertAction action = (EntityInsertAction) aBatch;
 					insertions.add( action );
 				}
 			}
 		}
 
 		/**
 		 * Finds an acceptable batch for this entity to be a member as part of the {@link InsertActionSorter}
 		 *
 		 * @param action The action being sorted
 		 * @param entityName The name of the entity affected by the action
 		 *
 		 * @return An appropriate batch number; todo document this process better
 		 */
 		@SuppressWarnings({ "UnnecessaryBoxing", "unchecked" })
 		private Integer findBatchNumber(
 				EntityInsertAction action,
 				String entityName) {
 			// loop through all the associated entities and make sure they have been
 			// processed before the latest
 			// batch associated with this entity type.
 
 			// the current batch number is the latest batch for this entity type.
 			Integer latestBatchNumberForType = ( Integer ) latestBatches.get( entityName );
 
 			// loop through all the associations of the current entity and make sure that they are processed
 			// before the current batch number
 			Object[] propertyValues = action.getState();
 			Type[] propertyTypes = action.getPersister().getClassMetadata()
 					.getPropertyTypes();
 
 			for ( int i = 0; i < propertyValues.length; i++ ) {
 				Object value = propertyValues[i];
 				Type type = propertyTypes[i];
 				if ( type.isEntityType() && value != null ) {
 					// find the batch number associated with the current association, if any.
 					Integer associationBatchNumber = ( Integer ) entityBatchNumber.get( value );
 					if ( associationBatchNumber != null && associationBatchNumber.compareTo( latestBatchNumberForType ) > 0 ) {
 						// create a new batch for this type. The batch number is the number of current batches.
 						latestBatchNumberForType = Integer.valueOf( actionBatches.size() );
 						latestBatches.put( entityName, latestBatchNumberForType );
 						// since this entity will now be processed in the latest possible batch,
 						// we can be assured that it will come after all other associations,
 						// there's not need to continue checking.
 						break;
 					}
 				}
 			}
 			return latestBatchNumberForType;
 		}
 
 		@SuppressWarnings({ "unchecked" })
 		private void addToBatch(Integer batchNumber, EntityInsertAction action) {
 			List actions = ( List ) actionBatches.get( batchNumber );
 
 			if ( actions == null ) {
 				actions = new LinkedList();
 				actionBatches.put( batchNumber, actions );
 			}
 			actions.add( action );
 		}
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/Cascade.java b/hibernate-core/src/main/java/org/hibernate/engine/Cascade.java
index 6d84d4e6c3..53fc0541d2 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/Cascade.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/Cascade.java
@@ -1,474 +1,474 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Stack;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.event.EventSource;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Delegate responsible for, in conjunction with the various
  * {@link CascadingAction actions}, implementing cascade processing.
  *
  * @author Gavin King
  * @see CascadingAction
  */
 public final class Cascade {
 
 	/**
 	 * A cascade point that occurs just after the insertion of the parent entity and
 	 * just before deletion
 	 */
 	public static final int AFTER_INSERT_BEFORE_DELETE = 1;
 	/**
 	 * A cascade point that occurs just before the insertion of the parent entity and
 	 * just after deletion
 	 */
 	public static final int BEFORE_INSERT_AFTER_DELETE = 2;
 	/**
 	 * A cascade point that occurs just after the insertion of the parent entity and
 	 * just before deletion, inside a collection
 	 */
 	public static final int AFTER_INSERT_BEFORE_DELETE_VIA_COLLECTION = 3;
 	/**
 	 * A cascade point that occurs just after update of the parent entity
 	 */
 	public static final int AFTER_UPDATE = 0;
 	/**
 	 * A cascade point that occurs just before the session is flushed
 	 */
 	public static final int BEFORE_FLUSH = 0;
 	/**
 	 * A cascade point that occurs just after eviction of the parent entity from the
 	 * session cache
 	 */
 	public static final int AFTER_EVICT = 0;
 	/**
 	 * A cascade point that occurs just after locking a transient parent entity into the
 	 * session cache
 	 */
 	public static final int BEFORE_REFRESH = 0;
 	/**
 	 * A cascade point that occurs just after refreshing a parent entity
 	 */
 	public static final int AFTER_LOCK = 0;
 	/**
 	 * A cascade point that occurs just before merging from a transient parent entity into
 	 * the object in the session cache
 	 */
 	public static final int BEFORE_MERGE = 0;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Cascade.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Cascade.class.getName());
 
 
 	private int cascadeTo;
 	private EventSource eventSource;
 	private CascadingAction action;
 
 	public Cascade(final CascadingAction action, final int cascadeTo, final EventSource eventSource) {
 		this.cascadeTo = cascadeTo;
 		this.eventSource = eventSource;
 		this.action = action;
 	}
 
 	private SessionFactoryImplementor getFactory() {
 		return eventSource.getFactory();
 	}
 
 	/**
 	 * Cascade an action from the parent entity instance to all its children.
 	 *
 	 * @param persister The parent's entity persister
 	 * @param parent The parent reference.
 	 * @throws HibernateException
 	 */
 	public void cascade(final EntityPersister persister, final Object parent)
 	throws HibernateException {
 		cascade( persister, parent, null );
 	}
 
 	/**
 	 * Cascade an action from the parent entity instance to all its children.  This
 	 * form is typicaly called from within cascade actions.
 	 *
 	 * @param persister The parent's entity persister
 	 * @param parent The parent reference.
 	 * @param anything Anything ;)   Typically some form of cascade-local cache
 	 * which is specific to each CascadingAction type
 	 * @throws HibernateException
 	 */
 	public void cascade(final EntityPersister persister, final Object parent, final Object anything)
 			throws HibernateException {
 
 		if ( persister.hasCascades() || action.requiresNoCascadeChecking() ) { // performance opt
             LOG.trace("Processing cascade " + action + " for: " + persister.getEntityName());
 
 			Type[] types = persister.getPropertyTypes();
 			CascadeStyle[] cascadeStyles = persister.getPropertyCascadeStyles();
 			EntityMode entityMode = eventSource.getEntityMode();
 			boolean hasUninitializedLazyProperties = persister.hasUninitializedLazyProperties( parent, entityMode );
 			for ( int i=0; i<types.length; i++) {
 				final CascadeStyle style = cascadeStyles[i];
 				final String propertyName = persister.getPropertyNames()[i];
 				if ( hasUninitializedLazyProperties && persister.getPropertyLaziness()[i] && ! action.performOnLazyProperty() ) {
 					//do nothing to avoid a lazy property initialization
 					continue;
 				}
 
 				if ( style.doCascade( action ) ) {
 					cascadeProperty(
 						    parent,
 					        persister.getPropertyValue( parent, i, entityMode ),
 					        types[i],
 					        style,
 							propertyName,
 					        anything,
 					        false
 					);
 				}
 				else if ( action.requiresNoCascadeChecking() ) {
 					action.noCascade(
 							eventSource,
 							persister.getPropertyValue( parent, i, entityMode ),
 							parent,
 							persister,
 							i
 					);
 				}
 			}
 
             LOG.trace("Done processing cascade " + action + " for: " + persister.getEntityName());
 		}
 	}
 
 	/**
 	 * Cascade an action to the child or children
 	 */
 	private void cascadeProperty(
 			final Object parent,
 			final Object child,
 			final Type type,
 			final CascadeStyle style,
 			final String propertyName,
 			final Object anything,
 			final boolean isCascadeDeleteEnabled) throws HibernateException {
 
 		if (child!=null) {
 			if ( type.isAssociationType() ) {
 				AssociationType associationType = (AssociationType) type;
 				if ( cascadeAssociationNow( associationType ) ) {
 					cascadeAssociation(
 							parent,
 							child,
 							type,
 							style,
 							anything,
 							isCascadeDeleteEnabled
 						);
 				}
 			}
 			else if ( type.isComponentType() ) {
 				cascadeComponent( parent, child, (CompositeType) type, propertyName, anything );
 			}
 		}
 		else {
 			// potentially we need to handle orphan deletes for one-to-ones here...
 			if ( isLogicalOneToOne( type ) ) {
 				// We have a physical or logical one-to-one and from previous checks we know we
 				// have a null value.  See if the attribute cascade settings and action-type require
 				// orphan checking
 				if ( style.hasOrphanDelete() && action.deleteOrphans() ) {
 					// value is orphaned if loaded state for this property shows not null
 					// because it is currently null.
 					final EntityEntry entry = eventSource.getPersistenceContext().getEntry( parent );
 					if ( entry != null && entry.getStatus() != Status.SAVING ) {
 						final Object loadedValue;
 						if ( componentPathStack.isEmpty() ) {
 							// association defined on entity
 							loadedValue = entry.getLoadedValue( propertyName );
 						}
 						else {
 							// association defined on component
 							// 		todo : this is currently unsupported because of the fact that
 							//		we do not know the loaded state of this value properly
 							//		and doing so would be very difficult given how components and
 							//		entities are loaded (and how 'loaded state' is put into the
 							//		EntityEntry).  Solutions here are to either:
 							//			1) properly account for components as a 2-phase load construct
 							//			2) just assume the association was just now orphaned and
 							// 				issue the orphan delete.  This would require a special
 							//				set of SQL statements though since we do not know the
 							//				orphaned value, something a delete with a subquery to
 							// 				match the owner.
 //							final EntityType entityType = (EntityType) type;
 //							final String propertyPath = composePropertyPath( entityType.getPropertyName() );
 							loadedValue = null;
 						}
 						if ( loadedValue != null ) {
 							final String entityName = entry.getPersister().getEntityName();
                             if (LOG.isTraceEnabled()) {
 								final Serializable id = entry.getPersister().getIdentifier( loadedValue, eventSource );
 								final String description = MessageHelper.infoString( entityName, id );
                                 LOG.trace("Deleting orphaned entity instance: " + description);
 							}
 							eventSource.delete( entityName, loadedValue, false, new HashSet() );
 						}
 					}
 				}
 			}
 		}
 	}
 
 	/**
 	 * Check if the association is a one to one in the logical model (either a shared-pk
 	 * or unique fk).
 	 *
 	 * @param type The type representing the attribute metadata
 	 *
 	 * @return True if the attribute represents a logical one to one association
 	 */
 	private boolean isLogicalOneToOne(Type type) {
 		return type.isEntityType() && ( (EntityType) type ).isLogicalOneToOne();
 	}
 
 	private String composePropertyPath(String propertyName) {
 		if ( componentPathStack.isEmpty() ) {
 			return propertyName;
 		}
 		else {
 			StringBuffer buffer = new StringBuffer();
 			Iterator itr = componentPathStack.iterator();
 			while ( itr.hasNext() ) {
 				buffer.append( itr.next() ).append( '.' );
 			}
 			buffer.append( propertyName );
 			return buffer.toString();
 		}
 	}
 
 	private Stack componentPathStack = new Stack();
 
 	private boolean cascadeAssociationNow(AssociationType associationType) {
 		return associationType.getForeignKeyDirection().cascadeNow(cascadeTo) &&
 			( eventSource.getEntityMode()!=EntityMode.DOM4J || associationType.isEmbeddedInXML() );
 	}
 
 	private void cascadeComponent(
 			final Object parent,
 			final Object child,
 			final CompositeType componentType,
 			final String componentPropertyName,
 			final Object anything) {
 		componentPathStack.push( componentPropertyName );
 		Object[] children = componentType.getPropertyValues( child, eventSource );
 		Type[] types = componentType.getSubtypes();
 		for ( int i=0; i<types.length; i++ ) {
 			final CascadeStyle componentPropertyStyle = componentType.getCascadeStyle(i);
 			final String subPropertyName = componentType.getPropertyNames()[i];
 			if ( componentPropertyStyle.doCascade(action) ) {
 				cascadeProperty(
 						parent,
 						children[i],
 						types[i],
 						componentPropertyStyle,
 						subPropertyName,
 						anything,
 						false
 					);
 			}
 		}
 		componentPathStack.pop();
 	}
 
 	private void cascadeAssociation(
 			final Object parent,
 			final Object child,
 			final Type type,
 			final CascadeStyle style,
 			final Object anything,
 			final boolean isCascadeDeleteEnabled) {
 		if ( type.isEntityType() || type.isAnyType() ) {
 			cascadeToOne( parent, child, type, style, anything, isCascadeDeleteEnabled );
 		}
 		else if ( type.isCollectionType() ) {
 			cascadeCollection( parent, child, style, anything, (CollectionType) type );
 		}
 	}
 
 	/**
 	 * Cascade an action to a collection
 	 */
 	private void cascadeCollection(
 			final Object parent,
 			final Object child,
 			final CascadeStyle style,
 			final Object anything,
 			final CollectionType type) {
 		CollectionPersister persister = eventSource.getFactory()
 				.getCollectionPersister( type.getRole() );
 		Type elemType = persister.getElementType();
 
 		final int oldCascadeTo = cascadeTo;
 		if ( cascadeTo==AFTER_INSERT_BEFORE_DELETE) {
 			cascadeTo = AFTER_INSERT_BEFORE_DELETE_VIA_COLLECTION;
 		}
 
 		//cascade to current collection elements
 		if ( elemType.isEntityType() || elemType.isAnyType() || elemType.isComponentType() ) {
 			cascadeCollectionElements(
 				parent,
 				child,
 				type,
 				style,
 				elemType,
 				anything,
 				persister.isCascadeDeleteEnabled()
 			);
 		}
 
 		cascadeTo = oldCascadeTo;
 	}
 
 	/**
 	 * Cascade an action to a to-one association or any type
 	 */
 	private void cascadeToOne(
 			final Object parent,
 			final Object child,
 			final Type type,
 			final CascadeStyle style,
 			final Object anything,
 			final boolean isCascadeDeleteEnabled) {
 		final String entityName = type.isEntityType()
 				? ( (EntityType) type ).getAssociatedEntityName()
 				: null;
 		if ( style.reallyDoCascade(action) ) { //not really necessary, but good for consistency...
 			eventSource.getPersistenceContext().addChildParent(child, parent);
 			try {
 				action.cascade(eventSource, child, entityName, anything, isCascadeDeleteEnabled);
 			}
 			finally {
 				eventSource.getPersistenceContext().removeChildParent(child);
 			}
 		}
 	}
 
 	/**
 	 * Cascade to the collection elements
 	 */
 	private void cascadeCollectionElements(
 			final Object parent,
 			final Object child,
 			final CollectionType collectionType,
 			final CascadeStyle style,
 			final Type elemType,
 			final Object anything,
 			final boolean isCascadeDeleteEnabled) throws HibernateException {
 		// we can't cascade to non-embedded elements
 		boolean embeddedElements = eventSource.getEntityMode()!=EntityMode.DOM4J ||
 				( (EntityType) collectionType.getElementType( eventSource.getFactory() ) ).isEmbeddedInXML();
 
 		boolean reallyDoCascade = style.reallyDoCascade(action) &&
 			embeddedElements && child!=CollectionType.UNFETCHED_COLLECTION;
 
 		if ( reallyDoCascade ) {
             LOG.trace("Cascade " + action + " for collection: " + collectionType.getRole());
 
 			Iterator iter = action.getCascadableChildrenIterator(eventSource, collectionType, child);
 			while ( iter.hasNext() ) {
 				cascadeProperty(
 						parent,
 						iter.next(),
 						elemType,
 						style,
 						null,
 						anything,
 						isCascadeDeleteEnabled
 					);
 			}
 
             LOG.trace("Done cascade " + action + " for collection: " + collectionType.getRole());
 		}
 
 		final boolean deleteOrphans = style.hasOrphanDelete() &&
 				action.deleteOrphans() &&
 				elemType.isEntityType() &&
 				child instanceof PersistentCollection; //a newly instantiated collection can't have orphans
 
 		if ( deleteOrphans ) { // handle orphaned entities!!
             LOG.trace("Deleting orphans for collection: " + collectionType.getRole());
 
 			// we can do the cast since orphan-delete does not apply to:
 			// 1. newly instantiated collections
 			// 2. arrays (we can't track orphans for detached arrays)
 			final String entityName = collectionType.getAssociatedEntityName( eventSource.getFactory() );
 			deleteOrphans( entityName, (PersistentCollection) child );
 
             LOG.trace("Done deleting orphans for collection: " + collectionType.getRole());
 		}
 	}
 
 	/**
 	 * Delete any entities that were removed from the collection
 	 */
 	private void deleteOrphans(String entityName, PersistentCollection pc) throws HibernateException {
 		//TODO: suck this logic into the collection!
 		final Collection orphans;
 		if ( pc.wasInitialized() ) {
 			CollectionEntry ce = eventSource.getPersistenceContext().getCollectionEntry(pc);
 			orphans = ce==null ?
 					CollectionHelper.EMPTY_COLLECTION :
 					ce.getOrphans(entityName, pc);
 		}
 		else {
 			orphans = pc.getQueuedOrphans(entityName);
 		}
 
 		final Iterator orphanIter = orphans.iterator();
 		while ( orphanIter.hasNext() ) {
 			Object orphan = orphanIter.next();
 			if (orphan!=null) {
                 LOG.trace("Deleting orphaned entity instance: " + entityName);
 				eventSource.delete( entityName, orphan, false, new HashSet() );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/CascadingAction.java b/hibernate-core/src/main/java/org/hibernate/engine/CascadingAction.java
index 2fd0994f97..91d83f95ad 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/CascadingAction.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/CascadingAction.java
@@ -1,468 +1,468 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.ReplicationMode;
 import org.hibernate.TransientObjectException;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.event.EventSource;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * A session action that may be cascaded from parent entity to its children
  *
  * @author Gavin King
  */
 public abstract class CascadingAction {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, CascadingAction.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CascadingAction.class.getName());
 
 
 	// the CascadingAction contract ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * protected constructor
 	 */
 	CascadingAction() {
 	}
 
 	/**
 	 * Cascade the action to the child object.
 	 *
 	 * @param session The session within which the cascade is occuring.
 	 * @param child The child to which cascading should be performed.
 	 * @param entityName The child's entity name
 	 * @param anything Anything ;)  Typically some form of cascade-local cache
 	 * which is specific to each CascadingAction type
 	 * @param isCascadeDeleteEnabled Are cascading deletes enabled.
 	 * @throws HibernateException
 	 */
 	public abstract void cascade(
 			EventSource session,
 			Object child,
 			String entityName,
 			Object anything,
 			boolean isCascadeDeleteEnabled) throws HibernateException;
 
 	/**
 	 * Given a collection, get an iterator of the children upon which the
 	 * current cascading action should be visited.
 	 *
 	 * @param session The session within which the cascade is occuring.
 	 * @param collectionType The mapping type of the collection.
 	 * @param collection The collection instance.
 	 * @return The children iterator.
 	 */
 	public abstract Iterator getCascadableChildrenIterator(
 			EventSource session,
 			CollectionType collectionType,
 			Object collection);
 
 	/**
 	 * Does this action potentially extrapolate to orphan deletes?
 	 *
 	 * @return True if this action can lead to deletions of orphans.
 	 */
 	public abstract boolean deleteOrphans();
 
 
 	/**
 	 * Does the specified cascading action require verification of no cascade validity?
 	 *
 	 * @return True if this action requires no-cascade verification; false otherwise.
 	 */
 	public boolean requiresNoCascadeChecking() {
 		return false;
 	}
 
 	/**
 	 * Called (in the case of {@link #requiresNoCascadeChecking} returning true) to validate
 	 * that no cascade on the given property is considered a valid semantic.
 	 *
 	 * @param session The session witin which the cascade is occurring.
 	 * @param child The property value
 	 * @param parent The property value owner
 	 * @param persister The entity persister for the owner
 	 * @param propertyIndex The index of the property within the owner.
 	 */
 	public void noCascade(EventSource session, Object child, Object parent, EntityPersister persister, int propertyIndex) {
 	}
 
 	/**
 	 * Should this action be performed (or noCascade consulted) in the case of lazy properties.
 	 */
 	public boolean performOnLazyProperty() {
 		return true;
 	}
 
 
 	// the CascadingAction implementations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * @see org.hibernate.Session#delete(Object)
 	 */
 	public static final CascadingAction DELETE = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to delete: " + entityName);
 			session.delete( entityName, child, isCascadeDeleteEnabled, ( Set ) anything );
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// delete does cascade to uninitialized collections
 			return CascadingAction.getAllElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			// orphans should be deleted during delete
 			return true;
 		}
 		@Override
         public String toString() {
 			return "ACTION_DELETE";
 		}
 	};
 
 	/**
 	 * @see org.hibernate.Session#lock(Object, LockMode)
 	 */
 	public static final CascadingAction LOCK = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to lock: " + entityName);
 			LockMode lockMode = LockMode.NONE;
 			LockOptions lr = new LockOptions();
 			if ( anything instanceof LockOptions) {
 				LockOptions lockOptions = (LockOptions)anything;
 				lr.setTimeOut(lockOptions.getTimeOut());
 				lr.setScope( lockOptions.getScope());
 				if ( lockOptions.getScope() == true )	// cascade specified lockMode
 					lockMode = lockOptions.getLockMode();
 			}
 			lr.setLockMode(lockMode);
 			session.buildLockRequest(lr).lock(entityName, child);
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// lock doesn't cascade to uninitialized collections
 			return getLoadedElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			//TODO: should orphans really be deleted during lock???
 			return false;
 		}
 		@Override
         public String toString() {
 			return "ACTION_LOCK";
 		}
 	};
 
 	/**
 	 * @see org.hibernate.Session#refresh(Object)
 	 */
 	public static final CascadingAction REFRESH = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to refresh: " + entityName);
 			session.refresh( child, (Map) anything );
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// refresh doesn't cascade to uninitialized collections
 			return getLoadedElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			return false;
 		}
 		@Override
         public String toString() {
 			return "ACTION_REFRESH";
 		}
 	};
 
 	/**
 	 * @see org.hibernate.Session#evict(Object)
 	 */
 	public static final CascadingAction EVICT = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to evict: " + entityName);
 			session.evict(child);
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// evicts don't cascade to uninitialized collections
 			return getLoadedElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			return false;
 		}
 		@Override
         public boolean performOnLazyProperty() {
 			return false;
 		}
 		@Override
         public String toString() {
 			return "ACTION_EVICT";
 		}
 	};
 
 	/**
 	 * @see org.hibernate.Session#saveOrUpdate(Object)
 	 */
 	public static final CascadingAction SAVE_UPDATE = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to save or update: " + entityName);
 			session.saveOrUpdate(entityName, child);
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// saves / updates don't cascade to uninitialized collections
 			return getLoadedElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			// orphans should be deleted during save/update
 			return true;
 		}
 		@Override
         public boolean performOnLazyProperty() {
 			return false;
 		}
 		@Override
         public String toString() {
 			return "ACTION_SAVE_UPDATE";
 		}
 	};
 
 	/**
 	 * @see org.hibernate.Session#merge(Object)
 	 */
 	public static final CascadingAction MERGE = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to merge: " + entityName);
 			session.merge( entityName, child, (Map) anything );
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// merges don't cascade to uninitialized collections
 //			//TODO: perhaps this does need to cascade after all....
 			return getLoadedElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			// orphans should not be deleted during merge??
 			return false;
 		}
 		@Override
         public String toString() {
 			return "ACTION_MERGE";
 		}
 	};
 
 	/**
 	 * @see org.hibernate.Session#persist(Object)
 	 */
 	public static final CascadingAction PERSIST = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to persist: " + entityName);
 			session.persist( entityName, child, (Map) anything );
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// persists don't cascade to uninitialized collections
 			return CascadingAction.getAllElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			return false;
 		}
 		@Override
         public boolean performOnLazyProperty() {
 			return false;
 		}
 		@Override
         public String toString() {
 			return "ACTION_PERSIST";
 		}
 	};
 
 	/**
 	 * Execute persist during flush time
 	 *
 	 * @see org.hibernate.Session#persist(Object)
 	 */
 	public static final CascadingAction PERSIST_ON_FLUSH = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to persist on flush: " + entityName);
 			session.persistOnFlush( entityName, child, (Map) anything );
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// persists don't cascade to uninitialized collections
 			return CascadingAction.getLoadedElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			return true;
 		}
 		@Override
         public boolean requiresNoCascadeChecking() {
 			return true;
 		}
 		@Override
         public void noCascade(
 				EventSource session,
 				Object child,
 				Object parent,
 				EntityPersister persister,
 				int propertyIndex) {
 			if ( child == null ) {
 				return;
 			}
 			Type type = persister.getPropertyTypes()[propertyIndex];
 			if ( type.isEntityType() ) {
 				String childEntityName = ( ( EntityType ) type ).getAssociatedEntityName( session.getFactory() );
 
 				if ( ! isInManagedState( child, session )
 						&& ! ( child instanceof HibernateProxy ) //a proxy cannot be transient and it breaks ForeignKeys.isTransient
 						&& ForeignKeys.isTransient( childEntityName, child, null, session ) ) {
 					String parentEntiytName = persister.getEntityName();
 					String propertyName = persister.getPropertyNames()[propertyIndex];
 					throw new TransientObjectException(
 							"object references an unsaved transient instance - " +
 							"save the transient instance before flushing: " +
 							parentEntiytName + "." + propertyName + " -> " + childEntityName
 					);
 
 				}
 			}
 		}
 		@Override
         public boolean performOnLazyProperty() {
 			return false;
 		}
 
 		private boolean isInManagedState(Object child, EventSource session) {
 			EntityEntry entry = session.getPersistenceContext().getEntry( child );
 			return entry != null && (entry.getStatus() == Status.MANAGED || entry.getStatus() == Status.READ_ONLY);
 		}
 
 		@Override
         public String toString() {
 			return "ACTION_PERSIST_ON_FLUSH";
 		}
 	};
 
 	/**
 	 * @see org.hibernate.Session#replicate(Object, org.hibernate.ReplicationMode)
 	 */
 	public static final CascadingAction REPLICATE = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to replicate: " + entityName);
 			session.replicate( entityName, child, (ReplicationMode) anything );
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// replicate does cascade to uninitialized collections
 			return getLoadedElementsIterator(session, collectionType, collection);
 		}
 		@Override
         public boolean deleteOrphans() {
 			return false; //I suppose?
 		}
 		@Override
         public String toString() {
 			return "ACTION_REPLICATE";
 		}
 	};
 
 
 	// static helper methods ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Given a collection, get an iterator of all its children, loading them
 	 * from the database if necessary.
 	 *
 	 * @param session The session within which the cascade is occuring.
 	 * @param collectionType The mapping type of the collection.
 	 * @param collection The collection instance.
 	 * @return The children iterator.
 	 */
 	private static Iterator getAllElementsIterator(
 			EventSource session,
 			CollectionType collectionType,
 			Object collection) {
 		return collectionType.getElementsIterator( collection, session );
 	}
 
 	/**
 	 * Iterate just the elements of the collection that are already there. Don't load
 	 * any new elements from the database.
 	 */
 	public static Iterator getLoadedElementsIterator(SessionImplementor session, CollectionType collectionType, Object collection) {
 		if ( collectionIsInitialized(collection) ) {
 			// handles arrays and newly instantiated collections
 			return collectionType.getElementsIterator(collection, session);
 		}
 		else {
 			// does not handle arrays (thats ok, cos they can't be lazy)
 			// or newly instantiated collections, so we can do the cast
 			return ( (PersistentCollection) collection ).queuedAdditionIterator();
 		}
 	}
 
 	private static boolean collectionIsInitialized(Object collection) {
 		return !(collection instanceof PersistentCollection) || ( (PersistentCollection) collection ).wasInitialized();
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/CollectionEntry.java b/hibernate-core/src/main/java/org/hibernate/engine/CollectionEntry.java
index 3011c46270..deea980558 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/CollectionEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/CollectionEntry.java
@@ -1,416 +1,416 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.Collection;
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.jboss.logging.Logger;
 
 /**
  * We need an entry to tell us all about the current state
  * of a collection with respect to its persistent state
  *
  * @author Gavin King
  */
 public final class CollectionEntry implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, CollectionEntry.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CollectionEntry.class.getName());
 
 	//ATTRIBUTES MAINTAINED BETWEEN FLUSH CYCLES
 
 	// session-start/post-flush persistent state
 	private Serializable snapshot;
 	// allow the CollectionSnapshot to be serialized
 	private String role;
 
 	// "loaded" means the reference that is consistent
 	// with the current database state
 	private transient CollectionPersister loadedPersister;
 	private Serializable loadedKey;
 
 	// ATTRIBUTES USED ONLY DURING FLUSH CYCLE
 
 	// during flush, we navigate the object graph to
 	// collections and decide what to do with them
 	private transient boolean reached;
 	private transient boolean processed;
 	private transient boolean doupdate;
 	private transient boolean doremove;
 	private transient boolean dorecreate;
 	// if we instantiate a collection during the flush() process,
 	// we must ignore it for the rest of the flush()
 	private transient boolean ignore;
 
 	// "current" means the reference that was found during flush()
 	private transient CollectionPersister currentPersister;
 	private transient Serializable currentKey;
 
 	/**
 	 * For newly wrapped collections, or dereferenced collection wrappers
 	 */
 	public CollectionEntry(CollectionPersister persister, PersistentCollection collection) {
 		// new collections that get found + wrapped
 		// during flush shouldn't be ignored
 		ignore = false;
 
 		collection.clearDirty(); //a newly wrapped collection is NOT dirty (or we get unnecessary version updates)
 
 		snapshot = persister.isMutable() ?
 				collection.getSnapshot(persister) :
 				null;
 		collection.setSnapshot(loadedKey, role, snapshot);
 	}
 
 	/**
 	 * For collections just loaded from the database
 	 */
 	public CollectionEntry(
 			final PersistentCollection collection,
 			final CollectionPersister loadedPersister,
 			final Serializable loadedKey,
 			final boolean ignore
 	) {
 		this.ignore=ignore;
 
 		//collection.clearDirty()
 
 		this.loadedKey = loadedKey;
 		setLoadedPersister(loadedPersister);
 
 		collection.setSnapshot(loadedKey, role, null);
 
 		//postInitialize() will be called after initialization
 	}
 
 	/**
 	 * For uninitialized detached collections
 	 */
 	public CollectionEntry(CollectionPersister loadedPersister, Serializable loadedKey) {
 		// detached collection wrappers that get found + reattached
 		// during flush shouldn't be ignored
 		ignore = false;
 
 		//collection.clearDirty()
 
 		this.loadedKey = loadedKey;
 		setLoadedPersister(loadedPersister);
 	}
 
 	/**
 	 * For initialized detached collections
 	 */
 	CollectionEntry(PersistentCollection collection, SessionFactoryImplementor factory)
 	throws MappingException {
 		// detached collections that get found + reattached
 		// during flush shouldn't be ignored
 		ignore = false;
 
 		loadedKey = collection.getKey();
 		setLoadedPersister( factory.getCollectionPersister( collection.getRole() ) );
 
 		snapshot = collection.getStoredSnapshot();
 	}
 
 	/**
 	 * Used from custom serialization.
 	 *
 	 * @see #serialize
 	 * @see #deserialize
 	 */
 	private CollectionEntry(
 			String role,
 	        Serializable snapshot,
 	        Serializable loadedKey,
 	        SessionFactoryImplementor factory) {
 		this.role = role;
 		this.snapshot = snapshot;
 		this.loadedKey = loadedKey;
 		if ( role != null ) {
 			afterDeserialize( factory );
 		}
 	}
 
 	/**
 	 * Determine if the collection is "really" dirty, by checking dirtiness
 	 * of the collection elements, if necessary
 	 */
 	private void dirty(PersistentCollection collection) throws HibernateException {
 
 		boolean forceDirty = collection.wasInitialized() &&
 				!collection.isDirty() && //optimization
 				getLoadedPersister() != null &&
 				getLoadedPersister().isMutable() && //optimization
 				( collection.isDirectlyAccessible() || getLoadedPersister().getElementType().isMutable() ) && //optimization
 				!collection.equalsSnapshot( getLoadedPersister() );
 
 		if ( forceDirty ) {
 			collection.dirty();
 		}
 
 	}
 
 	public void preFlush(PersistentCollection collection) throws HibernateException {
 
 		boolean nonMutableChange = collection.isDirty() &&
 				getLoadedPersister()!=null &&
 				!getLoadedPersister().isMutable();
 		if (nonMutableChange) {
 			throw new HibernateException(
 					"changed an immutable collection instance: " +
 					MessageHelper.collectionInfoString( getLoadedPersister().getRole(), getLoadedKey() )
 				);
 		}
 
 		dirty(collection);
 
         if (LOG.isDebugEnabled() && collection.isDirty() && getLoadedPersister() != null) LOG.debugf("Collection dirty: %s",
                                                                                                      MessageHelper.collectionInfoString(getLoadedPersister().getRole(),
                                                                                                                                         getLoadedKey()));
 
 		setDoupdate(false);
 		setDoremove(false);
 		setDorecreate(false);
 		setReached(false);
 		setProcessed(false);
 	}
 
 	public void postInitialize(PersistentCollection collection) throws HibernateException {
 		snapshot = getLoadedPersister().isMutable() ?
 				collection.getSnapshot( getLoadedPersister() ) :
 				null;
 		collection.setSnapshot(loadedKey, role, snapshot);
 	}
 
 	/**
 	 * Called after a successful flush
 	 */
 	public void postFlush(PersistentCollection collection) throws HibernateException {
 		if ( isIgnore() ) {
 			ignore = false;
 		}
 		else if ( !isProcessed() ) {
 			throw new AssertionFailure( "collection [" + collection.getRole() + "] was not processed by flush()" );
 		}
 		collection.setSnapshot(loadedKey, role, snapshot);
 	}
 
 	/**
 	 * Called after execution of an action
 	 */
 	public void afterAction(PersistentCollection collection) {
 		loadedKey = getCurrentKey();
 		setLoadedPersister( getCurrentPersister() );
 
 		boolean resnapshot = collection.wasInitialized() &&
 				( isDoremove() || isDorecreate() || isDoupdate() );
 		if ( resnapshot ) {
 			snapshot = loadedPersister==null || !loadedPersister.isMutable() ?
 					null :
 					collection.getSnapshot(loadedPersister); //re-snapshot
 		}
 
 		collection.postAction();
 	}
 
 	public Serializable getKey() {
 		return getLoadedKey();
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public Serializable getSnapshot() {
 		return snapshot;
 	}
 
 	private void setLoadedPersister(CollectionPersister persister) {
 		loadedPersister = persister;
 		setRole( persister == null ? null : persister.getRole() );
 	}
 
 	void afterDeserialize(SessionFactoryImplementor factory) {
 		loadedPersister = ( factory == null ? null : factory.getCollectionPersister(role) );
 	}
 
 	public boolean wasDereferenced() {
 		return getLoadedKey() == null;
 	}
 
 	public boolean isReached() {
 		return reached;
 	}
 
 	public void setReached(boolean reached) {
 		this.reached = reached;
 	}
 
 	public boolean isProcessed() {
 		return processed;
 	}
 
 	public void setProcessed(boolean processed) {
 		this.processed = processed;
 	}
 
 	public boolean isDoupdate() {
 		return doupdate;
 	}
 
 	public void setDoupdate(boolean doupdate) {
 		this.doupdate = doupdate;
 	}
 
 	public boolean isDoremove() {
 		return doremove;
 	}
 
 	public void setDoremove(boolean doremove) {
 		this.doremove = doremove;
 	}
 
 	public boolean isDorecreate() {
 		return dorecreate;
 	}
 
 	public void setDorecreate(boolean dorecreate) {
 		this.dorecreate = dorecreate;
 	}
 
 	public boolean isIgnore() {
 		return ignore;
 	}
 
 	public CollectionPersister getCurrentPersister() {
 		return currentPersister;
 	}
 
 	public void setCurrentPersister(CollectionPersister currentPersister) {
 		this.currentPersister = currentPersister;
 	}
 
 	/**
 	 * This is only available late during the flush
 	 * cycle
 	 */
 	public Serializable getCurrentKey() {
 		return currentKey;
 	}
 
 	public void setCurrentKey(Serializable currentKey) {
 		this.currentKey = currentKey;
 	}
 
 	/**
 	 * This is only available late during the flush cycle
 	 */
 	public CollectionPersister getLoadedPersister() {
 		return loadedPersister;
 	}
 
 	public Serializable getLoadedKey() {
 		return loadedKey;
 	}
 
 	public void setRole(String role) {
 		this.role = role;
 	}
 
 	@Override
     public String toString() {
 		String result = "CollectionEntry" +
 				MessageHelper.collectionInfoString( loadedPersister.getRole(), loadedKey );
 		if (currentPersister!=null) {
 			result += "->" +
 					MessageHelper.collectionInfoString( currentPersister.getRole(), currentKey );
 		}
 		return result;
 	}
 
 	/**
 	 * Get the collection orphans (entities which were removed from the collection)
 	 */
 	public Collection getOrphans(String entityName, PersistentCollection collection)
 	throws HibernateException {
 		if (snapshot==null) {
 			throw new AssertionFailure("no collection snapshot for orphan delete");
 		}
 		return collection.getOrphans( snapshot, entityName );
 	}
 
 	public boolean isSnapshotEmpty(PersistentCollection collection) {
 		//TODO: does this really need to be here?
 		//      does the collection already have
 		//      it's own up-to-date snapshot?
 		return collection.wasInitialized() &&
 			( getLoadedPersister()==null || getLoadedPersister().isMutable() ) &&
 			collection.isSnapshotEmpty( getSnapshot() );
 	}
 
 
 
 	/**
 	 * Custom serialization routine used during serialization of a
 	 * Session/PersistenceContext for increased performance.
 	 *
 	 * @param oos The stream to which we should write the serial data.
 	 * @throws java.io.IOException
 	 */
 	void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeObject( role );
 		oos.writeObject( snapshot );
 		oos.writeObject( loadedKey );
 	}
 
 	/**
 	 * Custom deserialization routine used during deserialization of a
 	 * Session/PersistenceContext for increased performance.
 	 *
 	 * @param ois The stream from which to read the entry.
 	 * @param session The session being deserialized.
 	 * @return The deserialized CollectionEntry
 	 * @throws IOException
 	 * @throws ClassNotFoundException
 	 */
 	static CollectionEntry deserialize(
 			ObjectInputStream ois,
 	        SessionImplementor session) throws IOException, ClassNotFoundException {
 		return new CollectionEntry(
 				( String ) ois.readObject(),
 		        ( Serializable ) ois.readObject(),
 		        ( Serializable ) ois.readObject(),
 		        ( session == null ? null : session.getFactory() )
 		);
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/Collections.java b/hibernate-core/src/main/java/org/hibernate/engine/Collections.java
index 9747412240..f8193b74ba 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/Collections.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/Collections.java
@@ -1,261 +1,261 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.CollectionType;
 
 /**
  * Implements book-keeping for the collection persistence by reachability algorithm
  * @author Gavin King
  */
 public final class Collections {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Collections.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Collections.class.getName());
 
 	private Collections() {}
 
 	/**
 	 * record the fact that this collection was dereferenced
 	 *
 	 * @param coll The collection to be updated by unreachability.
 	 * @throws HibernateException
 	 */
 	public static void processUnreachableCollection(PersistentCollection coll, SessionImplementor session)
 	throws HibernateException {
 
 		if ( coll.getOwner()==null ) {
 			processNeverReferencedCollection(coll, session);
 		}
 		else {
 			processDereferencedCollection(coll, session);
 		}
 
 	}
 
 	private static void processDereferencedCollection(PersistentCollection coll, SessionImplementor session)
 	throws HibernateException {
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		CollectionEntry entry = persistenceContext.getCollectionEntry(coll);
 		final CollectionPersister loadedPersister = entry.getLoadedPersister();
 
         if (LOG.isDebugEnabled() && loadedPersister != null) LOG.debugf("Collection dereferenced: %s",
                                                                         MessageHelper.collectionInfoString(loadedPersister,
                                                                                                            entry.getLoadedKey(),
                                                                                                            session.getFactory()));
 
 		// do a check
 		boolean hasOrphanDelete = loadedPersister != null &&
 		                          loadedPersister.hasOrphanDelete();
 		if (hasOrphanDelete) {
 			Serializable ownerId = loadedPersister.getOwnerEntityPersister().getIdentifier( coll.getOwner(), session );
 			if ( ownerId == null ) {
 				// the owning entity may have been deleted and its identifier unset due to
 				// identifier-rollback; in which case, try to look up its identifier from
 				// the persistence context
 				if ( session.getFactory().getSettings().isIdentifierRollbackEnabled() ) {
 					EntityEntry ownerEntry = persistenceContext.getEntry( coll.getOwner() );
 					if ( ownerEntry != null ) {
 						ownerId = ownerEntry.getId();
 					}
 				}
 				if ( ownerId == null ) {
 					throw new AssertionFailure( "Unable to determine collection owner identifier for orphan-delete processing" );
 				}
 			}
 			EntityKey key = session.generateEntityKey( ownerId, loadedPersister.getOwnerEntityPersister() );
 			Object owner = persistenceContext.getEntity(key);
 			if ( owner == null ) {
 				throw new AssertionFailure(
 						"collection owner not associated with session: " +
 						loadedPersister.getRole()
 				);
 			}
 			EntityEntry e = persistenceContext.getEntry(owner);
 			//only collections belonging to deleted entities are allowed to be dereferenced in the case of orphan delete
 			if ( e != null && e.getStatus() != Status.DELETED && e.getStatus() != Status.GONE ) {
 				throw new HibernateException(
 						"A collection with cascade=\"all-delete-orphan\" was no longer referenced by the owning entity instance: " +
 						loadedPersister.getRole()
 				);
 			}
 		}
 
 		// do the work
 		entry.setCurrentPersister(null);
 		entry.setCurrentKey(null);
 		prepareCollectionForUpdate( coll, entry, session.getEntityMode(), session.getFactory() );
 
 	}
 
 	private static void processNeverReferencedCollection(PersistentCollection coll, SessionImplementor session)
 	throws HibernateException {
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		CollectionEntry entry = persistenceContext.getCollectionEntry(coll);
 
         LOG.debugf("Found collection with unloaded owner: %s",
                    MessageHelper.collectionInfoString(entry.getLoadedPersister(), entry.getLoadedKey(), session.getFactory()));
 
 		entry.setCurrentPersister( entry.getLoadedPersister() );
 		entry.setCurrentKey( entry.getLoadedKey() );
 
 		prepareCollectionForUpdate( coll, entry, session.getEntityMode(), session.getFactory() );
 
 	}
 
     /**
      * Initialize the role of the collection.
      *
      * @param collection The collection to be updated by reachability.
      * @param type The type of the collection.
      * @param entity The owner of the collection.
      * @throws HibernateException
      */
 	public static void processReachableCollection(
 			PersistentCollection collection,
 	        CollectionType type,
 	        Object entity,
 	        SessionImplementor session)
 	throws HibernateException {
 
 		collection.setOwner(entity);
 
 		CollectionEntry ce = session.getPersistenceContext().getCollectionEntry(collection);
 
 		if ( ce == null ) {
 			// refer to comment in StatefulPersistenceContext.addCollection()
 			throw new HibernateException(
 					"Found two representations of same collection: " +
 					type.getRole()
 			);
 		}
 
 		// The CollectionEntry.isReached() stuff is just to detect any silly users
 		// who set up circular or shared references between/to collections.
 		if ( ce.isReached() ) {
 			// We've been here before
 			throw new HibernateException(
 					"Found shared references to a collection: " +
 					type.getRole()
 			);
 		}
 		ce.setReached(true);
 
 		SessionFactoryImplementor factory = session.getFactory();
 		CollectionPersister persister = factory.getCollectionPersister( type.getRole() );
 		ce.setCurrentPersister(persister);
 		ce.setCurrentKey( type.getKeyOfOwner(entity, session) ); //TODO: better to pass the id in as an argument?
 
         if (LOG.isDebugEnabled()) {
             if (collection.wasInitialized()) LOG.debugf("Collection found: %s, was: %s (initialized)",
                                                         MessageHelper.collectionInfoString(persister, ce.getCurrentKey(), factory),
                                                         MessageHelper.collectionInfoString(ce.getLoadedPersister(),
                                                                                            ce.getLoadedKey(),
                                                                                            factory));
             else LOG.debugf("Collection found: %s, was: %s (uninitialized)",
                             MessageHelper.collectionInfoString(persister, ce.getCurrentKey(), factory),
                             MessageHelper.collectionInfoString(ce.getLoadedPersister(), ce.getLoadedKey(), factory));
         }
 
 		prepareCollectionForUpdate( collection, ce, session.getEntityMode(), factory );
 
 	}
 
 	/**
 	 * 1. record the collection role that this collection is referenced by
 	 * 2. decide if the collection needs deleting/creating/updating (but
 	 *	don't actually schedule the action yet)
 	 */
 	private static void prepareCollectionForUpdate(
 			PersistentCollection collection,
 	        CollectionEntry entry,
 	        EntityMode entityMode,
 	        SessionFactoryImplementor factory)
 	throws HibernateException {
 
 		if ( entry.isProcessed() ) {
 			throw new AssertionFailure( "collection was processed twice by flush()" );
 		}
 		entry.setProcessed(true);
 
 		final CollectionPersister loadedPersister = entry.getLoadedPersister();
 		final CollectionPersister currentPersister = entry.getCurrentPersister();
 		if ( loadedPersister != null || currentPersister != null ) {					// it is or was referenced _somewhere_
 
 			boolean ownerChanged = loadedPersister != currentPersister ||				// if either its role changed,
 			                       !currentPersister
 					                       .getKeyType().isEqual(                       // or its key changed
 													entry.getLoadedKey(),
 			                                        entry.getCurrentKey(),
 			                                        entityMode, factory
 			                       );
 
 			if (ownerChanged) {
 
 				// do a check
 				final boolean orphanDeleteAndRoleChanged = loadedPersister != null &&
 				                                           currentPersister != null &&
 				                                           loadedPersister.hasOrphanDelete();
 
 				if (orphanDeleteAndRoleChanged) {
 					throw new HibernateException(
 							"Don't change the reference to a collection with cascade=\"all-delete-orphan\": " +
 							loadedPersister.getRole()
 						);
 				}
 
 				// do the work
 				if ( currentPersister != null ) {
 					entry.setDorecreate(true);											// we will need to create new entries
 				}
 
 				if ( loadedPersister != null ) {
 					entry.setDoremove(true);											// we will need to remove ye olde entries
 					if ( entry.isDorecreate() ) {
                         LOG.trace("Forcing collection initialization");
 						collection.forceInitialization();								// force initialize!
 					}
 				}
 
 			}
 			else if ( collection.isDirty() ) {											// else if it's elements changed
 				entry.setDoupdate(true);
 			}
 
 		}
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/IdentifierValue.java b/hibernate-core/src/main/java/org/hibernate/engine/IdentifierValue.java
index 3ba194f3f2..6adcfe38ea 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/IdentifierValue.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/IdentifierValue.java
@@ -1,149 +1,151 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
 import java.io.Serializable;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * A strategy for determining if an identifier value is an identifier of
  * a new transient instance or a previously persistent transient instance.
  * The strategy is determined by the <tt>unsaved-value</tt> attribute in
  * the mapping file.
  *
  * @author Gavin King
  */
 public class IdentifierValue {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, IdentifierValue.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, IdentifierValue.class.getName());
 
 	private final Serializable value;
 
 	/**
 	 * Always assume the transient instance is newly instantiated
 	 */
 	public static final IdentifierValue ANY = new IdentifierValue() {
 		@Override
         public final Boolean isUnsaved(Serializable id) {
             LOG.trace("ID unsaved-value strategy ANY");
 			return Boolean.TRUE;
 		}
 		@Override
         public Serializable getDefaultValue(Serializable currentValue) {
 			return currentValue;
 		}
 		@Override
         public String toString() {
 			return "SAVE_ANY";
 		}
 	};
 
 	/**
 	 * Never assume the transient instance is newly instantiated
 	 */
 	public static final IdentifierValue NONE = new IdentifierValue() {
 		@Override
         public final Boolean isUnsaved(Serializable id) {
             LOG.trace("ID unsaved-value strategy NONE");
 			return Boolean.FALSE;
 		}
 		@Override
         public Serializable getDefaultValue(Serializable currentValue) {
 			return currentValue;
 		}
 		@Override
         public String toString() {
 			return "SAVE_NONE";
 		}
 	};
 
 	/**
 	 * Assume the transient instance is newly instantiated if the identifier
 	 * is null.
 	 */
 	public static final IdentifierValue NULL = new IdentifierValue() {
 		@Override
         public final Boolean isUnsaved(Serializable id) {
             LOG.trace("ID unsaved-value strategy NULL");
 			return id==null ? Boolean.TRUE : Boolean.FALSE;
 		}
 		@Override
         public Serializable getDefaultValue(Serializable currentValue) {
 			return null;
 		}
 		@Override
         public String toString() {
 			return "SAVE_NULL";
 		}
 	};
 
 	/**
 	 * Assume nothing.
 	 */
 	public static final IdentifierValue UNDEFINED = new IdentifierValue() {
 		@Override
         public final Boolean isUnsaved(Serializable id) {
             LOG.trace("ID unsaved-value strategy UNDEFINED");
 			return null;
 		}
 		@Override
         public Serializable getDefaultValue(Serializable currentValue) {
 			return null;
 		}
 		@Override
         public String toString() {
 			return "UNDEFINED";
 		}
 	};
 
 	protected IdentifierValue() {
 		this.value = null;
 	}
 
 	/**
 	 * Assume the transient instance is newly instantiated if
 	 * its identifier is null or equal to <tt>value</tt>
 	 */
 	public IdentifierValue(Serializable value) {
 		this.value = value;
 	}
 
 	/**
 	 * Does the given identifier belong to a new instance?
 	 */
 	public Boolean isUnsaved(Serializable id) {
         LOG.trace("ID unsaved-value: " + value);
 		return id==null || id.equals(value) ? Boolean.TRUE : Boolean.FALSE;
 	}
 
 	public Serializable getDefaultValue(Serializable currentValue) {
 		return value;
 	}
 
 	@Override
     public String toString() {
 		return "identifier unsaved-value: " + value;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/ParameterBinder.java b/hibernate-core/src/main/java/org/hibernate/engine/ParameterBinder.java
index 5e45dc0800..9dc3570fdd 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/ParameterBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/ParameterBinder.java
@@ -1,129 +1,129 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Map;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Centralizes the commonality regarding binding of parameter values into
  * PreparedStatements as this logic is used in many places.
  * <p/>
  * Ideally would like to move to the parameter handling as it is done in
  * the hql.ast package.
  *
  * @author Steve Ebersole
  */
 public class ParameterBinder {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ParameterBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ParameterBinder.class.getName());
 
 	public static interface NamedParameterSource {
 		public int[] getNamedParameterLocations(String name);
 	}
 
 	private ParameterBinder() {
 	}
 
 	public static int bindQueryParameters(
 	        final PreparedStatement st,
 	        final QueryParameters queryParameters,
 	        final int start,
 	        final NamedParameterSource source,
 	        SessionImplementor session) throws SQLException, HibernateException {
 		int col = start;
 		col += bindPositionalParameters( st, queryParameters, col, session );
 		col += bindNamedParameters( st, queryParameters, col, source, session );
 		return col;
 	}
 
 	public static int bindPositionalParameters(
 	        final PreparedStatement st,
 	        final QueryParameters queryParameters,
 	        final int start,
 	        final SessionImplementor session) throws SQLException, HibernateException {
 		return bindPositionalParameters(
 		        st,
 		        queryParameters.getPositionalParameterValues(),
 		        queryParameters.getPositionalParameterTypes(),
 		        start,
 		        session
 		);
 	}
 
 	public static int bindPositionalParameters(
 	        final PreparedStatement st,
 	        final Object[] values,
 	        final Type[] types,
 	        final int start,
 	        final SessionImplementor session) throws SQLException, HibernateException {
 		int span = 0;
 		for ( int i = 0; i < values.length; i++ ) {
 			types[i].nullSafeSet( st, values[i], start + span, session );
 			span += types[i].getColumnSpan( session.getFactory() );
 		}
 		return span;
 	}
 
 	public static int bindNamedParameters(
 	        final PreparedStatement ps,
 	        final QueryParameters queryParameters,
 	        final int start,
 	        final NamedParameterSource source,
 	        final SessionImplementor session) throws SQLException, HibernateException {
 		return bindNamedParameters( ps, queryParameters.getNamedParameters(), start, source, session );
 	}
 
 	public static int bindNamedParameters(
 	        final PreparedStatement ps,
 	        final Map namedParams,
 	        final int start,
 	        final NamedParameterSource source,
 	        final SessionImplementor session) throws SQLException, HibernateException {
 		if ( namedParams != null ) {
 			// assumes that types are all of span 1
 			Iterator iter = namedParams.entrySet().iterator();
 			int result = 0;
 			while ( iter.hasNext() ) {
 				Map.Entry e = ( Map.Entry ) iter.next();
 				String name = ( String ) e.getKey();
 				TypedValue typedval = ( TypedValue ) e.getValue();
 				int[] locations = source.getNamedParameterLocations( name );
 				for ( int i = 0; i < locations.length; i++ ) {
                     LOG.debugf("bindNamedParameters() %s -> %s [%s]", typedval.getValue(), name, locations[i] + start);
 					typedval.getType().nullSafeSet( ps, typedval.getValue(), locations[i] + start, session );
 				}
 				result += locations.length;
 			}
 			return result;
 		}
         return 0;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/QueryParameters.java b/hibernate-core/src/main/java/org/hibernate/engine/QueryParameters.java
index 237ecfc9f5..b0f371e7fb 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/QueryParameters.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/QueryParameters.java
@@ -1,562 +1,562 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.StringTokenizer;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.hql.classic.ParserHelper;
 import org.hibernate.impl.FilterImpl;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.pretty.Printer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * @author Gavin King
  */
 public final class QueryParameters {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, QueryParameters.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QueryParameters.class.getName());
 
 	private Type[] positionalParameterTypes;
 	private Object[] positionalParameterValues;
 	private Map namedParameters;
 	private LockOptions lockOptions;
 	private RowSelection rowSelection;
 	private boolean cacheable;
 	private String cacheRegion;
 	private String comment;
 	private ScrollMode scrollMode;
 	private Serializable[] collectionKeys;
 	private Object optionalObject;
 	private String optionalEntityName;
 	private Serializable optionalId;
 	private boolean isReadOnlyInitialized;
 	private boolean readOnly;
 	private boolean callable = false;
 	private boolean autodiscovertypes = false;
 	private boolean isNaturalKeyLookup;
 
 	private final ResultTransformer resultTransformer; // why is all others non final ?
 
 	private String processedSQL;
 	private Type[] processedPositionalParameterTypes;
 	private Object[] processedPositionalParameterValues;
 
 	public QueryParameters() {
 		this( ArrayHelper.EMPTY_TYPE_ARRAY, ArrayHelper.EMPTY_OBJECT_ARRAY );
 	}
 
 	public QueryParameters(Type type, Object value) {
 		this( new Type[] { type }, new Object[] { value } );
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] postionalParameterValues,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalObjectId) {
 		this( positionalParameterTypes, postionalParameterValues );
 		this.optionalObject = optionalObject;
 		this.optionalId = optionalObjectId;
 		this.optionalEntityName = optionalEntityName;
 
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] postionalParameterValues) {
 		this( positionalParameterTypes, postionalParameterValues, null, null, false, false, false, null, null, false, null );
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] postionalParameterValues,
 			final Serializable[] collectionKeys) {
 		this( positionalParameterTypes, postionalParameterValues, null, collectionKeys );
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] postionalParameterValues,
 			final Map namedParameters,
 			final Serializable[] collectionKeys) {
 		this(
 				positionalParameterTypes,
 				postionalParameterValues,
 				namedParameters,
 				null,
 				null,
 				false,
 				false,
 				false,
 				null,
 				null,
 				collectionKeys,
 				null
 		);
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final LockOptions lockOptions,
 			final RowSelection rowSelection,
 			final boolean isReadOnlyInitialized,
 			final boolean readOnly,
 			final boolean cacheable,
 			final String cacheRegion,
 			//final boolean forceCacheRefresh,
 			final String comment,
 			final boolean isLookupByNaturalKey,
 			final ResultTransformer transformer) {
 		this(
 				positionalParameterTypes,
 				positionalParameterValues,
 				null,
 				lockOptions,
 				rowSelection,
 				isReadOnlyInitialized,
 				readOnly,
 				cacheable,
 				cacheRegion,
 				comment,
 				null,
 				transformer
 		);
 		isNaturalKeyLookup = isLookupByNaturalKey;
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final Map namedParameters,
 			final LockOptions lockOptions,
 			final RowSelection rowSelection,
 			final boolean isReadOnlyInitialized,
 			final boolean readOnly,
 			final boolean cacheable,
 			final String cacheRegion,
 			//final boolean forceCacheRefresh,
 			final String comment,
 			final Serializable[] collectionKeys,
 			ResultTransformer transformer) {
 		this.positionalParameterTypes = positionalParameterTypes;
 		this.positionalParameterValues = positionalParameterValues;
 		this.namedParameters = namedParameters;
 		this.lockOptions = lockOptions;
 		this.rowSelection = rowSelection;
 		this.cacheable = cacheable;
 		this.cacheRegion = cacheRegion;
 		//this.forceCacheRefresh = forceCacheRefresh;
 		this.comment = comment;
 		this.collectionKeys = collectionKeys;
 		this.isReadOnlyInitialized = isReadOnlyInitialized;
 		this.readOnly = readOnly;
 		this.resultTransformer = transformer;
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final Map namedParameters,
 			final LockOptions lockOptions,
 			final RowSelection rowSelection,
 			final boolean isReadOnlyInitialized,
 			final boolean readOnly,
 			final boolean cacheable,
 			final String cacheRegion,
 			//final boolean forceCacheRefresh,
 			final String comment,
 			final Serializable[] collectionKeys,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalId,
 			final ResultTransformer transformer) {
 		this(
 				positionalParameterTypes,
 				positionalParameterValues,
 				namedParameters,
 				lockOptions,
 				rowSelection,
 				isReadOnlyInitialized,
 				readOnly,
 				cacheable,
 				cacheRegion,
 				comment,
 				collectionKeys,
 				transformer
 		);
 		this.optionalEntityName = optionalEntityName;
 		this.optionalId = optionalId;
 		this.optionalObject = optionalObject;
 	}
 
 	public boolean hasRowSelection() {
 		return rowSelection != null;
 	}
 
 	public Map getNamedParameters() {
 		return namedParameters;
 	}
 
 	public Type[] getPositionalParameterTypes() {
 		return positionalParameterTypes;
 	}
 
 	public Object[] getPositionalParameterValues() {
 		return positionalParameterValues;
 	}
 
 	public RowSelection getRowSelection() {
 		return rowSelection;
 	}
 
 	public ResultTransformer getResultTransformer() {
 		return resultTransformer;
 	}
 
 	public void setNamedParameters(Map map) {
 		namedParameters = map;
 	}
 
 	public void setPositionalParameterTypes(Type[] types) {
 		positionalParameterTypes = types;
 	}
 
 	public void setPositionalParameterValues(Object[] objects) {
 		positionalParameterValues = objects;
 	}
 
 	public void setRowSelection(RowSelection selection) {
 		rowSelection = selection;
 	}
 
 	public LockOptions getLockOptions() {
 		return lockOptions;
 	}
 
 	public void setLockOptions(LockOptions lockOptions) {
 		this.lockOptions = lockOptions;
 	}
 
 	public void traceParameters(SessionFactoryImplementor factory) throws HibernateException {
 		Printer print = new Printer( factory );
         if (positionalParameterValues.length != 0) LOG.trace("Parameters: "
                                                              + print.toString(positionalParameterTypes, positionalParameterValues));
         if (namedParameters != null) LOG.trace("Named parameters: " + print.toString(namedParameters));
 	}
 
 	public boolean isCacheable() {
 		return cacheable;
 	}
 
 	public void setCacheable(boolean b) {
 		cacheable = b;
 	}
 
 	public String getCacheRegion() {
 		return cacheRegion;
 	}
 
 	public void setCacheRegion(String cacheRegion) {
 		this.cacheRegion = cacheRegion;
 	}
 
 	public void validateParameters() throws QueryException {
 		int types = positionalParameterTypes == null ? 0 : positionalParameterTypes.length;
 		int values = positionalParameterValues == null ? 0 : positionalParameterValues.length;
 		if ( types != values ) {
 			throw new QueryException(
 					"Number of positional parameter types:" + types +
 							" does not match number of positional parameters: " + values
 			);
 		}
 	}
 
 	public String getComment() {
 		return comment;
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public ScrollMode getScrollMode() {
 		return scrollMode;
 	}
 
 	public void setScrollMode(ScrollMode scrollMode) {
 		this.scrollMode = scrollMode;
 	}
 
 	public Serializable[] getCollectionKeys() {
 		return collectionKeys;
 	}
 
 	public void setCollectionKeys(Serializable[] collectionKeys) {
 		this.collectionKeys = collectionKeys;
 	}
 
 	public String getOptionalEntityName() {
 		return optionalEntityName;
 	}
 
 	public void setOptionalEntityName(String optionalEntityName) {
 		this.optionalEntityName = optionalEntityName;
 	}
 
 	public Serializable getOptionalId() {
 		return optionalId;
 	}
 
 	public void setOptionalId(Serializable optionalId) {
 		this.optionalId = optionalId;
 	}
 
 	public Object getOptionalObject() {
 		return optionalObject;
 	}
 
 	public void setOptionalObject(Object optionalObject) {
 		this.optionalObject = optionalObject;
 	}
 
 	/**
 	 * Has the read-only/modifiable mode been explicitly set?
 	 * @see QueryParameters#setReadOnly(boolean)
 	 * @see QueryParameters#isReadOnly(SessionImplementor)
 	 *
 	 * @return true, the read-only/modifiable mode was explicitly set
 	 *         false, the read-only/modifiable mode was not explicitly set
 	 */
 	public boolean isReadOnlyInitialized() {
 		return isReadOnlyInitialized;
 	}
 
 	/**
 	 * Should entities and proxies loaded by the Query be put in read-only mode? The
 	 * read-only/modifiable setting must be initialized via QueryParameters#setReadOnly(boolean)
 	 * before calling this method.
 	 *
 	 * @see QueryParameters#isReadOnlyInitialized()
 	 * @see QueryParameters#isReadOnly(SessionImplementor)
 	 * @see QueryParameters#setReadOnly(boolean)
 	 *
 	 * The read-only/modifiable setting has no impact on entities/proxies returned by the
 	 * query that existed in the session before the query was executed.
 	 *
 	 * @return true, entities and proxies loaded by the Query will be put in read-only mode
 	 *         false, entities and proxies loaded by the Query will be put in modifiable mode
 	 * @throws IllegalStateException if the read-only/modifiable setting has not been
 	 * initialized (i.e., isReadOnlyInitialized() == false).
 	 */
 	public boolean isReadOnly() {
 		if ( ! isReadOnlyInitialized() ) {
 			throw new IllegalStateException( "cannot call isReadOnly() when isReadOnlyInitialized() returns false" );
 		}
 		return readOnly;
 	}
 
 	/**
 	 * Should entities and proxies loaded by the Query be put in read-only mode? If the
 	 * read-only/modifiable setting was not initialized
 	 * (i.e., QueryParameters#isReadOnlyInitialized() == false), then the default
 	 * read-only/modifiable setting for the persistence context is returned instead.
 	 *
 	 * @see QueryParameters#isReadOnlyInitialized()
 	 * @see QueryParameters#setReadOnly(boolean)
 	 * @see org.hibernate.engine.PersistenceContext#isDefaultReadOnly()
 	 *
 	 * The read-only/modifiable setting has no impact on entities/proxies returned by the
 	 * query that existed in the session before the query was executed.
 	 *
 	 * @return true, entities and proxies loaded by the query will be put in read-only mode
 	 *         false, entities and proxies loaded by the query will be put in modifiable mode
 	 */
 	public boolean isReadOnly(SessionImplementor session) {
 		return ( isReadOnlyInitialized ?
 				isReadOnly() :
 				session.getPersistenceContext().isDefaultReadOnly()
 		);
 	}
 
 	/**
 	 * Set the read-only/modifiable mode for entities and proxies loaded by the query.
 	 * 	 *
 	 * @see QueryParameters#isReadOnlyInitialized()
 	 * @see QueryParameters#isReadOnly(SessionImplementor)
 	 * @see QueryParameters#setReadOnly(boolean)
 	 * @see org.hibernate.engine.PersistenceContext#isDefaultReadOnly()
 	 *
 	 * The read-only/modifiable setting has no impact on entities/proxies returned by the
 	 * query that existed in the session before the query was executed.
 	 *
 	 * @return true, entities and proxies loaded by the query will be put in read-only mode
 	 *         false, entities and proxies loaded by the query will be put in modifiable mode
 	 */
 	public void setReadOnly(boolean readOnly) {
 		this.readOnly = readOnly;
 		this.isReadOnlyInitialized = true;
 	}
 
 	public void setCallable(boolean callable) {
 		this.callable = callable;
 	}
 
 	public boolean isCallable() {
 		return callable;
 	}
 
 	public boolean hasAutoDiscoverScalarTypes() {
 		return autodiscovertypes;
 	}
 
 	public void processFilters(String sql, SessionImplementor session) {
 		processFilters( sql, session.getLoadQueryInfluencers().getEnabledFilters(), session.getFactory() );
 	}
 
 	public void processFilters(String sql, Map filters, SessionFactoryImplementor factory) {
 		if ( filters.size() == 0 || sql.indexOf( ParserHelper.HQL_VARIABLE_PREFIX ) < 0 ) {
 			// HELLA IMPORTANT OPTIMIZATION!!!
 			processedPositionalParameterValues = getPositionalParameterValues();
 			processedPositionalParameterTypes = getPositionalParameterTypes();
 			processedSQL = sql;
 		}
 		else {
 			final Dialect dialect = factory.getDialect();
 			String symbols = new StringBuffer().append( ParserHelper.HQL_SEPARATORS )
 					.append( dialect.openQuote() )
 					.append( dialect.closeQuote() )
 					.toString();
 			StringTokenizer tokens = new StringTokenizer( sql, symbols, true );
 			StringBuffer result = new StringBuffer();
 
 			List parameters = new ArrayList();
 			List parameterTypes = new ArrayList();
 
 			int positionalIndex = 0;
 			while ( tokens.hasMoreTokens() ) {
 				final String token = tokens.nextToken();
 				if ( token.startsWith( ParserHelper.HQL_VARIABLE_PREFIX ) ) {
 					final String filterParameterName = token.substring( 1 );
 					final String[] parts = LoadQueryInfluencers.parseFilterParameterName( filterParameterName );
 					final FilterImpl filter = ( FilterImpl ) filters.get( parts[0] );
 					final Object value = filter.getParameter( parts[1] );
 					final Type type = filter.getFilterDefinition().getParameterType( parts[1] );
 					if ( value != null && Collection.class.isAssignableFrom( value.getClass() ) ) {
 						Iterator itr = ( ( Collection ) value ).iterator();
 						while ( itr.hasNext() ) {
 							Object elementValue = itr.next();
 							result.append( '?' );
 							parameters.add( elementValue );
 							parameterTypes.add( type );
 							if ( itr.hasNext() ) {
 								result.append( ", " );
 							}
 						}
 					}
 					else {
 						result.append( '?' );
 						parameters.add( value );
 						parameterTypes.add( type );
 					}
 				}
 				else {
 					if ( "?".equals( token ) && positionalIndex < getPositionalParameterValues().length ) {
 						parameters.add( getPositionalParameterValues()[positionalIndex] );
 						parameterTypes.add( getPositionalParameterTypes()[positionalIndex] );
 						positionalIndex++;
 					}
 					result.append( token );
 				}
 			}
 			processedPositionalParameterValues = parameters.toArray();
 			processedPositionalParameterTypes = ( Type[] ) parameterTypes.toArray( new Type[parameterTypes.size()] );
 			processedSQL = result.toString();
 		}
 	}
 
 	public String getFilteredSQL() {
 		return processedSQL;
 	}
 
 	public Object[] getFilteredPositionalParameterValues() {
 		return processedPositionalParameterValues;
 	}
 
 	public Type[] getFilteredPositionalParameterTypes() {
 		return processedPositionalParameterTypes;
 	}
 
 	public boolean isNaturalKeyLookup() {
 		return isNaturalKeyLookup;
 	}
 
 	public void setNaturalKeyLookup(boolean isNaturalKeyLookup) {
 		this.isNaturalKeyLookup = isNaturalKeyLookup;
 	}
 
 	public void setAutoDiscoverScalarTypes(boolean autodiscovertypes) {
 		this.autodiscovertypes = autodiscovertypes;
 	}
 
 	public QueryParameters createCopyUsing(RowSelection selection) {
 		QueryParameters copy = new QueryParameters(
 				this.positionalParameterTypes,
 				this.positionalParameterValues,
 				this.namedParameters,
 				this.lockOptions,
 				selection,
 				this.isReadOnlyInitialized,
 				this.readOnly,
 				this.cacheable,
 				this.cacheRegion,
 				this.comment,
 				this.collectionKeys,
 				this.optionalObject,
 				this.optionalEntityName,
 				this.optionalId,
 				this.resultTransformer
 		);
 		copy.processedSQL = this.processedSQL;
 		copy.processedPositionalParameterTypes = this.processedPositionalParameterTypes;
 		copy.processedPositionalParameterValues = this.processedPositionalParameterValues;
 		return copy;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/StatefulPersistenceContext.java b/hibernate-core/src/main/java/org/hibernate/engine/StatefulPersistenceContext.java
index 8a3419e73d..617e7d5ae6 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/StatefulPersistenceContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/StatefulPersistenceContext.java
@@ -1,1080 +1,1080 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.apache.commons.collections.map.AbstractReferenceMap;
 import org.apache.commons.collections.map.ReferenceMap;
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.NonUniqueObjectException;
 import org.hibernate.PersistentObjectException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.loading.LoadContexts;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.collections.IdentityMap;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.tuple.ElementWrapper;
 
 import static org.jboss.logging.Logger.Level.WARN;
 
 /**
  * A <tt>PersistenceContext</tt> represents the state of persistent "stuff" which
  * Hibernate is tracking.  This includes persistent entities, collections,
  * as well as proxies generated.
  * </p>
  * There is meant to be a one-to-one correspondence between a SessionImpl and
  * a PersistentContext.  The SessionImpl uses the PersistentContext to track
  * the current state of its context.  Event-listeners then use the
  * PersistentContext to drive their processing.
  *
  * @author Steve Ebersole
  */
 public class StatefulPersistenceContext implements PersistenceContext {
 
 	public static final Object NO_ROW = new MarkerObject( "NO_ROW" );
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        StatefulPersistenceContext.class.getName());
 	private static final int INIT_COLL_SIZE = 8;
 
 	private SessionImplementor session;
 
 	// Loaded entity instances, by EntityKey
 	private Map entitiesByKey;
 
 	// Loaded entity instances, by EntityUniqueKey
 	private Map entitiesByUniqueKey;
 
 	// Identity map of EntityEntry instances, by the entity instance
 	private Map entityEntries;
 
 	// Entity proxies, by EntityKey
 	private Map proxiesByKey;
 
 	// Snapshots of current database state for entities
 	// that have *not* been loaded
 	private Map entitySnapshotsByKey;
 
 	// Identity map of array holder ArrayHolder instances, by the array instance
 	private Map arrayHolders;
 
 	// Identity map of CollectionEntry instances, by the collection wrapper
 	private Map collectionEntries;
 
 	// Collection wrappers, by the CollectionKey
 	private Map collectionsByKey; //key=CollectionKey, value=PersistentCollection
 
 	// Set of EntityKeys of deleted objects
 	private HashSet nullifiableEntityKeys;
 
 	// properties that we have tried to load, and not found in the database
 	private HashSet nullAssociations;
 
 	// A list of collection wrappers that were instantiating during result set
 	// processing, that we will need to initialize at the end of the query
 	private List nonlazyCollections;
 
 	// A container for collections we load up when the owning entity is not
 	// yet loaded ... for now, this is purely transient!
 	private Map unownedCollections;
 
 	// Parent entities cache by their child for cascading
 	// May be empty or not contains all relation
 	private Map parentsByChild;
 
 	private int cascading = 0;
 	private int loadCounter = 0;
 	private boolean flushing = false;
 
 	private boolean defaultReadOnly = false;
 	private boolean hasNonReadOnlyEntities = false;
 
 	private LoadContexts loadContexts;
 	private BatchFetchQueue batchFetchQueue;
 
 
 
 	/**
 	 * Constructs a PersistentContext, bound to the given session.
 	 *
 	 * @param session The session "owning" this context.
 	 */
 	public StatefulPersistenceContext(SessionImplementor session) {
 		this.session = session;
 
 		entitiesByKey = new HashMap( INIT_COLL_SIZE );
 		entitiesByUniqueKey = new HashMap( INIT_COLL_SIZE );
 		proxiesByKey = new ReferenceMap( AbstractReferenceMap.HARD, AbstractReferenceMap.WEAK );
 		entitySnapshotsByKey = new HashMap( INIT_COLL_SIZE );
 
 		entityEntries = IdentityMap.instantiateSequenced( INIT_COLL_SIZE );
 		collectionEntries = IdentityMap.instantiateSequenced( INIT_COLL_SIZE );
 		collectionsByKey = new HashMap( INIT_COLL_SIZE );
 		arrayHolders = IdentityMap.instantiate( INIT_COLL_SIZE );
 		parentsByChild = IdentityMap.instantiateSequenced( INIT_COLL_SIZE );
 
 		nullifiableEntityKeys = new HashSet();
 
 		initTransientState();
 	}
 
 	private void initTransientState() {
 		nullAssociations = new HashSet( INIT_COLL_SIZE );
 		nonlazyCollections = new ArrayList( INIT_COLL_SIZE );
 	}
 
 	public boolean isStateless() {
 		return false;
 	}
 
 	public SessionImplementor getSession() {
 		return session;
 	}
 
 	public LoadContexts getLoadContexts() {
 		if ( loadContexts == null ) {
 			loadContexts = new LoadContexts( this );
 		}
 		return loadContexts;
 	}
 
 	public void addUnownedCollection(CollectionKey key, PersistentCollection collection) {
 		if (unownedCollections==null) {
 			unownedCollections = new HashMap(8);
 		}
 		unownedCollections.put(key, collection);
 	}
 
 	public PersistentCollection useUnownedCollection(CollectionKey key) {
 		if (unownedCollections==null) {
 			return null;
 		}
 		else {
 			return (PersistentCollection) unownedCollections.remove(key);
 		}
 	}
 
 	/**
 	 * Get the <tt>BatchFetchQueue</tt>, instantiating one if
 	 * necessary.
 	 */
 	public BatchFetchQueue getBatchFetchQueue() {
 		if (batchFetchQueue==null) {
 			batchFetchQueue = new BatchFetchQueue(this);
 		}
 		return batchFetchQueue;
 	}
 
 	public void clear() {
 		Iterator itr = proxiesByKey.values().iterator();
 		while ( itr.hasNext() ) {
 			final LazyInitializer li = ( ( HibernateProxy ) itr.next() ).getHibernateLazyInitializer();
 			li.unsetSession();
 		}
 		Map.Entry[] collectionEntryArray = IdentityMap.concurrentEntries( collectionEntries );
 		for ( int i = 0; i < collectionEntryArray.length; i++ ) {
 			( ( PersistentCollection ) collectionEntryArray[i].getKey() ).unsetSession( getSession() );
 		}
 		arrayHolders.clear();
 		entitiesByKey.clear();
 		entitiesByUniqueKey.clear();
 		entityEntries.clear();
 		parentsByChild.clear();
 		entitySnapshotsByKey.clear();
 		collectionsByKey.clear();
 		collectionEntries.clear();
 		if ( unownedCollections != null ) {
 			unownedCollections.clear();
 		}
 		proxiesByKey.clear();
 		nullifiableEntityKeys.clear();
 		if ( batchFetchQueue != null ) {
 			batchFetchQueue.clear();
 		}
 		// defaultReadOnly is unaffected by clear()
 		hasNonReadOnlyEntities = false;
 		if ( loadContexts != null ) {
 			loadContexts.cleanup();
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public boolean isDefaultReadOnly() {
 		return defaultReadOnly;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void setDefaultReadOnly(boolean defaultReadOnly) {
 		this.defaultReadOnly = defaultReadOnly;
 	}
 
 	public boolean hasNonReadOnlyEntities() {
 		return hasNonReadOnlyEntities;
 	}
 
 	public void setEntryStatus(EntityEntry entry, Status status) {
 		entry.setStatus(status);
 		setHasNonReadOnlyEnties(status);
 	}
 
 	private void setHasNonReadOnlyEnties(Status status) {
 		if ( status==Status.DELETED || status==Status.MANAGED || status==Status.SAVING ) {
 			hasNonReadOnlyEntities = true;
 		}
 	}
 
 	public void afterTransactionCompletion() {
 		cleanUpInsertedKeysAfterTransaction();
 		// Downgrade locks
 		Iterator iter = entityEntries.values().iterator();
 		while ( iter.hasNext() ) {
 			( (EntityEntry) iter.next() ).setLockMode(LockMode.NONE);
 		}
 	}
 
 	/**
 	 * Get the current state of the entity as known to the underlying
 	 * database, or null if there is no corresponding row
 	 */
 	public Object[] getDatabaseSnapshot(Serializable id, EntityPersister persister)
 	throws HibernateException {
 		final EntityKey key = session.generateEntityKey( id, persister );
 		Object cached = entitySnapshotsByKey.get(key);
 		if (cached!=null) {
 			return cached==NO_ROW ? null : (Object[]) cached;
 		}
 		else {
 			Object[] snapshot = persister.getDatabaseSnapshot( id, session );
 			entitySnapshotsByKey.put( key, snapshot==null ? NO_ROW : snapshot );
 			return snapshot;
 		}
 	}
 
 	public Object[] getNaturalIdSnapshot(Serializable id, EntityPersister persister)
 	throws HibernateException {
 		if ( !persister.hasNaturalIdentifier() ) {
 			return null;
 		}
 
 		// if the natural-id is marked as non-mutable, it is not retrieved during a
 		// normal database-snapshot operation...
 		int[] props = persister.getNaturalIdentifierProperties();
 		boolean[] updateable = persister.getPropertyUpdateability();
 		boolean allNatualIdPropsAreUpdateable = true;
 		for ( int i = 0; i < props.length; i++ ) {
 			if ( !updateable[ props[i] ] ) {
 				allNatualIdPropsAreUpdateable = false;
 				break;
 			}
 		}
 
 		if ( allNatualIdPropsAreUpdateable ) {
 			// do this when all the properties are updateable since there is
 			// a certain likelihood that the information will already be
 			// snapshot-cached.
 			Object[] entitySnapshot = getDatabaseSnapshot( id, persister );
 			if ( entitySnapshot == NO_ROW ) {
 				return null;
 			}
 			Object[] naturalIdSnapshot = new Object[ props.length ];
 			for ( int i = 0; i < props.length; i++ ) {
 				naturalIdSnapshot[i] = entitySnapshot[ props[i] ];
 			}
 			return naturalIdSnapshot;
 		}
 		else {
 			return persister.getNaturalIdentifierSnapshot( id, session );
 		}
 	}
 
 	/**
 	 * Retrieve the cached database snapshot for the requested entity key.
 	 * <p/>
 	 * This differs from {@link #getDatabaseSnapshot} is two important respects:<ol>
 	 * <li>no snapshot is obtained from the database if not already cached</li>
 	 * <li>an entry of {@link #NO_ROW} here is interpretet as an exception</li>
 	 * </ol>
 	 * @param key The entity key for which to retrieve the cached snapshot
 	 * @return The cached snapshot
 	 * @throws IllegalStateException if the cached snapshot was == {@link #NO_ROW}.
 	 */
 	public Object[] getCachedDatabaseSnapshot(EntityKey key) {
 		Object snapshot = entitySnapshotsByKey.get( key );
 		if ( snapshot == NO_ROW ) {
 			throw new IllegalStateException( "persistence context reported no row snapshot for " + MessageHelper.infoString( key.getEntityName(), key.getIdentifier() ) );
 		}
 		return ( Object[] ) snapshot;
 	}
 
 	/*public void removeDatabaseSnapshot(EntityKey key) {
 		entitySnapshotsByKey.remove(key);
 	}*/
 
 	public void addEntity(EntityKey key, Object entity) {
 		entitiesByKey.put(key, entity);
 		getBatchFetchQueue().removeBatchLoadableEntityKey(key);
 	}
 
 	/**
 	 * Get the entity instance associated with the given
 	 * <tt>EntityKey</tt>
 	 */
 	public Object getEntity(EntityKey key) {
 		return entitiesByKey.get(key);
 	}
 
 	public boolean containsEntity(EntityKey key) {
 		return entitiesByKey.containsKey(key);
 	}
 
 	/**
 	 * Remove an entity from the session cache, also clear
 	 * up other state associated with the entity, all except
 	 * for the <tt>EntityEntry</tt>
 	 */
 	public Object removeEntity(EntityKey key) {
 		Object entity = entitiesByKey.remove(key);
 		Iterator iter = entitiesByUniqueKey.values().iterator();
 		while ( iter.hasNext() ) {
 			if ( iter.next()==entity ) iter.remove();
 		}
 		// Clear all parent cache
 		parentsByChild.clear();
 		entitySnapshotsByKey.remove(key);
 		nullifiableEntityKeys.remove(key);
 		getBatchFetchQueue().removeBatchLoadableEntityKey(key);
 		getBatchFetchQueue().removeSubselect(key);
 		return entity;
 	}
 
 	/**
 	 * Get an entity cached by unique key
 	 */
 	public Object getEntity(EntityUniqueKey euk) {
 		return entitiesByUniqueKey.get(euk);
 	}
 
 	/**
 	 * Add an entity to the cache by unique key
 	 */
 	public void addEntity(EntityUniqueKey euk, Object entity) {
 		entitiesByUniqueKey.put(euk, entity);
 	}
 
 	/**
 	 * Retreive the EntityEntry representation of the given entity.
 	 *
 	 * @param entity The entity for which to locate the EntityEntry.
 	 * @return The EntityEntry for the given entity.
 	 */
 	public EntityEntry getEntry(Object entity) {
 		return (EntityEntry) entityEntries.get(entity);
 	}
 
 	/**
 	 * Remove an entity entry from the session cache
 	 */
 	public EntityEntry removeEntry(Object entity) {
 		return (EntityEntry) entityEntries.remove(entity);
 	}
 
 	/**
 	 * Is there an EntityEntry for this instance?
 	 */
 	public boolean isEntryFor(Object entity) {
 		return entityEntries.containsKey(entity);
 	}
 
 	/**
 	 * Get the collection entry for a persistent collection
 	 */
 	public CollectionEntry getCollectionEntry(PersistentCollection coll) {
 		return (CollectionEntry) collectionEntries.get(coll);
 	}
 
 	/**
 	 * Adds an entity to the internal caches.
 	 */
 	public EntityEntry addEntity(
 			final Object entity,
 			final Status status,
 			final Object[] loadedState,
 			final EntityKey entityKey,
 			final Object version,
 			final LockMode lockMode,
 			final boolean existsInDatabase,
 			final EntityPersister persister,
 			final boolean disableVersionIncrement,
 			boolean lazyPropertiesAreUnfetched
 	) {
 
 		addEntity( entityKey, entity );
 
 		return addEntry(
 				entity,
 				status,
 				loadedState,
 				null,
 				entityKey.getIdentifier(),
 				version,
 				lockMode,
 				existsInDatabase,
 				persister,
 				disableVersionIncrement,
 				lazyPropertiesAreUnfetched
 			);
 	}
 
 
 	/**
 	 * Generates an appropriate EntityEntry instance and adds it
 	 * to the event source's internal caches.
 	 */
 	public EntityEntry addEntry(
 			final Object entity,
 			final Status status,
 			final Object[] loadedState,
 			final Object rowId,
 			final Serializable id,
 			final Object version,
 			final LockMode lockMode,
 			final boolean existsInDatabase,
 			final EntityPersister persister,
 			final boolean disableVersionIncrement,
 			boolean lazyPropertiesAreUnfetched) {
 
 		EntityEntry e = new EntityEntry(
 				status,
 				loadedState,
 				rowId,
 				id,
 				version,
 				lockMode,
 				existsInDatabase,
 				persister,
 				session.getEntityMode(),
 				session.getTenantIdentifier(),
 				disableVersionIncrement,
 				lazyPropertiesAreUnfetched
 		);
 		entityEntries.put(entity, e);
 
 		setHasNonReadOnlyEnties(status);
 		return e;
 	}
 
 	public boolean containsCollection(PersistentCollection collection) {
 		return collectionEntries.containsKey(collection);
 	}
 
 	public boolean containsProxy(Object entity) {
 		return proxiesByKey.containsValue( entity );
 	}
 
 	/**
 	 * Takes the given object and, if it represents a proxy, reassociates it with this event source.
 	 *
 	 * @param value The possible proxy to be reassociated.
 	 * @return Whether the passed value represented an actual proxy which got initialized.
 	 * @throws MappingException
 	 */
 	public boolean reassociateIfUninitializedProxy(Object value) throws MappingException {
 		if ( value instanceof ElementWrapper ) {
 			value = ( (ElementWrapper) value ).getElement();
 		}
 
 		if ( !Hibernate.isInitialized(value) ) {
 			HibernateProxy proxy = (HibernateProxy) value;
 			LazyInitializer li = proxy.getHibernateLazyInitializer();
 			reassociateProxy(li, proxy);
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	/**
 	 * If a deleted entity instance is re-saved, and it has a proxy, we need to
 	 * reset the identifier of the proxy
 	 */
 	public void reassociateProxy(Object value, Serializable id) throws MappingException {
 		if ( value instanceof ElementWrapper ) {
 			value = ( (ElementWrapper) value ).getElement();
 		}
 
 		if ( value instanceof HibernateProxy ) {
             LOG.debugf("Setting proxy identifier: %s", id);
 			HibernateProxy proxy = (HibernateProxy) value;
 			LazyInitializer li = proxy.getHibernateLazyInitializer();
 			li.setIdentifier(id);
 			reassociateProxy(li, proxy);
 		}
 	}
 
 	/**
 	 * Associate a proxy that was instantiated by another session with this session
 	 *
 	 * @param li The proxy initializer.
 	 * @param proxy The proxy to reassociate.
 	 */
 	private void reassociateProxy(LazyInitializer li, HibernateProxy proxy) {
 		if ( li.getSession() != this.getSession() ) {
 			final EntityPersister persister = session.getFactory().getEntityPersister( li.getEntityName() );
 			final EntityKey key = session.generateEntityKey( li.getIdentifier(), persister );
 		  	// any earlier proxy takes precedence
 			if ( !proxiesByKey.containsKey( key ) ) {
 				proxiesByKey.put( key, proxy );
 			}
 			proxy.getHibernateLazyInitializer().setSession( session );
 		}
 	}
 
 	/**
 	 * Get the entity instance underlying the given proxy, throwing
 	 * an exception if the proxy is uninitialized. If the given object
 	 * is not a proxy, simply return the argument.
 	 */
 	public Object unproxy(Object maybeProxy) throws HibernateException {
 		if ( maybeProxy instanceof ElementWrapper ) {
 			maybeProxy = ( (ElementWrapper) maybeProxy ).getElement();
 		}
 
 		if ( maybeProxy instanceof HibernateProxy ) {
 			HibernateProxy proxy = (HibernateProxy) maybeProxy;
 			LazyInitializer li = proxy.getHibernateLazyInitializer();
 			if ( li.isUninitialized() ) {
 				throw new PersistentObjectException(
 						"object was an uninitialized proxy for " +
 						li.getEntityName()
 				);
 			}
 			return li.getImplementation(); //unwrap the object
 		}
 		else {
 			return maybeProxy;
 		}
 	}
 
 	/**
 	 * Possibly unproxy the given reference and reassociate it with the current session.
 	 *
 	 * @param maybeProxy The reference to be unproxied if it currently represents a proxy.
 	 * @return The unproxied instance.
 	 * @throws HibernateException
 	 */
 	public Object unproxyAndReassociate(Object maybeProxy) throws HibernateException {
 		if ( maybeProxy instanceof ElementWrapper ) {
 			maybeProxy = ( (ElementWrapper) maybeProxy ).getElement();
 		}
 
 		if ( maybeProxy instanceof HibernateProxy ) {
 			HibernateProxy proxy = (HibernateProxy) maybeProxy;
 			LazyInitializer li = proxy.getHibernateLazyInitializer();
 			reassociateProxy(li, proxy);
 			return li.getImplementation(); //initialize + unwrap the object
 		}
 		else {
 			return maybeProxy;
 		}
 	}
 
 	/**
 	 * Attempts to check whether the given key represents an entity already loaded within the
 	 * current session.
 	 * @param object The entity reference against which to perform the uniqueness check.
 	 * @throws HibernateException
 	 */
 	public void checkUniqueness(EntityKey key, Object object) throws HibernateException {
 		Object entity = getEntity(key);
 		if ( entity == object ) {
 			throw new AssertionFailure( "object already associated, but no entry was found" );
 		}
 		if ( entity != null ) {
 			throw new NonUniqueObjectException( key.getIdentifier(), key.getEntityName() );
 		}
 	}
 
 	/**
 	 * If the existing proxy is insufficiently "narrow" (derived), instantiate a new proxy
 	 * and overwrite the registration of the old one. This breaks == and occurs only for
 	 * "class" proxies rather than "interface" proxies. Also init the proxy to point to
 	 * the given target implementation if necessary.
 	 *
 	 * @param proxy The proxy instance to be narrowed.
 	 * @param persister The persister for the proxied entity.
 	 * @param key The internal cache key for the proxied entity.
 	 * @param object (optional) the actual proxied entity instance.
 	 * @return An appropriately narrowed instance.
 	 * @throws HibernateException
 	 */
 	public Object narrowProxy(Object proxy, EntityPersister persister, EntityKey key, Object object)
 	throws HibernateException {
 
 		boolean alreadyNarrow = persister.getConcreteProxyClass( session.getEntityMode() )
 				.isAssignableFrom( proxy.getClass() );
 
 		if ( !alreadyNarrow ) {
             if (LOG.isEnabled(WARN)) LOG.narrowingProxy(persister.getConcreteProxyClass(session.getEntityMode()));
 
 			if ( object != null ) {
 				proxiesByKey.remove(key);
 				return object; //return the proxied object
 			}
 			else {
 				proxy = persister.createProxy( key.getIdentifier(), session );
 				Object proxyOrig = proxiesByKey.put(key, proxy); //overwrite old proxy
 				if ( proxyOrig != null ) {
 					if ( ! ( proxyOrig instanceof HibernateProxy ) ) {
 						throw new AssertionFailure(
 								"proxy not of type HibernateProxy; it is " + proxyOrig.getClass()
 						);
 					}
 					// set the read-only/modifiable mode in the new proxy to what it was in the original proxy
 					boolean readOnlyOrig = ( ( HibernateProxy ) proxyOrig ).getHibernateLazyInitializer().isReadOnly();
 					( ( HibernateProxy ) proxy ).getHibernateLazyInitializer().setReadOnly( readOnlyOrig );
 				}
 				return proxy;
 			}
 		}
 		else {
 
 			if ( object != null ) {
 				LazyInitializer li = ( (HibernateProxy) proxy ).getHibernateLazyInitializer();
 				li.setImplementation(object);
 			}
 
 			return proxy;
 
 		}
 
 	}
 
 	/**
 	 * Return the existing proxy associated with the given <tt>EntityKey</tt>, or the
 	 * third argument (the entity associated with the key) if no proxy exists. Init
 	 * the proxy to the target implementation, if necessary.
 	 */
 	public Object proxyFor(EntityPersister persister, EntityKey key, Object impl)
 	throws HibernateException {
 		if ( !persister.hasProxy() ) return impl;
 		Object proxy = proxiesByKey.get(key);
 		if ( proxy != null ) {
 			return narrowProxy(proxy, persister, key, impl);
 		}
 		else {
 			return impl;
 		}
 	}
 
 	/**
 	 * Return the existing proxy associated with the given <tt>EntityKey</tt>, or the
 	 * argument (the entity associated with the key) if no proxy exists.
 	 * (slower than the form above)
 	 */
 	public Object proxyFor(Object impl) throws HibernateException {
 		EntityEntry e = getEntry(impl);
 		return proxyFor( e.getPersister(), e.getEntityKey(), impl );
 	}
 
 	/**
 	 * Get the entity that owns this persistent collection
 	 */
 	public Object getCollectionOwner(Serializable key, CollectionPersister collectionPersister) throws MappingException {
 		return getEntity( session.generateEntityKey( key, collectionPersister.getOwnerEntityPersister() ) );
 	}
 
 	/**
 	 * Get the entity that owned this persistent collection when it was loaded
 	 *
 	 * @param collection The persistent collection
 	 * @return the owner, if its entity ID is available from the collection's loaded key
 	 * and the owner entity is in the persistence context; otherwise, returns null
 	 */
 	public Object getLoadedCollectionOwnerOrNull(PersistentCollection collection) {
 		CollectionEntry ce = getCollectionEntry( collection );
 		if ( ce.getLoadedPersister() == null ) {
 			return null; // early exit...
 		}
 		Object loadedOwner = null;
 		// TODO: an alternative is to check if the owner has changed; if it hasn't then
 		// return collection.getOwner()
 		Serializable entityId = getLoadedCollectionOwnerIdOrNull( ce );
 		if ( entityId != null ) {
 			loadedOwner = getCollectionOwner( entityId, ce.getLoadedPersister() );
 		}
 		return loadedOwner;
 	}
 
 	/**
 	 * Get the ID for the entity that owned this persistent collection when it was loaded
 	 *
 	 * @param collection The persistent collection
 	 * @return the owner ID if available from the collection's loaded key; otherwise, returns null
 	 */
 	public Serializable getLoadedCollectionOwnerIdOrNull(PersistentCollection collection) {
 		return getLoadedCollectionOwnerIdOrNull( getCollectionEntry( collection ) );
 	}
 
 	/**
 	 * Get the ID for the entity that owned this persistent collection when it was loaded
 	 *
 	 * @param ce The collection entry
 	 * @return the owner ID if available from the collection's loaded key; otherwise, returns null
 	 */
 	private Serializable getLoadedCollectionOwnerIdOrNull(CollectionEntry ce) {
 		if ( ce == null || ce.getLoadedKey() == null || ce.getLoadedPersister() == null ) {
 			return null;
 		}
 		// TODO: an alternative is to check if the owner has changed; if it hasn't then
 		// get the ID from collection.getOwner()
 		return ce.getLoadedPersister().getCollectionType().getIdOfOwnerOrNull( ce.getLoadedKey(), session );
 	}
 
 	/**
 	 * add a collection we just loaded up (still needs initializing)
 	 */
 	public void addUninitializedCollection(CollectionPersister persister, PersistentCollection collection, Serializable id) {
 		CollectionEntry ce = new CollectionEntry(collection, persister, id, flushing);
 		addCollection(collection, ce, id);
 	}
 
 	/**
 	 * add a detached uninitialized collection
 	 */
 	public void addUninitializedDetachedCollection(CollectionPersister persister, PersistentCollection collection) {
 		CollectionEntry ce = new CollectionEntry( persister, collection.getKey() );
 		addCollection( collection, ce, collection.getKey() );
 	}
 
 	/**
 	 * Add a new collection (ie. a newly created one, just instantiated by the
 	 * application, with no database state or snapshot)
 	 * @param collection The collection to be associated with the persistence context
 	 */
 	public void addNewCollection(CollectionPersister persister, PersistentCollection collection)
 	throws HibernateException {
 		addCollection(collection, persister);
 	}
 
 	/**
 	 * Add an collection to the cache, with a given collection entry.
 	 *
 	 * @param coll The collection for which we are adding an entry.
 	 * @param entry The entry representing the collection.
 	 * @param key The key of the collection's entry.
 	 */
 	private void addCollection(PersistentCollection coll, CollectionEntry entry, Serializable key) {
 		collectionEntries.put( coll, entry );
 		CollectionKey collectionKey = new CollectionKey( entry.getLoadedPersister(), key, session.getEntityMode() );
 		PersistentCollection old = ( PersistentCollection ) collectionsByKey.put( collectionKey, coll );
 		if ( old != null ) {
 			if ( old == coll ) {
 				throw new AssertionFailure("bug adding collection twice");
 			}
 			// or should it actually throw an exception?
 			old.unsetSession( session );
 			collectionEntries.remove( old );
 			// watch out for a case where old is still referenced
 			// somewhere in the object graph! (which is a user error)
 		}
 	}
 
 	/**
 	 * Add a collection to the cache, creating a new collection entry for it
 	 *
 	 * @param collection The collection for which we are adding an entry.
 	 * @param persister The collection persister
 	 */
 	private void addCollection(PersistentCollection collection, CollectionPersister persister) {
 		CollectionEntry ce = new CollectionEntry( persister, collection );
 		collectionEntries.put( collection, ce );
 	}
 
 	/**
 	 * add an (initialized) collection that was created by another session and passed
 	 * into update() (ie. one with a snapshot and existing state on the database)
 	 */
 	public void addInitializedDetachedCollection(CollectionPersister collectionPersister, PersistentCollection collection)
 	throws HibernateException {
 		if ( collection.isUnreferenced() ) {
 			//treat it just like a new collection
 			addCollection( collection, collectionPersister );
 		}
 		else {
 			CollectionEntry ce = new CollectionEntry( collection, session.getFactory() );
 			addCollection( collection, ce, collection.getKey() );
 		}
 	}
 
 	/**
 	 * add a collection we just pulled out of the cache (does not need initializing)
 	 */
 	public CollectionEntry addInitializedCollection(CollectionPersister persister, PersistentCollection collection, Serializable id)
 	throws HibernateException {
 		CollectionEntry ce = new CollectionEntry(collection, persister, id, flushing);
 		ce.postInitialize(collection);
 		addCollection(collection, ce, id);
 		return ce;
 	}
 
 	/**
 	 * Get the collection instance associated with the <tt>CollectionKey</tt>
 	 */
 	public PersistentCollection getCollection(CollectionKey collectionKey) {
 		return (PersistentCollection) collectionsByKey.get(collectionKey);
 	}
 
 	/**
 	 * Register a collection for non-lazy loading at the end of the
 	 * two-phase load
 	 */
 	public void addNonLazyCollection(PersistentCollection collection) {
 		nonlazyCollections.add(collection);
 	}
 
 	/**
 	 * Force initialization of all non-lazy collections encountered during
 	 * the current two-phase load (actually, this is a no-op, unless this
 	 * is the "outermost" load)
 	 */
 	public void initializeNonLazyCollections() throws HibernateException {
 		if ( loadCounter == 0 ) {
             LOG.debugf("Initializing non-lazy collections");
 			//do this work only at the very highest level of the load
 			loadCounter++; //don't let this method be called recursively
 			try {
 				int size;
 				while ( ( size = nonlazyCollections.size() ) > 0 ) {
 					//note that each iteration of the loop may add new elements
 					( (PersistentCollection) nonlazyCollections.remove( size - 1 ) ).forceInitialization();
 				}
 			}
 			finally {
 				loadCounter--;
 				clearNullProperties();
 			}
 		}
 	}
 
 
 	/**
 	 * Get the <tt>PersistentCollection</tt> object for an array
 	 */
 	public PersistentCollection getCollectionHolder(Object array) {
 		return (PersistentCollection) arrayHolders.get(array);
 	}
 
 	/**
 	 * Register a <tt>PersistentCollection</tt> object for an array.
 	 * Associates a holder with an array - MUST be called after loading
 	 * array, since the array instance is not created until endLoad().
 	 */
 	public void addCollectionHolder(PersistentCollection holder) {
 		//TODO:refactor + make this method private
 		arrayHolders.put( holder.getValue(), holder );
 	}
 
 	public PersistentCollection removeCollectionHolder(Object array) {
 		return (PersistentCollection) arrayHolders.remove(array);
 	}
 
 	/**
 	 * Get the snapshot of the pre-flush collection state
 	 */
 	public Serializable getSnapshot(PersistentCollection coll) {
 		return getCollectionEntry(coll).getSnapshot();
 	}
 
 	/**
 	 * Get the collection entry for a collection passed to filter,
 	 * which might be a collection wrapper, an array, or an unwrapped
 	 * collection. Return null if there is no entry.
 	 */
 	public CollectionEntry getCollectionEntryOrNull(Object collection) {
 		PersistentCollection coll;
 		if ( collection instanceof PersistentCollection ) {
 			coll = (PersistentCollection) collection;
 			//if (collection==null) throw new TransientObjectException("Collection was not yet persistent");
 		}
 		else {
 			coll = getCollectionHolder(collection);
 			if ( coll == null ) {
 				//it might be an unwrapped collection reference!
 				//try to find a wrapper (slowish)
 				Iterator wrappers = IdentityMap.keyIterator(collectionEntries);
 				while ( wrappers.hasNext() ) {
 					PersistentCollection pc = (PersistentCollection) wrappers.next();
 					if ( pc.isWrapper(collection) ) {
 						coll = pc;
 						break;
 					}
 				}
 			}
 		}
 
 		return (coll == null) ? null : getCollectionEntry(coll);
 	}
 
 	/**
 	 * Get an existing proxy by key
 	 */
 	public Object getProxy(EntityKey key) {
 		return proxiesByKey.get(key);
 	}
 
 	/**
 	 * Add a proxy to the session cache
 	 */
 	public void addProxy(EntityKey key, Object proxy) {
 		proxiesByKey.put(key, proxy);
 	}
 
 	/**
 	 * Remove a proxy from the session cache.
 	 * <p/>
 	 * Additionally, ensure that any load optimization references
 	 * such as batch or subselect loading get cleaned up as well.
 	 *
 	 * @param key The key of the entity proxy to be removed
 	 * @return The proxy reference.
 	 */
 	public Object removeProxy(EntityKey key) {
 		if ( batchFetchQueue != null ) {
 			batchFetchQueue.removeBatchLoadableEntityKey( key );
 			batchFetchQueue.removeSubselect( key );
 		}
 		return proxiesByKey.remove( key );
 	}
 
 	/**
 	 * Record the fact that an entity does not exist in the database
 	 *
 	 * @param key the primary key of the entity
 	 */
 	/*public void addNonExistantEntityKey(EntityKey key) {
 		nonExistantEntityKeys.add(key);
 	}*/
 
 	/**
 	 * Record the fact that an entity does not exist in the database
 	 *
 	 * @param key a unique key of the entity
 	 */
 	/*public void addNonExistantEntityUniqueKey(EntityUniqueKey key) {
 		nonExistentEntityUniqueKeys.add(key);
 	}*/
 
 	/*public void removeNonExist(EntityKey key) {
 		nonExistantEntityKeys.remove(key);
 	}*/
 
 	/**
 	 * Retrieve the set of EntityKeys representing nullifiable references
 	 */
 	public HashSet getNullifiableEntityKeys() {
 		return nullifiableEntityKeys;
 	}
 
 	public Map getEntitiesByKey() {
 		return entitiesByKey;
 	}
 
 	public Map getProxiesByKey() {
 		return proxiesByKey;
 	}
 
 	public Map getEntityEntries() {
 		return entityEntries;
 	}
 
 	public Map getCollectionEntries() {
 		return collectionEntries;
 	}
 
 	public Map getCollectionsByKey() {
 		return collectionsByKey;
 	}
 
 	/**
 	 * Do we already know that the entity does not exist in the
 	 * database?
 	 */
 	/*public boolean isNonExistant(EntityKey key) {
 		return nonExistantEntityKeys.contains(key);
 	}*/
 
 	/**
 	 * Do we already know that the entity does not exist in the
 	 * database?
 	 */
 	/*public boolean isNonExistant(EntityUniqueKey key) {
 		return nonExistentEntityUniqueKeys.contains(key);
 	}*/
 
 	public int getCascadeLevel() {
 		return cascading;
 	}
 
 	public int incrementCascadeLevel() {
 		return ++cascading;
 	}
 
 	public int decrementCascadeLevel() {
 		return --cascading;
 	}
 
 	public boolean isFlushing() {
 		return flushing;
 	}
 
 	public void setFlushing(boolean flushing) {
 		this.flushing = flushing;
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/TwoPhaseLoad.java b/hibernate-core/src/main/java/org/hibernate/engine/TwoPhaseLoad.java
index 14a4059695..89ee2e4a21 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/TwoPhaseLoad.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/TwoPhaseLoad.java
@@ -1,334 +1,334 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.entry.CacheEntry;
 import org.hibernate.event.EventType;
 import org.hibernate.event.PostLoadEvent;
 import org.hibernate.event.PostLoadEventListener;
 import org.hibernate.event.PreLoadEvent;
 import org.hibernate.event.PreLoadEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.property.BackrefPropertyAccessor;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.service.event.spi.EventListenerGroup;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 
 /**
  * Functionality relating to Hibernate's two-phase loading process,
  * that may be reused by persisters that do not use the Loader
  * framework
  *
  * @author Gavin King
  */
 public final class TwoPhaseLoad {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(
-			HibernateLogger.class, TwoPhaseLoad.class.getName()
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(
+			CoreMessageLogger.class, TwoPhaseLoad.class.getName()
 	);
 
 	private TwoPhaseLoad() {}
 
 	/**
 	 * Register the "hydrated" state of an entity instance, after the first step of 2-phase loading.
 	 *
 	 * Add the "hydrated state" (an array) of an uninitialized entity to the session. We don't try
 	 * to resolve any associations yet, because there might be other entities waiting to be
 	 * read from the JDBC result set we are currently processing
 	 */
 	public static void postHydrate(
 		final EntityPersister persister,
 		final Serializable id,
 		final Object[] values,
 		final Object rowId,
 		final Object object,
 		final LockMode lockMode,
 		final boolean lazyPropertiesAreUnfetched,
 		final SessionImplementor session)
 	throws HibernateException {
 
 		Object version = Versioning.getVersion(values, persister);
 		session.getPersistenceContext().addEntry(
 				object,
 				Status.LOADING,
 				values,
 				rowId,
 				id,
 				version,
 				lockMode,
 				true,
 				persister,
 				false,
 				lazyPropertiesAreUnfetched
 			);
 
         if (LOG.isTraceEnabled() && version != null) {
 			String versionStr = persister.isVersioned()
 					? persister.getVersionType().toLoggableString( version, session.getFactory() )
 			        : "null";
             LOG.trace("Version: " + versionStr);
 		}
 
 	}
 
 	/**
 	 * Perform the second step of 2-phase load. Fully initialize the entity
 	 * instance.
 	 *
 	 * After processing a JDBC result set, we "resolve" all the associations
 	 * between the entities which were instantiated and had their state
 	 * "hydrated" into an array
 	 */
 	public static void initializeEntity(
 			final Object entity,
 			final boolean readOnly,
 			final SessionImplementor session,
 			final PreLoadEvent preLoadEvent,
 			final PostLoadEvent postLoadEvent) throws HibernateException {
 
 		//TODO: Should this be an InitializeEntityEventListener??? (watch out for performance!)
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		EntityEntry entityEntry = persistenceContext.getEntry(entity);
 		if ( entityEntry == null ) {
 			throw new AssertionFailure( "possible non-threadsafe access to the session" );
 		}
 		EntityPersister persister = entityEntry.getPersister();
 		Serializable id = entityEntry.getId();
 		Object[] hydratedState = entityEntry.getLoadedState();
 
         if (LOG.isDebugEnabled()) LOG.debugf(
 				"Resolving associations for %s",
 				MessageHelper.infoString( persister, id, session.getFactory() )
 		);
 
 		Type[] types = persister.getPropertyTypes();
 		for ( int i = 0; i < hydratedState.length; i++ ) {
 			final Object value = hydratedState[i];
 			if ( value!=LazyPropertyInitializer.UNFETCHED_PROPERTY && value!=BackrefPropertyAccessor.UNKNOWN ) {
 				hydratedState[i] = types[i].resolve( value, session, entity );
 			}
 		}
 
 		//Must occur after resolving identifiers!
 		if ( session.isEventSource() ) {
 			preLoadEvent.setEntity( entity ).setState( hydratedState ).setId( id ).setPersister( persister );
 
 			final EventListenerGroup<PreLoadEventListener> listenerGroup = session
 					.getFactory()
 					.getServiceRegistry()
 					.getService( EventListenerRegistry.class )
 					.getEventListenerGroup( EventType.PRE_LOAD );
 			for ( PreLoadEventListener listener : listenerGroup.listeners() ) {
 				listener.onPreLoad( preLoadEvent );
 			}
 		}
 
 		persister.setPropertyValues( entity, hydratedState, session.getEntityMode() );
 
 		final SessionFactoryImplementor factory = session.getFactory();
 		if ( persister.hasCache() && session.getCacheMode().isPutEnabled() ) {
 
             if (LOG.isDebugEnabled()) LOG.debugf(
 					"Adding entity to second-level cache: %s",
 					MessageHelper.infoString( persister, id, session.getFactory() )
 			);
 
 			Object version = Versioning.getVersion(hydratedState, persister);
 			CacheEntry entry = new CacheEntry(
 					hydratedState,
 					persister,
 					entityEntry.isLoadedWithLazyPropertiesUnfetched(),
 					version,
 					session,
 					entity
 			);
 			CacheKey cacheKey = session.generateCacheKey( id, persister.getIdentifierType(), persister.getRootEntityName() );
 
 			// explicit handling of caching for rows just inserted and then somehow forced to be read
 			// from the database *within the same transaction*.  usually this is done by
 			// 		1) Session#refresh, or
 			// 		2) Session#clear + some form of load
 			//
 			// we need to be careful not to clobber the lock here in the cache so that it can be rolled back if need be
 			if ( session.getPersistenceContext().wasInsertedDuringTransaction( persister, id ) ) {
 				persister.getCacheAccessStrategy().update(
 						cacheKey,
 						persister.getCacheEntryStructure().structure( entry ),
 						version,
 						version
 				);
 			}
 			else {
 				boolean put = persister.getCacheAccessStrategy().putFromLoad(
 						cacheKey,
 						persister.getCacheEntryStructure().structure( entry ),
 						session.getTimestamp(),
 						version,
 						useMinimalPuts( session, entityEntry )
 				);
 
 				if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 					factory.getStatisticsImplementor().secondLevelCachePut( persister.getCacheAccessStrategy().getRegion().getName() );
 				}
 			}
 		}
 
 		boolean isReallyReadOnly = readOnly;
 		if ( !persister.isMutable() ) {
 			isReallyReadOnly = true;
 		}
 		else {
 			Object proxy = persistenceContext.getProxy( entityEntry.getEntityKey() );
 			if ( proxy != null ) {
 				// there is already a proxy for this impl
 				// only set the status to read-only if the proxy is read-only
 				isReallyReadOnly = ( ( HibernateProxy ) proxy ).getHibernateLazyInitializer().isReadOnly();
 			}
 		}
 		if ( isReallyReadOnly ) {
 			//no need to take a snapshot - this is a
 			//performance optimization, but not really
 			//important, except for entities with huge
 			//mutable property values
 			persistenceContext.setEntryStatus(entityEntry, Status.READ_ONLY);
 		}
 		else {
 			//take a snapshot
 			TypeHelper.deepCopy(
 					hydratedState,
 					persister.getPropertyTypes(),
 					persister.getPropertyUpdateability(),
 					hydratedState,  //after setting values to object, entityMode
 					session
 			);
 			persistenceContext.setEntryStatus(entityEntry, Status.MANAGED);
 		}
 
 		persister.afterInitialize(
 				entity,
 				entityEntry.isLoadedWithLazyPropertiesUnfetched(),
 				session
 			);
 
 		if ( session.isEventSource() ) {
 			postLoadEvent.setEntity( entity ).setId( id ).setPersister( persister );
 
 			final EventListenerGroup<PostLoadEventListener> listenerGroup = session
 					.getFactory()
 					.getServiceRegistry()
 					.getService( EventListenerRegistry.class )
 					.getEventListenerGroup( EventType.POST_LOAD );
 			for ( PostLoadEventListener listener : listenerGroup.listeners() ) {
 				listener.onPostLoad( postLoadEvent );
 			}
 		}
 
         if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Done materializing entity %s",
 					MessageHelper.infoString( persister, id, session.getFactory() )
 			);
 		}
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().loadEntity( persister.getEntityName() );
 		}
 
 	}
 
 	private static boolean useMinimalPuts(SessionImplementor session, EntityEntry entityEntry) {
 		return ( session.getFactory().getSettings().isMinimalPutsEnabled() &&
 						session.getCacheMode()!=CacheMode.REFRESH ) ||
 				( entityEntry.getPersister().hasLazyProperties() &&
 						entityEntry.isLoadedWithLazyPropertiesUnfetched() &&
 						entityEntry.getPersister().isLazyPropertiesCacheable() );
 	}
 
 	/**
 	 * Add an uninitialized instance of an entity class, as a placeholder to ensure object
 	 * identity. Must be called before <tt>postHydrate()</tt>.
 	 *
 	 * Create a "temporary" entry for a newly instantiated entity. The entity is uninitialized,
 	 * but we need the mapping from id to instance in order to guarantee uniqueness.
 	 */
 	public static void addUninitializedEntity(
 			final EntityKey key,
 			final Object object,
 			final EntityPersister persister,
 			final LockMode lockMode,
 			final boolean lazyPropertiesAreUnfetched,
 			final SessionImplementor session
 	) {
 		session.getPersistenceContext().addEntity(
 				object,
 				Status.LOADING,
 				null,
 				key,
 				null,
 				lockMode,
 				true,
 				persister,
 				false,
 				lazyPropertiesAreUnfetched
 			);
 	}
 
 	public static void addUninitializedCachedEntity(
 			final EntityKey key,
 			final Object object,
 			final EntityPersister persister,
 			final LockMode lockMode,
 			final boolean lazyPropertiesAreUnfetched,
 			final Object version,
 			final SessionImplementor session
 	) {
 		session.getPersistenceContext().addEntity(
 				object,
 				Status.LOADING,
 				null,
 				key,
 				version,
 				lockMode,
 				true,
 				persister,
 				false,
 				lazyPropertiesAreUnfetched
 			);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/VersionValue.java b/hibernate-core/src/main/java/org/hibernate/engine/VersionValue.java
index b4b9a4c8ca..ae09aebcb5 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/VersionValue.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/VersionValue.java
@@ -1,139 +1,139 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.jboss.logging.Logger;
 
 /**
  * A strategy for determining if a version value is an version of
  * a new transient instance or a previously persistent transient instance.
  * The strategy is determined by the <tt>unsaved-value</tt> attribute in
  * the mapping file.
  *
  * @author Gavin King
  */
 public class VersionValue {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, VersionValue.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, VersionValue.class.getName());
 
 	private final Object value;
 	/**
 	 * Assume the transient instance is newly instantiated if the version
 	 * is null, otherwise assume it is a detached instance.
 	 */
 	public static final VersionValue NULL = new VersionValue() {
 		@Override
         public final Boolean isUnsaved(Object version) {
             LOG.trace("Version unsaved-value strategy NULL");
 			return version==null ? Boolean.TRUE : Boolean.FALSE;
 		}
 		@Override
         public Object getDefaultValue(Object currentValue) {
 			return null;
 		}
 		@Override
         public String toString() {
 			return "VERSION_SAVE_NULL";
 		}
 	};
 	/**
 	 * Assume the transient instance is newly instantiated if the version
 	 * is null, otherwise defer to the identifier unsaved-value.
 	 */
 	public static final VersionValue UNDEFINED = new VersionValue() {
 		@Override
         public final Boolean isUnsaved(Object version) {
             LOG.trace("Version unsaved-value strategy UNDEFINED");
 			return version==null ? Boolean.TRUE : null;
 		}
 		@Override
         public Object getDefaultValue(Object currentValue) {
 			return currentValue;
 		}
 		@Override
         public String toString() {
 			return "VERSION_UNDEFINED";
 		}
 	};
 	/**
 	 * Assume the transient instance is newly instantiated if the version
 	 * is negative, otherwise assume it is a detached instance.
 	 */
 	public static final VersionValue NEGATIVE = new VersionValue() {
 
 		@Override
         public final Boolean isUnsaved(Object version) throws MappingException {
             LOG.trace("Version unsaved-value strategy NEGATIVE");
 			if (version==null) return Boolean.TRUE;
             if (version instanceof Number) return ((Number)version).longValue() < 0l ? Boolean.TRUE : Boolean.FALSE;
             throw new MappingException("unsaved-value NEGATIVE may only be used with short, int and long types");
 		}
 		@Override
         public Object getDefaultValue(Object currentValue) {
 			return IdentifierGeneratorHelper.getIntegralDataTypeHolder( currentValue.getClass() )
 					.initialize( -1L )
 					.makeValue();
 		}
 		@Override
         public String toString() {
 			return "VERSION_NEGATIVE";
 		}
 	};
 
 	protected VersionValue() {
 		this.value = null;
 	}
 
 	/**
 	 * Assume the transient instance is newly instantiated if
 	 * its version is null or equal to <tt>value</tt>
 	 * @param value value to compare to
 	 */
 	public VersionValue(Object value) {
 		this.value = value;
 	}
 
 	/**
 	 * Does the given version belong to a new instance?
 	 *
 	 * @param version version to check
 	 * @return true is unsaved, false is saved, null is undefined
 	 */
 	public Boolean isUnsaved(Object version) throws MappingException  {
         LOG.trace("Version unsaved-value: " + value);
 		return version==null || version.equals(value) ? Boolean.TRUE : Boolean.FALSE;
 	}
 
 	public Object getDefaultValue(Object currentValue) {
 		return value;
 	}
 
 	@Override
     public String toString() {
 		return "version unsaved-value: " + value;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/Versioning.java b/hibernate-core/src/main/java/org/hibernate/engine/Versioning.java
index 81932c7704..991358e9ff 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/Versioning.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/Versioning.java
@@ -1,181 +1,181 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.VersionType;
 import org.jboss.logging.Logger;
 
 /**
  * Utilities for dealing with optimisitic locking values.
  *
  * @author Gavin King
  */
 public final class Versioning {
 	/**
 	 * Apply no optimistic locking
 	 */
 	public static final int OPTIMISTIC_LOCK_NONE = -1;
 
 	/**
 	 * Apply optimisitc locking based on the defined version or timestamp
 	 * property.
 	 */
 	public static final int OPTIMISTIC_LOCK_VERSION = 0;
 
 	/**
 	 * Apply optimisitc locking based on the a current vs. snapshot comparison
 	 * of <b>all</b> properties.
 	 */
 	public static final int OPTIMISTIC_LOCK_ALL = 2;
 
 	/**
 	 * Apply optimisitc locking based on the a current vs. snapshot comparison
 	 * of <b>dirty</b> properties.
 	 */
 	public static final int OPTIMISTIC_LOCK_DIRTY = 1;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Versioning.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Versioning.class.getName());
 
 	/**
 	 * Private constructor disallowing instantiation.
 	 */
 	private Versioning() {}
 
 	/**
 	 * Create an initial optimisitc locking value according the {@link VersionType}
 	 * contract for the version property.
 	 *
 	 * @param versionType The version type.
 	 * @param session The originating session
 	 * @return The initial optimisitc locking value
 	 */
 	private static Object seed(VersionType versionType, SessionImplementor session) {
 		Object seed = versionType.seed( session );
         LOG.trace("Seeding: " + seed);
 		return seed;
 	}
 
 	/**
 	 * Create an initial optimisitc locking value according the {@link VersionType}
 	 * contract for the version property <b>if required</b> and inject it into
 	 * the snapshot state.
 	 *
 	 * @param fields The current snapshot state
 	 * @param versionProperty The index of the version property
 	 * @param versionType The version type
 	 * @param session The orginating session
 	 * @return True if we injected a new version value into the fields array; false
 	 * otherwise.
 	 */
 	public static boolean seedVersion(
 	        Object[] fields,
 	        int versionProperty,
 	        VersionType versionType,
 	        SessionImplementor session) {
 		Object initialVersion = fields[versionProperty];
 		if (
 			initialVersion==null ||
 			// This next bit is to allow for both unsaved-value="negative"
 			// and for "older" behavior where version number did not get
 			// seeded if it was already set in the object
 			// TODO: shift it into unsaved-value strategy
 			( (initialVersion instanceof Number) && ( (Number) initialVersion ).longValue()<0 )
 		) {
 			fields[versionProperty] = seed( versionType, session );
 			return true;
 		}
         LOG.trace("Using initial version: " + initialVersion);
         return false;
 	}
 
 
 	/**
 	 * Generate the next increment in the optimisitc locking value according
 	 * the {@link VersionType} contract for the version property.
 	 *
 	 * @param version The current version
 	 * @param versionType The version type
 	 * @param session The originating session
 	 * @return The incremented optimistic locking value.
 	 */
 	public static Object increment(Object version, VersionType versionType, SessionImplementor session) {
 		Object next = versionType.next( version, session );
         if (LOG.isTraceEnabled()) LOG.trace("Incrementing: " + versionType.toLoggableString(version, session.getFactory()) + " to "
                                             + versionType.toLoggableString(next, session.getFactory()));
 		return next;
 	}
 
 	/**
 	 * Inject the optimisitc locking value into the entity state snapshot.
 	 *
 	 * @param fields The state snapshot
 	 * @param version The optimisitc locking value
 	 * @param persister The entity persister
 	 */
 	public static void setVersion(Object[] fields, Object version, EntityPersister persister) {
 		if ( !persister.isVersioned() ) {
 			return;
 		}
 		fields[ persister.getVersionProperty() ] = version;
 	}
 
 	/**
 	 * Extract the optimisitc locking value out of the entity state snapshot.
 	 *
 	 * @param fields The state snapshot
 	 * @param persister The entity persister
 	 * @return The extracted optimisitc locking value
 	 */
 	public static Object getVersion(Object[] fields, EntityPersister persister) {
 		if ( !persister.isVersioned() ) {
 			return null;
 		}
 		return fields[ persister.getVersionProperty() ];
 	}
 
 	/**
 	 * Do we need to increment the version number, given the dirty properties?
 	 *
 	 * @param dirtyProperties The array of property indexes which were deemed dirty
 	 * @param hasDirtyCollections Were any collections found to be dirty (structurally changed)
 	 * @param propertyVersionability An array indicating versionability of each property.
 	 * @return True if a version increment is required; false otherwise.
 	 */
 	public static boolean isVersionIncrementRequired(
 			final int[] dirtyProperties,
 			final boolean hasDirtyCollections,
 			final boolean[] propertyVersionability) {
 		if ( hasDirtyCollections ) {
 			return true;
 		}
 		for ( int i = 0; i < dirtyProperties.length; i++ ) {
 			if ( propertyVersionability[ dirtyProperties[i] ] ) {
 				return true;
 			}
 		}
 	    return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/ResultSetWrapperProxy.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/ResultSetWrapperProxy.java
index 70ba6ca3aa..2dbaca6f51 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/ResultSetWrapperProxy.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/ResultSetWrapperProxy.java
@@ -1,186 +1,188 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc;
 
 import java.lang.reflect.InvocationHandler;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.lang.reflect.Proxy;
 import java.sql.ResultSet;
 import java.sql.SQLException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * A proxy for a ResultSet delegate, responsible for locally caching the columnName-to-columnIndex resolution that
  * has been found to be inefficient in a few vendor's drivers (i.e., Oracle and Postgres).
  *
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public class ResultSetWrapperProxy implements InvocationHandler {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ResultSetWrapperProxy.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ResultSetWrapperProxy.class.getName());
 	private static final Class[] PROXY_INTERFACES = new Class[] { ResultSet.class };
 	private static final SqlExceptionHelper sqlExceptionHelper = new SqlExceptionHelper();
 
 	private final ResultSet rs;
 	private final ColumnNameCache columnNameCache;
 
 	private ResultSetWrapperProxy(ResultSet rs, ColumnNameCache columnNameCache) {
 		this.rs = rs;
 		this.columnNameCache = columnNameCache;
 	}
 
 	/**
 	 * Generates a proxy wrapping the ResultSet.
 	 *
 	 * @param resultSet The resultSet to wrap.
 	 * @param columnNameCache The cache storing data for converting column names to column indexes.
 	 * @return The generated proxy.
 	 */
 	public static ResultSet generateProxy(ResultSet resultSet, ColumnNameCache columnNameCache) {
 		return ( ResultSet ) Proxy.newProxyInstance(
 				getProxyClassLoader(),
 				PROXY_INTERFACES,
 				new ResultSetWrapperProxy( resultSet, columnNameCache )
 		);
 	}
 
 	/**
 	 * Determines the appropriate class loader to which the generated proxy
 	 * should be scoped.
 	 *
 	 * @return The class loader appropriate for proxy construction.
 	 */
 	public static ClassLoader getProxyClassLoader() {
 		ClassLoader cl = Thread.currentThread().getContextClassLoader();
 		if ( cl == null ) {
 			cl = ResultSet.class.getClassLoader();
 		}
 		return cl;
 	}
 
 	@Override
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
 		if ( "findColumn".equals( method.getName() ) ) {
 			return Integer.valueOf( findColumn( ( String ) args[0] ) );
 		}
 
 		if ( isFirstArgColumnLabel( method, args ) ) {
 			try {
 				int columnIndex = findColumn( ( String ) args[0] );
 				return invokeMethod(
 						locateCorrespondingColumnIndexMethod( method ), buildColumnIndexMethodArgs( args, columnIndex )
 				);
 			}
 			catch ( SQLException ex ) {
 				StringBuffer buf = new StringBuffer()
 						.append( "Exception getting column index for column: [" )
 						.append( args[0] )
 						.append( "].\nReverting to using: [" )
 						.append( args[0] )
 						.append( "] as first argument for method: [" )
 						.append( method )
 						.append( "]" );
 				sqlExceptionHelper.logExceptions( ex, buf.toString() );
 			}
 			catch ( NoSuchMethodException ex ) {
                 LOG.unableToSwitchToMethodUsingColumnIndex(method);
 			}
 		}
 		return invokeMethod( method, args );
 	}
 
 	/**
 	 * Locate the column index corresponding to the given column name via the cache.
 	 *
 	 * @param columnName The column name to resolve into an index.
 	 * @return The column index corresponding to the given column name.
 	 * @throws SQLException if the ResultSet object does not contain columnName or a database access error occurs
 	 */
 	private int findColumn(String columnName) throws SQLException {
 		return columnNameCache.getIndexForColumnName( columnName, rs );
 	}
 
 	private boolean isFirstArgColumnLabel(Method method, Object args[]) {
 		// method name should start with either get or update
 		if ( ! ( method.getName().startsWith( "get" ) || method.getName().startsWith( "update" ) ) ) {
 			return false;
 		}
 
 		// method should have arguments, and have same number as incoming arguments
 		if ( ! ( method.getParameterTypes().length > 0 && args.length == method.getParameterTypes().length ) ) {
 			return false;
 		}
 
 		// The first argument should be a String (the column name)
 		//noinspection RedundantIfStatement
 		if ( ! ( String.class.isInstance( args[0] ) && method.getParameterTypes()[0].equals( String.class ) ) ) {
 			return false;
 		}
 
 		return true;
 	}
 
 	/**
 	 * For a given {@link ResultSet} method passed a column name, locate the corresponding method passed the same
 	 * parameters but the column index.
 	 *
 	 * @param columnNameMethod The method passed the column name
 	 * @return The corresponding method passed the column index.
 	 * @throws NoSuchMethodException Should never happen, but...
 	 */
 	private Method locateCorrespondingColumnIndexMethod(Method columnNameMethod) throws NoSuchMethodException {
 		Class actualParameterTypes[] = new Class[columnNameMethod.getParameterTypes().length];
 		actualParameterTypes[0] = int.class;
 		System.arraycopy(
 				columnNameMethod.getParameterTypes(),
 				1,
 				actualParameterTypes,
 				1,
 				columnNameMethod.getParameterTypes().length - 1
 		);
 		return columnNameMethod.getDeclaringClass().getMethod( columnNameMethod.getName(), actualParameterTypes );
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	private Object[] buildColumnIndexMethodArgs(Object[] incomingArgs, int columnIndex) {
 		Object actualArgs[] = new Object[incomingArgs.length];
 		actualArgs[0] = Integer.valueOf( columnIndex );
 		System.arraycopy( incomingArgs, 1, actualArgs, 1, incomingArgs.length - 1 );
 		return actualArgs;
 	}
 
 	private Object invokeMethod(Method method, Object args[]) throws Throwable {
 		try {
 			return method.invoke( rs, args );
 		}
 		catch ( InvocationTargetException e ) {
 			throw e.getTargetException();
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/AbstractBatchImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/AbstractBatchImpl.java
index f4da3fd962..fed5486691 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/AbstractBatchImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/AbstractBatchImpl.java
@@ -1,205 +1,207 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.batch.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.LinkedHashMap;
 import java.util.LinkedHashSet;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.batch.spi.BatchObserver;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * Convenience base class for implementors of the Batch interface.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractBatchImpl implements Batch {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, AbstractBatchImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, AbstractBatchImpl.class.getName());
 
 	private final BatchKey key;
 	private final JdbcCoordinator jdbcCoordinator;
 	private LinkedHashMap<String,PreparedStatement> statements = new LinkedHashMap<String,PreparedStatement>();
 	private LinkedHashSet<BatchObserver> observers = new LinkedHashSet<BatchObserver>();
 
 	protected AbstractBatchImpl(BatchKey key, JdbcCoordinator jdbcCoordinator) {
 		if ( key == null ) {
 			throw new IllegalArgumentException( "batch key cannot be null" );
 		}
 		if ( jdbcCoordinator == null ) {
 			throw new IllegalArgumentException( "JDBC coordinator cannot be null" );
 		}
 		this.key = key;
 		this.jdbcCoordinator = jdbcCoordinator;
 	}
 
 	/**
 	 * Perform batch execution.
 	 * <p/>
 	 * This is called from the explicit {@link #execute() execution}, but may also be called from elsewhere
 	 * depending on the exact implementation.
 	 */
 	protected abstract void doExecuteBatch();
 
 	/**
 	 * Convenience access to the SQLException helper.
 	 *
 	 * @return The underlying SQLException helper.
 	 */
 	protected SqlExceptionHelper sqlExceptionHelper() {
 		return jdbcCoordinator.getTransactionCoordinator()
 				.getTransactionContext()
 				.getTransactionEnvironment()
 				.getJdbcServices()
 				.getSqlExceptionHelper();
 	}
 
 	/**
 	 * Convenience access to the SQL statement logger.
 	 *
 	 * @return The underlying JDBC services.
 	 */
 	protected SqlStatementLogger sqlStatementLogger() {
 		return jdbcCoordinator.getTransactionCoordinator()
 				.getTransactionContext()
 				.getTransactionEnvironment()
 				.getJdbcServices()
 				.getSqlStatementLogger();
 	}
 
 	/**
 	 * Access to the batch's map of statements (keyed by SQL statement string).
 	 *
 	 * @return This batch's statements.
 	 */
 	protected LinkedHashMap<String,PreparedStatement> getStatements() {
 		return statements;
 	}
 
 	@Override
 	public final BatchKey getKey() {
 		return key;
 	}
 
 	@Override
 	public void addObserver(BatchObserver observer) {
 		observers.add( observer );
 	}
 
 	@Override
 	public PreparedStatement getBatchStatement(String sql, boolean callable) {
 		if ( sql == null ) {
 			throw new IllegalArgumentException( "sql must be non-null." );
 		}
 		PreparedStatement statement = statements.get( sql );
 		if ( statement == null ) {
 			statement = buildBatchStatement( sql, callable );
 			statements.put( sql, statement );
 		}
 		else {
             LOG.debugf("Reusing batch statement");
 			sqlStatementLogger().logStatement( sql );
 		}
 		return statement;
 	}
 
 	private PreparedStatement buildBatchStatement(String sql, boolean callable) {
 		try {
 			if ( callable ) {
 				return jdbcCoordinator.getLogicalConnection().getShareableConnectionProxy().prepareCall( sql );
 			}
 			else {
 				return jdbcCoordinator.getLogicalConnection().getShareableConnectionProxy().prepareStatement( sql );
 			}
 		}
 		catch ( SQLException sqle ) {
             LOG.sqlExceptionEscapedProxy(sqle);
 			throw sqlExceptionHelper().convert( sqle, "could not prepare batch statement", sql );
 		}
 	}
 
 	@Override
 	public final void execute() {
 		notifyObserversExplicitExecution();
 		if ( statements.isEmpty() ) {
 			return;
 		}
 		try {
 			try {
 				doExecuteBatch();
 			}
 			finally {
 				releaseStatements();
 			}
 		}
 		finally {
 			statements.clear();
 		}
 	}
 
 	private void releaseStatements() {
 		for ( PreparedStatement statement : getStatements().values() ) {
 			try {
 				statement.close();
 			}
 			catch ( SQLException e ) {
                 LOG.unableToReleaseBatchStatement();
                 LOG.sqlExceptionEscapedProxy(e);
 			}
 		}
 		getStatements().clear();
 	}
 
 	/**
 	 * Convenience method to notify registered observers of an explicit execution of this batch.
 	 */
 	protected final void notifyObserversExplicitExecution() {
 		for ( BatchObserver observer : observers ) {
 			observer.batchExplicitlyExecuted();
 		}
 	}
 
 	/**
 	 * Convenience method to notify registered observers of an implicit execution of this batch.
 	 */
 	protected final void notifyObserversImplicitExecution() {
 		for ( BatchObserver observer : observers ) {
 			observer.batchImplicitlyExecuted();
 		}
 	}
 
 	@Override
 	public void release() {
         if (getStatements() != null && !getStatements().isEmpty()) LOG.batchContainedStatementsOnRelease();
 		releaseStatements();
 		observers.clear();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchBuilderImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchBuilderImpl.java
index f858736f94..8f43e1407a 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchBuilderImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchBuilderImpl.java
@@ -1,87 +1,88 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.batch.internal;
 
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.jdbc.batch.spi.BatchBuilder;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.spi.Configurable;
 import org.jboss.logging.Logger;
 
 /**
  * A builder for {@link Batch} instances.
  *
  * @author Steve Ebersole
  */
 public class BatchBuilderImpl implements BatchBuilder, Configurable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BatchBuilderImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BatchBuilderImpl.class.getName());
 
 	private int size;
 
 	public BatchBuilderImpl() {
 	}
 
 	@Override
 	public void configure(Map configurationValues) {
 		size = ConfigurationHelper.getInt( Environment.STATEMENT_BATCH_SIZE, configurationValues, size );
 	}
 
 	public BatchBuilderImpl(int size) {
 		this.size = size;
 	}
 
 	public void setJdbcBatchSize(int size) {
 		this.size = size;
 	}
 
 	@Override
 	public Batch buildBatch(BatchKey key, JdbcCoordinator jdbcCoordinator) {
         LOG.tracef("Building batch [size=%s]", size);
 		return size > 1
 				? new BatchingBatch( key, jdbcCoordinator, size )
 				: new NonBatchingBatch( key, jdbcCoordinator );
 	}
 
 	@Override
 	public String getManagementDomain() {
 		return null; // use Hibernate default domain
 	}
 
 	@Override
 	public String getManagementServiceType() {
 		return null;  // use Hibernate default scheme
 	}
 
 	@Override
 	public Object getManagementBean() {
 		return this;
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
index 26f9a74137..25d503df50 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
@@ -1,134 +1,135 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.batch.internal;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Map;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
+
 import org.jboss.logging.Logger;
 
 /**
  * A {@link org.hibernate.engine.jdbc.batch.spi.Batch} implementation which does bathing based on a given size.  Once
  * the batch size is reached for a statement in the batch, the entire batch is implicitly executed.
  *
  * @author Steve Ebersole
  */
 public class BatchingBatch extends AbstractBatchImpl {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BatchingBatch.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BatchingBatch.class.getName());
 
 	// IMPL NOTE : Until HHH-5797 is fixed, there will only be 1 statement in a batch
 
 	private final int batchSize;
 	private int batchPosition;
 	private int statementPosition;
 
 	public BatchingBatch(
 			BatchKey key,
 			JdbcCoordinator jdbcCoordinator,
 			int batchSize) {
 		super( key, jdbcCoordinator );
 		if ( ! key.getExpectation().canBeBatched() ) {
 			throw new HibernateException( "attempting to batch an operation which cannot be batched" );
 		}
 		this.batchSize = batchSize;
 	}
 
 	private String currentStatementSql;
 	private PreparedStatement currentStatement;
 
 	@Override
 	public PreparedStatement getBatchStatement(String sql, boolean callable) {
 		currentStatementSql = sql;
 		currentStatement = super.getBatchStatement( sql, callable );
 		return currentStatement;
 	}
 
 	@Override
 	public void addToBatch() {
 		try {
 			currentStatement.addBatch();
 		}
 		catch ( SQLException e ) {
 			LOG.debugf( "SQLException escaped proxy", e );
 			throw sqlExceptionHelper().convert( e, "could not perform addBatch", currentStatementSql );
 		}
 		statementPosition++;
 		if ( statementPosition >= getKey().getBatchedStatementCount() ) {
 			batchPosition++;
 			if ( batchPosition == batchSize ) {
 				notifyObserversImplicitExecution();
 				performExecution();
 				batchPosition = 0;
 			}
 			statementPosition = 0;
 		}
 	}
 
 	@Override
 	protected void doExecuteBatch() {
 		if ( batchPosition == 0 ) {
 		    LOG.debugf("No batched statements to execute");
 		}
 		else {
 			LOG.debugf( "Executing batch size: %s", batchPosition );
 			performExecution();
 		}
 	}
 
 	private void performExecution() {
 		try {
 			for ( Map.Entry<String,PreparedStatement> entry : getStatements().entrySet() ) {
 				try {
 					final PreparedStatement statement = entry.getValue();
 					checkRowCounts( statement.executeBatch(), statement );
 				}
 				catch ( SQLException e ) {
 		            LOG.debugf( "SQLException escaped proxy", e );
 					throw sqlExceptionHelper().convert( e, "could not perform addBatch", entry.getKey() );
 				}
 			}
 		}
 		catch ( RuntimeException re ) {
 			LOG.unableToExecuteBatch( re.getMessage() );
 			throw re;
 		}
 		finally {
 			batchPosition = 0;
 		}
 	}
 
 	private void checkRowCounts(int[] rowCounts, PreparedStatement ps) throws SQLException, HibernateException {
 		int numberOfRowCounts = rowCounts.length;
 		if ( numberOfRowCounts != batchPosition ) {
             LOG.unexpectedRowCounts();
 		}
 		for ( int i = 0; i < numberOfRowCounts; i++ ) {
 			getKey().getExpectation().verifyOutcome( rowCounts[i], ps, i );
 		}
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/NonBatchingBatch.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/NonBatchingBatch.java
index 4dacb7504d..aa9abbc124 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/NonBatchingBatch.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/NonBatchingBatch.java
@@ -1,75 +1,77 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.batch.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
+
 import org.jboss.logging.Logger;
 
 /**
  * An implementation of {@link org.hibernate.engine.jdbc.batch.spi.Batch} which does not perform batching.  It simply
  * executes each statement as it is encountered.
  *
  * @author Steve Ebersole
  */
 public class NonBatchingBatch extends AbstractBatchImpl {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, NonBatchingBatch.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, NonBatchingBatch.class.getName());
 
 	protected NonBatchingBatch(BatchKey key, JdbcCoordinator jdbcCoordinator) {
 		super( key, jdbcCoordinator );
 	}
 
 	@Override
 	public void addToBatch() {
 		notifyObserversImplicitExecution();
 		for ( Map.Entry<String,PreparedStatement> entry : getStatements().entrySet() ) {
 			try {
 				final PreparedStatement statement = entry.getValue();
 				final int rowCount = statement.executeUpdate();
 				getKey().getExpectation().verifyOutcome( rowCount, statement, 0 );
 				try {
 					statement.close();
 				}
 				catch (SQLException e) {
                     LOG.debug("Unable to close non-batched batch statement", e);
 				}
 			}
 			catch ( SQLException e ) {
                 LOG.debug("SQLException escaped proxy", e);
 				throw sqlExceptionHelper().convert( e, "could not execute batch statement", entry.getKey() );
 			}
 		}
 		getStatements().clear();
 	}
 
 	@Override
 	protected void doExecuteBatch() {
 		// nothing to do
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcCoordinatorImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcCoordinatorImpl.java
index 347ccb5875..f4f2874943 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcCoordinatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcCoordinatorImpl.java
@@ -1,241 +1,241 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.sql.Connection;
 import java.sql.SQLException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.jdbc.batch.spi.BatchBuilder;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.StatementPreparer;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.jdbc.WorkExecutor;
 
 import org.jboss.logging.Logger;
 
 /**
  * Standard Hibernate implementation of {@link JdbcCoordinator}
  * <p/>
  * IMPL NOTE : Custom serialization handling!
  *
  * @author Steve Ebersole
  */
 public class JdbcCoordinatorImpl implements JdbcCoordinator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JdbcCoordinatorImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JdbcCoordinatorImpl.class.getName());
 
 	private transient TransactionCoordinatorImpl transactionCoordinator;
 
 	private final transient LogicalConnectionImpl logicalConnection;
 
 	private transient Batch currentBatch;
 
 	public JdbcCoordinatorImpl(
 			Connection userSuppliedConnection,
 			TransactionCoordinatorImpl transactionCoordinator) {
 		this.transactionCoordinator = transactionCoordinator;
 		this.logicalConnection = new LogicalConnectionImpl(
 				userSuppliedConnection,
 				transactionCoordinator.getTransactionContext().getConnectionReleaseMode(),
 				transactionCoordinator.getTransactionContext().getTransactionEnvironment().getJdbcServices(),
 				transactionCoordinator.getTransactionContext().getJdbcConnectionAccess()
 		);
 	}
 
 	private JdbcCoordinatorImpl(LogicalConnectionImpl logicalConnection) {
 		this.logicalConnection = logicalConnection;
 	}
 
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		return transactionCoordinator;
 	}
 
 	@Override
 	public LogicalConnectionImplementor getLogicalConnection() {
 		return logicalConnection;
 	}
 
 	protected TransactionEnvironment transactionEnvironment() {
 		return getTransactionCoordinator().getTransactionContext().getTransactionEnvironment();
 	}
 
 	protected SessionFactoryImplementor sessionFactory() {
 		return transactionEnvironment().getSessionFactory();
 	}
 
 	protected BatchBuilder batchBuilder() {
 		return sessionFactory().getServiceRegistry().getService( BatchBuilder.class );
 	}
 
 	private SqlExceptionHelper sqlExceptionHelper() {
 		return transactionEnvironment().getJdbcServices().getSqlExceptionHelper();
 	}
 
 
 	private int flushDepth = 0;
 
 	@Override
 	public void flushBeginning() {
 		if ( flushDepth == 0 ) {
 			logicalConnection.disableReleases();
 		}
 		flushDepth++;
 	}
 
 	@Override
 	public void flushEnding() {
 		flushDepth--;
 		if ( flushDepth < 0 ) {
 			throw new HibernateException( "Mismatched flush handling" );
 		}
 		if ( flushDepth == 0 ) {
 			logicalConnection.enableReleases();
 		}
 	}
 
 	@Override
 	public Connection close() {
 		if ( currentBatch != null ) {
             LOG.closingUnreleasedBatch();
 			currentBatch.release();
 		}
 		return logicalConnection.close();
 	}
 
 	@Override
 	public Batch getBatch(BatchKey key) {
 		if ( currentBatch != null ) {
 			if ( currentBatch.getKey().equals( key ) ) {
 				return currentBatch;
 			}
 			else {
 				currentBatch.execute();
 				currentBatch.release();
 			}
 		}
 		currentBatch = batchBuilder().buildBatch( key, this );
 		return currentBatch;
 	}
 
 	@Override
 	public void abortBatch() {
 		if ( currentBatch != null ) {
 			currentBatch.release();
 		}
 	}
 
 	private transient StatementPreparer statementPreparer;
 
 	@Override
 	public StatementPreparer getStatementPreparer() {
 		if ( statementPreparer == null ) {
 			statementPreparer = new StatementPreparerImpl( this );
 		}
 		return statementPreparer;
 	}
 
 	@Override
 	public void setTransactionTimeOut(int timeOut) {
 		getStatementPreparer().setTransactionTimeOut( timeOut );
 	}
 
 	/**
 	 * To be called after local transaction completion.  Used to conditionally
 	 * release the JDBC connection aggressively if the configured release mode
 	 * indicates.
 	 */
 	public void afterTransaction() {
 		logicalConnection.afterTransaction();
 		if ( statementPreparer != null ) {
 			statementPreparer.unsetTransactionTimeOut();
 		}
 	}
 
 	@Override
 	public <T> T coordinateWork(WorkExecutorVisitable<T> work) {
 		Connection connection = getLogicalConnection().getDistinctConnectionProxy();
 		try {
 			T result = work.accept( new WorkExecutor<T>(), connection );
 			getLogicalConnection().afterStatementExecution();
 			return result;
 		}
 		catch ( SQLException e ) {
 			throw sqlExceptionHelper().convert( e, "error executing work" );
 		}
 		finally {
 			try {
 				if ( ! connection.isClosed() ) {
 					connection.close();
 				}
 			}
 			catch (SQLException e) {
                 LOG.debug("Error closing connection proxy", e);
 			}
 		}
 	}
 
 	public void executeBatch() {
 		if ( currentBatch != null ) {
 			currentBatch.execute();
 			currentBatch.release(); // needed?
 		}
 	}
 
 	@Override
 	public void cancelLastQuery() {
 		logicalConnection.getResourceRegistry().cancelLastQuery();
 	}
 
 
 	public void serialize(ObjectOutputStream oos) throws IOException {
 		if ( ! logicalConnection.isReadyForSerialization() ) {
 			throw new HibernateException( "Cannot serialize Session while connected" );
 		}
 		logicalConnection.serialize( oos );
 	}
 
 	public static JdbcCoordinatorImpl deserialize(
 			ObjectInputStream ois,
 			TransactionContext transactionContext) throws IOException, ClassNotFoundException {
 		return new JdbcCoordinatorImpl( LogicalConnectionImpl.deserialize( ois, transactionContext ) );
  	}
 
 	public void afterDeserialize(TransactionCoordinatorImpl transactionCoordinator) {
 		this.transactionCoordinator = transactionCoordinator;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcResourceRegistryImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcResourceRegistryImpl.java
index 121d009a79..69117a5400 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcResourceRegistryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcResourceRegistryImpl.java
@@ -1,299 +1,300 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.spi.InvalidatableWrapper;
 import org.hibernate.engine.jdbc.spi.JdbcResourceRegistry;
 import org.hibernate.engine.jdbc.spi.JdbcWrapper;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
+
 import org.jboss.logging.Logger;
 import org.jboss.logging.Logger.Level;
 
 /**
  * Standard implementation of the {@link org.hibernate.engine.jdbc.spi.JdbcResourceRegistry} contract
  *
  * @author Steve Ebersole
  */
 public class JdbcResourceRegistryImpl implements JdbcResourceRegistry {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        JdbcResourceRegistryImpl.class.getName());
 
 	private final HashMap<Statement,Set<ResultSet>> xref = new HashMap<Statement,Set<ResultSet>>();
 	private final Set<ResultSet> unassociatedResultSets = new HashSet<ResultSet>();
 	private final SqlExceptionHelper exceptionHelper;
 
 	private Statement lastQuery;
 
 	public JdbcResourceRegistryImpl(SqlExceptionHelper exceptionHelper) {
 		this.exceptionHelper = exceptionHelper;
 	}
 
 	public void register(Statement statement) {
         LOG.trace("Registering statement [" + statement + "]");
 		if ( xref.containsKey( statement ) ) {
 			throw new HibernateException( "statement already registered with JDBCContainer" );
 		}
 		xref.put( statement, null );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void registerLastQuery(Statement statement) {
         LOG.trace("Registering last query statement [" + statement + "]");
 		if ( statement instanceof JdbcWrapper ) {
 			JdbcWrapper<Statement> wrapper = ( JdbcWrapper<Statement> ) statement;
 			registerLastQuery( wrapper.getWrappedObject() );
 			return;
 		}
 		lastQuery = statement;
 	}
 
 	public void cancelLastQuery() {
 		try {
 			if (lastQuery != null) {
 				lastQuery.cancel();
 			}
 		}
 		catch (SQLException sqle) {
 			throw exceptionHelper.convert(
 			        sqle,
 			        "Cannot cancel query"
 				);
 		}
 		finally {
 			lastQuery = null;
 		}
 	}
 
 	public void release(Statement statement) {
         LOG.trace("Releasing statement [" + statement + "]");
 		Set<ResultSet> resultSets = xref.get( statement );
 		if ( resultSets != null ) {
 			for ( ResultSet resultSet : resultSets ) {
 				close( resultSet );
 			}
 			resultSets.clear();
 		}
 		xref.remove( statement );
 		close( statement );
 	}
 
 	public void register(ResultSet resultSet) {
         LOG.trace("Registering result set [" + resultSet + "]");
 		Statement statement;
 		try {
 			statement = resultSet.getStatement();
 		}
 		catch ( SQLException e ) {
 			throw exceptionHelper.convert( e, "unable to access statement from resultset" );
 		}
 		if ( statement != null ) {
             if (LOG.isEnabled(Level.WARN) && !xref.containsKey(statement)) LOG.unregisteredStatement();
 			Set<ResultSet> resultSets = xref.get( statement );
 			if ( resultSets == null ) {
 				resultSets = new HashSet<ResultSet>();
 				xref.put( statement, resultSets );
 			}
 			resultSets.add( resultSet );
 		}
 		else {
 			unassociatedResultSets.add( resultSet );
 		}
 	}
 
 	public void release(ResultSet resultSet) {
         LOG.trace("Releasing result set [" + resultSet + "]");
 		Statement statement;
 		try {
 			statement = resultSet.getStatement();
 		}
 		catch ( SQLException e ) {
 			throw exceptionHelper.convert( e, "unable to access statement from resultset" );
 		}
 		if ( statement != null ) {
             if (LOG.isEnabled(Level.WARN) && !xref.containsKey(statement)) LOG.unregisteredStatement();
 			Set<ResultSet> resultSets = xref.get( statement );
 			if ( resultSets != null ) {
 				resultSets.remove( resultSet );
 				if ( resultSets.isEmpty() ) {
 					xref.remove( statement );
 				}
 			}
 		}
 		else {
 			boolean removed = unassociatedResultSets.remove( resultSet );
             if (!removed) LOG.unregisteredResultSetWithoutStatement();
 		}
 		close( resultSet );
 	}
 
 	public boolean hasRegisteredResources() {
 		return ! xref.isEmpty() || ! unassociatedResultSets.isEmpty();
 	}
 
 	public void releaseResources() {
         LOG.trace("Releasing JDBC container resources [" + this + "]");
 		cleanup();
 	}
 
 	private void cleanup() {
 		for ( Map.Entry<Statement,Set<ResultSet>> entry : xref.entrySet() ) {
 			if ( entry.getValue() != null ) {
 				for ( ResultSet resultSet : entry.getValue() ) {
 					close( resultSet );
 				}
 				entry.getValue().clear();
 			}
 			close( entry.getKey() );
 		}
 		xref.clear();
 
 		for ( ResultSet resultSet : unassociatedResultSets ) {
 			close( resultSet );
 		}
 		unassociatedResultSets.clear();
 
 		// TODO: can ConcurrentModificationException still happen???
 		// Following is from old AbstractBatcher...
 		/*
 		Iterator iter = resultSetsToClose.iterator();
 		while ( iter.hasNext() ) {
 			try {
 				logCloseResults();
 				( ( ResultSet ) iter.next() ).close();
 			}
 			catch ( SQLException e ) {
 				// no big deal
 				log.warn( "Could not close a JDBC result set", e );
 			}
 			catch ( ConcurrentModificationException e ) {
 				// this has been shown to happen occasionally in rare cases
 				// when using a transaction manager + transaction-timeout
 				// where the timeout calls back through Hibernate's
 				// registered transaction synchronization on a separate
 				// "reaping" thread.  In cases where that reaping thread
 				// executes through this block at the same time the main
 				// application thread does we can get into situations where
 				// these CMEs occur.  And though it is not "allowed" per-se,
 				// the end result without handling it specifically is infinite
 				// looping.  So here, we simply break the loop
 				log.info( "encountered CME attempting to release batcher; assuming cause is tx-timeout scenario and ignoring" );
 				break;
 			}
 			catch ( Throwable e ) {
 				// sybase driver (jConnect) throwing NPE here in certain
 				// cases, but we'll just handle the general "unexpected" case
 				log.warn( "Could not close a JDBC result set", e );
 			}
 		}
 		resultSetsToClose.clear();
 
 		iter = statementsToClose.iterator();
 		while ( iter.hasNext() ) {
 			try {
 				closeQueryStatement( ( PreparedStatement ) iter.next() );
 			}
 			catch ( ConcurrentModificationException e ) {
 				// see explanation above...
 				log.info( "encountered CME attempting to release batcher; assuming cause is tx-timeout scenario and ignoring" );
 				break;
 			}
 			catch ( SQLException e ) {
 				// no big deal
 				log.warn( "Could not close a JDBC statement", e );
 			}
 		}
 		statementsToClose.clear();
         */
 	}
 
 	public void close() {
         LOG.trace("Closing JDBC container [" + this + "]");
 		cleanup();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected void close(Statement statement) {
         LOG.trace("Closing prepared statement [" + statement + "]");
 
 		if ( statement instanceof InvalidatableWrapper ) {
 			InvalidatableWrapper<Statement> wrapper = ( InvalidatableWrapper<Statement> ) statement;
 			close( wrapper.getWrappedObject() );
 			wrapper.invalidate();
 			return;
 		}
 
 		try {
 			// if we are unable to "clean" the prepared statement,
 			// we do not close it
 			try {
 				if ( statement.getMaxRows() != 0 ) {
 					statement.setMaxRows( 0 );
 				}
 				if ( statement.getQueryTimeout() != 0 ) {
 					statement.setQueryTimeout( 0 );
 				}
 			}
 			catch( SQLException sqle ) {
 				// there was a problem "cleaning" the prepared statement
                 LOG.debugf("Exception clearing maxRows/queryTimeout [%s]", sqle.getMessage());
 				return; // EARLY EXIT!!!
 			}
 			statement.close();
 			if ( lastQuery == statement ) {
 				lastQuery = null;
 			}
 		}
 		catch( SQLException sqle ) {
             LOG.debugf("Unable to release statement [%s]", sqle.getMessage());
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected void close(ResultSet resultSet) {
         LOG.trace("Closing result set [" + resultSet + "]");
 
 		if ( resultSet instanceof InvalidatableWrapper ) {
 			InvalidatableWrapper<ResultSet> wrapper = (InvalidatableWrapper<ResultSet>) resultSet;
 			close( wrapper.getWrappedObject() );
 			wrapper.invalidate();
 		}
 
 		try {
 			resultSet.close();
 		}
 		catch( SQLException e ) {
             LOG.debugf("Unable to release result set [%s]", e.getMessage());
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcServicesImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcServicesImpl.java
index 400f575011..f6da35c108 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcServicesImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcServicesImpl.java
@@ -1,425 +1,425 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.lang.reflect.InvocationTargetException;
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.LinkedHashSet;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.spi.ExtractedDatabaseMetaData;
 import org.hibernate.engine.jdbc.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.ResultSetWrapper;
 import org.hibernate.engine.jdbc.spi.SchemaNameResolver;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.jdbc.connections.spi.MultiTenantConnectionProvider;
 import org.hibernate.service.jdbc.dialect.spi.DialectFactory;
 import org.hibernate.service.spi.Configurable;
 import org.hibernate.service.spi.ServiceRegistryAwareService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 
 /**
  * Standard implementation of the {@link JdbcServices} contract
  *
  * @author Steve Ebersole
  */
 public class JdbcServicesImpl implements JdbcServices, ServiceRegistryAwareService, Configurable {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JdbcServicesImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JdbcServicesImpl.class.getName());
 
 	private ServiceRegistryImplementor serviceRegistry;
 
 	private Dialect dialect;
 	private ConnectionProvider connectionProvider;
 	private SqlStatementLogger sqlStatementLogger;
 	private SqlExceptionHelper sqlExceptionHelper;
 	private ExtractedDatabaseMetaData extractedMetaDataSupport;
 	private LobCreatorBuilder lobCreatorBuilder;
 
 	@Override
 	public void injectServices(ServiceRegistryImplementor serviceRegistry) {
 		this.serviceRegistry = serviceRegistry;
 	}
 
 	@Override
 	public void configure(Map configValues) {
 		final JdbcConnectionAccess jdbcConnectionAccess = buildJdbcConnectionAccess( configValues );
 		final DialectFactory dialectFactory = serviceRegistry.getService( DialectFactory.class );
 
 		Dialect dialect = null;
 		LobCreatorBuilder lobCreatorBuilder = null;
 
 		boolean metaSupportsScrollable = false;
 		boolean metaSupportsGetGeneratedKeys = false;
 		boolean metaSupportsBatchUpdates = false;
 		boolean metaReportsDDLCausesTxnCommit = false;
 		boolean metaReportsDDLInTxnSupported = true;
 		String extraKeywordsString = "";
 		int sqlStateType = -1;
 		boolean lobLocatorUpdateCopy = false;
 		String catalogName = null;
 		String schemaName = null;
 		LinkedHashSet<TypeInfo> typeInfoSet = new LinkedHashSet<TypeInfo>();
 
 		// 'hibernate.temp.use_jdbc_metadata_defaults' is a temporary magic value.
 		// The need for it is intended to be alleviated with future development, thus it is
 		// not defined as an Environment constant...
 		//
 		// it is used to control whether we should consult the JDBC metadata to determine
 		// certain Settings default values; it is useful to *not* do this when the database
 		// may not be available (mainly in tools usage).
 		boolean useJdbcMetadata = ConfigurationHelper.getBoolean( "hibernate.temp.use_jdbc_metadata_defaults", configValues, true );
 		if ( useJdbcMetadata ) {
 			try {
 				Connection connection = jdbcConnectionAccess.obtainConnection();
 				try {
 					DatabaseMetaData meta = connection.getMetaData();
                     LOG.database(meta.getDatabaseProductName(),
                                  meta.getDatabaseProductVersion(),
                                  meta.getDatabaseMajorVersion(),
                                  meta.getDatabaseMinorVersion());
                     LOG.driver(meta.getDriverName(),
                                meta.getDriverVersion(),
                                meta.getDriverMajorVersion(),
                                meta.getDriverMinorVersion());
                     LOG.jdbcVersion(meta.getJDBCMajorVersion(), meta.getJDBCMinorVersion());
 
 					metaSupportsScrollable = meta.supportsResultSetType( ResultSet.TYPE_SCROLL_INSENSITIVE );
 					metaSupportsBatchUpdates = meta.supportsBatchUpdates();
 					metaReportsDDLCausesTxnCommit = meta.dataDefinitionCausesTransactionCommit();
 					metaReportsDDLInTxnSupported = !meta.dataDefinitionIgnoredInTransactions();
 					metaSupportsGetGeneratedKeys = meta.supportsGetGeneratedKeys();
 					extraKeywordsString = meta.getSQLKeywords();
 					sqlStateType = meta.getSQLStateType();
 					lobLocatorUpdateCopy = meta.locatorsUpdateCopy();
 					typeInfoSet.addAll( TypeInfoExtracter.extractTypeInfo( meta ) );
 
 					dialect = dialectFactory.buildDialect( configValues, connection );
 
 					catalogName = connection.getCatalog();
 					SchemaNameResolver schemaNameResolver = determineExplicitSchemaNameResolver( configValues );
 					if ( schemaNameResolver == null ) {
 // todo : add dialect method
 //						schemaNameResolver = dialect.getSchemaNameResolver();
 					}
 					if ( schemaNameResolver != null ) {
 						schemaName = schemaNameResolver.resolveSchemaName( connection );
 					}
 					lobCreatorBuilder = new LobCreatorBuilder( configValues, connection );
 				}
 				catch ( SQLException sqle ) {
                     LOG.unableToObtainConnectionMetadata(sqle.getMessage());
 				}
 				finally {
 					if ( connection != null ) {
 						jdbcConnectionAccess.releaseConnection( connection );
 					}
 				}
 			}
 			catch ( SQLException sqle ) {
                 LOG.unableToObtainConnectionToQueryMetadata(sqle.getMessage());
 				dialect = dialectFactory.buildDialect( configValues, null );
 			}
 			catch ( UnsupportedOperationException uoe ) {
 				// user supplied JDBC connections
 				dialect = dialectFactory.buildDialect( configValues, null );
 			}
 		}
 		else {
 			dialect = dialectFactory.buildDialect( configValues, null );
 		}
 
 		final boolean showSQL = ConfigurationHelper.getBoolean( Environment.SHOW_SQL, configValues, false );
 		final boolean formatSQL = ConfigurationHelper.getBoolean( Environment.FORMAT_SQL, configValues, false );
 
 		this.dialect = dialect;
 		this.lobCreatorBuilder = (
 				lobCreatorBuilder == null ?
 						new LobCreatorBuilder( configValues, null ) :
 						lobCreatorBuilder
 		);
 
 		this.sqlStatementLogger =  new SqlStatementLogger( showSQL, formatSQL );
 		this.sqlExceptionHelper = new SqlExceptionHelper( dialect.buildSQLExceptionConverter() );
 		this.extractedMetaDataSupport = new ExtractedDatabaseMetaDataImpl(
 				metaSupportsScrollable,
 				metaSupportsGetGeneratedKeys,
 				metaSupportsBatchUpdates,
 				metaReportsDDLInTxnSupported,
 				metaReportsDDLCausesTxnCommit,
 				parseKeywords( extraKeywordsString ),
 				parseSQLStateType( sqlStateType ),
 				lobLocatorUpdateCopy,
 				schemaName,
 				catalogName,
 				typeInfoSet
 		);
 	}
 
 	private JdbcConnectionAccess buildJdbcConnectionAccess(Map configValues) {
 		final MultiTenancyStrategy multiTenancyStrategy = MultiTenancyStrategy.determineMultiTenancyStrategy( configValues );
 
 		if ( MultiTenancyStrategy.NONE == multiTenancyStrategy ) {
 			connectionProvider = serviceRegistry.getService( ConnectionProvider.class );
 			return new ConnectionProviderJdbcConnectionAccess( connectionProvider );
 		}
 		else {
 			connectionProvider = null;
 			final MultiTenantConnectionProvider multiTenantConnectionProvider = serviceRegistry.getService( MultiTenantConnectionProvider.class );
 			return new MultiTenantConnectionProviderJdbcConnectionAccess( multiTenantConnectionProvider );
 		}
 	}
 
 	private static class ConnectionProviderJdbcConnectionAccess implements JdbcConnectionAccess {
 		private final ConnectionProvider connectionProvider;
 
 		public ConnectionProviderJdbcConnectionAccess(ConnectionProvider connectionProvider) {
 			this.connectionProvider = connectionProvider;
 		}
 
 		@Override
 		public Connection obtainConnection() throws SQLException {
 			return connectionProvider.getConnection();
 		}
 
 		@Override
 		public void releaseConnection(Connection connection) throws SQLException {
 			connection.close();
 		}
 	}
 
 	private static class MultiTenantConnectionProviderJdbcConnectionAccess implements JdbcConnectionAccess {
 		private final MultiTenantConnectionProvider connectionProvider;
 
 		public MultiTenantConnectionProviderJdbcConnectionAccess(MultiTenantConnectionProvider connectionProvider) {
 			this.connectionProvider = connectionProvider;
 		}
 
 		@Override
 		public Connection obtainConnection() throws SQLException {
 			return connectionProvider.getAnyConnection();
 		}
 
 		@Override
 		public void releaseConnection(Connection connection) throws SQLException {
 			connection.close();
 		}
 	}
 
 
 	// todo : add to Environment
 	public static final String SCHEMA_NAME_RESOLVER = "hibernate.schema_name_resolver";
 
 	private SchemaNameResolver determineExplicitSchemaNameResolver(Map configValues) {
 		Object setting = configValues.get( SCHEMA_NAME_RESOLVER );
 		if ( SchemaNameResolver.class.isInstance( setting ) ) {
 			return (SchemaNameResolver) setting;
 		}
 
 		String resolverClassName = (String) setting;
 		if ( resolverClassName != null ) {
 			try {
 				Class resolverClass = ReflectHelper.classForName( resolverClassName, getClass() );
 				return (SchemaNameResolver) ReflectHelper.getDefaultConstructor( resolverClass ).newInstance();
 			}
 			catch ( ClassNotFoundException e ) {
                 LOG.unableToLocateConfiguredSchemaNameResolver(resolverClassName, e.toString());
 			}
 			catch ( InvocationTargetException e ) {
                 LOG.unableToInstantiateConfiguredSchemaNameResolver(resolverClassName, e.getTargetException().toString());
 			}
 			catch ( Exception e ) {
                 LOG.unableToInstantiateConfiguredSchemaNameResolver(resolverClassName, e.toString());
 			}
 		}
 		return null;
 	}
 
 	private Set<String> parseKeywords(String extraKeywordsString) {
 		Set<String> keywordSet = new HashSet<String>();
 		keywordSet.addAll( Arrays.asList( extraKeywordsString.split( "," ) ) );
 		return keywordSet;
 	}
 
 	private ExtractedDatabaseMetaData.SQLStateType parseSQLStateType(int sqlStateType) {
 		switch ( sqlStateType ) {
 			case DatabaseMetaData.sqlStateSQL99 : {
 				return ExtractedDatabaseMetaData.SQLStateType.SQL99;
 			}
 			case DatabaseMetaData.sqlStateXOpen : {
 				return ExtractedDatabaseMetaData.SQLStateType.XOpen;
 			}
 			default : {
 				return ExtractedDatabaseMetaData.SQLStateType.UNKOWN;
 			}
 		}
 	}
 
 	private static class ExtractedDatabaseMetaDataImpl implements ExtractedDatabaseMetaData {
 		private final boolean supportsScrollableResults;
 		private final boolean supportsGetGeneratedKeys;
 		private final boolean supportsBatchUpdates;
 		private final boolean supportsDataDefinitionInTransaction;
 		private final boolean doesDataDefinitionCauseTransactionCommit;
 		private final Set<String> extraKeywords;
 		private final SQLStateType sqlStateType;
 		private final boolean lobLocatorUpdateCopy;
 		private final String connectionSchemaName;
 		private final String connectionCatalogName;
 		private final LinkedHashSet<TypeInfo> typeInfoSet;
 
 		private ExtractedDatabaseMetaDataImpl(
 				boolean supportsScrollableResults,
 				boolean supportsGetGeneratedKeys,
 				boolean supportsBatchUpdates,
 				boolean supportsDataDefinitionInTransaction,
 				boolean doesDataDefinitionCauseTransactionCommit,
 				Set<String> extraKeywords,
 				SQLStateType sqlStateType,
 				boolean lobLocatorUpdateCopy,
 				String connectionSchemaName,
 				String connectionCatalogName,
 				LinkedHashSet<TypeInfo> typeInfoSet) {
 			this.supportsScrollableResults = supportsScrollableResults;
 			this.supportsGetGeneratedKeys = supportsGetGeneratedKeys;
 			this.supportsBatchUpdates = supportsBatchUpdates;
 			this.supportsDataDefinitionInTransaction = supportsDataDefinitionInTransaction;
 			this.doesDataDefinitionCauseTransactionCommit = doesDataDefinitionCauseTransactionCommit;
 			this.extraKeywords = extraKeywords;
 			this.sqlStateType = sqlStateType;
 			this.lobLocatorUpdateCopy = lobLocatorUpdateCopy;
 			this.connectionSchemaName = connectionSchemaName;
 			this.connectionCatalogName = connectionCatalogName;
 			this.typeInfoSet = typeInfoSet;
 		}
 
 		@Override
 		public boolean supportsScrollableResults() {
 			return supportsScrollableResults;
 		}
 
 		@Override
 		public boolean supportsGetGeneratedKeys() {
 			return supportsGetGeneratedKeys;
 		}
 
 		@Override
 		public boolean supportsBatchUpdates() {
 			return supportsBatchUpdates;
 		}
 
 		@Override
 		public boolean supportsDataDefinitionInTransaction() {
 			return supportsDataDefinitionInTransaction;
 		}
 
 		@Override
 		public boolean doesDataDefinitionCauseTransactionCommit() {
 			return doesDataDefinitionCauseTransactionCommit;
 		}
 
 		@Override
 		public Set<String> getExtraKeywords() {
 			return extraKeywords;
 		}
 
 		@Override
 		public SQLStateType getSqlStateType() {
 			return sqlStateType;
 		}
 
 		@Override
 		public boolean doesLobLocatorUpdateCopy() {
 			return lobLocatorUpdateCopy;
 		}
 
 		@Override
 		public String getConnectionSchemaName() {
 			return connectionSchemaName;
 		}
 
 		@Override
 		public String getConnectionCatalogName() {
 			return connectionCatalogName;
 		}
 
 		@Override
 		public LinkedHashSet<TypeInfo> getTypeInfoSet() {
 			return typeInfoSet;
 		}
 	}
 
 	@Override
 	public ConnectionProvider getConnectionProvider() {
 		return connectionProvider;
 	}
 
 	@Override
 	public SqlStatementLogger getSqlStatementLogger() {
 		return sqlStatementLogger;
 	}
 
 	@Override
 	public SqlExceptionHelper getSqlExceptionHelper() {
 		return sqlExceptionHelper;
 	}
 
 	@Override
 	public Dialect getDialect() {
 		return dialect;
 	}
 
 	@Override
 	public ExtractedDatabaseMetaData getExtractedMetaDataSupport() {
 		return extractedMetaDataSupport;
 	}
 
 	@Override
 	public LobCreator getLobCreator(LobCreationContext lobCreationContext) {
 		return lobCreatorBuilder.buildLobCreator( lobCreationContext );
 	}
 
 	@Override
 	public ResultSetWrapper getResultSetWrapper() {
 		return ResultSetWrapperImpl.INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LobCreatorBuilder.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LobCreatorBuilder.java
index 62388d40d1..f928f69fef 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LobCreatorBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LobCreatorBuilder.java
@@ -1,133 +1,135 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.lang.reflect.Method;
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
 import java.sql.SQLException;
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.ContextualLobCreator;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.NonContextualLobCreator;
 import org.hibernate.internal.util.config.ConfigurationHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * Builds {@link LobCreator} instances based on the capabilities of the environment.
  *
  * @author Steve Ebersole
  */
 public class LobCreatorBuilder {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, LobCreatorBuilder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, LobCreatorBuilder.class.getName());
 
     private boolean useContextualLobCreation;
 
 	/**
 	 * The public factory method for obtaining the appropriate (according to given JDBC {@link java.sql.Connection}.
 	 *
 	 *
 	 * @param jdbcConnection A JDBC {@link java.sql.Connection} which can be used to gauge the drivers level of support,
 	 * specifically for creating LOB references.
 	 */
 	public LobCreatorBuilder(Map configValues, Connection jdbcConnection) {
 		this.useContextualLobCreation = useContextualLobCreation( configValues, jdbcConnection );
 	}
 
 	private static final Class[] NO_ARG_SIG = new Class[0];
 	private static final Object[] NO_ARGS = new Object[0];
 
 	/**
 	 * Basically here we are simply checking whether we can call the {@link Connection} methods for
 	 * LOB creation added in JDBC 4.  We not only check whether the {@link Connection} declares these methods,
 	 * but also whether the actual {@link Connection} instance implements them (i.e. can be called without simply
 	 * throwing an exception).
 	 *
 	 * @param jdbcConnection The connection which can be used in level-of-support testing.
 	 *
 	 * @return True if the connection can be used to create LOBs; false otherwise.
 	 */
 	private static boolean useContextualLobCreation(Map configValues, Connection jdbcConnection) {
 		boolean isNonContextualLobCreationRequired =
 				ConfigurationHelper.getBoolean( Environment.NON_CONTEXTUAL_LOB_CREATION, configValues );
 		if ( isNonContextualLobCreationRequired ) {
             LOG.disablingContextualLOBCreation(Environment.NON_CONTEXTUAL_LOB_CREATION);
 			return false;
 		}
 		if ( jdbcConnection == null ) {
             LOG.disablingContextualLOBCreationSinceConnectionNull();
 			return false;
 		}
 
 		try {
 			try {
 				DatabaseMetaData meta = jdbcConnection.getMetaData();
 				// if the jdbc driver version is less than 4, it shouldn't have createClob
 				if ( meta.getJDBCMajorVersion() < 4 ) {
                     LOG.disablingContextualLOBCreationSinceOldJdbcVersion(meta.getJDBCMajorVersion());
 					return false;
 				}
 			}
 			catch ( SQLException ignore ) {
 				// ignore exception and continue
 			}
 
 			Class connectionClass = Connection.class;
 			Method createClobMethod = connectionClass.getMethod( "createClob", NO_ARG_SIG );
 			if ( createClobMethod.getDeclaringClass().equals( Connection.class ) ) {
 				// If we get here we are running in a jdk 1.6 (jdbc 4) environment...
 				// Further check to make sure the driver actually implements the LOB creation methods.  We
 				// check against createClob() as indicative of all; should we check against all 3 explicitly?
 				try {
 					Object clob = createClobMethod.invoke( jdbcConnection, NO_ARGS );
 					try {
 						Method freeMethod = clob.getClass().getMethod( "free", NO_ARG_SIG );
 						freeMethod.invoke( clob, NO_ARGS );
 					}
 					catch ( Throwable ignore ) {
                         LOG.tracef("Unable to free CLOB created to test createClob() implementation : %s", ignore);
 					}
 					return true;
 				}
 				catch ( Throwable t ) {
                     LOG.disablingContextualLOBCreationSinceCreateClobFailed(t);
 				}
 			}
 		}
 		catch ( NoSuchMethodException ignore ) {
 		}
 
 		return false;
 	}
 
 	public LobCreator buildLobCreator(LobCreationContext lobCreationContext) {
 		return useContextualLobCreation
 				? new ContextualLobCreator( lobCreationContext )
 				: NonContextualLobCreator.INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LogicalConnectionImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LogicalConnectionImpl.java
index 8220ef8d09..30d7f843a7 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LogicalConnectionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LogicalConnectionImpl.java
@@ -1,445 +1,446 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.engine.jdbc.internal.proxy.ProxyBuilder;
 import org.hibernate.engine.jdbc.spi.ConnectionObserver;
 import org.hibernate.engine.jdbc.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.spi.JdbcResourceRegistry;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
 import org.hibernate.engine.jdbc.spi.NonDurableConnectionObserver;
 import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.internal.util.collections.CollectionHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * Standard Hibernate {@link org.hibernate.engine.jdbc.spi.LogicalConnection} implementation
  * <p/>
  * IMPL NOTE : Custom serialization handling!
  *
  * @author Steve Ebersole
  */
 public class LogicalConnectionImpl implements LogicalConnectionImplementor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, LogicalConnectionImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, LogicalConnectionImpl.class.getName());
 
 	private transient Connection physicalConnection;
 	private transient Connection shareableConnectionProxy;
 
 	private final transient ConnectionReleaseMode connectionReleaseMode;
 	private final transient JdbcServices jdbcServices;
 	private final transient JdbcConnectionAccess jdbcConnectionAccess;
 	private final transient JdbcResourceRegistry jdbcResourceRegistry;
 	private final transient List<ConnectionObserver> observers;
 
 	private boolean releasesEnabled = true;
 
 	private final boolean isUserSuppliedConnection;
 
 	private boolean isClosed;
 
 	public LogicalConnectionImpl(
 			Connection userSuppliedConnection,
 			ConnectionReleaseMode connectionReleaseMode,
 			JdbcServices jdbcServices,
 			JdbcConnectionAccess jdbcConnectionAccess) {
 		this(
 				connectionReleaseMode,
 				jdbcServices,
 				jdbcConnectionAccess,
 				(userSuppliedConnection != null),
 				false,
 				new ArrayList<ConnectionObserver>()
 		);
 		this.physicalConnection = userSuppliedConnection;
 	}
 
 	private LogicalConnectionImpl(
 			ConnectionReleaseMode connectionReleaseMode,
 			JdbcServices jdbcServices,
 			JdbcConnectionAccess jdbcConnectionAccess,
 			boolean isUserSuppliedConnection,
 			boolean isClosed,
 			List<ConnectionObserver> observers) {
 		this.connectionReleaseMode = determineConnectionReleaseMode(
 				jdbcServices, isUserSuppliedConnection, connectionReleaseMode
 		);
 		this.jdbcServices = jdbcServices;
 		this.jdbcConnectionAccess = jdbcConnectionAccess;
 		this.jdbcResourceRegistry = new JdbcResourceRegistryImpl( getJdbcServices().getSqlExceptionHelper() );
 		this.observers = observers;
 
 		this.isUserSuppliedConnection = isUserSuppliedConnection;
 		this.isClosed = isClosed;
 	}
 
 	private static ConnectionReleaseMode determineConnectionReleaseMode(
 			JdbcServices jdbcServices,
 			boolean isUserSuppliedConnection,
 			ConnectionReleaseMode connectionReleaseMode) {
 		if ( isUserSuppliedConnection ) {
 			return ConnectionReleaseMode.ON_CLOSE;
 		}
 		else if ( connectionReleaseMode == ConnectionReleaseMode.AFTER_STATEMENT &&
 				! jdbcServices.getConnectionProvider().supportsAggressiveRelease() ) {
             LOG.debugf("Connection provider reports to not support aggressive release; overriding");
 			return ConnectionReleaseMode.AFTER_TRANSACTION;
 		}
 		else {
 			return connectionReleaseMode;
 		}
 	}
 
 	@Override
 	public JdbcServices getJdbcServices() {
 		return jdbcServices;
 	}
 
 	@Override
 	public JdbcResourceRegistry getResourceRegistry() {
 		return jdbcResourceRegistry;
 	}
 
 	@Override
 	public void addObserver(ConnectionObserver observer) {
 		observers.add( observer );
 	}
 
 	@Override
 	public void removeObserver(ConnectionObserver connectionObserver) {
 		observers.remove( connectionObserver );
 	}
 
 	@Override
 	public boolean isOpen() {
 		return !isClosed;
 	}
 
 	@Override
 	public boolean isPhysicallyConnected() {
 		return physicalConnection != null;
 	}
 
 	@Override
 	public Connection getConnection() throws HibernateException {
 		if ( isClosed ) {
 			throw new HibernateException( "Logical connection is closed" );
 		}
 		if ( physicalConnection == null ) {
 			if ( isUserSuppliedConnection ) {
 				// should never happen
 				throw new HibernateException( "User-supplied connection was null" );
 			}
 			obtainConnection();
 		}
 		return physicalConnection;
 	}
 
 	@Override
 	public Connection getShareableConnectionProxy() {
 		if ( shareableConnectionProxy == null ) {
 			shareableConnectionProxy = buildConnectionProxy();
 		}
 		return shareableConnectionProxy;
 	}
 
 	private Connection buildConnectionProxy() {
 		return ProxyBuilder.buildConnection( this );
 	}
 
 	@Override
 	public Connection getDistinctConnectionProxy() {
 		return buildConnectionProxy();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Connection close() {
 		LOG.trace( "Closing logical connection" );
 		Connection c = isUserSuppliedConnection ? physicalConnection : null;
 		try {
 			releaseProxies();
 			jdbcResourceRegistry.close();
 			if ( !isUserSuppliedConnection && physicalConnection != null ) {
 				releaseConnection();
 			}
 			return c;
 		}
 		finally {
 			// no matter what
 			physicalConnection = null;
 			isClosed = true;
             LOG.trace("Logical connection closed");
 			for ( ConnectionObserver observer : observers ) {
 				observer.logicalConnectionClosed();
 			}
 			observers.clear();
 		}
 	}
 
 	private void releaseProxies() {
 		if ( shareableConnectionProxy != null ) {
 			try {
 				shareableConnectionProxy.close();
 			}
 			catch (SQLException e) {
 				LOG.debug( "Error releasing shared connection proxy", e );
 			}
 		}
 		shareableConnectionProxy = null;
 	}
 
 	@Override
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return connectionReleaseMode;
 	}
 
 	@Override
 	public void afterStatementExecution() {
         LOG.trace("Starting after statement execution processing [" + connectionReleaseMode + "]");
 		if ( connectionReleaseMode == ConnectionReleaseMode.AFTER_STATEMENT ) {
 			if ( ! releasesEnabled ) {
                 LOG.debugf("Skipping aggressive release due to manual disabling");
 				return;
 			}
 			if ( jdbcResourceRegistry.hasRegisteredResources() ) {
                 LOG.debugf("Skipping aggressive release due to registered resources");
 				return;
 			}
 			releaseConnection();
 		}
 	}
 
 	@Override
 	public void afterTransaction() {
 		if ( connectionReleaseMode == ConnectionReleaseMode.AFTER_STATEMENT ||
 				connectionReleaseMode == ConnectionReleaseMode.AFTER_TRANSACTION ) {
 			if ( jdbcResourceRegistry.hasRegisteredResources() ) {
                 LOG.forcingContainerResourceCleanup();
 				jdbcResourceRegistry.releaseResources();
 			}
 			aggressiveRelease();
 		}
 	}
 
 	@Override
 	public void disableReleases() {
         LOG.trace("Disabling releases");
 		releasesEnabled = false;
 	}
 
 	@Override
 	public void enableReleases() {
         LOG.trace("(Re)enabling releases");
 		releasesEnabled = true;
 		afterStatementExecution();
 	}
 
 	/**
 	 * Force aggressive release of the underlying connection.
 	 */
 	public void aggressiveRelease() {
         if (isUserSuppliedConnection) LOG.debugf("Cannot aggressively release user-supplied connection; skipping");
 		else {
             LOG.debugf("Aggressively releasing JDBC connection");
 			if ( physicalConnection != null ) {
 				releaseConnection();
 			}
 		}
 	}
 
 
 	/**
 	 * Physically opens a JDBC Connection.
 	 *
 	 * @throws org.hibernate.JDBCException Indicates problem opening a connection
 	 */
 	private void obtainConnection() throws JDBCException {
         LOG.debugf("Obtaining JDBC connection");
 		try {
 			physicalConnection = jdbcConnectionAccess.obtainConnection();
 			for ( ConnectionObserver observer : observers ) {
 				observer.physicalConnectionObtained( physicalConnection );
 			}
             LOG.debugf("Obtained JDBC connection");
 		}
 		catch ( SQLException sqle) {
 			throw getJdbcServices().getSqlExceptionHelper().convert( sqle, "Could not open connection" );
 		}
 	}
 
 	/**
 	 * Physically closes the JDBC Connection.
 	 *
 	 * @throws JDBCException Indicates problem closing a connection
 	 */
 	private void releaseConnection() throws JDBCException {
         LOG.debugf("Releasing JDBC connection");
 		if ( physicalConnection == null ) {
 			return;
 		}
 		try {
             if ( ! physicalConnection.isClosed() ) {
 				getJdbcServices().getSqlExceptionHelper().logAndClearWarnings( physicalConnection );
 			}
             if ( ! isUserSuppliedConnection ) {
 				jdbcConnectionAccess.releaseConnection( physicalConnection );
 			}
 		}
 		catch (SQLException e) {
 			throw getJdbcServices().getSqlExceptionHelper().convert( e, "Could not close connection" );
 		}
 		finally {
 			physicalConnection = null;
 		}
         LOG.debugf("Released JDBC connection");
 		for ( ConnectionObserver observer : observers ) {
 			observer.physicalConnectionReleased();
 		}
 		releaseNonDurableObservers();
 	}
 
 	private void releaseNonDurableObservers() {
 		Iterator observers = this.observers.iterator();
 		while ( observers.hasNext() ) {
 			if ( NonDurableConnectionObserver.class.isInstance( observers.next() ) ) {
 				observers.remove();
 			}
 		}
 	}
 
 	@Override
 	public Connection manualDisconnect() {
 		if ( isClosed ) {
 			throw new IllegalStateException( "cannot manually disconnect because logical connection is already closed" );
 		}
 		releaseProxies();
 		Connection c = physicalConnection;
 		jdbcResourceRegistry.releaseResources();
 		releaseConnection();
 		return c;
 	}
 
 	@Override
 	public void manualReconnect(Connection suppliedConnection) {
 		if ( isClosed ) {
 			throw new IllegalStateException( "cannot manually reconnect because logical connection is already closed" );
 		}
 		if ( !isUserSuppliedConnection ) {
 			throw new IllegalStateException( "cannot manually reconnect unless Connection was originally supplied" );
 		}
 		else {
 			if ( suppliedConnection == null ) {
 				throw new IllegalArgumentException( "cannot reconnect a null user-supplied connection" );
 			}
 			else if ( suppliedConnection == physicalConnection ) {
                 LOG.debug("reconnecting the same connection that is already connected; should this connection have been disconnected?");
 			}
 			else if ( physicalConnection != null ) {
 				throw new IllegalArgumentException(
 						"cannot reconnect to a new user-supplied connection because currently connected; must disconnect before reconnecting."
 				);
 			}
 			physicalConnection = suppliedConnection;
             LOG.debugf("Reconnected JDBC connection");
 		}
 	}
 
 	@Override
 	public boolean isAutoCommit() {
 		if ( !isOpen() || ! isPhysicallyConnected() ) {
 			return true;
 		}
 
 		try {
 			return getConnection().getAutoCommit();
 		}
 		catch (SQLException e) {
 			throw jdbcServices.getSqlExceptionHelper().convert( e, "could not inspect JDBC autocommit mode" );
 		}
 	}
 
 	@Override
 	public void notifyObserversStatementPrepared() {
 		for ( ConnectionObserver observer : observers ) {
 			observer.statementPrepared();
 		}
 	}
 
 	@Override
 	public boolean isReadyForSerialization() {
 		return isUserSuppliedConnection
 				? ! isPhysicallyConnected()
 				: ! getResourceRegistry().hasRegisteredResources();
 	}
 
 	public void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeBoolean( isUserSuppliedConnection );
 		oos.writeBoolean( isClosed );
 		List<ConnectionObserver> durableConnectionObservers = new ArrayList<ConnectionObserver>();
 		for ( ConnectionObserver observer : observers ) {
 			if ( ! NonDurableConnectionObserver.class.isInstance( observer ) ) {
 				durableConnectionObservers.add( observer );
 			}
 		}
 		oos.writeInt( durableConnectionObservers.size() );
 		for ( ConnectionObserver observer : durableConnectionObservers ) {
 			oos.writeObject( observer );
 		}
 	}
 
 	public static LogicalConnectionImpl deserialize(
 			ObjectInputStream ois,
 			TransactionContext transactionContext) throws IOException, ClassNotFoundException {
 		boolean isUserSuppliedConnection = ois.readBoolean();
 		boolean isClosed = ois.readBoolean();
 		int observerCount = ois.readInt();
 		List<ConnectionObserver> observers = CollectionHelper.arrayList( observerCount );
 		for ( int i = 0; i < observerCount; i++ ) {
 			observers.add( (ConnectionObserver) ois.readObject() );
 		}
 		return new LogicalConnectionImpl(
 				transactionContext.getConnectionReleaseMode(),
 				transactionContext.getTransactionEnvironment().getJdbcServices(),
 				transactionContext.getJdbcConnectionAccess(),
 				isUserSuppliedConnection,
 				isClosed,
 				observers
 		);
  	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/TypeInfoExtracter.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/TypeInfoExtracter.java
index 495f8c1f31..68593725a9 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/TypeInfoExtracter.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/TypeInfoExtracter.java
@@ -1,103 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.LinkedHashSet;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.collections.ArrayHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * Helper to extract type innformation from {@link DatabaseMetaData JDBC metadata}
  *
  * @author Steve Ebersole
  */
 public class TypeInfoExtracter {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TypeInfoExtracter.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TypeInfoExtracter.class.getName());
 
 	private TypeInfoExtracter() {
 	}
 
 	/**
 	 * Perform the extraction
 	 *
 	 * @param metaData The JDBC metadata
 	 *
 	 * @return The extracted metadata
 	 */
 	public static LinkedHashSet<TypeInfo> extractTypeInfo(DatabaseMetaData metaData) {
 		LinkedHashSet<TypeInfo> typeInfoSet = new LinkedHashSet<TypeInfo>();
 		try {
 			ResultSet resultSet = metaData.getTypeInfo();
 			try {
 				while ( resultSet.next() ) {
 					typeInfoSet.add(
 							new TypeInfo(
 									resultSet.getString( "TYPE_NAME" ),
 									resultSet.getInt( "DATA_TYPE" ),
 									interpretCreateParams( resultSet.getString( "CREATE_PARAMS" ) ),
 									resultSet.getBoolean( "UNSIGNED_ATTRIBUTE" ),
 									resultSet.getInt( "PRECISION" ),
 									resultSet.getShort( "MINIMUM_SCALE" ),
 									resultSet.getShort( "MAXIMUM_SCALE" ),
 									resultSet.getBoolean( "FIXED_PREC_SCALE" ),
 									resultSet.getString( "LITERAL_PREFIX" ),
 									resultSet.getString( "LITERAL_SUFFIX" ),
 									resultSet.getBoolean( "CASE_SENSITIVE" ),
 									TypeSearchability.interpret( resultSet.getShort( "SEARCHABLE" ) ),
 									TypeNullability.interpret( resultSet.getShort( "NULLABLE" ) )
 							)
 					);
 				}
 			}
 			catch ( SQLException e ) {
                 LOG.unableToAccessTypeInfoResultSet(e.toString());
 			}
 			finally {
 				try {
 					resultSet.close();
 				}
 				catch ( SQLException e ) {
                     LOG.unableToReleaseTypeInfoResultSet();
 				}
 			}
 		}
 		catch ( SQLException e ) {
             LOG.unableToRetrieveTypeInfoResultSet(e.toString());
 		}
 
 		return typeInfoSet;
 	}
 
 	private static String[] interpretCreateParams(String value) {
 		if ( value == null || value.length() == 0 ) {
 			return ArrayHelper.EMPTY_STRING_ARRAY;
 		}
 		return value.split( "," );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/AbstractResultSetProxyHandler.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/AbstractResultSetProxyHandler.java
index 13b03218f5..26f3623f69 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/AbstractResultSetProxyHandler.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/AbstractResultSetProxyHandler.java
@@ -1,122 +1,124 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal.proxy;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.spi.JdbcResourceRegistry;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
+
 import org.jboss.logging.Logger;
 
 /**
  * Basic support for building {@link ResultSet}-based proxy handlers
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractResultSetProxyHandler extends AbstractProxyHandler {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractResultSetProxyHandler.class.getName());
 
 	private ResultSet resultSet;
 
 	public AbstractResultSetProxyHandler(ResultSet resultSet) {
 		super( resultSet.hashCode() );
 		this.resultSet = resultSet;
 	}
 
 	protected abstract JdbcServices getJdbcServices();
 
 	protected abstract JdbcResourceRegistry getResourceRegistry();
 
 	protected abstract Statement getExposableStatement();
 
 	protected final ResultSet getResultSet() {
 		errorIfInvalid();
 		return resultSet;
 	}
 
 	protected final ResultSet getResultSetWithoutChecks() {
 		return resultSet;
 	}
 
 	@Override
     protected Object continueInvocation(Object proxy, Method method, Object[] args) throws Throwable {
 		String methodName = method.getName();
         LOG.trace("Handling invocation of ResultSet method [" + methodName + "]");
 
 		// other methods allowed while invalid ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		if ( "close".equals( methodName ) ) {
 			explicitClose( ( ResultSet ) proxy );
 			return null;
 		}
 		if ( "invalidate".equals( methodName ) ) {
 			invalidateHandle();
 			return null;
 		}
 
 		errorIfInvalid();
 
 		// handle the JDBC 4 Wrapper#isWrapperFor and Wrapper#unwrap calls
 		//		these cause problems to the whole proxy scheme though as we need to return the raw objects
 		if ( "isWrapperFor".equals( methodName ) && args.length == 1 ) {
 			return method.invoke( getResultSetWithoutChecks(), args );
 		}
 		if ( "unwrap".equals( methodName ) && args.length == 1 ) {
 			return method.invoke( getResultSetWithoutChecks(), args );
 		}
 
 		if ( "getWrappedObject".equals( methodName ) ) {
 			return getResultSetWithoutChecks();
 		}
 
 		if ( "getStatement".equals( methodName ) ) {
 			return getExposableStatement();
 		}
 
 		try {
 			return method.invoke( resultSet, args );
 		}
 		catch ( InvocationTargetException e ) {
 			Throwable realException = e.getTargetException();
             if (SQLException.class.isInstance(realException)) throw getJdbcServices().getSqlExceptionHelper().convert((SQLException)realException,
                                                                                                                       realException.getMessage());
             throw realException;
 		}
 	}
 
 	private void explicitClose(ResultSet proxy) {
 		if ( isValid() ) {
 			getResourceRegistry().release( proxy );
 		}
 	}
 
 	protected void invalidateHandle() {
 		resultSet = null;
 		invalidate();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/AbstractStatementProxyHandler.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/AbstractStatementProxyHandler.java
index 7205917db0..4a8bb8e446 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/AbstractStatementProxyHandler.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/AbstractStatementProxyHandler.java
@@ -1,168 +1,170 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal.proxy;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.sql.Connection;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.spi.JdbcResourceRegistry;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
+
 import org.jboss.logging.Logger;
 
 /**
  * Basic support for building {@link Statement}-based proxy handlers
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractStatementProxyHandler extends AbstractProxyHandler {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractStatementProxyHandler.class.getName());
 
 	private ConnectionProxyHandler connectionProxyHandler;
 	private Connection connectionProxy;
 	private Statement statement;
 
 	protected AbstractStatementProxyHandler(
 			Statement statement,
 			ConnectionProxyHandler connectionProxyHandler,
 			Connection connectionProxy) {
 		super( statement.hashCode() );
 		this.statement = statement;
 		this.connectionProxyHandler = connectionProxyHandler;
 		this.connectionProxy = connectionProxy;
 	}
 
 	protected ConnectionProxyHandler getConnectionProxy() {
 		errorIfInvalid();
 		return connectionProxyHandler;
 	}
 
 	protected JdbcServices getJdbcServices() {
 		return getConnectionProxy().getJdbcServices();
 	}
 
 	protected JdbcResourceRegistry getResourceRegistry() {
 		return getConnectionProxy().getResourceRegistry();
 	}
 
 	protected Statement getStatement() {
 		errorIfInvalid();
 		return statement;
 	}
 
 	protected Statement getStatementWithoutChecks() {
 		return statement;
 	}
 
 	@Override
     protected Object continueInvocation(Object proxy, Method method, Object[] args) throws Throwable {
 		String methodName = method.getName();
         LOG.trace("Handling invocation of statement method [" + methodName + "]");
 
 		// other methods allowed while invalid ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		if ( "close".equals( methodName ) ) {
 			explicitClose( ( Statement ) proxy );
 			return null;
 		}
 		if ( "invalidate".equals( methodName ) ) {
 			invalidateHandle();
 			return null;
 		}
 
 		errorIfInvalid();
 
 		// handle the JDBC 4 Wrapper#isWrapperFor and Wrapper#unwrap calls
 		//		these cause problems to the whole proxy scheme though as we need to return the raw objects
 		if ( "isWrapperFor".equals( methodName ) && args.length == 1 ) {
 			return method.invoke( getStatementWithoutChecks(), args );
 		}
 		if ( "unwrap".equals( methodName ) && args.length == 1 ) {
 			return method.invoke( getStatementWithoutChecks(), args );
 		}
 
 		if ( "getWrappedObject".equals( methodName ) ) {
 			return getStatementWithoutChecks();
 		}
 
 		if ( "getConnection".equals( methodName ) ) {
 			return connectionProxy;
 		}
 
 		beginningInvocationHandling( method, args );
 
 		try {
 			Object result = method.invoke( statement, args );
 			result = wrapIfNecessary( result, proxy, method );
 			return result;
 		}
 		catch ( InvocationTargetException e ) {
 			Throwable realException = e.getTargetException();
 			if ( SQLException.class.isInstance( realException ) ) {
 				throw connectionProxyHandler.getJdbcServices().getSqlExceptionHelper()
 						.convert( ( SQLException ) realException, realException.getMessage() );
 			}
 			else {
 				throw realException;
 			}
 		}
 	}
 
 	private Object wrapIfNecessary(Object result, Object proxy, Method method) {
 		if ( !( ResultSet.class.isAssignableFrom( method.getReturnType() ) ) ) {
 			return result;
 		}
 
 		final ResultSet wrapper;
 		if ( "getGeneratedKeys".equals( method.getName() ) ) {
 			wrapper = ProxyBuilder.buildImplicitResultSet( ( ResultSet ) result, connectionProxyHandler, connectionProxy, ( Statement ) proxy );
 		}
 		else {
 			wrapper = ProxyBuilder.buildResultSet( ( ResultSet ) result, this, ( Statement ) proxy );
 		}
 		getResourceRegistry().register( wrapper );
 		return wrapper;
 	}
 
 	protected void beginningInvocationHandling(Method method, Object[] args) {
 	}
 
 	private void explicitClose(Statement proxy) {
 		if ( isValid() ) {
 			LogicalConnectionImplementor lc = getConnectionProxy().getLogicalConnection();
 			getResourceRegistry().release( proxy );
 			lc.afterStatementExecution();
 		}
 	}
 
 	private void invalidateHandle() {
 		connectionProxyHandler = null;
 		statement = null;
 		invalidate();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/ConnectionProxyHandler.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/ConnectionProxyHandler.java
index 270c7b2735..b84fa4954c 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/ConnectionProxyHandler.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/ConnectionProxyHandler.java
@@ -1,230 +1,231 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal.proxy;
 
 import java.lang.reflect.InvocationHandler;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.sql.CallableStatement;
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.sql.Statement;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.spi.JdbcResourceRegistry;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
 import org.hibernate.engine.jdbc.spi.NonDurableConnectionObserver;
+
 import org.jboss.logging.Logger;
 
 /**
  * The {@link InvocationHandler} for intercepting messages to {@link java.sql.Connection} proxies.
  *
  * @author Steve Ebersole
  */
 public class ConnectionProxyHandler
 		extends AbstractProxyHandler
 		implements InvocationHandler, NonDurableConnectionObserver {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        ConnectionProxyHandler.class.getName());
 
 	private LogicalConnectionImplementor logicalConnection;
 
 	public ConnectionProxyHandler(LogicalConnectionImplementor logicalConnection) {
 		super( logicalConnection.hashCode() );
 		this.logicalConnection = logicalConnection;
 		this.logicalConnection.addObserver( this );
 	}
 
 	/**
 	 * Access to our logical connection.
 	 *
 	 * @return the logical connection
 	 */
 	protected LogicalConnectionImplementor getLogicalConnection() {
 		errorIfInvalid();
 		return logicalConnection;
 	}
 
 	/**
 	 * Get reference to physical connection.
 	 * <p/>
 	 * NOTE : be sure this handler is still valid before calling!
 	 *
 	 * @return The physical connection
 	 */
 	private Connection extractPhysicalConnection() {
 		return logicalConnection.getConnection();
 	}
 
 	/**
 	 * Provide access to JDBCServices.
 	 * <p/>
 	 * NOTE : package-protected
 	 *
 	 * @return JDBCServices
 	 */
 	JdbcServices getJdbcServices() {
 		return logicalConnection.getJdbcServices();
 	}
 
 	/**
 	 * Provide access to JDBCContainer.
 	 * <p/>
 	 * NOTE : package-protected
 	 *
 	 * @return JDBCContainer
 	 */
 	JdbcResourceRegistry getResourceRegistry() {
 		return logicalConnection.getResourceRegistry();
 	}
 
 	@Override
     protected Object continueInvocation(Object proxy, Method method, Object[] args) throws Throwable {
 		String methodName = method.getName();
         LOG.trace("Handling invocation of connection method [" + methodName + "]");
 
 		// other methods allowed while invalid ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		if ( "close".equals( methodName ) ) {
 			explicitClose();
 			return null;
 		}
 
 		if ( "isClosed".equals( methodName ) ) {
 			return ! isValid();
 		}
 
 		errorIfInvalid();
 
 		// handle the JDBC 4 Wrapper#isWrapperFor and Wrapper#unwrap calls
 		//		these cause problems to the whole proxy scheme though as we need to return the raw objects
 		if ( "isWrapperFor".equals( methodName ) && args.length == 1 ) {
 			return method.invoke( extractPhysicalConnection(), args );
 		}
 		if ( "unwrap".equals( methodName ) && args.length == 1 ) {
 			return method.invoke( extractPhysicalConnection(), args );
 		}
 
 		if ( "getWrappedObject".equals( methodName ) ) {
 			return extractPhysicalConnection();
 		}
 
 		try {
 			Object result = method.invoke( extractPhysicalConnection(), args );
 			result = postProcess( result, proxy, method, args );
 
 			return result;
 		}
 		catch( InvocationTargetException e ) {
 			Throwable realException = e.getTargetException();
 			if ( SQLException.class.isInstance( realException ) ) {
 				throw logicalConnection.getJdbcServices().getSqlExceptionHelper()
 						.convert( ( SQLException ) realException, realException.getMessage() );
 			}
 			else {
 				throw realException;
 			}
 		}
 	}
 
 	private Object postProcess(Object result, Object proxy, Method method, Object[] args) throws SQLException {
 		String methodName = method.getName();
 		Object wrapped = result;
 		if ( "createStatement".equals( methodName ) ) {
 			wrapped = ProxyBuilder.buildStatement(
 					(Statement) result,
 					this,
 					( Connection ) proxy
 			);
 			postProcessStatement( ( Statement ) wrapped );
 		}
 		else if ( "prepareStatement".equals( methodName ) ) {
 			wrapped = ProxyBuilder.buildPreparedStatement(
 					( String ) args[0],
 					(PreparedStatement) result,
 					this,
 					( Connection ) proxy
 			);
 			postProcessPreparedStatement( ( Statement ) wrapped );
 		}
 		else if ( "prepareCall".equals( methodName ) ) {
 			wrapped = ProxyBuilder.buildCallableStatement(
 					( String ) args[0],
 					(CallableStatement) result,
 					this,
 					( Connection ) proxy
 			);
 			postProcessPreparedStatement( ( Statement ) wrapped );
 		}
 		else if ( "getMetaData".equals( methodName ) ) {
 			wrapped = ProxyBuilder.buildDatabaseMetaData( (DatabaseMetaData) result, this, ( Connection ) proxy );
 		}
 		return wrapped;
 	}
 
 	private void postProcessStatement(Statement statement) throws SQLException {
 		getResourceRegistry().register( statement );
 	}
 
 	private void postProcessPreparedStatement(Statement statement) throws SQLException  {
 		logicalConnection.notifyObserversStatementPrepared();
 		postProcessStatement( statement );
 	}
 
 	private void explicitClose() {
 		if ( isValid() ) {
 			invalidateHandle();
 		}
 	}
 
 	private void invalidateHandle() {
         LOG.trace("Invalidating connection handle");
 		logicalConnection = null;
 		invalidate();
 	}
 
 	// ConnectionObserver ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void physicalConnectionObtained(Connection connection) {
 	}
 
 	@Override
 	public void physicalConnectionReleased() {
         LOG.logicalConnectionReleasingPhysicalConnection();
 	}
 
 	@Override
 	public void logicalConnectionClosed() {
         LOG.logicalConnectionClosed();
 		invalidateHandle();
 	}
 
 	@Override
 	public void statementPrepared() {
 		// N/A
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/PreparedStatementProxyHandler.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/PreparedStatementProxyHandler.java
index 09b594d910..633f5bfc5a 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/PreparedStatementProxyHandler.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/proxy/PreparedStatementProxyHandler.java
@@ -1,82 +1,84 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal.proxy;
 import java.lang.reflect.Method;
 import java.sql.Connection;
 import java.sql.Statement;
 import java.util.Arrays;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * Invocation handler for {@link java.sql.PreparedStatement} proxies
  *
  * @author Steve Ebersole
  */
 public class PreparedStatementProxyHandler extends AbstractStatementProxyHandler {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        PreparedStatementProxyHandler.class.getName());
 
 	private final String sql;
 
 	protected PreparedStatementProxyHandler(
 			String sql,
 			Statement statement,
 			ConnectionProxyHandler connectionProxyHandler,
 			Connection connectionProxy) {
 		super( statement, connectionProxyHandler, connectionProxy );
 		connectionProxyHandler.getJdbcServices().getSqlStatementLogger().logStatement( sql );
 		this.sql = sql;
 	}
 
 	@Override
     protected void beginningInvocationHandling(Method method, Object[] args) {
 		if ( isExecution( method ) ) {
 			logExecution();
 		}
 		else {
 			journalPossibleParameterBind( method, args );
 		}
 	}
 
 	private void journalPossibleParameterBind(Method method, Object[] args) {
 		String methodName = method.getName();
 		// todo : is this enough???
 		if ( methodName.startsWith( "set" ) && args != null && args.length >= 2 ) {
 			journalParameterBind( method, args );
 		}
 	}
 
 	private void journalParameterBind(Method method, Object[] args) {
         LOG.trace("Binding via " + method.getName() + ": " + Arrays.asList(args));
 	}
 
 	private boolean isExecution(Method method) {
 		return false;
 	}
 
     private void logExecution() {
     }
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlExceptionHelper.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlExceptionHelper.java
index c7e2cafeb8..4b5e1f7b09 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlExceptionHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlExceptionHelper.java
@@ -1,294 +1,294 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.spi;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
 import java.sql.Statement;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.exception.SQLStateConverter;
 import org.hibernate.exception.ViolatedConstraintNameExtracter;
 import org.hibernate.internal.util.StringHelper;
 import org.jboss.logging.Logger;
 import org.jboss.logging.Logger.Level;
 
 /**
  * Helper for handling SQLExceptions in various manners.
  *
  * @author Steve Ebersole
  */
 public class SqlExceptionHelper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SqlExceptionHelper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SqlExceptionHelper.class.getName());
 
 	public static final String DEFAULT_EXCEPTION_MSG = "SQL Exception";
 	public static final String DEFAULT_WARNING_MSG = "SQL Warning";
 
 	public static final SQLExceptionConverter DEFAULT_CONVERTER = new SQLStateConverter(
 			new ViolatedConstraintNameExtracter() {
 				public String extractConstraintName(SQLException e) {
 					return null;
 				}
 			}
 	);
 
 	private SQLExceptionConverter sqlExceptionConverter;
 
 	/**
 	 * Create an exception helper with a default exception converter.
 	 */
 	public SqlExceptionHelper() {
 		sqlExceptionConverter = DEFAULT_CONVERTER;
 	}
 
 	/**
 	 * Create an exception helper with a specific exception converter.
 	 *
 	 * @param sqlExceptionConverter The exception converter to use.
 	 */
 	public SqlExceptionHelper(SQLExceptionConverter sqlExceptionConverter) {
 		this.sqlExceptionConverter = sqlExceptionConverter;
 	}
 
 	/**
 	 * Access the current exception converter being used internally.
 	 *
 	 * @return The current exception converter.
 	 */
 	public SQLExceptionConverter getSqlExceptionConverter() {
 		return sqlExceptionConverter;
 	}
 
 	/**
 	 * Inject the exception converter to use.
 	 * <p/>
 	 * NOTE : <tt>null</tt> is allowed and signifies to use the default.
 	 *
 	 * @param sqlExceptionConverter The converter to use.
 	 */
 	public void setSqlExceptionConverter(SQLExceptionConverter sqlExceptionConverter) {
 		this.sqlExceptionConverter = ( sqlExceptionConverter == null ? DEFAULT_CONVERTER : sqlExceptionConverter );
 	}
 
     // SQLException ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
     /**
      * Convert an SQLException using the current converter, doing some logging first.
      *
      * @param sqlException The exception to convert
      * @param message An error message.
      * @return The converted exception
      */
     public JDBCException convert( SQLException sqlException,
                                   String message ) {
         return convert(sqlException, message, "n/a");
     }
 
     /**
      * Convert an SQLException using the current converter, doing some logging first.
      *
      * @param sqlException The exception to convert
      * @param message An error message.
      * @param sql The SQL being executed when the exception occurred
      * @return The converted exception
      */
     public JDBCException convert( SQLException sqlException,
                                   String message,
                                   String sql ) {
         logExceptions(sqlException, message + " [" + sql + "]");
         return sqlExceptionConverter.convert(sqlException, message, sql);
     }
 
     /**
      * Log the given (and any nested) exception.
      *
      * @param sqlException The exception to log
      * @param message The message text to use as a preamble.
      */
     public void logExceptions( SQLException sqlException,
                                String message ) {
         if (LOG.isEnabled(Level.ERROR)) {
             if (LOG.isDebugEnabled()) {
                 message = StringHelper.isNotEmpty(message) ? message : DEFAULT_EXCEPTION_MSG;
                 LOG.debug(message, sqlException);
             }
             while (sqlException != null) {
                 StringBuffer buf = new StringBuffer(30).append("SQL Error: ").append(sqlException.getErrorCode()).append(", SQLState: ").append(sqlException.getSQLState());
                 LOG.warn(buf.toString());
                 LOG.error(sqlException.getMessage());
                 sqlException = sqlException.getNextException();
             }
         }
     }
 
     // SQLWarning ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
     /**
      * Contract for handling {@link SQLWarning warnings}
      */
     public static interface WarningHandler {
         /**
          * Should processing be done? Allows short-circuiting if not.
          *
          * @return True to process warnings, false otherwise.
          */
         public boolean doProcess();
 
         /**
          * Prepare for processing of a {@link SQLWarning warning} stack.
          * <p/>
          * Note that the warning here is also the first passed to {@link #handleWarning}
          *
          * @param warning The first warning in the stack.
          */
         public void prepare( SQLWarning warning );
 
         /**
          * Handle an individual warning in the stack.
          *
          * @param warning The warning to handle.
          */
         public void handleWarning( SQLWarning warning );
     }
 
     /**
      * Basic support for {@link WarningHandler} implementations which log
      */
     public static abstract class WarningHandlerLoggingSupport implements WarningHandler {
         public final void handleWarning( SQLWarning warning ) {
             StringBuffer buf = new StringBuffer(30).append("SQL Warning Code: ").append(warning.getErrorCode()).append(", SQLState: ").append(warning.getSQLState());
             logWarning(buf.toString(), warning.getMessage());
         }
 
         /**
          * Delegate to log common details of a {@link SQLWarning warning}
          *
          * @param description A description of the warning
          * @param message The warning message
          */
         protected abstract void logWarning( String description,
                                             String message );
     }
 
     public static class StandardWarningHandler extends WarningHandlerLoggingSupport {
         private final String introMessage;
 
         public StandardWarningHandler( String introMessage ) {
             this.introMessage = introMessage;
         }
 
         public boolean doProcess() {
             return LOG.isEnabled(Level.WARN);
         }
 
         public void prepare( SQLWarning warning ) {
             LOG.debug(introMessage, warning);
         }
 
         @Override
         protected void logWarning( String description,
                                    String message ) {
             LOG.warn(description);
             LOG.warn(message);
         }
     }
 
     public static StandardWarningHandler STANDARD_WARNING_HANDLER = new StandardWarningHandler(DEFAULT_WARNING_MSG);
 
     public void walkWarnings( SQLWarning warning,
                               WarningHandler handler ) {
         if (warning == null || handler.doProcess()) {
             return;
         }
         handler.prepare(warning);
         while (warning != null) {
             handler.handleWarning(warning);
             warning = warning.getNextWarning();
         }
     }
 
     /**
      * Standard (legacy) behavior for logging warnings associated with a JDBC {@link Connection} and clearing them.
      * <p/>
      * Calls {@link #handleAndClearWarnings(Connection, WarningHandler)} using {@link #STANDARD_WARNING_HANDLER}
      *
      * @param connection The JDBC connection potentially containing warnings
      */
     public void logAndClearWarnings( Connection connection ) {
         handleAndClearWarnings(connection, STANDARD_WARNING_HANDLER);
     }
 
     /**
      * General purpose handling of warnings associated with a JDBC {@link Connection}.
      *
      * @param connection The JDBC connection potentially containing warnings
      * @param handler The handler for each individual warning in the stack.
      * @see #walkWarnings
      */
     @SuppressWarnings( {"ThrowableResultOfMethodCallIgnored"} )
     public void handleAndClearWarnings( Connection connection,
                                         WarningHandler handler ) {
         try {
             walkWarnings(connection.getWarnings(), handler);
         } catch (SQLException sqle) {
             // workaround for WebLogic
             LOG.debug("could not log warnings", sqle);
         }
         try {
             // Sybase fail if we don't do that, sigh...
             connection.clearWarnings();
         } catch (SQLException sqle) {
             LOG.debug("could not clear warnings", sqle);
         }
     }
 
     /**
      * General purpose handling of warnings associated with a JDBC {@link Statement}.
      *
      * @param statement The JDBC statement potentially containing warnings
      * @param handler The handler for each individual warning in the stack.
      * @see #walkWarnings
      */
     @SuppressWarnings( {"ThrowableResultOfMethodCallIgnored"} )
     public void handleAndClearWarnings( Statement statement,
                                         WarningHandler handler ) {
         try {
             walkWarnings(statement.getWarnings(), handler);
         } catch (SQLException sqlException) {
             // workaround for WebLogic
             LOG.debug("could not log warnings", sqlException);
         }
         try {
             // Sybase fail if we don't do that, sigh...
             statement.clearWarnings();
         } catch (SQLException sqle) {
             LOG.debug("could not clear warnings", sqle);
         }
     }
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlStatementLogger.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlStatementLogger.java
index 89aec68f26..7b144d4662 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlStatementLogger.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/SqlStatementLogger.java
@@ -1,109 +1,110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.spi;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.internal.Formatter;
+
 import org.jboss.logging.Logger;
 
 /**
  * Centralize logging for SQL statements.
  *
  * @author Steve Ebersole
  */
 public class SqlStatementLogger {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SqlStatementLogger.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SqlStatementLogger.class.getName());
 
 	private boolean logToStdout;
 	private boolean format;
 
 	/**
 	 * Constructs a new SqlStatementLogger instance.
 	 */
 	public SqlStatementLogger() {
 		this( false, false );
 	}
 
 	/**
 	 * Constructs a new SqlStatementLogger instance.
 	 *
 	 * @param logToStdout Should we log to STDOUT in addition to our internal logger.
 	 * @param format Should we format the statements prior to logging
 	 */
 	public SqlStatementLogger(boolean logToStdout, boolean format) {
 		this.logToStdout = logToStdout;
 		this.format = format;
 	}
 
 	/**
 	 * Are we currently logging to stdout?
 	 *
 	 * @return True if we are currently logging to stdout; false otherwise.
 	 */
 	public boolean isLogToStdout() {
 		return logToStdout;
 	}
 
 	/**
 	 * Enable (true) or disable (false) logging to stdout.
 	 *
 	 * @param logToStdout True to enable logging to stdout; false to disable.
 	 */
 	public void setLogToStdout(boolean logToStdout) {
 		this.logToStdout = logToStdout;
 	}
 
 	public boolean isFormat() {
 		return format;
 	}
 
 	public void setFormat(boolean format) {
 		this.format = format;
 	}
 
 	/**
 	 * Log a SQL statement string.
 	 *
 	 * @param statement The SQL statement.
 	 */
 	public void logStatement(String statement) {
 		// for now just assume a DML log for formatting
 		logStatement( statement, FormatStyle.BASIC.getFormatter() );
 	}
 
 	public void logStatement(String statement, Formatter formatter) {
 		if ( format ) {
             if (logToStdout || LOG.isDebugEnabled()) {
 				statement = formatter.format( statement );
 			}
 		}
         LOG.debug( statement );
 		if ( logToStdout ) {
 			System.out.println( "Hibernate: " + statement );
 		}
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/loading/CollectionLoadContext.java b/hibernate-core/src/main/java/org/hibernate/engine/loading/CollectionLoadContext.java
index 59be09a6c6..ebe4480703 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/loading/CollectionLoadContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/loading/CollectionLoadContext.java
@@ -1,343 +1,343 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.loading;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.CacheMode;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.entry.CollectionCacheEntry;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.CollectionEntry;
 import org.hibernate.engine.CollectionKey;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * Represents state associated with the processing of a given {@link ResultSet}
  * in regards to loading collections.
  * <p/>
  * Another implementation option to consider is to not expose {@link ResultSet}s
  * directly (in the JDBC redesign) but to always "wrap" them and apply a
  * [series of] context[s] to that wrapper.
  *
  * @author Steve Ebersole
  */
 public class CollectionLoadContext {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, CollectionLoadContext.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CollectionLoadContext.class.getName());
 
 	private final LoadContexts loadContexts;
 	private final ResultSet resultSet;
 	private Set localLoadingCollectionKeys = new HashSet();
 
 	/**
 	 * Creates a collection load context for the given result set.
 	 *
 	 * @param loadContexts Callback to other collection load contexts.
 	 * @param resultSet The result set this is "wrapping".
 	 */
 	public CollectionLoadContext(LoadContexts loadContexts, ResultSet resultSet) {
 		this.loadContexts = loadContexts;
 		this.resultSet = resultSet;
 	}
 
 	public ResultSet getResultSet() {
 		return resultSet;
 	}
 
 	public LoadContexts getLoadContext() {
 		return loadContexts;
 	}
 
 	/**
 	 * Retrieve the collection that is being loaded as part of processing this
 	 * result set.
 	 * <p/>
 	 * Basically, there are two valid return values from this method:<ul>
 	 * <li>an instance of {@link PersistentCollection} which indicates to
 	 * continue loading the result set row data into that returned collection
 	 * instance; this may be either an instance already associated and in the
 	 * midst of being loaded, or a newly instantiated instance as a matching
 	 * associated collection was not found.</li>
 	 * <li><i>null</i> indicates to ignore the corresponding result set row
 	 * data relating to the requested collection; this indicates that either
 	 * the collection was found to already be associated with the persistence
 	 * context in a fully loaded state, or it was found in a loading state
 	 * associated with another result set processing context.</li>
 	 * </ul>
 	 *
 	 * @param persister The persister for the collection being requested.
 	 * @param key The key of the collection being requested.
 	 *
 	 * @return The loading collection (see discussion above).
 	 */
 	public PersistentCollection getLoadingCollection(final CollectionPersister persister, final Serializable key) {
 		final EntityMode em = loadContexts.getPersistenceContext().getSession().getEntityMode();
 		final CollectionKey collectionKey = new CollectionKey( persister, key, em );
         if (LOG.isTraceEnabled()) LOG.trace("Starting attempt to find loading collection ["
                                             + MessageHelper.collectionInfoString(persister.getRole(), key) + "]");
 		final LoadingCollectionEntry loadingCollectionEntry = loadContexts.locateLoadingCollectionEntry( collectionKey );
 		if ( loadingCollectionEntry == null ) {
 			// look for existing collection as part of the persistence context
 			PersistentCollection collection = loadContexts.getPersistenceContext().getCollection( collectionKey );
 			if ( collection != null ) {
 				if ( collection.wasInitialized() ) {
                     LOG.trace("Collection already initialized; ignoring");
 					return null; // ignore this row of results! Note the early exit
                 }
                 LOG.trace("Collection not yet initialized; initializing");
 			}
 			else {
 				Object owner = loadContexts.getPersistenceContext().getCollectionOwner( key, persister );
 				final boolean newlySavedEntity = owner != null
 						&& loadContexts.getPersistenceContext().getEntry( owner ).getStatus() != Status.LOADING
 						&& em != EntityMode.DOM4J;
 				if ( newlySavedEntity ) {
 					// important, to account for newly saved entities in query
 					// todo : some kind of check for new status...
                     LOG.trace("Owning entity already loaded; ignoring");
 					return null;
 				}
                 // create one
                 LOG.trace("Instantiating new collection [key=" + key + ", rs=" + resultSet + "]");
                 collection = persister.getCollectionType().instantiate(loadContexts.getPersistenceContext().getSession(),
                                                                        persister,
                                                                        key);
 			}
 			collection.beforeInitialize( persister, -1 );
 			collection.beginRead();
 			localLoadingCollectionKeys.add( collectionKey );
 			loadContexts.registerLoadingCollectionXRef( collectionKey, new LoadingCollectionEntry( resultSet, persister, key, collection ) );
 			return collection;
 		}
         if (loadingCollectionEntry.getResultSet() == resultSet) {
             LOG.trace("Found loading collection bound to current result set processing; reading row");
             return loadingCollectionEntry.getCollection();
 		}
         // ignore this row, the collection is in process of
         // being loaded somewhere further "up" the stack
         LOG.trace("Collection is already being initialized; ignoring row");
         return null;
 	}
 
 	/**
 	 * Finish the process of collection-loading for this bound result set.  Mainly this
 	 * involves cleaning up resources and notifying the collections that loading is
 	 * complete.
 	 *
 	 * @param persister The persister for which to complete loading.
 	 */
 	public void endLoadingCollections(CollectionPersister persister) {
 		SessionImplementor session = getLoadContext().getPersistenceContext().getSession();
 		if ( !loadContexts.hasLoadingCollectionEntries()
 				&& localLoadingCollectionKeys.isEmpty() ) {
 			return;
 		}
 
 		// in an effort to avoid concurrent-modification-exceptions (from
 		// potential recursive calls back through here as a result of the
 		// eventual call to PersistentCollection#endRead), we scan the
 		// internal loadingCollections map for matches and store those matches
 		// in a temp collection.  the temp collection is then used to "drive"
 		// the #endRead processing.
 		List matches = null;
 		Iterator iter = localLoadingCollectionKeys.iterator();
 		while ( iter.hasNext() ) {
 			final CollectionKey collectionKey = (CollectionKey) iter.next();
 			final LoadingCollectionEntry lce = loadContexts.locateLoadingCollectionEntry( collectionKey );
             if (lce == null) LOG.loadingCollectionKeyNotFound(collectionKey);
 			else if ( lce.getResultSet() == resultSet && lce.getPersister() == persister ) {
 				if ( matches == null ) {
 					matches = new ArrayList();
 				}
 				matches.add( lce );
 				if ( lce.getCollection().getOwner() == null ) {
 					session.getPersistenceContext().addUnownedCollection(
 							new CollectionKey( persister, lce.getKey(), session.getEntityMode() ),
 							lce.getCollection()
 					);
 				}
                 LOG.trace("Removing collection load entry [" + lce + "]");
 
 				// todo : i'd much rather have this done from #endLoadingCollection(CollectionPersister,LoadingCollectionEntry)...
 				loadContexts.unregisterLoadingCollectionXRef( collectionKey );
 				iter.remove();
 			}
 		}
 
 		endLoadingCollections( persister, matches );
 		if ( localLoadingCollectionKeys.isEmpty() ) {
 			// todo : hack!!!
 			// NOTE : here we cleanup the load context when we have no more local
 			// LCE entries.  This "works" for the time being because really
 			// only the collection load contexts are implemented.  Long term,
 			// this cleanup should become part of the "close result set"
 			// processing from the (sandbox/jdbc) jdbc-container code.
 			loadContexts.cleanup( resultSet );
 		}
 	}
 
 	private void endLoadingCollections(CollectionPersister persister, List matchedCollectionEntries) {
 		if ( matchedCollectionEntries == null ) {
             LOG.debugf("No collections were found in result set for role: %s", persister.getRole());
 			return;
 		}
 
 		final int count = matchedCollectionEntries.size();
         LOG.debugf("%s collections were found in result set for role: %s", count, persister.getRole());
 
 		for ( int i = 0; i < count; i++ ) {
 			LoadingCollectionEntry lce = ( LoadingCollectionEntry ) matchedCollectionEntries.get( i );
 			endLoadingCollection( lce, persister );
 		}
 
         LOG.debugf("%s collections initialized for role: %s", count, persister.getRole());
 	}
 
 	private void endLoadingCollection(LoadingCollectionEntry lce, CollectionPersister persister) {
         LOG.trace("Ending loading collection [" + lce + "]");
 		final SessionImplementor session = getLoadContext().getPersistenceContext().getSession();
 		final EntityMode em = session.getEntityMode();
 
 		boolean hasNoQueuedAdds = lce.getCollection().endRead(); // warning: can cause a recursive calls! (proxy initialization)
 
 		if ( persister.getCollectionType().hasHolder( em ) ) {
 			getLoadContext().getPersistenceContext().addCollectionHolder( lce.getCollection() );
 		}
 
 		CollectionEntry ce = getLoadContext().getPersistenceContext().getCollectionEntry( lce.getCollection() );
 		if ( ce == null ) {
 			ce = getLoadContext().getPersistenceContext().addInitializedCollection( persister, lce.getCollection(), lce.getKey() );
 		}
 		else {
 			ce.postInitialize( lce.getCollection() );
 		}
 
 		boolean addToCache = hasNoQueuedAdds && // there were no queued additions
 				persister.hasCache() &&             // and the role has a cache
 				session.getCacheMode().isPutEnabled() &&
 				!ce.isDoremove();                   // and this is not a forced initialization during flush
         if (addToCache) addCollectionToCache(lce, persister);
 
         if (LOG.isDebugEnabled()) LOG.debugf("Collection fully initialized: %s",
                                              MessageHelper.collectionInfoString(persister, lce.getKey(), session.getFactory()));
         if (session.getFactory().getStatistics().isStatisticsEnabled()) session.getFactory().getStatisticsImplementor().loadCollection(persister.getRole());
 	}
 
 	/**
 	 * Add the collection to the second-level cache
 	 *
 	 * @param lce The entry representing the collection to add
 	 * @param persister The persister
 	 */
 	private void addCollectionToCache(LoadingCollectionEntry lce, CollectionPersister persister) {
 		final SessionImplementor session = getLoadContext().getPersistenceContext().getSession();
 		final SessionFactoryImplementor factory = session.getFactory();
 
         if (LOG.isDebugEnabled()) LOG.debugf("Caching collection: %s",
                                              MessageHelper.collectionInfoString(persister, lce.getKey(), factory));
 
 		if ( !session.getEnabledFilters().isEmpty() && persister.isAffectedByEnabledFilters( session ) ) {
 			// some filters affecting the collection are enabled on the session, so do not do the put into the cache.
             LOG.debugf("Refusing to add to cache due to enabled filters");
 			// todo : add the notion of enabled filters to the CacheKey to differentiate filtered collections from non-filtered;
 			//      but CacheKey is currently used for both collections and entities; would ideally need to define two seperate ones;
 			//      currently this works in conjuction with the check on
 			//      DefaultInitializeCollectionEventHandler.initializeCollectionFromCache() (which makes sure to not read from
 			//      cache with enabled filters).
 			return; // EARLY EXIT!!!!!
 		}
 
 		final Object version;
 		if ( persister.isVersioned() ) {
 			Object collectionOwner = getLoadContext().getPersistenceContext().getCollectionOwner( lce.getKey(), persister );
 			if ( collectionOwner == null ) {
 				// generally speaking this would be caused by the collection key being defined by a property-ref, thus
 				// the collection key and the owner key would not match up.  In this case, try to use the key of the
 				// owner instance associated with the collection itself, if one.  If the collection does already know
 				// about its owner, that owner should be the same instance as associated with the PC, but we do the
 				// resolution against the PC anyway just to be safe since the lookup should not be costly.
 				if ( lce.getCollection() != null ) {
 					Object linkedOwner = lce.getCollection().getOwner();
 					if ( linkedOwner != null ) {
 						final Serializable ownerKey = persister.getOwnerEntityPersister().getIdentifier( linkedOwner, session );
 						collectionOwner = getLoadContext().getPersistenceContext().getCollectionOwner( ownerKey, persister );
 					}
 				}
 				if ( collectionOwner == null ) {
 					throw new HibernateException(
 							"Unable to resolve owner of loading collection [" +
 									MessageHelper.collectionInfoString( persister, lce.getKey(), factory ) +
 									"] for second level caching"
 					);
 				}
 			}
 			version = getLoadContext().getPersistenceContext().getEntry( collectionOwner ).getVersion();
 		}
 		else {
 			version = null;
 		}
 
 		CollectionCacheEntry entry = new CollectionCacheEntry( lce.getCollection(), persister );
 		CacheKey cacheKey = session.generateCacheKey( lce.getKey(), persister.getKeyType(), persister.getRole() );
 		boolean put = persister.getCacheAccessStrategy().putFromLoad(
 				cacheKey,
 				persister.getCacheEntryStructure().structure(entry),
 				session.getTimestamp(),
 				version,
 				factory.getSettings().isMinimalPutsEnabled() && session.getCacheMode()!= CacheMode.REFRESH
 		);
 
 		if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().secondLevelCachePut( persister.getCacheAccessStrategy().getRegion().getName() );
 		}
 	}
 
 	void cleanup() {
         if (!localLoadingCollectionKeys.isEmpty()) LOG.localLoadingCollectionKeysCount(localLoadingCollectionKeys.size());
 		loadContexts.cleanupCollectionXRefs( localLoadingCollectionKeys );
 		localLoadingCollectionKeys.clear();
 	}
 
 
 	@Override
     public String toString() {
 		return super.toString() + "<rs=" + resultSet + ">";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/loading/EntityLoadContext.java b/hibernate-core/src/main/java/org/hibernate/engine/loading/EntityLoadContext.java
index 24199806aa..e1c5332fb2 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/loading/EntityLoadContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/loading/EntityLoadContext.java
@@ -1,60 +1,62 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ *
+ */
 package org.hibernate.engine.loading;
-import java.sql.ResultSet;
-import java.util.ArrayList;
-import java.util.List;
-import org.hibernate.HibernateLogger;
-import org.jboss.logging.Logger;
-
-/**
- * {@inheritDoc}
- *
- * @author Steve Ebersole
- */
-public class EntityLoadContext {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, EntityLoadContext.class.getName());
-
-	private final LoadContexts loadContexts;
-	private final ResultSet resultSet;
-	private final List hydratingEntities = new ArrayList( 20 ); // todo : need map? the prob is a proper key, right?
-
-	public EntityLoadContext(LoadContexts loadContexts, ResultSet resultSet) {
-		this.loadContexts = loadContexts;
-		this.resultSet = resultSet;
-	}
-
-	void cleanup() {
-        if (!hydratingEntities.isEmpty()) LOG.hydratingEntitiesCount(hydratingEntities.size());
-		hydratingEntities.clear();
-	}
-
-
-	@Override
-    public String toString() {
-		return super.toString() + "<rs=" + resultSet + ">";
-	}
-}
+import java.sql.ResultSet;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.hibernate.internal.CoreMessageLogger;
+
+import org.jboss.logging.Logger;
+
+/**
+ * {@inheritDoc}
+ *
+ * @author Steve Ebersole
+ */
+public class EntityLoadContext {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityLoadContext.class.getName());
+
+	private final LoadContexts loadContexts;
+	private final ResultSet resultSet;
+	private final List hydratingEntities = new ArrayList( 20 ); // todo : need map? the prob is a proper key, right?
+
+	public EntityLoadContext(LoadContexts loadContexts, ResultSet resultSet) {
+		this.loadContexts = loadContexts;
+		this.resultSet = resultSet;
+	}
+
+	void cleanup() {
+        if (!hydratingEntities.isEmpty()) LOG.hydratingEntitiesCount(hydratingEntities.size());
+		hydratingEntities.clear();
+	}
+
+
+	@Override
+    public String toString() {
+		return super.toString() + "<rs=" + resultSet + ">";
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/loading/LoadContexts.java b/hibernate-core/src/main/java/org/hibernate/engine/loading/LoadContexts.java
index 4a31a51eec..d7e29f7cd5 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/loading/LoadContexts.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/loading/LoadContexts.java
@@ -1,309 +1,310 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ *
+ */
 package org.hibernate.engine.loading;
-
-import java.io.Serializable;
-import java.sql.ResultSet;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Set;
-import org.hibernate.EntityMode;
-import org.hibernate.HibernateLogger;
-import org.hibernate.collection.PersistentCollection;
-import org.hibernate.engine.CollectionKey;
-import org.hibernate.engine.PersistenceContext;
-import org.hibernate.engine.SessionImplementor;
-import org.hibernate.internal.util.collections.IdentityMap;
-import org.hibernate.persister.collection.CollectionPersister;
-import org.hibernate.pretty.MessageHelper;
-import org.jboss.logging.Logger;
-
-/**
- * Maps {@link ResultSet result-sets} to specific contextual data
- * related to processing that {@link ResultSet result-sets}.
- * <p/>
- * Implementation note: internally an {@link IdentityMap} is used to maintain
- * the mappings; {@link IdentityMap} was chosen because I'd rather not be
- * dependent upon potentially bad {@link ResultSet#equals} and {ResultSet#hashCode}
- * implementations.
- * <p/>
- * Considering the JDBC-redesign work, would further like this contextual info
- * not mapped seperately, but available based on the result set being processed.
- * This would also allow maintaining a single mapping as we could reliably get
- * notification of the result-set closing...
- *
- * @author Steve Ebersole
- */
-public class LoadContexts {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, LoadContexts.class.getName());
-
-	private final PersistenceContext persistenceContext;
-	private Map collectionLoadContexts;
-	private Map entityLoadContexts;
-
-	private Map xrefLoadingCollectionEntries;
-
-	/**
-	 * Creates and binds this to the given persistence context.
-	 *
-	 * @param persistenceContext The persistence context to which this
-	 * will be bound.
-	 */
-	public LoadContexts(PersistenceContext persistenceContext) {
-		this.persistenceContext = persistenceContext;
-	}
-
-	/**
-	 * Retrieves the persistence context to which this is bound.
-	 *
-	 * @return The persistence context to which this is bound.
-	 */
-	public PersistenceContext getPersistenceContext() {
-		return persistenceContext;
-	}
-
-	private SessionImplementor getSession() {
-		return getPersistenceContext().getSession();
-	}
-
-	private EntityMode getEntityMode() {
-		return getSession().getEntityMode();
-	}
-
-
-	// cleanup code ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
- 	/**
-	 * Release internal state associated with the given result set.
-	 * <p/>
-	 * This should be called when we are done with processing said result set,
-	 * ideally as the result set is being closed.
-	 *
-	 * @param resultSet The result set for which it is ok to release
-	 * associated resources.
-	 */
-	public void cleanup(ResultSet resultSet) {
-		if ( collectionLoadContexts != null ) {
-			CollectionLoadContext collectionLoadContext = ( CollectionLoadContext ) collectionLoadContexts.remove( resultSet );
-			collectionLoadContext.cleanup();
-		}
-		if ( entityLoadContexts != null ) {
-			EntityLoadContext entityLoadContext = ( EntityLoadContext ) entityLoadContexts.remove( resultSet );
-			entityLoadContext.cleanup();
-		}
-	}
-
-	/**
-	 * Release internal state associated with *all* result sets.
-	 * <p/>
-	 * This is intended as a "failsafe" process to make sure we get everything
-	 * cleaned up and released.
-	 */
-	public void cleanup() {
-		if ( collectionLoadContexts != null ) {
-			Iterator itr = collectionLoadContexts.values().iterator();
-			while ( itr.hasNext() ) {
-				CollectionLoadContext collectionLoadContext = ( CollectionLoadContext ) itr.next();
-                LOG.failSafeCollectionsCleanup(collectionLoadContext);
-				collectionLoadContext.cleanup();
-			}
-			collectionLoadContexts.clear();
-		}
-		if ( entityLoadContexts != null ) {
-			Iterator itr = entityLoadContexts.values().iterator();
-			while ( itr.hasNext() ) {
-				EntityLoadContext entityLoadContext = ( EntityLoadContext ) itr.next();
-                LOG.failSafeEntitiesCleanup(entityLoadContext);
-				entityLoadContext.cleanup();
-			}
-			entityLoadContexts.clear();
-		}
-	}
-
-
-	// Collection load contexts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-	/**
-	 * Do we currently have any internal entries corresponding to loading
-	 * collections?
-	 *
-	 * @return True if we currently hold state pertaining to loading collections;
-	 * false otherwise.
-	 */
-	public boolean hasLoadingCollectionEntries() {
-		return ( collectionLoadContexts != null && !collectionLoadContexts.isEmpty() );
-	}
-
-	/**
-	 * Do we currently have any registered internal entries corresponding to loading
-	 * collections?
-	 *
-	 * @return True if we currently hold state pertaining to a registered loading collections;
-	 * false otherwise.
-	 */
-	public boolean hasRegisteredLoadingCollectionEntries() {
-		return ( xrefLoadingCollectionEntries != null && !xrefLoadingCollectionEntries.isEmpty() );
-	}
-
-
-	/**
-	 * Get the {@link CollectionLoadContext} associated with the given
-	 * {@link ResultSet}, creating one if needed.
-	 *
-	 * @param resultSet The result set for which to retrieve the context.
-	 * @return The processing context.
-	 */
-	public CollectionLoadContext getCollectionLoadContext(ResultSet resultSet) {
-		CollectionLoadContext context = null;
-        if (collectionLoadContexts == null) collectionLoadContexts = IdentityMap.instantiate(8);
-        else context = (CollectionLoadContext)collectionLoadContexts.get(resultSet);
-		if ( context == null ) {
-            LOG.trace("Constructing collection load context for result set [" + resultSet + "]");
-			context = new CollectionLoadContext( this, resultSet );
-			collectionLoadContexts.put( resultSet, context );
-		}
-		return context;
-	}
-
-	/**
-	 * Attempt to locate the loading collection given the owner's key.  The lookup here
-	 * occurs against all result-set contexts...
-	 *
-	 * @param persister The collection persister
-	 * @param ownerKey The owner key
-	 * @return The loading collection, or null if not found.
-	 */
-	public PersistentCollection locateLoadingCollection(CollectionPersister persister, Serializable ownerKey) {
-		LoadingCollectionEntry lce = locateLoadingCollectionEntry( new CollectionKey( persister, ownerKey, getEntityMode() ) );
-		if ( lce != null ) {
-            if (LOG.isTraceEnabled()) LOG.trace("Returning loading collection: "
-                                                + MessageHelper.collectionInfoString(persister, ownerKey, getSession().getFactory()));
-			return lce.getCollection();
-		}
-        // TODO : should really move this log statement to CollectionType, where this is used from...
-        if (LOG.isTraceEnabled()) LOG.trace("Creating collection wrapper: "
-                                            + MessageHelper.collectionInfoString(persister, ownerKey, getSession().getFactory()));
-        return null;
-	}
-
-	// loading collection xrefs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-	/**
-	 * Register a loading collection xref.
-	 * <p/>
-	 * This xref map is used because sometimes a collection is in process of
-	 * being loaded from one result set, but needs to be accessed from the
-	 * context of another "nested" result set processing.
-	 * <p/>
-	 * Implementation note: package protected, as this is meant solely for use
-	 * by {@link CollectionLoadContext} to be able to locate collections
-	 * being loaded by other {@link CollectionLoadContext}s/{@link ResultSet}s.
-	 *
-	 * @param entryKey The xref collection key
-	 * @param entry The corresponding loading collection entry
-	 */
-	void registerLoadingCollectionXRef(CollectionKey entryKey, LoadingCollectionEntry entry) {
-		if ( xrefLoadingCollectionEntries == null ) {
-			xrefLoadingCollectionEntries = new HashMap();
-		}
-		xrefLoadingCollectionEntries.put( entryKey, entry );
-	}
-
-	/**
-	 * The inverse of {@link #registerLoadingCollectionXRef}.  Here, we are done
-	 * processing the said collection entry, so we remove it from the
-	 * load context.
-	 * <p/>
-	 * The idea here is that other loading collections can now reference said
-	 * collection directly from the {@link PersistenceContext} because it
-	 * has completed its load cycle.
-	 * <p/>
-	 * Implementation note: package protected, as this is meant solely for use
-	 * by {@link CollectionLoadContext} to be able to locate collections
-	 * being loaded by other {@link CollectionLoadContext}s/{@link ResultSet}s.
-	 *
-	 * @param key The key of the collection we are done processing.
-	 */
-	void unregisterLoadingCollectionXRef(CollectionKey key) {
-		if ( !hasRegisteredLoadingCollectionEntries() ) {
-			return;
-		}
-		xrefLoadingCollectionEntries.remove(key);
-	 }
-
-	/*package*/Map getLoadingCollectionXRefs() {
- 		return xrefLoadingCollectionEntries;
- 	}
-
-
-	/**
-	 * Locate the LoadingCollectionEntry within *any* of the tracked
-	 * {@link CollectionLoadContext}s.
-	 * <p/>
-	 * Implementation note: package protected, as this is meant solely for use
-	 * by {@link CollectionLoadContext} to be able to locate collections
-	 * being loaded by other {@link CollectionLoadContext}s/{@link ResultSet}s.
-	 *
-	 * @param key The collection key.
-	 * @return The located entry; or null.
-	 */
-	LoadingCollectionEntry locateLoadingCollectionEntry(CollectionKey key) {
-        if (xrefLoadingCollectionEntries == null) return null;
-        LOG.trace("Attempting to locate loading collection entry [" + key + "] in any result-set context");
-		LoadingCollectionEntry rtn = ( LoadingCollectionEntry ) xrefLoadingCollectionEntries.get( key );
-        if (rtn == null) LOG.trace("Collection [" + key + "] not located in load context");
-        else LOG.trace("Collection [" + key + "] located in load context");
-		return rtn;
-	}
-
-	/*package*/void cleanupCollectionXRefs(Set entryKeys) {
-		Iterator itr = entryKeys.iterator();
-		while ( itr.hasNext() ) {
-			final CollectionKey entryKey = ( CollectionKey ) itr.next();
-			xrefLoadingCollectionEntries.remove( entryKey );
-		}
-	}
-
-
-	// Entity load contexts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-	// 	* currently, not yet used...
-
-	public EntityLoadContext getEntityLoadContext(ResultSet resultSet) {
-		EntityLoadContext context = null;
-		if ( entityLoadContexts == null ) {
-			entityLoadContexts = IdentityMap.instantiate( 8 );
-		}
-		else {
-			context = ( EntityLoadContext ) entityLoadContexts.get( resultSet );
-		}
-		if ( context == null ) {
-			context = new EntityLoadContext( this, resultSet );
-			entityLoadContexts.put( resultSet, context );
-		}
-		return context;
-	}
-}
+
+import java.io.Serializable;
+import java.sql.ResultSet;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Set;
+import org.hibernate.EntityMode;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.collection.PersistentCollection;
+import org.hibernate.engine.CollectionKey;
+import org.hibernate.engine.PersistenceContext;
+import org.hibernate.engine.SessionImplementor;
+import org.hibernate.internal.util.collections.IdentityMap;
+import org.hibernate.persister.collection.CollectionPersister;
+import org.hibernate.pretty.MessageHelper;
+
+import org.jboss.logging.Logger;
+
+/**
+ * Maps {@link ResultSet result-sets} to specific contextual data
+ * related to processing that {@link ResultSet result-sets}.
+ * <p/>
+ * Implementation note: internally an {@link IdentityMap} is used to maintain
+ * the mappings; {@link IdentityMap} was chosen because I'd rather not be
+ * dependent upon potentially bad {@link ResultSet#equals} and {ResultSet#hashCode}
+ * implementations.
+ * <p/>
+ * Considering the JDBC-redesign work, would further like this contextual info
+ * not mapped seperately, but available based on the result set being processed.
+ * This would also allow maintaining a single mapping as we could reliably get
+ * notification of the result-set closing...
+ *
+ * @author Steve Ebersole
+ */
+public class LoadContexts {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, LoadContexts.class.getName());
+
+	private final PersistenceContext persistenceContext;
+	private Map collectionLoadContexts;
+	private Map entityLoadContexts;
+
+	private Map xrefLoadingCollectionEntries;
+
+	/**
+	 * Creates and binds this to the given persistence context.
+	 *
+	 * @param persistenceContext The persistence context to which this
+	 * will be bound.
+	 */
+	public LoadContexts(PersistenceContext persistenceContext) {
+		this.persistenceContext = persistenceContext;
+	}
+
+	/**
+	 * Retrieves the persistence context to which this is bound.
+	 *
+	 * @return The persistence context to which this is bound.
+	 */
+	public PersistenceContext getPersistenceContext() {
+		return persistenceContext;
+	}
+
+	private SessionImplementor getSession() {
+		return getPersistenceContext().getSession();
+	}
+
+	private EntityMode getEntityMode() {
+		return getSession().getEntityMode();
+	}
+
+
+	// cleanup code ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+ 	/**
+	 * Release internal state associated with the given result set.
+	 * <p/>
+	 * This should be called when we are done with processing said result set,
+	 * ideally as the result set is being closed.
+	 *
+	 * @param resultSet The result set for which it is ok to release
+	 * associated resources.
+	 */
+	public void cleanup(ResultSet resultSet) {
+		if ( collectionLoadContexts != null ) {
+			CollectionLoadContext collectionLoadContext = ( CollectionLoadContext ) collectionLoadContexts.remove( resultSet );
+			collectionLoadContext.cleanup();
+		}
+		if ( entityLoadContexts != null ) {
+			EntityLoadContext entityLoadContext = ( EntityLoadContext ) entityLoadContexts.remove( resultSet );
+			entityLoadContext.cleanup();
+		}
+	}
+
+	/**
+	 * Release internal state associated with *all* result sets.
+	 * <p/>
+	 * This is intended as a "failsafe" process to make sure we get everything
+	 * cleaned up and released.
+	 */
+	public void cleanup() {
+		if ( collectionLoadContexts != null ) {
+			Iterator itr = collectionLoadContexts.values().iterator();
+			while ( itr.hasNext() ) {
+				CollectionLoadContext collectionLoadContext = ( CollectionLoadContext ) itr.next();
+                LOG.failSafeCollectionsCleanup(collectionLoadContext);
+				collectionLoadContext.cleanup();
+			}
+			collectionLoadContexts.clear();
+		}
+		if ( entityLoadContexts != null ) {
+			Iterator itr = entityLoadContexts.values().iterator();
+			while ( itr.hasNext() ) {
+				EntityLoadContext entityLoadContext = ( EntityLoadContext ) itr.next();
+                LOG.failSafeEntitiesCleanup(entityLoadContext);
+				entityLoadContext.cleanup();
+			}
+			entityLoadContexts.clear();
+		}
+	}
+
+
+	// Collection load contexts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	/**
+	 * Do we currently have any internal entries corresponding to loading
+	 * collections?
+	 *
+	 * @return True if we currently hold state pertaining to loading collections;
+	 * false otherwise.
+	 */
+	public boolean hasLoadingCollectionEntries() {
+		return ( collectionLoadContexts != null && !collectionLoadContexts.isEmpty() );
+	}
+
+	/**
+	 * Do we currently have any registered internal entries corresponding to loading
+	 * collections?
+	 *
+	 * @return True if we currently hold state pertaining to a registered loading collections;
+	 * false otherwise.
+	 */
+	public boolean hasRegisteredLoadingCollectionEntries() {
+		return ( xrefLoadingCollectionEntries != null && !xrefLoadingCollectionEntries.isEmpty() );
+	}
+
+
+	/**
+	 * Get the {@link CollectionLoadContext} associated with the given
+	 * {@link ResultSet}, creating one if needed.
+	 *
+	 * @param resultSet The result set for which to retrieve the context.
+	 * @return The processing context.
+	 */
+	public CollectionLoadContext getCollectionLoadContext(ResultSet resultSet) {
+		CollectionLoadContext context = null;
+        if (collectionLoadContexts == null) collectionLoadContexts = IdentityMap.instantiate(8);
+        else context = (CollectionLoadContext)collectionLoadContexts.get(resultSet);
+		if ( context == null ) {
+            LOG.trace("Constructing collection load context for result set [" + resultSet + "]");
+			context = new CollectionLoadContext( this, resultSet );
+			collectionLoadContexts.put( resultSet, context );
+		}
+		return context;
+	}
+
+	/**
+	 * Attempt to locate the loading collection given the owner's key.  The lookup here
+	 * occurs against all result-set contexts...
+	 *
+	 * @param persister The collection persister
+	 * @param ownerKey The owner key
+	 * @return The loading collection, or null if not found.
+	 */
+	public PersistentCollection locateLoadingCollection(CollectionPersister persister, Serializable ownerKey) {
+		LoadingCollectionEntry lce = locateLoadingCollectionEntry( new CollectionKey( persister, ownerKey, getEntityMode() ) );
+		if ( lce != null ) {
+            if (LOG.isTraceEnabled()) LOG.trace("Returning loading collection: "
+                                                + MessageHelper.collectionInfoString(persister, ownerKey, getSession().getFactory()));
+			return lce.getCollection();
+		}
+        // TODO : should really move this log statement to CollectionType, where this is used from...
+        if (LOG.isTraceEnabled()) LOG.trace("Creating collection wrapper: "
+                                            + MessageHelper.collectionInfoString(persister, ownerKey, getSession().getFactory()));
+        return null;
+	}
+
+	// loading collection xrefs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	/**
+	 * Register a loading collection xref.
+	 * <p/>
+	 * This xref map is used because sometimes a collection is in process of
+	 * being loaded from one result set, but needs to be accessed from the
+	 * context of another "nested" result set processing.
+	 * <p/>
+	 * Implementation note: package protected, as this is meant solely for use
+	 * by {@link CollectionLoadContext} to be able to locate collections
+	 * being loaded by other {@link CollectionLoadContext}s/{@link ResultSet}s.
+	 *
+	 * @param entryKey The xref collection key
+	 * @param entry The corresponding loading collection entry
+	 */
+	void registerLoadingCollectionXRef(CollectionKey entryKey, LoadingCollectionEntry entry) {
+		if ( xrefLoadingCollectionEntries == null ) {
+			xrefLoadingCollectionEntries = new HashMap();
+		}
+		xrefLoadingCollectionEntries.put( entryKey, entry );
+	}
+
+	/**
+	 * The inverse of {@link #registerLoadingCollectionXRef}.  Here, we are done
+	 * processing the said collection entry, so we remove it from the
+	 * load context.
+	 * <p/>
+	 * The idea here is that other loading collections can now reference said
+	 * collection directly from the {@link PersistenceContext} because it
+	 * has completed its load cycle.
+	 * <p/>
+	 * Implementation note: package protected, as this is meant solely for use
+	 * by {@link CollectionLoadContext} to be able to locate collections
+	 * being loaded by other {@link CollectionLoadContext}s/{@link ResultSet}s.
+	 *
+	 * @param key The key of the collection we are done processing.
+	 */
+	void unregisterLoadingCollectionXRef(CollectionKey key) {
+		if ( !hasRegisteredLoadingCollectionEntries() ) {
+			return;
+		}
+		xrefLoadingCollectionEntries.remove(key);
+	 }
+
+	/*package*/Map getLoadingCollectionXRefs() {
+ 		return xrefLoadingCollectionEntries;
+ 	}
+
+
+	/**
+	 * Locate the LoadingCollectionEntry within *any* of the tracked
+	 * {@link CollectionLoadContext}s.
+	 * <p/>
+	 * Implementation note: package protected, as this is meant solely for use
+	 * by {@link CollectionLoadContext} to be able to locate collections
+	 * being loaded by other {@link CollectionLoadContext}s/{@link ResultSet}s.
+	 *
+	 * @param key The collection key.
+	 * @return The located entry; or null.
+	 */
+	LoadingCollectionEntry locateLoadingCollectionEntry(CollectionKey key) {
+        if (xrefLoadingCollectionEntries == null) return null;
+        LOG.trace("Attempting to locate loading collection entry [" + key + "] in any result-set context");
+		LoadingCollectionEntry rtn = ( LoadingCollectionEntry ) xrefLoadingCollectionEntries.get( key );
+        if (rtn == null) LOG.trace("Collection [" + key + "] not located in load context");
+        else LOG.trace("Collection [" + key + "] located in load context");
+		return rtn;
+	}
+
+	/*package*/void cleanupCollectionXRefs(Set entryKeys) {
+		Iterator itr = entryKeys.iterator();
+		while ( itr.hasNext() ) {
+			final CollectionKey entryKey = ( CollectionKey ) itr.next();
+			xrefLoadingCollectionEntries.remove( entryKey );
+		}
+	}
+
+
+	// Entity load contexts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+	// 	* currently, not yet used...
+
+	public EntityLoadContext getEntityLoadContext(ResultSet resultSet) {
+		EntityLoadContext context = null;
+		if ( entityLoadContexts == null ) {
+			entityLoadContexts = IdentityMap.instantiate( 8 );
+		}
+		else {
+			context = ( EntityLoadContext ) entityLoadContexts.get( resultSet );
+		}
+		if ( context == null ) {
+			context = new EntityLoadContext( this, resultSet );
+			entityLoadContexts.put( resultSet, context );
+		}
+		return context;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/profile/FetchProfile.java b/hibernate-core/src/main/java/org/hibernate/engine/profile/FetchProfile.java
index c59ebccaf8..e49a26909d 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/profile/FetchProfile.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/profile/FetchProfile.java
@@ -1,167 +1,167 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.profile;
 import java.util.HashMap;
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.type.BagType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * A 'fetch profile' allows a user to dynamically modify the fetching strategy used for particular associations at
  * runtime, whereas that information was historically only statically defined in the metadata.
  * <p/>
  * This class defines the runtime representation of this data.
  *
  * @author Steve Ebersole
  */
 public class FetchProfile {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, FetchProfile.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, FetchProfile.class.getName());
 
 	private final String name;
 	private Map<String,Fetch> fetches = new HashMap<String,Fetch>();
 
 	private boolean containsJoinFetchedCollection = false;
 	private boolean containsJoinFetchedBag = false;
 	private Fetch bagJoinFetch;
 
 	/**
 	 * A 'fetch profile' is uniquely named within a
 	 * {@link SessionFactoryImplementor SessionFactory}, thus it is also
 	 * uniquely and easily identifiable within that
 	 * {@link SessionFactoryImplementor SessionFactory}.
 	 *
 	 * @param name The name under which we are bound in the sessionFactory
 	 */
 	public FetchProfile(String name) {
 		this.name = name;
 	}
 
 	/**
 	 * Add a fetch to the profile.
 	 *
 	 * @param association The association to be fetched
 	 * @param fetchStyleName The name of the fetch style to apply
 	 */
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public void addFetch(Association association, String fetchStyleName) {
 		addFetch( association, Fetch.Style.parse( fetchStyleName ) );
 	}
 
 	/**
 	 * Add a fetch to the profile.
 	 *
 	 * @param association The association to be fetched
 	 * @param style The style to apply
 	 */
 	public void addFetch(Association association, Fetch.Style style) {
 		addFetch( new Fetch( association, style ) );
 	}
 
 	/**
 	 * Add a fetch to the profile.
 	 *
 	 * @param fetch The fetch to add.
 	 */
 	public void addFetch(Fetch fetch) {
 		Type associationType = fetch.getAssociation().getOwner().getPropertyType( fetch.getAssociation().getAssociationPath() );
 		if ( associationType.isCollectionType() ) {
             LOG.trace("Handling request to add collection fetch [" + fetch.getAssociation().getRole() + "]");
 
 			// couple of things for which to account in the case of collection
 			// join fetches
 			if ( Fetch.Style.JOIN == fetch.getStyle() ) {
 				// first, if this is a bag we need to ignore it if we previously
 				// processed collection join fetches
 				if ( BagType.class.isInstance( associationType ) ) {
 					if ( containsJoinFetchedCollection ) {
                         LOG.containsJoinFetchedCollection(fetch.getAssociation().getRole());
 						return; // EARLY EXIT!!!
 					}
 				}
 
 				// also, in cases where we are asked to add a collection join
 				// fetch where we had already added a bag join fetch previously,
 				// we need to go back and ignore that previous bag join fetch.
 				if ( containsJoinFetchedBag ) {
                     // just for safety...
                     if (fetches.remove(bagJoinFetch.getAssociation().getRole()) != bagJoinFetch) LOG.unableToRemoveBagJoinFetch();
 					bagJoinFetch = null;
 					containsJoinFetchedBag = false;
 				}
 
 				containsJoinFetchedCollection = true;
 			}
 		}
 		fetches.put( fetch.getAssociation().getRole(), fetch );
 	}
 
 	/**
 	 * Getter for property 'name'.
 	 *
 	 * @return Value for property 'name'.
 	 */
 	public String getName() {
 		return name;
 	}
 
 	/**
 	 * Getter for property 'fetches'.  Map of {@link Fetch} instances, keyed by association <tt>role</tt>
 	 *
 	 * @return Value for property 'fetches'.
 	 */
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public Map<String,Fetch> getFetches() {
 		return fetches;
 	}
 
 	public Fetch getFetchByRole(String role) {
 		return fetches.get( role );
 	}
 
 	/**
 	 * Getter for property 'containsJoinFetchedCollection', which flags whether
 	 * this fetch profile contained any collection join fetches.
 	 *
 	 * @return Value for property 'containsJoinFetchedCollection'.
 	 */
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public boolean isContainsJoinFetchedCollection() {
 		return containsJoinFetchedCollection;
 	}
 
 	/**
 	 * Getter for property 'containsJoinFetchedBag', which flags whether this
 	 * fetch profile contained any bag join fetches
 	 *
 	 * @return Value for property 'containsJoinFetchedBag'.
 	 */
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public boolean isContainsJoinFetchedBag() {
 		return containsJoinFetchedBag;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/query/HQLQueryPlan.java b/hibernate-core/src/main/java/org/hibernate/engine/query/HQLQueryPlan.java
index a4e41bc5ef..26241ff587 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/query/HQLQueryPlan.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/query/HQLQueryPlan.java
@@ -1,339 +1,339 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.query;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.RowSelection;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.hql.FilterTranslator;
 import org.hibernate.hql.ParameterTranslations;
 import org.hibernate.hql.QuerySplitter;
 import org.hibernate.hql.QueryTranslator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.collections.EmptyIterator;
 import org.hibernate.internal.util.collections.IdentitySet;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.type.Type;
 
 /**
  * Defines a query execution plan for an HQL query (or filter).
  *
  * @author Steve Ebersole
  */
 public class HQLQueryPlan implements Serializable {
 
     // TODO : keep separate notions of QT[] here for shallow/non-shallow queries...
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, HQLQueryPlan.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HQLQueryPlan.class.getName());
 
 	private final String sourceQuery;
 	private final QueryTranslator[] translators;
 	private final String[] sqlStrings;
 
 	private final ParameterMetadata parameterMetadata;
 	private final ReturnMetadata returnMetadata;
 	private final Set querySpaces;
 
 	private final Set enabledFilterNames;
 	private final boolean shallow;
 
 
 	public HQLQueryPlan(String hql, boolean shallow, Map enabledFilters, SessionFactoryImplementor factory) {
 		this( hql, null, shallow, enabledFilters, factory );
 	}
 
 	protected HQLQueryPlan(String hql, String collectionRole, boolean shallow, Map enabledFilters, SessionFactoryImplementor factory) {
 		this.sourceQuery = hql;
 		this.shallow = shallow;
 
 		Set copy = new HashSet();
 		copy.addAll( enabledFilters.keySet() );
 		this.enabledFilterNames = java.util.Collections.unmodifiableSet( copy );
 
 		Set combinedQuerySpaces = new HashSet();
 		String[] concreteQueryStrings = QuerySplitter.concreteQueries( hql, factory );
 		final int length = concreteQueryStrings.length;
 		translators = new QueryTranslator[length];
 		List sqlStringList = new ArrayList();
 		for ( int i=0; i<length; i++ ) {
 			if ( collectionRole == null ) {
 				translators[i] = factory.getSettings()
 						.getQueryTranslatorFactory()
 						.createQueryTranslator( hql, concreteQueryStrings[i], enabledFilters, factory );
 				translators[i].compile( factory.getSettings().getQuerySubstitutions(), shallow );
 			}
 			else {
 				translators[i] = factory.getSettings()
 						.getQueryTranslatorFactory()
 						.createFilterTranslator( hql, concreteQueryStrings[i], enabledFilters, factory );
 				( ( FilterTranslator ) translators[i] ).compile( collectionRole, factory.getSettings().getQuerySubstitutions(), shallow );
 			}
 			combinedQuerySpaces.addAll( translators[i].getQuerySpaces() );
 			sqlStringList.addAll( translators[i].collectSqlStrings() );
 		}
 
 		this.sqlStrings = ArrayHelper.toStringArray( sqlStringList );
 		this.querySpaces = combinedQuerySpaces;
 
 		if ( length == 0 ) {
 			parameterMetadata = new ParameterMetadata( null, null );
 			returnMetadata = null;
 		}
 		else {
 			this.parameterMetadata = buildParameterMetadata( translators[0].getParameterTranslations(), hql );
 			if ( translators[0].isManipulationStatement() ) {
 				returnMetadata = null;
 			}
 			else {
 				if ( length > 1 ) {
 					final int returns = translators[0].getReturnTypes().length;
 					returnMetadata = new ReturnMetadata( translators[0].getReturnAliases(), new Type[returns] );
 				}
 				else {
 					returnMetadata = new ReturnMetadata( translators[0].getReturnAliases(), translators[0].getReturnTypes() );
 				}
 			}
 		}
 	}
 
 	public String getSourceQuery() {
 		return sourceQuery;
 	}
 
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	public ParameterMetadata getParameterMetadata() {
 		return parameterMetadata;
 	}
 
 	public ReturnMetadata getReturnMetadata() {
 		return returnMetadata;
 	}
 
 	public Set getEnabledFilterNames() {
 		return enabledFilterNames;
 	}
 
 	public String[] getSqlStrings() {
 		return sqlStrings;
 	}
 
 	public Set getUtilizedFilterNames() {
 		// TODO : add this info to the translator and aggregate it here...
 		return null;
 	}
 
 	public boolean isShallow() {
 		return shallow;
 	}
 
 	public List performList(
 			QueryParameters queryParameters,
 	        SessionImplementor session) throws HibernateException {
         if (LOG.isTraceEnabled()) {
             LOG.trace("Find: " + getSourceQuery());
 			queryParameters.traceParameters( session.getFactory() );
 		}
 		boolean hasLimit = queryParameters.getRowSelection() != null &&
 		                   queryParameters.getRowSelection().definesLimits();
 		boolean needsLimit = hasLimit && translators.length > 1;
 		QueryParameters queryParametersToUse;
 		if ( needsLimit ) {
             LOG.needsLimit();
 			RowSelection selection = new RowSelection();
 			selection.setFetchSize( queryParameters.getRowSelection().getFetchSize() );
 			selection.setTimeout( queryParameters.getRowSelection().getTimeout() );
 			queryParametersToUse = queryParameters.createCopyUsing( selection );
 		}
 		else {
 			queryParametersToUse = queryParameters;
 		}
 
 		List combinedResults = new ArrayList();
 		IdentitySet distinction = new IdentitySet();
 		int includedCount = -1;
 		translator_loop: for ( int i = 0; i < translators.length; i++ ) {
 			List tmp = translators[i].list( session, queryParametersToUse );
 			if ( needsLimit ) {
 				// NOTE : firstRow is zero-based
 				int first = queryParameters.getRowSelection().getFirstRow() == null
 				            ? 0
 			                : queryParameters.getRowSelection().getFirstRow().intValue();
 				int max = queryParameters.getRowSelection().getMaxRows() == null
 				            ? -1
 			                : queryParameters.getRowSelection().getMaxRows().intValue();
 				final int size = tmp.size();
 				for ( int x = 0; x < size; x++ ) {
 					final Object result = tmp.get( x );
 					if ( ! distinction.add( result ) ) {
 						continue;
 					}
 					includedCount++;
 					if ( includedCount < first ) {
 						continue;
 					}
 					combinedResults.add( result );
 					if ( max >= 0 && includedCount > max ) {
 						// break the outer loop !!!
 						break translator_loop;
 					}
 				}
 			}
 			else {
 				combinedResults.addAll( tmp );
 			}
 		}
 		return combinedResults;
 	}
 
 	public Iterator performIterate(
 			QueryParameters queryParameters,
 	        EventSource session) throws HibernateException {
         if (LOG.isTraceEnabled()) {
             LOG.trace("Iterate: " + getSourceQuery());
 			queryParameters.traceParameters( session.getFactory() );
 		}
 		if ( translators.length == 0 ) {
 			return EmptyIterator.INSTANCE;
 		}
 
 		Iterator[] results = null;
 		boolean many = translators.length > 1;
 		if (many) {
 			results = new Iterator[translators.length];
 		}
 
 		Iterator result = null;
 		for ( int i = 0; i < translators.length; i++ ) {
 			result = translators[i].iterate( queryParameters, session );
 			if (many) results[i] = result;
 		}
 
 		return many ? new JoinedIterator(results) : result;
 	}
 
 	public ScrollableResults performScroll(
 			QueryParameters queryParameters,
 	        SessionImplementor session) throws HibernateException {
         if (LOG.isTraceEnabled()) {
             LOG.trace("Iterate: " + getSourceQuery());
 			queryParameters.traceParameters( session.getFactory() );
 		}
 		if ( translators.length != 1 ) {
 			throw new QueryException( "implicit polymorphism not supported for scroll() queries" );
 		}
 		if ( queryParameters.getRowSelection().definesLimits() && translators[0].containsCollectionFetches() ) {
 			throw new QueryException( "firstResult/maxResults not supported in conjunction with scroll() of a query containing collection fetches" );
 		}
 
 		return translators[0].scroll( queryParameters, session );
 	}
 
 	public int performExecuteUpdate(QueryParameters queryParameters, SessionImplementor session)
 			throws HibernateException {
         if (LOG.isTraceEnabled()) {
             LOG.trace("Execute update: " + getSourceQuery());
 			queryParameters.traceParameters( session.getFactory() );
 		}
         if (translators.length != 1) LOG.splitQueries(getSourceQuery(), translators.length);
 		int result = 0;
 		for ( int i = 0; i < translators.length; i++ ) {
 			result += translators[i].executeUpdate( queryParameters, session );
 		}
 		return result;
 	}
 
 	private ParameterMetadata buildParameterMetadata(ParameterTranslations parameterTranslations, String hql) {
 		long start = System.currentTimeMillis();
 		ParamLocationRecognizer recognizer = ParamLocationRecognizer.parseLocations( hql );
 		long end = System.currentTimeMillis();
         LOG.trace("HQL param location recognition took " + (end - start) + " mills (" + hql + ")");
 
 		int ordinalParamCount = parameterTranslations.getOrdinalParameterCount();
 		int[] locations = ArrayHelper.toIntArray( recognizer.getOrdinalParameterLocationList() );
 		if ( parameterTranslations.supportsOrdinalParameterMetadata() && locations.length != ordinalParamCount ) {
 			throw new HibernateException( "ordinal parameter mismatch" );
 		}
 		ordinalParamCount = locations.length;
 		OrdinalParameterDescriptor[] ordinalParamDescriptors = new OrdinalParameterDescriptor[ordinalParamCount];
 		for ( int i = 1; i <= ordinalParamCount; i++ ) {
 			ordinalParamDescriptors[ i - 1 ] = new OrdinalParameterDescriptor(
 					i,
 			        parameterTranslations.supportsOrdinalParameterMetadata()
 		                    ? parameterTranslations.getOrdinalParameterExpectedType( i )
 		                    : null,
 			        locations[ i - 1 ]
 			);
 		}
 
 		Iterator itr = recognizer.getNamedParameterDescriptionMap().entrySet().iterator();
 		Map namedParamDescriptorMap = new HashMap();
 		while( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String name = ( String ) entry.getKey();
 			final ParamLocationRecognizer.NamedParameterDescription description =
 					( ParamLocationRecognizer.NamedParameterDescription ) entry.getValue();
 			namedParamDescriptorMap.put(
 					name,
 					new NamedParameterDescriptor(
 							name,
 					        parameterTranslations.getNamedParameterExpectedType( name ),
 					        description.buildPositionsArray(),
 					        description.isJpaStyle()
 					)
 			);
 		}
 
 		return new ParameterMetadata( ordinalParamDescriptors, namedParamDescriptorMap );
 	}
 
 	public QueryTranslator[] getTranslators() {
 		QueryTranslator[] copy = new QueryTranslator[translators.length];
 		System.arraycopy(translators, 0, copy, 0, copy.length);
 		return copy;
 	}
 
 	public Class getDynamicInstantiationResultType() {
 		return translators[0].getDynamicInstantiationResultType();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/query/NativeSQLQueryPlan.java b/hibernate-core/src/main/java/org/hibernate/engine/query/NativeSQLQueryPlan.java
index a5946332eb..bd677857d9 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/query/NativeSQLQueryPlan.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/query/NativeSQLQueryPlan.java
@@ -1,217 +1,217 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine.query;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
 import org.hibernate.action.internal.BulkOperationCleanupAction;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.TypedValue;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.event.EventSource;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.custom.sql.SQLCustomQuery;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Defines a query execution plan for a native-SQL query.
  *
  * @author Steve Ebersole
  */
 public class NativeSQLQueryPlan implements Serializable {
 	private final String sourceQuery;
 
 	private final SQLCustomQuery customQuery;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, NativeSQLQueryPlan.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, NativeSQLQueryPlan.class.getName());
 
 	public NativeSQLQueryPlan(
 			NativeSQLQuerySpecification specification,
 			SessionFactoryImplementor factory) {
 		this.sourceQuery = specification.getQueryString();
 
 		customQuery = new SQLCustomQuery(
 				specification.getQueryString(),
 				specification.getQueryReturns(),
 				specification.getQuerySpaces(),
 				factory );
 	}
 
 	public String getSourceQuery() {
 		return sourceQuery;
 	}
 
 	public SQLCustomQuery getCustomQuery() {
 		return customQuery;
 	}
 
 	private int[] getNamedParameterLocs(String name) throws QueryException {
 		Object loc = customQuery.getNamedParameterBindPoints().get( name );
 		if ( loc == null ) {
 			throw new QueryException(
 					"Named parameter does not appear in Query: " + name,
 					customQuery.getSQL() );
 		}
 		if ( loc instanceof Integer ) {
 			return new int[] { ((Integer) loc ).intValue() };
 		}
 		else {
 			return ArrayHelper.toIntArray( (List) loc );
 		}
 	}
 
 	/**
 	 * Perform binding of all the JDBC bind parameter values based on the user-defined
 	 * positional query parameters (these are the '?'-style hibernate query
 	 * params) into the JDBC {@link PreparedStatement}.
 	 *
 	 * @param st The prepared statement to which to bind the parameter values.
 	 * @param queryParameters The query parameters specified by the application.
 	 * @param start JDBC paramer binds are positional, so this is the position
 	 * from which to start binding.
 	 * @param session The session from which the query originated.
 	 *
 	 * @return The number of JDBC bind positions accounted for during execution.
 	 *
 	 * @throws SQLException Some form of JDBC error binding the values.
 	 * @throws HibernateException Generally indicates a mapping problem or type mismatch.
 	 */
 	private int bindPositionalParameters(
 			final PreparedStatement st,
 			final QueryParameters queryParameters,
 			final int start,
 			final SessionImplementor session) throws SQLException {
 		final Object[] values = queryParameters.getFilteredPositionalParameterValues();
 		final Type[] types = queryParameters.getFilteredPositionalParameterTypes();
 		int span = 0;
 		for (int i = 0; i < values.length; i++) {
 			types[i].nullSafeSet( st, values[i], start + span, session );
 			span += types[i].getColumnSpan( session.getFactory() );
 		}
 		return span;
 	}
 
 	/**
 	 * Perform binding of all the JDBC bind parameter values based on the user-defined
 	 * named query parameters into the JDBC {@link PreparedStatement}.
 	 *
 	 * @param ps The prepared statement to which to bind the parameter values.
 	 * @param namedParams The named query parameters specified by the application.
 	 * @param start JDBC paramer binds are positional, so this is the position
 	 * from which to start binding.
 	 * @param session The session from which the query originated.
 	 *
 	 * @return The number of JDBC bind positions accounted for during execution.
 	 *
 	 * @throws SQLException Some form of JDBC error binding the values.
 	 * @throws HibernateException Generally indicates a mapping problem or type mismatch.
 	 */
 	private int bindNamedParameters(
 			final PreparedStatement ps,
 			final Map namedParams,
 			final int start,
 			final SessionImplementor session) throws SQLException {
 		if ( namedParams != null ) {
 			// assumes that types are all of span 1
 			Iterator iter = namedParams.entrySet().iterator();
 			int result = 0;
 			while ( iter.hasNext() ) {
 				Map.Entry e = (Map.Entry) iter.next();
 				String name = (String) e.getKey();
 				TypedValue typedval = (TypedValue) e.getValue();
 				int[] locs = getNamedParameterLocs( name );
 				for (int i = 0; i < locs.length; i++) {
                     LOG.debugf("bindNamedParameters() %s -> %s [%s]", typedval.getValue(), name, locs[i] + start);
 					typedval.getType().nullSafeSet( ps, typedval.getValue(),
 							locs[i] + start, session );
 				}
 				result += locs.length;
 			}
 			return result;
 		}
         return 0;
 	}
 
 	protected void coordinateSharedCacheCleanup(SessionImplementor session) {
 		BulkOperationCleanupAction action = new BulkOperationCleanupAction( session, getCustomQuery().getQuerySpaces() );
 
 		if ( session.isEventSource() ) {
 			( ( EventSource ) session ).getActionQueue().addAction( action );
 		}
 		else {
 			action.getAfterTransactionCompletionProcess().doAfterTransactionCompletion( true, session );
 		}
 	}
 
 	public int performExecuteUpdate(QueryParameters queryParameters,
 			SessionImplementor session) throws HibernateException {
 
 		coordinateSharedCacheCleanup( session );
 
 		if(queryParameters.isCallable()) {
 			throw new IllegalArgumentException("callable not yet supported for native queries");
 		}
 
 		int result = 0;
 		PreparedStatement ps;
 		try {
 			queryParameters.processFilters( this.customQuery.getSQL(),
 					session );
 			String sql = queryParameters.getFilteredSQL();
 
 			ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql, false );
 
 			try {
 				int col = 1;
 				col += bindPositionalParameters( ps, queryParameters, col,
 						session );
 				col += bindNamedParameters( ps, queryParameters
 						.getNamedParameters(), col, session );
 				result = ps.executeUpdate();
 			}
 			finally {
 				if ( ps != null ) {
 					ps.close();
 				}
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle, "could not execute native bulk manipulation query", this.sourceQuery );
 		}
 
 		return result;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/query/QueryPlanCache.java b/hibernate-core/src/main/java/org/hibernate/engine/query/QueryPlanCache.java
index 4bfa89626d..f9ac14b64f 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/query/QueryPlanCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/query/QueryPlanCache.java
@@ -1,345 +1,347 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.query;
 
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.impl.FilterImpl;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.collections.SimpleMRUCache;
 import org.hibernate.internal.util.collections.SoftLimitMRUCache;
 import org.hibernate.internal.util.config.ConfigurationHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * Acts as a cache for compiled query plans, as well as query-parameter metadata.
  *
  * @see Environment#QUERY_PLAN_CACHE_MAX_STRONG_REFERENCES
  * @see Environment#QUERY_PLAN_CACHE_MAX_SOFT_REFERENCES
  *
  * @author Steve Ebersole
  */
 public class QueryPlanCache implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, QueryPlanCache.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QueryPlanCache.class.getName());
 
 	private SessionFactoryImplementor factory;
 
 	public QueryPlanCache(SessionFactoryImplementor factory) {
 		int maxStrongReferenceCount = ConfigurationHelper.getInt(
 				Environment.QUERY_PLAN_CACHE_MAX_STRONG_REFERENCES,
 				factory.getProperties(),
 				SoftLimitMRUCache.DEFAULT_STRONG_REF_COUNT
 		);
 		int maxSoftReferenceCount = ConfigurationHelper.getInt(
 				Environment.QUERY_PLAN_CACHE_MAX_SOFT_REFERENCES,
 				factory.getProperties(),
 				SoftLimitMRUCache.DEFAULT_SOFT_REF_COUNT
 		);
 
 		this.factory = factory;
 		this.sqlParamMetadataCache = new SimpleMRUCache( maxStrongReferenceCount );
 		this.planCache = new SoftLimitMRUCache( maxStrongReferenceCount, maxSoftReferenceCount );
 	}
 
 	/**
 	 * simple cache of param metadata based on query string.  Ideally, the original "user-supplied query"
 	 * string should be used to obtain this metadata (i.e., not the para-list-expanded query string) to avoid
 	 * unnecessary cache entries.
 	 * <p>
 	 * Used solely for caching param metadata for native-sql queries, see {@link #getSQLParameterMetadata} for a
 	 * discussion as to why...
 	 */
 	private final SimpleMRUCache sqlParamMetadataCache;
 
 	/**
 	 * the cache of the actual plans...
 	 */
 	private final SoftLimitMRUCache planCache;
 
 
 	/**
 	 * Obtain the parameter metadata for given native-sql query.
 	 * <p/>
 	 * for native-sql queries, the param metadata is determined outside any relation to a query plan, because
 	 * query plan creation and/or retrieval for a native-sql query depends on all of the return types having been
 	 * set, which might not be the case up-front when param metadata would be most useful
 	 *
 	 * @param query The query
 	 * @return The parameter metadata
 	 */
 	public ParameterMetadata getSQLParameterMetadata(String query) {
 		ParameterMetadata metadata = ( ParameterMetadata ) sqlParamMetadataCache.get( query );
 		if ( metadata == null ) {
 			metadata = buildNativeSQLParameterMetadata( query );
 			sqlParamMetadataCache.put( query, metadata );
 		}
 		return metadata;
 	}
 
 	public HQLQueryPlan getHQLQueryPlan(String queryString, boolean shallow, Map enabledFilters)
 			throws QueryException, MappingException {
 		HQLQueryPlanKey key = new HQLQueryPlanKey( queryString, shallow, enabledFilters );
 		HQLQueryPlan plan = ( HQLQueryPlan ) planCache.get ( key );
 
 		if ( plan == null ) {
             LOG.trace("Unable to locate HQL query plan in cache; generating (" + queryString + ")");
 			plan = new HQLQueryPlan(queryString, shallow, enabledFilters, factory );
         } else LOG.trace("Located HQL query plan in cache (" + queryString + ")");
 
 		planCache.put( key, plan );
 
 		return plan;
 	}
 
 	public FilterQueryPlan getFilterQueryPlan(String filterString, String collectionRole, boolean shallow, Map enabledFilters)
 			throws QueryException, MappingException {
 		FilterQueryPlanKey key = new FilterQueryPlanKey( filterString, collectionRole, shallow, enabledFilters );
 		FilterQueryPlan plan = ( FilterQueryPlan ) planCache.get ( key );
 
 		if ( plan == null ) {
             LOG.trace("Unable to locate collection-filter query plan in cache; generating (" + collectionRole + " : "
                       + filterString + ")");
 			plan = new FilterQueryPlan( filterString, collectionRole, shallow, enabledFilters, factory );
         } else LOG.trace("Located collection-filter query plan in cache (" + collectionRole + " : " + filterString + ")");
 
 		planCache.put( key, plan );
 
 		return plan;
 	}
 
 	public NativeSQLQueryPlan getNativeSQLQueryPlan(NativeSQLQuerySpecification spec) {
 		NativeSQLQueryPlan plan = ( NativeSQLQueryPlan ) planCache.get( spec );
 
 		if ( plan == null ) {
             LOG.trace("Unable to locate native-sql query plan in cache; generating (" + spec.getQueryString() + ")");
 			plan = new NativeSQLQueryPlan( spec, factory );
         } else LOG.trace("Located native-sql query plan in cache (" + spec.getQueryString() + ")");
 
 		planCache.put( spec, plan );
 		return plan;
 	}
 
 	@SuppressWarnings({ "UnnecessaryUnboxing" })
 	private ParameterMetadata buildNativeSQLParameterMetadata(String sqlString) {
 		ParamLocationRecognizer recognizer = ParamLocationRecognizer.parseLocations( sqlString );
 
 		OrdinalParameterDescriptor[] ordinalDescriptors =
 				new OrdinalParameterDescriptor[ recognizer.getOrdinalParameterLocationList().size() ];
 		for ( int i = 0; i < recognizer.getOrdinalParameterLocationList().size(); i++ ) {
 			final Integer position = ( Integer ) recognizer.getOrdinalParameterLocationList().get( i );
 			ordinalDescriptors[i] = new OrdinalParameterDescriptor( i, null, position.intValue() );
 		}
 
 		Iterator itr = recognizer.getNamedParameterDescriptionMap().entrySet().iterator();
 		Map<String,NamedParameterDescriptor> namedParamDescriptorMap = new HashMap<String,NamedParameterDescriptor>();
 		while( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String name = ( String ) entry.getKey();
 			final ParamLocationRecognizer.NamedParameterDescription description =
 					( ParamLocationRecognizer.NamedParameterDescription ) entry.getValue();
 			namedParamDescriptorMap.put(
 					name ,
 			        new NamedParameterDescriptor( name, null, description.buildPositionsArray(), description.isJpaStyle() )
 			);
 		}
 
 		return new ParameterMetadata( ordinalDescriptors, namedParamDescriptorMap );
 	}
 
 	private static class HQLQueryPlanKey implements Serializable {
 		private final String query;
 		private final boolean shallow;
 		private final Set<DynamicFilterKey> filterKeys;
 		private final int hashCode;
 
 		public HQLQueryPlanKey(String query, boolean shallow, Map enabledFilters) {
 			this.query = query;
 			this.shallow = shallow;
 
 			if ( enabledFilters == null || enabledFilters.isEmpty() ) {
 				filterKeys = Collections.emptySet();
 			}
 			else {
 				Set<DynamicFilterKey> tmp = new HashSet<DynamicFilterKey>(
 						CollectionHelper.determineProperSizing( enabledFilters ),
 						CollectionHelper.LOAD_FACTOR
 				);
 				for ( Object o : enabledFilters.values() ) {
 					tmp.add( new DynamicFilterKey( (FilterImpl) o ) );
 				}
 				this.filterKeys = Collections.unmodifiableSet( tmp );
 			}
 
 			int hash = query.hashCode();
 			hash = 29 * hash + ( shallow ? 1 : 0 );
 			hash = 29 * hash + filterKeys.hashCode();
 			this.hashCode = hash;
 		}
 
 		@Override
         public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			final HQLQueryPlanKey that = ( HQLQueryPlanKey ) o;
 
 			return shallow == that.shallow
 					&& filterKeys.equals( that.filterKeys )
 					&& query.equals( that.query );
 
 		}
 
 		@Override
         public int hashCode() {
 			return hashCode;
 		}
 	}
 
 	private static class DynamicFilterKey implements Serializable {
 		private final String filterName;
 		private final Map<String,Integer> parameterMetadata;
 		private final int hashCode;
 
 		@SuppressWarnings({ "UnnecessaryBoxing" })
 		private DynamicFilterKey(FilterImpl filter) {
 			this.filterName = filter.getName();
 			if ( filter.getParameters().isEmpty() ) {
 				parameterMetadata = Collections.emptyMap();
 			}
 			else {
 				parameterMetadata = new HashMap<String,Integer>(
 						CollectionHelper.determineProperSizing( filter.getParameters() ),
 						CollectionHelper.LOAD_FACTOR
 				);
 				for ( Object o : filter.getParameters().entrySet() ) {
 					final Map.Entry entry = (Map.Entry) o;
 					final String key = (String) entry.getKey();
 					final Integer valueCount;
 					if ( Collection.class.isInstance( entry.getValue() ) ) {
 						valueCount = new Integer( ( (Collection) entry.getValue() ).size() );
 					}
 					else {
 						valueCount = new Integer( 1 );
 					}
 					parameterMetadata.put( key, valueCount );
 				}
 			}
 
 			int hash = filterName.hashCode();
 			hash = 31 * hash + parameterMetadata.hashCode();
 			this.hashCode = hash;
 		}
 
 		@Override
         public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			DynamicFilterKey that = ( DynamicFilterKey ) o;
 
 			return filterName.equals( that.filterName )
 					&& parameterMetadata.equals( that.parameterMetadata );
 
 		}
 
 		@Override
         public int hashCode() {
 			return hashCode;
 		}
 	}
 
 	private static class FilterQueryPlanKey implements Serializable {
 		private final String query;
 		private final String collectionRole;
 		private final boolean shallow;
 		private final Set<String> filterNames;
 		private final int hashCode;
 
 		@SuppressWarnings({ "unchecked" })
 		public FilterQueryPlanKey(String query, String collectionRole, boolean shallow, Map enabledFilters) {
 			this.query = query;
 			this.collectionRole = collectionRole;
 			this.shallow = shallow;
 
 			if ( enabledFilters == null || enabledFilters.isEmpty() ) {
 				filterNames = Collections.emptySet();
 			}
 			else {
 				Set<String> tmp = new HashSet<String>();
 				tmp.addAll( enabledFilters.keySet() );
 				this.filterNames = Collections.unmodifiableSet( tmp );
 			}
 
 			int hash = query.hashCode();
 			hash = 29 * hash + collectionRole.hashCode();
 			hash = 29 * hash + ( shallow ? 1 : 0 );
 			hash = 29 * hash + filterNames.hashCode();
 			this.hashCode = hash;
 		}
 
 		@Override
         public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			final FilterQueryPlanKey that = ( FilterQueryPlanKey ) o;
 
 			return shallow == that.shallow
 					&& filterNames.equals( that.filterNames )
 					&& query.equals( that.query )
 					&& collectionRole.equals( that.collectionRole );
 
 		}
 
 		@Override
         public int hashCode() {
 			return hashCode;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/SynchronizationRegistryImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/SynchronizationRegistryImpl.java
index 4a0094b504..ddcdab1b5a 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/SynchronizationRegistryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/SynchronizationRegistryImpl.java
@@ -1,95 +1,96 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.internal;
 
 import java.util.LinkedHashSet;
 import javax.transaction.Synchronization;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.transaction.spi.SynchronizationRegistry;
 import org.jboss.logging.Logger;
 
 /**
  * Manages a registry of {@link Synchronization Synchronizations}.
  *
  * @author Steve Ebersole
  */
 public class SynchronizationRegistryImpl implements SynchronizationRegistry {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        SynchronizationRegistryImpl.class.getName());
 
 	private LinkedHashSet<Synchronization> synchronizations;
 
 	@Override
 	public void registerSynchronization(Synchronization synchronization) {
 		if ( synchronization == null ) {
 			throw new NullSynchronizationException();
 		}
 
 		if ( synchronizations == null ) {
 			synchronizations = new LinkedHashSet<Synchronization>();
 		}
 
 		boolean added = synchronizations.add( synchronization );
         if (!added) LOG.synchronizationAlreadyRegistered(synchronization);
 	}
 
 	@Override
 	public void notifySynchronizationsBeforeTransactionCompletion() {
 		if ( synchronizations != null ) {
 			for ( Synchronization synchronization : synchronizations ) {
 				try {
 					synchronization.beforeCompletion();
 				}
 				catch ( Throwable t ) {
                     LOG.synchronizationFailed(synchronization, t);
 				}
 			}
 		}
 	}
 
 	@Override
 	public void notifySynchronizationsAfterTransactionCompletion(int status) {
 		if ( synchronizations != null ) {
 			for ( Synchronization synchronization : synchronizations ) {
 				try {
 					synchronization.afterCompletion( status );
 				}
 				catch ( Throwable t ) {
                     LOG.synchronizationFailed(synchronization, t);
 				}
 			}
 		}
 	}
 
 	/**
 	 * Package-protected access to clear registered synchronizations.
 	 */
 	void clearSynchronizations() {
 		if ( synchronizations != null ) {
 			synchronizations.clear();
 			synchronizations = null;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionCoordinatorImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionCoordinatorImpl.java
index d31898e2bc..0b05ff90da 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionCoordinatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionCoordinatorImpl.java
@@ -1,355 +1,355 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.internal;
 
 import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.ResourceClosedException;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.spi.JoinStatus;
 import org.hibernate.engine.transaction.spi.SynchronizationRegistry;
 import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.engine.transaction.spi.TransactionObserver;
 import org.hibernate.engine.transaction.synchronization.internal.RegisteredSynchronization;
 import org.hibernate.engine.transaction.synchronization.internal.SynchronizationCallbackCoordinatorImpl;
 import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.jboss.logging.Logger;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.sql.Connection;
 import java.util.ArrayList;
 import java.util.List;
 
 /**
  * Standard implementation of the Hibernate {@link TransactionCoordinator}
  * <p/>
  * IMPL NOTE : Custom serialization handling!
  *
  * @author Steve Ebersole
  */
 public class TransactionCoordinatorImpl implements TransactionCoordinator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TransactionCoordinatorImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TransactionCoordinatorImpl.class.getName());
 
 	private final transient TransactionContext transactionContext;
 	private final transient JdbcCoordinatorImpl jdbcCoordinator;
 
 	private final transient List<TransactionObserver> observers;
 	private final transient SynchronizationRegistryImpl synchronizationRegistry;
 
 	private transient TransactionImplementor currentHibernateTransaction;
 
 	private transient SynchronizationCallbackCoordinatorImpl callbackCoordinator;
 
 	private transient boolean open = true;
 	private transient boolean synchronizationRegistered;
 	private transient boolean ownershipTaken;
 
 	public TransactionCoordinatorImpl(
 			Connection userSuppliedConnection,
 			TransactionContext transactionContext) {
 		this.transactionContext = transactionContext;
 		this.jdbcCoordinator = new JdbcCoordinatorImpl( userSuppliedConnection, this );
 		this.observers = new ArrayList<TransactionObserver>();
 		this.synchronizationRegistry = new SynchronizationRegistryImpl();
 		reset();
 
 		final boolean registerSynchronization = transactionContext.isAutoCloseSessionEnabled()
 		        || transactionContext.isFlushBeforeCompletionEnabled()
 		        || transactionContext.getConnectionReleaseMode() == ConnectionReleaseMode.AFTER_TRANSACTION;
 		if ( registerSynchronization ) {
 			pulse();
 		}
 	}
 
 	public TransactionCoordinatorImpl(
 			TransactionContext transactionContext,
 			JdbcCoordinatorImpl jdbcCoordinator,
 			List<TransactionObserver> observers) {
 		this.transactionContext = transactionContext;
 		this.jdbcCoordinator = jdbcCoordinator;
 		this.observers = observers;
 		this.synchronizationRegistry = new SynchronizationRegistryImpl();
 		reset();
 	}
 
 	/**
 	 * Reset the internal state.
 	 */
 	public void reset() {
 		synchronizationRegistered = false;
 		ownershipTaken = false;
 
 		if ( currentHibernateTransaction != null ) {
 			currentHibernateTransaction.invalidate();
 		}
 		currentHibernateTransaction = transactionFactory().createTransaction( this );
 		if ( transactionContext.shouldAutoJoinTransaction() ) {
 			currentHibernateTransaction.markForJoin();
 			currentHibernateTransaction.join();
 		}
 
 		// IMPL NOTE : reset clears synchronizations (following jta spec), but not observers!
 		synchronizationRegistry.clearSynchronizations();
 	}
 
 	public void afterTransaction(TransactionImplementor hibernateTransaction, int status) {
 		LOG.trace( "after transaction completion" );
 
 		final boolean success = JtaStatusHelper.isCommitted( status );
 
 		transactionContext.getTransactionEnvironment().getStatisticsImplementor().endTransaction( success );
 
 		getJdbcCoordinator().afterTransaction();
 
 		getTransactionContext().afterTransactionCompletion( hibernateTransaction, success );
 		sendAfterTransactionCompletionNotifications( hibernateTransaction, status );
 		reset();
 	}
 
 	private SessionFactoryImplementor sessionFactory() {
 		return transactionContext.getTransactionEnvironment().getSessionFactory();
 	}
 
 	public boolean isSynchronizationRegistered() {
 		return synchronizationRegistered;
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public boolean isTransactionInProgress() {
 		return getTransaction().isActive() && getTransaction().getJoinStatus() == JoinStatus.JOINED;
 	}
 
 	@Override
 	public TransactionContext getTransactionContext() {
 		return transactionContext;
 	}
 
 	@Override
 	public JdbcCoordinator getJdbcCoordinator() {
 		return jdbcCoordinator;
 	}
 
 	private TransactionFactory transactionFactory() {
 		return getTransactionEnvironment().getTransactionFactory();
 	}
 
 	private TransactionEnvironment getTransactionEnvironment() {
 		return getTransactionContext().getTransactionEnvironment();
 	}
 
 	@Override
 	public TransactionImplementor getTransaction() {
 		if ( ! open ) {
 			throw new ResourceClosedException( "This TransactionCoordinator has been closed" );
 		}
 		pulse();
 		return currentHibernateTransaction;
 	}
 
 	public void afterNonTransactionalQuery(boolean success) {
 		// check to see if the connection is in auto-commit mode (no connection means aggressive connection
 		// release outside a JTA transaction context, so MUST be autocommit mode)
 		boolean isAutocommit = getJdbcCoordinator().getLogicalConnection().isAutoCommit();
 		getJdbcCoordinator().getLogicalConnection().afterTransaction();
 
 		if ( isAutocommit ) {
 			for ( TransactionObserver observer : observers ) {
 				observer.afterCompletion( success, this.getTransaction() );
 			}
 		}
 	}
 
 	@Override
 	public void resetJoinStatus() {
 		getTransaction().resetJoinStatus();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private void attemptToRegisterJtaSync() {
 		if ( synchronizationRegistered ) {
 			return;
 		}
 
 		// Has the local transaction (Hibernate facade) taken on the responsibility of driving the transaction inflow?
 		if ( currentHibernateTransaction.isInitiator() ) {
 			return;
 		}
 
 		if ( ! transactionContext.shouldAutoJoinTransaction() ) {
 			if ( currentHibernateTransaction.getJoinStatus() != JoinStatus.MARKED_FOR_JOINED ) {
 				LOG.debug( "Skipping JTA sync registration due to auto join checking" );
 				return;
 			}
 		}
 
 		// IMPL NOTE : At this point the local callback is the "maybe" one.  The only time that needs to change is if
 		// we are able to successfully register the transaction synchronization in which case the local callback would  become
 		// non driving.  To that end, the following checks are simply opt outs where we are unable to register the
 		// synchronization
 
 		JtaPlatform jtaPlatform = getTransactionEnvironment().getJtaPlatform();
 		if ( jtaPlatform == null ) {
 			// if no jta platform was registered we wont be able to register a jta synchronization
 			return;
 		}
 
 		// Can we resister a synchronization
 		if ( ! jtaPlatform.canRegisterSynchronization() ) {
 			LOG.trace(  "registered JTA platform says we cannot currently resister synchronization; skipping" );
 			return;
 		}
 
 		// Should we resister a synchronization
 		if ( ! transactionFactory().isJoinableJtaTransaction( this, currentHibernateTransaction ) ) {
 			LOG.trace( "TransactionFactory reported no JTA transaction to join; skipping Synchronization registration" );
 			return;
 		}
 
 		jtaPlatform.registerSynchronization( new RegisteredSynchronization( getSynchronizationCallbackCoordinator() ) );
 		synchronizationRegistered = true;
 		LOG.debug( "successfully registered Synchronization" );
 	}
 
 	@Override
 	public SynchronizationCallbackCoordinator getSynchronizationCallbackCoordinator() {
 		if ( callbackCoordinator == null ) {
 			callbackCoordinator = new SynchronizationCallbackCoordinatorImpl( this );
 		}
 		return callbackCoordinator;
 	}
 
 	public void pulse() {
 		LOG.trace( "Starting transaction coordinator pulse" );
 		if ( transactionFactory().compatibleWithJtaSynchronization() ) {
 			// the configured transaction strategy says it supports callbacks via JTA synchronization, so attempt to
 			// register JTA synchronization if possible
 			attemptToRegisterJtaSync();
 		}
 	}
 
 	public Connection close() {
 		open = false;
 		reset();
 		observers.clear();
 		return jdbcCoordinator.close();
 	}
 
 	public SynchronizationRegistry getSynchronizationRegistry() {
 		return synchronizationRegistry;
 	}
 
 	public void addObserver(TransactionObserver observer) {
 		observers.add( observer );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public boolean isTransactionJoinable() {
 		return transactionFactory().isJoinableJtaTransaction( this, currentHibernateTransaction );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public boolean isTransactionJoined() {
 		return currentHibernateTransaction != null && currentHibernateTransaction.getJoinStatus() == JoinStatus.JOINED;
 	}
 
 	public void setRollbackOnly() {
 		getTransaction().markRollbackOnly();
 	}
 
 	@Override
 	public boolean takeOwnership() {
 		if ( ownershipTaken ) {
 			return false;
 		}
 		else {
 			ownershipTaken = true;
 			return true;
 		}
 	}
 
 	@Override
 	public void sendAfterTransactionBeginNotifications(TransactionImplementor hibernateTransaction) {
 		for ( TransactionObserver observer : observers ) {
 			observer.afterBegin( currentHibernateTransaction );
 		}
 	}
 
 	@Override
 	public void sendBeforeTransactionCompletionNotifications(TransactionImplementor hibernateTransaction) {
 		synchronizationRegistry.notifySynchronizationsBeforeTransactionCompletion();
 		for ( TransactionObserver observer : observers ) {
 			observer.beforeCompletion( hibernateTransaction );
 		}
 	}
 
 	@Override
 	public void sendAfterTransactionCompletionNotifications(TransactionImplementor hibernateTransaction, int status) {
 		final boolean successful = JtaStatusHelper.isCommitted( status );
 		for ( TransactionObserver observer : observers ) {
 			observer.afterCompletion( successful, hibernateTransaction );
 		}
 		synchronizationRegistry.notifySynchronizationsAfterTransactionCompletion( status );
 	}
 
 
 	// serialization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void serialize(ObjectOutputStream oos) throws IOException {
 		jdbcCoordinator.serialize( oos );
 		oos.writeInt( observers.size() );
 		for ( TransactionObserver observer : observers ) {
 			oos.writeObject( observer );
 		}
 	}
 
 	public static TransactionCoordinatorImpl deserialize(
 			ObjectInputStream ois,
 			TransactionContext transactionContext) throws ClassNotFoundException, IOException {
 		final JdbcCoordinatorImpl jdbcCoordinator = JdbcCoordinatorImpl.deserialize( ois, transactionContext );
 		final int observerCount = ois.readInt();
 		final List<TransactionObserver> observers = CollectionHelper.arrayList( observerCount );
 		for ( int i = 0; i < observerCount; i++ ) {
 			observers.add( (TransactionObserver) ois.readObject() );
 		}
 		final TransactionCoordinatorImpl transactionCoordinator = new TransactionCoordinatorImpl( transactionContext, jdbcCoordinator, observers );
 		jdbcCoordinator.afterDeserialize( transactionCoordinator );
 		return transactionCoordinator;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionFactoryInitiator.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionFactoryInitiator.java
index b1c4813107..5dcfdf819a 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionFactoryInitiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionFactoryInitiator.java
@@ -1,100 +1,100 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.internal;
 
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.transaction.internal.jdbc.JdbcTransactionFactory;
 import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.engine.transaction.internal.jta.JtaTransactionFactory;
 import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.service.classloading.spi.ClassLoaderService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.BasicServiceInitiator;
 
 /**
  * Standard instantiator for the standard {@link TransactionFactory} service.
  *
  * @author Steve Ebersole
  */
 public class TransactionFactoryInitiator<T extends TransactionImplementor> implements BasicServiceInitiator<TransactionFactory> {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        TransactionFactoryInitiator.class.getName());
 
 	public static final TransactionFactoryInitiator INSTANCE = new TransactionFactoryInitiator();
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public Class<TransactionFactory> getServiceInitiated() {
 		return TransactionFactory.class;
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public TransactionFactory initiateService(Map configurationValues, ServiceRegistryImplementor registry) {
 		final Object strategy = configurationValues.get( Environment.TRANSACTION_STRATEGY );
 		if ( TransactionFactory.class.isInstance( strategy ) ) {
 			return (TransactionFactory) strategy;
 		}
 
 		if ( strategy == null ) {
             LOG.usingDefaultTransactionStrategy();
 			return new JdbcTransactionFactory();
 		}
 
 		final String strategyClassName = mapLegacyNames( strategy.toString() );
         LOG.transactionStrategy(strategyClassName);
 
 		ClassLoaderService classLoaderService = registry.getService( ClassLoaderService.class );
 		try {
 			return (TransactionFactory) classLoaderService.classForName( strategyClassName ).newInstance();
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Unable to instantiate specified TransactionFactory class [" + strategyClassName + "]", e );
 		}
 	}
 
 	private String mapLegacyNames(String name) {
 		if ( "org.hibernate.transaction.JDBCTransactionFactory".equals( name ) ) {
 			return JdbcTransactionFactory.class.getName();
 		}
 
 		if ( "org.hibernate.transaction.JTATransactionFactory".equals( name ) ) {
 			return JtaTransactionFactory.class.getName();
 		}
 
 		if ( "org.hibernate.transaction.CMTTransactionFactory".equals( name ) ) {
 			return CMTTransactionFactory.class.getName();
 		}
 
 		return name;
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcIsolationDelegate.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcIsolationDelegate.java
index be97d17a79..e631ddc27b 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcIsolationDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcIsolationDelegate.java
@@ -1,124 +1,125 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.internal.jdbc;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.transaction.spi.IsolationDelegate;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+
 import org.jboss.logging.Logger;
 
 /**
  * The isolation delegate for JDBC {@link Connection} based transactions
  *
  * @author Steve Ebersole
  */
 public class JdbcIsolationDelegate implements IsolationDelegate {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JdbcIsolationDelegate.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JdbcIsolationDelegate.class.getName());
 
 	private final TransactionCoordinator transactionCoordinator;
 
 	public JdbcIsolationDelegate(TransactionCoordinator transactionCoordinator) {
 		this.transactionCoordinator = transactionCoordinator;
 	}
 
 	protected ConnectionProvider connectionProvider() {
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getJdbcServices().getConnectionProvider();
 	}
 
 	protected SqlExceptionHelper sqlExceptionHelper() {
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getJdbcServices().getSqlExceptionHelper();
 	}
 
 	@Override
 	public <T> T delegateWork(WorkExecutorVisitable<T> work, boolean transacted) throws HibernateException {
 		boolean wasAutoCommit = false;
 		try {
 			// todo : should we use a connection proxy here?
 			Connection connection = connectionProvider().getConnection();
 			try {
 				if ( transacted ) {
 					if ( connection.getAutoCommit() ) {
 						wasAutoCommit = true;
 						connection.setAutoCommit( false );
 					}
 				}
 
 				T result = work.accept( new WorkExecutor<T>(), connection );
 
 				if ( transacted ) {
 					connection.commit();
 				}
 
 				return result;
 			}
 			catch ( Exception e ) {
 				try {
 					if ( transacted && !connection.isClosed() ) {
 						connection.rollback();
 					}
 				}
 				catch ( Exception ignore ) {
                     LOG.unableToRollbackConnection(ignore);
 				}
 
 				if ( e instanceof HibernateException ) {
 					throw (HibernateException) e;
 				}
 				else if ( e instanceof SQLException ) {
 					throw sqlExceptionHelper().convert( (SQLException) e, "error performing isolated work" );
 				}
 				else {
 					throw new HibernateException( "error performing isolated work", e );
 				}
 			}
 			finally {
 				if ( transacted && wasAutoCommit ) {
 					try {
 						connection.setAutoCommit( true );
 					}
 					catch ( Exception ignore ) {
                         LOG.trace("was unable to reset connection back to auto-commit");
 					}
 				}
 				try {
 					connectionProvider().closeConnection( connection );
 				}
 				catch ( Exception ignore ) {
                     LOG.unableToReleaseIsolatedConnection(ignore);
 				}
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper().convert( sqle, "unable to obtain isolated JDBC connection" );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransaction.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransaction.java
index 5996870911..5fd7daa0ff 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransaction.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransaction.java
@@ -1,206 +1,207 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.internal.jdbc;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.TransactionException;
 import org.hibernate.engine.transaction.spi.AbstractTransactionImpl;
 import org.hibernate.engine.transaction.spi.IsolationDelegate;
 import org.hibernate.engine.transaction.spi.JoinStatus;
 import org.hibernate.engine.transaction.spi.LocalStatus;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
+
 import org.jboss.logging.Logger;
 
 /**
  * {@link org.hibernate.Transaction} implementation based on transaction management through a JDBC {@link java.sql.Connection}.
  * <p/>
  * This the default transaction strategy.
  *
  * @author Anton van Straaten
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class JdbcTransaction extends AbstractTransactionImpl {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JdbcTransaction.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JdbcTransaction.class.getName());
 
 	private Connection managedConnection;
 	private boolean wasInitiallyAutoCommit;
 	private boolean isDriver;
 
 	protected JdbcTransaction(TransactionCoordinator transactionCoordinator) {
 		super( transactionCoordinator );
 	}
 
 	@Override
 	protected void doBegin() {
 		try {
 			if ( managedConnection != null ) {
 				throw new TransactionException( "Already have an associated managed connection" );
 			}
 			managedConnection = transactionCoordinator().getJdbcCoordinator().getLogicalConnection().getConnection();
 			wasInitiallyAutoCommit = managedConnection.getAutoCommit();
             LOG.debug("initial autocommit status: " + wasInitiallyAutoCommit);
 			if ( wasInitiallyAutoCommit ) {
                 LOG.debug("disabling autocommit");
 				managedConnection.setAutoCommit( false );
 			}
 		}
 		catch( SQLException e ) {
 			throw new TransactionException( "JDBC begin transaction failed: ", e );
 		}
 
 		isDriver = transactionCoordinator().takeOwnership();
 	}
 
 	@Override
 	protected void afterTransactionBegin() {
 		if ( getTimeout() > 0 ) {
 			transactionCoordinator().getJdbcCoordinator().setTransactionTimeOut( getTimeout() );
 		}
 		transactionCoordinator().sendAfterTransactionBeginNotifications( this );
 		if ( isDriver ) {
 			transactionCoordinator().getTransactionContext().afterTransactionBegin( this );
 		}
 	}
 
 	@Override
 	protected void beforeTransactionCommit() {
 		transactionCoordinator().sendBeforeTransactionCompletionNotifications( this );
 
 		// basically, if we are the driver of the transaction perform a managed flush prior to
 		// physically committing the transaction
 		if ( isDriver && !transactionCoordinator().getTransactionContext().isFlushModeNever() ) {
 			// if an exception occurs during flush, user must call rollback()
 			transactionCoordinator().getTransactionContext().managedFlush();
 		}
 
 		if ( isDriver ) {
 			transactionCoordinator().getTransactionContext().beforeTransactionCompletion( this );
 		}
 	}
 
 	@Override
 	protected void doCommit() throws TransactionException {
 		try {
 			managedConnection.commit();
             LOG.debug("committed JDBC Connection");
 		}
 		catch( SQLException e ) {
 			throw new TransactionException( "unable to commit against JDBC connection", e );
 		}
 		finally {
 			releaseManagedConnection();
 		}
 	}
 
 	private void releaseManagedConnection() {
 		try {
 			if ( wasInitiallyAutoCommit ) {
                 LOG.debug("re-enabling autocommit");
 				managedConnection.setAutoCommit( true );
 			}
 			managedConnection = null;
 		}
 		catch ( Exception e ) {
             LOG.debug("Could not toggle autocommit", e);
 		}
 	}
 
 	@Override
 	protected void afterTransactionCompletion(int status) {
 		transactionCoordinator().afterTransaction( this, status );
 	}
 
 	@Override
 	protected void afterAfterCompletion() {
 		if ( isDriver
 				&& transactionCoordinator().getTransactionContext().shouldAutoClose()
 				&& !transactionCoordinator().getTransactionContext().isClosed() ) {
 			try {
 				transactionCoordinator().getTransactionContext().managedClose();
 			}
 			catch (HibernateException e) {
                 LOG.unableToCloseSessionButSwallowingError(e);
 			}
 		}
 	}
 
 	@Override
 	protected void beforeTransactionRollBack() {
 		// nothing to do here
 	}
 
 	@Override
 	protected void doRollback() throws TransactionException {
 		try {
 			managedConnection.rollback();
             LOG.debug("rolled JDBC Connection");
 		}
 		catch( SQLException e ) {
 			throw new TransactionException( "unable to rollback against JDBC connection", e );
 		}
 		finally {
 			releaseManagedConnection();
 		}
 	}
 
 	@Override
 	public boolean isInitiator() {
 		return isActive();
 	}
 
 	@Override
 	public IsolationDelegate createIsolationDelegate() {
 		return new JdbcIsolationDelegate( transactionCoordinator() );
 	}
 
 	@Override
 	public JoinStatus getJoinStatus() {
 		return isActive() ? JoinStatus.JOINED : JoinStatus.NOT_JOINED;
 	}
 
 	@Override
 	public void markRollbackOnly() {
 		// nothing to do here
 	}
 
 	@Override
 	public void join() {
 		// nothing to do
 	}
 
 	@Override
 	public void resetJoinStatus() {
 		// nothing to do
 	}
 
 	@Override
 	public boolean isActive() throws HibernateException {
 		return getLocalStatus() == LocalStatus.ACTIVE;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaIsolationDelegate.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaIsolationDelegate.java
index 5ff3b2f93c..d90683ae16 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaIsolationDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaIsolationDelegate.java
@@ -1,182 +1,183 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.internal.jta;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import javax.transaction.NotSupportedException;
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.transaction.spi.IsolationDelegate;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+
 import org.jboss.logging.Logger;
 
 /**
  * An isolation delegate for JTA environments.
  *
  * @author Steve Ebersole
  */
 public class JtaIsolationDelegate implements IsolationDelegate {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JtaIsolationDelegate.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JtaIsolationDelegate.class.getName());
 
 	private final TransactionCoordinator transactionCoordinator;
 
 	public JtaIsolationDelegate(TransactionCoordinator transactionCoordinator) {
 		this.transactionCoordinator = transactionCoordinator;
 	}
 
 	protected TransactionManager transactionManager() {
 		return transactionCoordinator.getTransactionContext()
 				.getTransactionEnvironment()
 				.getJtaPlatform()
 				.retrieveTransactionManager();
 	}
 
 	protected ConnectionProvider connectionProvider() {
 		return transactionCoordinator.getTransactionContext()
 				.getTransactionEnvironment()
 				.getJdbcServices()
 				.getConnectionProvider();
 	}
 
 	protected SqlExceptionHelper sqlExceptionHelper() {
 		return transactionCoordinator.getTransactionContext()
 				.getTransactionEnvironment()
 				.getJdbcServices()
 				.getSqlExceptionHelper();
 	}
 
 	@Override
 	public <T> T delegateWork(WorkExecutorVisitable<T> work, boolean transacted) throws HibernateException {
 		TransactionManager transactionManager = transactionManager();
 
 		try {
 			// First we suspend any current JTA transaction
 			Transaction surroundingTransaction = transactionManager.suspend();
             LOG.debugf("Surrounding JTA transaction suspended [%s]", surroundingTransaction);
 
 			boolean hadProblems = false;
 			try {
 				// then perform the requested work
 				if ( transacted ) {
 					return doTheWorkInNewTransaction( work, transactionManager );
 				}
 				else {
 					return doTheWorkInNoTransaction( work );
 				}
 			}
 			catch ( HibernateException e ) {
 				hadProblems = true;
 				throw e;
 			}
 			finally {
 				try {
 					transactionManager.resume( surroundingTransaction );
                     LOG.debugf( "Surrounding JTA transaction resumed [%s]", surroundingTransaction );
 				}
 				catch( Throwable t ) {
 					// if the actually work had an error use that, otherwise error based on t
 					if ( !hadProblems ) {
 						//noinspection ThrowFromFinallyBlock
 						throw new HibernateException( "Unable to resume previously suspended transaction", t );
 					}
 				}
 			}
 		}
 		catch ( SystemException e ) {
 			throw new HibernateException( "Unable to suspend current JTA transaction", e );
 		}
 	}
 
 	private <T> T doTheWorkInNewTransaction(WorkExecutorVisitable<T> work, TransactionManager transactionManager) {
 		T result = null;
 		try {
 			// start the new isolated transaction
 			transactionManager.begin();
 
 			try {
 				result = doTheWork( work );
 				// if everything went ok, commit the isolated transaction
 				transactionManager.commit();
 			}
 			catch ( Exception e ) {
 				try {
 					transactionManager.rollback();
 				}
 				catch ( Exception ignore ) {
                     LOG.unableToRollbackIsolatedTransaction(e, ignore);
 				}
 			}
 		}
 		catch ( SystemException e ) {
 			throw new HibernateException( "Unable to start isolated transaction", e );
 		}
 		catch ( NotSupportedException e ) {
 			throw new HibernateException( "Unable to start isolated transaction", e );
 		}
 		return result;
 	}
 
 	private <T> T doTheWorkInNoTransaction(WorkExecutorVisitable<T> work) {
 		return doTheWork( work );
 	}
 
 	private <T> T doTheWork(WorkExecutorVisitable<T> work) {
 		try {
 			// obtain our isolated connection
 			Connection connection = connectionProvider().getConnection();
 			try {
 				// do the actual work
 				return work.accept( new WorkExecutor<T>(), connection );
 			}
 			catch ( HibernateException e ) {
 				throw e;
 			}
 			catch ( Exception e ) {
 				throw new HibernateException( "Unable to perform isolated work", e );
 			}
 			finally {
 				try {
 					// no matter what, release the connection (handle)
 					connectionProvider().closeConnection( connection );
 				}
 				catch ( Throwable ignore ) {
                     LOG.unableToReleaseIsolatedConnection(ignore);
 				}
 			}
 		}
 		catch ( SQLException e ) {
 			throw sqlExceptionHelper().convert( e, "unable to obtain isolated JDBC connection" );
 		}
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransaction.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransaction.java
index 42fa8019e6..8f1fd7d0d8 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransaction.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransaction.java
@@ -1,276 +1,277 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.internal.jta;
 
 import javax.transaction.Status;
 import javax.transaction.SystemException;
 import javax.transaction.TransactionManager;
 import javax.transaction.UserTransaction;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.TransactionException;
 import org.hibernate.engine.transaction.spi.AbstractTransactionImpl;
 import org.hibernate.engine.transaction.spi.IsolationDelegate;
 import org.hibernate.engine.transaction.spi.JoinStatus;
 import org.hibernate.engine.transaction.spi.LocalStatus;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
+
 import org.jboss.logging.Logger;
 
 /**
  * Implements a transaction strategy based on transaction management through a JTA {@link UserTransaction}.
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Les Hazlewood
  */
 public class JtaTransaction extends AbstractTransactionImpl {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JtaTransaction.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JtaTransaction.class.getName());
 
 	private UserTransaction userTransaction;
 
 	private boolean isInitiator;
 	private boolean isDriver;
 
 	protected JtaTransaction(TransactionCoordinator transactionCoordinator) {
 		super( transactionCoordinator );
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public UserTransaction getUserTransaction() {
 		return userTransaction;
 	}
 
 	@Override
 	protected void doBegin() {
         LOG.debug("begin");
 
 		userTransaction = jtaPlatform().retrieveUserTransaction();
 		if ( userTransaction == null ) {
 			throw new TransactionException( "Unable to locate JTA UserTransaction" );
 		}
 
 		try {
 			if ( userTransaction.getStatus() == Status.STATUS_NO_TRANSACTION ) {
 				userTransaction.begin();
 				isInitiator = true;
                 LOG.debug("Began a new JTA transaction");
 			}
 		}
 		catch ( Exception e ) {
 			throw new TransactionException( "JTA transaction begin failed", e );
 		}
 
 	}
 
 	@Override
 	protected void afterTransactionBegin() {
 		transactionCoordinator().pulse();
 
 		if ( !transactionCoordinator().isSynchronizationRegistered() ) {
 			isDriver = transactionCoordinator().takeOwnership();
 		}
 
 		applyTimeout();
 		transactionCoordinator().sendAfterTransactionBeginNotifications( this );
 		transactionCoordinator().getTransactionContext().afterTransactionBegin( this );
 	}
 
 	private void applyTimeout() {
 		if ( getTimeout() > 0 ) {
 			if ( userTransaction != null ) {
 				try {
 					userTransaction.setTransactionTimeout( getTimeout() );
 				}
 				catch ( SystemException e ) {
 					throw new TransactionException( "Unable to apply requested transaction timeout", e );
 				}
 			}
 			else {
                 LOG.debug("Unable to apply requested transaction timeout; no UserTransaction.  Will try later");
 			}
 		}
 	}
 
 	@Override
 	protected void beforeTransactionCommit() {
 		transactionCoordinator().sendBeforeTransactionCompletionNotifications( this );
 
 		final boolean flush = ! transactionCoordinator().getTransactionContext().isFlushModeNever() &&
 				( isDriver || ! transactionCoordinator().getTransactionContext().isFlushBeforeCompletionEnabled() );
 
 		if ( flush ) {
 			// if an exception occurs during flush, user must call rollback()
 			transactionCoordinator().getTransactionContext().managedFlush();
 		}
 
 		if ( isDriver && isInitiator ) {
 			transactionCoordinator().getTransactionContext().beforeTransactionCompletion( this );
 		}
 
 		closeIfRequired();
 	}
 
 	private void closeIfRequired() throws HibernateException {
 		final boolean close = isDriver &&
 				transactionCoordinator().getTransactionContext().shouldAutoClose() &&
 				! transactionCoordinator().getTransactionContext().isClosed();
 		if ( close ) {
 			transactionCoordinator().getTransactionContext().managedClose();
 		}
 	}
 
 	@Override
 	protected void doCommit() {
 		try {
 			if ( isInitiator ) {
 				userTransaction.commit();
                 LOG.debug("Committed JTA UserTransaction");
 			}
 		}
 		catch ( Exception e ) {
 			throw new TransactionException( "JTA commit failed: ", e );
 		}
 		finally {
 			isInitiator = false;
 		}
 	}
 
 	@Override
 	protected void afterTransactionCompletion(int status) {
 		// nothing to do
 	}
 
 	@Override
 	protected void afterAfterCompletion() {
 		// this method is a noop if there is a Synchronization!
 		if ( isDriver ) {
 			if ( !isInitiator ) {
                 LOG.setManagerLookupClass();
 			}
 			try {
 				transactionCoordinator().afterTransaction( this, userTransaction.getStatus() );
 			}
 			catch (SystemException e) {
 				throw new TransactionException( "Unable to determine UserTransaction status", e );
 			}
 		}
 	}
 
 	@Override
 	protected void beforeTransactionRollBack() {
 		// nothing to do
 	}
 
 	@Override
 	protected void doRollback() {
 		try {
 			if ( isInitiator ) {
 				// failed commits automatically rollback the transaction per JTA spec
 				if ( getLocalStatus() != LocalStatus.FAILED_COMMIT  ) {
 					userTransaction.rollback();
                     LOG.debug("Rolled back JTA UserTransaction");
 				}
 			}
 			else {
 				markRollbackOnly();
 			}
 		}
 		catch ( Exception e ) {
 			throw new TransactionException( "JTA rollback failed", e );
 		}
 	}
 
 	@Override
 	public void markRollbackOnly() {
         LOG.trace("Marking transaction for rollback only");
 		try {
 			userTransaction.setRollbackOnly();
             LOG.debug("set JTA UserTransaction to rollback only");
 		}
 		catch (SystemException e) {
             LOG.debug("Unable to mark transaction for rollback only", e);
 		}
 	}
 
 	@Override
 	public IsolationDelegate createIsolationDelegate() {
 		return new JtaIsolationDelegate( transactionCoordinator() );
 	}
 
 	@Override
 	public boolean isInitiator() {
 		return isInitiator;
 	}
 
 	@Override
 	public boolean isActive() throws HibernateException {
 		if ( getLocalStatus() != LocalStatus.ACTIVE ) {
 			return false;
 		}
 
 		final int status;
 		try {
 			status = userTransaction.getStatus();
 		}
 		catch ( SystemException se ) {
 			throw new TransactionException( "Could not determine transaction status: ", se );
 		}
 		return JtaStatusHelper.isActive( status );
 	}
 
 	@Override
 	public void setTimeout(int seconds) {
 		super.setTimeout( seconds );
 		applyTimeout();
 	}
 
 	@Override
 	public void join() {
 	}
 
 	@Override
 	public void resetJoinStatus() {
 	}
 
 	@Override
 	public JoinStatus getJoinStatus() {
 		// if we already have the UserTransaction cached locally, use it to avoid JNDI look ups
 		if ( this.userTransaction != null ) {
 			return JtaStatusHelper.isActive( this.userTransaction ) ? JoinStatus.JOINED : JoinStatus.NOT_JOINED;
 		}
 
 		// Otherwise, try to use the TransactionManager since it is generally cached
 		TransactionManager transactionManager = jtaPlatform().retrieveTransactionManager();
 		if ( transactionManager != null ) {
 			return JtaStatusHelper.isActive( transactionManager ) ? JoinStatus.JOINED : JoinStatus.NOT_JOINED;
 		}
 
 		// Finally, look up the UserTransaction
 		UserTransaction userTransaction = jtaPlatform().retrieveUserTransaction();
 		return userTransaction != null && JtaStatusHelper.isActive( userTransaction )
 				? JoinStatus.JOINED
 				: JoinStatus.NOT_JOINED;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/AbstractTransactionImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/AbstractTransactionImpl.java
index 8a14fedade..0ed200a6f2 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/AbstractTransactionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/AbstractTransactionImpl.java
@@ -1,247 +1,247 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.spi;
 
 import javax.transaction.Status;
 import javax.transaction.Synchronization;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.TransactionException;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.jboss.logging.Logger;
 
 /**
  * Abstract support for creating {@link TransactionImplementor transaction} implementations
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractTransactionImpl implements TransactionImplementor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractTransactionImpl.class.getName());
 
 	private final TransactionCoordinator transactionCoordinator;
 
 	private boolean valid = true;
 
 	private LocalStatus localStatus = LocalStatus.NOT_ACTIVE;
 	private int timeout = -1;
 
 	protected AbstractTransactionImpl(TransactionCoordinator transactionCoordinator) {
 		this.transactionCoordinator = transactionCoordinator;
 	}
 
 	@Override
 	public void invalidate() {
 		valid = false;
 	}
 
 	/**
 	 * Perform the actual steps of beginning a transaction according to the strategy.
 	 *
 	 * @throws org.hibernate.TransactionException Indicates a problem beginning the transaction
 	 */
 	protected abstract void doBegin();
 
 	/**
 	 * Perform the actual steps of committing a transaction according to the strategy.
 	 *
 	 * @throws org.hibernate.TransactionException Indicates a problem committing the transaction
 	 */
 	protected abstract void doCommit();
 
 	/**
 	 * Perform the actual steps of rolling back a transaction according to the strategy.
 	 *
 	 * @throws org.hibernate.TransactionException Indicates a problem rolling back the transaction
 	 */
 	protected abstract void doRollback();
 
 	protected abstract void afterTransactionBegin();
 	protected abstract void beforeTransactionCommit();
 	protected abstract void beforeTransactionRollBack();
 	protected abstract void afterTransactionCompletion(int status);
 	protected abstract void afterAfterCompletion();
 
 	/**
 	 * Provide subclasses with access to the transaction coordinator.
 	 *
 	 * @return This transaction's context.
 	 */
 	protected TransactionCoordinator transactionCoordinator() {
 		return transactionCoordinator;
 	}
 
 	/**
 	 * Provide subclasses with convenient access to the configured {@link JtaPlatform}
 	 *
 	 * @return The {@link org.hibernate.service.jta.platform.spi.JtaPlatform}
 	 */
 	protected JtaPlatform jtaPlatform() {
 		return transactionCoordinator().getTransactionContext().getTransactionEnvironment().getJtaPlatform();
 	}
 
 	@Override
 	public void registerSynchronization(Synchronization synchronization) {
 		transactionCoordinator().getSynchronizationRegistry().registerSynchronization( synchronization );
 	}
 
 	@Override
 	public LocalStatus getLocalStatus() {
 		return localStatus;
 	}
 
 	@Override
 	public boolean isActive() {
 		return localStatus == LocalStatus.ACTIVE && doExtendedActiveCheck();
 	}
 
 	@Override
 	public boolean isParticipating() {
 		return getJoinStatus() == JoinStatus.JOINED && isActive();
 	}
 
 	@Override
 	public boolean wasCommitted() {
 		return localStatus == LocalStatus.COMMITTED;
 	}
 
 	@Override
 	public boolean wasRolledBack() throws HibernateException {
 		return localStatus == LocalStatus.ROLLED_BACK;
 	}
 
 	/**
 	 * Active has been checked against local state.  Perform any needed checks against resource transactions.
 	 *
 	 * @return {@code true} if the extended active check checks out as well; false otherwise.
 	 */
 	protected boolean doExtendedActiveCheck() {
 		return true;
 	}
 
 	@Override
 	public void begin() throws HibernateException {
 		if ( ! valid ) {
 			throw new TransactionException( "Transaction instance is no longer valid" );
 		}
 		if ( localStatus == LocalStatus.ACTIVE ) {
 			throw new TransactionException( "nested transactions not supported" );
 		}
 		if ( localStatus != LocalStatus.NOT_ACTIVE ) {
 			throw new TransactionException( "reuse of Transaction instances not supported" );
 		}
 
         LOG.debug("begin");
 
 		doBegin();
 
 		localStatus = LocalStatus.ACTIVE;
 
 		afterTransactionBegin();
 	}
 
 	@Override
 	public void commit() throws HibernateException {
 		if ( localStatus != LocalStatus.ACTIVE ) {
 			throw new TransactionException( "Transaction not successfully started" );
 		}
 
         LOG.debug("committing");
 
 		beforeTransactionCommit();
 
 		try {
 			doCommit();
 			localStatus = LocalStatus.COMMITTED;
 			afterTransactionCompletion( Status.STATUS_COMMITTED );
 		}
 		catch ( Exception e ) {
 			localStatus = LocalStatus.FAILED_COMMIT;
 			afterTransactionCompletion( Status.STATUS_UNKNOWN );
 			throw new TransactionException( "commit failed", e );
 		}
 		finally {
 			invalidate();
 			afterAfterCompletion();
 		}
 	}
 
 	protected boolean allowFailedCommitToPhysicallyRollback() {
 		return false;
 	}
 
 	@Override
 	public void rollback() throws HibernateException {
 		if ( localStatus != LocalStatus.ACTIVE && localStatus != LocalStatus.FAILED_COMMIT ) {
 			throw new TransactionException( "Transaction not successfully started" );
 		}
 
         LOG.debug("rolling back");
 
 		beforeTransactionRollBack();
 
 		if ( localStatus != LocalStatus.FAILED_COMMIT || allowFailedCommitToPhysicallyRollback() ) {
 			try {
 				doRollback();
 				localStatus = LocalStatus.ROLLED_BACK;
 				afterTransactionCompletion( Status.STATUS_ROLLEDBACK );
 			}
 			catch ( Exception e ) {
 				afterTransactionCompletion( Status.STATUS_UNKNOWN );
 				throw new TransactionException( "rollback failed", e );
 			}
 			finally {
 				invalidate();
 				afterAfterCompletion();
 			}
 		}
 
 	}
 
 	@Override
 	public void setTimeout(int seconds) {
 		timeout = seconds;
 	}
 
 	@Override
 	public int getTimeout() {
 		return timeout;
 	}
 
 	@Override
 	public void markForJoin() {
 		// generally speaking this is no-op
 	}
 
 	@Override
 	public void join() {
 		// generally speaking this is no-op
 	}
 
 	@Override
 	public void resetJoinStatus() {
 		// generally speaking this is no-op
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/RegisteredSynchronization.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/RegisteredSynchronization.java
index bfcced983b..e5e11f894e 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/RegisteredSynchronization.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/RegisteredSynchronization.java
@@ -1,62 +1,64 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.synchronization.internal;
 
 import javax.transaction.Synchronization;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
+
 import org.jboss.logging.Logger;
 
 /**
  * The JTA {@link javax.transaction.Synchronization} Hibernate registers when needed for JTA callbacks
  *
  * @author Steve Ebersole
  */
 public class RegisteredSynchronization implements Synchronization {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        RegisteredSynchronization.class.getName());
 
 	private final SynchronizationCallbackCoordinator synchronizationCallbackCoordinator;
 
 	public RegisteredSynchronization(SynchronizationCallbackCoordinator synchronizationCallbackCoordinator) {
 		this.synchronizationCallbackCoordinator = synchronizationCallbackCoordinator;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void beforeCompletion() {
         LOG.trace("JTA sync : beforeCompletion()");
 		synchronizationCallbackCoordinator.beforeCompletion();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void afterCompletion(int status) {
         LOG.tracef("JTA sync : afterCompletion(%s)", status);
 		synchronizationCallbackCoordinator.afterCompletion( status );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorImpl.java
index 0cb49f6635..b68610fce1 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorImpl.java
@@ -1,173 +1,175 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.synchronization.internal;
 
 import javax.transaction.SystemException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.TransactionException;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.synchronization.spi.AfterCompletionAction;
 import org.hibernate.engine.transaction.synchronization.spi.ExceptionMapper;
 import org.hibernate.engine.transaction.synchronization.spi.ManagedFlushChecker;
 import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
+
 import org.jboss.logging.Logger;
 
 /**
  * Manages callbacks from the {@link javax.transaction.Synchronization} registered by Hibernate.
  *
  * @author Steve Ebersole
  */
 public class SynchronizationCallbackCoordinatorImpl implements SynchronizationCallbackCoordinator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SynchronizationCallbackCoordinatorImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SynchronizationCallbackCoordinatorImpl.class.getName());
 
 	private final TransactionCoordinator transactionCoordinator;
 
 	private ManagedFlushChecker managedFlushChecker;
 	private AfterCompletionAction afterCompletionAction;
 	private ExceptionMapper exceptionMapper;
 
 	public SynchronizationCallbackCoordinatorImpl(TransactionCoordinator transactionCoordinator) {
 		this.transactionCoordinator = transactionCoordinator;
 		reset();
 	}
 
 	public void reset() {
 		managedFlushChecker = STANDARD_MANAGED_FLUSH_CHECKER;
 		exceptionMapper = STANDARD_EXCEPTION_MAPPER;
 		afterCompletionAction = STANDARD_AFTER_COMPLETION_ACTION;
 	}
 
 	@Override
 	public void setManagedFlushChecker(ManagedFlushChecker managedFlushChecker) {
 		this.managedFlushChecker = managedFlushChecker;
 	}
 
 	@Override
 	public void setExceptionMapper(ExceptionMapper exceptionMapper) {
 		this.exceptionMapper = exceptionMapper;
 	}
 
 	@Override
 	public void setAfterCompletionAction(AfterCompletionAction afterCompletionAction) {
 		this.afterCompletionAction = afterCompletionAction;
 	}
 
 
 	// sync callbacks ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void beforeCompletion() {
         LOG.trace("Transaction before completion callback");
 
 		boolean flush;
 		try {
 			final int status = transactionCoordinator
 					.getTransactionContext()
 					.getTransactionEnvironment()
 					.getJtaPlatform()
 					.getCurrentStatus();
 			flush = managedFlushChecker.shouldDoManagedFlush( transactionCoordinator, status );
 		}
 		catch ( SystemException se ) {
 			setRollbackOnly();
 			throw exceptionMapper.mapStatusCheckFailure( "could not determine transaction status in beforeCompletion()", se );
 		}
 
 		try {
 			if ( flush ) {
                 LOG.trace("Automatically flushing session");
 				transactionCoordinator.getTransactionContext().managedFlush();
 			}
 		}
 		catch ( RuntimeException re ) {
 			setRollbackOnly();
 			throw exceptionMapper.mapManagedFlushFailure( "error during managed flush", re );
 		}
 		finally {
 			transactionCoordinator.sendBeforeTransactionCompletionNotifications( null );
 			transactionCoordinator.getTransactionContext().beforeTransactionCompletion( null );
 		}
 	}
 
 	private void setRollbackOnly() {
 		transactionCoordinator.setRollbackOnly();
 	}
 
 	public void afterCompletion(int status) {
         LOG.trace("Transaction after completion callback [status=" + status + "]");
 
 		if ( transactionContext().isClosed() ) {
 			// usually this happens during failed tests
 			LOG.debug( "Transaction context was closed prior to synchronization callback" );
 			return;
 		}
 
 		try {
 			afterCompletionAction.doAction( transactionCoordinator, status );
 			transactionCoordinator.afterTransaction( null, status );
 		}
 		finally {
 			reset();
             if (transactionContext().shouldAutoClose() && !transactionContext().isClosed()) {
                 LOG.trace("Automatically closing session");
 				transactionContext().managedClose();
 			}
 		}
 	}
 
 	private TransactionContext transactionContext() {
 		return transactionCoordinator.getTransactionContext();
 	}
 
 	private static final ManagedFlushChecker STANDARD_MANAGED_FLUSH_CHECKER = new ManagedFlushChecker() {
 		@Override
 		public boolean shouldDoManagedFlush(TransactionCoordinator coordinator, int jtaStatus) {
 			return ! coordinator.getTransactionContext().isClosed() &&
 					! coordinator.getTransactionContext().isFlushModeNever() &&
 					coordinator.getTransactionContext().isFlushBeforeCompletionEnabled() &&
 					! JtaStatusHelper.isRollback( jtaStatus );
 		}
 	};
 
 	private static final ExceptionMapper STANDARD_EXCEPTION_MAPPER = new ExceptionMapper() {
 		public RuntimeException mapStatusCheckFailure(String message, SystemException systemException) {
             LOG.error(LOG.unableToDetermineTransactionStatus(), systemException);
 			return new TransactionException( "could not determine transaction status in beforeCompletion()", systemException );
 		}
 
 		public RuntimeException mapManagedFlushFailure(String message, RuntimeException failure) {
             LOG.unableToPerformManagedFlush(failure.getMessage());
 			return failure;
 		}
 	};
 
 	private static final AfterCompletionAction STANDARD_AFTER_COMPLETION_ACTION = new AfterCompletionAction() {
 		@Override
 		public void doAction(TransactionCoordinator transactionCoordinator, int status) {
 			// nothing to do by default.
 		}
 	};
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractFlushingEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractFlushingEventListener.java
index 291705cfe9..272aba4a38 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractFlushingEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractFlushingEventListener.java
@@ -1,387 +1,387 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.action.internal.CollectionRecreateAction;
 import org.hibernate.action.internal.CollectionRemoveAction;
 import org.hibernate.action.internal.CollectionUpdateAction;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.ActionQueue;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.CollectionEntry;
 import org.hibernate.engine.CollectionKey;
 import org.hibernate.engine.Collections;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.EventType;
 import org.hibernate.event.FlushEntityEvent;
 import org.hibernate.event.FlushEntityEventListener;
 import org.hibernate.event.FlushEvent;
 import org.hibernate.internal.util.collections.IdentityMap;
 import org.hibernate.internal.util.collections.LazyIterator;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.Printer;
 import org.hibernate.service.event.spi.EventListenerGroup;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 
 /**
  * A convenience base class for listeners whose functionality results in flushing.
  *
  * @author Steve Eberole
  */
 public abstract class AbstractFlushingEventListener implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(
-			HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(
+			CoreMessageLogger.class,
 			AbstractFlushingEventListener.class.getName()
 	);
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Pre-flushing section
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Coordinates the processing necessary to get things ready for executions
 	 * as db calls by preping the session caches and moving the appropriate
 	 * entities and collections to their respective execution queues.
 	 *
 	 * @param event The flush event.
 	 * @throws HibernateException Error flushing caches to execution queues.
 	 */
 	protected void flushEverythingToExecutions(FlushEvent event) throws HibernateException {
 
         LOG.trace("Flushing session");
 
 		EventSource session = event.getSession();
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		session.getInterceptor().preFlush( new LazyIterator( persistenceContext.getEntitiesByKey() ) );
 
 		prepareEntityFlushes(session);
 		// we could move this inside if we wanted to
 		// tolerate collection initializations during
 		// collection dirty checking:
 		prepareCollectionFlushes(session);
 		// now, any collections that are initialized
 		// inside this block do not get updated - they
 		// are ignored until the next flush
 
 		persistenceContext.setFlushing(true);
 		try {
 			flushEntities(event);
 			flushCollections(session);
 		}
 		finally {
 			persistenceContext.setFlushing(false);
 		}
 
 		//some statistics
         if (LOG.isDebugEnabled()) {
             LOG.debugf(
 					"Flushed: %s insertions, %s updates, %s deletions to %s objects",
 					session.getActionQueue().numberOfInsertions(),
 					session.getActionQueue().numberOfUpdates(),
 					session.getActionQueue().numberOfDeletions(),
 					persistenceContext.getEntityEntries().size()
 			);
             LOG.debugf(
 					"Flushed: %s (re)creations, %s updates, %s removals to %s collections",
 					session.getActionQueue().numberOfCollectionCreations(),
 					session.getActionQueue().numberOfCollectionUpdates(),
 					session.getActionQueue().numberOfCollectionRemovals(),
 					persistenceContext.getCollectionEntries().size()
 			);
 			new Printer( session.getFactory() ).toString(
 					persistenceContext.getEntitiesByKey().values().iterator(),
 					session.getEntityMode()
 				);
 		}
 	}
 
 	/**
 	 * process cascade save/update at the start of a flush to discover
 	 * any newly referenced entity that must be passed to saveOrUpdate(),
 	 * and also apply orphan delete
 	 */
 	private void prepareEntityFlushes(EventSource session) throws HibernateException {
 
         LOG.debugf( "Processing flush-time cascades" );
 
 		final Map.Entry[] list = IdentityMap.concurrentEntries( session.getPersistenceContext().getEntityEntries() );
 		//safe from concurrent modification because of how entryList() is implemented on IdentityMap
 		final int size = list.length;
 		final Object anything = getAnything();
 		for ( int i=0; i<size; i++ ) {
 			Map.Entry me = list[i];
 			EntityEntry entry = (EntityEntry) me.getValue();
 			Status status = entry.getStatus();
 			if ( status == Status.MANAGED || status == Status.SAVING || status == Status.READ_ONLY ) {
 				cascadeOnFlush( session, entry.getPersister(), me.getKey(), anything );
 			}
 		}
 	}
 
 	private void cascadeOnFlush(EventSource session, EntityPersister persister, Object object, Object anything)
 	throws HibernateException {
 		session.getPersistenceContext().incrementCascadeLevel();
 		try {
 			new Cascade( getCascadingAction(), Cascade.BEFORE_FLUSH, session )
 			.cascade( persister, object, anything );
 		}
 		finally {
 			session.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 	protected Object getAnything() { return null; }
 
 	protected CascadingAction getCascadingAction() {
 		return CascadingAction.SAVE_UPDATE;
 	}
 
 	/**
 	 * Initialize the flags of the CollectionEntry, including the
 	 * dirty check.
 	 */
 	private void prepareCollectionFlushes(SessionImplementor session) throws HibernateException {
 
 		// Initialize dirty flags for arrays + collections with composite elements
 		// and reset reached, doupdate, etc.
 
         LOG.debugf( "Dirty checking collections" );
 
 		final List list = IdentityMap.entries( session.getPersistenceContext().getCollectionEntries() );
 		final int size = list.size();
 		for ( int i = 0; i < size; i++ ) {
 			Map.Entry e = ( Map.Entry ) list.get( i );
 			( (CollectionEntry) e.getValue() ).preFlush( (PersistentCollection) e.getKey() );
 		}
 	}
 
 	/**
 	 * 1. detect any dirty entities
 	 * 2. schedule any entity updates
 	 * 3. search out any reachable collections
 	 */
 	private void flushEntities(FlushEvent event) throws HibernateException {
 
         LOG.trace("Flushing entities and processing referenced collections");
 
 		// Among other things, updateReachables() will recursively load all
 		// collections that are moving roles. This might cause entities to
 		// be loaded.
 
 		// So this needs to be safe from concurrent modification problems.
 		// It is safe because of how IdentityMap implements entrySet()
 
 		final EventSource source = event.getSession();
 
 		final Map.Entry[] list = IdentityMap.concurrentEntries( source.getPersistenceContext().getEntityEntries() );
 		final int size = list.length;
 		for ( int i = 0; i < size; i++ ) {
 
 			// Update the status of the object and if necessary, schedule an update
 
 			Map.Entry me = list[i];
 			EntityEntry entry = (EntityEntry) me.getValue();
 			Status status = entry.getStatus();
 
 			if ( status != Status.LOADING && status != Status.GONE ) {
 				final FlushEntityEvent entityEvent = new FlushEntityEvent( source, me.getKey(), entry );
 				final EventListenerGroup<FlushEntityEventListener> listenerGroup = source
 						.getFactory()
 						.getServiceRegistry()
 						.getService( EventListenerRegistry.class )
 						.getEventListenerGroup( EventType.FLUSH_ENTITY );
 				for ( FlushEntityEventListener listener : listenerGroup.listeners() ) {
 					listener.onFlushEntity( entityEvent );
 				}
 			}
 		}
 
 		source.getActionQueue().sortActions();
 	}
 
 	/**
 	 * process any unreferenced collections and then inspect all known collections,
 	 * scheduling creates/removes/updates
 	 */
 	private void flushCollections(EventSource session) throws HibernateException {
 
         LOG.trace("Processing unreferenced collections");
 
 		List list = IdentityMap.entries( session.getPersistenceContext().getCollectionEntries() );
 		int size = list.size();
 		for ( int i = 0; i < size; i++ ) {
 			Map.Entry me = ( Map.Entry ) list.get( i );
 			CollectionEntry ce = (CollectionEntry) me.getValue();
 			if ( !ce.isReached() && !ce.isIgnore() ) {
 				Collections.processUnreachableCollection( (PersistentCollection) me.getKey(), session );
 			}
 		}
 
 		// Schedule updates to collections:
 
         LOG.trace("Scheduling collection removes/(re)creates/updates");
 
 		list = IdentityMap.entries( session.getPersistenceContext().getCollectionEntries() );
 		size = list.size();
 		ActionQueue actionQueue = session.getActionQueue();
 		for ( int i = 0; i < size; i++ ) {
 			Map.Entry me = (Map.Entry) list.get(i);
 			PersistentCollection coll = (PersistentCollection) me.getKey();
 			CollectionEntry ce = (CollectionEntry) me.getValue();
 
 			if ( ce.isDorecreate() ) {
 				session.getInterceptor().onCollectionRecreate( coll, ce.getCurrentKey() );
 				actionQueue.addAction(
 						new CollectionRecreateAction(
 								coll,
 								ce.getCurrentPersister(),
 								ce.getCurrentKey(),
 								session
 							)
 					);
 			}
 			if ( ce.isDoremove() ) {
 				session.getInterceptor().onCollectionRemove( coll, ce.getLoadedKey() );
 				actionQueue.addAction(
 						new CollectionRemoveAction(
 								coll,
 								ce.getLoadedPersister(),
 								ce.getLoadedKey(),
 								ce.isSnapshotEmpty(coll),
 								session
 							)
 					);
 			}
 			if ( ce.isDoupdate() ) {
 				session.getInterceptor().onCollectionUpdate( coll, ce.getLoadedKey() );
 				actionQueue.addAction(
 						new CollectionUpdateAction(
 								coll,
 								ce.getLoadedPersister(),
 								ce.getLoadedKey(),
 								ce.isSnapshotEmpty(coll),
 								session
 							)
 					);
 			}
 
 		}
 
 		actionQueue.sortCollectionActions();
 
 	}
 
 	/**
 	 * Execute all SQL and second-level cache updates, in a
 	 * special order so that foreign-key constraints cannot
 	 * be violated:
 	 * <ol>
 	 * <li> Inserts, in the order they were performed
 	 * <li> Updates
 	 * <li> Deletion of collection elements
 	 * <li> Insertion of collection elements
 	 * <li> Deletes, in the order they were performed
 	 * </ol>
 	 */
 	protected void performExecutions(EventSource session) throws HibernateException {
 
         LOG.trace("Executing flush");
 
 		try {
 			session.getTransactionCoordinator().getJdbcCoordinator().flushBeginning();
 			// we need to lock the collection caches before
 			// executing entity inserts/updates in order to
 			// account for bidi associations
 			session.getActionQueue().prepareActions();
 			session.getActionQueue().executeActions();
 		}
 		finally {
 			session.getTransactionCoordinator().getJdbcCoordinator().flushEnding();
 		}
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Post-flushing section
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * 1. Recreate the collection key -> collection map
 	 * 2. rebuild the collection entries
 	 * 3. call Interceptor.postFlush()
 	 */
 	protected void postFlush(SessionImplementor session) throws HibernateException {
 
         LOG.trace("Post flush");
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		persistenceContext.getCollectionsByKey().clear();
 		persistenceContext.getBatchFetchQueue()
 				.clearSubselects(); //the database has changed now, so the subselect results need to be invalidated
 
 		Iterator iter = persistenceContext.getCollectionEntries().entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = (Map.Entry) iter.next();
 			CollectionEntry collectionEntry = (CollectionEntry) me.getValue();
 			PersistentCollection persistentCollection = (PersistentCollection) me.getKey();
 			collectionEntry.postFlush(persistentCollection);
 			if ( collectionEntry.getLoadedPersister() == null ) {
 				//if the collection is dereferenced, remove from the session cache
 				//iter.remove(); //does not work, since the entrySet is not backed by the set
 				persistenceContext.getCollectionEntries()
 						.remove(persistentCollection);
 			}
 			else {
 				//otherwise recreate the mapping between the collection and its key
 				CollectionKey collectionKey = new CollectionKey(
 						collectionEntry.getLoadedPersister(),
 						collectionEntry.getLoadedKey(),
 						session.getEntityMode()
 					);
 				persistenceContext.getCollectionsByKey()
 						.put(collectionKey, persistentCollection);
 			}
 		}
 
 		session.getInterceptor().postFlush( new LazyIterator( persistenceContext.getEntitiesByKey() ) );
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractLockUpgradeEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractLockUpgradeEventListener.java
index eff80880f3..9c9d82b90a 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractLockUpgradeEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractLockUpgradeEventListener.java
@@ -1,114 +1,114 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.access.SoftLock;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.Status;
 import org.hibernate.event.EventSource;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * A convenience base class for listeners that respond to requests to perform a
  * pessimistic lock upgrade on an entity.
  *
  * @author Gavin King
  */
 public class AbstractLockUpgradeEventListener extends AbstractReassociateEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractLockUpgradeEventListener.class.getName());
 
 	/**
 	 * Performs a pessimistic lock upgrade on a given entity, if needed.
 	 *
 	 * @param object The entity for which to upgrade the lock.
 	 * @param entry The entity's EntityEntry instance.
 	 * @param lockOptions contains the requested lock mode.
 	 * @param source The session which is the source of the event being processed.
 	 */
 	protected void upgradeLock(Object object, EntityEntry entry, LockOptions lockOptions, EventSource source) {
 
 		LockMode requestedLockMode = lockOptions.getLockMode();
 		if ( requestedLockMode.greaterThan( entry.getLockMode() ) ) {
 			// The user requested a "greater" (i.e. more restrictive) form of
 			// pessimistic lock
 
 			if ( entry.getStatus() != Status.MANAGED ) {
 				throw new ObjectDeletedException(
 						"attempted to lock a deleted instance",
 						entry.getId(),
 						entry.getPersister().getEntityName()
 				);
 			}
 
 			final EntityPersister persister = entry.getPersister();
 
             if (LOG.isTraceEnabled()) LOG.trace("Locking "
                                                 + MessageHelper.infoString(persister, entry.getId(), source.getFactory())
                                                 + " in mode: " + requestedLockMode);
 
 			final SoftLock lock;
 			final CacheKey ck;
 			if ( persister.hasCache() ) {
 				ck = source.generateCacheKey( entry.getId(), persister.getIdentifierType(), persister.getRootEntityName() );
 				lock = persister.getCacheAccessStrategy().lockItem( ck, entry.getVersion() );
 			}
 			else {
 				ck = null;
 				lock = null;
 			}
 
 			try {
 				if ( persister.isVersioned() && requestedLockMode == LockMode.FORCE  ) {
 					// todo : should we check the current isolation mode explicitly?
 					Object nextVersion = persister.forceVersionIncrement(
 							entry.getId(), entry.getVersion(), source
 					);
 					entry.forceLocked( object, nextVersion );
 				}
 				else {
 					persister.lock( entry.getId(), entry.getVersion(), object, lockOptions, source );
 				}
 				entry.setLockMode(requestedLockMode);
 			}
 			finally {
 				// the database now holds a lock + the object is flushed from the cache,
 				// so release the soft lock
 				if ( persister.hasCache() ) {
 					persister.getCacheAccessStrategy().unlockItem( ck, lock );
 				}
 			}
 
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractReassociateEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractReassociateEventListener.java
index c166c62b25..3916a71245 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractReassociateEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractReassociateEventListener.java
@@ -1,105 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.Status;
 import org.hibernate.engine.Versioning;
 import org.hibernate.event.AbstractEvent;
 import org.hibernate.event.EventSource;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.TypeHelper;
 
 /**
  * A convenience base class for listeners that respond to requests to reassociate an entity
  * to a session ( such as through lock() or update() ).
  *
  * @author Gavin King
  */
 public class AbstractReassociateEventListener implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractReassociateEventListener.class.getName());
 
 	/**
 	 * Associates a given entity (either transient or associated with another session) to
 	 * the given session.
 	 *
 	 * @param event The event triggering the re-association
 	 * @param object The entity to be associated
 	 * @param id The id of the entity.
 	 * @param persister The entity's persister instance.
 	 *
 	 * @return An EntityEntry representing the entity within this session.
 	 */
 	protected final EntityEntry reassociate(AbstractEvent event, Object object, Serializable id, EntityPersister persister) {
 
         if (LOG.isTraceEnabled()) LOG.trace("Reassociating transient instance: "
                                             + MessageHelper.infoString(persister, id, event.getSession().getFactory()));
 
 		final EventSource source = event.getSession();
 		final EntityKey key = source.generateEntityKey( id, persister );
 
 		source.getPersistenceContext().checkUniqueness( key, object );
 
 		//get a snapshot
 		Object[] values = persister.getPropertyValues( object, source.getEntityMode() );
 		TypeHelper.deepCopy(
 				values,
 				persister.getPropertyTypes(),
 				persister.getPropertyUpdateability(),
 				values,
 				source
 		);
 		Object version = Versioning.getVersion( values, persister );
 
 		EntityEntry newEntry = source.getPersistenceContext().addEntity(
 				object,
 				( persister.isMutable() ? Status.MANAGED : Status.READ_ONLY ),
 				values,
 				key,
 				version,
 				LockMode.NONE,
 				true,
 				persister,
 				false,
 				true //will be ignored, using the existing Entry instead
 		);
 
 		new OnLockVisitor( source, id, object ).process( object, persister );
 
 		persister.afterReassociate( object, source );
 
 		return newEntry;
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractSaveEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractSaveEventListener.java
index 6d715fc3bd..7d6dc578b7 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractSaveEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractSaveEventListener.java
@@ -1,517 +1,517 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.NonUniqueObjectException;
 import org.hibernate.action.internal.EntityIdentityInsertAction;
 import org.hibernate.action.internal.EntityInsertAction;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.ForeignKeys;
 import org.hibernate.engine.Nullability;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.engine.Versioning;
 import org.hibernate.event.EventSource;
 import org.hibernate.id.IdentifierGenerationException;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 
 /**
  * A convenience bas class for listeners responding to save events.
  *
  * @author Steve Ebersole.
  */
 public abstract class AbstractSaveEventListener extends AbstractReassociateEventListener {
 
 	protected static final int PERSISTENT = 0;
 	protected static final int TRANSIENT = 1;
 	protected static final int DETACHED = 2;
 	protected static final int DELETED = 3;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractSaveEventListener.class.getName());
 
 	/**
 	 * Prepares the save call using the given requested id.
 	 *
 	 * @param entity The entity to be saved.
 	 * @param requestedId The id to which to associate the entity.
 	 * @param entityName The name of the entity being saved.
 	 * @param anything Generally cascade-specific information.
 	 * @param source The session which is the source of this save event.
 	 *
 	 * @return The id used to save the entity.
 	 */
 	protected Serializable saveWithRequestedId(
 			Object entity,
 			Serializable requestedId,
 			String entityName,
 			Object anything,
 			EventSource source) {
 		return performSave(
 				entity,
 				requestedId,
 				source.getEntityPersister( entityName, entity ),
 				false,
 				anything,
 				source,
 				true
 		);
 	}
 
 	/**
 	 * Prepares the save call using a newly generated id.
 	 *
 	 * @param entity The entity to be saved
 	 * @param entityName The entity-name for the entity to be saved
 	 * @param anything Generally cascade-specific information.
 	 * @param source The session which is the source of this save event.
 	 * @param requiresImmediateIdAccess does the event context require
 	 * access to the identifier immediately after execution of this method (if
 	 * not, post-insert style id generators may be postponed if we are outside
 	 * a transaction).
 	 *
 	 * @return The id used to save the entity; may be null depending on the
 	 *         type of id generator used and the requiresImmediateIdAccess value
 	 */
 	protected Serializable saveWithGeneratedId(
 			Object entity,
 			String entityName,
 			Object anything,
 			EventSource source,
 			boolean requiresImmediateIdAccess) {
 		EntityPersister persister = source.getEntityPersister( entityName, entity );
 		Serializable generatedId = persister.getIdentifierGenerator().generate( source, entity );
 		if ( generatedId == null ) {
 			throw new IdentifierGenerationException( "null id generated for:" + entity.getClass() );
 		}
 		else if ( generatedId == IdentifierGeneratorHelper.SHORT_CIRCUIT_INDICATOR ) {
 			return source.getIdentifier( entity );
 		}
 		else if ( generatedId == IdentifierGeneratorHelper.POST_INSERT_INDICATOR ) {
 			return performSave( entity, null, persister, true, anything, source, requiresImmediateIdAccess );
 		}
 		else {
             // TODO: define toString()s for generators
             if (LOG.isDebugEnabled()) LOG.debugf("Generated identifier: %s, using strategy: %s",
                                                  persister.getIdentifierType().toLoggableString(generatedId, source.getFactory()),
                                                  persister.getIdentifierGenerator().getClass().getName());
 
 			return performSave( entity, generatedId, persister, false, anything, source, true );
 		}
 	}
 
 	/**
 	 * Ppepares the save call by checking the session caches for a pre-existing
 	 * entity and performing any lifecycle callbacks.
 	 *
 	 * @param entity The entity to be saved.
 	 * @param id The id by which to save the entity.
 	 * @param persister The entity's persister instance.
 	 * @param useIdentityColumn Is an identity column being used?
 	 * @param anything Generally cascade-specific information.
 	 * @param source The session from which the event originated.
 	 * @param requiresImmediateIdAccess does the event context require
 	 * access to the identifier immediately after execution of this method (if
 	 * not, post-insert style id generators may be postponed if we are outside
 	 * a transaction).
 	 *
 	 * @return The id used to save the entity; may be null depending on the
 	 *         type of id generator used and the requiresImmediateIdAccess value
 	 */
 	protected Serializable performSave(
 			Object entity,
 			Serializable id,
 			EntityPersister persister,
 			boolean useIdentityColumn,
 			Object anything,
 			EventSource source,
 			boolean requiresImmediateIdAccess) {
 
         if ( LOG.isTraceEnabled() ) {
 			LOG.trace("Saving " + MessageHelper.infoString(persister, id, source.getFactory()));
 		}
 
 		final EntityKey key;
 		if ( !useIdentityColumn ) {
 			key = source.generateEntityKey( id, persister );
 			Object old = source.getPersistenceContext().getEntity( key );
 			if ( old != null ) {
 				if ( source.getPersistenceContext().getEntry( old ).getStatus() == Status.DELETED ) {
 					source.forceFlush( source.getPersistenceContext().getEntry( old ) );
 				}
 				else {
 					throw new NonUniqueObjectException( id, persister.getEntityName() );
 				}
 			}
 			persister.setIdentifier( entity, id, source );
 		}
 		else {
 			key = null;
 		}
 
 		if ( invokeSaveLifecycle( entity, persister, source ) ) {
 			return id; //EARLY EXIT
 		}
 
 		return performSaveOrReplicate(
 				entity,
 				key,
 				persister,
 				useIdentityColumn,
 				anything,
 				source,
 				requiresImmediateIdAccess
 		);
 	}
 
 	protected boolean invokeSaveLifecycle(Object entity, EntityPersister persister, EventSource source) {
 		// Sub-insertions should occur before containing insertion so
 		// Try to do the callback now
 		if ( persister.implementsLifecycle( source.getEntityMode() ) ) {
             LOG.debugf("Calling onSave()");
 			if ( ( ( Lifecycle ) entity ).onSave( source ) ) {
                 LOG.debugf("Insertion vetoed by onSave()");
 				return true;
 			}
 		}
 		return false;
 	}
 
 	/**
 	 * Performs all the actual work needed to save an entity (well to get the save moved to
 	 * the execution queue).
 	 *
 	 * @param entity The entity to be saved
 	 * @param key The id to be used for saving the entity (or null, in the case of identity columns)
 	 * @param persister The entity's persister instance.
 	 * @param useIdentityColumn Should an identity column be used for id generation?
 	 * @param anything Generally cascade-specific information.
 	 * @param source The session which is the source of the current event.
 	 * @param requiresImmediateIdAccess Is access to the identifier required immediately
 	 * after the completion of the save?  persist(), for example, does not require this...
 	 *
 	 * @return The id used to save the entity; may be null depending on the
 	 *         type of id generator used and the requiresImmediateIdAccess value
 	 */
 	protected Serializable performSaveOrReplicate(
 			Object entity,
 			EntityKey key,
 			EntityPersister persister,
 			boolean useIdentityColumn,
 			Object anything,
 			EventSource source,
 			boolean requiresImmediateIdAccess) {
 
 		Serializable id = key == null ? null : key.getIdentifier();
 
 		boolean inTxn = source.getTransactionCoordinator().isTransactionInProgress();
 		boolean shouldDelayIdentityInserts = !inTxn && !requiresImmediateIdAccess;
 
 		// Put a placeholder in entries, so we don't recurse back and try to save() the
 		// same object again. QUESTION: should this be done before onSave() is called?
 		// likewise, should it be done before onUpdate()?
 		source.getPersistenceContext().addEntry(
 				entity,
 				Status.SAVING,
 				null,
 				null,
 				id,
 				null,
 				LockMode.WRITE,
 				useIdentityColumn,
 				persister,
 				false,
 				false
 		);
 
 		cascadeBeforeSave( source, persister, entity, anything );
 
 		if ( useIdentityColumn && !shouldDelayIdentityInserts ) {
             LOG.trace("Executing insertions");
 			source.getActionQueue().executeInserts();
 		}
 
 		Object[] values = persister.getPropertyValuesToInsert( entity, getMergeMap( anything ), source );
 		Type[] types = persister.getPropertyTypes();
 
 		boolean substitute = substituteValuesIfNecessary( entity, id, values, persister, source );
 
 		if ( persister.hasCollections() ) {
 			substitute = substitute || visitCollectionsBeforeSave( entity, id, values, types, source );
 		}
 
 		if ( substitute ) {
 			persister.setPropertyValues( entity, values, source.getEntityMode() );
 		}
 
 		TypeHelper.deepCopy(
 				values,
 				types,
 				persister.getPropertyUpdateability(),
 				values,
 				source
 		);
 
 		new ForeignKeys.Nullifier( entity, false, useIdentityColumn, source )
 				.nullifyTransientReferences( values, types );
 		new Nullability( source ).checkNullability( values, persister, false );
 
 		if ( useIdentityColumn ) {
 			EntityIdentityInsertAction insert = new EntityIdentityInsertAction(
 					values, entity, persister, source, shouldDelayIdentityInserts
 			);
 			if ( !shouldDelayIdentityInserts ) {
                 LOG.debugf("Executing identity-insert immediately");
 				source.getActionQueue().execute( insert );
 				id = insert.getGeneratedId();
 				key = source.generateEntityKey( id, persister );
 				source.getPersistenceContext().checkUniqueness( key, entity );
 			}
 			else {
                 LOG.debugf("Delaying identity-insert due to no transaction in progress");
 				source.getActionQueue().addAction( insert );
 				key = insert.getDelayedEntityKey();
 			}
 		}
 
 		Object version = Versioning.getVersion( values, persister );
 		source.getPersistenceContext().addEntity(
 				entity,
 				( persister.isMutable() ? Status.MANAGED : Status.READ_ONLY ),
 				values,
 				key,
 				version,
 				LockMode.WRITE,
 				useIdentityColumn,
 				persister,
 				isVersionIncrementDisabled(),
 				false
 		);
 		//source.getPersistenceContext().removeNonExist( new EntityKey( id, persister, source.getEntityMode() ) );
 
 		if ( !useIdentityColumn ) {
 			source.getActionQueue().addAction(
 					new EntityInsertAction( id, values, entity, version, persister, source )
 			);
 		}
 
 		cascadeAfterSave( source, persister, entity, anything );
 
 		markInterceptorDirty( entity, persister, source );
 
 		return id;
 	}
 
 	private void markInterceptorDirty(Object entity, EntityPersister persister, EventSource source) {
 		if ( FieldInterceptionHelper.isInstrumented( entity ) ) {
 			FieldInterceptor interceptor = FieldInterceptionHelper.injectFieldInterceptor(
 					entity,
 					persister.getEntityName(),
 					null,
 					source
 			);
 			interceptor.dirty();
 		}
 	}
 
 	protected Map getMergeMap(Object anything) {
 		return null;
 	}
 
 	/**
 	 * After the save, will te version number be incremented
 	 * if the instance is modified?
 	 *
 	 * @return True if the version will be incremented on an entity change after save;
 	 *         false otherwise.
 	 */
 	protected boolean isVersionIncrementDisabled() {
 		return false;
 	}
 
 	protected boolean visitCollectionsBeforeSave(Object entity, Serializable id, Object[] values, Type[] types, EventSource source) {
 		WrapVisitor visitor = new WrapVisitor( source );
 		// substitutes into values by side-effect
 		visitor.processEntityPropertyValues( values, types );
 		return visitor.isSubstitutionRequired();
 	}
 
 	/**
 	 * Perform any property value substitution that is necessary
 	 * (interceptor callback, version initialization...)
 	 *
 	 * @param entity The entity
 	 * @param id The entity identifier
 	 * @param values The snapshot entity state
 	 * @param persister The entity persister
 	 * @param source The originating session
 	 *
 	 * @return True if the snapshot state changed such that
 	 * reinjection of the values into the entity is required.
 	 */
 	protected boolean substituteValuesIfNecessary(
 			Object entity,
 			Serializable id,
 			Object[] values,
 			EntityPersister persister,
 			SessionImplementor source) {
 		boolean substitute = source.getInterceptor().onSave(
 				entity,
 				id,
 				values,
 				persister.getPropertyNames(),
 				persister.getPropertyTypes()
 		);
 
 		//keep the existing version number in the case of replicate!
 		if ( persister.isVersioned() ) {
 			substitute = Versioning.seedVersion(
 					values,
 					persister.getVersionProperty(),
 					persister.getVersionType(),
 					source
 			) || substitute;
 		}
 		return substitute;
 	}
 
 	/**
 	 * Handles the calls needed to perform pre-save cascades for the given entity.
 	 *
 	 * @param source The session from whcih the save event originated.
 	 * @param persister The entity's persister instance.
 	 * @param entity The entity to be saved.
 	 * @param anything Generally cascade-specific data
 	 */
 	protected void cascadeBeforeSave(
 			EventSource source,
 			EntityPersister persister,
 			Object entity,
 			Object anything) {
 
 		// cascade-save to many-to-one BEFORE the parent is saved
 		source.getPersistenceContext().incrementCascadeLevel();
 		try {
 			new Cascade( getCascadeAction(), Cascade.BEFORE_INSERT_AFTER_DELETE, source )
 					.cascade( persister, entity, anything );
 		}
 		finally {
 			source.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 	/**
 	 * Handles to calls needed to perform post-save cascades.
 	 *
 	 * @param source The session from which the event originated.
 	 * @param persister The entity's persister instance.
 	 * @param entity The entity beng saved.
 	 * @param anything Generally cascade-specific data
 	 */
 	protected void cascadeAfterSave(
 			EventSource source,
 			EntityPersister persister,
 			Object entity,
 			Object anything) {
 
 		// cascade-save to collections AFTER the collection owner was saved
 		source.getPersistenceContext().incrementCascadeLevel();
 		try {
 			new Cascade( getCascadeAction(), Cascade.AFTER_INSERT_BEFORE_DELETE, source )
 					.cascade( persister, entity, anything );
 		}
 		finally {
 			source.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 	protected abstract CascadingAction getCascadeAction();
 
 	/**
 	 * Determine whether the entity is persistent, detached, or transient
 	 *
 	 * @param entity The entity to check
 	 * @param entityName The name of the entity
 	 * @param entry The entity's entry in the persistence context
 	 * @param source The originating session.
 	 *
 	 * @return The state.
 	 */
 	protected int getEntityState(
 			Object entity,
 			String entityName,
 			EntityEntry entry, //pass this as an argument only to avoid double looking
 			SessionImplementor source) {
 
 		if ( entry != null ) { // the object is persistent
 
 			//the entity is associated with the session, so check its status
 			if ( entry.getStatus() != Status.DELETED ) {
 				// do nothing for persistent instances
                 if (LOG.isTraceEnabled()) LOG.trace("Persistent instance of: " + getLoggableName(entityName, entity));
 				return PERSISTENT;
 			}
             // ie. e.status==DELETED
             if (LOG.isTraceEnabled()) LOG.trace("Deleted instance of: " + getLoggableName(entityName, entity));
             return DELETED;
 
 		}
         // the object is transient or detached
 
 		// the entity is not associated with the session, so
         // try interceptor and unsaved-value
 
 		if (ForeignKeys.isTransient(entityName, entity, getAssumedUnsaved(), source)) {
             if (LOG.isTraceEnabled()) LOG.trace("Transient instance of: " + getLoggableName(entityName, entity));
             return TRANSIENT;
 		}
         if (LOG.isTraceEnabled()) LOG.trace("Detached instance of: " + getLoggableName(entityName, entity));
         return DETACHED;
 	}
 
 	protected String getLoggableName(String entityName, Object entity) {
 		return entityName == null ? entity.getClass().getName() : entityName;
 	}
 
 	protected Boolean getAssumedUnsaved() {
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultAutoFlushEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultAutoFlushEventListener.java
index a09dee0b84..358a595f9a 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultAutoFlushEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultAutoFlushEventListener.java
@@ -1,86 +1,87 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.event.def;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.event.AutoFlushEvent;
 import org.hibernate.event.AutoFlushEventListener;
 import org.hibernate.event.EventSource;
+
 import org.jboss.logging.Logger;
 
 /**
  * Defines the default flush event listeners used by hibernate for
  * flushing session state in response to generated auto-flush events.
  *
  * @author Steve Ebersole
  */
 public class DefaultAutoFlushEventListener extends AbstractFlushingEventListener implements AutoFlushEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultAutoFlushEventListener.class.getName());
 
     /** Handle the given auto-flush event.
      *
      * @param event The auto-flush event to be handled.
      * @throws HibernateException
      */
 	public void onAutoFlush(AutoFlushEvent event) throws HibernateException {
 		final EventSource source = event.getSession();
 		if ( flushMightBeNeeded(source) ) {
 			final int oldSize = source.getActionQueue().numberOfCollectionRemovals();
 			flushEverythingToExecutions(event);
 			if ( flushIsReallyNeeded(event, source) ) {
                 LOG.trace("Need to execute flush");
 
 				performExecutions(source);
 				postFlush(source);
 				// note: performExecutions() clears all collectionXxxxtion
 				// collections (the collection actions) in the session
 
                 if (source.getFactory().getStatistics().isStatisticsEnabled()) source.getFactory().getStatisticsImplementor().flush();
 			}
 			else {
                 LOG.trace("Don't need to execute flush");
 				source.getActionQueue().clearFromFlushNeededCheck( oldSize );
 			}
 
 			event.setFlushRequired( flushIsReallyNeeded( event, source ) );
 		}
 	}
 
 	private boolean flushIsReallyNeeded(AutoFlushEvent event, final EventSource source) {
 		return source.getActionQueue()
 				.areTablesToBeUpdated( event.getQuerySpaces() ) ||
 						source.getFlushMode()==FlushMode.ALWAYS;
 	}
 
 	private boolean flushMightBeNeeded(final EventSource source) {
 		return !source.getFlushMode().lessThan(FlushMode.AUTO) &&
 				source.getDontFlushFromFind() == 0 &&
 				( source.getPersistenceContext().getEntityEntries().size() > 0 ||
 						source.getPersistenceContext().getCollectionEntries().size() > 0 );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultDeleteEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultDeleteEventListener.java
index e324207bad..f127fab2ae 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultDeleteEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultDeleteEventListener.java
@@ -1,351 +1,351 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.CacheMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.TransientObjectException;
 import org.hibernate.action.internal.EntityDeleteAction;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.ForeignKeys;
 import org.hibernate.engine.Nullability;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.Status;
 import org.hibernate.event.DeleteEvent;
 import org.hibernate.event.DeleteEventListener;
 import org.hibernate.event.EventSource;
 import org.hibernate.internal.util.collections.IdentitySet;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 
 /**
  * Defines the default delete event listener used by hibernate for deleting entities
  * from the datastore in response to generated delete events.
  *
  * @author Steve Ebersole
  */
 public class DefaultDeleteEventListener implements DeleteEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultDeleteEventListener.class.getName());
 
 	/**
 	 * Handle the given delete event.
 	 *
 	 * @param event The delete event to be handled.
 	 *
 	 * @throws HibernateException
 	 */
 	public void onDelete(DeleteEvent event) throws HibernateException {
 		onDelete( event, new IdentitySet() );
 	}
 
 	/**
 	 * Handle the given delete event.  This is the cascaded form.
 	 *
 	 * @param event The delete event.
 	 * @param transientEntities The cache of entities already deleted
 	 *
 	 * @throws HibernateException
 	 */
 	public void onDelete(DeleteEvent event, Set transientEntities) throws HibernateException {
 
 		final EventSource source = event.getSession();
 
 		final PersistenceContext persistenceContext = source.getPersistenceContext();
 		Object entity = persistenceContext.unproxyAndReassociate( event.getObject() );
 
 		EntityEntry entityEntry = persistenceContext.getEntry( entity );
 		final EntityPersister persister;
 		final Serializable id;
 		final Object version;
 
 		if ( entityEntry == null ) {
             LOG.trace("Entity was not persistent in delete processing");
 
 			persister = source.getEntityPersister( event.getEntityName(), entity );
 
 			if ( ForeignKeys.isTransient( persister.getEntityName(), entity, null, source ) ) {
 				deleteTransientEntity( source, entity, event.isCascadeDeleteEnabled(), persister, transientEntities );
 				// EARLY EXIT!!!
 				return;
 			}
             performDetachedEntityDeletionCheck(event);
 
 			id = persister.getIdentifier( entity, source );
 
 			if ( id == null ) {
 				throw new TransientObjectException(
 						"the detached instance passed to delete() had a null identifier"
 				);
 			}
 
 			final EntityKey key = source.generateEntityKey( id, persister );
 
 			persistenceContext.checkUniqueness( key, entity );
 
 			new OnUpdateVisitor( source, id, entity ).process( entity, persister );
 
 			version = persister.getVersion( entity, source.getEntityMode() );
 
 			entityEntry = persistenceContext.addEntity(
 					entity,
 					( persister.isMutable() ? Status.MANAGED : Status.READ_ONLY ),
 					persister.getPropertyValues( entity, source.getEntityMode() ),
 					key,
 					version,
 					LockMode.NONE,
 					true,
 					persister,
 					false,
 					false
 			);
 		}
 		else {
             LOG.trace("Deleting a persistent instance");
 
 			if ( entityEntry.getStatus() == Status.DELETED || entityEntry.getStatus() == Status.GONE ) {
                 LOG.trace("Object was already deleted");
 				return;
 			}
 			persister = entityEntry.getPersister();
 			id = entityEntry.getId();
 			version = entityEntry.getVersion();
 		}
 
 		/*if ( !persister.isMutable() ) {
 			throw new HibernateException(
 					"attempted to delete an object of immutable class: " +
 					MessageHelper.infoString(persister)
 				);
 		}*/
 
 		if ( invokeDeleteLifecycle( source, entity, persister ) ) {
 			return;
 		}
 
 		deleteEntity( source, entity, entityEntry, event.isCascadeDeleteEnabled(), persister, transientEntities );
 
 		if ( source.getFactory().getSettings().isIdentifierRollbackEnabled() ) {
 			persister.resetIdentifier( entity, id, version, source );
 		}
 	}
 
 	/**
 	 * Called when we have recognized an attempt to delete a detached entity.
 	 * <p/>
 	 * This is perfectly valid in Hibernate usage; JPA, however, forbids this.
 	 * Thus, this is a hook for HEM to affect this behavior.
 	 *
 	 * @param event The event.
 	 */
 	protected void performDetachedEntityDeletionCheck(DeleteEvent event) {
 		// ok in normal Hibernate usage to delete a detached entity; JPA however
 		// forbids it, thus this is a hook for HEM to affect this behavior
 	}
 
 	/**
 	 * We encountered a delete request on a transient instance.
 	 * <p/>
 	 * This is a deviation from historical Hibernate (pre-3.2) behavior to
 	 * align with the JPA spec, which states that transient entities can be
 	 * passed to remove operation in which case cascades still need to be
 	 * performed.
 	 *
 	 * @param session The session which is the source of the event
 	 * @param entity The entity being delete processed
 	 * @param cascadeDeleteEnabled Is cascading of deletes enabled
 	 * @param persister The entity persister
 	 * @param transientEntities A cache of already visited transient entities
 	 * (to avoid infinite recursion).
 	 */
 	protected void deleteTransientEntity(
 			EventSource session,
 			Object entity,
 			boolean cascadeDeleteEnabled,
 			EntityPersister persister,
 			Set transientEntities) {
         LOG.handlingTransientEntity();
 		if ( transientEntities.contains( entity ) ) {
             LOG.trace("Already handled transient entity; skipping");
 			return;
 		}
 		transientEntities.add( entity );
 		cascadeBeforeDelete( session, persister, entity, null, transientEntities );
 		cascadeAfterDelete( session, persister, entity, transientEntities );
 	}
 
 	/**
 	 * Perform the entity deletion.  Well, as with most operations, does not
 	 * really perform it; just schedules an action/execution with the
 	 * {@link org.hibernate.engine.ActionQueue} for execution during flush.
 	 *
 	 * @param session The originating session
 	 * @param entity The entity to delete
 	 * @param entityEntry The entity's entry in the {@link PersistenceContext}
 	 * @param isCascadeDeleteEnabled Is delete cascading enabled?
 	 * @param persister The entity persister.
 	 * @param transientEntities A cache of already deleted entities.
 	 */
 	protected final void deleteEntity(
 			final EventSource session,
 			final Object entity,
 			final EntityEntry entityEntry,
 			final boolean isCascadeDeleteEnabled,
 			final EntityPersister persister,
 			final Set transientEntities) {
 
         if (LOG.isTraceEnabled()) LOG.trace("Deleting "
                                             + MessageHelper.infoString(persister, entityEntry.getId(), session.getFactory()));
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		final Type[] propTypes = persister.getPropertyTypes();
 		final Object version = entityEntry.getVersion();
 
 		final Object[] currentState;
 		if ( entityEntry.getLoadedState() == null ) { //ie. the entity came in from update()
 			currentState = persister.getPropertyValues( entity, session.getEntityMode() );
 		}
 		else {
 			currentState = entityEntry.getLoadedState();
 		}
 
 		final Object[] deletedState = createDeletedState( persister, currentState, session );
 		entityEntry.setDeletedState( deletedState );
 
 		session.getInterceptor().onDelete(
 				entity,
 				entityEntry.getId(),
 				deletedState,
 				persister.getPropertyNames(),
 				propTypes
 		);
 
 		// before any callbacks, etc, so subdeletions see that this deletion happened first
 		persistenceContext.setEntryStatus( entityEntry, Status.DELETED );
 		final EntityKey key = session.generateEntityKey( entityEntry.getId(), persister );
 
 		cascadeBeforeDelete( session, persister, entity, entityEntry, transientEntities );
 
 		new ForeignKeys.Nullifier( entity, true, false, session )
 				.nullifyTransientReferences( entityEntry.getDeletedState(), propTypes );
 		new Nullability( session ).checkNullability( entityEntry.getDeletedState(), persister, true );
 		persistenceContext.getNullifiableEntityKeys().add( key );
 
 		// Ensures that containing deletions happen before sub-deletions
 		session.getActionQueue().addAction(
 				new EntityDeleteAction(
 						entityEntry.getId(),
 						deletedState,
 						version,
 						entity,
 						persister,
 						isCascadeDeleteEnabled,
 						session
 				)
 		);
 
 		cascadeAfterDelete( session, persister, entity, transientEntities );
 
 		// the entry will be removed after the flush, and will no longer
 		// override the stale snapshot
 		// This is now handled by removeEntity() in EntityDeleteAction
 		//persistenceContext.removeDatabaseSnapshot(key);
 	}
 
 	private Object[] createDeletedState(EntityPersister persister, Object[] currentState, EventSource session) {
 		Type[] propTypes = persister.getPropertyTypes();
 		final Object[] deletedState = new Object[propTypes.length];
 //		TypeFactory.deepCopy( currentState, propTypes, persister.getPropertyUpdateability(), deletedState, session );
 		boolean[] copyability = new boolean[propTypes.length];
 		java.util.Arrays.fill( copyability, true );
 		TypeHelper.deepCopy( currentState, propTypes, copyability, deletedState, session );
 		return deletedState;
 	}
 
 	protected boolean invokeDeleteLifecycle(EventSource session, Object entity, EntityPersister persister) {
 		if ( persister.implementsLifecycle( session.getEntityMode() ) ) {
             LOG.debugf("Calling onDelete()");
 			if ( ( ( Lifecycle ) entity ).onDelete( session ) ) {
                 LOG.debugf("Deletion vetoed by onDelete()");
 				return true;
 			}
 		}
 		return false;
 	}
 
 	protected void cascadeBeforeDelete(
 			EventSource session,
 			EntityPersister persister,
 			Object entity,
 			EntityEntry entityEntry,
 			Set transientEntities) throws HibernateException {
 
 		CacheMode cacheMode = session.getCacheMode();
 		session.setCacheMode( CacheMode.GET );
 		session.getPersistenceContext().incrementCascadeLevel();
 		try {
 			// cascade-delete to collections BEFORE the collection owner is deleted
 			new Cascade( CascadingAction.DELETE, Cascade.AFTER_INSERT_BEFORE_DELETE, session )
 					.cascade( persister, entity, transientEntities );
 		}
 		finally {
 			session.getPersistenceContext().decrementCascadeLevel();
 			session.setCacheMode( cacheMode );
 		}
 	}
 
 	protected void cascadeAfterDelete(
 			EventSource session,
 			EntityPersister persister,
 			Object entity,
 			Set transientEntities) throws HibernateException {
 
 		CacheMode cacheMode = session.getCacheMode();
 		session.setCacheMode( CacheMode.GET );
 		session.getPersistenceContext().incrementCascadeLevel();
 		try {
 			// cascade-delete to many-to-one AFTER the parent was deleted
 			new Cascade( CascadingAction.DELETE, Cascade.BEFORE_INSERT_AFTER_DELETE, session )
 					.cascade( persister, entity, transientEntities );
 		}
 		finally {
 			session.getPersistenceContext().decrementCascadeLevel();
 			session.setCacheMode( cacheMode );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultDirtyCheckEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultDirtyCheckEventListener.java
index af16d00232..2de4ffec8b 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultDirtyCheckEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultDirtyCheckEventListener.java
@@ -1,65 +1,66 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.event.def;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.event.DirtyCheckEvent;
 import org.hibernate.event.DirtyCheckEventListener;
+
 import org.jboss.logging.Logger;
 
 /**
  * Defines the default dirty-check event listener used by hibernate for
  * checking the session for dirtiness in response to generated dirty-check
  * events.
  *
  * @author Steve Ebersole
  */
 public class DefaultDirtyCheckEventListener extends AbstractFlushingEventListener implements DirtyCheckEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultDirtyCheckEventListener.class.getName());
 
     /** Handle the given dirty-check event.
      *
      * @param event The dirty-check event to be handled.
      * @throws HibernateException
      */
 	public void onDirtyCheck(DirtyCheckEvent event) throws HibernateException {
 
 		int oldSize = event.getSession().getActionQueue().numberOfCollectionRemovals();
 
 		try {
 			flushEverythingToExecutions(event);
 			boolean wasNeeded = event.getSession().getActionQueue().hasAnyQueuedActions();
             if (wasNeeded) LOG.debugf("Session dirty");
             else LOG.debugf("Session not dirty");
 			event.setDirty( wasNeeded );
 		}
 		finally {
 			event.getSession().getActionQueue().clearFromFlushNeededCheck( oldSize );
 		}
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultEvictEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultEvictEventListener.java
index db61e294ce..03f2835be4 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultEvictEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultEvictEventListener.java
@@ -1,119 +1,120 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.event.def;
 import java.io.Serializable;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.EvictEvent;
 import org.hibernate.event.EvictEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
+
 import org.jboss.logging.Logger;
 
 /**
  * Defines the default evict event listener used by hibernate for evicting entities
  * in response to generated flush events.  In particular, this implementation will
  * remove any hard references to the entity that are held by the infrastructure
  * (references held by application or other persistent instances are okay)
  *
  * @author Steve Ebersole
  */
 public class DefaultEvictEventListener implements EvictEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultEvictEventListener.class.getName());
 
 	/**
 	 * Handle the given evict event.
 	 *
 	 * @param event The evict event to be handled.
 	 * @throws HibernateException
 	 */
 	public void onEvict(EvictEvent event) throws HibernateException {
 		EventSource source = event.getSession();
 		final Object object = event.getObject();
 		final PersistenceContext persistenceContext = source.getPersistenceContext();
 
 		if ( object instanceof HibernateProxy ) {
 			LazyInitializer li = ( (HibernateProxy) object ).getHibernateLazyInitializer();
 			Serializable id = li.getIdentifier();
 			EntityPersister persister = source.getFactory().getEntityPersister( li.getEntityName() );
 			if ( id == null ) {
 				throw new IllegalArgumentException("null identifier");
 			}
 
 			final EntityKey key = source.generateEntityKey( id, persister );
 			persistenceContext.removeProxy( key );
 
 			if ( !li.isUninitialized() ) {
 				final Object entity = persistenceContext.removeEntity( key );
 				if ( entity != null ) {
 					EntityEntry e = event.getSession().getPersistenceContext().removeEntry( entity );
 					doEvict( entity, key, e.getPersister(), event.getSession() );
 				}
 			}
 			li.unsetSession();
 		}
 		else {
 			EntityEntry e = persistenceContext.removeEntry( object );
 			if ( e != null ) {
 				persistenceContext.removeEntity( e.getEntityKey() );
 				doEvict( object, e.getEntityKey(), e.getPersister(), source );
 			}
 		}
 	}
 
 	protected void doEvict(
 		final Object object,
 		final EntityKey key,
 		final EntityPersister persister,
 		final EventSource session)
 	throws HibernateException {
 
         if (LOG.isTraceEnabled()) LOG.trace("Evicting " + MessageHelper.infoString(persister));
 
 		// remove all collections for the entity from the session-level cache
 		if ( persister.hasCollections() ) {
 			new EvictVisitor( session ).process( object, persister );
 		}
 
 		// remove any snapshot, not really for memory management purposes, but
 		// rather because it might now be stale, and there is no longer any
 		// EntityEntry to take precedence
 		// This is now handled by removeEntity()
 		//session.getPersistenceContext().removeDatabaseSnapshot(key);
 
 		new Cascade( CascadingAction.EVICT, Cascade.AFTER_EVICT, session )
 				.cascade( persister, object );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultFlushEntityEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultFlushEntityEventListener.java
index 3c78156aeb..b2b0342738 100755
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultFlushEntityEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultFlushEntityEventListener.java
@@ -1,564 +1,564 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.action.internal.DelayedPostInsertIdentifier;
 import org.hibernate.action.internal.EntityUpdateAction;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.Nullability;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.engine.Versioning;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.FlushEntityEvent;
 import org.hibernate.event.FlushEntityEventListener;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 /**
  * An event that occurs for each entity instance at flush time
  *
  * @author Gavin King
  */
 public class DefaultFlushEntityEventListener implements FlushEntityEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultFlushEntityEventListener.class.getName());
 
 	/**
 	 * make sure user didn't mangle the id
 	 */
 	public void checkId(
 			Object object,
 			EntityPersister persister,
 			Serializable id,
 			EntityMode entityMode,
 			SessionImplementor session) throws HibernateException {
 
 		if ( id != null && id instanceof DelayedPostInsertIdentifier ) {
 			// this is a situation where the entity id is assigned by a post-insert generator
 			// and was saved outside the transaction forcing it to be delayed
 			return;
 		}
 
 		if ( persister.canExtractIdOutOfEntity() ) {
 
 			Serializable oid = persister.getIdentifier( object, session );
 			if (id==null) {
 				throw new AssertionFailure("null id in " + persister.getEntityName() + " entry (don't flush the Session after an exception occurs)");
 			}
 			if ( !persister.getIdentifierType().isEqual( id, oid, entityMode, session.getFactory() ) ) {
 				throw new HibernateException(
 						"identifier of an instance of " +
 						persister.getEntityName() +
 						" was altered from " + id +
 						" to " + oid
 					);
 			}
 		}
 
 	}
 
 	private void checkNaturalId(
 			EntityPersister persister,
 	        EntityEntry entry,
 	        Object[] current,
 	        Object[] loaded,
 	        EntityMode entityMode,
 	        SessionImplementor session) {
 		if ( persister.hasNaturalIdentifier() && entry.getStatus() != Status.READ_ONLY ) {
  			Object[] snapshot = null;
 			Type[] types = persister.getPropertyTypes();
 			int[] props = persister.getNaturalIdentifierProperties();
 			boolean[] updateable = persister.getPropertyUpdateability();
 			for ( int i=0; i<props.length; i++ ) {
 				int prop = props[i];
 				if ( !updateable[prop] ) {
  					Object loadedVal;
  					if ( loaded == null ) {
  						if ( snapshot == null) {
  							snapshot = session.getPersistenceContext().getNaturalIdSnapshot( entry.getId(), persister );
  						}
  						loadedVal = snapshot[i];
  					} else {
  						loadedVal = loaded[prop];
  					}
  					if ( !types[prop].isEqual( current[prop], loadedVal, entityMode ) ) {
 						throw new HibernateException(
 								"immutable natural identifier of an instance of " +
 								persister.getEntityName() +
 								" was altered"
 							);
 					}
 				}
 			}
 		}
 	}
 
 	/**
 	 * Flushes a single entity's state to the database, by scheduling
 	 * an update action, if necessary
 	 */
 	public void onFlushEntity(FlushEntityEvent event) throws HibernateException {
 		final Object entity = event.getEntity();
 		final EntityEntry entry = event.getEntityEntry();
 		final EventSource session = event.getSession();
 		final EntityPersister persister = entry.getPersister();
 		final Status status = entry.getStatus();
 		final EntityMode entityMode = session.getEntityMode();
 		final Type[] types = persister.getPropertyTypes();
 
 		final boolean mightBeDirty = entry.requiresDirtyCheck(entity);
 
 		final Object[] values = getValues( entity, entry, entityMode, mightBeDirty, session );
 
 		event.setPropertyValues(values);
 
 		//TODO: avoid this for non-new instances where mightBeDirty==false
 		boolean substitute = wrapCollections( session, persister, types, values);
 
 		if ( isUpdateNecessary( event, mightBeDirty ) ) {
 			substitute = scheduleUpdate( event ) || substitute;
 		}
 
 		if ( status != Status.DELETED ) {
 			// now update the object .. has to be outside the main if block above (because of collections)
 			if (substitute) persister.setPropertyValues( entity, values, entityMode );
 
 			// Search for collections by reachability, updating their role.
 			// We don't want to touch collections reachable from a deleted object
 			if ( persister.hasCollections() ) {
 				new FlushVisitor(session, entity).processEntityPropertyValues(values, types);
 			}
 		}
 
 	}
 
 	private Object[] getValues(
 			Object entity,
 			EntityEntry entry,
 			EntityMode entityMode,
 			boolean mightBeDirty,
 	        SessionImplementor session) {
 		final Object[] loadedState = entry.getLoadedState();
 		final Status status = entry.getStatus();
 		final EntityPersister persister = entry.getPersister();
 
 		final Object[] values;
 		if ( status == Status.DELETED ) {
 			//grab its state saved at deletion
 			values = entry.getDeletedState();
 		}
 		else if ( !mightBeDirty && loadedState!=null ) {
 			values = loadedState;
 		}
 		else {
 			checkId( entity, persister, entry.getId(), entityMode, session );
 
 			// grab its current state
 			values = persister.getPropertyValues( entity, entityMode );
 
 			checkNaturalId( persister, entry, values, loadedState, entityMode, session );
 		}
 		return values;
 	}
 
 	private boolean wrapCollections(
 			EventSource session,
 			EntityPersister persister,
 			Type[] types,
 			Object[] values
 	) {
 		if ( persister.hasCollections() ) {
 
 			// wrap up any new collections directly referenced by the object
 			// or its components
 
 			// NOTE: we need to do the wrap here even if its not "dirty",
 			// because collections need wrapping but changes to _them_
 			// don't dirty the container. Also, for versioned data, we
 			// need to wrap before calling searchForDirtyCollections
 
 			WrapVisitor visitor = new WrapVisitor(session);
 			// substitutes into values by side-effect
 			visitor.processEntityPropertyValues(values, types);
 			return visitor.isSubstitutionRequired();
 		}
 		else {
 			return false;
 		}
 	}
 
 	private boolean isUpdateNecessary(final FlushEntityEvent event, final boolean mightBeDirty) {
 		final Status status = event.getEntityEntry().getStatus();
 		if ( mightBeDirty || status==Status.DELETED ) {
 			// compare to cached state (ignoring collections unless versioned)
 			dirtyCheck(event);
 			if ( isUpdateNecessary(event) ) {
 				return true;
 			}
 			else {
 				FieldInterceptionHelper.clearDirty( event.getEntity() );
 				return false;
 			}
 		}
 		else {
 			return hasDirtyCollections( event, event.getEntityEntry().getPersister(), status );
 		}
 	}
 
 	private boolean scheduleUpdate(final FlushEntityEvent event) {
 
 		final EntityEntry entry = event.getEntityEntry();
 		final EventSource session = event.getSession();
 		final Object entity = event.getEntity();
 		final Status status = entry.getStatus();
 		final EntityMode entityMode = session.getEntityMode();
 		final EntityPersister persister = entry.getPersister();
 		final Object[] values = event.getPropertyValues();
 
         if (LOG.isTraceEnabled()) {
 			if ( status == Status.DELETED ) {
                 if (!persister.isMutable()) LOG.trace("Updating immutable, deleted entity: "
                                                       + MessageHelper.infoString(persister, entry.getId(), session.getFactory()));
                 else if (!entry.isModifiableEntity()) LOG.trace("Updating non-modifiable, deleted entity: "
                                                                 + MessageHelper.infoString(persister,
                                                                                            entry.getId(),
                                                                                            session.getFactory()));
                 else LOG.trace("Updating deleted entity: "
                                + MessageHelper.infoString(persister, entry.getId(), session.getFactory()));
             } else LOG.trace("Updating entity: " + MessageHelper.infoString(persister, entry.getId(), session.getFactory()));
 		}
 
 		final boolean intercepted = !entry.isBeingReplicated() && handleInterception( event );
 
 		// increment the version number (if necessary)
 		final Object nextVersion = getNextVersion(event);
 
 		// if it was dirtied by a collection only
 		int[] dirtyProperties = event.getDirtyProperties();
 		if ( event.isDirtyCheckPossible() && dirtyProperties == null ) {
 			if ( ! intercepted && !event.hasDirtyCollection() ) {
 				throw new AssertionFailure( "dirty, but no dirty properties" );
 			}
 			dirtyProperties = ArrayHelper.EMPTY_INT_ARRAY;
 		}
 
 		// check nullability but do not doAfterTransactionCompletion command execute
 		// we'll use scheduled updates for that.
 		new Nullability(session).checkNullability( values, persister, true );
 
 		// schedule the update
 		// note that we intentionally do _not_ pass in currentPersistentState!
 		session.getActionQueue().addAction(
 				new EntityUpdateAction(
 						entry.getId(),
 						values,
 						dirtyProperties,
 						event.hasDirtyCollection(),
 						( status == Status.DELETED && ! entry.isModifiableEntity() ?
 								persister.getPropertyValues( entity, entityMode ) :
 								entry.getLoadedState() ),
 						entry.getVersion(),
 						nextVersion,
 						entity,
 						entry.getRowId(),
 						persister,
 						session
 					)
 			);
 
 		return intercepted;
 	}
 
 	protected boolean handleInterception(FlushEntityEvent event) {
 		SessionImplementor session = event.getSession();
 		EntityEntry entry = event.getEntityEntry();
 		EntityPersister persister = entry.getPersister();
 		Object entity = event.getEntity();
 
 		//give the Interceptor a chance to modify property values
 		final Object[] values = event.getPropertyValues();
 		final boolean intercepted = invokeInterceptor( session, entity, entry, values, persister );
 
 		//now we might need to recalculate the dirtyProperties array
 		if ( intercepted && event.isDirtyCheckPossible() && !event.isDirtyCheckHandledByInterceptor() ) {
 			int[] dirtyProperties;
 			if ( event.hasDatabaseSnapshot() ) {
 				dirtyProperties = persister.findModified( event.getDatabaseSnapshot(), values, entity, session );
 			}
 			else {
 				dirtyProperties = persister.findDirty( values, entry.getLoadedState(), entity, session );
 			}
 			event.setDirtyProperties(dirtyProperties);
 		}
 
 		return intercepted;
 	}
 
 	protected boolean invokeInterceptor(
 			SessionImplementor session,
 			Object entity,
 			EntityEntry entry,
 			final Object[] values,
 			EntityPersister persister) {
 		return session.getInterceptor().onFlushDirty(
 				entity,
 				entry.getId(),
 				values,
 				entry.getLoadedState(),
 				persister.getPropertyNames(),
 				persister.getPropertyTypes()
 		);
 	}
 
 	/**
 	 * Convience method to retreive an entities next version value
 	 */
 	private Object getNextVersion(FlushEntityEvent event) throws HibernateException {
 
 		EntityEntry entry = event.getEntityEntry();
 		EntityPersister persister = entry.getPersister();
 		if ( persister.isVersioned() ) {
 
 			Object[] values = event.getPropertyValues();
 
 			if ( entry.isBeingReplicated() ) {
 				return Versioning.getVersion(values, persister);
 			}
 			else {
 				int[] dirtyProperties = event.getDirtyProperties();
 
 				final boolean isVersionIncrementRequired = isVersionIncrementRequired(
 						event,
 						entry,
 						persister,
 						dirtyProperties
 					);
 
 				final Object nextVersion = isVersionIncrementRequired ?
 						Versioning.increment( entry.getVersion(), persister.getVersionType(), event.getSession() ) :
 						entry.getVersion(); //use the current version
 
 				Versioning.setVersion(values, nextVersion, persister);
 
 				return nextVersion;
 			}
 		}
 		else {
 			return null;
 		}
 
 	}
 
 	private boolean isVersionIncrementRequired(
 			FlushEntityEvent event,
 			EntityEntry entry,
 			EntityPersister persister,
 			int[] dirtyProperties
 	) {
 		final boolean isVersionIncrementRequired = entry.getStatus()!=Status.DELETED && (
 				dirtyProperties==null ||
 				Versioning.isVersionIncrementRequired(
 						dirtyProperties,
 						event.hasDirtyCollection(),
 						persister.getPropertyVersionability()
 					)
 			);
 		return isVersionIncrementRequired;
 	}
 
 	/**
 	 * Performs all necessary checking to determine if an entity needs an SQL update
 	 * to synchronize its state to the database. Modifies the event by side-effect!
 	 * Note: this method is quite slow, avoid calling if possible!
 	 */
 	protected final boolean isUpdateNecessary(FlushEntityEvent event) throws HibernateException {
 
 		EntityPersister persister = event.getEntityEntry().getPersister();
 		Status status = event.getEntityEntry().getStatus();
 
 		if ( !event.isDirtyCheckPossible() ) {
 			return true;
 		}
 		else {
 
 			int[] dirtyProperties = event.getDirtyProperties();
 			if ( dirtyProperties!=null && dirtyProperties.length!=0 ) {
 				return true; //TODO: suck into event class
 			}
 			else {
 				return hasDirtyCollections( event, persister, status );
 			}
 
 		}
 	}
 
 	private boolean hasDirtyCollections(FlushEntityEvent event, EntityPersister persister, Status status) {
 		if ( isCollectionDirtyCheckNecessary(persister, status ) ) {
 			DirtyCollectionSearchVisitor visitor = new DirtyCollectionSearchVisitor(
 					event.getSession(),
 					persister.getPropertyVersionability()
 				);
 			visitor.processEntityPropertyValues( event.getPropertyValues(), persister.getPropertyTypes() );
 			boolean hasDirtyCollections = visitor.wasDirtyCollectionFound();
 			event.setHasDirtyCollection(hasDirtyCollections);
 			return hasDirtyCollections;
 		}
 		else {
 			return false;
 		}
 	}
 
 	private boolean isCollectionDirtyCheckNecessary(EntityPersister persister, Status status) {
 		return ( status == Status.MANAGED || status == Status.READ_ONLY ) &&
 				persister.isVersioned() &&
 				persister.hasCollections();
 	}
 
 	/**
 	 * Perform a dirty check, and attach the results to the event
 	 */
 	protected void dirtyCheck(FlushEntityEvent event) throws HibernateException {
 
 		final Object entity = event.getEntity();
 		final Object[] values = event.getPropertyValues();
 		final SessionImplementor session = event.getSession();
 		final EntityEntry entry = event.getEntityEntry();
 		final EntityPersister persister = entry.getPersister();
 		final Serializable id = entry.getId();
 		final Object[] loadedState = entry.getLoadedState();
 
 		int[] dirtyProperties = session.getInterceptor().findDirty(
 				entity,
 				id,
 				values,
 				loadedState,
 				persister.getPropertyNames(),
 				persister.getPropertyTypes()
 			);
 
 		event.setDatabaseSnapshot(null);
 
 		final boolean interceptorHandledDirtyCheck;
 		boolean cannotDirtyCheck;
 
 		if ( dirtyProperties==null ) {
 			// Interceptor returned null, so do the dirtycheck ourself, if possible
 			interceptorHandledDirtyCheck = false;
 
 			cannotDirtyCheck = loadedState==null; // object loaded by update()
 			if ( !cannotDirtyCheck ) {
 				// dirty check against the usual snapshot of the entity
 				dirtyProperties = persister.findDirty( values, loadedState, entity, session );
 			}
 			else if ( entry.getStatus() == Status.DELETED && ! event.getEntityEntry().isModifiableEntity() ) {
 				// A non-modifiable (e.g., read-only or immutable) entity needs to be have
 				// references to transient entities set to null before being deleted. No other
 				// fields should be updated.
 				if ( values != entry.getDeletedState() ) {
 					throw new IllegalStateException(
 							"Entity has status Status.DELETED but values != entry.getDeletedState"
 					);
 				}
 				// Even if loadedState == null, we can dirty-check by comparing currentState and
 				// entry.getDeletedState() because the only fields to be updated are those that
 				// refer to transient entities that are being set to null.
 				// - currentState contains the entity's current property values.
 				// - entry.getDeletedState() contains the entity's current property values with
 				//   references to transient entities set to null.
 				// - dirtyProperties will only contain properties that refer to transient entities
 				final Object[] currentState =
 						persister.getPropertyValues( event.getEntity(), event.getSession().getEntityMode() );
 				dirtyProperties = persister.findDirty( entry.getDeletedState(), currentState, entity, session );
 				cannotDirtyCheck = false;
 			}
 			else {
 				// dirty check against the database snapshot, if possible/necessary
 				final Object[] databaseSnapshot = getDatabaseSnapshot(session, persister, id);
 				if ( databaseSnapshot != null ) {
 					dirtyProperties = persister.findModified(databaseSnapshot, values, entity, session);
 					cannotDirtyCheck = false;
 					event.setDatabaseSnapshot(databaseSnapshot);
 				}
 			}
 		}
 		else {
 			// the Interceptor handled the dirty checking
 			cannotDirtyCheck = false;
 			interceptorHandledDirtyCheck = true;
 		}
 
 		logDirtyProperties( id, dirtyProperties, persister );
 
 		event.setDirtyProperties(dirtyProperties);
 		event.setDirtyCheckHandledByInterceptor(interceptorHandledDirtyCheck);
 		event.setDirtyCheckPossible(!cannotDirtyCheck);
 
 	}
 
 	private void logDirtyProperties(Serializable id, int[] dirtyProperties, EntityPersister persister) {
         if (LOG.isTraceEnabled() && dirtyProperties != null && dirtyProperties.length > 0) {
 			final String[] allPropertyNames = persister.getPropertyNames();
 			final String[] dirtyPropertyNames = new String[ dirtyProperties.length ];
 			for ( int i = 0; i < dirtyProperties.length; i++ ) {
 				dirtyPropertyNames[i] = allPropertyNames[ dirtyProperties[i]];
 			}
             LOG.trace("Found dirty properties [" + MessageHelper.infoString(persister.getEntityName(), id) + "] : "
                       + dirtyPropertyNames);
 		}
 	}
 
 	private Object[] getDatabaseSnapshot(SessionImplementor session, EntityPersister persister, Serializable id) {
 		if ( persister.isSelectBeforeUpdateRequired() ) {
 			Object[] snapshot = session.getPersistenceContext()
 					.getDatabaseSnapshot(id, persister);
 			if (snapshot==null) {
 				//do we even really need this? the update will fail anyway....
 				if ( session.getFactory().getStatistics().isStatisticsEnabled() ) {
 					session.getFactory().getStatisticsImplementor()
 							.optimisticFailure( persister.getEntityName() );
 				}
 				throw new StaleObjectStateException( persister.getEntityName(), id );
 			}
             return snapshot;
 		}
         // TODO: optimize away this lookup for entities w/o unsaved-value="undefined"
         final EntityKey entityKey = session.generateEntityKey( id, persister );
         return session.getPersistenceContext().getCachedDatabaseSnapshot(entityKey);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultInitializeCollectionEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultInitializeCollectionEventListener.java
index 53f2968a93..b3e789ba86 100755
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultInitializeCollectionEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultInitializeCollectionEventListener.java
@@ -1,146 +1,146 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.entry.CollectionCacheEntry;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.CollectionEntry;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.InitializeCollectionEvent;
 import org.hibernate.event.InitializeCollectionEventListener;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * @author Gavin King
  */
 public class DefaultInitializeCollectionEventListener implements InitializeCollectionEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultInitializeCollectionEventListener.class.getName());
 
 	/**
 	 * called by a collection that wants to initialize itself
 	 */
 	public void onInitializeCollection(InitializeCollectionEvent event)
 	throws HibernateException {
 
 		PersistentCollection collection = event.getCollection();
 		SessionImplementor source = event.getSession();
 
 		CollectionEntry ce = source.getPersistenceContext().getCollectionEntry(collection);
 		if (ce==null) throw new HibernateException("collection was evicted");
 		if ( !collection.wasInitialized() ) {
             if (LOG.isTraceEnabled()) LOG.trace("Initializing collection "
                                                 + MessageHelper.collectionInfoString(ce.getLoadedPersister(),
                                                                                      ce.getLoadedKey(),
                                                                                      source.getFactory()));
 
             LOG.trace("Checking second-level cache");
 			final boolean foundInCache = initializeCollectionFromCache(
 					ce.getLoadedKey(),
 					ce.getLoadedPersister(),
 					collection,
 					source
 				);
 
             if (foundInCache) LOG.trace("Collection initialized from cache");
 			else {
                 LOG.trace("Collection not cached");
 				ce.getLoadedPersister().initialize( ce.getLoadedKey(), source );
                 LOG.trace("Collection initialized");
 
 				if ( source.getFactory().getStatistics().isStatisticsEnabled() ) {
 					source.getFactory().getStatisticsImplementor().fetchCollection(
 							ce.getLoadedPersister().getRole()
 						);
 				}
 			}
 		}
 	}
 
 	/**
 	 * Try to initialize a collection from the cache
 	 *
 	 * @param id The id of the collection of initialize
 	 * @param persister The collection persister
 	 * @param collection The collection to initialize
 	 * @param source The originating session
 	 * @return true if we were able to initialize the collection from the cache;
 	 * false otherwise.
 	 */
 	private boolean initializeCollectionFromCache(
 			Serializable id,
 			CollectionPersister persister,
 			PersistentCollection collection,
 			SessionImplementor source) {
 
 		if ( !source.getEnabledFilters().isEmpty() && persister.isAffectedByEnabledFilters( source ) ) {
             LOG.trace("Disregarding cached version (if any) of collection due to enabled filters");
 			return false;
 		}
 
 		final boolean useCache = persister.hasCache() &&
 				source.getCacheMode().isGetEnabled();
 
         if (!useCache) return false;
 
         final SessionFactoryImplementor factory = source.getFactory();
 
         final CacheKey ck = source.generateCacheKey( id, persister.getKeyType(), persister.getRole() );
         Object ce = persister.getCacheAccessStrategy().get(ck, source.getTimestamp());
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
             if (ce == null) {
                 factory.getStatisticsImplementor()
 						.secondLevelCacheMiss( persister.getCacheAccessStrategy().getRegion().getName() );
             }
 			else {
                 factory.getStatisticsImplementor()
 						.secondLevelCacheHit( persister.getCacheAccessStrategy().getRegion().getName() );
             }
 		}
 
         if ( ce == null ) {
 			return false;
 		}
 
 		CollectionCacheEntry cacheEntry = (CollectionCacheEntry)persister.getCacheEntryStructure().destructure(ce, factory);
 
 		final PersistenceContext persistenceContext = source.getPersistenceContext();
         cacheEntry.assemble(collection, persister, persistenceContext.getCollectionOwner(id, persister));
         persistenceContext.getCollectionEntry(collection).postInitialize(collection);
         // addInitializedCollection(collection, persister, id);
         return true;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultLoadEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultLoadEventListener.java
index 9aedb3c283..b4e0000801 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultLoadEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultLoadEventListener.java
@@ -1,668 +1,668 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.NonUniqueObjectException;
 import org.hibernate.PersistentObjectException;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.access.SoftLock;
 import org.hibernate.cache.entry.CacheEntry;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.engine.TwoPhaseLoad;
 import org.hibernate.engine.Versioning;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.EventType;
 import org.hibernate.event.LoadEvent;
 import org.hibernate.event.LoadEventListener;
 import org.hibernate.event.PostLoadEvent;
 import org.hibernate.event.PostLoadEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 import org.hibernate.type.EmbeddedComponentType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 
 /**
  * Defines the default load event listeners used by hibernate for loading entities
  * in response to generated load events.
  *
  * @author Steve Ebersole
  */
 public class DefaultLoadEventListener extends AbstractLockUpgradeEventListener implements LoadEventListener {
 
 	public static final Object REMOVED_ENTITY_MARKER = new Object();
 	public static final Object INCONSISTENT_RTN_CLASS_MARKER = new Object();
 	public static final LockMode DEFAULT_LOCK_MODE = LockMode.NONE;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultLoadEventListener.class.getName());
 
 
 	/**
 	 * Handle the given load event.
 	 *
 	 * @param event The load event to be handled.
 	 * @throws HibernateException
 	 */
 	public void onLoad(LoadEvent event, LoadEventListener.LoadType loadType) throws HibernateException {
 
 		final SessionImplementor source = event.getSession();
 
 		EntityPersister persister;
 		if ( event.getInstanceToLoad() != null ) {
 			persister = source.getEntityPersister( null, event.getInstanceToLoad() ); //the load() which takes an entity does not pass an entityName
 			event.setEntityClassName( event.getInstanceToLoad().getClass().getName() );
 		}
 		else {
 			persister = source.getFactory().getEntityPersister( event.getEntityClassName() );
 		}
 
 		if ( persister == null ) {
 			throw new HibernateException(
 					"Unable to locate persister: " +
 					event.getEntityClassName()
 				);
 		}
 
 		final Class idClass = persister.getIdentifierType().getReturnedClass();
 		if ( persister.getIdentifierType().isComponentType() && EntityMode.DOM4J == event.getSession().getEntityMode() ) {
 			// skip this check for composite-ids relating to dom4j entity-mode;
 			// alternatively, we could add a check to make sure the incoming id value is
 			// an instance of Element...
 		}
 		else {
 			if ( idClass != null && ! idClass.isInstance( event.getEntityId() ) ) {
 				// we may have the kooky jpa requirement of allowing find-by-id where
 				// "id" is the "simple pk value" of a dependent objects parent.  This
 				// is part of its generally goofy "derived identity" "feature"
 				if ( persister.getEntityMetamodel().getIdentifierProperty().isEmbedded() ) {
 					final EmbeddedComponentType dependentIdType =
 							(EmbeddedComponentType) persister.getEntityMetamodel().getIdentifierProperty().getType();
 					if ( dependentIdType.getSubtypes().length == 1 ) {
 						final Type singleSubType = dependentIdType.getSubtypes()[0];
 						if ( singleSubType.isEntityType() ) {
 							final EntityType dependentParentType = (EntityType) singleSubType;
 							final Type dependentParentIdType = dependentParentType.getIdentifierOrUniqueKeyType( source.getFactory() );
 							if ( dependentParentIdType.getReturnedClass().isInstance( event.getEntityId() ) ) {
 								// yep that's what we have...
 								loadByDerivedIdentitySimplePkValue(
 										event,
 										loadType,
 										persister,
 										dependentIdType,
 										source.getFactory().getEntityPersister( dependentParentType.getAssociatedEntityName() )
 								);
 								return;
 							}
 						}
 					}
 				}
 				throw new TypeMismatchException(
 						"Provided id of the wrong type for class " + persister.getEntityName() + ". Expected: " + idClass + ", got " + event.getEntityId().getClass()
 				);
 			}
 		}
 
 		final  EntityKey keyToLoad = source.generateEntityKey( event.getEntityId(), persister );
 
 		try {
 			if ( loadType.isNakedEntityReturned() ) {
 				//do not return a proxy!
 				//(this option indicates we are initializing a proxy)
 				event.setResult( load(event, persister, keyToLoad, loadType) );
 			}
 			else {
 				//return a proxy if appropriate
 				if ( event.getLockMode() == LockMode.NONE ) {
 					event.setResult( proxyOrLoad(event, persister, keyToLoad, loadType) );
 				}
 				else {
 					event.setResult( lockAndLoad(event, persister, keyToLoad, loadType, source) );
 				}
 			}
 		}
 		catch(HibernateException e) {
             LOG.unableToLoadCommand(e);
 			throw e;
 		}
 	}
 
 	private void loadByDerivedIdentitySimplePkValue(
 			LoadEvent event,
 			LoadEventListener.LoadType options,
 			EntityPersister dependentPersister,
 			EmbeddedComponentType dependentIdType,
 			EntityPersister parentPersister) {
 		final EntityKey parentEntityKey = event.getSession().generateEntityKey( event.getEntityId(), parentPersister );
 		final Object parent = doLoad( event, parentPersister, parentEntityKey, options );
 
 		final Serializable dependent = (Serializable) dependentIdType.instantiate( parent, event.getSession() );
 		dependentIdType.setPropertyValues( dependent, new Object[] {parent}, event.getSession().getEntityMode() );
 		final EntityKey dependentEntityKey = event.getSession().generateEntityKey( dependent, dependentPersister );
 		event.setEntityId( dependent );
 
 		event.setResult( doLoad( event, dependentPersister, dependentEntityKey, options ) );
 	}
 
 	/**
 	 * Performs the load of an entity.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @return The loaded entity.
 	 * @throws HibernateException
 	 */
 	protected Object load(
 		final LoadEvent event,
 		final EntityPersister persister,
 		final EntityKey keyToLoad,
 		final LoadEventListener.LoadType options) {
 
 		if ( event.getInstanceToLoad() != null ) {
 			if ( event.getSession().getPersistenceContext().getEntry( event.getInstanceToLoad() ) != null ) {
 				throw new PersistentObjectException(
 						"attempted to load into an instance that was already associated with the session: " +
 						MessageHelper.infoString( persister, event.getEntityId(), event.getSession().getFactory() )
 					);
 			}
 			persister.setIdentifier( event.getInstanceToLoad(), event.getEntityId(), event.getSession() );
 		}
 
 		Object entity = doLoad(event, persister, keyToLoad, options);
 
 		boolean isOptionalInstance = event.getInstanceToLoad() != null;
 
 		if ( !options.isAllowNulls() || isOptionalInstance ) {
 			if ( entity == null ) {
 				event.getSession().getFactory().getEntityNotFoundDelegate().handleEntityNotFound( event.getEntityClassName(), event.getEntityId() );
 			}
 		}
 
 		if ( isOptionalInstance && entity != event.getInstanceToLoad() ) {
 			throw new NonUniqueObjectException( event.getEntityId(), event.getEntityClassName() );
 		}
 
 		return entity;
 	}
 
 	/**
 	 * Based on configured options, will either return a pre-existing proxy,
 	 * generate a new proxy, or perform an actual load.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @return The result of the proxy/load operation.
 	 */
 	protected Object proxyOrLoad(
 		final LoadEvent event,
 		final EntityPersister persister,
 		final EntityKey keyToLoad,
 		final LoadEventListener.LoadType options) {
 
         if (LOG.isTraceEnabled()) LOG.trace("Loading entity: "
                                             + MessageHelper.infoString(persister,
                                                                              event.getEntityId(),
                                                                              event.getSession().getFactory()));
 
         // this class has no proxies (so do a shortcut)
         if (!persister.hasProxy()) return load(event, persister, keyToLoad, options);
         final PersistenceContext persistenceContext = event.getSession().getPersistenceContext();
 
 		// look for a proxy
         Object proxy = persistenceContext.getProxy(keyToLoad);
         if (proxy != null) return returnNarrowedProxy(event, persister, keyToLoad, options, persistenceContext, proxy);
         if (options.isAllowProxyCreation()) return createProxyIfNecessary(event, persister, keyToLoad, options, persistenceContext);
         // return a newly loaded object
         return load(event, persister, keyToLoad, options);
 	}
 
 	/**
 	 * Given a proxy, initialize it and/or narrow it provided either
 	 * is necessary.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @param persistenceContext The originating session
 	 * @param proxy The proxy to narrow
 	 * @return The created/existing proxy
 	 */
 	private Object returnNarrowedProxy(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options,
 			final PersistenceContext persistenceContext,
 			final Object proxy) {
         LOG.trace("Entity proxy found in session cache");
 		LazyInitializer li = ( (HibernateProxy) proxy ).getHibernateLazyInitializer();
 		if ( li.isUnwrap() ) {
 			return li.getImplementation();
 		}
 		Object impl = null;
 		if ( !options.isAllowProxyCreation() ) {
 			impl = load( event, persister, keyToLoad, options );
 			if ( impl == null ) {
 				event.getSession().getFactory().getEntityNotFoundDelegate().handleEntityNotFound( persister.getEntityName(), keyToLoad.getIdentifier());
 			}
 		}
 		return persistenceContext.narrowProxy( proxy, persister, keyToLoad, impl );
 	}
 
 	/**
 	 * If there is already a corresponding proxy associated with the
 	 * persistence context, return it; otherwise create a proxy, associate it
 	 * with the persistence context, and return the just-created proxy.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @param persistenceContext The originating session
 	 * @return The created/existing proxy
 	 */
 	private Object createProxyIfNecessary(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options,
 			final PersistenceContext persistenceContext) {
 		Object existing = persistenceContext.getEntity( keyToLoad );
 		if ( existing != null ) {
 			// return existing object or initialized proxy (unless deleted)
             LOG.trace("Entity found in session cache");
 			if ( options.isCheckDeleted() ) {
 				EntityEntry entry = persistenceContext.getEntry( existing );
 				Status status = entry.getStatus();
 				if ( status == Status.DELETED || status == Status.GONE ) {
 					return null;
 				}
 			}
 			return existing;
 		}
         LOG.trace("Creating new proxy for entity");
         // return new uninitialized proxy
         Object proxy = persister.createProxy(event.getEntityId(), event.getSession());
         persistenceContext.getBatchFetchQueue().addBatchLoadableEntityKey(keyToLoad);
         persistenceContext.addProxy(keyToLoad, proxy);
         return proxy;
 	}
 
 	/**
 	 * If the class to be loaded has been configured with a cache, then lock
 	 * given id in that cache and then perform the load.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @param source The originating session
 	 * @return The loaded entity
 	 * @throws HibernateException
 	 */
 	protected Object lockAndLoad(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options,
 			final SessionImplementor source) {
 		SoftLock lock = null;
 		final CacheKey ck;
 		if ( persister.hasCache() ) {
 			ck = source.generateCacheKey(
 					event.getEntityId(),
 					persister.getIdentifierType(),
 					persister.getRootEntityName()
 			);
 			lock = persister.getCacheAccessStrategy().lockItem( ck, null );
 		}
 		else {
 			ck = null;
 		}
 
 		Object entity;
 		try {
 			entity = load(event, persister, keyToLoad, options);
 		}
 		finally {
 			if ( persister.hasCache() ) {
 				persister.getCacheAccessStrategy().unlockItem( ck, lock );
 			}
 		}
 
 		return event.getSession().getPersistenceContext().proxyFor( persister, keyToLoad, entity );
 	}
 
 
 	/**
 	 * Coordinates the efforts to load a given entity.  First, an attempt is
 	 * made to load the entity from the session-level cache.  If not found there,
 	 * an attempt is made to locate it in second-level cache.  Lastly, an
 	 * attempt is made to load it directly from the datasource.
 	 *
 	 * @param event The load event
 	 * @param persister The persister for the entity being requested for load
 	 * @param keyToLoad The EntityKey representing the entity to be loaded.
 	 * @param options The load options.
 	 * @return The loaded entity, or null.
 	 */
 	protected Object doLoad(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options) {
 
         if (LOG.isTraceEnabled()) LOG.trace("Attempting to resolve: "
                                             + MessageHelper.infoString(persister,
                                                                        event.getEntityId(),
                                                                        event.getSession().getFactory()));
 
 		Object entity = loadFromSessionCache( event, keyToLoad, options );
 		if ( entity == REMOVED_ENTITY_MARKER ) {
             LOG.debugf("Load request found matching entity in context, but it is scheduled for removal; returning null");
 			return null;
 		}
 		if ( entity == INCONSISTENT_RTN_CLASS_MARKER ) {
             LOG.debugf("Load request found matching entity in context, but the matched entity was of an inconsistent return type; returning null");
 			return null;
 		}
 		if ( entity != null ) {
             if (LOG.isTraceEnabled()) LOG.trace("Resolved object in session cache: "
                                                 + MessageHelper.infoString(persister,
                                                                            event.getEntityId(),
                                                                            event.getSession().getFactory()));
 			return entity;
 		}
 
 		entity = loadFromSecondLevelCache(event, persister, options);
 		if ( entity != null ) {
             if (LOG.isTraceEnabled()) LOG.trace("Resolved object in second-level cache: "
                                                 + MessageHelper.infoString(persister,
                                                                            event.getEntityId(),
                                                                            event.getSession().getFactory()));
 			return entity;
 		}
 
         if (LOG.isTraceEnabled()) LOG.trace("Object not resolved in any cache: "
                                             + MessageHelper.infoString(persister,
                                                                        event.getEntityId(),
                                                                        event.getSession().getFactory()));
 
 		return loadFromDatasource(event, persister, keyToLoad, options);
 	}
 
 	/**
 	 * Performs the process of loading an entity from the configured
 	 * underlying datasource.
 	 *
 	 * @param event The load event
 	 * @param persister The persister for the entity being requested for load
 	 * @param keyToLoad The EntityKey representing the entity to be loaded.
 	 * @param options The load options.
 	 * @return The object loaded from the datasource, or null if not found.
 	 */
 	protected Object loadFromDatasource(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options) {
 		final SessionImplementor source = event.getSession();
 		Object entity = persister.load(
 				event.getEntityId(),
 				event.getInstanceToLoad(),
 				event.getLockOptions(),
 				source
 		);
 
 		if ( event.isAssociationFetch() && source.getFactory().getStatistics().isStatisticsEnabled() ) {
 			source.getFactory().getStatisticsImplementor().fetchEntity( event.getEntityClassName() );
 		}
 
 		return entity;
 	}
 
 	/**
 	 * Attempts to locate the entity in the session-level cache.
 	 * <p/>
 	 * If allowed to return nulls, then if the entity happens to be found in
 	 * the session cache, we check the entity type for proper handling
 	 * of entity hierarchies.
 	 * <p/>
 	 * If checkDeleted was set to true, then if the entity is found in the
 	 * session-level cache, it's current status within the session cache
 	 * is checked to see if it has previously been scheduled for deletion.
 	 *
 	 * @param event The load event
 	 * @param keyToLoad The EntityKey representing the entity to be loaded.
 	 * @param options The load options.
 	 * @return The entity from the session-level cache, or null.
 	 * @throws HibernateException Generally indicates problems applying a lock-mode.
 	 */
 	protected Object loadFromSessionCache(
 			final LoadEvent event,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options) throws HibernateException {
 
 		SessionImplementor session = event.getSession();
 		Object old = session.getEntityUsingInterceptor( keyToLoad );
 
 		if ( old != null ) {
 			// this object was already loaded
 			EntityEntry oldEntry = session.getPersistenceContext().getEntry( old );
 			if ( options.isCheckDeleted() ) {
 				Status status = oldEntry.getStatus();
 				if ( status == Status.DELETED || status == Status.GONE ) {
 					return REMOVED_ENTITY_MARKER;
 				}
 			}
 			if ( options.isAllowNulls() ) {
 //				EntityPersister persister = event.getSession().getFactory().getEntityPersister( event.getEntityClassName() );
 				EntityPersister persister = event.getSession().getFactory().getEntityPersister( keyToLoad.getEntityName() );
 				if ( ! persister.isInstance( old, event.getSession().getEntityMode() ) ) {
 					return INCONSISTENT_RTN_CLASS_MARKER;
 				}
 			}
 			upgradeLock( old, oldEntry, event.getLockOptions(), event.getSession() );
 		}
 
 		return old;
 	}
 
 	/**
 	 * Attempts to load the entity from the second-level cache.
 	 *
 	 * @param event The load event
 	 * @param persister The persister for the entity being requested for load
 	 * @param options The load options.
 	 * @return The entity from the second-level cache, or null.
 	 */
 	protected Object loadFromSecondLevelCache(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final LoadEventListener.LoadType options) {
 
 		final SessionImplementor source = event.getSession();
 
 		final boolean useCache = persister.hasCache()
 				&& source.getCacheMode().isGetEnabled()
 				&& event.getLockMode().lessThan(LockMode.READ);
 
 		if ( useCache ) {
 
 			final SessionFactoryImplementor factory = source.getFactory();
 
 			final CacheKey ck = source.generateCacheKey(
 					event.getEntityId(),
 					persister.getIdentifierType(),
 					persister.getRootEntityName()
 			);
 			Object ce = persister.getCacheAccessStrategy().get( ck, source.getTimestamp() );
 			if ( factory.getStatistics().isStatisticsEnabled() ) {
 				if ( ce == null ) {
 					factory.getStatisticsImplementor().secondLevelCacheMiss(
 							persister.getCacheAccessStrategy().getRegion().getName()
 					);
 				}
 				else {
 					factory.getStatisticsImplementor().secondLevelCacheHit(
 							persister.getCacheAccessStrategy().getRegion().getName()
 					);
 				}
 			}
 
 			if ( ce != null ) {
 				CacheEntry entry = (CacheEntry) persister.getCacheEntryStructure().destructure( ce, factory );
 
 				// Entity was found in second-level cache...
 				return assembleCacheEntry(
 						entry,
 						event.getEntityId(),
 						persister,
 						event
 				);
 			}
 		}
 
 		return null;
 	}
 
 	private Object assembleCacheEntry(
 			final CacheEntry entry,
 			final Serializable id,
 			final EntityPersister persister,
 			final LoadEvent event) throws HibernateException {
 
 		final Object optionalObject = event.getInstanceToLoad();
 		final EventSource session = event.getSession();
 		final SessionFactoryImplementor factory = session.getFactory();
 
         if (LOG.isTraceEnabled()) LOG.trace("Assembling entity from second-level cache: "
                                             + MessageHelper.infoString(persister, id, factory));
 
 		EntityPersister subclassPersister = factory.getEntityPersister( entry.getSubclass() );
 		Object result = optionalObject == null ?
 				session.instantiate( subclassPersister, id ) : optionalObject;
 
 		// make it circular-reference safe
 		final EntityKey entityKey = session.generateEntityKey( id, subclassPersister );
 		TwoPhaseLoad.addUninitializedCachedEntity(
 				entityKey,
 				result,
 				subclassPersister,
 				LockMode.NONE,
 				entry.areLazyPropertiesUnfetched(),
 				entry.getVersion(),
 				session
 			);
 
 		Type[] types = subclassPersister.getPropertyTypes();
 		Object[] values = entry.assemble( result, id, subclassPersister, session.getInterceptor(), session ); // intializes result by side-effect
 		TypeHelper.deepCopy(
 				values,
 				types,
 				subclassPersister.getPropertyUpdateability(),
 				values,
 				session
 		);
 
 		Object version = Versioning.getVersion( values, subclassPersister );
         if (LOG.isTraceEnabled()) LOG.trace("Cached Version: " + version);
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		boolean isReadOnly = session.isDefaultReadOnly();
 		if ( persister.isMutable() ) {
 			Object proxy = persistenceContext.getProxy( entityKey );
 			if ( proxy != null ) {
 				// there is already a proxy for this impl
 				// only set the status to read-only if the proxy is read-only
 				isReadOnly = ( ( HibernateProxy ) proxy ).getHibernateLazyInitializer().isReadOnly();
 			}
 		}
 		else {
 			isReadOnly = true;
 		}
 		persistenceContext.addEntry(
 				result,
 				( isReadOnly ? Status.READ_ONLY : Status.MANAGED ),
 				values,
 				null,
 				id,
 				version,
 				LockMode.NONE,
 				true,
 				subclassPersister,
 				false,
 				entry.areLazyPropertiesUnfetched()
 			);
 		subclassPersister.afterInitialize( result, entry.areLazyPropertiesUnfetched(), session );
 		persistenceContext.initializeNonLazyCollections();
 		// upgrade the lock if necessary:
 		//lock(result, lockMode);
 
 		//PostLoad is needed for EJB3
 		//TODO: reuse the PostLoadEvent...
 		PostLoadEvent postLoadEvent = new PostLoadEvent( session )
 				.setEntity( result )
 				.setId( id )
 				.setPersister( persister );
 
 		for ( PostLoadEventListener listener : postLoadEventListeners( session ) ) {
 			listener.onPostLoad( postLoadEvent );
 		}
 
 		return result;
 	}
 
 	private Iterable<PostLoadEventListener> postLoadEventListeners(EventSource session) {
 		return session
 				.getFactory()
 				.getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( EventType.POST_LOAD )
 				.listeners();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultMergeEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultMergeEventListener.java
index 3f0391dd7a..cc5dbcd3d7 100755
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultMergeEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultMergeEventListener.java
@@ -1,657 +1,657 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.PropertyValueException;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.WrongClassException;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.MergeEvent;
 import org.hibernate.event.MergeEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.type.ForeignKeyDirection;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 
 /**
  * Defines the default copy event listener used by hibernate for copying entities
  * in response to generated copy events.
  *
  * @author Gavin King
  */
 public class DefaultMergeEventListener extends AbstractSaveEventListener
 	implements MergeEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultMergeEventListener.class.getName());
 
 	@Override
     protected Map getMergeMap(Object anything) {
 		return ( ( EventCache ) anything ).invertMap();
 	}
 
 	/**
 	 * Handle the given merge event.
 	 *
 	 * @param event The merge event to be handled.
 	 * @throws HibernateException
 	 */
 	public void onMerge(MergeEvent event) throws HibernateException {
 		EventCache copyCache = new EventCache();
 		onMerge( event, copyCache );
 		// TODO: iteratively get transient entities and retry merge until one of the following conditions:
 		//       1) transientCopyCache.size() == 0
 		//       2) transientCopyCache.size() is not decreasing and copyCache.size() is not increasing
 		// TODO: find out if retrying can add entities to copyCache (don't think it can...)
 		// For now, just retry once; throw TransientObjectException if there are still any transient entities
 		Map transientCopyCache = getTransientCopyCache(event, copyCache );
 		if ( transientCopyCache.size() > 0 ) {
 			retryMergeTransientEntities( event, transientCopyCache, copyCache, true );
 			// find any entities that are still transient after retry
 			transientCopyCache = getTransientCopyCache(event, copyCache );
 			if ( transientCopyCache.size() > 0 ) {
 				Set transientEntityNames = new HashSet();
 				for( Iterator it=transientCopyCache.entrySet().iterator(); it.hasNext(); ) {
 					Object transientEntity = ( ( Map.Entry ) it.next() ).getKey();
 					String transientEntityName = event.getSession().guessEntityName( transientEntity );
 					transientEntityNames.add( transientEntityName );
                     LOG.trace("Transient instance could not be processed by merge when checking nullability: "
                               + transientEntityName + "[" + transientEntity + "]");
 				}
                 if (isNullabilityCheckedGlobal(event.getSession())) throw new TransientObjectException(
 						"one or more objects is an unsaved transient instance - save transient instance(s) before merging: " +
 						transientEntityNames );
                 LOG.trace("Retry saving transient instances without checking nullability");
                 // failures will be detected later...
                 retryMergeTransientEntities(event, transientCopyCache, copyCache, false);
 			}
 		}
 		copyCache.clear();
 		copyCache = null;
 	}
 
 	protected EventCache getTransientCopyCache(MergeEvent event, EventCache copyCache) {
 		EventCache transientCopyCache = new EventCache();
 		for ( Iterator it=copyCache.entrySet().iterator(); it.hasNext(); ) {
 			Map.Entry mapEntry = ( Map.Entry ) it.next();
 			Object entity = mapEntry.getKey();
 			Object copy = mapEntry.getValue();
 			if ( copy instanceof HibernateProxy ) {
 				copy = ( (HibernateProxy) copy ).getHibernateLazyInitializer().getImplementation();
 			}
 			EntityEntry copyEntry = event.getSession().getPersistenceContext().getEntry( copy );
 			if ( copyEntry == null ) {
 				// entity name will not be available for non-POJO entities
 				// TODO: cache the entity name somewhere so that it is available to this exception
                 LOG.trace("Transient instance could not be processed by merge: " + event.getSession().guessEntityName(copy) + "["
                           + entity + "]");
 				// merge did not cascade to this entity; it's in copyCache because a
 				// different entity has a non-nullable reference to this entity;
 				// this entity should not be put in transientCopyCache, because it was
 				// not included in the merge;
 				// if the global setting for checking nullability is false, the non-nullable
 				// reference to this entity will be detected later
 				if ( isNullabilityCheckedGlobal( event.getSession() ) ) {
 					throw new TransientObjectException(
 						"object is an unsaved transient instance - save the transient instance before merging: " +
 							event.getSession().guessEntityName( copy )
 					);
 				}
 			}
 			else if ( copyEntry.getStatus() == Status.SAVING ) {
 				transientCopyCache.put( entity, copy, copyCache.isOperatedOn( entity ) );
 			}
 			else if ( copyEntry.getStatus() != Status.MANAGED && copyEntry.getStatus() != Status.READ_ONLY ) {
 				throw new AssertionFailure( "Merged entity does not have status set to MANAGED or READ_ONLY; "+copy+" status="+copyEntry.getStatus() );
 			}
 		}
 		return transientCopyCache;
 	}
 
 	protected void retryMergeTransientEntities(
 			MergeEvent event,
 			Map transientCopyCache,
 			EventCache copyCache,
 			boolean isNullabilityChecked) {
 		// TODO: The order in which entities are saved may matter (e.g., a particular transient entity
 		//       may need to be saved before other transient entities can be saved;
 		//       Keep retrying the batch of transient entities until either:
 		//       1) there are no transient entities left in transientCopyCache
 		//       or 2) no transient entities were saved in the last batch
 		// For now, just run through the transient entities and retry the merge
 		for ( Iterator it=transientCopyCache.entrySet().iterator(); it.hasNext(); ) {
 			Map.Entry mapEntry = ( Map.Entry ) it.next();
 			Object entity = mapEntry.getKey();
 			Object copy = transientCopyCache.get( entity );
 			EntityEntry copyEntry = event.getSession().getPersistenceContext().getEntry( copy );
 			mergeTransientEntity(
 					entity,
 					copyEntry.getEntityName(),
 					( entity == event.getEntity() ? event.getRequestedId() : copyEntry.getId() ),
 					event.getSession(),
 					copyCache,
 					isNullabilityChecked
 			);
 		}
 	}
 
 	/**
 	 * Handle the given merge event.
 	 *
 	 * @param event The merge event to be handled.
 	 * @throws HibernateException
 	 */
 	public void onMerge(MergeEvent event, Map copiedAlready) throws HibernateException {
 
 		final EventCache copyCache = ( EventCache ) copiedAlready;
 		final EventSource source = event.getSession();
 		final Object original = event.getOriginal();
 
 		if ( original != null ) {
 
 			final Object entity;
 			if ( original instanceof HibernateProxy ) {
 				LazyInitializer li = ( (HibernateProxy) original ).getHibernateLazyInitializer();
 				if ( li.isUninitialized() ) {
                     LOG.trace("Ignoring uninitialized proxy");
 					event.setResult( source.load( li.getEntityName(), li.getIdentifier() ) );
 					return; //EARLY EXIT!
 				}
 				else {
 					entity = li.getImplementation();
 				}
 			}
 			else {
 				entity = original;
 			}
 
 			if ( copyCache.containsKey( entity ) &&
 					( copyCache.isOperatedOn( entity ) ) ) {
                 LOG.trace("Already in merge process");
 				event.setResult( entity );
 			}
 			else {
 				if ( copyCache.containsKey( entity ) ) {
                     LOG.trace("Already in copyCache; setting in merge process");
 					copyCache.setOperatedOn( entity, true );
 				}
 				event.setEntity( entity );
 				int entityState = -1;
 
 				// Check the persistence context for an entry relating to this
 				// entity to be merged...
 				EntityEntry entry = source.getPersistenceContext().getEntry( entity );
 				if ( entry == null ) {
 					EntityPersister persister = source.getEntityPersister( event.getEntityName(), entity );
 					Serializable id = persister.getIdentifier( entity, source );
 					if ( id != null ) {
 						final EntityKey key = source.generateEntityKey( id, persister );
 						final Object managedEntity = source.getPersistenceContext().getEntity( key );
 						entry = source.getPersistenceContext().getEntry( managedEntity );
 						if ( entry != null ) {
 							// we have specialized case of a detached entity from the
 							// perspective of the merge operation.  Specifically, we
 							// have an incoming entity instance which has a corresponding
 							// entry in the current persistence context, but registered
 							// under a different entity instance
 							entityState = DETACHED;
 						}
 					}
 				}
 
 				if ( entityState == -1 ) {
 					entityState = getEntityState( entity, event.getEntityName(), entry, source );
 				}
 
 				switch (entityState) {
 					case DETACHED:
 						entityIsDetached(event, copyCache);
 						break;
 					case TRANSIENT:
 						entityIsTransient(event, copyCache);
 						break;
 					case PERSISTENT:
 						entityIsPersistent(event, copyCache);
 						break;
 					default: //DELETED
 						throw new ObjectDeletedException(
 								"deleted instance passed to merge",
 								null,
 								getLoggableName( event.getEntityName(), entity )
 							);
 				}
 			}
 
 		}
 
 	}
 
 	protected void entityIsPersistent(MergeEvent event, Map copyCache) {
         LOG.trace("Ignoring persistent instance");
 
 		//TODO: check that entry.getIdentifier().equals(requestedId)
 
 		final Object entity = event.getEntity();
 		final EventSource source = event.getSession();
 		final EntityPersister persister = source.getEntityPersister( event.getEntityName(), entity );
 
 		( ( EventCache ) copyCache ).put( entity, entity, true  );  //before cascade!
 
 		cascadeOnMerge(source, persister, entity, copyCache);
 		copyValues(persister, entity, entity, source, copyCache);
 
 		event.setResult(entity);
 	}
 
 	protected void entityIsTransient(MergeEvent event, Map copyCache) {
 
         LOG.trace("Merging transient instance");
 
 		final Object entity = event.getEntity();
 		final EventSource source = event.getSession();
 
 		final EntityPersister persister = source.getEntityPersister( event.getEntityName(), entity );
 		final String entityName = persister.getEntityName();
 
 		event.setResult( mergeTransientEntity( entity, entityName, event.getRequestedId(), source, copyCache, true ) );
 	}
 
 	protected Object mergeTransientEntity(Object entity, String entityName, Serializable requestedId, EventSource source, Map copyCache) {
 		return mergeTransientEntity( entity, entityName, requestedId, source, copyCache, true );
 	}
 
 	private Object mergeTransientEntity(
 			Object entity,
 			String entityName,
 			Serializable requestedId,
 			EventSource source,
 			Map copyCache,
 			boolean isNullabilityChecked) {
 
         LOG.trace("Merging transient instance");
 
 		final EntityPersister persister = source.getEntityPersister( entityName, entity );
 
 		final Serializable id = persister.hasIdentifierProperty() ?
 				persister.getIdentifier( entity, source ) :
 		        null;
 		if ( copyCache.containsKey( entity ) ) {
 			persister.setIdentifier( copyCache.get( entity ), id, source );
 		}
 		else {
 			( ( EventCache ) copyCache ).put( entity, source.instantiate( persister, id ), true ); //before cascade!
 		}
 		final Object copy = copyCache.get( entity );
 
 		// cascade first, so that all unsaved objects get their
 		// copy created before we actually copy
 		//cascadeOnMerge(event, persister, entity, copyCache, Cascades.CASCADE_BEFORE_MERGE);
 		super.cascadeBeforeSave(source, persister, entity, copyCache);
 		copyValues(persister, entity, copy, source, copyCache, ForeignKeyDirection.FOREIGN_KEY_FROM_PARENT);
 
 		try {
 			// try saving; check for non-nullable properties that are null or transient entities before saving
 			saveTransientEntity( copy, entityName, requestedId, source, copyCache, isNullabilityChecked );
 		}
 		catch (PropertyValueException ex) {
 			String propertyName = ex.getPropertyName();
 			Object propertyFromCopy = persister.getPropertyValue( copy, propertyName, source.getEntityMode() );
 			Object propertyFromEntity = persister.getPropertyValue( entity, propertyName, source.getEntityMode() );
 			Type propertyType = persister.getPropertyType( propertyName );
 			EntityEntry copyEntry = source.getPersistenceContext().getEntry( copy );
 			if ( propertyFromCopy == null ||
 					propertyFromEntity == null ||
 					! propertyType.isEntityType() ||
 					! copyCache.containsKey( propertyFromEntity ) ) {
 				if ( LOG.isTraceEnabled() ) {
                     LOG.trace("Property '" + copyEntry.getEntityName() + "." + propertyName + "' in copy is "
                               + (propertyFromCopy == null ? "null" : propertyFromCopy));
                     LOG.trace("Property '" + copyEntry.getEntityName() + "." + propertyName + "' in original is "
                               + (propertyFromCopy == null ? "null" : propertyFromCopy));
                     LOG.trace("Property '" + copyEntry.getEntityName() + "." + propertyName + "' is"
                               + (propertyType.isEntityType() ? "" : " not") + " an entity type");
                     if (propertyFromEntity != null && !copyCache.containsKey(propertyFromEntity)) LOG.trace("Property '"
                                                                                                             + copyEntry.getEntityName()
                                                                                                             + "."
                                                                                                             + propertyName
                                                                                                             + "' is not in copy cache");
 	            }
                 if ( isNullabilityCheckedGlobal( source ) ) {
                     throw ex;
                 }
                 else {
                     // retry save w/o checking for non-nullable properties
                     // (the failure will be detected later)
                     saveTransientEntity( copy, entityName, requestedId, source, copyCache, false );
 				}
 			}
 			if ( LOG.isTraceEnabled() && propertyFromEntity != null ) {
                 if (((EventCache)copyCache).isOperatedOn(propertyFromEntity)) LOG.trace("Property '"
                                                                                         + copyEntry.getEntityName()
                                                                                         + "."
                                                                                         + propertyName
                                                                                         + "' from original entity is in copyCache and is in the process of being merged; "
                                                                                         + propertyName + " =[" + propertyFromEntity
                                                                                         + "]");
                 else LOG.trace("Property '" + copyEntry.getEntityName() + "." + propertyName
                                + "' from original entity is in copyCache and is not in the process of being merged; "
                                + propertyName + " =[" + propertyFromEntity + "]");
 			}
 			// continue...; we'll find out if it ends up not getting saved later
 		}
 
 		// cascade first, so that all unsaved objects get their
 		// copy created before we actually copy
 		super.cascadeAfterSave(source, persister, entity, copyCache);
 		copyValues(persister, entity, copy, source, copyCache, ForeignKeyDirection.FOREIGN_KEY_TO_PARENT);
 
 		return copy;
 
 	}
 
 	private boolean isNullabilityCheckedGlobal(EventSource source) {
 		return source.getFactory().getSettings().isCheckNullability();
 	}
 
 	private void saveTransientEntity(
 			Object entity,
 			String entityName,
 			Serializable requestedId,
 			EventSource source,
 			Map copyCache,
 			boolean isNullabilityChecked) {
 
 		boolean isNullabilityCheckedOrig =
 			source.getFactory().getSettings().isCheckNullability();
 		try {
 			source.getFactory().getSettings().setCheckNullability( isNullabilityChecked );
 			//this bit is only *really* absolutely necessary for handling
 			//requestedId, but is also good if we merge multiple object
 			//graphs, since it helps ensure uniqueness
 			if (requestedId==null) {
 				saveWithGeneratedId( entity, entityName, copyCache, source, false );
 			}
 			else {
 				saveWithRequestedId( entity, requestedId, entityName, copyCache, source );
 			}
 		}
 		finally {
 			source.getFactory().getSettings().setCheckNullability( isNullabilityCheckedOrig );
 		}
 	}
 	protected void entityIsDetached(MergeEvent event, Map copyCache) {
 
         LOG.trace("Merging detached instance");
 
 		final Object entity = event.getEntity();
 		final EventSource source = event.getSession();
 
 		final EntityPersister persister = source.getEntityPersister( event.getEntityName(), entity );
 		final String entityName = persister.getEntityName();
 
 		Serializable id = event.getRequestedId();
 		if ( id == null ) {
 			id = persister.getIdentifier( entity, source );
 		}
 		else {
 			// check that entity id = requestedId
 			Serializable entityId = persister.getIdentifier( entity, source );
 			if ( !persister.getIdentifierType().isEqual( id, entityId, source.getEntityMode(), source.getFactory() ) ) {
 				throw new HibernateException( "merge requested with id not matching id of passed entity" );
 			}
 		}
 
 		String previousFetchProfile = source.getFetchProfile();
 		source.setFetchProfile("merge");
 		//we must clone embedded composite identifiers, or
 		//we will get back the same instance that we pass in
 		final Serializable clonedIdentifier = (Serializable) persister.getIdentifierType()
 				.deepCopy( id, source.getEntityMode(), source.getFactory() );
 		final Object result = source.get(entityName, clonedIdentifier);
 		source.setFetchProfile(previousFetchProfile);
 
 		if ( result == null ) {
 			//TODO: we should throw an exception if we really *know* for sure
 			//      that this is a detached instance, rather than just assuming
 			//throw new StaleObjectStateException(entityName, id);
 
 			// we got here because we assumed that an instance
 			// with an assigned id was detached, when it was
 			// really persistent
 			entityIsTransient(event, copyCache);
 		}
 		else {
 			( ( EventCache ) copyCache ).put( entity, result, true ); //before cascade!
 
 			final Object target = source.getPersistenceContext().unproxy(result);
 			if ( target == entity ) {
 				throw new AssertionFailure("entity was not detached");
 			}
 			else if ( !source.getEntityName(target).equals(entityName) ) {
 				throw new WrongClassException(
 						"class of the given object did not match class of persistent copy",
 						event.getRequestedId(),
 						entityName
 					);
 			}
 			else if ( isVersionChanged( entity, source, persister, target ) ) {
 				if ( source.getFactory().getStatistics().isStatisticsEnabled() ) {
 					source.getFactory().getStatisticsImplementor()
 							.optimisticFailure( entityName );
 				}
 				throw new StaleObjectStateException( entityName, id );
 			}
 
 			// cascade first, so that all unsaved objects get their
 			// copy created before we actually copy
 			cascadeOnMerge(source, persister, entity, copyCache);
 			copyValues(persister, entity, target, source, copyCache);
 
 			//copyValues works by reflection, so explicitly mark the entity instance dirty
 			markInterceptorDirty( entity, target );
 
 			event.setResult(result);
 		}
 
 	}
 
 	private void markInterceptorDirty(final Object entity, final Object target) {
 		if ( FieldInterceptionHelper.isInstrumented( entity ) ) {
 			FieldInterceptor interceptor = FieldInterceptionHelper.extractFieldInterceptor( target );
 			if ( interceptor != null ) {
 				interceptor.dirty();
 			}
 		}
 	}
 
 	private boolean isVersionChanged(Object entity, EventSource source, EntityPersister persister, Object target) {
 		if ( ! persister.isVersioned() ) {
 			return false;
 		}
 		// for merging of versioned entities, we consider the version having
 		// been changed only when:
 		// 1) the two version values are different;
 		//      *AND*
 		// 2) The target actually represents database state!
 		//
 		// This second condition is a special case which allows
 		// an entity to be merged during the same transaction
 		// (though during a seperate operation) in which it was
 		// originally persisted/saved
 		boolean changed = ! persister.getVersionType().isSame(
 				persister.getVersion( target, source.getEntityMode() ),
 				persister.getVersion( entity, source.getEntityMode() ),
 				source.getEntityMode()
 		);
 
 		// TODO : perhaps we should additionally require that the incoming entity
 		// version be equivalent to the defined unsaved-value?
 		return changed && existsInDatabase( target, source, persister );
 	}
 
 	private boolean existsInDatabase(Object entity, EventSource source, EntityPersister persister) {
 		EntityEntry entry = source.getPersistenceContext().getEntry( entity );
 		if ( entry == null ) {
 			Serializable id = persister.getIdentifier( entity, source );
 			if ( id != null ) {
 				final EntityKey key = source.generateEntityKey( id, persister );
 				final Object managedEntity = source.getPersistenceContext().getEntity( key );
 				entry = source.getPersistenceContext().getEntry( managedEntity );
 			}
 		}
 
 		return entry != null && entry.isExistsInDatabase();
 	}
 
 	protected void copyValues(
 			final EntityPersister persister,
 			final Object entity,
 			final Object target,
 			final SessionImplementor source,
 			final Map copyCache) {
 		final Object[] copiedValues = TypeHelper.replace(
 				persister.getPropertyValues( entity, source.getEntityMode() ),
 				persister.getPropertyValues( target, source.getEntityMode() ),
 				persister.getPropertyTypes(),
 				source,
 				target,
 				copyCache
 		);
 
 		persister.setPropertyValues( target, copiedValues, source.getEntityMode() );
 	}
 
 	protected void copyValues(
 			final EntityPersister persister,
 			final Object entity,
 			final Object target,
 			final SessionImplementor source,
 			final Map copyCache,
 			final ForeignKeyDirection foreignKeyDirection) {
 
 		final Object[] copiedValues;
 
 		if ( foreignKeyDirection == ForeignKeyDirection.FOREIGN_KEY_TO_PARENT ) {
 			// this is the second pass through on a merge op, so here we limit the
 			// replacement to associations types (value types were already replaced
 			// during the first pass)
 			copiedValues = TypeHelper.replaceAssociations(
 					persister.getPropertyValues( entity, source.getEntityMode() ),
 					persister.getPropertyValues( target, source.getEntityMode() ),
 					persister.getPropertyTypes(),
 					source,
 					target,
 					copyCache,
 					foreignKeyDirection
 			);
 		}
 		else {
 			copiedValues = TypeHelper.replace(
 					persister.getPropertyValues( entity, source.getEntityMode() ),
 					persister.getPropertyValues( target, source.getEntityMode() ),
 					persister.getPropertyTypes(),
 					source,
 					target,
 					copyCache,
 					foreignKeyDirection
 			);
 		}
 
 		persister.setPropertyValues( target, copiedValues, source.getEntityMode() );
 	}
 
 	/**
 	 * Perform any cascades needed as part of this copy event.
 	 *
 	 * @param source The merge event being processed.
 	 * @param persister The persister of the entity being copied.
 	 * @param entity The entity being copied.
 	 * @param copyCache A cache of already copied instance.
 	 */
 	protected void cascadeOnMerge(
 		final EventSource source,
 		final EntityPersister persister,
 		final Object entity,
 		final Map copyCache
 	) {
 		source.getPersistenceContext().incrementCascadeLevel();
 		try {
 			new Cascade( getCascadeAction(), Cascade.BEFORE_MERGE, source )
 					.cascade(persister, entity, copyCache);
 		}
 		finally {
 			source.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 
 	@Override
     protected CascadingAction getCascadeAction() {
 		return CascadingAction.MERGE;
 	}
 
 	@Override
     protected Boolean getAssumedUnsaved() {
 		return Boolean.FALSE;
 	}
 
 	/**
 	 * Cascade behavior is redefined by this subclass, disable superclass behavior
 	 */
 	@Override
     protected void cascadeAfterSave(EventSource source, EntityPersister persister, Object entity, Object anything)
 	throws HibernateException {
 	}
 
 	/**
 	 * Cascade behavior is redefined by this subclass, disable superclass behavior
 	 */
 	@Override
     protected void cascadeBeforeSave(EventSource source, EntityPersister persister, Object entity, Object anything)
 	throws HibernateException {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultPersistEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultPersistEventListener.java
index 0821e9d796..3ccda95fcc 100755
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultPersistEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultPersistEventListener.java
@@ -1,190 +1,191 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.util.Map;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.PersistentObjectException;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.PersistEvent;
 import org.hibernate.event.PersistEventListener;
 import org.hibernate.id.ForeignGenerator;
 import org.hibernate.internal.util.collections.IdentityMap;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
+
 import org.jboss.logging.Logger;
 
 /**
  * Defines the default create event listener used by hibernate for creating
  * transient entities in response to generated create events.
  *
  * @author Gavin King
  */
 public class DefaultPersistEventListener extends AbstractSaveEventListener implements PersistEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultPersistEventListener.class.getName());
 
 	/**
 	 * Handle the given create event.
 	 *
 	 * @param event The create event to be handled.
 	 * @throws HibernateException
 	 */
 	public void onPersist(PersistEvent event) throws HibernateException {
 		onPersist( event, IdentityMap.instantiate(10) );
 	}
 
 
 	/**
 	 * Handle the given create event.
 	 *
 	 * @param event The create event to be handled.
 	 * @throws HibernateException
 	 */
 	public void onPersist(PersistEvent event, Map createCache) throws HibernateException {
 		final SessionImplementor source = event.getSession();
 		final Object object = event.getObject();
 
 		final Object entity;
 		if ( object instanceof HibernateProxy ) {
 			LazyInitializer li = ( (HibernateProxy) object ).getHibernateLazyInitializer();
 			if ( li.isUninitialized() ) {
 				if ( li.getSession() == source ) {
 					return; //NOTE EARLY EXIT!
 				}
 				else {
 					throw new PersistentObjectException( "uninitialized proxy passed to persist()" );
 				}
 			}
 			entity = li.getImplementation();
 		}
 		else {
 			entity = object;
 		}
 
 		final String entityName;
 		if ( event.getEntityName() != null ) {
 			entityName = event.getEntityName();
 		}
 		else {
 			entityName = source.bestGuessEntityName( entity );
 			event.setEntityName( entityName );
 		}
 
 		final EntityEntry entityEntry = source.getPersistenceContext().getEntry( entity );
 		int entityState = getEntityState( entity, entityName, entityEntry, source );
 		if ( entityState == DETACHED ) {
 			// JPA 2, in its version of a "foreign generated", allows the id attribute value
 			// to be manually set by the user, even though this manual value is irrelevant.
 			// The issue is that this causes problems with the Hibernate unsaved-value strategy
 			// which comes into play here in determining detached/transient state.
 			//
 			// Detect if we have this situation and if so null out the id value and calculate the
 			// entity state again.
 
 			// NOTE: entityEntry must be null to get here, so we cannot use any of its values
 			EntityPersister persister = source.getFactory().getEntityPersister( entityName );
 			if ( ForeignGenerator.class.isInstance( persister.getIdentifierGenerator() ) ) {
                 if (LOG.isDebugEnabled() && persister.getIdentifier(entity, source) != null) LOG.debugf("Resetting entity id attribute to null for foreign generator");
 				persister.setIdentifier( entity, null, source );
 				entityState = getEntityState( entity, entityName, entityEntry, source );
 			}
 		}
 
 		switch ( entityState ) {
 			case DETACHED:
 				throw new PersistentObjectException(
 						"detached entity passed to persist: " +
 								getLoggableName( event.getEntityName(), entity )
 				);
 			case PERSISTENT:
 				entityIsPersistent( event, createCache );
 				break;
 			case TRANSIENT:
 				entityIsTransient( event, createCache );
 				break;
 			default:
 				throw new ObjectDeletedException(
 						"deleted entity passed to persist",
 						null,
 						getLoggableName( event.getEntityName(), entity )
 				);
 		}
 
 	}
 
 	protected void entityIsPersistent(PersistEvent event, Map createCache) {
         LOG.trace("Ignoring persistent instance");
 		final EventSource source = event.getSession();
 
 		//TODO: check that entry.getIdentifier().equals(requestedId)
 
 		final Object entity = source.getPersistenceContext().unproxy( event.getObject() );
 		final EntityPersister persister = source.getEntityPersister( event.getEntityName(), entity );
 
 		if ( createCache.put(entity, entity)==null ) {
 			//TODO: merge into one method!
 			cascadeBeforeSave(source, persister, entity, createCache);
 			cascadeAfterSave(source, persister, entity, createCache);
 		}
 
 	}
 
 	/**
 	 * Handle the given create event.
 	 *
 	 * @param event The save event to be handled.
 	 * @throws HibernateException
 	 */
 	protected void entityIsTransient(PersistEvent event, Map createCache) throws HibernateException {
 
         LOG.trace("Saving transient instance");
 
 		final EventSource source = event.getSession();
 
 		final Object entity = source.getPersistenceContext().unproxy( event.getObject() );
 
 		if ( createCache.put(entity, entity)==null ) {
 			saveWithGeneratedId( entity, event.getEntityName(), createCache, source, false );
 		}
 
 	}
 
 	@Override
     protected CascadingAction getCascadeAction() {
 		return CascadingAction.PERSIST;
 	}
 
 	@Override
     protected Boolean getAssumedUnsaved() {
 		return Boolean.TRUE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultRefreshEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultRefreshEventListener.java
index 5e9d626214..37cd79cfe9 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultRefreshEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultRefreshEventListener.java
@@ -1,176 +1,176 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.PersistentObjectException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.RefreshEvent;
 import org.hibernate.event.RefreshEventListener;
 import org.hibernate.internal.util.collections.IdentityMap;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 
 /**
  * Defines the default refresh event listener used by hibernate for refreshing entities
  * in response to generated refresh events.
  *
  * @author Steve Ebersole
  */
 public class DefaultRefreshEventListener implements RefreshEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultRefreshEventListener.class.getName());
 
 	public void onRefresh(RefreshEvent event) throws HibernateException {
 		onRefresh( event, IdentityMap.instantiate(10) );
 	}
 
 	/**
 	 * Handle the given refresh event.
 	 *
 	 * @param event The refresh event to be handled.
 	 */
 	public void onRefresh(RefreshEvent event, Map refreshedAlready) {
 
 		final EventSource source = event.getSession();
 
 		boolean isTransient = ! source.contains( event.getObject() );
 		if ( source.getPersistenceContext().reassociateIfUninitializedProxy( event.getObject() ) ) {
 			if ( isTransient ) {
 				source.setReadOnly( event.getObject(), source.isDefaultReadOnly() );
 			}
 			return;
 		}
 
 		final Object object = source.getPersistenceContext().unproxyAndReassociate( event.getObject() );
 
 		if ( refreshedAlready.containsKey(object) ) {
             LOG.trace("Already refreshed");
 			return;
 		}
 
 		final EntityEntry e = source.getPersistenceContext().getEntry( object );
 		final EntityPersister persister;
 		final Serializable id;
 
 		if ( e == null ) {
 			persister = source.getEntityPersister(null, object); //refresh() does not pass an entityName
 			id = persister.getIdentifier( object, event.getSession() );
             if (LOG.isTraceEnabled()) LOG.trace("Refreshing transient "
                                                 + MessageHelper.infoString(persister, id, source.getFactory()));
 			final EntityKey key = source.generateEntityKey( id, persister );
 			if ( source.getPersistenceContext().getEntry(key) != null ) {
 				throw new PersistentObjectException(
 						"attempted to refresh transient instance when persistent instance was already associated with the Session: " +
 						MessageHelper.infoString(persister, id, source.getFactory() )
 					);
 			}
 		}
 		else {
             if (LOG.isTraceEnabled()) LOG.trace("Refreshing "
                                                 + MessageHelper.infoString(e.getPersister(), e.getId(), source.getFactory()));
 			if ( !e.isExistsInDatabase() ) {
 				throw new HibernateException( "this instance does not yet exist as a row in the database" );
 			}
 
 			persister = e.getPersister();
 			id = e.getId();
 		}
 
 		// cascade the refresh prior to refreshing this entity
 		refreshedAlready.put(object, object);
 		new Cascade(CascadingAction.REFRESH, Cascade.BEFORE_REFRESH, source)
 				.cascade( persister, object, refreshedAlready );
 
 		if ( e != null ) {
 			final EntityKey key = source.generateEntityKey( id, persister );
 			source.getPersistenceContext().removeEntity(key);
 			if ( persister.hasCollections() ) new EvictVisitor( source ).process(object, persister);
 		}
 
 		if ( persister.hasCache() ) {
 			final CacheKey ck = source.generateCacheKey(
 					id,
 					persister.getIdentifierType(),
 					persister.getRootEntityName()
 			);
 			persister.getCacheAccessStrategy().evict( ck );
 		}
 
 		evictCachedCollections( persister, id, source.getFactory() );
 
 		String previousFetchProfile = source.getFetchProfile();
 		source.setFetchProfile("refresh");
 		Object result = persister.load( id, object, event.getLockOptions(), source );
 		// Keep the same read-only/modifiable setting for the entity that it had before refreshing;
 		// If it was transient, then set it to the default for the source.
 		if ( result != null ) {
 			if ( ! persister.isMutable() ) {
 				// this is probably redundant; it should already be read-only
 				source.setReadOnly( result, true );
 			}
 			else {
 				source.setReadOnly( result, ( e == null ? source.isDefaultReadOnly() : e.isReadOnly() ) );
 			}
 		}
 		source.setFetchProfile(previousFetchProfile);
 
 		UnresolvableObjectException.throwIfNull( result, id, persister.getEntityName() );
 
 	}
 
 	private void evictCachedCollections(EntityPersister persister, Serializable id, SessionFactoryImplementor factory) {
 		evictCachedCollections( persister.getPropertyTypes(), id, factory );
 	}
 
 	private void evictCachedCollections(Type[] types, Serializable id, SessionFactoryImplementor factory)
 	throws HibernateException {
 		for ( int i = 0; i < types.length; i++ ) {
 			if ( types[i].isCollectionType() ) {
 				factory.evictCollection( ( (CollectionType) types[i] ).getRole(), id );
 			}
 			else if ( types[i].isComponentType() ) {
 				CompositeType actype = (CompositeType) types[i];
 				evictCachedCollections( actype.getSubtypes(), id, factory );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultReplicateEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultReplicateEventListener.java
index 871972b45a..28ac584388 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultReplicateEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultReplicateEventListener.java
@@ -1,216 +1,216 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.ReplicationMode;
 import org.hibernate.TransientObjectException;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.ReplicateEvent;
 import org.hibernate.event.ReplicateEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 /**
  * Defines the default replicate event listener used by Hibernate to replicate
  * entities in response to generated replicate events.
  *
  * @author Steve Ebersole
  */
 public class DefaultReplicateEventListener extends AbstractSaveEventListener implements ReplicateEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultReplicateEventListener.class.getName());
 
 	/**
 	 * Handle the given replicate event.
 	 *
 	 * @param event The replicate event to be handled.
 	 *
 	 * @throws TransientObjectException An invalid attempt to replicate a transient entity.
 	 */
 	public void onReplicate(ReplicateEvent event) {
 		final EventSource source = event.getSession();
 		if ( source.getPersistenceContext().reassociateIfUninitializedProxy( event.getObject() ) ) {
             LOG.trace("Uninitialized proxy passed to replicate()");
 			return;
 		}
 
 		Object entity = source.getPersistenceContext().unproxyAndReassociate( event.getObject() );
 
 		if ( source.getPersistenceContext().isEntryFor( entity ) ) {
             LOG.trace("Ignoring persistent instance passed to replicate()");
 			//hum ... should we cascade anyway? throw an exception? fine like it is?
 			return;
 		}
 
 		EntityPersister persister = source.getEntityPersister( event.getEntityName(), entity );
 
 		// get the id from the object
 		/*if ( persister.isUnsaved(entity, source) ) {
 			throw new TransientObjectException("transient instance passed to replicate()");
 		}*/
 		Serializable id = persister.getIdentifier( entity, source );
 		if ( id == null ) {
 			throw new TransientObjectException( "instance with null id passed to replicate()" );
 		}
 
 		final ReplicationMode replicationMode = event.getReplicationMode();
 
 		final Object oldVersion;
 		if ( replicationMode == ReplicationMode.EXCEPTION ) {
 			//always do an INSERT, and let it fail by constraint violation
 			oldVersion = null;
 		}
 		else {
 			//what is the version on the database?
 			oldVersion = persister.getCurrentVersion( id, source );
 		}
 
 		if ( oldVersion != null ) {
             if (LOG.isTraceEnabled()) LOG.trace("Found existing row for "
                                                 + MessageHelper.infoString(persister, id, source.getFactory()));
 
 			/// HHH-2378
 			final Object realOldVersion = persister.isVersioned() ? oldVersion : null;
 
 			boolean canReplicate = replicationMode.shouldOverwriteCurrentVersion(
 					entity,
 					realOldVersion,
 					persister.getVersion( entity, source.getEntityMode() ),
 					persister.getVersionType()
 			);
 
             // if can replicate, will result in a SQL UPDATE
             // else do nothing (don't even reassociate object!)
             if (canReplicate) performReplication(entity, id, realOldVersion, persister, replicationMode, source);
             else LOG.trace("No need to replicate");
 
 			//TODO: would it be better to do a refresh from db?
 		}
 		else {
 			// no existing row - do an insert
             if (LOG.isTraceEnabled()) LOG.trace("No existing row, replicating new instance "
                                                 + MessageHelper.infoString(persister, id, source.getFactory()));
 
 			final boolean regenerate = persister.isIdentifierAssignedByInsert(); // prefer re-generation of identity!
 			final EntityKey key = regenerate ? null : source.generateEntityKey( id, persister );
 
 			performSaveOrReplicate(
 					entity,
 					key,
 					persister,
 					regenerate,
 					replicationMode,
 					source,
 					true
 			);
 
 		}
 	}
 
 	@Override
     protected boolean visitCollectionsBeforeSave(Object entity, Serializable id, Object[] values, Type[] types, EventSource source) {
 		//TODO: we use two visitors here, inefficient!
 		OnReplicateVisitor visitor = new OnReplicateVisitor( source, id, entity, false );
 		visitor.processEntityPropertyValues( values, types );
 		return super.visitCollectionsBeforeSave( entity, id, values, types, source );
 	}
 
 	@Override
     protected boolean substituteValuesIfNecessary(
 			Object entity,
 			Serializable id,
 			Object[] values,
 			EntityPersister persister,
 			SessionImplementor source) {
 		return false;
 	}
 
 	@Override
     protected boolean isVersionIncrementDisabled() {
 		return true;
 	}
 
 	private void performReplication(
 			Object entity,
 			Serializable id,
 			Object version,
 			EntityPersister persister,
 			ReplicationMode replicationMode,
 			EventSource source) throws HibernateException {
 
         if (LOG.isTraceEnabled()) LOG.trace("Replicating changes to "
                                             + MessageHelper.infoString(persister, id, source.getFactory()));
 
 		new OnReplicateVisitor( source, id, entity, true ).process( entity, persister );
 
 		source.getPersistenceContext().addEntity(
 				entity,
 				( persister.isMutable() ? Status.MANAGED : Status.READ_ONLY ),
 				null,
 				source.generateEntityKey( id, persister ),
 				version,
 				LockMode.NONE,
 				true,
 				persister,
 				true,
 				false
 		);
 
 		cascadeAfterReplicate( entity, persister, replicationMode, source );
 	}
 
 	private void cascadeAfterReplicate(
 			Object entity,
 			EntityPersister persister,
 			ReplicationMode replicationMode,
 			EventSource source) {
 		source.getPersistenceContext().incrementCascadeLevel();
 		try {
 			new Cascade( CascadingAction.REPLICATE, Cascade.AFTER_UPDATE, source )
 					.cascade( persister, entity, replicationMode );
 		}
 		finally {
 			source.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 	@Override
     protected CascadingAction getCascadeAction() {
 		return CascadingAction.REPLICATE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultSaveOrUpdateEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultSaveOrUpdateEventListener.java
index e8d9d7b565..02bd34629e 100755
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultSaveOrUpdateEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultSaveOrUpdateEventListener.java
@@ -1,365 +1,365 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.PersistentObjectException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.SaveOrUpdateEvent;
 import org.hibernate.event.SaveOrUpdateEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 
 /**
  * Defines the default listener used by Hibernate for handling save-update
  * events.
  *
  * @author Steve Ebersole
  * @author Gavin King
  */
 public class DefaultSaveOrUpdateEventListener extends AbstractSaveEventListener implements SaveOrUpdateEventListener {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultSaveOrUpdateEventListener.class.getName());
 
 	/**
 	 * Handle the given update event.
 	 *
 	 * @param event The update event to be handled.
 	 */
 	public void onSaveOrUpdate(SaveOrUpdateEvent event) {
 		final SessionImplementor source = event.getSession();
 		final Object object = event.getObject();
 		final Serializable requestedId = event.getRequestedId();
 
 		if ( requestedId != null ) {
 			//assign the requested id to the proxy, *before*
 			//reassociating the proxy
 			if ( object instanceof HibernateProxy ) {
 				( ( HibernateProxy ) object ).getHibernateLazyInitializer().setIdentifier( requestedId );
 			}
 		}
 
         // For an uninitialized proxy, noop, don't even need to return an id, since it is never a save()
         if (reassociateIfUninitializedProxy(object, source)) LOG.trace("Reassociated uninitialized proxy");
 		else {
 			//initialize properties of the event:
 			final Object entity = source.getPersistenceContext().unproxyAndReassociate( object );
 			event.setEntity( entity );
 			event.setEntry( source.getPersistenceContext().getEntry( entity ) );
 			//return the id in the event object
 			event.setResultId( performSaveOrUpdate( event ) );
 		}
 
 	}
 
 	protected boolean reassociateIfUninitializedProxy(Object object, SessionImplementor source) {
 		return source.getPersistenceContext().reassociateIfUninitializedProxy( object );
 	}
 
 	protected Serializable performSaveOrUpdate(SaveOrUpdateEvent event) {
 		int entityState = getEntityState(
 				event.getEntity(),
 				event.getEntityName(),
 				event.getEntry(),
 				event.getSession()
 		);
 
 		switch ( entityState ) {
 			case DETACHED:
 				entityIsDetached( event );
 				return null;
 			case PERSISTENT:
 				return entityIsPersistent( event );
 			default: //TRANSIENT or DELETED
 				return entityIsTransient( event );
 		}
 	}
 
 	protected Serializable entityIsPersistent(SaveOrUpdateEvent event) throws HibernateException {
         LOG.trace("Ignoring persistent instance");
 
 		EntityEntry entityEntry = event.getEntry();
 		if ( entityEntry == null ) {
 			throw new AssertionFailure( "entity was transient or detached" );
 		}
 		else {
 
 			if ( entityEntry.getStatus() == Status.DELETED ) {
 				throw new AssertionFailure( "entity was deleted" );
 			}
 
 			final SessionFactoryImplementor factory = event.getSession().getFactory();
 
 			Serializable requestedId = event.getRequestedId();
 
 			Serializable savedId;
 			if ( requestedId == null ) {
 				savedId = entityEntry.getId();
 			}
 			else {
 
 				final boolean isEqual = !entityEntry.getPersister().getIdentifierType()
 						.isEqual( requestedId, entityEntry.getId(), event.getSession().getEntityMode(), factory );
 
 				if ( isEqual ) {
 					throw new PersistentObjectException(
 							"object passed to save() was already persistent: " +
 									MessageHelper.infoString( entityEntry.getPersister(), requestedId, factory )
 					);
 				}
 
 				savedId = requestedId;
 
 			}
 
             if (LOG.isTraceEnabled()) LOG.trace("Object already associated with session: "
                                                 + MessageHelper.infoString(entityEntry.getPersister(), savedId, factory));
 
 			return savedId;
 
 		}
 	}
 
 	/**
 	 * The given save-update event named a transient entity.
 	 * <p/>
 	 * Here, we will perform the save processing.
 	 *
 	 * @param event The save event to be handled.
 	 *
 	 * @return The entity's identifier after saving.
 	 */
 	protected Serializable entityIsTransient(SaveOrUpdateEvent event) {
 
         LOG.trace("Saving transient instance");
 
 		final EventSource source = event.getSession();
 
 		EntityEntry entityEntry = event.getEntry();
 		if ( entityEntry != null ) {
 			if ( entityEntry.getStatus() == Status.DELETED ) {
 				source.forceFlush( entityEntry );
 			}
 			else {
 				throw new AssertionFailure( "entity was persistent" );
 			}
 		}
 
 		Serializable id = saveWithGeneratedOrRequestedId( event );
 
 		source.getPersistenceContext().reassociateProxy( event.getObject(), id );
 
 		return id;
 	}
 
 	/**
 	 * Save the transient instance, assigning the right identifier
 	 *
 	 * @param event The initiating event.
 	 *
 	 * @return The entity's identifier value after saving.
 	 */
 	protected Serializable saveWithGeneratedOrRequestedId(SaveOrUpdateEvent event) {
 		return saveWithGeneratedId(
 				event.getEntity(),
 				event.getEntityName(),
 				null,
 				event.getSession(),
 				true
 		);
 	}
 
 	/**
 	 * The given save-update event named a detached entity.
 	 * <p/>
 	 * Here, we will perform the update processing.
 	 *
 	 * @param event The update event to be handled.
 	 */
 	protected void entityIsDetached(SaveOrUpdateEvent event) {
 
         LOG.trace("Updating detached instance");
 
 		if ( event.getSession().getPersistenceContext().isEntryFor( event.getEntity() ) ) {
 			//TODO: assertion only, could be optimized away
 			throw new AssertionFailure( "entity was persistent" );
 		}
 
 		Object entity = event.getEntity();
 
 		EntityPersister persister = event.getSession().getEntityPersister( event.getEntityName(), entity );
 
 		event.setRequestedId(
 				getUpdateId(
 						entity, persister, event.getRequestedId(), event.getSession()
 				)
 		);
 
 		performUpdate( event, entity, persister );
 
 	}
 
 	/**
 	 * Determine the id to use for updating.
 	 *
 	 * @param entity The entity.
 	 * @param persister The entity persister
 	 * @param requestedId The requested identifier
 	 * @param session The session
 	 *
 	 * @return The id.
 	 *
 	 * @throws TransientObjectException If the entity is considered transient.
 	 */
 	protected Serializable getUpdateId(
 			Object entity,
 			EntityPersister persister,
 			Serializable requestedId,
 			SessionImplementor session) {
 		// use the id assigned to the instance
 		Serializable id = persister.getIdentifier( entity, session );
 		if ( id == null ) {
 			// assume this is a newly instantiated transient object
 			// which should be saved rather than updated
 			throw new TransientObjectException(
 					"The given object has a null identifier: " +
 							persister.getEntityName()
 			);
 		}
 		else {
 			return id;
 		}
 
 	}
 
 	protected void performUpdate(
 			SaveOrUpdateEvent event,
 			Object entity,
 			EntityPersister persister) throws HibernateException {
 
         if (!persister.isMutable()) LOG.trace("Immutable instance passed to performUpdate()");
 
         if (LOG.isTraceEnabled()) LOG.trace("Updating "
                                             + MessageHelper.infoString(persister,
                                                                        event.getRequestedId(),
                                                                        event.getSession().getFactory()));
 
         final EventSource source = event.getSession();
 		final EntityKey key = source.generateEntityKey( event.getRequestedId(), persister );
 
 		source.getPersistenceContext().checkUniqueness(key, entity);
 
 		if (invokeUpdateLifecycle(entity, persister, source)) {
             reassociate(event, event.getObject(), event.getRequestedId(), persister);
             return;
         }
 
 		// this is a transient object with existing persistent state not loaded by the session
 
 		new OnUpdateVisitor(source, event.getRequestedId(), entity).process(entity, persister);
 
 		// TODO: put this stuff back in to read snapshot from
         // the second-level cache (needs some extra work)
         /*Object[] cachedState = null;
 
         if ( persister.hasCache() ) {
         	CacheEntry entry = (CacheEntry) persister.getCache()
         			.get( event.getRequestedId(), source.getTimestamp() );
             cachedState = entry==null ?
             		null :
             		entry.getState(); //TODO: half-assemble this stuff
         }*/
 
 		source.getPersistenceContext().addEntity(entity, (persister.isMutable() ? Status.MANAGED : Status.READ_ONLY), null, // cachedState,
                                                  key,
                                                  persister.getVersion(entity, source.getEntityMode()),
                                                  LockMode.NONE,
                                                  true,
                                                  persister,
                                                  false,
                                                  true // assume true, since we don't really know, and it doesn't matter
         );
 
 		persister.afterReassociate(entity, source);
 
         if (LOG.isTraceEnabled()) LOG.trace("Updating "
                                             + MessageHelper.infoString(persister, event.getRequestedId(), source.getFactory()));
 
         cascadeOnUpdate(event, persister, entity);
 	}
 
 	protected boolean invokeUpdateLifecycle(Object entity, EntityPersister persister, EventSource source) {
 		if ( persister.implementsLifecycle( source.getEntityMode() ) ) {
             LOG.debugf("Calling onUpdate()");
             if (((Lifecycle)entity).onUpdate(source)) {
                 LOG.debugf("Update vetoed by onUpdate()");
 				return true;
 			}
 		}
 		return false;
 	}
 
 	/**
 	 * Handles the calls needed to perform cascades as part of an update request
 	 * for the given entity.
 	 *
 	 * @param event The event currently being processed.
 	 * @param persister The defined persister for the entity being updated.
 	 * @param entity The entity being updated.
 	 */
 	private void cascadeOnUpdate(SaveOrUpdateEvent event, EntityPersister persister, Object entity) {
 		EventSource source = event.getSession();
 		source.getPersistenceContext().incrementCascadeLevel();
 		try {
 			new Cascade( CascadingAction.SAVE_UPDATE, Cascade.AFTER_UPDATE, source )
 					.cascade( persister, entity );
 		}
 		finally {
 			source.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 	@Override
     protected CascadingAction getCascadeAction() {
 		return CascadingAction.SAVE_UPDATE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/EvictVisitor.java b/hibernate-core/src/main/java/org/hibernate/event/def/EvictVisitor.java
index 6fe2af2904..aa9b89f453 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/EvictVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/EvictVisitor.java
@@ -1,89 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.event.def;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.CollectionEntry;
 import org.hibernate.engine.CollectionKey;
 import org.hibernate.event.EventSource;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.CollectionType;
 import org.jboss.logging.Logger;
 
 /**
  * Evict any collections referenced by the object from the session cache.
  * This will NOT pick up any collections that were dereferenced, so they
  * will be deleted (suboptimal but not exactly incorrect).
  *
  * @author Gavin King
  */
 public class EvictVisitor extends AbstractVisitor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, EvictVisitor.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EvictVisitor.class.getName());
 
 	EvictVisitor(EventSource session) {
 		super(session);
 	}
 
 	@Override
     Object processCollection(Object collection, CollectionType type)
 		throws HibernateException {
 
 		if (collection!=null) evictCollection(collection, type);
 
 		return null;
 	}
 	public void evictCollection(Object value, CollectionType type) {
 
 		final Object pc;
 		if ( type.hasHolder( getSession().getEntityMode() ) ) {
 			pc = getSession().getPersistenceContext().removeCollectionHolder(value);
 		}
 		else if ( value instanceof PersistentCollection ) {
 			pc = value;
 		}
 		else {
 			return; //EARLY EXIT!
 		}
 
 		PersistentCollection collection = (PersistentCollection) pc;
 		if ( collection.unsetSession( getSession() ) ) evictCollection(collection);
 	}
 
 	private void evictCollection(PersistentCollection collection) {
 		CollectionEntry ce = (CollectionEntry) getSession().getPersistenceContext().getCollectionEntries().remove(collection);
         if (LOG.isDebugEnabled()) LOG.debugf("Evicting collection: %s",
                                              MessageHelper.collectionInfoString(ce.getLoadedPersister(),
                                                                                 ce.getLoadedKey(),
                                                                                 getSession().getFactory()));
 		if ( ce.getLoadedPersister() != null && ce.getLoadedKey() != null ) {
 			//TODO: is this 100% correct?
 			getSession().getPersistenceContext().getCollectionsByKey().remove(
 					new CollectionKey( ce.getLoadedPersister(), ce.getLoadedKey(), getSession().getEntityMode() )
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/ReattachVisitor.java b/hibernate-core/src/main/java/org/hibernate/event/def/ReattachVisitor.java
index ee7cf18df8..aed42622f0 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/ReattachVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/ReattachVisitor.java
@@ -1,117 +1,117 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 import java.io.Serializable;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.action.internal.CollectionRemoveAction;
 import org.hibernate.event.EventSource;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Abstract superclass of visitors that reattach collections.
  *
  * @author Gavin King
  */
 public abstract class ReattachVisitor extends ProxyVisitor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ReattachVisitor.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ReattachVisitor.class.getName());
 
 	private final Serializable ownerIdentifier;
 	private final Object owner;
 
 	public ReattachVisitor(EventSource session, Serializable ownerIdentifier, Object owner) {
 		super( session );
 		this.ownerIdentifier = ownerIdentifier;
 		this.owner = owner;
 	}
 
 	/**
 	 * Retrieve the identifier of the entity being visited.
 	 *
 	 * @return The entity's identifier.
 	 */
 	final Serializable getOwnerIdentifier() {
 		return ownerIdentifier;
 	}
 
 	/**
 	 * Retrieve the entity being visited.
 	 *
 	 * @return The entity.
 	 */
 	final Object getOwner() {
 		return owner;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     Object processComponent(Object component, CompositeType componentType) throws HibernateException {
 		Type[] types = componentType.getSubtypes();
 		if ( component == null ) {
 			processValues( new Object[types.length], types );
 		}
 		else {
 			super.processComponent( component, componentType );
 		}
 
 		return null;
 	}
 
 	/**
 	 * Schedules a collection for deletion.
 	 *
 	 * @param role The persister representing the collection to be removed.
 	 * @param collectionKey The collection key (differs from owner-id in the case of property-refs).
 	 * @param source The session from which the request originated.
 	 * @throws HibernateException
 	 */
 	void removeCollection(CollectionPersister role, Serializable collectionKey, EventSource source) throws HibernateException {
         if (LOG.isTraceEnabled()) LOG.trace("Collection dereferenced while transient "
                                             + MessageHelper.collectionInfoString(role, ownerIdentifier, source.getFactory()));
 		source.getActionQueue().addAction( new CollectionRemoveAction( owner, role, collectionKey, false, source ) );
 	}
 
 	/**
 	 * This version is slightly different for say
 	 * {@link org.hibernate.type.CollectionType#getKeyOfOwner} in that here we
 	 * need to assume that the owner is not yet associated with the session,
 	 * and thus we cannot rely on the owner's EntityEntry snapshot...
 	 *
 	 * @param role The persister for the collection role being processed.
 	 * @return
 	 */
 	final Serializable extractCollectionKeyFromOwner(CollectionPersister role) {
         if (role.getCollectionType().useLHSPrimaryKey()) return ownerIdentifier;
         return (Serializable)role.getOwnerEntityPersister().getPropertyValue(owner,
                                                                              role.getCollectionType().getLHSPropertyName(),
                                                                              getSession().getEntityMode());
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/WrapVisitor.java b/hibernate-core/src/main/java/org/hibernate/event/def/WrapVisitor.java
index bf82e1665a..88ba876c57 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/WrapVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/WrapVisitor.java
@@ -1,161 +1,161 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Wrap collections in a Hibernate collection
  * wrapper.
  * @author Gavin King
  */
 public class WrapVisitor extends ProxyVisitor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, WrapVisitor.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, WrapVisitor.class.getName());
 
 	boolean substitute = false;
 
 	boolean isSubstitutionRequired() {
 		return substitute;
 	}
 
 	WrapVisitor(EventSource session) {
 		super(session);
 	}
 
 	@Override
     Object processCollection(Object collection, CollectionType collectionType)
 	throws HibernateException {
 
 		if ( collection!=null && (collection instanceof PersistentCollection) ) {
 
 			final SessionImplementor session = getSession();
 			PersistentCollection coll = (PersistentCollection) collection;
 			if ( coll.setCurrentSession(session) ) {
 				reattachCollection( coll, collectionType );
 			}
 			return null;
 
 		}
 		else {
 			return processArrayOrNewCollection(collection, collectionType);
 		}
 
 	}
 
 	final Object processArrayOrNewCollection(Object collection, CollectionType collectionType)
 	throws HibernateException {
 
 		final SessionImplementor session = getSession();
 
 		if (collection==null) {
 			//do nothing
 			return null;
 		}
 		else {
 			CollectionPersister persister = session.getFactory().getCollectionPersister( collectionType.getRole() );
 
 			final PersistenceContext persistenceContext = session.getPersistenceContext();
 			//TODO: move into collection type, so we can use polymorphism!
 			if ( collectionType.hasHolder( session.getEntityMode() ) ) {
 
 				if (collection==CollectionType.UNFETCHED_COLLECTION) return null;
 
 				PersistentCollection ah = persistenceContext.getCollectionHolder(collection);
 				if (ah==null) {
 					ah = collectionType.wrap(session, collection);
 					persistenceContext.addNewCollection( persister, ah );
 					persistenceContext.addCollectionHolder(ah);
 				}
 				return null;
 			}
 			else {
 
 				PersistentCollection persistentCollection = collectionType.wrap(session, collection);
 				persistenceContext.addNewCollection( persister, persistentCollection );
 
                 if (LOG.isTraceEnabled()) LOG.trace("Wrapped collection in role: " + collectionType.getRole());
 
 				return persistentCollection; //Force a substitution!
 
 			}
 
 		}
 
 	}
 
 	@Override
     void processValue(int i, Object[] values, Type[] types) {
 		Object result = processValue( values[i], types[i] );
 		if (result!=null) {
 			substitute = true;
 			values[i] = result;
 		}
 	}
 
 	@Override
     Object processComponent(Object component, CompositeType componentType)
 	throws HibernateException {
 
 		if (component!=null) {
 			Object[] values = componentType.getPropertyValues( component, getSession() );
 			Type[] types = componentType.getSubtypes();
 			boolean substituteComponent = false;
 			for ( int i=0; i<types.length; i++ ) {
 				Object result = processValue( values[i], types[i] );
 				if (result!=null) {
 					values[i] = result;
 					substituteComponent = true;
 				}
 			}
 			if (substituteComponent) {
 				componentType.setPropertyValues( component, values, getSession().getEntityMode() );
 			}
 		}
 
 		return null;
 	}
 
 	@Override
     void process(Object object, EntityPersister persister) throws HibernateException {
 		EntityMode entityMode = getSession().getEntityMode();
 		Object[] values = persister.getPropertyValues( object, entityMode );
 		Type[] types = persister.getPropertyTypes();
 		processEntityPropertyValues(values, types);
 		if ( isSubstitutionRequired() ) {
 			persister.setPropertyValues( object, values, entityMode );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/exception/SQLExceptionConverterFactory.java b/hibernate-core/src/main/java/org/hibernate/exception/SQLExceptionConverterFactory.java
index c735a0b57c..40e4b58265 100644
--- a/hibernate-core/src/main/java/org/hibernate/exception/SQLExceptionConverterFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/exception/SQLExceptionConverterFactory.java
@@ -1,137 +1,138 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.exception;
 
 import java.lang.reflect.Constructor;
 import java.sql.SQLException;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * A factory for building SQLExceptionConverter instances.
  *
  * @author Steve Ebersole
  */
 public class SQLExceptionConverterFactory {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        SQLExceptionConverterFactory.class.getName());
 
 	private SQLExceptionConverterFactory() {
 		// Private constructor - stops checkstyle from complaining.
 	}
 
 	/**
 	 * Build a SQLExceptionConverter instance.
 	 * <p/>
 	 * First, looks for a {@link Environment#SQL_EXCEPTION_CONVERTER} property to see
 	 * if the configuration specified the class of a specific converter to use.  If this
 	 * property is set, attempt to construct an instance of that class.  If not set, or
 	 * if construction fails, the converter specific to the dialect will be used.
 	 *
 	 * @param dialect    The defined dialect.
 	 * @param properties The configuration properties.
 	 * @return An appropriate SQLExceptionConverter instance.
 	 * @throws HibernateException There was an error building the SQLExceptionConverter.
 	 */
 	public static SQLExceptionConverter buildSQLExceptionConverter(Dialect dialect, Properties properties) throws HibernateException {
 		SQLExceptionConverter converter = null;
 
 		String converterClassName = ( String ) properties.get( Environment.SQL_EXCEPTION_CONVERTER );
 		if ( StringHelper.isNotEmpty( converterClassName ) ) {
 			converter = constructConverter( converterClassName, dialect.getViolatedConstraintNameExtracter() );
 		}
 
 		if ( converter == null ) {
             LOG.trace("Using dialect defined converter");
 			converter = dialect.buildSQLExceptionConverter();
 		}
 
 		if ( converter instanceof Configurable ) {
 			try {
 				( ( Configurable ) converter ).configure( properties );
 			}
 			catch ( HibernateException e ) {
                 LOG.unableToConfigureSqlExceptionConverter(e);
 				throw e;
 			}
 		}
 
 		return converter;
 	}
 
 	/**
 	 * Builds a minimal converter.  The instance returned here just always converts to
 	 * {@link GenericJDBCException}.
 	 *
 	 * @return The minimal converter.
 	 */
 	public static SQLExceptionConverter buildMinimalSQLExceptionConverter() {
 		return new SQLExceptionConverter() {
 			public JDBCException convert(SQLException sqlException, String message, String sql) {
 				return new GenericJDBCException( message, sqlException, sql );
 			}
 		};
 	}
 
 	private static SQLExceptionConverter constructConverter(String converterClassName, ViolatedConstraintNameExtracter violatedConstraintNameExtracter) {
 		try {
             LOG.trace("Attempting to construct instance of specified SQLExceptionConverter [" + converterClassName + "]");
 			Class converterClass = ReflectHelper.classForName( converterClassName );
 
 			// First, try to find a matching constructor accepting a ViolatedConstraintNameExtracter param...
 			Constructor[] ctors = converterClass.getDeclaredConstructors();
 			for ( int i = 0; i < ctors.length; i++ ) {
 				if ( ctors[i].getParameterTypes() != null && ctors[i].getParameterTypes().length == 1 ) {
 					if ( ViolatedConstraintNameExtracter.class.isAssignableFrom( ctors[i].getParameterTypes()[0] ) ) {
 						try {
 							return ( SQLExceptionConverter )
 									ctors[i].newInstance( new Object[]{violatedConstraintNameExtracter} );
 						}
 						catch ( Throwable t ) {
 							// eat it and try next
 						}
 					}
 				}
 			}
 
 			// Otherwise, try to use the no-arg constructor
 			return ( SQLExceptionConverter ) converterClass.newInstance();
 
 		}
 		catch ( Throwable t ) {
             LOG.unableToConstructSqlExceptionConverter(t);
 		}
 
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/QuerySplitter.java b/hibernate-core/src/main/java/org/hibernate/hql/QuerySplitter.java
index 354c75fa41..12a6962025 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/QuerySplitter.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/QuerySplitter.java
@@ -1,156 +1,157 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql;
 
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.Set;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.hql.classic.ParserHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.jboss.logging.Logger;
 
 /**
  * Provides query splitting methods, which were originally in QueryTranslator.
  * <br>
  * TODO: This will need to be refactored at some point.
  *
  * @author josh
  */
 public final class QuerySplitter {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, QuerySplitter.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QuerySplitter.class.getName());
 
 	private static final Set BEFORE_CLASS_TOKENS = new HashSet();
 	private static final Set NOT_AFTER_CLASS_TOKENS = new HashSet();
 
 	static {
 		BEFORE_CLASS_TOKENS.add( "from" );
 		BEFORE_CLASS_TOKENS.add( "delete" );
 		BEFORE_CLASS_TOKENS.add( "update" );
 		//beforeClassTokens.add("new"); DEFINITELY DON'T HAVE THIS!!
 		BEFORE_CLASS_TOKENS.add( "," );
 		NOT_AFTER_CLASS_TOKENS.add( "in" );
 		//notAfterClassTokens.add(",");
 		NOT_AFTER_CLASS_TOKENS.add( "from" );
 		NOT_AFTER_CLASS_TOKENS.add( ")" );
 	}
 
 	/**
 	 * Private empty constructor.
 	 * (or else checkstyle says: 'warning: Utility classes should not have a public or default constructor.')
 	 */
 	private QuerySplitter() {
 	}
 
 	/**
 	 * Handle Hibernate "implicit" polymorphism, by translating the query string into
 	 * several "concrete" queries against mapped classes.
 	 */
 	public static String[] concreteQueries(String query, SessionFactoryImplementor factory) throws MappingException {
 
 		//scan the query string for class names appearing in the from clause and replace
 		//with all persistent implementors of the class/interface, returning multiple
 		//query strings (make sure we don't pick up a class in the select clause!)
 
 		//TODO: this is one of the ugliest and most fragile pieces of code in Hibernate....
 
 		String[] tokens = StringHelper.split( StringHelper.WHITESPACE + "(),", query, true );
 		if ( tokens.length == 0 ) return new String[]{query}; // just especially for the trivial collection filter
 		ArrayList placeholders = new ArrayList();
 		ArrayList replacements = new ArrayList();
 		StringBuffer templateQuery = new StringBuffer( 40 );
 		int count = 0;
 		String last = null;
 		int nextIndex = 0;
 		String next = null;
 		boolean isSelectClause = false;
 
 		templateQuery.append( tokens[0] );
 		if ( "select".equals( tokens[0].toLowerCase() ) ) isSelectClause = true;
 
 		for ( int i = 1; i < tokens.length; i++ ) {
 
 			//update last non-whitespace token, if necessary
 			if ( !ParserHelper.isWhitespace( tokens[i - 1] ) ) last = tokens[i - 1].toLowerCase();
 
 			// select-range is terminated by declaration of "from"
 			if ( "from".equals( tokens[i].toLowerCase() ) ) isSelectClause = false;
 
 			String token = tokens[i];
 			if ( !ParserHelper.isWhitespace( token ) || last == null ) {
 
 				//scan for next non-whitespace token
 				if ( nextIndex <= i ) {
 					for ( nextIndex = i + 1; nextIndex < tokens.length; nextIndex++ ) {
 						next = tokens[nextIndex].toLowerCase();
 						if ( !ParserHelper.isWhitespace( next ) ) break;
 					}
 				}
 
 				boolean process = !isSelectClause &&
 						isJavaIdentifier( token ) &&
 						isPossiblyClassName( last, next );
 
 				if (process) {
 					String importedClassName = getImportedClass( token, factory );
 					if ( importedClassName != null ) {
 						String[] implementors = factory.getImplementors( importedClassName );
 						String placeholder = "$clazz" + count++ + "$";
 						if ( implementors != null ) {
 							placeholders.add( placeholder );
 							replacements.add( implementors );
 						}
 						token = placeholder; // Note this!!
 					}
 				}
 
 			}
 
 			templateQuery.append( token );
 
 		}
 		String[] results = StringHelper.multiply( templateQuery.toString(), placeholders.iterator(), replacements.iterator() );
         if (results.length == 0) LOG.noPersistentClassesFound(query);
 		return results;
 	}
 
 	private static boolean isPossiblyClassName(String last, String next) {
 		return "class".equals( last ) || (
 				BEFORE_CLASS_TOKENS.contains( last ) &&
 				!NOT_AFTER_CLASS_TOKENS.contains( next )
 			);
 	}
 
 	private static boolean isJavaIdentifier(String token) {
 		return Character.isJavaIdentifierStart( token.charAt( 0 ) );
 	}
 
 	public static String getImportedClass(String name, SessionFactoryImplementor factory) {
 		return factory.getImportedClassName( name );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/ASTQueryTranslatorFactory.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/ASTQueryTranslatorFactory.java
index 374a53b539..b8d7fa13e1 100755
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/ASTQueryTranslatorFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/ASTQueryTranslatorFactory.java
@@ -1,70 +1,72 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast;
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.hql.FilterTranslator;
 import org.hibernate.hql.QueryTranslator;
 import org.hibernate.hql.QueryTranslatorFactory;
+
 import org.jboss.logging.Logger;
 
 /**
  * Generates translators which uses the Antlr-based parser to perform
  * the translation.
  *
  * @author Gavin King
  */
 public class ASTQueryTranslatorFactory implements QueryTranslatorFactory {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        ASTQueryTranslatorFactory.class.getName());
 
 	public ASTQueryTranslatorFactory() {
         LOG.usingAstQueryTranslatorFactory();
 	}
 
 	/**
 	 * @see QueryTranslatorFactory#createQueryTranslator
 	 */
 	public QueryTranslator createQueryTranslator(
 			String queryIdentifier,
 	        String queryString,
 	        Map filters,
 	        SessionFactoryImplementor factory) {
 		return new QueryTranslatorImpl( queryIdentifier, queryString, filters, factory );
 	}
 
 	/**
 	 * @see QueryTranslatorFactory#createFilterTranslator
 	 */
 	public FilterTranslator createFilterTranslator(
 			String queryIdentifier,
 	        String queryString,
 	        Map filters,
 	        SessionFactoryImplementor factory) {
 		return new QueryTranslatorImpl( queryIdentifier, queryString, filters, factory );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/ErrorCounter.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/ErrorCounter.java
index df13566959..fd4ac0b3f4 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/ErrorCounter.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/ErrorCounter.java
@@ -1,82 +1,84 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
+
 import org.jboss.logging.Logger;
 import antlr.RecognitionException;
 
 /**
  * An error handler that counts parsing errors and warnings.
  */
 public class ErrorCounter implements ParseErrorHandler {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ErrorCounter.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ErrorCounter.class.getName());
 
 	private List errorList = new ArrayList();
 	private List warningList = new ArrayList();
 	private List recognitionExceptions = new ArrayList();
 
 	public void reportError(RecognitionException e) {
 		reportError( e.toString() );
 		recognitionExceptions.add( e );
         LOG.error(e.toString(), e);
 	}
 
 	public void reportError(String message) {
         LOG.error(message);
 		errorList.add( message );
 	}
 
 	public int getErrorCount() {
 		return errorList.size();
 	}
 
 	public void reportWarning(String message) {
         LOG.debugf(message);
 		warningList.add( message );
 	}
 
 	private String getErrorString() {
 		StringBuffer buf = new StringBuffer();
 		for ( Iterator iterator = errorList.iterator(); iterator.hasNext(); ) {
 			buf.append( ( String ) iterator.next() );
 			if ( iterator.hasNext() ) buf.append( "\n" );
 
 		}
 		return buf.toString();
 	}
 
 	public void throwQueryException() throws QueryException {
 		if ( getErrorCount() > 0 ) {
             if (recognitionExceptions.size() > 0) throw QuerySyntaxException.convert((RecognitionException)recognitionExceptions.get(0));
             throw new QueryException(getErrorString());
         }
         LOG.debugf("throwQueryException() : no errors");
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlParser.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlParser.java
index 7a28576773..d338027218 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlParser.java
@@ -1,383 +1,385 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast;
 
 import java.io.PrintStream;
 import java.io.PrintWriter;
 import java.io.StringReader;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
 import org.hibernate.hql.antlr.HqlBaseParser;
 import org.hibernate.hql.antlr.HqlTokenTypes;
 import org.hibernate.hql.ast.util.ASTPrinter;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.internal.util.StringHelper;
+
 import org.jboss.logging.Logger;
 import antlr.ASTPair;
 import antlr.MismatchedTokenException;
 import antlr.RecognitionException;
 import antlr.Token;
 import antlr.TokenStream;
 import antlr.TokenStreamException;
 import antlr.collections.AST;
 
 /**
  * Implements the semantic action methods defined in the HQL base parser to keep the grammar
  * source file a little cleaner.  Extends the parser class generated by ANTLR.
  *
  * @author Joshua Davis (pgmjsd@sourceforge.net)
  */
 public final class HqlParser extends HqlBaseParser {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, HqlParser.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HqlParser.class.getName());
 
 	private ParseErrorHandler parseErrorHandler;
 	private ASTPrinter printer = getASTPrinter();
 
 	private static ASTPrinter getASTPrinter() {
 		return new ASTPrinter( org.hibernate.hql.antlr.HqlTokenTypes.class );
 	}
 
 	public static HqlParser getInstance(String hql) {
         // [jsd] The fix for HHH-558...
         HqlLexer lexer = new HqlLexer( new StringReader( hql ) );
 		return new HqlParser( lexer );
 	}
 
 	private HqlParser(TokenStream lexer) {
 		super( lexer );
 		initialize();
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private int traceDepth = 0;
 
 	@Override
     public void traceIn(String ruleName) {
         if (!LOG.isTraceEnabled()) return;
         if (inputState.guessing > 0) return;
 		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
         LOG.trace(prefix + ruleName);
 	}
 
 	@Override
     public void traceOut(String ruleName) {
         if (!LOG.isTraceEnabled()) return;
         if (inputState.guessing > 0) return;
 		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
         LOG.trace(prefix + ruleName);
 	}
 
 	@Override
     public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	@Override
     public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	@Override
     public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	/**
 	 * Overrides the base behavior to retry keywords as identifiers.
 	 *
 	 * @param token The token.
 	 * @param ex    The recognition exception.
 	 * @return AST - The new AST.
 	 * @throws antlr.RecognitionException if the substitution was not possible.
 	 * @throws antlr.TokenStreamException if the substitution was not possible.
 	 */
 	@Override
     public AST handleIdentifierError(Token token, RecognitionException ex) throws RecognitionException, TokenStreamException {
 		// If the token can tell us if it could be an identifier...
 		if ( token instanceof HqlToken ) {
 			HqlToken hqlToken = ( HqlToken ) token;
 			// ... and the token could be an identifer and the error is
 			// a mismatched token error ...
 			if ( hqlToken.isPossibleID() && ( ex instanceof MismatchedTokenException ) ) {
 				MismatchedTokenException mte = ( MismatchedTokenException ) ex;
 				// ... and the expected token type was an identifier, then:
 				if ( mte.expecting == HqlTokenTypes.IDENT ) {
 					// Use the token as an identifier.
 					reportWarning( "Keyword  '"
 							+ token.getText()
 							+ "' is being interpreted as an identifier due to: " + mte.getMessage() );
 					// Add the token to the AST.
 					ASTPair currentAST = new ASTPair();
 					token.setType( HqlTokenTypes.WEIRD_IDENT );
 					astFactory.addASTChild( currentAST, astFactory.create( token ) );
 					consume();
 					AST identifierAST = currentAST.root;
 					return identifierAST;
 				}
 			} // if
 		} // if
 		// Otherwise, handle the error normally.
 		return super.handleIdentifierError( token, ex );
 	}
 
 	/**
 	 * Returns an equivalent tree for (NOT (a relop b) ), for example:<pre>
 	 * (NOT (GT a b) ) => (LE a b)
 	 * </pre>
 	 *
 	 * @param x The sub tree to transform, the parent is assumed to be NOT.
 	 * @return AST - The equivalent sub-tree.
 	 */
 	@Override
     public AST negateNode(AST x) {
 		//TODO: switch statements are always evil! We already had bugs because
 		//      of forgotten token types. Use polymorphism for this!
 		switch ( x.getType() ) {
 			case OR:
 				x.setType(AND);
 				x.setText("{and}");
 				negateNode( x.getFirstChild() );
 				negateNode( x.getFirstChild().getNextSibling() );
 				return x;
 			case AND:
 				x.setType(OR);
 				x.setText("{or}");
 				negateNode( x.getFirstChild() );
 				negateNode( x.getFirstChild().getNextSibling() );
 				return x;
 			case EQ:
 				x.setType( NE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (EQ a b) ) => (NE a b)
 			case NE:
 				x.setType( EQ );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NE a b) ) => (EQ a b)
 			case GT:
 				x.setType( LE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (GT a b) ) => (LE a b)
 			case LT:
 				x.setType( GE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LT a b) ) => (GE a b)
 			case GE:
 				x.setType( LT );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (GE a b) ) => (LT a b)
 			case LE:
 				x.setType( GT );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LE a b) ) => (GT a b)
 			case LIKE:
 				x.setType( NOT_LIKE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LIKE a b) ) => (NOT_LIKE a b)
 			case NOT_LIKE:
 				x.setType( LIKE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NOT_LIKE a b) ) => (LIKE a b)
 			case IN:
 				x.setType( NOT_IN );
 				x.setText( "{not}" + x.getText() );
 				return x;
 			case NOT_IN:
 				x.setType( IN );
 				x.setText( "{not}" + x.getText() );
 				return x;
 			case IS_NULL:
 				x.setType( IS_NOT_NULL );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (IS_NULL a b) ) => (IS_NOT_NULL a b)
 			case IS_NOT_NULL:
 				x.setType( IS_NULL );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (IS_NOT_NULL a b) ) => (IS_NULL a b)
 			case BETWEEN:
 				x.setType( NOT_BETWEEN );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (BETWEEN a b) ) => (NOT_BETWEEN a b)
 			case NOT_BETWEEN:
 				x.setType( BETWEEN );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NOT_BETWEEN a b) ) => (BETWEEN a b)
 /* This can never happen because this rule will always eliminate the child NOT.
 			case NOT:
 				return x.getFirstChild();			// (NOT (NOT x) ) => (x)
 */
 			default:
 				return super.negateNode( x );		// Just add a 'not' parent.
 		}
 	}
 
 	/**
 	 * Post process equality expressions, clean up the subtree.
 	 *
 	 * @param x The equality expression.
 	 * @return AST - The clean sub-tree.
 	 */
 	@Override
     public AST processEqualityExpression(AST x) {
 		if ( x == null ) {
             LOG.processEqualityExpression();
 			return null;
 		}
 
 		int type = x.getType();
 		if ( type == EQ || type == NE ) {
 			boolean negated = type == NE;
 			if ( x.getNumberOfChildren() == 2 ) {
 				AST a = x.getFirstChild();
 				AST b = a.getNextSibling();
 				// (EQ NULL b) => (IS_NULL b)
 				if ( a.getType() == NULL && b.getType() != NULL ) {
 					return createIsNullParent( b, negated );
 				}
 				// (EQ a NULL) => (IS_NULL a)
 				else if ( b.getType() == NULL && a.getType() != NULL ) {
 					return createIsNullParent( a, negated );
 				}
 				else if ( b.getType() == EMPTY ) {
 					return processIsEmpty( a, negated );
 				}
 				else {
 					return x;
 				}
 			}
 			else {
 				return x;
 			}
 		}
 		else {
 			return x;
 		}
 	}
 
 	private AST createIsNullParent(AST node, boolean negated) {
 		node.setNextSibling( null );
 		int type = negated ? IS_NOT_NULL : IS_NULL;
 		String text = negated ? "is not null" : "is null";
 		return ASTUtil.createParent( astFactory, type, text, node );
 	}
 
 	private AST processIsEmpty(AST node, boolean negated) {
 		node.setNextSibling( null );
 		// NOTE: Because we're using ASTUtil.createParent(), the tree must be created from the bottom up.
 		// IS EMPTY x => (EXISTS (QUERY (SELECT_FROM (FROM x) ) ) )
 		AST ast = createSubquery( node );
 		ast = ASTUtil.createParent( astFactory, EXISTS, "exists", ast );
 		// Add NOT if it's negated.
 		if ( !negated ) {
 			ast = ASTUtil.createParent( astFactory, NOT, "not", ast );
 		}
 		return ast;
 	}
 
 	private AST createSubquery(AST node) {
 		AST ast = ASTUtil.createParent( astFactory, RANGE, "RANGE", node );
 		ast = ASTUtil.createParent( astFactory, FROM, "from", ast );
 		ast = ASTUtil.createParent( astFactory, SELECT_FROM, "SELECT_FROM", ast );
 		ast = ASTUtil.createParent( astFactory, QUERY, "QUERY", ast );
 		return ast;
 	}
 
 	public void showAst(AST ast, PrintStream out) {
 		showAst( ast, new PrintWriter( out ) );
 	}
 
 	private void showAst(AST ast, PrintWriter pw) {
 		printer.showAst( ast, pw );
 	}
 
 	private void initialize() {
 		// Initialize the error handling delegate.
 		parseErrorHandler = new ErrorCounter();
 		setASTFactory(new HqlASTFactory());	// Create nodes that track line and column number.
 	}
 
 	@Override
     public void weakKeywords() throws TokenStreamException {
 
 		int t = LA( 1 );
 		switch ( t ) {
 			case ORDER:
 			case GROUP:
                 // Case 1: Multi token keywords GROUP BY and ORDER BY
 				// The next token ( LT(2) ) should be 'by'... otherwise, this is just an ident.
 				if ( LA( 2 ) != LITERAL_by ) {
 					LT( 1 ).setType( IDENT );
                     LOG.debugf("weakKeywords() : new LT(1) token - %s", LT(1));
 				}
 				break;
 			default:
                 // Case 2: The current token is after FROM and before '.'.
                 if (LA(0) == FROM && t != IDENT && LA(2) == DOT) {
                     HqlToken hqlToken = (HqlToken)LT(1);
                     if (hqlToken.isPossibleID()) {
                         hqlToken.setType(IDENT);
                         LOG.debugf("weakKeywords() : new LT(1) token - %s", LT(1));
                     }
                 }
 				break;
 		}
 	}
 
     @Override
     public void handleDotIdent() throws TokenStreamException {
         // This handles HHH-354, where there is a strange property name in a where clause.
         // If the lookahead contains a DOT then something that isn't an IDENT...
         if (LA(1) == DOT && LA(2) != IDENT) {
             // See if the second lookahead token can be an identifier.
             HqlToken t = (HqlToken)LT(2);
             if (t.isPossibleID())
             {
                 // Set it!
                 LT( 2 ).setType( IDENT );
                 LOG.debugf("handleDotIdent() : new LT(2) token - %s", LT(1));
             }
         }
     }
 
 	@Override
     public void processMemberOf(Token n, AST p, ASTPair currentAST) {
 		AST inAst = n == null ? astFactory.create( IN, "in" ) : astFactory.create( NOT_IN, "not in" );
 		astFactory.makeASTRoot( currentAST, inAst );
 		AST ast = createSubquery( p );
 		ast = ASTUtil.createParent( astFactory, IN_LIST, "inList", ast );
 		inAst.addChild( ast );
 	}
 
 	static public void panic() {
 		//overriden to avoid System.exit
 		throw new QueryException("Parser: panic");
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlSqlWalker.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlSqlWalker.java
index 64a9958fc4..3d1042b758 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlSqlWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlSqlWalker.java
@@ -1,1120 +1,1120 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.engine.ParameterBinder;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.hql.QueryTranslator;
 import org.hibernate.hql.antlr.HqlSqlBaseWalker;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.antlr.HqlTokenTypes;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.tree.AggregateNode;
 import org.hibernate.hql.ast.tree.AssignmentSpecification;
 import org.hibernate.hql.ast.tree.CollectionFunction;
 import org.hibernate.hql.ast.tree.ConstructorNode;
 import org.hibernate.hql.ast.tree.DeleteStatement;
 import org.hibernate.hql.ast.tree.DotNode;
 import org.hibernate.hql.ast.tree.FromClause;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.hql.ast.tree.FromElementFactory;
 import org.hibernate.hql.ast.tree.FromReferenceNode;
 import org.hibernate.hql.ast.tree.IdentNode;
 import org.hibernate.hql.ast.tree.IndexNode;
 import org.hibernate.hql.ast.tree.InsertStatement;
 import org.hibernate.hql.ast.tree.IntoClause;
 import org.hibernate.hql.ast.tree.MethodNode;
 import org.hibernate.hql.ast.tree.OperatorNode;
 import org.hibernate.hql.ast.tree.ParameterContainer;
 import org.hibernate.hql.ast.tree.ParameterNode;
 import org.hibernate.hql.ast.tree.QueryNode;
 import org.hibernate.hql.ast.tree.ResolvableNode;
 import org.hibernate.hql.ast.tree.RestrictableStatement;
 import org.hibernate.hql.ast.tree.ResultVariableRefNode;
 import org.hibernate.hql.ast.tree.SelectClause;
 import org.hibernate.hql.ast.tree.SelectExpression;
 import org.hibernate.hql.ast.tree.UpdateStatement;
 import org.hibernate.hql.ast.util.ASTPrinter;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.hql.ast.util.AliasGenerator;
 import org.hibernate.hql.ast.util.JoinProcessor;
 import org.hibernate.hql.ast.util.LiteralProcessor;
 import org.hibernate.hql.ast.util.NodeTraverser;
 import org.hibernate.hql.ast.util.SessionFactoryHelper;
 import org.hibernate.hql.ast.util.SyntheticAndFactory;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.id.SequenceGenerator;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.param.CollectionFilterKeyParameterSpecification;
 import org.hibernate.param.NamedParameterSpecification;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.param.PositionalParameterSpecification;
 import org.hibernate.param.VersionTypeSeedParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.DbTimestampType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 import org.hibernate.usertype.UserVersionType;
 import org.jboss.logging.Logger;
 import antlr.ASTFactory;
 import antlr.RecognitionException;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Implements methods used by the HQL->SQL tree transform grammar (a.k.a. the second phase).
  * <ul>
  * <li>Isolates the Hibernate API-specific code from the ANTLR generated code.</li>
  * <li>Handles the SQL fragments generated by the persisters in order to create the SELECT and FROM clauses,
  * taking into account the joins and projections that are implied by the mappings (persister/queryable).</li>
  * <li>Uses SqlASTFactory to create customized AST nodes.</li>
  * </ul>
  *
  * @see SqlASTFactory
  */
 public class HqlSqlWalker extends HqlSqlBaseWalker implements ErrorReporter, ParameterBinder.NamedParameterSource {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, HqlSqlWalker.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HqlSqlWalker.class.getName());
 
 	private final QueryTranslatorImpl queryTranslatorImpl;
 	private final HqlParser hqlParser;
 	private final SessionFactoryHelper sessionFactoryHelper;
 	private final Map tokenReplacements;
 	private final AliasGenerator aliasGenerator = new AliasGenerator();
 	private final LiteralProcessor literalProcessor;
 	private final ParseErrorHandler parseErrorHandler;
 	private final ASTPrinter printer;
 	private final String collectionFilterRole;
 
 	private FromClause currentFromClause = null;
 	private SelectClause selectClause;
 
 	/**
 	 * Maps each top-level result variable to its SelectExpression;
 	 * (excludes result variables defined in subqueries)
 	 **/
 	private Map<String, SelectExpression> selectExpressionsByResultVariable = new HashMap();
 
 	private Set querySpaces = new HashSet();
 
 	private int parameterCount;
 	private Map namedParameters = new HashMap();
 	private ArrayList parameters = new ArrayList();
 	private int numberOfParametersInSetClause;
 	private int positionalParameterCount;
 
 	private ArrayList assignmentSpecifications = new ArrayList();
 
 	private int impliedJoinType;
 
 	/**
 	 * Create a new tree transformer.
 	 *
 	 * @param qti Back pointer to the query translator implementation that is using this tree transform.
 	 * @param sfi The session factory implementor where the Hibernate mappings can be found.
 	 * @param parser A reference to the phase-1 parser
 	 * @param tokenReplacements Registers the token replacement map with the walker.  This map will
 	 * be used to substitute function names and constants.
 	 * @param collectionRole The collection role name of the collection used as the basis for the
 	 * filter, NULL if this is not a collection filter compilation.
 	 */
 	public HqlSqlWalker(
 			QueryTranslatorImpl qti,
 			SessionFactoryImplementor sfi,
 			HqlParser parser,
 			Map tokenReplacements,
 			String collectionRole) {
 		setASTFactory( new SqlASTFactory( this ) );
 		// Initialize the error handling delegate.
 		this.parseErrorHandler = new ErrorCounter();
 		this.queryTranslatorImpl = qti;
 		this.sessionFactoryHelper = new SessionFactoryHelper( sfi );
 		this.literalProcessor = new LiteralProcessor( this );
 		this.tokenReplacements = tokenReplacements;
 		this.collectionFilterRole = collectionRole;
 		this.hqlParser = parser;
 		this.printer = new ASTPrinter( SqlTokenTypes.class );
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private int traceDepth = 0;
 
 	@Override
     public void traceIn(String ruleName, AST tree) {
         if (!LOG.isTraceEnabled()) return;
         if (inputState.guessing > 0) return;
 		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
 		String traceText = ruleName + " (" + buildTraceNodeName(tree) + ")";
         LOG.trace(prefix + traceText);
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	@Override
     public void traceOut(String ruleName, AST tree) {
         if (!LOG.isTraceEnabled()) return;
         if (inputState.guessing > 0) return;
 		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
         LOG.trace(prefix + ruleName);
 	}
 
 
 	@Override
     protected void prepareFromClauseInputTree(AST fromClauseInput) {
 		if ( !isSubQuery() ) {
 //			// inject param specifications to account for dynamic filter param values
 //			if ( ! getEnabledFilters().isEmpty() ) {
 //				Iterator filterItr = getEnabledFilters().values().iterator();
 //				while ( filterItr.hasNext() ) {
 //					FilterImpl filter = ( FilterImpl ) filterItr.next();
 //					if ( ! filter.getFilterDefinition().getParameterNames().isEmpty() ) {
 //						Iterator paramItr = filter.getFilterDefinition().getParameterNames().iterator();
 //						while ( paramItr.hasNext() ) {
 //							String parameterName = ( String ) paramItr.next();
 //							// currently param filters *only* work with single-column parameter types;
 //							// if that limitation is ever lifted, this logic will need to change to account for that
 //							ParameterNode collectionFilterKeyParameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 //							DynamicFilterParameterSpecification paramSpec = new DynamicFilterParameterSpecification(
 //									filter.getName(),
 //									parameterName,
 //									filter.getFilterDefinition().getParameterType( parameterName ),
 //									 positionalParameterCount++
 //							);
 //							collectionFilterKeyParameter.setHqlParameterSpecification( paramSpec );
 //							parameters.add( paramSpec );
 //						}
 //					}
 //				}
 //			}
 
 			if ( isFilter() ) {
                 // Handle collection-filter compilation.
 				// IMPORTANT NOTE: This is modifying the INPUT (HQL) tree, not the output tree!
 				QueryableCollection persister = sessionFactoryHelper.getCollectionPersister( collectionFilterRole );
 				Type collectionElementType = persister.getElementType();
 				if ( !collectionElementType.isEntityType() ) {
 					throw new QueryException( "collection of values in filter: this" );
 				}
 
 				String collectionElementEntityName = persister.getElementPersister().getEntityName();
 				ASTFactory inputAstFactory = hqlParser.getASTFactory();
 				AST fromElement = ASTUtil.create( inputAstFactory, HqlTokenTypes.FILTER_ENTITY, collectionElementEntityName );
 				ASTUtil.createSibling( inputAstFactory, HqlTokenTypes.ALIAS, "this", fromElement );
 				fromClauseInput.addChild( fromElement );
 				// Show the modified AST.
                 LOG.debugf("prepareFromClauseInputTree() : Filter - Added 'this' as a from element...");
 				queryTranslatorImpl.showHqlAst( hqlParser.getAST() );
 
 				// Create a parameter specification for the collection filter...
 				Type collectionFilterKeyType = sessionFactoryHelper.requireQueryableCollection( collectionFilterRole ).getKeyType();
 				ParameterNode collectionFilterKeyParameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 				CollectionFilterKeyParameterSpecification collectionFilterKeyParameterSpec = new CollectionFilterKeyParameterSpecification(
 						collectionFilterRole, collectionFilterKeyType, positionalParameterCount++
 				);
 				collectionFilterKeyParameter.setHqlParameterSpecification( collectionFilterKeyParameterSpec );
 				parameters.add( collectionFilterKeyParameterSpec );
 			}
 		}
 	}
 
 	public boolean isFilter() {
 		return collectionFilterRole != null;
 	}
 
 	public String getCollectionFilterRole() {
 		return collectionFilterRole;
 	}
 
 	public SessionFactoryHelper getSessionFactoryHelper() {
 		return sessionFactoryHelper;
 	}
 
 	public Map getTokenReplacements() {
 		return tokenReplacements;
 	}
 
 	public AliasGenerator getAliasGenerator() {
 		return aliasGenerator;
 	}
 
 	public FromClause getCurrentFromClause() {
 		return currentFromClause;
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	@Override
     public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	@Override
     public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	@Override
     public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	/**
 	 * Returns the set of unique query spaces (a.k.a.
 	 * table names) that occurred in the query.
 	 *
 	 * @return A set of table names (Strings).
 	 */
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	@Override
     protected AST createFromElement(String path, AST alias, AST propertyFetch) throws SemanticException {
 		FromElement fromElement = currentFromClause.addFromElement( path, alias );
 		fromElement.setAllPropertyFetch(propertyFetch!=null);
 		return fromElement;
 	}
 
 	@Override
     protected AST createFromFilterElement(AST filterEntity, AST alias) throws SemanticException {
 		FromElement fromElement = currentFromClause.addFromElement( filterEntity.getText(), alias );
 		FromClause fromClause = fromElement.getFromClause();
 		QueryableCollection persister = sessionFactoryHelper.getCollectionPersister( collectionFilterRole );
 		// Get the names of the columns used to link between the collection
 		// owner and the collection elements.
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		String fkTableAlias = persister.isOneToMany()
 				? fromElement.getTableAlias()
 				: fromClause.getAliasGenerator().createName( collectionFilterRole );
 		JoinSequence join = sessionFactoryHelper.createJoinSequence();
 		join.setRoot( persister, fkTableAlias );
 		if ( !persister.isOneToMany() ) {
 			join.addJoin( ( AssociationType ) persister.getElementType(),
 					fromElement.getTableAlias(),
 					JoinFragment.INNER_JOIN,
 					persister.getElementColumnNames( fkTableAlias ) );
 		}
 		join.addCondition( fkTableAlias, keyColumnNames, " = ?" );
 		fromElement.setJoinSequence( join );
 		fromElement.setFilter( true );
         LOG.debugf("createFromFilterElement() : processed filter FROM element.");
 		return fromElement;
 	}
 
 	@Override
     protected void createFromJoinElement(
 	        AST path,
 	        AST alias,
 	        int joinType,
 	        AST fetchNode,
 	        AST propertyFetch,
 	        AST with) throws SemanticException {
 		boolean fetch = fetchNode != null;
 		if ( fetch && isSubQuery() ) {
 			throw new QueryException( "fetch not allowed in subquery from-elements" );
 		}
 		// The path AST should be a DotNode, and it should have been evaluated already.
 		if ( path.getType() != SqlTokenTypes.DOT ) {
 			throw new SemanticException( "Path expected for join!" );
 		}
 		DotNode dot = ( DotNode ) path;
 		int hibernateJoinType = JoinProcessor.toHibernateJoinType( joinType );
 		dot.setJoinType( hibernateJoinType );	// Tell the dot node about the join type.
 		dot.setFetch( fetch );
 		// Generate an explicit join for the root dot node.   The implied joins will be collected and passed up
 		// to the root dot node.
 		dot.resolve( true, false, alias == null ? null : alias.getText() );
 
 		final FromElement fromElement;
 		if ( dot.getDataType() != null && dot.getDataType().isComponentType() ) {
 			FromElementFactory factory = new FromElementFactory(
 					getCurrentFromClause(),
 					dot.getLhs().getFromElement(),
 					dot.getPropertyPath(),
 					alias == null ? null : alias.getText(),
 					null,
 					false
 			);
 			fromElement = factory.createComponentJoin( (ComponentType) dot.getDataType() );
 		}
 		else {
 			fromElement = dot.getImpliedJoin();
 			fromElement.setAllPropertyFetch( propertyFetch != null );
 
 			if ( with != null ) {
 				if ( fetch ) {
 					throw new SemanticException( "with-clause not allowed on fetched associations; use filters" );
 				}
 				handleWithFragment( fromElement, with );
 			}
 		}
 
         if (LOG.isDebugEnabled()) LOG.debugf("createFromJoinElement() : %s",
                                              getASTPrinter().showAsString(fromElement, "-- join tree --"));
 	}
 
 	private void handleWithFragment(FromElement fromElement, AST hqlWithNode) throws SemanticException {
 		try {
 			withClause( hqlWithNode );
 			AST hqlSqlWithNode = returnAST;
             if (LOG.isDebugEnabled()) LOG.debugf("handleWithFragment() : %s",
                                                  getASTPrinter().showAsString(hqlSqlWithNode, "-- with clause --"));
 			WithClauseVisitor visitor = new WithClauseVisitor( fromElement );
 			NodeTraverser traverser = new NodeTraverser( visitor );
 			traverser.traverseDepthFirst( hqlSqlWithNode );
 
 			String withClauseJoinAlias = visitor.getJoinAlias();
 			if ( withClauseJoinAlias == null ) {
 				withClauseJoinAlias = fromElement.getCollectionTableAlias();
 			}
 			else {
 				FromElement referencedFromElement = visitor.getReferencedFromElement();
 				if ( referencedFromElement != fromElement ) {
 					throw new InvalidWithClauseException( "with-clause expressions did not reference from-clause element to which the with-clause was associated" );
 				}
 			}
 
 			SqlGenerator sql = new SqlGenerator( getSessionFactoryHelper().getFactory() );
 			sql.whereExpr( hqlSqlWithNode.getFirstChild() );
 
 			fromElement.setWithClauseFragment( withClauseJoinAlias, "(" + sql.getSQL() + ")" );
 		}
 		catch( SemanticException e ) {
 			throw e;
 		}
 		catch( InvalidWithClauseException e ) {
 			throw e;
 		}
 		catch ( Exception e) {
 			throw new SemanticException( e.getMessage() );
 		}
 	}
 
 	private static class WithClauseVisitor implements NodeTraverser.VisitationStrategy {
 		private final FromElement joinFragment;
 		private FromElement referencedFromElement;
 		private String joinAlias;
 
 		public WithClauseVisitor(FromElement fromElement) {
 			this.joinFragment = fromElement;
 		}
 
 		public void visit(AST node) {
             // TODO : currently expects that the individual with expressions apply to the same sql table join.
 			//      This may not be the case for joined-subclass where the property values
 			//      might be coming from different tables in the joined hierarchy.  At some
 			//      point we should expand this to support that capability.  However, that has
 			//      some difficulties:
 			//          1) the biggest is how to handle ORs when the individual comparisons are
 			//              linked to different sql joins.
 			//          2) here we would need to track each comparison individually, along with
 			//              the join alias to which it applies and then pass that information
 			//              back to the FromElement so it can pass it along to the JoinSequence
 			if ( node instanceof DotNode ) {
 				DotNode dotNode = ( DotNode ) node;
 				FromElement fromElement = dotNode.getFromElement();
 				if ( referencedFromElement != null ) {
 					if ( fromElement != referencedFromElement ) {
 						throw new HibernateException( "with-clause referenced two different from-clause elements" );
 					}
 				}
 				else {
 					referencedFromElement = fromElement;
 					joinAlias = extractAppliedAlias( dotNode );
                     // TODO : temporary
 					//      needed because currently persister is the one that
                     // creates and renders the join fragments for inheritance
 					//      hierarchies...
 					if ( !joinAlias.equals( referencedFromElement.getTableAlias() ) ) {
 						throw new InvalidWithClauseException( "with clause can only reference columns in the driving table" );
 					}
 				}
 			}
 			else if ( node instanceof ParameterNode ) {
 				applyParameterSpecification( ( ( ParameterNode ) node ).getHqlParameterSpecification() );
 			}
 			else if ( node instanceof ParameterContainer ) {
 				applyParameterSpecifications( ( ParameterContainer ) node );
 			}
 		}
 
 		private void applyParameterSpecifications(ParameterContainer parameterContainer) {
 			if ( parameterContainer.hasEmbeddedParameters() ) {
 				ParameterSpecification[] specs = parameterContainer.getEmbeddedParameters();
 				for ( int i = 0; i < specs.length; i++ ) {
 					applyParameterSpecification( specs[i] );
 				}
 			}
 		}
 
 		private void applyParameterSpecification(ParameterSpecification paramSpec) {
 			joinFragment.addEmbeddedParameter( paramSpec );
 		}
 
 		private String extractAppliedAlias(DotNode dotNode) {
 			return dotNode.getText().substring( 0, dotNode.getText().indexOf( '.' ) );
 		}
 
 		public FromElement getReferencedFromElement() {
 			return referencedFromElement;
 		}
 
 		public String getJoinAlias() {
 			return joinAlias;
 		}
 	}
 
 	/**
 	 * Sets the current 'FROM' context.
 	 *
 	 * @param fromNode      The new 'FROM' context.
 	 * @param inputFromNode The from node from the input AST.
 	 */
 	@Override
     protected void pushFromClause(AST fromNode, AST inputFromNode) {
 		FromClause newFromClause = ( FromClause ) fromNode;
 		newFromClause.setParentFromClause( currentFromClause );
 		currentFromClause = newFromClause;
 	}
 
 	/**
 	 * Returns to the previous 'FROM' context.
 	 */
 	private void popFromClause() {
 		currentFromClause = currentFromClause.getParentFromClause();
 	}
 
 	@Override
     protected void lookupAlias(AST aliasRef)
 			throws SemanticException {
 		FromElement alias = currentFromClause.getFromElement( aliasRef.getText() );
 		FromReferenceNode aliasRefNode = ( FromReferenceNode ) aliasRef;
 		aliasRefNode.setFromElement( alias );
 	}
 
 	@Override
     protected void setImpliedJoinType(int joinType) {
 		impliedJoinType = JoinProcessor.toHibernateJoinType( joinType );
 	}
 
 	public int getImpliedJoinType() {
 		return impliedJoinType;
 	}
 
 	@Override
     protected AST lookupProperty(AST dot, boolean root, boolean inSelect) throws SemanticException {
 		DotNode dotNode = ( DotNode ) dot;
 		FromReferenceNode lhs = dotNode.getLhs();
 		AST rhs = lhs.getNextSibling();
 		switch ( rhs.getType() ) {
 			case SqlTokenTypes.ELEMENTS:
 			case SqlTokenTypes.INDICES:
                 if (LOG.isDebugEnabled()) LOG.debugf("lookupProperty() %s => %s(%s)",
                                                      dotNode.getPath(),
                                                      rhs.getText(),
                                                      lhs.getPath());
 				CollectionFunction f = ( CollectionFunction ) rhs;
 				// Re-arrange the tree so that the collection function is the root and the lhs is the path.
 				f.setFirstChild( lhs );
 				lhs.setNextSibling( null );
 				dotNode.setFirstChild( f );
 				resolve( lhs );			// Don't forget to resolve the argument!
 				f.resolve( inSelect );	// Resolve the collection function now.
 				return f;
 			default:
 				// Resolve everything up to this dot, but don't resolve the placeholders yet.
 				dotNode.resolveFirstChild();
 				return dotNode;
 		}
 	}
 
 	@Override
     protected boolean isNonQualifiedPropertyRef(AST ident) {
 		final String identText = ident.getText();
 		if ( currentFromClause.isFromElementAlias( identText ) ) {
 			return false;
 		}
 
 		List fromElements = currentFromClause.getExplicitFromElements();
 		if ( fromElements.size() == 1 ) {
 			final FromElement fromElement = ( FromElement ) fromElements.get( 0 );
 			try {
                 LOG.trace("Attempting to resolve property [" + identText + "] as a non-qualified ref");
 				return fromElement.getPropertyMapping( identText ).toType( identText ) != null;
 			}
 			catch( QueryException e ) {
 				// Should mean that no such property was found
 			}
 		}
 
 		return false;
 	}
 
 	@Override
     protected AST lookupNonQualifiedProperty(AST property) throws SemanticException {
 		final FromElement fromElement = ( FromElement ) currentFromClause.getExplicitFromElements().get( 0 );
 		AST syntheticDotNode = generateSyntheticDotNodeForNonQualifiedPropertyRef( property, fromElement );
 		return lookupProperty( syntheticDotNode, false, getCurrentClauseType() == HqlSqlTokenTypes.SELECT );
 	}
 
 	private AST generateSyntheticDotNodeForNonQualifiedPropertyRef(AST property, FromElement fromElement) {
 		AST dot = getASTFactory().create( DOT, "{non-qualified-property-ref}" );
 		// TODO : better way?!?
 		( ( DotNode ) dot ).setPropertyPath( ( ( FromReferenceNode ) property ).getPath() );
 
 		IdentNode syntheticAlias = ( IdentNode ) getASTFactory().create( IDENT, "{synthetic-alias}" );
 		syntheticAlias.setFromElement( fromElement );
 		syntheticAlias.setResolved();
 
 		dot.setFirstChild( syntheticAlias );
 		dot.addChild( property );
 
 		return dot;
 	}
 
 	@Override
     protected void processQuery(AST select, AST query) throws SemanticException {
         LOG.debugf("processQuery() : %s", query.toStringTree());
 
 		try {
 			QueryNode qn = ( QueryNode ) query;
 
 			// Was there an explicit select expression?
 			boolean explicitSelect = select != null && select.getNumberOfChildren() > 0;
 
 			if ( !explicitSelect ) {
 				// No explicit select expression; render the id and properties
 				// projection lists for every persister in the from clause into
 				// a single 'token node'.
 				//TODO: the only reason we need this stuff now is collection filters,
 				//      we should get rid of derived select clause completely!
 				createSelectClauseFromFromClause( qn );
 			}
 			else {
 				// Use the explicitly declared select expression; determine the
 				// return types indicated by each select token
 				useSelectClause( select );
 			}
 
 			// After that, process the JOINs.
 			// Invoke a delegate to do the work, as this is farily complex.
 			JoinProcessor joinProcessor = new JoinProcessor( this );
 			joinProcessor.processJoins( qn );
 
 			// Attach any mapping-defined "ORDER BY" fragments
 			Iterator itr = qn.getFromClause().getProjectionList().iterator();
 			while ( itr.hasNext() ) {
 				final FromElement fromElement = ( FromElement ) itr.next();
 //			if ( fromElement.isFetch() && fromElement.isCollectionJoin() ) {
 				if ( fromElement.isFetch() && fromElement.getQueryableCollection() != null ) {
 					// Does the collection referenced by this FromElement
 					// specify an order-by attribute?  If so, attach it to
 					// the query's order-by
 					if ( fromElement.getQueryableCollection().hasOrdering() ) {
 						String orderByFragment = fromElement
 								.getQueryableCollection()
 								.getSQLOrderByString( fromElement.getCollectionTableAlias() );
 						qn.getOrderByClause().addOrderFragment( orderByFragment );
 					}
 					if ( fromElement.getQueryableCollection().hasManyToManyOrdering() ) {
 						String orderByFragment = fromElement.getQueryableCollection()
 								.getManyToManyOrderByString( fromElement.getTableAlias() );
 						qn.getOrderByClause().addOrderFragment( orderByFragment );
 					}
 				}
 			}
 		}
 		finally {
 			popFromClause();
 		}
 	}
 
 	protected void postProcessDML(RestrictableStatement statement) throws SemanticException {
 		statement.getFromClause().resolve();
 
 		FromElement fromElement = ( FromElement ) statement.getFromClause().getFromElements().get( 0 );
 		Queryable persister = fromElement.getQueryable();
 		// Make #@%$^#^&# sure no alias is applied to the table name
 		fromElement.setText( persister.getTableName() );
 
 //		// append any filter fragments; the EMPTY_MAP is used under the assumption that
 //		// currently enabled filters should not affect this process
 //		if ( persister.getDiscriminatorType() != null ) {
 //			new SyntheticAndFactory( getASTFactory() ).addDiscriminatorWhereFragment(
 //			        statement,
 //			        persister,
 //			        java.util.Collections.EMPTY_MAP,
 //			        fromElement.getTableAlias()
 //			);
 //		}
 		if ( persister.getDiscriminatorType() != null || ! queryTranslatorImpl.getEnabledFilters().isEmpty() ) {
 			new SyntheticAndFactory( this ).addDiscriminatorWhereFragment(
 			        statement,
 			        persister,
 			        queryTranslatorImpl.getEnabledFilters(),
 			        fromElement.getTableAlias()
 			);
 		}
 
 	}
 
 	@Override
     protected void postProcessUpdate(AST update) throws SemanticException {
 		UpdateStatement updateStatement = ( UpdateStatement ) update;
 
 		postProcessDML( updateStatement );
 	}
 
 	@Override
     protected void postProcessDelete(AST delete) throws SemanticException {
 		postProcessDML( ( DeleteStatement ) delete );
 	}
 
 	public static boolean supportsIdGenWithBulkInsertion(IdentifierGenerator generator) {
 		return SequenceGenerator.class.isAssignableFrom( generator.getClass() )
 		        || PostInsertIdentifierGenerator.class.isAssignableFrom( generator.getClass() );
 	}
 
 	@Override
     protected void postProcessInsert(AST insert) throws SemanticException, QueryException {
 		InsertStatement insertStatement = ( InsertStatement ) insert;
 		insertStatement.validate();
 
 		SelectClause selectClause = insertStatement.getSelectClause();
 		Queryable persister = insertStatement.getIntoClause().getQueryable();
 
 		if ( !insertStatement.getIntoClause().isExplicitIdInsertion() ) {
 			// We need to generate ids as part of this bulk insert.
 			//
 			// Note that this is only supported for sequence-style generators and
 			// post-insert-style generators; basically, only in-db generators
 			IdentifierGenerator generator = persister.getIdentifierGenerator();
 			if ( !supportsIdGenWithBulkInsertion( generator ) ) {
 				throw new QueryException( "can only generate ids as part of bulk insert with either sequence or post-insert style generators" );
 			}
 
 			AST idSelectExprNode = null;
 
 			if ( SequenceGenerator.class.isAssignableFrom( generator.getClass() ) ) {
 				String seqName = ( String ) ( ( SequenceGenerator ) generator ).generatorKey();
 				String nextval = sessionFactoryHelper.getFactory().getDialect().getSelectSequenceNextValString( seqName );
 				idSelectExprNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, nextval );
 			}
 			else {
 				//Don't need this, because we should never ever be selecting no columns in an insert ... select...
 				//and because it causes a bug on DB2
 				/*String idInsertString = sessionFactoryHelper.getFactory().getDialect().getIdentityInsertString();
 				if ( idInsertString != null ) {
 					idSelectExprNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, idInsertString );
 				}*/
 			}
 
 			if ( idSelectExprNode != null ) {
 				AST currentFirstSelectExprNode = selectClause.getFirstChild();
 				selectClause.setFirstChild( idSelectExprNode );
 				idSelectExprNode.setNextSibling( currentFirstSelectExprNode );
 
 				insertStatement.getIntoClause().prependIdColumnSpec();
 			}
 		}
 
 		final boolean includeVersionProperty = persister.isVersioned() &&
 				!insertStatement.getIntoClause().isExplicitVersionInsertion() &&
 				persister.isVersionPropertyInsertable();
 		if ( includeVersionProperty ) {
 			// We need to seed the version value as part of this bulk insert
 			VersionType versionType = persister.getVersionType();
 			AST versionValueNode = null;
 
 			if ( sessionFactoryHelper.getFactory().getDialect().supportsParametersInInsertSelect() ) {
 				int sqlTypes[] = versionType.sqlTypes( sessionFactoryHelper.getFactory() );
 				if ( sqlTypes == null || sqlTypes.length == 0 ) {
 					throw new IllegalStateException( versionType.getClass() + ".sqlTypes() returns null or empty array" );
 				}
 				if ( sqlTypes.length > 1 ) {
 					throw new IllegalStateException(
 							versionType.getClass() +
 									".sqlTypes() returns > 1 element; only single-valued versions are allowed."
 					);
 				}
 				versionValueNode = getASTFactory().create( HqlSqlTokenTypes.PARAM, "?" );
 				ParameterSpecification paramSpec = new VersionTypeSeedParameterSpecification( versionType );
 				( ( ParameterNode ) versionValueNode ).setHqlParameterSpecification( paramSpec );
 				parameters.add( 0, paramSpec );
 
 				if ( sessionFactoryHelper.getFactory().getDialect().requiresCastingOfParametersInSelectClause() ) {
 					// we need to wrtap the param in a cast()
 					MethodNode versionMethodNode = ( MethodNode ) getASTFactory().create( HqlSqlTokenTypes.METHOD_CALL, "(" );
 					AST methodIdentNode = getASTFactory().create( HqlSqlTokenTypes.IDENT, "cast" );
 					versionMethodNode.addChild( methodIdentNode );
 					versionMethodNode.initializeMethodNode(methodIdentNode, true );
 					AST castExprListNode = getASTFactory().create( HqlSqlTokenTypes.EXPR_LIST, "exprList" );
 					methodIdentNode.setNextSibling( castExprListNode );
 					castExprListNode.addChild( versionValueNode );
 					versionValueNode.setNextSibling(
 							getASTFactory().create(
 									HqlSqlTokenTypes.IDENT,
 									sessionFactoryHelper.getFactory().getDialect().getTypeName( sqlTypes[0] ) )
 					);
 					processFunction( versionMethodNode, true );
 					versionValueNode = versionMethodNode;
 				}
 			}
 			else {
 				if ( isIntegral( versionType ) ) {
 					try {
 						Object seedValue = versionType.seed( null );
 						versionValueNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, seedValue.toString() );
 					}
 					catch( Throwable t ) {
 						throw new QueryException( "could not determine seed value for version on bulk insert [" + versionType + "]" );
 					}
 				}
 				else if ( isDatabaseGeneratedTimestamp( versionType ) ) {
 					String functionName = sessionFactoryHelper.getFactory().getDialect().getCurrentTimestampSQLFunctionName();
 					versionValueNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, functionName );
 				}
 				else {
 					throw new QueryException( "cannot handle version type [" + versionType + "] on bulk inserts with dialects not supporting parameters in insert-select statements" );
 				}
 			}
 
 			AST currentFirstSelectExprNode = selectClause.getFirstChild();
 			selectClause.setFirstChild( versionValueNode );
 			versionValueNode.setNextSibling( currentFirstSelectExprNode );
 
 			insertStatement.getIntoClause().prependVersionColumnSpec();
 		}
 
 		if ( insertStatement.getIntoClause().isDiscriminated() ) {
 			String sqlValue = insertStatement.getIntoClause().getQueryable().getDiscriminatorSQLValue();
 			AST discrimValue = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, sqlValue );
 			insertStatement.getSelectClause().addChild( discrimValue );
 		}
 
 	}
 
 	private boolean isDatabaseGeneratedTimestamp(Type type) {
 		// currently only the Hibernate-supplied DbTimestampType is supported here
 		return DbTimestampType.class.isAssignableFrom( type.getClass() );
 	}
 
 	private boolean isIntegral(Type type) {
 		return Long.class.isAssignableFrom( type.getReturnedClass() )
 		       || Integer.class.isAssignableFrom( type.getReturnedClass() )
 		       || long.class.isAssignableFrom( type.getReturnedClass() )
 		       || int.class.isAssignableFrom( type.getReturnedClass() );
 	}
 
 	private void useSelectClause(AST select) throws SemanticException {
 		selectClause = ( SelectClause ) select;
 		selectClause.initializeExplicitSelectClause( currentFromClause );
 	}
 
 	private void createSelectClauseFromFromClause(QueryNode qn) throws SemanticException {
 		AST select = astFactory.create( SELECT_CLAUSE, "{derived select clause}" );
 		AST sibling = qn.getFromClause();
 		qn.setFirstChild( select );
 		select.setNextSibling( sibling );
 		selectClause = ( SelectClause ) select;
 		selectClause.initializeDerivedSelectClause( currentFromClause );
         LOG.debugf("Derived SELECT clause created.");
 	}
 
 	@Override
     protected void resolve(AST node) throws SemanticException {
 		if ( node != null ) {
 			// This is called when it's time to fully resolve a path expression.
 			ResolvableNode r = ( ResolvableNode ) node;
 			if ( isInFunctionCall() ) {
 				r.resolveInFunctionCall( false, true );
 			}
 			else {
 				r.resolve( false, true );	// Generate implicit joins, only if necessary.
 			}
 		}
 	}
 
 	@Override
     protected void resolveSelectExpression(AST node) throws SemanticException {
 		// This is called when it's time to fully resolve a path expression.
 		int type = node.getType();
 		switch ( type ) {
 			case DOT: {
 				DotNode dot = ( DotNode ) node;
 				dot.resolveSelectExpression();
 				break;
 			}
 			case ALIAS_REF: {
 				// Notify the FROM element that it is being referenced by the select.
 				FromReferenceNode aliasRefNode = ( FromReferenceNode ) node;
 				//aliasRefNode.resolve( false, false, aliasRefNode.getText() ); //TODO: is it kosher to do it here?
 				aliasRefNode.resolve( false, false ); //TODO: is it kosher to do it here?
 				FromElement fromElement = aliasRefNode.getFromElement();
 				if ( fromElement != null ) {
 					fromElement.setIncludeSubclasses( true );
 				}
 				break;
 			}
 			default: {
 				break;
 			}
 		}
 	}
 
 	@Override
     protected void beforeSelectClause() throws SemanticException {
 		// Turn off includeSubclasses on all FromElements.
 		FromClause from = getCurrentFromClause();
 		List fromElements = from.getFromElements();
 		for ( Iterator iterator = fromElements.iterator(); iterator.hasNext(); ) {
 			FromElement fromElement = ( FromElement ) iterator.next();
 			fromElement.setIncludeSubclasses( false );
 		}
 	}
 
 	@Override
     protected AST generatePositionalParameter(AST inputNode) throws SemanticException {
 		if ( namedParameters.size() > 0 ) {
 			throw new SemanticException( "cannot define positional parameter after any named parameters have been defined" );
 		}
 		ParameterNode parameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 		PositionalParameterSpecification paramSpec = new PositionalParameterSpecification(
 				inputNode.getLine(),
 		        inputNode.getColumn(),
 				positionalParameterCount++
 		);
 		parameter.setHqlParameterSpecification( paramSpec );
 		parameters.add( paramSpec );
 		return parameter;
 	}
 
 	@Override
     protected AST generateNamedParameter(AST delimiterNode, AST nameNode) throws SemanticException {
 		String name = nameNode.getText();
 		trackNamedParameterPositions( name );
 
 		// create the node initially with the param name so that it shows
 		// appropriately in the "original text" attribute
 		ParameterNode parameter = ( ParameterNode ) astFactory.create( NAMED_PARAM, name );
 		parameter.setText( "?" );
 
 		NamedParameterSpecification paramSpec = new NamedParameterSpecification(
 				delimiterNode.getLine(),
 		        delimiterNode.getColumn(),
 				name
 		);
 		parameter.setHqlParameterSpecification( paramSpec );
 		parameters.add( paramSpec );
 		return parameter;
 	}
 
 	private void trackNamedParameterPositions(String name) {
 		Integer loc = new Integer( parameterCount++ );
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
 			( ( ArrayList ) o ).add( loc );
 		}
 	}
 
 	@Override
     protected void processConstant(AST constant) throws SemanticException {
 		literalProcessor.processConstant( constant, true );  // Use the delegate, resolve identifiers as FROM element aliases.
 	}
 
 	@Override
     protected void processBoolean(AST constant) throws SemanticException {
 		literalProcessor.processBoolean( constant );  // Use the delegate.
 	}
 
 	@Override
     protected void processNumericLiteral(AST literal) {
 		literalProcessor.processNumeric( literal );
 	}
 
 	@Override
     protected void processIndex(AST indexOp) throws SemanticException {
 		IndexNode indexNode = ( IndexNode ) indexOp;
 		indexNode.resolve( true, true );
 	}
 
 	@Override
     protected void processFunction(AST functionCall, boolean inSelect) throws SemanticException {
 		MethodNode methodNode = ( MethodNode ) functionCall;
 		methodNode.resolve( inSelect );
 	}
 
 	@Override
     protected void processAggregation(AST node, boolean inSelect) throws SemanticException {
 		AggregateNode aggregateNode = ( AggregateNode ) node;
 		aggregateNode.resolve();
 	}
 
 	@Override
     protected void processConstructor(AST constructor) throws SemanticException {
 		ConstructorNode constructorNode = ( ConstructorNode ) constructor;
 		constructorNode.prepare();
 	}
 
     @Override
     protected void setAlias(AST selectExpr, AST ident) {
         ((SelectExpression) selectExpr).setAlias(ident.getText());
 		// only put the alias (i.e., result variable) in selectExpressionsByResultVariable
 		// if is not defined in a subquery.
 		if ( ! isSubQuery() ) {
 			selectExpressionsByResultVariable.put( ident.getText(), ( SelectExpression ) selectExpr );
 		}
     }
 
 	@Override
     protected boolean isOrderExpressionResultVariableRef(AST orderExpressionNode) throws SemanticException {
 		// ORDER BY is not supported in a subquery
 		// TODO: should an exception be thrown if an ORDER BY is in a subquery?
 		if ( ! isSubQuery() &&
 				orderExpressionNode.getType() == IDENT &&
 				selectExpressionsByResultVariable.containsKey( orderExpressionNode.getText() ) ) {
 			return true;
 		}
 		return false;
 	}
 
 	@Override
     protected void handleResultVariableRef(AST resultVariableRef) throws SemanticException {
 		if ( isSubQuery() ) {
 			throw new SemanticException(
 					"References to result variables in subqueries are not supported."
 			);
 		}
 		( ( ResultVariableRefNode ) resultVariableRef ).setSelectExpression(
 				selectExpressionsByResultVariable.get( resultVariableRef.getText() )
 		);
 	}
 
 	/**
 	 * Returns the locations of all occurrences of the named parameter.
 	 */
 	public int[] getNamedParameterLocations(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			QueryException qe = new QueryException( QueryTranslator.ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name );
 			qe.setQueryString( queryTranslatorImpl.getQueryString() );
 			throw qe;
 		}
 		if ( o instanceof Integer ) {
 			return new int[]{( ( Integer ) o ).intValue()};
 		}
 		else {
 			return ArrayHelper.toIntArray( (ArrayList) o );
 		}
 	}
 
 	public void addQuerySpaces(Serializable[] spaces) {
 		querySpaces.addAll( Arrays.asList( spaces ) );
 	}
 
 	public Type[] getReturnTypes() {
 		return selectClause.getQueryReturnTypes();
 	}
 
 	public String[] getReturnAliases() {
 		return selectClause.getQueryReturnAliases();
 	}
 
 	public SelectClause getSelectClause() {
 		return selectClause;
 	}
 
 	public FromClause getFinalFromClause() {
 		FromClause top = currentFromClause;
 		while ( top.getParentFromClause() != null ) {
 			top = top.getParentFromClause();
 		}
 		return top;
 	}
 
 	public boolean isShallowQuery() {
 		// select clauses for insert statements should alwasy be treated as shallow
 		return getStatementType() == INSERT || queryTranslatorImpl.isShallowQuery();
 	}
 
 	public Map getEnabledFilters() {
 		return queryTranslatorImpl.getEnabledFilters();
 	}
 
 	public LiteralProcessor getLiteralProcessor() {
 		return literalProcessor;
 	}
 
 	public ASTPrinter getASTPrinter() {
 		return printer;
 	}
 
 	public ArrayList getParameters() {
 		return parameters;
 	}
 
 	public int getNumberOfParametersInSetClause() {
 		return numberOfParametersInSetClause;
 	}
 
 	@Override
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/QueryTranslatorImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/QueryTranslatorImpl.java
index c10ebd0f62..daacae6820 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/QueryTranslatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/QueryTranslatorImpl.java
@@ -1,600 +1,600 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.ast;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import antlr.ANTLRException;
 import antlr.RecognitionException;
 import antlr.TokenStreamException;
 import antlr.collections.AST;
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.RowSelection;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.hql.FilterTranslator;
 import org.hibernate.hql.ParameterTranslations;
 import org.hibernate.hql.QueryExecutionRequestException;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.antlr.HqlTokenTypes;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.exec.BasicExecutor;
 import org.hibernate.hql.ast.exec.MultiTableDeleteExecutor;
 import org.hibernate.hql.ast.exec.MultiTableUpdateExecutor;
 import org.hibernate.hql.ast.exec.StatementExecutor;
 import org.hibernate.hql.ast.tree.AggregatedSelectExpression;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.hql.ast.tree.InsertStatement;
 import org.hibernate.hql.ast.tree.QueryNode;
 import org.hibernate.hql.ast.tree.Statement;
 import org.hibernate.hql.ast.util.ASTPrinter;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.hql.ast.util.NodeTraverser;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.IdentitySet;
 import org.hibernate.loader.hql.QueryLoader;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.type.Type;
 
 /**
  * A QueryTranslator that uses an Antlr-based parser.
  *
  * @author Joshua Davis (pgmjsd@sourceforge.net)
  */
 public class QueryTranslatorImpl implements FilterTranslator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, QueryTranslatorImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QueryTranslatorImpl.class.getName());
 
 	private SessionFactoryImplementor factory;
 
 	private final String queryIdentifier;
 	private String hql;
 	private boolean shallowQuery;
 	private Map tokenReplacements;
 
 	private Map enabledFilters; //TODO:this is only needed during compilation .. can we eliminate the instvar?
 
 	private boolean compiled;
 	private QueryLoader queryLoader;
 	private StatementExecutor statementExecutor;
 
 	private Statement sqlAst;
 	private String sql;
 
 	private ParameterTranslations paramTranslations;
 	private List collectedParameterSpecifications;
 
 
 	/**
 	 * Creates a new AST-based query translator.
 	 *
 	 * @param queryIdentifier The query-identifier (used in stats collection)
 	 * @param query The hql query to translate
 	 * @param enabledFilters Currently enabled filters
 	 * @param factory The session factory constructing this translator instance.
 	 */
 	public QueryTranslatorImpl(
 			String queryIdentifier,
 	        String query,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		this.queryIdentifier = queryIdentifier;
 		this.hql = query;
 		this.compiled = false;
 		this.shallowQuery = false;
 		this.enabledFilters = enabledFilters;
 		this.factory = factory;
 	}
 
 	/**
 	 * Compile a "normal" query. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 *
 	 * @param replacements Defined query substitutions.
 	 * @param shallow      Does this represent a shallow (scalar or entity-id) select?
 	 * @throws QueryException   There was a problem parsing the query string.
 	 * @throws MappingException There was a problem querying defined mappings.
 	 */
 	public void compile(
 	        Map replacements,
 	        boolean shallow) throws QueryException, MappingException {
 		doCompile( replacements, shallow, null );
 	}
 
 	/**
 	 * Compile a filter. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 *
 	 * @param collectionRole the role name of the collection used as the basis for the filter.
 	 * @param replacements   Defined query substitutions.
 	 * @param shallow        Does this represent a shallow (scalar or entity-id) select?
 	 * @throws QueryException   There was a problem parsing the query string.
 	 * @throws MappingException There was a problem querying defined mappings.
 	 */
 	public void compile(
 	        String collectionRole,
 	        Map replacements,
 	        boolean shallow) throws QueryException, MappingException {
 		doCompile( replacements, shallow, collectionRole );
 	}
 
 	/**
 	 * Performs both filter and non-filter compiling.
 	 *
 	 * @param replacements   Defined query substitutions.
 	 * @param shallow        Does this represent a shallow (scalar or entity-id) select?
 	 * @param collectionRole the role name of the collection used as the basis for the filter, NULL if this
 	 *                       is not a filter.
 	 */
 	private synchronized void doCompile(Map replacements, boolean shallow, String collectionRole) {
 		// If the query is already compiled, skip the compilation.
 		if ( compiled ) {
             LOG.debugf("compile() : The query is already compiled, skipping...");
 			return;
 		}
 
 		// Remember the parameters for the compilation.
 		this.tokenReplacements = replacements;
 		if ( tokenReplacements == null ) {
 			tokenReplacements = new HashMap();
 		}
 		this.shallowQuery = shallow;
 
 		try {
 			// PHASE 1 : Parse the HQL into an AST.
 			HqlParser parser = parse( true );
 
 			// PHASE 2 : Analyze the HQL AST, and produce an SQL AST.
 			HqlSqlWalker w = analyze( parser, collectionRole );
 
 			sqlAst = ( Statement ) w.getAST();
 
 			// at some point the generate phase needs to be moved out of here,
 			// because a single object-level DML might spawn multiple SQL DML
 			// command executions.
 			//
 			// Possible to just move the sql generation for dml stuff, but for
 			// consistency-sake probably best to just move responsiblity for
 			// the generation phase completely into the delegates
 			// (QueryLoader/StatementExecutor) themselves.  Also, not sure why
 			// QueryLoader currently even has a dependency on this at all; does
 			// it need it?  Ideally like to see the walker itself given to the delegates directly...
 
 			if ( sqlAst.needsExecutor() ) {
 				statementExecutor = buildAppropriateStatementExecutor( w );
 			}
 			else {
 				// PHASE 3 : Generate the SQL.
 				generate( ( QueryNode ) sqlAst );
 				queryLoader = new QueryLoader( this, factory, w.getSelectClause() );
 			}
 
 			compiled = true;
 		}
 		catch ( QueryException qe ) {
 			qe.setQueryString( hql );
 			throw qe;
 		}
 		catch ( RecognitionException e ) {
             // we do not actually propagate ANTLRExceptions as a cause, so
 			// log it here for diagnostic purposes
             LOG.trace("Converted antlr.RecognitionException", e);
 			throw QuerySyntaxException.convert( e, hql );
 		}
 		catch ( ANTLRException e ) {
             // we do not actually propagate ANTLRExceptions as a cause, so
 			// log it here for diagnostic purposes
             LOG.trace("Converted antlr.ANTLRException", e);
 			throw new QueryException( e.getMessage(), hql );
 		}
 
 		this.enabledFilters = null; //only needed during compilation phase...
 	}
 
 	private void generate(AST sqlAst) throws QueryException, RecognitionException {
 		if ( sql == null ) {
 			SqlGenerator gen = new SqlGenerator(factory);
 			gen.statement( sqlAst );
 			sql = gen.getSQL();
             if (LOG.isDebugEnabled()) {
                 LOG.debugf("HQL: %s", hql);
                 LOG.debugf("SQL: %s", sql);
 			}
 			gen.getParseErrorHandler().throwQueryException();
 			collectedParameterSpecifications = gen.getCollectedParameters();
 		}
 	}
 
 	private HqlSqlWalker analyze(HqlParser parser, String collectionRole) throws QueryException, RecognitionException {
 		HqlSqlWalker w = new HqlSqlWalker( this, factory, parser, tokenReplacements, collectionRole );
 		AST hqlAst = parser.getAST();
 
 		// Transform the tree.
 		w.statement( hqlAst );
 
         if (LOG.isDebugEnabled()) {
 			ASTPrinter printer = new ASTPrinter( SqlTokenTypes.class );
             LOG.debug( printer.showAsString( w.getAST(), "--- SQL AST ---" ) );
 		}
 
 		w.getParseErrorHandler().throwQueryException();
 
 		return w;
 	}
 
 	private HqlParser parse(boolean filter) throws TokenStreamException, RecognitionException {
 		// Parse the query string into an HQL AST.
 		HqlParser parser = HqlParser.getInstance( hql );
 		parser.setFilter( filter );
 
         LOG.debugf("parse() - HQL: %s", hql);
 		parser.statement();
 
 		AST hqlAst = parser.getAST();
 
 		JavaConstantConverter converter = new JavaConstantConverter();
 		NodeTraverser walker = new NodeTraverser( converter );
 		walker.traverseDepthFirst( hqlAst );
 
 		showHqlAst( hqlAst );
 
 		parser.getParseErrorHandler().throwQueryException();
 		return parser;
 	}
 
 	void showHqlAst(AST hqlAst) {
         if (LOG.isDebugEnabled()) {
 			ASTPrinter printer = new ASTPrinter( HqlTokenTypes.class );
             LOG.debug( printer.showAsString( hqlAst, "--- HQL AST ---" ) );
 		}
 	}
 
 	private void errorIfDML() throws HibernateException {
 		if ( sqlAst.needsExecutor() ) {
 			throw new QueryExecutionRequestException( "Not supported for DML operations", hql );
 		}
 	}
 
 	private void errorIfSelect() throws HibernateException {
 		if ( !sqlAst.needsExecutor() ) {
 			throw new QueryExecutionRequestException( "Not supported for select queries", hql );
 		}
 	}
 
 	public String getQueryIdentifier() {
 		return queryIdentifier;
 	}
 
 	public Statement getSqlAST() {
 		return sqlAst;
 	}
 
 	private HqlSqlWalker getWalker() {
 		return sqlAst.getWalker();
 	}
 
 	/**
 	 * Types of the return values of an <tt>iterate()</tt> style query.
 	 *
 	 * @return an array of <tt>Type</tt>s.
 	 */
 	public Type[] getReturnTypes() {
 		errorIfDML();
 		return getWalker().getReturnTypes();
 	}
 
 	public String[] getReturnAliases() {
 		errorIfDML();
 		return getWalker().getReturnAliases();
 	}
 
 	public String[][] getColumnNames() {
 		errorIfDML();
 		return getWalker().getSelectClause().getColumnNames();
 	}
 
 	public Set getQuerySpaces() {
 		return getWalker().getQuerySpaces();
 	}
 
 	public List list(SessionImplementor session, QueryParameters queryParameters)
 			throws HibernateException {
 		// Delegate to the QueryLoader...
 		errorIfDML();
 		QueryNode query = ( QueryNode ) sqlAst;
 		boolean hasLimit = queryParameters.getRowSelection() != null && queryParameters.getRowSelection().definesLimits();
 		boolean needsDistincting = ( query.getSelectClause().isDistinct() || hasLimit ) && containsCollectionFetches();
 
 		QueryParameters queryParametersToUse;
 		if ( hasLimit && containsCollectionFetches() ) {
             LOG.firstOrMaxResultsSpecifiedWithCollectionFetch();
 			RowSelection selection = new RowSelection();
 			selection.setFetchSize( queryParameters.getRowSelection().getFetchSize() );
 			selection.setTimeout( queryParameters.getRowSelection().getTimeout() );
 			queryParametersToUse = queryParameters.createCopyUsing( selection );
 		}
 		else {
 			queryParametersToUse = queryParameters;
 		}
 
 		List results = queryLoader.list( session, queryParametersToUse );
 
 		if ( needsDistincting ) {
 			int includedCount = -1;
 			// NOTE : firstRow is zero-based
 			int first = !hasLimit || queryParameters.getRowSelection().getFirstRow() == null
 						? 0
 						: queryParameters.getRowSelection().getFirstRow().intValue();
 			int max = !hasLimit || queryParameters.getRowSelection().getMaxRows() == null
 						? -1
 						: queryParameters.getRowSelection().getMaxRows().intValue();
 			int size = results.size();
 			List tmp = new ArrayList();
 			IdentitySet distinction = new IdentitySet();
 			for ( int i = 0; i < size; i++ ) {
 				final Object result = results.get( i );
 				if ( !distinction.add( result ) ) {
 					continue;
 				}
 				includedCount++;
 				if ( includedCount < first ) {
 					continue;
 				}
 				tmp.add( result );
 				// NOTE : ( max - 1 ) because first is zero-based while max is not...
 				if ( max >= 0 && ( includedCount - first ) >= ( max - 1 ) ) {
 					break;
 				}
 			}
 			results = tmp;
 		}
 
 		return results;
 	}
 
 	/**
 	 * Return the query results as an iterator
 	 */
 	public Iterator iterate(QueryParameters queryParameters, EventSource session)
 			throws HibernateException {
 		// Delegate to the QueryLoader...
 		errorIfDML();
 		return queryLoader.iterate( queryParameters, session );
 	}
 
 	/**
 	 * Return the query results, as an instance of <tt>ScrollableResults</tt>
 	 */
 	public ScrollableResults scroll(QueryParameters queryParameters, SessionImplementor session)
 			throws HibernateException {
 		// Delegate to the QueryLoader...
 		errorIfDML();
 		return queryLoader.scroll( queryParameters, session );
 	}
 
 	public int executeUpdate(QueryParameters queryParameters, SessionImplementor session)
 			throws HibernateException {
 		errorIfSelect();
 		return statementExecutor.execute( queryParameters, session );
 	}
 
 	/**
 	 * The SQL query string to be called; implemented by all subclasses
 	 */
 	public String getSQLString() {
 		return sql;
 	}
 
 	public List collectSqlStrings() {
 		ArrayList list = new ArrayList();
 		if ( isManipulationStatement() ) {
 			String[] sqlStatements = statementExecutor.getSqlStatements();
 			for ( int i = 0; i < sqlStatements.length; i++ ) {
 				list.add( sqlStatements[i] );
 			}
 		}
 		else {
 			list.add( sql );
 		}
 		return list;
 	}
 
 	// -- Package local methods for the QueryLoader delegate --
 
 	public boolean isShallowQuery() {
 		return shallowQuery;
 	}
 
 	public String getQueryString() {
 		return hql;
 	}
 
 	public Map getEnabledFilters() {
 		return enabledFilters;
 	}
 
 	public int[] getNamedParameterLocs(String name) {
 		return getWalker().getNamedParameterLocations( name );
 	}
 
 	public boolean containsCollectionFetches() {
 		errorIfDML();
 		List collectionFetches = ( ( QueryNode ) sqlAst ).getFromClause().getCollectionFetches();
 		return collectionFetches != null && collectionFetches.size() > 0;
 	}
 
 	public boolean isManipulationStatement() {
 		return sqlAst.needsExecutor();
 	}
 
 	public void validateScrollability() throws HibernateException {
 		// Impl Note: allows multiple collection fetches as long as the
 		// entire fecthed graph still "points back" to a single
 		// root entity for return
 
 		errorIfDML();
 
 		QueryNode query = ( QueryNode ) sqlAst;
 
 		// If there are no collection fetches, then no further checks are needed
 		List collectionFetches = query.getFromClause().getCollectionFetches();
 		if ( collectionFetches.isEmpty() ) {
 			return;
 		}
 
 		// A shallow query is ok (although technically there should be no fetching here...)
 		if ( isShallowQuery() ) {
 			return;
 		}
 
 		// Otherwise, we have a non-scalar select with defined collection fetch(es).
 		// Make sure that there is only a single root entity in the return (no tuples)
 		if ( getReturnTypes().length > 1 ) {
 			throw new HibernateException( "cannot scroll with collection fetches and returned tuples" );
 		}
 
 		FromElement owner = null;
 		Iterator itr = query.getSelectClause().getFromElementsForLoad().iterator();
 		while ( itr.hasNext() ) {
 			// should be the first, but just to be safe...
 			final FromElement fromElement = ( FromElement ) itr.next();
 			if ( fromElement.getOrigin() == null ) {
 				owner = fromElement;
 				break;
 			}
 		}
 
 		if ( owner == null ) {
 			throw new HibernateException( "unable to locate collection fetch(es) owner for scrollability checks" );
 		}
 
 		// This is not strictly true.  We actually just need to make sure that
 		// it is ordered by root-entity PK and that that order-by comes before
 		// any non-root-entity ordering...
 
 		AST primaryOrdering = query.getOrderByClause().getFirstChild();
 		if ( primaryOrdering != null ) {
 			// TODO : this is a bit dodgy, come up with a better way to check this (plus see above comment)
 			String [] idColNames = owner.getQueryable().getIdentifierColumnNames();
 			String expectedPrimaryOrderSeq = StringHelper.join(
 			        ", ",
 			        StringHelper.qualify( owner.getTableAlias(), idColNames )
 			);
 			if (  !primaryOrdering.getText().startsWith( expectedPrimaryOrderSeq ) ) {
 				throw new HibernateException( "cannot scroll results with collection fetches which are not ordered primarily by the root entity's PK" );
 			}
 		}
 	}
 
 	private StatementExecutor buildAppropriateStatementExecutor(HqlSqlWalker walker) {
 		Statement statement = ( Statement ) walker.getAST();
 		if ( walker.getStatementType() == HqlSqlTokenTypes.DELETE ) {
 			FromElement fromElement = walker.getFinalFromClause().getFromElement();
 			Queryable persister = fromElement.getQueryable();
 			if ( persister.isMultiTable() ) {
 				return new MultiTableDeleteExecutor( walker );
 			}
 			else {
 				return new BasicExecutor( walker, persister );
 			}
 		}
 		else if ( walker.getStatementType() == HqlSqlTokenTypes.UPDATE ) {
 			FromElement fromElement = walker.getFinalFromClause().getFromElement();
 			Queryable persister = fromElement.getQueryable();
 			if ( persister.isMultiTable() ) {
 				// even here, if only properties mapped to the "base table" are referenced
 				// in the set and where clauses, this could be handled by the BasicDelegate.
 				// TODO : decide if it is better performance-wise to doAfterTransactionCompletion that check, or to simply use the MultiTableUpdateDelegate
 				return new MultiTableUpdateExecutor( walker );
 			}
 			else {
 				return new BasicExecutor( walker, persister );
 			}
 		}
 		else if ( walker.getStatementType() == HqlSqlTokenTypes.INSERT ) {
 			return new BasicExecutor( walker, ( ( InsertStatement ) statement ).getIntoClause().getQueryable() );
 		}
 		else {
 			throw new QueryException( "Unexpected statement type" );
 		}
 	}
 
 	public ParameterTranslations getParameterTranslations() {
 		if ( paramTranslations == null ) {
 			paramTranslations = new ParameterTranslationsImpl( getWalker().getParameters() );
 //			paramTranslations = new ParameterTranslationsImpl( collectedParameterSpecifications );
 		}
 		return paramTranslations;
 	}
 
 	public List getCollectedParameterSpecifications() {
 		return collectedParameterSpecifications;
 	}
 
 	@Override
 	public Class getDynamicInstantiationResultType() {
 		AggregatedSelectExpression aggregation = queryLoader.getAggregatedSelectExpression();
 		return aggregation == null ? null : aggregation.getAggregationResultType();
 	}
 
 	public static class JavaConstantConverter implements NodeTraverser.VisitationStrategy {
 		private AST dotRoot;
 		public void visit(AST node) {
 			if ( dotRoot != null ) {
 				// we are already processing a dot-structure
                 if (ASTUtil.isSubtreeChild(dotRoot, node)) return;
                 // we are now at a new tree level
                 dotRoot = null;
 			}
 
 			if ( dotRoot == null && node.getType() == HqlTokenTypes.DOT ) {
 				dotRoot = node;
 				handleDotStructure( dotRoot );
 			}
 		}
 		private void handleDotStructure(AST dotStructureRoot) {
 			String expression = ASTUtil.getPathText( dotStructureRoot );
 			Object constant = ReflectHelper.getConstantValue( expression );
 			if ( constant != null ) {
 				dotStructureRoot.setFirstChild( null );
 				dotStructureRoot.setType( HqlTokenTypes.JAVA_CONSTANT );
 				dotStructureRoot.setText( expression );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/SqlGenerator.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/SqlGenerator.java
index 19e4a83868..a753240b4b 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/SqlGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/SqlGenerator.java
@@ -1,367 +1,368 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.LinkedList;
 import java.util.List;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.hql.antlr.SqlGeneratorBase;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.hql.ast.tree.FunctionNode;
 import org.hibernate.hql.ast.tree.Node;
 import org.hibernate.hql.ast.tree.ParameterContainer;
 import org.hibernate.hql.ast.tree.ParameterNode;
 import org.hibernate.hql.ast.util.ASTPrinter;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.RecognitionException;
 import antlr.collections.AST;
 
 /**
  * Generates SQL by overriding callback methods in the base class, which does
  * the actual SQL AST walking.
  *
  * @author Joshua Davis
  * @author Steve Ebersole
  */
 public class SqlGenerator extends SqlGeneratorBase implements ErrorReporter {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SqlGenerator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SqlGenerator.class.getName());
 
 	public static boolean REGRESSION_STYLE_CROSS_JOINS = false;
 
 	/**
 	 * all append invocations on the buf should go through this Output instance variable.
 	 * The value of this variable may be temporarily substituted by sql function processing code
 	 * to catch generated arguments.
 	 * This is because sql function templates need arguments as separate string chunks
 	 * that will be assembled into the target dialect-specific function call.
 	 */
 	private SqlWriter writer = new DefaultWriter();
 
 	private ParseErrorHandler parseErrorHandler;
 	private SessionFactoryImplementor sessionFactory;
 	private LinkedList<SqlWriter> outputStack = new LinkedList<SqlWriter>();
 	private final ASTPrinter printer = new ASTPrinter( SqlTokenTypes.class );
 	private List collectedParameters = new ArrayList();
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private int traceDepth = 0;
 
 	@Override
     public void traceIn(String ruleName, AST tree) {
         if (!LOG.isTraceEnabled()) return;
         if (inputState.guessing > 0) return;
 		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
 		String traceText = ruleName + " (" + buildTraceNodeName(tree) + ")";
         LOG.trace(prefix + traceText);
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	@Override
     public void traceOut(String ruleName, AST tree) {
         if (!LOG.isTraceEnabled()) return;
         if (inputState.guessing > 0) return;
 		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
         LOG.trace(prefix + ruleName);
 	}
 
 	public List getCollectedParameters() {
 		return collectedParameters;
 	}
 
 	@Override
     protected void out(String s) {
 		writer.clause( s );
 	}
 
 	@Override
     protected void out(AST n) {
 		if ( n instanceof Node ) {
 			out( ( ( Node ) n ).getRenderText( sessionFactory ) );
 		}
 		else {
 			super.out( n );
 		}
 
 		if ( n instanceof ParameterNode ) {
 			collectedParameters.add( ( ( ParameterNode ) n ).getHqlParameterSpecification() );
 		}
 		else if ( n instanceof ParameterContainer ) {
 			if ( ( ( ParameterContainer ) n ).hasEmbeddedParameters() ) {
 				ParameterSpecification[] specifications = ( ( ParameterContainer ) n ).getEmbeddedParameters();
 				if ( specifications != null ) {
 					collectedParameters.addAll( Arrays.asList( specifications ) );
 				}
 			}
 		}
 	}
 
 	@Override
     protected void commaBetweenParameters(String comma) {
 		writer.commaBetweenParameters( comma );
 	}
 
 	@Override
     public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	@Override
     public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	@Override
     public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	public SqlGenerator(SessionFactoryImplementor sfi) {
 		super();
 		parseErrorHandler = new ErrorCounter();
 		sessionFactory = sfi;
 	}
 
 	public String getSQL() {
 		return getStringBuffer().toString();
 	}
 
 	@Override
     protected void optionalSpace() {
 		int c = getLastChar();
 		switch ( c ) {
 			case -1:
 				return;
 			case ' ':
 				return;
 			case ')':
 				return;
 			case '(':
 				return;
 			default:
 				out( " " );
 		}
 	}
 
 	@Override
     protected void beginFunctionTemplate(AST node, AST nameNode) {
 		// NOTE for AGGREGATE both nodes are the same; for METHOD the first is the METHOD, the second is the
 		// 		METHOD_NAME
 		FunctionNode functionNode = ( FunctionNode ) node;
 		SQLFunction sqlFunction = functionNode.getSQLFunction();
 		if ( sqlFunction == null ) {
 			// if SQLFunction is null we just write the function out as it appears in the hql statement
 			super.beginFunctionTemplate( node, nameNode );
 		}
 		else {
 			// this function has a registered SQLFunction -> redirect output and catch the arguments
 			outputStack.addFirst( writer );
 			writer = new FunctionArguments();
 		}
 	}
 
 	@Override
     protected void endFunctionTemplate(AST node) {
 		FunctionNode functionNode = ( FunctionNode ) node;
 		SQLFunction sqlFunction = functionNode.getSQLFunction();
 		if ( sqlFunction == null ) {
 			super.endFunctionTemplate( node );
 		}
 		else {
 			final Type functionType = functionNode.getFirstArgumentType();
 			// this function has a registered SQLFunction -> redirect output and catch the arguments
 			FunctionArguments functionArguments = ( FunctionArguments ) writer;
 			writer = outputStack.removeFirst();
 			out( sqlFunction.render( functionType, functionArguments.getArgs(), sessionFactory ) );
 		}
 	}
 
 	// --- Inner classes (moved here from sql-gen.g) ---
 
 	/**
 	 * Writes SQL fragments.
 	 */
 	interface SqlWriter {
 		void clause(String clause);
 
 		/**
 		 * todo remove this hack
 		 * The parameter is either ", " or " , ". This is needed to pass sql generating tests as the old
 		 * sql generator uses " , " in the WHERE and ", " in SELECT.
 		 *
 		 * @param comma either " , " or ", "
 		 */
 		void commaBetweenParameters(String comma);
 	}
 
 	/**
 	 * SQL function processing code redirects generated SQL output to an instance of this class
 	 * which catches function arguments.
 	 */
 	class FunctionArguments implements SqlWriter {
 		private int argInd;
 		private final List<String> args = new ArrayList<String>(3);
 
 		public void clause(String clause) {
 			if ( argInd == args.size() ) {
 				args.add( clause );
 			}
 			else {
 				args.set( argInd, args.get( argInd ) + clause );
 			}
 		}
 
 		public void commaBetweenParameters(String comma) {
 			++argInd;
 		}
 
 		public List getArgs() {
 			return args;
 		}
 	}
 
 	/**
 	 * The default SQL writer.
 	 */
 	class DefaultWriter implements SqlWriter {
 		public void clause(String clause) {
 			getStringBuffer().append( clause );
 		}
 
 		public void commaBetweenParameters(String comma) {
 			getStringBuffer().append( comma );
 		}
 	}
 
     public static void panic() {
 		throw new QueryException( "TreeWalker: panic" );
 	}
 
 	@Override
     protected void fromFragmentSeparator(AST a) {
 		// check two "adjecent" nodes at the top of the from-clause tree
 		AST next = a.getNextSibling();
 		if ( next == null || !hasText( a ) ) {
 			return;
 		}
 
 		FromElement left = ( FromElement ) a;
 		FromElement right = ( FromElement ) next;
 
 		///////////////////////////////////////////////////////////////////////
 		// HACK ALERT !!!!!!!!!!!!!!!!!!!!!!!!!!!!
 		// Attempt to work around "ghost" ImpliedFromElements that occasionally
 		// show up between the actual things being joined.  This consistently
 		// occurs from index nodes (at least against many-to-many).  Not sure
 		// if there are other conditions
 		//
 		// Essentially, look-ahead to the next FromElement that actually
 		// writes something to the SQL
 		while ( right != null && !hasText( right ) ) {
 			right = ( FromElement ) right.getNextSibling();
 		}
 		if ( right == null ) {
 			return;
 		}
 		///////////////////////////////////////////////////////////////////////
 
 		if ( !hasText( right ) ) {
 			return;
 		}
 
 		if ( right.getRealOrigin() == left ||
 		     ( right.getRealOrigin() != null && right.getRealOrigin() == left.getRealOrigin() ) ) {
 			// right represents a joins originating from left; or
 			// both right and left reprersent joins originating from the same FromElement
 			if ( right.getJoinSequence() != null && right.getJoinSequence().isThetaStyle() ) {
 				writeCrossJoinSeparator();
 			}
 			else {
 				out( " " );
 			}
 		}
 		else {
 			// these are just two unrelated table references
 			writeCrossJoinSeparator();
 		}
 	}
 
 	private void writeCrossJoinSeparator() {
 		if ( REGRESSION_STYLE_CROSS_JOINS ) {
 			out( ", " );
 		}
 		else {
 			out( sessionFactory.getDialect().getCrossJoinSeparator() );
 		}
 	}
 
 	@Override
     protected void nestedFromFragment(AST d, AST parent) {
 		// check a set of parent/child nodes in the from-clause tree
 		// to determine if a comma is required between them
 		if ( d != null && hasText( d ) ) {
 			if ( parent != null && hasText( parent ) ) {
 				// again, both should be FromElements
 				FromElement left = ( FromElement ) parent;
 				FromElement right = ( FromElement ) d;
 				if ( right.getRealOrigin() == left ) {
 					// right represents a joins originating from left...
 					if ( right.getJoinSequence() != null && right.getJoinSequence().isThetaStyle() ) {
 						out( ", " );
 					}
 					else {
 						out( " " );
 					}
 				}
 				else {
 					// not so sure this is even valid subtree.  but if it was, it'd
 					// represent two unrelated table references...
 					out( ", " );
 				}
 			}
 			out( d );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/AbstractStatementExecutor.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/AbstractStatementExecutor.java
index 8fbe3d4d19..c151332ddc 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/AbstractStatementExecutor.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/AbstractStatementExecutor.java
@@ -1,308 +1,308 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.ast.exec;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLWarning;
 import java.sql.Statement;
 import java.util.Collections;
 import java.util.List;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.action.internal.BulkOperationCleanupAction;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.event.EventSource;
 import org.hibernate.hql.ast.HqlSqlWalker;
 import org.hibernate.hql.ast.SqlGenerator;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.jdbc.AbstractWork;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.InsertSelect;
 import org.hibernate.sql.Select;
 import org.hibernate.sql.SelectFragment;
 import org.jboss.logging.Logger;
 import antlr.RecognitionException;
 import antlr.collections.AST;
 
 /**
  * Implementation of AbstractStatementExecutor.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractStatementExecutor implements StatementExecutor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractStatementExecutor.class.getName());
 
 	private final HqlSqlWalker walker;
 	private List idSelectParameterSpecifications = Collections.EMPTY_LIST;
 
     public AbstractStatementExecutor( HqlSqlWalker walker,
-                                      HibernateLogger log ) {
+                                      CoreMessageLogger log ) {
 		this.walker = walker;
 	}
 
 	protected HqlSqlWalker getWalker() {
 		return walker;
 	}
 
 	protected SessionFactoryImplementor getFactory() {
 		return walker.getSessionFactoryHelper().getFactory();
 	}
 
 	protected List getIdSelectParameterSpecifications() {
 		return idSelectParameterSpecifications;
 	}
 
 	protected abstract Queryable[] getAffectedQueryables();
 
 	protected String generateIdInsertSelect(Queryable persister, String tableAlias, AST whereClause) {
 		Select select = new Select( getFactory().getDialect() );
 		SelectFragment selectFragment = new SelectFragment()
 				.addColumns( tableAlias, persister.getIdentifierColumnNames(), persister.getIdentifierColumnNames() );
 		select.setSelectClause( selectFragment.toFragmentString().substring( 2 ) );
 
 		String rootTableName = persister.getTableName();
 		String fromJoinFragment = persister.fromJoinFragment( tableAlias, true, false );
 		String whereJoinFragment = persister.whereJoinFragment( tableAlias, true, false );
 
 		select.setFromClause( rootTableName + ' ' + tableAlias + fromJoinFragment );
 
 		if ( whereJoinFragment == null ) {
 			whereJoinFragment = "";
 		}
 		else {
 			whereJoinFragment = whereJoinFragment.trim();
 			if ( whereJoinFragment.startsWith( "and" ) ) {
 				whereJoinFragment = whereJoinFragment.substring( 4 );
 			}
 		}
 
 		String userWhereClause = "";
 		if ( whereClause.getNumberOfChildren() != 0 ) {
 			// If a where clause was specified in the update/delete query, use it to limit the
 			// returned ids here...
 			try {
 				SqlGenerator sqlGenerator = new SqlGenerator( getFactory() );
 				sqlGenerator.whereClause( whereClause );
 				userWhereClause = sqlGenerator.getSQL().substring( 7 );  // strip the " where "
 				idSelectParameterSpecifications = sqlGenerator.getCollectedParameters();
 			}
 			catch ( RecognitionException e ) {
 				throw new HibernateException( "Unable to generate id select for DML operation", e );
 			}
 			if ( whereJoinFragment.length() > 0 ) {
 				whereJoinFragment += " and ";
 			}
 		}
 
 		select.setWhereClause( whereJoinFragment + userWhereClause );
 
 		InsertSelect insert = new InsertSelect( getFactory().getDialect() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert-select for " + persister.getEntityName() + " ids" );
 		}
 		insert.setTableName( persister.getTemporaryIdTableName() );
 		insert.setSelect( select );
 		return insert.toStatementString();
 	}
 
 	protected String generateIdSubselect(Queryable persister) {
 		return "select " + StringHelper.join( ", ", persister.getIdentifierColumnNames() ) +
 			        " from " + persister.getTemporaryIdTableName();
 	}
 
 	private static class TemporaryTableCreationWork extends AbstractWork {
 		private final Queryable persister;
 
 		private TemporaryTableCreationWork(Queryable persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public void execute(Connection connection) {
 			try {
 				Statement statement = connection.createStatement();
 				try {
 					statement.executeUpdate( persister.getTemporaryIdTableDDL() );
 					persister.getFactory()
 							.getServiceRegistry()
 							.getService( JdbcServices.class )
 							.getSqlExceptionHelper()
 							.handleAndClearWarnings( statement, CREATION_WARNING_HANDLER );
 				}
 				finally {
 					try {
 						statement.close();
 					}
 					catch( Throwable ignore ) {
 						// ignore
 					}
 				}
 			}
 			catch( Exception e ) {
 				LOG.debug( "unable to create temporary id table [" + e.getMessage() + "]" );
 			}
 		}
 	}
 	protected void createTemporaryTableIfNecessary(final Queryable persister, final SessionImplementor session) {
 		// Don't really know all the codes required to adequately decipher returned jdbc exceptions here.
 		// simply allow the failure to be eaten and the subsequent insert-selects/deletes should fail
 		TemporaryTableCreationWork work = new TemporaryTableCreationWork( persister );
 		if ( shouldIsolateTemporaryTableDDL() ) {
 			session.getTransactionCoordinator()
 					.getTransaction()
 					.createIsolationDelegate()
 					.delegateWork( work, getFactory().getSettings().isDataDefinitionInTransactionSupported() );
 		}
 		else {
 			final Connection connection = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getLogicalConnection()
 					.getShareableConnectionProxy();
 			work.execute( connection );
 			session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getLogicalConnection()
 					.afterStatementExecution();
 		}
 	}
 
 	private static SqlExceptionHelper.WarningHandler CREATION_WARNING_HANDLER = new SqlExceptionHelper.WarningHandlerLoggingSupport() {
 		public boolean doProcess() {
 			return LOG.isDebugEnabled();
 		}
 
 		public void prepare(SQLWarning warning) {
             LOG.warningsCreatingTempTable(warning);
 		}
 
 		@Override
 		protected void logWarning(String description, String message) {
             LOG.debugf(description);
             LOG.debugf(message);
 		}
 	};
 
 	private static class TemporaryTableDropWork extends AbstractWork {
 		private final Queryable persister;
 		private final SessionImplementor session;
 
 		private TemporaryTableDropWork(Queryable persister, SessionImplementor session) {
 			this.persister = persister;
 			this.session = session;
 		}
 
 		@Override
 		public void execute(Connection connection) {
 			final String command = session.getFactory().getDialect().getDropTemporaryTableString()
 					+ ' ' + persister.getTemporaryIdTableName();
 			try {
 				Statement statement = connection.createStatement();
 				try {
 					statement = connection.createStatement();
 					statement.executeUpdate( command );
 				}
 				finally {
 					try {
 						statement.close();
 					}
 					catch( Throwable ignore ) {
 						// ignore
 					}
 				}
 			}
 			catch( Exception e ) {
 				LOG.warn( "unable to drop temporary id table after use [" + e.getMessage() + "]" );
 			}
 		}
 	}
 
 	protected void dropTemporaryTableIfNecessary(final Queryable persister, final SessionImplementor session) {
 		if ( getFactory().getDialect().dropTemporaryTableAfterUse() ) {
 			TemporaryTableDropWork work = new TemporaryTableDropWork( persister, session );
 			if ( shouldIsolateTemporaryTableDDL() ) {
 				session.getTransactionCoordinator()
 						.getTransaction()
 						.createIsolationDelegate()
 						.delegateWork( work, getFactory().getSettings().isDataDefinitionInTransactionSupported() );
 			}
 			else {
 				final Connection connection = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getLogicalConnection()
 						.getShareableConnectionProxy();
 				work.execute( connection );
 				session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getLogicalConnection()
 						.afterStatementExecution();
 			}
 		}
 		else {
 			// at the very least cleanup the data :)
 			PreparedStatement ps = null;
 			try {
 				final String sql = "delete from " + persister.getTemporaryIdTableName();
 				ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql, false );
 				ps.executeUpdate();
 			}
 			catch( Throwable t ) {
                 LOG.unableToCleanupTemporaryIdTable(t);
 			}
 			finally {
 				if ( ps != null ) {
 					try {
 						ps.close();
 					}
 					catch( Throwable ignore ) {
 						// ignore
 					}
 				}
 			}
 		}
 	}
 
 	protected void coordinateSharedCacheCleanup(SessionImplementor session) {
 		BulkOperationCleanupAction action = new BulkOperationCleanupAction( session, getAffectedQueryables() );
 
 		if ( session.isEventSource() ) {
 			( ( EventSource ) session ).getActionQueue().addAction( action );
 		}
 		else {
 			action.getAfterTransactionCompletionProcess().doAfterTransactionCompletion( true, session );
 		}
 	}
 
 	@SuppressWarnings({ "UnnecessaryUnboxing" })
 	protected boolean shouldIsolateTemporaryTableDDL() {
 		Boolean dialectVote = getFactory().getDialect().performTemporaryTableDDLInIsolation();
         if (dialectVote != null) return dialectVote.booleanValue();
         return getFactory().getSettings().isDataDefinitionImplicitCommit();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/MultiTableDeleteExecutor.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/MultiTableDeleteExecutor.java
index dfa63a0368..7504b5e302 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/MultiTableDeleteExecutor.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/MultiTableDeleteExecutor.java
@@ -1,164 +1,164 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.exec;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.hql.ast.HqlSqlWalker;
 import org.hibernate.hql.ast.tree.DeleteStatement;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.Delete;
 import org.jboss.logging.Logger;
 
 /**
  * Implementation of MultiTableDeleteExecutor.
  *
  * @author Steve Ebersole
  */
 public class MultiTableDeleteExecutor extends AbstractStatementExecutor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        MultiTableDeleteExecutor.class.getName());
 
 	private final Queryable persister;
 	private final String idInsertSelect;
 	private final String[] deletes;
 
 	public MultiTableDeleteExecutor(HqlSqlWalker walker) {
         super(walker, null);
 
 		if ( !walker.getSessionFactoryHelper().getFactory().getDialect().supportsTemporaryTables() ) {
 			throw new HibernateException( "cannot doAfterTransactionCompletion multi-table deletes using dialect not supporting temp tables" );
 		}
 
 		DeleteStatement deleteStatement = ( DeleteStatement ) walker.getAST();
 		FromElement fromElement = deleteStatement.getFromClause().getFromElement();
 		String bulkTargetAlias = fromElement.getTableAlias();
 		this.persister = fromElement.getQueryable();
 
 		this.idInsertSelect = generateIdInsertSelect( persister, bulkTargetAlias, deleteStatement.getWhereClause() );
         LOG.trace("Generated ID-INSERT-SELECT SQL (multi-table delete) : " + idInsertSelect);
 
 		String[] tableNames = persister.getConstraintOrderedTableNameClosure();
 		String[][] columnNames = persister.getContraintOrderedTableKeyColumnClosure();
 		String idSubselect = generateIdSubselect( persister );
 
 		deletes = new String[tableNames.length];
 		for ( int i = tableNames.length - 1; i >= 0; i-- ) {
 			// TODO : an optimization here would be to consider cascade deletes and not gen those delete statements;
 			//      the difficulty is the ordering of the tables here vs the cascade attributes on the persisters ->
 			//          the table info gotten here should really be self-contained (i.e., a class representation
 			//          defining all the needed attributes), then we could then get an array of those
 			final Delete delete = new Delete()
 					.setTableName( tableNames[i] )
 					.setWhere( "(" + StringHelper.join( ", ", columnNames[i] ) + ") IN (" + idSubselect + ")" );
 			if ( getFactory().getSettings().isCommentsEnabled() ) {
 				delete.setComment( "bulk delete" );
 			}
 
 			deletes[i] = delete.toStatementString();
 		}
 	}
 
 	public String[] getSqlStatements() {
 		return deletes;
 	}
 
 	public int execute(QueryParameters parameters, SessionImplementor session) throws HibernateException {
 		coordinateSharedCacheCleanup( session );
 
 		createTemporaryTableIfNecessary( persister, session );
 
 		try {
 			// First, save off the pertinent ids, saving the number of pertinent ids for return
 			PreparedStatement ps = null;
 			int resultCount = 0;
 			try {
 				try {
 					ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( idInsertSelect, false );
 					Iterator paramSpecifications = getIdSelectParameterSpecifications().iterator();
 					int pos = 1;
 					while ( paramSpecifications.hasNext() ) {
 						final ParameterSpecification paramSpec = ( ParameterSpecification ) paramSpecifications.next();
 						pos += paramSpec.bind( ps, parameters, session, pos );
 					}
 					resultCount = ps.executeUpdate();
 				}
 				finally {
 					if ( ps != null ) {
 						ps.close();
 					}
 				}
 			}
 			catch( SQLException e ) {
 				throw getFactory().getSQLExceptionHelper().convert(
 				        e,
 				        "could not insert/select ids for bulk delete",
 				        idInsertSelect
 					);
 			}
 
 			// Start performing the deletes
 			for ( int i = 0; i < deletes.length; i++ ) {
 				try {
 					try {
 						ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( deletes[i], false );
 						ps.executeUpdate();
 					}
 					finally {
 						if ( ps != null ) {
 							ps.close();
 						}
 					}
 				}
 				catch( SQLException e ) {
 					throw getFactory().getSQLExceptionHelper().convert(
 					        e,
 					        "error performing bulk delete",
 					        deletes[i]
 						);
 				}
 			}
 
 			return resultCount;
 		}
 		finally {
 			dropTemporaryTableIfNecessary( persister, session );
 		}
 	}
 
 	@Override
     protected Queryable[] getAffectedQueryables() {
 		return new Queryable[] { persister };
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/MultiTableUpdateExecutor.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/MultiTableUpdateExecutor.java
index f0e6ca6665..dd9f5f0c36 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/MultiTableUpdateExecutor.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/exec/MultiTableUpdateExecutor.java
@@ -1,199 +1,199 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.exec;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.hql.ast.HqlSqlWalker;
 import org.hibernate.hql.ast.tree.AssignmentSpecification;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.hql.ast.tree.UpdateStatement;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.Update;
 import org.jboss.logging.Logger;
 
 /**
  * Implementation of MultiTableUpdateExecutor.
  *
  * @author Steve Ebersole
  */
 public class MultiTableUpdateExecutor extends AbstractStatementExecutor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        MultiTableUpdateExecutor.class.getName());
 
 	private final Queryable persister;
 	private final String idInsertSelect;
 	private final String[] updates;
 	private final ParameterSpecification[][] hqlParameters;
 
 	public MultiTableUpdateExecutor(HqlSqlWalker walker) {
         super(walker, null);
 
 		if ( !walker.getSessionFactoryHelper().getFactory().getDialect().supportsTemporaryTables() ) {
 			throw new HibernateException( "cannot doAfterTransactionCompletion multi-table updates using dialect not supporting temp tables" );
 		}
 
 		UpdateStatement updateStatement = ( UpdateStatement ) walker.getAST();
 		FromElement fromElement = updateStatement.getFromClause().getFromElement();
 		String bulkTargetAlias = fromElement.getTableAlias();
 		this.persister = fromElement.getQueryable();
 
 		this.idInsertSelect = generateIdInsertSelect( persister, bulkTargetAlias, updateStatement.getWhereClause() );
         LOG.trace("Generated ID-INSERT-SELECT SQL (multi-table update) : " + idInsertSelect);
 
 		String[] tableNames = persister.getConstraintOrderedTableNameClosure();
 		String[][] columnNames = persister.getContraintOrderedTableKeyColumnClosure();
 
 		String idSubselect = generateIdSubselect( persister );
 		List assignmentSpecifications = walker.getAssignmentSpecifications();
 
 		updates = new String[tableNames.length];
 		hqlParameters = new ParameterSpecification[tableNames.length][];
 		for ( int tableIndex = 0; tableIndex < tableNames.length; tableIndex++ ) {
 			boolean affected = false;
 			List parameterList = new ArrayList();
 			Update update = new Update( getFactory().getDialect() )
 					.setTableName( tableNames[tableIndex] )
 					.setWhere( "(" + StringHelper.join( ", ", columnNames[tableIndex] ) + ") IN (" + idSubselect + ")" );
 			if ( getFactory().getSettings().isCommentsEnabled() ) {
 				update.setComment( "bulk update" );
 			}
 			final Iterator itr = assignmentSpecifications.iterator();
 			while ( itr.hasNext() ) {
 				final AssignmentSpecification specification = ( AssignmentSpecification ) itr.next();
 				if ( specification.affectsTable( tableNames[tableIndex] ) ) {
 					affected = true;
 					update.appendAssignmentFragment( specification.getSqlAssignmentFragment() );
 					if ( specification.getParameters() != null ) {
 						for ( int paramIndex = 0; paramIndex < specification.getParameters().length; paramIndex++ ) {
 							parameterList.add( specification.getParameters()[paramIndex] );
 						}
 					}
 				}
 			}
 			if ( affected ) {
 				updates[tableIndex] = update.toStatementString();
 				hqlParameters[tableIndex] = ( ParameterSpecification[] ) parameterList.toArray( new ParameterSpecification[0] );
 			}
 		}
 	}
 
 	public Queryable getAffectedQueryable() {
 		return persister;
 	}
 
 	public String[] getSqlStatements() {
 		return updates;
 	}
 
 	public int execute(QueryParameters parameters, SessionImplementor session) throws HibernateException {
 		coordinateSharedCacheCleanup( session );
 
 		createTemporaryTableIfNecessary( persister, session );
 
 		try {
 			// First, save off the pertinent ids, as the return value
 			PreparedStatement ps = null;
 			int resultCount = 0;
 			try {
 				try {
 					ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( idInsertSelect, false );
 //					int parameterStart = getWalker().getNumberOfParametersInSetClause();
 //					List allParams = getIdSelectParameterSpecifications();
 //					Iterator whereParams = allParams.subList( parameterStart, allParams.size() ).iterator();
 					Iterator whereParams = getIdSelectParameterSpecifications().iterator();
 					int sum = 1; // jdbc params are 1-based
 					while ( whereParams.hasNext() ) {
 						sum += ( ( ParameterSpecification ) whereParams.next() ).bind( ps, parameters, session, sum );
 					}
 					resultCount = ps.executeUpdate();
 				}
 				finally {
 					if ( ps != null ) {
 						ps.close();
 					}
 				}
 			}
 			catch( SQLException e ) {
 				throw getFactory().getSQLExceptionHelper().convert(
 				        e,
 				        "could not insert/select ids for bulk update",
 				        idInsertSelect
 					);
 			}
 
 			// Start performing the updates
 			for ( int i = 0; i < updates.length; i++ ) {
 				if ( updates[i] == null ) {
 					continue;
 				}
 				try {
 					try {
 						ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( updates[i], false );
 						if ( hqlParameters[i] != null ) {
 							int position = 1; // jdbc params are 1-based
 							for ( int x = 0; x < hqlParameters[i].length; x++ ) {
 								position += hqlParameters[i][x].bind( ps, parameters, session, position );
 							}
 						}
 						ps.executeUpdate();
 					}
 					finally {
 						if ( ps != null ) {
 							ps.close();
 						}
 					}
 				}
 				catch( SQLException e ) {
 					throw getFactory().getSQLExceptionHelper().convert(
 					        e,
 					        "error performing bulk update",
 					        updates[i]
 						);
 				}
 			}
 
 			return resultCount;
 		}
 		finally {
 			dropTemporaryTableIfNecessary( persister, session );
 		}
 	}
 
 	@Override
     protected Queryable[] getAffectedQueryables() {
 		return new Queryable[] { persister };
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/AbstractRestrictableStatement.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/AbstractRestrictableStatement.java
index c15506631d..a23eabadaf 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/AbstractRestrictableStatement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/AbstractRestrictableStatement.java
@@ -1,86 +1,86 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.ast.util.ASTUtil;
 import antlr.collections.AST;
 
 /**
  * Convenience implementation of {@link RestrictableStatement}
  * to centralize common functionality.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractRestrictableStatement extends AbstractStatement implements RestrictableStatement {
 
 	private FromClause fromClause;
 	private AST whereClause;
 
 	protected abstract int getWhereClauseParentTokenType();
 
-    protected abstract HibernateLogger getLog();
+    protected abstract CoreMessageLogger getLog();
 
 	/**
 	 * @see org.hibernate.hql.ast.tree.RestrictableStatement#getFromClause
 	 */
 	public final FromClause getFromClause() {
 		if ( fromClause == null ) {
 			fromClause = ( FromClause ) ASTUtil.findTypeInChildren( this, HqlSqlTokenTypes.FROM );
 		}
 		return fromClause;
 	}
 
 	/**
 	 * @see RestrictableStatement#hasWhereClause
 	 */
 	public final boolean hasWhereClause() {
 		AST whereClause = locateWhereClause();
 		return whereClause != null && whereClause.getNumberOfChildren() > 0;
 	}
 
 	/**
 	 * @see org.hibernate.hql.ast.tree.RestrictableStatement#getWhereClause
 	 */
 	public final AST getWhereClause() {
 		if ( whereClause == null ) {
 			whereClause = locateWhereClause();
 			// If there is no WHERE node, make one.
 			if ( whereClause == null ) {
 				getLog().debug( "getWhereClause() : Creating a new WHERE clause..." );
 				whereClause = ASTUtil.create( getWalker().getASTFactory(), HqlSqlTokenTypes.WHERE, "WHERE" );
 				// inject the WHERE after the parent
 				AST parent = ASTUtil.findTypeInChildren( this, getWhereClauseParentTokenType() );
 				whereClause.setNextSibling( parent.getNextSibling() );
 				parent.setNextSibling( whereClause );
 			}
 		}
 		return whereClause;
 	}
 
 	protected AST locateWhereClause() {
 		return ASTUtil.findTypeInChildren( this, HqlSqlTokenTypes.WHERE );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/AggregateNode.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/AggregateNode.java
index 0fe2b51454..0fc0e60828 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/AggregateNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/AggregateNode.java
@@ -1,94 +1,94 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.ast.tree;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.hql.ast.util.ColumnHelper;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents an aggregate function i.e. min, max, sum, avg.
  *
  * @author Joshua Davis
  */
 public class AggregateNode extends AbstractSelectExpression implements SelectExpression, FunctionNode {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, AggregateNode.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, AggregateNode.class.getName());
 
 	private SQLFunction sqlFunction;
 
 	public SQLFunction getSQLFunction() {
 		return sqlFunction;
 	}
 
 	public void resolve() {
 		resolveFunction();
 	}
 
 	private SQLFunction resolveFunction() {
 		if ( sqlFunction == null ) {
 			final String name = getText();
 			sqlFunction = getSessionFactoryHelper().findSQLFunction( getText() );
 			if ( sqlFunction == null ) {
                 LOG.unableToResolveAggregateFunction(name);
 				sqlFunction = new StandardSQLFunction( name );
 			}
 		}
 		return sqlFunction;
 	}
 
 	public Type getFirstArgumentType() {
 		AST argument = getFirstChild();
 		while ( argument != null ) {
 			if ( argument instanceof SqlNode ) {
 				final Type type = ( (SqlNode) argument ).getDataType();
 				if ( type != null ) {
 					return type;
 				}
 				argument = argument.getNextSibling();
 			}
 		}
 		return null;
 	}
 
 	@Override
     public Type getDataType() {
 		// Get the function return value type, based on the type of the first argument.
 		return getSessionFactoryHelper().findFunctionReturnType( getText(), resolveFunction(), getFirstChild() );
 	}
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		ColumnHelper.generateSingleScalarColumn( this, i );
 	}
 
 	@Override
     public boolean isScalar() throws SemanticException {
 		// functions in a SELECT should always be considered scalar.
 		return true;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/DeleteStatement.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/DeleteStatement.java
index c3cb3e4563..9cf021b8ab 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/DeleteStatement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/DeleteStatement.java
@@ -1,63 +1,64 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.antlr.SqlTokenTypes;
+
 import org.jboss.logging.Logger;
 
 /**
  * Defines a top-level AST node representing an HQL delete statement.
  *
  * @author Steve Ebersole
  */
 public class DeleteStatement extends AbstractRestrictableStatement {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, DeleteStatement.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DeleteStatement.class.getName());
 
 	/**
 	 * @see org.hibernate.hql.ast.tree.Statement#getStatementType()
 	 */
 	public int getStatementType() {
 		return HqlSqlTokenTypes.DELETE;
 	}
 
 	/**
 	 * @see org.hibernate.hql.ast.tree.Statement#needsExecutor()
 	 */
 	public boolean needsExecutor() {
 		return true;
 	}
 
 	@Override
     protected int getWhereClauseParentTokenType() {
 		return SqlTokenTypes.FROM;
 	}
 
     @Override
-    protected HibernateLogger getLog() {
+    protected CoreMessageLogger getLog() {
         return LOG;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/DotNode.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/DotNode.java
index 7b5e81757d..7371365675 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/DotNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/DotNode.java
@@ -1,689 +1,689 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.hql.CollectionProperties;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.hql.ast.util.ColumnHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents a reference to a property or alias expression.  This should duplicate the relevant behaviors in
  * PathExpressionParser.
  *
  * @author Joshua Davis
  */
 public class DotNode extends FromReferenceNode implements DisplayableNode, SelectExpression {
 
 	///////////////////////////////////////////////////////////////////////////
 	// USED ONLY FOR REGRESSION TESTING!!!!
 	//
 	// todo : obviously get rid of all this junk ;)
 	///////////////////////////////////////////////////////////////////////////
 	public static boolean useThetaStyleImplicitJoins = false;
 	public static boolean REGRESSION_STYLE_JOIN_SUPPRESSION = false;
 	public static interface IllegalCollectionDereferenceExceptionBuilder {
 		public QueryException buildIllegalCollectionDereferenceException(String collectionPropertyName, FromReferenceNode lhs);
 	}
 	public static final IllegalCollectionDereferenceExceptionBuilder DEF_ILLEGAL_COLL_DEREF_EXCP_BUILDER = new IllegalCollectionDereferenceExceptionBuilder() {
 		public QueryException buildIllegalCollectionDereferenceException(String propertyName, FromReferenceNode lhs) {
 			String lhsPath = ASTUtil.getPathText( lhs );
 			return new QueryException( "illegal attempt to dereference collection [" + lhsPath + "] with element property reference [" + propertyName + "]" );
 		}
 	};
 	public static IllegalCollectionDereferenceExceptionBuilder ILLEGAL_COLL_DEREF_EXCP_BUILDER = DEF_ILLEGAL_COLL_DEREF_EXCP_BUILDER;
 	///////////////////////////////////////////////////////////////////////////
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, DotNode.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DotNode.class.getName());
 
 	private static final int DEREF_UNKNOWN = 0;
 	private static final int DEREF_ENTITY = 1;
 	private static final int DEREF_COMPONENT = 2;
 	private static final int DEREF_COLLECTION = 3;
 	private static final int DEREF_PRIMITIVE = 4;
 	private static final int DEREF_IDENTIFIER = 5;
 	private static final int DEREF_JAVA_CONSTANT = 6;
 
 	/**
 	 * The identifier that is the name of the property.
 	 */
 	private String propertyName;
 	/**
 	 * The full path, to the root alias of this dot node.
 	 */
 	private String path;
 	/**
 	 * The unresolved property path relative to this dot node.
 	 */
 	private String propertyPath;
 
 	/**
 	 * The column names that this resolves to.
 	 */
 	private String[] columns;
 
 	/**
 	 * The type of join to create.   Default is an inner join.
 	 */
 	private int joinType = JoinFragment.INNER_JOIN;
 
 	/**
 	 * Fetch join or not.
 	 */
 	private boolean fetch = false;
 
 	/**
 	 * The type of dereference that hapened (DEREF_xxx).
 	 */
 	private int dereferenceType = DEREF_UNKNOWN;
 
 	private FromElement impliedJoin;
 
 	/**
 	 * Sets the join type for this '.' node structure.
 	 *
 	 * @param joinType The type of join to use.
 	 * @see JoinFragment
 	 */
 	public void setJoinType(int joinType) {
 		this.joinType = joinType;
 	}
 
 	private String[] getColumns() throws QueryException {
 		if ( columns == null ) {
 			// Use the table fromElement and the property name to get the array of column names.
 			String tableAlias = getLhs().getFromElement().getTableAlias();
 			columns = getFromElement().toColumns( tableAlias, propertyPath, false );
 		}
 		return columns;
 	}
 
 	@Override
     public String getDisplayText() {
 		StringBuffer buf = new StringBuffer();
 		FromElement fromElement = getFromElement();
 		buf.append( "{propertyName=" ).append( propertyName );
 		buf.append( ",dereferenceType=" ).append( getWalker().getASTPrinter().getTokenTypeName( dereferenceType ) );
 		buf.append( ",propertyPath=" ).append( propertyPath );
 		buf.append( ",path=" ).append( getPath() );
 		if ( fromElement != null ) {
 			buf.append( ",tableAlias=" ).append( fromElement.getTableAlias() );
 			buf.append( ",className=" ).append( fromElement.getClassName() );
 			buf.append( ",classAlias=" ).append( fromElement.getClassAlias() );
 		}
 		else {
 			buf.append( ",no from element" );
 		}
 		buf.append( '}' );
 		return buf.toString();
 	}
 
 	/**
 	 * Resolves the left hand side of the DOT.
 	 *
 	 * @throws SemanticException
 	 */
 	@Override
     public void resolveFirstChild() throws SemanticException {
 		FromReferenceNode lhs = ( FromReferenceNode ) getFirstChild();
 		SqlNode property = ( SqlNode ) lhs.getNextSibling();
 
 		// Set the attributes of the property reference expression.
 		String propName = property.getText();
 		propertyName = propName;
 		// If the uresolved property path isn't set yet, just use the property name.
 		if ( propertyPath == null ) {
 			propertyPath = propName;
 		}
 		// Resolve the LHS fully, generate implicit joins.  Pass in the property name so that the resolver can
 		// discover foreign key (id) properties.
 		lhs.resolve( true, true, null, this );
 		setFromElement( lhs.getFromElement() );			// The 'from element' that the property is in.
 
 		checkSubclassOrSuperclassPropertyReference( lhs, propName );
 	}
 
 	@Override
     public void resolveInFunctionCall(boolean generateJoin, boolean implicitJoin) throws SemanticException {
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs();			// Prepare the left hand side and get the data type.
 		if ( propertyType!=null && propertyType.isCollectionType() ) {
 			resolveIndex(null);
 		}
 		else {
 			resolveFirstChild();
 			super.resolve(generateJoin, implicitJoin);
 		}
 	}
 
 
 	public void resolveIndex(AST parent) throws SemanticException {
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs();			// Prepare the left hand side and get the data type.
 		dereferenceCollection( ( CollectionType ) propertyType, true, true, null, parent );
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin, String classAlias, AST parent)
 	throws SemanticException {
 		// If this dot has already been resolved, stop now.
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs(); // Prepare the left hand side and get the data type.
 
 		// If there is no data type for this node, and we're at the end of the path (top most dot node), then
 		// this might be a Java constant.
 		if ( propertyType == null ) {
 			if ( parent == null ) {
 				getWalker().getLiteralProcessor().lookupConstant( this );
 			}
 			// If the propertyType is null and there isn't a parent, just
 			// stop now... there was a problem resolving the node anyway.
 			return;
 		}
 
 		if ( propertyType.isComponentType() ) {
 			// The property is a component...
 			checkLhsIsNotCollection();
 			dereferenceComponent( parent );
 			initText();
 		}
 		else if ( propertyType.isEntityType() ) {
 			// The property is another class..
 			checkLhsIsNotCollection();
 			dereferenceEntity( ( EntityType ) propertyType, implicitJoin, classAlias, generateJoin, parent );
 			initText();
 		}
 		else if ( propertyType.isCollectionType() ) {
 			// The property is a collection...
 			checkLhsIsNotCollection();
 			dereferenceCollection( ( CollectionType ) propertyType, implicitJoin, false, classAlias, parent );
 		}
 		else {
 			// Otherwise, this is a primitive type.
 			if ( ! CollectionProperties.isAnyCollectionProperty( propertyName ) ) {
 				checkLhsIsNotCollection();
 			}
 			dereferenceType = DEREF_PRIMITIVE;
 			initText();
 		}
 		setResolved();
 	}
 
 	private void initText() {
 		String[] cols = getColumns();
 		String text = StringHelper.join( ", ", cols );
 		if ( cols.length > 1 && getWalker().isComparativeExpressionClause() ) {
 			text = "(" + text + ")";
 		}
 		setText( text );
 	}
 
 	private Type prepareLhs() throws SemanticException {
 		FromReferenceNode lhs = getLhs();
 		lhs.prepareForDot( propertyName );
 		return getDataType();
 	}
 
 	private void dereferenceCollection(CollectionType collectionType, boolean implicitJoin, boolean indexed, String classAlias, AST parent)
 	throws SemanticException {
 
 		dereferenceType = DEREF_COLLECTION;
 		String role = collectionType.getRole();
 
 		//foo.bars.size (also handles deprecated stuff like foo.bars.maxelement for backwardness)
 		boolean isSizeProperty = getNextSibling()!=null &&
 			CollectionProperties.isAnyCollectionProperty( getNextSibling().getText() );
 
 		if ( isSizeProperty ) indexed = true; //yuck!
 
 		QueryableCollection queryableCollection = getSessionFactoryHelper().requireQueryableCollection( role );
 		String propName = getPath();
 		FromClause currentFromClause = getWalker().getCurrentFromClause();
 
 		if ( getWalker().getStatementType() != SqlTokenTypes.SELECT && indexed && classAlias == null ) {
 			// should indicate that we are processing an INSERT/UPDATE/DELETE
 			// query with a subquery implied via a collection property
 			// function. Here, we need to use the table name itself as the
 			// qualification alias.
 			// TODO : verify this works for all databases...
 			// TODO : is this also the case in non-"indexed" scenarios?
 			String alias = getLhs().getFromElement().getQueryable().getTableName();
 			columns = getFromElement().toColumns( alias, propertyPath, false, true );
 		}
 
 		//We do not look for an existing join on the same path, because
 		//it makes sense to join twice on the same collection role
 		FromElementFactory factory = new FromElementFactory(
 		        currentFromClause,
 		        getLhs().getFromElement(),
 		        propName,
 				classAlias,
 		        getColumns(),
 		        implicitJoin
 		);
 		FromElement elem = factory.createCollection( queryableCollection, role, joinType, fetch, indexed );
 
         LOG.debugf("dereferenceCollection() : Created new FROM element for %s : %s", propName, elem);
 
 		setImpliedJoin( elem );
 		setFromElement( elem );	// This 'dot' expression now refers to the resulting from element.
 
 		if ( isSizeProperty ) {
 			elem.setText("");
 			elem.setUseWhereFragment(false);
 		}
 
 		if ( !implicitJoin ) {
 			EntityPersister entityPersister = elem.getEntityPersister();
 			if ( entityPersister != null ) {
 				getWalker().addQuerySpaces( entityPersister.getQuerySpaces() );
 			}
 		}
 		getWalker().addQuerySpaces( queryableCollection.getCollectionSpaces() );	// Always add the collection's query spaces.
 	}
 
 	private void dereferenceEntity(EntityType entityType, boolean implicitJoin, String classAlias, boolean generateJoin, AST parent) throws SemanticException {
 		checkForCorrelatedSubquery( "dereferenceEntity" );
 		// three general cases we check here as to whether to render a physical SQL join:
 		// 1) is our parent a DotNode as well?  If so, our property reference is
 		// 		being further de-referenced...
 		// 2) is this a DML statement
 		// 3) we were asked to generate any needed joins (generateJoins==true) *OR*
 		//		we are currently processing a select or from clause
 		// (an additional check is the REGRESSION_STYLE_JOIN_SUPPRESSION check solely intended for the test suite)
 		//
 		// The REGRESSION_STYLE_JOIN_SUPPRESSION is an additional check
 		// intended solely for use within the test suite.  This forces the
 		// implicit join resolution to behave more like the classic parser.
 		// The underlying issue is that classic translator is simply wrong
 		// about its decisions on whether or not to render an implicit join
 		// into a physical SQL join in a lot of cases.  The piece it generally
 		// tends to miss is that INNER joins effect the results by further
 		// restricting the data set!  A particular manifestation of this is
 		// the fact that the classic translator will skip the physical join
 		// for ToOne implicit joins *if the query is shallow*; the result
 		// being that Query.list() and Query.iterate() could return
 		// different number of results!
 		DotNode parentAsDotNode = null;
 		String property = propertyName;
 		final boolean joinIsNeeded;
 
 		if ( isDotNode( parent ) ) {
 			// our parent is another dot node, meaning we are being further dereferenced.
 			// thus we need to generate a join unless the parent refers to the associated
 			// entity's PK (because 'our' table would know the FK).
 			parentAsDotNode = ( DotNode ) parent;
 			property = parentAsDotNode.propertyName;
 			joinIsNeeded = generateJoin && !isReferenceToPrimaryKey( parentAsDotNode.propertyName, entityType );
 		}
 		else if ( ! getWalker().isSelectStatement() ) {
 			// in non-select queries, the only time we should need to join is if we are in a subquery from clause
 			joinIsNeeded = getWalker().getCurrentStatementType() == SqlTokenTypes.SELECT && getWalker().isInFrom();
 		}
 		else if ( REGRESSION_STYLE_JOIN_SUPPRESSION ) {
 			// this is the regression style determination which matches the logic of the classic translator
 			joinIsNeeded = generateJoin && ( !getWalker().isInSelect() || !getWalker().isShallowQuery() );
 		}
 		else {
 			joinIsNeeded = generateJoin || ( getWalker().isInSelect() || getWalker().isInFrom() );
 		}
 
 		if ( joinIsNeeded ) {
 			dereferenceEntityJoin( classAlias, entityType, implicitJoin, parent );
 		}
 		else {
 			dereferenceEntityIdentifier( property, parentAsDotNode );
 		}
 
 	}
 
 	private boolean isDotNode(AST n) {
 		return n != null && n.getType() == SqlTokenTypes.DOT;
 	}
 
 	private void dereferenceEntityJoin(String classAlias, EntityType propertyType, boolean impliedJoin, AST parent)
 	throws SemanticException {
 		dereferenceType = DEREF_ENTITY;
         if (LOG.isDebugEnabled()) LOG.debugf("dereferenceEntityJoin() : generating join for %s in %s (%s) parent = %s",
                                              propertyName,
                                              getFromElement().getClassName(),
                                              classAlias == null ? "<no alias>" : classAlias,
                                              ASTUtil.getDebugString(parent));
 		// Create a new FROM node for the referenced class.
 		String associatedEntityName = propertyType.getAssociatedEntityName();
 		String tableAlias = getAliasGenerator().createName( associatedEntityName );
 
 		String[] joinColumns = getColumns();
 		String joinPath = getPath();
 
 		if ( impliedJoin && getWalker().isInFrom() ) {
 			joinType = getWalker().getImpliedJoinType();
 		}
 
 		FromClause currentFromClause = getWalker().getCurrentFromClause();
 		FromElement elem = currentFromClause.findJoinByPath( joinPath );
 
 ///////////////////////////////////////////////////////////////////////////////
 //
 // This is the piece which recognizes the condition where an implicit join path
 // resolved earlier in a correlated subquery is now being referenced in the
 // outer query.  For 3.0final, we just let this generate a second join (which
 // is exactly how the old parser handles this).  Eventually we need to add this
 // logic back in and complete the logic in FromClause.promoteJoin; however,
 // FromClause.promoteJoin has its own difficulties (see the comments in
 // FromClause.promoteJoin).
 //
 //		if ( elem == null ) {
 //			// see if this joinPath has been used in a "child" FromClause, and if so
 //			// promote that element to the outer query
 //			FromClause currentNodeOwner = getFromElement().getFromClause();
 //			FromClause currentJoinOwner = currentNodeOwner.locateChildFromClauseWithJoinByPath( joinPath );
 //			if ( currentJoinOwner != null && currentNodeOwner != currentJoinOwner ) {
 //				elem = currentJoinOwner.findJoinByPathLocal( joinPath );
 //				if ( elem != null ) {
 //					currentFromClause.promoteJoin( elem );
 //					// EARLY EXIT!!!
 //					return;
 //				}
 //			}
 //		}
 //
 ///////////////////////////////////////////////////////////////////////////////
 
 		boolean found = elem != null;
 		// even though we might find a pre-existing element by join path, for FromElements originating in a from-clause
 		// we should only ever use the found element if the aliases match (null != null here).  Implied joins are
 		// always (?) ok to reuse.
 		boolean useFoundFromElement = found && ( elem.isImplied() || areSame( classAlias, elem.getClassAlias() ) );
 
 		if ( ! useFoundFromElement ) {
 			// If this is an implied join in a from element, then use the impled join type which is part of the
 			// tree parser's state (set by the gramamar actions).
 			JoinSequence joinSequence = getSessionFactoryHelper()
 				.createJoinSequence( impliedJoin, propertyType, tableAlias, joinType, joinColumns );
 
 			// If the lhs of the join is a "component join", we need to go back to the
 			// first non-component-join as the origin to properly link aliases and
 			// join columns
 			FromElement lhsFromElement = getLhs().getFromElement();
 			while ( lhsFromElement != null &&  ComponentJoin.class.isInstance( lhsFromElement ) ) {
 				lhsFromElement = lhsFromElement.getOrigin();
 			}
 			if ( lhsFromElement == null ) {
 				throw new QueryException( "Unable to locate appropriate lhs" );
 			}
 
 			FromElementFactory factory = new FromElementFactory(
 			        currentFromClause,
 					lhsFromElement,
 					joinPath,
 					classAlias,
 					joinColumns,
 					impliedJoin
 			);
 			elem = factory.createEntityJoin(
 					associatedEntityName,
 					tableAlias,
 					joinSequence,
 					fetch,
 					getWalker().isInFrom(),
 					propertyType
 			);
 		}
 		else {
 			// NOTE : addDuplicateAlias() already performs nullness checks on the alias.
 			currentFromClause.addDuplicateAlias( classAlias, elem );
 		}
 		setImpliedJoin( elem );
 		getWalker().addQuerySpaces( elem.getEntityPersister().getQuerySpaces() );
 		setFromElement( elem );	// This 'dot' expression now refers to the resulting from element.
 	}
 
 	private boolean areSame(String alias1, String alias2) {
 		// again, null != null here
 		return !StringHelper.isEmpty( alias1 ) && !StringHelper.isEmpty( alias2 ) && alias1.equals( alias2 );
 	}
 
 	private void setImpliedJoin(FromElement elem) {
 		this.impliedJoin = elem;
 		if ( getFirstChild().getType() == SqlTokenTypes.DOT ) {
 			DotNode dotLhs = ( DotNode ) getFirstChild();
 			if ( dotLhs.getImpliedJoin() != null ) {
 				this.impliedJoin = dotLhs.getImpliedJoin();
 			}
 		}
 	}
 
 	@Override
     public FromElement getImpliedJoin() {
 		return impliedJoin;
 	}
 
 	/**
 	 * Is the given property name a reference to the primary key of the associated
 	 * entity construed by the given entity type?
 	 * <p/>
 	 * For example, consider a fragment like order.customer.id
 	 * (where order is a from-element alias).  Here, we'd have:
 	 * propertyName = "id" AND
 	 * owningType = ManyToOneType(Customer)
 	 * and are being asked to determine whether "customer.id" is a reference
 	 * to customer's PK...
 	 *
 	 * @param propertyName The name of the property to check.
 	 * @param owningType The type represeting the entity "owning" the property
 	 * @return True if propertyName references the entity's (owningType->associatedEntity)
 	 * primary key; false otherwise.
 	 */
 	private boolean isReferenceToPrimaryKey(String propertyName, EntityType owningType) {
 		EntityPersister persister = getSessionFactoryHelper()
 				.getFactory()
 				.getEntityPersister( owningType.getAssociatedEntityName() );
 		if ( persister.getEntityMetamodel().hasNonIdentifierPropertyNamedId() ) {
 			// only the identifier property field name can be a reference to the associated entity's PK...
 			return propertyName.equals( persister.getIdentifierPropertyName() ) && owningType.isReferenceToPrimaryKey();
 		}
         // here, we have two possibilities:
         // 1) the property-name matches the explicitly identifier property name
         // 2) the property-name matches the implicit 'id' property name
         // the referenced node text is the special 'id'
         if (EntityPersister.ENTITY_ID.equals(propertyName)) return owningType.isReferenceToPrimaryKey();
         String keyPropertyName = getSessionFactoryHelper().getIdentifierOrUniqueKeyPropertyName(owningType);
         return keyPropertyName != null && keyPropertyName.equals(propertyName) && owningType.isReferenceToPrimaryKey();
 	}
 
 	private void checkForCorrelatedSubquery(String methodName) {
         if (isCorrelatedSubselect()) LOG.debugf("%s() : correlated subquery", methodName);
 	}
 
 	private boolean isCorrelatedSubselect() {
 		return getWalker().isSubQuery() &&
 			getFromElement().getFromClause() != getWalker().getCurrentFromClause();
 	}
 
 	private void checkLhsIsNotCollection() throws SemanticException {
 		if ( getLhs().getDataType() != null && getLhs().getDataType().isCollectionType() ) {
 			throw ILLEGAL_COLL_DEREF_EXCP_BUILDER.buildIllegalCollectionDereferenceException( propertyName, getLhs() );
 		}
 	}
 	private void dereferenceComponent(AST parent) {
 		dereferenceType = DEREF_COMPONENT;
 		setPropertyNameAndPath( parent );
 	}
 
 	private void dereferenceEntityIdentifier(String propertyName, DotNode dotParent) {
 		// special shortcut for id properties, skip the join!
 		// this must only occur at the _end_ of a path expression
         LOG.debugf("dereferenceShortcut() : property %s in %s does not require a join.",
                    propertyName,
                    getFromElement().getClassName());
 
 		initText();
 		setPropertyNameAndPath( dotParent ); // Set the unresolved path in this node and the parent.
 		// Set the text for the parent.
 		if ( dotParent != null ) {
 			dotParent.dereferenceType = DEREF_IDENTIFIER;
 			dotParent.setText( getText() );
 			dotParent.columns = getColumns();
 		}
 	}
 
 	private void setPropertyNameAndPath(AST parent) {
 		if ( isDotNode( parent ) ) {
 			DotNode dotNode = ( DotNode ) parent;
 			AST lhs = dotNode.getFirstChild();
 			AST rhs = lhs.getNextSibling();
 			propertyName = rhs.getText();
 			propertyPath = propertyPath + "." + propertyName; // Append the new property name onto the unresolved path.
 			dotNode.propertyPath = propertyPath;
             LOG.debugf("Unresolved property path is now '%s'", dotNode.propertyPath);
         } else LOG.debugf("Terminal propertyPath = [%s]", propertyPath);
 	}
 
 	@Override
     public Type getDataType() {
 		if ( super.getDataType() == null ) {
 			FromElement fromElement = getLhs().getFromElement();
             if (fromElement == null) return null;
 			// If the lhs is a collection, use CollectionPropertyMapping
 			Type propertyType = fromElement.getPropertyType( propertyName, propertyPath );
             LOG.debugf("getDataType() : %s -> %s", propertyPath, propertyType);
 			super.setDataType( propertyType );
 		}
 		return super.getDataType();
 	}
 
 	public void setPropertyPath(String propertyPath) {
 		this.propertyPath = propertyPath;
 	}
 
 	public String getPropertyPath() {
 		return propertyPath;
 	}
 
 	public FromReferenceNode getLhs() {
 		FromReferenceNode lhs = ( ( FromReferenceNode ) getFirstChild() );
 		if ( lhs == null ) {
 			throw new IllegalStateException( "DOT node with no left-hand-side!" );
 		}
 		return lhs;
 	}
 
 	/**
 	 * Returns the full path of the node.
 	 *
 	 * @return the full path of the node.
 	 */
 	@Override
     public String getPath() {
 		if ( path == null ) {
 			FromReferenceNode lhs = getLhs();
 			if ( lhs == null ) {
 				path = getText();
 			}
 			else {
 				SqlNode rhs = ( SqlNode ) lhs.getNextSibling();
 				path = lhs.getPath() + "." + rhs.getOriginalText();
 			}
 		}
 		return path;
 	}
 
 	public void setFetch(boolean fetch) {
 		this.fetch = fetch;
 	}
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		String[] sqlColumns = getColumns();
 		ColumnHelper.generateScalarColumns( this, sqlColumns, i );
 	}
 
 	/**
 	 * Special method to resolve expressions in the SELECT list.
 	 *
 	 * @throws SemanticException if this cannot be resolved.
 	 */
 	public void resolveSelectExpression() throws SemanticException {
 		if ( getWalker().isShallowQuery() || getWalker().getCurrentFromClause().isSubQuery() ) {
 			resolve(false, true);
 		}
 		else {
 			resolve(true, false);
 			Type type = getDataType();
 			if ( type.isEntityType() ) {
 				FromElement fromElement = getFromElement();
 				fromElement.setIncludeSubclasses( true ); // Tell the destination fromElement to 'includeSubclasses'.
 				if ( useThetaStyleImplicitJoins ) {
 					fromElement.getJoinSequence().setUseThetaStyle( true );	// Use theta style (for regression)
 					// Move the node up, after the origin node.
 					FromElement origin = fromElement.getOrigin();
 					if ( origin != null ) {
 						ASTUtil.makeSiblingOfParent( origin, fromElement );
 					}
 				}
 			}
 		}
 
 		FromReferenceNode lhs = getLhs();
 		while ( lhs != null ) {
 			checkSubclassOrSuperclassPropertyReference( lhs, lhs.getNextSibling().getText() );
 			lhs = ( FromReferenceNode ) lhs.getFirstChild();
 		}
 	}
 
 	public void setResolvedConstant(String text) {
 		path = text;
 		dereferenceType = DEREF_JAVA_CONSTANT;
 		setResolved(); // Don't resolve the node again.
 	}
 
 	private boolean checkSubclassOrSuperclassPropertyReference(FromReferenceNode lhs, String propertyName) {
 		if ( lhs != null && !( lhs instanceof IndexNode ) ) {
 			final FromElement source = lhs.getFromElement();
 			if ( source != null ) {
 				source.handlePropertyBeingDereferenced( lhs.getDataType(), propertyName );
 			}
 		}
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromClause.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromClause.java
index 098b955f41..ab28190c74 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromClause.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromClause.java
@@ -1,406 +1,407 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.ast.util.ASTIterator;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.jboss.logging.Logger;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents the 'FROM' part of a query or subquery, containing all mapped class references.
  *
  * @author josh
  */
 public class FromClause extends HqlSqlWalkerNode implements HqlSqlTokenTypes, DisplayableNode {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, FromClause.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, FromClause.class.getName());
 	public static final int ROOT_LEVEL = 1;
 
 	private int level = ROOT_LEVEL;
 	private Set fromElements = new HashSet();
 	private Map fromElementByClassAlias = new HashMap();
 	private Map fromElementByTableAlias = new HashMap();
 	private Map fromElementsByPath = new HashMap();
 
 	/**
 	 * All of the implicit FROM xxx JOIN yyy elements that are the destination of a collection.  These are created from
 	 * index operators on collection property references.
 	 */
 	private Map collectionJoinFromElementsByPath = new HashMap();
 	/**
 	 * Pointer to the parent FROM clause, if there is one.
 	 */
 	private FromClause parentFromClause;
 	/**
 	 * Collection of FROM clauses of which this is the parent.
 	 */
 	private Set childFromClauses;
 	/**
 	 * Counts the from elements as they are added.
 	 */
 	private int fromElementCounter = 0;
 	/**
 	 * Implied FROM elements to add onto the end of the FROM clause.
 	 */
 	private List impliedElements = new LinkedList();
 
 	/**
 	 * Adds a new from element to the from node.
 	 *
 	 * @param path  The reference to the class.
 	 * @param alias The alias AST.
 	 * @return FromElement - The new FROM element.
 	 */
 	public FromElement addFromElement(String path, AST alias) throws SemanticException {
 		// The path may be a reference to an alias defined in the parent query.
 		String classAlias = ( alias == null ) ? null : alias.getText();
 		checkForDuplicateClassAlias( classAlias );
 		FromElementFactory factory = new FromElementFactory( this, null, path, classAlias, null, false );
 		return factory.addFromElement();
 	}
 
 	void registerFromElement(FromElement element) {
 		fromElements.add( element );
 		String classAlias = element.getClassAlias();
 		if ( classAlias != null ) {
 			// The HQL class alias refers to the class name.
 			fromElementByClassAlias.put( classAlias, element );
 		}
 		// Associate the table alias with the element.
 		String tableAlias = element.getTableAlias();
 		if ( tableAlias != null ) {
 			fromElementByTableAlias.put( tableAlias, element );
 		}
 	}
 
 	void addDuplicateAlias(String alias, FromElement element) {
 		if ( alias != null ) {
 			fromElementByClassAlias.put( alias, element );
 		}
 	}
 
 	private void checkForDuplicateClassAlias(String classAlias) throws SemanticException {
 		if ( classAlias != null && fromElementByClassAlias.containsKey( classAlias ) ) {
 			throw new SemanticException( "Duplicate definition of alias '" + classAlias + "'" );
 		}
 	}
 
 	/**
 	 * Retreives the from-element represented by the given alias.
 	 *
 	 * @param aliasOrClassName The alias by which to locate the from-element.
 	 * @return The from-element assigned the given alias, or null if none.
 	 */
 	public FromElement getFromElement(String aliasOrClassName) {
 		FromElement fromElement = ( FromElement ) fromElementByClassAlias.get( aliasOrClassName );
 		if ( fromElement == null && getSessionFactoryHelper().isStrictJPAQLComplianceEnabled() ) {
 			fromElement = findIntendedAliasedFromElementBasedOnCrazyJPARequirements( aliasOrClassName );
 		}
 		if ( fromElement == null && parentFromClause != null ) {
 			fromElement = parentFromClause.getFromElement( aliasOrClassName );
 		}
 		return fromElement;
 	}
 
 	public FromElement findFromElementBySqlAlias(String sqlAlias) {
 		FromElement fromElement = ( FromElement ) fromElementByTableAlias.get( sqlAlias );
 		if ( fromElement == null && parentFromClause != null ) {
 			fromElement = parentFromClause.getFromElement( sqlAlias );
 		}
 		return fromElement;
 	}
 
 	public FromElement findFromElementByUserOrSqlAlias(String userAlias, String sqlAlias) {
 		FromElement fromElement = null;
 		if ( userAlias != null ) {
 			fromElement = getFromElement( userAlias );
 		}
 
 		if ( fromElement == null ) {
 			fromElement = findFromElementBySqlAlias( sqlAlias );
 		}
 
 		return fromElement;
 	}
 
 	private FromElement findIntendedAliasedFromElementBasedOnCrazyJPARequirements(String specifiedAlias) {
 		Iterator itr = fromElementByClassAlias.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			Map.Entry entry = ( Map.Entry ) itr.next();
 			String alias = ( String ) entry.getKey();
 			if ( alias.equalsIgnoreCase( specifiedAlias ) ) {
 				return ( FromElement ) entry.getValue();
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Convenience method to check whether a given token represents a from-element alias.
 	 *
 	 * @param possibleAlias The potential from-element alias to check.
 	 * @return True if the possibleAlias is an alias to a from-element visible
 	 *         from this point in the query graph.
 	 */
 	public boolean isFromElementAlias(String possibleAlias) {
 		boolean isAlias = containsClassAlias( possibleAlias );
 		if ( !isAlias && parentFromClause != null ) {
 			// try the parent FromClause...
 			isAlias = parentFromClause.isFromElementAlias( possibleAlias );
 		}
 		return isAlias;
 	}
 
 	/**
 	 * Returns the list of from elements in order.
 	 *
 	 * @return the list of from elements (instances of FromElement).
 	 */
 	public List getFromElements() {
 		return ASTUtil.collectChildren( this, fromElementPredicate );
 	}
 
 	public FromElement getFromElement() {
 		// TODO: not sure about this one
 //		List fromElements = getFromElements();
 //		if ( fromElements == null || fromElements.isEmpty() ) {
 //			throw new QueryException( "Unable to locate from element" );
 //		}
 		return (FromElement) getFromElements().get(0);
 	}
 
 	/**
 	 * Returns the list of from elements that will be part of the result set.
 	 *
 	 * @return the list of from elements that will be part of the result set.
 	 */
 	public List getProjectionList() {
 		return ASTUtil.collectChildren( this, projectionListPredicate );
 	}
 
 	public List getCollectionFetches() {
 		return ASTUtil.collectChildren( this, collectionFetchPredicate );
 	}
 
 	public boolean hasCollectionFecthes() {
 		return getCollectionFetches().size() > 0;
 	}
 
 	public List getExplicitFromElements() {
 		return ASTUtil.collectChildren( this, explicitFromPredicate );
 	}
 
 	private static ASTUtil.FilterPredicate fromElementPredicate = new ASTUtil.IncludePredicate() {
 		@Override
         public boolean include(AST node) {
 			FromElement fromElement = ( FromElement ) node;
 			return fromElement.isFromOrJoinFragment();
 		}
 	};
 
 	private static ASTUtil.FilterPredicate projectionListPredicate = new ASTUtil.IncludePredicate() {
 		@Override
         public boolean include(AST node) {
 			FromElement fromElement = ( FromElement ) node;
 			return fromElement.inProjectionList();
 		}
 	};
 
 	private static ASTUtil.FilterPredicate collectionFetchPredicate = new ASTUtil.IncludePredicate() {
 		@Override
         public boolean include(AST node) {
 			FromElement fromElement = ( FromElement ) node;
 			return fromElement.isFetch() && fromElement.getQueryableCollection() != null;
 		}
 	};
 
 	private static ASTUtil.FilterPredicate explicitFromPredicate = new ASTUtil.IncludePredicate() {
 		@Override
         public boolean include(AST node) {
 			final FromElement fromElement = ( FromElement ) node;
 			return !fromElement.isImplied();
 		}
 	};
 
 	FromElement findCollectionJoin(String path) {
 		return ( FromElement ) collectionJoinFromElementsByPath.get( path );
 	}
 
 	/**
 	 * Look for an existing implicit or explicit join by the
 	 * given path.
 	 */
 	FromElement findJoinByPath(String path) {
 		FromElement elem = findJoinByPathLocal( path );
 		if ( elem == null && parentFromClause != null ) {
 			elem = parentFromClause.findJoinByPath( path );
 		}
 		return elem;
 	}
 
 	FromElement findJoinByPathLocal(String path) {
 		Map joinsByPath = fromElementsByPath;
 		return ( FromElement ) joinsByPath.get( path );
 	}
 
 	void addJoinByPathMap(String path, FromElement destination) {
         LOG.debugf("addJoinByPathMap() : %s -> %s", path, destination.getDisplayText());
 		fromElementsByPath.put( path, destination );
 	}
 
 	/**
 	 * Returns true if the from node contains the class alias name.
 	 *
 	 * @param alias The HQL class alias name.
 	 * @return true if the from node contains the class alias name.
 	 */
 	public boolean containsClassAlias(String alias) {
 		boolean isAlias = fromElementByClassAlias.containsKey( alias );
 		if ( !isAlias && getSessionFactoryHelper().isStrictJPAQLComplianceEnabled() ) {
 			isAlias = findIntendedAliasedFromElementBasedOnCrazyJPARequirements( alias ) != null;
 		}
 		return isAlias;
 	}
 
 	/**
 	 * Returns true if the from node contains the table alias name.
 	 *
 	 * @param alias The SQL table alias name.
 	 * @return true if the from node contains the table alias name.
 	 */
 	public boolean containsTableAlias(String alias) {
 		return fromElementByTableAlias.keySet().contains( alias );
 	}
 
 	public String getDisplayText() {
 		return "FromClause{" +
 				"level=" + level +
 				", fromElementCounter=" + fromElementCounter +
 				", fromElements=" + fromElements.size() +
 				", fromElementByClassAlias=" + fromElementByClassAlias.keySet() +
 				", fromElementByTableAlias=" + fromElementByTableAlias.keySet() +
 				", fromElementsByPath=" + fromElementsByPath.keySet() +
 				", collectionJoinFromElementsByPath=" + collectionJoinFromElementsByPath.keySet() +
 				", impliedElements=" + impliedElements +
 				"}";
 	}
 
 	public void setParentFromClause(FromClause parentFromClause) {
 		this.parentFromClause = parentFromClause;
 		if ( parentFromClause != null ) {
 			level = parentFromClause.getLevel() + 1;
 			parentFromClause.addChild( this );
 		}
 	}
 
 	private void addChild(FromClause fromClause) {
 		if ( childFromClauses == null ) {
 			childFromClauses = new HashSet();
 		}
 		childFromClauses.add( fromClause );
 	}
 
 	public FromClause locateChildFromClauseWithJoinByPath(String path) {
 		if ( childFromClauses != null && !childFromClauses.isEmpty() ) {
 			Iterator children = childFromClauses.iterator();
 			while ( children.hasNext() ) {
 				FromClause child = ( FromClause ) children.next();
 				if ( child.findJoinByPathLocal( path ) != null ) {
 					return child;
 				}
 			}
 		}
 		return null;
 	}
 
 	public void promoteJoin(FromElement elem) {
         LOG.debugf("Promoting [%s] to [%s]", elem, this);
 		//TODO: implement functionality
 		//  this might be painful to do here, as the "join post processing" for
 		//  the subquery has already been performed (meaning that for
 		//  theta-join dialects, the join conditions have already been moved
 		//  over to the where clause).  A "simple" solution here might to
 		//  doAfterTransactionCompletion "join post processing" once for the entire query (including
 		//  any subqueries) at one fell swoop
 	}
 
 	public boolean isSubQuery() {
 		// TODO : this is broke for subqueries in statements other than selects...
 		return parentFromClause != null;
 	}
 
 	void addCollectionJoinFromElementByPath(String path, FromElement destination) {
         LOG.debugf("addCollectionJoinFromElementByPath() : %s -> %s", path, destination);
 		collectionJoinFromElementsByPath.put( path, destination );	// Add the new node to the map so that we don't create it twice.
 	}
 
 	public FromClause getParentFromClause() {
 		return parentFromClause;
 	}
 
 	public int getLevel() {
 		return level;
 	}
 
 	public int nextFromElementCounter() {
 		return fromElementCounter++;
 	}
 
 	public void resolve() {
 		// Make sure that all from elements registered with this FROM clause are actually in the AST.
 		ASTIterator iter = new ASTIterator( this.getFirstChild() );
 		Set childrenInTree = new HashSet();
 		while ( iter.hasNext() ) {
 			childrenInTree.add( iter.next() );
 		}
 		for ( Iterator iterator = fromElements.iterator(); iterator.hasNext(); ) {
 			FromElement fromElement = ( FromElement ) iterator.next();
 			if ( !childrenInTree.contains( fromElement ) ) {
 				throw new IllegalStateException( "Element not in AST: " + fromElement );
 			}
 		}
 	}
 
 	public void addImpliedFromElement(FromElement element) {
 		impliedElements.add( element );
 	}
 
 	@Override
     public String toString() {
 		return "FromClause{" +
 				"level=" + level +
 				"}";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElement.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElement.java
index b9163ffbb8..b520038a42 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElement.java
@@ -1,684 +1,685 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
 
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.hql.CollectionProperties;
 import org.hibernate.hql.QueryTranslator;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.TypeDiscriminatorMetadata;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.DiscriminatorMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Represents a single mapped class mentioned in an HQL FROM clause.  Each
  * class reference will have the following symbols:
  * <ul>
  * <li>A class name - This is the name of the Java class that is mapped by Hibernate.</li>
  * <li>[optional] an HQL alias for the mapped class.</li>
  * <li>A table name - The name of the table that is mapped to the Java class.</li>
  * <li>A table alias - The alias for the table that will be used in the resulting SQL.</li>
  * </ul>
  *
  * @author josh
  */
 public class FromElement extends HqlSqlWalkerNode implements DisplayableNode, ParameterContainer {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, FromElement.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, FromElement.class.getName());
 
 	private String className;
 	private String classAlias;
 	private String tableAlias;
 	private String collectionTableAlias;
 	private FromClause fromClause;
 	private boolean includeSubclasses = true;
 	private boolean collectionJoin = false;
 	private FromElement origin;
 	private String[] columns;
 	private String role;
 	private boolean fetch;
 	private boolean isAllPropertyFetch;
 	private boolean filter = false;
 	private int sequence = -1;
 	private boolean useFromFragment = false;
 	private boolean initialized = false;
 	private FromElementType elementType;
 	private boolean useWhereFragment = true;
 	private List destinations = new LinkedList();
 	private boolean manyToMany = false;
 	private String withClauseFragment = null;
 	private String withClauseJoinAlias;
 	private boolean dereferencedBySuperclassProperty;
 	private boolean dereferencedBySubclassProperty;
 
 	public FromElement() {
 	}
 
 	/**
 	 * Constructor form used to initialize {@link ComponentJoin}
 	 *
 	 * @param fromClause The FROM clause to which this element belongs
 	 * @param origin The origin (LHS) of this element
 	 * @param alias The alias applied to this element
 	 */
 	protected FromElement(
 			FromClause fromClause,
 			FromElement origin,
 			String alias) {
 		this.fromClause = fromClause;
 		this.origin = origin;
 		this.classAlias = alias;
 		this.tableAlias = origin.getTableAlias();
 		super.initialize( fromClause.getWalker() );
 	}
 
 	protected void initializeComponentJoin(FromElementType elementType) {
 		this.elementType = elementType;
 		fromClause.registerFromElement( this );
 		initialized = true;
 	}
 
 	public String getCollectionSuffix() {
 		return elementType.getCollectionSuffix();
 	}
 
 	public void setCollectionSuffix(String suffix) {
 		elementType.setCollectionSuffix(suffix);
 	}
 
 	public void initializeCollection(FromClause fromClause, String classAlias, String tableAlias) {
 		doInitialize( fromClause, tableAlias, null, classAlias, null, null );
 		initialized = true;
 	}
 
 	public void initializeEntity(
 	        FromClause fromClause,
 	        String className,
 	        EntityPersister persister,
 	        EntityType type,
 	        String classAlias,
 	        String tableAlias) {
 		doInitialize( fromClause, tableAlias, className, classAlias, persister, type );
 		this.sequence = fromClause.nextFromElementCounter();
 		initialized = true;
 	}
 
 	private void doInitialize(FromClause fromClause, String tableAlias, String className, String classAlias,
 							  EntityPersister persister, EntityType type) {
 		if ( initialized ) {
 			throw new IllegalStateException( "Already initialized!!" );
 		}
 		this.fromClause = fromClause;
 		this.tableAlias = tableAlias;
 		this.className = className;
 		this.classAlias = classAlias;
 		this.elementType = new FromElementType( this, persister, type );
 		// Register the FromElement with the FROM clause, now that we have the names and aliases.
 		fromClause.registerFromElement( this );
         LOG.debugf("%s : %s (%s) -> %s", fromClause, className, classAlias == null ? "<no alias>" : classAlias, tableAlias);
 	}
 
 	public EntityPersister getEntityPersister() {
 		return elementType.getEntityPersister();
 	}
 
 	@Override
     public Type getDataType() {
 		return elementType.getDataType();
 	}
 
 	public Type getSelectType() {
 		return elementType.getSelectType();
 	}
 
 	public Queryable getQueryable() {
 		return elementType.getQueryable();
 	}
 
 	public String getClassName() {
 		return className;
 	}
 
 	public String getClassAlias() {
 		return classAlias;
 		//return classAlias == null ? className : classAlias;
 	}
 
 	private String getTableName() {
 		Queryable queryable = getQueryable();
 		return ( queryable != null ) ? queryable.getTableName() : "{none}";
 	}
 
 	public String getTableAlias() {
 		return tableAlias;
 	}
 
 	/**
 	 * Render the identifier select, but in a 'scalar' context (i.e. generate the column alias).
 	 *
 	 * @param i the sequence of the returned type
 	 * @return the identifier select with the column alias.
 	 */
 	String renderScalarIdentifierSelect(int i) {
 		return elementType.renderScalarIdentifierSelect( i );
 	}
 
 	void checkInitialized() {
 		if ( !initialized ) {
 			throw new IllegalStateException( "FromElement has not been initialized!" );
 		}
 	}
 
 	/**
 	 * Returns the identifier select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the identifier select SQL fragment.
 	 */
 	String renderIdentifierSelect(int size, int k) {
 		return elementType.renderIdentifierSelect( size, k );
 	}
 
 	/**
 	 * Returns the property select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the property select SQL fragment.
 	 */
 	String renderPropertySelect(int size, int k) {
 		return elementType.renderPropertySelect( size, k, isAllPropertyFetch );
 	}
 
 	String renderCollectionSelectFragment(int size, int k) {
 		return elementType.renderCollectionSelectFragment( size, k );
 	}
 
 	String renderValueCollectionSelectFragment(int size, int k) {
 		return elementType.renderValueCollectionSelectFragment( size, k );
 	}
 
 	public FromClause getFromClause() {
 		return fromClause;
 	}
 
 	/**
 	 * Returns true if this FromElement was implied by a path, or false if this FROM element is explicitly declared in
 	 * the FROM clause.
 	 *
 	 * @return true if this FromElement was implied by a path, or false if this FROM element is explicitly declared
 	 */
 	public boolean isImplied() {
 		return false;	// This is an explicit FROM element.
 	}
 
 	/**
 	 * Returns additional display text for the AST node.
 	 *
 	 * @return String - The additional display text.
 	 */
 	public String getDisplayText() {
 		StringBuffer buf = new StringBuffer();
 		buf.append( "FromElement{" );
 		appendDisplayText( buf );
 		buf.append( "}" );
 		return buf.toString();
 	}
 
 	protected void appendDisplayText(StringBuffer buf) {
 		buf.append( isImplied() ? (
 				isImpliedInFromClause() ? "implied in FROM clause" : "implied" )
 				: "explicit" );
 		buf.append( "," ).append( isCollectionJoin() ? "collection join" : "not a collection join" );
 		buf.append( "," ).append( fetch ? "fetch join" : "not a fetch join" );
 		buf.append( "," ).append( isAllPropertyFetch ? "fetch all properties" : "fetch non-lazy properties" );
 		buf.append( ",classAlias=" ).append( getClassAlias() );
 		buf.append( ",role=" ).append( role );
 		buf.append( ",tableName=" ).append( getTableName() );
 		buf.append( ",tableAlias=" ).append( getTableAlias() );
 		FromElement origin = getRealOrigin();
 		buf.append( ",origin=" ).append( origin == null ? "null" : origin.getText() );
 		buf.append( ",columns={" );
 		if ( columns != null ) {
 			for ( int i = 0; i < columns.length; i++ ) {
 				buf.append( columns[i] );
 				if ( i < columns.length ) {
 					buf.append( " " );
 				}
 			}
 		}
 		buf.append( ",className=" ).append( className );
 		buf.append( "}" );
 	}
 
 	@Override
     public int hashCode() {
 		return super.hashCode();
 	}
 
 	@Override
     public boolean equals(Object obj) {
 		return super.equals( obj );
 	}
 
 
 	public void setJoinSequence(JoinSequence joinSequence) {
 		elementType.setJoinSequence( joinSequence );
 	}
 
 	public JoinSequence getJoinSequence() {
 		return elementType.getJoinSequence();
 	}
 
 	public void setIncludeSubclasses(boolean includeSubclasses) {
         if (LOG.isTraceEnabled() && isDereferencedBySuperclassOrSubclassProperty() && !includeSubclasses) LOG.trace("Attempt to disable subclass-inclusions : "
                                                                                                                     + new Exception(
                                                                                                                                     "Stack-trace source"));
 		this.includeSubclasses = includeSubclasses;
 	}
 
 	public boolean isIncludeSubclasses() {
 		return includeSubclasses;
 	}
 
 	public boolean isDereferencedBySuperclassOrSubclassProperty() {
 		return dereferencedBySubclassProperty || dereferencedBySuperclassProperty;
 	}
 
 	public String getIdentityColumn() {
 		checkInitialized();
 		String table = getTableAlias();
 		if ( table == null ) {
 			throw new IllegalStateException( "No table alias for node " + this );
 		}
 		String[] cols;
 		String propertyName;
 		if ( getEntityPersister() != null && getEntityPersister().getEntityMetamodel() != null
 				&& getEntityPersister().getEntityMetamodel().hasNonIdentifierPropertyNamedId() ) {
 			propertyName = getEntityPersister().getIdentifierPropertyName();
 		}
 		else {
 			propertyName = EntityPersister.ENTITY_ID;
 		}
 		if ( getWalker().getStatementType() == HqlSqlTokenTypes.SELECT ) {
 			cols = getPropertyMapping( propertyName ).toColumns( table, propertyName );
 		}
 		else {
 			cols = getPropertyMapping( propertyName ).toColumns( propertyName );
 		}
 		String result = StringHelper.join( ", ", cols );
 		return  cols.length == 1 ? result : "(" + result + ")";
 	}
 
 	public void setCollectionJoin(boolean collectionJoin) {
 		this.collectionJoin = collectionJoin;
 	}
 
 	public boolean isCollectionJoin() {
 		return collectionJoin;
 	}
 
 	public void setRole(String role) {
 		this.role = role;
 	}
 
 	public void setQueryableCollection(QueryableCollection queryableCollection) {
 		elementType.setQueryableCollection( queryableCollection );
 	}
 
 	public QueryableCollection getQueryableCollection() {
 		return elementType.getQueryableCollection();
 	}
 
 	public void setColumns(String[] columns) {
 		this.columns = columns;
 	}
 
 	public void setOrigin(FromElement origin, boolean manyToMany) {
 		this.origin = origin;
 		this.manyToMany = manyToMany;
 		origin.addDestination( this );
 		if ( origin.getFromClause() == this.getFromClause() ) {
 			// TODO: Figure out a better way to get the FROM elements in a proper tree structure.
 			// If this is not the destination of a many-to-many, add it as a child of the origin.
 			if ( manyToMany ) {
 				ASTUtil.appendSibling( origin, this );
 			}
 			else {
 				if ( !getWalker().isInFrom() && !getWalker().isInSelect() ) {
 					getFromClause().addChild( this );
 				}
 				else {
 					origin.addChild( this );
 				}
 			}
 		}
 		else if ( !getWalker().isInFrom() ) {
 			// HHH-276 : implied joins in a subselect where clause - The destination needs to be added
 			// to the destination's from clause.
 			getFromClause().addChild( this );	// Not sure if this is will fix everything, but it works.
 		}
 		else {
 			// Otherwise, the destination node was implied by the FROM clause and the FROM clause processor
 			// will automatically add it in the right place.
 		}
 	}
 
 	public boolean isManyToMany() {
 		return manyToMany;
 	}
 
 	private void addDestination(FromElement fromElement) {
 		destinations.add( fromElement );
 	}
 
 	public List getDestinations() {
 		return destinations;
 	}
 
 	public FromElement getOrigin() {
 		return origin;
 	}
 
 	public FromElement getRealOrigin() {
 		if ( origin == null ) {
 			return null;
 		}
 		if ( origin.getText() == null || "".equals( origin.getText() ) ) {
 			return origin.getRealOrigin();
 		}
 		return origin;
 	}
 
 	public static final String DISCRIMINATOR_PROPERTY_NAME = "class";
 	private TypeDiscriminatorMetadata typeDiscriminatorMetadata;
 
 	private static class TypeDiscriminatorMetadataImpl implements TypeDiscriminatorMetadata {
 		private final DiscriminatorMetadata persisterDiscriminatorMetadata;
 		private final String alias;
 
 		private TypeDiscriminatorMetadataImpl(
 				DiscriminatorMetadata persisterDiscriminatorMetadata,
 				String alias) {
 			this.persisterDiscriminatorMetadata = persisterDiscriminatorMetadata;
 			this.alias = alias;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public String getSqlFragment() {
 			return persisterDiscriminatorMetadata.getSqlFragment( alias );
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Type getResolutionType() {
 			return persisterDiscriminatorMetadata.getResolutionType();
 		}
 	}
 
 	public TypeDiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( typeDiscriminatorMetadata == null ) {
 			typeDiscriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return typeDiscriminatorMetadata;
 	}
 
 	private TypeDiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		final String aliasToUse = getTableAlias();
 		Queryable queryable = getQueryable();
 		if ( queryable == null ) {
 			QueryableCollection collection = getQueryableCollection();
 			if ( ! collection.getElementType().isEntityType() ) {
 				throw new QueryException( "type discrimination cannot be applied to value collection [" + collection.getRole() + "]" );
 			}
 			queryable = (Queryable) collection.getElementPersister();
 		}
 
 		handlePropertyBeingDereferenced( getDataType(), DISCRIMINATOR_PROPERTY_NAME );
 
 		return new TypeDiscriminatorMetadataImpl( queryable.getTypeDiscriminatorMetadata(), aliasToUse );
 	}
 
 	public Type getPropertyType(String propertyName, String propertyPath) {
 		return elementType.getPropertyType( propertyName, propertyPath );
 	}
 
 	public String[] toColumns(String tableAlias, String path, boolean inSelect) {
 		return elementType.toColumns( tableAlias, path, inSelect );
 	}
 
 	public String[] toColumns(String tableAlias, String path, boolean inSelect, boolean forceAlias) {
 		return elementType.toColumns( tableAlias, path, inSelect, forceAlias );
 	}
 
 	public PropertyMapping getPropertyMapping(String propertyName) {
 		return elementType.getPropertyMapping( propertyName );
 	}
 
 	public void setFetch(boolean fetch) {
 		this.fetch = fetch;
 		// Fetch can't be used with scroll() or iterate().
 		if ( fetch && getWalker().isShallowQuery() ) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_FETCH_WITH_ITERATE );
 		}
 	}
 
 	public boolean isFetch() {
 		return fetch;
 	}
 
 	public int getSequence() {
 		return sequence;
 	}
 
 	public void setFilter(boolean b) {
 		filter = b;
 	}
 
 	public boolean isFilter() {
 		return filter;
 	}
 
 	public boolean useFromFragment() {
 		checkInitialized();
 		// If it's not implied or it is implied and it's a many to many join where the target wasn't found.
 		return !isImplied() || this.useFromFragment;
 	}
 
 	public void setUseFromFragment(boolean useFromFragment) {
 		this.useFromFragment = useFromFragment;
 	}
 
 	public boolean useWhereFragment() {
 		return useWhereFragment;
 	}
 
 	public void setUseWhereFragment(boolean b) {
 		useWhereFragment = b;
 	}
 
 
 	public void setCollectionTableAlias(String collectionTableAlias) {
 		this.collectionTableAlias = collectionTableAlias;
 	}
 
 	public String getCollectionTableAlias() {
 		return collectionTableAlias;
 	}
 
 	public boolean isCollectionOfValuesOrComponents() {
 		return elementType.isCollectionOfValuesOrComponents();
 	}
 
 	public boolean isEntity() {
 		return elementType.isEntity();
 	}
 
 	public void setImpliedInFromClause(boolean flag) {
 		throw new UnsupportedOperationException( "Explicit FROM elements can't be implied in the FROM clause!" );
 	}
 
 	public boolean isImpliedInFromClause() {
 		return false;	// Since this is an explicit FROM element, it can't be implied in the FROM clause.
 	}
 
 	public void setInProjectionList(boolean inProjectionList) {
 		// Do nothing, eplicit from elements are *always* in the projection list.
 	}
 
 	public boolean inProjectionList() {
 		return !isImplied() && isFromOrJoinFragment();
 	}
 
 	public boolean isFromOrJoinFragment() {
 		return getType() == SqlTokenTypes.FROM_FRAGMENT || getType() == SqlTokenTypes.JOIN_FRAGMENT;
 	}
 
 	public boolean isAllPropertyFetch() {
 		return isAllPropertyFetch;
 	}
 
 	public void setAllPropertyFetch(boolean fetch) {
 		isAllPropertyFetch = fetch;
 	}
 
 	public String getWithClauseFragment() {
 		return withClauseFragment;
 	}
 
 	public String getWithClauseJoinAlias() {
 		return withClauseJoinAlias;
 	}
 
 	public void setWithClauseFragment(String withClauseJoinAlias, String withClauseFragment) {
 		this.withClauseJoinAlias = withClauseJoinAlias;
 		this.withClauseFragment = withClauseFragment;
 	}
 
 	public boolean hasCacheablePersister() {
 		if ( getQueryableCollection() != null ) {
 			return getQueryableCollection().hasCache();
 		}
 		else {
 			return getQueryable().hasCache();
 		}
 	}
 
 	public void handlePropertyBeingDereferenced(Type propertySource, String propertyName) {
 		if ( getQueryableCollection() != null && CollectionProperties.isCollectionProperty( propertyName ) ) {
 			// propertyName refers to something like collection.size...
 			return;
 		}
 		if ( propertySource.isComponentType() ) {
 			// property name is a sub-path of a component...
 			return;
 		}
 
 		Queryable persister = getQueryable();
 		if ( persister != null ) {
 			try {
 				Queryable.Declarer propertyDeclarer = persister.getSubclassPropertyDeclarer( propertyName );
                 LOG.trace("Handling property dereference [" + persister.getEntityName() + " (" + getClassAlias() + ") -> "
                           + propertyName + " (" + propertyDeclarer + ")]");
 				if ( propertyDeclarer == Queryable.Declarer.SUBCLASS ) {
 					dereferencedBySubclassProperty = true;
 					includeSubclasses = true;
 				}
 				else if ( propertyDeclarer == Queryable.Declarer.SUPERCLASS ) {
 					dereferencedBySuperclassProperty = true;
 				}
 			}
 			catch( QueryException ignore ) {
 				// ignore it; the incoming property could not be found so we
 				// cannot be sure what to do here.  At the very least, the
 				// safest is to simply not apply any dereference toggling...
 
 			}
 		}
 	}
 
 	public boolean isDereferencedBySuperclassProperty() {
 		return dereferencedBySuperclassProperty;
 	}
 
 	public boolean isDereferencedBySubclassProperty() {
 		return dereferencedBySubclassProperty;
 	}
 
 
 	// ParameterContainer impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private List embeddedParameters;
 
 	public void addEmbeddedParameter(ParameterSpecification specification) {
 		if ( embeddedParameters == null ) {
 			embeddedParameters = new ArrayList();
 		}
 		embeddedParameters.add( specification );
 	}
 
 	public boolean hasEmbeddedParameters() {
 		return embeddedParameters != null && ! embeddedParameters.isEmpty();
 	}
 
 	public ParameterSpecification[] getEmbeddedParameters() {
 		return ( ParameterSpecification[] ) embeddedParameters.toArray( new ParameterSpecification[ embeddedParameters.size() ] );
 	}
 
 	public ParameterSpecification getIndexCollectionSelectorParamSpec() {
 		return elementType.getIndexCollectionSelectorParamSpec();
 	}
 
 	public void setIndexCollectionSelectorParamSpec(ParameterSpecification indexCollectionSelectorParamSpec) {
 		if ( indexCollectionSelectorParamSpec == null ) {
 			if ( elementType.getIndexCollectionSelectorParamSpec() != null ) {
 				embeddedParameters.remove( elementType.getIndexCollectionSelectorParamSpec() );
 				elementType.setIndexCollectionSelectorParamSpec( null );
 			}
 		}
 		else {
 			elementType.setIndexCollectionSelectorParamSpec( indexCollectionSelectorParamSpec );
 			addEmbeddedParameter( indexCollectionSelectorParamSpec );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElementFactory.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElementFactory.java
index 91031dff14..aee2b43377 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElementFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElementFactory.java
@@ -1,515 +1,515 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.hql.ast.util.AliasGenerator;
 import org.hibernate.hql.ast.util.PathHelper;
 import org.hibernate.hql.ast.util.SessionFactoryHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.ASTFactory;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Encapsulates the creation of FromElements and JoinSequences.
  *
  * @author josh
  */
 public class FromElementFactory implements SqlTokenTypes {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, FromElementFactory.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, FromElementFactory.class.getName());
 
 	private FromClause fromClause;
 	private FromElement origin;
 	private String path;
 
 	private String classAlias;
 	private String[] columns;
 	private boolean implied;
 	private boolean inElementsFunction;
 	private boolean collection;
 	private QueryableCollection queryableCollection;
 	private CollectionType collectionType;
 
 	/**
 	 * Creates entity from elements.
 	 */
 	public FromElementFactory(FromClause fromClause, FromElement origin, String path) {
 		this.fromClause = fromClause;
 		this.origin = origin;
 		this.path = path;
 		collection = false;
 	}
 
 	/**
 	 * Creates collection from elements.
 	 */
 	public FromElementFactory(
 	        FromClause fromClause,
 	        FromElement origin,
 	        String path,
 	        String classAlias,
 	        String[] columns,
 	        boolean implied) {
 		this( fromClause, origin, path );
 		this.classAlias = classAlias;
 		this.columns = columns;
 		this.implied = implied;
 		collection = true;
 	}
 
 	FromElement addFromElement() throws SemanticException {
 		FromClause parentFromClause = fromClause.getParentFromClause();
 		if ( parentFromClause != null ) {
 			// Look up class name using the first identifier in the path.
 			String pathAlias = PathHelper.getAlias( path );
 			FromElement parentFromElement = parentFromClause.getFromElement( pathAlias );
 			if ( parentFromElement != null ) {
 				return createFromElementInSubselect( path, pathAlias, parentFromElement, classAlias );
 			}
 		}
 
 		EntityPersister entityPersister = fromClause.getSessionFactoryHelper().requireClassPersister( path );
 
 		FromElement elem = createAndAddFromElement( path,
 				classAlias,
 				entityPersister,
 				( EntityType ) ( ( Queryable ) entityPersister ).getType(),
 				null );
 
 		// Add to the query spaces.
 		fromClause.getWalker().addQuerySpaces( entityPersister.getQuerySpaces() );
 
 		return elem;
 	}
 
 	private FromElement createFromElementInSubselect(
 	        String path,
 	        String pathAlias,
 	        FromElement parentFromElement,
 	        String classAlias) throws SemanticException {
         LOG.debugf("createFromElementInSubselect() : path = %s", path);
 		// Create an DotNode AST for the path and resolve it.
 		FromElement fromElement = evaluateFromElementPath( path, classAlias );
 		EntityPersister entityPersister = fromElement.getEntityPersister();
 
         // If the first identifier in the path refers to the class alias (not the class name), then this
 		// is a correlated subselect.  If it's a correlated sub-select, use the existing table alias.  Otherwise
 		// generate a new one.
 		String tableAlias = null;
 		boolean correlatedSubselect = pathAlias.equals( parentFromElement.getClassAlias() );
 		if ( correlatedSubselect ) {
 			tableAlias = fromElement.getTableAlias();
 		}
 		else {
 			tableAlias = null;
 		}
 
 		// If the from element isn't in the same clause, create a new from element.
 		if ( fromElement.getFromClause() != fromClause ) {
             LOG.debugf("createFromElementInSubselect() : creating a new FROM element...");
 			fromElement = createFromElement( entityPersister );
 			initializeAndAddFromElement( fromElement,
 					path,
 					classAlias,
 					entityPersister,
 					( EntityType ) ( ( Queryable ) entityPersister ).getType(),
 					tableAlias
 			);
 		}
         LOG.debugf("createFromElementInSubselect() : %s -> %s", path, fromElement);
 		return fromElement;
 	}
 
 	private FromElement evaluateFromElementPath(String path, String classAlias) throws SemanticException {
 		ASTFactory factory = fromClause.getASTFactory();
 		FromReferenceNode pathNode = ( FromReferenceNode ) PathHelper.parsePath( path, factory );
 		pathNode.recursiveResolve( FromReferenceNode.ROOT_LEVEL, // This is the root level node.
 				false, // Generate an explicit from clause at the root.
 				classAlias,
 		        null
 		);
         if (pathNode.getImpliedJoin() != null) return pathNode.getImpliedJoin();
         return pathNode.getFromElement();
 	}
 
 	FromElement createCollectionElementsJoin(
 	        QueryableCollection queryableCollection,
 	        String collectionName) throws SemanticException {
 		JoinSequence collectionJoinSequence = fromClause.getSessionFactoryHelper()
 		        .createCollectionJoinSequence( queryableCollection, collectionName );
 		this.queryableCollection = queryableCollection;
 		return createCollectionJoin( collectionJoinSequence, null );
 	}
 
 	FromElement createCollection(
 	        QueryableCollection queryableCollection,
 	        String role,
 	        int joinType,
 	        boolean fetchFlag,
 	        boolean indexed)
 			throws SemanticException {
 		if ( !collection ) {
 			throw new IllegalStateException( "FromElementFactory not initialized for collections!" );
 		}
 		this.inElementsFunction = indexed;
 		FromElement elem;
 		this.queryableCollection = queryableCollection;
 		collectionType = queryableCollection.getCollectionType();
 		String roleAlias = fromClause.getAliasGenerator().createName( role );
 
 		// Correlated subqueries create 'special' implied from nodes
 		// because correlated subselects can't use an ANSI-style join
 		boolean explicitSubqueryFromElement = fromClause.isSubQuery() && !implied;
 		if ( explicitSubqueryFromElement ) {
 			String pathRoot = StringHelper.root( path );
 			FromElement origin = fromClause.getFromElement( pathRoot );
 			if ( origin == null || origin.getFromClause() != fromClause ) {
 				implied = true;
 			}
 		}
 
 		// super-duper-classic-parser-regression-testing-mojo-magic...
 		if ( explicitSubqueryFromElement && DotNode.useThetaStyleImplicitJoins ) {
 			implied = true;
 		}
 
 		Type elementType = queryableCollection.getElementType();
 		if ( elementType.isEntityType() ) { 			// A collection of entities...
 			elem = createEntityAssociation( role, roleAlias, joinType );
 		}
 		else if ( elementType.isComponentType() ) {		// A collection of components...
 			JoinSequence joinSequence = createJoinSequence( roleAlias, joinType );
 			elem = createCollectionJoin( joinSequence, roleAlias );
 		}
 		else {											// A collection of scalar elements...
 			JoinSequence joinSequence = createJoinSequence( roleAlias, joinType );
 			elem = createCollectionJoin( joinSequence, roleAlias );
 		}
 
 		elem.setRole( role );
 		elem.setQueryableCollection( queryableCollection );
 		// Don't include sub-classes for implied collection joins or subquery joins.
 		if ( implied ) {
 			elem.setIncludeSubclasses( false );
 		}
 
 		if ( explicitSubqueryFromElement ) {
 			elem.setInProjectionList( true );	// Treat explict from elements in sub-queries properly.
 		}
 
 		if ( fetchFlag ) {
 			elem.setFetch( true );
 		}
 		return elem;
 	}
 
 	FromElement createEntityJoin(
 	        String entityClass,
 	        String tableAlias,
 	        JoinSequence joinSequence,
 	        boolean fetchFlag,
 	        boolean inFrom,
 	        EntityType type) throws SemanticException {
 		FromElement elem = createJoin( entityClass, tableAlias, joinSequence, type, false );
 		elem.setFetch( fetchFlag );
 		EntityPersister entityPersister = elem.getEntityPersister();
 		int numberOfTables = entityPersister.getQuerySpaces().length;
 		if ( numberOfTables > 1 && implied && !elem.useFromFragment() ) {
             LOG.debugf("createEntityJoin() : Implied multi-table entity join");
 			elem.setUseFromFragment( true );
 		}
 
 		// If this is an implied join in a FROM clause, then use ANSI-style joining, and set the
 		// flag on the FromElement that indicates that it was implied in the FROM clause itself.
 		if ( implied && inFrom ) {
 			joinSequence.setUseThetaStyle( false );
 			elem.setUseFromFragment( true );
 			elem.setImpliedInFromClause( true );
 		}
 		if ( elem.getWalker().isSubQuery() ) {
 			// two conditions where we need to transform this to a theta-join syntax:
 			//      1) 'elem' is the "root from-element" in correlated subqueries
 			//      2) The DotNode.useThetaStyleImplicitJoins has been set to true
 			//          and 'elem' represents an implicit join
 			if ( elem.getFromClause() != elem.getOrigin().getFromClause() ||
 //			        ( implied && DotNode.useThetaStyleImplicitJoins ) ) {
 			        DotNode.useThetaStyleImplicitJoins ) {
 				// the "root from-element" in correlated subqueries do need this piece
 				elem.setType( FROM_FRAGMENT );
 				joinSequence.setUseThetaStyle( true );
 				elem.setUseFromFragment( false );
 			}
 		}
 
 		return elem;
 	}
 
 	public FromElement createComponentJoin(ComponentType type) {
 		// need to create a "place holder" from-element that can store the component/alias for this
 		// 		component join
 		return new ComponentJoin( fromClause, origin, classAlias, path, type );
 	}
 
 	FromElement createElementJoin(QueryableCollection queryableCollection) throws SemanticException {
 		FromElement elem;
 
 		implied = true; //TODO: always true for now, but not if we later decide to support elements() in the from clause
 		inElementsFunction = true;
 		Type elementType = queryableCollection.getElementType();
 		if ( !elementType.isEntityType() ) {
 			throw new IllegalArgumentException( "Cannot create element join for a collection of non-entities!" );
 		}
 		this.queryableCollection = queryableCollection;
 		SessionFactoryHelper sfh = fromClause.getSessionFactoryHelper();
 		FromElement destination = null;
 		String tableAlias = null;
 		EntityPersister entityPersister = queryableCollection.getElementPersister();
 		tableAlias = fromClause.getAliasGenerator().createName( entityPersister.getEntityName() );
 		String associatedEntityName = entityPersister.getEntityName();
 		EntityPersister targetEntityPersister = sfh.requireClassPersister( associatedEntityName );
 		// Create the FROM element for the target (the elements of the collection).
 		destination = createAndAddFromElement(
 				associatedEntityName,
 				classAlias,
 				targetEntityPersister,
 				( EntityType ) queryableCollection.getElementType(),
 				tableAlias
 			);
 		// If the join is implied, then don't include sub-classes on the element.
 		if ( implied ) {
 			destination.setIncludeSubclasses( false );
 		}
 		fromClause.addCollectionJoinFromElementByPath( path, destination );
 //		origin.addDestination(destination);
 		// Add the query spaces.
 		fromClause.getWalker().addQuerySpaces( entityPersister.getQuerySpaces() );
 
 		CollectionType type = queryableCollection.getCollectionType();
 		String role = type.getRole();
 		String roleAlias = origin.getTableAlias();
 
 		String[] targetColumns = sfh.getCollectionElementColumns( role, roleAlias );
 		AssociationType elementAssociationType = sfh.getElementAssociationType( type );
 
 		// Create the join element under the from element.
 		int joinType = JoinFragment.INNER_JOIN;
 		JoinSequence joinSequence = sfh.createJoinSequence( implied, elementAssociationType, tableAlias, joinType, targetColumns );
 		elem = initializeJoin( path, destination, joinSequence, targetColumns, origin, false );
 		elem.setUseFromFragment( true );	// The associated entity is implied, but it must be included in the FROM.
 		elem.setCollectionTableAlias( roleAlias );	// The collection alias is the role.
 		return elem;
 	}
 
 	private FromElement createCollectionJoin(JoinSequence collectionJoinSequence, String tableAlias) throws SemanticException {
 		String text = queryableCollection.getTableName();
 		AST ast = createFromElement( text );
 		FromElement destination = ( FromElement ) ast;
 		Type elementType = queryableCollection.getElementType();
 		if ( elementType.isCollectionType() ) {
 			throw new SemanticException( "Collections of collections are not supported!" );
 		}
 		destination.initializeCollection( fromClause, classAlias, tableAlias );
 		destination.setType( JOIN_FRAGMENT );		// Tag this node as a JOIN.
 		destination.setIncludeSubclasses( false );	// Don't include subclasses in the join.
 		destination.setCollectionJoin( true );		// This is a clollection join.
 		destination.setJoinSequence( collectionJoinSequence );
 		destination.setOrigin( origin, false );
 		destination.setCollectionTableAlias(tableAlias);
 //		origin.addDestination( destination );
 // This was the cause of HHH-242
 //		origin.setType( FROM_FRAGMENT );			// Set the parent node type so that the AST is properly formed.
 		origin.setText( "" );						// The destination node will have all the FROM text.
 		origin.setCollectionJoin( true );			// The parent node is a collection join too (voodoo - see JoinProcessor)
 		fromClause.addCollectionJoinFromElementByPath( path, destination );
 		fromClause.getWalker().addQuerySpaces( queryableCollection.getCollectionSpaces() );
 		return destination;
 	}
 
 	private FromElement createEntityAssociation(
 	        String role,
 	        String roleAlias,
 	        int joinType) throws SemanticException {
 		FromElement elem;
 		Queryable entityPersister = ( Queryable ) queryableCollection.getElementPersister();
 		String associatedEntityName = entityPersister.getEntityName();
 		// Get the class name of the associated entity.
 		if ( queryableCollection.isOneToMany() ) {
             LOG.debugf("createEntityAssociation() : One to many - path = %s role = %s associatedEntityName = %s",
                        path,
                        role,
                        associatedEntityName);
 			JoinSequence joinSequence = createJoinSequence( roleAlias, joinType );
 
 			elem = createJoin( associatedEntityName, roleAlias, joinSequence, ( EntityType ) queryableCollection.getElementType(), false );
 		}
 		else {
             LOG.debugf("createManyToMany() : path = %s role = %s associatedEntityName = %s", path, role, associatedEntityName);
 			elem = createManyToMany( role, associatedEntityName,
 					roleAlias, entityPersister, ( EntityType ) queryableCollection.getElementType(), joinType );
 			fromClause.getWalker().addQuerySpaces( queryableCollection.getCollectionSpaces() );
 		}
 		elem.setCollectionTableAlias( roleAlias );
 		return elem;
 	}
 
 	private FromElement createJoin(
 	        String entityClass,
 	        String tableAlias,
 	        JoinSequence joinSequence,
 	        EntityType type,
 	        boolean manyToMany) throws SemanticException {
 		//  origin, path, implied, columns, classAlias,
 		EntityPersister entityPersister = fromClause.getSessionFactoryHelper().requireClassPersister( entityClass );
 		FromElement destination = createAndAddFromElement( entityClass,
 				classAlias,
 				entityPersister,
 				type,
 				tableAlias );
 		return initializeJoin( path, destination, joinSequence, getColumns(), origin, manyToMany );
 	}
 
 	private FromElement createManyToMany(
 	        String role,
 	        String associatedEntityName,
 	        String roleAlias,
 	        Queryable entityPersister,
 	        EntityType type,
 	        int joinType) throws SemanticException {
 		FromElement elem;
 		SessionFactoryHelper sfh = fromClause.getSessionFactoryHelper();
 		if ( inElementsFunction /*implied*/ ) {
 			// For implied many-to-many, just add the end join.
 			JoinSequence joinSequence = createJoinSequence( roleAlias, joinType );
 			elem = createJoin( associatedEntityName, roleAlias, joinSequence, type, true );
 		}
 		else {
 			// For an explicit many-to-many relationship, add a second join from the intermediate
 			// (many-to-many) table to the destination table.  Also, make sure that the from element's
 			// idea of the destination is the destination table.
 			String tableAlias = fromClause.getAliasGenerator().createName( entityPersister.getEntityName() );
 			String[] secondJoinColumns = sfh.getCollectionElementColumns( role, roleAlias );
 			// Add the second join, the one that ends in the destination table.
 			JoinSequence joinSequence = createJoinSequence( roleAlias, joinType );
 			joinSequence.addJoin( sfh.getElementAssociationType( collectionType ), tableAlias, joinType, secondJoinColumns );
 			elem = createJoin( associatedEntityName, tableAlias, joinSequence, type, false );
 			elem.setUseFromFragment( true );
 		}
 		return elem;
 	}
 
 	private JoinSequence createJoinSequence(String roleAlias, int joinType) {
 		SessionFactoryHelper sessionFactoryHelper = fromClause.getSessionFactoryHelper();
 		String[] joinColumns = getColumns();
 		if ( collectionType == null ) {
 			throw new IllegalStateException( "collectionType is null!" );
 		}
 		return sessionFactoryHelper.createJoinSequence( implied, collectionType, roleAlias, joinType, joinColumns );
 	}
 
 	private FromElement createAndAddFromElement(
 	        String className,
 	        String classAlias,
 	        EntityPersister entityPersister,
 	        EntityType type,
 	        String tableAlias) {
 		if ( !( entityPersister instanceof Joinable ) ) {
 			throw new IllegalArgumentException( "EntityPersister " + entityPersister + " does not implement Joinable!" );
 		}
 		FromElement element = createFromElement( entityPersister );
 		initializeAndAddFromElement( element, className, classAlias, entityPersister, type, tableAlias );
 		return element;
 	}
 
 	private void initializeAndAddFromElement(
 	        FromElement element,
 	        String className,
 	        String classAlias,
 	        EntityPersister entityPersister,
 	        EntityType type,
 	        String tableAlias) {
 		if ( tableAlias == null ) {
 			AliasGenerator aliasGenerator = fromClause.getAliasGenerator();
 			tableAlias = aliasGenerator.createName( entityPersister.getEntityName() );
 		}
 		element.initializeEntity( fromClause, className, entityPersister, type, classAlias, tableAlias );
 	}
 
 	private FromElement createFromElement(EntityPersister entityPersister) {
 		Joinable joinable = ( Joinable ) entityPersister;
 		String text = joinable.getTableName();
 		AST ast = createFromElement( text );
 		FromElement element = ( FromElement ) ast;
 		return element;
 	}
 
 	private AST createFromElement(String text) {
 		AST ast = ASTUtil.create( fromClause.getASTFactory(),
 				implied ? IMPLIED_FROM : FROM_FRAGMENT, // This causes the factory to instantiate the desired class.
 				text );
 		// Reset the node type, because the rest of the system is expecting FROM_FRAGMENT, all we wanted was
 		// for the factory to create the right sub-class.  This might get reset again later on anyway to make the
 		// SQL generation simpler.
 		ast.setType( FROM_FRAGMENT );
 		return ast;
 	}
 
 	private FromElement initializeJoin(
 	        String path,
 	        FromElement destination,
 	        JoinSequence joinSequence,
 	        String[] columns,
 	        FromElement origin,
 	        boolean manyToMany) {
 		destination.setType( JOIN_FRAGMENT );
 		destination.setJoinSequence( joinSequence );
 		destination.setColumns( columns );
 		destination.setOrigin( origin, manyToMany );
 		fromClause.addJoinByPathMap( path, destination );
 		return destination;
 	}
 
 	private String[] getColumns() {
 		if ( columns == null ) {
 			throw new IllegalStateException( "No foriegn key columns were supplied!" );
 		}
 		return columns;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElementType.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElementType.java
index a87e219386..ca925eb003 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElementType.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromElementType.java
@@ -1,517 +1,518 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
 
 import java.util.List;
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.hql.CollectionProperties;
 import org.hibernate.hql.CollectionSubqueryFactory;
 import org.hibernate.hql.NameGenerator;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.collection.CollectionPropertyMapping;
 import org.hibernate.persister.collection.CollectionPropertyNames;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Delegate that handles the type and join sequence information for a FromElement.
  *
  * @author josh
  */
 class FromElementType {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, FromElementType.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, FromElementType.class.getName());
 
 	private FromElement fromElement;
 	private EntityType entityType;
 	private EntityPersister persister;
 	private QueryableCollection queryableCollection;
 	private CollectionPropertyMapping collectionPropertyMapping;
 	private JoinSequence joinSequence;
 	private String collectionSuffix;
 	private ParameterSpecification indexCollectionSelectorParamSpec;
 
 	public FromElementType(FromElement fromElement, EntityPersister persister, EntityType entityType) {
 		this.fromElement = fromElement;
 		this.persister = persister;
 		this.entityType = entityType;
 		if ( persister != null ) {
 			fromElement.setText( ( ( Queryable ) persister ).getTableName() + " " + getTableAlias() );
 		}
 	}
 
 	protected FromElementType(FromElement fromElement) {
 		this.fromElement = fromElement;
 	}
 
 	private String getTableAlias() {
 		return fromElement.getTableAlias();
 	}
 
 	private String getCollectionTableAlias() {
 		return fromElement.getCollectionTableAlias();
 	}
 
 	public String getCollectionSuffix() {
 		return collectionSuffix;
 	}
 
 	public void setCollectionSuffix(String suffix) {
 		collectionSuffix = suffix;
 	}
 
 	public EntityPersister getEntityPersister() {
 		return persister;
 	}
 
 	public Type getDataType() {
 		if ( persister == null ) {
 			if ( queryableCollection == null ) {
 				return null;
 			}
 			return queryableCollection.getType();
 		}
 		else {
 			return entityType;
 		}
 	}
 
 	public Type getSelectType() {
 		if (entityType==null) return null;
 		boolean shallow = fromElement.getFromClause().getWalker().isShallowQuery();
 		return fromElement.getSessionFactoryHelper()
 				.getFactory()
 				.getTypeResolver()
 				.getTypeFactory().manyToOne( entityType.getAssociatedEntityName(), shallow );
 	}
 
 	/**
 	 * Returns the Hibernate queryable implementation for the HQL class.
 	 *
 	 * @return the Hibernate queryable implementation for the HQL class.
 	 */
 	public Queryable getQueryable() {
 		return ( persister instanceof Queryable ) ? ( Queryable ) persister : null;
 	}
 
 	/**
 	 * Render the identifier select, but in a 'scalar' context (i.e. generate the column alias).
 	 *
 	 * @param i the sequence of the returned type
 	 * @return the identifier select with the column alias.
 	 */
 	String renderScalarIdentifierSelect(int i) {
 		checkInitialized();
 		String[] cols = getPropertyMapping( EntityPersister.ENTITY_ID ).toColumns( getTableAlias(), EntityPersister.ENTITY_ID );
 		StringBuffer buf = new StringBuffer();
 		// For property references generate <tablealias>.<columnname> as <projectionalias>
 		for ( int j = 0; j < cols.length; j++ ) {
 			String column = cols[j];
 			if ( j > 0 ) {
 				buf.append( ", " );
 			}
 			buf.append( column ).append( " as " ).append( NameGenerator.scalarName( i, j ) );
 		}
 		return buf.toString();
 	}
 
 	/**
 	 * Returns the identifier select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the identifier select SQL fragment.
 	 */
 	String renderIdentifierSelect(int size, int k) {
 		checkInitialized();
 		// Render the identifier select fragment using the table alias.
 		if ( fromElement.getFromClause().isSubQuery() ) {
 			// TODO: Replace this with a more elegant solution.
 			String[] idColumnNames = ( persister != null ) ?
 					( ( Queryable ) persister ).getIdentifierColumnNames() : new String[0];
 			StringBuffer buf = new StringBuffer();
 			for ( int i = 0; i < idColumnNames.length; i++ ) {
 				buf.append( fromElement.getTableAlias() ).append( '.' ).append( idColumnNames[i] );
 				if ( i != idColumnNames.length - 1 ) buf.append( ", " );
 			}
 			return buf.toString();
 		}
 		else {
 			if (persister==null) {
 				throw new QueryException( "not an entity" );
 			}
 			String fragment = ( ( Queryable ) persister ).identifierSelectFragment( getTableAlias(), getSuffix( size, k ) );
 			return trimLeadingCommaAndSpaces( fragment );
 		}
 	}
 
 	private String getSuffix(int size, int sequence) {
 		return generateSuffix( size, sequence );
 	}
 
 	private static String generateSuffix(int size, int k) {
 		String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 		return suffix;
 	}
 
 	private void checkInitialized() {
 		fromElement.checkInitialized();
 	}
 
 	/**
 	 * Returns the property select SQL fragment.
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the property select SQL fragment.
 	 */
 	String renderPropertySelect(int size, int k, boolean allProperties) {
 		checkInitialized();
 		if ( persister == null ) {
 			return "";
 		}
 		else {
 			String fragment =  ( ( Queryable ) persister ).propertySelectFragment(
 					getTableAlias(),
 					getSuffix( size, k ),
 					allProperties
 				);
 			return trimLeadingCommaAndSpaces( fragment );
 		}
 	}
 
 	String renderCollectionSelectFragment(int size, int k) {
 		if ( queryableCollection == null ) {
 			return "";
 		}
 		else {
 			if ( collectionSuffix == null ) {
 				collectionSuffix = generateSuffix( size, k );
 			}
 			String fragment = queryableCollection.selectFragment( getCollectionTableAlias(), collectionSuffix );
 			return trimLeadingCommaAndSpaces( fragment );
 		}
 	}
 
 	public String renderValueCollectionSelectFragment(int size, int k) {
 		if ( queryableCollection == null ) {
 			return "";
 		}
 		else {
 			if ( collectionSuffix == null ) {
 				collectionSuffix = generateSuffix( size, k );
 			}
 			String fragment =  queryableCollection.selectFragment( getTableAlias(), collectionSuffix );
 			return trimLeadingCommaAndSpaces( fragment );
 		}
 	}
 
 	/**
 	 * This accounts for a quirk in Queryable, where it sometimes generates ',  ' in front of the
 	 * SQL fragment.  :-P
 	 *
 	 * @param fragment An SQL fragment.
 	 * @return The fragment, without the leading comma and spaces.
 	 */
 	private static String trimLeadingCommaAndSpaces(String fragment) {
 		if ( fragment.length() > 0 && fragment.charAt( 0 ) == ',' ) {
 			fragment = fragment.substring( 1 );
 		}
 		fragment = fragment.trim();
 		return fragment.trim();
 	}
 
 	public void setJoinSequence(JoinSequence joinSequence) {
 		this.joinSequence = joinSequence;
 	}
 
 	public JoinSequence getJoinSequence() {
 		if ( joinSequence != null ) {
 			return joinSequence;
 		}
 
 		// Class names in the FROM clause result in a JoinSequence (the old FromParser does this).
 		if ( persister instanceof Joinable ) {
 			Joinable joinable = ( Joinable ) persister;
 			return fromElement.getSessionFactoryHelper().createJoinSequence().setRoot( joinable, getTableAlias() );
 		}
 		else {
 			return null;	// TODO: Should this really return null?  If not, figure out something better to do here.
 		}
 	}
 
 	public void setQueryableCollection(QueryableCollection queryableCollection) {
 		if ( this.queryableCollection != null ) {
 			throw new IllegalStateException( "QueryableCollection is already defined for " + this + "!" );
 		}
 		this.queryableCollection = queryableCollection;
 		if ( !queryableCollection.isOneToMany() ) {
 			// For many-to-many joins, use the tablename from the queryable collection for the default text.
 			fromElement.setText( queryableCollection.getTableName() + " " + getTableAlias() );
 		}
 	}
 
 	public QueryableCollection getQueryableCollection() {
 		return queryableCollection;
 	}
 
 	/**
 	 * Returns the type of a property, given it's name (the last part) and the full path.
 	 *
 	 * @param propertyName The last part of the full path to the property.
 	 * @return The type.
 	 * @0param propertyPath The full property path.
 	 */
 	public Type getPropertyType(String propertyName, String propertyPath) {
 		checkInitialized();
 		Type type = null;
 		// If this is an entity and the property is the identifier property, then use getIdentifierType().
 		//      Note that the propertyName.equals( propertyPath ) checks whether we have a component
 		//      key reference, where the component class property name is the same as the
 		//      entity id property name; if the two are not equal, this is the case and
 		//      we'd need to "fall through" to using the property mapping.
 		if ( persister != null && propertyName.equals( propertyPath ) && propertyName.equals( persister.getIdentifierPropertyName() ) ) {
 			type = persister.getIdentifierType();
 		}
 		else {	// Otherwise, use the property mapping.
 			PropertyMapping mapping = getPropertyMapping( propertyName );
 			type = mapping.toType( propertyPath );
 		}
 		if ( type == null ) {
 			throw new MappingException( "Property " + propertyName + " does not exist in " +
 					( ( queryableCollection == null ) ? "class" : "collection" ) + " "
 					+ ( ( queryableCollection == null ) ? fromElement.getClassName() : queryableCollection.getRole() ) );
 		}
 		return type;
 	}
 
 	String[] toColumns(String tableAlias, String path, boolean inSelect) {
 		return toColumns( tableAlias, path, inSelect, false );
 	}
 
 	String[] toColumns(String tableAlias, String path, boolean inSelect, boolean forceAlias) {
 		checkInitialized();
 		PropertyMapping propertyMapping = getPropertyMapping( path );
 		// If this from element is a collection and the path is a collection property (maxIndex, etc.) then
 		// generate a sub-query.
 		//
 		// NOTE : in the case of this being a collection property in the select, not generating the subquery
 		// will not generally work.  The specific cases I am thinking about are the minIndex, maxIndex
 		// (most likely minElement, maxElement as well) cases.
 		//	todo : if ^^ is the case we should thrown an exception here rather than waiting for the sql error
 		//		if the dialect supports select-clause subqueries we could go ahead and generate the subquery also
 		if ( !inSelect && queryableCollection != null && CollectionProperties.isCollectionProperty( path ) ) {
 			Map enabledFilters = fromElement.getWalker().getEnabledFilters();
 			String subquery = CollectionSubqueryFactory.createCollectionSubquery(
 					joinSequence.copy().setUseThetaStyle( true ),
 			        enabledFilters,
 					propertyMapping.toColumns( tableAlias, path )
 			);
             LOG.debugf("toColumns(%s,%s) : subquery = %s", tableAlias, path, subquery);
 			return new String[]{"(" + subquery + ")"};
 		}
         if (forceAlias) {
             return propertyMapping.toColumns(tableAlias, path);
         } else if (fromElement.getWalker().getStatementType() == HqlSqlTokenTypes.SELECT) {
             return propertyMapping.toColumns(tableAlias, path);
         } else if (fromElement.getWalker().getCurrentClauseType() == HqlSqlTokenTypes.SELECT) {
             return propertyMapping.toColumns(tableAlias, path);
         } else if (fromElement.getWalker().isSubQuery()) {
             // for a subquery, the alias to use depends on a few things (we
             // already know this is not an overall SELECT):
             // 1) if this FROM_ELEMENT represents a correlation to the
             // outer-most query
             // A) if the outer query represents a multi-table
             // persister, we need to use the given alias
             // in anticipation of one of the multi-table
             // executors being used (as this subquery will
             // actually be used in the "id select" phase
             // of that multi-table executor)
             // B) otherwise, we need to use the persister's
             // table name as the column qualification
             // 2) otherwise (not correlated), use the given alias
             if (isCorrelation()) {
                 if (isMultiTable()) return propertyMapping.toColumns(tableAlias, path);
                 return propertyMapping.toColumns(extractTableName(), path);
 			}
             return propertyMapping.toColumns(tableAlias, path);
         } else {
             String[] columns = propertyMapping.toColumns(path);
             LOG.trace("Using non-qualified column reference [" + path + " -> (" + ArrayHelper.toString(columns) + ")]");
             return columns;
         }
 	}
 
 	private boolean isCorrelation() {
 		FromClause top = fromElement.getWalker().getFinalFromClause();
 		return fromElement.getFromClause() != fromElement.getWalker().getCurrentFromClause() &&
 	           fromElement.getFromClause() == top;
 	}
 
 	private boolean isMultiTable() {
 		// should be safe to only ever expect EntityPersister references here
 		return fromElement.getQueryable() != null &&
 	           fromElement.getQueryable().isMultiTable();
 	}
 
 	private String extractTableName() {
 		// should be safe to only ever expect EntityPersister references here
 		return fromElement.getQueryable().getTableName();
 	}
 
 	private static final List SPECIAL_MANY2MANY_TREATMENT_FUNCTION_NAMES = java.util.Arrays.asList(
 			new String[] {
 					CollectionPropertyNames.COLLECTION_INDEX,
 					CollectionPropertyNames.COLLECTION_MIN_INDEX,
 					CollectionPropertyNames.COLLECTION_MAX_INDEX
 			}
 	);
 
 	PropertyMapping getPropertyMapping(String propertyName) {
 		checkInitialized();
 		if ( queryableCollection == null ) {		// Not a collection?
 			return ( PropertyMapping ) persister;	// Return the entity property mapping.
 		}
 
 		// indexed, many-to-many collections must be treated specially here if the property to
 		// be mapped touches on the index as we must adjust the alias to use the alias from
 		// the association table (which i different than the one passed in
 		if ( queryableCollection.isManyToMany()
 				&& queryableCollection.hasIndex()
 				&& SPECIAL_MANY2MANY_TREATMENT_FUNCTION_NAMES.contains( propertyName ) ) {
 			return new SpecialManyToManyCollectionPropertyMapping();
 		}
 
 		// If the property is a special collection property name, return a CollectionPropertyMapping.
 		if ( CollectionProperties.isCollectionProperty( propertyName ) ) {
 			if ( collectionPropertyMapping == null ) {
 				collectionPropertyMapping = new CollectionPropertyMapping( queryableCollection );
 			}
 			return collectionPropertyMapping;
 		}
 
 		if ( queryableCollection.getElementType().isAnyType() ) {
 			// collection of <many-to-any/> mappings...
 			// used to circumvent the component-collection check below...
 			return queryableCollection;
 
 		}
 
 		if ( queryableCollection.getElementType().isComponentType() ) {
 			// Collection of components.
 			if ( propertyName.equals( EntityPersister.ENTITY_ID ) ) {
 				return ( PropertyMapping ) queryableCollection.getOwnerEntityPersister();
 			}
 		}
 		return queryableCollection;
 	}
 
 	public boolean isCollectionOfValuesOrComponents() {
 		return persister == null
 				&& queryableCollection != null
 				&& !queryableCollection.getElementType().isEntityType();
 	}
 
 	public boolean isEntity() {
 		return persister != null;
 	}
 
 	public ParameterSpecification getIndexCollectionSelectorParamSpec() {
 		return indexCollectionSelectorParamSpec;
 	}
 
 	public void setIndexCollectionSelectorParamSpec(ParameterSpecification indexCollectionSelectorParamSpec) {
 		this.indexCollectionSelectorParamSpec = indexCollectionSelectorParamSpec;
 	}
 
 	private class SpecialManyToManyCollectionPropertyMapping implements PropertyMapping {
 		/**
 		 * {@inheritDoc}
 		 */
 		public Type getType() {
 			return queryableCollection.getCollectionType();
 		}
 
 		private void validate(String propertyName) {
 			if ( ! ( CollectionPropertyNames.COLLECTION_INDEX.equals( propertyName )
 					|| CollectionPropertyNames.COLLECTION_MAX_INDEX.equals( propertyName )
 					|| CollectionPropertyNames.COLLECTION_MIN_INDEX.equals( propertyName ) ) ) {
 				throw new IllegalArgumentException( "Expecting index-related function call" );
 			}
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Type toType(String propertyName) throws QueryException {
 			validate( propertyName );
 			return queryableCollection.getIndexType();
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public String[] toColumns(String alias, String propertyName) throws QueryException {
 			validate( propertyName );
 			final String joinTableAlias = joinSequence.getFirstJoin().getAlias();
 			if ( CollectionPropertyNames.COLLECTION_INDEX.equals( propertyName ) ) {
 				return queryableCollection.toColumns( joinTableAlias, propertyName );
 			}
 
 			final String[] cols = queryableCollection.getIndexColumnNames( joinTableAlias );
 			if ( CollectionPropertyNames.COLLECTION_MIN_INDEX.equals( propertyName ) ) {
 				if ( cols.length != 1 ) {
 					throw new QueryException( "composite collection index in minIndex()" );
 				}
 				return new String[] { "min(" + cols[0] + ')' };
 			}
 			else {
 				if ( cols.length != 1 ) {
 					throw new QueryException( "composite collection index in maxIndex()" );
 				}
 				return new String[] { "max(" + cols[0] + ')' };
 			}
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public String[] toColumns(String propertyName) throws QueryException, UnsupportedOperationException {
 			validate( propertyName );
 			return queryableCollection.toColumns( propertyName );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromReferenceNode.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromReferenceNode.java
index d5935a30b1..fc1a2c7de8 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromReferenceNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/FromReferenceNode.java
@@ -1,130 +1,131 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents a reference to a FROM element, for example a class alias in a WHERE clause.
  *
  * @author josh
  */
 public abstract class FromReferenceNode extends AbstractSelectExpression
         implements ResolvableNode, DisplayableNode, InitializeableNode, PathNode {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, FromReferenceNode.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, FromReferenceNode.class.getName());
 
 	private FromElement fromElement;
 	private boolean resolved = false;
 	public static final int ROOT_LEVEL = 0;
 
 	@Override
     public FromElement getFromElement() {
 		return fromElement;
 	}
 
 	public void setFromElement(FromElement fromElement) {
 		this.fromElement = fromElement;
 	}
 
 	/**
 	 * Resolves the left hand side of the DOT.
 	 *
 	 * @throws SemanticException
 	 */
 	public void resolveFirstChild() throws SemanticException {
 	}
 
 	public String getPath() {
 		return getOriginalText();
 	}
 
 	public boolean isResolved() {
 		return resolved;
 	}
 
 	public void setResolved() {
 		this.resolved = true;
         LOG.debugf("Resolved : %s -> %s", this.getPath(), this.getText());
 	}
 
 	public String getDisplayText() {
 		StringBuffer buf = new StringBuffer();
 		buf.append( "{" ).append( ( fromElement == null ) ? "no fromElement" : fromElement.getDisplayText() );
 		buf.append( "}" );
 		return buf.toString();
 	}
 
 	public void recursiveResolve(int level, boolean impliedAtRoot, String classAlias) throws SemanticException {
 		recursiveResolve( level, impliedAtRoot, classAlias, this );
 	}
 
 	public void recursiveResolve(int level, boolean impliedAtRoot, String classAlias, AST parent) throws SemanticException {
 		AST lhs = getFirstChild();
 		int nextLevel = level + 1;
 		if ( lhs != null ) {
 			FromReferenceNode n = ( FromReferenceNode ) lhs;
 			n.recursiveResolve( nextLevel, impliedAtRoot, null, this );
 		}
 		resolveFirstChild();
 		boolean impliedJoin = true;
 		if ( level == ROOT_LEVEL && !impliedAtRoot ) {
 			impliedJoin = false;
 		}
 		resolve( true, impliedJoin, classAlias, parent );
 	}
 
 	@Override
     public boolean isReturnableEntity() throws SemanticException {
 		return !isScalar() && fromElement.isEntity();
 	}
 
 	public void resolveInFunctionCall(boolean generateJoin, boolean implicitJoin) throws SemanticException {
 		resolve( generateJoin, implicitJoin );
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin) throws SemanticException {
 		resolve( generateJoin, implicitJoin, null );
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin, String classAlias) throws SemanticException {
 		resolve( generateJoin, implicitJoin, classAlias, null );
 	}
 
 	public void prepareForDot(String propertyName) throws SemanticException {
 	}
 
 	/**
 	 * Sub-classes can override this method if they produce implied joins (e.g. DotNode).
 	 *
 	 * @return an implied join created by this from reference.
 	 */
 	public FromElement getImpliedJoin() {
 		return null;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/IndexNode.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/IndexNode.java
index 60b6e52691..b8c4df202b 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/IndexNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/IndexNode.java
@@ -1,211 +1,211 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.List;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.QueryException;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.hql.ast.SqlGenerator;
 import org.hibernate.hql.ast.util.SessionFactoryHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.RecognitionException;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents the [] operator and provides it's semantics.
  *
  * @author josh
  */
 public class IndexNode extends FromReferenceNode {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, IndexNode.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, IndexNode.class.getName());
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		throw new UnsupportedOperationException( "An IndexNode cannot generate column text!" );
 	}
 
 	@Override
     public void prepareForDot(String propertyName) throws SemanticException {
 		FromElement fromElement = getFromElement();
 		if ( fromElement == null ) {
 			throw new IllegalStateException( "No FROM element for index operator!" );
 		}
 		QueryableCollection queryableCollection = fromElement.getQueryableCollection();
 		if ( queryableCollection != null && !queryableCollection.isOneToMany() ) {
 
 			FromReferenceNode collectionNode = ( FromReferenceNode ) getFirstChild();
 			String path = collectionNode.getPath() + "[]." + propertyName;
             LOG.debugf("Creating join for many-to-many elements for %s", path);
 			FromElementFactory factory = new FromElementFactory( fromElement.getFromClause(), fromElement, path );
 			// This will add the new from element to the origin.
 			FromElement elementJoin = factory.createElementJoin( queryableCollection );
 			setFromElement( elementJoin );
 		}
 	}
 
 	public void resolveIndex(AST parent) throws SemanticException {
 		throw new UnsupportedOperationException();
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin, String classAlias, AST parent)
 	throws SemanticException {
 		if ( isResolved() ) {
 			return;
 		}
 		FromReferenceNode collectionNode = ( FromReferenceNode ) getFirstChild();
 		SessionFactoryHelper sessionFactoryHelper = getSessionFactoryHelper();
 		collectionNode.resolveIndex( this );		// Fully resolve the map reference, create implicit joins.
 
 		Type type = collectionNode.getDataType();
 		if ( !type.isCollectionType() ) {
 			throw new SemanticException( "The [] operator cannot be applied to type " + type.toString() );
 		}
 		String collectionRole = ( ( CollectionType ) type ).getRole();
 		QueryableCollection queryableCollection = sessionFactoryHelper.requireQueryableCollection( collectionRole );
 		if ( !queryableCollection.hasIndex() ) {
 			throw new QueryException( "unindexed fromElement before []: " + collectionNode.getPath() );
 		}
 
 		// Generate the inner join -- The elements need to be joined to the collection they are in.
 		FromElement fromElement = collectionNode.getFromElement();
 		String elementTable = fromElement.getTableAlias();
 		FromClause fromClause = fromElement.getFromClause();
 		String path = collectionNode.getPath();
 
 		FromElement elem = fromClause.findCollectionJoin( path );
 		if ( elem == null ) {
 			FromElementFactory factory = new FromElementFactory( fromClause, fromElement, path );
 			elem = factory.createCollectionElementsJoin( queryableCollection, elementTable );
             LOG.debugf("No FROM element found for the elements of collection join path %s, created %s", path, elem);
         } else LOG.debugf("FROM element found for collection join path %s", path);
 
 		// The 'from element' that represents the elements of the collection.
 		setFromElement( fromElement );
 
 		// Add the condition to the join sequence that qualifies the indexed element.
 		AST selector = collectionNode.getNextSibling();
 		if ( selector == null ) {
 			throw new QueryException( "No index value!" );
 		}
 
 		// Sometimes use the element table alias, sometimes use the... umm... collection table alias (many to many)
 		String collectionTableAlias = elementTable;
 		if ( elem.getCollectionTableAlias() != null ) {
 			collectionTableAlias = elem.getCollectionTableAlias();
 		}
 
 		// TODO: get SQL rendering out of here, create an AST for the join expressions.
 		// Use the SQL generator grammar to generate the SQL text for the index expression.
 		JoinSequence joinSequence = fromElement.getJoinSequence();
 		String[] indexCols = queryableCollection.getIndexColumnNames();
 		if ( indexCols.length != 1 ) {
 			throw new QueryException( "composite-index appears in []: " + collectionNode.getPath() );
 		}
 		SqlGenerator gen = new SqlGenerator( getSessionFactoryHelper().getFactory() );
 		try {
 			gen.simpleExpr( selector ); //TODO: used to be exprNoParens! was this needed?
 		}
 		catch ( RecognitionException e ) {
 			throw new QueryException( e.getMessage(), e );
 		}
 		String selectorExpression = gen.getSQL();
 		joinSequence.addCondition( collectionTableAlias + '.' + indexCols[0] + " = " + selectorExpression );
 		List paramSpecs = gen.getCollectedParameters();
 		if ( paramSpecs != null ) {
 			switch ( paramSpecs.size() ) {
 				case 0 :
 					// nothing to do
 					break;
 				case 1 :
 					ParameterSpecification paramSpec = ( ParameterSpecification ) paramSpecs.get( 0 );
 					paramSpec.setExpectedType( queryableCollection.getIndexType() );
 					fromElement.setIndexCollectionSelectorParamSpec( paramSpec );
 					break;
 				default:
 					fromElement.setIndexCollectionSelectorParamSpec(
 							new AggregatedIndexCollectionSelectorParameterSpecifications( paramSpecs )
 					);
 					break;
 			}
 		}
 
 		// Now, set the text for this node.  It should be the element columns.
 		String[] elementColumns = queryableCollection.getElementColumnNames( elementTable );
 		setText( elementColumns[0] );
 		setResolved();
 	}
 
 	/**
 	 * In the (rare?) case where the index selector contains multiple parameters...
 	 */
 	private static class AggregatedIndexCollectionSelectorParameterSpecifications implements ParameterSpecification {
 		private final List paramSpecs;
 
 		public AggregatedIndexCollectionSelectorParameterSpecifications(List paramSpecs) {
 			this.paramSpecs = paramSpecs;
 		}
 
 		public int bind(PreparedStatement statement, QueryParameters qp, SessionImplementor session, int position)
 		throws SQLException {
 			int bindCount = 0;
 			Iterator itr = paramSpecs.iterator();
 			while ( itr.hasNext() ) {
 				final ParameterSpecification paramSpec = ( ParameterSpecification ) itr.next();
 				bindCount += paramSpec.bind( statement, qp, session, position + bindCount );
 			}
 			return bindCount;
 		}
 
 		public Type getExpectedType() {
 			return null;
 		}
 
 		public void setExpectedType(Type expectedType) {
 		}
 
 		public String renderDisplayInfo() {
 			return "index-selector [" + collectDisplayInfo() + "]" ;
 		}
 
 		private String collectDisplayInfo() {
 			StringBuffer buffer = new StringBuffer();
 			Iterator itr = paramSpecs.iterator();
 			while ( itr.hasNext() ) {
 				buffer.append( ( ( ParameterSpecification ) itr.next() ).renderDisplayInfo() );
 			}
 			return buffer.toString();
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/MethodNode.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/MethodNode.java
index 56990ff8d6..2a4a41fc34 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/MethodNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/MethodNode.java
@@ -1,243 +1,244 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
 import java.util.Arrays;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.CollectionProperties;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.TypeDiscriminatorMetadata;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.hql.ast.util.ColumnHelper;
 import org.hibernate.persister.collection.CollectionPropertyNames;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents a method call.
  *
  * @author josh
  */
 public class MethodNode extends AbstractSelectExpression implements FunctionNode {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, MethodNode.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, MethodNode.class.getName());
 
 	private String methodName;
 	private FromElement fromElement;
 	private String[] selectColumns;
 	private SQLFunction function;
 	private boolean inSelect;
 
 	public void resolve(boolean inSelect) throws SemanticException {
 		// Get the function name node.
 		AST name = getFirstChild();
 		initializeMethodNode( name, inSelect );
 		AST exprList = name.getNextSibling();
 		// If the expression list has exactly one expression, and the type of the expression is a collection
 		// then this might be a collection function, such as index(c) or size(c).
 		if ( ASTUtil.hasExactlyOneChild( exprList ) ) {
 			if ( "type".equals( methodName ) ) {
 				typeDiscriminator( exprList.getFirstChild() );
 				return;
 			}
 			if ( isCollectionPropertyMethod() ) {
 				collectionProperty( exprList.getFirstChild(), name );
 				return;
 			}
 		}
 
 		dialectFunction( exprList );
 	}
 
 	private void typeDiscriminator(AST path) throws SemanticException {
 		if ( path == null ) {
 			throw new SemanticException( "type() discriminator reference has no path!" );
 		}
 
 		FromReferenceNode pathAsFromReferenceNode = (FromReferenceNode) path;
 		FromElement fromElement = pathAsFromReferenceNode.getFromElement();
 		TypeDiscriminatorMetadata typeDiscriminatorMetadata = fromElement.getTypeDiscriminatorMetadata();
 
 		setDataType( typeDiscriminatorMetadata.getResolutionType() );
 		setText( typeDiscriminatorMetadata.getSqlFragment() );
 		setType( SqlTokenTypes.SQL_TOKEN );
 	}
 
 	public SQLFunction getSQLFunction() {
 		return function;
 	}
 
 	public Type getFirstArgumentType() {
 		AST argument = getFirstChild();
 		while ( argument != null ) {
 			if ( argument instanceof SqlNode ) {
 				final Type type = ( (SqlNode) argument ).getDataType();
 				if ( type != null ) {
 					return type;
 				}
 				argument = argument.getNextSibling();
 			}
 		}
 		return null;
 	}
 
 	private void dialectFunction(AST exprList) {
 		function = getSessionFactoryHelper().findSQLFunction( methodName );
 		if ( function != null ) {
 			AST firstChild = exprList != null ? exprList.getFirstChild() : null;
 			Type functionReturnType = getSessionFactoryHelper()
 					.findFunctionReturnType( methodName, firstChild );
 			setDataType( functionReturnType );
 		}
 		//TODO:
 		/*else {
 			methodName = (String) getWalker().getTokenReplacements().get( methodName );
 		}*/
 	}
 
 	public boolean isCollectionPropertyMethod() {
 		return CollectionProperties.isAnyCollectionProperty( methodName );
 	}
 
 	public void initializeMethodNode(AST name, boolean inSelect) {
 		name.setType( SqlTokenTypes.METHOD_NAME );
 		String text = name.getText();
 		methodName = text.toLowerCase();	// Use the lower case function name.
 		this.inSelect = inSelect;			// Remember whether we're in a SELECT clause or not.
 	}
 
 	private String getMethodName() {
 		return methodName;
 	}
 
 	private void collectionProperty(AST path, AST name) throws SemanticException {
 		if ( path == null ) {
 			throw new SemanticException( "Collection function " + name.getText() + " has no path!" );
 		}
 
 		SqlNode expr = ( SqlNode ) path;
 		Type type = expr.getDataType();
         LOG.debugf("collectionProperty() :  name=%s type=%s", name, type);
 
 		resolveCollectionProperty( expr );
 	}
 
 	@Override
     public boolean isScalar() throws SemanticException {
 		// Method expressions in a SELECT should always be considered scalar.
 		return true;
 	}
 
 	public void resolveCollectionProperty(AST expr) throws SemanticException {
 		String propertyName = CollectionProperties.getNormalizedPropertyName( getMethodName() );
 		if ( expr instanceof FromReferenceNode ) {
 			FromReferenceNode collectionNode = ( FromReferenceNode ) expr;
 			// If this is 'elements' then create a new FROM element.
 			if ( CollectionPropertyNames.COLLECTION_ELEMENTS.equals( propertyName ) ) {
 				handleElements( collectionNode, propertyName );
 			}
 			else {
 				// Not elements(x)
 				fromElement = collectionNode.getFromElement();
 				setDataType( fromElement.getPropertyType( propertyName, propertyName ) );
 				selectColumns = fromElement.toColumns( fromElement.getTableAlias(), propertyName, inSelect );
 			}
 			if ( collectionNode instanceof DotNode ) {
 				prepareAnyImplicitJoins( ( DotNode ) collectionNode );
 			}
 			if ( !inSelect ) {
 				fromElement.setText( "" );
 				fromElement.setUseWhereFragment( false );
 			}
 			prepareSelectColumns( selectColumns );
 			setText( selectColumns[0] );
 			setType( SqlTokenTypes.SQL_TOKEN );
 		}
 		else {
 			throw new SemanticException(
 					"Unexpected expression " + expr +
 					" found for collection function " + propertyName
 				);
 		}
 	}
 
 	private void prepareAnyImplicitJoins(DotNode dotNode) throws SemanticException {
 		if ( dotNode.getLhs() instanceof DotNode ) {
 			DotNode lhs = ( DotNode ) dotNode.getLhs();
 			FromElement lhsOrigin = lhs.getFromElement();
 			if ( lhsOrigin != null && "".equals( lhsOrigin.getText() ) ) {
 				String lhsOriginText = lhsOrigin.getQueryable().getTableName() +
 				        " " + lhsOrigin.getTableAlias();
 				lhsOrigin.setText( lhsOriginText );
 			}
 			prepareAnyImplicitJoins( lhs );
 		}
 	}
 
 	private void handleElements(FromReferenceNode collectionNode, String propertyName) {
 		FromElement collectionFromElement = collectionNode.getFromElement();
 		QueryableCollection queryableCollection = collectionFromElement.getQueryableCollection();
 
 		String path = collectionNode.getPath() + "[]." + propertyName;
         LOG.debugf("Creating elements for %s", path);
 
 		fromElement = collectionFromElement;
 		if ( !collectionFromElement.isCollectionOfValuesOrComponents() ) {
 			getWalker().addQuerySpaces( queryableCollection.getElementPersister().getQuerySpaces() );
 		}
 
 		setDataType( queryableCollection.getElementType() );
 		selectColumns = collectionFromElement.toColumns( fromElement.getTableAlias(), propertyName, inSelect );
 	}
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		if ( selectColumns == null ) { 	// Dialect function
 			ColumnHelper.generateSingleScalarColumn( this, i );
 		}
 		else {	// Collection 'property function'
 			ColumnHelper.generateScalarColumns( this, selectColumns, i );
 		}
 	}
 
 	protected void prepareSelectColumns(String[] columns) {
 	}
 
 	@Override
     public FromElement getFromElement() {
 		return fromElement;
 	}
 
 	public String getDisplayText() {
 		return "{" +
 				"method=" + getMethodName() +
 				",selectColumns=" + ( selectColumns == null ?
 						null : Arrays.asList( selectColumns ) ) +
 				",fromElement=" + fromElement.getTableAlias() +
 				"}";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/QueryNode.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/QueryNode.java
index 83b40f188c..514ca04d0d 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/QueryNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/QueryNode.java
@@ -1,166 +1,166 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.hql.ast.util.ColumnHelper;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Defines a top-level AST node representing an HQL select statement.
  *
  * @author Joshua Davis
  */
 public class QueryNode extends AbstractRestrictableStatement implements SelectExpression {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, QueryNode.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QueryNode.class.getName());
 
 	private OrderByClause orderByClause;
 	private int scalarColumnIndex = -1;
 
 	/**
 	 * @see Statement#getStatementType()
 	 */
 	public int getStatementType() {
 		return HqlSqlTokenTypes.QUERY;
 	}
 
 	/**
 	 * @see Statement#needsExecutor()
 	 */
 	public boolean needsExecutor() {
 		return false;
 	}
 
 	@Override
     protected int getWhereClauseParentTokenType() {
 		return SqlTokenTypes.FROM;
 	}
 
 	@Override
-    protected HibernateLogger getLog() {
+    protected CoreMessageLogger getLog() {
         return LOG;
 	}
 
 	/**
 	 * Locate the select clause that is part of this select statement.
 	 * </p>
 	 * Note, that this might return null as derived select clauses (i.e., no
 	 * select clause at the HQL-level) get generated much later than when we
 	 * get created; thus it depends upon lifecycle.
 	 *
 	 * @return Our select clause, or null.
 	 */
 	public final SelectClause getSelectClause() {
 		// Due to the complexity in initializing the SelectClause, do not generate one here.
 		// If it is not found; simply return null...
 		//
 		// Also, do not cache since it gets generated well after we are created.
 		return ( SelectClause ) ASTUtil.findTypeInChildren( this, SqlTokenTypes.SELECT_CLAUSE );
 	}
 
 	public final boolean hasOrderByClause() {
 		OrderByClause orderByClause = locateOrderByClause();
 		return orderByClause != null && orderByClause.getNumberOfChildren() > 0;
 	}
 
 	public final OrderByClause getOrderByClause() {
 		if ( orderByClause == null ) {
 			orderByClause = locateOrderByClause();
 
 			// if there is no order by, make one
 			if ( orderByClause == null ) {
                 LOG.debugf("getOrderByClause() : Creating a new ORDER BY clause");
 				orderByClause = ( OrderByClause ) ASTUtil.create( getWalker().getASTFactory(), SqlTokenTypes.ORDER, "ORDER" );
 
 				// Find the WHERE; if there is no WHERE, find the FROM...
 				AST prevSibling = ASTUtil.findTypeInChildren( this, SqlTokenTypes.WHERE );
 				if ( prevSibling == null ) {
 					prevSibling = ASTUtil.findTypeInChildren( this, SqlTokenTypes.FROM );
 				}
 
 				// Now, inject the newly built ORDER BY into the tree
 				orderByClause.setNextSibling( prevSibling.getNextSibling() );
 				prevSibling.setNextSibling( orderByClause );
 			}
 		}
 		return orderByClause;
 	}
 
 	private OrderByClause locateOrderByClause() {
 		return ( OrderByClause ) ASTUtil.findTypeInChildren( this, SqlTokenTypes.ORDER );
 	}
 
 
 	private String alias;
 
 	public String getAlias() {
 		return alias;
 	}
 
 	public FromElement getFromElement() {
 		return null;
 	}
 
 	public boolean isConstructor() {
 		return false;
 	}
 
 	public boolean isReturnableEntity() throws SemanticException {
 		return false;
 	}
 
 	public boolean isScalar() throws SemanticException {
 		return true;
 	}
 
 	public void setAlias(String alias) {
 		this.alias = alias;
 	}
 
 	public void setScalarColumn(int i) throws SemanticException {
 		scalarColumnIndex = i;
 		setScalarColumnText( i );
 	}
 
 	public int getScalarColumnIndex() {
 		return scalarColumnIndex;
 	}
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		ColumnHelper.generateSingleScalarColumn( this, i );
 	}
 
 	@Override
     public Type getDataType() {
 		return ( (SelectExpression) getSelectClause().getFirstSelectExpression() ).getDataType();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/UpdateStatement.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/UpdateStatement.java
index 870e9e072e..a226034ffd 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/UpdateStatement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/tree/UpdateStatement.java
@@ -1,69 +1,70 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.tree;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.util.ASTUtil;
+
 import org.jboss.logging.Logger;
 import antlr.collections.AST;
 
 /**
  * Defines a top-level AST node representing an HQL update statement.
  *
  * @author Steve Ebersole
  */
 public class UpdateStatement extends AbstractRestrictableStatement {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, UpdateStatement.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, UpdateStatement.class.getName());
 
 	/**
 	 * @see org.hibernate.hql.ast.tree.Statement#getStatementType()
 	 */
 	public int getStatementType() {
 		return SqlTokenTypes.UPDATE;
 	}
 
 	/**
 	 * @see org.hibernate.hql.ast.tree.Statement#needsExecutor()
 	 */
 	public boolean needsExecutor() {
 		return true;
 	}
 
 	@Override
     protected int getWhereClauseParentTokenType() {
 		return SqlTokenTypes.SET;
 	}
 
 	@Override
-    protected HibernateLogger getLog() {
+    protected CoreMessageLogger getLog() {
         return LOG;
 	}
 
 	public AST getSetClause() {
 		return ASTUtil.findTypeInChildren( this, HqlSqlTokenTypes.SET );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/util/JoinProcessor.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/util/JoinProcessor.java
index bb5b039baa..c45a049d36 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/util/JoinProcessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/util/JoinProcessor.java
@@ -1,254 +1,254 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.util;
 
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
 import java.util.ListIterator;
 import java.util.StringTokenizer;
 import org.hibernate.AssertionFailure;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.HqlSqlWalker;
 import org.hibernate.hql.ast.tree.DotNode;
 import org.hibernate.hql.ast.tree.FromClause;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.hql.ast.tree.ParameterContainer;
 import org.hibernate.hql.ast.tree.QueryNode;
 import org.hibernate.hql.classic.ParserHelper;
 import org.hibernate.impl.FilterImpl;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.param.DynamicFilterParameterSpecification;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Performs the post-processing of the join information gathered during semantic analysis.
  * The join generating classes are complex, this encapsulates some of the JoinSequence-related
  * code.
  *
  * @author Joshua Davis
  */
 public class JoinProcessor implements SqlTokenTypes {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JoinProcessor.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JoinProcessor.class.getName());
 
 	private final HqlSqlWalker walker;
 	private final SyntheticAndFactory syntheticAndFactory;
 
 	/**
 	 * Constructs a new JoinProcessor.
 	 *
 	 * @param walker The walker to which we are bound, giving us access to needed resources.
 	 */
 	public JoinProcessor(HqlSqlWalker walker) {
 		this.walker = walker;
 		this.syntheticAndFactory = new SyntheticAndFactory( walker );
 	}
 
 	/**
 	 * Translates an AST join type (i.e., the token type) into a JoinFragment.XXX join type.
 	 *
 	 * @param astJoinType The AST join type (from HqlSqlTokenTypes or SqlTokenTypes)
 	 * @return a JoinFragment.XXX join type.
 	 * @see JoinFragment
 	 * @see SqlTokenTypes
 	 */
 	public static int toHibernateJoinType(int astJoinType) {
 		switch ( astJoinType ) {
 			case LEFT_OUTER:
 				return JoinFragment.LEFT_OUTER_JOIN;
 			case INNER:
 				return JoinFragment.INNER_JOIN;
 			case RIGHT_OUTER:
 				return JoinFragment.RIGHT_OUTER_JOIN;
 			default:
 				throw new AssertionFailure( "undefined join type " + astJoinType );
 		}
 	}
 
 	public void processJoins(QueryNode query) {
 		final FromClause fromClause = query.getFromClause();
 
 		final List fromElements;
 		if ( DotNode.useThetaStyleImplicitJoins ) {
 			// for regression testing against output from the old parser...
 			// found it easiest to simply reorder the FromElements here into ascending order
 			// in terms of injecting them into the resulting sql ast in orders relative to those
 			// expected by the old parser; this is definitely another of those "only needed
 			// for regression purposes".  The SyntheticAndFactory, then, simply injects them as it
 			// encounters them.
 			fromElements = new ArrayList();
 			ListIterator liter = fromClause.getFromElements().listIterator( fromClause.getFromElements().size() );
 			while ( liter.hasPrevious() ) {
 				fromElements.add( liter.previous() );
 			}
 		}
 		else {
 			fromElements = fromClause.getFromElements();
 		}
 
 		// Iterate through the alias,JoinSequence pairs and generate SQL token nodes.
 		Iterator iter = fromElements.iterator();
 		while ( iter.hasNext() ) {
 			final FromElement fromElement = ( FromElement ) iter.next();
 			JoinSequence join = fromElement.getJoinSequence();
             join.setSelector(new JoinSequence.Selector() {
                 public boolean includeSubclasses( String alias ) {
                     // The uber-rule here is that we need to include subclass joins if
                     // the FromElement is in any way dereferenced by a property from
                     // the subclass table; otherwise we end up with column references
                     // qualified by a non-existent table reference in the resulting SQL...
                     boolean containsTableAlias = fromClause.containsTableAlias(alias);
                     if (fromElement.isDereferencedBySubclassProperty()) {
                         // TODO : or should we return 'containsTableAlias'??
                         LOG.trace("Forcing inclusion of extra joins [alias=" + alias + ", containsTableAlias=" + containsTableAlias
                                   + "]");
                         return true;
                     }
                     boolean shallowQuery = walker.isShallowQuery();
                     boolean includeSubclasses = fromElement.isIncludeSubclasses();
                     boolean subQuery = fromClause.isSubQuery();
                     return includeSubclasses && containsTableAlias && !subQuery && !shallowQuery;
 					}
             }
 			);
 			addJoinNodes( query, join, fromElement );
 		}
 
 	}
 
 	private void addJoinNodes(QueryNode query, JoinSequence join, FromElement fromElement) {
 		JoinFragment joinFragment = join.toJoinFragment(
 				walker.getEnabledFilters(),
 				fromElement.useFromFragment() || fromElement.isDereferencedBySuperclassOrSubclassProperty(),
 				fromElement.getWithClauseFragment(),
 				fromElement.getWithClauseJoinAlias()
 		);
 
 		String frag = joinFragment.toFromFragmentString();
 		String whereFrag = joinFragment.toWhereFragmentString();
 
 		// If the from element represents a JOIN_FRAGMENT and it is
 		// a theta-style join, convert its type from JOIN_FRAGMENT
 		// to FROM_FRAGMENT
 		if ( fromElement.getType() == JOIN_FRAGMENT &&
 				( join.isThetaStyle() || StringHelper.isNotEmpty( whereFrag ) ) ) {
 			fromElement.setType( FROM_FRAGMENT );
 			fromElement.getJoinSequence().setUseThetaStyle( true ); // this is used during SqlGenerator processing
 		}
 
 		// If there is a FROM fragment and the FROM element is an explicit, then add the from part.
 		if ( fromElement.useFromFragment() /*&& StringHelper.isNotEmpty( frag )*/ ) {
 			String fromFragment = processFromFragment( frag, join ).trim();
             LOG.debugf("Using FROM fragment [%s]", fromFragment);
 			processDynamicFilterParameters(
 					fromFragment,
 					fromElement,
 					walker
 			);
 		}
 
 		syntheticAndFactory.addWhereFragment(
 				joinFragment,
 				whereFrag,
 				query,
 				fromElement,
 				walker
 		);
 	}
 
 	private String processFromFragment(String frag, JoinSequence join) {
 		String fromFragment = frag.trim();
 		// The FROM fragment will probably begin with ', '.  Remove this if it is present.
 		if ( fromFragment.startsWith( ", " ) ) {
 			fromFragment = fromFragment.substring( 2 );
 		}
 		return fromFragment;
 	}
 
 	public static void processDynamicFilterParameters(
 			final String sqlFragment,
 			final ParameterContainer container,
 			final HqlSqlWalker walker) {
 		if ( walker.getEnabledFilters().isEmpty()
 				&& ( ! hasDynamicFilterParam( sqlFragment ) )
 				&& ( ! ( hasCollectionFilterParam( sqlFragment ) ) ) ) {
 			return;
 		}
 
 		Dialect dialect = walker.getSessionFactoryHelper().getFactory().getDialect();
 		String symbols = new StringBuffer().append( ParserHelper.HQL_SEPARATORS )
 				.append( dialect.openQuote() )
 				.append( dialect.closeQuote() )
 				.toString();
 		StringTokenizer tokens = new StringTokenizer( sqlFragment, symbols, true );
 		StringBuffer result = new StringBuffer();
 
 		while ( tokens.hasMoreTokens() ) {
 			final String token = tokens.nextToken();
 			if ( token.startsWith( ParserHelper.HQL_VARIABLE_PREFIX ) ) {
 				final String filterParameterName = token.substring( 1 );
 				final String[] parts = LoadQueryInfluencers.parseFilterParameterName( filterParameterName );
 				final FilterImpl filter = ( FilterImpl ) walker.getEnabledFilters().get( parts[0] );
 				final Object value = filter.getParameter( parts[1] );
 				final Type type = filter.getFilterDefinition().getParameterType( parts[1] );
 				final String typeBindFragment = StringHelper.join(
 						",",
 						ArrayHelper.fillArray(
 								"?", type.getColumnSpan(
 								walker.getSessionFactoryHelper().getFactory()
 						)
 						)
 				);
 				final String bindFragment = ( value != null && Collection.class.isInstance( value ) )
 						? StringHelper.join( ",", ArrayHelper.fillArray( typeBindFragment, ( ( Collection ) value ).size() ) )
 						: typeBindFragment;
 				result.append( bindFragment );
 				container.addEmbeddedParameter( new DynamicFilterParameterSpecification( parts[0], parts[1], type ) );
 			}
 			else {
 				result.append( token );
 			}
 		}
 
 		container.setText( result.toString() );
 	}
 
 	private static boolean hasDynamicFilterParam(String sqlFragment) {
 		return sqlFragment.indexOf( ParserHelper.HQL_VARIABLE_PREFIX ) < 0;
 	}
 
 	private static boolean hasCollectionFilterParam(String sqlFragment) {
 		return sqlFragment.indexOf( "?" ) < 0;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/util/LiteralProcessor.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/util/LiteralProcessor.java
index 93f2d6b323..bd0dc76f1c 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/util/LiteralProcessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/util/LiteralProcessor.java
@@ -1,319 +1,319 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.util;
 
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.text.DecimalFormat;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.hql.QueryTranslator;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.HqlSqlWalker;
 import org.hibernate.hql.ast.InvalidPathException;
 import org.hibernate.hql.ast.tree.DotNode;
 import org.hibernate.hql.ast.tree.FromClause;
 import org.hibernate.hql.ast.tree.IdentNode;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.InFragment;
 import org.hibernate.type.LiteralType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * A delegate that handles literals and constants for HqlSqlWalker, performing the token replacement functions and
  * classifying literals.
  *
  * @author josh
  */
 public class LiteralProcessor implements HqlSqlTokenTypes {
 	/**
 	 * Indicates that Float and Double literal values should
 	 * be treated using the SQL "exact" format (i.e., '.001')
 	 */
 	public static final int EXACT = 0;
 	/**
 	 * Indicates that Float and Double literal values should
 	 * be treated using the SQL "approximate" format (i.e., '1E-3')
 	 */
 	public static final int APPROXIMATE = 1;
 	/**
 	 * In what format should Float and Double literal values be sent
 	 * to the database?
 	 * @see #EXACT, #APPROXIMATE
 	 */
 	public static int DECIMAL_LITERAL_FORMAT = EXACT;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, LiteralProcessor.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, LiteralProcessor.class.getName());
 
 	private HqlSqlWalker walker;
 
 	public LiteralProcessor(HqlSqlWalker hqlSqlWalker) {
 		this.walker = hqlSqlWalker;
 	}
 
 	public boolean isAlias(String alias) {
 		FromClause from = walker.getCurrentFromClause();
 		while ( from.isSubQuery() ) {
 			if ( from.containsClassAlias(alias) ) {
 				return true;
 			}
 			from = from.getParentFromClause();
 		}
 		return from.containsClassAlias(alias);
 	}
 
 	public void processConstant(AST constant, boolean resolveIdent) throws SemanticException {
 		// If the constant is an IDENT, figure out what it means...
 		boolean isIdent = ( constant.getType() == IDENT || constant.getType() == WEIRD_IDENT );
 		if ( resolveIdent && isIdent && isAlias( constant.getText() ) ) { // IDENT is a class alias in the FROM.
 			IdentNode ident = ( IdentNode ) constant;
 			// Resolve to an identity column.
 			ident.resolve(false, true);
 		}
 		else {	// IDENT might be the name of a class.
 			Queryable queryable = walker.getSessionFactoryHelper().findQueryableUsingImports( constant.getText() );
 			if ( isIdent && queryable != null ) {
 				constant.setText( queryable.getDiscriminatorSQLValue() );
 			}
 			// Otherwise, it's a literal.
 			else {
 				processLiteral( constant );
 			}
 		}
 	}
 
 	public void lookupConstant(DotNode node) throws SemanticException {
 		String text = ASTUtil.getPathText( node );
 		Queryable persister = walker.getSessionFactoryHelper().findQueryableUsingImports( text );
 		if ( persister != null ) {
 			// the name of an entity class
 			final String discrim = persister.getDiscriminatorSQLValue();
 			node.setDataType( persister.getDiscriminatorType() );
             if (InFragment.NULL.equals(discrim) || InFragment.NOT_NULL.equals(discrim)) throw new InvalidPathException(
                                                                                                                        "subclass test not allowed for null or not null discriminator: '"
                                                                                                                        + text + "'");
             setSQLValue(node, text, discrim); // the class discriminator value
 		}
 		else {
 			Object value = ReflectHelper.getConstantValue( text );
             if (value == null) throw new InvalidPathException("Invalid path: '" + text + "'");
             setConstantValue(node, text, value);
 		}
 	}
 
 	private void setSQLValue(DotNode node, String text, String value) {
         LOG.debugf("setSQLValue() %s -> %s", text, value);
 		node.setFirstChild( null );	// Chop off the rest of the tree.
 		node.setType( SqlTokenTypes.SQL_TOKEN );
 		node.setText(value);
 		node.setResolvedConstant( text );
 	}
 
 	private void setConstantValue(DotNode node, String text, Object value) {
         LOG.debugf("setConstantValue() %s -> %s %s", text, value, value.getClass().getName());
 		node.setFirstChild( null );	// Chop off the rest of the tree.
 		if ( value instanceof String ) {
 			node.setType( SqlTokenTypes.QUOTED_STRING );
 		}
 		else if ( value instanceof Character ) {
 			node.setType( SqlTokenTypes.QUOTED_STRING );
 		}
 		else if ( value instanceof Byte ) {
 			node.setType( SqlTokenTypes.NUM_INT );
 		}
 		else if ( value instanceof Short ) {
 			node.setType( SqlTokenTypes.NUM_INT );
 		}
 		else if ( value instanceof Integer ) {
 			node.setType( SqlTokenTypes.NUM_INT );
 		}
 		else if ( value instanceof Long ) {
 			node.setType( SqlTokenTypes.NUM_LONG );
 		}
 		else if ( value instanceof Double ) {
 			node.setType( SqlTokenTypes.NUM_DOUBLE );
 		}
 		else if ( value instanceof Float ) {
 			node.setType( SqlTokenTypes.NUM_FLOAT );
 		}
 		else {
 			node.setType( SqlTokenTypes.CONSTANT );
 		}
 		Type type;
 		try {
 			type = walker.getSessionFactoryHelper().getFactory().getTypeResolver().heuristicType( value.getClass().getName() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 		if ( type == null ) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_DETERMINE_TYPE + node.getText() );
 		}
 		try {
 			LiteralType literalType = ( LiteralType ) type;
 			Dialect dialect = walker.getSessionFactoryHelper().getFactory().getDialect();
 			node.setText( literalType.objectToSQLString( value, dialect ) );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_FORMAT_LITERAL + node.getText(), e );
 		}
 		node.setDataType( type );
 		node.setResolvedConstant( text );
 	}
 
 	public void processBoolean(AST constant) {
 		// TODO: something much better - look at the type of the other expression!
 		// TODO: Have comparisonExpression and/or arithmeticExpression rules complete the resolution of boolean nodes.
 		String replacement = ( String ) walker.getTokenReplacements().get( constant.getText() );
 		if ( replacement != null ) {
 			constant.setText( replacement );
 		}
 		else {
 			boolean bool = "true".equals( constant.getText().toLowerCase() );
 			Dialect dialect = walker.getSessionFactoryHelper().getFactory().getDialect();
 			constant.setText( dialect.toBooleanValueString(bool) );
 		}
 	}
 
 	private void processLiteral(AST constant) {
 		String replacement = ( String ) walker.getTokenReplacements().get( constant.getText() );
 		if ( replacement != null ) {
             LOG.debugf("processConstant() : Replacing '%s' with '%s'", constant.getText(), replacement);
 			constant.setText( replacement );
 		}
 	}
 
 	public void processNumeric(AST literal) {
 		if ( literal.getType() == NUM_INT
 				|| literal.getType() == NUM_LONG
 				|| literal.getType() == NUM_BIG_INTEGER ) {
 			literal.setText( determineIntegerRepresentation( literal.getText(), literal.getType() ) );
         } else if (literal.getType() == NUM_FLOAT
 				|| literal.getType() == NUM_DOUBLE
 				|| literal.getType() == NUM_BIG_DECIMAL ) {
 			literal.setText( determineDecimalRepresentation( literal.getText(), literal.getType() ) );
         } else LOG.unexpectedLiteralTokenType(literal.getType());
 	}
 
 	private String determineIntegerRepresentation(String text, int type) {
 		try {
 			if ( type == NUM_BIG_INTEGER ) {
 				String literalValue = text;
 				if ( literalValue.endsWith( "bi" ) || literalValue.endsWith( "BI" ) ) {
 					literalValue = literalValue.substring( 0, literalValue.length() - 2 );
 				}
 				return new BigInteger( literalValue ).toString();
 			}
 			if ( type == NUM_INT ) {
 				try {
 					return Integer.valueOf( text ).toString();
 				}
 				catch( NumberFormatException e ) {
                     LOG.trace("Could not format incoming text [" + text
                               + "] as a NUM_INT; assuming numeric overflow and attempting as NUM_LONG");
 				}
 			}
 			String literalValue = text;
 			if ( literalValue.endsWith( "l" ) || literalValue.endsWith( "L" ) ) {
 				literalValue = literalValue.substring( 0, literalValue.length() - 1 );
 			}
 			return Long.valueOf( literalValue ).toString();
 		}
 		catch( Throwable t ) {
 			throw new HibernateException( "Could not parse literal [" + text + "] as integer", t );
 		}
 	}
 
 	public String determineDecimalRepresentation(String text, int type) {
 		String literalValue = text;
 		if ( type == NUM_FLOAT ) {
 			if ( literalValue.endsWith( "f" ) || literalValue.endsWith( "F" ) ) {
 				literalValue = literalValue.substring( 0, literalValue.length() - 1 );
 			}
 		}
 		else if ( type == NUM_DOUBLE ) {
 			if ( literalValue.endsWith( "d" ) || literalValue.endsWith( "D" ) ) {
 				literalValue = literalValue.substring( 0, literalValue.length() - 1 );
 			}
 		}
 		else if ( type == NUM_BIG_DECIMAL ) {
 			if ( literalValue.endsWith( "bd" ) || literalValue.endsWith( "BD" ) ) {
 				literalValue = literalValue.substring( 0, literalValue.length() - 2 );
 			}
 		}
 
 		BigDecimal number = null;
 		try {
 			number = new BigDecimal( literalValue );
 		}
 		catch( Throwable t ) {
 			throw new HibernateException( "Could not parse literal [" + text + "] as big-decimal", t );
 		}
 
 		return formatters[ DECIMAL_LITERAL_FORMAT ].format( number );
 	}
 
 
 	private static interface DecimalFormatter {
 		String format(BigDecimal number);
 	}
 
 	private static class ExactDecimalFormatter implements DecimalFormatter {
 		public String format(BigDecimal number) {
 			return number.toString();
 		}
 	}
 
 	private static class ApproximateDecimalFormatter implements DecimalFormatter {
 		private static final String FORMAT_STRING = "#0.0E0";
 		public String format(BigDecimal number) {
 			try {
 				// TODO : what amount of significant digits need to be supported here?
 				//      - from the DecimalFormat docs:
 				//          [significant digits] = [minimum integer digits] + [maximum fraction digits]
 				DecimalFormat jdkFormatter = new DecimalFormat( FORMAT_STRING );
 				jdkFormatter.setMinimumIntegerDigits( 1 );
 				jdkFormatter.setMaximumFractionDigits( Integer.MAX_VALUE );
 				return jdkFormatter.format( number );
 			}
 			catch( Throwable t ) {
 				throw new HibernateException( "Unable to format decimal literal in approximate format [" + number.toString() + "]", t );
 			}
 		}
 	}
 
 	private static final DecimalFormatter[] formatters = new DecimalFormatter[] {
 			new ExactDecimalFormatter(),
 			new ApproximateDecimalFormatter()
 	};
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/util/PathHelper.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/util/PathHelper.java
index e2f99e0f80..7bd9276be6 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/util/PathHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/util/PathHelper.java
@@ -1,73 +1,73 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.util;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.internal.util.StringHelper;
 import org.jboss.logging.Logger;
 import antlr.ASTFactory;
 import antlr.collections.AST;
 
 /**
  * Provides utility methods for paths.
  *
  * @author josh
  */
 public final class PathHelper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, PathHelper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, PathHelper.class.getName());
 
 	private PathHelper() {
 	}
 
 	/**
 	 * Turns a path into an AST.
 	 *
 	 * @param path    The path.
 	 * @param factory The AST factory to use.
 	 * @return An HQL AST representing the path.
 	 */
 	public static AST parsePath(String path, ASTFactory factory) {
 		String[] identifiers = StringHelper.split( ".", path );
 		AST lhs = null;
 		for ( int i = 0; i < identifiers.length; i++ ) {
 			String identifier = identifiers[i];
 			AST child = ASTUtil.create( factory, HqlSqlTokenTypes.IDENT, identifier );
 			if ( i == 0 ) {
 				lhs = child;
 			}
 			else {
 				lhs = ASTUtil.createBinarySubtree( factory, HqlSqlTokenTypes.DOT, ".", lhs, child );
 			}
 		}
         if (LOG.isDebugEnabled()) LOG.debugf("parsePath() : %s -> %s", path, ASTUtil.getDebugString(lhs));
 		return lhs;
 	}
 
 	public static String getAlias(String path) {
 		return StringHelper.root( path );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/util/SyntheticAndFactory.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/util/SyntheticAndFactory.java
index 56f96576d4..4a82ef96b8 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/util/SyntheticAndFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/util/SyntheticAndFactory.java
@@ -1,203 +1,204 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast.util;
 
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.ast.HqlSqlWalker;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.hql.ast.tree.Node;
 import org.hibernate.hql.ast.tree.QueryNode;
 import org.hibernate.hql.ast.tree.RestrictableStatement;
 import org.hibernate.hql.ast.tree.SqlFragment;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.CollectionFilterKeyParameterSpecification;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 import antlr.collections.AST;
 
 /**
  * Creates synthetic and nodes based on the where fragment part of a JoinSequence.
  *
  * @author josh
  */
 public class SyntheticAndFactory implements HqlSqlTokenTypes {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SyntheticAndFactory.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SyntheticAndFactory.class.getName());
 
 	private HqlSqlWalker hqlSqlWalker;
 	private AST thetaJoins;
 	private AST filters;
 
 	public SyntheticAndFactory(HqlSqlWalker hqlSqlWalker) {
 		this.hqlSqlWalker = hqlSqlWalker;
 	}
 
 	private Node create(int tokenType, String text) {
 		return ( Node ) ASTUtil.create( hqlSqlWalker.getASTFactory(), tokenType, text );
 	}
 
 	public void addWhereFragment(
 			JoinFragment joinFragment,
 			String whereFragment,
 			QueryNode query,
 			FromElement fromElement,
 			HqlSqlWalker hqlSqlWalker) {
 		if ( whereFragment == null ) {
 			return;
 		}
 
 		if ( !fromElement.useWhereFragment() && !joinFragment.hasThetaJoins() ) {
 			return;
 		}
 
 		whereFragment = whereFragment.trim();
 		if ( StringHelper.isEmpty( whereFragment ) ) {
 			return;
 		}
 
 		// Forcefully remove leading ands from where fragments; the grammar will
 		// handle adding them
 		if ( whereFragment.startsWith( "and" ) ) {
 			whereFragment = whereFragment.substring( 4 );
 		}
 
         LOG.debugf("Using unprocessed WHERE-fragment [%s]", whereFragment);
 
 		SqlFragment fragment = ( SqlFragment ) create( SQL_TOKEN, whereFragment );
 		fragment.setJoinFragment( joinFragment );
 		fragment.setFromElement( fromElement );
 
 		if ( fromElement.getIndexCollectionSelectorParamSpec() != null ) {
 			fragment.addEmbeddedParameter( fromElement.getIndexCollectionSelectorParamSpec() );
 			fromElement.setIndexCollectionSelectorParamSpec( null );
 		}
 
 		if ( hqlSqlWalker.isFilter() ) {
 			if ( whereFragment.indexOf( '?' ) >= 0 ) {
 				Type collectionFilterKeyType = hqlSqlWalker.getSessionFactoryHelper()
 						.requireQueryableCollection( hqlSqlWalker.getCollectionFilterRole() )
 						.getKeyType();
 				CollectionFilterKeyParameterSpecification paramSpec = new CollectionFilterKeyParameterSpecification(
 						hqlSqlWalker.getCollectionFilterRole(),
 						collectionFilterKeyType,
 						0
 				);
 				fragment.addEmbeddedParameter( paramSpec );
 			}
 		}
 
 		JoinProcessor.processDynamicFilterParameters(
 				whereFragment,
 				fragment,
 				hqlSqlWalker
 		);
 
         LOG.debugf("Using processed WHERE-fragment [%s]", fragment.getText());
 
 		// Filter conditions need to be inserted before the HQL where condition and the
 		// theta join node.  This is because org.hibernate.loader.Loader binds the filter parameters first,
 		// then it binds all the HQL query parameters, see org.hibernate.loader.Loader.processFilterParameters().
 		if ( fragment.getFromElement().isFilter() || fragment.hasFilterCondition() ) {
 			if ( filters == null ) {
 				// Find or create the WHERE clause
 				AST where = query.getWhereClause();
 				// Create a new FILTERS node as a parent of all filters
 				filters = create( FILTERS, "{filter conditions}" );
 				// Put the FILTERS node before the HQL condition and theta joins
 				ASTUtil.insertChild( where, filters );
 			}
 
 			// add the current fragment to the FILTERS node
 			filters.addChild( fragment );
 		}
 		else {
 			if ( thetaJoins == null ) {
 				// Find or create the WHERE clause
 				AST where = query.getWhereClause();
 				// Create a new THETA_JOINS node as a parent of all filters
 				thetaJoins = create( THETA_JOINS, "{theta joins}" );
 				// Put the THETA_JOINS node before the HQL condition, after the filters.
 				if (filters==null) {
 					ASTUtil.insertChild( where, thetaJoins );
 				}
 				else {
 					ASTUtil.insertSibling( thetaJoins, filters );
 				}
 			}
 
 			// add the current fragment to the THETA_JOINS node
 			thetaJoins.addChild(fragment);
 		}
 
 	}
 
 	public void addDiscriminatorWhereFragment(
 			RestrictableStatement statement,
 			Queryable persister,
 			Map enabledFilters,
 			String alias) {
 		String whereFragment = persister.filterFragment( alias, enabledFilters ).trim();
 		if ( "".equals( whereFragment ) ) {
 			return;
 		}
 		if ( whereFragment.startsWith( "and" ) ) {
 			whereFragment = whereFragment.substring( 4 );
 		}
 
 		// Need to parse off the column qualifiers; this is assuming (which is true as of now)
 		// that this is only used from update and delete HQL statement parsing
 		whereFragment = StringHelper.replace( whereFragment, persister.generateFilterConditionAlias( alias ) + ".", "" );
 
 		// Note: this simply constructs a "raw" SQL_TOKEN representing the
 		// where fragment and injects this into the tree.  This "works";
 		// however it is probably not the best long-term solution.
 		//
 		// At some point we probably want to apply an additional grammar to
 		// properly tokenize this where fragment into constituent parts
 		// focused on the operators embedded within the fragment.
 		SqlFragment discrimNode = ( SqlFragment ) create( SQL_TOKEN, whereFragment );
 
 		JoinProcessor.processDynamicFilterParameters(
 				whereFragment,
 				discrimNode,
 				hqlSqlWalker
 		);
 
 		if ( statement.getWhereClause().getNumberOfChildren() == 0 ) {
 			statement.getWhereClause().setFirstChild( discrimNode );
 		}
 		else {
 			AST and = create( AND, "{and}" );
 			AST currentFirstChild = statement.getWhereClause().getFirstChild();
 			and.setFirstChild( discrimNode );
 			and.addChild( currentFirstChild );
 			statement.getWhereClause().setFirstChild( and );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/classic/QueryTranslatorImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/classic/QueryTranslatorImpl.java
index acb54eca99..ed68612245 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/classic/QueryTranslatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/classic/QueryTranslatorImpl.java
@@ -1,1082 +1,1082 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.classic;
 
 import java.io.Serializable;
 import java.lang.reflect.Constructor;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.hql.FilterTranslator;
 import org.hibernate.hql.HolderInstantiator;
 import org.hibernate.hql.NameGenerator;
 import org.hibernate.hql.ParameterTranslations;
 import org.hibernate.impl.IteratorImpl;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.QuerySelect;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * An instance of <tt>QueryTranslator</tt> translates a Hibernate
  * query string to SQL.
  */
 public class QueryTranslatorImpl extends BasicLoader implements FilterTranslator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, QueryTranslatorImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QueryTranslatorImpl.class.getName());
 
 	private static final String[] NO_RETURN_ALIASES = new String[] {};
 
 	private final String queryIdentifier;
 	private final String queryString;
 
 	private final Map typeMap = new LinkedHashMap();
 	private final Map collections = new LinkedHashMap();
 	private List returnedTypes = new ArrayList();
 	private final List fromTypes = new ArrayList();
 	private final List scalarTypes = new ArrayList();
 	private final Map namedParameters = new HashMap();
 	private final Map aliasNames = new HashMap();
 	private final Map oneToOneOwnerNames = new HashMap();
 	private final Map uniqueKeyOwnerReferences = new HashMap();
 	private final Map decoratedPropertyMappings = new HashMap();
 
 	private final List scalarSelectTokens = new ArrayList();
 	private final List whereTokens = new ArrayList();
 	private final List havingTokens = new ArrayList();
 	private final Map joins = new LinkedHashMap();
 	private final List orderByTokens = new ArrayList();
 	private final List groupByTokens = new ArrayList();
 	private final Set querySpaces = new HashSet();
 	private final Set entitiesToFetch = new HashSet();
 
 	private final Map pathAliases = new HashMap();
 	private final Map pathJoins = new HashMap();
 
 	private Queryable[] persisters;
 	private int[] owners;
 	private EntityType[] ownerAssociationTypes;
 	private String[] names;
 	private boolean[] includeInSelect;
 	private int selectLength;
 	private Type[] returnTypes;
 	private Type[] actualReturnTypes;
 	private String[][] scalarColumnNames;
 	private Map tokenReplacements;
 	private int nameCount = 0;
 	private int parameterCount = 0;
 	private boolean distinct = false;
 	private boolean compiled;
 	private String sqlString;
 	private Class holderClass;
 	private Constructor holderConstructor;
 	private boolean hasScalars;
 	private boolean shallowQuery;
 	private QueryTranslatorImpl superQuery;
 
 	private QueryableCollection collectionPersister;
 	private int collectionOwnerColumn = -1;
 	private String collectionOwnerName;
 	private String fetchName;
 
 	private String[] suffixes;
 
 	private Map enabledFilters;
 
 	/**
 	 * Construct a query translator
 	 *
 	 * @param queryIdentifier A unique identifier for the query of which this
 	 * translation is part; typically this is the original, user-supplied query string.
 	 * @param queryString The "preprocessed" query string; at the very least
 	 * already processed by {@link org.hibernate.hql.QuerySplitter}.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 			String queryIdentifier,
 	        String queryString,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		super( factory );
 		this.queryIdentifier = queryIdentifier;
 		this.queryString = queryString;
 		this.enabledFilters = enabledFilters;
 	}
 
 	/**
 	 * Construct a query translator; this form used internally.
 	 *
 	 * @param queryString The query string to process.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 	        String queryString,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		this( queryString, queryString, enabledFilters, factory );
 	}
 
 	/**
 	 * Compile a subquery.
 	 *
 	 * @param superquery The containing query of the query to be compiled.
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	void compile(QueryTranslatorImpl superquery) throws QueryException, MappingException {
 		this.tokenReplacements = superquery.tokenReplacements;
 		this.superQuery = superquery;
 		this.shallowQuery = true;
 		this.enabledFilters = superquery.getEnabledFilters();
 		compile();
 	}
 
 
 	/**
 	 * Compile a "normal" query. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 		if ( !compiled ) {
 			this.tokenReplacements = replacements;
 			this.shallowQuery = scalar;
 			compile();
 		}
 	}
 
 	/**
 	 * Compile a filter. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			String collectionRole,
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 
 		if ( !isCompiled() ) {
 			addFromAssociation( "this", collectionRole );
 			compile( replacements, scalar );
 		}
 	}
 
 	/**
 	 * Compile the query (generate the SQL).
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	private void compile() throws QueryException, MappingException {
 
         LOG.trace("Compiling query");
 		try {
 			ParserHelper.parse( new PreprocessingParser( tokenReplacements ),
 					queryString,
 					ParserHelper.HQL_SEPARATORS,
 					this );
 			renderSQL();
 		}
 		catch ( QueryException qe ) {
 			qe.setQueryString( queryString );
 			throw qe;
 		}
 		catch ( MappingException me ) {
 			throw me;
 		}
 		catch ( Exception e ) {
             LOG.debug("Unexpected query compilation problem", e);
 			e.printStackTrace();
 			QueryException qe = new QueryException( "Incorrect query syntax", e );
 			qe.setQueryString( queryString );
 			throw qe;
 		}
 
 		postInstantiate();
 
 		compiled = true;
 
 	}
 
 	@Override
     public String getSQLString() {
 		return sqlString;
 	}
 
 	public List collectSqlStrings() {
 		return ArrayHelper.toList( new String[] { sqlString } );
 	}
 
 	public String getQueryString() {
 		return queryString;
 	}
 
 	/**
 	 * Persisters for the return values of a <tt>find()</tt> style query.
 	 *
 	 * @return an array of <tt>EntityPersister</tt>s.
 	 */
 	@Override
     protected Loadable[] getEntityPersisters() {
 		return persisters;
 	}
 
 	/**
 	 * Types of the return values of an <tt>iterate()</tt> style query.
 	 *
 	 * @return an array of <tt>Type</tt>s.
 	 */
 	public Type[] getReturnTypes() {
 		return actualReturnTypes;
 	}
 
 	public String[] getReturnAliases() {
 		// return aliases not supported in classic translator!
 		return NO_RETURN_ALIASES;
 	}
 
 	public String[][] getColumnNames() {
 		return scalarColumnNames;
 	}
 
 	private static void logQuery(String hql, String sql) {
         if (LOG.isDebugEnabled()) {
             LOG.debugf("HQL: %s", hql);
             LOG.debugf("SQL: %s", sql);
 		}
 	}
 
 	void setAliasName(String alias, String name) {
 		aliasNames.put( alias, name );
 	}
 
 	public String getAliasName(String alias) {
 		String name = ( String ) aliasNames.get( alias );
 		if ( name == null ) {
 			if ( superQuery != null ) {
 				name = superQuery.getAliasName( alias );
 			}
 			else {
 				name = alias;
 			}
 		}
 		return name;
 	}
 
 	String unalias(String path) {
 		String alias = StringHelper.root( path );
 		String name = getAliasName( alias );
         if (name != null) return name + path.substring(alias.length());
         return path;
 	}
 
 	void addEntityToFetch(String name, String oneToOneOwnerName, AssociationType ownerAssociationType) {
 		addEntityToFetch( name );
 		if ( oneToOneOwnerName != null ) oneToOneOwnerNames.put( name, oneToOneOwnerName );
 		if ( ownerAssociationType != null ) uniqueKeyOwnerReferences.put( name, ownerAssociationType );
 	}
 
 	private void addEntityToFetch(String name) {
 		entitiesToFetch.add( name );
 	}
 
 	private int nextCount() {
 		return ( superQuery == null ) ? nameCount++ : superQuery.nameCount++;
 	}
 
 	String createNameFor(String type) {
 		return StringHelper.generateAlias( type, nextCount() );
 	}
 
 	String createNameForCollection(String role) {
 		return StringHelper.generateAlias( role, nextCount() );
 	}
 
 	private String getType(String name) {
 		String type = ( String ) typeMap.get( name );
 		if ( type == null && superQuery != null ) {
 			type = superQuery.getType( name );
 		}
 		return type;
 	}
 
 	private String getRole(String name) {
 		String role = ( String ) collections.get( name );
 		if ( role == null && superQuery != null ) {
 			role = superQuery.getRole( name );
 		}
 		return role;
 	}
 
 	boolean isName(String name) {
 		return aliasNames.containsKey( name ) ||
 				typeMap.containsKey( name ) ||
 				collections.containsKey( name ) || (
 				superQuery != null && superQuery.isName( name )
 				);
 	}
 
 	PropertyMapping getPropertyMapping(String name) throws QueryException {
 		PropertyMapping decorator = getDecoratedPropertyMapping( name );
 		if ( decorator != null ) return decorator;
 
 		String type = getType( name );
 		if ( type == null ) {
 			String role = getRole( name );
 			if ( role == null ) {
 				throw new QueryException( "alias not found: " + name );
 			}
 			return getCollectionPersister( role ); //.getElementPropertyMapping();
 		}
 		else {
 			Queryable persister = getEntityPersister( type );
 			if ( persister == null ) throw new QueryException( "persistent class not found: " + type );
 			return persister;
 		}
 	}
 
 	private PropertyMapping getDecoratedPropertyMapping(String name) {
 		return ( PropertyMapping ) decoratedPropertyMappings.get( name );
 	}
 
 	void decoratePropertyMapping(String name, PropertyMapping mapping) {
 		decoratedPropertyMappings.put( name, mapping );
 	}
 
 	private Queryable getEntityPersisterForName(String name) throws QueryException {
 		String type = getType( name );
 		Queryable persister = getEntityPersister( type );
 		if ( persister == null ) throw new QueryException( "persistent class not found: " + type );
 		return persister;
 	}
 
 	Queryable getEntityPersisterUsingImports(String className) {
 		final String importedClassName = getFactory().getImportedClassName( className );
 		if ( importedClassName == null ) {
 			return null;
 		}
 		try {
 			return ( Queryable ) getFactory().getEntityPersister( importedClassName );
 		}
 		catch ( MappingException me ) {
 			return null;
 		}
 	}
 
 	Queryable getEntityPersister(String entityName) throws QueryException {
 		try {
 			return ( Queryable ) getFactory().getEntityPersister( entityName );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( "persistent class not found: " + entityName );
 		}
 	}
 
 	QueryableCollection getCollectionPersister(String role) throws QueryException {
 		try {
 			return ( QueryableCollection ) getFactory().getCollectionPersister( role );
 		}
 		catch ( ClassCastException cce ) {
 			throw new QueryException( "collection role is not queryable: " + role );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( "collection role not found: " + role );
 		}
 	}
 
 	void addType(String name, String type) {
 		typeMap.put( name, type );
 	}
 
 	void addCollection(String name, String role) {
 		collections.put( name, role );
 	}
 
 	void addFrom(String name, String type, JoinSequence joinSequence)
 			throws QueryException {
 		addType( name, type );
 		addFrom( name, joinSequence );
 	}
 
 	void addFromCollection(String name, String collectionRole, JoinSequence joinSequence)
 			throws QueryException {
 		//register collection role
 		addCollection( name, collectionRole );
 		addJoin( name, joinSequence );
 	}
 
 	void addFrom(String name, JoinSequence joinSequence)
 			throws QueryException {
 		fromTypes.add( name );
 		addJoin( name, joinSequence );
 	}
 
 	void addFromClass(String name, Queryable classPersister)
 			throws QueryException {
 		JoinSequence joinSequence = new JoinSequence( getFactory() )
 				.setRoot( classPersister, name );
 		//crossJoins.add(name);
 		addFrom( name, classPersister.getEntityName(), joinSequence );
 	}
 
 	void addSelectClass(String name) {
 		returnedTypes.add( name );
 	}
 
 	void addSelectScalar(Type type) {
 		scalarTypes.add( type );
 	}
 
 	void appendWhereToken(String token) {
 		whereTokens.add( token );
 	}
 
 	void appendHavingToken(String token) {
 		havingTokens.add( token );
 	}
 
 	void appendOrderByToken(String token) {
 		orderByTokens.add( token );
 	}
 
 	void appendGroupByToken(String token) {
 		groupByTokens.add( token );
 	}
 
 	void appendScalarSelectToken(String token) {
 		scalarSelectTokens.add( token );
 	}
 
 	void appendScalarSelectTokens(String[] tokens) {
 		scalarSelectTokens.add( tokens );
 	}
 
 	void addFromJoinOnly(String name, JoinSequence joinSequence) throws QueryException {
 		addJoin( name, joinSequence.getFromPart() );
 	}
 
 	void addJoin(String name, JoinSequence joinSequence) throws QueryException {
 		if ( !joins.containsKey( name ) ) joins.put( name, joinSequence );
 	}
 
 	void addNamedParameter(String name) {
 		if ( superQuery != null ) superQuery.addNamedParameter( name );
 		Integer loc = new Integer( parameterCount++ );
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
 			( ( ArrayList ) o ).add( loc );
 		}
 	}
 
 	@Override
     public int[] getNamedParameterLocs(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			QueryException qe = new QueryException( ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name );
 			qe.setQueryString( queryString );
 			throw qe;
 		}
 		if ( o instanceof Integer ) {
 			return new int[]{ ( ( Integer ) o ).intValue() };
 		}
 		else {
 			return ArrayHelper.toIntArray( ( ArrayList ) o );
 		}
 	}
 
 	private void renderSQL() throws QueryException, MappingException {
 
 		final int rtsize;
 		if ( returnedTypes.size() == 0 && scalarTypes.size() == 0 ) {
 			//ie no select clause in HQL
 			returnedTypes = fromTypes;
 			rtsize = returnedTypes.size();
 		}
 		else {
 			rtsize = returnedTypes.size();
 			Iterator iter = entitiesToFetch.iterator();
 			while ( iter.hasNext() ) {
 				returnedTypes.add( iter.next() );
 			}
 		}
 		int size = returnedTypes.size();
 		persisters = new Queryable[size];
 		names = new String[size];
 		owners = new int[size];
 		ownerAssociationTypes = new EntityType[size];
 		suffixes = new String[size];
 		includeInSelect = new boolean[size];
 		for ( int i = 0; i < size; i++ ) {
 			String name = ( String ) returnedTypes.get( i );
 			//if ( !isName(name) ) throw new QueryException("unknown type: " + name);
 			persisters[i] = getEntityPersisterForName( name );
 			// TODO: cannot use generateSuffixes() - it handles the initial suffix differently.
 			suffixes[i] = ( size == 1 ) ? "" : Integer.toString( i ) + '_';
 			names[i] = name;
 			includeInSelect[i] = !entitiesToFetch.contains( name );
 			if ( includeInSelect[i] ) selectLength++;
 			if ( name.equals( collectionOwnerName ) ) collectionOwnerColumn = i;
 			String oneToOneOwner = ( String ) oneToOneOwnerNames.get( name );
 			owners[i] = ( oneToOneOwner == null ) ? -1 : returnedTypes.indexOf( oneToOneOwner );
 			ownerAssociationTypes[i] = (EntityType) uniqueKeyOwnerReferences.get( name );
 		}
 
 		if ( ArrayHelper.isAllNegative( owners ) ) owners = null;
 
 		String scalarSelect = renderScalarSelect(); //Must be done here because of side-effect! yuck...
 
 		int scalarSize = scalarTypes.size();
 		hasScalars = scalarTypes.size() != rtsize;
 
 		returnTypes = new Type[scalarSize];
 		for ( int i = 0; i < scalarSize; i++ ) {
 			returnTypes[i] = ( Type ) scalarTypes.get( i );
 		}
 
 		QuerySelect sql = new QuerySelect( getFactory().getDialect() );
 		sql.setDistinct( distinct );
 
 		if ( !shallowQuery ) {
 			renderIdentifierSelect( sql );
 			renderPropertiesSelect( sql );
 		}
 
 		if ( collectionPersister != null ) {
 			sql.addSelectFragmentString( collectionPersister.selectFragment( fetchName, "__" ) );
 		}
 
 		if ( hasScalars || shallowQuery ) sql.addSelectFragmentString( scalarSelect );
 
 		//TODO: for some dialects it would be appropriate to add the renderOrderByPropertiesSelect() to other select strings
 		mergeJoins( sql.getJoinFragment() );
 
 		sql.setWhereTokens( whereTokens.iterator() );
 
 		sql.setGroupByTokens( groupByTokens.iterator() );
 		sql.setHavingTokens( havingTokens.iterator() );
 		sql.setOrderByTokens( orderByTokens.iterator() );
 
 		if ( collectionPersister != null && collectionPersister.hasOrdering() ) {
 			sql.addOrderBy( collectionPersister.getSQLOrderByString( fetchName ) );
 		}
 
 		scalarColumnNames = NameGenerator.generateColumnNames( returnTypes, getFactory() );
 
 		// initialize the Set of queried identifier spaces (ie. tables)
 		Iterator iter = collections.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = getCollectionPersister( ( String ) iter.next() );
 			addQuerySpaces( p.getCollectionSpaces() );
 		}
 		iter = typeMap.keySet().iterator();
 		while ( iter.hasNext() ) {
 			Queryable p = getEntityPersisterForName( ( String ) iter.next() );
 			addQuerySpaces( p.getQuerySpaces() );
 		}
 
 		sqlString = sql.toQueryString();
 
 		if ( holderClass != null ) holderConstructor = ReflectHelper.getConstructor( holderClass, returnTypes );
 
 		if ( hasScalars ) {
 			actualReturnTypes = returnTypes;
 		}
 		else {
 			actualReturnTypes = new Type[selectLength];
 			int j = 0;
 			for ( int i = 0; i < persisters.length; i++ ) {
 				if ( includeInSelect[i] ) {
 					actualReturnTypes[j++] = getFactory().getTypeResolver()
 							.getTypeFactory()
 							.manyToOne( persisters[i].getEntityName(), shallowQuery );
 				}
 			}
 		}
 
 	}
 
 	private void renderIdentifierSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 
 		for ( int k = 0; k < size; k++ ) {
 			String name = ( String ) returnedTypes.get( k );
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			sql.addSelectFragmentString( persisters[k].identifierSelectFragment( name, suffix ) );
 		}
 
 	}
 
 	/*private String renderOrderByPropertiesSelect() {
 		StringBuffer buf = new StringBuffer(10);
 
 		//add the columns we are ordering by to the select ID select clause
 		Iterator iter = orderByTokens.iterator();
 		while ( iter.hasNext() ) {
 			String token = (String) iter.next();
 			if ( token.lastIndexOf(".") > 0 ) {
 				//ie. it is of form "foo.bar", not of form "asc" or "desc"
 				buf.append(StringHelper.COMMA_SPACE).append(token);
 			}
 		}
 
 		return buf.toString();
 	}*/
 
 	private void renderPropertiesSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 		for ( int k = 0; k < size; k++ ) {
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			String name = ( String ) returnedTypes.get( k );
 			sql.addSelectFragmentString( persisters[k].propertySelectFragment( name, suffix, false ) );
 		}
 	}
 
 	/**
 	 * WARNING: side-effecty
 	 */
 	private String renderScalarSelect() {
 
 		boolean isSubselect = superQuery != null;
 
 		StringBuffer buf = new StringBuffer( 20 );
 
 		if ( scalarTypes.size() == 0 ) {
 			//ie. no select clause
 			int size = returnedTypes.size();
 			for ( int k = 0; k < size; k++ ) {
 
 				scalarTypes.add(
 						getFactory().getTypeResolver().getTypeFactory().manyToOne( persisters[k].getEntityName(), shallowQuery )
 				);
 
 				String[] idColumnNames = persisters[k].getIdentifierColumnNames();
 				for ( int i = 0; i < idColumnNames.length; i++ ) {
 					buf.append( returnedTypes.get( k ) ).append( '.' ).append( idColumnNames[i] );
 					if ( !isSubselect ) buf.append( " as " ).append( NameGenerator.scalarName( k, i ) );
 					if ( i != idColumnNames.length - 1 || k != size - 1 ) buf.append( ", " );
 				}
 
 			}
 
 		}
 		else {
 			//there _was_ a select clause
 			Iterator iter = scalarSelectTokens.iterator();
 			int c = 0;
 			boolean nolast = false; //real hacky...
 			int parenCount = 0; // used to count the nesting of parentheses
 			while ( iter.hasNext() ) {
 				Object next = iter.next();
 				if ( next instanceof String ) {
 					String token = ( String ) next;
 
 					if ( "(".equals( token ) ) {
 						parenCount++;
 					}
 					else if ( ")".equals( token ) ) {
 						parenCount--;
 					}
 
 					String lc = token.toLowerCase();
 					if ( lc.equals( ", " ) ) {
 						if ( nolast ) {
 							nolast = false;
 						}
 						else {
 							if ( !isSubselect && parenCount == 0 ) {
 								int x = c++;
 								buf.append( " as " )
 										.append( NameGenerator.scalarName( x, 0 ) );
 							}
 						}
 					}
 					buf.append( token );
 					if ( lc.equals( "distinct" ) || lc.equals( "all" ) ) {
 						buf.append( ' ' );
 					}
 				}
 				else {
 					nolast = true;
 					String[] tokens = ( String[] ) next;
 					for ( int i = 0; i < tokens.length; i++ ) {
 						buf.append( tokens[i] );
 						if ( !isSubselect ) {
 							buf.append( " as " )
 									.append( NameGenerator.scalarName( c, i ) );
 						}
 						if ( i != tokens.length - 1 ) buf.append( ", " );
 					}
 					c++;
 				}
 			}
 			if ( !isSubselect && !nolast ) {
 				int x = c++;
 				buf.append( " as " )
 						.append( NameGenerator.scalarName( x, 0 ) );
 			}
 
 		}
 
 		return buf.toString();
 	}
 
 	private void mergeJoins(JoinFragment ojf) throws MappingException, QueryException {
 
 		Iterator iter = joins.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = ( Map.Entry ) iter.next();
 			String name = ( String ) me.getKey();
 			JoinSequence join = ( JoinSequence ) me.getValue();
 			join.setSelector( new JoinSequence.Selector() {
 				public boolean includeSubclasses(String alias) {
 					boolean include = returnedTypes.contains( alias ) && !isShallowQuery();
 					return include;
 				}
 			} );
 
 			if ( typeMap.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 			else if ( collections.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 			else {
 				//name from a super query (a bit inelegant that it shows up here)
 			}
 
 		}
 
 	}
 
 	public final Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	/**
 	 * Is this query called by scroll() or iterate()?
 	 *
 	 * @return true if it is, false if it is called by find() or list()
 	 */
 	boolean isShallowQuery() {
 		return shallowQuery;
 	}
 
 	void addQuerySpaces(Serializable[] spaces) {
 		for ( int i = 0; i < spaces.length; i++ ) {
 			querySpaces.add( spaces[i] );
 		}
 		if ( superQuery != null ) superQuery.addQuerySpaces( spaces );
 	}
 
 	void setDistinct(boolean distinct) {
 		this.distinct = distinct;
 	}
 
 	boolean isSubquery() {
 		return superQuery != null;
 	}
 
 	/**
 	 * Overrides method from Loader
 	 */
 	@Override
     public CollectionPersister[] getCollectionPersisters() {
 		return collectionPersister == null ? null : new CollectionPersister[] { collectionPersister };
 	}
 
 	@Override
     protected String[] getCollectionSuffixes() {
 		return collectionPersister == null ? null : new String[] { "__" };
 	}
 
 	void setCollectionToFetch(String role, String name, String ownerName, String entityName)
 			throws QueryException {
 		fetchName = name;
 		collectionPersister = getCollectionPersister( role );
 		collectionOwnerName = ownerName;
 		if ( collectionPersister.getElementType().isEntityType() ) {
 			addEntityToFetch( entityName );
 		}
 	}
 
 	@Override
     protected String[] getSuffixes() {
 		return suffixes;
 	}
 
 	@Override
     protected String[] getAliases() {
 		return names;
 	}
 
 	/**
 	 * Used for collection filters
 	 */
 	private void addFromAssociation(final String elementName, final String collectionRole)
 			throws QueryException {
 		//q.addCollection(collectionName, collectionRole);
 		QueryableCollection persister = getCollectionPersister( collectionRole );
 		Type collectionElementType = persister.getElementType();
 		if ( !collectionElementType.isEntityType() ) {
 			throw new QueryException( "collection of values in filter: " + elementName );
 		}
 
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		//if (keyColumnNames.length!=1) throw new QueryException("composite-key collection in filter: " + collectionRole);
 
 		String collectionName;
 		JoinSequence join = new JoinSequence( getFactory() );
 		collectionName = persister.isOneToMany() ?
 				elementName :
 				createNameForCollection( collectionRole );
 		join.setRoot( persister, collectionName );
 		if ( !persister.isOneToMany() ) {
 			//many-to-many
 			addCollection( collectionName, collectionRole );
 			try {
 				join.addJoin( ( AssociationType ) persister.getElementType(),
 						elementName,
 						JoinFragment.INNER_JOIN,
 						persister.getElementColumnNames(collectionName) );
 			}
 			catch ( MappingException me ) {
 				throw new QueryException( me );
 			}
 		}
 		join.addCondition( collectionName, keyColumnNames, " = ?" );
 		//if ( persister.hasWhere() ) join.addCondition( persister.getSQLWhereString(collectionName) );
 		EntityType elemType = ( EntityType ) collectionElementType;
 		addFrom( elementName, elemType.getAssociatedEntityName(), join );
 
 	}
 
 	String getPathAlias(String path) {
 		return ( String ) pathAliases.get( path );
 	}
 
 	JoinSequence getPathJoin(String path) {
 		return ( JoinSequence ) pathJoins.get( path );
 	}
 
 	void addPathAliasAndJoin(String path, String alias, JoinSequence joinSequence) {
 		pathAliases.put( path, alias );
 		pathJoins.put( path, joinSequence );
 	}
 
 	public List list(SessionImplementor session, QueryParameters queryParameters)
 			throws HibernateException {
 		return list( session, queryParameters, getQuerySpaces(), actualReturnTypes );
 	}
 
 	/**
 	 * Return the query results as an iterator
 	 */
 	public Iterator iterate(QueryParameters queryParameters, EventSource session)
 			throws HibernateException {
 
 		boolean stats = session.getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) startTime = System.currentTimeMillis();
 
 		try {
 
 			PreparedStatement st = prepareQueryStatement( queryParameters, false, session );
 			ResultSet rs = getResultSet( st, queryParameters.hasAutoDiscoverScalarTypes(), false, queryParameters.getRowSelection(), session );
 			HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(holderConstructor, queryParameters.getResultTransformer());
 			Iterator result = new IteratorImpl( rs, st, session, queryParameters.isReadOnly( session ), returnTypes, getColumnNames(), hi );
 
 			if ( stats ) {
 				session.getFactory().getStatisticsImplementor().queryExecuted(
 						"HQL: " + queryString,
 						0,
 						System.currentTimeMillis() - startTime
 					);
 			}
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using iterate",
 					getSQLString()
 				);
 		}
 
 	}
 
 	public int executeUpdate(QueryParameters queryParameters, SessionImplementor session) throws HibernateException {
 		throw new UnsupportedOperationException( "Not supported!  Use the AST translator...");
 	}
 
 	@Override
     protected boolean[] includeInResultRow() {
 		boolean[] isResultReturned = includeInSelect;
 		if ( hasScalars ) {
 			isResultReturned = new boolean[ returnedTypes.size() ];
 			Arrays.fill( isResultReturned, true );
 		}
 		return isResultReturned;
 	}
 
 
 	@Override
     protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return HolderInstantiator.resolveClassicResultTransformer(
 				holderConstructor,
 				resultTransformer
 		);
 	}
 
 	@Override
     protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow = getResultRow( row, rs, session );
 		return ( holderClass == null && resultRow.length == 1 ?
 				resultRow[ 0 ] :
 				resultRow
 		);
 	}
 
 	@Override
     protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow;
 		if ( hasScalars ) {
 			String[][] scalarColumns = getColumnNames();
 			int queryCols = returnTypes.length;
 			resultRow = new Object[queryCols];
 			for ( int i = 0; i < queryCols; i++ ) {
 				resultRow[i] = returnTypes[i].nullSafeGet( rs, scalarColumns[i], session, null );
 			}
 		}
 		else {
 			resultRow = toResultRow( row );
 		}
 		return resultRow;
 	}
 
 	@Override
     protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		if ( holderClass != null ) {
 			for ( int i = 0; i < results.size(); i++ ) {
 				Object[] row = ( Object[] ) results.get( i );
 				try {
 					results.set( i, holderConstructor.newInstance( row ) );
 				}
 				catch ( Exception e ) {
 					throw new QueryException( "could not instantiate: " + holderClass, e );
 				}
 			}
 		}
 		return results;
 	}
 
 	private Object[] toResultRow(Object[] row) {
 		if ( selectLength == row.length ) {
 			return row;
 		}
 		else {
 			Object[] result = new Object[selectLength];
 			int j = 0;
 			for ( int i = 0; i < row.length; i++ ) {
 				if ( includeInSelect[i] ) result[j++] = row[i];
 			}
 			return result;
 		}
 	}
 
 	void setHolderClass(Class clazz) {
 		holderClass = clazz;
 	}
 
 	@Override
     protected LockMode[] getLockModes(LockOptions lockOptions) {
 
 		// unfortunately this stuff can't be cached because
 		// it is per-invocation, not constant for the
 		// QueryTranslator instance
 		HashMap nameLockOptions = new HashMap();
 		if ( lockOptions == null) {
 			lockOptions = LockOptions.NONE;
 		}
 
 		if ( lockOptions.getAliasLockCount() > 0 ) {
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
 				Map.Entry me = ( Map.Entry ) iter.next();
 				nameLockOptions.put( getAliasName( ( String ) me.getKey() ),
 						me.getValue() );
diff --git a/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
index 0368e7e419..a3c559021f 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
@@ -1,82 +1,82 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionImplementor;
 import org.jboss.logging.Logger;
 
 /**
  * Generates <tt>string</tt> values using the SQL Server NEWID() function.
  *
  * @author Joseph Fifield
  */
 public class GUIDGenerator implements IdentifierGenerator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, GUIDGenerator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, GUIDGenerator.class.getName());
 	private static boolean warned = false;
 
 	public GUIDGenerator() {
 		if ( ! warned ) {
 			warned = true;
             LOG.deprecatedUuidGenerator(UUIDGenerator.class.getName(), UUIDGenerationStrategy.class.getName());
 		}
 	}
 
 	public Serializable generate(SessionImplementor session, Object obj)
 	throws HibernateException {
 
 		final String sql = session.getFactory().getDialect().getSelectGUIDString();
 		try {
 			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				ResultSet rs = st.executeQuery();
 				final String result;
 				try {
 					rs.next();
 					result = rs.getString(1);
 				}
 				finally {
 					rs.close();
 				}
                 LOG.guidGenerated(result);
 				return result;
 			}
 			finally {
 				st.close();
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve GUID",
 					sql
 				);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/IdentifierGeneratorHelper.java b/hibernate-core/src/main/java/org/hibernate/id/IdentifierGeneratorHelper.java
index 3e7dc6baa7..ebdcaa2214 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/IdentifierGeneratorHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/IdentifierGeneratorHelper.java
@@ -1,684 +1,684 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.id;
 import java.io.Serializable;
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.CustomType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Factory and helper methods for {@link IdentifierGenerator} framework.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public final class IdentifierGeneratorHelper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        IdentifierGeneratorHelper.class.getName());
 
 	/**
 	 * Marker object returned from {@link IdentifierGenerator#generate} to indicate that we should short-circuit any
 	 * continued generated id checking.  Currently this is only used in the case of the
 	 * {@link org.hibernate.id.ForeignGenerator foreign} generator as a way to signal that we should use the associated
 	 * entity's id value.
 	 */
 	public static final Serializable SHORT_CIRCUIT_INDICATOR = new Serializable() {
 		@Override
         public String toString() {
 			return "SHORT_CIRCUIT_INDICATOR";
 		}
 	};
 
 	/**
 	 * Marker object returned from {@link IdentifierGenerator#generate} to indicate that the entity's identifier will
 	 * be generated as part of the datbase insertion.
 	 */
 	public static final Serializable POST_INSERT_INDICATOR = new Serializable() {
 		@Override
         public String toString() {
 			return "POST_INSERT_INDICATOR";
 		}
 	};
 
 
 	/**
 	 * Get the generated identifier when using identity columns
 	 *
 	 * @param rs The result set from which to extract the the generated identity.
 	 * @param type The expected type mapping for the identity value.
 	 * @return The generated identity value
 	 * @throws SQLException Can be thrown while accessing the result set
 	 * @throws HibernateException Indicates a problem reading back a generated identity value.
 	 */
 	public static Serializable getGeneratedIdentity(ResultSet rs, Type type) throws SQLException, HibernateException {
 		if ( !rs.next() ) {
 			throw new HibernateException( "The database returned no natively generated identity value" );
 		}
 		final Serializable id = IdentifierGeneratorHelper.get( rs, type );
         LOG.debugf("Natively generated identity: %s", id);
 		return id;
 	}
 
 	/**
 	 * Extract the value from the result set (which is assumed to already have been positioned to the apopriate row)
 	 * and wrp it in the appropriate Java numeric type.
 	 *
 	 * @param rs The result set from which to extract the value.
 	 * @param type The expected type of the value.
 	 * @return The extracted value.
 	 * @throws SQLException Indicates problems access the result set
 	 * @throws IdentifierGenerationException Indicates an unknown type.
 	 */
 	public static Serializable get(ResultSet rs, Type type) throws SQLException, IdentifierGenerationException {
 		if ( ResultSetIdentifierConsumer.class.isInstance( type ) ) {
 			return ( ( ResultSetIdentifierConsumer ) type ).consumeIdentifier( rs );
 		}
 		if ( CustomType.class.isInstance( type ) ) {
 			final CustomType customType = (CustomType) type;
 			if ( ResultSetIdentifierConsumer.class.isInstance( customType.getUserType() ) ) {
 				return ( (ResultSetIdentifierConsumer) customType.getUserType() ).consumeIdentifier( rs );
 			}
 		}
 
 		Class clazz = type.getReturnedClass();
 		if ( clazz == Long.class ) {
 			return new Long( rs.getLong( 1 ) );
 		}
 		else if ( clazz == Integer.class ) {
 			return new Integer( rs.getInt( 1 ) );
 		}
 		else if ( clazz == Short.class ) {
 			return new Short( rs.getShort( 1 ) );
 		}
 		else if ( clazz == String.class ) {
 			return rs.getString( 1 );
 		}
 		else if ( clazz == BigInteger.class ) {
 			return rs.getBigDecimal( 1 ).setScale( 0, BigDecimal.ROUND_UNNECESSARY ).toBigInteger();
 		}
 		else if ( clazz == BigDecimal.class ) {
 			return rs.getBigDecimal( 1 ).setScale( 0, BigDecimal.ROUND_UNNECESSARY );
 		}
 		else {
 			throw new IdentifierGenerationException(
 					"unrecognized id type : " + type.getName() + " -> " + clazz.getName()
 			);
 		}
 	}
 
 	/**
 	 * Wrap the given value in the given Java numeric class.
 	 *
 	 * @param value The primitive value to wrap.
 	 * @param clazz The Java numeric type in which to wrap the value.
 	 *
 	 * @return The wrapped type.
 	 *
 	 * @throws IdentifierGenerationException Indicates an unhandled 'clazz'.
 	 *
 	 * @deprecated Use the {@link #getIntegralDataTypeHolder holders} instead.
 	 */
 	@Deprecated
     public static Number createNumber(long value, Class clazz) throws IdentifierGenerationException {
 		if ( clazz == Long.class ) {
 			return new Long( value );
 		}
 		else if ( clazz == Integer.class ) {
 			return new Integer( ( int ) value );
 		}
 		else if ( clazz == Short.class ) {
 			return new Short( ( short ) value );
 		}
 		else {
 			throw new IdentifierGenerationException( "unrecognized id type : " + clazz.getName() );
 		}
 	}
 
 	public static IntegralDataTypeHolder getIntegralDataTypeHolder(Class integralType) {
 		if ( integralType == Long.class
 				|| integralType == Integer.class
 				|| integralType == Short.class ) {
 			return new BasicHolder( integralType );
 		}
 		else if ( integralType == BigInteger.class ) {
 			return new BigIntegerHolder();
 		}
 		else if ( integralType == BigDecimal.class ) {
 			return new BigDecimalHolder();
 		}
 		else {
 			throw new IdentifierGenerationException(
 					"Unknown integral data type for ids : " + integralType.getName()
 			);
 		}
 	}
 
 	public static long extractLong(IntegralDataTypeHolder holder) {
 		if ( holder.getClass() == BasicHolder.class ) {
 			( (BasicHolder) holder ).checkInitialized();
 			return ( (BasicHolder) holder ).value;
 		}
 		else if ( holder.getClass() == BigIntegerHolder.class ) {
 			( (BigIntegerHolder) holder ).checkInitialized();
 			return ( (BigIntegerHolder) holder ).value.longValue();
 		}
 		else if ( holder.getClass() == BigDecimalHolder.class ) {
 			( (BigDecimalHolder) holder ).checkInitialized();
 			return ( (BigDecimalHolder) holder ).value.longValue();
 		}
 		throw new IdentifierGenerationException( "Unknown IntegralDataTypeHolder impl [" + holder + "]" );
 	}
 
 	public static BigInteger extractBigInteger(IntegralDataTypeHolder holder) {
 		if ( holder.getClass() == BasicHolder.class ) {
 			( (BasicHolder) holder ).checkInitialized();
 			return BigInteger.valueOf( ( (BasicHolder) holder ).value );
 		}
 		else if ( holder.getClass() == BigIntegerHolder.class ) {
 			( (BigIntegerHolder) holder ).checkInitialized();
 			return ( (BigIntegerHolder) holder ).value;
 		}
 		else if ( holder.getClass() == BigDecimalHolder.class ) {
 			( (BigDecimalHolder) holder ).checkInitialized();
 			// scale should already be set...
 			return ( (BigDecimalHolder) holder ).value.toBigInteger();
 		}
 		throw new IdentifierGenerationException( "Unknown IntegralDataTypeHolder impl [" + holder + "]" );
 	}
 
 	public static BigDecimal extractBigDecimal(IntegralDataTypeHolder holder) {
 		if ( holder.getClass() == BasicHolder.class ) {
 			( (BasicHolder) holder ).checkInitialized();
 			return BigDecimal.valueOf( ( (BasicHolder) holder ).value );
 		}
 		else if ( holder.getClass() == BigIntegerHolder.class ) {
 			( (BigIntegerHolder) holder ).checkInitialized();
 			return new BigDecimal( ( (BigIntegerHolder) holder ).value );
 		}
 		else if ( holder.getClass() == BigDecimalHolder.class ) {
 			( (BigDecimalHolder) holder ).checkInitialized();
 			// scale should already be set...
 			return ( (BigDecimalHolder) holder ).value;
 		}
 		throw new IdentifierGenerationException( "Unknown IntegralDataTypeHolder impl [" + holder + "]" );
 	}
 
 	public static class BasicHolder implements IntegralDataTypeHolder {
 		private final Class exactType;
 		private long value = Long.MIN_VALUE;
 
 		public BasicHolder(Class exactType) {
 			this.exactType = exactType;
 			if ( exactType != Long.class && exactType != Integer.class && exactType != Short.class ) {
 				throw new IdentifierGenerationException( "Invalid type for basic integral holder : " + exactType );
 			}
 		}
 
 		public long getActualLongValue() {
 			return value;
 		}
 
 		public IntegralDataTypeHolder initialize(long value) {
 			this.value = value;
 			return this;
 		}
 
 		public IntegralDataTypeHolder initialize(ResultSet resultSet, long defaultValue) throws SQLException {
 			long value = resultSet.getLong( 1 );
 			if ( resultSet.wasNull() ) {
 				value = defaultValue;
 			}
 			return initialize( value );
 		}
 
 		public void bind(PreparedStatement preparedStatement, int position) throws SQLException {
 			// TODO : bind it as 'exact type'?  Not sure if that gains us anything...
 			preparedStatement.setLong( position, value );
 		}
 
 		public IntegralDataTypeHolder increment() {
 			checkInitialized();
 			value++;
 			return this;
 		}
 
 		private void checkInitialized() {
 			if ( value == Long.MIN_VALUE ) {
 				throw new IdentifierGenerationException( "integral holder was not initialized" );
 			}
 		}
 
 		public IntegralDataTypeHolder add(long addend) {
 			checkInitialized();
 			value += addend;
 			return this;
 		}
 
 		public IntegralDataTypeHolder decrement() {
 			checkInitialized();
 			value--;
 			return this;
 		}
 
 		public IntegralDataTypeHolder subtract(long subtrahend) {
 			checkInitialized();
 			value -= subtrahend;
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(IntegralDataTypeHolder factor) {
 			return multiplyBy( extractLong( factor ) );
 		}
 
 		public IntegralDataTypeHolder multiplyBy(long factor) {
 			checkInitialized();
 			value *= factor;
 			return this;
 		}
 
 		public boolean eq(IntegralDataTypeHolder other) {
 			return eq( extractLong( other ) );
 		}
 
 		public boolean eq(long value) {
 			checkInitialized();
 			return this.value == value;
 		}
 
 		public boolean lt(IntegralDataTypeHolder other) {
 			return lt( extractLong( other ) );
 		}
 
 		public boolean lt(long value) {
 			checkInitialized();
 			return this.value < value;
 		}
 
 		public boolean gt(IntegralDataTypeHolder other) {
 			return gt( extractLong( other ) );
 		}
 
 		public boolean gt(long value) {
 			checkInitialized();
 			return this.value > value;
 		}
 
 		public IntegralDataTypeHolder copy() {
 			BasicHolder copy = new BasicHolder( exactType );
 			copy.value = value;
 			return copy;
 		}
 
 		public Number makeValue() {
 			// TODO : should we check for truncation?
 			checkInitialized();
 			if ( exactType == Long.class ) {
 				return new Long( value );
 			}
 			else if ( exactType == Integer.class ) {
 				return new Integer( ( int ) value );
 			}
 			else {
 				return new Short( ( short ) value );
 			}
 		}
 
 		public Number makeValueThenIncrement() {
 			final Number result = makeValue();
 			value++;
 			return result;
 		}
 
 		public Number makeValueThenAdd(long addend) {
 			final Number result = makeValue();
 			value += addend;
 			return result;
 		}
 
 		@Override
         public String toString() {
 			return "BasicHolder[" + exactType.getName() + "[" + value + "]]";
 		}
 
 		@Override
         public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			BasicHolder that = (BasicHolder) o;
 
 			return value == that.value;
 		}
 
 		@Override
         public int hashCode() {
 			return (int) ( value ^ ( value >>> 32 ) );
 		}
 	}
 
 	public static class BigIntegerHolder implements IntegralDataTypeHolder {
 		private BigInteger value;
 
 		public IntegralDataTypeHolder initialize(long value) {
 			this.value = BigInteger.valueOf( value );
 			return this;
 		}
 
 		public IntegralDataTypeHolder initialize(ResultSet resultSet, long defaultValue) throws SQLException {
 			final BigDecimal rsValue = resultSet.getBigDecimal( 1 );
 			if ( resultSet.wasNull() ) {
 				return initialize( defaultValue );
 			}
 			this.value = rsValue.setScale( 0, BigDecimal.ROUND_UNNECESSARY ).toBigInteger();
 			return this;
 		}
 
 		public void bind(PreparedStatement preparedStatement, int position) throws SQLException {
 			preparedStatement.setBigDecimal( position, new BigDecimal( value ) );
 		}
 
 		public IntegralDataTypeHolder increment() {
 			checkInitialized();
 			value = value.add( BigInteger.ONE );
 			return this;
 		}
 
 		private void checkInitialized() {
 			if ( value == null ) {
 				throw new IdentifierGenerationException( "integral holder was not initialized" );
 			}
 		}
 
 		public IntegralDataTypeHolder add(long increment) {
 			checkInitialized();
 			value = value.add( BigInteger.valueOf( increment ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder decrement() {
 			checkInitialized();
 			value = value.subtract( BigInteger.ONE );
 			return this;
 		}
 
 		public IntegralDataTypeHolder subtract(long subtrahend) {
 			checkInitialized();
 			value = value.subtract( BigInteger.valueOf( subtrahend ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(IntegralDataTypeHolder factor) {
 			checkInitialized();
 			value = value.multiply( extractBigInteger( factor ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(long factor) {
 			checkInitialized();
 			value = value.multiply( BigInteger.valueOf( factor ) );
 			return this;
 		}
 
 		public boolean eq(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigInteger( other ) ) == 0;
 		}
 
 		public boolean eq(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigInteger.valueOf( value ) ) == 0;
 		}
 
 		public boolean lt(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigInteger( other ) ) < 0;
 		}
 
 		public boolean lt(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigInteger.valueOf( value ) ) < 0;
 		}
 
 		public boolean gt(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigInteger( other ) ) > 0;
 		}
 
 		public boolean gt(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigInteger.valueOf( value ) ) > 0;
 		}
 
 		public IntegralDataTypeHolder copy() {
 			BigIntegerHolder copy = new BigIntegerHolder();
 			copy.value = value;
 			return copy;
 		}
 
 		public Number makeValue() {
 			checkInitialized();
 			return value;
 		}
 
 		public Number makeValueThenIncrement() {
 			final Number result = makeValue();
 			value = value.add( BigInteger.ONE );
 			return result;
 		}
 
 		public Number makeValueThenAdd(long addend) {
 			final Number result = makeValue();
 			value = value.add( BigInteger.valueOf( addend ) );
 			return result;
 		}
 
 		@Override
         public String toString() {
 			return "BigIntegerHolder[" + value + "]";
 		}
 
 		@Override
         public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			BigIntegerHolder that = (BigIntegerHolder) o;
 
 			return this.value == null
 					? that.value == null
 					: value.equals( that.value );
 		}
 
 		@Override
         public int hashCode() {
 			return value != null ? value.hashCode() : 0;
 		}
 	}
 
 	public static class BigDecimalHolder implements IntegralDataTypeHolder {
 		private BigDecimal value;
 
 		public IntegralDataTypeHolder initialize(long value) {
 			this.value = BigDecimal.valueOf( value );
 			return this;
 		}
 
 		public IntegralDataTypeHolder initialize(ResultSet resultSet, long defaultValue) throws SQLException {
 			final BigDecimal rsValue = resultSet.getBigDecimal( 1 );
 			if ( resultSet.wasNull() ) {
 				return initialize( defaultValue );
 			}
 			this.value = rsValue.setScale( 0, BigDecimal.ROUND_UNNECESSARY );
 			return this;
 		}
 
 		public void bind(PreparedStatement preparedStatement, int position) throws SQLException {
 			preparedStatement.setBigDecimal( position, value );
 		}
 
 		public IntegralDataTypeHolder increment() {
 			checkInitialized();
 			value = value.add( BigDecimal.ONE );
 			return this;
 		}
 
 		private void checkInitialized() {
 			if ( value == null ) {
 				throw new IdentifierGenerationException( "integral holder was not initialized" );
 			}
 		}
 
 		public IntegralDataTypeHolder add(long increment) {
 			checkInitialized();
 			value = value.add( BigDecimal.valueOf( increment ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder decrement() {
 			checkInitialized();
 			value = value.subtract( BigDecimal.ONE );
 			return this;
 		}
 
 		public IntegralDataTypeHolder subtract(long subtrahend) {
 			checkInitialized();
 			value = value.subtract( BigDecimal.valueOf( subtrahend ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(IntegralDataTypeHolder factor) {
 			checkInitialized();
 			value = value.multiply( extractBigDecimal( factor ) );
 			return this;
 		}
 
 		public IntegralDataTypeHolder multiplyBy(long factor) {
 			checkInitialized();
 			value = value.multiply( BigDecimal.valueOf( factor ) );
 			return this;
 		}
 
 		public boolean eq(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigDecimal( other ) ) == 0;
 		}
 
 		public boolean eq(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigDecimal.valueOf( value ) ) == 0;
 		}
 
 		public boolean lt(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigDecimal( other ) ) < 0;
 		}
 
 		public boolean lt(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigDecimal.valueOf( value ) ) < 0;
 		}
 
 		public boolean gt(IntegralDataTypeHolder other) {
 			checkInitialized();
 			return value.compareTo( extractBigDecimal( other ) ) > 0;
 		}
 
 		public boolean gt(long value) {
 			checkInitialized();
 			return this.value.compareTo( BigDecimal.valueOf( value ) ) > 0;
 		}
 
 		public IntegralDataTypeHolder copy() {
 			BigDecimalHolder copy = new BigDecimalHolder();
 			copy.value = value;
 			return copy;
 		}
 
 		public Number makeValue() {
 			checkInitialized();
 			return value;
 		}
 
 		public Number makeValueThenIncrement() {
 			final Number result = makeValue();
 			value = value.add( BigDecimal.ONE );
 			return result;
 		}
 
 		public Number makeValueThenAdd(long addend) {
 			final Number result = makeValue();
 			value = value.add( BigDecimal.valueOf( addend ) );
 			return result;
 		}
 
 		@Override
         public String toString() {
 			return "BigDecimalHolder[" + value + "]";
 		}
 
 		@Override
         public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			BigDecimalHolder that = (BigDecimalHolder) o;
 
 			return this.value == null
 					? that.value == null
 					: this.value.equals( that.value );
 		}
 
 		@Override
         public int hashCode() {
 			return value != null ? value.hashCode() : 0;
 		}
 	}
 
 	/**
 	 * Disallow instantiation of IdentifierGeneratorHelper.
 	 */
 	private IdentifierGeneratorHelper() {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
index 886719d27d..20167be397 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
@@ -1,149 +1,149 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * <b>increment</b><br>
  * <br>
  * An <tt>IdentifierGenerator</tt> that returns a <tt>long</tt>, constructed by
  * counting from the maximum primary key value at startup. Not safe for use in a
  * cluster!<br>
  * <br>
  * Mapping parameters supported, but not usually needed: tables, column.
  * (The tables parameter specified a comma-separated list of table names.)
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class IncrementGenerator implements IdentifierGenerator, Configurable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, IncrementGenerator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, IncrementGenerator.class.getName());
 
 	private Class returnClass;
 	private String sql;
 
 	private IntegralDataTypeHolder previousValueHolder;
 
 	public synchronized Serializable generate(SessionImplementor session, Object object) throws HibernateException {
 		if ( sql != null ) {
 			initializePreviousValueHolder( session );
 		}
 		return previousValueHolder.makeValueThenIncrement();
 	}
 
 	public void configure(Type type, Properties params, Dialect dialect) throws MappingException {
 		returnClass = type.getReturnedClass();
 
 		ObjectNameNormalizer normalizer =
 				( ObjectNameNormalizer ) params.get( PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER );
 
 		String column = params.getProperty( "column" );
 		if ( column == null ) {
 			column = params.getProperty( PersistentIdentifierGenerator.PK );
 		}
 		column = dialect.quote( normalizer.normalizeIdentifierQuoting( column ) );
 
 		String tableList = params.getProperty( "tables" );
 		if ( tableList == null ) {
 			tableList = params.getProperty( PersistentIdentifierGenerator.TABLES );
 		}
 		String[] tables = StringHelper.split( ", ", tableList );
 
 		final String schema = dialect.quote(
 				normalizer.normalizeIdentifierQuoting(
 						params.getProperty( PersistentIdentifierGenerator.SCHEMA )
 				)
 		);
 		final String catalog = dialect.quote(
 				normalizer.normalizeIdentifierQuoting(
 						params.getProperty( PersistentIdentifierGenerator.CATALOG )
 				)
 		);
 
 		StringBuffer buf = new StringBuffer();
 		for ( int i=0; i < tables.length; i++ ) {
 			final String tableName = dialect.quote( normalizer.normalizeIdentifierQuoting( tables[i] ) );
 			if ( tables.length > 1 ) {
 				buf.append( "select " ).append( column ).append( " from " );
 			}
 			buf.append( Table.qualify( catalog, schema, tableName ) );
 			if ( i < tables.length-1 ) {
 				buf.append( " union " );
 			}
 		}
 		if ( tables.length > 1 ) {
 			buf.insert( 0, "( " ).append( " ) ids_" );
 			column = "ids_." + column;
 		}
 
 		sql = "select max(" + column + ") from " + buf.toString();
 	}
 
 	private void initializePreviousValueHolder(SessionImplementor session) {
 		previousValueHolder = IdentifierGeneratorHelper.getIntegralDataTypeHolder( returnClass );
 
         LOG.debugf("Fetching initial value: %s", sql);
 		try {
 			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				ResultSet rs = st.executeQuery();
 				try {
                     if (rs.next()) previousValueHolder.initialize(rs, 0L).increment();
                     else previousValueHolder.initialize(1L);
 					sql = null;
                     LOG.debugf("First free id: %s", previousValueHolder.makeValue());
 				}
 				finally {
 					rs.close();
 				}
 			}
 			finally {
 				st.close();
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not fetch initial value for increment generator",
 					sql
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
index c4c86e7700..e79eab5af4 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
@@ -1,294 +1,294 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.id.enhanced.AccessCallback;
 import org.hibernate.id.enhanced.OptimizerFactory;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  *
  * A hilo <tt>IdentifierGenerator</tt> that returns a <tt>Long</tt>, constructed using
  * a hi/lo algorithm. The hi value MUST be fetched in a seperate transaction
  * to the <tt>Session</tt> transaction so the generator must be able to obtain
  * a new connection and commit it. Hence this implementation may not
  * be used  when the user is supplying connections. In this
  * case a <tt>SequenceHiLoGenerator</tt> would be a better choice (where
  * supported).<br>
  * <br>
  *
  * A hilo <tt>IdentifierGenerator</tt> that uses a database
  * table to store the last generated values. A table can contains
  * several hi values. They are distinct from each other through a key
  * <p/>
  * <p>This implementation is not compliant with a user connection</p>
  * <p/>
  *
  * <p>Allowed parameters (all of them are optional):</p>
  * <ul>
  * <li>table: table name (default <tt>hibernate_sequences</tt>)</li>
  * <li>primary_key_column: key column name (default <tt>sequence_name</tt>)</li>
  * <li>value_column: hi value column name(default <tt>sequence_next_hi_value</tt>)</li>
  * <li>primary_key_value: key value for the current entity (default to the entity's primary table name)</li>
  * <li>primary_key_length: length of the key column in DB represented as a varchar (default to 255)</li>
  * <li>max_lo: max low value before increasing hi (default to Short.MAX_VALUE)</li>
  * </ul>
  *
  * @author Emmanuel Bernard
  * @author <a href="mailto:kr@hbt.de">Klaus Richarz</a>.
  */
 public class MultipleHiLoPerTableGenerator implements PersistentIdentifierGenerator, Configurable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        MultipleHiLoPerTableGenerator.class.getName());
 
 	public static final String ID_TABLE = "table";
 	public static final String PK_COLUMN_NAME = "primary_key_column";
 	public static final String PK_VALUE_NAME = "primary_key_value";
 	public static final String VALUE_COLUMN_NAME = "value_column";
 	public static final String PK_LENGTH_NAME = "primary_key_length";
 
 	private static final int DEFAULT_PK_LENGTH = 255;
 	public static final String DEFAULT_TABLE = "hibernate_sequences";
 	private static final String DEFAULT_PK_COLUMN = "sequence_name";
 	private static final String DEFAULT_VALUE_COLUMN = "sequence_next_hi_value";
 
 	private String tableName;
 	private String pkColumnName;
 	private String valueColumnName;
 	private String query;
 	private String insert;
 	private String update;
 
 	//hilo params
 	public static final String MAX_LO = "max_lo";
 
 	private int maxLo;
 	private OptimizerFactory.LegacyHiLoAlgorithmOptimizer hiloOptimizer;
 
 	private Class returnClass;
 	private int keySize;
 
 
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		return new String[] {
 			new StringBuffer( dialect.getCreateTableString() )
 					.append( ' ' )
 					.append( tableName )
 					.append( " ( " )
 					.append( pkColumnName )
 					.append( ' ' )
 					.append( dialect.getTypeName( Types.VARCHAR, keySize, 0, 0 ) )
 					.append( ",  " )
 					.append( valueColumnName )
 					.append( ' ' )
 					.append( dialect.getTypeName( Types.INTEGER ) )
 					.append( " ) " )
 					.toString()
 		};
 	}
 
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		StringBuffer sqlDropString = new StringBuffer( "drop table " );
 		if ( dialect.supportsIfExistsBeforeTableName() ) {
 			sqlDropString.append( "if exists " );
 		}
 		sqlDropString.append( tableName ).append( dialect.getCascadeConstraintsString() );
 		if ( dialect.supportsIfExistsAfterTableName() ) {
 			sqlDropString.append( " if exists" );
 		}
 		return new String[] { sqlDropString.toString() };
 	}
 
 	public Object generatorKey() {
 		return tableName;
 	}
 
 	public synchronized Serializable generate(final SessionImplementor session, Object obj) {
 		final WorkExecutorVisitable<IntegralDataTypeHolder> work = new AbstractReturningWork<IntegralDataTypeHolder>() {
 			@Override
 			public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
 				IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( returnClass );
 				SqlStatementLogger statementLogger = session
 						.getFactory()
 						.getServiceRegistry()
 						.getService( JdbcServices.class )
 						.getSqlStatementLogger();
 				int rows;
 				do {
 					statementLogger.logStatement( query, FormatStyle.BASIC.getFormatter() );
 					PreparedStatement qps = connection.prepareStatement( query );
 					PreparedStatement ips = null;
 					try {
 						ResultSet rs = qps.executeQuery();
 						boolean isInitialized = rs.next();
 						if ( !isInitialized ) {
 							value.initialize( 0 );
 							statementLogger.logStatement( insert, FormatStyle.BASIC.getFormatter() );
 							ips = connection.prepareStatement( insert );
 							value.bind( ips, 1 );
 							ips.execute();
 						}
 						else {
 							value.initialize( rs, 0 );
 						}
 						rs.close();
 					}
 					catch (SQLException sqle) {
                         LOG.unableToReadOrInitHiValue(sqle);
 						throw sqle;
 					}
 					finally {
 						if (ips != null) {
 							ips.close();
 						}
 						qps.close();
 					}
 
 					statementLogger.logStatement( update, FormatStyle.BASIC.getFormatter() );
 					PreparedStatement ups = connection.prepareStatement( update );
 					try {
 						value.copy().increment().bind( ups, 1 );
 						value.bind( ups, 2 );
 						rows = ups.executeUpdate();
 					}
 					catch (SQLException sqle) {
                         LOG.error(LOG.unableToUpdateHiValue(tableName), sqle);
 						throw sqle;
 					}
 					finally {
 						ups.close();
 					}
 				} while ( rows==0 );
 
 				return value;
 			}
 		};
 
 		// maxLo < 1 indicates a hilo generator with no hilo :?
 		if ( maxLo < 1 ) {
 			//keep the behavior consistent even for boundary usages
 			IntegralDataTypeHolder value = null;
 			while ( value == null || value.lt( 1 ) ) {
 				value = session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork( work, true );
 			}
 			return value.makeValue();
 		}
 
 		return hiloOptimizer.generate(
 				new AccessCallback() {
 					public IntegralDataTypeHolder getNextValue() {
 						return session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork( work, true );
 					}
 				}
 		);
 	}
 
 	public void configure(Type type, Properties params, Dialect dialect) throws MappingException {
 		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 
 		tableName = normalizer.normalizeIdentifierQuoting( ConfigurationHelper.getString( ID_TABLE, params, DEFAULT_TABLE ) );
 		if ( tableName.indexOf( '.' ) < 0 ) {
 			tableName = dialect.quote( tableName );
 			final String schemaName = dialect.quote(
 					normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) )
 			);
 			final String catalogName = dialect.quote(
 					normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) )
 			);
 			tableName = Table.qualify( catalogName, schemaName, tableName );
 		}
 		else {
 			// if already qualified there is not much we can do in a portable manner so we pass it
 			// through and assume the user has set up the name correctly.
 		}
 
 		pkColumnName = dialect.quote(
 				normalizer.normalizeIdentifierQuoting(
 						ConfigurationHelper.getString( PK_COLUMN_NAME, params, DEFAULT_PK_COLUMN )
 				)
 		);
 		valueColumnName = dialect.quote(
 				normalizer.normalizeIdentifierQuoting(
 						ConfigurationHelper.getString( VALUE_COLUMN_NAME, params, DEFAULT_VALUE_COLUMN )
 				)
 		);
 		keySize = ConfigurationHelper.getInt(PK_LENGTH_NAME, params, DEFAULT_PK_LENGTH);
 		String keyValue = ConfigurationHelper.getString(PK_VALUE_NAME, params, params.getProperty(TABLE) );
 
 		query = "select " +
 			valueColumnName +
 			" from " +
 			dialect.appendLockHint( LockMode.PESSIMISTIC_WRITE, tableName ) +
 			" where " + pkColumnName + " = '" + keyValue + "'" +
 			dialect.getForUpdateString();
 
 		update = "update " +
 			tableName +
 			" set " +
 			valueColumnName +
 			" = ? where " +
 			valueColumnName +
 			" = ? and " +
 			pkColumnName +
 			" = '" +
 			keyValue
 			+ "'";
 
 		insert = "insert into " + tableName +
 			"(" + pkColumnName + ", " +	valueColumnName + ") " +
 			"values('"+ keyValue +"', ?)";
 
 
 		//hilo config
 		maxLo = ConfigurationHelper.getInt(MAX_LO, params, Short.MAX_VALUE);
 		returnClass = type.getReturnedClass();
 
 		if ( maxLo >= 1 ) {
 			hiloOptimizer = new OptimizerFactory.LegacyHiLoAlgorithmOptimizer( returnClass, maxLo );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
index d4feea644f..90d0cef6d5 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
@@ -1,159 +1,159 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * <b>sequence</b><br>
  * <br>
  * Generates <tt>long</tt> values using an oracle-style sequence. A higher
  * performance algorithm is <tt>SequenceHiLoGenerator</tt>.<br>
  * <br>
  * Mapping parameters supported: sequence, parameters.
  *
  * @see SequenceHiLoGenerator
  * @see TableHiLoGenerator
  * @author Gavin King
  */
 public class SequenceGenerator implements PersistentIdentifierGenerator, Configurable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SequenceGenerator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SequenceGenerator.class.getName());
 
 	/**
 	 * The sequence parameter
 	 */
 	public static final String SEQUENCE = "sequence";
 
 	/**
 	 * The parameters parameter, appended to the create sequence DDL.
 	 * For example (Oracle): <tt>INCREMENT BY 1 START WITH 1 MAXVALUE 100 NOCACHE</tt>.
 	 */
 	public static final String PARAMETERS = "parameters";
 
 	private String sequenceName;
 	private String parameters;
 	private Type identifierType;
 	private String sql;
 
 	protected Type getIdentifierType() {
 		return identifierType;
 	}
 
 	public void configure(Type type, Properties params, Dialect dialect) throws MappingException {
 		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 		sequenceName = normalizer.normalizeIdentifierQuoting(
 				ConfigurationHelper.getString( SEQUENCE, params, "hibernate_sequence" )
 		);
 		parameters = params.getProperty( PARAMETERS );
 
 		if ( sequenceName.indexOf( '.' ) < 0 ) {
 			final String schemaName = normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) );
 			final String catalogName = normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) );
 			sequenceName = Table.qualify(
 					dialect.quote( catalogName ),
 					dialect.quote( schemaName ),
 					dialect.quote( sequenceName )
 			);
 		}
 		else {
 			// if already qualified there is not much we can do in a portable manner so we pass it
 			// through and assume the user has set up the name correctly.
 		}
 
 		this.identifierType = type;
 		sql = dialect.getSequenceNextValString( sequenceName );
 	}
 
 	public Serializable generate(SessionImplementor session, Object obj) {
 		return generateHolder( session ).makeValue();
 	}
 
 	protected IntegralDataTypeHolder generateHolder(SessionImplementor session) {
 		try {
 			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				ResultSet rs = st.executeQuery();
 				try {
 					rs.next();
 					IntegralDataTypeHolder result = buildHolder();
 					result.initialize( rs, 1 );
                     LOG.debugf("Sequence identifier generated: %s", result);
 					return result;
 				}
 				finally {
 					rs.close();
 				}
 			}
 			finally {
 				st.close();
 			}
 
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not get next sequence value",
 					sql
 			);
 		}
 	}
 
 	protected IntegralDataTypeHolder buildHolder() {
 		return IdentifierGeneratorHelper.getIntegralDataTypeHolder( identifierType.getReturnedClass() );
 	}
 
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		String[] ddl = dialect.getCreateSequenceStrings(sequenceName);
 		if ( parameters != null ) {
 			ddl[ddl.length - 1] += ' ' + parameters;
 		}
 		return ddl;
 	}
 
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		return dialect.getDropSequenceStrings(sequenceName);
 	}
 
 	public Object generatorKey() {
 		return sequenceName;
 	}
 
 	public String getSequenceName() {
 		return sequenceName;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
index cd67d1420e..15de75381c 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
@@ -1,128 +1,128 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ *
+ */
 package org.hibernate.id;
-
-import java.io.Serializable;
-import java.sql.PreparedStatement;
-import java.sql.SQLException;
-import java.util.Properties;
-import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.MappingException;
-import org.hibernate.dialect.Dialect;
-import org.hibernate.engine.SessionImplementor;
-import org.hibernate.id.insert.AbstractReturningDelegate;
-import org.hibernate.id.insert.IdentifierGeneratingInsert;
-import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
-import org.hibernate.sql.Insert;
-import org.hibernate.type.Type;
-import org.jboss.logging.Logger;
-
-/**
- * A generator which combines sequence generation with immediate retrieval
- * through JDBC3 {@link java.sql.Connection#prepareStatement(String, String[]) getGeneratedKeys}.
- * In this respect it works much like ANSI-SQL IDENTITY generation.
- * <p/>
- * This generator only known to work with newer Oracle drivers compiled for
- * JDK 1.4 (JDBC3).
- * <p/>
- * Note: Due to a bug in Oracle drivers, sql comments on these insert statements
- * are completely disabled.
- *
- * @author Steve Ebersole
- */
-public class SequenceIdentityGenerator extends SequenceGenerator
-		implements PostInsertIdentifierGenerator {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
-                                                                       SequenceIdentityGenerator.class.getName());
-
-	@Override
-    public Serializable generate(SessionImplementor s, Object obj) {
-		return IdentifierGeneratorHelper.POST_INSERT_INDICATOR;
-	}
-
-	public InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
-			PostInsertIdentityPersister persister,
-	        Dialect dialect,
-	        boolean isGetGeneratedKeysEnabled) throws HibernateException {
-		return new Delegate( persister, dialect, getSequenceName() );
-	}
-
-	@Override
-    public void configure(Type type, Properties params, Dialect dialect) throws MappingException {
-		super.configure( type, params, dialect );
-	}
-
-	public static class Delegate extends AbstractReturningDelegate {
-		private final Dialect dialect;
-		private final String sequenceNextValFragment;
-		private final String[] keyColumns;
-
-		public Delegate(PostInsertIdentityPersister persister, Dialect dialect, String sequenceName) {
-			super( persister );
-			this.dialect = dialect;
-			this.sequenceNextValFragment = dialect.getSelectSequenceNextValString( sequenceName );
-			this.keyColumns = getPersister().getRootTableKeyColumnNames();
-			if ( keyColumns.length > 1 ) {
-				throw new HibernateException( "sequence-identity generator cannot be used with with multi-column keys" );
-			}
-		}
-
-		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
-			NoCommentsInsert insert = new NoCommentsInsert( dialect );
-			insert.addColumn( getPersister().getRootTableKeyColumnNames()[0], sequenceNextValFragment );
-			return insert;
-		}
-
-		@Override
-        protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
-			return session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( insertSQL, keyColumns );
-		}
-
-		@Override
-        protected Serializable executeAndExtract(PreparedStatement insert) throws SQLException {
-			insert.executeUpdate();
-			return IdentifierGeneratorHelper.getGeneratedIdentity(
-					insert.getGeneratedKeys(),
-			        getPersister().getIdentifierType()
-			);
-		}
-	}
-
-	public static class NoCommentsInsert extends IdentifierGeneratingInsert {
-		public NoCommentsInsert(Dialect dialect) {
-			super( dialect );
-		}
-
-		@Override
-        public Insert setComment(String comment) {
-			// don't allow comments on these insert statements as comments totally
-			// blow up the Oracle getGeneratedKeys "support" :(
-            LOG.disallowingInsertStatementComment();
-			return this;
-		}
-	}
-}
+
+import java.io.Serializable;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.util.Properties;
+import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.MappingException;
+import org.hibernate.dialect.Dialect;
+import org.hibernate.engine.SessionImplementor;
+import org.hibernate.id.insert.AbstractReturningDelegate;
+import org.hibernate.id.insert.IdentifierGeneratingInsert;
+import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
+import org.hibernate.sql.Insert;
+import org.hibernate.type.Type;
+import org.jboss.logging.Logger;
+
+/**
+ * A generator which combines sequence generation with immediate retrieval
+ * through JDBC3 {@link java.sql.Connection#prepareStatement(String, String[]) getGeneratedKeys}.
+ * In this respect it works much like ANSI-SQL IDENTITY generation.
+ * <p/>
+ * This generator only known to work with newer Oracle drivers compiled for
+ * JDK 1.4 (JDBC3).
+ * <p/>
+ * Note: Due to a bug in Oracle drivers, sql comments on these insert statements
+ * are completely disabled.
+ *
+ * @author Steve Ebersole
+ */
+public class SequenceIdentityGenerator extends SequenceGenerator
+		implements PostInsertIdentifierGenerator {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
+                                                                       SequenceIdentityGenerator.class.getName());
+
+	@Override
+    public Serializable generate(SessionImplementor s, Object obj) {
+		return IdentifierGeneratorHelper.POST_INSERT_INDICATOR;
+	}
+
+	public InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
+			PostInsertIdentityPersister persister,
+	        Dialect dialect,
+	        boolean isGetGeneratedKeysEnabled) throws HibernateException {
+		return new Delegate( persister, dialect, getSequenceName() );
+	}
+
+	@Override
+    public void configure(Type type, Properties params, Dialect dialect) throws MappingException {
+		super.configure( type, params, dialect );
+	}
+
+	public static class Delegate extends AbstractReturningDelegate {
+		private final Dialect dialect;
+		private final String sequenceNextValFragment;
+		private final String[] keyColumns;
+
+		public Delegate(PostInsertIdentityPersister persister, Dialect dialect, String sequenceName) {
+			super( persister );
+			this.dialect = dialect;
+			this.sequenceNextValFragment = dialect.getSelectSequenceNextValString( sequenceName );
+			this.keyColumns = getPersister().getRootTableKeyColumnNames();
+			if ( keyColumns.length > 1 ) {
+				throw new HibernateException( "sequence-identity generator cannot be used with with multi-column keys" );
+			}
+		}
+
+		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
+			NoCommentsInsert insert = new NoCommentsInsert( dialect );
+			insert.addColumn( getPersister().getRootTableKeyColumnNames()[0], sequenceNextValFragment );
+			return insert;
+		}
+
+		@Override
+        protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
+			return session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( insertSQL, keyColumns );
+		}
+
+		@Override
+        protected Serializable executeAndExtract(PreparedStatement insert) throws SQLException {
+			insert.executeUpdate();
+			return IdentifierGeneratorHelper.getGeneratedIdentity(
+					insert.getGeneratedKeys(),
+			        getPersister().getIdentifierType()
+			);
+		}
+	}
+
+	public static class NoCommentsInsert extends IdentifierGeneratingInsert {
+		public NoCommentsInsert(Dialect dialect) {
+			super( dialect );
+		}
+
+		@Override
+        public Insert setComment(String comment) {
+			// don't allow comments on these insert statements as comments totally
+			// blow up the Oracle getGeneratedKeys "support" :(
+            LOG.disallowingInsertStatementComment();
+			return this;
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/id/TableGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/TableGenerator.java
index cfe9a4104d..48ad3bb580 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/TableGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/TableGenerator.java
@@ -1,226 +1,226 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * An <tt>IdentifierGenerator</tt> that uses a database
  * table to store the last generated value. It is not
  * intended that applications use this strategy directly.
  * However, it may be used to build other (efficient)
  * strategies. The returned type is any supported by
  * {@link IntegralDataTypeHolder}
  * <p/>
  * The value MUST be fetched in a separate transaction
  * from that of the main {@link SessionImplementor session}
  * transaction so the generator must be able to obtain a new
  * connection and commit it. Hence this implementation may only
  * be used when Hibernate is fetching connections, not when the
  * user is supplying connections.
  * <p/>
  * Again, the return types supported here are any of the ones
  * supported by {@link IntegralDataTypeHolder}.  This is new
  * as of 3.5.  Prior to that this generator only returned {@link Integer}
  * values.
  * <p/>
  * Mapping parameters supported: table, column
  *
  * @see TableHiLoGenerator
  * @author Gavin King
  */
 public class TableGenerator implements PersistentIdentifierGenerator, Configurable {
 	/* COLUMN and TABLE should be renamed but it would break the public API */
 	/** The column parameter */
 	public static final String COLUMN = "column";
 
 	/** Default column name */
 	public static final String DEFAULT_COLUMN_NAME = "next_hi";
 
 	/** The table parameter */
 	public static final String TABLE = "table";
 
 	/** Default table name */
 	public static final String DEFAULT_TABLE_NAME = "hibernate_unique_key";
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TableGenerator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TableGenerator.class.getName());
 
 	private Type identifierType;
 	private String tableName;
 	private String columnName;
 	private String query;
 	private String update;
 
 	public void configure(Type type, Properties params, Dialect dialect) {
 		identifierType = type;
 
 		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 
 		tableName = ConfigurationHelper.getString( TABLE, params, DEFAULT_TABLE_NAME );
 		if ( tableName.indexOf( '.' ) < 0 ) {
 			final String schemaName = normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) );
 			final String catalogName = normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) );
 			tableName = Table.qualify(
 					dialect.quote( catalogName ),
 					dialect.quote( schemaName ),
 					dialect.quote( tableName )
 			);
 		}
 		else {
 			// if already qualified there is not much we can do in a portable manner so we pass it
 			// through and assume the user has set up the name correctly.
 		}
 
 		columnName = dialect.quote(
 				normalizer.normalizeIdentifierQuoting(
 						ConfigurationHelper.getString( COLUMN, params, DEFAULT_COLUMN_NAME )
 				)
 		);
 
 		query = "select " +
 			columnName +
 			" from " +
 			dialect.appendLockHint(LockMode.PESSIMISTIC_WRITE, tableName) +
 			dialect.getForUpdateString();
 
 		update = "update " +
 			tableName +
 			" set " +
 			columnName +
 			" = ? where " +
 			columnName +
 			" = ?";
 	}
 
 	public synchronized Serializable generate(SessionImplementor session, Object object) {
 		return generateHolder( session ).makeValue();
 	}
 
 	protected IntegralDataTypeHolder generateHolder(SessionImplementor session) {
 		final SqlStatementLogger statementLogger = session
 				.getFactory()
 				.getServiceRegistry()
 				.getService( JdbcServices.class )
 				.getSqlStatementLogger();
 		return session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork(
 				new AbstractReturningWork<IntegralDataTypeHolder>() {
 					@Override
 					public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
 						IntegralDataTypeHolder value = buildHolder();
 						int rows;
 						do {
 							// The loop ensures atomicity of the
 							// select + update even for no transaction
 							// or read committed isolation level
 
 							statementLogger.logStatement( query, FormatStyle.BASIC.getFormatter() );
 							PreparedStatement qps = connection.prepareStatement( query );
 							try {
 								ResultSet rs = qps.executeQuery();
 								if ( !rs.next() ) {
 									String err = "could not read a hi value - you need to populate the table: " + tableName;
 									LOG.error(err);
 									throw new IdentifierGenerationException(err);
 								}
 								value.initialize( rs, 1 );
 								rs.close();
 							}
 							catch (SQLException e) {
 								LOG.error("Could not read a hi value", e);
 								throw e;
 							}
 							finally {
 								qps.close();
 							}
 
 							statementLogger.logStatement( update, FormatStyle.BASIC.getFormatter() );
 							PreparedStatement ups = connection.prepareStatement(update);
 							try {
 								value.copy().increment().bind( ups, 1 );
 								value.bind( ups, 2 );
 								rows = ups.executeUpdate();
 							}
 							catch (SQLException sqle) {
 								LOG.error(LOG.unableToUpdateHiValue(tableName), sqle);
 								throw sqle;
 							}
 							finally {
 								ups.close();
 							}
 						}
 						while (rows==0);
 						return value;
 					}
 				},
 				true
 		);
 	}
 
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		return new String[] {
 			dialect.getCreateTableString() + " " + tableName + " ( " + columnName + " " + dialect.getTypeName(Types.INTEGER) + " )",
 			"insert into " + tableName + " values ( 0 )"
 		};
 	}
 
 	public String[] sqlDropStrings(Dialect dialect) {
 		StringBuffer sqlDropString = new StringBuffer( "drop table " );
 		if ( dialect.supportsIfExistsBeforeTableName() ) {
 			sqlDropString.append( "if exists " );
 		}
 		sqlDropString.append( tableName ).append( dialect.getCascadeConstraintsString() );
 		if ( dialect.supportsIfExistsAfterTableName() ) {
 			sqlDropString.append( " if exists" );
 		}
 		return new String[] { sqlDropString.toString() };
 	}
 
 	public Object generatorKey() {
 		return tableName;
 	}
 
 	protected IntegralDataTypeHolder buildHolder() {
 		return IdentifierGeneratorHelper.getIntegralDataTypeHolder( identifierType.getReturnedClass() );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/UUIDGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/UUIDGenerator.java
index 60321c8dea..0b870f45b8 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/UUIDGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/UUIDGenerator.java
@@ -1,116 +1,116 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.util.Properties;
 import java.util.UUID;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.id.uuid.StandardRandomStrategy;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.Type;
 import org.hibernate.type.descriptor.java.UUIDTypeDescriptor;
 import org.jboss.logging.Logger;
 
 /**
  * An {@link IdentifierGenerator} which generates {@link UUID} values using a pluggable
  * {@link UUIDGenerationStrategy generation strategy}.  The values this generator can return
  * include {@link UUID}, {@link String} and byte[16]
  * <p/>
  * Supports 2 config parameters:<ul>
  * <li>{@link #UUID_GEN_STRATEGY} - names the {@link UUIDGenerationStrategy} instance to use</li>
  * <li>{@link #UUID_GEN_STRATEGY_CLASS} - names the {@link UUIDGenerationStrategy} class to use</li>
  * </ul>
  * <p/>
  * Currently there are 2 standard implementations of {@link UUIDGenerationStrategy}:<ul>
  * <li>{@link StandardRandomStrategy} (the default, if none specified)</li>
  * <li>{@link org.hibernate.id.uuid.CustomVersionOneStrategy}</li>
  * </ul>
  *
  * @author Steve Ebersole
  */
 public class UUIDGenerator implements IdentifierGenerator, Configurable {
 	public static final String UUID_GEN_STRATEGY = "uuid_gen_strategy";
 	public static final String UUID_GEN_STRATEGY_CLASS = "uuid_gen_strategy_class";
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, UUIDGenerator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, UUIDGenerator.class.getName());
 
 	private UUIDGenerationStrategy strategy;
 	private UUIDTypeDescriptor.ValueTransformer valueTransformer;
 
 	public static UUIDGenerator buildSessionFactoryUniqueIdentifierGenerator() {
 		final UUIDGenerator generator = new UUIDGenerator();
 		generator.strategy = StandardRandomStrategy.INSTANCE;
 		generator.valueTransformer = UUIDTypeDescriptor.ToStringTransformer.INSTANCE;
 		return generator;
 	}
 
 	public void configure(Type type, Properties params, Dialect d) throws MappingException {
 		// check first for the strategy instance
 		strategy = (UUIDGenerationStrategy) params.get( UUID_GEN_STRATEGY );
 		if ( strategy == null ) {
 			// next check for the strategy class
 			final String strategyClassName = params.getProperty( UUID_GEN_STRATEGY_CLASS );
 			if ( strategyClassName != null ) {
 				try {
 					final Class strategyClass = ReflectHelper.classForName( strategyClassName );
 					try {
 						strategy = (UUIDGenerationStrategy) strategyClass.newInstance();
 					}
 					catch ( Exception ignore ) {
                         LOG.unableToInstantiateUuidGenerationStrategy(ignore);
 					}
 				}
 				catch ( ClassNotFoundException ignore ) {
                     LOG.unableToLocateUuidGenerationStrategy(strategyClassName);
 				}
 			}
 		}
 		if ( strategy == null ) {
 			// lastly use the standard random generator
 			strategy = StandardRandomStrategy.INSTANCE;
 		}
 
 		if ( UUID.class.isAssignableFrom( type.getReturnedClass() ) ) {
 			valueTransformer = UUIDTypeDescriptor.PassThroughTransformer.INSTANCE;
 		}
 		else if ( String.class.isAssignableFrom( type.getReturnedClass() ) ) {
 			valueTransformer = UUIDTypeDescriptor.ToStringTransformer.INSTANCE;
 		}
 		else if ( byte[].class.isAssignableFrom( type.getReturnedClass() ) ) {
 			valueTransformer = UUIDTypeDescriptor.ToBytesTransformer.INSTANCE;
 		}
 		else {
 			throw new HibernateException( "Unanticipated return type [" + type.getReturnedClass().getName() + "] for UUID conversion" );
 		}
 	}
 
 	public Serializable generate(SessionImplementor session, Object object) throws HibernateException {
 		return valueTransformer.transform( strategy.generateUUID( session ) );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
index 289de57b2d..e46833cc88 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
@@ -1,94 +1,95 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 import java.io.Serializable;
 import java.util.Properties;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * <b>uuid</b><br>
  * <br>
  * A <tt>UUIDGenerator</tt> that returns a string of length 32,
  * This string will consist of only hex digits. Optionally,
  * the string may be generated with separators between each
  * component of the UUID.
  *
  * Mapping parameters supported: separator.
  *
  * @author Gavin King
  */
 public class UUIDHexGenerator extends AbstractUUIDGenerator implements Configurable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, UUIDHexGenerator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, UUIDHexGenerator.class.getName());
 
 	private static boolean warned = false;
 
 	private String sep = "";
 
 	public UUIDHexGenerator() {
 		if ( ! warned ) {
 			warned = true;
             LOG.usingUuidHexGenerator(this.getClass().getName(), UUIDGenerator.class.getName());
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void configure(Type type, Properties params, Dialect d) {
 		sep = ConfigurationHelper.getString( "separator", params, "" );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Serializable generate(SessionImplementor session, Object obj) {
 		return new StringBuffer( 36 )
 				.append( format( getIP() ) ).append( sep )
 				.append( format( getJVM() ) ).append( sep )
 				.append( format( getHiTime() ) ).append( sep )
 				.append( format( getLoTime() ) ).append( sep )
 				.append( format( getCount() ) )
 				.toString();
 	}
 
 	protected String format(int intValue) {
 		String formatted = Integer.toHexString( intValue );
 		StringBuffer buf = new StringBuffer( "00000000" );
 		buf.replace( 8 - formatted.length(), 8, formatted );
 		return buf.toString();
 	}
 
 	protected String format(short shortValue) {
 		String formatted = Integer.toHexString( shortValue );
 		StringBuffer buf = new StringBuffer( "0000" );
 		buf.replace( 4 - formatted.length(), 4, formatted );
 		return buf.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/enhanced/OptimizerFactory.java b/hibernate-core/src/main/java/org/hibernate/id/enhanced/OptimizerFactory.java
index 78a174e657..aa55471b8f 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/enhanced/OptimizerFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/enhanced/OptimizerFactory.java
@@ -1,494 +1,495 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
 package org.hibernate.id.enhanced;
-
-import java.io.Serializable;
-import java.lang.reflect.Constructor;
-import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.id.IntegralDataTypeHolder;
-import org.hibernate.internal.util.ReflectHelper;
-import org.jboss.logging.Logger;
-
-/**
- * Factory for {@link Optimizer} instances.
- *
- * @author Steve Ebersole
- */
-public class OptimizerFactory {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, OptimizerFactory.class.getName());
-
-	public static final String NONE = "none";
-	public static final String HILO = "hilo";
-	public static final String LEGACY_HILO = "legacy-hilo";
-	public static final String POOL = "pooled";
-	public static final String POOL_LO = "pooled-lo";
-
-	private static Class[] CTOR_SIG = new Class[] { Class.class, int.class };
-
-	/**
-	 * Marker interface for optimizer which wish to know the user-specified initial value.
-	 * <p/>
-	 * Used instead of constructor injection since that is already a public understanding and
-	 * because not all optimizers care.
-	 */
-	public static interface InitialValueAwareOptimizer {
-		/**
-		 * Reports the user specified initial value to the optimizer.
-		 * <p/>
-		 * <tt>-1</tt> is used to indicate that the user did not specify.
-		 *
-		 * @param initialValue The initial value specified by the user, or <tt>-1</tt> to indicate that the
-		 * user did not specify.
-		 */
-		public void injectInitialValue(long initialValue);
-	}
-
-	/**
-	 * Builds an optimizer
-	 *
-	 * @param type The optimizer type, either a short-hand name or the {@link Optimizer} class name.
-	 * @param returnClass The generated value java type
-	 * @param incrementSize The increment size.
-	 *
-	 * @return The built optimizer
-	 *
-	 * @deprecated Use {@link #buildOptimizer(String, Class, int, long)} instead
-	 */
-	@Deprecated
-    @SuppressWarnings({ "UnnecessaryBoxing" })
-	public static Optimizer buildOptimizer(String type, Class returnClass, int incrementSize) {
-		String optimizerClassName;
-		if ( NONE.equals( type ) ) {
-			optimizerClassName = NoopOptimizer.class.getName();
-		}
-		else if ( HILO.equals( type ) ) {
-			optimizerClassName = HiLoOptimizer.class.getName();
-		}
-		else if ( LEGACY_HILO.equals( type ) ) {
-			optimizerClassName = LegacyHiLoAlgorithmOptimizer.class.getName();
-		}
-		else if ( POOL.equals( type ) ) {
-			optimizerClassName = PooledOptimizer.class.getName();
-		}
-		else if ( POOL_LO.equals( type ) ) {
-			optimizerClassName = PooledLoOptimizer.class.getName();
-		}
-		else {
-			optimizerClassName = type;
-		}
-
-		try {
-			Class optimizerClass = ReflectHelper.classForName( optimizerClassName );
-			Constructor ctor = optimizerClass.getConstructor( CTOR_SIG );
-			return ( Optimizer ) ctor.newInstance( returnClass, Integer.valueOf( incrementSize ) );
-		}
-		catch( Throwable ignore ) {
-            LOG.unableToInstantiateOptimizer(type);
-		}
-
-		// the default...
-		return new NoopOptimizer( returnClass, incrementSize );
-	}
-
-
-	/**
-	 * Builds an optimizer
-	 *
-	 * @param type The optimizer type, either a short-hand name or the {@link Optimizer} class name.
-	 * @param returnClass The generated value java type
-	 * @param incrementSize The increment size.
-	 * @param explicitInitialValue The user supplied initial-value (-1 indicates the user did not specify).
-	 *
-	 * @return The built optimizer
-	 */
-	@SuppressWarnings({ "UnnecessaryBoxing", "deprecation" })
-	public static Optimizer buildOptimizer(String type, Class returnClass, int incrementSize, long explicitInitialValue) {
-		final Optimizer optimizer = buildOptimizer( type, returnClass, incrementSize );
-		if ( InitialValueAwareOptimizer.class.isInstance( optimizer ) ) {
-			( (InitialValueAwareOptimizer) optimizer ).injectInitialValue( explicitInitialValue );
-		}
-		return optimizer;
-	}
-
-	/**
-	 * Common support for optimizer implementations.
-	 */
-	public static abstract class OptimizerSupport implements Optimizer {
-		protected final Class returnClass;
-		protected final int incrementSize;
-
-		/**
-		 * Construct an optimizer
-		 *
-		 * @param returnClass The expected id class.
-		 * @param incrementSize The increment size
-		 */
-		protected OptimizerSupport(Class returnClass, int incrementSize) {
-			if ( returnClass == null ) {
-				throw new HibernateException( "return class is required" );
-			}
-			this.returnClass = returnClass;
-			this.incrementSize = incrementSize;
-		}
-
-		/**
-		 * Getter for property 'returnClass'.  This is the Java
-		 * class which is used to represent the id (e.g. {@link java.lang.Long}).
-		 *
-		 * @return Value for property 'returnClass'.
-		 */
-		public final Class getReturnClass() {
-			return returnClass;
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public final int getIncrementSize() {
-			return incrementSize;
-		}
-	}
-
-	/**
-	 * An optimizer that performs no optimization.  The database is hit for
-	 * every request.
-	 */
-	public static class NoopOptimizer extends OptimizerSupport {
-		private IntegralDataTypeHolder lastSourceValue;
-
-		public NoopOptimizer(Class returnClass, int incrementSize) {
-			super( returnClass, incrementSize );
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public Serializable generate(AccessCallback callback) {
-			// IMPL NOTE : it is incredibly important that the method-local variable be used here to
-			//		avoid concurrency issues.
-			IntegralDataTypeHolder value = null;
-			while ( value == null || value.lt( 1 ) ) {
-				value = callback.getNextValue();
-			}
-			lastSourceValue = value;
-			return value.makeValue();
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public IntegralDataTypeHolder getLastSourceValue() {
-			return lastSourceValue;
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public boolean applyIncrementSizeToSourceValues() {
-			return false;
-		}
-	}
-
-	/**
-	 * Optimizer which applies a 'hilo' algorithm in memory to achieve
-	 * optimization.
-	 * <p/>
-	 * A 'hilo' algorithm is simply a means for a single value stored in the
-	 * database to represent a "bucket" of possible, contiguous values.  The
-	 * database value identifies which particular bucket we are on.
-	 * <p/>
-	 * This database value must be paired with another value that defines the
-	 * size of the bucket; the number of possible values available.
-	 * The {@link #getIncrementSize() incrementSize} serves this purpose.  The
-	 * naming here is meant more for consistency in that this value serves the
-	 * same purpose as the increment supplied to the {@link PooledOptimizer}.
-	 * <p/>
-	 * The general algorithms used to determine the bucket are:<ol>
-	 * <li>{@code upperLimit = (databaseValue * incrementSize) + 1}</li>
-	 * <li>{@code lowerLimit = upperLimit - 1}</li>
-	 * </ol>
-	 * As an example, consider a case with incrementSize of 10.  Initially the
-	 * database holds 1:<ol>
-	 * <li>{@code upperLimit = (1 * 20) + 1 = 21}</li>
-	 * <li>{@code lowerLimit = 21 - 20 = 1}</li>
-	 * </ol>
-	 * From there we increment the value from lowerLimit until we reach the
-	 * upperLimit, at which point we would define a new bucket.  The database
-	 * now contains 2, though incrementSize remains unchanged:<ol>
-	 * <li>{@code upperLimit = (2 * 20) + 1 = 41}</li>
-	 * <li>{@code lowerLimit = 41 - 20 = 21}</li>
-	 * </ol>
-	 * And so on...
-	 * <p/>
-	 * Note, 'value' always (after init) holds the next value to return
-	 */
-	public static class HiLoOptimizer extends OptimizerSupport {
-		private IntegralDataTypeHolder lastSourceValue;
-		private IntegralDataTypeHolder upperLimit;
-		private IntegralDataTypeHolder value;
-
-		public HiLoOptimizer(Class returnClass, int incrementSize) {
-			super( returnClass, incrementSize );
-            if (incrementSize < 1) throw new HibernateException("increment size cannot be less than 1");
-            LOG.trace("Creating hilo optimizer with [incrementSize=" + incrementSize + "; returnClass=" + returnClass.getName()
-                      + "]");
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public synchronized Serializable generate(AccessCallback callback) {
-			if ( lastSourceValue == null ) {
-				// first call, so initialize ourselves.  we need to read the database
-				// value and set up the 'bucket' boundaries
-				lastSourceValue = callback.getNextValue();
-				while ( lastSourceValue.lt( 1 ) ) {
-					lastSourceValue = callback.getNextValue();
-				}
-				// upperLimit defines the upper end of the bucket values
-				upperLimit = lastSourceValue.copy().multiplyBy( incrementSize ).increment();
-				// initialize value to the low end of the bucket
-				value = upperLimit.copy().subtract( incrementSize );
-			}
-			else if ( ! upperLimit.gt( value ) ) {
-				lastSourceValue = callback.getNextValue();
-				upperLimit = lastSourceValue.copy().multiplyBy( incrementSize ).increment();
-			}
-			return value.makeValueThenIncrement();
-		}
-
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public IntegralDataTypeHolder getLastSourceValue() {
-			return lastSourceValue;
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public boolean applyIncrementSizeToSourceValues() {
-			return false;
-		}
-
-		/**
-		 * Getter for property 'lastValue'.
-		 * <p/>
-		 * Exposure intended for testing purposes.
-		 *
-		 * @return Value for property 'lastValue'.
-		 */
-		public IntegralDataTypeHolder getLastValue() {
-			return value.copy().decrement();
-		}
-
-		/**
-		 * Getter for property 'upperLimit'.
-		 * <p/>
-		 * Exposure intended for testing purposes.
-		 *
-		 * @return Value for property 'upperLimit'.
-		 */
-		public IntegralDataTypeHolder getHiValue() {
-			return upperLimit;
-		}
-	}
-
-	public static class LegacyHiLoAlgorithmOptimizer extends OptimizerSupport {
-		private long maxLo;
-		private long lo;
-		private IntegralDataTypeHolder hi;
-
-		private IntegralDataTypeHolder lastSourceValue;
-		private IntegralDataTypeHolder value;
-
-
-		public LegacyHiLoAlgorithmOptimizer(Class returnClass, int incrementSize) {
-			super( returnClass, incrementSize );
-            if (incrementSize < 1) throw new HibernateException("increment size cannot be less than 1");
-            LOG.trace("Creating hilo optimizer (legacy) with [incrementSize=" + incrementSize + "; returnClass="
-                      + returnClass.getName() + "]");
-			maxLo = incrementSize;
-			lo = maxLo+1;
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public synchronized Serializable generate(AccessCallback callback) {
-			if ( lo > maxLo ) {
-				lastSourceValue = callback.getNextValue();
-				lo = lastSourceValue.eq( 0 ) ? 1 : 0;
-				hi = lastSourceValue.copy().multiplyBy( maxLo+1 );
-			}
-			value = hi.copy().add( lo++ );
-			return value.makeValue();
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public IntegralDataTypeHolder getLastSourceValue() {
-			return lastSourceValue.copy();
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public boolean applyIncrementSizeToSourceValues() {
-			return false;
-		}
-
-		/**
-		 * Getter for property 'lastValue'.
-		 * <p/>
-		 * Exposure intended for testing purposes.
-		 *
-		 * @return Value for property 'lastValue'.
-		 */
-		public IntegralDataTypeHolder getLastValue() {
-			return value;
-		}
-	}
-
-	/**
-	 * Optimizer which uses a pool of values, storing the next low value of the
-	 * range in the database.
-	 * <p/>
-	 * Note that this optimizer works essentially the same as the
-	 * {@link HiLoOptimizer} except that here the bucket ranges are actually
-	 * encoded into the database structures.
-	 * <p/>
-	 * Note if you prefer that the database value be interpreted as the bottom end of our current range,
-	 * then use the {@link PooledLoOptimizer} strategy
-	 */
-	public static class PooledOptimizer extends OptimizerSupport implements InitialValueAwareOptimizer {
-		private IntegralDataTypeHolder hiValue;
-		private IntegralDataTypeHolder value;
-		private long initialValue = -1;
-
-		public PooledOptimizer(Class returnClass, int incrementSize) {
-			super( returnClass, incrementSize );
-			if ( incrementSize < 1 ) {
-				throw new HibernateException( "increment size cannot be less than 1" );
-			}
-            LOG.trace("Creating pooled optimizer with [incrementSize=" + incrementSize + "; returnClass=" + returnClass.getName()
-                      + "]");
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public synchronized Serializable generate(AccessCallback callback) {
-			if ( hiValue == null ) {
-				value = callback.getNextValue();
-                // unfortunately not really safe to normalize this
-                // to 1 as an initial value like we do the others
-                // because we would not be able to control this if
-                // we are using a sequence...
-                if (value.lt(1)) LOG.pooledOptimizerReportedInitialValue(value);
-                // the call to obtain next-value just gave us the initialValue
-                if ((initialValue == -1 && value.lt(incrementSize)) || value.eq(initialValue)) hiValue = callback.getNextValue();
-				else {
-					hiValue = value;
-					value = hiValue.copy().subtract( incrementSize );
-				}
-			}
-			else if ( ! hiValue.gt( value ) ) {
-				hiValue = callback.getNextValue();
-				value = hiValue.copy().subtract( incrementSize );
-			}
-			return value.makeValueThenIncrement();
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public IntegralDataTypeHolder getLastSourceValue() {
-			return hiValue;
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public boolean applyIncrementSizeToSourceValues() {
-			return true;
-		}
-
-		/**
-		 * Getter for property 'lastValue'.
-		 * <p/>
-		 * Exposure intended for testing purposes.
-		 *
-		 * @return Value for property 'lastValue'.
-		 */
-		public IntegralDataTypeHolder getLastValue() {
-			return value.copy().decrement();
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public void injectInitialValue(long initialValue) {
-			this.initialValue = initialValue;
-		}
-	}
-
-	public static class PooledLoOptimizer extends OptimizerSupport {
-		private IntegralDataTypeHolder lastSourceValue; // last value read from db source
-		private IntegralDataTypeHolder value; // the current generator value
-
-		public PooledLoOptimizer(Class returnClass, int incrementSize) {
-			super( returnClass, incrementSize );
-			if ( incrementSize < 1 ) {
-				throw new HibernateException( "increment size cannot be less than 1" );
-			}
-            LOG.trace("Creating pooled optimizer (lo) with [incrementSize=" + incrementSize + "; returnClass="
-                      + returnClass.getName() + "]");
-		}
-
-		public Serializable generate(AccessCallback callback) {
-			if ( lastSourceValue == null || ! value.lt( lastSourceValue.copy().add( incrementSize ) ) ) {
-				lastSourceValue = callback.getNextValue();
-				value = lastSourceValue.copy();
-				// handle cases where initial-value is less that one (hsqldb for instance).
-				while ( value.lt( 1 ) ) {
-					value.increment();
-				}
-			}
-			return value.makeValueThenIncrement();
-		}
-
-		public IntegralDataTypeHolder getLastSourceValue() {
-			return lastSourceValue;
-		}
-
-		public boolean applyIncrementSizeToSourceValues() {
-			return true;
-		}
-	}
-}
+
+import java.io.Serializable;
+import java.lang.reflect.Constructor;
+import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.id.IntegralDataTypeHolder;
+import org.hibernate.internal.util.ReflectHelper;
+
+import org.jboss.logging.Logger;
+
+/**
+ * Factory for {@link Optimizer} instances.
+ *
+ * @author Steve Ebersole
+ */
+public class OptimizerFactory {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, OptimizerFactory.class.getName());
+
+	public static final String NONE = "none";
+	public static final String HILO = "hilo";
+	public static final String LEGACY_HILO = "legacy-hilo";
+	public static final String POOL = "pooled";
+	public static final String POOL_LO = "pooled-lo";
+
+	private static Class[] CTOR_SIG = new Class[] { Class.class, int.class };
+
+	/**
+	 * Marker interface for optimizer which wish to know the user-specified initial value.
+	 * <p/>
+	 * Used instead of constructor injection since that is already a public understanding and
+	 * because not all optimizers care.
+	 */
+	public static interface InitialValueAwareOptimizer {
+		/**
+		 * Reports the user specified initial value to the optimizer.
+		 * <p/>
+		 * <tt>-1</tt> is used to indicate that the user did not specify.
+		 *
+		 * @param initialValue The initial value specified by the user, or <tt>-1</tt> to indicate that the
+		 * user did not specify.
+		 */
+		public void injectInitialValue(long initialValue);
+	}
+
+	/**
+	 * Builds an optimizer
+	 *
+	 * @param type The optimizer type, either a short-hand name or the {@link Optimizer} class name.
+	 * @param returnClass The generated value java type
+	 * @param incrementSize The increment size.
+	 *
+	 * @return The built optimizer
+	 *
+	 * @deprecated Use {@link #buildOptimizer(String, Class, int, long)} instead
+	 */
+	@Deprecated
+    @SuppressWarnings({ "UnnecessaryBoxing" })
+	public static Optimizer buildOptimizer(String type, Class returnClass, int incrementSize) {
+		String optimizerClassName;
+		if ( NONE.equals( type ) ) {
+			optimizerClassName = NoopOptimizer.class.getName();
+		}
+		else if ( HILO.equals( type ) ) {
+			optimizerClassName = HiLoOptimizer.class.getName();
+		}
+		else if ( LEGACY_HILO.equals( type ) ) {
+			optimizerClassName = LegacyHiLoAlgorithmOptimizer.class.getName();
+		}
+		else if ( POOL.equals( type ) ) {
+			optimizerClassName = PooledOptimizer.class.getName();
+		}
+		else if ( POOL_LO.equals( type ) ) {
+			optimizerClassName = PooledLoOptimizer.class.getName();
+		}
+		else {
+			optimizerClassName = type;
+		}
+
+		try {
+			Class optimizerClass = ReflectHelper.classForName( optimizerClassName );
+			Constructor ctor = optimizerClass.getConstructor( CTOR_SIG );
+			return ( Optimizer ) ctor.newInstance( returnClass, Integer.valueOf( incrementSize ) );
+		}
+		catch( Throwable ignore ) {
+            LOG.unableToInstantiateOptimizer(type);
+		}
+
+		// the default...
+		return new NoopOptimizer( returnClass, incrementSize );
+	}
+
+
+	/**
+	 * Builds an optimizer
+	 *
+	 * @param type The optimizer type, either a short-hand name or the {@link Optimizer} class name.
+	 * @param returnClass The generated value java type
+	 * @param incrementSize The increment size.
+	 * @param explicitInitialValue The user supplied initial-value (-1 indicates the user did not specify).
+	 *
+	 * @return The built optimizer
+	 */
+	@SuppressWarnings({ "UnnecessaryBoxing", "deprecation" })
+	public static Optimizer buildOptimizer(String type, Class returnClass, int incrementSize, long explicitInitialValue) {
+		final Optimizer optimizer = buildOptimizer( type, returnClass, incrementSize );
+		if ( InitialValueAwareOptimizer.class.isInstance( optimizer ) ) {
+			( (InitialValueAwareOptimizer) optimizer ).injectInitialValue( explicitInitialValue );
+		}
+		return optimizer;
+	}
+
+	/**
+	 * Common support for optimizer implementations.
+	 */
+	public static abstract class OptimizerSupport implements Optimizer {
+		protected final Class returnClass;
+		protected final int incrementSize;
+
+		/**
+		 * Construct an optimizer
+		 *
+		 * @param returnClass The expected id class.
+		 * @param incrementSize The increment size
+		 */
+		protected OptimizerSupport(Class returnClass, int incrementSize) {
+			if ( returnClass == null ) {
+				throw new HibernateException( "return class is required" );
+			}
+			this.returnClass = returnClass;
+			this.incrementSize = incrementSize;
+		}
+
+		/**
+		 * Getter for property 'returnClass'.  This is the Java
+		 * class which is used to represent the id (e.g. {@link java.lang.Long}).
+		 *
+		 * @return Value for property 'returnClass'.
+		 */
+		public final Class getReturnClass() {
+			return returnClass;
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public final int getIncrementSize() {
+			return incrementSize;
+		}
+	}
+
+	/**
+	 * An optimizer that performs no optimization.  The database is hit for
+	 * every request.
+	 */
+	public static class NoopOptimizer extends OptimizerSupport {
+		private IntegralDataTypeHolder lastSourceValue;
+
+		public NoopOptimizer(Class returnClass, int incrementSize) {
+			super( returnClass, incrementSize );
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public Serializable generate(AccessCallback callback) {
+			// IMPL NOTE : it is incredibly important that the method-local variable be used here to
+			//		avoid concurrency issues.
+			IntegralDataTypeHolder value = null;
+			while ( value == null || value.lt( 1 ) ) {
+				value = callback.getNextValue();
+			}
+			lastSourceValue = value;
+			return value.makeValue();
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public IntegralDataTypeHolder getLastSourceValue() {
+			return lastSourceValue;
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public boolean applyIncrementSizeToSourceValues() {
+			return false;
+		}
+	}
+
+	/**
+	 * Optimizer which applies a 'hilo' algorithm in memory to achieve
+	 * optimization.
+	 * <p/>
+	 * A 'hilo' algorithm is simply a means for a single value stored in the
+	 * database to represent a "bucket" of possible, contiguous values.  The
+	 * database value identifies which particular bucket we are on.
+	 * <p/>
+	 * This database value must be paired with another value that defines the
+	 * size of the bucket; the number of possible values available.
+	 * The {@link #getIncrementSize() incrementSize} serves this purpose.  The
+	 * naming here is meant more for consistency in that this value serves the
+	 * same purpose as the increment supplied to the {@link PooledOptimizer}.
+	 * <p/>
+	 * The general algorithms used to determine the bucket are:<ol>
+	 * <li>{@code upperLimit = (databaseValue * incrementSize) + 1}</li>
+	 * <li>{@code lowerLimit = upperLimit - 1}</li>
+	 * </ol>
+	 * As an example, consider a case with incrementSize of 10.  Initially the
+	 * database holds 1:<ol>
+	 * <li>{@code upperLimit = (1 * 20) + 1 = 21}</li>
+	 * <li>{@code lowerLimit = 21 - 20 = 1}</li>
+	 * </ol>
+	 * From there we increment the value from lowerLimit until we reach the
+	 * upperLimit, at which point we would define a new bucket.  The database
+	 * now contains 2, though incrementSize remains unchanged:<ol>
+	 * <li>{@code upperLimit = (2 * 20) + 1 = 41}</li>
+	 * <li>{@code lowerLimit = 41 - 20 = 21}</li>
+	 * </ol>
+	 * And so on...
+	 * <p/>
+	 * Note, 'value' always (after init) holds the next value to return
+	 */
+	public static class HiLoOptimizer extends OptimizerSupport {
+		private IntegralDataTypeHolder lastSourceValue;
+		private IntegralDataTypeHolder upperLimit;
+		private IntegralDataTypeHolder value;
+
+		public HiLoOptimizer(Class returnClass, int incrementSize) {
+			super( returnClass, incrementSize );
+            if (incrementSize < 1) throw new HibernateException("increment size cannot be less than 1");
+            LOG.trace("Creating hilo optimizer with [incrementSize=" + incrementSize + "; returnClass=" + returnClass.getName()
+                      + "]");
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public synchronized Serializable generate(AccessCallback callback) {
+			if ( lastSourceValue == null ) {
+				// first call, so initialize ourselves.  we need to read the database
+				// value and set up the 'bucket' boundaries
+				lastSourceValue = callback.getNextValue();
+				while ( lastSourceValue.lt( 1 ) ) {
+					lastSourceValue = callback.getNextValue();
+				}
+				// upperLimit defines the upper end of the bucket values
+				upperLimit = lastSourceValue.copy().multiplyBy( incrementSize ).increment();
+				// initialize value to the low end of the bucket
+				value = upperLimit.copy().subtract( incrementSize );
+			}
+			else if ( ! upperLimit.gt( value ) ) {
+				lastSourceValue = callback.getNextValue();
+				upperLimit = lastSourceValue.copy().multiplyBy( incrementSize ).increment();
+			}
+			return value.makeValueThenIncrement();
+		}
+
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public IntegralDataTypeHolder getLastSourceValue() {
+			return lastSourceValue;
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public boolean applyIncrementSizeToSourceValues() {
+			return false;
+		}
+
+		/**
+		 * Getter for property 'lastValue'.
+		 * <p/>
+		 * Exposure intended for testing purposes.
+		 *
+		 * @return Value for property 'lastValue'.
+		 */
+		public IntegralDataTypeHolder getLastValue() {
+			return value.copy().decrement();
+		}
+
+		/**
+		 * Getter for property 'upperLimit'.
+		 * <p/>
+		 * Exposure intended for testing purposes.
+		 *
+		 * @return Value for property 'upperLimit'.
+		 */
+		public IntegralDataTypeHolder getHiValue() {
+			return upperLimit;
+		}
+	}
+
+	public static class LegacyHiLoAlgorithmOptimizer extends OptimizerSupport {
+		private long maxLo;
+		private long lo;
+		private IntegralDataTypeHolder hi;
+
+		private IntegralDataTypeHolder lastSourceValue;
+		private IntegralDataTypeHolder value;
+
+
+		public LegacyHiLoAlgorithmOptimizer(Class returnClass, int incrementSize) {
+			super( returnClass, incrementSize );
+            if (incrementSize < 1) throw new HibernateException("increment size cannot be less than 1");
+            LOG.trace("Creating hilo optimizer (legacy) with [incrementSize=" + incrementSize + "; returnClass="
+                      + returnClass.getName() + "]");
+			maxLo = incrementSize;
+			lo = maxLo+1;
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public synchronized Serializable generate(AccessCallback callback) {
+			if ( lo > maxLo ) {
+				lastSourceValue = callback.getNextValue();
+				lo = lastSourceValue.eq( 0 ) ? 1 : 0;
+				hi = lastSourceValue.copy().multiplyBy( maxLo+1 );
+			}
+			value = hi.copy().add( lo++ );
+			return value.makeValue();
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public IntegralDataTypeHolder getLastSourceValue() {
+			return lastSourceValue.copy();
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public boolean applyIncrementSizeToSourceValues() {
+			return false;
+		}
+
+		/**
+		 * Getter for property 'lastValue'.
+		 * <p/>
+		 * Exposure intended for testing purposes.
+		 *
+		 * @return Value for property 'lastValue'.
+		 */
+		public IntegralDataTypeHolder getLastValue() {
+			return value;
+		}
+	}
+
+	/**
+	 * Optimizer which uses a pool of values, storing the next low value of the
+	 * range in the database.
+	 * <p/>
+	 * Note that this optimizer works essentially the same as the
+	 * {@link HiLoOptimizer} except that here the bucket ranges are actually
+	 * encoded into the database structures.
+	 * <p/>
+	 * Note if you prefer that the database value be interpreted as the bottom end of our current range,
+	 * then use the {@link PooledLoOptimizer} strategy
+	 */
+	public static class PooledOptimizer extends OptimizerSupport implements InitialValueAwareOptimizer {
+		private IntegralDataTypeHolder hiValue;
+		private IntegralDataTypeHolder value;
+		private long initialValue = -1;
+
+		public PooledOptimizer(Class returnClass, int incrementSize) {
+			super( returnClass, incrementSize );
+			if ( incrementSize < 1 ) {
+				throw new HibernateException( "increment size cannot be less than 1" );
+			}
+            LOG.trace("Creating pooled optimizer with [incrementSize=" + incrementSize + "; returnClass=" + returnClass.getName()
+                      + "]");
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public synchronized Serializable generate(AccessCallback callback) {
+			if ( hiValue == null ) {
+				value = callback.getNextValue();
+                // unfortunately not really safe to normalize this
+                // to 1 as an initial value like we do the others
+                // because we would not be able to control this if
+                // we are using a sequence...
+                if (value.lt(1)) LOG.pooledOptimizerReportedInitialValue(value);
+                // the call to obtain next-value just gave us the initialValue
+                if ((initialValue == -1 && value.lt(incrementSize)) || value.eq(initialValue)) hiValue = callback.getNextValue();
+				else {
+					hiValue = value;
+					value = hiValue.copy().subtract( incrementSize );
+				}
+			}
+			else if ( ! hiValue.gt( value ) ) {
+				hiValue = callback.getNextValue();
+				value = hiValue.copy().subtract( incrementSize );
+			}
+			return value.makeValueThenIncrement();
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public IntegralDataTypeHolder getLastSourceValue() {
+			return hiValue;
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public boolean applyIncrementSizeToSourceValues() {
+			return true;
+		}
+
+		/**
+		 * Getter for property 'lastValue'.
+		 * <p/>
+		 * Exposure intended for testing purposes.
+		 *
+		 * @return Value for property 'lastValue'.
+		 */
+		public IntegralDataTypeHolder getLastValue() {
+			return value.copy().decrement();
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public void injectInitialValue(long initialValue) {
+			this.initialValue = initialValue;
+		}
+	}
+
+	public static class PooledLoOptimizer extends OptimizerSupport {
+		private IntegralDataTypeHolder lastSourceValue; // last value read from db source
+		private IntegralDataTypeHolder value; // the current generator value
+
+		public PooledLoOptimizer(Class returnClass, int incrementSize) {
+			super( returnClass, incrementSize );
+			if ( incrementSize < 1 ) {
+				throw new HibernateException( "increment size cannot be less than 1" );
+			}
+            LOG.trace("Creating pooled optimizer (lo) with [incrementSize=" + incrementSize + "; returnClass="
+                      + returnClass.getName() + "]");
+		}
+
+		public Serializable generate(AccessCallback callback) {
+			if ( lastSourceValue == null || ! value.lt( lastSourceValue.copy().add( incrementSize ) ) ) {
+				lastSourceValue = callback.getNextValue();
+				value = lastSourceValue.copy();
+				// handle cases where initial-value is less that one (hsqldb for instance).
+				while ( value.lt( 1 ) ) {
+					value.increment();
+				}
+			}
+			return value.makeValueThenIncrement();
+		}
+
+		public IntegralDataTypeHolder getLastSourceValue() {
+			return lastSourceValue;
+		}
+
+		public boolean applyIncrementSizeToSourceValues() {
+			return true;
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStructure.java b/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStructure.java
index 6129c72ed6..e777777985 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStructure.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStructure.java
@@ -1,159 +1,160 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ *
+ */
 package org.hibernate.id.enhanced;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.dialect.Dialect;
-import org.hibernate.engine.SessionImplementor;
-import org.hibernate.id.IdentifierGeneratorHelper;
-import org.hibernate.id.IntegralDataTypeHolder;
-import org.jboss.logging.Logger;
-
-/**
- * Describes a sequence.
- *
- * @author Steve Ebersole
- */
-public class SequenceStructure implements DatabaseStructure {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SequenceStructure.class.getName());
-
-	private final String sequenceName;
-	private final int initialValue;
-	private final int incrementSize;
-	private final Class numberType;
-	private final String sql;
-	private boolean applyIncrementSizeToSourceValues;
-	private int accessCounter;
-
-	public SequenceStructure(
-			Dialect dialect,
-			String sequenceName,
-			int initialValue,
-			int incrementSize,
-			Class numberType) {
-		this.sequenceName = sequenceName;
-		this.initialValue = initialValue;
-		this.incrementSize = incrementSize;
-		this.numberType = numberType;
-		sql = dialect.getSequenceNextValString( sequenceName );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public String getName() {
-		return sequenceName;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public int getIncrementSize() {
-		return incrementSize;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public int getTimesAccessed() {
-		return accessCounter;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public int getInitialValue() {
-		return initialValue;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public AccessCallback buildCallback(final SessionImplementor session) {
-		return new AccessCallback() {
-			public IntegralDataTypeHolder getNextValue() {
-				accessCounter++;
-				try {
-					PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
-					try {
-						ResultSet rs = st.executeQuery();
-						try {
-							rs.next();
-							IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( numberType );
-							value.initialize( rs, 1 );
-                            LOG.debugf("Sequence value obtained: %s", value.makeValue());
-							return value;
-						}
-						finally {
-							try {
-								rs.close();
-							}
-							catch( Throwable ignore ) {
-								// intentionally empty
-							}
-						}
-					}
-					finally {
-						st.close();
-					}
-
-				}
-				catch ( SQLException sqle) {
-					throw session.getFactory().getSQLExceptionHelper().convert(
-							sqle,
-							"could not get next sequence value",
-							sql
-					);
-				}
-			}
-		};
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public void prepare(Optimizer optimizer) {
-		applyIncrementSizeToSourceValues = optimizer.applyIncrementSizeToSourceValues();
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
-		int sourceIncrementSize = applyIncrementSizeToSourceValues ? incrementSize : 1;
-		return dialect.getCreateSequenceStrings( sequenceName, initialValue, sourceIncrementSize );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
-		return dialect.getDropSequenceStrings( sequenceName );
-	}
-}
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.dialect.Dialect;
+import org.hibernate.engine.SessionImplementor;
+import org.hibernate.id.IdentifierGeneratorHelper;
+import org.hibernate.id.IntegralDataTypeHolder;
+
+import org.jboss.logging.Logger;
+
+/**
+ * Describes a sequence.
+ *
+ * @author Steve Ebersole
+ */
+public class SequenceStructure implements DatabaseStructure {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SequenceStructure.class.getName());
+
+	private final String sequenceName;
+	private final int initialValue;
+	private final int incrementSize;
+	private final Class numberType;
+	private final String sql;
+	private boolean applyIncrementSizeToSourceValues;
+	private int accessCounter;
+
+	public SequenceStructure(
+			Dialect dialect,
+			String sequenceName,
+			int initialValue,
+			int incrementSize,
+			Class numberType) {
+		this.sequenceName = sequenceName;
+		this.initialValue = initialValue;
+		this.incrementSize = incrementSize;
+		this.numberType = numberType;
+		sql = dialect.getSequenceNextValString( sequenceName );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public String getName() {
+		return sequenceName;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public int getIncrementSize() {
+		return incrementSize;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public int getTimesAccessed() {
+		return accessCounter;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public int getInitialValue() {
+		return initialValue;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public AccessCallback buildCallback(final SessionImplementor session) {
+		return new AccessCallback() {
+			public IntegralDataTypeHolder getNextValue() {
+				accessCounter++;
+				try {
+					PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+					try {
+						ResultSet rs = st.executeQuery();
+						try {
+							rs.next();
+							IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( numberType );
+							value.initialize( rs, 1 );
+                            LOG.debugf("Sequence value obtained: %s", value.makeValue());
+							return value;
+						}
+						finally {
+							try {
+								rs.close();
+							}
+							catch( Throwable ignore ) {
+								// intentionally empty
+							}
+						}
+					}
+					finally {
+						st.close();
+					}
+
+				}
+				catch ( SQLException sqle) {
+					throw session.getFactory().getSQLExceptionHelper().convert(
+							sqle,
+							"could not get next sequence value",
+							sql
+					);
+				}
+			}
+		};
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public void prepare(Optimizer optimizer) {
+		applyIncrementSizeToSourceValues = optimizer.applyIncrementSizeToSourceValues();
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
+		int sourceIncrementSize = applyIncrementSizeToSourceValues ? incrementSize : 1;
+		return dialect.getCreateSequenceStrings( sequenceName, initialValue, sourceIncrementSize );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
+		return dialect.getDropSequenceStrings( sequenceName );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStyleGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStyleGenerator.java
index 43ec69c926..e8e008d409 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStyleGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStyleGenerator.java
@@ -1,369 +1,369 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id.enhanced;
 import java.io.Serializable;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.id.Configurable;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Generates identifier values based on an sequence-style database structure.
  * Variations range from actually using a sequence to using a table to mimic
  * a sequence.  These variations are encapsulated by the {@link DatabaseStructure}
  * interface internally.
  * <p/>
  * General configuration parameters:
  * <table>
  * 	 <tr>
  *     <td><b>NAME</b></td>
  *     <td><b>DEFAULT</b></td>
  *     <td><b>DESCRIPTION</b></td>
  *   </tr>
  *   <tr>
  *     <td>{@link #SEQUENCE_PARAM}</td>
  *     <td>{@link #DEF_SEQUENCE_NAME}</td>
  *     <td>The name of the sequence/table to use to store/retrieve values</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #INITIAL_PARAM}</td>
  *     <td>{@link #DEFAULT_INITIAL_VALUE}</td>
  *     <td>The initial value to be stored for the given segment; the effect in terms of storage varies based on {@link Optimizer} and {@link DatabaseStructure}</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #INCREMENT_PARAM}</td>
  *     <td>{@link #DEFAULT_INCREMENT_SIZE}</td>
  *     <td>The increment size for the underlying segment; the effect in terms of storage varies based on {@link Optimizer} and {@link DatabaseStructure}</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #OPT_PARAM}</td>
  *     <td><i>depends on defined increment size</i></td>
  *     <td>Allows explicit definition of which optimization strategy to use</td>
  *   </tr>
  *     <td>{@link #FORCE_TBL_PARAM}</td>
  *     <td><b><i>false<i/></b></td>
  *     <td>Allows explicit definition of which optimization strategy to use</td>
  *   </tr>
  * </table>
  * <p/>
  * Configuration parameters used specifically when the underlying structure is a table:
  * <table>
  * 	 <tr>
  *     <td><b>NAME</b></td>
  *     <td><b>DEFAULT</b></td>
  *     <td><b>DESCRIPTION</b></td>
  *   </tr>
  *   <tr>
  *     <td>{@link #VALUE_COLUMN_PARAM}</td>
  *     <td>{@link #DEF_VALUE_COLUMN}</td>
  *     <td>The name of column which holds the sequence value for the given segment</td>
  *   </tr>
  * </table>
  *
  * @author Steve Ebersole
  */
 public class SequenceStyleGenerator implements PersistentIdentifierGenerator, Configurable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        SequenceStyleGenerator.class.getName());
 
 	// general purpose parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public static final String SEQUENCE_PARAM = "sequence_name";
 	public static final String DEF_SEQUENCE_NAME = "hibernate_sequence";
 
 	public static final String INITIAL_PARAM = "initial_value";
 	public static final int DEFAULT_INITIAL_VALUE = 1;
 
 	public static final String INCREMENT_PARAM = "increment_size";
 	public static final int DEFAULT_INCREMENT_SIZE = 1;
 
 	public static final String OPT_PARAM = "optimizer";
 
 	public static final String FORCE_TBL_PARAM = "force_table_use";
 
 
 	// table-specific parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public static final String VALUE_COLUMN_PARAM = "value_column";
 	public static final String DEF_VALUE_COLUMN = "next_val";
 
 
 	// state ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private DatabaseStructure databaseStructure;
 	private Optimizer optimizer;
 	private Type identifierType;
 
 	/**
 	 * Getter for property 'databaseStructure'.
 	 *
 	 * @return Value for property 'databaseStructure'.
 	 */
 	public DatabaseStructure getDatabaseStructure() {
 		return databaseStructure;
 	}
 
 	/**
 	 * Getter for property 'optimizer'.
 	 *
 	 * @return Value for property 'optimizer'.
 	 */
 	public Optimizer getOptimizer() {
 		return optimizer;
 	}
 
 	/**
 	 * Getter for property 'identifierType'.
 	 *
 	 * @return Value for property 'identifierType'.
 	 */
 	public Type getIdentifierType() {
 		return identifierType;
 	}
 
 
 	// Configurable implementation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void configure(Type type, Properties params, Dialect dialect) throws MappingException {
 		this.identifierType = type;
 		boolean forceTableUse = ConfigurationHelper.getBoolean( FORCE_TBL_PARAM, params, false );
 
 		final String sequenceName = determineSequenceName( params, dialect );
 
 		final int initialValue = determineInitialValue( params );
 		int incrementSize = determineIncrementSize( params );
 
 		final String optimizationStrategy = determineOptimizationStrategy( params, incrementSize );
 		incrementSize = determineAdjustedIncrementSize( optimizationStrategy, incrementSize );
 
 		if ( dialect.supportsSequences() && !forceTableUse ) {
 			if ( OptimizerFactory.POOL.equals( optimizationStrategy ) && !dialect.supportsPooledSequences() ) {
 				forceTableUse = true;
                 LOG.forcingTableUse();
 			}
 		}
 
 		this.databaseStructure = buildDatabaseStructure(
 				type,
 				params,
 				dialect,
 				forceTableUse,
 				sequenceName,
 				initialValue,
 				incrementSize
 		);
 		this.optimizer = OptimizerFactory.buildOptimizer(
 				optimizationStrategy,
 				identifierType.getReturnedClass(),
 				incrementSize,
 				ConfigurationHelper.getInt( INITIAL_PARAM, params, -1 )
 		);
 		this.databaseStructure.prepare( optimizer );
 	}
 
 	/**
 	 * Determine the name of the sequence (or table if this resolves to a physical table)
 	 * to use.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect in effect
 	 * @return The sequence name
 	 */
 	protected String determineSequenceName(Properties params, Dialect dialect) {
 		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 		String sequenceName = ConfigurationHelper.getString( SEQUENCE_PARAM, params, DEF_SEQUENCE_NAME );
 		if ( sequenceName.indexOf( '.' ) < 0 ) {
 			sequenceName = normalizer.normalizeIdentifierQuoting( sequenceName );
 			String schemaName = params.getProperty( SCHEMA );
 			String catalogName = params.getProperty( CATALOG );
 			sequenceName = Table.qualify(
 					dialect.quote( catalogName ),
 					dialect.quote( schemaName ),
 					dialect.quote( sequenceName )
 			);
 		}
 		else {
 			// if already qualified there is not much we can do in a portable manner so we pass it
 			// through and assume the user has set up the name correctly.
 		}
 		return sequenceName;
 	}
 
 	/**
 	 * Determine the name of the column used to store the generator value in
 	 * the db.
 	 * <p/>
 	 * Called during {@link #configure configuration} <b>when resolving to a
 	 * physical table</b>.
 	 *
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect in effect.
 	 * @return The value column name
 	 */
 	protected String determineValueColumnName(Properties params, Dialect dialect) {
 		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 		String name = ConfigurationHelper.getString( VALUE_COLUMN_PARAM, params, DEF_VALUE_COLUMN );
 		return dialect.quote( normalizer.normalizeIdentifierQuoting( name ) );
 	}
 
 	/**
 	 * Determine the initial sequence value to use.  This value is used when
 	 * initializing the {@link #getDatabaseStructure() database structure}
 	 * (i.e. sequence/table).
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @return The initial value
 	 */
 	protected int determineInitialValue(Properties params) {
 		return ConfigurationHelper.getInt( INITIAL_PARAM, params, DEFAULT_INITIAL_VALUE );
 	}
 
 	/**
 	 * Determine the increment size to be applied.  The exact implications of
 	 * this value depends on the {@link #getOptimizer() optimizer} being used.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @return The increment size
 	 */
 	protected int determineIncrementSize(Properties params) {
 		return ConfigurationHelper.getInt( INCREMENT_PARAM, params, DEFAULT_INCREMENT_SIZE );
 	}
 
 	/**
 	 * Determine the optimizer to use.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param incrementSize The {@link #determineIncrementSize determined increment size}
 	 * @return The optimizer strategy (name)
 	 */
 	protected String determineOptimizationStrategy(Properties params, int incrementSize) {
 		// if the increment size is greater than one, we prefer pooled optimization; but we
 		// need to see if the user prefers POOL or POOL_LO...
 		String defaultPooledOptimizerStrategy = ConfigurationHelper.getBoolean( Environment.PREFER_POOLED_VALUES_LO, params, false )
 				? OptimizerFactory.POOL_LO
 				: OptimizerFactory.POOL;
 		String defaultOptimizerStrategy = incrementSize <= 1 ? OptimizerFactory.NONE : defaultPooledOptimizerStrategy;
 		return ConfigurationHelper.getString( OPT_PARAM, params, defaultOptimizerStrategy );
 	}
 
 	/**
 	 * In certain cases we need to adjust the increment size based on the
 	 * selected optimizer.  This is the hook to achieve that.
 	 *
 	 * @param optimizationStrategy The optimizer strategy (name)
 	 * @param incrementSize The {@link #determineIncrementSize determined increment size}
 	 * @return The adjusted increment size.
 	 */
 	protected int determineAdjustedIncrementSize(String optimizationStrategy, int incrementSize) {
 		if ( OptimizerFactory.NONE.equals( optimizationStrategy ) && incrementSize > 1 ) {
             LOG.honoringOptimizerSetting(OptimizerFactory.NONE, INCREMENT_PARAM, incrementSize);
 			incrementSize = 1;
 		}
 		return incrementSize;
 	}
 
 	/**
 	 * Build the database structure.
 	 *
 	 * @param type The Hibernate type of the identifier property
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect being used.
 	 * @param forceTableUse Should a table be used even if the dialect supports sequences?
 	 * @param sequenceName The name to use for the sequence or table.
 	 * @param initialValue The initial value.
 	 * @param incrementSize the increment size to use (after any adjustments).
 	 *
 	 * @return An abstraction for the actual database structure in use (table vs. sequence).
 	 */
 	protected DatabaseStructure buildDatabaseStructure(
 			Type type,
 			Properties params,
 			Dialect dialect,
 			boolean forceTableUse,
 			String sequenceName,
 			int initialValue,
 			int incrementSize) {
 		boolean useSequence = dialect.supportsSequences() && !forceTableUse;
 		if ( useSequence ) {
 			return new SequenceStructure( dialect, sequenceName, initialValue, incrementSize, type.getReturnedClass() );
 		}
 		else {
 			String valueColumnName = determineValueColumnName( params, dialect );
 			return new TableStructure( dialect, sequenceName, valueColumnName, initialValue, incrementSize, type.getReturnedClass() );
 		}
 	}
 
 
 	// IdentifierGenerator implementation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Serializable generate(SessionImplementor session, Object object) throws HibernateException {
 		return optimizer.generate( databaseStructure.buildCallback( session ) );
 	}
 
 
 	// PersistentIdentifierGenerator implementation ~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Object generatorKey() {
 		return databaseStructure.getName();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		return databaseStructure.sqlCreateStrings( dialect );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		return databaseStructure.sqlDropStrings( dialect );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableGenerator.java
index 5197d8e332..0ec68ee1d1 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableGenerator.java
@@ -1,580 +1,580 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id.enhanced;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Collections;
 import java.util.Map;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.id.Configurable;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.id.IntegralDataTypeHolder;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * An enhanced version of table-based id generation.
  * <p/>
  * Unlike the simplistic legacy one (which, btw, was only ever intended for subclassing
  * support) we "segment" the table into multiple values.  Thus a single table can
  * actually serve as the persistent storage for multiple independent generators.  One
  * approach would be to segment the values by the name of the entity for which we are
  * performing generation, which would mean that we would have a row in the generator
  * table for each entity name.  Or any configuration really; the setup is very flexible.
  * <p/>
  * In this respect it is very similar to the legacy
  * {@link org.hibernate.id.MultipleHiLoPerTableGenerator} in terms of the
  * underlying storage structure (namely a single table capable of holding
  * multiple generator values).  The differentiator is, as with
  * {@link SequenceStyleGenerator} as well, the externalized notion
  * of an optimizer.
  * <p/>
  * <b>NOTE</b> that by default we use a single row for all generators (based
  * on {@link #DEF_SEGMENT_VALUE}).  The configuration parameter
  * {@link #CONFIG_PREFER_SEGMENT_PER_ENTITY} can be used to change that to
  * instead default to using a row for each entity name.
  * <p/>
  * Configuration parameters:
  * <table>
  * 	 <tr>
  *     <td><b>NAME</b></td>
  *     <td><b>DEFAULT</b></td>
  *     <td><b>DESCRIPTION</b></td>
  *   </tr>
  *   <tr>
  *     <td>{@link #TABLE_PARAM}</td>
  *     <td>{@link #DEF_TABLE}</td>
  *     <td>The name of the table to use to store/retrieve values</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #VALUE_COLUMN_PARAM}</td>
  *     <td>{@link #DEF_VALUE_COLUMN}</td>
  *     <td>The name of column which holds the sequence value for the given segment</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #SEGMENT_COLUMN_PARAM}</td>
  *     <td>{@link #DEF_SEGMENT_COLUMN}</td>
  *     <td>The name of the column which holds the segment key</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #SEGMENT_VALUE_PARAM}</td>
  *     <td>{@link #DEF_SEGMENT_VALUE}</td>
  *     <td>The value indicating which segment is used by this generator; refers to values in the {@link #SEGMENT_COLUMN_PARAM} column</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #SEGMENT_LENGTH_PARAM}</td>
  *     <td>{@link #DEF_SEGMENT_LENGTH}</td>
  *     <td>The data length of the {@link #SEGMENT_COLUMN_PARAM} column; used for schema creation</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #INITIAL_PARAM}</td>
  *     <td>{@link #DEFAULT_INITIAL_VALUE}</td>
  *     <td>The initial value to be stored for the given segment</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #INCREMENT_PARAM}</td>
  *     <td>{@link #DEFAULT_INCREMENT_SIZE}</td>
  *     <td>The increment size for the underlying segment; see the discussion on {@link Optimizer} for more details.</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #OPT_PARAM}</td>
  *     <td><i>depends on defined increment size</i></td>
  *     <td>Allows explicit definition of which optimization strategy to use</td>
  *   </tr>
  * </table>
  *
  * @author Steve Ebersole
  */
 public class TableGenerator implements PersistentIdentifierGenerator, Configurable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TableGenerator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TableGenerator.class.getName());
 
 	public static final String CONFIG_PREFER_SEGMENT_PER_ENTITY = "prefer_entity_table_as_segment_value";
 
 	public static final String TABLE_PARAM = "table_name";
 	public static final String DEF_TABLE = "hibernate_sequences";
 
 	public static final String VALUE_COLUMN_PARAM = "value_column_name";
 	public static final String DEF_VALUE_COLUMN = "next_val";
 
 	public static final String SEGMENT_COLUMN_PARAM = "segment_column_name";
 	public static final String DEF_SEGMENT_COLUMN = "sequence_name";
 
 	public static final String SEGMENT_VALUE_PARAM = "segment_value";
 	public static final String DEF_SEGMENT_VALUE = "default";
 
 	public static final String SEGMENT_LENGTH_PARAM = "segment_value_length";
 	public static final int DEF_SEGMENT_LENGTH = 255;
 
 	public static final String INITIAL_PARAM = "initial_value";
 	public static final int DEFAULT_INITIAL_VALUE = 1;
 
 	public static final String INCREMENT_PARAM = "increment_size";
 	public static final int DEFAULT_INCREMENT_SIZE = 1;
 
 	public static final String OPT_PARAM = "optimizer";
 
 
 	private Type identifierType;
 
 	private String tableName;
 
 	private String segmentColumnName;
 	private String segmentValue;
 	private int segmentValueLength;
 
 	private String valueColumnName;
 	private int initialValue;
 	private int incrementSize;
 
 	private String selectQuery;
 	private String insertQuery;
 	private String updateQuery;
 
 	private Optimizer optimizer;
 	private long accessCount = 0;
 
 	@Override
 	public Object generatorKey() {
 		return tableName;
 	}
 
 	/**
 	 * Type mapping for the identifier.
 	 *
 	 * @return The identifier type mapping.
 	 */
 	public final Type getIdentifierType() {
 		return identifierType;
 	}
 
 	/**
 	 * The name of the table in which we store this generator's persistent state.
 	 *
 	 * @return The table name.
 	 */
 	public final String getTableName() {
 		return tableName;
 	}
 
 	/**
 	 * The name of the column in which we store the segment to which each row
 	 * belongs.  The value here acts as PK.
 	 *
 	 * @return The segment column name
 	 */
 	public final String getSegmentColumnName() {
 		return segmentColumnName;
 	}
 
 	/**
 	 * The value in {@link #getSegmentColumnName segment column} which
 	 * corresponding to this generator instance.  In other words this value
 	 * indicates the row in which this generator instance will store values.
 	 *
 	 * @return The segment value for this generator instance.
 	 */
 	public final String getSegmentValue() {
 		return segmentValue;
 	}
 
 	/**
 	 * The size of the {@link #getSegmentColumnName segment column} in the
 	 * underlying table.
 	 * <p/>
 	 * <b>NOTE</b> : should really have been called 'segmentColumnLength' or
 	 * even better 'segmentColumnSize'
 	 *
 	 * @return the column size.
 	 */
 	public final int getSegmentValueLength() {
 		return segmentValueLength;
 	}
 
 	/**
 	 * The name of the column in which we store our persistent generator value.
 	 *
 	 * @return The name of the value column.
 	 */
 	public final String getValueColumnName() {
 		return valueColumnName;
 	}
 
 	/**
 	 * The initial value to use when we find no previous state in the
 	 * generator table corresponding to our sequence.
 	 *
 	 * @return The initial value to use.
 	 */
 	public final int getInitialValue() {
 		return initialValue;
 	}
 
 	/**
 	 * The amount of increment to use.  The exact implications of this
 	 * depends on the {@link #getOptimizer() optimizer} being used.
 	 *
 	 * @return The increment amount.
 	 */
 	public final int getIncrementSize() {
 		return incrementSize;
 	}
 
 	/**
 	 * The optimizer being used by this generator.
 	 *
 	 * @return Out optimizer.
 	 */
 	public final Optimizer getOptimizer() {
 		return optimizer;
 	}
 
 	/**
 	 * Getter for property 'tableAccessCount'.  Only really useful for unit test
 	 * assertions.
 	 *
 	 * @return Value for property 'tableAccessCount'.
 	 */
 	public final long getTableAccessCount() {
 		return accessCount;
 	}
 
 	@Override
 	public void configure(Type type, Properties params, Dialect dialect) throws MappingException {
 		identifierType = type;
 
 		tableName = determineGeneratorTableName( params, dialect );
 		segmentColumnName = determineSegmentColumnName( params, dialect );
 		valueColumnName = determineValueColumnName( params, dialect );
 
 		segmentValue = determineSegmentValue( params );
 
 		segmentValueLength = determineSegmentColumnSize( params );
 		initialValue = determineInitialValue( params );
 		incrementSize = determineIncrementSize( params );
 
 		this.selectQuery = buildSelectQuery( dialect );
 		this.updateQuery = buildUpdateQuery();
 		this.insertQuery = buildInsertQuery();
 
 		// if the increment size is greater than one, we prefer pooled optimization; but we
 		// need to see if the user prefers POOL or POOL_LO...
 		String defaultPooledOptimizerStrategy = ConfigurationHelper.getBoolean( Environment.PREFER_POOLED_VALUES_LO, params, false )
 				? OptimizerFactory.POOL_LO
 				: OptimizerFactory.POOL;
 		final String defaultOptimizerStrategy = incrementSize <= 1 ? OptimizerFactory.NONE : defaultPooledOptimizerStrategy;
 		final String optimizationStrategy = ConfigurationHelper.getString( OPT_PARAM, params, defaultOptimizerStrategy );
 		optimizer = OptimizerFactory.buildOptimizer(
 				optimizationStrategy,
 				identifierType.getReturnedClass(),
 				incrementSize,
 				ConfigurationHelper.getInt( INITIAL_PARAM, params, -1 )
 		);
 	}
 
 	/**
 	 * Determine the table name to use for the generator values.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getTableName()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect in effect
 	 * @return The table name to use.
 	 */
 	protected String determineGeneratorTableName(Properties params, Dialect dialect) {
 		String name = ConfigurationHelper.getString( TABLE_PARAM, params, DEF_TABLE );
 		boolean isGivenNameUnqualified = name.indexOf( '.' ) < 0;
 		if ( isGivenNameUnqualified ) {
 			ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 			name = normalizer.normalizeIdentifierQuoting( name );
 			// if the given name is un-qualified we may neen to qualify it
 			String schemaName = normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) );
 			String catalogName = normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) );
 			name = Table.qualify(
 					dialect.quote( catalogName ),
 					dialect.quote( schemaName ),
 					dialect.quote( name)
 			);
 		}
 		else {
 			// if already qualified there is not much we can do in a portable manner so we pass it
 			// through and assume the user has set up the name correctly.
 		}
 		return name;
 	}
 
 	/**
 	 * Determine the name of the column used to indicate the segment for each
 	 * row.  This column acts as the primary key.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getSegmentColumnName()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect in effect
 	 * @return The name of the segment column
 	 */
 	protected String determineSegmentColumnName(Properties params, Dialect dialect) {
 		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 		String name = ConfigurationHelper.getString( SEGMENT_COLUMN_PARAM, params, DEF_SEGMENT_COLUMN );
 		return dialect.quote( normalizer.normalizeIdentifierQuoting( name ) );
 	}
 
 	/**
 	 * Determine the name of the column in which we will store the generator persistent value.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getValueColumnName()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect in effect
 	 * @return The name of the value column
 	 */
 	protected String determineValueColumnName(Properties params, Dialect dialect) {
 		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 		String name = ConfigurationHelper.getString( VALUE_COLUMN_PARAM, params, DEF_VALUE_COLUMN );
 		return dialect.quote( normalizer.normalizeIdentifierQuoting( name ) );
 	}
 
 	/**
 	 * Determine the segment value corresponding to this generator instance.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getSegmentValue()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @return The name of the value column
 	 */
 	protected String determineSegmentValue(Properties params) {
 		String segmentValue = params.getProperty( SEGMENT_VALUE_PARAM );
 		if ( StringHelper.isEmpty( segmentValue ) ) {
 			segmentValue = determineDefaultSegmentValue( params );
 		}
 		return segmentValue;
 	}
 
 	/**
 	 * Used in the cases where {@link #determineSegmentValue} is unable to
 	 * determine the value to use.
 	 *
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @return The default segment value to use.
 	 */
 	protected String determineDefaultSegmentValue(Properties params) {
 		boolean preferSegmentPerEntity = ConfigurationHelper.getBoolean( CONFIG_PREFER_SEGMENT_PER_ENTITY, params, false );
 		String defaultToUse = preferSegmentPerEntity ? params.getProperty( TABLE ) : DEF_SEGMENT_VALUE;
         LOG.usingDefaultIdGeneratorSegmentValue(tableName, segmentColumnName, defaultToUse);
 		return defaultToUse;
 	}
 
 	/**
 	 * Determine the size of the {@link #getSegmentColumnName segment column}
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getSegmentValueLength()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @return The size of the segment column
 	 */
 	protected int determineSegmentColumnSize(Properties params) {
 		return ConfigurationHelper.getInt( SEGMENT_LENGTH_PARAM, params, DEF_SEGMENT_LENGTH );
 	}
 
 	protected int determineInitialValue(Properties params) {
 		return ConfigurationHelper.getInt( INITIAL_PARAM, params, DEFAULT_INITIAL_VALUE );
 	}
 
 	protected int determineIncrementSize(Properties params) {
 		return ConfigurationHelper.getInt( INCREMENT_PARAM, params, DEFAULT_INCREMENT_SIZE );
 	}
 
 	protected String buildSelectQuery(Dialect dialect) {
 		final String alias = "tbl";
 		String query = "select " + StringHelper.qualify( alias, valueColumnName ) +
 				" from " + tableName + ' ' + alias +
 				" where " + StringHelper.qualify( alias, segmentColumnName ) + "=?";
 		LockOptions lockOptions = new LockOptions( LockMode.PESSIMISTIC_WRITE );
 		lockOptions.setAliasSpecificLockMode( alias, LockMode.PESSIMISTIC_WRITE );
 		Map updateTargetColumnsMap = Collections.singletonMap( alias, new String[] { valueColumnName } );
 		return dialect.applyLocksToSql( query, lockOptions, updateTargetColumnsMap );
 	}
 
 	protected String buildUpdateQuery() {
 		return "update " + tableName +
 				" set " + valueColumnName + "=? " +
 				" where " + valueColumnName + "=? and " + segmentColumnName + "=?";
 	}
 
 	protected String buildInsertQuery() {
 		return "insert into " + tableName + " (" + segmentColumnName + ", " + valueColumnName + ") " + " values (?,?)";
 	}
 
 	@Override
 	public synchronized Serializable generate(final SessionImplementor session, Object obj) {
 		final SqlStatementLogger statementLogger = session
 				.getFactory()
 				.getServiceRegistry()
 				.getService( JdbcServices.class )
 				.getSqlStatementLogger();
 		return optimizer.generate(
 				new AccessCallback() {
 					@Override
 					public IntegralDataTypeHolder getNextValue() {
 						return session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork(
 								new AbstractReturningWork<IntegralDataTypeHolder>() {
 									@Override
 									public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
 										IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( identifierType.getReturnedClass() );
 										int rows;
 										do {
 											statementLogger.logStatement( selectQuery, FormatStyle.BASIC.getFormatter() );
 											PreparedStatement selectPS = connection.prepareStatement( selectQuery );
 											try {
 												selectPS.setString( 1, segmentValue );
 												ResultSet selectRS = selectPS.executeQuery();
 												if ( !selectRS.next() ) {
 													value.initialize( initialValue );
 													PreparedStatement insertPS = null;
 													try {
 														statementLogger.logStatement( insertQuery, FormatStyle.BASIC.getFormatter() );
 														insertPS = connection.prepareStatement( insertQuery );
 														insertPS.setString( 1, segmentValue );
 														value.bind( insertPS, 2 );
 														insertPS.execute();
 													}
 													finally {
 														if ( insertPS != null ) {
 															insertPS.close();
 														}
 													}
 												}
 												else {
 													value.initialize( selectRS, 1 );
 												}
 												selectRS.close();
 											}
 											catch ( SQLException e ) {
 											    LOG.unableToReadOrInitHiValue(e);
 												throw e;
 											}
 											finally {
 												selectPS.close();
 											}
 
 											statementLogger.logStatement( updateQuery, FormatStyle.BASIC.getFormatter() );
 											PreparedStatement updatePS = connection.prepareStatement( updateQuery );
 											try {
 												final IntegralDataTypeHolder updateValue = value.copy();
 												if ( optimizer.applyIncrementSizeToSourceValues() ) {
 													updateValue.add( incrementSize );
 												}
 												else {
 													updateValue.increment();
 												}
 												updateValue.bind( updatePS, 1 );
 												value.bind( updatePS, 2 );
 												updatePS.setString( 3, segmentValue );
 												rows = updatePS.executeUpdate();
 											}
 											catch ( SQLException e ) {
 												LOG.unableToUpdateQueryHiValue(tableName, e);
 												throw e;
 											}
 											finally {
 												updatePS.close();
 											}
 										}
 										while ( rows == 0 );
 
 										accessCount++;
 
 										return value;
 									}
 								},
 								true
 						);
 					}
 				}
 		);
 	}
 
 	@Override
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		return new String[] {
 				new StringBuffer()
 						.append( dialect.getCreateTableString() )
 						.append( ' ' )
 						.append( tableName )
 						.append( " ( " )
 						.append( segmentColumnName )
 						.append( ' ' )
 						.append( dialect.getTypeName( Types.VARCHAR, segmentValueLength, 0, 0 ) )
 						.append( " not null " )
 						.append( ",  " )
 						.append( valueColumnName )
 						.append( ' ' )
 						.append( dialect.getTypeName( Types.BIGINT ) )
 						.append( ", primary key ( " )
 						.append( segmentColumnName )
 						.append( " ) ) " )
 						.toString()
 		};
 	}
 
 	@Override
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		StringBuffer sqlDropString = new StringBuffer().append( "drop table " );
 		if ( dialect.supportsIfExistsBeforeTableName() ) {
 			sqlDropString.append( "if exists " );
 		}
 		sqlDropString.append( tableName ).append( dialect.getCascadeConstraintsString() );
 		if ( dialect.supportsIfExistsAfterTableName() ) {
 			sqlDropString.append( " if exists" );
 		}
 		return new String[] { sqlDropString.toString() };
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableStructure.java b/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableStructure.java
index b478ea3e61..b86c6c6e45 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableStructure.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableStructure.java
@@ -1,198 +1,199 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.id.enhanced;
-
-import java.sql.Connection;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.sql.Types;
-import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.LockMode;
-import org.hibernate.dialect.Dialect;
-import org.hibernate.engine.SessionImplementor;
-import org.hibernate.engine.jdbc.internal.FormatStyle;
-import org.hibernate.engine.jdbc.spi.JdbcServices;
-import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
-import org.hibernate.id.IdentifierGenerationException;
-import org.hibernate.id.IdentifierGeneratorHelper;
-import org.hibernate.id.IntegralDataTypeHolder;
-import org.hibernate.jdbc.AbstractReturningWork;
-import org.jboss.logging.Logger;
-
-/**
- * Describes a table used to mimic sequence behavior
- *
- * @author Steve Ebersole
- */
-public class TableStructure implements DatabaseStructure {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TableStructure.class.getName());
-
-	private final String tableName;
-	private final String valueColumnName;
-	private final int initialValue;
-	private final int incrementSize;
-	private final Class numberType;
-	private final String selectQuery;
-	private final String updateQuery;
-
-	private boolean applyIncrementSizeToSourceValues;
-	private int accessCounter;
-
-	public TableStructure(
-			Dialect dialect,
-			String tableName,
-			String valueColumnName,
-			int initialValue,
-			int incrementSize,
-			Class numberType) {
-		this.tableName = tableName;
-		this.initialValue = initialValue;
-		this.incrementSize = incrementSize;
-		this.valueColumnName = valueColumnName;
-		this.numberType = numberType;
-
-		selectQuery = "select " + valueColumnName + " as id_val" +
-				" from " + dialect.appendLockHint( LockMode.PESSIMISTIC_WRITE, tableName ) +
-				dialect.getForUpdateString();
-
-		updateQuery = "update " + tableName +
-				" set " + valueColumnName + "= ?" +
-				" where " + valueColumnName + "=?";
-	}
-
-	@Override
-	public String getName() {
-		return tableName;
-	}
-
-	@Override
-	public int getInitialValue() {
-		return initialValue;
-	}
-
-	@Override
-	public int getIncrementSize() {
-		return incrementSize;
-	}
-
-	@Override
-	public int getTimesAccessed() {
-		return accessCounter;
-	}
-
-	@Override
-	public void prepare(Optimizer optimizer) {
-		applyIncrementSizeToSourceValues = optimizer.applyIncrementSizeToSourceValues();
-	}
-
-	@Override
-	public AccessCallback buildCallback(final SessionImplementor session) {
-		return new AccessCallback() {
-			@Override
-			public IntegralDataTypeHolder getNextValue() {
-				return session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork(
-						new AbstractReturningWork<IntegralDataTypeHolder>() {
-							@Override
-							public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
-								final SqlStatementLogger statementLogger = session
-										.getFactory()
-										.getServiceRegistry()
-										.getService( JdbcServices.class )
-										.getSqlStatementLogger();
-								IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( numberType );
-								int rows;
-								do {
-									statementLogger.logStatement( selectQuery, FormatStyle.BASIC.getFormatter() );
-									PreparedStatement selectStatement = connection.prepareStatement( selectQuery );
-									try {
-										ResultSet selectRS = selectStatement.executeQuery();
-										if ( !selectRS.next() ) {
-											String err = "could not read a hi value - you need to populate the table: " + tableName;
-											LOG.error( err );
-											throw new IdentifierGenerationException( err );
-										}
-										value.initialize( selectRS, 1 );
-										selectRS.close();
-									}
-									catch ( SQLException sqle ) {
-										LOG.error( "could not read a hi value", sqle );
-										throw sqle;
-									}
-									finally {
-										selectStatement.close();
-									}
-
-									statementLogger.logStatement( updateQuery, FormatStyle.BASIC.getFormatter() );
-									PreparedStatement updatePS = connection.prepareStatement( updateQuery );
-									try {
-										final int increment = applyIncrementSizeToSourceValues ? incrementSize : 1;
-										final IntegralDataTypeHolder updateValue = value.copy().add( increment );
-										updateValue.bind( updatePS, 1 );
-										value.bind( updatePS, 2 );
-										rows = updatePS.executeUpdate();
-									}
-									catch ( SQLException e ) {
-									    LOG.unableToUpdateQueryHiValue(tableName, e);
-										throw e;
-									}
-									finally {
-										updatePS.close();
-									}
-								} while ( rows == 0 );
-
-								accessCounter++;
-
-								return value;
-							}
-						},
-						true
-				);
-			}
-		};
-	}
-
-	@Override
-	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
-		return new String[] {
-				dialect.getCreateTableString() + " " + tableName + " ( " + valueColumnName + " " + dialect.getTypeName( Types.BIGINT ) + " )",
-				"insert into " + tableName + " values ( " + initialValue + " )"
-		};
-	}
-
-	@Override
-	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
-		StringBuffer sqlDropString = new StringBuffer().append( "drop table " );
-		if ( dialect.supportsIfExistsBeforeTableName() ) {
-			sqlDropString.append( "if exists " );
-		}
-		sqlDropString.append( tableName ).append( dialect.getCascadeConstraintsString() );
-		if ( dialect.supportsIfExistsAfterTableName() ) {
-			sqlDropString.append( " if exists" );
-		}
-		return new String[] { sqlDropString.toString() };
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.id.enhanced;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.Types;
+import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.LockMode;
+import org.hibernate.dialect.Dialect;
+import org.hibernate.engine.SessionImplementor;
+import org.hibernate.engine.jdbc.internal.FormatStyle;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
+import org.hibernate.id.IdentifierGenerationException;
+import org.hibernate.id.IdentifierGeneratorHelper;
+import org.hibernate.id.IntegralDataTypeHolder;
+import org.hibernate.jdbc.AbstractReturningWork;
+
+import org.jboss.logging.Logger;
+
+/**
+ * Describes a table used to mimic sequence behavior
+ *
+ * @author Steve Ebersole
+ */
+public class TableStructure implements DatabaseStructure {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TableStructure.class.getName());
+
+	private final String tableName;
+	private final String valueColumnName;
+	private final int initialValue;
+	private final int incrementSize;
+	private final Class numberType;
+	private final String selectQuery;
+	private final String updateQuery;
+
+	private boolean applyIncrementSizeToSourceValues;
+	private int accessCounter;
+
+	public TableStructure(
+			Dialect dialect,
+			String tableName,
+			String valueColumnName,
+			int initialValue,
+			int incrementSize,
+			Class numberType) {
+		this.tableName = tableName;
+		this.initialValue = initialValue;
+		this.incrementSize = incrementSize;
+		this.valueColumnName = valueColumnName;
+		this.numberType = numberType;
+
+		selectQuery = "select " + valueColumnName + " as id_val" +
+				" from " + dialect.appendLockHint( LockMode.PESSIMISTIC_WRITE, tableName ) +
+				dialect.getForUpdateString();
+
+		updateQuery = "update " + tableName +
+				" set " + valueColumnName + "= ?" +
+				" where " + valueColumnName + "=?";
+	}
+
+	@Override
+	public String getName() {
+		return tableName;
+	}
+
+	@Override
+	public int getInitialValue() {
+		return initialValue;
+	}
+
+	@Override
+	public int getIncrementSize() {
+		return incrementSize;
+	}
+
+	@Override
+	public int getTimesAccessed() {
+		return accessCounter;
+	}
+
+	@Override
+	public void prepare(Optimizer optimizer) {
+		applyIncrementSizeToSourceValues = optimizer.applyIncrementSizeToSourceValues();
+	}
+
+	@Override
+	public AccessCallback buildCallback(final SessionImplementor session) {
+		return new AccessCallback() {
+			@Override
+			public IntegralDataTypeHolder getNextValue() {
+				return session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork(
+						new AbstractReturningWork<IntegralDataTypeHolder>() {
+							@Override
+							public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
+								final SqlStatementLogger statementLogger = session
+										.getFactory()
+										.getServiceRegistry()
+										.getService( JdbcServices.class )
+										.getSqlStatementLogger();
+								IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( numberType );
+								int rows;
+								do {
+									statementLogger.logStatement( selectQuery, FormatStyle.BASIC.getFormatter() );
+									PreparedStatement selectStatement = connection.prepareStatement( selectQuery );
+									try {
+										ResultSet selectRS = selectStatement.executeQuery();
+										if ( !selectRS.next() ) {
+											String err = "could not read a hi value - you need to populate the table: " + tableName;
+											LOG.error( err );
+											throw new IdentifierGenerationException( err );
+										}
+										value.initialize( selectRS, 1 );
+										selectRS.close();
+									}
+									catch ( SQLException sqle ) {
+										LOG.error( "could not read a hi value", sqle );
+										throw sqle;
+									}
+									finally {
+										selectStatement.close();
+									}
+
+									statementLogger.logStatement( updateQuery, FormatStyle.BASIC.getFormatter() );
+									PreparedStatement updatePS = connection.prepareStatement( updateQuery );
+									try {
+										final int increment = applyIncrementSizeToSourceValues ? incrementSize : 1;
+										final IntegralDataTypeHolder updateValue = value.copy().add( increment );
+										updateValue.bind( updatePS, 1 );
+										value.bind( updatePS, 2 );
+										rows = updatePS.executeUpdate();
+									}
+									catch ( SQLException e ) {
+									    LOG.unableToUpdateQueryHiValue(tableName, e);
+										throw e;
+									}
+									finally {
+										updatePS.close();
+									}
+								} while ( rows == 0 );
+
+								accessCounter++;
+
+								return value;
+							}
+						},
+						true
+				);
+			}
+		};
+	}
+
+	@Override
+	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
+		return new String[] {
+				dialect.getCreateTableString() + " " + tableName + " ( " + valueColumnName + " " + dialect.getTypeName( Types.BIGINT ) + " )",
+				"insert into " + tableName + " values ( " + initialValue + " )"
+		};
+	}
+
+	@Override
+	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
+		StringBuffer sqlDropString = new StringBuffer().append( "drop table " );
+		if ( dialect.supportsIfExistsBeforeTableName() ) {
+			sqlDropString.append( "if exists " );
+		}
+		sqlDropString.append( tableName ).append( dialect.getCascadeConstraintsString() );
+		if ( dialect.supportsIfExistsAfterTableName() ) {
+			sqlDropString.append( " if exists" );
+		}
+		return new String[] { sqlDropString.toString() };
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/id/factory/DefaultIdentifierGeneratorFactory.java b/hibernate-core/src/main/java/org/hibernate/id/factory/DefaultIdentifierGeneratorFactory.java
index 14e63267f4..169893cc88 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/factory/DefaultIdentifierGeneratorFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/factory/DefaultIdentifierGeneratorFactory.java
@@ -1,138 +1,139 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id.factory;
 import java.io.Serializable;
 import java.util.Properties;
 import java.util.concurrent.ConcurrentHashMap;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.id.Assigned;
 import org.hibernate.id.Configurable;
 import org.hibernate.id.ForeignGenerator;
 import org.hibernate.id.GUIDGenerator;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.id.IncrementGenerator;
 import org.hibernate.id.SelectGenerator;
 import org.hibernate.id.SequenceGenerator;
 import org.hibernate.id.SequenceHiLoGenerator;
 import org.hibernate.id.SequenceIdentityGenerator;
 import org.hibernate.id.TableHiLoGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.UUIDHexGenerator;
 import org.hibernate.id.enhanced.SequenceStyleGenerator;
 import org.hibernate.id.enhanced.TableGenerator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Basic <tt>templated</tt> support for {@link IdentifierGeneratorFactory} implementations.
  *
  * @author Steve Ebersole
  */
 public class DefaultIdentifierGeneratorFactory implements IdentifierGeneratorFactory, Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultIdentifierGeneratorFactory.class.getName());
 
 	private transient Dialect dialect;
 	private ConcurrentHashMap<String, Class> generatorStrategyToClassNameMap = new ConcurrentHashMap<String, Class>();
 
 	/**
 	 * Constructs a new DefaultIdentifierGeneratorFactory.
 	 */
 	public DefaultIdentifierGeneratorFactory() {
 		register( "uuid2", UUIDGenerator.class );
 		register( "guid", GUIDGenerator.class );			// can be done with UUIDGenerator + strategy
 		register( "uuid", UUIDHexGenerator.class );			// "deprecated" for new use
 		register( "uuid.hex", UUIDHexGenerator.class ); 	// uuid.hex is deprecated
 		register( "hilo", TableHiLoGenerator.class );
 		register( "assigned", Assigned.class );
 		register( "identity", IdentityGenerator.class );
 		register( "select", SelectGenerator.class );
 		register( "sequence", SequenceGenerator.class );
 		register( "seqhilo", SequenceHiLoGenerator.class );
 		register( "increment", IncrementGenerator.class );
 		register( "foreign", ForeignGenerator.class );
 		register( "sequence-identity", SequenceIdentityGenerator.class );
 		register( "enhanced-sequence", SequenceStyleGenerator.class );
 		register( "enhanced-table", TableGenerator.class );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void setDialect(Dialect dialect) {
         LOG.debugf("Setting dialect [%s]", dialect);
 		this.dialect = dialect;
 	}
 
 	public void register(String strategy, Class generatorClass) {
 		Object old = generatorStrategyToClassNameMap.put( strategy, generatorClass );
         String msg = "Registering IdentifierGenerator strategy [" + strategy + "] -> [" + generatorClass + "]";
         if (old != null) msg += ", overriding [" + old + "]";
         LOG.debugf(msg);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public IdentifierGenerator createIdentifierGenerator(String strategy, Type type, Properties config) {
 		try {
 			Class clazz = getIdentifierGeneratorClass( strategy );
 			IdentifierGenerator idgen = ( IdentifierGenerator ) clazz.newInstance();
 			if ( idgen instanceof Configurable ) {
 				( ( Configurable ) idgen ).configure( type, config, dialect );
 			}
 			return idgen;
 		}
 		catch ( Exception e ) {
 			String msg = "Could not instantiate id generator [entity-name="
 					+ config.get( IdentifierGenerator.ENTITY_NAME ) + "]";
 			throw new MappingException( msg, e );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Class getIdentifierGeneratorClass(String strategy) {
 		if ( "native".equals( strategy ) ) {
 			return dialect.getNativeIdentifierGeneratorClass();
 		}
 
 		Class generatorClass = generatorStrategyToClassNameMap.get( strategy );
 		try {
 			if ( generatorClass == null ) {
 				generatorClass = ReflectHelper.classForName( strategy );
 			}
 		}
 		catch ( ClassNotFoundException e ) {
 			throw new MappingException( "Could not interpret id generator strategy [" + strategy + "]" );
 		}
 		return generatorClass;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/impl/AbstractScrollableResults.java b/hibernate-core/src/main/java/org/hibernate/impl/AbstractScrollableResults.java
index d6f077fe0a..0ac3c78a22 100644
--- a/hibernate-core/src/main/java/org/hibernate/impl/AbstractScrollableResults.java
+++ b/hibernate-core/src/main/java/org/hibernate/impl/AbstractScrollableResults.java
@@ -1,288 +1,288 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.impl;
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.Locale;
 import java.util.TimeZone;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.hql.HolderInstantiator;
 import org.hibernate.loader.Loader;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Implementation of the <tt>ScrollableResults</tt> interface
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractScrollableResults implements ScrollableResults {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractScrollableResults.class.getName());
 
 	private final ResultSet resultSet;
 	private final PreparedStatement ps;
 	private final SessionImplementor session;
 	private final Loader loader;
 	private final QueryParameters queryParameters;
 	private final Type[] types;
 	private HolderInstantiator holderInstantiator;
 
 	public AbstractScrollableResults(
 	        ResultSet rs,
 	        PreparedStatement ps,
 	        SessionImplementor sess,
 			Loader loader,
 			QueryParameters queryParameters,
 	        Type[] types,
 	        HolderInstantiator holderInstantiator) throws MappingException {
 		this.resultSet=rs;
 		this.ps=ps;
 		this.session = sess;
 		this.loader = loader;
 		this.queryParameters = queryParameters;
 		this.types = types;
 		this.holderInstantiator = holderInstantiator!=null && holderInstantiator.isRequired()
 		        ? holderInstantiator
 		        : null;
 	}
 
 	protected abstract Object[] getCurrentRow();
 
 	protected ResultSet getResultSet() {
 		return resultSet;
 	}
 
 	protected PreparedStatement getPs() {
 		return ps;
 	}
 
 	protected SessionImplementor getSession() {
 		return session;
 	}
 
 	protected Loader getLoader() {
 		return loader;
 	}
 
 	protected QueryParameters getQueryParameters() {
 		return queryParameters;
 	}
 
 	protected Type[] getTypes() {
 		return types;
 	}
 
 	protected HolderInstantiator getHolderInstantiator() {
 		return holderInstantiator;
 	}
 
 	public final void close() throws HibernateException {
 		try {
 			// not absolutely necessary, but does help with aggressive release
 			//session.getJDBCContext().getConnectionManager().closeQueryStatement( ps, resultSet );
 			ps.close();
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not close results"
 				);
 		}
 		finally {
 			try {
 				session.getPersistenceContext().getLoadContexts().cleanup( resultSet );
 			}
 			catch( Throwable ignore ) {
 				// ignore this error for now
                 LOG.trace("Exception trying to cleanup load context : " + ignore.getMessage());
 			}
 		}
 	}
 
 	public final Object[] get() throws HibernateException {
 		return getCurrentRow();
 	}
 
 	public final Object get(int col) throws HibernateException {
 		return getCurrentRow()[col];
 	}
 
 	/**
 	 * Check that the requested type is compatible with the result type, and
 	 * return the column value.  This version makes sure the the classes
 	 * are identical.
 	 *
 	 * @param col the column
 	 * @param returnType a "final" type
 	 */
 	protected final Object getFinal(int col, Type returnType) throws HibernateException {
 		if ( holderInstantiator!=null ) {
 			throw new HibernateException("query specifies a holder class");
 		}
 
 		if ( returnType.getReturnedClass()==types[col].getReturnedClass() ) {
 			return get(col);
 		}
 		else {
 			return throwInvalidColumnTypeException(col, types[col], returnType);
 		}
 	}
 
 	/**
 	 * Check that the requested type is compatible with the result type, and
 	 * return the column value.  This version makes sure the the classes
 	 * are "assignable".
 	 *
 	 * @param col the column
 	 * @param returnType any type
 	 */
 	protected final Object getNonFinal(int col, Type returnType) throws HibernateException {
 		if ( holderInstantiator!=null ) {
 			throw new HibernateException("query specifies a holder class");
 		}
 
 		if ( returnType.getReturnedClass().isAssignableFrom( types[col].getReturnedClass() ) ) {
 			return get(col);
 		}
 		else {
 			return throwInvalidColumnTypeException(col, types[col], returnType);
 		}
 	}
 
 	public final BigDecimal getBigDecimal(int col) throws HibernateException {
 		return (BigDecimal) getFinal(col, Hibernate.BIG_DECIMAL);
 	}
 
 	public final BigInteger getBigInteger(int col) throws HibernateException {
 		return (BigInteger) getFinal(col, Hibernate.BIG_INTEGER);
 	}
 
 	public final byte[] getBinary(int col) throws HibernateException {
 		return (byte[]) getFinal(col, Hibernate.BINARY);
 	}
 
 	public final String getText(int col) throws HibernateException {
 		return (String) getFinal(col, Hibernate.TEXT);
 	}
 
 	public final Blob getBlob(int col) throws HibernateException {
 		return (Blob) getNonFinal(col, Hibernate.BLOB);
 	}
 
 	public final Clob getClob(int col) throws HibernateException {
 		return (Clob) getNonFinal(col, Hibernate.CLOB);
 	}
 
 	public final Boolean getBoolean(int col) throws HibernateException {
 		return (Boolean) getFinal(col, Hibernate.BOOLEAN);
 	}
 
 	public final Byte getByte(int col) throws HibernateException {
 		return (Byte) getFinal(col, Hibernate.BYTE);
 	}
 
 	public final Character getCharacter(int col) throws HibernateException {
 		return (Character) getFinal(col, Hibernate.CHARACTER);
 	}
 
 	public final Date getDate(int col) throws HibernateException {
 		return (Date) getNonFinal(col, Hibernate.TIMESTAMP);
 	}
 
 	public final Calendar getCalendar(int col) throws HibernateException {
 		return (Calendar) getNonFinal(col, Hibernate.CALENDAR);
 	}
 
 	public final Double getDouble(int col) throws HibernateException {
 		return (Double) getFinal(col, Hibernate.DOUBLE);
 	}
 
 	public final Float getFloat(int col) throws HibernateException {
 		return (Float) getFinal(col, Hibernate.FLOAT);
 	}
 
 	public final Integer getInteger(int col) throws HibernateException {
 		return (Integer) getFinal(col, Hibernate.INTEGER);
 	}
 
 	public final Long getLong(int col) throws HibernateException {
 		return (Long) getFinal(col, Hibernate.LONG);
 	}
 
 	public final Short getShort(int col) throws HibernateException {
 		return (Short) getFinal(col, Hibernate.SHORT);
 	}
 
 	public final String getString(int col) throws HibernateException {
 		return (String) getFinal(col, Hibernate.STRING);
 	}
 
 	public final Locale getLocale(int col) throws HibernateException {
 		return (Locale) getFinal(col, Hibernate.LOCALE);
 	}
 
 	/*public final Currency getCurrency(int col) throws HibernateException {
 		return (Currency) get(col);
 	}*/
 
 	public final TimeZone getTimeZone(int col) throws HibernateException {
 		return (TimeZone) getNonFinal(col, Hibernate.TIMEZONE);
 	}
 
 	public final Type getType(int i) {
 		return types[i];
 	}
 
 	private Object throwInvalidColumnTypeException(
 	        int i,
 	        Type type,
 	        Type returnType) throws HibernateException {
 		throw new HibernateException(
 				"incompatible column types: " +
 				type.getName() +
 				", " +
 				returnType.getName()
 		);
 	}
 
 	protected void afterScrollOperation() {
 		session.afterScrollOperation();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/impl/IteratorImpl.java b/hibernate-core/src/main/java/org/hibernate/impl/IteratorImpl.java
index fcce6fb492..b9fd62bf5c 100644
--- a/hibernate-core/src/main/java/org/hibernate/impl/IteratorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/impl/IteratorImpl.java
@@ -1,182 +1,182 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.impl;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.NoSuchElementException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.engine.HibernateIterator;
 import org.hibernate.event.EventSource;
 import org.hibernate.hql.HolderInstantiator;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * An implementation of <tt>java.util.Iterator</tt> that is
  * returned by <tt>iterate()</tt> query execution methods.
  * @author Gavin King
  */
 public final class IteratorImpl implements HibernateIterator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, IteratorImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, IteratorImpl.class.getName());
 
 	private ResultSet rs;
 	private final EventSource session;
 	private boolean readOnly;
 	private final Type[] types;
 	private final boolean single;
 	private Object currentResult;
 	private boolean hasNext;
 	private final String[][] names;
 	private PreparedStatement ps;
 	private HolderInstantiator holderInstantiator;
 
 	public IteratorImpl(
 	        ResultSet rs,
 	        PreparedStatement ps,
 	        EventSource sess,
 	        boolean readOnly,
 	        Type[] types,
 	        String[][] columnNames,
 	        HolderInstantiator holderInstantiator)
 	throws HibernateException, SQLException {
 
 		this.rs=rs;
 		this.ps=ps;
 		this.session = sess;
 		this.readOnly = readOnly;
 		this.types = types;
 		this.names = columnNames;
 		this.holderInstantiator = holderInstantiator;
 
 		single = types.length==1;
 
 		postNext();
 	}
 
 	public void close() throws JDBCException {
 		if (ps!=null) {
 			try {
                 LOG.debugf("Closing iterator");
 				ps.close();
 				ps = null;
 				rs = null;
 				hasNext = false;
 			}
 			catch (SQLException e) {
                 LOG.unableToCloseIterator(e);
 				throw session.getFactory().getSQLExceptionHelper().convert(
 				        e,
 				        "Unable to close iterator"
 					);
 			}
 			finally {
 				try {
 					session.getPersistenceContext().getLoadContexts().cleanup( rs );
 				}
 				catch( Throwable ignore ) {
 					// ignore this error for now
                     LOG.debugf("Exception trying to cleanup load context : %s", ignore.getMessage());
 				}
 			}
 		}
 	}
 
 	private void postNext() throws SQLException {
         LOG.debugf("Attempting to retrieve next results");
 		this.hasNext = rs.next();
 		if (!hasNext) {
             LOG.debugf("Exhausted results");
 			close();
         } else LOG.debugf("Retrieved next results");
 	}
 
 	public boolean hasNext() {
 		return hasNext;
 	}
 
 	public Object next() throws HibernateException {
 		if ( !hasNext ) throw new NoSuchElementException("No more results");
 		boolean sessionDefaultReadOnlyOrig = session.isDefaultReadOnly();
 		session.setDefaultReadOnly( readOnly );
 		try {
 			boolean isHolder = holderInstantiator.isRequired();
 
             LOG.debugf("Assembling results");
 			if ( single && !isHolder ) {
 				currentResult = types[0].nullSafeGet( rs, names[0], session, null );
 			}
 			else {
 				Object[] currentResults = new Object[types.length];
 				for (int i=0; i<types.length; i++) {
 					currentResults[i] = types[i].nullSafeGet( rs, names[i], session, null );
 				}
 
 				if (isHolder) {
 					currentResult = holderInstantiator.instantiate(currentResults);
 				}
 				else {
 					currentResult = currentResults;
 				}
 			}
 
 			postNext();
             LOG.debugf("Returning current results");
 			return currentResult;
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not get next iterator result"
 				);
 		}
 		finally {
 			session.setDefaultReadOnly( sessionDefaultReadOnlyOrig );
 		}
 	}
 
 	public void remove() {
 		if (!single) {
 			throw new UnsupportedOperationException("Not a single column hibernate query result set");
 		}
 		if (currentResult==null) {
 			throw new IllegalStateException("Called Iterator.remove() before next()");
 		}
 		if ( !( types[0] instanceof EntityType ) ) {
 			throw new UnsupportedOperationException("Not an entity");
 		}
 
 		session.delete(
 				( (EntityType) types[0] ).getAssociatedEntityName(),
 				currentResult,
 				false,
 		        null
 			);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/impl/NonFlushedChangesImpl.java b/hibernate-core/src/main/java/org/hibernate/impl/NonFlushedChangesImpl.java
index de7d3c7035..2c9ffbabb7 100644
--- a/hibernate-core/src/main/java/org/hibernate/impl/NonFlushedChangesImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/impl/NonFlushedChangesImpl.java
@@ -1,100 +1,101 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.impl;
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.ActionQueue;
 import org.hibernate.engine.NonFlushedChanges;
 import org.hibernate.engine.StatefulPersistenceContext;
 import org.hibernate.event.EventSource;
+
 import org.jboss.logging.Logger;
 
 public final class NonFlushedChangesImpl implements NonFlushedChanges {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, NonFlushedChangesImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, NonFlushedChangesImpl.class.getName());
 
 	private static class SessionNonFlushedChanges implements Serializable {
 		private transient EntityMode entityMode;
 		private transient ActionQueue actionQueue;
 		private transient StatefulPersistenceContext persistenceContext;
 
 		public SessionNonFlushedChanges(EventSource session) {
 			this.entityMode = session.getEntityMode();
 			this.actionQueue = session.getActionQueue();
 			this.persistenceContext = ( StatefulPersistenceContext ) session.getPersistenceContext();
 		}
 
 		private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 			ois.defaultReadObject();
 			entityMode = EntityMode.parse( ( String ) ois.readObject() );
 			persistenceContext = StatefulPersistenceContext.deserialize( ois, null );
 			actionQueue = ActionQueue.deserialize( ois, null );
 		}
 
 		private void writeObject(ObjectOutputStream oos) throws IOException {
             LOG.trace("Serializing SessionNonFlushedChanges");
 			oos.defaultWriteObject();
 			oos.writeObject( entityMode.toString() );
 			persistenceContext.serialize( oos );
 			actionQueue.serialize( oos );
 		}
 	}
 	private Map nonFlushedChangesByEntityMode = new HashMap();
 
 	public NonFlushedChangesImpl( EventSource session ) {
 		extractFromSession( session );
 	}
 
 	public void extractFromSession(EventSource session) {
 		if ( nonFlushedChangesByEntityMode.containsKey( session.getEntityMode() ) ) {
 			throw new AssertionFailure( "Already has non-flushed changes for entity mode: " + session.getEntityMode() );
 		}
 		nonFlushedChangesByEntityMode.put( session.getEntityMode(), new SessionNonFlushedChanges( session ) );
 	}
 
 	private SessionNonFlushedChanges getSessionNonFlushedChanges(EntityMode entityMode) {
 		return ( SessionNonFlushedChanges ) nonFlushedChangesByEntityMode.get( entityMode );
 	}
 
 	/* package-protected */
 	ActionQueue getActionQueue(EntityMode entityMode) {
 		return getSessionNonFlushedChanges( entityMode ).actionQueue;
 	}
 
 	/* package-protected */
 	StatefulPersistenceContext getPersistenceContext(EntityMode entityMode) {
 		return getSessionNonFlushedChanges( entityMode ).persistenceContext;
 	}
 
 	public void clear() {
 		nonFlushedChangesByEntityMode.clear();
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryImpl.java
index acc9bf4d82..8400d17551 100644
--- a/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryImpl.java
@@ -1,1169 +1,1169 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.impl;
 
 import javax.naming.NamingException;
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.ObjectStreamException;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.ServiceLoader;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.StatelessSession;
 import org.hibernate.TypeHelper;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.CollectionRegion;
 import org.hibernate.cache.EntityRegion;
 import org.hibernate.cache.QueryCache;
 import org.hibernate.cache.Region;
 import org.hibernate.cache.UpdateTimestampsCache;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.impl.CacheDataDescriptionImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
 import org.hibernate.cfg.beanvalidation.BeanValidationIntegrator;
 import org.hibernate.cfg.search.HibernateSearchIntegrator;
 import org.hibernate.context.CurrentSessionContext;
 import org.hibernate.context.JTASessionContext;
 import org.hibernate.context.ManagedSessionContext;
 import org.hibernate.context.ThreadLocalSessionContext;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.profile.Association;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.QueryPlanCache;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.collections.EmptyIterator;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterFactory;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistryFactory;
 import org.hibernate.spi.Integrator;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 import org.hibernate.tool.hbm2ddl.SchemaValidator;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
 
 /**
  * Concrete implementation of the <tt>SessionFactory</tt> interface. Has the following
  * responsibilities
  * <ul>
  * <li>caches configuration settings (immutably)
  * <li>caches "compiled" mappings ie. <tt>EntityPersister</tt>s and
  *     <tt>CollectionPersister</tt>s (immutable)
  * <li>caches "compiled" queries (memory sensitive cache)
  * <li>manages <tt>PreparedStatement</tt>s
  * <li> delegates JDBC <tt>Connection</tt> management to the <tt>ConnectionProvider</tt>
  * <li>factory for instances of <tt>SessionImpl</tt>
  * </ul>
  * This class must appear immutable to clients, even if it does all kinds of caching
  * and pooling under the covers. It is crucial that the class is not only thread
  * safe, but also highly concurrent. Synchronization must be used extremely sparingly.
  *
  * @see org.hibernate.service.jdbc.connections.spi.ConnectionProvider
  * @see org.hibernate.Session
  * @see org.hibernate.hql.QueryTranslator
  * @see org.hibernate.persister.entity.EntityPersister
  * @see org.hibernate.persister.collection.CollectionPersister
  * @author Gavin King
  */
 public final class SessionFactoryImpl
 		implements SessionFactory, SessionFactoryImplementor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SessionFactoryImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionFactoryImpl.class.getName());
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
 	private final String name;
 	private final String uuid;
 
 	private final transient Map entityPersisters;
 	private final transient Map<String,ClassMetadata> classMetadata;
 	private final transient Map collectionPersisters;
 	private final transient Map collectionMetadata;
 	private final transient Map<String,Set<String>> collectionRolesByEntityParticipant;
 	private final transient Map identifierGenerators;
 	private final transient Map namedQueries;
 	private final transient Map namedSqlQueries;
 	private final transient Map sqlResultSetMappings;
 	private final transient Map filters;
 	private final transient Map fetchProfiles;
 	private final transient Map imports;
 	private final transient Interceptor interceptor;
 	private final transient SessionFactoryServiceRegistry serviceRegistry;
 	private final transient Settings settings;
 	private final transient Properties properties;
 	private transient SchemaExport schemaExport;
 	private final transient QueryCache queryCache;
 	private final transient UpdateTimestampsCache updateTimestampsCache;
 	private final transient Map<String,QueryCache> queryCaches;
 	private final transient ConcurrentMap<String,Region> allCacheRegions = new ConcurrentHashMap<String, Region>();
 	private final transient CurrentSessionContext currentSessionContext;
 	private final transient EntityNotFoundDelegate entityNotFoundDelegate;
 	private final transient SQLFunctionRegistry sqlFunctionRegistry;
 	private final transient SessionFactoryObserverChain observer = new SessionFactoryObserverChain();
 	private final transient HashMap entityNameResolvers = new HashMap();
 	private final transient QueryPlanCache queryPlanCache;
 	private final transient Cache cacheAccess = new CacheImpl();
 	private transient boolean isClosed = false;
 	private final transient TypeResolver typeResolver;
 	private final transient TypeHelper typeHelper;
 	private final transient TransactionEnvironment transactionEnvironment;
 
 	public SessionFactoryImpl(
 			Configuration cfg,
 	        Mapping mapping,
 			ServiceRegistry serviceRegistry,
 	        Settings settings,
 			SessionFactoryObserver observer) throws HibernateException {
         LOG.buildingSessionFactory();
 
 		this.settings = settings;
 		this.interceptor = cfg.getInterceptor();
 
 		this.properties = new Properties();
 		this.properties.putAll( cfg.getProperties() );
 
 		this.serviceRegistry = serviceRegistry.getService( SessionFactoryServiceRegistryFactory.class ).buildServiceRegistry(
 				this,
 				cfg
 		);
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), cfg.getSqlFunctions() );
 		if ( observer != null ) {
 			this.observer.addObserver( observer );
 		}
 
 		this.typeResolver = cfg.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap();
 		this.filters.putAll( cfg.getFilterDefinitions() );
 
         LOG.debugf("Session factory constructed with filter configurations : %s", filters);
         LOG.debugf("Instantiating session factory with properties: %s", properties);
 
 		// Caches
 		settings.getRegionFactory().start( settings, properties );
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		// todo : everything above here consider implementing as standard SF service.  specifically: stats, caches, types, function-reg
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
 			}
 		}
 
 		final IntegratorObserver integratorObserver = new IntegratorObserver();
 		this.observer.addObserver( integratorObserver );
 		for ( Integrator integrator : locateIntegrators( this.serviceRegistry ) ) {
 			integrator.integrate( cfg, this, this.serviceRegistry );
 			integratorObserver.integrators.add( integrator );
 		}
 
 		//Generators:
 
 		identifierGenerators = new HashMap();
 		Iterator classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			PersistentClass model = (PersistentClass) classes.next();
 			if ( !model.isInherited() ) {
 				IdentifierGenerator generator = model.getIdentifier().createIdentifierGenerator(
 						cfg.getIdentifierGeneratorFactory(),
 						getDialect(),
 				        settings.getDefaultCatalogName(),
 				        settings.getDefaultSchemaName(),
 				        (RootClass) model
 				);
 				identifierGenerators.put( model.getEntityName(), generator );
 			}
 		}
 
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		final String cacheRegionPrefix = settings.getCacheRegionPrefix() == null ? "" : settings.getCacheRegionPrefix() + ".";
 
 		entityPersisters = new HashMap();
 		Map entityAccessStrategies = new HashMap();
 		Map<String,ClassMetadata> classMeta = new HashMap<String,ClassMetadata>();
 		classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			final PersistentClass model = (PersistentClass) classes.next();
 			model.prepareTemporaryTables( mapping, getDialect() );
 			final String cacheRegionName = cacheRegionPrefix + model.getRootClass().getCacheRegionName();
 			// cache region is defined by the root-class in the hierarchy...
 			EntityRegionAccessStrategy accessStrategy = ( EntityRegionAccessStrategy ) entityAccessStrategies.get( cacheRegionName );
 			if ( accessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 				final AccessType accessType = AccessType.parse( model.getCacheConcurrencyStrategy() );
 				if ( accessType != null ) {
                     LOG.trace("Building cache for entity data [" + model.getEntityName() + "]");
 					EntityRegion entityRegion = settings.getRegionFactory().buildEntityRegion( cacheRegionName, properties, CacheDataDescriptionImpl.decode( model ) );
 					accessStrategy = entityRegion.buildAccessStrategy( accessType );
 					entityAccessStrategies.put( cacheRegionName, accessStrategy );
 					allCacheRegions.put( cacheRegionName, entityRegion );
 				}
 			}
 			EntityPersister cp = serviceRegistry.getService( PersisterFactory.class ).createEntityPersister(
 					model,
 					accessStrategy,
 					this,
 					mapping
 			);
 			entityPersisters.put( model.getEntityName(), cp );
 			classMeta.put( model.getEntityName(), cp.getClassMetadata() );
 		}
 		this.classMetadata = Collections.unmodifiableMap(classMeta);
 
 		Map<String,Set<String>> tmpEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		collectionPersisters = new HashMap();
 		Iterator collections = cfg.getCollectionMappings();
 		while ( collections.hasNext() ) {
 			Collection model = (Collection) collections.next();
 			final String cacheRegionName = cacheRegionPrefix + model.getCacheRegionName();
 			final AccessType accessType = AccessType.parse( model.getCacheConcurrencyStrategy() );
 			CollectionRegionAccessStrategy accessStrategy = null;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
                 LOG.trace("Building cache for collection data [" + model.getRole() + "]");
 				CollectionRegion collectionRegion = settings.getRegionFactory().buildCollectionRegion( cacheRegionName, properties, CacheDataDescriptionImpl.decode( model ) );
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				entityAccessStrategies.put( cacheRegionName, accessStrategy );
 				allCacheRegions.put( cacheRegionName, collectionRegion );
 			}
 			CollectionPersister persister = serviceRegistry.getService( PersisterFactory.class ).createCollectionPersister(
 					cfg,
 					model,
 					accessStrategy,
 					this
 			) ;
 			collectionPersisters.put( model.getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		collectionMetadata = Collections.unmodifiableMap(collectionPersisters);
 		Iterator itr = tmpEntityToCollectionRoleMap.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			entry.setValue( Collections.unmodifiableSet( ( Set ) entry.getValue() ) );
 		}
 		collectionRolesByEntityParticipant = Collections.unmodifiableMap( tmpEntityToCollectionRoleMap );
 
 		//Named Queries:
 		namedQueries = new HashMap( cfg.getNamedQueries() );
 		namedSqlQueries = new HashMap( cfg.getNamedSQLQueries() );
 		sqlResultSetMappings = new HashMap( cfg.getSqlResultSetMappings() );
 		imports = new HashMap( cfg.getImports() );
 
 		// after *all* persisters and named queries are registered
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final EntityPersister persister = ( ( EntityPersister ) iter.next() );
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 
 		}
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final CollectionPersister persister = ( ( CollectionPersister ) iter.next() );
 			persister.postInstantiate();
 		}
 
 		//JNDI + Serialization:
 
 		name = settings.getSessionFactoryName();
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 		SessionFactoryObjectFactory.addInstance(uuid, name, this, properties);
 
         LOG.debugf("Instantiated session factory");
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( serviceRegistry, cfg ).create( false, true );
 		}
 		if ( settings.isAutoUpdateSchema() ) {
 			new SchemaUpdate( serviceRegistry, cfg ).execute( false, true );
 		}
 		if ( settings.isAutoValidateSchema() ) {
 			new SchemaValidator( serviceRegistry, cfg ).validate();
 		}
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( serviceRegistry, cfg );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		if ( settings.isQueryCacheEnabled() ) {
 			updateTimestampsCache = new UpdateTimestampsCache(settings, properties);
 			queryCache = settings.getQueryCacheFactory()
 			        .getQueryCache(null, updateTimestampsCache, settings, properties);
 			queryCaches = new HashMap<String,QueryCache>();
 			allCacheRegions.put( updateTimestampsCache.getRegion().getName(), updateTimestampsCache.getRegion() );
 			allCacheRegions.put( queryCache.getRegion().getName(), queryCache.getRegion() );
 		}
 		else {
 			updateTimestampsCache = null;
 			queryCache = null;
 			queryCaches = null;
 		}
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			Map errors = checkNamedQueries();
 			if ( !errors.isEmpty() ) {
 				Set keys = errors.keySet();
 				StringBuffer failingQueries = new StringBuffer( "Errors in named queries: " );
 				for ( Iterator iterator = keys.iterator() ; iterator.hasNext() ; ) {
 					String queryName = ( String ) iterator.next();
 					HibernateException e = ( HibernateException ) errors.get( queryName );
 					failingQueries.append( queryName );
                     if (iterator.hasNext()) failingQueries.append(", ");
                     LOG.namedQueryError(queryName, e);
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// EntityNotFoundDelegate
 		EntityNotFoundDelegate entityNotFoundDelegate = cfg.getEntityNotFoundDelegate();
 		if ( entityNotFoundDelegate == null ) {
 			entityNotFoundDelegate = new EntityNotFoundDelegate() {
 				public void handleEntityNotFound(String entityName, Serializable id) {
 					throw new ObjectNotFoundException( id, entityName );
 				}
 			};
 		}
 		this.entityNotFoundDelegate = entityNotFoundDelegate;
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap();
 		itr = cfg.iterateFetchProfiles();
 		while ( itr.hasNext() ) {
 			final org.hibernate.mapping.FetchProfile mappingProfile =
 					( org.hibernate.mapping.FetchProfile ) itr.next();
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			Iterator fetches = mappingProfile.getFetches().iterator();
 			while ( fetches.hasNext() ) {
 				final org.hibernate.mapping.FetchProfile.Fetch mappingFetch =
 						( org.hibernate.mapping.FetchProfile.Fetch ) fetches.next();
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = ( EntityPersister ) ( entityName == null ? null : entityPersisters.get( entityName ) );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || !associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				( ( Loadable ) owner ).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.transactionEnvironment = new TransactionEnvironmentImpl( this );
 		this.observer.sessionFactoryCreated( this );
 	}
 
 	private Iterable<Integrator> locateIntegrators(ServiceRegistryImplementor serviceRegistry) {
 		List<Integrator> integrators = new ArrayList<Integrator>();
 
 		// todo : Envers needs to be handled by discovery to be because it is in a separate project
 		integrators.add( new BeanValidationIntegrator() );
 		integrators.add( new HibernateSearchIntegrator() );
 
 		for ( Integrator integrator : ServiceLoader.load( Integrator.class ) ) {
 			integrators.add( integrator );
 		}
 
 		return integrators;
 	}
 
 	public Session openSession() throws HibernateException {
 		return withOptions().openSession();
 	}
 
 	public Session openTemporarySession() throws HibernateException {
 		return withOptions()
 				.autoClose( false )
 				.flushBeforeCompletion( false )
 				.connectionReleaseMode( ConnectionReleaseMode.AFTER_STATEMENT )
 				.openSession();
 	}
 
 	public Session getCurrentSession() throws HibernateException {
 		if ( currentSessionContext == null ) {
 			throw new HibernateException( "No CurrentSessionContext configured!" );
 		}
 		return currentSessionContext.currentSession();
 	}
 
 	@Override
 	public SessionBuilder withOptions() {
 		return new SessionBuilderImpl( this );
 	}
 
 	public StatelessSession openStatelessSession() {
 		return new StatelessSessionImpl( null, this );
 	}
 
 	public StatelessSession openStatelessSession(Connection connection) {
 		return new StatelessSessionImpl( connection, this );
 	}
 
 	@Override
 	public void addObserver(SessionFactoryObserver observer) {
 		this.observer.addObserver( observer );
 	}
 
 	public TransactionEnvironment getTransactionEnvironment() {
 		return transactionEnvironment;
 	}
 
 	public Properties getProperties() {
 		return properties;
 	}
 
 	public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return null;
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	private void registerEntityNameResolvers(EntityPersister persister) {
 		if ( persister.getEntityMetamodel() == null || persister.getEntityMetamodel().getTuplizerMapping() == null ) {
 			return;
 		}
 		Iterator itr = persister.getEntityMetamodel().getTuplizerMapping().iterateTuplizers();
 		while ( itr.hasNext() ) {
 			final EntityTuplizer tuplizer = ( EntityTuplizer ) itr.next();
 			registerEntityNameResolvers( tuplizer );
 		}
 	}
 
 	private void registerEntityNameResolvers(EntityTuplizer tuplizer) {
 		EntityNameResolver[] resolvers = tuplizer.getEntityNameResolvers();
 		if ( resolvers == null ) {
 			return;
 		}
 
 		for ( int i = 0; i < resolvers.length; i++ ) {
 			registerEntityNameResolver( resolvers[i], tuplizer.getEntityMode() );
 		}
 	}
 
 	public void registerEntityNameResolver(EntityNameResolver resolver, EntityMode entityMode) {
 		LinkedHashSet resolversForMode = ( LinkedHashSet ) entityNameResolvers.get( entityMode );
 		if ( resolversForMode == null ) {
 			resolversForMode = new LinkedHashSet();
 			entityNameResolvers.put( entityMode, resolversForMode );
 		}
 		resolversForMode.add( resolver );
 	}
 
 	public Iterator iterateEntityNameResolvers(EntityMode entityMode) {
 		Set actualEntityNameResolvers = ( Set ) entityNameResolvers.get( entityMode );
 		return actualEntityNameResolvers == null
 				? EmptyIterator.INSTANCE
 				: actualEntityNameResolvers.iterator();
 	}
 
 	public QueryPlanCache getQueryPlanCache() {
 		return queryPlanCache;
 	}
 
 	private Map checkNamedQueries() throws HibernateException {
 		Map errors = new HashMap();
 
 		// Check named HQL queries
         LOG.debugf("Checking %s named HQL queries", namedQueries.size());
 		Iterator itr = namedQueries.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String queryName = ( String ) entry.getKey();
 			final NamedQueryDefinition qd = ( NamedQueryDefinition ) entry.getValue();
 			// this will throw an error if there's something wrong.
 			try {
                 LOG.debugf("Checking named query: %s", queryName);
 				//TODO: BUG! this currently fails for named queries for non-POJO entities
 				queryPlanCache.getHQLQueryPlan( qd.getQueryString(), false, CollectionHelper.EMPTY_MAP );
 			}
 			catch ( QueryException e ) {
 				errors.put( queryName, e );
 			}
 			catch ( MappingException e ) {
 				errors.put( queryName, e );
 			}
 		}
 
         LOG.debugf("Checking %s named SQL queries", namedSqlQueries.size());
 		itr = namedSqlQueries.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String queryName = ( String ) entry.getKey();
 			final NamedSQLQueryDefinition qd = ( NamedSQLQueryDefinition ) entry.getValue();
 			// this will throw an error if there's something wrong.
 			try {
                 LOG.debugf("Checking named SQL query: %s", queryName);
 				// TODO : would be really nice to cache the spec on the query-def so as to not have to re-calc the hash;
 				// currently not doable though because of the resultset-ref stuff...
 				NativeSQLQuerySpecification spec;
 				if ( qd.getResultSetRef() != null ) {
 					ResultSetMappingDefinition definition = ( ResultSetMappingDefinition ) sqlResultSetMappings.get( qd.getResultSetRef() );
 					if ( definition == null ) {
 						throw new MappingException( "Unable to find resultset-ref definition: " + qd.getResultSetRef() );
 					}
 					spec = new NativeSQLQuerySpecification(
 							qd.getQueryString(),
 					        definition.getQueryReturns(),
 					        qd.getQuerySpaces()
 					);
 				}
 				else {
 					spec =  new NativeSQLQuerySpecification(
 							qd.getQueryString(),
 					        qd.getQueryReturns(),
 					        qd.getQuerySpaces()
 					);
 				}
 				queryPlanCache.getNativeSQLQueryPlan( spec );
 			}
 			catch ( QueryException e ) {
 				errors.put( queryName, e );
 			}
 			catch ( MappingException e ) {
 				errors.put( queryName, e );
 			}
 		}
 
 		return errors;
 	}
 
 	public EntityPersister getEntityPersister(String entityName) throws MappingException {
 		EntityPersister result = (EntityPersister) entityPersisters.get(entityName);
 		if (result==null) {
 			throw new MappingException( "Unknown entity: " + entityName );
 		}
 		return result;
 	}
 
 	public CollectionPersister getCollectionPersister(String role) throws MappingException {
 		CollectionPersister result = (CollectionPersister) collectionPersisters.get(role);
 		if (result==null) {
 			throw new MappingException( "Unknown collection role: " + role );
 		}
 		return result;
 	}
 
 	public Settings getSettings() {
 		return settings;
 	}
 
 	public JdbcServices getJdbcServices() {
 		return serviceRegistry.getService( JdbcServices.class );
 	}
 
 	public Dialect getDialect() {
 		if ( serviceRegistry == null ) {
 			throw new IllegalStateException( "Cannot determine dialect because serviceRegistry is null." );
 		}
 		return getJdbcServices().getDialect();
 	}
 
 	public Interceptor getInterceptor()
 	{
 		return interceptor;
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	public SqlExceptionHelper getSQLExceptionHelper() {
 		return getJdbcServices().getSqlExceptionHelper();
 	}
 
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName) {
 		return collectionRolesByEntityParticipant.get( entityName );
 	}
 
 	// from javax.naming.Referenceable
 	public Reference getReference() throws NamingException {
         LOG.debugf( "Returning a Reference to the SessionFactory" );
 		return new Reference(
 			SessionFactoryImpl.class.getName(),
 		    new StringRefAddr("uuid", uuid),
 		    SessionFactoryObjectFactory.class.getName(),
 		    null
 		);
 	}
 
 	private Object readResolve() throws ObjectStreamException {
         LOG.trace("Resolving serialized SessionFactory");
 		// look for the instance by uuid
 		Object result = SessionFactoryObjectFactory.getInstance(uuid);
 		if (result==null) {
 			// in case we were deserialized in a different JVM, look for an instance with the same name
 			// (alternatively we could do an actual JNDI lookup here....)
 			result = SessionFactoryObjectFactory.getNamedInstance(name);
             if (result == null) throw new InvalidObjectException("Could not find a SessionFactory named: " + name);
             LOG.debugf("Resolved SessionFactory by name");
         } else LOG.debugf("Resolved SessionFactory by UID");
 		return result;
 	}
 
 	public NamedQueryDefinition getNamedQuery(String queryName) {
 		return (NamedQueryDefinition) namedQueries.get(queryName);
 	}
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName) {
 		return (NamedSQLQueryDefinition) namedSqlQueries.get(queryName);
 	}
 
 	public ResultSetMappingDefinition getResultSetMapping(String resultSetName) {
 		return (ResultSetMappingDefinition) sqlResultSetMappings.get(resultSetName);
 	}
 
 	public Type getIdentifierType(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierType();
 	}
 	public String getIdentifierPropertyName(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierPropertyName();
 	}
 
 	private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
         LOG.trace( "Deserializing" );
 		in.defaultReadObject();
         LOG.debugf( "Deserialized: %s", uuid );
 	}
 
 	private void writeObject(ObjectOutputStream out) throws IOException {
         LOG.debugf("Serializing: %s", uuid);
 		out.defaultWriteObject();
         LOG.trace("Serialized");
 	}
 
 	public Type[] getReturnTypes(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, CollectionHelper.EMPTY_MAP ).getReturnMetadata().getReturnTypes();
 	}
 
 	public String[] getReturnAliases(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, CollectionHelper.EMPTY_MAP ).getReturnMetadata().getReturnAliases();
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getClassMetadata( persistentClass.getName() );
 	}
 
 	public CollectionMetadata getCollectionMetadata(String roleName) throws HibernateException {
 		return (CollectionMetadata) collectionMetadata.get(roleName);
 	}
 
 	public ClassMetadata getClassMetadata(String entityName) throws HibernateException {
 		return classMetadata.get(entityName);
 	}
 
 	/**
 	 * Return the names of all persistent (mapped) classes that extend or implement the
 	 * given class or interface, accounting for implicit/explicit polymorphism settings
 	 * and excluding mapped subclasses/joined-subclasses of other classes in the result.
 	 */
 	public String[] getImplementors(String className) throws MappingException {
 
 		final Class clazz;
 		try {
 			clazz = ReflectHelper.classForName(className);
 		}
 		catch (ClassNotFoundException cnfe) {
 			return new String[] { className }; //for a dynamic-class
 		}
 
 		ArrayList results = new ArrayList();
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			//test this entity to see if we must query it
 			EntityPersister testPersister = (EntityPersister) iter.next();
 			if ( testPersister instanceof Queryable ) {
 				Queryable testQueryable = (Queryable) testPersister;
 				String testClassName = testQueryable.getEntityName();
 				boolean isMappedClass = className.equals(testClassName);
 				if ( testQueryable.isExplicitPolymorphism() ) {
 					if ( isMappedClass ) {
 						return new String[] {className}; //NOTE EARLY EXIT
 					}
 				}
 				else {
 					if (isMappedClass) {
 						results.add(testClassName);
 					}
 					else {
 						final Class mappedClass = testQueryable.getMappedClass( EntityMode.POJO );
 						if ( mappedClass!=null && clazz.isAssignableFrom( mappedClass ) ) {
 							final boolean assignableSuperclass;
 							if ( testQueryable.isInherited() ) {
 								Class mappedSuperclass = getEntityPersister( testQueryable.getMappedSuperclass() ).getMappedClass( EntityMode.POJO);
 								assignableSuperclass = clazz.isAssignableFrom(mappedSuperclass);
 							}
 							else {
 								assignableSuperclass = false;
 							}
 							if ( !assignableSuperclass ) {
 								results.add( testClassName );
 							}
 						}
 					}
 				}
 			}
 		}
 		return (String[]) results.toArray( new String[ results.size() ] );
 	}
 
 	public String getImportedClassName(String className) {
 		String result = (String) imports.get(className);
 		if (result==null) {
 			try {
 				ReflectHelper.classForName( className );
 				return className;
 			}
 			catch (ClassNotFoundException cnfe) {
 				return null;
 			}
 		}
 		else {
 			return result;
 		}
 	}
 
 	public Map<String,ClassMetadata> getAllClassMetadata() throws HibernateException {
 		return classMetadata;
 	}
 
 	public Map getAllCollectionMetadata() throws HibernateException {
 		return collectionMetadata;
 	}
 
 	public Type getReferencedPropertyType(String className, String propertyName)
 		throws MappingException {
 		return getEntityPersister( className ).getPropertyType( propertyName );
 	}
 
 	public ConnectionProvider getConnectionProvider() {
 		return serviceRegistry.getService( JdbcServices.class ).getConnectionProvider();
 	}
 
 	/**
 	 * Closes the session factory, releasing all held resources.
 	 *
 	 * <ol>
 	 * <li>cleans up used cache regions and "stops" the cache provider.
 	 * <li>close the JDBC connection
 	 * <li>remove the JNDI binding
 	 * </ol>
 	 *
 	 * Note: Be aware that the sessionFactory instance still can
 	 * be a "heavy" object memory wise after close() has been called.  Thus
 	 * it is important to not keep referencing the instance to let the garbage
 	 * collector release the memory.
 	 */
 	public void close() throws HibernateException {
 
 		if ( isClosed ) {
             LOG.trace("Already closed");
 			return;
 		}
 
         LOG.closing();
 
 		isClosed = true;
 
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			EntityPersister p = (EntityPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = (CollectionPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		if ( settings.isQueryCacheEnabled() )  {
 			queryCache.destroy();
 
 			iter = queryCaches.values().iterator();
 			while ( iter.hasNext() ) {
 				QueryCache cache = (QueryCache) iter.next();
 				cache.destroy();
 			}
 			updateTimestampsCache.destroy();
 		}
 
 		settings.getRegionFactory().stop();
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport.drop( false, true );
 		}
 
 		SessionFactoryObjectFactory.removeInstance(uuid, name, properties);
 
 		observer.sessionFactoryClosed( this );
 		serviceRegistry.destroy();
 	}
 
 	private class CacheImpl implements Cache {
 		public boolean containsEntity(Class entityClass, Serializable identifier) {
 			return containsEntity( entityClass.getName(), identifier );
 		}
 
 		public boolean containsEntity(String entityName, Serializable identifier) {
 			EntityPersister p = getEntityPersister( entityName );
 			return p.hasCache() &&
 					p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( identifier, p ) );
 		}
 
 		public void evictEntity(Class entityClass, Serializable identifier) {
 			evictEntity( entityClass.getName(), identifier );
 		}
 
 		public void evictEntity(String entityName, Serializable identifier) {
 			EntityPersister p = getEntityPersister( entityName );
 			if ( p.hasCache() ) {
                 if (LOG.isDebugEnabled()) LOG.debugf("Evicting second-level cache: %s",
                                                      MessageHelper.infoString(p, identifier, SessionFactoryImpl.this));
 				p.getCacheAccessStrategy().evict( buildCacheKey( identifier, p ) );
 			}
 		}
 
 		private CacheKey buildCacheKey(Serializable identifier, EntityPersister p) {
 			return new CacheKey(
 					identifier,
 					p.getIdentifierType(),
 					p.getRootEntityName(),
 					EntityMode.POJO,			// we have to assume POJO
 					null, 						// and also assume non tenancy
 					SessionFactoryImpl.this
 			);
 		}
 
 		public void evictEntityRegion(Class entityClass) {
 			evictEntityRegion( entityClass.getName() );
 		}
 
 		public void evictEntityRegion(String entityName) {
 			EntityPersister p = getEntityPersister( entityName );
 			if ( p.hasCache() ) {
                 LOG.debugf("Evicting second-level cache: %s", p.getEntityName());
 				p.getCacheAccessStrategy().evictAll();
 			}
 		}
 
 		public void evictEntityRegions() {
 			Iterator entityNames = entityPersisters.keySet().iterator();
 			while ( entityNames.hasNext() ) {
 				evictEntityRegion( ( String ) entityNames.next() );
 			}
 		}
 
 		public boolean containsCollection(String role, Serializable ownerIdentifier) {
 			CollectionPersister p = getCollectionPersister( role );
 			return p.hasCache() &&
 					p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( ownerIdentifier, p ) );
 		}
 
 		public void evictCollection(String role, Serializable ownerIdentifier) {
 			CollectionPersister p = getCollectionPersister( role );
 			if ( p.hasCache() ) {
                 if (LOG.isDebugEnabled()) LOG.debugf("Evicting second-level cache: %s",
                                                      MessageHelper.collectionInfoString(p, ownerIdentifier, SessionFactoryImpl.this));
 				CacheKey cacheKey = buildCacheKey( ownerIdentifier, p );
 				p.getCacheAccessStrategy().evict( cacheKey );
 			}
 		}
 
 		private CacheKey buildCacheKey(Serializable ownerIdentifier, CollectionPersister p) {
 			return new CacheKey(
 					ownerIdentifier,
 					p.getKeyType(),
 					p.getRole(),
 					EntityMode.POJO,			// we have to assume POJO
 					null,						// and also assume non tenancy
 					SessionFactoryImpl.this
 			);
 		}
 
 		public void evictCollectionRegion(String role) {
 			CollectionPersister p = getCollectionPersister( role );
 			if ( p.hasCache() ) {
                 LOG.debugf("Evicting second-level cache: %s", p.getRole());
 				p.getCacheAccessStrategy().evictAll();
 			}
 		}
 
 		public void evictCollectionRegions() {
 			Iterator collectionRoles = collectionPersisters.keySet().iterator();
 			while ( collectionRoles.hasNext() ) {
 				evictCollectionRegion( ( String ) collectionRoles.next() );
 			}
 		}
 
 		public boolean containsQuery(String regionName) {
 			return queryCaches.get( regionName ) != null;
 		}
 
 		public void evictDefaultQueryRegion() {
 			if ( settings.isQueryCacheEnabled() ) {
 				queryCache.clear();
 			}
 		}
 
 		public void evictQueryRegion(String regionName) {
             if (regionName == null) throw new NullPointerException(
                                                                    "Region-name cannot be null (use Cache#evictDefaultQueryRegion to evict the default query cache)");
             if (settings.isQueryCacheEnabled()) {
                 QueryCache namedQueryCache = queryCaches.get(regionName);
                 // TODO : cleanup entries in queryCaches + allCacheRegions ?
                 if (namedQueryCache != null) namedQueryCache.clear();
 			}
 		}
 
 		public void evictQueryRegions() {
 			if ( queryCaches != null ) {
 				for ( QueryCache queryCache : queryCaches.values() ) {
 					queryCache.clear();
 					// TODO : cleanup entries in queryCaches + allCacheRegions ?
 				}
 			}
 		}
 	}
 
 	public Cache getCache() {
 		return cacheAccess;
 	}
 
 	public void evictEntity(String entityName, Serializable id) throws HibernateException {
 		getCache().evictEntity( entityName, id );
 	}
 
 	public void evictEntity(String entityName) throws HibernateException {
 		getCache().evictEntityRegion( entityName );
 	}
 
 	public void evict(Class persistentClass, Serializable id) throws HibernateException {
 		getCache().evictEntity( persistentClass, id );
 	}
 
 	public void evict(Class persistentClass) throws HibernateException {
 		getCache().evictEntityRegion( persistentClass );
 	}
 
 	public void evictCollection(String roleName, Serializable id) throws HibernateException {
 		getCache().evictCollection( roleName, id );
 	}
 
 	public void evictCollection(String roleName) throws HibernateException {
 		getCache().evictCollectionRegion( roleName );
 	}
 
 	public void evictQueries() throws HibernateException {
 		if ( settings.isQueryCacheEnabled() ) {
 			queryCache.clear();
 		}
 	}
 
 	public void evictQueries(String regionName) throws HibernateException {
 		getCache().evictQueryRegion( regionName );
 	}
 
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return updateTimestampsCache;
 	}
 
 	public QueryCache getQueryCache() {
 		return queryCache;
 	}
 
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		if ( regionName == null ) {
 			return getQueryCache();
 		}
 
 		if ( !settings.isQueryCacheEnabled() ) {
 			return null;
 		}
 
 		QueryCache currentQueryCache = queryCaches.get( regionName );
 		if ( currentQueryCache == null ) {
 			currentQueryCache = settings.getQueryCacheFactory().getQueryCache( regionName, updateTimestampsCache, settings, properties );
 			queryCaches.put( regionName, currentQueryCache );
 			allCacheRegions.put( currentQueryCache.getRegion().getName(), currentQueryCache.getRegion() );
 		}
 
 		return currentQueryCache;
 	}
 
 	public Region getSecondLevelCacheRegion(String regionName) {
 		return allCacheRegions.get( regionName );
 	}
 
 	public Map getAllSecondLevelCacheRegions() {
 		return new HashMap( allCacheRegions );
 	}
 
 	public boolean isClosed() {
 		return isClosed;
 	}
 
 	public Statistics getStatistics() {
 		return getStatisticsImplementor();
 	}
 
 	public StatisticsImplementor getStatisticsImplementor() {
 		return serviceRegistry.getService( StatisticsImplementor.class );
 	}
 
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException {
diff --git a/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryObjectFactory.java b/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryObjectFactory.java
index e54c4b0034..f942f2b078 100644
--- a/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryObjectFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryObjectFactory.java
@@ -1,167 +1,169 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.impl;
 import java.util.Hashtable;
 import java.util.Iterator;
 import java.util.Properties;
 import java.util.concurrent.ConcurrentHashMap;
 import javax.naming.Context;
 import javax.naming.InvalidNameException;
 import javax.naming.Name;
 import javax.naming.NamingException;
 import javax.naming.Reference;
 import javax.naming.event.EventContext;
 import javax.naming.event.NamespaceChangeListener;
 import javax.naming.event.NamingEvent;
 import javax.naming.event.NamingExceptionEvent;
 import javax.naming.event.NamingListener;
 import javax.naming.spi.ObjectFactory;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.SessionFactory;
 import org.hibernate.internal.util.jndi.JndiHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * Resolves {@link SessionFactory} instances during <tt>JNDI<tt> look-ups as well as during deserialization
  */
 public class SessionFactoryObjectFactory implements ObjectFactory {
 
 	@SuppressWarnings({ "UnusedDeclaration" })
 	private static final SessionFactoryObjectFactory INSTANCE; //to stop the class from being unloaded
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        SessionFactoryObjectFactory.class.getName());
 
 	static {
 		INSTANCE = new SessionFactoryObjectFactory();
         LOG.debugf("Initializing class SessionFactoryObjectFactory");
 	}
 
 	private static final ConcurrentHashMap<String, SessionFactory> INSTANCES = new ConcurrentHashMap<String, SessionFactory>();
 	private static final ConcurrentHashMap<String, SessionFactory> NAMED_INSTANCES = new ConcurrentHashMap<String, SessionFactory>();
 
 	private static final NamingListener LISTENER = new NamespaceChangeListener() {
 		public void objectAdded(NamingEvent evt) {
             LOG.debugf("A factory was successfully bound to name: %s", evt.getNewBinding().getName());
 		}
 		public void objectRemoved(NamingEvent evt) {
 			String name = evt.getOldBinding().getName();
             LOG.factoryUnboundFromName(name);
 			Object instance = NAMED_INSTANCES.remove(name);
 			Iterator iter = INSTANCES.values().iterator();
 			while ( iter.hasNext() ) {
 				if ( iter.next()==instance ) iter.remove();
 			}
 		}
 		public void objectRenamed(NamingEvent evt) {
 			String name = evt.getOldBinding().getName();
             LOG.factoryRenamedFromName(name);
 			NAMED_INSTANCES.put( evt.getNewBinding().getName(), NAMED_INSTANCES.remove(name) );
 		}
 		public void namingExceptionThrown(NamingExceptionEvent evt) {
 			//noinspection ThrowableResultOfMethodCallIgnored
             LOG.namingExceptionAccessingFactory(evt.getException());
 		}
 	};
 
 	public Object getObjectInstance(Object reference, Name name, Context ctx, Hashtable env) throws Exception {
         LOG.debugf("JNDI lookup: %s", name);
 		String uid = (String) ( (Reference) reference ).get(0).getContent();
 		return getInstance(uid);
 	}
 
 	public static void addInstance(String uid, String name, SessionFactory instance, Properties properties) {
         LOG.debugf("Registered: %s (%s)", uid, name == null ? "<unnamed>" : name);
 		INSTANCES.put(uid, instance);
 		if (name!=null) NAMED_INSTANCES.put(name, instance);
 
 		//must add to JNDI _after_ adding to HashMaps, because some JNDI servers use serialization
         if (name == null) LOG.notBindingFactoryToJndi();
 		else {
             LOG.factoryName(name);
 
 			try {
 				Context ctx = JndiHelper.getInitialContext(properties);
 				JndiHelper.bind(ctx, name, instance);
                 LOG.factoryBoundToJndiName(name);
 				( (EventContext) ctx ).addNamingListener(name, EventContext.OBJECT_SCOPE, LISTENER);
 			}
 			catch (InvalidNameException ine) {
                 LOG.invalidJndiName(name, ine);
 			}
 			catch (NamingException ne) {
                 LOG.unableToBindFactoryToJndi(ne);
 			}
 			catch(ClassCastException cce) {
                 LOG.initialContextDidNotImplementEventContext();
 			}
 		}
 	}
 
 	public static void removeInstance(String uid, String name, Properties properties) {
 		//TODO: theoretically non-threadsafe...
 
 		if (name!=null) {
             LOG.unbindingFactoryFromJndiName(name);
 
 			try {
 				Context ctx = JndiHelper.getInitialContext(properties);
 				ctx.unbind(name);
                 LOG.factoryUnboundFromJndiName(name);
 			}
 			catch (InvalidNameException ine) {
                 LOG.invalidJndiName(name, ine);
 			}
 			catch (NamingException ne) {
                 LOG.unableToUnbindFactoryFromJndi(ne);
 			}
 
 			NAMED_INSTANCES.remove(name);
 
 		}
 
 		INSTANCES.remove(uid);
 
 	}
 
 	public static Object getNamedInstance(String name) {
         LOG.debugf("Lookup: name=%s", name);
 		Object result = NAMED_INSTANCES.get(name);
 		if (result==null) {
             LOG.debugf("Not found: %s", name);
             LOG.debugf(NAMED_INSTANCES.toString());
 		}
 		return result;
 	}
 
 	public static Object getInstance(String uid) {
         LOG.debugf("Lookup: uid=%s", uid);
 		Object result = INSTANCES.get(uid);
 		if (result==null) {
             LOG.debugf("Not found: %s", uid);
             LOG.debugf(INSTANCES.toString());
 		}
 		return result;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/impl/SessionImpl.java b/hibernate-core/src/main/java/org/hibernate/impl/SessionImpl.java
index 95e07fa6a2..a6a1f7bd67 100644
--- a/hibernate-core/src/main/java/org/hibernate/impl/SessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/impl/SessionImpl.java
@@ -1,1171 +1,1170 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2005-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.impl;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Reader;
 import java.io.Serializable;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.CacheMode;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.Filter;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.Interceptor;
 import org.hibernate.LobHelper;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ReplicationMode;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
-import org.hibernate.SessionBuilder;
 import org.hibernate.SessionException;
 import org.hibernate.SharedSessionBuilder;
 import org.hibernate.Transaction;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeHelper;
 import org.hibernate.UnknownProfileException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.ActionQueue;
 import org.hibernate.engine.CollectionEntry;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.NonFlushedChanges;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.StatefulPersistenceContext;
 import org.hibernate.engine.Status;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.query.FilterQueryPlan;
 import org.hibernate.engine.query.HQLQueryPlan;
 import org.hibernate.engine.query.NativeSQLQueryPlan;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.event.AutoFlushEvent;
 import org.hibernate.event.AutoFlushEventListener;
 import org.hibernate.event.DeleteEvent;
 import org.hibernate.event.DeleteEventListener;
 import org.hibernate.event.DirtyCheckEvent;
 import org.hibernate.event.DirtyCheckEventListener;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.EventType;
 import org.hibernate.event.EvictEvent;
 import org.hibernate.event.EvictEventListener;
 import org.hibernate.event.FlushEvent;
 import org.hibernate.event.FlushEventListener;
 import org.hibernate.event.InitializeCollectionEvent;
 import org.hibernate.event.InitializeCollectionEventListener;
 import org.hibernate.event.LoadEvent;
 import org.hibernate.event.LoadEventListener;
 import org.hibernate.event.LoadEventListener.LoadType;
 import org.hibernate.event.LockEvent;
 import org.hibernate.event.LockEventListener;
 import org.hibernate.event.MergeEvent;
 import org.hibernate.event.MergeEventListener;
 import org.hibernate.event.PersistEvent;
 import org.hibernate.event.PersistEventListener;
 import org.hibernate.event.RefreshEvent;
 import org.hibernate.event.RefreshEventListener;
 import org.hibernate.event.ReplicateEvent;
 import org.hibernate.event.ReplicateEventListener;
 import org.hibernate.event.SaveOrUpdateEvent;
 import org.hibernate.event.SaveOrUpdateEventListener;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.jdbc.Work;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.service.event.spi.EventListenerGroup;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 import org.hibernate.stat.SessionStatistics;
 import org.hibernate.stat.internal.SessionStatisticsImpl;
 import org.hibernate.type.SerializationException;
 import org.hibernate.type.Type;
 
 /**
  * Concrete implementation of a Session.
  *
  * Exposes two interfaces:<ul>
  *     <li>{@link Session} to the application</li>
  *     <li>{@link org.hibernate.engine.SessionImplementor} to other Hibernate components (SPI)</li>
  * </ul>
  *
  * This class is not thread-safe.
  *
  * @author Gavin King
  */
 public final class SessionImpl
 		extends AbstractSessionImpl
 		implements EventSource, org.hibernate.Session, TransactionContext, LobCreationContext {
 
 	// todo : need to find a clean way to handle the "event source" role
 	// a separate class responsible for generating/dispatching events just duplicates most of the Session methods...
 	// passing around separate interceptor, factory, actionQueue, and persistentContext is not manageable...
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SessionImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionImpl.class.getName());
 
 	private transient long timestamp;
 
 	private transient ActionQueue actionQueue;
 	private transient StatefulPersistenceContext persistenceContext;
 	private transient TransactionCoordinatorImpl transactionCoordinator;
 	private transient Interceptor interceptor;
 	private transient EntityNameResolver entityNameResolver = new CoordinatingEntityNameResolver();
 
 	private transient ConnectionReleaseMode connectionReleaseMode;
 	private transient FlushMode flushMode = FlushMode.AUTO;
 	private transient CacheMode cacheMode = CacheMode.NORMAL;
 	private transient EntityMode entityMode = EntityMode.POJO;
 
 	private transient boolean autoClear; //for EJB3
 	private transient boolean autoJoinTransactions = true;
 	private transient boolean flushBeforeCompletionEnabled;
 	private transient boolean autoCloseSessionEnabled;
 
 	private transient int dontFlushFromFind = 0;
 
 	private transient LoadQueryInfluencers loadQueryInfluencers;
 
 	private transient Session rootSession;
 	private transient Map childSessionsByEntityMode;
 
 	/**
 	 * Constructor used in building "child sessions".
 	 *
 	 * @param parent The parent session
 	 * @param entityMode
 	 */
 	private SessionImpl(SessionImpl parent, EntityMode entityMode) {
 		super( parent.factory );
 		this.rootSession = parent;
 		this.timestamp = parent.timestamp;
 		this.transactionCoordinator = parent.transactionCoordinator;
 		this.interceptor = parent.interceptor;
 		this.actionQueue = new ActionQueue( this );
 		this.entityMode = entityMode;
 		this.persistenceContext = new StatefulPersistenceContext( this );
 		this.flushBeforeCompletionEnabled = false;
 		this.autoCloseSessionEnabled = false;
 		this.connectionReleaseMode = null;
 
 		loadQueryInfluencers = new LoadQueryInfluencers( factory );
 
         if (factory.getStatistics().isStatisticsEnabled()) factory.getStatisticsImplementor().openSession();
 
         LOG.debugf("Opened session [%s]", entityMode);
 	}
 
 	/**
 	 * Constructor used for openSession(...) processing, as well as construction
 	 * of sessions for getCurrentSession().
 	 *
 	 * @param connection The user-supplied connection to use for this session.
 	 * @param factory The factory from which this session was obtained
 	 * @param transactionCoordinator The transaction coordinator to use, may be null to indicate that a new transaction
 	 * coordinator should get created.
 	 * @param autoJoinTransactions Should the session automatically join JTA transactions?
 	 * @param timestamp The timestamp for this session
 	 * @param interceptor The interceptor to be applied to this session
 	 * @param entityMode The entity-mode for this session
 	 * @param flushBeforeCompletionEnabled Should we auto flush before completion of transaction
 	 * @param autoCloseSessionEnabled Should we auto close after completion of transaction
 	 * @param connectionReleaseMode The mode by which we should release JDBC connections.
 	 */
 	SessionImpl(
 			final Connection connection,
 			final SessionFactoryImpl factory,
 			final TransactionCoordinatorImpl transactionCoordinator,
 			final boolean autoJoinTransactions,
 			final long timestamp,
 			final Interceptor interceptor,
 			final EntityMode entityMode,
 			final boolean flushBeforeCompletionEnabled,
 			final boolean autoCloseSessionEnabled,
 			final ConnectionReleaseMode connectionReleaseMode) {
 		super( factory );
 		this.rootSession = null;
 		this.timestamp = timestamp;
 		this.entityMode = entityMode;
 		this.interceptor = interceptor == null ? EmptyInterceptor.INSTANCE : interceptor;
 		this.actionQueue = new ActionQueue( this );
 		this.persistenceContext = new StatefulPersistenceContext( this );
 		this.flushBeforeCompletionEnabled = flushBeforeCompletionEnabled;
 		this.autoCloseSessionEnabled = autoCloseSessionEnabled;
 		this.connectionReleaseMode = connectionReleaseMode;
 		this.autoJoinTransactions = autoJoinTransactions;
 
 		if ( transactionCoordinator == null ) {
 			this.transactionCoordinator = new TransactionCoordinatorImpl( connection, this );
 			this.transactionCoordinator.getJdbcCoordinator().getLogicalConnection().addObserver(
 					new ConnectionObserverStatsBridge( factory )
 			);
 		}
 		else {
 			if ( connection != null ) {
 				throw new SessionException( "Cannot simultaneously share transaction context and specify connection" );
 			}
 			this.transactionCoordinator = transactionCoordinator;
 		}
 
 		loadQueryInfluencers = new LoadQueryInfluencers( factory );
 
         if (factory.getStatistics().isStatisticsEnabled()) factory.getStatisticsImplementor().openSession();
 
         LOG.debugf("Opened session at timestamp: %s", timestamp);
 	}
 
 	@Override
 	public SharedSessionBuilder sessionWithOptions() {
 		return new SharedSessionBuilderImpl( this );
 	}
 
 	public Session getSession(EntityMode entityMode) {
 		if ( this.entityMode == entityMode ) {
 			return this;
 		}
 
 		if ( rootSession != null ) {
 			return rootSession.getSession( entityMode );
 		}
 
 		errorIfClosed();
 		checkTransactionSynchStatus();
 
 		SessionImpl rtn = null;
 		if ( childSessionsByEntityMode == null ) {
 			childSessionsByEntityMode = new HashMap();
 		}
 		else {
 			rtn = (SessionImpl) childSessionsByEntityMode.get( entityMode );
 		}
 
 		if ( rtn == null ) {
 			rtn = new SessionImpl( this, entityMode );
 			childSessionsByEntityMode.put( entityMode, rtn );
 		}
 
 		return rtn;
 	}
 
 	public void clear() {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		persistenceContext.clear();
 		actionQueue.clear();
 	}
 
 	public long getTimestamp() {
 		checkTransactionSynchStatus();
 		return timestamp;
 	}
 
 	public Connection close() throws HibernateException {
         LOG.trace("Closing session");
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed" );
 		}
 
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().closeSession();
 		}
 
 		try {
 			try {
 				if ( childSessionsByEntityMode != null ) {
 					Iterator childSessions = childSessionsByEntityMode.values().iterator();
 					while ( childSessions.hasNext() ) {
 						final SessionImpl child = ( SessionImpl ) childSessions.next();
 						child.close();
 					}
 				}
 			}
 			catch( Throwable t ) {
 				// just ignore
 			}
 
 			if ( rootSession == null ) {
 				return transactionCoordinator.close();
 			}
 			else {
 				return null;
 			}
 		}
 		finally {
 			setClosed();
 			cleanup();
 		}
 	}
 
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return connectionReleaseMode;
 	}
 
 	@Override
 	public boolean shouldAutoJoinTransaction() {
 		return autoJoinTransactions;
 	}
 
 	public boolean isAutoCloseSessionEnabled() {
 		return autoCloseSessionEnabled;
 	}
 
 	public boolean isOpen() {
 		checkTransactionSynchStatus();
 		return !isClosed();
 	}
 
 	public boolean isFlushModeNever() {
 		return FlushMode.isManualFlushMode( getFlushMode() );
 	}
 
 	public boolean isFlushBeforeCompletionEnabled() {
 		return flushBeforeCompletionEnabled;
 	}
 
 	public void managedFlush() {
 		if ( isClosed() ) {
             LOG.trace("Skipping auto-flush due to session closed");
 			return;
 		}
         LOG.trace( "Automatically flushing session" );
 		flush();
 
 		if ( childSessionsByEntityMode != null ) {
 			Iterator iter = childSessionsByEntityMode.values().iterator();
 			while ( iter.hasNext() ) {
 				( (Session) iter.next() ).flush();
 			}
 		}
 	}
 
 	/**
 	 * Return changes to this session and its child sessions that have not been flushed yet.
 	 * <p/>
 	 * @return The non-flushed changes.
 	 */
 	public NonFlushedChanges getNonFlushedChanges() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		NonFlushedChanges nonFlushedChanges = new NonFlushedChangesImpl( this );
 		if ( childSessionsByEntityMode != null ) {
 			Iterator it = childSessionsByEntityMode.values().iterator();
 			while ( it.hasNext() ) {
 				nonFlushedChanges.extractFromSession( ( EventSource ) it.next() );
 			}
 		}
 		return nonFlushedChanges;
 	}
 
 	/**
 	 * Apply non-flushed changes from a different session to this session. It is assumed
 	 * that this SessionImpl is "clean" (e.g., has no non-flushed changes, no cached entities,
 	 * no cached collections, no queued actions). The specified NonFlushedChanges object cannot
 	 * be bound to any session.
 	 * <p/>
 	 * @param nonFlushedChanges the non-flushed changes
 	 */
 	public void applyNonFlushedChanges(NonFlushedChanges nonFlushedChanges) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		replacePersistenceContext( ( ( NonFlushedChangesImpl ) nonFlushedChanges ).getPersistenceContext( entityMode) );
 		replaceActionQueue( ( ( NonFlushedChangesImpl ) nonFlushedChanges ).getActionQueue( entityMode ) );
 		if ( childSessionsByEntityMode != null ) {
 			for ( Iterator it = childSessionsByEntityMode.values().iterator(); it.hasNext(); ) {
 				( ( SessionImpl ) it.next() ).applyNonFlushedChanges( nonFlushedChanges );
 			}
 		}
 	}
 
 	private void replacePersistenceContext(StatefulPersistenceContext persistenceContextNew) {
 		if ( persistenceContextNew.getSession() != null ) {
 			throw new IllegalStateException( "new persistence context is already connected to a session " );
 		}
 		persistenceContext.clear();
 		ObjectInputStream ois = null;
 		try {
 			ois = new ObjectInputStream( new ByteArrayInputStream( serializePersistenceContext( persistenceContextNew ) ) );
 			this.persistenceContext = StatefulPersistenceContext.deserialize( ois, this );
 		}
 		catch (IOException ex) {
 			throw new SerializationException( "could not deserialize the persistence context",  ex );
 		}
 		catch (ClassNotFoundException ex) {
 			throw new SerializationException( "could not deserialize the persistence context", ex );
 		}
 		finally {
 			try {
 				if (ois != null) ois.close();
 			}
 			catch (IOException ex) {}
 		}
 	}
 
 	private static byte[] serializePersistenceContext(StatefulPersistenceContext pc) {
 		ByteArrayOutputStream baos = new ByteArrayOutputStream( 512 );
 		ObjectOutputStream oos = null;
 		try {
 			oos = new ObjectOutputStream( baos );
 			( pc ).serialize( oos );
 		}
 		catch (IOException ex) {
 			throw new SerializationException( "could not serialize persistence context", ex );
 		}
 		finally {
 			if ( oos != null ) {
 				try {
 					oos.close();
 				}
 				catch( IOException ex ) {
 					//ignore
 				}
 			}
 		}
 		return baos.toByteArray();
 	}
 
 	private void replaceActionQueue(ActionQueue actionQueueNew) {
 		if ( actionQueue.hasAnyQueuedActions() ) {
 			throw new IllegalStateException( "cannot replace an ActionQueue with queued actions " );
 		}
 		actionQueue.clear();
 		ObjectInputStream ois = null;
 		try {
 			ois = new ObjectInputStream( new ByteArrayInputStream( serializeActionQueue( actionQueueNew ) ) );
 			actionQueue = ActionQueue.deserialize( ois, this );
 		}
 		catch (IOException ex) {
 			throw new SerializationException( "could not deserialize the action queue",  ex );
 		}
 		catch (ClassNotFoundException ex) {
 			throw new SerializationException( "could not deserialize the action queue", ex );
 		}
 		finally {
 			try {
 				if (ois != null) ois.close();
 			}
 			catch (IOException ex) {}
 		}
 	}
 
 	private static byte[] serializeActionQueue(ActionQueue actionQueue) {
 		ByteArrayOutputStream baos = new ByteArrayOutputStream( 512 );
 		ObjectOutputStream oos = null;
 		try {
 			oos = new ObjectOutputStream( baos );
 			actionQueue.serialize( oos );
 		}
 		catch (IOException ex) {
 			throw new SerializationException( "could not serialize action queue", ex );
 		}
 		finally {
 			if ( oos != null ) {
 				try {
 					oos.close();
 				}
 				catch( IOException ex ) {
 					//ignore
 				}
 			}
 		}
 		return baos.toByteArray();
 	}
 
 	public boolean shouldAutoClose() {
 		return isAutoCloseSessionEnabled() && !isClosed();
 	}
 
 	public void managedClose() {
         LOG.trace( "Automatically closing session" );
 		close();
 	}
 
 	public Connection connection() throws HibernateException {
 		errorIfClosed();
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getDistinctConnectionProxy();
 	}
 
 	public boolean isConnected() {
 		checkTransactionSynchStatus();
 		return !isClosed() && transactionCoordinator.getJdbcCoordinator().getLogicalConnection().isOpen();
 	}
 
 	public boolean isTransactionInProgress() {
 		checkTransactionSynchStatus();
 		return !isClosed() && transactionCoordinator.isTransactionInProgress();
 	}
 
 	@Override
 	public Connection disconnect() throws HibernateException {
 		errorIfClosed();
         LOG.debugf("Disconnecting session");
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().manualDisconnect();
 	}
 
 	@Override
 	public void reconnect(Connection conn) throws HibernateException {
 		errorIfClosed();
         LOG.debugf("Reconnecting session");
 		checkTransactionSynchStatus();
 		transactionCoordinator.getJdbcCoordinator().getLogicalConnection().manualReconnect( conn );
 	}
 
 	public void setAutoClear(boolean enabled) {
 		errorIfClosed();
 		autoClear = enabled;
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		errorIfClosed();
 		autoJoinTransactions = false;
 	}
 
 	/**
 	 * Check if there is a Hibernate or JTA transaction in progress and,
 	 * if there is not, flush if necessary, make sure the connection has
 	 * been committed (if it is not in autocommit mode) and run the after
 	 * completion processing
 	 */
 	public void afterOperation(boolean success) {
 		if ( ! transactionCoordinator.isTransactionInProgress() ) {
 			transactionCoordinator.afterNonTransactionalQuery( success );
 		}
 	}
 
 	@Override
 	public void afterTransactionBegin(TransactionImplementor hibernateTransaction) {
 		errorIfClosed();
 		interceptor.afterTransactionBegin( hibernateTransaction );
 	}
 
 	@Override
 	public void beforeTransactionCompletion(TransactionImplementor hibernateTransaction) {
 		LOG.trace( "before transaction completion" );
 		actionQueue.beforeTransactionCompletion();
 		if ( rootSession == null ) {
 			try {
 				interceptor.beforeTransactionCompletion( hibernateTransaction );
 			}
 			catch (Throwable t) {
                 LOG.exceptionInBeforeTransactionCompletionInterceptor(t);
 			}
 		}
 	}
 
 	@Override
 	public void afterTransactionCompletion(TransactionImplementor hibernateTransaction, boolean successful) {
 		LOG.trace( "after transaction completion" );
 		persistenceContext.afterTransactionCompletion();
 		actionQueue.afterTransactionCompletion( successful );
 		if ( rootSession == null && hibernateTransaction != null ) {
 			try {
 				interceptor.afterTransactionCompletion( hibernateTransaction );
 			}
 			catch (Throwable t) {
                 LOG.exceptionInAfterTransactionCompletionInterceptor(t);
 			}
 		}
 		if ( autoClear ) {
 			clear();
 		}
 	}
 
 	/**
 	 * clear all the internal collections, just
 	 * to help the garbage collector, does not
 	 * clear anything that is needed during the
 	 * afterTransactionCompletion() phase
 	 */
 	private void cleanup() {
 		persistenceContext.clear();
 	}
 
 	public LockMode getCurrentLockMode(Object object) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object == null ) {
 			throw new NullPointerException( "null object passed to getCurrentLockMode()" );
 		}
 		if ( object instanceof HibernateProxy ) {
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation(this);
 			if ( object == null ) {
 				return LockMode.NONE;
 			}
 		}
 		EntityEntry e = persistenceContext.getEntry(object);
 		if ( e == null ) {
 			throw new TransientObjectException( "Given object not associated with the session" );
 		}
 		if ( e.getStatus() != Status.MANAGED ) {
 			throw new ObjectDeletedException(
 					"The given object was deleted",
 					e.getId(),
 					e.getPersister().getEntityName()
 				);
 		}
 		return e.getLockMode();
 	}
 
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		// todo : should this get moved to PersistentContext?
 		// logically, is PersistentContext the "thing" to which an interceptor gets attached?
 		final Object result = persistenceContext.getEntity(key);
 		if ( result == null ) {
 			final Object newObject = interceptor.getEntity( key.getEntityName(), key.getIdentifier() );
 			if ( newObject != null ) {
 				lock( newObject, LockMode.NONE );
 			}
 			return newObject;
 		}
 		else {
 			return result;
 		}
 	}
 
 
 	// saveOrUpdate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void saveOrUpdate(Object object) throws HibernateException {
 		saveOrUpdate( null, object );
 	}
 
 	public void saveOrUpdate(String entityName, Object obj) throws HibernateException {
 		fireSaveOrUpdate( new SaveOrUpdateEvent( entityName, obj, this ) );
 	}
 
 	private void fireSaveOrUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE_UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 	}
 
 	private <T> Iterable<T> listeners(EventType<T> type) {
 		return eventListenerGroup( type ).listeners();
 	}
 
 	private <T> EventListenerGroup<T> eventListenerGroup(EventType<T> type) {
 		return factory.getServiceRegistry().getService( EventListenerRegistry.class ).getEventListenerGroup( type );
 	}
 
 
 	// save() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Serializable save(Object obj) throws HibernateException {
 		return save( null, obj );
 	}
 
 	public Serializable save(String entityName, Object object) throws HibernateException {
 		return fireSave( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private Serializable fireSave(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		return event.getResultId();
 	}
 
 
 	// update() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void update(Object obj) throws HibernateException {
 		update(null, obj);
 	}
 
 	public void update(String entityName, Object object) throws HibernateException {
 		fireUpdate( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private void fireUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 	}
 
 
 	// lock() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void lock(String entityName, Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent(entityName, object, lockMode, this) );
 	}
 
 	public LockRequest buildLockRequest(LockOptions lockOptions) {
 		return new LockRequestImpl(lockOptions);
 	}
 
 	public void lock(Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent(object, lockMode, this) );
 	}
 
 	private void fireLock(String entityName, Object object, LockOptions options) {
 		fireLock( new LockEvent( entityName, object, options, this) );
 	}
 
 	private void fireLock( Object object, LockOptions options) {
 		fireLock( new LockEvent( object, options, this ) );
 	}
 
 	private void fireLock(LockEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LockEventListener listener : listeners( EventType.LOCK ) ) {
 			listener.onLock( event );
 		}
 	}
 
 
 	// persist() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void persist(String entityName, Object object) throws HibernateException {
 		firePersist( new PersistEvent( entityName, object, this ) );
 	}
 
 	public void persist(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	public void persist(String entityName, Object object, Map copiedAlready)
 	throws HibernateException {
 		firePersist( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersist(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 	}
 
 	private void firePersist(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event );
 		}
 	}
 
 
 	// persistOnFlush() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void persistOnFlush(String entityName, Object object)
 			throws HibernateException {
 		firePersistOnFlush( new PersistEvent( entityName, object, this ) );
 	}
 
 	public void persistOnFlush(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	public void persistOnFlush(String entityName, Object object, Map copiedAlready)
 			throws HibernateException {
 		firePersistOnFlush( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersistOnFlush(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 	}
 
 	private void firePersistOnFlush(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event );
 		}
 	}
 
 
 	// merge() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Object merge(String entityName, Object object) throws HibernateException {
 		return fireMerge( new MergeEvent( entityName, object, this ) );
 	}
 
 	public Object merge(Object object) throws HibernateException {
 		return merge( null, object );
 	}
 
 	public void merge(String entityName, Object object, Map copiedAlready) throws HibernateException {
 		fireMerge( copiedAlready, new MergeEvent( entityName, object, this ) );
 	}
 
 	private Object fireMerge(MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event );
 		}
 		return event.getResult();
 	}
 
 	private void fireMerge(Map copiedAlready, MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event, copiedAlready );
 		}
 	}
 
 
 	// delete() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Delete a persistent object
 	 */
 	public void delete(Object object) throws HibernateException {
 		fireDelete( new DeleteEvent(object, this) );
 	}
 
 	/**
 	 * Delete a persistent object (by explicit entity name)
 	 */
 	public void delete(String entityName, Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( entityName, object, this ) );
 	}
 
 	/**
 	 * Delete a persistent object
 	 */
 	public void delete(String entityName, Object object, boolean isCascadeDeleteEnabled, Set transientEntities) throws HibernateException {
 		fireDelete( new DeleteEvent( entityName, object, isCascadeDeleteEnabled, this ), transientEntities );
 	}
 
 	private void fireDelete(DeleteEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event );
 		}
 	}
 
 	private void fireDelete(DeleteEvent event, Set transientEntities) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event, transientEntities );
 		}
 	}
 
 
 	// load()/get() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void load(Object object, Serializable id) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, object, this);
 		fireLoad( event, LoadEventListener.RELOAD );
 	}
 
 	public Object load(Class entityClass, Serializable id) throws HibernateException {
 		return load( entityClass.getName(), id );
 	}
 
 	public Object load(String entityName, Serializable id) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, entityName, false, this);
 		boolean success = false;
 		try {
 			fireLoad( event, LoadEventListener.LOAD );
 			if ( event.getResult() == null ) {
 				getFactory().getEntityNotFoundDelegate().handleEntityNotFound( entityName, id );
 			}
 			success = true;
 			return event.getResult();
 		}
 		finally {
 			afterOperation(success);
 		}
 	}
 
 	public Object get(Class entityClass, Serializable id) throws HibernateException {
 		return get( entityClass.getName(), id );
 	}
 
 	public Object get(String entityName, Serializable id) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, entityName, false, this);
 		boolean success = false;
 		try {
 			fireLoad(event, LoadEventListener.GET);
 			success = true;
 			return event.getResult();
 		}
 		finally {
 			afterOperation(success);
 		}
 	}
 
 	/**
 	 * Load the data for the object with the specified id into a newly created object.
 	 * This is only called when lazily initializing a proxy.
 	 * Do NOT return a proxy.
 	 */
 	public Object immediateLoad(String entityName, Serializable id) throws HibernateException {
         if (LOG.isDebugEnabled()) {
 			EntityPersister persister = getFactory().getEntityPersister(entityName);
             LOG.debugf("Initializing proxy: %s", MessageHelper.infoString(persister, id, getFactory()));
 		}
 
 		LoadEvent event = new LoadEvent(id, entityName, true, this);
 		fireLoad(event, LoadEventListener.IMMEDIATE_LOAD);
 		return event.getResult();
 	}
 
 	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable) throws HibernateException {
 		// todo : remove
 		LoadEventListener.LoadType type = nullable
 				? LoadEventListener.INTERNAL_LOAD_NULLABLE
 				: eager
 						? LoadEventListener.INTERNAL_LOAD_EAGER
 						: LoadEventListener.INTERNAL_LOAD_LAZY;
 		LoadEvent event = new LoadEvent(id, entityName, true, this);
 		fireLoad(event, type);
 		if ( !nullable ) {
 			UnresolvableObjectException.throwIfNull( event.getResult(), id, entityName );
 		}
 		return event.getResult();
 	}
 
 	public Object load(Class entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return load( entityClass.getName(), id, lockMode );
 	}
 
 	public Object load(Class entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return load( entityClass.getName(), id, lockOptions );
 	}
 
 	public Object load(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, entityName, lockMode, this);
 		fireLoad( event, LoadEventListener.LOAD );
 		return event.getResult();
 	}
 
 	public Object load(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, entityName, lockOptions, this);
 		fireLoad( event, LoadEventListener.LOAD );
 		return event.getResult();
 	}
 
 	public Object get(Class entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return get( entityClass.getName(), id, lockMode );
 	}
 
 	public Object get(Class entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return get( entityClass.getName(), id, lockOptions );
 	}
 
 	public Object get(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, entityName, lockMode, this);
 	   	fireLoad(event, LoadEventListener.GET);
 		return event.getResult();
 	}
 
 	public Object get(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, entityName, lockOptions, this);
 	   	fireLoad( event, LoadEventListener.GET );
 		return event.getResult();
 	}
 
 	private void fireLoad(LoadEvent event, LoadType loadType) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LoadEventListener listener : listeners( EventType.LOAD ) ) {
 			listener.onLoad( event, loadType );
 		}
 	}
 
 
 	// refresh() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void refresh(Object object) throws HibernateException {
 		fireRefresh( new RefreshEvent(object, this) );
 	}
 
 	public void refresh(Object object, LockMode lockMode) throws HibernateException {
 		fireRefresh( new RefreshEvent(object, lockMode, this) );
 	}
 
 	public void refresh(Object object, LockOptions lockOptions) throws HibernateException {
 		fireRefresh( new RefreshEvent(object, lockOptions, this) );
 	}
 
 	public void refresh(Object object, Map refreshedAlready) throws HibernateException {
 		fireRefresh( refreshedAlready, new RefreshEvent( object, this ) );
 	}
 
 	private void fireRefresh(RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event );
 		}
 	}
 
 	private void fireRefresh(Map refreshedAlready, RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event, refreshedAlready );
 		}
 	}
 
 
 	// replicate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void replicate(Object obj, ReplicationMode replicationMode) throws HibernateException {
 		fireReplicate( new ReplicateEvent(obj, replicationMode, this) );
 	}
 
 	public void replicate(String entityName, Object obj, ReplicationMode replicationMode)
 	throws HibernateException {
 		fireReplicate( new ReplicateEvent( entityName, obj, replicationMode, this ) );
 	}
 
 	private void fireReplicate(ReplicateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ReplicateEventListener listener : listeners( EventType.REPLICATE ) ) {
 			listener.onReplicate( event );
 		}
 	}
 
 
 	// evict() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * remove any hard references to the entity that are held by the infrastructure
 	 * (references held by application or other persistant instances are okay)
 	 */
 	public void evict(Object object) throws HibernateException {
 		fireEvict( new EvictEvent( object, this ) );
 	}
 
 	private void fireEvict(EvictEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( EvictEventListener listener : listeners( EventType.EVICT ) ) {
 			listener.onEvict( event );
 		}
 	}
 
 	/**
 	 * detect in-memory changes, determine if the changes are to tables
 	 * named in the query and, if so, complete execution the flush
 	 */
 	protected boolean autoFlushIfRequired(Set querySpaces) throws HibernateException {
 		errorIfClosed();
 		if ( ! isTransactionInProgress() ) {
 			// do not auto-flush while outside a transaction
 			return false;
 		}
 		AutoFlushEvent event = new AutoFlushEvent( querySpaces, this );
 		for ( AutoFlushEventListener listener : listeners( EventType.AUTO_FLUSH ) ) {
 			listener.onAutoFlush( event );
 		}
 		return event.isFlushRequired();
 	}
 
 	public boolean isDirty() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
         LOG.debugf("Checking session dirtiness");
 		if ( actionQueue.areInsertionsOrDeletionsQueued() ) {
             LOG.debugf("Session dirty (scheduled updates and insertions)");
 			return true;
 		}
         DirtyCheckEvent event = new DirtyCheckEvent( this );
 		for ( DirtyCheckEventListener listener : listeners( EventType.DIRTY_CHECK ) ) {
 			listener.onDirtyCheck( event );
 		}
         return event.isDirty();
 	}
 
 	public void flush() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( persistenceContext.getCascadeLevel() > 0 ) {
 			throw new HibernateException("Flush during cascade is dangerous");
 		}
 		for ( FlushEventListener listener : listeners( EventType.FLUSH ) ) {
 			listener.onFlush( new FlushEvent( this ) );
 		}
 	}
 
 	public void forceFlush(EntityEntry entityEntry) throws HibernateException {
 		errorIfClosed();
         if (LOG.isDebugEnabled()) LOG.debugf("Flushing to force deletion of re-saved object: %s",
                                              MessageHelper.infoString(entityEntry.getPersister(), entityEntry.getId(), getFactory()));
diff --git a/hibernate-core/src/main/java/org/hibernate/impl/StatelessSessionImpl.java b/hibernate-core/src/main/java/org/hibernate/impl/StatelessSessionImpl.java
index e8cddb7633..92c7b1a6ad 100755
--- a/hibernate-core/src/main/java/org/hibernate/impl/StatelessSessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/impl/StatelessSessionImpl.java
@@ -1,709 +1,708 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.impl;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.CacheMode;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.Interceptor;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.SessionException;
 import org.hibernate.StatelessSession;
 import org.hibernate.Transaction;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.NonFlushedChanges;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.StatefulPersistenceContext;
 import org.hibernate.engine.Versioning;
 import org.hibernate.engine.query.HQLQueryPlan;
 import org.hibernate.engine.query.NativeSQLQueryPlan;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.engine.transaction.spi.TransactionImplementor;
-import org.hibernate.event.EventListeners;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.type.Type;
 
 /**
  * @author Gavin King
  */
 public class StatelessSessionImpl extends AbstractSessionImpl implements StatelessSession {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, StatelessSessionImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, StatelessSessionImpl.class.getName());
 
 	private TransactionCoordinator transactionCoordinator;
 	private PersistenceContext temporaryPersistenceContext = new StatefulPersistenceContext( this );
 
 	StatelessSessionImpl(Connection connection, SessionFactoryImpl factory) {
 		super( factory );
 		this.transactionCoordinator = new TransactionCoordinatorImpl( connection, this );
 	}
 
 	// TransactionContext ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		return transactionCoordinator;
 	}
 
 	@Override
 	public TransactionEnvironment getTransactionEnvironment() {
 		return factory.getTransactionEnvironment();
 	}
 
 	// inserts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Serializable insert(Object entity) {
 		errorIfClosed();
 		return insert(null, entity);
 	}
 
 	public Serializable insert(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister(entityName, entity);
 		Serializable id = persister.getIdentifierGenerator().generate(this, entity);
 		Object[] state = persister.getPropertyValues(entity, EntityMode.POJO);
 		if ( persister.isVersioned() ) {
 			boolean substitute = Versioning.seedVersion(state, persister.getVersionProperty(), persister.getVersionType(), this);
 			if ( substitute ) {
 				persister.setPropertyValues( entity, state, EntityMode.POJO );
 			}
 		}
 		if ( id == IdentifierGeneratorHelper.POST_INSERT_INDICATOR ) {
 			id = persister.insert(state, entity, this);
 		}
 		else {
 			persister.insert(id, state, entity, this);
 		}
 		persister.setIdentifier( entity, id, this );
 		return id;
 	}
 
 
 	// deletes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void delete(Object entity) {
 		errorIfClosed();
 		delete(null, entity);
 	}
 
 	public void delete(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister(entityName, entity);
 		Serializable id = persister.getIdentifier( entity, this );
 		Object version = persister.getVersion(entity, EntityMode.POJO);
 		persister.delete(id, version, entity, this);
 	}
 
 
 	// updates ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void update(Object entity) {
 		errorIfClosed();
 		update(null, entity);
 	}
 
 	public void update(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister(entityName, entity);
 		Serializable id = persister.getIdentifier( entity, this );
 		Object[] state = persister.getPropertyValues(entity, EntityMode.POJO);
 		Object oldVersion;
 		if ( persister.isVersioned() ) {
 			oldVersion = persister.getVersion(entity, EntityMode.POJO);
 			Object newVersion = Versioning.increment( oldVersion, persister.getVersionType(), this );
 			Versioning.setVersion(state, newVersion, persister);
 			persister.setPropertyValues(entity, state, EntityMode.POJO);
 		}
 		else {
 			oldVersion = null;
 		}
 		persister.update(id, state, null, false, null, oldVersion, entity, null, this);
 	}
 
 
 	// loading ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Object get(Class entityClass, Serializable id) {
 		return get( entityClass.getName(), id );
 	}
 
 	public Object get(Class entityClass, Serializable id, LockMode lockMode) {
 		return get( entityClass.getName(), id, lockMode );
 	}
 
 	public Object get(String entityName, Serializable id) {
 		return get(entityName, id, LockMode.NONE);
 	}
 
 	public Object get(String entityName, Serializable id, LockMode lockMode) {
 		errorIfClosed();
 		Object result = getFactory().getEntityPersister(entityName)
 				.load(id, null, lockMode, this);
 		if ( temporaryPersistenceContext.isLoadFinished() ) {
 			temporaryPersistenceContext.clear();
 		}
 		return result;
 	}
 
 	public void refresh(Object entity) {
 		refresh( bestGuessEntityName( entity ), entity, LockMode.NONE );
 	}
 
 	public void refresh(String entityName, Object entity) {
 		refresh( entityName, entity, LockMode.NONE );
 	}
 
 	public void refresh(Object entity, LockMode lockMode) {
 		refresh( bestGuessEntityName( entity ), entity, lockMode );
 	}
 
 	public void refresh(String entityName, Object entity, LockMode lockMode) {
 		final EntityPersister persister = this.getEntityPersister( entityName, entity );
 		final Serializable id = persister.getIdentifier( entity, this );
         if (LOG.isTraceEnabled()) LOG.trace("Refreshing transient " + MessageHelper.infoString(persister, id, this.getFactory()));
 		// TODO : can this ever happen???
 //		EntityKey key = new EntityKey( id, persister, source.getEntityMode() );
 //		if ( source.getPersistenceContext().getEntry( key ) != null ) {
 //			throw new PersistentObjectException(
 //					"attempted to refresh transient instance when persistent " +
 //					"instance was already associated with the Session: " +
 //					MessageHelper.infoString( persister, id, source.getFactory() )
 //			);
 //		}
 
 		if ( persister.hasCache() ) {
 			final CacheKey ck = generateCacheKey( id, persister.getIdentifierType(), persister.getRootEntityName() );
 			persister.getCacheAccessStrategy().evict( ck );
 		}
 
 		String previousFetchProfile = this.getFetchProfile();
 		Object result = null;
 		try {
 			this.setFetchProfile( "refresh" );
 			result = persister.load( id, entity, lockMode, this );
 		}
 		finally {
 			this.setFetchProfile( previousFetchProfile );
 		}
 		UnresolvableObjectException.throwIfNull( result, id, persister.getEntityName() );
 	}
 
 	public Object immediateLoad(String entityName, Serializable id)
 			throws HibernateException {
 		throw new SessionException("proxies cannot be fetched by a stateless session");
 	}
 
 	public void initializeCollection(
 			PersistentCollection collection,
 	        boolean writing) throws HibernateException {
 		throw new SessionException("collections cannot be fetched by a stateless session");
 	}
 
 	public Object instantiate(
 			String entityName,
 	        Serializable id) throws HibernateException {
 		errorIfClosed();
 		return getFactory().getEntityPersister( entityName )
 				.instantiate( id, this );
 	}
 
 	public Object internalLoad(
 			String entityName,
 	        Serializable id,
 	        boolean eager,
 	        boolean nullable) throws HibernateException {
 		errorIfClosed();
 		EntityPersister persister = getFactory().getEntityPersister( entityName );
 		// first, try to load it from the temp PC associated to this SS
 		Object loaded = temporaryPersistenceContext.getEntity( generateEntityKey( id, persister ) );
 		if ( loaded != null ) {
 			// we found it in the temp PC.  Should indicate we are in the midst of processing a result set
 			// containing eager fetches via join fetch
 			return loaded;
 		}
 		if ( !eager && persister.hasProxy() ) {
 			// if the metadata allowed proxy creation and caller did not request forceful eager loading,
 			// generate a proxy
 			return persister.createProxy( id, this );
 		}
 		// otherwise immediately materialize it
 		return get( entityName, id );
 	}
 
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters)
 	throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters)
 	throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 
 	public boolean isOpen() {
 		return !isClosed();
 	}
 
 	public void close() {
 		managedClose();
 	}
 
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return factory.getSettings().getConnectionReleaseMode();
 	}
 
 	@Override
 	public boolean shouldAutoJoinTransaction() {
 		return true;
 	}
 
 	public boolean isAutoCloseSessionEnabled() {
 		return factory.getSettings().isAutoCloseSessionEnabled();
 	}
 
 	public boolean isFlushBeforeCompletionEnabled() {
 		return true;
 	}
 
 	public boolean isFlushModeNever() {
 		return false;
 	}
 
 	public void managedClose() {
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed!" );
 		}
 		transactionCoordinator.close();
 		setClosed();
 	}
 
 	public void managedFlush() {
 		errorIfClosed();
 		getTransactionCoordinator().getJdbcCoordinator().executeBatch();
 	}
 
 	public boolean shouldAutoClose() {
 		return isAutoCloseSessionEnabled() && !isClosed();
 	}
 
 	@Override
 	public void afterTransactionBegin(TransactionImplementor hibernateTransaction) {
 		// nothing to do here
 	}
 
 	@Override
 	public void beforeTransactionCompletion(TransactionImplementor hibernateTransaction) {
 		// nothing to do here
 	}
 
 	@Override
 	public void afterTransactionCompletion(TransactionImplementor hibernateTransaction, boolean successful) {
 		// nothing to do here
 	}
 
 	public String bestGuessEntityName(Object object) {
 		if (object instanceof HibernateProxy) {
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation();
 		}
 		return guessEntityName(object);
 	}
 
 	public Connection connection() {
 		errorIfClosed();
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getDistinctConnectionProxy();
 	}
 
 	public int executeUpdate(String query, QueryParameters queryParameters)
 			throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate( queryParameters, this );
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return result;
 	}
 
 	public CacheMode getCacheMode() {
 		return CacheMode.IGNORE;
 	}
 
 	public int getDontFlushFromFind() {
 		return 0;
 	}
 
 	public Map getEnabledFilters() {
 		return CollectionHelper.EMPTY_MAP;
 	}
 
 	public Serializable getContextEntityIdentifier(Object object) {
 		errorIfClosed();
 		return null;
 	}
 
 	public EntityMode getEntityMode() {
 		return EntityMode.POJO;
 	}
 
 	public EntityPersister getEntityPersister(String entityName, Object object)
 			throws HibernateException {
 		errorIfClosed();
 		if ( entityName==null ) {
 			return factory.getEntityPersister( guessEntityName( object ) );
 		}
 		else {
 			return factory.getEntityPersister( entityName )
 					.getSubclassEntityPersister( object, getFactory(), EntityMode.POJO );
 		}
 	}
 
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		return null;
 	}
 
 	public Type getFilterParameterType(String filterParameterName) {
 		throw new UnsupportedOperationException();
 	}
 
 	public Object getFilterParameterValue(String filterParameterName) {
 		throw new UnsupportedOperationException();
 	}
 
 	public FlushMode getFlushMode() {
 		return FlushMode.COMMIT;
 	}
 
 	public Interceptor getInterceptor() {
 		return EmptyInterceptor.INSTANCE;
 	}
 
 	public PersistenceContext getPersistenceContext() {
 		return temporaryPersistenceContext;
 	}
 
 	public long getTimestamp() {
 		throw new UnsupportedOperationException();
 	}
 
 	public String guessEntityName(Object entity) throws HibernateException {
 		errorIfClosed();
 		return entity.getClass().getName();
 	}
 
 
 	public boolean isConnected() {
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().isPhysicallyConnected();
 	}
 
 	public boolean isTransactionInProgress() {
 		return transactionCoordinator.isTransactionInProgress();
 	}
 
 	public void setAutoClear(boolean enabled) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		throw new UnsupportedOperationException();
 	}
 
 	public void setCacheMode(CacheMode cm) {
 		throw new UnsupportedOperationException();
 	}
 
 	public void setFlushMode(FlushMode fm) {
 		throw new UnsupportedOperationException();
 	}
 
 	public Transaction getTransaction() throws HibernateException {
 		errorIfClosed();
 		return transactionCoordinator.getTransaction();
 	}
 
 	public Transaction beginTransaction() throws HibernateException {
 		errorIfClosed();
 		Transaction result = getTransaction();
 		result.begin();
 		return result;
 	}
 
 	public boolean isEventSource() {
 		return false;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public boolean isDefaultReadOnly() {
 		return false;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void setDefaultReadOnly(boolean readOnly) throws HibernateException {
 		if ( readOnly == true ) {
 			throw new UnsupportedOperationException();
 		}
 	}
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////
 
 	//TODO: COPY/PASTE FROM SessionImpl, pull up!
 
 	public List list(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		boolean success = false;
 		List results = CollectionHelper.EMPTY_LIST;
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	public void afterOperation(boolean success) {
 		if ( ! transactionCoordinator.isTransactionInProgress() ) {
 			transactionCoordinator.afterNonTransactionalQuery( success );;
 		}
 	}
 
 	public Criteria createCriteria(Class persistentClass, String alias) {
 		errorIfClosed();
 		return new CriteriaImpl( persistentClass.getName(), alias, this );
 	}
 
 	public Criteria createCriteria(String entityName, String alias) {
 		errorIfClosed();
 		return new CriteriaImpl(entityName, alias, this);
 	}
 
 	public Criteria createCriteria(Class persistentClass) {
 		errorIfClosed();
 		return new CriteriaImpl( persistentClass.getName(), this );
 	}
 
 	public Criteria createCriteria(String entityName) {
 		errorIfClosed();
 		return new CriteriaImpl(entityName, this);
 	}
 
 	public ScrollableResults scroll(CriteriaImpl criteria, ScrollMode scrollMode) {
 		errorIfClosed();
 		String entityName = criteria.getEntityOrClassName();
 		CriteriaLoader loader = new CriteriaLoader(
 				getOuterJoinLoadable( entityName ),
 		        factory,
 		        criteria,
 		        entityName,
 		        getLoadQueryInfluencers()
 		);
 		return loader.scroll(this, scrollMode);
 	}
 
 	public List list(CriteriaImpl criteria) throws HibernateException {
 		errorIfClosed();
 		String[] implementors = factory.getImplementors( criteria.getEntityOrClassName() );
 		int size = implementors.length;
 
 		CriteriaLoader[] loaders = new CriteriaLoader[size];
 		for( int i=0; i <size; i++ ) {
 			loaders[i] = new CriteriaLoader(
 					getOuterJoinLoadable( implementors[i] ),
 			        factory,
 			        criteria,
 			        implementors[i],
 			        getLoadQueryInfluencers()
 			);
 		}
 
 
 		List results = Collections.EMPTY_LIST;
 		boolean success = false;
 		try {
 			for( int i=0; i<size; i++ ) {
 				final List currentResults = loaders[i].list(this);
 				currentResults.addAll(results);
 				results = currentResults;
 			}
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	private OuterJoinLoadable getOuterJoinLoadable(String entityName) throws MappingException {
 		EntityPersister persister = factory.getEntityPersister(entityName);
 		if ( !(persister instanceof OuterJoinLoadable) ) {
 			throw new MappingException( "class persister is not OuterJoinLoadable: " + entityName );
 		}
 		return ( OuterJoinLoadable ) persister;
 	}
 
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 
 		boolean success = false;
 		List results;
 		try {
 			results = loader.list(this, queryParameters);
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 		return loader.scroll( queryParameters, this );
 	}
 
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		return plan.performScroll( queryParameters, this );
 	}
 
 	public void afterScrollOperation() {
 		temporaryPersistenceContext.clear();
 	}
 
 	public void flush() {}
 
 	public NonFlushedChanges getNonFlushedChanges() {
 		throw new UnsupportedOperationException();
 	}
 
 	public void applyNonFlushedChanges(NonFlushedChanges nonFlushedChanges) {
 		throw new UnsupportedOperationException();
 	}
 
 	public String getFetchProfile() {
 		return null;
 	}
 
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return LoadQueryInfluencers.NONE;
 	}
 
 	public void registerInsertedKey(EntityPersister persister, Serializable id) {
 		errorIfClosed();
 		// nothing to do
 	}
 
 	public boolean wasInsertedDuringTransaction(EntityPersister persister, Serializable id) {
 		errorIfClosed();
 		// not in any meaning we need to worry about here.
 		return false;
 	}
 
 	public void setFetchProfile(String name) {}
 
 	protected boolean autoFlushIfRequired(Set querySpaces) throws HibernateException {
 		// no auto-flushing to support in stateless session
 		return false;
 	}
 
 	public int executeNativeUpdate(NativeSQLQuerySpecification nativeSQLQuerySpecification,
 			QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		NativeSQLQueryPlan plan = getNativeSQLQueryPlan(nativeSQLQuerySpecification);
 
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate(queryParameters, this);
 			success = true;
 		} finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return result;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/HibernateLogger.java b/hibernate-core/src/main/java/org/hibernate/internal/CoreMessageLogger.java
similarity index 99%
rename from hibernate-core/src/main/java/org/hibernate/HibernateLogger.java
rename to hibernate-core/src/main/java/org/hibernate/internal/CoreMessageLogger.java
index af81d38a71..77e761bb35 100644
--- a/hibernate-core/src/main/java/org/hibernate/HibernateLogger.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/CoreMessageLogger.java
@@ -1,1069 +1,1073 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate;
+package org.hibernate.internal;
 
 import static org.jboss.logging.Logger.Level.ERROR;
 import static org.jboss.logging.Logger.Level.INFO;
 import static org.jboss.logging.Logger.Level.WARN;
 import java.io.File;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.lang.reflect.Method;
 import java.net.URL;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
 import java.util.Hashtable;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import javax.naming.InvalidNameException;
 import javax.naming.NameNotFoundException;
 import javax.naming.NamingException;
 import javax.transaction.Synchronization;
 import javax.transaction.SystemException;
+
+import org.hibernate.EntityMode;
+import org.hibernate.HibernateException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cfg.AccessType;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.CollectionKey;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.loading.CollectionLoadContext;
 import org.hibernate.engine.loading.EntityLoadContext;
 import org.hibernate.id.IntegralDataTypeHolder;
 import org.hibernate.service.jdbc.dialect.internal.AbstractDialectResolver;
 import org.hibernate.type.BasicType;
 import org.hibernate.type.SerializationException;
 import org.hibernate.type.Type;
 import org.jboss.logging.BasicLogger;
 import org.jboss.logging.Cause;
 import org.jboss.logging.LogMessage;
 import org.jboss.logging.Message;
 import org.jboss.logging.MessageLogger;
 
 /**
- * Defines internationalized messages for this hibernate-core, with IDs ranging from 00001 to 10000 inclusively. New messages must
- * be added after the last message defined to ensure message codes are unique.
+ * The jboss-logging {@link MessageLogger} for the hibernate-core module.  It reserves message ids ranging from
+ * 00001 to 10000 inclusively.
+ * <p/>
+ * New messages must be added after the last message defined to ensure message codes are unique.
  */
-// TODO: tracef
 @MessageLogger( projectCode = "HHH" )
-public interface HibernateLogger extends BasicLogger {
+public interface CoreMessageLogger extends BasicLogger {
 
     @LogMessage( level = INFO )
     @Message( value = "Adding secondary table to entity %s -> %s", id = 1 )
     void addingSecondaryTableToEntity( String entity,
                                        String table );
 
     @LogMessage( level = WARN )
     @Message( value = "Already session bound on call to bind(); make sure you clean up your sessions!", id = 2 )
     void alreadySessionBound();
 
     @LogMessage( level = WARN )
     @Message( value = "Placing @Access(AccessType.%s) on a field does not have any effect.", id = 3 )
     void annotationHasNoEffect( AccessType type );
 
     @LogMessage( level = WARN )
     @Message( value = "Attempt to map column [%s] to no target column after explicit target column(s) named for FK [name=%s]", id = 4 )
     void attemptToMapColumnToNoTargetColumn( String loggableString,
                                              String name );
 
     @LogMessage( level = WARN )
     @Message( value = "Attribute \"order-by\" ignored in JDK1.3 or less", id = 5 )
     void attributeIgnored();
 
     @LogMessage( level = INFO )
     @Message( value = "Autocommit mode: %s", id = 6 )
     void autoCommitMode( boolean autocommit );
 
     @LogMessage( level = INFO )
     @Message( value = "Automatic flush during beforeCompletion(): %s", id = 7 )
     void autoFlush( String enabledDisabled );
 
     @LogMessage( level = WARN )
     @Message( value = "JTASessionContext being used with JDBCTransactionFactory; auto-flush will not operate correctly with getCurrentSession()", id = 8 )
     void autoFlushWillNotWork();
 
     @LogMessage( level = INFO )
     @Message( value = "Automatic session close at end of transaction: %s", id = 9 )
     void autoSessionClose( String enabledDisabled );
 
     @LogMessage( level = INFO )
     @Message( value = "On release of batch it still contained JDBC statements", id = 10 )
     void batchContainedStatementsOnRelease();
 
     @LogMessage( level = INFO )
     @Message( value = "Batcher factory: %s", id = 11 )
     void batcherFactory( String batcherClass );
 
     @LogMessage( level = INFO )
     @Message( value = "Bind entity %s on table %s", id = 12 )
     void bindEntityOnTable( String entity,
                             String table );
 
     @LogMessage( level = INFO )
     @Message( value = "Binding Any Meta definition: %s", id = 13 )
     void bindingAnyMetaDefinition( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Binding entity from annotated class: %s", id = 14 )
     void bindingEntityFromClass( String className );
 
     @LogMessage( level = INFO )
     @Message( value = "Binding filter definition: %s", id = 15 )
     void bindingFilterDefinition( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Binding named native query: %s => %s", id = 16 )
     void bindingNamedNativeQuery( String name,
                                   String query );
 
     @LogMessage( level = INFO )
     @Message( value = "Binding named query: %s => %s", id = 17 )
     void bindingNamedQuery( String name,
                             String query );
 
     @LogMessage( level = INFO )
     @Message( value = "Binding result set mapping: %s", id = 18 )
     void bindingResultSetMapping( String mapping );
 
     @LogMessage( level = INFO )
     @Message( value = "Binding type definition: %s", id = 19 )
     void bindingTypeDefinition( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Building session factory", id = 20 )
     void buildingSessionFactory();
 
     @LogMessage( level = INFO )
     @Message( value = "Bytecode provider name : %s", id = 21 )
     void bytecodeProvider( String provider );
 
     @LogMessage( level = WARN )
     @Message( value = "c3p0 properties were encountered, but the %s provider class was not found on the classpath; these properties are going to be ignored.", id = 22 )
     void c3p0ProviderClassNotFound( String c3p0ProviderClassName );
 
     @LogMessage( level = WARN )
     @Message( value = "I/O reported cached file could not be found : %s : %s", id = 23 )
     void cachedFileNotFound( String path,
                              FileNotFoundException error );
 
     @LogMessage( level = INFO )
     @Message( value = "Cache provider: %s", id = 24 )
     void cacheProvider( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Cache region factory : %s", id = 25 )
     void cacheRegionFactory( String regionFactoryClassName );
 
     @LogMessage( level = INFO )
     @Message( value = "Cache region prefix: %s", id = 26 )
     void cacheRegionPrefix( String prefix );
 
     @LogMessage( level = WARN )
     @Message( value = "Calling joinTransaction() on a non JTA EntityManager", id = 27 )
     void callingJoinTransactionOnNonJtaEntityManager();
 
     @Message( value = "CGLIB Enhancement failed: %s", id = 28 )
     String cglibEnhancementFailed( String entityName );
 
     @LogMessage( level = INFO )
     @Message( value = "Check Nullability in Core (should be disabled when Bean Validation is on): %s", id = 29 )
     void checkNullability( String enabledDisabled );
 
     @LogMessage( level = INFO )
     @Message( value = "Cleaning up connection pool [%s]", id = 30 )
     void cleaningUpConnectionPool( String url );
 
     @LogMessage( level = INFO )
     @Message( value = "Closing", id = 31 )
     void closing();
 
     @LogMessage( level = INFO )
     @Message( value = "Collections fetched (minimize this): %s", id = 32 )
     void collectionsFetched( long collectionFetchCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Collections loaded: %s", id = 33 )
     void collectionsLoaded( long collectionLoadCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Collections recreated: %s", id = 34 )
     void collectionsRecreated( long collectionRecreateCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Collections removed: %s", id = 35 )
     void collectionsRemoved( long collectionRemoveCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Collections updated: %s", id = 36 )
     void collectionsUpdated( long collectionUpdateCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Columns: %s", id = 37 )
     void columns( Set keySet );
 
     @LogMessage( level = WARN )
     @Message( value = "Composite-id class does not override equals(): %s", id = 38 )
     void compositeIdClassDoesNotOverrideEquals( String name );
 
     @LogMessage( level = WARN )
     @Message( value = "Composite-id class does not override hashCode(): %s", id = 39 )
     void compositeIdClassDoesNotOverrideHashCode( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuration resource: %s", id = 40 )
     void configurationResource( String resource );
 
     @LogMessage( level = INFO )
     @Message( value = "Configured SessionFactory: %s", id = 41 )
     void configuredSessionFactory( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuring from file: %s", id = 42 )
     void configuringFromFile( String file );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuring from resource: %s", id = 43 )
     void configuringFromResource( String resource );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuring from URL: %s", id = 44 )
     void configuringFromUrl( URL url );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuring from XML document", id = 45 )
     void configuringFromXmlDocument();
 
     @LogMessage( level = INFO )
     @Message( value = "Connection properties: %s", id = 46 )
     void connectionProperties( Properties connectionProps );
 
     @LogMessage( level = INFO )
     @Message( value = "Connection release mode: %s", id = 47 )
     void connectionReleaseMode( String releaseModeName );
 
     @LogMessage( level = INFO )
     @Message( value = "Connections obtained: %s", id = 48 )
     void connectionsObtained( long connectCount );
 
     @LogMessage( level = INFO )
     @Message( value = "%s did not provide constructor accepting java.util.Properties; attempting no-arg constructor.", id = 49 )
     void constructorWithPropertiesNotFound( String regionFactoryClassName );
 
     @LogMessage( level = ERROR )
     @Message( value = "Container is providing a null PersistenceUnitRootUrl: discovery impossible", id = 50 )
     void containerProvidingNullPersistenceUnitRootUrl();
 
     @LogMessage( level = WARN )
     @Message( value = "Ignoring bag join fetch [%s] due to prior collection join fetch", id = 51 )
     void containsJoinFetchedCollection( String role );
 
     @Message( value = "Could not close connection", id = 52 )
     Object couldNotCloseConnection();
 
     @LogMessage( level = INFO )
     @Message( value = "Creating subcontext: %s", id = 53 )
     void creatingSubcontextInfo( String intermediateContextName );
 
     @LogMessage( level = INFO )
     @Message( value = "Database ->\n" + "       name : %s\n" + "    version : %s\n" + "      major : %s\n" + "      minor : %s", id = 54 )
     void database( String databaseProductName,
                    String databaseProductVersion,
                    int databaseMajorVersion,
                    int databaseMinorVersion );
 
     @LogMessage( level = INFO )
     @Message( value = "Default batch fetch size: %s", id = 55 )
     void defaultBatchFetchSize( int batchFetchSize );
 
     @LogMessage( level = INFO )
     @Message( value = "Default catalog: %s", id = 56 )
     void defaultCatalog( String defaultCatalog );
 
     @LogMessage( level = INFO )
     @Message( value = "Default entity-mode: %s", id = 57 )
     void defaultEntityMode( EntityMode defaultEntityMode );
 
     @LogMessage( level = INFO )
     @Message( value = "Default schema: %s", id = 58 )
     void defaultSchema( String defaultSchema );
 
     @LogMessage( level = WARN )
     @Message( value = "Defining %s=true ignored in HEM", id = 59 )
     void definingFlushBeforeCompletionIgnoredInHem( String flushBeforeCompletion );
 
     @LogMessage( level = INFO )
     @Message( value = "Deleted entity synthetic identifier rollback: %s", id = 60 )
     void deletedEntitySyntheticIdentifierRollback( String enabledDisabled );
 
     @LogMessage( level = WARN )
     @Message( value = "Per HHH-5451 support for cglib as a bytecode provider has been deprecated.", id = 61 )
     void deprecated();
 
     @LogMessage( level = WARN )
     @Message( value = "@ForceDiscriminator is deprecated use @DiscriminatorOptions instead.", id = 62 )
     void deprecatedForceDescriminatorAnnotation();
 
     @LogMessage( level = WARN )
     @Message( value = "The Oracle9Dialect dialect has been deprecated; use either Oracle9iDialect or Oracle10gDialect instead", id = 63 )
     void deprecatedOracle9Dialect();
 
     @LogMessage( level = WARN )
     @Message( value = "The OracleDialect dialect has been deprecated; use Oracle8iDialect instead", id = 64 )
     void deprecatedOracleDialect();
 
     @LogMessage( level = WARN )
     @Message( value = "DEPRECATED : use {} instead with custom {} implementation", id = 65 )
     void deprecatedUuidGenerator( String name,
                                   String name2 );
 
     @LogMessage( level = WARN )
     @Message( value = "Dialect resolver class not found: %s", id = 66 )
     void dialectResolverNotFound( String resolverName );
 
     @LogMessage( level = INFO )
     @Message( value = "Disallowing insert statement comment for select-identity due to Oracle driver bug", id = 67 )
     void disallowingInsertStatementComment();
 
     @LogMessage( level = INFO )
     @Message( value = "Driver ->\n" + "       name : %s\n" + "    version : %s\n" + "      major : %s\n" + "      minor : %s", id = 68 )
     void driver( String driverProductName,
                  String driverProductVersion,
                  int driverMajorVersion,
                  int driverMinorVersion );
 
     @LogMessage( level = WARN )
     @Message( value = "Duplicate generator name %s", id = 69 )
     void duplicateGeneratorName( String name );
 
     @LogMessage( level = WARN )
     @Message( value = "Duplicate generator table: %s", id = 70 )
     void duplicateGeneratorTable( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Duplicate import: %s -> %s", id = 71 )
     void duplicateImport( String entityName,
                           String rename );
 
     @LogMessage( level = WARN )
     @Message( value = "Duplicate joins for class: %s", id = 72 )
     void duplicateJoins( String entityName );
 
     @LogMessage( level = INFO )
     @Message( value = "entity-listener duplication, first event definition will be used: %s", id = 73 )
     void duplicateListener( String className );
 
     @LogMessage( level = WARN )
     @Message( value = "Found more than one <persistence-unit-metadata>, subsequent ignored", id = 74 )
     void duplicateMetadata();
 
     @LogMessage( level = INFO )
     @Message( value = "Echoing all SQL to stdout", id = 75 )
     void echoingSql();
 
     @LogMessage( level = INFO )
     @Message( value = "Entities deleted: %s", id = 76 )
     void entitiesDeleted( long entityDeleteCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Entities fetched (minimize this): %s", id = 77 )
     void entitiesFetched( long entityFetchCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Entities inserted: %s", id = 78 )
     void entitiesInserted( long entityInsertCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Entities loaded: %s", id = 79 )
     void entitiesLoaded( long entityLoadCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Entities updated: %s", id = 80 )
     void entitiesUpdated( long entityUpdateCount );
 
     @LogMessage( level = WARN )
     @Message( value = "@org.hibernate.annotations.Entity used on a non root entity: ignored for %s", id = 81 )
     void entityAnnotationOnNonRoot( String className );
 
     @LogMessage( level = WARN )
     @Message( value = "Entity Manager closed by someone else (%s must not be used)", id = 82 )
     void entityManagerClosedBySomeoneElse( String autoCloseSession );
 
     @LogMessage( level = INFO )
     @Message( value = "Hibernate EntityManager %s", id = 83 )
     void entityManagerVersion( String versionString );
 
     @LogMessage( level = WARN )
     @Message( value = "Entity [%s] is abstract-class/interface explicitly mapped as non-abstract; be sure to supply entity-names", id = 84 )
     void entityMappedAsNonAbstract( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "%s %s found", id = 85 )
     void exceptionHeaderFound( String exceptionHeader,
                                String metaInfOrmXml );
 
     @LogMessage( level = INFO )
     @Message( value = "%s No %s found", id = 86 )
     void exceptionHeaderNotFound( String exceptionHeader,
                                   String metaInfOrmXml );
 
     @LogMessage( level = ERROR )
     @Message( value = "Exception in interceptor afterTransactionCompletion()", id = 87 )
     void exceptionInAfterTransactionCompletionInterceptor( @Cause Throwable e );
 
     @LogMessage( level = ERROR )
     @Message( value = "Exception in interceptor beforeTransactionCompletion()", id = 88 )
     void exceptionInBeforeTransactionCompletionInterceptor( @Cause Throwable e );
 
     @LogMessage( level = INFO )
     @Message( value = "Sub-resolver threw unexpected exception, continuing to next : %s", id = 89 )
     void exceptionInSubResolver( String message );
 
     @LogMessage( level = INFO )
     @Message( value = "Executing import script: %s", id = 90 )
     void executingImportScript( String name );
 
     @LogMessage( level = ERROR )
     @Message( value = "Expected type: %s, actual value: %s", id = 91 )
     void expectedType( String name,
                        String string );
 
     @LogMessage( level = WARN )
     @Message( value = "An item was expired by the cache while it was locked (increase your cache timeout): %s", id = 92 )
     void expired( Object key );
 
     @LogMessage( level = INFO )
     @Message( value = "Exporting generated schema to database", id = 93 )
     void exportingGeneratedSchemaToDatabase();
 
     @LogMessage( level = INFO )
     @Message( value = "Bound factory to JNDI name: %s", id = 94 )
     void factoryBoundToJndiName( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Factory name: %s", id = 95 )
     void factoryName( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "A factory was renamed from name: %s", id = 96 )
     void factoryRenamedFromName( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Unbound factory from JNDI name: %s", id = 97 )
     void factoryUnboundFromJndiName( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "A factory was unbound from name: %s", id = 98 )
     void factoryUnboundFromName( String name );
 
     @LogMessage( level = ERROR )
     @Message( value = "an assertion failure occured" + " (this may indicate a bug in Hibernate, but is more likely due"
                       + " to unsafe use of the session): %s", id = 99 )
     void failed( Throwable throwable );
 
     @LogMessage( level = WARN )
     @Message( value = "Fail-safe cleanup (collections) : %s", id = 100 )
     void failSafeCollectionsCleanup( CollectionLoadContext collectionLoadContext );
 
     @LogMessage( level = WARN )
     @Message( value = "Fail-safe cleanup (entities) : %s", id = 101 )
     void failSafeEntitiesCleanup( EntityLoadContext entityLoadContext );
 
     @LogMessage( level = INFO )
     @Message( value = "Fetching database metadata", id = 102 )
     void fetchingDatabaseMetadata();
 
     @LogMessage( level = WARN )
     @Message( value = "@Filter not allowed on subclasses (ignored): %s", id = 103 )
     void filterAnnotationOnSubclass( String className );
 
     @LogMessage( level = WARN )
     @Message( value = "firstResult/maxResults specified with collection fetch; applying in memory!", id = 104 )
     void firstOrMaxResultsSpecifiedWithCollectionFetch();
 
     @LogMessage( level = INFO )
     @Message( value = "Flushes: %s", id = 105 )
     void flushes( long flushCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Forcing container resource cleanup on transaction completion", id = 106 )
     void forcingContainerResourceCleanup();
 
     @LogMessage( level = INFO )
     @Message( value = "Forcing table use for sequence-style generator due to pooled optimizer selection where db does not support pooled sequences", id = 107 )
     void forcingTableUse();
 
     @LogMessage( level = INFO )
     @Message( value = "Foreign keys: %s", id = 108 )
     void foreignKeys( Set keySet );
 
     @LogMessage( level = INFO )
     @Message( value = "Found mapping document in jar: %s", id = 109 )
     void foundMappingDocument( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "JVM does not support Statement.getGeneratedKeys()", id = 110 )
     void generatedKeysNotSupported();
 
     @LogMessage( level = INFO )
     @Message( value = "Generate SQL with comments: %s", id = 111 )
     void generateSqlWithComments( String enabledDisabled );
 
     @LogMessage( level = ERROR )
     @Message( value = "Getters of lazy classes cannot be final: %s.%s", id = 112 )
     void gettersOfLazyClassesCannotBeFinal( String entityName,
                                             String name );
 
     @LogMessage( level = WARN )
     @Message( value = "GUID identifier generated: %s", id = 113 )
     void guidGenerated( String result );
 
     @LogMessage( level = INFO )
     @Message( value = "Handling transient entity in delete processing", id = 114 )
     void handlingTransientEntity();
 
     @LogMessage( level = INFO )
     @Message( value = "Hibernate connection pool size: %s", id = 115 )
     void hibernateConnectionPoolSize( int poolSize );
 
     @LogMessage( level = WARN )
     @Message( value = "Config specified explicit optimizer of [%s], but [%s=%s; honoring optimizer setting", id = 116 )
     void honoringOptimizerSetting( String none,
                                    String incrementParam,
                                    int incrementSize );
 
     @LogMessage( level = INFO )
     @Message( value = "HQL: %s, time: %sms, rows: %s", id = 117 )
     void hql( String hql,
               Long valueOf,
               Long valueOf2 );
 
     @LogMessage( level = WARN )
     @Message( value = "HSQLDB supports only READ_UNCOMMITTED isolation", id = 118 )
     void hsqldbSupportsOnlyReadCommittedIsolation();
 
     @LogMessage( level = WARN )
     @Message( value = "On EntityLoadContext#clear, hydratingEntities contained [%s] entries", id = 119 )
     void hydratingEntitiesCount( int size );
 
     @LogMessage( level = WARN )
     @Message( value = "Ignoring unique constraints specified on table generator [%s]", id = 120 )
     void ignoringTableGeneratorConstraints( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Ignoring unrecognized query hint [%s]", id = 121 )
     void ignoringUnrecognizedQueryHint( String hintName );
 
     @LogMessage( level = ERROR )
     @Message( value = "IllegalArgumentException in class: %s, getter method of property: %s", id = 122 )
     void illegalPropertyGetterArgument( String name,
                                         String propertyName );
 
     @LogMessage( level = ERROR )
     @Message( value = "IllegalArgumentException in class: %s, setter method of property: %s", id = 123 )
     void illegalPropertySetterArgument( String name,
                                         String propertyName );
 
     @LogMessage( level = WARN )
     @Message( value = "@Immutable used on a non root entity: ignored for %s", id = 124 )
     void immutableAnnotationOnNonRoot( String className );
 
     @LogMessage( level = WARN )
     @Message( value = "Mapping metadata cache was not completely processed", id = 125 )
     void incompleteMappingMetadataCacheProcessing();
 
     @LogMessage( level = INFO )
     @Message( value = "Indexes: %s", id = 126 )
     void indexes( Set keySet );
 
     @LogMessage( level = WARN )
     @Message( value = "InitialContext did not implement EventContext", id = 127 )
     void initialContextDidNotImplementEventContext();
 
     @LogMessage( level = WARN )
     @Message( value = "InitialContext did not implement EventContext", id = 128 )
     void initialContextDoesNotImplementEventContext();
 
     @LogMessage( level = INFO )
     @Message( value = "Instantiated TransactionManagerLookup", id = 129 )
     void instantiatedTransactionManagerLookup();
 
     @LogMessage( level = INFO )
     @Message( value = "Instantiating explicit connection provider: %s", id = 130 )
     void instantiatingExplicitConnectinProvider( String providerClassName );
 
     @LogMessage( level = INFO )
     @Message( value = "Instantiating TransactionManagerLookup: %s", id = 131 )
     void instantiatingTransactionManagerLookup( String tmLookupClass );
 
     @LogMessage( level = ERROR )
     @Message( value = "Array element type error\n%s", id = 132 )
     void invalidArrayElementType( String message );
 
     @LogMessage( level = WARN )
     @Message( value = "Discriminator column has to be defined in the root entity, it will be ignored in subclass: %s", id = 133 )
     void invalidDescriminatorAnnotation( String className );
 
     @LogMessage( level = ERROR )
     @Message( value = "Application attempted to edit read only item: %s", id = 134 )
     void invalidEditOfReadOnlyItem( Object key );
 
     @LogMessage( level = ERROR )
     @Message( value = "Invalid JNDI name: %s", id = 135 )
     void invalidJndiName( String name,
                           @Cause InvalidNameException e );
 
     @LogMessage( level = WARN )
     @Message( value = "Inapropriate use of @OnDelete on entity, annotation ignored: %s", id = 136 )
     void invalidOnDeleteAnnotation( String entityName );
 
     @LogMessage( level = WARN )
     @Message( value = "Root entity should not hold an PrimaryKeyJoinColum(s), will be ignored", id = 137 )
     void invalidPrimaryKeyJoinColumnAnnotation();
 
     @LogMessage( level = WARN )
     @Message( value = "Mixing inheritance strategy in a entity hierarchy is not allowed, ignoring sub strategy in: %s", id = 138 )
     void invalidSubStrategy( String className );
 
     @LogMessage( level = WARN )
     @Message( value = "Illegal use of @Table in a subclass of a SINGLE_TABLE hierarchy: %s", id = 139 )
     void invalidTableAnnotation( String className );
 
     @LogMessage( level = INFO )
     @Message( value = "JACC contextID: %s", id = 140 )
     void jaccContextId( String contextId );
 
     @LogMessage( level = INFO )
     @Message( value = "java.sql.Types mapped the same code [%s] multiple times; was [%s]; now [%s]", id = 141 )
     void JavaSqlTypesMappedSameCodeMultipleTimes( int code,
                                                   String old,
                                                   String name );
 
     @Message( value = "Javassist Enhancement failed: %s", id = 142 )
     String javassistEnhancementFailed( String entityName );
 
     @LogMessage( level = INFO )
     @Message( value = "JDBC3 getGeneratedKeys(): %s", id = 143 )
     void jdbc3GeneratedKeys( String enabledDisabled );
 
     @LogMessage( level = WARN )
     @Message( value = "%s = false breaks the EJB3 specification", id = 144 )
     void jdbcAutoCommitFalseBreaksEjb3Spec( String autocommit );
 
     @LogMessage( level = INFO )
     @Message( value = "JDBC batch size: %s", id = 145 )
     void jdbcBatchSize( int batchSize );
 
     @LogMessage( level = INFO )
     @Message( value = "JDBC batch updates for versioned data: %s", id = 146 )
     void jdbcBatchUpdates( String enabledDisabled );
 
     @Message( value = "JDBC begin failed", id = 147 )
     String jdbcBeginFailed();
 
     @LogMessage( level = WARN )
     @Message( value = "No JDBC Driver class was specified by property %s", id = 148 )
     void jdbcDriverNotSpecified( String driver );
 
     @LogMessage( level = INFO )
     @Message( value = "JDBC isolation level: %s", id = 149 )
     void jdbcIsolationLevel( String isolationLevelToString );
 
     @LogMessage( level = INFO )
     @Message( value = "JDBC result set fetch size: %s", id = 150 )
     void jdbcResultSetFetchSize( Integer statementFetchSize );
 
     @Message( value = "JDBC rollback failed", id = 151 )
     String jdbcRollbackFailed();
 
     @Message( value = "JDBC URL was not specified by property %s", id = 152 )
     String jdbcUrlNotSpecified( String url );
 
     @LogMessage( level = INFO )
     @Message( value = "JDBC version : %s.%s", id = 153 )
     void jdbcVersion( int jdbcMajorVersion,
                       int jdbcMinorVersion );
 
     @LogMessage( level = INFO )
     @Message( value = "JNDI InitialContext properties:%s", id = 154 )
     void jndiInitialContextProperties( Hashtable hash );
 
     @LogMessage( level = ERROR )
     @Message( value = "JNDI name %s does not handle a session factory reference", id = 155 )
     void jndiNameDoesNotHandleSessionFactoryReference( String sfJNDIName,
                                                        @Cause ClassCastException e );
 
     @LogMessage( level = INFO )
     @Message( value = "JPA-QL strict compliance: %s", id = 156 )
     void jpaQlStrictCompliance( String enabledDisabled );
 
     @LogMessage( level = INFO )
     @Message( value = "Lazy property fetching available for: %s", id = 157 )
     void lazyPropertyFetchingAvailable( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "JVM does not support LinkedHashMap, LinkedHashSet - ordered maps and sets disabled", id = 158 )
     void linkedMapsAndSetsNotSupported();
 
     @LogMessage( level = WARN )
     @Message( value = "In CollectionLoadContext#endLoadingCollections, localLoadingCollectionKeys contained [%s], but no LoadingCollectionEntry was found in loadContexts", id = 159 )
     void loadingCollectionKeyNotFound( CollectionKey collectionKey );
 
     @LogMessage( level = WARN )
     @Message( value = "On CollectionLoadContext#cleanup, localLoadingCollectionKeys contained [%s] entries", id = 160 )
     void localLoadingCollectionKeysCount( int size );
 
     @LogMessage( level = INFO )
     @Message( value = "Logging statistics....", id = 161 )
     void loggingStatistics();
 
     @LogMessage( level = INFO )
     @Message( value = "*** Logical connection closed ***", id = 162 )
     void logicalConnectionClosed();
 
     @LogMessage( level = INFO )
     @Message( value = "Logical connection releasing its physical connection", id = 163 )
     void logicalConnectionReleasingPhysicalConnection();
 
     @LogMessage( level = WARN )
     @Message( value = "You should set hibernate.transaction.manager_lookup_class if cache is enabled", id = 164 )
     void managerLookupClassShouldBeSet();
 
     @LogMessage( level = INFO )
     @Message( value = "Mapping class: %s -> %s", id = 165 )
     void mappingClass( String entityName,
                        String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Mapping class join: %s -> %s", id = 166 )
     void mappingClassJoin( String entityName,
                            String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Mapping collection: %s -> %s", id = 167 )
     void mappingCollection( String name1,
                             String name2 );
 
     @LogMessage( level = INFO )
     @Message( value = "Mapping joined-subclass: %s -> %s", id = 168 )
     void mappingJoinedSubclass( String entityName,
                                 String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Mapping Package %s", id = 169 )
     void mappingPackage( String packageName );
 
     @LogMessage( level = INFO )
     @Message( value = "Mapping subclass: %s -> %s", id = 170 )
     void mappingSubclass( String entityName,
                           String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Mapping union-subclass: %s -> %s", id = 171 )
     void mappingUnionSubclass( String entityName,
                                String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Maximum outer join fetch depth: %s", id = 172 )
     void maxOuterJoinFetchDepth( Integer maxFetchDepth );
 
     @LogMessage( level = INFO )
     @Message( value = "Max query time: %sms", id = 173 )
     void maxQueryTime( long queryExecutionMaxTime );
 
     @LogMessage( level = WARN )
     @Message( value = "Function template anticipated %s arguments, but %s arguments encountered", id = 174 )
     void missingArguments( int anticipatedNumberOfArguments,
                            int numberOfArguments );
 
     @LogMessage( level = WARN )
     @Message( value = "Class annotated @org.hibernate.annotations.Entity but not javax.persistence.Entity (most likely a user error): %s", id = 175 )
     void missingEntityAnnotation( String className );
 
     @LogMessage( level = INFO )
     @Message( value = "Named query checking : %s", id = 176 )
     void namedQueryChecking( String enabledDisabled );
 
     @LogMessage( level = ERROR )
     @Message( value = "Error in named query: %s", id = 177 )
     void namedQueryError( String queryName,
                           @Cause HibernateException e );
 
     @LogMessage( level = WARN )
     @Message( value = "Naming exception occurred accessing factory: %s", id = 178 )
     void namingExceptionAccessingFactory( NamingException exception );
 
     @LogMessage( level = WARN )
     @Message( value = "Narrowing proxy to %s - this operation breaks ==", id = 179 )
     void narrowingProxy( Class concreteProxyClass );
 
     @LogMessage( level = WARN )
     @Message( value = "FirstResult/maxResults specified on polymorphic query; applying in memory!", id = 180 )
     void needsLimit();
 
     @LogMessage( level = WARN )
     @Message( value = "No appropriate connection provider encountered, assuming application will be supplying connections", id = 181 )
     void noAppropriateConnectionProvider();
 
     @LogMessage( level = INFO )
     @Message( value = "No default (no-argument) constructor for class: %s (class must be instantiated by Interceptor)", id = 182 )
     void noDefaultConstructor( String name );
 
     @LogMessage( level = WARN )
     @Message( value = "no persistent classes found for query class: %s", id = 183 )
     void noPersistentClassesFound( String query );
 
     @LogMessage( level = ERROR )
     @Message( value = "No session factory with JNDI name %s", id = 184 )
     void noSessionFactoryWithJndiName( String sfJNDIName,
                                        @Cause NameNotFoundException e );
 
     @LogMessage( level = INFO )
     @Message( value = "Not binding factory to JNDI, no JNDI name configured", id = 185 )
     void notBindingFactoryToJndi();
 
     @LogMessage( level = INFO )
     @Message( value = "Obtaining TransactionManager", id = 186 )
     void obtainingTransactionManager();
 
     @LogMessage( level = INFO )
     @Message( value = "Optimistic lock failures: %s", id = 187 )
     void optimisticLockFailures( long optimisticFailureCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Optimize cache for minimal puts: %s", id = 188 )
     void optimizeCacheForMinimalInputs( String enabledDisabled );
 
     @LogMessage( level = WARN )
     @Message( value = "@OrderBy not allowed for an indexed collection, annotation ignored.", id = 189 )
     void orderByAnnotationIndexedCollection();
 
     @LogMessage( level = WARN )
     @Message( value = "Attribute \"order-by\" ignored in JDK1.3 or less", id = 190 )
     void orderByAttributeIgnored();
 
     @LogMessage( level = INFO )
     @Message( value = "Order SQL inserts for batching: %s", id = 191 )
     void orderSqlInsertsForBatching( String enabledDisabled );
 
     @LogMessage( level = INFO )
     @Message( value = "Order SQL updates by primary key: %s", id = 192 )
     void orderSqlUpdatesByPrimaryKey( String enabledDisabled );
 
     @LogMessage( level = WARN )
     @Message( value = "Overriding %s is dangerous, this might break the EJB3 specification implementation", id = 193 )
     void overridingTransactionStrategyDangerous( String transactionStrategy );
 
     @LogMessage( level = WARN )
     @Message( value = "Package not found or wo package-info.java: %s", id = 194 )
     void packageNotFound( String packageName );
 
     @LogMessage( level = WARN )
     @Message( value = "Parameter position [%s] occurred as both JPA and Hibernate positional parameter", id = 195 )
     void parameterPositionOccurredAsBothJpaAndHibernatePositionalParameter( Integer position );
 
     @LogMessage( level = ERROR )
     @Message( value = "Error parsing XML (%s) : %s", id = 196 )
     void parsingXmlError( int lineNumber,
                           String message );
 
     @LogMessage( level = ERROR )
     @Message( value = "Error parsing XML: %s(%s) %s", id = 197 )
     void parsingXmlErrorForFile( String file,
                                  int lineNumber,
                                  String message );
 
     @LogMessage( level = ERROR )
     @Message( value = "Warning parsing XML (%s) : %s", id = 198 )
     void parsingXmlWarning( int lineNumber,
                             String message );
 
     @LogMessage( level = WARN )
     @Message( value = "Warning parsing XML: %s(%s) %s", id = 199 )
     void parsingXmlWarningForFile( String file,
                                    int lineNumber,
                                    String message );
 
     @LogMessage( level = WARN )
     @Message( value = "Persistence provider caller does not implement the EJB3 spec correctly."
                       + "PersistenceUnitInfo.getNewTempClassLoader() is null.", id = 200 )
     void persistenceProviderCallerDoesNotImplementEjb3SpecCorrectly();
 
     @LogMessage( level = INFO )
     @Message( value = "Pooled optimizer source reported [%s] as the initial value; use of 1 or greater highly recommended", id = 201 )
     void pooledOptimizerReportedInitialValue( IntegralDataTypeHolder value );
 
     @LogMessage( level = ERROR )
     @Message( value = "PreparedStatement was already in the batch, [%s].", id = 202 )
     void preparedStatementAlreadyInBatch( String sql );
 
     @LogMessage( level = WARN )
     @Message( value = "processEqualityExpression() : No expression to process!", id = 203 )
     void processEqualityExpression();
 
     @LogMessage( level = INFO )
     @Message( value = "Processing PersistenceUnitInfo [\n\tname: %s\n\t...]", id = 204 )
     void processingPersistenceUnitInfoName( String persistenceUnitName );
 
     @LogMessage( level = INFO )
     @Message( value = "Loaded properties from resource hibernate.properties: %s", id = 205 )
     void propertiesLoaded( Properties maskOut );
 
     @LogMessage( level = INFO )
     @Message( value = "hibernate.properties not found", id = 206 )
     void propertiesNotFound();
 
     @LogMessage( level = WARN )
     @Message( value = "Property %s not found in class but described in <mapping-file/> (possible typo error)", id = 207 )
     void propertyNotFound( String property );
 
     @LogMessage( level = WARN )
     @Message( value = "%s has been deprecated in favor of %s; that provider will be used instead.", id = 208 )
     void providerClassDeprecated( String providerClassName,
                                   String actualProviderClassName );
 
     @LogMessage( level = WARN )
     @Message( value = "proxool properties were encountered, but the %s provider class was not found on the classpath; these properties are going to be ignored.", id = 209 )
     void proxoolProviderClassNotFound( String proxoolProviderClassName );
 
     @LogMessage( level = INFO )
     @Message( value = "Queries executed to database: %s", id = 210 )
     void queriesExecuted( long queryExecutionCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Query cache: %s", id = 211 )
     void queryCache( String enabledDisabled );
 
     @LogMessage( level = INFO )
     @Message( value = "Query cache factory: %s", id = 212 )
     void queryCacheFactory( String queryCacheFactoryClassName );
 
     @LogMessage( level = INFO )
     @Message( value = "Query cache hits: %s", id = 213 )
     void queryCacheHits( long queryCacheHitCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Query cache misses: %s", id = 214 )
     void queryCacheMisses( long queryCacheMissCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Query cache puts: %s", id = 215 )
     void queryCachePuts( long queryCachePutCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Query language substitutions: %s", id = 216 )
     void queryLanguageSubstitutions( Map querySubstitutions );
 
     @LogMessage( level = INFO )
     @Message( value = "Query translator: %s", id = 217 )
     void queryTranslator( String className );
 
     @LogMessage( level = INFO )
     @Message( value = "RDMSOS2200Dialect version: 1.0", id = 218 )
     void rdmsOs2200Dialect();
 
     @LogMessage( level = INFO )
     @Message( value = "Reading mappings from cache file: %s", id = 219 )
     void readingCachedMappings( File cachedFile );
 
     @LogMessage( level = INFO )
     @Message( value = "Reading mappings from file: %s", id = 220 )
     void readingMappingsFromFile( String path );
 
     @LogMessage( level = INFO )
     @Message( value = "Reading mappings from resource: %s", id = 221 )
     void readingMappingsFromResource( String resourceName );
 
     @LogMessage( level = WARN )
     @Message( value = "read-only cache configured for mutable collection [%s]", id = 222 )
     void readOnlyCacheConfiguredForMutableCollection( String name );
 
     @LogMessage( level = WARN )
     @Message( value = "Recognized obsolete hibernate namespace %s. Use namespace %s instead. Refer to Hibernate 3.6 Migration Guide!", id = 223 )
     void recognizedObsoleteHibernateNamespace( String oldHibernateNamespace,
                                                String hibernateNamespace );
 
     @LogMessage( level = WARN )
     @Message( value = "Reconnecting the same connection that is already connected; should this connection have been disconnected?", id = 224 )
     void reconnectingConnectedConnection();
 
     @LogMessage( level = WARN )
     @Message( value = "Property [%s] has been renamed to [%s]; update your properties appropriately", id = 225 )
     void renamedProperty( Object propertyName,
                           Object newPropertyName );
 
     @LogMessage( level = INFO )
     @Message( value = "Required a different provider: %s", id = 226 )
     void requiredDifferentProvider( String provider );
 
     @LogMessage( level = INFO )
     @Message( value = "Running hbm2ddl schema export", id = 227 )
     void runningHbm2ddlSchemaExport();
 
     @LogMessage( level = INFO )
     @Message( value = "Running hbm2ddl schema update", id = 228 )
     void runningHbm2ddlSchemaUpdate();
 
     @LogMessage( level = INFO )
     @Message( value = "Running schema validator", id = 229 )
     void runningSchemaValidator();
 
     @LogMessage( level = INFO )
     @Message( value = "Schema export complete", id = 230 )
     void schemaExportComplete();
 
     @LogMessage( level = ERROR )
     @Message( value = "Schema export unsuccessful", id = 231 )
     void schemaExportUnsuccessful( @Cause Exception e );
 
     @LogMessage( level = INFO )
     @Message( value = "Schema update complete", id = 232 )
     void schemaUpdateComplete();
 
     @LogMessage( level = WARN )
     @Message( value = "Scoping types to session factory %s after already scoped %s", id = 233 )
     void scopingTypesToSessionFactoryAfterAlreadyScoped( SessionFactoryImplementor factory,
                                                          SessionFactoryImplementor factory2 );
 
     @LogMessage( level = INFO )
     @Message( value = "Scrollable result sets: %s", id = 234 )
     void scrollabelResultSets( String enabledDisabled );
 
     @LogMessage( level = INFO )
     @Message( value = "Searching for mapping documents in jar: %s", id = 235 )
     void searchingForMappingDocuments( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Second-level cache: %s", id = 236 )
     void secondLevelCache( String enabledDisabled );
 
     @LogMessage( level = INFO )
     @Message( value = "Second level cache hits: %s", id = 237 )
     void secondLevelCacheHits( long secondLevelCacheHitCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Second level cache misses: %s", id = 238 )
     void secondLevelCacheMisses( long secondLevelCacheMissCount );
 
     @LogMessage( level = INFO )
     @Message( value = "Second level cache puts: %s", id = 239 )
     void secondLevelCachePuts( long secondLevelCachePutCount );
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
index 7b5f344a98..ea84f0d0e8 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/ConfigHelper.java
@@ -1,204 +1,205 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
 import java.net.MalformedURLException;
 import java.net.URL;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
+
 import org.jboss.logging.Logger;
 
 /**
  * A simple class to centralize logic needed to locate config files on the system.
  *
  * @todo : Update usages to use {@link org.hibernate.service.classloading.spi.ClassLoaderService}
  *
  * @author Steve Ebersole
  */
 public final class ConfigHelper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ConfigHelper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ConfigHelper.class.getName());
 
 	/** Try to locate a local URL representing the incoming path.  The first attempt
 	 * assumes that the incoming path is an actual URL string (file://, etc).  If this
 	 * does not work, then the next attempts try to locate this UURL as a java system
 	 * resource.
 	 *
 	 * @param path The path representing the config location.
 	 * @return An appropriate URL or null.
 	 */
 	public static URL locateConfig(final String path) {
 		try {
 			return new URL(path);
 		}
 		catch(MalformedURLException e) {
 			return findAsResource(path);
 		}
 	}
 
 	/**
 	 * Try to locate a local URL representing the incoming path.
 	 * This method <b>only</b> attempts to locate this URL as a
 	 * java system resource.
 	 *
 	 * @param path The path representing the config location.
 	 * @return An appropriate URL or null.
 	 */
 	public static URL findAsResource(final String path) {
 		URL url = null;
 
 		// First, try to locate this resource through the current
 		// context classloader.
 		ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();
 		if (contextClassLoader!=null) {
 			url = contextClassLoader.getResource(path);
 		}
 		if (url != null)
 			return url;
 
 		// Next, try to locate this resource through this class's classloader
 		url = ConfigHelper.class.getClassLoader().getResource(path);
 		if (url != null)
 			return url;
 
 		// Next, try to locate this resource through the system classloader
 		url = ClassLoader.getSystemClassLoader().getResource(path);
 
 		// Anywhere else we should look?
 		return url;
 	}
 
 	/** Open an InputStream to the URL represented by the incoming path.  First makes a call
 	 * to {@link #locateConfig(java.lang.String)} in order to find an appropriate URL.
 	 * {@link java.net.URL#openStream()} is then called to obtain the stream.
 	 *
 	 * @param path The path representing the config location.
 	 * @return An input stream to the requested config resource.
 	 * @throws HibernateException Unable to open stream to that resource.
 	 */
 	public static InputStream getConfigStream(final String path) throws HibernateException {
 		final URL url = ConfigHelper.locateConfig(path);
 
 		if (url == null) {
             String msg = LOG.unableToLocateConfigFile(path);
             LOG.error(msg);
 			throw new HibernateException(msg);
 		}
 
 		try {
 			return url.openStream();
         }
 		catch(IOException e) {
 	        throw new HibernateException("Unable to open config file: " + path, e);
         }
 	}
 
 	/** Open an Reader to the URL represented by the incoming path.  First makes a call
 	 * to {@link #locateConfig(java.lang.String)} in order to find an appropriate URL.
 	 * {@link java.net.URL#openStream()} is then called to obtain a stream, which is then
 	 * wrapped in a Reader.
 	 *
 	 * @param path The path representing the config location.
 	 * @return An input stream to the requested config resource.
 	 * @throws HibernateException Unable to open reader to that resource.
 	 */
 	public static Reader getConfigStreamReader(final String path) throws HibernateException {
 		return new InputStreamReader( getConfigStream(path) );
 	}
 
 	/** Loads a properties instance based on the data at the incoming config location.
 	 *
 	 * @param path The path representing the config location.
 	 * @return The loaded properties instance.
 	 * @throws HibernateException Unable to load properties from that resource.
 	 */
 	public static Properties getConfigProperties(String path) throws HibernateException {
 		try {
 			Properties properties = new Properties();
 			properties.load( getConfigStream(path) );
 			return properties;
 		}
 		catch(IOException e) {
 			throw new HibernateException("Unable to load properties from specified config file: " + path, e);
 		}
 	}
 
 	private ConfigHelper() {}
 
 	public static InputStream getResourceAsStream(String resource) {
 		String stripped = resource.startsWith("/") ?
 				resource.substring(1) : resource;
 
 		InputStream stream = null;
 		ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
 		if (classLoader!=null) {
 			stream = classLoader.getResourceAsStream( stripped );
 		}
 		if ( stream == null ) {
 			stream = Environment.class.getResourceAsStream( resource );
 		}
 		if ( stream == null ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( stripped );
 		}
 		if ( stream == null ) {
 			throw new HibernateException( resource + " not found" );
 		}
 		return stream;
 	}
 
 
 	public static InputStream getUserResourceAsStream(String resource) {
 		boolean hasLeadingSlash = resource.startsWith( "/" );
 		String stripped = hasLeadingSlash ? resource.substring(1) : resource;
 
 		InputStream stream = null;
 
 		ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
 		if ( classLoader != null ) {
 			stream = classLoader.getResourceAsStream( resource );
 			if ( stream == null && hasLeadingSlash ) {
 				stream = classLoader.getResourceAsStream( stripped );
 			}
 		}
 
 		if ( stream == null ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( resource );
 		}
 		if ( stream == null && hasLeadingSlash ) {
 			stream = Environment.class.getClassLoader().getResourceAsStream( stripped );
 		}
 
 		if ( stream == null ) {
 			throw new HibernateException( resource + " not found" );
 		}
 
 		return stream;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
index cb0661d374..f3b7474496 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/SerializationHelper.java
@@ -1,371 +1,371 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.ObjectStreamClass;
 import java.io.OutputStream;
 import java.io.Serializable;
 import org.hibernate.Hibernate;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.SerializationException;
 import org.jboss.logging.Logger;
 
 /**
  * <p>Assists with the serialization process and performs additional functionality based
  * on serialization.</p>
  * <p>
  * <ul>
  * <li>Deep clone using serialization
  * <li>Serialize managing finally and IOException
  * <li>Deserialize managing finally and IOException
  * </ul>
  *
  * <p>This class throws exceptions for invalid <code>null</code> inputs.
  * Each method documents its behaviour in more detail.</p>
  *
  * @author <a href="mailto:nissim@nksystems.com">Nissim Karpenstein</a>
  * @author <a href="mailto:janekdb@yahoo.co.uk">Janek Bogucki</a>
  * @author <a href="mailto:dlr@finemaltcoding.com">Daniel Rall</a>
  * @author Stephen Colebourne
  * @author Jeff Varszegi
  * @author Gary Gregory
  * @version $Id: SerializationHelper.java 9180 2006-01-30 23:51:27Z steveebersole $
  * @since 1.0
  */
 public final class SerializationHelper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SerializationHelper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SerializationHelper.class.getName());
 
 	private SerializationHelper() {
 	}
 
 	// Clone
 	//-----------------------------------------------------------------------
 
 	/**
 	 * <p>Deep clone an <code>Object</code> using serialization.</p>
 	 *
 	 * <p>This is many times slower than writing clone methods by hand
 	 * on all objects in your object graph. However, for complex object
 	 * graphs, or for those that don't support deep cloning this can
 	 * be a simple alternative implementation. Of course all the objects
 	 * must be <code>Serializable</code>.</p>
 	 *
 	 * @param object the <code>Serializable</code> object to clone
 	 *
 	 * @return the cloned object
 	 *
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object clone(Serializable object) throws SerializationException {
         LOG.trace("Starting clone through serialization");
 		if ( object == null ) {
 			return null;
 		}
 		return deserialize( serialize( object ), object.getClass().getClassLoader() );
 	}
 
 	// Serialize
 	//-----------------------------------------------------------------------
 
 	/**
 	 * <p>Serializes an <code>Object</code> to the specified stream.</p>
 	 *
 	 * <p>The stream will be closed once the object is written.
 	 * This avoids the need for a finally clause, and maybe also exception
 	 * handling, in the application code.</p>
 	 *
 	 * <p>The stream passed in is not buffered internally within this method.
 	 * This is the responsibility of your application if desired.</p>
 	 *
 	 * @param obj the object to serialize to bytes, may be null
 	 * @param outputStream the stream to write to, must not be null
 	 *
 	 * @throws IllegalArgumentException if <code>outputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static void serialize(Serializable obj, OutputStream outputStream) throws SerializationException {
 		if ( outputStream == null ) {
 			throw new IllegalArgumentException( "The OutputStream must not be null" );
 		}
 
         if (LOG.isTraceEnabled()) {
             if (Hibernate.isInitialized(obj)) LOG.trace("Starting serialization of object [" + obj + "]");
             else LOG.trace("Starting serialization of [uninitialized proxy]");
 		}
 
 		ObjectOutputStream out = null;
 		try {
 			// stream closed in the finally
 			out = new ObjectOutputStream( outputStream );
 			out.writeObject( obj );
 
 		}
 		catch ( IOException ex ) {
 			throw new SerializationException( "could not serialize", ex );
 		}
 		finally {
 			try {
 				if ( out != null ) {
 					out.close();
 				}
 			}
 			catch ( IOException ignored ) {
 			}
 		}
 	}
 
 	/**
 	 * <p>Serializes an <code>Object</code> to a byte array for
 	 * storage/serialization.</p>
 	 *
 	 * @param obj the object to serialize to bytes
 	 *
 	 * @return a byte[] with the converted Serializable
 	 *
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static byte[] serialize(Serializable obj) throws SerializationException {
 		ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream( 512 );
 		serialize( obj, byteArrayOutputStream );
 		return byteArrayOutputStream.toByteArray();
 	}
 
 	// Deserialize
 	//-----------------------------------------------------------------------
 
 	/**
 	 * Deserializes an object from the specified stream using the Thread Context
 	 * ClassLoader (TCCL).
 	 * <p/>
 	 * Delegates to {@link #doDeserialize}
 	 *
 	 * @param inputStream the serialized object input stream, must not be null
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>inputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(InputStream inputStream) throws SerializationException {
 		return doDeserialize( inputStream, defaultClassLoader(), hibernateClassLoader(), null );
 	}
 
 	/**
 	 * Returns the Thread Context ClassLoader (TCCL).
 	 *
 	 * @return The current TCCL
 	 */
 	public static ClassLoader defaultClassLoader() {
 		return Thread.currentThread().getContextClassLoader();
 	}
 
 	public static ClassLoader hibernateClassLoader() {
 		return SerializationHelper.class.getClassLoader();
 	}
 
 	/**
 	 * Deserializes an object from the specified stream using the Thread Context
 	 * ClassLoader (TCCL).  If there is no TCCL set, the classloader of the calling
 	 * class is used.
 	 * <p/>
 	 * The stream will be closed once the object is read. This avoids the need
 	 * for a finally clause, and maybe also exception handling, in the application
 	 * code.
 	 * <p/>
 	 * The stream passed in is not buffered internally within this method.  This is
 	 * the responsibility of the caller, if desired.
 	 *
 	 * @param inputStream the serialized object input stream, must not be null
 	 * @param loader The classloader to use
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>inputStream</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(InputStream inputStream, ClassLoader loader) throws SerializationException {
 		return doDeserialize( inputStream, loader, defaultClassLoader(), hibernateClassLoader() );
 	}
 
 	public static Object doDeserialize(
 			InputStream inputStream,
 			ClassLoader loader,
 			ClassLoader fallbackLoader1,
 			ClassLoader fallbackLoader2) throws SerializationException {
 		if ( inputStream == null ) {
 			throw new IllegalArgumentException( "The InputStream must not be null" );
 		}
 
         LOG.trace("Starting deserialization of object");
 
 		try {
 			CustomObjectInputStream in = new CustomObjectInputStream(
 					inputStream,
 					loader,
 					fallbackLoader1,
 					fallbackLoader2
 			);
 			try {
 				return in.readObject();
 			}
 			catch ( ClassNotFoundException e ) {
 				throw new SerializationException( "could not deserialize", e );
 			}
 			catch ( IOException e ) {
 				throw new SerializationException( "could not deserialize", e );
 			}
 			finally {
 				try {
 					in.close();
 				}
 				catch ( IOException ignore ) {
 					// ignore
 				}
 			}
 		}
 		catch ( IOException e ) {
 			throw new SerializationException( "could not deserialize", e );
 		}
 	}
 
 	/**
 	 * Deserializes an object from an array of bytes using the Thread Context
 	 * ClassLoader (TCCL).  If there is no TCCL set, the classloader of the calling
 	 * class is used.
 	 * <p/>
 	 * Delegates to {@link #deserialize(byte[], ClassLoader)}
 	 *
 	 * @param objectData the serialized object, must not be null
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>objectData</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(byte[] objectData) throws SerializationException {
 		return doDeserialize( wrap( objectData ), defaultClassLoader(), hibernateClassLoader(), null );
 	}
 
 	private static InputStream wrap(byte[] objectData) {
 		if ( objectData == null ) {
 			throw new IllegalArgumentException( "The byte[] must not be null" );
 		}
 		return new ByteArrayInputStream( objectData );
 	}
 
 	/**
 	 * Deserializes an object from an array of bytes.
 	 * <p/>
 	 * Delegates to {@link #deserialize(java.io.InputStream, ClassLoader)} using a
 	 * {@link ByteArrayInputStream} to wrap the array.
 	 *
 	 * @param objectData the serialized object, must not be null
 	 * @param loader The classloader to use
 	 *
 	 * @return the deserialized object
 	 *
 	 * @throws IllegalArgumentException if <code>objectData</code> is <code>null</code>
 	 * @throws SerializationException (runtime) if the serialization fails
 	 */
 	public static Object deserialize(byte[] objectData, ClassLoader loader) throws SerializationException {
 		return doDeserialize( wrap( objectData ), loader, defaultClassLoader(), hibernateClassLoader() );
 	}
 
 
 	/**
 	 * By default, to resolve the classes being deserialized JDK serialization uses the
 	 * classes loader which loaded the class which initiated the deserialization call.  Here
 	 * that would be hibernate classes.  However, there are cases where that is not the correct
 	 * class loader to use; mainly here we are worried about deserializing user classes in
 	 * environments (app servers, etc) where Hibernate is on a parent classes loader.  To
 	 * facilitate for that we allow passing in the class loader we should use.
 	 */
 	private static final class CustomObjectInputStream extends ObjectInputStream {
 		private final ClassLoader loader1;
 		private final ClassLoader loader2;
 		private final ClassLoader loader3;
 
 		private CustomObjectInputStream(
 				InputStream in,
 				ClassLoader loader1,
 				ClassLoader loader2,
 				ClassLoader loader3) throws IOException {
 			super( in );
 			this.loader1 = loader1;
 			this.loader2 = loader2;
 			this.loader3 = loader3;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		@Override
         protected Class resolveClass(ObjectStreamClass v) throws IOException, ClassNotFoundException {
 			String className = v.getName();
             LOG.trace("Attempting to locate class [" + className + "]");
 
 			try {
 				return Class.forName( className, false, loader1 );
 			}
 			catch ( ClassNotFoundException e ) {
                 LOG.trace("Unable to locate class using given classloader");
 			}
 
 			if ( different( loader1, loader2 ) ) {
 				try {
 					return Class.forName( className, false, loader2 );
 				}
 				catch ( ClassNotFoundException e ) {
                     LOG.trace("Unable to locate class using given classloader");
 				}
 			}
 
 			if ( different( loader1, loader3 ) && different( loader2, loader3 ) ) {
 				try {
 					return Class.forName( className, false, loader3 );
 				}
 				catch ( ClassNotFoundException e ) {
                     LOG.trace("Unable to locate class using given classloader");
 				}
 			}
 
 			// By default delegate to normal JDK deserialization which will use the class loader
 			// of the class which is calling this deserialization.
 			return super.resolveClass( v );
 		}
 
 		private boolean different(ClassLoader one, ClassLoader other) {
             if (one == null) return other != null;
             return !one.equals(other);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/jndi/JndiHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/jndi/JndiHelper.java
index c1cfda898d..f05315cde0 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/jndi/JndiHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/jndi/JndiHelper.java
@@ -1,237 +1,239 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.jndi;
 import java.util.Hashtable;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import javax.naming.Context;
 import javax.naming.InitialContext;
 import javax.naming.Name;
 import javax.naming.NameNotFoundException;
 import javax.naming.NamingException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
+
 import org.jboss.logging.Logger;
 
 public final class JndiHelper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JndiHelper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JndiHelper.class.getName());
 
 	private JndiHelper() {
 	}
 
 	/**
 	 * Given a hodge-podge of properties, extract out the ones relevant for JNDI interaction.
 	 *
 	 * @param properties
 	 * @return
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public static Properties extractJndiProperties(Map configurationValues) {
 		final Properties jndiProperties = new Properties();
 
 		for ( Map.Entry entry : (Set<Map.Entry>) configurationValues.entrySet() ) {
 			if ( !String.class.isInstance( entry.getKey() ) ) {
 				continue;
 			}
 			final String propertyName = (String) entry.getKey();
 			final Object propertyValue = entry.getValue();
 			if ( propertyName.startsWith( Environment.JNDI_PREFIX ) ) {
 				// write the IntialContextFactory class and provider url to the result only if they are
 				// non-null; this allows the environmental defaults (if any) to remain in effect
 				if ( Environment.JNDI_CLASS.equals( propertyName ) ) {
 					if ( propertyValue != null ) {
 						jndiProperties.put( Context.INITIAL_CONTEXT_FACTORY, propertyValue );
 					}
 				}
 				else if ( Environment.JNDI_URL.equals( propertyName ) ) {
 					if ( propertyValue != null ) {
 						jndiProperties.put( Context.PROVIDER_URL, propertyValue );
 					}
 				}
 				else {
 					final String passThruPropertyname = propertyName.substring( Environment.JNDI_PREFIX.length() + 1 );
 					jndiProperties.put( passThruPropertyname, propertyValue );
 				}
 			}
 		}
 
 		return jndiProperties;
 	}
 
 	/**
 	 * Do a JNDI lookup.  Mainly we are handling {@link NamingException}
 	 *
 	 * @param jndiName The namespace of the object to locate
 	 * @param context The context in which to resolve the namespace.
 	 *
 	 * @return The located object; may be null.
 	 *
 	 * @throws JndiException if a {@link NamingException} occurs
 	 */
 	public static Object locate(String jndiName, Context context) {
 		try {
 			return context.lookup( jndiName );
 		}
 		catch ( NamingException e ) {
 			throw new JndiException( "Unable to lookup JNDI name [" + jndiName + "]", e );
 		}
 	}
 
 	/**
 	 * Bind val to name in ctx, and make sure that all intermediate contexts exist.
 	 *
 	 * @param ctx the root context
 	 * @param name the name as a string
 	 * @param val the object to be bound
 	 *
 	 * @throws JndiException if a {@link NamingException} occurs
 	 */
 	public static void bind(String jndiName, Object value, Context context) {
 		try {
             LOG.trace("Binding : " + jndiName);
 			context.rebind( jndiName, value );
 		}
 		catch ( Exception initialException ) {
 			// We had problems doing a simple bind operation.  This could very well be caused by missing intermediate
 			// contexts, so we attempt to create those intermmediate contexts and bind again
 			Name n = tokenizeName( jndiName, context );
 			Context intermediateContextBase = context;
 			while ( n.size() > 1 ) {
 				final String intermediateContextName = n.get( 0 );
 
 				Context intermediateContext = null;
 				try {
                     LOG.trace("Intermediate lookup: " + intermediateContextName);
 					intermediateContext = (Context) intermediateContextBase.lookup( intermediateContextName );
 				}
 				catch ( NameNotFoundException handledBelow ) {
 					// ok as we will create it below if not found
 				}
 				catch ( NamingException e ) {
 					throw new JndiException( "Unaniticipated error doing intermediate lookup", e );
 				}
 
                 if (intermediateContext != null) LOG.trace("Found intermediate context: " + intermediateContextName);
 				else {
                     LOG.trace("Creating subcontext: " + intermediateContextName);
 					try {
 						intermediateContext = intermediateContextBase.createSubcontext( intermediateContextName );
 					}
 					catch ( NamingException e ) {
 						throw new JndiException( "Error creating intermediate context [" + intermediateContextName + "]", e );
 					}
 				}
 				intermediateContextBase = intermediateContext;
 				n = n.getSuffix( 1 );
 			}
             LOG.trace("Binding : " + n);
 			try {
 				intermediateContextBase.rebind( n, value );
 			}
 			catch ( NamingException e ) {
 				throw new JndiException( "Error performing intermediate bind [" + n + "]", e );
 			}
 		}
         LOG.debugf("Bound name: %s", jndiName);
 	}
 
 	private static Name tokenizeName(String jndiName, Context context) {
 		try {
 			return context.getNameParser( "" ).parse( jndiName );
 		}
 		catch ( NamingException e ) {
 			throw new JndiException( "Unable to tokenize JNDI name [" + jndiName + "]", e );
 		}
 	}
 
 
 
 
 
 	// todo : remove these once we get the services in place and integrated into the SessionFactory
 
 
 
 
 
 
 	public static InitialContext getInitialContext(Properties props) throws NamingException {
 
 		Hashtable hash = extractJndiProperties(props);
         LOG.jndiInitialContextProperties(hash);
 		try {
 			return hash.size()==0 ?
 					new InitialContext() :
 					new InitialContext(hash);
 		}
 		catch (NamingException e) {
             LOG.unableToObtainInitialContext(e);
 			throw e;
 		}
 	}
 
 	/**
 	 * Bind val to name in ctx, and make sure that all intermediate contexts exist.
 	 *
 	 * @param ctx the root context
 	 * @param name the name as a string
 	 * @param val the object to be bound
 	 * @throws NamingException
 	 */
 	public static void bind(Context ctx, String name, Object val) throws NamingException {
 		try {
             LOG.trace("Binding : " + name);
 			ctx.rebind(name, val);
 		}
 		catch (Exception e) {
 			Name n = ctx.getNameParser("").parse(name);
 			while ( n.size() > 1 ) {
 				String ctxName = n.get(0);
 
 				Context subctx=null;
 				try {
                     LOG.trace("Lookup: " + ctxName);
 					subctx = (Context) ctx.lookup(ctxName);
 				}
 				catch (NameNotFoundException nfe) {}
 
 				if (subctx!=null) {
                     LOG.debugf("Found subcontext: %s", ctxName);
 					ctx = subctx;
 				}
 				else {
                     LOG.creatingSubcontextInfo(ctxName);
 					ctx = ctx.createSubcontext(ctxName);
 				}
 				n = n.getSuffix(1);
 			}
             LOG.trace("Binding : " + n);
 			ctx.rebind(n, val);
 		}
         LOG.debugf("Bound name: %s", name);
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/DTDEntityResolver.java b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/DTDEntityResolver.java
index 232ce9eef8..69af2908b2 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/DTDEntityResolver.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/DTDEntityResolver.java
@@ -1,121 +1,122 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.xml;
 
 import java.io.InputStream;
 import java.io.Serializable;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ConfigHelper;
+
 import org.jboss.logging.Logger;
 import org.xml.sax.EntityResolver;
 import org.xml.sax.InputSource;
 
 /**
  * An {@link EntityResolver} implementation which attempts to resolve
  * various systemId URLs to local classpath look ups<ol>
  * <li>Any systemId URL beginning with <tt>http://www.hibernate.org/dtd/</tt> is
  * searched for as a classpath resource in the classloader which loaded the
  * Hibernate classes.</li>
  * <li>Any systemId URL using <tt>classpath</tt> as the scheme (i.e. starting
  * with <tt>classpath://</tt> is searched for as a classpath resource using first
  * the current thread context classloader and then the classloader which loaded
  * the Hibernate classes.
  * </ol>
  * <p/>
  * Any entity references which cannot be resolved in relation to the above
  * rules result in returning null, which should force the SAX reader to
  * handle the entity reference in its default manner.
  *
  * @author Markus Meissner
  * @author Gavin King
  * @author Steve Ebersole
  * @author Hardy Ferentschik
  */
 public class DTDEntityResolver implements EntityResolver, Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, DTDEntityResolver.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DTDEntityResolver.class.getName());
 
 	private static final String HIBERNATE_NAMESPACE = "http://www.hibernate.org/dtd/";
 	private static final String OLD_HIBERNATE_NAMESPACE = "http://hibernate.sourceforge.net/";
 	private static final String USER_NAMESPACE = "classpath://";
 
 	public InputSource resolveEntity(String publicId, String systemId) {
 		InputSource source = null; // returning null triggers default behavior
 		if ( systemId != null ) {
             LOG.debugf("Trying to resolve system-id [%s]", systemId);
 			if ( systemId.startsWith( HIBERNATE_NAMESPACE ) ) {
                 LOG.debugf("Recognized hibernate namespace; attempting to resolve on classpath under org/hibernate/");
 				source = resolveOnClassPath( publicId, systemId, HIBERNATE_NAMESPACE );
 			}
 			else if ( systemId.startsWith( OLD_HIBERNATE_NAMESPACE ) ) {
                 LOG.recognizedObsoleteHibernateNamespace(OLD_HIBERNATE_NAMESPACE, HIBERNATE_NAMESPACE);
                 LOG.debugf("Attempting to resolve on classpath under org/hibernate/");
 				source = resolveOnClassPath( publicId, systemId, OLD_HIBERNATE_NAMESPACE );
 			}
 			else if ( systemId.startsWith( USER_NAMESPACE ) ) {
                 LOG.debugf("Recognized local namespace; attempting to resolve on classpath");
 				String path = systemId.substring( USER_NAMESPACE.length() );
 				InputStream stream = resolveInLocalNamespace( path );
                 if (stream == null) LOG.debugf("Unable to locate [%s] on classpath", systemId);
 				else {
                     LOG.debugf("Located [%s] in classpath", systemId);
 					source = new InputSource( stream );
 					source.setPublicId( publicId );
 					source.setSystemId( systemId );
 				}
 			}
 		}
 		return source;
 	}
 
 	private InputSource resolveOnClassPath(String publicId, String systemId, String namespace) {
 		InputSource source = null;
 		String path = "org/hibernate/" + systemId.substring( namespace.length() );
 		InputStream dtdStream = resolveInHibernateNamespace( path );
 		if ( dtdStream == null ) {
             LOG.debugf("Unable to locate [%s] on classpath", systemId);
             if (systemId.substring(namespace.length()).indexOf("2.0") > -1) LOG.usingOldDtd();
 		}
 		else {
             LOG.debugf("Located [%s] in classpath", systemId);
 			source = new InputSource( dtdStream );
 			source.setPublicId( publicId );
 			source.setSystemId( systemId );
 		}
 		return source;
 	}
 
 	protected InputStream resolveInHibernateNamespace(String path) {
 		return this.getClass().getClassLoader().getResourceAsStream( path );
 	}
 
 	protected InputStream resolveInLocalNamespace(String path) {
 		try {
 			return ConfigHelper.getUserResourceAsStream( path );
 		}
 		catch ( Throwable t ) {
 			return null;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/ErrorLogger.java b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/ErrorLogger.java
index 63d2de5d7d..c3272d28f9 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/ErrorLogger.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/ErrorLogger.java
@@ -1,78 +1,80 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.xml;
 
 import java.io.Serializable;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 import org.xml.sax.ErrorHandler;
 import org.xml.sax.SAXParseException;
 
 /**
  * Implements an {@link ErrorHandler} that mainly just logs errors/warnings.  However, it does track
  * the intial error it encounters and makes it available via {@link #getError}.
  *
  * @author Steve Ebersole
  */
 public class ErrorLogger implements ErrorHandler, Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ErrorLogger.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ErrorLogger.class.getName());
 
 	private SAXParseException error; // capture the initial error
 
 	/**
 	 * Retrieve the initial error encountered, or null if no error was encountered.
 	 *
 	 * @return The initial error, or null if none.
 	 */
 	public SAXParseException getError() {
 		return error;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void error(SAXParseException error) {
         LOG.parsingXmlError(error.getLineNumber(), error.getMessage());
         if (this.error == null) this.error = error;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void fatalError(SAXParseException error) {
 		error( error );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void warning(SAXParseException warn) {
         LOG.parsingXmlWarning(error.getLineNumber(), error.getMessage());
 	}
 
 	public void reset() {
 		error = null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/MappingReader.java b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/MappingReader.java
index b57c96ccb3..ce7b278c43 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/MappingReader.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/MappingReader.java
@@ -1,256 +1,258 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.xml;
 
 import java.io.StringReader;
 import org.dom4j.Document;
 import org.dom4j.io.SAXReader;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.InvalidMappingException;
+
 import org.jboss.logging.Logger;
 import org.xml.sax.EntityResolver;
 import org.xml.sax.InputSource;
 import org.xml.sax.SAXException;
 
 /**
  * Handles reading mapping documents, both {@code hbm} and {@code orm} varieties.
  *
  * @author Steve Ebersole
  */
 public class MappingReader {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, MappingReader.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, MappingReader.class.getName());
 
 	public static final String ASSUMED_ORM_XSD_VERSION = "2.0";
 	public static final MappingReader INSTANCE = new MappingReader();
 
 	/**
 	 * Disallow direct instantiation.
 	 * <p/>
 	 * Eventually we perhaps need to have this configurable by the "configuration" and simply reference it
 	 * from there (registry).  This would allow, for example, injection of the entity resolver to use as
 	 * instance state.
 	 */
 	private MappingReader() {
 	}
 
 	public XmlDocument readMappingDocument(EntityResolver entityResolver, InputSource source, Origin origin) {
 		// IMPL NOTE : this is the legacy logic as pulled from the old AnnotationConfiguration code
 
 		Exception failure;
 		ErrorLogger errorHandler = new ErrorLogger();
 
 		SAXReader saxReader = new SAXReader();
 		saxReader.setEntityResolver( entityResolver );
 		saxReader.setErrorHandler( errorHandler );
 		saxReader.setMergeAdjacentText( true );
 		saxReader.setValidation( true );
 
 		Document document = null;
 		try {
 			// first try with orm 2.0 xsd validation
 			setValidationFor( saxReader, "orm_2_0.xsd" );
 			document = saxReader.read( source );
 			if ( errorHandler.getError() != null ) {
 				throw errorHandler.getError();
 			}
 			return new XmlDocumentImpl( document, origin.getType(), origin.getName() );
 		}
 		catch ( Exception orm2Problem ) {
             LOG.debugf("Problem parsing XML using orm 2 xsd : %s", orm2Problem.getMessage());
 			failure = orm2Problem;
 			errorHandler.reset();
 
 			if ( document != null ) {
 				// next try with orm 1.0 xsd validation
 				try {
 					setValidationFor( saxReader, "orm_1_0.xsd" );
 					document = saxReader.read(  new StringReader( document.asXML() ) );
 					if ( errorHandler.getError() != null ) {
 						throw errorHandler.getError();
 					}
 					return new XmlDocumentImpl( document, origin.getType(), origin.getName() );
 				}
 				catch ( Exception orm1Problem ) {
                     LOG.debugf("Problem parsing XML using orm 1 xsd : %s", orm1Problem.getMessage());
 				}
 			}
 		}
 		throw new InvalidMappingException( "Unable to read XML", origin.getType(), origin.getName(), failure );
 	}
 
 	private void setValidationFor(SAXReader saxReader, String xsd) {
 		try {
 			saxReader.setFeature( "http://apache.org/xml/features/validation/schema", true );
 			//saxReader.setFeature( "http://apache.org/xml/features/validation/dynamic", true );
 			//set the default schema locators
 			saxReader.setProperty(
 					"http://apache.org/xml/properties/schema/external-schemaLocation",
 					"http://java.sun.com/xml/ns/persistence/orm " + xsd
 			);
 		}
 		catch ( SAXException e ) {
 			saxReader.setValidation( false );
 		}
 	}
 
 	// this is the version of the code I'd like to use, but it unfortunately works very differently between
 	// JDK 1.5 ad JDK 1.6.  On 1.5 the vaildation "passes" even with invalid content.
 	//
 	// Options:
 	// 		1) continue using the code above
 	//		2) Document the issue on 1.5 and how to fix (specifying alternate SchemaFactory instance)
 	//		3) Use a specific JAXP library (Xerces2, Saxon, Jing, MSV) and its SchemaFactory instance directly
 
 //	public XmlDocument readMappingDocument(EntityResolver entityResolver, InputSource source, Origin origin) {
 //		ErrorLogger errorHandler = new ErrorLogger();
 //
 //		SAXReader saxReader = new SAXReader( new DOMDocumentFactory() );
 //		saxReader.setEntityResolver( entityResolver );
 //		saxReader.setErrorHandler( errorHandler );
 //		saxReader.setMergeAdjacentText( true );
 //
 //		Document documentTree = null;
 //
 //		// IMPL NOTE : here we enable DTD validation in case the mapping is a HBM file.  This will validate
 //		// the document as it is parsed.  This is needed because the DTD defines default values that have to be
 //		// applied as the document is parsed, so thats something we need to account for as we (if we) transition
 //		// to XSD.
 //		saxReader.setValidation( true );
 //		try {
 //			documentTree = saxReader.read( source );
 //		}
 //		catch ( DocumentException e ) {
 //			// we had issues reading the input, most likely malformed document or validation error against DTD
 //			throw new InvalidMappingException( "Unable to read XML", origin.getType(), origin.getName(), e );
 //		}
 //
 //		Element rootElement = documentTree.getRootElement();
 //		if ( rootElement ==  null ) {
 //			throw new InvalidMappingException( "No root element", origin.getType(), origin.getName() );
 //		}
 //
 //		if ( "entity-mappings".equals( rootElement.getName() ) ) {
 //			final String explicitVersion = rootElement.attributeValue( "version" );
 //			final String xsdVersionString = explicitVersion == null ? ASSUMED_ORM_XSD_VERSION : explicitVersion;
 //			final SupportedOrmXsdVersion xsdVersion = SupportedOrmXsdVersion.parse( xsdVersionString );
 //			final Schema schema = xsdVersion == SupportedOrmXsdVersion.ORM_1_0 ? orm1Schema() : orm2Schema();
 //			try {
 //				schema.newValidator().validate( new DOMSource( (org.w3c.dom.Document) documentTree ) );
 //			}
 //			catch ( SAXException e ) {
 //				throw new InvalidMappingException( "Validation problem", origin.getType(), origin.getName(), e );
 //			}
 //			catch ( IOException e ) {
 //				throw new InvalidMappingException( "Validation problem", origin.getType(), origin.getName(), e );
 //			}
 //		}
 //		else {
 //			if ( errorHandler.getError() != null ) {
 //				throw new InvalidMappingException(
 //						"Error validating hibernate-mapping against DTD",
 //						origin.getType(),
 //						origin.getName(),
 //						errorHandler.getError()
 //				);
 //			}
 //		}
 //
 //		return new XmlDocumentImpl( documentTree, origin );
 //	}
 //
 //	public static enum SupportedOrmXsdVersion {
 //		ORM_1_0,
 //		ORM_2_0;
 //
 //		public static SupportedOrmXsdVersion parse(String name) {
 //			if ( "1.0".equals( name ) ) {
 //				return ORM_1_0;
 //			}
 //			else if ( "2.0".equals( name ) ) {
 //				return ORM_2_0;
 //			}
 //			throw new IllegalArgumentException( "Unsupported orm.xml XSD version encountered [" + name + "]" );
 //		}
 //	}
 //
 //
 //	public static final String ORM_1_SCHEMA_NAME = "org/hibernate/ejb/orm_1_0.xsd";
 //	public static final String ORM_2_SCHEMA_NAME = "org/hibernate/ejb/orm_2_0.xsd";
 //
 //	private static Schema orm1Schema;
 //
 //	private static Schema orm1Schema() {
 //		if ( orm1Schema == null ) {
 //			orm1Schema = resolveLocalSchema( ORM_1_SCHEMA_NAME );
 //		}
 //		return orm1Schema;
 //	}
 //
 //	private static Schema orm2Schema;
 //
 //	private static Schema orm2Schema() {
 //		if ( orm2Schema == null ) {
 //			orm2Schema = resolveLocalSchema( ORM_2_SCHEMA_NAME );
 //		}
 //		return orm2Schema;
 //	}
 //
 //	private static Schema resolveLocalSchema(String schemaName) {
 //		return resolveLocalSchema( schemaName, XMLConstants.W3C_XML_SCHEMA_NS_URI );
 //	}
 //
 //	private static Schema resolveLocalSchema(String schemaName, String schemaLanguage) {
 //        URL url = ConfigHelper.findAsResource( schemaName );
 //		if ( url == null ) {
 //			throw new MappingException( "Unable to locate schema [" + schemaName + "] via classpath" );
 //		}
 //		try {
 //			InputStream schemaStream = url.openStream();
 //			try {
 //				StreamSource source = new StreamSource(url.openStream());
 //				SchemaFactory schemaFactory = SchemaFactory.newInstance( schemaLanguage );
 //				return schemaFactory.newSchema(source);
 //			}
 //			catch ( SAXException e ) {
 //				throw new MappingException( "Unable to load schema [" + schemaName + "]", e );
 //			}
 //			catch ( IOException e ) {
 //				throw new MappingException( "Unable to load schema [" + schemaName + "]", e );
 //			}
 //			finally {
 //				try {
 //					schemaStream.close();
 //				}
 //				catch ( IOException e ) {
 //					log.warn( "Problem closing schema stream [{}]", e.toString() );
 //				}
 //			}
 //		}
 //		catch ( IOException e ) {
 //			throw new MappingException( "Stream error handling schema url [" + url.toExternalForm() + "]" );
 //		}
 //
 //	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/XMLHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/XMLHelper.java
index a24e97e541..5272251545 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/XMLHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/XMLHelper.java
@@ -1,119 +1,121 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.xml;
 
 import java.util.List;
 import org.dom4j.DocumentFactory;
 import org.dom4j.Element;
 import org.dom4j.io.DOMReader;
 import org.dom4j.io.OutputFormat;
 import org.dom4j.io.SAXReader;
 import org.dom4j.io.XMLWriter;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 import org.xml.sax.EntityResolver;
 import org.xml.sax.ErrorHandler;
 import org.xml.sax.SAXParseException;
 
 
 /**
  * Small helper class that lazy loads DOM and SAX reader and keep them for fast use afterwards.
  */
 public final class XMLHelper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, XMLHelper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, XMLHelper.class.getName());
 
 	public static final EntityResolver DEFAULT_DTD_RESOLVER = new DTDEntityResolver();
 
 	private DOMReader domReader;
 	private SAXReader saxReader;
 
 	/**
 	 * Create a dom4j SAXReader which will append all validation errors
 	 * to errorList
 	 */
 	public SAXReader createSAXReader(String file, List errorsList, EntityResolver entityResolver) {
 		SAXReader saxReader = resolveSAXReader();
 		saxReader.setEntityResolver(entityResolver);
 		saxReader.setErrorHandler( new ErrorLogger(file, errorsList) );
 		return saxReader;
 	}
 
 	private SAXReader resolveSAXReader() {
 		if ( saxReader == null ) {
 			saxReader = new SAXReader();
 			saxReader.setMergeAdjacentText(true);
 			saxReader.setValidation(true);
 		}
 		return saxReader;
 	}
 
 	/**
 	 * Create a dom4j DOMReader
 	 */
 	public DOMReader createDOMReader() {
 		if (domReader==null) domReader = new DOMReader();
 		return domReader;
 	}
 
 	public static class ErrorLogger implements ErrorHandler {
 		private String file;
 		private List<SAXParseException> errors;
 
 		private ErrorLogger(String file, List errors) {
 			this.file=file;
 			this.errors = errors;
 		}
 		public void error(SAXParseException error) {
             LOG.parsingXmlErrorForFile(file, error.getLineNumber(), error.getMessage());
 			errors.add(error);
 		}
 		public void fatalError(SAXParseException error) {
 			error(error);
 		}
 		public void warning(SAXParseException warn) {
             LOG.parsingXmlWarningForFile(file, warn.getLineNumber(), warn.getMessage());
 		}
 	}
 
 	public static Element generateDom4jElement(String elementName) {
 		return DocumentFactory.getInstance().createElement( elementName );
 	}
 
 	public static void dump(Element element) {
 		try {
 			// try to "pretty print" it
 			OutputFormat outformat = OutputFormat.createPrettyPrint();
 			XMLWriter writer = new XMLWriter( System.out, outformat );
 			writer.write( element );
 			writer.flush();
 			System.out.println( "" );
 		}
 		catch( Throwable t ) {
 			// otherwise, just dump it
 			System.out.println( element.asXML() );
 		}
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java b/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
index 23dea5a0a9..0bc98e63b0 100644
--- a/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
+++ b/hibernate-core/src/main/java/org/hibernate/jdbc/Expectations.java
@@ -1,193 +1,194 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.jdbc;
-
-import java.sql.CallableStatement;
-import java.sql.PreparedStatement;
-import java.sql.SQLException;
-import java.sql.Types;
-import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.StaleStateException;
-import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
-import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
-import org.hibernate.exception.GenericJDBCException;
-import org.jboss.logging.Logger;
-
-/**
- * Holds various often used {@link Expectation} definitions.
- *
- * @author Steve Ebersole
- */
-public class Expectations {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Expectations.class.getName());
-	private static SqlExceptionHelper sqlExceptionHelper = new SqlExceptionHelper();
-
-	public static final int USUAL_EXPECTED_COUNT = 1;
-	public static final int USUAL_PARAM_POSITION = 1;
-
-
-	// Base Expectation impls ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-	public static class BasicExpectation implements Expectation {
-		private final int expectedRowCount;
-
-		protected BasicExpectation(int expectedRowCount) {
-			this.expectedRowCount = expectedRowCount;
-			if ( expectedRowCount < 0 ) {
-				throw new IllegalArgumentException( "Expected row count must be greater than zero" );
-			}
-		}
-
-		public final void verifyOutcome(int rowCount, PreparedStatement statement, int batchPosition) {
-			rowCount = determineRowCount( rowCount, statement );
-			if ( batchPosition < 0 ) {
-				checkNonBatched( rowCount );
-			}
-			else {
-				checkBatched( rowCount, batchPosition );
-			}
-		}
-
-		private void checkBatched(int rowCount, int batchPosition) {
-            if (rowCount == -2) LOG.debugf("Success of batch update unknown: %s", batchPosition);
-            else if (rowCount == -3) throw new BatchFailedException("Batch update failed: " + batchPosition);
-			else {
-                if (expectedRowCount > rowCount) throw new StaleStateException(
-                                                                               "Batch update returned unexpected row count from update ["
-                                                                               + batchPosition + "]; actual row count: " + rowCount
-                                                                               + "; expected: " + expectedRowCount);
-				if ( expectedRowCount < rowCount ) {
-					String msg = "Batch update returned unexpected row count from update [" +
-					             batchPosition + "]; actual row count: " + rowCount +
-					             "; expected: " + expectedRowCount;
-					throw new BatchedTooManyRowsAffectedException( msg, expectedRowCount, rowCount, batchPosition );
-				}
-			}
-		}
-
-		private void checkNonBatched(int rowCount) {
-			if ( expectedRowCount > rowCount ) {
-				throw new StaleStateException(
-						"Unexpected row count: " + rowCount + "; expected: " + expectedRowCount
-				);
-			}
-			if ( expectedRowCount < rowCount ) {
-				String msg = "Unexpected row count: " + rowCount + "; expected: " + expectedRowCount;
-				throw new TooManyRowsAffectedException( msg, expectedRowCount, rowCount );
-			}
-		}
-
-		public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
-			return 0;
-		}
-
-		public boolean canBeBatched() {
-			return true;
-		}
-
-		protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
-			return reportedRowCount;
-		}
-	}
-
-	public static class BasicParamExpectation extends BasicExpectation {
-		private final int parameterPosition;
-		protected BasicParamExpectation(int expectedRowCount, int parameterPosition) {
-			super( expectedRowCount );
-			this.parameterPosition = parameterPosition;
-		}
-
-		@Override
-        public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
-			toCallableStatement( statement ).registerOutParameter( parameterPosition, Types.NUMERIC );
-			return 1;
-		}
-
-		@Override
-        public boolean canBeBatched() {
-			return false;
-		}
-
-		@Override
-        protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
-			try {
-				return toCallableStatement( statement ).getInt( parameterPosition );
-			}
-			catch( SQLException sqle ) {
-				sqlExceptionHelper.logExceptions( sqle, "could not extract row counts from CallableStatement" );
-				throw new GenericJDBCException( "could not extract row counts from CallableStatement", sqle );
-			}
-		}
-
-		private CallableStatement toCallableStatement(PreparedStatement statement) {
-			if ( ! CallableStatement.class.isInstance( statement ) ) {
-				throw new HibernateException( "BasicParamExpectation operates exclusively on CallableStatements : " + statement.getClass() );
-			}
-			return ( CallableStatement ) statement;
-		}
-	}
-
-
-	// Various Expectation instances ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-	public static final Expectation NONE = new Expectation() {
-		public void verifyOutcome(int rowCount, PreparedStatement statement, int batchPosition) {
-			// explicitly doAfterTransactionCompletion no checking...
-		}
-
-		public int prepare(PreparedStatement statement) {
-			return 0;
-		}
-
-		public boolean canBeBatched() {
-			return true;
-		}
-	};
-
-	public static final Expectation BASIC = new BasicExpectation( USUAL_EXPECTED_COUNT );
-
-	public static final Expectation PARAM = new BasicParamExpectation( USUAL_EXPECTED_COUNT, USUAL_PARAM_POSITION );
-
-
-	public static Expectation appropriateExpectation(ExecuteUpdateResultCheckStyle style) {
-		if ( style == ExecuteUpdateResultCheckStyle.NONE ) {
-			return NONE;
-		}
-		else if ( style == ExecuteUpdateResultCheckStyle.COUNT ) {
-			return BASIC;
-		}
-		else if ( style == ExecuteUpdateResultCheckStyle.PARAM ) {
-			return PARAM;
-		}
-		else {
-			throw new HibernateException( "unknown check style : " + style );
-		}
-	}
-
-	private Expectations() {
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ *
+ */
+package org.hibernate.jdbc;
+
+import java.sql.CallableStatement;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.sql.Types;
+import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.StaleStateException;
+import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
+import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
+import org.hibernate.exception.GenericJDBCException;
+
+import org.jboss.logging.Logger;
+
+/**
+ * Holds various often used {@link Expectation} definitions.
+ *
+ * @author Steve Ebersole
+ */
+public class Expectations {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Expectations.class.getName());
+	private static SqlExceptionHelper sqlExceptionHelper = new SqlExceptionHelper();
+
+	public static final int USUAL_EXPECTED_COUNT = 1;
+	public static final int USUAL_PARAM_POSITION = 1;
+
+
+	// Base Expectation impls ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	public static class BasicExpectation implements Expectation {
+		private final int expectedRowCount;
+
+		protected BasicExpectation(int expectedRowCount) {
+			this.expectedRowCount = expectedRowCount;
+			if ( expectedRowCount < 0 ) {
+				throw new IllegalArgumentException( "Expected row count must be greater than zero" );
+			}
+		}
+
+		public final void verifyOutcome(int rowCount, PreparedStatement statement, int batchPosition) {
+			rowCount = determineRowCount( rowCount, statement );
+			if ( batchPosition < 0 ) {
+				checkNonBatched( rowCount );
+			}
+			else {
+				checkBatched( rowCount, batchPosition );
+			}
+		}
+
+		private void checkBatched(int rowCount, int batchPosition) {
+            if (rowCount == -2) LOG.debugf("Success of batch update unknown: %s", batchPosition);
+            else if (rowCount == -3) throw new BatchFailedException("Batch update failed: " + batchPosition);
+			else {
+                if (expectedRowCount > rowCount) throw new StaleStateException(
+                                                                               "Batch update returned unexpected row count from update ["
+                                                                               + batchPosition + "]; actual row count: " + rowCount
+                                                                               + "; expected: " + expectedRowCount);
+				if ( expectedRowCount < rowCount ) {
+					String msg = "Batch update returned unexpected row count from update [" +
+					             batchPosition + "]; actual row count: " + rowCount +
+					             "; expected: " + expectedRowCount;
+					throw new BatchedTooManyRowsAffectedException( msg, expectedRowCount, rowCount, batchPosition );
+				}
+			}
+		}
+
+		private void checkNonBatched(int rowCount) {
+			if ( expectedRowCount > rowCount ) {
+				throw new StaleStateException(
+						"Unexpected row count: " + rowCount + "; expected: " + expectedRowCount
+				);
+			}
+			if ( expectedRowCount < rowCount ) {
+				String msg = "Unexpected row count: " + rowCount + "; expected: " + expectedRowCount;
+				throw new TooManyRowsAffectedException( msg, expectedRowCount, rowCount );
+			}
+		}
+
+		public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
+			return 0;
+		}
+
+		public boolean canBeBatched() {
+			return true;
+		}
+
+		protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
+			return reportedRowCount;
+		}
+	}
+
+	public static class BasicParamExpectation extends BasicExpectation {
+		private final int parameterPosition;
+		protected BasicParamExpectation(int expectedRowCount, int parameterPosition) {
+			super( expectedRowCount );
+			this.parameterPosition = parameterPosition;
+		}
+
+		@Override
+        public int prepare(PreparedStatement statement) throws SQLException, HibernateException {
+			toCallableStatement( statement ).registerOutParameter( parameterPosition, Types.NUMERIC );
+			return 1;
+		}
+
+		@Override
+        public boolean canBeBatched() {
+			return false;
+		}
+
+		@Override
+        protected int determineRowCount(int reportedRowCount, PreparedStatement statement) {
+			try {
+				return toCallableStatement( statement ).getInt( parameterPosition );
+			}
+			catch( SQLException sqle ) {
+				sqlExceptionHelper.logExceptions( sqle, "could not extract row counts from CallableStatement" );
+				throw new GenericJDBCException( "could not extract row counts from CallableStatement", sqle );
+			}
+		}
+
+		private CallableStatement toCallableStatement(PreparedStatement statement) {
+			if ( ! CallableStatement.class.isInstance( statement ) ) {
+				throw new HibernateException( "BasicParamExpectation operates exclusively on CallableStatements : " + statement.getClass() );
+			}
+			return ( CallableStatement ) statement;
+		}
+	}
+
+
+	// Various Expectation instances ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	public static final Expectation NONE = new Expectation() {
+		public void verifyOutcome(int rowCount, PreparedStatement statement, int batchPosition) {
+			// explicitly doAfterTransactionCompletion no checking...
+		}
+
+		public int prepare(PreparedStatement statement) {
+			return 0;
+		}
+
+		public boolean canBeBatched() {
+			return true;
+		}
+	};
+
+	public static final Expectation BASIC = new BasicExpectation( USUAL_EXPECTED_COUNT );
+
+	public static final Expectation PARAM = new BasicParamExpectation( USUAL_EXPECTED_COUNT, USUAL_PARAM_POSITION );
+
+
+	public static Expectation appropriateExpectation(ExecuteUpdateResultCheckStyle style) {
+		if ( style == ExecuteUpdateResultCheckStyle.NONE ) {
+			return NONE;
+		}
+		else if ( style == ExecuteUpdateResultCheckStyle.COUNT ) {
+			return BASIC;
+		}
+		else if ( style == ExecuteUpdateResultCheckStyle.PARAM ) {
+			return PARAM;
+		}
+		else {
+			throw new HibernateException( "unknown check style : " + style );
+		}
+	}
+
+	private Expectations() {
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/jmx/HibernateService.java b/hibernate-core/src/main/java/org/hibernate/jmx/HibernateService.java
index 5e787168aa..9d4a46b4b5 100644
--- a/hibernate-core/src/main/java/org/hibernate/jmx/HibernateService.java
+++ b/hibernate-core/src/main/java/org/hibernate/jmx/HibernateService.java
@@ -1,194 +1,194 @@
 //$Id: HibernateService.java 6100 2005-03-17 10:48:03Z turin42 $
 package org.hibernate.jmx;
 
 import java.util.Map;
 import java.util.Properties;
 import javax.naming.InitialContext;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.ExternalSessionFactoryConfig;
 import org.hibernate.internal.util.jndi.JndiHelper;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 import org.hibernate.service.jta.platform.internal.JtaPlatformInitiator;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.jboss.logging.Logger;
 
 
 /**
  * Implementation of <tt>HibernateServiceMBean</tt>. Creates a
  * <tt>SessionFactory</tt> and binds it to the specified JNDI name.<br>
  * <br>
  * All mapping documents are loaded as resources by the MBean.
  * @see HibernateServiceMBean
  * @see org.hibernate.SessionFactory
  * @author John Urberg, Gavin King
  */
 public class HibernateService extends ExternalSessionFactoryConfig implements HibernateServiceMBean {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, HibernateService.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HibernateService.class.getName());
 
 	private String boundName;
 	private Properties properties = new Properties();
 
 	@Override
 	public void start() throws HibernateException {
 		boundName = getJndiName();
 		try {
 			buildSessionFactory();
 		}
 		catch (HibernateException he) {
             LOG.unableToBuildSessionFactoryUsingMBeanClasspath(he.getMessage());
             LOG.debug("Error was", he);
 			new SessionFactoryStub(this);
 		}
 	}
 
 	@Override
 	public void stop() {
         LOG.stoppingService();
 		try {
 			InitialContext context = JndiHelper.getInitialContext( buildProperties() );
 			( (SessionFactory) context.lookup(boundName) ).close();
 			//context.unbind(boundName);
 		}
 		catch (Exception e) {
             LOG.unableToStopHibernateService(e);
 		}
 	}
 
 	SessionFactory buildSessionFactory() throws HibernateException {
         LOG.startingServiceAtJndiName(boundName);
         LOG.serviceProperties(properties);
         return buildConfiguration().buildSessionFactory(new BasicServiceRegistryImpl(properties));
 	}
 
 	@Override
 	protected Map getExtraProperties() {
 		return properties;
 	}
 
 	@Override
 	public String getTransactionStrategy() {
 		return getProperty(Environment.TRANSACTION_STRATEGY);
 	}
 
 	@Override
 	public void setTransactionStrategy(String txnStrategy) {
 		setProperty(Environment.TRANSACTION_STRATEGY, txnStrategy);
 	}
 
 	@Override
 	public String getUserTransactionName() {
 		return getProperty(Environment.USER_TRANSACTION);
 	}
 
 	@Override
 	public void setUserTransactionName(String utName) {
 		setProperty(Environment.USER_TRANSACTION, utName);
 	}
 
 	@Override
 	public String getJtaPlatformName() {
 		return getProperty( JtaPlatformInitiator.JTA_PLATFORM );
 	}
 
 	@Override
 	public void setJtaPlatformName(String name) {
 		setProperty( JtaPlatformInitiator.JTA_PLATFORM, name );
 	}
 
 	@Override
 	public String getPropertyList() {
 		return buildProperties().toString();
 	}
 
 	@Override
 	public String getProperty(String property) {
 		return properties.getProperty(property);
 	}
 
 	@Override
 	public void setProperty(String property, String value) {
 		properties.setProperty(property, value);
 	}
 
 	@Override
 	public void dropSchema() {
 		new SchemaExport( buildConfiguration() ).drop(false, true);
 	}
 
 	@Override
 	public void createSchema() {
 		new SchemaExport( buildConfiguration() ).create(false, true);
 	}
 
 	public String getName() {
 		return getProperty(Environment.SESSION_FACTORY_NAME);
 	}
 
 	@Override
 	public String getDatasource() {
 		return getProperty(Environment.DATASOURCE);
 	}
 
 	@Override
 	public void setDatasource(String datasource) {
 		setProperty(Environment.DATASOURCE, datasource);
 	}
 
 	@Override
 	public String getJndiName() {
 		return getProperty(Environment.SESSION_FACTORY_NAME);
 	}
 
 	@Override
 	public void setJndiName(String jndiName) {
 		setProperty(Environment.SESSION_FACTORY_NAME, jndiName);
 	}
 
 	@Override
 	public String getUserName() {
 		return getProperty(Environment.USER);
 	}
 
 	@Override
 	public void setUserName(String userName) {
 		setProperty(Environment.USER, userName);
 	}
 
 	@Override
 	public String getPassword() {
 		return getProperty(Environment.PASS);
 	}
 
 	@Override
 	public void setPassword(String password) {
 		setProperty(Environment.PASS, password);
 	}
 
 	@Override
 	public void setFlushBeforeCompletionEnabled(String enabled) {
 		setProperty(Environment.FLUSH_BEFORE_COMPLETION, enabled);
 	}
 
 	@Override
 	public String getFlushBeforeCompletionEnabled() {
 		return getProperty(Environment.FLUSH_BEFORE_COMPLETION);
 	}
 
 	@Override
 	public void setAutoCloseSessionEnabled(String enabled) {
 		setProperty(Environment.AUTO_CLOSE_SESSION, enabled);
 	}
 
 	@Override
 	public String getAutoCloseSessionEnabled() {
 		return getProperty(Environment.AUTO_CLOSE_SESSION);
 	}
 
 	public Properties getProperties() {
 		return buildProperties();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/jmx/SessionFactoryStub.java b/hibernate-core/src/main/java/org/hibernate/jmx/SessionFactoryStub.java
index da7096246e..397725521e 100644
--- a/hibernate-core/src/main/java/org/hibernate/jmx/SessionFactoryStub.java
+++ b/hibernate-core/src/main/java/org/hibernate/jmx/SessionFactoryStub.java
@@ -1,223 +1,223 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jmx;
 
 import javax.naming.NamingException;
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import java.io.InvalidObjectException;
 import java.io.ObjectStreamException;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionFactory;
 import org.hibernate.StatelessSession;
 import org.hibernate.TypeHelper;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.impl.SessionFactoryObjectFactory;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.stat.Statistics;
 
 /**
  * A flyweight for <tt>SessionFactory</tt>. If the MBean itself does not
  * have classpath to the persistent classes, then a stub will be registered
  * with JNDI and the actual <tt>SessionFactoryImpl</tt> built upon first
  * access.
  * @author Gavin King
  */
 public class SessionFactoryStub implements SessionFactory {
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SessionFactoryStub.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionFactoryStub.class.getName());
 
 	private transient SessionFactory impl;
 	private transient HibernateService service;
 	private String uuid;
 	private String name;
 
 	SessionFactoryStub(HibernateService service) {
 		this.service = service;
 		this.name = service.getJndiName();
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 
 		SessionFactoryObjectFactory.addInstance( uuid, name, this, service.getProperties() );
 	}
 
 	@Override
 	public SessionBuilder withOptions() {
 		return getImpl().withOptions();
 	}
 
 	public Session openSession() throws HibernateException {
 		return getImpl().openSession();
 	}
 
 	public Session getCurrentSession() {
 		return getImpl().getCurrentSession();
 	}
 
 	private synchronized SessionFactory getImpl() {
 		if (impl==null) impl = service.buildSessionFactory();
 		return impl;
 	}
 
 	//readResolveObject
 	private Object readResolve() throws ObjectStreamException {
 		// look for the instance by uuid
 		Object result = SessionFactoryObjectFactory.getInstance(uuid);
 		if (result==null) {
             // in case we were deserialized in a different JVM, look for an instance with the same name
 			// (alternatively we could do an actual JNDI lookup here....)
 			result = SessionFactoryObjectFactory.getNamedInstance(name);
             if (result == null) throw new InvalidObjectException("Could not find a stub SessionFactory named: " + name);
             LOG.debugf("Resolved stub SessionFactory by name");
         } else LOG.debugf("Resolved stub SessionFactory by uid");
 		return result;
 	}
 
 	/**
 	 * @see javax.naming.Referenceable#getReference()
 	 */
 	public Reference getReference() throws NamingException {
 		return new Reference(
 			SessionFactoryStub.class.getName(),
 			new StringRefAddr("uuid", uuid),
 			SessionFactoryObjectFactory.class.getName(),
 			null
 		);
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getImpl().getClassMetadata(persistentClass);
 	}
 
 	public ClassMetadata getClassMetadata(String entityName)
 	throws HibernateException {
 		return getImpl().getClassMetadata(entityName);
 	}
 
 	public CollectionMetadata getCollectionMetadata(String roleName) throws HibernateException {
 		return getImpl().getCollectionMetadata(roleName);
 	}
 
 	public Map<String,ClassMetadata> getAllClassMetadata() throws HibernateException {
 		return getImpl().getAllClassMetadata();
 	}
 
 	public Map getAllCollectionMetadata() throws HibernateException {
 		return getImpl().getAllCollectionMetadata();
 	}
 
 	public void close() throws HibernateException {
 	}
 
 	public boolean isClosed() {
 		return false;
 	}
 
 	public Cache getCache() {
 		return getImpl().getCache();
 	}
 
 	public void evict(Class persistentClass, Serializable id)
 		throws HibernateException {
 		getImpl().evict(persistentClass, id);
 	}
 
 	public void evict(Class persistentClass) throws HibernateException {
 		getImpl().evict(persistentClass);
 	}
 
 	public void evictEntity(String entityName, Serializable id)
 	throws HibernateException {
 		getImpl().evictEntity(entityName, id);
 	}
 
 	public void evictEntity(String entityName) throws HibernateException {
 		getImpl().evictEntity(entityName);
 	}
 
 	public void evictCollection(String roleName, Serializable id)
 		throws HibernateException {
 		getImpl().evictCollection(roleName, id);
 	}
 
 	public void evictCollection(String roleName) throws HibernateException {
 		getImpl().evictCollection(roleName);
 	}
 
 	public void evictQueries() throws HibernateException {
 		getImpl().evictQueries();
 	}
 
 	public void evictQueries(String cacheRegion) throws HibernateException {
 		getImpl().evictQueries(cacheRegion);
 	}
 
 	public Statistics getStatistics() {
 		return getImpl().getStatistics();
 	}
 
 	public StatelessSession openStatelessSession() {
 		return getImpl().openStatelessSession();
 	}
 
 	public StatelessSession openStatelessSession(Connection conn) {
 		return getImpl().openStatelessSession(conn);
 	}
 
 	public Set getDefinedFilterNames() {
 		return getImpl().getDefinedFilterNames();
 	}
 
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException {
 		return getImpl().getFilterDefinition( filterName );
 	}
 
 	public boolean containsFetchProfileDefinition(String name) {
 		return getImpl().containsFetchProfileDefinition( name );
 	}
 
 	public TypeHelper getTypeHelper() {
 		return getImpl().getTypeHelper();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/jmx/StatisticsService.java b/hibernate-core/src/main/java/org/hibernate/jmx/StatisticsService.java
index 106813fb1b..7626d58cb0 100644
--- a/hibernate-core/src/main/java/org/hibernate/jmx/StatisticsService.java
+++ b/hibernate-core/src/main/java/org/hibernate/jmx/StatisticsService.java
@@ -1,316 +1,317 @@
 //$Id: StatisticsService.java 8262 2005-09-30 07:48:53Z oneovthafew $
 package org.hibernate.jmx;
 import javax.naming.InitialContext;
 import javax.naming.NameNotFoundException;
 import javax.naming.NamingException;
 import javax.naming.Reference;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.SessionFactory;
 import org.hibernate.impl.SessionFactoryObjectFactory;
 import org.hibernate.stat.CollectionStatistics;
 import org.hibernate.stat.EntityStatistics;
 import org.hibernate.stat.QueryStatistics;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.internal.ConcurrentStatisticsImpl;
 
 import org.jboss.logging.Logger;
 
 /**
  * JMX service for Hibernate statistics<br>
  * <br>
  * Register this MBean in your JMX server for a specific session factory
  * <pre>
  * //build the ObjectName you want
  * Hashtable tb = new Hashtable();
  * tb.put("type", "statistics");
  * tb.put("sessionFactory", "myFinancialApp");
  * ObjectName on = new ObjectName("hibernate", tb);
  * StatisticsService stats = new StatisticsService();
  * stats.setSessionFactory(sessionFactory);
  * server.registerMBean(stats, on);
  * </pre>
  * And call the MBean the way you want<br>
  * <br>
  * Register this MBean in your JMX server with no specific session factory
  * <pre>
  * //build the ObjectName you want
  * Hashtable tb = new Hashtable();
  * tb.put("type", "statistics");
  * tb.put("sessionFactory", "myFinancialApp");
  * ObjectName on = new ObjectName("hibernate", tb);
  * StatisticsService stats = new StatisticsService();
  * server.registerMBean(stats, on);
  * </pre>
  * And call the MBean by providing the <code>SessionFactoryJNDIName</code> first.
  * Then the session factory will be retrieved from JNDI and the statistics
  * loaded.
  *
  * @author Emmanuel Bernard
  */
 public class StatisticsService implements StatisticsServiceMBean {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, StatisticsService.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, StatisticsService.class.getName());
 	//TODO: We probably should have a StatisticsNotPublishedException, to make it clean
 
 	SessionFactory sf;
 	String sfJNDIName;
 	Statistics stats = new ConcurrentStatisticsImpl();
 
 	/**
 	 * @see StatisticsServiceMBean#setSessionFactoryJNDIName(java.lang.String)
 	 */
 	public void setSessionFactoryJNDIName(String sfJNDIName) {
 		this.sfJNDIName = sfJNDIName;
 		try {
 			Object obj = new InitialContext().lookup(sfJNDIName);
 			if (obj instanceof Reference) {
 				Reference ref = (Reference) obj;
 				setSessionFactory( (SessionFactory) SessionFactoryObjectFactory.getInstance( (String) ref.get(0).getContent() ) );
 			}
 			else {
 				setSessionFactory( (SessionFactory) obj );
 			}
 		}
 		catch (NameNotFoundException e) {
             LOG.noSessionFactoryWithJndiName(sfJNDIName, e);
 			setSessionFactory(null);
 		}
 		catch (NamingException e) {
             LOG.unableToAccessSessionFactory(sfJNDIName, e);
 			setSessionFactory(null);
 		}
 		catch (ClassCastException e) {
             LOG.jndiNameDoesNotHandleSessionFactoryReference(sfJNDIName, e);
 			setSessionFactory(null);
 		}
 	}
 
 	/**
 	 * Useful to init this MBean wo a JNDI session factory name
 	 *
 	 * @param sf session factory to register
 	 */
 	public void setSessionFactory(SessionFactory sf) {
 		this.sf = sf;
 		if (sf == null) {
 			stats = new ConcurrentStatisticsImpl();
 		}
 		else {
 			stats = sf.getStatistics();
 		}
 
 	}
 	/**
 	 * @see StatisticsServiceMBean#clear()
 	 */
 	public void clear() {
 		stats.clear();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getEntityStatistics(java.lang.String)
 	 */
 	public EntityStatistics getEntityStatistics(String entityName) {
 		return stats.getEntityStatistics(entityName);
 	}
 	/**
 	 * @see StatisticsServiceMBean#getCollectionStatistics(java.lang.String)
 	 */
 	public CollectionStatistics getCollectionStatistics(String role) {
 		return stats.getCollectionStatistics(role);
 	}
 	/**
 	 * @see StatisticsServiceMBean#getSecondLevelCacheStatistics(java.lang.String)
 	 */
 	public SecondLevelCacheStatistics getSecondLevelCacheStatistics(String regionName) {
 		return stats.getSecondLevelCacheStatistics(regionName);
 	}
 	/**
 	 * @see StatisticsServiceMBean#getQueryStatistics(java.lang.String)
 	 */
 	public QueryStatistics getQueryStatistics(String hql) {
 		return stats.getQueryStatistics(hql);
 	}
 	/**
 	 * @see StatisticsServiceMBean#getEntityDeleteCount()
 	 */
 	public long getEntityDeleteCount() {
 		return stats.getEntityDeleteCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getEntityInsertCount()
 	 */
 	public long getEntityInsertCount() {
 		return stats.getEntityInsertCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getEntityLoadCount()
 	 */
 	public long getEntityLoadCount() {
 		return stats.getEntityLoadCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getEntityFetchCount()
 	 */
 	public long getEntityFetchCount() {
 		return stats.getEntityFetchCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getEntityUpdateCount()
 	 */
 	public long getEntityUpdateCount() {
 		return stats.getEntityUpdateCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getQueryExecutionCount()
 	 */
 	public long getQueryExecutionCount() {
 		return stats.getQueryExecutionCount();
 	}
 	public long getQueryCacheHitCount() {
 		return stats.getQueryCacheHitCount();
 	}
 	public long getQueryExecutionMaxTime() {
 		return stats.getQueryExecutionMaxTime();
 	}
 	public long getQueryCacheMissCount() {
 		return stats.getQueryCacheMissCount();
 	}
 	public long getQueryCachePutCount() {
 		return stats.getQueryCachePutCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getFlushCount()
 	 */
 	public long getFlushCount() {
 		return stats.getFlushCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getConnectCount()
 	 */
 	public long getConnectCount() {
 		return stats.getConnectCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getSecondLevelCacheHitCount()
 	 */
 	public long getSecondLevelCacheHitCount() {
 		return stats.getSecondLevelCacheHitCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getSecondLevelCacheMissCount()
 	 */
 	public long getSecondLevelCacheMissCount() {
 		return stats.getSecondLevelCacheMissCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getSecondLevelCachePutCount()
 	 */
 	public long getSecondLevelCachePutCount() {
 		return stats.getSecondLevelCachePutCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getSessionCloseCount()
 	 */
 	public long getSessionCloseCount() {
 		return stats.getSessionCloseCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getSessionOpenCount()
 	 */
 	public long getSessionOpenCount() {
 		return stats.getSessionOpenCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getCollectionLoadCount()
 	 */
 	public long getCollectionLoadCount() {
 		return stats.getCollectionLoadCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getCollectionFetchCount()
 	 */
 	public long getCollectionFetchCount() {
 		return stats.getCollectionFetchCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getCollectionUpdateCount()
 	 */
 	public long getCollectionUpdateCount() {
 		return stats.getCollectionUpdateCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getCollectionRemoveCount()
 	 */
 	public long getCollectionRemoveCount() {
 		return stats.getCollectionRemoveCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getCollectionRecreateCount()
 	 */
 	public long getCollectionRecreateCount() {
 		return stats.getCollectionRecreateCount();
 	}
 	/**
 	 * @see StatisticsServiceMBean#getStartTime()
 	 */
 	public long getStartTime() {
 		return stats.getStartTime();
 	}
 
 	/**
 	 * @see StatisticsServiceMBean#isStatisticsEnabled()
 	 */
 	public boolean isStatisticsEnabled() {
 		return stats.isStatisticsEnabled();
 	}
 
 	/**
 	 * @see StatisticsServiceMBean#setStatisticsEnabled(boolean)
 	 */
 	public void setStatisticsEnabled(boolean enable) {
 		stats.setStatisticsEnabled(enable);
 	}
 
 	public void logSummary() {
 		stats.logSummary();
 	}
 
 	public String[] getCollectionRoleNames() {
 		return stats.getCollectionRoleNames();
 	}
 
 	public String[] getEntityNames() {
 		return stats.getEntityNames();
 	}
 
 	public String[] getQueries() {
 		return stats.getQueries();
 	}
 
 	public String[] getSecondLevelCacheRegionNames() {
 		return stats.getSecondLevelCacheRegionNames();
 	}
 
 	public long getSuccessfulTransactionCount() {
 		return stats.getSuccessfulTransactionCount();
 	}
 	public long getTransactionCount() {
 		return stats.getTransactionCount();
 	}
 
 	public long getCloseStatementCount() {
 		return stats.getCloseStatementCount();
 	}
 	public long getPrepareStatementCount() {
 		return stats.getPrepareStatementCount();
 	}
 
 	public long getOptimisticFailureCount() {
 		return stats.getOptimisticFailureCount();
 	}
 
 	public String getQueryExecutionMaxTimeQueryString() {
 		return stats.getQueryExecutionMaxTimeQueryString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
index 3372e54eca..06eb8de82e 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
@@ -1,1104 +1,1104 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.WrongClassException;
 import org.hibernate.cache.FilterKey;
 import org.hibernate.cache.QueryCache;
 import org.hibernate.cache.QueryKey;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.EntityUniqueKey;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.RowSelection;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.SubselectFetch;
 import org.hibernate.engine.TwoPhaseLoad;
 import org.hibernate.engine.TypedValue;
 import org.hibernate.engine.jdbc.ColumnNameCache;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.PostLoadEvent;
 import org.hibernate.event.PreLoadEvent;
 import org.hibernate.hql.HolderInstantiator;
 import org.hibernate.impl.FetchingScrollableResultsImpl;
 import org.hibernate.impl.ScrollableResultsImpl;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.UniqueKeyLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.transform.CacheableResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * Abstract superclass of object loading (and querying) strategies. This class implements
  * useful common functionality that concrete loaders delegate to. It is not intended that this
  * functionality would be directly accessed by client code. (Hence, all methods of this class
  * are declared <tt>protected</tt> or <tt>private</tt>.) This class relies heavily upon the
  * <tt>Loadable</tt> interface, which is the contract between this class and
  * <tt>EntityPersister</tt>s that may be loaded by it.<br>
  * <br>
  * The present implementation is able to load any number of columns of entities and at most
  * one collection role per query.
  *
  * @author Gavin King
  * @see org.hibernate.persister.entity.Loadable
  */
 public abstract class Loader {
 
-    protected static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Loader.class.getName());
+    protected static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Loader.class.getName());
 
 	private final SessionFactoryImplementor factory;
 	private ColumnNameCache columnNameCache;
 
 	public Loader(SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 
 	/**
 	 * The SQL query string to be called; implemented by all subclasses
 	 *
 	 * @return The sql command this loader should use to get its {@link ResultSet}.
 	 */
 	protected abstract String getSQLString();
 
 	/**
 	 * An array of persisters of entity classes contained in each row of results;
 	 * implemented by all subclasses
 	 *
 	 * @return The entity persisters.
 	 */
 	protected abstract Loadable[] getEntityPersisters();
 
 	/**
 	 * An array indicating whether the entities have eager property fetching
 	 * enabled.
 	 *
 	 * @return Eager property fetching indicators.
 	 */
 	protected boolean[] getEntityEagerPropertyFetches() {
 		return null;
 	}
 
 	/**
 	 * An array of indexes of the entity that owns a one-to-one association
 	 * to the entity at the given index (-1 if there is no "owner").  The
 	 * indexes contained here are relative to the result of
 	 * {@link #getEntityPersisters}.
 	 *
 	 * @return The owner indicators (see discussion above).
 	 */
 	protected int[] getOwners() {
 		return null;
 	}
 
 	/**
 	 * An array of the owner types corresponding to the {@link #getOwners()}
 	 * returns.  Indices indicating no owner would be null here.
 	 *
 	 * @return The types for the owners.
 	 */
 	protected EntityType[] getOwnerAssociationTypes() {
 		return null;
 	}
 
 	/**
 	 * An (optional) persister for a collection to be initialized; only
 	 * collection loaders return a non-null value
 	 */
 	protected CollectionPersister[] getCollectionPersisters() {
 		return null;
 	}
 
 	/**
 	 * Get the index of the entity that owns the collection, or -1
 	 * if there is no owner in the query results (ie. in the case of a
 	 * collection initializer) or no collection.
 	 */
 	protected int[] getCollectionOwners() {
 		return null;
 	}
 
 	protected int[][] getCompositeKeyManyToOneTargetIndices() {
 		return null;
 	}
 
 	/**
 	 * What lock options does this load entities with?
 	 *
 	 * @param lockOptions a collection of lock options specified dynamically via the Query interface
 	 */
 	//protected abstract LockOptions[] getLockOptions(Map lockOptions);
 	protected abstract LockMode[] getLockModes(LockOptions lockOptions);
 
 	/**
 	 * Append <tt>FOR UPDATE OF</tt> clause, if necessary. This
 	 * empty superclass implementation merely returns its first
 	 * argument.
 	 */
 	protected String applyLocks(String sql, LockOptions lockOptions, Dialect dialect) throws HibernateException {
 		return sql;
 	}
 
 	/**
 	 * Does this query return objects that might be already cached
 	 * by the session, whose lock mode may need upgrading
 	 */
 	protected boolean upgradeLocks() {
 		return false;
 	}
 
 	/**
 	 * Return false is this loader is a batch entity loader
 	 */
 	protected boolean isSingleRowLoader() {
 		return false;
 	}
 
 	/**
 	 * Get the SQL table aliases of entities whose
 	 * associations are subselect-loadable, returning
 	 * null if this loader does not support subselect
 	 * loading
 	 */
 	protected String[] getAliases() {
 		return null;
 	}
 
 	/**
 	 * Modify the SQL, adding lock hints and comments, if necessary
 	 */
 	protected String preprocessSQL(String sql, QueryParameters parameters, Dialect dialect)
 			throws HibernateException {
 
 		sql = applyLocks( sql, parameters.getLockOptions(), dialect );
 
 		return getFactory().getSettings().isCommentsEnabled() ?
 				prependComment( sql, parameters ) : sql;
 	}
 
 	private String prependComment(String sql, QueryParameters parameters) {
 		String comment = parameters.getComment();
 		if ( comment == null ) {
 			return sql;
 		}
 		else {
 			return new StringBuffer( comment.length() + sql.length() + 5 )
 					.append( "/* " )
 					.append( comment )
 					.append( " */ " )
 					.append( sql )
 					.toString();
 		}
 	}
 
 	/**
 	 * Execute an SQL query and attempt to instantiate instances of the class mapped by the given
 	 * persister from each row of the <tt>ResultSet</tt>. If an object is supplied, will attempt to
 	 * initialize that object. If a collection is supplied, attempt to initialize that collection.
 	 */
 	private List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException, SQLException {
 		return doQueryAndInitializeNonLazyCollections(
 				session,
 				queryParameters,
 				returnProxies,
 				null
 		);
 	}
 
 	private List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer)
 			throws HibernateException, SQLException {
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 		if ( queryParameters.isReadOnlyInitialized() ) {
 			// The read-only/modifiable mode for the query was explicitly set.
 			// Temporarily set the default read-only/modifiable setting to the query's setting.
 			persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 		}
 		else {
 			// The read-only/modifiable setting for the query was not initialized.
 			// Use the default read-only/modifiable from the persistence context instead.
 			queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 		}
 		persistenceContext.beforeLoad();
 		List result;
 		try {
 			try {
 				result = doQuery( session, queryParameters, returnProxies, forcedResultTransformer );
 			}
 			finally {
 				persistenceContext.afterLoad();
 			}
 			persistenceContext.initializeNonLazyCollections();
 		}
 		finally {
 			// Restore the original default
 			persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 		}
 		return result;
 	}
 
 	/**
 	 * Loads a single row from the result set.  This is the processing used from the
 	 * ScrollableResults where no collection fetches were encountered.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSingleRow(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final boolean returnProxies) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		final Object result;
 		try {
 			result = getRowFromResultSet(
 			        resultSet,
 					session,
 					queryParameters,
 					getLockModes( queryParameters.getLockOptions() ),
 					null,
 					hydratedObjects,
 					new EntityKey[entitySpan],
 					returnProxies
 				);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not read next row of results",
 			        getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 			);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private Object sequentialLoad(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final boolean returnProxies,
 	        final EntityKey keyToRead) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		Object result = null;
 		final EntityKey[] loadedKeys = new EntityKey[entitySpan];
 
 		try {
 			do {
 				Object loaded = getRowFromResultSet(
 						resultSet,
 						session,
 						queryParameters,
 						getLockModes( queryParameters.getLockOptions() ),
 						null,
 						hydratedObjects,
 						loadedKeys,
 						returnProxies
 					);
 				if ( result == null ) {
 					result = loaded;
 				}
 			}
 			while ( keyToRead.equals( loadedKeys[0] ) && resultSet.next() );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not doAfterTransactionCompletion sequential read of results (forward)",
 			        getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 			);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsForward(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final boolean returnProxies) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isAfterLast() ) {
 				// don't even bother trying to read further
 				return null;
 			}
 
 			if ( resultSet.isBeforeFirst() ) {
 				resultSet.next();
 			}
 
 			// We call getKeyFromResultSet() here so that we can know the
 			// key value upon which to doAfterTransactionCompletion the breaking logic.  However,
 			// it is also then called from getRowFromResultSet() which is certainly
 			// not the most efficient.  But the call here is needed, and there
 			// currently is no other way without refactoring of the doQuery()/getRowFromResultSet()
 			// methods
 			final EntityKey currentKey = getKeyFromResultSet(
 					0,
 					getEntityPersisters()[0],
 					null,
 					resultSet,
 					session
 				);
 
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, currentKey );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not doAfterTransactionCompletion sequential read of results (forward)",
 			        getSQLString()
 				);
 		}
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsReverse(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final boolean returnProxies,
 	        final boolean isLogicallyAfterLast) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isFirst() ) {
 				// don't even bother trying to read any further
 				return null;
 			}
 
 			EntityKey keyToRead = null;
 			// This check is needed since processing leaves the cursor
 			// after the last physical row for the current logical row;
 			// thus if we are after the last physical row, this might be
 			// caused by either:
 			//      1) scrolling to the last logical row
 			//      2) scrolling past the last logical row
 			// In the latter scenario, the previous logical row
 			// really is the last logical row.
 			//
 			// In all other cases, we should process back two
 			// logical records (the current logic row, plus the
 			// previous logical row).
 			if ( resultSet.isAfterLast() && isLogicallyAfterLast ) {
 				// position cursor to the last row
 				resultSet.last();
 				keyToRead = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 			}
 			else {
 				// Since the result set cursor is always left at the first
 				// physical row after the "last processed", we need to jump
 				// back one position to get the key value we are interested
 				// in skipping
 				resultSet.previous();
 
 				// sequentially read the result set in reverse until we recognize
 				// a change in the key value.  At that point, we are pointed at
 				// the last physical sequential row for the logical row in which
 				// we are interested in processing
 				boolean firstPass = true;
 				final EntityKey lastKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 				while ( resultSet.previous() ) {
 					EntityKey checkKey = getKeyFromResultSet(
 							0,
 							getEntityPersisters()[0],
 							null,
 							resultSet,
 							session
 						);
 
 					if ( firstPass ) {
 						firstPass = false;
 						keyToRead = checkKey;
 					}
 
 					if ( !lastKey.equals( checkKey ) ) {
 						break;
 					}
 				}
 
 			}
 
 			// Read backwards until we read past the first physical sequential
 			// row with the key we are interested in loading
 			while ( resultSet.previous() ) {
 				EntityKey checkKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 
 				if ( !keyToRead.equals( checkKey ) ) {
 					break;
 				}
 			}
 
 			// Finally, read ahead one row to position result set cursor
 			// at the first physical row we are interested in loading
 			resultSet.next();
 
 			// and doAfterTransactionCompletion the load
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, keyToRead );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not doAfterTransactionCompletion sequential read of results (forward)",
 			        getSQLString()
 				);
 		}
 	}
 
 	private static EntityKey getOptionalObjectKey(QueryParameters queryParameters, SessionImplementor session) {
 		final Object optionalObject = queryParameters.getOptionalObject();
 		final Serializable optionalId = queryParameters.getOptionalId();
 		final String optionalEntityName = queryParameters.getOptionalEntityName();
 
 		if ( optionalObject != null && optionalEntityName != null ) {
 			return session.generateEntityKey( optionalId, session.getEntityPersister( optionalEntityName, optionalObject ) );
 		}
 		else {
 			return null;
 		}
 
 	}
 
 	private Object getRowFromResultSet(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final LockMode[] lockModesArray,
 	        final EntityKey optionalObjectKey,
 	        final List hydratedObjects,
 	        final EntityKey[] keys,
 	        boolean returnProxies) throws SQLException, HibernateException {
 		return getRowFromResultSet(
 				resultSet,
 				session,
 				queryParameters,
 				lockModesArray,
 				optionalObjectKey,
 				hydratedObjects,
 				keys,
 				returnProxies,
 				null
 		);
 	}
 
 	private Object getRowFromResultSet(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final LockMode[] lockModesArray,
 	        final EntityKey optionalObjectKey,
 	        final List hydratedObjects,
 	        final EntityKey[] keys,
 	        boolean returnProxies,
 	        ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 		final Loadable[] persisters = getEntityPersisters();
 		final int entitySpan = persisters.length;
 		extractKeysFromResultSet( persisters, queryParameters, resultSet, session, keys, lockModesArray, hydratedObjects );
 
 		registerNonExists( keys, persisters, session );
 
 		// this call is side-effecty
 		Object[] row = getRow(
 		        resultSet,
 				persisters,
 				keys,
 				queryParameters.getOptionalObject(),
 				optionalObjectKey,
 				lockModesArray,
 				hydratedObjects,
 				session
 		);
 
 		readCollectionElements( row, resultSet, session );
 
 		if ( returnProxies ) {
 			// now get an existing proxy for each row element (if there is one)
 			for ( int i = 0; i < entitySpan; i++ ) {
 				Object entity = row[i];
 				Object proxy = session.getPersistenceContext().proxyFor( persisters[i], keys[i], entity );
 				if ( entity != proxy ) {
 					// force the proxy to resolve itself
 					( (HibernateProxy) proxy ).getHibernateLazyInitializer().setImplementation(entity);
 					row[i] = proxy;
 				}
 			}
 		}
 
 		applyPostLoadLocks( row, lockModesArray, session );
 
 		return forcedResultTransformer == null ?
 				getResultColumnOrRow( row, queryParameters.getResultTransformer(), resultSet, session ) :
 				forcedResultTransformer.transformTuple(
 						getResultRow( row, resultSet, session ),
 						getResultRowAliases()
 				)
 		;
 	}
 
 	protected void extractKeysFromResultSet(
 			Loadable[] persisters,
 			QueryParameters queryParameters,
 			ResultSet resultSet,
 			SessionImplementor session,
 			EntityKey[] keys,
 			LockMode[] lockModes,
 			List hydratedObjects) throws SQLException {
 		final int entitySpan = persisters.length;
 
 		final int numberOfPersistersToProcess;
 		final Serializable optionalId = queryParameters.getOptionalId();
 		if ( isSingleRowLoader() && optionalId != null ) {
 			keys[ entitySpan - 1 ] = session.generateEntityKey( optionalId, persisters[ entitySpan - 1 ] );
 			// skip the last persister below...
 			numberOfPersistersToProcess = entitySpan - 1;
 		}
 		else {
 			numberOfPersistersToProcess = entitySpan;
 		}
 
 		final Object[] hydratedKeyState = new Object[numberOfPersistersToProcess];
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			hydratedKeyState[i] = idType.hydrate( resultSet, getEntityAliases()[i].getSuffixedKeyAliases(), session, null );
 		}
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			if ( idType.isComponentType() && getCompositeKeyManyToOneTargetIndices() != null ) {
 				// we may need to force resolve any key-many-to-one(s)
 				int[] keyManyToOneTargetIndices = getCompositeKeyManyToOneTargetIndices()[i];
 				// todo : better solution is to order the index processing based on target indices
 				//		that would account for multiple levels whereas this scheme does not
 				if ( keyManyToOneTargetIndices != null ) {
 					for ( int targetIndex : keyManyToOneTargetIndices ) {
 						if ( targetIndex < numberOfPersistersToProcess ) {
 							final Type targetIdType = persisters[targetIndex].getIdentifierType();
 							final Serializable targetId = (Serializable) targetIdType.resolve(
 									hydratedKeyState[targetIndex],
 									session,
 									null
 							);
 							// todo : need a way to signal that this key is resolved and its data resolved
 							keys[targetIndex] = session.generateEntityKey( targetId, persisters[targetIndex] );
 						}
 
 						// this part copied from #getRow, this section could be refactored out
 						Object object = session.getEntityUsingInterceptor( keys[targetIndex] );
 						if ( object != null ) {
 							//its already loaded so don't need to hydrate it
 							instanceAlreadyLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									keys[targetIndex],
 									object,
 									lockModes[targetIndex],
 									session
 							);
 						}
 						else {
 							instanceNotYetLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									getEntityAliases()[targetIndex].getRowIdAlias(),
 									keys[targetIndex],
 									lockModes[targetIndex],
 									getOptionalObjectKey( queryParameters, session ),
 									queryParameters.getOptionalObject(),
 									hydratedObjects,
 									session
 							);
 						}
 					}
 				}
 			}
 			final Serializable resolvedId = (Serializable) idType.resolve( hydratedKeyState[i], session, null );
 			keys[i] = resolvedId == null ? null : session.generateEntityKey( resolvedId, persisters[i] );
 		}
 	}
 
 	private Serializable determineResultId(SessionImplementor session, Serializable optionalId, Type idType, Serializable resolvedId) {
 		final boolean idIsResultId = optionalId != null
 				&& resolvedId != null
 				&& idType.isEqual( optionalId, resolvedId, session.getEntityMode(), factory );
 		final Serializable resultId = idIsResultId ? optionalId : resolvedId;
 		return resultId;
 	}
 
 	protected void applyPostLoadLocks(Object[] row, LockMode[] lockModesArray, SessionImplementor session) {
 	}
 
 	/**
 	 * Read any collection elements contained in a single row of the result set
 	 */
 	private void readCollectionElements(Object[] row, ResultSet resultSet, SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		//TODO: make this handle multiple collection roles!
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 
 			final CollectionAliases[] descriptors = getCollectionAliases();
 			final int[] collectionOwners = getCollectionOwners();
 
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 
 				final boolean hasCollectionOwners = collectionOwners !=null &&
 						collectionOwners[i] > -1;
 				//true if this is a query and we are loading multiple instances of the same collection role
 				//otherwise this is a CollectionInitializer and we are loading up a single collection or batch
 
 				final Object owner = hasCollectionOwners ?
 						row[ collectionOwners[i] ] :
 						null; //if null, owner will be retrieved from session
 
 				final CollectionPersister collectionPersister = collectionPersisters[i];
 				final Serializable key;
 				if ( owner == null ) {
 					key = null;
 				}
 				else {
 					key = collectionPersister.getCollectionType().getKeyOfOwner( owner, session );
 					//TODO: old version did not require hashmap lookup:
 					//keys[collectionOwner].getIdentifier()
 				}
 
 				readCollectionElement(
 						owner,
 						key,
 						collectionPersister,
 						descriptors[i],
 						resultSet,
 						session
 					);
 
 			}
 
 		}
 	}
 
 	private List doQuery(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 
 		final RowSelection selection = queryParameters.getRowSelection();
 		final int maxRows = hasMaxRows( selection ) ?
 				selection.getMaxRows().intValue() :
 				Integer.MAX_VALUE;
 
 		final int entitySpan = getEntityPersisters().length;
 
 		final ArrayList hydratedObjects = entitySpan == 0 ? null : new ArrayList( entitySpan * 10 );
 		final PreparedStatement st = prepareQueryStatement( queryParameters, false, session );
 		final ResultSet rs = getResultSet( st, queryParameters.hasAutoDiscoverScalarTypes(), queryParameters.isCallable(), selection, session );
 
 // would be great to move all this below here into another method that could also be used
 // from the new scrolling stuff.
 //
 // Would need to change the way the max-row stuff is handled (i.e. behind an interface) so
 // that I could do the control breaking at the means to know when to stop
 
 		final EntityKey optionalObjectKey = getOptionalObjectKey( queryParameters, session );
 		final LockMode[] lockModesArray = getLockModes( queryParameters.getLockOptions() );
 		final boolean createSubselects = isSubselectLoadingEnabled();
 		final List subselectResultKeys = createSubselects ? new ArrayList() : null;
 		final List results = new ArrayList();
 
 		try {
 
 			handleEmptyCollections( queryParameters.getCollectionKeys(), rs, session );
 
 			EntityKey[] keys = new EntityKey[entitySpan]; //we can reuse it for each row
 
             LOG.trace("Processing result set");
 
 			int count;
 			for ( count = 0; count < maxRows && rs.next(); count++ ) {
 
                 LOG.debugf("Result set row: %s", count);
 
 				Object result = getRowFromResultSet(
 						rs,
 						session,
 						queryParameters,
 						lockModesArray,
 						optionalObjectKey,
 						hydratedObjects,
 						keys,
 						returnProxies,
 						forcedResultTransformer
 				);
 				results.add( result );
 
 				if ( createSubselects ) {
 					subselectResultKeys.add(keys);
 					keys = new EntityKey[entitySpan]; //can't reuse in this case
 				}
 
 			}
 
             LOG.trace("Done processing result set (" + count + " rows)");
 
 		}
 		finally {
 			st.close();
 		}
 
 		initializeEntitiesAndCollections( hydratedObjects, rs, session, queryParameters.isReadOnly( session ) );
 
 		if ( createSubselects ) createSubselects( subselectResultKeys, queryParameters, session );
 
 		return results; //getResultList(results);
 
 	}
 
 	protected boolean isSubselectLoadingEnabled() {
 		return false;
 	}
 
 	protected boolean hasSubselectLoadableCollections() {
 		final Loadable[] loadables = getEntityPersisters();
 		for (int i=0; i<loadables.length; i++ ) {
 			if ( loadables[i].hasSubselectLoadableCollections() ) return true;
 		}
 		return false;
 	}
 
 	private static Set[] transpose( List keys ) {
 		Set[] result = new Set[ ( ( EntityKey[] ) keys.get(0) ).length ];
 		for ( int j=0; j<result.length; j++ ) {
 			result[j] = new HashSet( keys.size() );
 			for ( int i=0; i<keys.size(); i++ ) {
 				result[j].add( ( ( EntityKey[] ) keys.get(i) ) [j] );
 			}
 		}
 		return result;
 	}
 
 	private void createSubselects(List keys, QueryParameters queryParameters, SessionImplementor session) {
 		if ( keys.size() > 1 ) { //if we only returned one entity, query by key is more efficient
 
 			Set[] keySets = transpose(keys);
 
 			Map namedParameterLocMap = buildNamedParameterLocMap( queryParameters );
 
 			final Loadable[] loadables = getEntityPersisters();
 			final String[] aliases = getAliases();
 			final Iterator iter = keys.iterator();
 			while ( iter.hasNext() ) {
 
 				final EntityKey[] rowKeys = (EntityKey[]) iter.next();
 				for ( int i=0; i<rowKeys.length; i++ ) {
 
 					if ( rowKeys[i]!=null && loadables[i].hasSubselectLoadableCollections() ) {
 
 						SubselectFetch subselectFetch = new SubselectFetch(
 								//getSQLString(),
 								aliases[i],
 								loadables[i],
 								queryParameters,
 								keySets[i],
 								namedParameterLocMap
 							);
 
 						session.getPersistenceContext()
 								.getBatchFetchQueue()
 								.addSubselect( rowKeys[i], subselectFetch );
 					}
 
 				}
 
 			}
 		}
 	}
 
 	private Map buildNamedParameterLocMap(QueryParameters queryParameters) {
 		if ( queryParameters.getNamedParameters()!=null ) {
 			final Map namedParameterLocMap = new HashMap();
 			Iterator piter = queryParameters.getNamedParameters().keySet().iterator();
 			while ( piter.hasNext() ) {
 				String name = (String) piter.next();
 				namedParameterLocMap.put(
 						name,
 						getNamedParameterLocs(name)
 					);
 			}
 			return namedParameterLocMap;
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly)
 	throws HibernateException {
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 				if ( collectionPersisters[i].isArray() ) {
 					//for arrays, we should end the collection load before resolving
 					//the entities, since the actual array instances are not instantiated
 					//during loading
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
 				}
 			}
 		}
 
 		//important: reuse the same event instances for performance!
 		final PreLoadEvent pre;
 		final PostLoadEvent post;
 		if ( session.isEventSource() ) {
 			pre = new PreLoadEvent( (EventSource) session );
 			post = new PostLoadEvent( (EventSource) session );
 		}
 		else {
 			pre = null;
 			post = null;
 		}
 
 		if ( hydratedObjects!=null ) {
 			int hydratedObjectsSize = hydratedObjects.size();
             LOG.trace("Total objects hydrated: " + hydratedObjectsSize);
 			for ( int i = 0; i < hydratedObjectsSize; i++ ) {
 				TwoPhaseLoad.initializeEntity( hydratedObjects.get(i), readOnly, session, pre, post );
 			}
 		}
 
 		if ( collectionPersisters != null ) {
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 				if ( !collectionPersisters[i].isArray() ) {
 					//for sets, we should end the collection load after resolving
 					//the entities, since we might call hashCode() on the elements
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
 				}
 			}
 		}
 
 	}
 
 	private void endCollectionLoad(
 			final Object resultSetId,
 			final SessionImplementor session,
 			final CollectionPersister collectionPersister) {
 		//this is a query and we are loading multiple instances of the same collection role
 		session.getPersistenceContext()
 				.getLoadContexts()
 				.getCollectionLoadContext( ( ResultSet ) resultSetId )
 				.endLoadingCollections( collectionPersister );
 	}
 
 	/**
 	 * Determine the actual ResultTransformer that will be used to
 	 * transform query results.
 	 *
 	 * @param resultTransformer the specified result transformer
 	 * @return the actual result transformer
 	 */
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return resultTransformer;
 	}
 
 	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		return results;
 	}
 
 	/**
 	 * Are rows transformed immediately after being read from the ResultSet?
 	 * @return true, if getResultColumnOrRow() transforms the results; false, otherwise
 	 */
 	protected boolean areResultSetRowsTransformedImmediately() {
 		return false;
 	}
 
 	/**
 	 * Returns the aliases that corresponding to a result row.
 	 * @return Returns the aliases that corresponding to a result row.
 	 */
 	protected String[] getResultRowAliases() {
 		 return null;
 	}
 
 	/**
 	 * Get the actual object that is returned in the user-visible result list.
 	 * This empty implementation merely returns its first argument. This is
 	 * overridden by some subclasses.
 	 */
 	protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		return row;
 	}
 
 	protected boolean[] includeInResultRow() {
 		return null;
 	}
 
 	protected Object[] getResultRow(Object[] row,
 														 ResultSet rs,
 														 SessionImplementor session)
 			throws SQLException, HibernateException {
 		return row;
 	}
 
 	/**
 	 * For missing objects associated by one-to-one with another object in the
 	 * result set, register the fact that the the object is missing with the
 	 * session.
 	 */
 	private void registerNonExists(
 	        final EntityKey[] keys,
 	        final Loadable[] persisters,
 	        final SessionImplementor session) {
 
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/collection/BasicCollectionLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/collection/BasicCollectionLoader.java
index b094d11f92..6aa525f7e7 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/collection/BasicCollectionLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/collection/BasicCollectionLoader.java
@@ -1,83 +1,84 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.collection;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.loader.JoinWalker;
 import org.hibernate.persister.collection.QueryableCollection;
+
 import org.jboss.logging.Logger;
 
 /**
  * Loads a collection of values or a many-to-many association.
  * <br>
  * The collection persister must implement <tt>QueryableCOllection<tt>. For
  * other collections, create a customized subclass of <tt>Loader</tt>.
  *
  * @see OneToManyLoader
  * @author Gavin King
  */
 public class BasicCollectionLoader extends CollectionLoader {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BasicCollectionLoader.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BasicCollectionLoader.class.getName());
 
 	public BasicCollectionLoader(
 			QueryableCollection collectionPersister,
 			SessionFactoryImplementor session,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		this( collectionPersister, 1, session, loadQueryInfluencers );
 	}
 
 	public BasicCollectionLoader(
 			QueryableCollection collectionPersister,
 			int batchSize,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		this( collectionPersister, batchSize, null, factory, loadQueryInfluencers );
 	}
 
 	protected BasicCollectionLoader(
 			QueryableCollection collectionPersister,
 			int batchSize,
 			String subquery,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		super( collectionPersister, factory, loadQueryInfluencers );
 
 		JoinWalker walker = new BasicCollectionJoinWalker(
 				collectionPersister,
 				batchSize,
 				subquery,
 				factory,
 				loadQueryInfluencers
 		);
 		initFromWalker( walker );
 
 		postInstantiate();
 
         LOG.debugf("Static select for collection %s: %s", collectionPersister.getRole(), getSQLString());
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/collection/OneToManyLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/collection/OneToManyLoader.java
index 087acb9975..54cfcbdf3b 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/collection/OneToManyLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/collection/OneToManyLoader.java
@@ -1,82 +1,82 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.collection;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.loader.JoinWalker;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.jboss.logging.Logger;
 
 /**
  * Loads one-to-many associations<br>
  * <br>
  * The collection persister must implement <tt>QueryableCOllection<tt>. For
  * other collections, create a customized subclass of <tt>Loader</tt>.
  *
  * @see BasicCollectionLoader
  * @author Gavin King
  */
 public class OneToManyLoader extends CollectionLoader {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, OneToManyLoader.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, OneToManyLoader.class.getName());
 
 	public OneToManyLoader(
 			QueryableCollection oneToManyPersister,
 			SessionFactoryImplementor session,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		this( oneToManyPersister, 1, session, loadQueryInfluencers );
 	}
 
 	public OneToManyLoader(
 			QueryableCollection oneToManyPersister,
 			int batchSize,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		this( oneToManyPersister, batchSize, null, factory, loadQueryInfluencers );
 	}
 
 	public OneToManyLoader(
 			QueryableCollection oneToManyPersister,
 			int batchSize,
 			String subquery,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		super( oneToManyPersister, factory, loadQueryInfluencers );
 
 		JoinWalker walker = new OneToManyJoinWalker(
 				oneToManyPersister,
 				batchSize,
 				subquery,
 				factory,
 				loadQueryInfluencers
 		);
 		initFromWalker( walker );
 
 		postInstantiate();
         LOG.debugf("Static select for one-to-many %s: %s", oneToManyPersister.getRole(), getSQLString());
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLCustomQuery.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLCustomQuery.java
index 1b1549aca7..a6b6c47a31 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLCustomQuery.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLCustomQuery.java
@@ -1,253 +1,254 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.custom.sql;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.query.sql.NativeSQLQueryReturn;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.collection.SQLLoadableCollection;
 import org.hibernate.persister.entity.SQLLoadable;
+
 import org.jboss.logging.Logger;
 
 /**
  * Implements Hibernate's built-in support for native SQL queries.
  * <p/>
  * This support is built on top of the notion of "custom queries"...
  *
  * @author Gavin King
  * @author Max Andersen
  * @author Steve Ebersole
  */
 public class SQLCustomQuery implements CustomQuery {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SQLCustomQuery.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SQLCustomQuery.class.getName());
 
 	private final String sql;
 	private final Set querySpaces = new HashSet();
 	private final Map namedParameterBindPoints = new HashMap();
 	private final List customQueryReturns = new ArrayList();
 
 
 	public String getSQL() {
 		return sql;
 	}
 
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	public Map getNamedParameterBindPoints() {
 		return namedParameterBindPoints;
 	}
 
 	public List getCustomQueryReturns() {
 		return customQueryReturns;
 	}
 
 	public SQLCustomQuery(
 			final String sqlQuery,
 			final NativeSQLQueryReturn[] queryReturns,
 			final Collection additionalQuerySpaces,
 			final SessionFactoryImplementor factory) throws HibernateException {
 
         LOG.trace("Starting processing of sql query [" + sqlQuery + "]");
 		SQLQueryReturnProcessor processor = new SQLQueryReturnProcessor(queryReturns, factory);
 		SQLQueryReturnProcessor.ResultAliasContext aliasContext = processor.process();
 
 
 //		Map[] propertyResultMaps =  (Map[]) processor.getPropertyResults().toArray( new Map[0] );
 //		Map[] collectionResultMaps =  (Map[]) processor.getCollectionPropertyResults().toArray( new Map[0] );
 //
 //		List collectionSuffixes = new ArrayList();
 //		List collectionOwnerAliases = processor.getCollectionOwnerAliases();
 //		List collectionPersisters = processor.getCollectionPersisters();
 //		int size = collectionPersisters.size();
 //		if (size!=0) {
 //			collectionOwners = new int[size];
 //			collectionRoles = new String[size];
 //			//collectionDescriptors = new CollectionAliases[size];
 //			for ( int i=0; i<size; i++ ) {
 //				CollectionPersister collectionPersister = (CollectionPersister) collectionPersisters.get(i);
 //				collectionRoles[i] = ( collectionPersister ).getRole();
 //				collectionOwners[i] = processor.getAliases().indexOf( collectionOwnerAliases.get(i) );
 //				String suffix = i + "__";
 //				collectionSuffixes.add(suffix);
 //				//collectionDescriptors[i] = new GeneratedCollectionAliases( collectionResultMaps[i], collectionPersister, suffix );
 //			}
 //		}
 //		else {
 //			collectionRoles = null;
 //			//collectionDescriptors = null;
 //			collectionOwners = null;
 //		}
 //
 //		String[] aliases = ArrayHelper.toStringArray( processor.getAliases() );
 //		String[] collAliases = ArrayHelper.toStringArray( processor.getCollectionAliases() );
 //		String[] collSuffixes = ArrayHelper.toStringArray(collectionSuffixes);
 //
 //		SQLLoadable[] entityPersisters = (SQLLoadable[]) processor.getPersisters().toArray( new SQLLoadable[0] );
 //		SQLLoadableCollection[] collPersisters = (SQLLoadableCollection[]) collectionPersisters.toArray( new SQLLoadableCollection[0] );
 //        lockModes = (LockMode[]) processor.getLockModes().toArray( new LockMode[0] );
 //
 //        scalarColumnAliases = ArrayHelper.toStringArray( processor.getScalarColumnAliases() );
 //		scalarTypes = ArrayHelper.toTypeArray( processor.getScalarTypes() );
 //
 //		// need to match the "sequence" of what we return. scalar first, entity last.
 //		returnAliases = ArrayHelper.join(scalarColumnAliases, aliases);
 //
 //		String[] suffixes = BasicLoader.generateSuffixes(entityPersisters.length);
 
 		SQLQueryParser parser = new SQLQueryParser( sqlQuery, new ParserContext( aliasContext ), factory );
 		this.sql = parser.process();
 		this.namedParameterBindPoints.putAll( parser.getNamedParameters() );
 
 //		SQLQueryParser parser = new SQLQueryParser(
 //				sqlQuery,
 //				processor.getAlias2Persister(),
 //				processor.getAlias2Return(),
 //				aliases,
 //				collAliases,
 //				collPersisters,
 //				suffixes,
 //				collSuffixes
 //		);
 //
 //		sql = parser.process();
 //
 //		namedParameterBindPoints = parser.getNamedParameters();
 
 
 		customQueryReturns.addAll( processor.generateCustomReturns( parser.queryHasAliases() ) );
 
 //		// Populate entityNames, entityDescrptors and querySpaces
 //		entityNames = new String[entityPersisters.length];
 //		entityDescriptors = new EntityAliases[entityPersisters.length];
 //		for (int i = 0; i < entityPersisters.length; i++) {
 //			SQLLoadable persister = entityPersisters[i];
 //			//alias2Persister.put( aliases[i], persister );
 //			//TODO: Does not consider any other tables referenced in the query
 //			ArrayHelper.addAll( querySpaces, persister.getQuerySpaces() );
 //			entityNames[i] = persister.getEntityName();
 //			if ( parser.queryHasAliases() ) {
 //				entityDescriptors[i] = new DefaultEntityAliases(
 //						propertyResultMaps[i],
 //						entityPersisters[i],
 //						suffixes[i]
 //					);
 //			}
 //			else {
 //				entityDescriptors[i] = new ColumnEntityAliases(
 //						propertyResultMaps[i],
 //						entityPersisters[i],
 //						suffixes[i]
 //					);
 //			}
 //		}
 		if ( additionalQuerySpaces != null ) {
 			querySpaces.addAll( additionalQuerySpaces );
 		}
 
 //		if (size!=0) {
 //			collectionDescriptors = new CollectionAliases[size];
 //			for ( int i=0; i<size; i++ ) {
 //				CollectionPersister collectionPersister = (CollectionPersister) collectionPersisters.get(i);
 //				String suffix = i + "__";
 //				if( parser.queryHasAliases() ) {
 //					collectionDescriptors[i] = new GeneratedCollectionAliases( collectionResultMaps[i], collectionPersister, suffix );
 //				} else {
 //					collectionDescriptors[i] = new ColumnCollectionAliases( collectionResultMaps[i], (SQLLoadableCollection) collectionPersister );
 //				}
 //			}
 //		}
 //		else {
 //			collectionDescriptors = null;
 //		}
 //
 //
 //		// Resolve owners
 //		Map alias2OwnerAlias = processor.getAlias2OwnerAlias();
 //		int[] ownersArray = new int[entityPersisters.length];
 //		for ( int j=0; j < aliases.length; j++ ) {
 //			String ownerAlias = (String) alias2OwnerAlias.get( aliases[j] );
 //			if ( StringHelper.isNotEmpty(ownerAlias) ) {
 //				ownersArray[j] =  processor.getAliases().indexOf( ownerAlias );
 //			}
 //			else {
 //				ownersArray[j] = -1;
 //			}
 //		}
 //		if ( ArrayHelper.isAllNegative(ownersArray) ) {
 //			ownersArray = null;
 //		}
 //		this.entityOwners = ownersArray;
 
 	}
 
 
 	private static class ParserContext implements SQLQueryParser.ParserContext {
 
 		private final SQLQueryReturnProcessor.ResultAliasContext aliasContext;
 
 		public ParserContext(SQLQueryReturnProcessor.ResultAliasContext aliasContext) {
 			this.aliasContext = aliasContext;
 		}
 
 		public boolean isEntityAlias(String alias) {
 			return getEntityPersisterByAlias( alias ) != null;
 		}
 
 		public SQLLoadable getEntityPersisterByAlias(String alias) {
 			return aliasContext.getEntityPersister( alias );
 		}
 
 		public String getEntitySuffixByAlias(String alias) {
 			return aliasContext.getEntitySuffix( alias );
 		}
 
 		public boolean isCollectionAlias(String alias) {
 			return getCollectionPersisterByAlias( alias ) != null;
 		}
 
 		public SQLLoadableCollection getCollectionPersisterByAlias(String alias) {
 			return aliasContext.getCollectionPersister( alias );
 		}
 
 		public String getCollectionSuffixByAlias(String alias) {
 			return aliasContext.getCollectionSuffix( alias );
 		}
 
 		public Map getPropertyResultsMapByAlias(String alias) {
 			return aliasContext.getPropertyResultsMap( alias );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
index 3c936eab79..1fa9998b9c 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
@@ -1,523 +1,523 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ *
+ */
 package org.hibernate.loader.custom.sql;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.MappingException;
-import org.hibernate.engine.SessionFactoryImplementor;
-import org.hibernate.engine.query.sql.NativeSQLQueryCollectionReturn;
-import org.hibernate.engine.query.sql.NativeSQLQueryJoinReturn;
-import org.hibernate.engine.query.sql.NativeSQLQueryNonScalarReturn;
-import org.hibernate.engine.query.sql.NativeSQLQueryReturn;
-import org.hibernate.engine.query.sql.NativeSQLQueryRootReturn;
-import org.hibernate.engine.query.sql.NativeSQLQueryScalarReturn;
-import org.hibernate.loader.BasicLoader;
-import org.hibernate.loader.CollectionAliases;
-import org.hibernate.loader.ColumnEntityAliases;
-import org.hibernate.loader.DefaultEntityAliases;
-import org.hibernate.loader.EntityAliases;
-import org.hibernate.loader.GeneratedCollectionAliases;
-import org.hibernate.loader.custom.CollectionFetchReturn;
-import org.hibernate.loader.custom.CollectionReturn;
-import org.hibernate.loader.custom.ColumnCollectionAliases;
-import org.hibernate.loader.custom.EntityFetchReturn;
-import org.hibernate.loader.custom.FetchReturn;
-import org.hibernate.loader.custom.NonScalarReturn;
-import org.hibernate.loader.custom.Return;
-import org.hibernate.loader.custom.RootReturn;
-import org.hibernate.loader.custom.ScalarReturn;
-import org.hibernate.persister.collection.SQLLoadableCollection;
-import org.hibernate.persister.entity.EntityPersister;
-import org.hibernate.persister.entity.SQLLoadable;
-import org.hibernate.type.EntityType;
-import org.hibernate.type.Type;
-import org.jboss.logging.Logger;
-
-/**
- * Responsible for processing the series of {@link org.hibernate.engine.query.sql.NativeSQLQueryReturn returns}
- * defined by a {@link org.hibernate.engine.query.sql.NativeSQLQuerySpecification} and
- * breaking them down into a series of {@link Return returns} for use within the
- * {@link org.hibernate.loader.custom.CustomLoader}.
- *
- * @author Gavin King
- * @author Max Andersen
- * @author Steve Ebersole
- */
-public class SQLQueryReturnProcessor {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
-                                                                       SQLQueryReturnProcessor.class.getName());
-
-	private NativeSQLQueryReturn[] queryReturns;
-
-//	private final List persisters = new ArrayList();
-
-	private final Map alias2Return = new HashMap();
-	private final Map alias2OwnerAlias = new HashMap();
-
-	private final Map alias2Persister = new HashMap();
-	private final Map alias2Suffix = new HashMap();
-
-	private final Map alias2CollectionPersister = new HashMap();
-	private final Map alias2CollectionSuffix = new HashMap();
-
-	private final Map entityPropertyResultMaps = new HashMap();
-	private final Map collectionPropertyResultMaps = new HashMap();
-
-//	private final List scalarTypes = new ArrayList();
-//	private final List scalarColumnAliases = new ArrayList();
-
-	private final SessionFactoryImplementor factory;
-
-//	private List collectionOwnerAliases = new ArrayList();
-//	private List collectionAliases = new ArrayList();
-//	private List collectionPersisters = new ArrayList();
-//	private List collectionResults = new ArrayList();
-
-	private int entitySuffixSeed = 0;
-	private int collectionSuffixSeed = 0;
-
-
-	public SQLQueryReturnProcessor(NativeSQLQueryReturn[] queryReturns, SessionFactoryImplementor factory) {
-		this.queryReturns = queryReturns;
-		this.factory = factory;
-	}
-
-	/*package*/ class ResultAliasContext {
-		public SQLLoadable getEntityPersister(String alias) {
-			return ( SQLLoadable ) alias2Persister.get( alias );
-		}
-
-		public SQLLoadableCollection getCollectionPersister(String alias) {
-			return ( SQLLoadableCollection ) alias2CollectionPersister.get( alias );
-		}
-
-		public String getEntitySuffix(String alias) {
-			return ( String ) alias2Suffix.get( alias );
-		}
-
-		public String getCollectionSuffix(String alias) {
-			return ( String ) alias2CollectionSuffix.get ( alias );
-		}
-
-		public String getOwnerAlias(String alias) {
-			return ( String ) alias2OwnerAlias.get( alias );
-		}
-
-		public Map getPropertyResultsMap(String alias) {
-			return internalGetPropertyResultsMap( alias );
-		}
-	}
-
-	private Map internalGetPropertyResultsMap(String alias) {
-		NativeSQLQueryReturn rtn = ( NativeSQLQueryReturn ) alias2Return.get( alias );
-		if ( rtn instanceof NativeSQLQueryNonScalarReturn ) {
-			return ( ( NativeSQLQueryNonScalarReturn ) rtn ).getPropertyResultsMap();
-		}
-		else {
-			return null;
-		}
-	}
-
-	private boolean hasPropertyResultMap(String alias) {
-		Map propertyMaps = internalGetPropertyResultsMap( alias );
-		return propertyMaps != null && ! propertyMaps.isEmpty();
-	}
-
-	public ResultAliasContext process() {
-		// first, break down the returns into maps keyed by alias
-		// so that role returns can be more easily resolved to their owners
-		for ( int i = 0; i < queryReturns.length; i++ ) {
-			if ( queryReturns[i] instanceof NativeSQLQueryNonScalarReturn ) {
-				NativeSQLQueryNonScalarReturn rtn = ( NativeSQLQueryNonScalarReturn ) queryReturns[i];
-				alias2Return.put( rtn.getAlias(), rtn );
-				if ( rtn instanceof NativeSQLQueryJoinReturn ) {
-					NativeSQLQueryJoinReturn fetchReturn = ( NativeSQLQueryJoinReturn ) rtn;
-					alias2OwnerAlias.put( fetchReturn.getAlias(), fetchReturn.getOwnerAlias() );
-				}
-			}
-		}
-
-		// Now, process the returns
-		for ( int i = 0; i < queryReturns.length; i++ ) {
-			processReturn( queryReturns[i] );
-		}
-
-		return new ResultAliasContext();
-	}
-
-	public List generateCustomReturns(boolean queryHadAliases) {
-		List customReturns = new ArrayList();
-		Map customReturnsByAlias = new HashMap();
-		for ( int i = 0; i < queryReturns.length; i++ ) {
-			if ( queryReturns[i] instanceof NativeSQLQueryScalarReturn ) {
-				NativeSQLQueryScalarReturn rtn = ( NativeSQLQueryScalarReturn ) queryReturns[i];
-				customReturns.add( new ScalarReturn( rtn.getType(), rtn.getColumnAlias() ) );
-			}
-			else if ( queryReturns[i] instanceof NativeSQLQueryRootReturn ) {
-				NativeSQLQueryRootReturn rtn = ( NativeSQLQueryRootReturn ) queryReturns[i];
-				String alias = rtn.getAlias();
-				EntityAliases entityAliases;
-				if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
-					entityAliases = new DefaultEntityAliases(
-							( Map ) entityPropertyResultMaps.get( alias ),
-							( SQLLoadable ) alias2Persister.get( alias ),
-							( String ) alias2Suffix.get( alias )
-					);
-				}
-				else {
-					entityAliases = new ColumnEntityAliases(
-							( Map ) entityPropertyResultMaps.get( alias ),
-							( SQLLoadable ) alias2Persister.get( alias ),
-							( String ) alias2Suffix.get( alias )
-					);
-				}
-				RootReturn customReturn = new RootReturn(
-						alias,
-						rtn.getReturnEntityName(),
-						entityAliases,
-						rtn.getLockMode()
-				);
-				customReturns.add( customReturn );
-				customReturnsByAlias.put( rtn.getAlias(), customReturn );
-			}
-			else if ( queryReturns[i] instanceof NativeSQLQueryCollectionReturn ) {
-				NativeSQLQueryCollectionReturn rtn = ( NativeSQLQueryCollectionReturn ) queryReturns[i];
-				String alias = rtn.getAlias();
-				SQLLoadableCollection persister = ( SQLLoadableCollection ) alias2CollectionPersister.get( alias );
-				boolean isEntityElements = persister.getElementType().isEntityType();
-				CollectionAliases collectionAliases;
-				EntityAliases elementEntityAliases = null;
-				if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
-					collectionAliases = new GeneratedCollectionAliases(
-							( Map ) collectionPropertyResultMaps.get( alias ),
-							( SQLLoadableCollection ) alias2CollectionPersister.get( alias ),
-							( String ) alias2CollectionSuffix.get( alias )
-					);
-					if ( isEntityElements ) {
-						elementEntityAliases = new DefaultEntityAliases(
-								( Map ) entityPropertyResultMaps.get( alias ),
-								( SQLLoadable ) alias2Persister.get( alias ),
-								( String ) alias2Suffix.get( alias )
-						);
-					}
-				}
-				else {
-					collectionAliases = new ColumnCollectionAliases(
-							( Map ) collectionPropertyResultMaps.get( alias ),
-							( SQLLoadableCollection ) alias2CollectionPersister.get( alias )
-					);
-					if ( isEntityElements ) {
-						elementEntityAliases = new ColumnEntityAliases(
-								( Map ) entityPropertyResultMaps.get( alias ),
-								( SQLLoadable ) alias2Persister.get( alias ),
-								( String ) alias2Suffix.get( alias )
-						);
-					}
-				}
-				CollectionReturn customReturn = new CollectionReturn(
-						alias,
-						rtn.getOwnerEntityName(),
-						rtn.getOwnerProperty(),
-						collectionAliases,
-				        elementEntityAliases,
-						rtn.getLockMode()
-				);
-				customReturns.add( customReturn );
-				customReturnsByAlias.put( rtn.getAlias(), customReturn );
-			}
-			else if ( queryReturns[i] instanceof NativeSQLQueryJoinReturn ) {
-				NativeSQLQueryJoinReturn rtn = ( NativeSQLQueryJoinReturn ) queryReturns[i];
-				String alias = rtn.getAlias();
-				FetchReturn customReturn;
-				NonScalarReturn ownerCustomReturn = ( NonScalarReturn ) customReturnsByAlias.get( rtn.getOwnerAlias() );
-				if ( alias2CollectionPersister.containsKey( alias ) ) {
-					SQLLoadableCollection persister = ( SQLLoadableCollection ) alias2CollectionPersister.get( alias );
-					boolean isEntityElements = persister.getElementType().isEntityType();
-					CollectionAliases collectionAliases;
-					EntityAliases elementEntityAliases = null;
-					if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
-						collectionAliases = new GeneratedCollectionAliases(
-								( Map ) collectionPropertyResultMaps.get( alias ),
-								persister,
-								( String ) alias2CollectionSuffix.get( alias )
-						);
-						if ( isEntityElements ) {
-							elementEntityAliases = new DefaultEntityAliases(
-									( Map ) entityPropertyResultMaps.get( alias ),
-									( SQLLoadable ) alias2Persister.get( alias ),
-									( String ) alias2Suffix.get( alias )
-							);
-						}
-					}
-					else {
-						collectionAliases = new ColumnCollectionAliases(
-								( Map ) collectionPropertyResultMaps.get( alias ),
-								persister
-						);
-						if ( isEntityElements ) {
-							elementEntityAliases = new ColumnEntityAliases(
-									( Map ) entityPropertyResultMaps.get( alias ),
-									( SQLLoadable ) alias2Persister.get( alias ),
-									( String ) alias2Suffix.get( alias )
-							);
-						}
-					}
-					customReturn = new CollectionFetchReturn(
-							alias,
-							ownerCustomReturn,
-							rtn.getOwnerProperty(),
-							collectionAliases,
-					        elementEntityAliases,
-							rtn.getLockMode()
-					);
-				}
-				else {
-					EntityAliases entityAliases;
-					if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
-						entityAliases = new DefaultEntityAliases(
-								( Map ) entityPropertyResultMaps.get( alias ),
-								( SQLLoadable ) alias2Persister.get( alias ),
-								( String ) alias2Suffix.get( alias )
-						);
-					}
-					else {
-						entityAliases = new ColumnEntityAliases(
-								( Map ) entityPropertyResultMaps.get( alias ),
-								( SQLLoadable ) alias2Persister.get( alias ),
-								( String ) alias2Suffix.get( alias )
-						);
-					}
-					customReturn = new EntityFetchReturn(
-							alias,
-							entityAliases,
-							ownerCustomReturn,
-							rtn.getOwnerProperty(),
-							rtn.getLockMode()
-					);
-				}
-				customReturns.add( customReturn );
-				customReturnsByAlias.put( alias, customReturn );
-			}
-		}
-		return customReturns;
-	}
-
-	private SQLLoadable getSQLLoadable(String entityName) throws MappingException {
-		EntityPersister persister = factory.getEntityPersister( entityName );
-		if ( !(persister instanceof SQLLoadable) ) {
-			throw new MappingException( "class persister is not SQLLoadable: " + entityName );
-		}
-		return (SQLLoadable) persister;
-	}
-
-	private String generateEntitySuffix() {
-		return BasicLoader.generateSuffixes( entitySuffixSeed++, 1 )[0];
-	}
-
-	private String generateCollectionSuffix() {
-		return collectionSuffixSeed++ + "__";
-	}
-
-	private void processReturn(NativeSQLQueryReturn rtn) {
-		if ( rtn instanceof NativeSQLQueryScalarReturn ) {
-			processScalarReturn( ( NativeSQLQueryScalarReturn ) rtn );
-		}
-		else if ( rtn instanceof NativeSQLQueryRootReturn ) {
-			processRootReturn( ( NativeSQLQueryRootReturn ) rtn );
-		}
-		else if ( rtn instanceof NativeSQLQueryCollectionReturn ) {
-			processCollectionReturn( ( NativeSQLQueryCollectionReturn ) rtn );
-		}
-		else {
-			processJoinReturn( ( NativeSQLQueryJoinReturn ) rtn );
-		}
-	}
-
-	private void processScalarReturn(NativeSQLQueryScalarReturn typeReturn) {
-//		scalarColumnAliases.add( typeReturn.getColumnAlias() );
-//		scalarTypes.add( typeReturn.getType() );
-	}
-
-	private void processRootReturn(NativeSQLQueryRootReturn rootReturn) {
-		if ( alias2Persister.containsKey( rootReturn.getAlias() ) ) {
-			// already been processed...
-			return;
-		}
-
-		SQLLoadable persister = getSQLLoadable( rootReturn.getReturnEntityName() );
-		addPersister( rootReturn.getAlias(), rootReturn.getPropertyResultsMap(), persister );
-	}
-
-	/**
-	 * @param propertyResult
-	 * @param persister
-	 */
-	private void addPersister(String alias, Map propertyResult, SQLLoadable persister) {
-		alias2Persister.put( alias, persister );
-		String suffix = generateEntitySuffix();
-        LOG.trace("Mapping alias [" + alias + "] to entity-suffix [" + suffix + "]");
-		alias2Suffix.put( alias, suffix );
-		entityPropertyResultMaps.put( alias, propertyResult );
-	}
-
-	private void addCollection(String role, String alias, Map propertyResults) {
-		SQLLoadableCollection collectionPersister = ( SQLLoadableCollection ) factory.getCollectionPersister( role );
-		alias2CollectionPersister.put( alias, collectionPersister );
-		String suffix = generateCollectionSuffix();
-        LOG.trace("Mapping alias [" + alias + "] to collection-suffix [" + suffix + "]");
-		alias2CollectionSuffix.put( alias, suffix );
-		collectionPropertyResultMaps.put( alias, propertyResults );
-
-		if ( collectionPersister.isOneToMany() || collectionPersister.isManyToMany() ) {
-			SQLLoadable persister = ( SQLLoadable ) collectionPersister.getElementPersister();
-			addPersister( alias, filter( propertyResults ), persister );
-		}
-	}
-
-	private Map filter(Map propertyResults) {
-		Map result = new HashMap( propertyResults.size() );
-
-		String keyPrefix = "element.";
-
-		Iterator iter = propertyResults.entrySet().iterator();
-		while ( iter.hasNext() ) {
-			Map.Entry element = ( Map.Entry ) iter.next();
-			String path = ( String ) element.getKey();
-			if ( path.startsWith( keyPrefix ) ) {
-				result.put( path.substring( keyPrefix.length() ), element.getValue() );
-			}
-		}
-
-		return result;
-	}
-
-	private void processCollectionReturn(NativeSQLQueryCollectionReturn collectionReturn) {
-		// we are initializing an owned collection
-		//collectionOwners.add( new Integer(-1) );
-//		collectionOwnerAliases.add( null );
-		String role = collectionReturn.getOwnerEntityName() + '.' + collectionReturn.getOwnerProperty();
-		addCollection(
-				role,
-				collectionReturn.getAlias(),
-				collectionReturn.getPropertyResultsMap()
-		);
-	}
-
-	private void processJoinReturn(NativeSQLQueryJoinReturn fetchReturn) {
-		String alias = fetchReturn.getAlias();
-//		if ( alias2Persister.containsKey( alias ) || collectionAliases.contains( alias ) ) {
-		if ( alias2Persister.containsKey( alias ) || alias2CollectionPersister.containsKey( alias ) ) {
-			// already been processed...
-			return;
-		}
-
-		String ownerAlias = fetchReturn.getOwnerAlias();
-
-		// Make sure the owner alias is known...
-		if ( !alias2Return.containsKey( ownerAlias ) ) {
-			throw new HibernateException( "Owner alias [" + ownerAlias + "] is unknown for alias [" + alias + "]" );
-		}
-
-		// If this return's alias has not been processed yet, do so b4 further processing of this return
-		if ( !alias2Persister.containsKey( ownerAlias ) ) {
-			NativeSQLQueryNonScalarReturn ownerReturn = ( NativeSQLQueryNonScalarReturn ) alias2Return.get(ownerAlias);
-			processReturn( ownerReturn );
-		}
-
-		SQLLoadable ownerPersister = ( SQLLoadable ) alias2Persister.get( ownerAlias );
-		Type returnType = ownerPersister.getPropertyType( fetchReturn.getOwnerProperty() );
-
-		if ( returnType.isCollectionType() ) {
-			String role = ownerPersister.getEntityName() + '.' + fetchReturn.getOwnerProperty();
-			addCollection( role, alias, fetchReturn.getPropertyResultsMap() );
-//			collectionOwnerAliases.add( ownerAlias );
-		}
-		else if ( returnType.isEntityType() ) {
-			EntityType eType = ( EntityType ) returnType;
-			String returnEntityName = eType.getAssociatedEntityName();
-			SQLLoadable persister = getSQLLoadable( returnEntityName );
-			addPersister( alias, fetchReturn.getPropertyResultsMap(), persister );
-		}
-
-	}
-
-//	public List getCollectionAliases() {
-//		return collectionAliases;
-//	}
-//
-//	/*public List getCollectionOwners() {
-//		return collectionOwners;
-//	}*/
-//
-//	public List getCollectionOwnerAliases() {
-//		return collectionOwnerAliases;
-//	}
-//
-//	public List getCollectionPersisters() {
-//		return collectionPersisters;
-//	}
-//
-//	public Map getAlias2Persister() {
-//		return alias2Persister;
-//	}
-//
-//	/*public boolean isCollectionInitializer() {
-//		return isCollectionInitializer;
-//	}*/
-//
-////	public List getPersisters() {
-////		return persisters;
-////	}
-//
-//	public Map getAlias2OwnerAlias() {
-//		return alias2OwnerAlias;
-//	}
-//
-//	public List getScalarTypes() {
-//		return scalarTypes;
-//	}
-//	public List getScalarColumnAliases() {
-//		return scalarColumnAliases;
-//	}
-//
-//	public List getPropertyResults() {
-//		return propertyResults;
-//	}
-//
-//	public List getCollectionPropertyResults() {
-//		return collectionResults;
-//	}
-//
-//
-//	public Map getAlias2Return() {
-//		return alias2Return;
-//	}
-}
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.MappingException;
+import org.hibernate.engine.SessionFactoryImplementor;
+import org.hibernate.engine.query.sql.NativeSQLQueryCollectionReturn;
+import org.hibernate.engine.query.sql.NativeSQLQueryJoinReturn;
+import org.hibernate.engine.query.sql.NativeSQLQueryNonScalarReturn;
+import org.hibernate.engine.query.sql.NativeSQLQueryReturn;
+import org.hibernate.engine.query.sql.NativeSQLQueryRootReturn;
+import org.hibernate.engine.query.sql.NativeSQLQueryScalarReturn;
+import org.hibernate.loader.BasicLoader;
+import org.hibernate.loader.CollectionAliases;
+import org.hibernate.loader.ColumnEntityAliases;
+import org.hibernate.loader.DefaultEntityAliases;
+import org.hibernate.loader.EntityAliases;
+import org.hibernate.loader.GeneratedCollectionAliases;
+import org.hibernate.loader.custom.CollectionFetchReturn;
+import org.hibernate.loader.custom.CollectionReturn;
+import org.hibernate.loader.custom.ColumnCollectionAliases;
+import org.hibernate.loader.custom.EntityFetchReturn;
+import org.hibernate.loader.custom.FetchReturn;
+import org.hibernate.loader.custom.NonScalarReturn;
+import org.hibernate.loader.custom.Return;
+import org.hibernate.loader.custom.RootReturn;
+import org.hibernate.loader.custom.ScalarReturn;
+import org.hibernate.persister.collection.SQLLoadableCollection;
+import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.entity.SQLLoadable;
+import org.hibernate.type.EntityType;
+import org.hibernate.type.Type;
+import org.jboss.logging.Logger;
+
+/**
+ * Responsible for processing the series of {@link org.hibernate.engine.query.sql.NativeSQLQueryReturn returns}
+ * defined by a {@link org.hibernate.engine.query.sql.NativeSQLQuerySpecification} and
+ * breaking them down into a series of {@link Return returns} for use within the
+ * {@link org.hibernate.loader.custom.CustomLoader}.
+ *
+ * @author Gavin King
+ * @author Max Andersen
+ * @author Steve Ebersole
+ */
+public class SQLQueryReturnProcessor {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
+                                                                       SQLQueryReturnProcessor.class.getName());
+
+	private NativeSQLQueryReturn[] queryReturns;
+
+//	private final List persisters = new ArrayList();
+
+	private final Map alias2Return = new HashMap();
+	private final Map alias2OwnerAlias = new HashMap();
+
+	private final Map alias2Persister = new HashMap();
+	private final Map alias2Suffix = new HashMap();
+
+	private final Map alias2CollectionPersister = new HashMap();
+	private final Map alias2CollectionSuffix = new HashMap();
+
+	private final Map entityPropertyResultMaps = new HashMap();
+	private final Map collectionPropertyResultMaps = new HashMap();
+
+//	private final List scalarTypes = new ArrayList();
+//	private final List scalarColumnAliases = new ArrayList();
+
+	private final SessionFactoryImplementor factory;
+
+//	private List collectionOwnerAliases = new ArrayList();
+//	private List collectionAliases = new ArrayList();
+//	private List collectionPersisters = new ArrayList();
+//	private List collectionResults = new ArrayList();
+
+	private int entitySuffixSeed = 0;
+	private int collectionSuffixSeed = 0;
+
+
+	public SQLQueryReturnProcessor(NativeSQLQueryReturn[] queryReturns, SessionFactoryImplementor factory) {
+		this.queryReturns = queryReturns;
+		this.factory = factory;
+	}
+
+	/*package*/ class ResultAliasContext {
+		public SQLLoadable getEntityPersister(String alias) {
+			return ( SQLLoadable ) alias2Persister.get( alias );
+		}
+
+		public SQLLoadableCollection getCollectionPersister(String alias) {
+			return ( SQLLoadableCollection ) alias2CollectionPersister.get( alias );
+		}
+
+		public String getEntitySuffix(String alias) {
+			return ( String ) alias2Suffix.get( alias );
+		}
+
+		public String getCollectionSuffix(String alias) {
+			return ( String ) alias2CollectionSuffix.get ( alias );
+		}
+
+		public String getOwnerAlias(String alias) {
+			return ( String ) alias2OwnerAlias.get( alias );
+		}
+
+		public Map getPropertyResultsMap(String alias) {
+			return internalGetPropertyResultsMap( alias );
+		}
+	}
+
+	private Map internalGetPropertyResultsMap(String alias) {
+		NativeSQLQueryReturn rtn = ( NativeSQLQueryReturn ) alias2Return.get( alias );
+		if ( rtn instanceof NativeSQLQueryNonScalarReturn ) {
+			return ( ( NativeSQLQueryNonScalarReturn ) rtn ).getPropertyResultsMap();
+		}
+		else {
+			return null;
+		}
+	}
+
+	private boolean hasPropertyResultMap(String alias) {
+		Map propertyMaps = internalGetPropertyResultsMap( alias );
+		return propertyMaps != null && ! propertyMaps.isEmpty();
+	}
+
+	public ResultAliasContext process() {
+		// first, break down the returns into maps keyed by alias
+		// so that role returns can be more easily resolved to their owners
+		for ( int i = 0; i < queryReturns.length; i++ ) {
+			if ( queryReturns[i] instanceof NativeSQLQueryNonScalarReturn ) {
+				NativeSQLQueryNonScalarReturn rtn = ( NativeSQLQueryNonScalarReturn ) queryReturns[i];
+				alias2Return.put( rtn.getAlias(), rtn );
+				if ( rtn instanceof NativeSQLQueryJoinReturn ) {
+					NativeSQLQueryJoinReturn fetchReturn = ( NativeSQLQueryJoinReturn ) rtn;
+					alias2OwnerAlias.put( fetchReturn.getAlias(), fetchReturn.getOwnerAlias() );
+				}
+			}
+		}
+
+		// Now, process the returns
+		for ( int i = 0; i < queryReturns.length; i++ ) {
+			processReturn( queryReturns[i] );
+		}
+
+		return new ResultAliasContext();
+	}
+
+	public List generateCustomReturns(boolean queryHadAliases) {
+		List customReturns = new ArrayList();
+		Map customReturnsByAlias = new HashMap();
+		for ( int i = 0; i < queryReturns.length; i++ ) {
+			if ( queryReturns[i] instanceof NativeSQLQueryScalarReturn ) {
+				NativeSQLQueryScalarReturn rtn = ( NativeSQLQueryScalarReturn ) queryReturns[i];
+				customReturns.add( new ScalarReturn( rtn.getType(), rtn.getColumnAlias() ) );
+			}
+			else if ( queryReturns[i] instanceof NativeSQLQueryRootReturn ) {
+				NativeSQLQueryRootReturn rtn = ( NativeSQLQueryRootReturn ) queryReturns[i];
+				String alias = rtn.getAlias();
+				EntityAliases entityAliases;
+				if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
+					entityAliases = new DefaultEntityAliases(
+							( Map ) entityPropertyResultMaps.get( alias ),
+							( SQLLoadable ) alias2Persister.get( alias ),
+							( String ) alias2Suffix.get( alias )
+					);
+				}
+				else {
+					entityAliases = new ColumnEntityAliases(
+							( Map ) entityPropertyResultMaps.get( alias ),
+							( SQLLoadable ) alias2Persister.get( alias ),
+							( String ) alias2Suffix.get( alias )
+					);
+				}
+				RootReturn customReturn = new RootReturn(
+						alias,
+						rtn.getReturnEntityName(),
+						entityAliases,
+						rtn.getLockMode()
+				);
+				customReturns.add( customReturn );
+				customReturnsByAlias.put( rtn.getAlias(), customReturn );
+			}
+			else if ( queryReturns[i] instanceof NativeSQLQueryCollectionReturn ) {
+				NativeSQLQueryCollectionReturn rtn = ( NativeSQLQueryCollectionReturn ) queryReturns[i];
+				String alias = rtn.getAlias();
+				SQLLoadableCollection persister = ( SQLLoadableCollection ) alias2CollectionPersister.get( alias );
+				boolean isEntityElements = persister.getElementType().isEntityType();
+				CollectionAliases collectionAliases;
+				EntityAliases elementEntityAliases = null;
+				if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
+					collectionAliases = new GeneratedCollectionAliases(
+							( Map ) collectionPropertyResultMaps.get( alias ),
+							( SQLLoadableCollection ) alias2CollectionPersister.get( alias ),
+							( String ) alias2CollectionSuffix.get( alias )
+					);
+					if ( isEntityElements ) {
+						elementEntityAliases = new DefaultEntityAliases(
+								( Map ) entityPropertyResultMaps.get( alias ),
+								( SQLLoadable ) alias2Persister.get( alias ),
+								( String ) alias2Suffix.get( alias )
+						);
+					}
+				}
+				else {
+					collectionAliases = new ColumnCollectionAliases(
+							( Map ) collectionPropertyResultMaps.get( alias ),
+							( SQLLoadableCollection ) alias2CollectionPersister.get( alias )
+					);
+					if ( isEntityElements ) {
+						elementEntityAliases = new ColumnEntityAliases(
+								( Map ) entityPropertyResultMaps.get( alias ),
+								( SQLLoadable ) alias2Persister.get( alias ),
+								( String ) alias2Suffix.get( alias )
+						);
+					}
+				}
+				CollectionReturn customReturn = new CollectionReturn(
+						alias,
+						rtn.getOwnerEntityName(),
+						rtn.getOwnerProperty(),
+						collectionAliases,
+				        elementEntityAliases,
+						rtn.getLockMode()
+				);
+				customReturns.add( customReturn );
+				customReturnsByAlias.put( rtn.getAlias(), customReturn );
+			}
+			else if ( queryReturns[i] instanceof NativeSQLQueryJoinReturn ) {
+				NativeSQLQueryJoinReturn rtn = ( NativeSQLQueryJoinReturn ) queryReturns[i];
+				String alias = rtn.getAlias();
+				FetchReturn customReturn;
+				NonScalarReturn ownerCustomReturn = ( NonScalarReturn ) customReturnsByAlias.get( rtn.getOwnerAlias() );
+				if ( alias2CollectionPersister.containsKey( alias ) ) {
+					SQLLoadableCollection persister = ( SQLLoadableCollection ) alias2CollectionPersister.get( alias );
+					boolean isEntityElements = persister.getElementType().isEntityType();
+					CollectionAliases collectionAliases;
+					EntityAliases elementEntityAliases = null;
+					if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
+						collectionAliases = new GeneratedCollectionAliases(
+								( Map ) collectionPropertyResultMaps.get( alias ),
+								persister,
+								( String ) alias2CollectionSuffix.get( alias )
+						);
+						if ( isEntityElements ) {
+							elementEntityAliases = new DefaultEntityAliases(
+									( Map ) entityPropertyResultMaps.get( alias ),
+									( SQLLoadable ) alias2Persister.get( alias ),
+									( String ) alias2Suffix.get( alias )
+							);
+						}
+					}
+					else {
+						collectionAliases = new ColumnCollectionAliases(
+								( Map ) collectionPropertyResultMaps.get( alias ),
+								persister
+						);
+						if ( isEntityElements ) {
+							elementEntityAliases = new ColumnEntityAliases(
+									( Map ) entityPropertyResultMaps.get( alias ),
+									( SQLLoadable ) alias2Persister.get( alias ),
+									( String ) alias2Suffix.get( alias )
+							);
+						}
+					}
+					customReturn = new CollectionFetchReturn(
+							alias,
+							ownerCustomReturn,
+							rtn.getOwnerProperty(),
+							collectionAliases,
+					        elementEntityAliases,
+							rtn.getLockMode()
+					);
+				}
+				else {
+					EntityAliases entityAliases;
+					if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
+						entityAliases = new DefaultEntityAliases(
+								( Map ) entityPropertyResultMaps.get( alias ),
+								( SQLLoadable ) alias2Persister.get( alias ),
+								( String ) alias2Suffix.get( alias )
+						);
+					}
+					else {
+						entityAliases = new ColumnEntityAliases(
+								( Map ) entityPropertyResultMaps.get( alias ),
+								( SQLLoadable ) alias2Persister.get( alias ),
+								( String ) alias2Suffix.get( alias )
+						);
+					}
+					customReturn = new EntityFetchReturn(
+							alias,
+							entityAliases,
+							ownerCustomReturn,
+							rtn.getOwnerProperty(),
+							rtn.getLockMode()
+					);
+				}
+				customReturns.add( customReturn );
+				customReturnsByAlias.put( alias, customReturn );
+			}
+		}
+		return customReturns;
+	}
+
+	private SQLLoadable getSQLLoadable(String entityName) throws MappingException {
+		EntityPersister persister = factory.getEntityPersister( entityName );
+		if ( !(persister instanceof SQLLoadable) ) {
+			throw new MappingException( "class persister is not SQLLoadable: " + entityName );
+		}
+		return (SQLLoadable) persister;
+	}
+
+	private String generateEntitySuffix() {
+		return BasicLoader.generateSuffixes( entitySuffixSeed++, 1 )[0];
+	}
+
+	private String generateCollectionSuffix() {
+		return collectionSuffixSeed++ + "__";
+	}
+
+	private void processReturn(NativeSQLQueryReturn rtn) {
+		if ( rtn instanceof NativeSQLQueryScalarReturn ) {
+			processScalarReturn( ( NativeSQLQueryScalarReturn ) rtn );
+		}
+		else if ( rtn instanceof NativeSQLQueryRootReturn ) {
+			processRootReturn( ( NativeSQLQueryRootReturn ) rtn );
+		}
+		else if ( rtn instanceof NativeSQLQueryCollectionReturn ) {
+			processCollectionReturn( ( NativeSQLQueryCollectionReturn ) rtn );
+		}
+		else {
+			processJoinReturn( ( NativeSQLQueryJoinReturn ) rtn );
+		}
+	}
+
+	private void processScalarReturn(NativeSQLQueryScalarReturn typeReturn) {
+//		scalarColumnAliases.add( typeReturn.getColumnAlias() );
+//		scalarTypes.add( typeReturn.getType() );
+	}
+
+	private void processRootReturn(NativeSQLQueryRootReturn rootReturn) {
+		if ( alias2Persister.containsKey( rootReturn.getAlias() ) ) {
+			// already been processed...
+			return;
+		}
+
+		SQLLoadable persister = getSQLLoadable( rootReturn.getReturnEntityName() );
+		addPersister( rootReturn.getAlias(), rootReturn.getPropertyResultsMap(), persister );
+	}
+
+	/**
+	 * @param propertyResult
+	 * @param persister
+	 */
+	private void addPersister(String alias, Map propertyResult, SQLLoadable persister) {
+		alias2Persister.put( alias, persister );
+		String suffix = generateEntitySuffix();
+        LOG.trace("Mapping alias [" + alias + "] to entity-suffix [" + suffix + "]");
+		alias2Suffix.put( alias, suffix );
+		entityPropertyResultMaps.put( alias, propertyResult );
+	}
+
+	private void addCollection(String role, String alias, Map propertyResults) {
+		SQLLoadableCollection collectionPersister = ( SQLLoadableCollection ) factory.getCollectionPersister( role );
+		alias2CollectionPersister.put( alias, collectionPersister );
+		String suffix = generateCollectionSuffix();
+        LOG.trace("Mapping alias [" + alias + "] to collection-suffix [" + suffix + "]");
+		alias2CollectionSuffix.put( alias, suffix );
+		collectionPropertyResultMaps.put( alias, propertyResults );
+
+		if ( collectionPersister.isOneToMany() || collectionPersister.isManyToMany() ) {
+			SQLLoadable persister = ( SQLLoadable ) collectionPersister.getElementPersister();
+			addPersister( alias, filter( propertyResults ), persister );
+		}
+	}
+
+	private Map filter(Map propertyResults) {
+		Map result = new HashMap( propertyResults.size() );
+
+		String keyPrefix = "element.";
+
+		Iterator iter = propertyResults.entrySet().iterator();
+		while ( iter.hasNext() ) {
+			Map.Entry element = ( Map.Entry ) iter.next();
+			String path = ( String ) element.getKey();
+			if ( path.startsWith( keyPrefix ) ) {
+				result.put( path.substring( keyPrefix.length() ), element.getValue() );
+			}
+		}
+
+		return result;
+	}
+
+	private void processCollectionReturn(NativeSQLQueryCollectionReturn collectionReturn) {
+		// we are initializing an owned collection
+		//collectionOwners.add( new Integer(-1) );
+//		collectionOwnerAliases.add( null );
+		String role = collectionReturn.getOwnerEntityName() + '.' + collectionReturn.getOwnerProperty();
+		addCollection(
+				role,
+				collectionReturn.getAlias(),
+				collectionReturn.getPropertyResultsMap()
+		);
+	}
+
+	private void processJoinReturn(NativeSQLQueryJoinReturn fetchReturn) {
+		String alias = fetchReturn.getAlias();
+//		if ( alias2Persister.containsKey( alias ) || collectionAliases.contains( alias ) ) {
+		if ( alias2Persister.containsKey( alias ) || alias2CollectionPersister.containsKey( alias ) ) {
+			// already been processed...
+			return;
+		}
+
+		String ownerAlias = fetchReturn.getOwnerAlias();
+
+		// Make sure the owner alias is known...
+		if ( !alias2Return.containsKey( ownerAlias ) ) {
+			throw new HibernateException( "Owner alias [" + ownerAlias + "] is unknown for alias [" + alias + "]" );
+		}
+
+		// If this return's alias has not been processed yet, do so b4 further processing of this return
+		if ( !alias2Persister.containsKey( ownerAlias ) ) {
+			NativeSQLQueryNonScalarReturn ownerReturn = ( NativeSQLQueryNonScalarReturn ) alias2Return.get(ownerAlias);
+			processReturn( ownerReturn );
+		}
+
+		SQLLoadable ownerPersister = ( SQLLoadable ) alias2Persister.get( ownerAlias );
+		Type returnType = ownerPersister.getPropertyType( fetchReturn.getOwnerProperty() );
+
+		if ( returnType.isCollectionType() ) {
+			String role = ownerPersister.getEntityName() + '.' + fetchReturn.getOwnerProperty();
+			addCollection( role, alias, fetchReturn.getPropertyResultsMap() );
+//			collectionOwnerAliases.add( ownerAlias );
+		}
+		else if ( returnType.isEntityType() ) {
+			EntityType eType = ( EntityType ) returnType;
+			String returnEntityName = eType.getAssociatedEntityName();
+			SQLLoadable persister = getSQLLoadable( returnEntityName );
+			addPersister( alias, fetchReturn.getPropertyResultsMap(), persister );
+		}
+
+	}
+
+//	public List getCollectionAliases() {
+//		return collectionAliases;
+//	}
+//
+//	/*public List getCollectionOwners() {
+//		return collectionOwners;
+//	}*/
+//
+//	public List getCollectionOwnerAliases() {
+//		return collectionOwnerAliases;
+//	}
+//
+//	public List getCollectionPersisters() {
+//		return collectionPersisters;
+//	}
+//
+//	public Map getAlias2Persister() {
+//		return alias2Persister;
+//	}
+//
+//	/*public boolean isCollectionInitializer() {
+//		return isCollectionInitializer;
+//	}*/
+//
+////	public List getPersisters() {
+////		return persisters;
+////	}
+//
+//	public Map getAlias2OwnerAlias() {
+//		return alias2OwnerAlias;
+//	}
+//
+//	public List getScalarTypes() {
+//		return scalarTypes;
+//	}
+//	public List getScalarColumnAliases() {
+//		return scalarColumnAliases;
+//	}
+//
+//	public List getPropertyResults() {
+//		return propertyResults;
+//	}
+//
+//	public List getCollectionPropertyResults() {
+//		return collectionResults;
+//	}
+//
+//
+//	public Map getAlias2Return() {
+//		return alias2Return;
+//	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/CollectionElementLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/CollectionElementLoader.java
index 9ddcf75565..63cbf23e90 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/CollectionElementLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/CollectionElementLoader.java
@@ -1,132 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.entity;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.List;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.JoinWalker;
 import org.hibernate.loader.OuterJoinLoader;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  *
  *
  * @author Gavin King
  */
 public class CollectionElementLoader extends OuterJoinLoader {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        CollectionElementLoader.class.getName());
 
 	private final OuterJoinLoadable persister;
 	private final Type keyType;
 	private final Type indexType;
 	private final String entityName;
 
 	public CollectionElementLoader(
 			QueryableCollection collectionPersister,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		super( factory, loadQueryInfluencers );
 
 		this.keyType = collectionPersister.getKeyType();
 		this.indexType = collectionPersister.getIndexType();
 		this.persister = (OuterJoinLoadable) collectionPersister.getElementPersister();
 		this.entityName = persister.getEntityName();
 
 		JoinWalker walker = new EntityJoinWalker(
 				persister, 
 				ArrayHelper.join(
 						collectionPersister.getKeyColumnNames(),
 						collectionPersister.getIndexColumnNames()
 				),
 				1, 
 				LockMode.NONE, 
 				factory, 
 				loadQueryInfluencers
 			);
 		initFromWalker( walker );
 
 		postInstantiate();
 
         LOG.debugf("Static select for entity %s: %s", entityName, getSQLString());
 
 	}
 
 	public Object loadElement(SessionImplementor session, Object key, Object index)
 	throws HibernateException {
 
 		List list = loadEntity(
 				session,
 				key,
 				index,
 				keyType,
 				indexType,
 				persister
 			);
 
 		if ( list.size()==1 ) {
 			return list.get(0);
 		}
 		else if ( list.size()==0 ) {
 			return null;
 		}
 		else {
 			if ( getCollectionOwners()!=null ) {
 				return list.get(0);
 			}
 			else {
 				throw new HibernateException("More than one row was found");
 			}
 		}
 
 	}
 
 	@Override
     protected Object getResultColumnOrRow(
 		Object[] row,
 		ResultTransformer transformer,
 		ResultSet rs, SessionImplementor session)
 	throws SQLException, HibernateException {
 		return row[row.length-1];
 	}
 
 	@Override
     protected boolean isSingleRowLoader() {
 		return true;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java b/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
index 5396a916fd..475ffdcd8b 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
@@ -1,347 +1,348 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 import java.io.Serializable;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.engine.Mapping;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.SingletonIterator;
 import org.jboss.logging.Logger;
 
 /**
  * The root class of an inheritance hierarchy
  * @author Gavin King
  */
 public class RootClass extends PersistentClass implements TableOwner {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, RootClass.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, RootClass.class.getName());
 
 	public static final String DEFAULT_IDENTIFIER_COLUMN_NAME = "id";
 	public static final String DEFAULT_DISCRIMINATOR_COLUMN_NAME = "class";
 
 	private Property identifierProperty; //may be final
 	private KeyValue identifier; //may be final
 	private Property version; //may be final
 	private boolean polymorphic;
 	private String cacheConcurrencyStrategy;
 	private String cacheRegionName;
 	private boolean lazyPropertiesCacheable = true;
 	private Value discriminator; //may be final
 	private boolean mutable = true;
 	private boolean embeddedIdentifier = false; // may be final
 	private boolean explicitPolymorphism;
 	private Class entityPersisterClass;
 	private boolean forceDiscriminator = false;
 	private String where;
 	private Table table;
 	private boolean discriminatorInsertable = true;
 	private int nextSubclassId = 0;
 	private Property declaredIdentifierProperty;
 	private Property declaredVersion;
 
 	@Override
     int nextSubclassId() {
 		return ++nextSubclassId;
 	}
 
 	@Override
     public int getSubclassId() {
 		return 0;
 	}
 
 	public void setTable(Table table) {
 		this.table=table;
 	}
 	@Override
     public Table getTable() {
 		return table;
 	}
 
 	@Override
     public Property getIdentifierProperty() {
 		return identifierProperty;
 	}
 
 	@Override
     public Property getDeclaredIdentifierProperty() {
 		return declaredIdentifierProperty;
 	}
 
 	public void setDeclaredIdentifierProperty(Property declaredIdentifierProperty) {
 		this.declaredIdentifierProperty = declaredIdentifierProperty;
 	}
 
 	@Override
     public KeyValue getIdentifier() {
 		return identifier;
 	}
 	@Override
     public boolean hasIdentifierProperty() {
 		return identifierProperty!=null;
 	}
 
 	@Override
     public Value getDiscriminator() {
 		return discriminator;
 	}
 
 	@Override
     public boolean isInherited() {
 		return false;
 	}
 	@Override
     public boolean isPolymorphic() {
 		return polymorphic;
 	}
 
 	public void setPolymorphic(boolean polymorphic) {
 		this.polymorphic = polymorphic;
 	}
 
 	@Override
     public RootClass getRootClass() {
 		return this;
 	}
 
 	@Override
     public Iterator getPropertyClosureIterator() {
 		return getPropertyIterator();
 	}
 	@Override
     public Iterator getTableClosureIterator() {
 		return new SingletonIterator( getTable() );
 	}
 	@Override
     public Iterator getKeyClosureIterator() {
 		return new SingletonIterator( getKey() );
 	}
 
 	@Override
     public void addSubclass(Subclass subclass) throws MappingException {
 		super.addSubclass(subclass);
 		setPolymorphic(true);
 	}
 
 	@Override
     public boolean isExplicitPolymorphism() {
 		return explicitPolymorphism;
 	}
 
 	@Override
     public Property getVersion() {
 		return version;
 	}
 
 	@Override
     public Property getDeclaredVersion() {
 		return declaredVersion;
 	}
 
 	public void setDeclaredVersion(Property declaredVersion) {
 		this.declaredVersion = declaredVersion;
 	}
 
 	public void setVersion(Property version) {
 		this.version = version;
 	}
 	@Override
     public boolean isVersioned() {
 		return version!=null;
 	}
 
 	@Override
     public boolean isMutable() {
 		return mutable;
 	}
 	@Override
     public boolean hasEmbeddedIdentifier() {
 		return embeddedIdentifier;
 	}
 
 	@Override
     public Class getEntityPersisterClass() {
 		return entityPersisterClass;
 	}
 
 	@Override
     public Table getRootTable() {
 		return getTable();
 	}
 
 	@Override
     public void setEntityPersisterClass(Class persister) {
 		this.entityPersisterClass = persister;
 	}
 
 	@Override
     public PersistentClass getSuperclass() {
 		return null;
 	}
 
 	@Override
     public KeyValue getKey() {
 		return getIdentifier();
 	}
 
 	public void setDiscriminator(Value discriminator) {
 		this.discriminator = discriminator;
 	}
 
 	public void setEmbeddedIdentifier(boolean embeddedIdentifier) {
 		this.embeddedIdentifier = embeddedIdentifier;
 	}
 
 	public void setExplicitPolymorphism(boolean explicitPolymorphism) {
 		this.explicitPolymorphism = explicitPolymorphism;
 	}
 
 	public void setIdentifier(KeyValue identifier) {
 		this.identifier = identifier;
 	}
 
 	public void setIdentifierProperty(Property identifierProperty) {
 		this.identifierProperty = identifierProperty;
 		identifierProperty.setPersistentClass(this);
 
 	}
 
 	public void setMutable(boolean mutable) {
 		this.mutable = mutable;
 	}
 
 	@Override
     public boolean isDiscriminatorInsertable() {
 		return discriminatorInsertable;
 	}
 
 	public void setDiscriminatorInsertable(boolean insertable) {
 		this.discriminatorInsertable = insertable;
 	}
 
 	@Override
     public boolean isForceDiscriminator() {
 		return forceDiscriminator;
 	}
 
 	public void setForceDiscriminator(boolean forceDiscriminator) {
 		this.forceDiscriminator = forceDiscriminator;
 	}
 
 	@Override
     public String getWhere() {
 		return where;
 	}
 
 	public void setWhere(String string) {
 		where = string;
 	}
 
 	@Override
     public void validate(Mapping mapping) throws MappingException {
 		super.validate(mapping);
 		if ( !getIdentifier().isValid(mapping) ) {
 			throw new MappingException(
 				"identifier mapping has wrong number of columns: " +
 				getEntityName() +
 				" type: " +
 				getIdentifier().getType().getName()
 			);
 		}
 		checkCompositeIdentifier();
 	}
 
 	private void checkCompositeIdentifier() {
 		if ( getIdentifier() instanceof Component ) {
 			Component id = (Component) getIdentifier();
 			if ( !id.isDynamic() ) {
 				Class idClass = id.getComponentClass();
                 if (idClass != null && !ReflectHelper.overridesEquals(idClass)) LOG.compositeIdClassDoesNotOverrideEquals(id.getComponentClass().getName());
                 if (!ReflectHelper.overridesHashCode(idClass)) LOG.compositeIdClassDoesNotOverrideHashCode(id.getComponentClass().getName());
                 if (!Serializable.class.isAssignableFrom(idClass)) throw new MappingException(
                                                                                               "Composite-id class must implement Serializable: "
                                                                                               + id.getComponentClass().getName());
 			}
 		}
 	}
 
 	@Override
     public String getCacheConcurrencyStrategy() {
 		return cacheConcurrencyStrategy;
 	}
 
 	public void setCacheConcurrencyStrategy(String cacheConcurrencyStrategy) {
 		this.cacheConcurrencyStrategy = cacheConcurrencyStrategy;
 	}
 
 	public String getCacheRegionName() {
 		return cacheRegionName==null ? getEntityName() : cacheRegionName;
 	}
 	public void setCacheRegionName(String cacheRegionName) {
 		this.cacheRegionName = cacheRegionName;
 	}
 
 	@Override
     public boolean isLazyPropertiesCacheable() {
 		return lazyPropertiesCacheable;
 	}
 
 	public void setLazyPropertiesCacheable(boolean lazyPropertiesCacheable) {
 		this.lazyPropertiesCacheable = lazyPropertiesCacheable;
 	}
 
 	@Override
     public boolean isJoinedSubclass() {
 		return false;
 	}
 
 	@Override
     public java.util.Set getSynchronizedTables() {
 		return synchronizedTables;
 	}
 
 	public Set getIdentityTables() {
 		Set tables = new HashSet();
 		Iterator iter = getSubclassClosureIterator();
 		while ( iter.hasNext() ) {
 			PersistentClass clazz = (PersistentClass) iter.next();
 			if ( clazz.isAbstract() == null || !clazz.isAbstract().booleanValue() ) tables.add( clazz.getIdentityTable() );
 		}
 		return tables;
 	}
 
 	@Override
     public Object accept(PersistentClassVisitor mv) {
 		return mv.accept(this);
 	}
 
 	@Override
     public int getOptimisticLockMode() {
 		return optimisticLockMode;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/metamodel/binding/EntityIdentifier.java b/hibernate-core/src/main/java/org/hibernate/metamodel/binding/EntityIdentifier.java
index 5af9b17264..57cefd3e8d 100644
--- a/hibernate-core/src/main/java/org/hibernate/metamodel/binding/EntityIdentifier.java
+++ b/hibernate-core/src/main/java/org/hibernate/metamodel/binding/EntityIdentifier.java
@@ -1,61 +1,62 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.metamodel.binding;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
 public class EntityIdentifier {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, EntityIdentifier.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityIdentifier.class.getName());
 
 	private final EntityBinding entityBinding;
 	private AttributeBinding attributeBinding;
 	// todo : generator, mappers, etc
 
 	/**
 	 * Create an identifier
 	 * @param entityBinding
 	 */
 	public EntityIdentifier(EntityBinding entityBinding) {
 		this.entityBinding = entityBinding;
 	}
 
 	public AttributeBinding getValueBinding() {
 		return attributeBinding;
 	}
 
 	public void setValueBinding(AttributeBinding attributeBinding) {
 		if ( this.attributeBinding != null ) {
 			// todo : error?  or just log?  for now just log
 			LOG.entityIdentifierValueBindingExists( entityBinding.getEntity().getName() );
 		}
 		this.attributeBinding = attributeBinding;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/metamodel/relational/AbstractSimpleValue.java b/hibernate-core/src/main/java/org/hibernate/metamodel/relational/AbstractSimpleValue.java
index f5fa60207c..99d2b9a024 100644
--- a/hibernate-core/src/main/java/org/hibernate/metamodel/relational/AbstractSimpleValue.java
+++ b/hibernate-core/src/main/java/org/hibernate/metamodel/relational/AbstractSimpleValue.java
@@ -1,78 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.metamodel.relational;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.metamodel.ValidationException;
 import org.jboss.logging.Logger;
 
 /**
  * Basic support for {@link SimpleValue} implementations.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractSimpleValue implements SimpleValue {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, AbstractSimpleValue.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, AbstractSimpleValue.class.getName());
 
 	private final TableSpecification table;
 	private final int position;
 	private Datatype datatype;
 
 	protected AbstractSimpleValue(TableSpecification table, int position) {
 		this.table = table;
 		this.position = position;
 	}
 
 	@Override
 	public TableSpecification getTable() {
 		return table;
 	}
 
 	public int getPosition() {
 		return position;
 	}
 
 	@Override
 	public Datatype getDatatype() {
 		return datatype;
 	}
 
 	@Override
 	public void setDatatype(Datatype datatype) {
 		LOG.debugf( "setting datatype for column %s : %s", toLoggableString(), datatype );
 		if ( this.datatype != null && ! this.datatype.equals( datatype ) ) {
 			LOG.debugf( "overriding previous datatype : %s", this.datatype );
 		}
 		this.datatype = datatype;
 	}
 
 	@Override
 	public void validateJdbcTypes(JdbcCodes typeCodes) {
 		// todo : better compatibility testing...
 		if ( datatype.getTypeCode() != typeCodes.nextJdbcCde() ) {
 			throw new ValidationException( "Mismatched types" );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/metamodel/relational/ForeignKey.java b/hibernate-core/src/main/java/org/hibernate/metamodel/relational/ForeignKey.java
index 3a890707f6..2f1b770e80 100644
--- a/hibernate-core/src/main/java/org/hibernate/metamodel/relational/ForeignKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/metamodel/relational/ForeignKey.java
@@ -1,127 +1,128 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.metamodel.relational;
 
 import java.util.ArrayList;
 import java.util.List;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 import org.jboss.logging.Logger.Level;
 
 /**
  * Models the notion of a foreign key.
  * <p/>
  * Note that this need not mean a physical foreign key; we just mean a relationship between 2 table
  * specifications.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class ForeignKey extends AbstractConstraint implements Constraint, Exportable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, AbstractConstraint.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, AbstractConstraint.class.getName());
 
 	private final TableSpecification targetTable;
 	private List<Column> targetColumns;
 	private ReferentialAction deleteRule = ReferentialAction.NO_ACTION;
 	public ReferentialAction updateRule = ReferentialAction.NO_ACTION;
 
 	protected ForeignKey(TableSpecification sourceTable, TableSpecification targetTable, String name) {
 		super( sourceTable, name );
 		this.targetTable = targetTable;
 	}
 
 	protected ForeignKey(TableSpecification sourceTable, TableSpecification targetTable) {
 		this( sourceTable, targetTable, null );
 	}
 
 	public TableSpecification getSourceTable() {
 		return getTable();
 	}
 
 	public TableSpecification getTargetTable() {
 		return targetTable;
 	}
 
 	public Iterable<Column> getSourceColumns() {
 		return getColumns();
 	}
 
 	public Iterable<Column> getTargetColumns() {
 		return targetColumns == null
 				? getTargetTable().getPrimaryKey().getColumns()
 				: targetColumns;
 	}
 
 	@Override
 	public void addColumn(Column column) {
 		addColumnMapping( column, null );
 	}
 
 	public void addColumnMapping(Column sourceColumn, Column targetColumn) {
 		if ( targetColumn == null ) {
 			if ( targetColumns != null ) {
-				if (LOG.isEnabled(Level.WARN)) LOG.attemptToMapColumnToNoTargetColumn(sourceColumn.toLoggableString(), getName());
+				if (LOG.isEnabled( Level.WARN )) LOG.attemptToMapColumnToNoTargetColumn(sourceColumn.toLoggableString(), getName());
 			}
 		}
 		else {
 			if ( targetColumns == null ) {
 				if (!internalColumnAccess().isEmpty()) LOG.valueMappingMismatch(getTable().toLoggableString(), getName(), sourceColumn.toLoggableString());
 				targetColumns = new ArrayList<Column>();
 			}
 			targetColumns.add( targetColumn );
 		}
 		internalColumnAccess().add( sourceColumn );
 	}
 
 	@Override
 	public String getExportIdentifier() {
 		return getSourceTable().getLoggableValueQualifier() + ".FK-" + getName();
 	}
 
 	public ReferentialAction getDeleteRule() {
 		return deleteRule;
 	}
 
 	public void setDeleteRule(ReferentialAction deleteRule) {
 		this.deleteRule = deleteRule;
 	}
 
 	public ReferentialAction getUpdateRule() {
 		return updateRule;
 	}
 
 	public void setUpdateRule(ReferentialAction updateRule) {
 		this.updateRule = updateRule;
 	}
 
 	public static enum ReferentialAction {
 		NO_ACTION,
 		CASCADE,
 		SET_NULL,
 		SET_DEFAULT,
 		RESTRICT
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/metamodel/source/ExtendsQueue.java b/hibernate-core/src/main/java/org/hibernate/metamodel/source/ExtendsQueue.java
index 27596144ea..3b3c719147 100644
--- a/hibernate-core/src/main/java/org/hibernate/metamodel/source/ExtendsQueue.java
+++ b/hibernate-core/src/main/java/org/hibernate/metamodel/source/ExtendsQueue.java
@@ -1,98 +1,98 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.metamodel.source;
 
 import java.io.Serializable;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.ExtendsQueueEntry;
 import org.hibernate.metamodel.source.hbm.HbmHelper;
 import org.jboss.logging.Logger;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
 public class ExtendsQueue implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ExtendsQueue.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ExtendsQueue.class.getName());
 
 	private final Metadata metadata;
 	private Set<ExtendsQueueEntry> extendsQueue = new HashSet<ExtendsQueueEntry>();
 
 	public ExtendsQueue(Metadata metadata) {
 		this.metadata = metadata;
 	}
 
 	public void add(ExtendsQueueEntry extendsQueueEntry) {
 		extendsQueue.add( extendsQueueEntry );
 	}
 
 	public int processExtendsQueue() {
 		LOG.debug( "processing extends queue" );
 		int added = 0;
 		ExtendsQueueEntry extendsQueueEntry = findPossibleExtends();
 		while ( extendsQueueEntry != null ) {
 			metadata.getMetadataSourceQueue().processHbmXml( extendsQueueEntry.getMetadataXml(), extendsQueueEntry.getEntityNames() );
 			extendsQueueEntry = findPossibleExtends();
 		}
 
 		if ( extendsQueue.size() > 0 ) {
 			Iterator iterator = extendsQueue.iterator();
 			StringBuffer buf = new StringBuffer( "Following super classes referenced in extends not found: " );
 			while ( iterator.hasNext() ) {
 				final ExtendsQueueEntry entry = ( ExtendsQueueEntry ) iterator.next();
 				buf.append( entry.getExplicitName() );
 				if ( entry.getMappingPackage() != null ) {
 					buf.append( "[" ).append( entry.getMappingPackage() ).append( "]" );
 				}
 				if ( iterator.hasNext() ) {
 					buf.append( "," );
 				}
 			}
 			throw new MappingException( buf.toString() );
 		}
 
 		return added;
 	}
 
 	protected ExtendsQueueEntry findPossibleExtends() {
 		Iterator<ExtendsQueueEntry> itr = extendsQueue.iterator();
 		while ( itr.hasNext() ) {
 			final ExtendsQueueEntry entry = itr.next();
 			boolean found = metadata.getEntityBinding( entry.getExplicitName() ) == null
 					&& metadata.getEntityBinding( HbmHelper.getClassName( entry.getExplicitName(), entry.getMappingPackage() ) ) != null;
 			if ( found ) {
 				itr.remove();
 				return entry;
 			}
 		}
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/metamodel/source/Metadata.java b/hibernate-core/src/main/java/org/hibernate/metamodel/source/Metadata.java
index 102b717bf5..6a9b819a86 100644
--- a/hibernate-core/src/main/java/org/hibernate/metamodel/source/Metadata.java
+++ b/hibernate-core/src/main/java/org/hibernate/metamodel/source/Metadata.java
@@ -1,189 +1,190 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.metamodel.source;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.DuplicateMappingException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.annotations.common.reflection.MetadataProvider;
 import org.hibernate.annotations.common.reflection.MetadataProviderInjector;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.java.JavaReflectionManager;
 import org.hibernate.cfg.EJB3NamingStrategy;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.annotations.reflection.JPAMetadataProvider;
 import org.hibernate.mapping.FetchProfile;
 import org.hibernate.mapping.MetadataSource;
 import org.hibernate.metamodel.binding.EntityBinding;
 import org.hibernate.metamodel.binding.PluralAttributeBinding;
 import org.hibernate.metamodel.relational.Database;
 import org.hibernate.metamodel.source.hbm.HibernateXmlBinder;
+
 import org.jboss.logging.Logger;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
 public class Metadata implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Metadata.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Metadata.class.getName());
 
 	private final HibernateXmlBinder hibernateXmlBinder = new HibernateXmlBinder( this );
 	private final ExtendsQueue extendsQueue = new ExtendsQueue( this );
 	private final MetadataSourceQueue metadataSourceQueue = new MetadataSourceQueue( this );
 
 	private transient ReflectionManager reflectionManager = createReflectionManager();
 
 	public HibernateXmlBinder getHibernateXmlBinder() {
 		return hibernateXmlBinder;
 	}
 
 	public ExtendsQueue getExtendsQueue() {
 		return extendsQueue;
 	}
 
 	public MetadataSourceQueue getMetadataSourceQueue() {
 		return metadataSourceQueue;
 	}
 
 	public ReflectionManager getReflectionManager() {
 		return reflectionManager;
 	}
 
 	public void setReflectionManager(ReflectionManager reflectionManager) {
 		this.reflectionManager = reflectionManager;
 	}
 
 	private ReflectionManager createReflectionManager() {
 		return createReflectionManager( new JPAMetadataProvider() );
 	}
 
 	private ReflectionManager createReflectionManager(MetadataProvider metadataProvider) {
 		ReflectionManager reflectionManager = new JavaReflectionManager();
 		( (MetadataProviderInjector) reflectionManager ).setMetadataProvider( metadataProvider );
 		return reflectionManager;
 	}
 
 	private final Database database = new Database();
 
 	public Database getDatabase() {
 		return database;
 	}
 
 	private NamingStrategy namingStrategy = EJB3NamingStrategy.INSTANCE;
 
 	public NamingStrategy getNamingStrategy() {
 		return namingStrategy;
 	}
 
 	public void setNamingStrategy(NamingStrategy namingStrategy) {
 		this.namingStrategy = namingStrategy;
 	}
 
 	private Map<String,EntityBinding> entityBindingMap = new HashMap<String, EntityBinding>();
 
 	public EntityBinding getEntityBinding(String entityName) {
 		return entityBindingMap.get( entityName );
 	}
 
 	public Iterable<EntityBinding> getEntityBindings() {
 		return entityBindingMap.values();
 	}
 
 	public void addEntity(EntityBinding entityBinding) {
 		final String entityName = entityBinding.getEntity().getName();
 		if ( entityBindingMap.containsKey( entityName ) ) {
 			throw new DuplicateMappingException( DuplicateMappingException.Type.ENTITY, entityName );
 		}
 		entityBindingMap.put( entityName, entityBinding );
 	}
 
 	private Map<String,PluralAttributeBinding> collectionBindingMap = new HashMap<String, PluralAttributeBinding>();
 
 	public PluralAttributeBinding getCollection(String collectionRole) {
 		return collectionBindingMap.get( collectionRole );
 	}
 
 	public Iterable<PluralAttributeBinding> getCollections() {
 		return collectionBindingMap.values();
 	}
 
 	public void addCollection(PluralAttributeBinding pluralAttributeBinding) {
 		final String owningEntityName = pluralAttributeBinding.getEntityBinding().getEntity().getName();
 		final String attributeName = pluralAttributeBinding.getAttribute().getName();
 		final String collectionRole = owningEntityName + '.' + attributeName;
 		if ( collectionBindingMap.containsKey( collectionRole ) ) {
 			throw new DuplicateMappingException( DuplicateMappingException.Type.ENTITY, collectionRole );
 		}
 		collectionBindingMap.put( collectionRole, pluralAttributeBinding );
 	}
 
 	private Map<String,String> imports;
 
 	public void addImport(String importName, String entityName) {
 		if ( imports == null ) {
 			imports = new HashMap<String, String>();
 		}
 		LOG.tracef( "Import: %s -> %s", importName, entityName );
 		String old = imports.put( importName, entityName );
 		if ( old != null ) {
 			LOG.debugf( "import name [%s] overrode previous [%s]", importName, old  );
 		}
 	}
 
 	private Map<String,FetchProfile> fetchProfiles = new HashMap<String, FetchProfile>();
 
 	public Iterable<FetchProfile> getFetchProfiles() {
 		return fetchProfiles.values();
 	}
 
 	public FetchProfile findOrCreateFetchProfile(String profileName, MetadataSource source) {
 		FetchProfile profile = fetchProfiles.get( profileName );
 		if ( profile == null ) {
 			profile = new FetchProfile( profileName, source );
 			fetchProfiles.put( profileName, profile );
 		}
 		return profile;
 	}
 
 	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		//we need  reflectionManager before reading the other components (MetadataSourceQueue in particular)
 		final MetadataProvider metadataProvider = (MetadataProvider) ois.readObject();
 		this.reflectionManager = createReflectionManager( metadataProvider );
 		ois.defaultReadObject();
 	}
 
 	private void writeObject(java.io.ObjectOutputStream out) throws IOException {
 		//We write MetadataProvider first as we need  reflectionManager before reading the other components
 		final MetadataProvider metadataProvider = ( ( MetadataProviderInjector ) reflectionManager ).getMetadataProvider();
 		out.writeObject( metadataProvider );
 		out.defaultWriteObject();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/metamodel/source/MetadataSourceQueue.java b/hibernate-core/src/main/java/org/hibernate/metamodel/source/MetadataSourceQueue.java
index 432cac3ac3..ae389e426c 100644
--- a/hibernate-core/src/main/java/org/hibernate/metamodel/source/MetadataSourceQueue.java
+++ b/hibernate-core/src/main/java/org/hibernate/metamodel/source/MetadataSourceQueue.java
@@ -1,278 +1,278 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.metamodel.source;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.Entity;
 
 import org.dom4j.Attribute;
 import org.dom4j.Document;
 import org.dom4j.Element;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.InvalidMappingException;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.cfg.MetadataSourceType;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.internal.util.xml.XmlDocument;
 import org.jboss.logging.Logger;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
 public class MetadataSourceQueue implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, MetadataSourceQueue.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, MetadataSourceQueue.class.getName());
 
 	private final Metadata metadata;
 
 	private LinkedHashMap<XmlDocument, Set<String>> hbmMetadataToEntityNamesMap
 			= new LinkedHashMap<XmlDocument, Set<String>>();
 	private Map<String, XmlDocument> hbmMetadataByEntityNameXRef = new HashMap<String, XmlDocument>();
 
 	//XClass are not serializable by default
 	private transient List<XClass> annotatedClasses = new ArrayList<XClass>();
 	//only used during the secondPhaseCompile pass, hence does not need to be serialized
 	private transient Map<String, XClass> annotatedClassesByEntityNameMap = new HashMap<String, XClass>();
 
 	public MetadataSourceQueue(Metadata metadata) {
 		this.metadata = metadata;
 	}
 
 	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		ois.defaultReadObject();
 		annotatedClassesByEntityNameMap = new HashMap<String, XClass>();
 
 		//build back annotatedClasses
 		@SuppressWarnings("unchecked")
 		List<Class> serializableAnnotatedClasses = (List<Class>) ois.readObject();
 		annotatedClasses = new ArrayList<XClass>( serializableAnnotatedClasses.size() );
 		for ( Class clazz : serializableAnnotatedClasses ) {
 			annotatedClasses.add( metadata.getReflectionManager().toXClass( clazz ) );
 		}
 	}
 
 	private void writeObject(java.io.ObjectOutputStream out) throws IOException {
 		out.defaultWriteObject();
 		List<Class> serializableAnnotatedClasses = new ArrayList<Class>( annotatedClasses.size() );
 		for ( XClass xClass : annotatedClasses ) {
 			serializableAnnotatedClasses.add( metadata.getReflectionManager().toClass( xClass ) );
 		}
 		out.writeObject( serializableAnnotatedClasses );
 	}
 
 	public void add(XmlDocument metadataXml) {
 		final Document document = metadataXml.getDocumentTree();
 		final Element hmNode = document.getRootElement();
 		Attribute packNode = hmNode.attribute( "package" );
 		String defaultPackage = packNode != null ? packNode.getValue() : "";
 		Set<String> entityNames = new HashSet<String>();
 		findClassNames( defaultPackage, hmNode, entityNames );
 		for ( String entity : entityNames ) {
 			hbmMetadataByEntityNameXRef.put( entity, metadataXml );
 		}
 		this.hbmMetadataToEntityNamesMap.put( metadataXml, entityNames );
 	}
 
 	private void findClassNames(String defaultPackage, Element startNode, Set<String> names) {
 		// if we have some extends we need to check if those classes possibly could be inside the
 		// same hbm.xml file...
 		Iterator[] classes = new Iterator[4];
 		classes[0] = startNode.elementIterator( "class" );
 		classes[1] = startNode.elementIterator( "subclass" );
 		classes[2] = startNode.elementIterator( "joined-subclass" );
 		classes[3] = startNode.elementIterator( "union-subclass" );
 
 		Iterator classIterator = new JoinedIterator( classes );
 		while ( classIterator.hasNext() ) {
 			Element element = (Element) classIterator.next();
 			String entityName = element.attributeValue( "entity-name" );
 			if ( entityName == null ) {
 				entityName = getClassName( element.attribute( "name" ), defaultPackage );
 			}
 			names.add( entityName );
 			findClassNames( defaultPackage, element, names );
 		}
 	}
 
 	private String getClassName(Attribute name, String defaultPackage) {
 		if ( name == null ) {
 			return null;
 		}
 		String unqualifiedName = name.getValue();
 		if ( unqualifiedName == null ) {
 			return null;
 		}
 		if ( unqualifiedName.indexOf( '.' ) < 0 && defaultPackage != null ) {
 			return defaultPackage + '.' + unqualifiedName;
 		}
 		return unqualifiedName;
 	}
 
 	public void add(XClass annotatedClass) {
 		annotatedClasses.add( annotatedClass );
 	}
 
 	protected void syncAnnotatedClasses() {
 		final Iterator<XClass> itr = annotatedClasses.iterator();
 		while ( itr.hasNext() ) {
 			final XClass annotatedClass = itr.next();
 			if ( annotatedClass.isAnnotationPresent( Entity.class ) ) {
 				annotatedClassesByEntityNameMap.put( annotatedClass.getName(), annotatedClass );
 				continue;
 			}
 
 			if ( !annotatedClass.isAnnotationPresent( javax.persistence.MappedSuperclass.class ) ) {
 				itr.remove();
 			}
 		}
 	}
 
 	protected void processMetadata(List<MetadataSourceType> order) {
 		syncAnnotatedClasses();
 
 		for ( MetadataSourceType type : order ) {
 			if ( MetadataSourceType.HBM.equals( type ) ) {
 				processHbmXmlQueue();
 			}
 			else if ( MetadataSourceType.CLASS.equals( type ) ) {
 				processAnnotatedClassesQueue();
 			}
 		}
 	}
 
 	private void processHbmXmlQueue() {
 		LOG.debug( "Processing hbm.xml files" );
 		for ( Map.Entry<XmlDocument, Set<String>> entry : hbmMetadataToEntityNamesMap.entrySet() ) {
 			// Unfortunately we have to create a Mappings instance for each iteration here
 			processHbmXml( entry.getKey(), entry.getValue() );
 		}
 		hbmMetadataToEntityNamesMap.clear();
 		hbmMetadataByEntityNameXRef.clear();
 	}
 
 	public void processHbmXml(XmlDocument metadataXml, Set<String> entityNames) {
 		try {
 			metadata.getHibernateXmlBinder().bindRoot( metadataXml, entityNames );
 		}
 		catch ( MappingException me ) {
 			throw new InvalidMappingException(
 					metadataXml.getOrigin().getType(),
 					metadataXml.getOrigin().getName(),
 					me
 			);
 		}
 
 		for ( String entityName : entityNames ) {
 			if ( annotatedClassesByEntityNameMap.containsKey( entityName ) ) {
 				annotatedClasses.remove( annotatedClassesByEntityNameMap.get( entityName ) );
 				annotatedClassesByEntityNameMap.remove( entityName );
 			}
 		}
 	}
 
 	private void processAnnotatedClassesQueue() {
 		LOG.debug( "Process annotated classes" );
 		//bind classes in the correct order calculating some inheritance state
 		List<XClass> orderedClasses = orderAndFillHierarchy( annotatedClasses );
 //		Map<XClass, InheritanceState> inheritanceStatePerClass = AnnotationBinder.buildInheritanceStates(
 //				orderedClasses, mappings
 //		);
 
 
 		for ( XClass clazz : orderedClasses ) {
 // todo : replace this with similar non-static code.
 //			AnnotationBinder.bindClass( clazz, inheritanceStatePerClass, mappings );
 
 			final String entityName = clazz.getName();
 			if ( hbmMetadataByEntityNameXRef.containsKey( entityName ) ) {
 				hbmMetadataToEntityNamesMap.remove( hbmMetadataByEntityNameXRef.get( entityName ) );
 				hbmMetadataByEntityNameXRef.remove( entityName );
 			}
 		}
 		annotatedClasses.clear();
 		annotatedClassesByEntityNameMap.clear();
 	}
 
 	private List<XClass> orderAndFillHierarchy(List<XClass> original) {
 		List<XClass> copy = new ArrayList<XClass>( original );
 		insertMappedSuperclasses( original, copy );
 
 		// order the hierarchy
 		List<XClass> workingCopy = new ArrayList<XClass>( copy );
 		List<XClass> newList = new ArrayList<XClass>( copy.size() );
 		while ( workingCopy.size() > 0 ) {
 			XClass clazz = workingCopy.get( 0 );
 			orderHierarchy( workingCopy, newList, copy, clazz );
 		}
 		return newList;
 	}
 
 	private void insertMappedSuperclasses(List<XClass> original, List<XClass> copy) {
 		for ( XClass clazz : original ) {
 			XClass superClass = clazz.getSuperclass();
 			while ( superClass != null
 					&& !metadata.getReflectionManager().equals( superClass, Object.class )
 					&& !copy.contains( superClass ) ) {
 				if ( superClass.isAnnotationPresent( Entity.class )
 						|| superClass.isAnnotationPresent( javax.persistence.MappedSuperclass.class ) ) {
 					copy.add( superClass );
 				}
 				superClass = superClass.getSuperclass();
 			}
 		}
 	}
 
 	private void orderHierarchy(List<XClass> copy, List<XClass> newList, List<XClass> original, XClass clazz) {
 		if ( clazz == null || metadata.getReflectionManager().equals( clazz, Object.class ) ) {
 			return;
 		}
 		//process superclass first
 		orderHierarchy( copy, newList, original, clazz.getSuperclass() );
 		if ( original.contains( clazz ) ) {
 			if ( !newList.contains( clazz ) ) {
 				newList.add( clazz );
 			}
 			copy.remove( clazz );
 		}
 	}
 
 	public boolean isEmpty() {
 		return hbmMetadataToEntityNamesMap.isEmpty() && annotatedClasses.isEmpty();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
index 441d462a0d..d402349119 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
@@ -1,1103 +1,1103 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.entry.CacheEntryStructure;
 import org.hibernate.cache.entry.StructuredCollectionCacheEntry;
 import org.hibernate.cache.entry.StructuredMapCacheEntry;
 import org.hibernate.cache.entry.UnstructuredCacheEntry;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.SubselectFetch;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.impl.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.List;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Table;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.ordering.antlr.ColumnMapper;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 
 /**
  * Base implementation of the <tt>QueryableCollection</tt> interface.
  *
  * @author Gavin King
  * @see BasicCollectionPersister
  * @see OneToManyPersister
  */
 public abstract class AbstractCollectionPersister
 		implements CollectionMetadata, SQLLoadableCollection {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractCollectionPersister.class.getName());
 
     // TODO: encapsulate the protected instance variables!
 
 	private final String role;
 
 	//SQL statements
 	private final String sqlDeleteString;
 	private final String sqlInsertRowString;
 	private final String sqlUpdateRowString;
 	private final String sqlDeleteRowString;
 	private final String sqlSelectSizeString;
 	private final String sqlSelectRowByIndexString;
 	private final String sqlDetectRowByIndexString;
 	private final String sqlDetectRowByElementString;
 
 	protected final String sqlWhereString;
 	private final String sqlOrderByStringTemplate;
 	private final String sqlWhereStringTemplate;
 	private final boolean hasOrder;
 	protected final boolean hasWhere;
 	private final int baseIndex;
 
 	private final String nodeName;
 	private final String elementNodeName;
 	private final String indexNodeName;
 
 	protected final boolean indexContainsFormula;
 	protected final boolean elementIsPureFormula;
 
 	//types
 	private final Type keyType;
 	private final Type indexType;
 	protected final Type elementType;
 	private final Type identifierType;
 
 	//columns
 	protected final String[] keyColumnNames;
 	protected final String[] indexColumnNames;
 	protected final String[] indexFormulaTemplates;
 	protected final String[] indexFormulas;
 	protected final boolean[] indexColumnIsSettable;
 	protected final String[] elementColumnNames;
 	protected final String[] elementColumnWriters;
 	protected final String[] elementColumnReaders;
 	protected final String[] elementColumnReaderTemplates;
 	protected final String[] elementFormulaTemplates;
 	protected final String[] elementFormulas;
 	protected final boolean[] elementColumnIsSettable;
 	protected final boolean[] elementColumnIsInPrimaryKey;
 	protected final String[] indexColumnAliases;
 	protected final String[] elementColumnAliases;
 	protected final String[] keyColumnAliases;
 
 	protected final String identifierColumnName;
 	private final String identifierColumnAlias;
 	//private final String unquotedIdentifierColumnName;
 
 	protected final String qualifiedTableName;
 
 	private final String queryLoaderName;
 
 	private final boolean isPrimitiveArray;
 	private final boolean isArray;
 	protected final boolean hasIndex;
 	protected final boolean hasIdentifier;
 	private final boolean isLazy;
 	private final boolean isExtraLazy;
 	private final boolean isInverse;
 	private final boolean isMutable;
 	private final boolean isVersioned;
 	protected final int batchSize;
 	private final FetchMode fetchMode;
 	private final boolean hasOrphanDelete;
 	private final boolean subselectLoadable;
 
 	//extra information about the element type
 	private final Class elementClass;
 	private final String entityName;
 
 	private final Dialect dialect;
 	private final SqlExceptionHelper sqlExceptionHelper;
 	private final SessionFactoryImplementor factory;
 	private final EntityPersister ownerPersister;
 	private final IdentifierGenerator identifierGenerator;
 	private final PropertyMapping elementPropertyMapping;
 	private final EntityPersister elementPersister;
 	private final CollectionRegionAccessStrategy cacheAccessStrategy;
 	private final CollectionType collectionType;
 	private CollectionInitializer initializer;
 
 	private final CacheEntryStructure cacheEntryStructure;
 
 	// dynamic filters for the collection
 	private final FilterHelper filterHelper;
 
 	// dynamic filters specifically for many-to-many inside the collection
 	private final FilterHelper manyToManyFilterHelper;
 
 	private final String manyToManyWhereString;
 	private final String manyToManyWhereTemplate;
 
 	private final boolean hasManyToManyOrder;
 	private final String manyToManyOrderByTemplate;
 
 	// custom sql
 	private final boolean insertCallable;
 	private final boolean updateCallable;
 	private final boolean deleteCallable;
 	private final boolean deleteAllCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteAllCheckStyle;
 
 	private final Serializable[] spaces;
 
 	private Map collectionPropertyColumnAliases = new HashMap();
 	private Map collectionPropertyColumnNames = new HashMap();
 
 	public AbstractCollectionPersister(
 			final Collection collection,
 			final CollectionRegionAccessStrategy cacheAccessStrategy,
 			final Configuration cfg,
 			final SessionFactoryImplementor factory) throws MappingException, CacheException {
 
 		this.factory = factory;
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		if ( factory.getSettings().isStructuredCacheEntriesEnabled() ) {
 			cacheEntryStructure = collection.isMap() ?
 					( CacheEntryStructure ) new StructuredMapCacheEntry() :
 					( CacheEntryStructure ) new StructuredCollectionCacheEntry();
 		}
 		else {
 			cacheEntryStructure = new UnstructuredCacheEntry();
 		}
 
 		dialect = factory.getDialect();
 		sqlExceptionHelper = factory.getSQLExceptionHelper();
 		collectionType = collection.getCollectionType();
 		role = collection.getRole();
 		entityName = collection.getOwnerEntityName();
 		ownerPersister = factory.getEntityPersister(entityName);
 		queryLoaderName = collection.getLoaderName();
 		nodeName = collection.getNodeName();
 		isMutable = collection.isMutable();
 
 		Table table = collection.getCollectionTable();
 		fetchMode = collection.getElement().getFetchMode();
 		elementType = collection.getElement().getType();
 		//isSet = collection.isSet();
 		//isSorted = collection.isSorted();
 		isPrimitiveArray = collection.isPrimitiveArray();
 		isArray = collection.isArray();
 		subselectLoadable = collection.isSubselectLoadable();
 
 		qualifiedTableName = table.getQualifiedName(
 				dialect,
 				factory.getSettings().getDefaultCatalogName(),
 				factory.getSettings().getDefaultSchemaName()
 			);
 
 		int spacesSize = 1 + collection.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = qualifiedTableName;
 		Iterator iter = collection.getSynchronizedTables().iterator();
 		for ( int i = 1; i < spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
 
 		sqlWhereString = StringHelper.isNotEmpty( collection.getWhere() ) ? "( " + collection.getWhere() + ") " : null;
 		hasWhere = sqlWhereString != null;
 		sqlWhereStringTemplate = hasWhere ?
 				Template.renderWhereStringTemplate(sqlWhereString, dialect, factory.getSqlFunctionRegistry()) :
 				null;
 
 		hasOrphanDelete = collection.hasOrphanDelete();
 
 		int batch = collection.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 
 		isVersioned = collection.isOptimisticLocked();
 
 		// KEY
 
 		keyType = collection.getKey().getType();
 		iter = collection.getKey().getColumnIterator();
 		int keySpan = collection.getKey().getColumnSpan();
 		keyColumnNames = new String[keySpan];
 		keyColumnAliases = new String[keySpan];
 		int k = 0;
 		while ( iter.hasNext() ) {
 			// NativeSQL: collect key column and auto-aliases
 			Column col = ( (Column) iter.next() );
 			keyColumnNames[k] = col.getQuotedName(dialect);
 			keyColumnAliases[k] = col.getAlias(dialect,collection.getOwner().getRootTable());
 			k++;
 		}
 
 		//unquotedKeyColumnNames = StringHelper.unQuote(keyColumnAliases);
 
 		//ELEMENT
 
 		String elemNode = collection.getElementNodeName();
 		if ( elementType.isEntityType() ) {
 			String entityName = ( (EntityType) elementType ).getAssociatedEntityName();
 			elementPersister = factory.getEntityPersister(entityName);
 			if ( elemNode==null ) {
 				elemNode = cfg.getClassMapping(entityName).getNodeName();
 			}
 			// NativeSQL: collect element column and auto-aliases
 
 		}
 		else {
 			elementPersister = null;
 		}
 		elementNodeName = elemNode;
 
 		int elementSpan = collection.getElement().getColumnSpan();
 		elementColumnAliases = new String[elementSpan];
 		elementColumnNames = new String[elementSpan];
 		elementColumnWriters = new String[elementSpan];
 		elementColumnReaders = new String[elementSpan];
 		elementColumnReaderTemplates = new String[elementSpan];
 		elementFormulaTemplates = new String[elementSpan];
 		elementFormulas = new String[elementSpan];
 		elementColumnIsSettable = new boolean[elementSpan];
 		elementColumnIsInPrimaryKey = new boolean[elementSpan];
 		boolean isPureFormula = true;
 		boolean hasNotNullableColumns = false;
 		int j = 0;
 		iter = collection.getElement().getColumnIterator();
 		while ( iter.hasNext() ) {
 			Selectable selectable = (Selectable) iter.next();
 			elementColumnAliases[j] = selectable.getAlias(dialect);
 			if ( selectable.isFormula() ) {
 				Formula form = (Formula) selectable;
 				elementFormulaTemplates[j] = form.getTemplate(dialect, factory.getSqlFunctionRegistry());
 				elementFormulas[j] = form.getFormula();
 			}
 			else {
 				Column col = (Column) selectable;
 				elementColumnNames[j] = col.getQuotedName(dialect);
 				elementColumnWriters[j] = col.getWriteExpr();
 				elementColumnReaders[j] = col.getReadExpr(dialect);
 				elementColumnReaderTemplates[j] = col.getTemplate(dialect, factory.getSqlFunctionRegistry());
 				elementColumnIsSettable[j] = true;
 				elementColumnIsInPrimaryKey[j] = !col.isNullable();
 				if ( !col.isNullable() ) {
 					hasNotNullableColumns = true;
 				}
 				isPureFormula = false;
 			}
 			j++;
 		}
 		elementIsPureFormula = isPureFormula;
 
 		//workaround, for backward compatibility of sets with no
 		//not-null columns, assume all columns are used in the
 		//row locator SQL
 		if ( !hasNotNullableColumns ) {
 			Arrays.fill( elementColumnIsInPrimaryKey, true );
 		}
 
 
 		// INDEX AND ROW SELECT
 
 		hasIndex = collection.isIndexed();
 		if (hasIndex) {
 			// NativeSQL: collect index column and auto-aliases
 			IndexedCollection indexedCollection = (IndexedCollection) collection;
 			indexType = indexedCollection.getIndex().getType();
 			int indexSpan = indexedCollection.getIndex().getColumnSpan();
 			iter = indexedCollection.getIndex().getColumnIterator();
 			indexColumnNames = new String[indexSpan];
 			indexFormulaTemplates = new String[indexSpan];
 			indexFormulas = new String[indexSpan];
 			indexColumnIsSettable = new boolean[indexSpan];
 			indexColumnAliases = new String[indexSpan];
 			int i = 0;
 			boolean hasFormula = false;
 			while ( iter.hasNext() ) {
 				Selectable s = (Selectable) iter.next();
 				indexColumnAliases[i] = s.getAlias(dialect);
 				if ( s.isFormula() ) {
 					Formula indexForm = (Formula) s;
 					indexFormulaTemplates[i] = indexForm.getTemplate(dialect, factory.getSqlFunctionRegistry());
 					indexFormulas[i] = indexForm.getFormula();
 					hasFormula = true;
 				}
 				else {
 					Column indexCol = (Column) s;
 					indexColumnNames[i] = indexCol.getQuotedName(dialect);
 					indexColumnIsSettable[i] = true;
 				}
 				i++;
 			}
 			indexContainsFormula = hasFormula;
 			baseIndex = indexedCollection.isList() ?
 					( (List) indexedCollection ).getBaseIndex() : 0;
 
 			indexNodeName = indexedCollection.getIndexNodeName();
 
 		}
 		else {
 			indexContainsFormula = false;
 			indexColumnIsSettable = null;
 			indexFormulaTemplates = null;
 			indexFormulas = null;
 			indexType = null;
 			indexColumnNames = null;
 			indexColumnAliases = null;
 			baseIndex = 0;
 			indexNodeName = null;
 		}
 
 		hasIdentifier = collection.isIdentified();
 		if (hasIdentifier) {
 			if ( collection.isOneToMany() ) {
 				throw new MappingException( "one-to-many collections with identifiers are not supported" );
 			}
 			IdentifierCollection idColl = (IdentifierCollection) collection;
 			identifierType = idColl.getIdentifier().getType();
 			iter = idColl.getIdentifier().getColumnIterator();
 			Column col = ( Column ) iter.next();
 			identifierColumnName = col.getQuotedName(dialect);
 			identifierColumnAlias = col.getAlias(dialect);
 			//unquotedIdentifierColumnName = identifierColumnAlias;
 			identifierGenerator = idColl.getIdentifier().createIdentifierGenerator(
 					cfg.getIdentifierGeneratorFactory(),
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName(),
 					null
 			);
 		}
 		else {
 			identifierType = null;
 			identifierColumnName = null;
 			identifierColumnAlias = null;
 			//unquotedIdentifierColumnName = null;
 			identifierGenerator = null;
 		}
 
 		//GENERATE THE SQL:
 
 		//sqlSelectString = sqlSelectString();
 		//sqlSelectRowString = sqlSelectRowString();
 
 		if ( collection.getCustomSQLInsert() == null ) {
 			sqlInsertRowString = generateInsertRowString();
 			insertCallable = false;
 			insertCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlInsertRowString = collection.getCustomSQLInsert();
 			insertCallable = collection.isCustomInsertCallable();
 			insertCheckStyle = collection.getCustomSQLInsertCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collection.getCustomSQLInsert(), insertCallable )
 		            : collection.getCustomSQLInsertCheckStyle();
 		}
 
 		if ( collection.getCustomSQLUpdate() == null ) {
 			sqlUpdateRowString = generateUpdateRowString();
 			updateCallable = false;
 			updateCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlUpdateRowString = collection.getCustomSQLUpdate();
 			updateCallable = collection.isCustomUpdateCallable();
 			updateCheckStyle = collection.getCustomSQLUpdateCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collection.getCustomSQLUpdate(), insertCallable )
 		            : collection.getCustomSQLUpdateCheckStyle();
 		}
 
 		if ( collection.getCustomSQLDelete() == null ) {
 			sqlDeleteRowString = generateDeleteRowString();
 			deleteCallable = false;
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteRowString = collection.getCustomSQLDelete();
 			deleteCallable = collection.isCustomDeleteCallable();
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		if ( collection.getCustomSQLDeleteAll() == null ) {
 			sqlDeleteString = generateDeleteString();
 			deleteAllCallable = false;
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteString = collection.getCustomSQLDeleteAll();
 			deleteAllCallable = collection.isCustomDeleteAllCallable();
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		sqlSelectSizeString = generateSelectSizeString(  collection.isIndexed() && !collection.isMap() );
 		sqlDetectRowByIndexString = generateDetectRowByIndexString();
 		sqlDetectRowByElementString = generateDetectRowByElementString();
 		sqlSelectRowByIndexString = generateSelectRowByIndexString();
 
 		logStaticSQL();
 
 		isLazy = collection.isLazy();
 		isExtraLazy = collection.isExtraLazy();
 
 		isInverse = collection.isInverse();
 
 		if ( collection.isArray() ) {
 			elementClass = ( (org.hibernate.mapping.Array) collection ).getElementClass();
 		}
 		else {
 			// for non-arrays, we don't need to know the element class
 			elementClass = null; //elementType.returnedClass();
 		}
 
 		if ( elementType.isComponentType() ) {
 			elementPropertyMapping = new CompositeElementPropertyMapping(
 					elementColumnNames,
 					elementColumnReaders,
 					elementColumnReaderTemplates,
 					elementFormulaTemplates,
 					(CompositeType) elementType,
 					factory
 				);
 		}
 		else if ( !elementType.isEntityType() ) {
 			elementPropertyMapping = new ElementPropertyMapping(
 					elementColumnNames,
 					elementType
 				);
 		}
 		else {
 			if ( elementPersister instanceof PropertyMapping ) { //not all classpersisters implement PropertyMapping!
 				elementPropertyMapping = (PropertyMapping) elementPersister;
 			}
 			else {
 				elementPropertyMapping = new ElementPropertyMapping(
 						elementColumnNames,
 						elementType
 					);
 			}
 		}
 
 		hasOrder = collection.getOrderBy() != null;
 		if ( hasOrder ) {
 			ColumnMapper mapper = new ColumnMapper() {
 				public String[] map(String reference) {
 					return elementPropertyMapping.toColumns( reference );
 				}
 			};
 			sqlOrderByStringTemplate = Template.renderOrderByStringTemplate(
 					collection.getOrderBy(),
 					mapper,
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			sqlOrderByStringTemplate = null;
 		}
 
 		// Handle any filters applied to this collection
 		filterHelper = new FilterHelper( collection.getFilterMap(), dialect, factory.getSqlFunctionRegistry() );
 
 		// Handle any filters applied to this collection for many-to-many
 		manyToManyFilterHelper = new FilterHelper( collection.getManyToManyFilterMap(), dialect, factory.getSqlFunctionRegistry() );
 		manyToManyWhereString = StringHelper.isNotEmpty( collection.getManyToManyWhere() ) ?
 				"( " + collection.getManyToManyWhere() + ")" :
 				null;
 		manyToManyWhereTemplate = manyToManyWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( manyToManyWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		hasManyToManyOrder = collection.getManyToManyOrdering() != null;
 		if ( hasManyToManyOrder ) {
 			ColumnMapper mapper = new ColumnMapper() {
 				public String[] map(String reference) {
 					return elementPropertyMapping.toColumns( reference );
 				}
 			};
 			manyToManyOrderByTemplate = Template.renderOrderByStringTemplate(
 					collection.getManyToManyOrdering(),
 					mapper,
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			manyToManyOrderByTemplate = null;
 		}
 
 		initCollectionPropertyMap();
 	}
 
 	public void postInstantiate() throws MappingException {
 		initializer = queryLoaderName == null ?
 				createCollectionInitializer( LoadQueryInfluencers.NONE ) :
 				new NamedQueryCollectionInitializer( queryLoaderName, this );
 	}
 
 	protected void logStaticSQL() {
         if (LOG.isDebugEnabled()) {
             LOG.debugf("Static SQL for collection: %s", getRole());
             if (getSQLInsertRowString() != null) LOG.debugf(" Row insert: %s", getSQLInsertRowString());
             if (getSQLUpdateRowString() != null) LOG.debugf(" Row update: %s", getSQLUpdateRowString());
             if (getSQLDeleteRowString() != null) LOG.debugf(" Row delete: %s", getSQLDeleteRowString());
             if (getSQLDeleteString() != null) LOG.debugf(" One-shot delete: %s", getSQLDeleteString());
 		}
 	}
 
 	public void initialize(Serializable key, SessionImplementor session) throws HibernateException {
 		getAppropriateInitializer( key, session ).initialize( key, session );
 	}
 
 	protected CollectionInitializer getAppropriateInitializer(Serializable key, SessionImplementor session) {
 		if ( queryLoaderName != null ) {
 			//if there is a user-specified loader, return that
 			//TODO: filters!?
 			return initializer;
 		}
 		CollectionInitializer subselectInitializer = getSubselectInitializer( key, session );
 		if ( subselectInitializer != null ) {
 			return subselectInitializer;
 		}
 		else if ( session.getEnabledFilters().isEmpty() ) {
 			return initializer;
 		}
 		else {
 			return createCollectionInitializer( session.getLoadQueryInfluencers() );
 		}
 	}
 
 	private CollectionInitializer getSubselectInitializer(Serializable key, SessionImplementor session) {
 
 		if ( !isSubselectLoadable() ) {
 			return null;
 		}
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		SubselectFetch subselect = persistenceContext.getBatchFetchQueue()
 				.getSubselect( session.generateEntityKey( key, getOwnerEntityPersister() ) );
 
 		if (subselect == null) {
 			return null;
 		}
 		else {
 
 			// Take care of any entities that might have
 			// been evicted!
 			Iterator iter = subselect.getResult().iterator();
 			while ( iter.hasNext() ) {
 				if ( !persistenceContext.containsEntity( (EntityKey) iter.next() ) ) {
 					iter.remove();
 				}
 			}
 
 			// Run a subquery loader
 			return createSubselectInitializer( subselect, session );
 		}
 	}
 
 	protected abstract CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session);
 
 	protected abstract CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException;
 
 	public CollectionRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	public CollectionType getCollectionType() {
 		return collectionType;
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	public String getSQLOrderByString(String alias) {
 		return hasOrdering()
 				? StringHelper.replace( sqlOrderByStringTemplate, Template.TEMPLATE, alias )
 				: "";
 	}
 
 	public String getManyToManyOrderByString(String alias) {
 		return hasManyToManyOrdering()
 				? StringHelper.replace( manyToManyOrderByTemplate, Template.TEMPLATE, alias )
 				: "";
 	}
 	public FetchMode getFetchMode() {
 		return fetchMode;
 	}
 
 	public boolean hasOrdering() {
 		return hasOrder;
 	}
 
 	public boolean hasManyToManyOrdering() {
 		return isManyToMany() && hasManyToManyOrder;
 	}
 
 	public boolean hasWhere() {
 		return hasWhere;
 	}
 
 	protected String getSQLDeleteString() {
 		return sqlDeleteString;
 	}
 
 	protected String getSQLInsertRowString() {
 		return sqlInsertRowString;
 	}
 
 	protected String getSQLUpdateRowString() {
 		return sqlUpdateRowString;
 	}
 
 	protected String getSQLDeleteRowString() {
 		return sqlDeleteRowString;
 	}
 
 	public Type getKeyType() {
 		return keyType;
 	}
 
 	public Type getIndexType() {
 		return indexType;
 	}
 
 	public Type getElementType() {
 		return elementType;
 	}
 
 	/**
 	 * Return the element class of an array, or null otherwise
 	 */
 	public Class getElementClass() { //needed by arrays
 		return elementClass;
 	}
 
 	public Object readElement(ResultSet rs, Object owner, String[] aliases, SessionImplementor session)
 	throws HibernateException, SQLException {
 		return getElementType().nullSafeGet( rs, aliases, session, owner );
 	}
 
 	public Object readIndex(ResultSet rs, String[] aliases, SessionImplementor session)
 	throws HibernateException, SQLException {
 		Object index = getIndexType().nullSafeGet( rs, aliases, session, null );
 		if ( index == null ) {
 			throw new HibernateException( "null index column for collection: " + role );
 		}
 		index = decrementIndexByBase( index );
 		return index;
 	}
 
 	protected Object decrementIndexByBase(Object index) {
 		if (baseIndex!=0) {
 			index = new Integer( ( (Integer) index ).intValue() - baseIndex );
 		}
 		return index;
 	}
 
 	public Object readIdentifier(ResultSet rs, String alias, SessionImplementor session)
 	throws HibernateException, SQLException {
 		Object id = getIdentifierType().nullSafeGet( rs, alias, session, null );
 		if ( id == null ) {
 			throw new HibernateException( "null identifier column for collection: " + role );
 		}
 		return id;
 	}
 
 	public Object readKey(ResultSet rs, String[] aliases, SessionImplementor session)
 	throws HibernateException, SQLException {
 		return getKeyType().nullSafeGet( rs, aliases, session, null );
 	}
 
 	/**
 	 * Write the key to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeKey(PreparedStatement st, Serializable key, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		if ( key == null ) {
 			throw new NullPointerException( "null key for collection: " + role );  //an assertion
 		}
 		getKeyType().nullSafeSet( st, key, i, session );
 		return i + keyColumnAliases.length;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElement(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getElementType().nullSafeSet(st, elt, i, elementColumnIsSettable, session);
 		return i + ArrayHelper.countTrue( elementColumnIsSettable );
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndex(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getIndexType().nullSafeSet( st, incrementIndexByBase(index), i, indexColumnIsSettable, session );
 		return i + ArrayHelper.countTrue(indexColumnIsSettable);
 	}
 
 	protected Object incrementIndexByBase(Object index) {
 		if (baseIndex!=0) {
 			index = new Integer( ( (Integer) index ).intValue() + baseIndex );
 		}
 		return index;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElementToWhere(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if (elementIsPureFormula) {
 			throw new AssertionFailure("cannot use a formula-based element in the where condition");
 		}
 		getElementType().nullSafeSet(st, elt, i, elementColumnIsInPrimaryKey, session);
 		return i + elementColumnAliases.length;
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndexToWhere(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if (indexContainsFormula) {
 			throw new AssertionFailure("cannot use a formula-based index in the where condition");
 		}
 		getIndexType().nullSafeSet( st, incrementIndexByBase(index), i, session );
 		return i + indexColumnAliases.length;
 	}
 
 	/**
 	 * Write the identifier to a JDBC <tt>PreparedStatement</tt>
 	 */
 	public int writeIdentifier(PreparedStatement st, Object id, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		getIdentifierType().nullSafeSet( st, id, i, session );
 		return i + 1;
 	}
 
 	public boolean isPrimitiveArray() {
 		return isPrimitiveArray;
 	}
 
 	public boolean isArray() {
 		return isArray;
 	}
 
 	public String[] getKeyColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( keyColumnAliases );
 	}
 
 	public String[] getElementColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( elementColumnAliases );
 	}
 
 	public String[] getIndexColumnAliases(String suffix) {
 		if ( hasIndex ) {
 			return new Alias( suffix ).toAliasStrings( indexColumnAliases );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String getIdentifierColumnAlias(String suffix) {
 		if ( hasIdentifier ) {
 			return new Alias( suffix ).toAliasString( identifierColumnAlias );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String getIdentifierColumnName() {
 		if ( hasIdentifier ) {
 			return identifierColumnName;
 		} else {
 			return null;
 		}
 	}
 
 	/**
 	 * Generate a list of collection index, key and element columns
 	 */
 	public String selectFragment(String alias, String columnSuffix) {
 		SelectFragment frag = generateSelectFragment( alias, columnSuffix );
 		appendElementColumns( frag, alias );
 		appendIndexColumns( frag, alias );
 		appendIdentifierColumns( frag, alias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); //strip leading ','
 	}
 
 	protected String generateSelectSizeString(boolean isIntegerIndexed) {
 		String selectValue = isIntegerIndexed ?
 			"max(" + getIndexColumnNames()[0] + ") + 1": //lists, arrays
 			"count(" + getElementColumnNames()[0] + ")"; //sets, maps, bags
 		return new SimpleSelect(dialect)
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addColumn(selectValue)
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect(dialect)
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumn("1")
 				.toStatementString();
 	}
 
 	protected String generateSelectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect(dialect)
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumns( getElementColumnNames(), elementColumnAliases )
 				.addColumns( indexFormulas, indexColumnAliases )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByElementString() {
 		return new SimpleSelect(dialect)
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getElementColumnNames(), "=?" )
 				.addCondition( elementFormulas, "=?" )
 				.addColumn("1")
 				.toStatementString();
 	}
 
 	protected SelectFragment generateSelectFragment(String alias, String columnSuffix) {
 		return new SelectFragment()
 				.setSuffix( columnSuffix )
 				.addColumns( alias, keyColumnNames, keyColumnAliases );
 	}
 
 	protected void appendElementColumns(SelectFragment frag, String elemAlias) {
 		for ( int i=0; i<elementColumnIsSettable.length; i++ ) {
 			if ( elementColumnIsSettable[i] ) {
 				frag.addColumnTemplate( elemAlias, elementColumnReaderTemplates[i], elementColumnAliases[i] );
 			}
 			else {
 				frag.addFormula( elemAlias, elementFormulaTemplates[i], elementColumnAliases[i] );
 			}
 		}
 	}
 
 	protected void appendIndexColumns(SelectFragment frag, String alias) {
 		if ( hasIndex ) {
 			for ( int i=0; i<indexColumnIsSettable.length; i++ ) {
 				if ( indexColumnIsSettable[i] ) {
 					frag.addColumn( alias, indexColumnNames[i], indexColumnAliases[i] );
 				}
 				else {
 					frag.addFormula( alias, indexFormulaTemplates[i], indexColumnAliases[i] );
 				}
 			}
 		}
 	}
 
 	protected void appendIdentifierColumns(SelectFragment frag, String alias) {
 		if ( hasIdentifier ) {
 			frag.addColumn( alias, identifierColumnName, identifierColumnAlias );
 		}
 	}
 
 	public String[] getIndexColumnNames() {
 		return indexColumnNames;
 	}
 
 	public String[] getIndexFormulas() {
 		return indexFormulas;
 	}
 
 	public String[] getIndexColumnNames(String alias) {
 		return qualify(alias, indexColumnNames, indexFormulaTemplates);
 
 	}
 
 	public String[] getElementColumnNames(String alias) {
 		return qualify(alias, elementColumnNames, elementFormulaTemplates);
 	}
 
 	private static String[] qualify(String alias, String[] columnNames, String[] formulaTemplates) {
 		int span = columnNames.length;
 		String[] result = new String[span];
 		for (int i=0; i<span; i++) {
 			if ( columnNames[i]==null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.qualify( alias, columnNames[i] );
 			}
 		}
 		return result;
 	}
 
 	public String[] getElementColumnNames() {
 		return elementColumnNames; //TODO: something with formulas...
 	}
 
 	public String[] getKeyColumnNames() {
 		return keyColumnNames;
 	}
 
 	public boolean hasIndex() {
 		return hasIndex;
 	}
 
 	public boolean isLazy() {
 		return isLazy;
 	}
 
 	public boolean isInverse() {
 		return isInverse;
 	}
 
 	public String getTableName() {
 		return qualifiedTableName;
 	}
 
 	private BasicBatchKey removeBatchKey;
 
 	public void remove(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !isInverse && isRowDeleteEnabled() ) {
 
             if (LOG.isDebugEnabled()) LOG.debugf("Deleting collection: %s",
                                                  MessageHelper.collectionInfoString(this, id, getFactory()));
 
 			// Remove all the old entries
 
 			try {
 				int offset = 1;
 				PreparedStatement st = null;
 				Expectation expectation = Expectations.appropriateExpectation( getDeleteAllCheckStyle() );
 				boolean callable = isDeleteAllCallable();
 				boolean useBatch = expectation.canBeBatched();
 				String sql = getSQLDeleteString();
 				if ( useBatch ) {
 					if ( removeBatchKey == null ) {
 						removeBatchKey = new BasicBatchKey(
 								getRole() + "#REMOVE",
 								expectation
 						);
 					}
 					st = session.getTransactionCoordinator()
 							.getJdbcCoordinator()
 							.getBatch( removeBatchKey )
 							.getBatchStatement( sql, callable );
 				}
 				else {
 					st = session.getTransactionCoordinator()
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql, callable );
 				}
 
 
 				try {
 					offset+= expectation.prepare( st );
 
 					writeKey( st, id, offset, session );
 					if ( useBatch ) {
 						session.getTransactionCoordinator()
 								.getJdbcCoordinator()
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/NamedQueryCollectionInitializer.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/NamedQueryCollectionInitializer.java
index ea53669ce1..34bd80df12 100755
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/NamedQueryCollectionInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/NamedQueryCollectionInitializer.java
@@ -1,75 +1,76 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 import java.io.Serializable;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.impl.AbstractQueryImpl;
 import org.hibernate.loader.collection.CollectionInitializer;
+
 import org.jboss.logging.Logger;
 
 /**
  * A wrapper around a named query.
  * @author Gavin King
  */
 public final class NamedQueryCollectionInitializer implements CollectionInitializer {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        NamedQueryCollectionInitializer.class.getName());
 
     private final String queryName;
 	private final CollectionPersister persister;
 
 	public NamedQueryCollectionInitializer(String queryName, CollectionPersister persister) {
 		super();
 		this.queryName = queryName;
 		this.persister = persister;
 	}
 
 	public void initialize(Serializable key, SessionImplementor session)
 	throws HibernateException {
 
         LOG.debugf("Initializing collection: %s using named query: %s", persister.getRole(), queryName);
 
 		//TODO: is there a more elegant way than downcasting?
 		AbstractQueryImpl query = (AbstractQueryImpl) session.getNamedSQLQuery(queryName);
 		if ( query.getNamedParameters().length>0 ) {
 			query.setParameter(
 					query.getNamedParameters()[0],
 					key,
 					persister.getKeyType()
 				);
 		}
 		else {
 			query.setParameter( 0, key, persister.getKeyType() );
 		}
 		query.setCollectionKey( key )
 				.setFlushMode( FlushMode.MANUAL )
 				.list();
 
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
index 978cbe4059..3ec487dbfa 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
@@ -1,1126 +1,1126 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.entry.CacheEntry;
 import org.hibernate.cache.entry.CacheEntryStructure;
 import org.hibernate.cache.entry.StructuredCacheEntry;
 import org.hibernate.cache.entry.UnstructuredCacheEntry;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.engine.CascadeStyle;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.ValueInclusion;
 import org.hibernate.engine.Versioning;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.id.insert.Binder;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.impl.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.jdbc.TooManyRowsAffectedException;
 import org.hibernate.loader.entity.BatchingEntityLoader;
 import org.hibernate.loader.entity.CascadeEntityLoader;
 import org.hibernate.loader.entity.EntityLoader;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.property.BackrefPropertyAccessor;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.Select;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.Update;
 import org.hibernate.tuple.Tuplizer;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 import org.hibernate.type.VersionType;
 
 /**
  * Basic functionality for persisting an entity via JDBC
  * through either generated or custom SQL
  *
  * @author Gavin King
  */
 public abstract class AbstractEntityPersister
 		implements OuterJoinLoadable, Queryable, ClassMetadata, UniqueKeyLoadable,
 				   SQLLoadable, LazyPropertyInitializer, PostInsertIdentityPersister, Lockable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractEntityPersister.class.getName());
 
 	public static final String ENTITY_CLASS = "class";
 
 	// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final SessionFactoryImplementor factory;
 	private final EntityRegionAccessStrategy cacheAccessStrategy;
 	private final boolean isLazyPropertiesCacheable;
 	private final CacheEntryStructure cacheEntryStructure;
 	private final EntityMetamodel entityMetamodel;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private final String[] rootTableKeyColumnNames;
 	private final String[] rootTableKeyColumnReaders;
 	private final String[] rootTableKeyColumnReaderTemplates;
 	private final String[] identifierAliases;
 	private final int identifierColumnSpan;
 	private final String versionColumnName;
 	private final boolean hasFormulaProperties;
 	private final int batchSize;
 	private final boolean hasSubselectLoadableCollections;
 	protected final String rowIdName;
 
 	private final Set lazyProperties;
 
 	// The optional SQL string defined in the where attribute
 	private final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	//information about properties of this class,
 	//including inherited properties
 	//(only really needed for updatable/insertable properties)
 	private final int[] propertyColumnSpans;
 	private final String[] propertySubclassNames;
 	private final String[][] propertyColumnAliases;
 	private final String[][] propertyColumnNames;
 	private final String[][] propertyColumnFormulaTemplates;
 	private final String[][] propertyColumnReaderTemplates;
 	private final String[][] propertyColumnWriters;
 	private final boolean[][] propertyColumnUpdateable;
 	private final boolean[][] propertyColumnInsertable;
 	private final boolean[] propertyUniqueness;
 	private final boolean[] propertySelectable;
 
 	//information about lazy properties of this class
 	private final String[] lazyPropertyNames;
 	private final int[] lazyPropertyNumbers;
 	private final Type[] lazyPropertyTypes;
 	private final String[][] lazyPropertyColumnAliases;
 
 	//information about all properties in class hierarchy
 	private final String[] subclassPropertyNameClosure;
 	private final String[] subclassPropertySubclassNameClosure;
 	private final Type[] subclassPropertyTypeClosure;
 	private final String[][] subclassPropertyFormulaTemplateClosure;
 	private final String[][] subclassPropertyColumnNameClosure;
 	private final String[][] subclassPropertyColumnReaderClosure;
 	private final String[][] subclassPropertyColumnReaderTemplateClosure;
 	private final FetchMode[] subclassPropertyFetchModeClosure;
 	private final boolean[] subclassPropertyNullabilityClosure;
 	private final boolean[] propertyDefinedOnSubclass;
 	private final int[][] subclassPropertyColumnNumberClosure;
 	private final int[][] subclassPropertyFormulaNumberClosure;
 	private final CascadeStyle[] subclassPropertyCascadeStyleClosure;
 
 	//information about all columns/formulas in class hierarchy
 	private final String[] subclassColumnClosure;
 	private final boolean[] subclassColumnLazyClosure;
 	private final String[] subclassColumnAliasClosure;
 	private final boolean[] subclassColumnSelectableClosure;
 	private final String[] subclassColumnReaderTemplateClosure;
 	private final String[] subclassFormulaClosure;
 	private final String[] subclassFormulaTemplateClosure;
 	private final String[] subclassFormulaAliasClosure;
 	private final boolean[] subclassFormulaLazyClosure;
 
 	// dynamic filters attached to the class-level
 	private final FilterHelper filterHelper;
 
 	private final Set affectingFetchProfileNames = new HashSet();
 
 	private final Map uniqueKeyLoaders = new HashMap();
 	private final Map lockers = new HashMap();
 	private final Map loaders = new HashMap();
 
 	// SQL strings
 	private String sqlVersionSelectString;
 	private String sqlSnapshotSelectString;
 	private String sqlLazySelectString;
 
 	private String sqlIdentityInsertString;
 	private String sqlUpdateByRowIdString;
 	private String sqlLazyUpdateByRowIdString;
 
 	private String[] sqlDeleteStrings;
 	private String[] sqlInsertStrings;
 	private String[] sqlUpdateStrings;
 	private String[] sqlLazyUpdateStrings;
 
 	private String sqlInsertGeneratedValuesSelectString;
 	private String sqlUpdateGeneratedValuesSelectString;
 
 	//Custom SQL (would be better if these were private)
 	protected boolean[] insertCallable;
 	protected boolean[] updateCallable;
 	protected boolean[] deleteCallable;
 	protected String[] customSQLInsert;
 	protected String[] customSQLUpdate;
 	protected String[] customSQLDelete;
 	protected ExecuteUpdateResultCheckStyle[] insertResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] updateResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] deleteResultCheckStyles;
 
 	private InsertGeneratedIdentifierDelegate identityDelegate;
 
 	private boolean[] tableHasColumns;
 
 	private final String loaderName;
 
 	private UniqueEntityLoader queryLoader;
 
 	private final String temporaryIdTableName;
 	private final String temporaryIdTableDDL;
 
 	private final Map subclassPropertyAliases = new HashMap();
 	private final Map subclassPropertyColumnNames = new HashMap();
 
 	protected final BasicEntityPropertyMapping propertyMapping;
 
 	protected void addDiscriminatorToInsert(Insert insert) {}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {}
 
 	protected abstract int[] getSubclassColumnTableNumberClosure();
 
 	protected abstract int[] getSubclassFormulaTableNumberClosure();
 
 	public abstract String getSubclassTableName(int j);
 
 	protected abstract String[] getSubclassTableKeyColumns(int j);
 
 	protected abstract boolean isClassOrSuperclassTable(int j);
 
 	protected abstract int getSubclassTableSpan();
 
 	protected abstract int getTableSpan();
 
 	protected abstract boolean isTableCascadeDeleteEnabled(int j);
 
 	protected abstract String getTableName(int j);
 
 	protected abstract String[] getKeyColumns(int j);
 
 	protected abstract boolean isPropertyOfTable(int property, int j);
 
 	protected abstract int[] getPropertyTableNumbersInSelect();
 
 	protected abstract int[] getPropertyTableNumbers();
 
 	protected abstract int getSubclassPropertyTableNumber(int i);
 
 	protected abstract String filterFragment(String alias) throws MappingException;
 
 	private static final String DISCRIMINATOR_ALIAS = "clazz_";
 
 	public String getDiscriminatorColumnName() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaderTemplate() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorAlias() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return null;
 	}
 
 	protected boolean isInverseTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableSubclassTable(int j) {
 		return false;
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return false;
 	}
 
 	public boolean isSubclassEntityName(String entityName) {
 		return entityMetamodel.getSubclassEntityNames().contains(entityName);
 	}
 
 	private boolean[] getTableHasColumns() {
 		return tableHasColumns;
 	}
 
 	public String[] getRootTableKeyColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	protected String[] getSQLUpdateByRowIdStrings() {
 		if ( sqlUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan() + 1];
 		result[0] = sqlUpdateByRowIdString;
 		System.arraycopy( sqlUpdateStrings, 0, result, 1, getTableSpan() );
 		return result;
 	}
 
 	protected String[] getSQLLazyUpdateByRowIdStrings() {
 		if ( sqlLazyUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan()];
 		result[0] = sqlLazyUpdateByRowIdString;
 		for ( int i = 1; i < getTableSpan(); i++ ) {
 			result[i] = sqlLazyUpdateStrings[i];
 		}
 		return result;
 	}
 
 	protected String getSQLSnapshotSelectString() {
 		return sqlSnapshotSelectString;
 	}
 
 	protected String getSQLLazySelectString() {
 		return sqlLazySelectString;
 	}
 
 	protected String[] getSQLDeleteStrings() {
 		return sqlDeleteStrings;
 	}
 
 	protected String[] getSQLInsertStrings() {
 		return sqlInsertStrings;
 	}
 
 	protected String[] getSQLUpdateStrings() {
 		return sqlUpdateStrings;
 	}
 
 	protected String[] getSQLLazyUpdateStrings() {
 		return sqlLazyUpdateStrings;
 	}
 
 	/**
 	 * The query that inserts a row, letting the database generate an id
 	 *
 	 * @return The IDENTITY-based insertion query.
 	 */
 	protected String getSQLIdentityInsertString() {
 		return sqlIdentityInsertString;
 	}
 
 	protected String getVersionSelectString() {
 		return sqlVersionSelectString;
 	}
 
 	protected boolean isInsertCallable(int j) {
 		return insertCallable[j];
 	}
 
 	protected boolean isUpdateCallable(int j) {
 		return updateCallable[j];
 	}
 
 	protected boolean isDeleteCallable(int j) {
 		return deleteCallable[j];
 	}
 
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return false;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return false;
 	}
 
 	public boolean hasSequentialSelect() {
 		return false;
 	}
 
 	/**
 	 * Decide which tables need to be updated.
 	 * <p/>
 	 * The return here is an array of boolean values with each index corresponding
 	 * to a given table in the scope of this persister.
 	 *
 	 * @param dirtyProperties The indices of all the entity properties considered dirty.
 	 * @param hasDirtyCollection Whether any collections owned by the entity which were considered dirty.
 	 *
 	 * @return Array of booleans indicating which table require updating.
 	 */
 	protected boolean[] getTableUpdateNeeded(final int[] dirtyProperties, boolean hasDirtyCollection) {
 
 		if ( dirtyProperties == null ) {
 			return getTableHasColumns(); // for objects that came in via update()
 		}
 		else {
 			boolean[] updateability = getPropertyUpdateability();
 			int[] propertyTableNumbers = getPropertyTableNumbers();
 			boolean[] tableUpdateNeeded = new boolean[ getTableSpan() ];
 			for ( int i = 0; i < dirtyProperties.length; i++ ) {
 				int property = dirtyProperties[i];
 				int table = propertyTableNumbers[property];
 				tableUpdateNeeded[table] = tableUpdateNeeded[table] ||
 						( getPropertyColumnSpan(property) > 0 && updateability[property] );
 			}
 			if ( isVersioned() ) {
 				tableUpdateNeeded[0] = tableUpdateNeeded[0] ||
 					Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
 			}
 			return tableUpdateNeeded;
 		}
 	}
 
 	public boolean hasRowId() {
 		return rowIdName != null;
 	}
 
 	protected boolean[][] getPropertyColumnUpdateable() {
 		return propertyColumnUpdateable;
 	}
 
 	protected boolean[][] getPropertyColumnInsertable() {
 		return propertyColumnInsertable;
 	}
 
 	protected boolean[] getPropertySelectable() {
 		return propertySelectable;
 	}
 
 	public AbstractEntityPersister(
 			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final SessionFactoryImplementor factory) throws HibernateException {
 
 		// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		this.factory = factory;
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		isLazyPropertiesCacheable = persistentClass.isLazyPropertiesCacheable();
 		this.cacheEntryStructure = factory.getSettings().isStructuredCacheEntriesEnabled() ?
 				(CacheEntryStructure) new StructuredCacheEntry(this) :
 				(CacheEntryStructure) new UnstructuredCacheEntry();
 
 		this.entityMetamodel = new EntityMetamodel( persistentClass, factory );
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		int batch = persistentClass.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 		hasSubselectLoadableCollections = persistentClass.hasSubselectLoadableCollections();
 
 		propertyMapping = new BasicEntityPropertyMapping( this );
 
 		// IDENTIFIER
 
 		identifierColumnSpan = persistentClass.getIdentifier().getColumnSpan();
 		rootTableKeyColumnNames = new String[identifierColumnSpan];
 		rootTableKeyColumnReaders = new String[identifierColumnSpan];
 		rootTableKeyColumnReaderTemplates = new String[identifierColumnSpan];
 		identifierAliases = new String[identifierColumnSpan];
 
 		rowIdName = persistentClass.getRootTable().getRowId();
 
 		loaderName = persistentClass.getLoaderName();
 
 		Iterator iter = persistentClass.getIdentifier().getColumnIterator();
 		int i = 0;
 		while ( iter.hasNext() ) {
 			Column col = ( Column ) iter.next();
 			rootTableKeyColumnNames[i] = col.getQuotedName( factory.getDialect() );
 			rootTableKeyColumnReaders[i] = col.getReadExpr( factory.getDialect() );
 			rootTableKeyColumnReaderTemplates[i] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 			identifierAliases[i] = col.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 			i++;
 		}
 
 		// VERSION
 
 		if ( persistentClass.isVersioned() ) {
 			versionColumnName = ( ( Column ) persistentClass.getVersion().getColumnIterator().next() ).getQuotedName( factory.getDialect() );
 		}
 		else {
 			versionColumnName = null;
 		}
 
 		//WHERE STRING
 
 		sqlWhereString = StringHelper.isNotEmpty( persistentClass.getWhere() ) ? "( " + persistentClass.getWhere() + ") " : null;
 		sqlWhereStringTemplate = sqlWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( sqlWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		// PROPERTIES
 
 		final boolean lazyAvailable = isInstrumented(EntityMode.POJO);
 
 		int hydrateSpan = entityMetamodel.getPropertySpan();
 		propertyColumnSpans = new int[hydrateSpan];
 		propertySubclassNames = new String[hydrateSpan];
 		propertyColumnAliases = new String[hydrateSpan][];
 		propertyColumnNames = new String[hydrateSpan][];
 		propertyColumnFormulaTemplates = new String[hydrateSpan][];
 		propertyColumnReaderTemplates = new String[hydrateSpan][];
 		propertyColumnWriters = new String[hydrateSpan][];
 		propertyUniqueness = new boolean[hydrateSpan];
 		propertySelectable = new boolean[hydrateSpan];
 		propertyColumnUpdateable = new boolean[hydrateSpan][];
 		propertyColumnInsertable = new boolean[hydrateSpan][];
 		HashSet thisClassProperties = new HashSet();
 
 		lazyProperties = new HashSet();
 		ArrayList lazyNames = new ArrayList();
 		ArrayList lazyNumbers = new ArrayList();
 		ArrayList lazyTypes = new ArrayList();
 		ArrayList lazyColAliases = new ArrayList();
 
 		iter = persistentClass.getPropertyClosureIterator();
 		i = 0;
 		boolean foundFormula = false;
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			thisClassProperties.add( prop );
 
 			int span = prop.getColumnSpan();
 			propertyColumnSpans[i] = span;
 			propertySubclassNames[i] = prop.getPersistentClass().getEntityName();
 			String[] colNames = new String[span];
 			String[] colAliases = new String[span];
 			String[] colReaderTemplates = new String[span];
 			String[] colWriters = new String[span];
 			String[] formulaTemplates = new String[span];
 			Iterator colIter = prop.getColumnIterator();
 			int k = 0;
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				colAliases[k] = thing.getAlias( factory.getDialect() , prop.getValue().getTable() );
 				if ( thing.isFormula() ) {
 					foundFormula = true;
 					formulaTemplates[k] = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				}
 				else {
 					Column col = (Column)thing;
 					colNames[k] = col.getQuotedName( factory.getDialect() );
 					colReaderTemplates[k] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					colWriters[k] = col.getWriteExpr();
 				}
 				k++;
 			}
 			propertyColumnNames[i] = colNames;
 			propertyColumnFormulaTemplates[i] = formulaTemplates;
 			propertyColumnReaderTemplates[i] = colReaderTemplates;
 			propertyColumnWriters[i] = colWriters;
 			propertyColumnAliases[i] = colAliases;
 
 			if ( lazyAvailable && prop.isLazy() ) {
 				lazyProperties.add( prop.getName() );
 				lazyNames.add( prop.getName() );
 				lazyNumbers.add( new Integer( i ) );
 				lazyTypes.add( prop.getValue().getType() );
 				lazyColAliases.add( colAliases );
 			}
 
 			propertyColumnUpdateable[i] = prop.getValue().getColumnUpdateability();
 			propertyColumnInsertable[i] = prop.getValue().getColumnInsertability();
 
 			propertySelectable[i] = prop.isSelectable();
 
 			propertyUniqueness[i] = prop.getValue().isAlternateUniqueKey();
 
 			i++;
 
 		}
 		hasFormulaProperties = foundFormula;
 		lazyPropertyColumnAliases = ArrayHelper.to2DStringArray( lazyColAliases );
 		lazyPropertyNames = ArrayHelper.toStringArray( lazyNames );
 		lazyPropertyNumbers = ArrayHelper.toIntArray( lazyNumbers );
 		lazyPropertyTypes = ArrayHelper.toTypeArray( lazyTypes );
 
 		// SUBCLASS PROPERTY CLOSURE
 
 		ArrayList columns = new ArrayList();
 		ArrayList columnsLazy = new ArrayList();
 		ArrayList columnReaderTemplates = new ArrayList();
 		ArrayList aliases = new ArrayList();
 		ArrayList formulas = new ArrayList();
 		ArrayList formulaAliases = new ArrayList();
 		ArrayList formulaTemplates = new ArrayList();
 		ArrayList formulasLazy = new ArrayList();
 		ArrayList types = new ArrayList();
 		ArrayList names = new ArrayList();
 		ArrayList classes = new ArrayList();
 		ArrayList templates = new ArrayList();
 		ArrayList propColumns = new ArrayList();
 		ArrayList propColumnReaders = new ArrayList();
 		ArrayList propColumnReaderTemplates = new ArrayList();
 		ArrayList joinedFetchesList = new ArrayList();
 		ArrayList cascades = new ArrayList();
 		ArrayList definedBySubclass = new ArrayList();
 		ArrayList propColumnNumbers = new ArrayList();
 		ArrayList propFormulaNumbers = new ArrayList();
 		ArrayList columnSelectables = new ArrayList();
 		ArrayList propNullables = new ArrayList();
 
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			names.add( prop.getName() );
 			classes.add( prop.getPersistentClass().getEntityName() );
 			boolean isDefinedBySubclass = !thisClassProperties.contains( prop );
 			definedBySubclass.add( Boolean.valueOf( isDefinedBySubclass ) );
 			propNullables.add( Boolean.valueOf( prop.isOptional() || isDefinedBySubclass ) ); //TODO: is this completely correct?
 			types.add( prop.getType() );
 
 			Iterator colIter = prop.getColumnIterator();
 			String[] cols = new String[prop.getColumnSpan()];
 			String[] readers = new String[prop.getColumnSpan()];
 			String[] readerTemplates = new String[prop.getColumnSpan()];
 			String[] forms = new String[prop.getColumnSpan()];
 			int[] colnos = new int[prop.getColumnSpan()];
 			int[] formnos = new int[prop.getColumnSpan()];
 			int l = 0;
 			Boolean lazy = Boolean.valueOf( prop.isLazy() && lazyAvailable );
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				if ( thing.isFormula() ) {
 					String template = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					formnos[l] = formulaTemplates.size();
 					colnos[l] = -1;
 					formulaTemplates.add( template );
 					forms[l] = template;
 					formulas.add( thing.getText( factory.getDialect() ) );
 					formulaAliases.add( thing.getAlias( factory.getDialect() ) );
 					formulasLazy.add( lazy );
 				}
 				else {
 					Column col = (Column)thing;
 					String colName = col.getQuotedName( factory.getDialect() );
 					colnos[l] = columns.size(); //before add :-)
 					formnos[l] = -1;
 					columns.add( colName );
 					cols[l] = colName;
 					aliases.add( thing.getAlias( factory.getDialect(), prop.getValue().getTable() ) );
 					columnsLazy.add( lazy );
 					columnSelectables.add( Boolean.valueOf( prop.isSelectable() ) );
 
 					readers[l] = col.getReadExpr( factory.getDialect() );
 					String readerTemplate = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					readerTemplates[l] = readerTemplate;
 					columnReaderTemplates.add( readerTemplate );
 				}
 				l++;
 			}
 			propColumns.add( cols );
 			propColumnReaders.add( readers );
 			propColumnReaderTemplates.add( readerTemplates );
 			templates.add( forms );
 			propColumnNumbers.add( colnos );
 			propFormulaNumbers.add( formnos );
 
 			joinedFetchesList.add( prop.getValue().getFetchMode() );
 			cascades.add( prop.getCascadeStyle() );
 		}
 		subclassColumnClosure = ArrayHelper.toStringArray( columns );
 		subclassColumnAliasClosure = ArrayHelper.toStringArray( aliases );
 		subclassColumnLazyClosure = ArrayHelper.toBooleanArray( columnsLazy );
 		subclassColumnSelectableClosure = ArrayHelper.toBooleanArray( columnSelectables );
 		subclassColumnReaderTemplateClosure = ArrayHelper.toStringArray( columnReaderTemplates );
 
 		subclassFormulaClosure = ArrayHelper.toStringArray( formulas );
 		subclassFormulaTemplateClosure = ArrayHelper.toStringArray( formulaTemplates );
 		subclassFormulaAliasClosure = ArrayHelper.toStringArray( formulaAliases );
 		subclassFormulaLazyClosure = ArrayHelper.toBooleanArray( formulasLazy );
 
 		subclassPropertyNameClosure = ArrayHelper.toStringArray( names );
 		subclassPropertySubclassNameClosure = ArrayHelper.toStringArray( classes );
 		subclassPropertyTypeClosure = ArrayHelper.toTypeArray( types );
 		subclassPropertyNullabilityClosure = ArrayHelper.toBooleanArray( propNullables );
 		subclassPropertyFormulaTemplateClosure = ArrayHelper.to2DStringArray( templates );
 		subclassPropertyColumnNameClosure = ArrayHelper.to2DStringArray( propColumns );
 		subclassPropertyColumnReaderClosure = ArrayHelper.to2DStringArray( propColumnReaders );
 		subclassPropertyColumnReaderTemplateClosure = ArrayHelper.to2DStringArray( propColumnReaderTemplates );
 		subclassPropertyColumnNumberClosure = ArrayHelper.to2DIntArray( propColumnNumbers );
 		subclassPropertyFormulaNumberClosure = ArrayHelper.to2DIntArray( propFormulaNumbers );
 
 		subclassPropertyCascadeStyleClosure = new CascadeStyle[cascades.size()];
 		iter = cascades.iterator();
 		int j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyCascadeStyleClosure[j++] = ( CascadeStyle ) iter.next();
 		}
 		subclassPropertyFetchModeClosure = new FetchMode[joinedFetchesList.size()];
 		iter = joinedFetchesList.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyFetchModeClosure[j++] = ( FetchMode ) iter.next();
 		}
 
 		propertyDefinedOnSubclass = new boolean[definedBySubclass.size()];
 		iter = definedBySubclass.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			propertyDefinedOnSubclass[j++] = ( ( Boolean ) iter.next() ).booleanValue();
 		}
 
 		// Handle any filters applied to the class level
 		filterHelper = new FilterHelper( persistentClass.getFilterMap(), factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		temporaryIdTableName = persistentClass.getTemporaryIdTableName();
 		temporaryIdTableDDL = persistentClass.getTemporaryIdTableDDL();
 	}
 
 	protected String generateLazySelectString() {
 
 		if ( !entityMetamodel.hasLazyProperties() ) {
 			return null;
 		}
 
 		HashSet tableNumbers = new HashSet();
 		ArrayList columnNumbers = new ArrayList();
 		ArrayList formulaNumbers = new ArrayList();
 		for ( int i = 0; i < lazyPropertyNames.length; i++ ) {
 			// all this only really needs to consider properties
 			// of this class, not its subclasses, but since we
 			// are reusing code used for sequential selects, we
 			// use the subclass closure
 			int propertyNumber = getSubclassPropertyIndex( lazyPropertyNames[i] );
 
 			int tableNumber = getSubclassPropertyTableNumber( propertyNumber );
 			tableNumbers.add( new Integer( tableNumber ) );
 
 			int[] colNumbers = subclassPropertyColumnNumberClosure[propertyNumber];
 			for ( int j = 0; j < colNumbers.length; j++ ) {
 				if ( colNumbers[j]!=-1 ) {
 					columnNumbers.add( new Integer( colNumbers[j] ) );
 				}
 			}
 			int[] formNumbers = subclassPropertyFormulaNumberClosure[propertyNumber];
 			for ( int j = 0; j < formNumbers.length; j++ ) {
 				if ( formNumbers[j]!=-1 ) {
 					formulaNumbers.add( new Integer( formNumbers[j] ) );
 				}
 			}
 		}
 
 		if ( columnNumbers.size()==0 && formulaNumbers.size()==0 ) {
 			// only one-to-one is lazy fetched
 			return null;
 		}
 
 		return renderSelect( ArrayHelper.toIntArray( tableNumbers ),
 				ArrayHelper.toIntArray( columnNumbers ),
 				ArrayHelper.toIntArray( formulaNumbers ) );
 
 	}
 
 	public Object initializeLazyProperty(String fieldName, Object entity, SessionImplementor session)
 			throws HibernateException {
 
 		final Serializable id = session.getContextEntityIdentifier( entity );
 
 		final EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 		if ( entry == null ) {
 			throw new HibernateException( "entity is not associated with the session: " + id );
 		}
 
         if ( LOG.isTraceEnabled() ) {
 			LOG.trace(
 					"Initializing lazy properties of: " +
 							MessageHelper.infoString( this, id, getFactory() ) +
 							", field access: " + fieldName
 			);
 		}
 
 		if ( hasCache() ) {
 			CacheKey cacheKey = session.generateCacheKey( id, getIdentifierType(), getEntityName() );
 			Object ce = getCacheAccessStrategy().get( cacheKey, session.getTimestamp() );
 			if (ce!=null) {
 				CacheEntry cacheEntry = (CacheEntry) getCacheEntryStructure().destructure(ce, factory);
 				if ( !cacheEntry.areLazyPropertiesUnfetched() ) {
 					//note early exit here:
 					return initializeLazyPropertiesFromCache( fieldName, entity, session, entry, cacheEntry );
 				}
 			}
 		}
 
 		return initializeLazyPropertiesFromDatastore( fieldName, entity, session, id, entry );
 
 	}
 
 	private Object initializeLazyPropertiesFromDatastore(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Serializable id,
 			final EntityEntry entry) {
 
         if (!hasLazyProperties()) throw new AssertionFailure("no lazy properties");
 
         LOG.trace("Initializing lazy properties from datastore");
 
 		try {
 
 			Object result = null;
 			PreparedStatement ps = null;
 			try {
 				final String lazySelect = getSQLLazySelectString();
 				ResultSet rs = null;
 				try {
 					if ( lazySelect != null ) {
 						// null sql means that the only lazy properties
 						// are shared PK one-to-one associations which are
 						// handled differently in the Type#nullSafeGet code...
 						ps = session.getTransactionCoordinator()
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( lazySelect );
 						getIdentifierType().nullSafeSet( ps, id, 1, session );
 						rs = ps.executeQuery();
 						rs.next();
 					}
 					final Object[] snapshot = entry.getLoadedState();
 					for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 						Object propValue = lazyPropertyTypes[j].nullSafeGet( rs, lazyPropertyColumnAliases[j], session, entity );
 						if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 							result = propValue;
 						}
 					}
 				}
 				finally {
 					if ( rs != null ) {
 						rs.close();
 					}
 				}
 			}
 			finally {
 				if ( ps != null ) {
 					ps.close();
 				}
 			}
 
             LOG.trace("Done initializing lazy properties");
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize lazy properties: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getSQLLazySelectString()
 				);
 		}
 	}
 
 	private Object initializeLazyPropertiesFromCache(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final EntityEntry entry,
 			final CacheEntry cacheEntry
 	) {
 
         LOG.trace("Initializing lazy properties from second-level cache");
 
 		Object result = null;
 		Serializable[] disassembledValues = cacheEntry.getDisassembledState();
 		final Object[] snapshot = entry.getLoadedState();
 		for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 			final Object propValue = lazyPropertyTypes[j].assemble(
 					disassembledValues[ lazyPropertyNumbers[j] ],
 					session,
 					entity
 				);
 			if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 				result = propValue;
 			}
 		}
 
         LOG.trace("Done initializing lazy properties");
 
 		return result;
 	}
 
 	private boolean initializeLazyProperty(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Object[] snapshot,
 			final int j,
 			final Object propValue) {
 		setPropertyValue( entity, lazyPropertyNumbers[j], propValue, session.getEntityMode() );
 		if (snapshot != null) {
 			// object have been loaded with setReadOnly(true); HHH-2236
 			snapshot[ lazyPropertyNumbers[j] ] = lazyPropertyTypes[j].deepCopy( propValue, session.getEntityMode(), factory );
 		}
 		return fieldName.equals( lazyPropertyNames[j] );
 	}
 
 	public boolean isBatchable() {
 		return optimisticLockMode()==Versioning.OPTIMISTIC_LOCK_NONE ||
 			( !isVersioned() && optimisticLockMode()==Versioning.OPTIMISTIC_LOCK_VERSION ) ||
 			getFactory().getSettings().isJdbcBatchVersionedData();
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return getPropertySpaces();
 	}
 
 	protected Set getLazyProperties() {
 		return lazyProperties;
 	}
 
 	public boolean isBatchLoadable() {
 		return batchSize > 1;
 	}
 
 	public String[] getIdentifierColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		return rootTableKeyColumnReaders;
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		return rootTableKeyColumnReaderTemplates;
 	}
 
 	protected int getIdentifierColumnSpan() {
 		return identifierColumnSpan;
 	}
 
 	protected String[] getIdentifierAliases() {
 		return identifierAliases;
 	}
 
 	public String getVersionColumnName() {
 		return versionColumnName;
 	}
 
 	protected String getVersionedTableName() {
 		return getTableName( 0 );
 	}
 
 	protected boolean[] getSubclassColumnLazyiness() {
 		return subclassColumnLazyClosure;
 	}
 
 	protected boolean[] getSubclassFormulaLazyiness() {
 		return subclassFormulaLazyClosure;
 	}
 
 	/**
 	 * We can't immediately add to the cache if we have formulas
 	 * which must be evaluated, or if we have the possibility of
 	 * two concurrent updates to the same item being merged on
 	 * the database. This can happen if (a) the item is not
 	 * versioned and either (b) we have dynamic update enabled
 	 * or (c) we have multiple tables holding the state of the
 	 * item.
 	 */
 	public boolean isCacheInvalidationRequired() {
 		return hasFormulaProperties() ||
 				( !isVersioned() && ( entityMetamodel.isDynamicUpdate() || getTableSpan() > 1 ) );
 	}
 
 	public boolean isLazyPropertiesCacheable() {
 		return isLazyPropertiesCacheable;
 	}
 
 	public String selectFragment(String alias, String suffix) {
 		return identifierSelectFragment( alias, suffix ) +
 				propertySelectFragment( alias, suffix, false );
 	}
 
 	public String[] getIdentifierAliases(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getIdentiferColumnNames() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return new Alias( suffix ).toAliasStrings( getIdentifierAliases() );
 	}
 
 	public String[] getPropertyAliases(String suffix, int i) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		return new Alias( suffix ).toUnquotedAliasStrings( propertyColumnAliases[i] );
 	}
 
 	public String getDiscriminatorAlias(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getdiscriminatorColumnName() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return entityMetamodel.hasSubclasses() ?
 				new Alias( suffix ).toAliasString( getDiscriminatorAlias() ) :
 				null;
 	}
 
 	public String identifierSelectFragment(String name, String suffix) {
 		return new SelectFragment()
 				.setSuffix( suffix )
 				.addColumns( name, getIdentifierColumnNames(), getIdentifierAliases() )
 				.toFragmentString()
 				.substring( 2 ); //strip leading ", "
 	}
 
 
 	public String propertySelectFragment(String tableAlias, String suffix, boolean allProperties) {
 		return propertySelectFragmentFragment( tableAlias, suffix, allProperties ).toFragmentString();
 	}
 
 	public SelectFragment propertySelectFragmentFragment(
 			String tableAlias,
 			String suffix,
 			boolean allProperties) {
 		SelectFragment select = new SelectFragment()
 				.setSuffix( suffix )
 				.setUsedAliases( getIdentifierAliases() );
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < getSubclassColumnClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassColumnLazyClosure[i] ) &&
 				!isSubclassTableSequentialSelect( columnTableNumbers[i] ) &&
 				subclassColumnSelectableClosure[i];
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, columnTableNumbers[i] );
 				select.addColumnTemplate( subalias, columnReaderTemplates[i], columnAliases[i] );
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < getSubclassFormulaTemplateClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassFormulaLazyClosure[i] )
 				&& !isSubclassTableSequentialSelect( formulaTableNumbers[i] );
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, formulaTableNumbers[i] );
 				select.addFormula( subalias, formulaTemplates[i], formulaAliases[i] );
 			}
 		}
 
 		if ( entityMetamodel.hasSubclasses() ) {
 			addDiscriminatorToSelect( select, tableAlias, suffix );
 		}
 
 		if ( hasRowId() ) {
 			select.addColumn( tableAlias, rowIdName, ROWID_ALIAS );
 		}
 
 		return select;
 	}
 
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 			throws HibernateException {
 
         if (LOG.isTraceEnabled()) LOG.trace("Getting current persistent state for: "
                                             + MessageHelper.infoString(this, id, getFactory()));
 
 		try {
 			PreparedStatement ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getSQLSnapshotSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				//if ( isVersioned() ) getVersionType().nullSafeSet( ps, version, getIdentifierColumnSpan()+1, session );
 				ResultSet rs = ps.executeQuery();
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					//otherwise return the "hydrated" state (ie. associations are not resolved)
 					Type[] types = getPropertyTypes();
 					Object[] values = new Object[types.length];
 					boolean[] includeProperty = getPropertyUpdateability();
 					for ( int i = 0; i < types.length; i++ ) {
 						if ( includeProperty[i] ) {
 							values[i] = types[i].hydrate( rs, getPropertyAliases( "", i ), session, null ); //null owner ok??
 						}
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
index 55d6d3b0f8..ba9b5f1786 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
@@ -1,299 +1,300 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.entity;
 
 import java.util.HashMap;
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.Mapping;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.sql.Template;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Basic implementation of the {@link PropertyMapping} contract.
  *
  * @author Gavin King
  */
 public abstract class AbstractPropertyMapping implements PropertyMapping {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractPropertyMapping.class.getName());
 
 	private final Map typesByPropertyPath = new HashMap();
 	private final Map columnsByPropertyPath = new HashMap();
 	private final Map columnReadersByPropertyPath = new HashMap();
 	private final Map columnReaderTemplatesByPropertyPath = new HashMap();
 	private final Map formulaTemplatesByPropertyPath = new HashMap();
 
 	public String[] getIdentifierColumnNames() {
 		throw new UnsupportedOperationException("one-to-one is not supported here");
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		throw new UnsupportedOperationException("one-to-one is not supported here");
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		throw new UnsupportedOperationException("one-to-one is not supported here");
 	}
 
 	protected abstract String getEntityName();
 
 	public Type toType(String propertyName) throws QueryException {
 		Type type = (Type) typesByPropertyPath.get(propertyName);
 		if ( type == null ) {
 			throw propertyException( propertyName );
 		}
 		return type;
 	}
 
 	protected final QueryException propertyException(String propertyName) throws QueryException {
 		return new QueryException( "could not resolve property: " + propertyName + " of: " + getEntityName() );
 	}
 
 	public String[] getColumnNames(String propertyName) {
 		String[] cols = (String[]) columnsByPropertyPath.get(propertyName);
 		if (cols==null) {
 			throw new MappingException("unknown property: " + propertyName);
 		}
 		return cols;
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		//TODO: *two* hashmap lookups here is one too many...
 		String[] columns = (String[]) columnsByPropertyPath.get(propertyName);
 		if ( columns == null ) {
 			throw propertyException( propertyName );
 		}
 		String[] formulaTemplates = (String[]) formulaTemplatesByPropertyPath.get(propertyName);
 		String[] columnReaderTemplates = (String[]) columnReaderTemplatesByPropertyPath.get(propertyName);
 		String[] result = new String[columns.length];
 		for ( int i=0; i<columns.length; i++ ) {
 			if ( columnReaderTemplates[i]==null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.replace( columnReaderTemplates[i], Template.TEMPLATE, alias );
 			}
 		}
 		return result;
 	}
 
 	public String[] toColumns(String propertyName) throws QueryException {
 		String[] columns = (String[]) columnsByPropertyPath.get(propertyName);
 		if ( columns == null ) {
 			throw propertyException( propertyName );
 		}
 		String[] formulaTemplates = (String[]) formulaTemplatesByPropertyPath.get(propertyName);
 		String[] columnReaders = (String[]) columnReadersByPropertyPath.get(propertyName);
 		String[] result = new String[columns.length];
 		for ( int i=0; i<columns.length; i++ ) {
 			if ( columnReaders[i]==null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, "" );
 			}
 			else {
 				result[i] = columnReaders[i];
 			}
 		}
 		return result;
 	}
 
 	protected void addPropertyPath(
 			String path,
 			Type type,
 			String[] columns,
 			String[] columnReaders,
 			String[] columnReaderTemplates,
 			String[] formulaTemplates) {
 		// TODO : not quite sure yet of the difference, but this is only needed from annotations for @Id @ManyToOne support
 		if ( typesByPropertyPath.containsKey( path ) ) {
             LOG.trace("Skipping duplicate registration of path [" + path + "], existing type = [" + typesByPropertyPath.get(path)
                       + "], incoming type = [" + type + "]");
 			return;
 		}
 		typesByPropertyPath.put(path, type);
 		columnsByPropertyPath.put(path, columns);
 		columnReadersByPropertyPath.put(path, columnReaders);
 		columnReaderTemplatesByPropertyPath.put(path, columnReaderTemplates);
 		if (formulaTemplates!=null) {
 			formulaTemplatesByPropertyPath.put(path, formulaTemplates);
 		}
 	}
 
 	/*protected void initPropertyPaths(
 			final String path,
 			final Type type,
 			final String[] columns,
 			final String[] formulaTemplates,
 			final Mapping factory)
 	throws MappingException {
 		//addFormulaPropertyPath(path, type, formulaTemplates);
 		initPropertyPaths(path, type, columns, formulaTemplates, factory);
 	}*/
 
 	protected void initPropertyPaths(
 			final String path,
 			final Type type,
 			String[] columns,
 			String[] columnReaders,
 			String[] columnReaderTemplates,
 			final String[] formulaTemplates,
 			final Mapping factory)
 	throws MappingException {
 
 		if ( columns.length!=type.getColumnSpan(factory) ) {
 			throw new MappingException(
 					"broken column mapping for: " + path +
 					" of: " + getEntityName()
 				);
 		}
 
 		if ( type.isAssociationType() ) {
 			AssociationType actype = (AssociationType) type;
 			if ( actype.useLHSPrimaryKey() ) {
 				columns = getIdentifierColumnNames();
 				columnReaders = getIdentifierColumnReaders();
 				columnReaderTemplates = getIdentifierColumnReaderTemplates();
 			}
 			else {
 				String foreignKeyProperty = actype.getLHSPropertyName();
 				if ( foreignKeyProperty!=null && !path.equals(foreignKeyProperty) ) {
 					//TODO: this requires that the collection is defined after the
 					//      referenced property in the mapping file (ok?)
 					columns = (String[]) columnsByPropertyPath.get(foreignKeyProperty);
 					if (columns==null) return; //get em on the second pass!
 					columnReaders = (String[]) columnReadersByPropertyPath.get(foreignKeyProperty);
 					columnReaderTemplates = (String[]) columnReaderTemplatesByPropertyPath.get(foreignKeyProperty);
 				}
 			}
 		}
 
 		if (path!=null) addPropertyPath(path, type, columns, columnReaders, columnReaderTemplates, formulaTemplates);
 
 		if ( type.isComponentType() ) {
 			CompositeType actype = (CompositeType) type;
 			initComponentPropertyPaths( path, actype, columns, columnReaders, columnReaderTemplates, formulaTemplates, factory );
 			if ( actype.isEmbedded() ) {
 				initComponentPropertyPaths(
 						path==null ? null : StringHelper.qualifier(path),
 						actype,
 						columns,
 						columnReaders,
 						columnReaderTemplates,
 						formulaTemplates,
 						factory
 					);
 			}
 		}
 		else if ( type.isEntityType() ) {
 			initIdentifierPropertyPaths( path, (EntityType) type, columns, columnReaders, columnReaderTemplates, factory );
 		}
 	}
 
 	protected void initIdentifierPropertyPaths(
 			final String path,
 			final EntityType etype,
 			final String[] columns,
 			final String[] columnReaders,
 			final String[] columnReaderTemplates,
 			final Mapping factory) throws MappingException {
 
 		Type idtype = etype.getIdentifierOrUniqueKeyType( factory );
 		String idPropName = etype.getIdentifierOrUniqueKeyPropertyName(factory);
 		boolean hasNonIdentifierPropertyNamedId = hasNonIdentifierPropertyNamedId( etype, factory );
 
 		if ( etype.isReferenceToPrimaryKey() ) {
 			if ( !hasNonIdentifierPropertyNamedId ) {
 				String idpath1 = extendPath(path, EntityPersister.ENTITY_ID);
 				addPropertyPath(idpath1, idtype, columns, columnReaders, columnReaderTemplates, null);
 				initPropertyPaths(idpath1, idtype, columns, columnReaders, columnReaderTemplates, null, factory);
 			}
 		}
 
 		if (idPropName!=null) {
 			String idpath2 = extendPath(path, idPropName);
 			addPropertyPath(idpath2, idtype, columns, columnReaders, columnReaderTemplates, null);
 			initPropertyPaths(idpath2, idtype, columns, columnReaders, columnReaderTemplates, null, factory);
 		}
 	}
 
 	private boolean hasNonIdentifierPropertyNamedId(final EntityType entityType, final Mapping factory) {
 		// TODO : would be great to have a Mapping#hasNonIdentifierPropertyNamedId method
 		// I don't believe that Mapping#getReferencedPropertyType accounts for the identifier property; so
 		// if it returns for a property named 'id', then we should have a non-id field named id
 		try {
 			return factory.getReferencedPropertyType( entityType.getAssociatedEntityName(), EntityPersister.ENTITY_ID ) != null;
 		}
 		catch( MappingException e ) {
 			return false;
 		}
 	}
 
 	protected void initComponentPropertyPaths(
 			final String path,
 			final CompositeType type,
 			final String[] columns,
 			final String[] columnReaders,
 			final String[] columnReaderTemplates,
 			String[] formulaTemplates, final Mapping factory) throws MappingException {
 
 		Type[] types = type.getSubtypes();
 		String[] properties = type.getPropertyNames();
 		int begin=0;
 		for ( int i=0; i<properties.length; i++ ) {
 			String subpath = extendPath( path, properties[i] );
 			try {
 				int length = types[i].getColumnSpan(factory);
 				String[] columnSlice = ArrayHelper.slice(columns, begin, length);
 				String[] columnReaderSlice = ArrayHelper.slice(columnReaders, begin, length);
 				String[] columnReaderTemplateSlice = ArrayHelper.slice( columnReaderTemplates, begin, length );
 				String[] formulaSlice = formulaTemplates==null ?
 						null : ArrayHelper.slice(formulaTemplates, begin, length);
 				initPropertyPaths(subpath, types[i], columnSlice, columnReaderSlice, columnReaderTemplateSlice, formulaSlice, factory);
 				begin+=length;
 			}
 			catch (Exception e) {
 				throw new MappingException("bug in initComponentPropertyPaths", e);
 			}
 		}
 	}
 
 	private static String extendPath(String path, String property) {
 		if ( path==null || "".equals(path) ) {
 			return property;
 		}
 		else {
 			return StringHelper.qualify(path, property);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/NamedQueryLoader.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/NamedQueryLoader.java
index a9cb2f407e..0850bf3c6a 100755
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/NamedQueryLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/NamedQueryLoader.java
@@ -1,86 +1,86 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.FlushMode;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockOptions;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.impl.AbstractQueryImpl;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 
 /**
  * Not really a <tt>Loader</tt>, just a wrapper around a
  * named query.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public final class NamedQueryLoader implements UniqueEntityLoader {
 	private final String queryName;
 	private final EntityPersister persister;
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, NamedQueryLoader.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, NamedQueryLoader.class.getName());
 
 	public NamedQueryLoader(String queryName, EntityPersister persister) {
 		super();
 		this.queryName = queryName;
 		this.persister = persister;
 	}
 
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session, LockOptions lockOptions) {
         if (lockOptions != null) LOG.debugf("Ignoring lock-options passed to named query loader");
 		return load( id, optionalObject, session );
 	}
 
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session) {
         LOG.debugf("Loading entity: %s using named query: %s", persister.getEntityName(), queryName);
 
 		AbstractQueryImpl query = (AbstractQueryImpl) session.getNamedQuery(queryName);
 		if ( query.hasNamedParameters() ) {
 			query.setParameter(
 					query.getNamedParameters()[0],
 					id,
 					persister.getIdentifierType()
 				);
 		}
 		else {
 			query.setParameter( 0, id, persister.getIdentifierType() );
 		}
 		query.setOptionalId(id);
 		query.setOptionalEntityName( persister.getEntityName() );
 		query.setOptionalObject(optionalObject);
 		query.setFlushMode( FlushMode.MANUAL );
 		query.list();
 
 		// now look up the object we are really interested in!
 		// (this lets us correctly handle proxies and multi-row or multi-column queries)
 		return session.getPersistenceContext().getEntity( session.generateEntityKey( id, persister ) );
 
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/pretty/Printer.java b/hibernate-core/src/main/java/org/hibernate/pretty/Printer.java
index acfd6424ca..40af4d61be 100644
--- a/hibernate-core/src/main/java/org/hibernate/pretty/Printer.java
+++ b/hibernate-core/src/main/java/org/hibernate/pretty/Printer.java
@@ -1,119 +1,119 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.pretty;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.TypedValue;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Renders entities to a nicely readable string.
  * @author Gavin King
  */
 public final class Printer {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Printer.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Printer.class.getName());
 
     private SessionFactoryImplementor factory;
 
 	/**
 	 * @param entity an actual entity object, not a proxy!
 	 */
 	public String toString(Object entity, EntityMode entityMode) throws HibernateException {
 
 		// todo : this call will not work for anything other than pojos!
 		ClassMetadata cm = factory.getClassMetadata( entity.getClass() );
 
 		if ( cm==null ) return entity.getClass().getName();
 
 		Map result = new HashMap();
 
 		if ( cm.hasIdentifierProperty() ) {
 			result.put(
 				cm.getIdentifierPropertyName(),
 				cm.getIdentifierType().toLoggableString( cm.getIdentifier( entity, entityMode ), factory )
 			);
 		}
 
 		Type[] types = cm.getPropertyTypes();
 		String[] names = cm.getPropertyNames();
 		Object[] values = cm.getPropertyValues( entity, entityMode );
 		for ( int i=0; i<types.length; i++ ) {
 			if ( !names[i].startsWith("_") ) {
 				String strValue = values[i]==LazyPropertyInitializer.UNFETCHED_PROPERTY ?
 					values[i].toString() :
 					types[i].toLoggableString( values[i], factory );
 				result.put( names[i], strValue );
 			}
 		}
 		return cm.getEntityName() + result.toString();
 	}
 
 	public String toString(Type[] types, Object[] values) throws HibernateException {
 		List list = new ArrayList( types.length * 5 );
 		for ( int i=0; i<types.length; i++ ) {
 			if ( types[i]!=null ) list.add( types[i].toLoggableString( values[i], factory ) );
 		}
 		return list.toString();
 	}
 
 	public String toString(Map namedTypedValues) throws HibernateException {
 		Map result = new HashMap();
 		Iterator iter = namedTypedValues.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = (Map.Entry) iter.next();
 			TypedValue tv = (TypedValue) me.getValue();
 			result.put( me.getKey(), tv.getType().toLoggableString( tv.getValue(), factory ) );
 		}
 		return result.toString();
 	}
 
 	public void toString(Iterator iter, EntityMode entityMode) throws HibernateException {
         if (!LOG.isDebugEnabled() || !iter.hasNext()) return;
         LOG.debugf("Listing entities:");
 		int i=0;
 		while ( iter.hasNext() ) {
 			if (i++>20) {
                 LOG.debugf("More......");
 				break;
 			}
             LOG.debugf(toString(iter.next(), entityMode));
 		}
 	}
 
 	public Printer(SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java b/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
index 7d9e219eac..8860f4ed58 100644
--- a/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
@@ -1,384 +1,385 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.property;
 import java.beans.Introspector;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Member;
 import java.lang.reflect.Method;
 import java.util.Map;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.PropertyAccessException;
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.ReflectHelper;
+
 import org.jboss.logging.Logger;
 
 /**
  * Accesses property values via a get/set pair, which may be nonpublic.
  * The default (and recommended strategy).
  *
  * @author Gavin King
  */
 public class BasicPropertyAccessor implements PropertyAccessor {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BasicPropertyAccessor.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BasicPropertyAccessor.class.getName());
 
 	public static final class BasicSetter implements Setter {
 		private Class clazz;
 		private final transient Method method;
 		private final String propertyName;
 
 		private BasicSetter(Class clazz, Method method, String propertyName) {
 			this.clazz=clazz;
 			this.method=method;
 			this.propertyName=propertyName;
 		}
 
 		public void set(Object target, Object value, SessionFactoryImplementor factory)
 		throws HibernateException {
 			try {
 				method.invoke( target, value );
 			}
 			catch (NullPointerException npe) {
 				if ( value==null && method.getParameterTypes()[0].isPrimitive() ) {
 					throw new PropertyAccessException(
 							npe,
 							"Null value was assigned to a property of primitive type",
 							true,
 							clazz,
 							propertyName
 						);
 				}
 				else {
 					throw new PropertyAccessException(
 							npe,
 							"NullPointerException occurred while calling",
 							true,
 							clazz,
 							propertyName
 						);
 				}
 			}
 			catch (InvocationTargetException ite) {
 				throw new PropertyAccessException(
 						ite,
 						"Exception occurred inside",
 						true,
 						clazz,
 						propertyName
 					);
 			}
 			catch (IllegalAccessException iae) {
 				throw new PropertyAccessException(
 						iae,
 						"IllegalAccessException occurred while calling",
 						true,
 						clazz,
 						propertyName
 					);
 				//cannot occur
 			}
 			catch (IllegalArgumentException iae) {
 				if ( value==null && method.getParameterTypes()[0].isPrimitive() ) {
 					throw new PropertyAccessException(
 							iae,
 							"Null value was assigned to a property of primitive type",
 							true,
 							clazz,
 							propertyName
 						);
 				}
 				else {
                     LOG.illegalPropertySetterArgument(clazz.getName(), propertyName);
                     LOG.expectedType(method.getParameterTypes()[0].getName(), value == null ? null : value.getClass().getName());
 					throw new PropertyAccessException(
 							iae,
 							"IllegalArgumentException occurred while calling",
 							true,
 							clazz,
 							propertyName
 						);
 				}
 			}
 		}
 
 		public Method getMethod() {
 			return method;
 		}
 
 		public String getMethodName() {
 			return method.getName();
 		}
 
 		Object readResolve() {
 			return createSetter(clazz, propertyName);
 		}
 
 		@Override
         public String toString() {
 			return "BasicSetter(" + clazz.getName() + '.' + propertyName + ')';
 		}
 	}
 
 	public static final class BasicGetter implements Getter {
 		private Class clazz;
 		private final transient Method method;
 		private final String propertyName;
 
 		private BasicGetter(Class clazz, Method method, String propertyName) {
 			this.clazz=clazz;
 			this.method=method;
 			this.propertyName=propertyName;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Object get(Object target) throws HibernateException {
 			try {
 				return method.invoke( target, (Object[]) null );
 			}
 			catch (InvocationTargetException ite) {
 				throw new PropertyAccessException(
 						ite,
 						"Exception occurred inside",
 						false,
 						clazz,
 						propertyName
 					);
 			}
 			catch (IllegalAccessException iae) {
 				throw new PropertyAccessException(
 						iae,
 						"IllegalAccessException occurred while calling",
 						false,
 						clazz,
 						propertyName
 					);
 				//cannot occur
 			}
 			catch (IllegalArgumentException iae) {
                 LOG.illegalPropertyGetterArgument(clazz.getName(), propertyName);
 				throw new PropertyAccessException(
 						iae,
 						"IllegalArgumentException occurred calling",
 						false,
 						clazz,
 						propertyName
 					);
 			}
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Object getForInsert(Object target, Map mergeMap, SessionImplementor session) {
 			return get( target );
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Class getReturnType() {
 			return method.getReturnType();
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Member getMember() {
 			return method;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Method getMethod() {
 			return method;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public String getMethodName() {
 			return method.getName();
 		}
 
 		@Override
         public String toString() {
 			return "BasicGetter(" + clazz.getName() + '.' + propertyName + ')';
 		}
 
 		Object readResolve() {
 			return createGetter(clazz, propertyName);
 		}
 	}
 
 
 	public Setter getSetter(Class theClass, String propertyName)
 	throws PropertyNotFoundException {
 		return createSetter(theClass, propertyName);
 	}
 
 	private static Setter createSetter(Class theClass, String propertyName)
 	throws PropertyNotFoundException {
 		BasicSetter result = getSetterOrNull(theClass, propertyName);
 		if (result==null) {
 			throw new PropertyNotFoundException(
 					"Could not find a setter for property " +
 					propertyName +
 					" in class " +
 					theClass.getName()
 				);
 		}
 		return result;
 	}
 
 	private static BasicSetter getSetterOrNull(Class theClass, String propertyName) {
 
 		if (theClass==Object.class || theClass==null) return null;
 
 		Method method = setterMethod(theClass, propertyName);
 
 		if (method!=null) {
 			if ( !ReflectHelper.isPublic(theClass, method) ) method.setAccessible(true);
 			return new BasicSetter(theClass, method, propertyName);
 		}
 		else {
 			BasicSetter setter = getSetterOrNull( theClass.getSuperclass(), propertyName );
 			if (setter==null) {
 				Class[] interfaces = theClass.getInterfaces();
 				for ( int i=0; setter==null && i<interfaces.length; i++ ) {
 					setter=getSetterOrNull( interfaces[i], propertyName );
 				}
 			}
 			return setter;
 		}
 
 	}
 
 	private static Method setterMethod(Class theClass, String propertyName) {
 
 		BasicGetter getter = getGetterOrNull(theClass, propertyName);
 		Class returnType = (getter==null) ? null : getter.getReturnType();
 
 		Method[] methods = theClass.getDeclaredMethods();
 		Method potentialSetter = null;
 		for ( Method method : methods ) {
 			final String methodName = method.getName();
 
 			if ( method.getParameterTypes().length == 1 && methodName.startsWith( "set" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 3 ) );
 				String testOldMethod = methodName.substring( 3 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					potentialSetter = method;
 					if ( returnType == null || method.getParameterTypes()[0].equals( returnType ) ) {
 						return potentialSetter;
 					}
 				}
 			}
 		}
 		return potentialSetter;
 	}
 
 	public Getter getGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		return createGetter(theClass, propertyName);
 	}
 
 	public static Getter createGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		BasicGetter result = getGetterOrNull(theClass, propertyName);
 		if (result==null) {
 			throw new PropertyNotFoundException(
 					"Could not find a getter for " +
 					propertyName +
 					" in class " +
 					theClass.getName()
 			);
 		}
 		return result;
 	}
 
 	private static BasicGetter getGetterOrNull(Class theClass, String propertyName) {
 		if (theClass==Object.class || theClass==null) {
 			return null;
 		}
 
 		Method method = getterMethod(theClass, propertyName);
 
 		if (method!=null) {
 			if ( !ReflectHelper.isPublic( theClass, method ) ) {
 				method.setAccessible(true);
 			}
 			return new BasicGetter(theClass, method, propertyName);
 		}
 		else {
 			BasicGetter getter = getGetterOrNull( theClass.getSuperclass(), propertyName );
 			if (getter==null) {
 				Class[] interfaces = theClass.getInterfaces();
 				for ( int i=0; getter==null && i<interfaces.length; i++ ) {
 					getter=getGetterOrNull( interfaces[i], propertyName );
 				}
 			}
 			return getter;
 		}
 	}
 
 	private static Method getterMethod(Class theClass, String propertyName) {
 		Method[] methods = theClass.getDeclaredMethods();
 		for ( Method method : methods ) {
 			// if the method has parameters, skip it
 			if ( method.getParameterTypes().length != 0 ) {
 				continue;
 			}
 			// if the method is a "bridge", skip it
 			if ( method.isBridge() ) {
 				continue;
 			}
 
 			final String methodName = method.getName();
 
 			// try "get"
 			if ( methodName.startsWith( "get" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 3 ) );
 				String testOldMethod = methodName.substring( 3 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					return method;
 				}
 			}
 
 			// if not "get", then try "is"
 			if ( methodName.startsWith( "is" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 2 ) );
 				String testOldMethod = methodName.substring( 2 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					return method;
 				}
 			}
 		}
 
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistLazyInitializer.java b/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistLazyInitializer.java
index 789c167718..7fd03f8836 100644
--- a/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistLazyInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistLazyInitializer.java
@@ -1,229 +1,229 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.proxy.pojo.javassist;
 
 import java.io.Serializable;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import javassist.util.proxy.MethodFilter;
 import javassist.util.proxy.MethodHandler;
 import javassist.util.proxy.ProxyFactory;
 import javassist.util.proxy.ProxyObject;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.pojo.BasicLazyInitializer;
 import org.hibernate.type.CompositeType;
 import org.jboss.logging.Logger;
 
 /**
  * A Javassist-based lazy initializer proxy.
  *
  * @author Muga Nishizawa
  */
 public class JavassistLazyInitializer extends BasicLazyInitializer implements MethodHandler {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        JavassistLazyInitializer.class.getName());
 
 	private static final MethodFilter FINALIZE_FILTER = new MethodFilter() {
 		public boolean isHandled(Method m) {
 			// skip finalize methods
 			return !( m.getParameterTypes().length == 0 && m.getName().equals( "finalize" ) );
 		}
 	};
 
 	private Class[] interfaces;
 	private boolean constructed = false;
 
 	private JavassistLazyInitializer(
 			final String entityName,
 	        final Class persistentClass,
 	        final Class[] interfaces,
 	        final Serializable id,
 	        final Method getIdentifierMethod,
 	        final Method setIdentifierMethod,
 	        final CompositeType componentIdType,
 	        final SessionImplementor session) {
 		super( entityName, persistentClass, id, getIdentifierMethod, setIdentifierMethod, componentIdType, session );
 		this.interfaces = interfaces;
 	}
 
 	public static HibernateProxy getProxy(
 			final String entityName,
 	        final Class persistentClass,
 	        final Class[] interfaces,
 	        final Method getIdentifierMethod,
 	        final Method setIdentifierMethod,
 	        CompositeType componentIdType,
 	        final Serializable id,
 	        final SessionImplementor session) throws HibernateException {
 		// note: interface is assumed to already contain HibernateProxy.class
 		try {
 			final JavassistLazyInitializer instance = new JavassistLazyInitializer(
 					entityName,
 			        persistentClass,
 			        interfaces,
 			        id,
 			        getIdentifierMethod,
 			        setIdentifierMethod,
 			        componentIdType,
 			        session
 			);
 			ProxyFactory factory = new ProxyFactory();
 			factory.setSuperclass( interfaces.length == 1 ? persistentClass : null );
 			factory.setInterfaces( interfaces );
 			factory.setFilter( FINALIZE_FILTER );
 			Class cl = factory.createClass();
 			final HibernateProxy proxy = ( HibernateProxy ) cl.newInstance();
 			( ( ProxyObject ) proxy ).setHandler( instance );
 			instance.constructed = true;
 			return proxy;
 		}
 		catch ( Throwable t ) {
             LOG.error(LOG.javassistEnhancementFailed(entityName), t);
             throw new HibernateException(LOG.javassistEnhancementFailed(entityName), t);
 		}
 	}
 
 	public static HibernateProxy getProxy(
 			final Class factory,
 	        final String entityName,
 	        final Class persistentClass,
 	        final Class[] interfaces,
 	        final Method getIdentifierMethod,
 	        final Method setIdentifierMethod,
 	        final CompositeType componentIdType,
 	        final Serializable id,
 	        final SessionImplementor session) throws HibernateException {
 
 		final JavassistLazyInitializer instance = new JavassistLazyInitializer(
 				entityName,
 		        persistentClass,
 		        interfaces, id,
 		        getIdentifierMethod,
 		        setIdentifierMethod,
 		        componentIdType,
 		        session
 		);
 
 		final HibernateProxy proxy;
 		try {
 			proxy = ( HibernateProxy ) factory.newInstance();
 		}
 		catch ( Exception e ) {
 			throw new HibernateException(
 					"Javassist Enhancement failed: "
 					+ persistentClass.getName(), e
 			);
 		}
 		( ( ProxyObject ) proxy ).setHandler( instance );
 		instance.constructed = true;
 		return proxy;
 	}
 
 	public static Class getProxyFactory(
 			Class persistentClass,
 	        Class[] interfaces) throws HibernateException {
 		// note: interfaces is assumed to already contain HibernateProxy.class
 
 		try {
 			ProxyFactory factory = new ProxyFactory();
 			factory.setSuperclass( interfaces.length == 1 ? persistentClass : null );
 			factory.setInterfaces( interfaces );
 			factory.setFilter( FINALIZE_FILTER );
 			return factory.createClass();
 		}
 		catch ( Throwable t ) {
             LOG.error(LOG.javassistEnhancementFailed(persistentClass.getName()), t);
             throw new HibernateException(LOG.javassistEnhancementFailed(persistentClass.getName()), t);
 		}
 	}
 
 	public Object invoke(
 			final Object proxy,
 			final Method thisMethod,
 			final Method proceed,
 			final Object[] args) throws Throwable {
 		if ( this.constructed ) {
 			Object result;
 			try {
 				result = this.invoke( thisMethod, args, proxy );
 			}
 			catch ( Throwable t ) {
 				throw new Exception( t.getCause() );
 			}
 			if ( result == INVOKE_IMPLEMENTATION ) {
 				Object target = getImplementation();
 				final Object returnValue;
 				try {
 					if ( ReflectHelper.isPublic( persistentClass, thisMethod ) ) {
 						if ( !thisMethod.getDeclaringClass().isInstance( target ) ) {
 							throw new ClassCastException( target.getClass().getName() );
 						}
 						returnValue = thisMethod.invoke( target, args );
 					}
 					else {
 						if ( !thisMethod.isAccessible() ) {
 							thisMethod.setAccessible( true );
 						}
 						returnValue = thisMethod.invoke( target, args );
 					}
 					return returnValue == target ? proxy : returnValue;
 				}
 				catch ( InvocationTargetException ite ) {
 					throw ite.getTargetException();
 				}
 			}
 			else {
 				return result;
 			}
 		}
 		else {
 			// while constructor is running
 			if ( thisMethod.getName().equals( "getHibernateLazyInitializer" ) ) {
 				return this;
 			}
 			else {
 				return proceed.invoke( proxy, args );
 			}
 		}
 	}
 
 	@Override
     protected Object serializableProxy() {
 		return new SerializableProxy(
 				getEntityName(),
 		        persistentClass,
 		        interfaces,
 		        getIdentifier(),
 		        ( isReadOnlySettingAvailable() ? Boolean.valueOf( isReadOnly() ) : isReadOnlyBeforeAttachedToSession() ),
 		        getIdentifierMethod,
 		        setIdentifierMethod,
 		        componentIdType
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/secure/JACCConfiguration.java b/hibernate-core/src/main/java/org/hibernate/secure/JACCConfiguration.java
index 8f4bf9e390..e398448ddb 100755
--- a/hibernate-core/src/main/java/org/hibernate/secure/JACCConfiguration.java
+++ b/hibernate-core/src/main/java/org/hibernate/secure/JACCConfiguration.java
@@ -1,86 +1,87 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.secure;
 import java.util.StringTokenizer;
 import javax.security.jacc.EJBMethodPermission;
 import javax.security.jacc.PolicyConfiguration;
 import javax.security.jacc.PolicyConfigurationFactory;
 import javax.security.jacc.PolicyContextException;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * Adds Hibernate permissions to roles via JACC
  *
  * @author Gavin King
  */
 public class JACCConfiguration {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JACCConfiguration.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JACCConfiguration.class.getName());
 
 	private final PolicyConfiguration policyConfiguration;
 
 	public JACCConfiguration(String contextId) throws HibernateException {
 		try {
 			policyConfiguration = PolicyConfigurationFactory
 					.getPolicyConfigurationFactory()
 					.getPolicyConfiguration( contextId, false );
 		}
 		catch (ClassNotFoundException cnfe) {
 			throw new HibernateException( "JACC provider class not found", cnfe );
 		}
 		catch (PolicyContextException pce) {
 			throw new HibernateException( "policy context exception occurred", pce );
 		}
 	}
 
 	public void addPermission(String role, String entityName, String action) {
 
 		if ( action.equals( "*" ) ) {
 			action = "insert,read,update,delete";
 		}
 
 		StringTokenizer tok = new StringTokenizer( action, "," );
 
 		while ( tok.hasMoreTokens() ) {
 			String methodName = tok.nextToken().trim();
 			EJBMethodPermission permission = new EJBMethodPermission(
 					entityName,
 					methodName,
 					null, // interfaces
 					null // arguments
 				);
 
             LOG.debugf("Adding permission to role %s: %s", role, permission);
 			try {
 				policyConfiguration.addToRole( role, permission );
 			}
 			catch (PolicyContextException pce) {
 				throw new HibernateException( "policy context exception occurred", pce );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/internal/AbstractServiceRegistryImpl.java b/hibernate-core/src/main/java/org/hibernate/service/internal/AbstractServiceRegistryImpl.java
index 679827ebfd..92ac4b03ef 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/internal/AbstractServiceRegistryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/internal/AbstractServiceRegistryImpl.java
@@ -1,250 +1,250 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.internal;
 
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.ListIterator;
 import java.util.concurrent.ConcurrentHashMap;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.service.Service;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.internal.proxy.javassist.ServiceProxyFactoryFactoryImpl;
 import org.hibernate.service.jmx.spi.JmxService;
 import org.hibernate.service.spi.InjectService;
 import org.hibernate.service.spi.Manageable;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.Startable;
 import org.hibernate.service.spi.Stoppable;
 import org.hibernate.service.UnknownServiceException;
 import org.hibernate.service.spi.proxy.ServiceProxyFactory;
 
 /**
  * @author Steve Ebersole
  */
 public abstract class AbstractServiceRegistryImpl implements ServiceRegistryImplementor {
-	private static final HibernateLogger LOG = Logger.getMessageLogger( HibernateLogger.class, AbstractServiceRegistryImpl.class.getName() );
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, AbstractServiceRegistryImpl.class.getName() );
 
 	private final ServiceRegistryImplementor parent;
 
 	// for now just hard-code the javassist factory
 	private ServiceProxyFactory serviceProxyFactory = new ServiceProxyFactoryFactoryImpl().makeServiceProxyFactory( this );
 
 	private ConcurrentHashMap<Class,ServiceBinding> serviceBindingMap;
 	// IMPL NOTE : the list used for ordered destruction.  Cannot used map above because we need to
 	// iterate it in reverse order which is only available through ListIterator
 	private List<Service> serviceList = new ArrayList<Service>();
 
 	protected AbstractServiceRegistryImpl() {
 		this( null );
 	}
 
 	protected AbstractServiceRegistryImpl(ServiceRegistryImplementor parent) {
 		this.parent = parent;
 		// assume 20 services for initial sizing
 		this.serviceBindingMap = CollectionHelper.concurrentMap( 20 );
 		this.serviceList = CollectionHelper.arrayList( 20 );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public ServiceRegistry getParentServiceRegistry() {
 		return parent;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <R extends Service> ServiceBinding<R> locateServiceBinding(Class<R> serviceRole) {
 		return locateServiceBinding( serviceRole, true );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected <R extends Service> ServiceBinding<R> locateServiceBinding(Class<R> serviceRole, boolean checkParent) {
 		ServiceBinding<R> serviceBinding = serviceBindingMap.get( serviceRole );
 		if ( serviceBinding == null && checkParent && parent != null ) {
 			// look in parent
 			serviceBinding = parent.locateServiceBinding( serviceRole );
 		}
 		return serviceBinding;
 	}
 
 	@Override
 	public <R extends Service> R getService(Class<R> serviceRole) {
 		return locateOrCreateServiceBinding( serviceRole, true ).getProxy();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected <R extends Service> ServiceBinding<R> locateOrCreateServiceBinding(Class<R> serviceRole, boolean checkParent) {
 		ServiceBinding<R> serviceBinding = locateServiceBinding( serviceRole, checkParent );
 		if ( serviceBinding == null ) {
 			createServiceBinding( serviceRole );
 		}
 		return serviceBinding;
 	}
 
 	protected <R extends Service> ServiceBinding<R> createServiceBinding(Class<R> serviceRole) {
 		R proxy = serviceProxyFactory.makeProxy( serviceRole );
 		ServiceBinding<R> serviceBinding = new ServiceBinding<R>( proxy );
 		serviceBindingMap.put( serviceRole, serviceBinding );
 		return serviceBinding;
 	}
 
 	@Override
 	public <R extends Service> void registerService(Class<R> serviceRole, R service) {
 		ServiceBinding<R> serviceBinding = locateOrCreateServiceBinding( serviceRole, false );
 		R priorServiceInstance = serviceBinding.getTarget();
 		serviceBinding.setTarget( service );
 		if ( priorServiceInstance != null ) {
 			serviceList.remove( priorServiceInstance );
 		}
 		serviceList.add( service );
 	}
 
 	private <R extends Service> R initializeService(Class<R> serviceRole) {
         LOG.trace("Initializing service [role=" + serviceRole.getName() + "]");
 
 		// PHASE 1 : create service
 		R service = createService( serviceRole );
 		if ( service == null ) {
 			return null;
 		}
 
 		// PHASE 2 : configure service (***potentially recursive***)
 		configureService( service );
 
 		// PHASE 3 : Start service
 		startService( service, serviceRole );
 
 		return service;
 	}
 
 	protected abstract <T extends Service> T createService(Class<T> serviceRole);
 	protected abstract <T extends Service> void configureService(T service);
 
 	protected <T extends Service> void applyInjections(T service) {
 		try {
 			for ( Method method : service.getClass().getMethods() ) {
 				InjectService injectService = method.getAnnotation( InjectService.class );
 				if ( injectService == null ) {
 					continue;
 				}
 
 				applyInjection( service, method, injectService );
 			}
 		}
 		catch (NullPointerException e) {
             LOG.error("NPE injecting service deps : " + service.getClass().getName());
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private <T extends Service> void applyInjection(T service, Method injectionMethod, InjectService injectService) {
 		if ( injectionMethod.getParameterTypes() == null || injectionMethod.getParameterTypes().length != 1 ) {
 			throw new ServiceDependencyException(
 					"Encountered @InjectService on method with unexpected number of parameters"
 			);
 		}
 
 		Class dependentServiceRole = injectService.serviceRole();
 		if ( dependentServiceRole == null || dependentServiceRole.equals( Void.class ) ) {
 			dependentServiceRole = injectionMethod.getParameterTypes()[0];
 		}
 
 		// todo : because of the use of proxies, this is no longer returning null here...
 
 		final Service dependantService = getService( dependentServiceRole );
 		if ( dependantService == null ) {
 			if ( injectService.required() ) {
 				throw new ServiceDependencyException(
 						"Dependency [" + dependentServiceRole + "] declared by service [" + service + "] not found"
 				);
 			}
 		}
 		else {
 			try {
 				injectionMethod.invoke( service, dependantService );
 			}
 			catch ( Exception e ) {
 				throw new ServiceDependencyException( "Cannot inject dependency service", e );
 			}
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected <T extends Service> void startService(T service, Class serviceRole) {
 		if ( Startable.class.isInstance( service ) ) {
 			( (Startable) service ).start();
 		}
 
 		if ( Manageable.class.isInstance( service ) ) {
 			getService( JmxService.class ).registerService( (Manageable) service, serviceRole );
 		}
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public <R extends Service> R getServiceInternal(Class<R> serviceRole) {
 		// this call comes from the binding proxy, we most definitely do not want to look up into the parent
 		// in this case!
 		ServiceBinding<R> serviceBinding = locateServiceBinding( serviceRole, false );
 		if ( serviceBinding == null ) {
 			throw new HibernateException( "Only proxies should invoke #getServiceInternal" );
 		}
 		R service = serviceBinding.getTarget();
 		if ( service == null ) {
 			service = initializeService( serviceRole );
 			serviceBinding.setTarget( service );
 		}
 		if ( service == null ) {
 			throw new UnknownServiceException( serviceRole );
 		}
 		return service;
 	}
 
 	public void destroy() {
 		ListIterator<Service> serviceIterator = serviceList.listIterator( serviceList.size() );
 		while ( serviceIterator.hasPrevious() ) {
 			final Service service = serviceIterator.previous();
 			if ( Stoppable.class.isInstance( service ) ) {
 				try {
 					( (Stoppable) service ).stop();
 				}
 				catch ( Exception e ) {
                     LOG.unableToStopService(service.getClass(), e.toString());
 				}
 			}
 		}
 		serviceList.clear();
 		serviceList = null;
 		serviceBindingMap.clear();
 		serviceBindingMap = null;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/internal/BasicServiceRegistryImpl.java b/hibernate-core/src/main/java/org/hibernate/service/internal/BasicServiceRegistryImpl.java
index f3b7b03f2e..3ae90cf755 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/internal/BasicServiceRegistryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/internal/BasicServiceRegistryImpl.java
@@ -1,136 +1,136 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.internal;
 
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.service.BasicServiceRegistry;
 import org.hibernate.service.Service;
 import org.hibernate.service.StandardServiceInitiators;
 import org.hibernate.service.UnknownServiceException;
 import org.hibernate.service.spi.BasicServiceInitiator;
 import org.hibernate.service.spi.Configurable;
 import org.hibernate.service.spi.ServiceException;
 import org.hibernate.service.spi.ServiceRegistryAwareService;
 
 /**
  * Standard Hibernate implementation of the service registry.
  *
  * @author Steve Ebersole
  */
 public class BasicServiceRegistryImpl extends AbstractServiceRegistryImpl implements BasicServiceRegistry {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BasicServiceRegistryImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BasicServiceRegistryImpl.class.getName());
 
 	private final Map<Class,BasicServiceInitiator> serviceInitiatorMap;
 	private final Map configurationValues;
 
 	public BasicServiceRegistryImpl(Map configurationValues) {
 		this( StandardServiceInitiators.LIST, configurationValues );
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public BasicServiceRegistryImpl(List<BasicServiceInitiator> serviceInitiators, Map configurationValues) {
 		super();
 		this.serviceInitiatorMap = toMap( serviceInitiators );
 		this.configurationValues = configurationValues;
 		for ( BasicServiceInitiator initiator : serviceInitiatorMap.values() ) {
 			// create the bindings up front to help identify to which registry services belong
 			createServiceBinding( initiator.getServiceInitiated() );
 		}
 	}
 
 	/**
 	 * We convert the incoming list of initiators to a map for 2 reasons:<ul>
 	 * <li>to make it easier to look up the initiator we need for a given service role</li>
 	 * <li>to make sure there is only one initiator for a given service role (last wins)</li>
 	 * </ul>
 	 *
 	 * @param serviceInitiators The list of individual initiators
 	 *
 	 * @return The map of initiators keyed by the service rle they initiate.
 	 */
 	private static Map<Class, BasicServiceInitiator> toMap(List<BasicServiceInitiator> serviceInitiators) {
 		final Map<Class, BasicServiceInitiator> result = new HashMap<Class, BasicServiceInitiator>();
 		for ( BasicServiceInitiator initiator : serviceInitiators ) {
 			result.put( initiator.getServiceInitiated(), initiator );
 		}
 		return result;
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public void registerServiceInitiator(BasicServiceInitiator initiator) {
 		ServiceBinding serviceBinding = locateServiceBinding( initiator.getServiceInitiated(), false );
 		if ( serviceBinding != null ) {
 			serviceBinding.setTarget( null );
 		}
 		else {
 			createServiceBinding( initiator.getServiceInitiated() );
 		}
 		final Object previous = serviceInitiatorMap.put( initiator.getServiceInitiated(), initiator );
 		if ( previous != null ) {
 			LOG.debugf( "Over-wrote existing service initiator [role=%s]", initiator.getServiceInitiated().getName() );
 		}
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	protected <T extends Service> T createService(Class<T> serviceRole) {
 		BasicServiceInitiator<T> initiator = serviceInitiatorMap.get( serviceRole );
 		if ( initiator == null ) {
 			throw new UnknownServiceException( serviceRole );
 		}
 		try {
 			T service = initiator.initiateService( configurationValues, this );
 			// IMPL NOTE : the register call here is important to avoid potential stack overflow issues
 			//		from recursive calls through #configureService
 			registerService( serviceRole, service );
 			return service;
 		}
 		catch ( ServiceException e ) {
 			throw e;
 		}
 		catch ( Exception e ) {
 			throw new ServiceException( "Unable to create requested service [" + serviceRole.getName() + "]", e );
 		}
 	}
 
 	@Override
 	protected <T extends Service> void configureService(T service) {
 		applyInjections( service );
 
 		if ( ServiceRegistryAwareService.class.isInstance( service ) ) {
 			( (ServiceRegistryAwareService) service ).injectServices( this );
 		}
 
 		if ( Configurable.class.isInstance( service ) ) {
 			( (Configurable) service ).configure( configurationValues );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/internal/SessionFactoryServiceRegistryImpl.java b/hibernate-core/src/main/java/org/hibernate/service/internal/SessionFactoryServiceRegistryImpl.java
index 73283d55d1..a106807a3b 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/internal/SessionFactoryServiceRegistryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/internal/SessionFactoryServiceRegistryImpl.java
@@ -1,132 +1,131 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.internal;
 
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.service.Service;
 import org.hibernate.service.StandardSessionFactoryServiceInitiators;
 import org.hibernate.service.UnknownServiceException;
-import org.hibernate.service.spi.BasicServiceInitiator;
 import org.hibernate.service.spi.ServiceException;
 import org.hibernate.service.spi.ServiceRegistryAwareService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceInitiator;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 
 /**
  * @author Steve Ebersole
  */
 public class SessionFactoryServiceRegistryImpl
 		extends AbstractServiceRegistryImpl
 		implements SessionFactoryServiceRegistry {
 
-	private static final HibernateLogger LOG = Logger.getMessageLogger( HibernateLogger.class, SessionFactoryServiceRegistryImpl.class.getName() );
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, SessionFactoryServiceRegistryImpl.class.getName() );
 
 	private final Map<Class,SessionFactoryServiceInitiator> serviceInitiatorMap;
 
 	// for now we need to hold on to the Configuration... :(
 	private Configuration configuration;
 	private final SessionFactoryImplementor sessionFactory;
 
 	@SuppressWarnings( {"unchecked"})
 	public SessionFactoryServiceRegistryImpl(
 			ServiceRegistryImplementor parent,
 			SessionFactoryImplementor sessionFactory,
 			Configuration configuration) {
 		super( parent );
 		// for now, just use the standard initiator list
 		this.serviceInitiatorMap = toMap( StandardSessionFactoryServiceInitiators.LIST );
 
 		this.sessionFactory = sessionFactory;
 		this.configuration = configuration;
 
 		for ( SessionFactoryServiceInitiator initiator : serviceInitiatorMap.values() ) {
 			// create the bindings up front to help identify to which registry services belong
 			createServiceBinding( initiator.getServiceInitiated() );
 		}
 	}
 
 	private static Map<Class, SessionFactoryServiceInitiator> toMap(List<SessionFactoryServiceInitiator> serviceInitiators) {
 		final Map<Class, SessionFactoryServiceInitiator> result = new HashMap<Class, SessionFactoryServiceInitiator>();
 		for ( SessionFactoryServiceInitiator initiator : serviceInitiators ) {
 			result.put( initiator.getServiceInitiated(), initiator );
 		}
 		return result;
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public void registerServiceInitiator(SessionFactoryServiceInitiator initiator) {
 		ServiceBinding serviceBinding = locateServiceBinding( initiator.getServiceInitiated(), false );
 		if ( serviceBinding != null ) {
 			serviceBinding.setTarget( null );
 		}
 		else {
 			createServiceBinding( initiator.getServiceInitiated() );
 		}
 		final Object previous = serviceInitiatorMap.put( initiator.getServiceInitiated(), initiator );
 		if ( previous != null ) {
 			LOG.debugf( "Over-wrote existing service initiator [role=%s]", initiator.getServiceInitiated().getName() );
 		}
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	protected <T extends Service> T createService(Class<T> serviceRole) {
 		SessionFactoryServiceInitiator<T> initiator = serviceInitiatorMap.get( serviceRole );
 		if ( initiator == null ) {
 			throw new UnknownServiceException( serviceRole );
 		}
 		try {
 			T service = initiator.initiateService( sessionFactory, configuration, this );
 			// IMPL NOTE : the register call here is important to avoid potential stack overflow issues
 			//		from recursive calls through #configureService
 			registerService( serviceRole, service );
 			return service;
 		}
 		catch ( ServiceException e ) {
 			throw e;
 		}
 		catch ( Exception e ) {
 			throw new ServiceException( "Unable to create requested service [" + serviceRole.getName() + "]", e );
 		}
 	}
 
 	@Override
 	protected <T extends Service> void configureService(T service) {
 		applyInjections( service );
 
 		if ( ServiceRegistryAwareService.class.isInstance( service ) ) {
 			( (ServiceRegistryAwareService) service ).injectServices( this );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/ConnectionProviderInitiator.java b/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/ConnectionProviderInitiator.java
index dc4b21010b..2730776ca2 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/ConnectionProviderInitiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/ConnectionProviderInitiator.java
@@ -1,285 +1,285 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.connections.internal;
 
 import java.beans.BeanInfo;
 import java.beans.PropertyDescriptor;
 import java.lang.reflect.Method;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.beans.BeanInfoHelper;
 import org.hibernate.service.classloading.spi.ClassLoaderService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.spi.BasicServiceInitiator;
 
 /**
  * Instantiates and configures an appropriate {@link ConnectionProvider}.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class ConnectionProviderInitiator implements BasicServiceInitiator<ConnectionProvider> {
 	public static final ConnectionProviderInitiator INSTANCE = new ConnectionProviderInitiator();
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        ConnectionProviderInitiator.class.getName());
 	public static final String C3P0_CONFIG_PREFIX = "hibernate.c3p0";
 	public static final String C3P0_PROVIDER_CLASS_NAME =
 			"org.hibernate.service.jdbc.connections.internal.C3P0ConnectionProvider";
 
 	public static final String PROXOOL_CONFIG_PREFIX = "hibernate.proxool";
 	public static final String PROXOOL_PROVIDER_CLASS_NAME =
 			"org.hibernate.service.jdbc.connections.internal.ProxoolConnectionProvider";
 
 	public static final String INJECTION_DATA = "hibernate.connection_provider.injection_data";
 
 	// mapping from legacy connection provider name to actual
 	// connection provider that will be used
 	private static final Map<String,String> LEGACY_CONNECTION_PROVIDER_MAPPING;
 
 	static {
 		LEGACY_CONNECTION_PROVIDER_MAPPING = new HashMap<String,String>( 5 );
 
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.DatasourceConnectionProvider",
 				DatasourceConnectionProviderImpl.class.getName()
 		);
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.DriverManagerConnectionProvider",
 				DriverManagerConnectionProviderImpl.class.getName()
 		);
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.UserSuppliedConnectionProvider",
 				UserSuppliedConnectionProviderImpl.class.getName()
 		);
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.C3P0ConnectionProvider",
 				C3P0_PROVIDER_CLASS_NAME
 		);
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.ProxoolConnectionProvider",
 				PROXOOL_PROVIDER_CLASS_NAME
 		);
 	}
 
 	@Override
 	public Class<ConnectionProvider> getServiceInitiated() {
 		return ConnectionProvider.class;
 	}
 
 	@Override
 	public ConnectionProvider initiateService(Map configurationValues, ServiceRegistryImplementor registry) {
 		if ( MultiTenancyStrategy.determineMultiTenancyStrategy( configurationValues ) != MultiTenancyStrategy.NONE ) {
 			// nothing to do, but given the separate hierarchies have to handle this here.
 		}
 
 		final ClassLoaderService classLoaderService = registry.getService( ClassLoaderService.class );
 
 		ConnectionProvider connectionProvider = null;
 		String providerClassName = getConfiguredConnectionProviderName( configurationValues );
 		if ( providerClassName != null ) {
 			connectionProvider = instantiateExplicitConnectionProvider( providerClassName, classLoaderService );
 		}
 		else if ( configurationValues.get( Environment.DATASOURCE ) != null ) {
 			connectionProvider = new DatasourceConnectionProviderImpl();
 		}
 
 		if ( connectionProvider == null ) {
 			if ( c3p0ConfigDefined( configurationValues ) && c3p0ProviderPresent( classLoaderService ) ) {
 				connectionProvider = instantiateExplicitConnectionProvider( C3P0_PROVIDER_CLASS_NAME,
 						classLoaderService
 				);
 			}
 		}
 
 		if ( connectionProvider == null ) {
 			if ( proxoolConfigDefined( configurationValues ) && proxoolProviderPresent( classLoaderService ) ) {
 				connectionProvider = instantiateExplicitConnectionProvider( PROXOOL_PROVIDER_CLASS_NAME,
 						classLoaderService
 				);
 			}
 		}
 
 		if ( connectionProvider == null ) {
 			if ( configurationValues.get( Environment.URL ) != null ) {
 				connectionProvider = new DriverManagerConnectionProviderImpl();
 			}
 		}
 
 		if ( connectionProvider == null ) {
             LOG.noAppropriateConnectionProvider();
 			connectionProvider = new UserSuppliedConnectionProviderImpl();
 		}
 
 
 		final Map injectionData = (Map) configurationValues.get( INJECTION_DATA );
 		if ( injectionData != null && injectionData.size() > 0 ) {
 			final ConnectionProvider theConnectionProvider = connectionProvider;
 			new BeanInfoHelper( connectionProvider.getClass() ).applyToBeanInfo(
 					connectionProvider,
 					new BeanInfoHelper.BeanInfoDelegate() {
 						public void processBeanInfo(BeanInfo beanInfo) throws Exception {
 							PropertyDescriptor[] descritors = beanInfo.getPropertyDescriptors();
 							for ( int i = 0, size = descritors.length; i < size; i++ ) {
 								String propertyName = descritors[i].getName();
 								if ( injectionData.containsKey( propertyName ) ) {
 									Method method = descritors[i].getWriteMethod();
 									method.invoke(
 											theConnectionProvider,
 											injectionData.get( propertyName )
 									);
 								}
 							}
 						}
 					}
 			);
 		}
 
 		return connectionProvider;
 	}
 
 	private String getConfiguredConnectionProviderName( Map configurationValues ) {
 		String providerClassName = ( String ) configurationValues.get( Environment.CONNECTION_PROVIDER );
 		if ( LEGACY_CONNECTION_PROVIDER_MAPPING.containsKey( providerClassName ) ) {
 			String actualProviderClassName = LEGACY_CONNECTION_PROVIDER_MAPPING.get( providerClassName );
             LOG.providerClassDeprecated(providerClassName, actualProviderClassName);
 			providerClassName = actualProviderClassName;
 		}
 		return providerClassName;
 	}
 
 	private ConnectionProvider instantiateExplicitConnectionProvider(
 			String providerClassName,
 			ClassLoaderService classLoaderService) {
 		try {
             LOG.instantiatingExplicitConnectinProvider(providerClassName);
 			return (ConnectionProvider) classLoaderService.classForName( providerClassName ).newInstance();
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Could not instantiate connection provider [" + providerClassName + "]", e );
 		}
 	}
 
 	private boolean c3p0ProviderPresent(ClassLoaderService classLoaderService) {
 		try {
 			classLoaderService.classForName( C3P0_PROVIDER_CLASS_NAME );
 		}
 		catch ( Exception e ) {
             LOG.c3p0ProviderClassNotFound(C3P0_PROVIDER_CLASS_NAME);
 			return false;
 		}
 		return true;
 	}
 
 	private static boolean c3p0ConfigDefined(Map configValues) {
 		for ( Object key : configValues.keySet() ) {
 			if ( String.class.isInstance( key )
 					&& ( (String) key ).startsWith( C3P0_CONFIG_PREFIX ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private boolean proxoolProviderPresent(ClassLoaderService classLoaderService) {
 		try {
 			classLoaderService.classForName( PROXOOL_PROVIDER_CLASS_NAME );
 		}
 		catch ( Exception e ) {
             LOG.proxoolProviderClassNotFound(PROXOOL_PROVIDER_CLASS_NAME);
 			return false;
 		}
 		return true;
 	}
 
 	private static boolean proxoolConfigDefined(Map configValues) {
 		for ( Object key : configValues.keySet() ) {
 			if ( String.class.isInstance( key )
 					&& ( (String) key ).startsWith( PROXOOL_CONFIG_PREFIX ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	/**
 	 * Build the connection properties capable of being passed to the {@link java.sql.DriverManager#getConnection}
 	 * forms taking {@link Properties} argument.  We seek out all keys in the passed map which start with
 	 * {@code hibernate.connection.}, using them to create a new {@link Properties} instance.  The keys in this
 	 * new {@link Properties} have the {@code hibernate.connection.} prefix trimmed.
 	 *
 	 * @param properties The map from which to build the connection specific properties.
 	 *
 	 * @return The connection properties.
 	 */
 	public static Properties getConnectionProperties(Map<?,?> properties) {
 		Properties result = new Properties();
 		for ( Map.Entry entry : properties.entrySet() ) {
 			if ( ! ( String.class.isInstance( entry.getKey() ) ) || ! String.class.isInstance( entry.getValue() ) ) {
 				continue;
 			}
 			final String key = (String) entry.getKey();
 			final String value = (String) entry.getValue();
 			if ( key.startsWith( Environment.CONNECTION_PREFIX ) ) {
 				if ( SPECIAL_PROPERTIES.contains( key ) ) {
 					if ( Environment.USER.equals( key ) ) {
 						result.setProperty( "user", value );
 					}
 				}
 				else {
 					result.setProperty(
 							key.substring( Environment.CONNECTION_PREFIX.length() + 1 ),
 							value
 					);
 				}
 			}
 		}
 		return result;
 	}
 
 	private static final Set<String> SPECIAL_PROPERTIES;
 
 	static {
 		SPECIAL_PROPERTIES = new HashSet<String>();
 		SPECIAL_PROPERTIES.add( Environment.DATASOURCE );
 		SPECIAL_PROPERTIES.add( Environment.URL );
 		SPECIAL_PROPERTIES.add( Environment.CONNECTION_PROVIDER );
 		SPECIAL_PROPERTIES.add( Environment.POOL_SIZE );
 		SPECIAL_PROPERTIES.add( Environment.ISOLATION );
 		SPECIAL_PROPERTIES.add( Environment.DRIVER );
 		SPECIAL_PROPERTIES.add( Environment.USER );
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java b/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
index 73af9e393a..dcecb7f9ca 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
@@ -1,214 +1,214 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.connections.internal;
 
 import java.sql.Connection;
 import java.sql.DriverManager;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Map;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.spi.Configurable;
 import org.hibernate.service.spi.Stoppable;
 import org.hibernate.service.UnknownUnwrapTypeException;
 import org.jboss.logging.Logger;
 
 /**
  * A connection provider that uses the {@link java.sql.DriverManager} directly to open connections and provides
  * a very rudimentary connection pool.
  * <p/>
  * IMPL NOTE : not intended for production use!
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 @SuppressWarnings( {"UnnecessaryUnboxing"})
 public class DriverManagerConnectionProviderImpl implements ConnectionProvider, Configurable, Stoppable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DriverManagerConnectionProviderImpl.class.getName());
 
 	private String url;
 	private Properties connectionProps;
 	private Integer isolation;
 	private int poolSize;
 	private boolean autocommit;
 
 	private final ArrayList<Connection> pool = new ArrayList<Connection>();
 	private int checkedOut = 0;
 
 	private boolean stopped;
 
 	@Override
 	public boolean isUnwrappableAs(Class unwrapType) {
 		return ConnectionProvider.class.equals( unwrapType ) ||
 				DriverManagerConnectionProviderImpl.class.isAssignableFrom( unwrapType );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public <T> T unwrap(Class<T> unwrapType) {
 		if ( ConnectionProvider.class.equals( unwrapType ) ||
 				DriverManagerConnectionProviderImpl.class.isAssignableFrom( unwrapType ) ) {
 			return (T) this;
 		}
 		else {
 			throw new UnknownUnwrapTypeException( unwrapType );
 		}
 	}
 
 	public void configure(Map configurationValues) {
         LOG.usingHibernateBuiltInConnectionPool();
 
 		String driverClassName = (String) configurationValues.get( Environment.DRIVER );
         if (driverClassName == null) LOG.jdbcDriverNotSpecified(Environment.DRIVER);
 		else {
 			try {
 				// trying via forName() first to be as close to DriverManager's semantics
 				Class.forName( driverClassName );
 			}
 			catch ( ClassNotFoundException cnfe ) {
 				try {
 					ReflectHelper.classForName( driverClassName );
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new HibernateException( "Specified JDBC Driver " + driverClassName + " class not found", e );
 				}
 			}
 		}
 
 		poolSize = ConfigurationHelper.getInt( Environment.POOL_SIZE, configurationValues, 20 ); // default pool size 20
         LOG.hibernateConnectionPoolSize(poolSize);
 
 		autocommit = ConfigurationHelper.getBoolean( Environment.AUTOCOMMIT, configurationValues );
-        LOG.autoCommitMode(autocommit);
+        LOG.autoCommitMode( autocommit );
 
 		isolation = ConfigurationHelper.getInteger( Environment.ISOLATION, configurationValues );
         if (isolation != null) LOG.jdbcIsolationLevel(Environment.isolationLevelToString(isolation.intValue()));
 
 		url = (String) configurationValues.get( Environment.URL );
 		if ( url == null ) {
             String msg = LOG.jdbcUrlNotSpecified(Environment.URL);
             LOG.error(msg);
 			throw new HibernateException( msg );
 		}
 
 		connectionProps = ConnectionProviderInitiator.getConnectionProperties( configurationValues );
 
         LOG.usingDriver(driverClassName, url);
 		// if debug level is enabled, then log the password, otherwise mask it
         if (LOG.isDebugEnabled()) LOG.connectionProperties(connectionProps);
         else LOG.connectionProperties(ConfigurationHelper.maskOut(connectionProps, "password"));
 	}
 
 	public void stop() {
         LOG.cleaningUpConnectionPool(url);
 
 		for ( Connection connection : pool ) {
 			try {
 				connection.close();
 			}
 			catch (SQLException sqle) {
                 LOG.unableToClosePooledConnection(sqle);
 			}
 		}
 		pool.clear();
 		stopped = true;
 	}
 
 	public Connection getConnection() throws SQLException {
         LOG.trace("Total checked-out connections: " + checkedOut);
 
 		// essentially, if we have available connections in the pool, use one...
 		synchronized (pool) {
 			if ( !pool.isEmpty() ) {
 				int last = pool.size() - 1;
                 if (LOG.isTraceEnabled()) {
                     LOG.trace("Using pooled JDBC connection, pool size: " + last);
 					checkedOut++;
 				}
 				Connection pooled = pool.remove(last);
 				if ( isolation != null ) {
 					pooled.setTransactionIsolation( isolation.intValue() );
 				}
 				if ( pooled.getAutoCommit() != autocommit ) {
 					pooled.setAutoCommit( autocommit );
 				}
 				return pooled;
 			}
 		}
 
 		// otherwise we open a new connection...
 
         LOG.debugf("Opening new JDBC connection");
 		Connection conn = DriverManager.getConnection( url, connectionProps );
 		if ( isolation != null ) {
 			conn.setTransactionIsolation( isolation.intValue() );
 		}
 		if ( conn.getAutoCommit() != autocommit ) {
 			conn.setAutoCommit(autocommit);
 		}
 
         LOG.debugf("Created connection to: %s, Isolation Level: %s", url, conn.getTransactionIsolation());
 
 		checkedOut++;
 
 		return conn;
 	}
 
 	public void closeConnection(Connection conn) throws SQLException {
 		checkedOut--;
 
 		// add to the pool if the max size is not yet reached.
 		synchronized (pool) {
 			int currentSize = pool.size();
 			if ( currentSize < poolSize ) {
                 LOG.trace("Returning connection to pool, pool size: " + (currentSize + 1));
 				pool.add(conn);
 				return;
 			}
 		}
 
         LOG.debugf("Closing JDBC connection");
 		conn.close();
 	}
 
 	@Override
     protected void finalize() throws Throwable {
 		if ( !stopped ) {
 			stop();
 		}
 		super.finalize();
 	}
 
 	public boolean supportsAggressiveRelease() {
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/AbstractDialectResolver.java b/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/AbstractDialectResolver.java
index 516319ab01..6b20d99dc2 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/AbstractDialectResolver.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/AbstractDialectResolver.java
@@ -1,76 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.dialect.internal;
 import java.sql.DatabaseMetaData;
 import java.sql.SQLException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.resolver.BasicSQLExceptionConverter;
 import org.hibernate.exception.JDBCConnectionException;
 import org.hibernate.service.jdbc.dialect.spi.DialectResolver;
+
 import org.jboss.logging.Logger;
 
 /**
  * A templated resolver impl which delegates to the {@link #resolveDialectInternal} method
  * and handles any thrown {@link SQLException SQL errors}.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractDialectResolver implements DialectResolver {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractDialectResolver.class.getName());
 
 	/**
 	 * {@inheritDoc}
 	 * <p/>
 	 * Here we template the resolution, delegating to {@link #resolveDialectInternal} and handling
 	 * {@link java.sql.SQLException}s properly.
 	 */
 	public final Dialect resolveDialect(DatabaseMetaData metaData) {
 		try {
 			return resolveDialectInternal( metaData );
 		}
 		catch ( SQLException sqlException ) {
 			JDBCException jdbcException = BasicSQLExceptionConverter.INSTANCE.convert( sqlException );
             if (jdbcException instanceof JDBCConnectionException) throw jdbcException;
             LOG.warnf("%s : %s", BasicSQLExceptionConverter.MSG, sqlException.getMessage());
             return null;
 		}
 		catch ( Throwable t ) {
             LOG.unableToExecuteResolver(this, t.getMessage());
 			return null;
 		}
 	}
 
 	/**
 	 * Perform the actual resolution without caring about handling {@link SQLException}s.
 	 *
 	 * @param metaData The database metadata
 	 * @return The resolved dialect, or null if we could not resolve.
 	 * @throws SQLException Indicates problems accessing the metadata.
 	 */
 	protected abstract Dialect resolveDialectInternal(DatabaseMetaData metaData) throws SQLException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/DialectResolverSet.java b/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/DialectResolverSet.java
index 0e3f05fb35..73fe821cac 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/DialectResolverSet.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/DialectResolverSet.java
@@ -1,96 +1,98 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.dialect.internal;
 import java.sql.DatabaseMetaData;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.exception.JDBCConnectionException;
 import org.hibernate.service.jdbc.dialect.spi.DialectResolver;
+
 import org.jboss.logging.Logger;
 
 /**
  * A {@link DialectResolver} implementation which coordinates resolution by delegating to sub-resolvers.
  *
  * @author Tomoto Shimizu Washio
  * @author Steve Ebersole
  */
 public class DialectResolverSet implements DialectResolver {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, DialectResolverSet.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DialectResolverSet.class.getName());
 
 	private List<DialectResolver> resolvers;
 
 	public DialectResolverSet() {
 		this( new ArrayList<DialectResolver>() );
 	}
 
 	public DialectResolverSet(List<DialectResolver> resolvers) {
 		this.resolvers = resolvers;
 	}
 
 	public DialectResolverSet(DialectResolver... resolvers) {
 		this( Arrays.asList( resolvers ) );
 	}
 
 	public Dialect resolveDialect(DatabaseMetaData metaData) throws JDBCConnectionException {
 		for ( DialectResolver resolver : resolvers ) {
 			try {
 				Dialect dialect = resolver.resolveDialect( metaData );
 				if ( dialect != null ) {
 					return dialect;
 				}
 			}
 			catch ( JDBCConnectionException e ) {
 				throw e;
 			}
 			catch ( Exception e ) {
                 LOG.exceptionInSubResolver(e.getMessage());
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Add a resolver at the end of the underlying resolver list.  The resolver added by this method is at lower
 	 * priority than any other existing resolvers.
 	 *
 	 * @param resolver The resolver to add.
 	 */
 	public void addResolver(DialectResolver resolver) {
 		resolvers.add( resolver );
 	}
 
 	/**
 	 * Add a resolver at the beginning of the underlying resolver list.  The resolver added by this method is at higher
 	 * priority than any other existing resolvers.
 	 *
 	 * @param resolver The resolver to add.
 	 */
 	public void addResolverAtFirst(DialectResolver resolver) {
 		resolvers.add( 0, resolver );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/StandardDialectResolver.java b/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/StandardDialectResolver.java
index 61cb4cd1d4..8a0b7d6e36 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/StandardDialectResolver.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jdbc/dialect/internal/StandardDialectResolver.java
@@ -1,158 +1,160 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.dialect.internal;
 import java.sql.DatabaseMetaData;
 import java.sql.SQLException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.DB2Dialect;
 import org.hibernate.dialect.DerbyDialect;
 import org.hibernate.dialect.DerbyTenFiveDialect;
 import org.hibernate.dialect.DerbyTenSixDialect;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.InformixDialect;
 import org.hibernate.dialect.Ingres10Dialect;
 import org.hibernate.dialect.Ingres9Dialect;
 import org.hibernate.dialect.IngresDialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.Oracle10gDialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.dialect.Oracle9iDialect;
 import org.hibernate.dialect.PostgreSQLDialect;
 import org.hibernate.dialect.SQLServer2005Dialect;
 import org.hibernate.dialect.SQLServer2008Dialect;
 import org.hibernate.dialect.SQLServerDialect;
 import org.hibernate.dialect.SybaseASE15Dialect;
 import org.hibernate.dialect.SybaseAnywhereDialect;
+
 import org.jboss.logging.Logger;
 
 /**
  * The standard Hibernate Dialect resolver.
  *
  * @author Steve Ebersole
  */
 public class StandardDialectResolver extends AbstractDialectResolver {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        StandardDialectResolver.class.getName());
 
 	@Override
     protected Dialect resolveDialectInternal(DatabaseMetaData metaData) throws SQLException {
 		String databaseName = metaData.getDatabaseProductName();
 		int databaseMajorVersion = metaData.getDatabaseMajorVersion();
 
 		if ( "HSQL Database Engine".equals( databaseName ) ) {
 			return new HSQLDialect();
 		}
 
 		if ( "H2".equals( databaseName ) ) {
 			return new H2Dialect();
 		}
 
 		if ( "MySQL".equals( databaseName ) ) {
 			return new MySQLDialect();
 		}
 
 		if ( "PostgreSQL".equals( databaseName ) ) {
 			return new PostgreSQLDialect();
 		}
 
 		if ( "Apache Derby".equals( databaseName ) ) {
 			final int databaseMinorVersion = metaData.getDatabaseMinorVersion();
 			if ( databaseMajorVersion > 10 || ( databaseMajorVersion == 10 && databaseMinorVersion >= 6 ) ) {
 				return new DerbyTenSixDialect();
 			}
 			else if ( databaseMajorVersion == 10 && databaseMinorVersion == 5 ) {
 				return new DerbyTenFiveDialect();
 			}
 			else {
 				return new DerbyDialect();
 			}
 		}
 
 		if ( "ingres".equalsIgnoreCase( databaseName ) ) {
             switch( databaseMajorVersion ) {
                 case 9:
                     int databaseMinorVersion = metaData.getDatabaseMinorVersion();
                     if (databaseMinorVersion > 2) {
                         return new Ingres9Dialect();
                     }
                     return new IngresDialect();
                 case 10:
                     return new Ingres10Dialect();
                 default:
                     LOG.unknownIngresVersion(databaseMajorVersion);
             }
 			return new IngresDialect();
 		}
 
 		if ( databaseName.startsWith( "Microsoft SQL Server" ) ) {
 			switch ( databaseMajorVersion ) {
                 case 8:
                     return new SQLServerDialect();
                 case 9:
                     return new SQLServer2005Dialect();
                 case 10:
                     return new SQLServer2008Dialect();
                 default:
                     LOG.unknownSqlServerVersion(databaseMajorVersion);
 			}
 			return new SQLServerDialect();
 		}
 
 		if ( "Sybase SQL Server".equals( databaseName ) || "Adaptive Server Enterprise".equals( databaseName ) ) {
 			return new SybaseASE15Dialect();
 		}
 
 		if ( databaseName.startsWith( "Adaptive Server Anywhere" ) ) {
 			return new SybaseAnywhereDialect();
 		}
 
 		if ( "Informix Dynamic Server".equals( databaseName ) ) {
 			return new InformixDialect();
 		}
 
 		if ( databaseName.startsWith( "DB2/" ) ) {
 			return new DB2Dialect();
 		}
 
 		if ( "Oracle".equals( databaseName ) ) {
 			switch ( databaseMajorVersion ) {
 				case 11:
 					return new Oracle10gDialect();
 				case 10:
 					return new Oracle10gDialect();
 				case 9:
 					return new Oracle9iDialect();
 				case 8:
 					return new Oracle8iDialect();
 				default:
                     LOG.unknownOracleVersion(databaseMajorVersion);
 			}
 		}
 
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jmx/internal/JmxServiceImpl.java b/hibernate-core/src/main/java/org/hibernate/service/jmx/internal/JmxServiceImpl.java
index 2c1c0d2cc3..d83b39b236 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jmx/internal/JmxServiceImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jmx/internal/JmxServiceImpl.java
@@ -1,218 +1,219 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jmx.internal;
 import java.lang.management.ManagementFactory;
 import java.util.ArrayList;
 import java.util.Map;
 import javax.management.MBeanServer;
 import javax.management.MBeanServerFactory;
 import javax.management.MalformedObjectNameException;
 import javax.management.ObjectName;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.Service;
 import org.hibernate.service.jmx.spi.JmxService;
 import org.hibernate.service.spi.Manageable;
 import org.hibernate.service.spi.Stoppable;
+
 import org.jboss.logging.Logger;
 
 /**
  * Standard implementation of JMX services
  *
  * @author Steve Ebersole
  */
 public class JmxServiceImpl implements JmxService, Stoppable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JmxServiceImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JmxServiceImpl.class.getName());
 
 	public static final String JMX_PLATFORM_SERVER = "hibernate.jmx.usePlatformServer";
 	public static final String JMX_AGENT_ID = "hibernate.jmx.agentId";
 	public static final String JMX_DOMAIN_NAME = "hibernate.jmx.defaultDomain";
 	public static final String JMX_SF_NAME = "hibernate.jmx.sessionFactoryName";
 
 	private final boolean usePlatformServer;
 	private final String agentId;
 	private final String defaultDomain;
 	private final String sessionFactoryName;
 
 	public JmxServiceImpl(Map configValues) {
 		usePlatformServer = ConfigurationHelper.getBoolean( JMX_PLATFORM_SERVER, configValues );
 		agentId = (String) configValues.get( JMX_AGENT_ID );
 		defaultDomain = (String) configValues.get( JMX_DOMAIN_NAME );
 		sessionFactoryName = ConfigurationHelper.getString(
 				JMX_SF_NAME,
 				configValues,
 				ConfigurationHelper.getString( Environment.SESSION_FACTORY_NAME, configValues )
 		);
 	}
 
 	private boolean startedServer;
 	private ArrayList<ObjectName> registeredMBeans;
 
 	@Override
 	public void stop() {
 		try {
 			// if we either started the JMX server or we registered some MBeans we at least need to look up
 			// MBean server and do *some* work on shutdwon.
 			if ( startedServer || registeredMBeans != null ) {
 				MBeanServer mBeanServer = findServer();
 				if ( mBeanServer == null ) {
                     LOG.unableToLocateMBeanServer();
 					return;
 				}
 
 				// release any MBeans we registered
 				if ( registeredMBeans != null ) {
 					for ( ObjectName objectName : registeredMBeans ) {
 						try {
                             LOG.trace("Unregistering registered MBean [ON=" + objectName + "]");
 							mBeanServer.unregisterMBean( objectName );
 						}
 						catch ( Exception e ) {
                             LOG.debugf("Unable to unregsiter registered MBean [ON=%s] : %s", objectName, e.toString());
 						}
 					}
 				}
 
 				// stop the MBean server if we started it
 				if ( startedServer ) {
                     LOG.trace("Attempting to release created MBeanServer");
 					try {
 						MBeanServerFactory.releaseMBeanServer( mBeanServer );
 					}
 					catch ( Exception e ) {
                         LOG.unableToReleaseCreatedMBeanServer(e.toString());
 					}
 				}
 			}
 		}
 		finally {
 			startedServer = false;
 			if ( registeredMBeans != null ) {
 				registeredMBeans.clear();
 				registeredMBeans = null;
 			}
 		}
 	}
 
 	public static final String DEFAULT_OBJ_NAME_DOMAIN = "org.hibernate.core";
 	public static final String OBJ_NAME_TEMPLATE = "%s:sessionFactory=%s,serviceRole=%s,serviceType=%s";
 
 	// todo : should serviceRole come first in ObjectName template?  depends on the groupings we want in the UI.
 	// 		as-is mbeans from each sessionFactory are grouped primarily.
 
 	@Override
 	public void registerService(Manageable service, Class<? extends Service> serviceRole) {
 		final String domain = service.getManagementDomain() == null
 				? DEFAULT_OBJ_NAME_DOMAIN
 				: service.getManagementDomain();
 		final String serviceType = service.getManagementServiceType() == null
 				? service.getClass().getName()
 				: service.getManagementServiceType();
 		try {
 			final ObjectName objectName = new ObjectName(
 					String.format(
 							OBJ_NAME_TEMPLATE,
 							domain,
 							sessionFactoryName,
 							serviceRole.getName(),
 							serviceType
 					)
 			);
 			registerMBean( objectName, service.getManagementBean() );
 		}
 		catch ( HibernateException e ) {
 			throw e;
 		}
 		catch ( MalformedObjectNameException e ) {
 			throw new HibernateException( "Unable to generate service IbjectName", e );
 		}
 	}
 
 	@Override
 	public void registerMBean(ObjectName objectName, Object mBean) {
 		MBeanServer mBeanServer = findServer();
 		if ( mBeanServer == null ) {
 			if ( startedServer ) {
 				throw new HibernateException( "Could not locate previously started MBeanServer" );
 			}
 			mBeanServer = startMBeanServer();
 			startedServer = true;
 		}
 
 		try {
 			mBeanServer.registerMBean( mBean, objectName );
 			if ( registeredMBeans == null ) {
 				registeredMBeans = new ArrayList<ObjectName>();
 			}
 			registeredMBeans.add( objectName );
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Unable to register MBean [ON=" + objectName + "]", e );
 		}
 	}
 
 	/**
 	 * Locate the MBean server to use based on user input from startup.
 	 *
 	 * @return The MBean server to use.
 	 */
 	private MBeanServer findServer() {
 		if ( usePlatformServer ) {
 			// they specified to use the platform (vm) server
 			return ManagementFactory.getPlatformMBeanServer();
 		}
 
 		// otherwise lookup all servers by (optional) agentId.
 		// IMPL NOTE : the findMBeanServer call treats a null agentId to mean match all...
 		ArrayList<MBeanServer> mbeanServers = MBeanServerFactory.findMBeanServer( agentId );
 
 		if ( defaultDomain == null ) {
 			// they did not specify a domain by which to locate a particular MBeanServer to use, so chose the first
 			return mbeanServers.get( 0 );
 		}
 
 		for ( MBeanServer mbeanServer : mbeanServers ) {
 			// they did specify a domain, so attempt to locate an MBEanServer with a matching default domain, returning it
 			// if we find it.
 			if ( defaultDomain.equals( mbeanServer.getDefaultDomain() ) ) {
 				return mbeanServer;
 			}
 		}
 
 		return null;
 	}
 
 	private MBeanServer startMBeanServer() {
 		try {
 			MBeanServer mbeanServer = MBeanServerFactory.createMBeanServer( defaultDomain );
 			return mbeanServer;
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Unable to start MBeanServer", e );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jndi/internal/JndiServiceImpl.java b/hibernate-core/src/main/java/org/hibernate/service/jndi/internal/JndiServiceImpl.java
index 65835e385d..4e0bfd0f40 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jndi/internal/JndiServiceImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jndi/internal/JndiServiceImpl.java
@@ -1,90 +1,92 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jndi.internal;
 import java.util.Hashtable;
 import java.util.Map;
 import javax.naming.InitialContext;
 import javax.naming.NamingException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.jndi.JndiException;
 import org.hibernate.internal.util.jndi.JndiHelper;
 import org.hibernate.service.jndi.spi.JndiService;
+
 import org.jboss.logging.Logger;
 
 /**
  * Standard implementation of JNDI services.
  *
  * @author Steve Ebersole
  */
 public class JndiServiceImpl implements JndiService {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JndiServiceImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JndiServiceImpl.class.getName());
 
 	private final Hashtable initialContextSettings;
 
 	public JndiServiceImpl(Map configurationValues) {
 		this.initialContextSettings = JndiHelper.extractJndiProperties( configurationValues );
 	}
 
 	@Override
 	public Object locate(String jndiName) {
 		InitialContext initialContext = buildInitialContext();
 		try {
 			return JndiHelper.locate( jndiName, initialContext );
 		}
 		finally {
 			try {
 				initialContext.close();
 			}
 			catch ( NamingException e ) {
                 LOG.unableToCloseInitialContext(e.toString());
 			}
 		}
 	}
 
 	private InitialContext buildInitialContext() {
 		try {
 			return initialContextSettings.size() == 0 ? new InitialContext() : new InitialContext( initialContextSettings );
 		}
 		catch ( NamingException e ) {
 			throw new JndiException( "Unable to open InitialContext", e );
 		}
 	}
 
 	@Override
 	public void bind(String jndiName, Object value) {
 		InitialContext initialContext = buildInitialContext();
 		try {
 			JndiHelper.bind( jndiName, value, initialContext );
 		}
 		finally {
 			try {
 				initialContext.close();
 			}
 			catch ( NamingException e ) {
                 LOG.unableToCloseInitialContext(e.toString());
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jta/platform/internal/JtaPlatformInitiator.java b/hibernate-core/src/main/java/org/hibernate/service/jta/platform/internal/JtaPlatformInitiator.java
index 02622c1cd2..896e6dd191 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jta/platform/internal/JtaPlatformInitiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jta/platform/internal/JtaPlatformInitiator.java
@@ -1,186 +1,186 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jta.platform.internal;
 
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.jndi.JndiHelper;
 import org.hibernate.service.classloading.spi.ClassLoaderService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.hibernate.service.jta.platform.spi.JtaPlatformException;
 import org.hibernate.service.spi.BasicServiceInitiator;
 import org.hibernate.transaction.TransactionManagerLookup;
 
 /**
  * Standard initiator for the standard {@link org.hibernate.service.jta.platform.spi.JtaPlatform}
  *
  * @author Steve Ebersole
  */
 public class JtaPlatformInitiator implements BasicServiceInitiator<JtaPlatform> {
 	public static final JtaPlatformInitiator INSTANCE = new JtaPlatformInitiator();
 	public static final String JTA_PLATFORM = "hibernate.jta.platform";
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JtaPlatformInitiator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JtaPlatformInitiator.class.getName());
 
 	@Override
 	public Class<JtaPlatform> getServiceInitiated() {
 		return JtaPlatform.class;
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public JtaPlatform initiateService(Map configurationValues, ServiceRegistryImplementor registry) {
 		final Object platform = getConfiguredPlatform( configurationValues, registry );
 		if ( platform == null ) {
 			return new NoJtaPlatform();
 		}
 
 		if ( JtaPlatform.class.isInstance( platform ) ) {
 			return (JtaPlatform) platform;
 		}
 
 		final Class<JtaPlatform> jtaPlatformImplClass;
 
 		if ( Class.class.isInstance( platform ) ) {
 			jtaPlatformImplClass = (Class<JtaPlatform>) platform;
 		}
 		else {
 			final String platformImplName = platform.toString();
 			final ClassLoaderService classLoaderService = registry.getService( ClassLoaderService.class );
 			try {
 				jtaPlatformImplClass = classLoaderService.classForName( platformImplName );
 			}
 			catch ( Exception e ) {
 				throw new HibernateException( "Unable to locate specified JtaPlatform class [" + platformImplName + "]", e );
 			}
 		}
 
 		try {
 			return jtaPlatformImplClass.newInstance();
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Unable to create specified JtaPlatform class [" + jtaPlatformImplClass.getName() + "]", e );
 		}
 	}
 
 	private Object getConfiguredPlatform(Map configVales, ServiceRegistryImplementor registry) {
 		Object platform = configVales.get( JTA_PLATFORM );
 		if ( platform == null ) {
 			final String transactionManagerLookupImplName = (String) configVales.get( Environment.TRANSACTION_MANAGER_STRATEGY );
 			if ( transactionManagerLookupImplName != null ) {
                 LOG.deprecatedTransactionManagerStrategy(TransactionManagerLookup.class.getName(),
                                                          Environment.TRANSACTION_MANAGER_STRATEGY,
                                                          JtaPlatform.class.getName(),
                                                          JTA_PLATFORM);
 				platform = mapLegacyClasses( transactionManagerLookupImplName, configVales, registry );
                 LOG.debugf("Mapped %s -> %s", transactionManagerLookupImplName, platform);
 			}
 		}
 		return platform;
 	}
 
 	private JtaPlatform mapLegacyClasses(String tmlImplName, Map configVales, ServiceRegistryImplementor registry) {
 		if ( tmlImplName == null ) {
 			return null;
 		}
 
         LOG.legacyTransactionManagerStrategy(JtaPlatform.class.getName(), JTA_PLATFORM);
 
 		if ( "org.hibernate.transaction.BESTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new BorlandEnterpriseServerJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.BTMTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new BitronixJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.JBossTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new JBossAppServerPlatform();
 		}
 
 		if ( "org.hibernate.transaction.JBossTSStandaloneTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new JBossStandAloneJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.JOnASTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new JOnASJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.JOTMTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new JOTMJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.JRun4TransactionManagerLookup".equals( tmlImplName ) ) {
 			return new JRun4JtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.OC4JTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new OC4JJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.OrionTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new OrionJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.ResinTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new ResinJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.SunONETransactionManagerLookup".equals( tmlImplName ) ) {
 			return new SunOneJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.WeblogicTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new WeblogicJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.WebSphereTransactionManagerLookup".equals( tmlImplName ) ) {
 			return new WebSphereJtaPlatform();
 		}
 
 		if ( "org.hibernate.transaction.WebSphereExtendedJTATransactionLookup".equals( tmlImplName ) ) {
 			return new WebSphereExtendedJtaPlatform();
 		}
 
 		try {
 			TransactionManagerLookup lookup = (TransactionManagerLookup) registry.getService( ClassLoaderService.class )
 					.classForName( tmlImplName )
 					.newInstance();
 			return new TransactionManagerLookupBridge( lookup, JndiHelper.extractJndiProperties( configVales ) );
 		}
 		catch ( Exception e ) {
 			throw new JtaPlatformException(
 					"Unable to build " + TransactionManagerLookupBridge.class.getName() + " from specified " +
 							TransactionManagerLookup.class.getName() + " implementation: " +
 							tmlImplName
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jta/platform/internal/WebSphereJtaPlatform.java b/hibernate-core/src/main/java/org/hibernate/service/jta/platform/internal/WebSphereJtaPlatform.java
index 89ce55fee5..ef980425a4 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jta/platform/internal/WebSphereJtaPlatform.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jta/platform/internal/WebSphereJtaPlatform.java
@@ -1,103 +1,104 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jta.platform.internal;
 
 import java.lang.reflect.Method;
 import javax.transaction.TransactionManager;
 import javax.transaction.UserTransaction;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.service.jta.platform.spi.JtaPlatformException;
+
 import org.jboss.logging.Logger;
 
 /**
  * JTA platform implementation for WebSphere (versions 4, 5.0 and 5.1)
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class WebSphereJtaPlatform extends AbstractJtaPlatform {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, WebSphereJtaPlatform.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, WebSphereJtaPlatform.class.getName());
 
 	public static final String VERSION_5_UT_NAME = "java:comp/UserTransaction";
 	public static final String VERSION_4_UT_NAME = "jta/usertransaction";
 
 	private final JtaSynchronizationStrategy synchronizationStrategy = new TransactionManagerBasedSynchronizationStrategy( this );
 
 	private final Class transactionManagerAccessClass;
 	private final int webSphereVersion;
 
 	public WebSphereJtaPlatform() {
 		try {
 			Class clazz;
 			int version;
 			try {
 				clazz = Class.forName( "com.ibm.ws.Transaction.TransactionManagerFactory" );
 				version = 5;
                 LOG.debug("WebSphere 5.1");
 			}
 			catch ( Exception e ) {
 				try {
 					clazz = Class.forName( "com.ibm.ejs.jts.jta.TransactionManagerFactory" );
 					version = 5;
                     LOG.debug("WebSphere 5.0");
 				}
 				catch ( Exception e2 ) {
 					clazz = Class.forName( "com.ibm.ejs.jts.jta.JTSXA" );
 					version = 4;
                     LOG.debug("WebSphere 4");
 				}
 			}
 
 			transactionManagerAccessClass = clazz;
 			webSphereVersion = version;
 		}
 		catch ( Exception e ) {
 			throw new JtaPlatformException( "Could not locate WebSphere TransactionManager access class", e );
 		}
 	}
 
 	@Override
 	protected TransactionManager locateTransactionManager() {
 		try {
 			final Method method = transactionManagerAccessClass.getMethod( "getTransactionManager" );
 			return ( TransactionManager ) method.invoke( null );
 		}
 		catch ( Exception e ) {
 			throw new JtaPlatformException( "Could not obtain WebSphere TransactionManager", e );
 		}
 
 	}
 
 	@Override
 	protected UserTransaction locateUserTransaction() {
 		final String utName = webSphereVersion == 5 ? VERSION_5_UT_NAME : VERSION_4_UT_NAME;
 		return (UserTransaction) jndiService().locate( utName );
 	}
 
 	@Override
 	protected JtaSynchronizationStrategy getSynchronizationStrategy() {
 		return synchronizationStrategy;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentParser.java b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentParser.java
index 730736e01f..4010a3c803 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentParser.java
@@ -1,239 +1,240 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql.ordering.antlr;
 
 import java.util.ArrayList;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.Template;
 import org.jboss.logging.Logger;
 import antlr.CommonAST;
 import antlr.TokenStream;
 import antlr.collections.AST;
 
 /**
  * Extension of the Antlr-generated parser for the purpose of adding our custom parsing behavior.
  *
  * @author Steve Ebersole
  */
 public class OrderByFragmentParser extends GeneratedOrderByFragmentParser {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, OrderByFragmentParser.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, OrderByFragmentParser.class.getName());
 
 	private final TranslationContext context;
 
 	public OrderByFragmentParser(TokenStream lexer, TranslationContext context) {
 		super( lexer );
 		super.setASTFactory( new Factory() );
 		this.context = context;
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
     private int traceDepth = 0;
 
 
 	@Override
     public void traceIn(String ruleName) {
 		if ( inputState.guessing > 0 ) {
 			return;
 		}
 		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
         LOG.trace(prefix + ruleName);
 	}
 
 	@Override
     public void traceOut(String ruleName) {
 		if ( inputState.guessing > 0 ) {
 			return;
 		}
 		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
         LOG.trace(prefix + ruleName);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected void trace(String msg) {
         LOG.trace(msg);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected AST quotedIdentifier(AST ident) {
 		return getASTFactory().create(
 				OrderByTemplateTokenTypes.IDENT,
 				Template.TEMPLATE + "." + context.getDialect().quote( '`' + ident.getText() + '`' )
 		);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected AST quotedString(AST ident) {
 		return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, context.getDialect().quote( ident.getText() ) );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected boolean isFunctionName(AST ast) {
 		AST child = ast.getFirstChild();
 		// assume it is a function if it has parameters
 		if ( child != null && "{param list}".equals( child.getText() ) ) {
 			return true;
 		}
 
 		final SQLFunction function = context.getSqlFunctionRegistry().findSQLFunction( ast.getText() );
 		if ( function == null ) {
 			return false;
 		}
 
 		// if function.hasParenthesesIfNoArguments() is true, then assume
 		// ast.getText() is not a function.
 		return ! function.hasParenthesesIfNoArguments();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected AST resolveFunction(AST ast) {
 		AST child = ast.getFirstChild();
 		if ( child != null ) {
 			assert "{param list}".equals(  child.getText() );
 			child = child.getFirstChild();
 		}
 
 		final String functionName = ast.getText();
 		final SQLFunction function = context.getSqlFunctionRegistry().findSQLFunction( functionName );
 		if ( function == null ) {
 			String text = functionName;
 			if ( child != null ) {
 				text += '(';
 				while ( child != null ) {
 					text += child.getText();
 					child = child.getNextSibling();
 					if ( child != null ) {
 						text += ", ";
 					}
 				}
 				text += ')';
 			}
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, text );
 		}
 		else {
 			ArrayList expressions = new ArrayList();
 			while ( child != null ) {
 				expressions.add( child.getText() );
 				child = child.getNextSibling();
 			}
 			final String text = function.render( null, expressions, context.getSessionFactory() );
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, text );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected AST resolveIdent(AST ident) {
 		String text = ident.getText();
 		String[] replacements;
 		try {
 			replacements = context.getColumnMapper().map( text );
 		}
 		catch( Throwable t ) {
 			replacements = null;
 		}
 
 		if ( replacements == null || replacements.length == 0 ) {
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, Template.TEMPLATE + "." + text );
 		}
 		else if ( replacements.length == 1 ) {
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, Template.TEMPLATE + "." + replacements[0] );
 		}
 		else {
 			final AST root = getASTFactory().create( OrderByTemplateTokenTypes.IDENT_LIST, "{ident list}" );
 			for ( int i = 0; i < replacements.length; i++ ) {
 				final String identText = Template.TEMPLATE + '.' + replacements[i];
 				root.addChild( getASTFactory().create( OrderByTemplateTokenTypes.IDENT, identText ) );
 			}
 			return root;
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected AST postProcessSortSpecification(AST sortSpec) {
 		assert SORT_SPEC == sortSpec.getType();
 		SortSpecification sortSpecification = ( SortSpecification ) sortSpec;
 		AST sortKey = sortSpecification.getSortKey();
 		if ( IDENT_LIST == sortKey.getFirstChild().getType() ) {
 			AST identList = sortKey.getFirstChild();
 			AST ident = identList.getFirstChild();
 			AST holder = new CommonAST();
 			do {
 				holder.addChild(
 						createSortSpecification(
 								ident,
 								sortSpecification.getCollation(),
 								sortSpecification.getOrdering()
 						)
 				);
 				ident = ident.getNextSibling();
 			} while ( ident != null );
 			sortSpec = holder.getFirstChild();
 		}
 		return sortSpec;
 	}
 
 	private SortSpecification createSortSpecification(
 			AST ident,
 			CollationSpecification collationSpecification,
 			OrderingSpecification orderingSpecification) {
 		AST sortSpecification = getASTFactory().create( SORT_SPEC, "{{sort specification}}" );
 		AST sortKey = getASTFactory().create( SORT_KEY, "{{sort key}}" );
 		AST newIdent = getASTFactory().create( ident.getType(), ident.getText() );
 		sortKey.setFirstChild( newIdent );
 		sortSpecification.setFirstChild( sortKey );
 		if ( collationSpecification != null ) {
 			sortSpecification.addChild( collationSpecification );
 		}
 		if ( orderingSpecification != null ) {
 			sortSpecification.addChild( orderingSpecification );
 		}
 		return ( SortSpecification ) sortSpecification;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentRenderer.java b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentRenderer.java
index 58aa00e6a0..6c0cb2c530 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentRenderer.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentRenderer.java
@@ -1,77 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql.ordering.antlr;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.ast.util.ASTPrinter;
 import org.hibernate.internal.util.StringHelper;
+
 import org.jboss.logging.Logger;
 import antlr.collections.AST;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
 public class OrderByFragmentRenderer extends GeneratedOrderByFragmentRenderer {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        OrderByFragmentRenderer.class.getName());
 	private static final ASTPrinter printer = new ASTPrinter( GeneratedOrderByFragmentRendererTokenTypes.class );
 
 	@Override
     protected void out(AST ast) {
 		out( ( ( Node ) ast ).getRenderableText() );
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
     private int traceDepth = 0;
 
 	@Override
     public void traceIn(String ruleName, AST tree) {
 		if ( inputState.guessing > 0 ) {
 			return;
 		}
 		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
 		String traceText = ruleName + " (" + buildTraceNodeName(tree) + ")";
         LOG.trace(prefix + traceText);
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	@Override
     public void traceOut(String ruleName, AST tree) {
 		if ( inputState.guessing > 0 ) {
 			return;
 		}
 		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
         LOG.trace(prefix + ruleName);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentTranslator.java b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentTranslator.java
index c4ad483d24..a4b1a35223 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentTranslator.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentTranslator.java
@@ -1,86 +1,87 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql.ordering.antlr;
 import java.io.StringReader;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.hql.ast.util.ASTPrinter;
+
 import org.jboss.logging.Logger;
 
 /**
  * A translator which coordinates translation of an <tt>order-by</tt> mapping.
  *
  * @author Steve Ebersole
  */
 public class OrderByFragmentTranslator {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        OrderByFragmentTranslator.class.getName());
 
 	public final TranslationContext context;
 
 	public OrderByFragmentTranslator(TranslationContext context) {
 		this.context = context;
 	}
 
 	/**
 	 * The main contract, performing the transaction.
 	 *
 	 * @param fragment The <tt>order-by</tt> mapping fragment to be translated.
 	 *
 	 * @return The translated fragment.
 	 */
 	public String render(String fragment) {
 		GeneratedOrderByLexer lexer = new GeneratedOrderByLexer( new StringReader( fragment ) );
 		OrderByFragmentParser parser = new OrderByFragmentParser( lexer, context );
 		try {
 			parser.orderByFragment();
 		}
 		catch ( HibernateException e ) {
 			throw e;
 		}
 		catch ( Throwable t ) {
 			throw new HibernateException( "Unable to parse order-by fragment", t );
 		}
 
         if (LOG.isTraceEnabled()) {
 			ASTPrinter printer = new ASTPrinter( OrderByTemplateTokenTypes.class );
             LOG.trace(printer.showAsString(parser.getAST(), "--- {order-by fragment} ---"));
 		}
 
 		OrderByFragmentRenderer renderer = new OrderByFragmentRenderer();
 		try {
 			renderer.orderByFragment( parser.getAST() );
 		}
 		catch ( HibernateException e ) {
 			throw e;
 		}
 		catch ( Throwable t ) {
 			throw new HibernateException( "Unable to render parsed order-by fragment", t );
 		}
 
 		return renderer.getRenderedFragment();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
index 3bb2bced11..58d36cd9f8 100644
--- a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
@@ -1,720 +1,720 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.stat.internal;
 
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cache.Region;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.service.Service;
 import org.hibernate.stat.CollectionStatistics;
 import org.hibernate.stat.EntityStatistics;
 import org.hibernate.stat.QueryStatistics;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 
 /**
  * Implementation of {@link org.hibernate.stat.Statistics} based on the {@link java.util.concurrent} package.
  *
  * @author Alex Snaps
  */
 @SuppressWarnings({ "unchecked" })
 public class ConcurrentStatisticsImpl implements StatisticsImplementor, Service {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, ConcurrentStatisticsImpl.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ConcurrentStatisticsImpl.class.getName());
 
 	private SessionFactoryImplementor sessionFactory;
 
 	private volatile boolean isStatisticsEnabled;
 	private volatile long startTime;
 	private AtomicLong sessionOpenCount = new AtomicLong();
 	private AtomicLong sessionCloseCount = new AtomicLong();
 	private AtomicLong flushCount = new AtomicLong();
 	private AtomicLong connectCount = new AtomicLong();
 
 	private AtomicLong prepareStatementCount = new AtomicLong();
 	private AtomicLong closeStatementCount = new AtomicLong();
 
 	private AtomicLong entityLoadCount = new AtomicLong();
 	private AtomicLong entityUpdateCount = new AtomicLong();
 	private AtomicLong entityInsertCount = new AtomicLong();
 	private AtomicLong entityDeleteCount = new AtomicLong();
 	private AtomicLong entityFetchCount = new AtomicLong();
 	private AtomicLong collectionLoadCount = new AtomicLong();
 	private AtomicLong collectionUpdateCount = new AtomicLong();
 	private AtomicLong collectionRemoveCount = new AtomicLong();
 	private AtomicLong collectionRecreateCount = new AtomicLong();
 	private AtomicLong collectionFetchCount = new AtomicLong();
 
 	private AtomicLong secondLevelCacheHitCount = new AtomicLong();
 	private AtomicLong secondLevelCacheMissCount = new AtomicLong();
 	private AtomicLong secondLevelCachePutCount = new AtomicLong();
 
 	private AtomicLong queryExecutionCount = new AtomicLong();
 	private AtomicLong queryExecutionMaxTime = new AtomicLong();
 	private volatile String queryExecutionMaxTimeQueryString;
 	private AtomicLong queryCacheHitCount = new AtomicLong();
 	private AtomicLong queryCacheMissCount = new AtomicLong();
 	private AtomicLong queryCachePutCount = new AtomicLong();
 
 	private AtomicLong committedTransactionCount = new AtomicLong();
 	private AtomicLong transactionCount = new AtomicLong();
 
 	private AtomicLong optimisticFailureCount = new AtomicLong();
 
 	/**
 	 * second level cache statistics per region
 	 */
 	private final ConcurrentMap secondLevelCacheStatistics = new ConcurrentHashMap();
 	/**
 	 * entity statistics per name
 	 */
 	private final ConcurrentMap entityStatistics = new ConcurrentHashMap();
 	/**
 	 * collection statistics per name
 	 */
 	private final ConcurrentMap collectionStatistics = new ConcurrentHashMap();
 	/**
 	 * entity statistics per query string (HQL or SQL)
 	 */
 	private final ConcurrentMap queryStatistics = new ConcurrentHashMap();
 
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public ConcurrentStatisticsImpl() {
 		clear();
 	}
 
 	public ConcurrentStatisticsImpl(SessionFactoryImplementor sessionFactory) {
 		clear();
 		this.sessionFactory = sessionFactory;
 	}
 
 	/**
 	 * reset all statistics
 	 */
 	public void clear() {
 		secondLevelCacheHitCount.set( 0 );
 		secondLevelCacheMissCount.set( 0 );
 		secondLevelCachePutCount.set( 0 );
 
 		sessionCloseCount.set( 0 );
 		sessionOpenCount.set( 0 );
 		flushCount.set( 0 );
 		connectCount.set( 0 );
 
 		prepareStatementCount.set( 0 );
 		closeStatementCount.set( 0 );
 
 		entityDeleteCount.set( 0 );
 		entityInsertCount.set( 0 );
 		entityUpdateCount.set( 0 );
 		entityLoadCount.set( 0 );
 		entityFetchCount.set( 0 );
 
 		collectionRemoveCount.set( 0 );
 		collectionUpdateCount.set( 0 );
 		collectionRecreateCount.set( 0 );
 		collectionLoadCount.set( 0 );
 		collectionFetchCount.set( 0 );
 
 		queryExecutionCount.set( 0 );
 		queryCacheHitCount.set( 0 );
 		queryExecutionMaxTime.set( 0 );
 		queryExecutionMaxTimeQueryString = null;
 		queryCacheMissCount.set( 0 );
 		queryCachePutCount.set( 0 );
 
 		transactionCount.set( 0 );
 		committedTransactionCount.set( 0 );
 
 		optimisticFailureCount.set( 0 );
 
 		secondLevelCacheStatistics.clear();
 		entityStatistics.clear();
 		collectionStatistics.clear();
 		queryStatistics.clear();
 
 		startTime = System.currentTimeMillis();
 	}
 
 	public void openSession() {
 		sessionOpenCount.getAndIncrement();
 	}
 
 	public void closeSession() {
 		sessionCloseCount.getAndIncrement();
 	}
 
 	public void flush() {
 		flushCount.getAndIncrement();
 	}
 
 	public void connect() {
 		connectCount.getAndIncrement();
 	}
 
 	public void loadEntity(String entityName) {
 		entityLoadCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementLoadCount();
 	}
 
 	public void fetchEntity(String entityName) {
 		entityFetchCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementFetchCount();
 	}
 
 	/**
 	 * find entity statistics per name
 	 *
 	 * @param entityName entity name
 	 *
 	 * @return EntityStatistics object
 	 */
 	public EntityStatistics getEntityStatistics(String entityName) {
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) entityStatistics.get( entityName );
 		if ( es == null ) {
 			es = new ConcurrentEntityStatisticsImpl( entityName );
 			ConcurrentEntityStatisticsImpl previous;
 			if ( ( previous = (ConcurrentEntityStatisticsImpl) entityStatistics.putIfAbsent(
 					entityName, es
 			) ) != null ) {
 				es = previous;
 			}
 		}
 		return es;
 	}
 
 	public void updateEntity(String entityName) {
 		entityUpdateCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementUpdateCount();
 	}
 
 	public void insertEntity(String entityName) {
 		entityInsertCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementInsertCount();
 	}
 
 	public void deleteEntity(String entityName) {
 		entityDeleteCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementDeleteCount();
 	}
 
 	/**
 	 * Get collection statistics per role
 	 *
 	 * @param role collection role
 	 *
 	 * @return CollectionStatistics
 	 */
 	public CollectionStatistics getCollectionStatistics(String role) {
 		ConcurrentCollectionStatisticsImpl cs = (ConcurrentCollectionStatisticsImpl) collectionStatistics.get( role );
 		if ( cs == null ) {
 			cs = new ConcurrentCollectionStatisticsImpl( role );
 			ConcurrentCollectionStatisticsImpl previous;
 			if ( ( previous = (ConcurrentCollectionStatisticsImpl) collectionStatistics.putIfAbsent(
 					role, cs
 			) ) != null ) {
 				cs = previous;
 			}
 		}
 		return cs;
 	}
 
 	public void loadCollection(String role) {
 		collectionLoadCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementLoadCount();
 	}
 
 	public void fetchCollection(String role) {
 		collectionFetchCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementFetchCount();
 	}
 
 	public void updateCollection(String role) {
 		collectionUpdateCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementUpdateCount();
 	}
 
 	public void recreateCollection(String role) {
 		collectionRecreateCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementRecreateCount();
 	}
 
 	public void removeCollection(String role) {
 		collectionRemoveCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementRemoveCount();
 	}
 
 	/**
 	 * Second level cache statistics per region
 	 *
 	 * @param regionName region name
 	 *
 	 * @return SecondLevelCacheStatistics
 	 */
 	public SecondLevelCacheStatistics getSecondLevelCacheStatistics(String regionName) {
 		ConcurrentSecondLevelCacheStatisticsImpl slcs
 				= (ConcurrentSecondLevelCacheStatisticsImpl) secondLevelCacheStatistics.get( regionName );
 		if ( slcs == null ) {
 			if ( sessionFactory == null ) {
 				return null;
 			}
 			Region region = sessionFactory.getSecondLevelCacheRegion( regionName );
 			if ( region == null ) {
 				return null;
 			}
 			slcs = new ConcurrentSecondLevelCacheStatisticsImpl( region );
 			ConcurrentSecondLevelCacheStatisticsImpl previous;
 			if ( ( previous = (ConcurrentSecondLevelCacheStatisticsImpl) secondLevelCacheStatistics.putIfAbsent(
 					regionName, slcs
 			) ) != null ) {
 				slcs = previous;
 			}
 		}
 		return slcs;
 	}
 
 	public void secondLevelCachePut(String regionName) {
 		secondLevelCachePutCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementPutCount();
 	}
 
 	public void secondLevelCacheHit(String regionName) {
 		secondLevelCacheHitCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementHitCount();
 	}
 
 	public void secondLevelCacheMiss(String regionName) {
 		secondLevelCacheMissCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementMissCount();
 	}
 
 	@SuppressWarnings({ "UnnecessaryBoxing" })
 	public void queryExecuted(String hql, int rows, long time) {
         LOG.hql(hql, Long.valueOf(time), Long.valueOf(rows));
 		queryExecutionCount.getAndIncrement();
 		boolean isLongestQuery = false;
 		for ( long old = queryExecutionMaxTime.get();
 			  ( isLongestQuery = time > old ) && ( !queryExecutionMaxTime.compareAndSet( old, time ) );
 			  old = queryExecutionMaxTime.get() ) {
 			// nothing to do here given the odd loop structure...
 		}
 		if ( isLongestQuery ) {
 			queryExecutionMaxTimeQueryString = hql;
 		}
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.executed( rows, time );
 		}
 	}
 
 	public void queryCacheHit(String hql, String regionName) {
 		queryCacheHitCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCacheHitCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementHitCount();
 	}
 
 	public void queryCacheMiss(String hql, String regionName) {
 		queryCacheMissCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCacheMissCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementMissCount();
 	}
 
 	public void queryCachePut(String hql, String regionName) {
 		queryCachePutCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCachePutCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementPutCount();
 	}
 
 	/**
 	 * Query statistics from query string (HQL or SQL)
 	 *
 	 * @param queryString query string
 	 *
 	 * @return QueryStatistics
 	 */
 	public QueryStatistics getQueryStatistics(String queryString) {
 		ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) queryStatistics.get( queryString );
 		if ( qs == null ) {
 			qs = new ConcurrentQueryStatisticsImpl( queryString );
 			ConcurrentQueryStatisticsImpl previous;
 			if ( ( previous = (ConcurrentQueryStatisticsImpl) queryStatistics.putIfAbsent(
 					queryString, qs
 			) ) != null ) {
 				qs = previous;
 			}
 		}
 		return qs;
 	}
 
 	/**
 	 * @return entity deletion count
 	 */
 	public long getEntityDeleteCount() {
 		return entityDeleteCount.get();
 	}
 
 	/**
 	 * @return entity insertion count
 	 */
 	public long getEntityInsertCount() {
 		return entityInsertCount.get();
 	}
 
 	/**
 	 * @return entity load (from DB)
 	 */
 	public long getEntityLoadCount() {
 		return entityLoadCount.get();
 	}
 
 	/**
 	 * @return entity fetch (from DB)
 	 */
 	public long getEntityFetchCount() {
 		return entityFetchCount.get();
 	}
 
 	/**
 	 * @return entity update
 	 */
 	public long getEntityUpdateCount() {
 		return entityUpdateCount.get();
 	}
 
 	public long getQueryExecutionCount() {
 		return queryExecutionCount.get();
 	}
 
 	public long getQueryCacheHitCount() {
 		return queryCacheHitCount.get();
 	}
 
 	public long getQueryCacheMissCount() {
 		return queryCacheMissCount.get();
 	}
 
 	public long getQueryCachePutCount() {
 		return queryCachePutCount.get();
 	}
 
 	/**
 	 * @return flush
 	 */
 	public long getFlushCount() {
 		return flushCount.get();
 	}
 
 	/**
 	 * @return session connect
 	 */
 	public long getConnectCount() {
 		return connectCount.get();
 	}
 
 	/**
 	 * @return second level cache hit
 	 */
 	public long getSecondLevelCacheHitCount() {
 		return secondLevelCacheHitCount.get();
 	}
 
 	/**
 	 * @return second level cache miss
 	 */
 	public long getSecondLevelCacheMissCount() {
 		return secondLevelCacheMissCount.get();
 	}
 
 	/**
 	 * @return second level cache put
 	 */
 	public long getSecondLevelCachePutCount() {
 		return secondLevelCachePutCount.get();
 	}
 
 	/**
 	 * @return session closing
 	 */
 	public long getSessionCloseCount() {
 		return sessionCloseCount.get();
 	}
 
 	/**
 	 * @return session opening
 	 */
 	public long getSessionOpenCount() {
 		return sessionOpenCount.get();
 	}
 
 	/**
 	 * @return collection loading (from DB)
 	 */
 	public long getCollectionLoadCount() {
 		return collectionLoadCount.get();
 	}
 
 	/**
 	 * @return collection fetching (from DB)
 	 */
 	public long getCollectionFetchCount() {
 		return collectionFetchCount.get();
 	}
 
 	/**
 	 * @return collection update
 	 */
 	public long getCollectionUpdateCount() {
 		return collectionUpdateCount.get();
 	}
 
 	/**
 	 * @return collection removal
 	 *         FIXME: even if isInverse="true"?
 	 */
 	public long getCollectionRemoveCount() {
 		return collectionRemoveCount.get();
 	}
 
 	/**
 	 * @return collection recreation
 	 */
 	public long getCollectionRecreateCount() {
 		return collectionRecreateCount.get();
 	}
 
 	/**
 	 * @return start time in ms (JVM standards {@link System#currentTimeMillis()})
 	 */
 	public long getStartTime() {
 		return startTime;
 	}
 
 	/**
 	 * log in info level the main statistics
 	 */
 	public void logSummary() {
         LOG.loggingStatistics();
         LOG.startTime(startTime);
         LOG.sessionsOpened(sessionOpenCount.get());
         LOG.sessionsClosed(sessionCloseCount.get());
         LOG.transactions(transactionCount.get());
         LOG.successfulTransactions(committedTransactionCount.get());
         LOG.optimisticLockFailures(optimisticFailureCount.get());
         LOG.flushes(flushCount.get());
         LOG.connectionsObtained(connectCount.get());
         LOG.statementsPrepared(prepareStatementCount.get());
         LOG.statementsClosed(closeStatementCount.get());
         LOG.secondLevelCachePuts(secondLevelCachePutCount.get());
         LOG.secondLevelCacheHits(secondLevelCacheHitCount.get());
         LOG.secondLevelCacheMisses(secondLevelCacheMissCount.get());
         LOG.entitiesLoaded(entityLoadCount.get());
         LOG.entitiesUpdated(entityUpdateCount.get());
         LOG.entitiesInserted(entityInsertCount.get());
         LOG.entitiesDeleted(entityDeleteCount.get());
         LOG.entitiesFetched(entityFetchCount.get());
         LOG.collectionsLoaded(collectionLoadCount.get());
         LOG.collectionsUpdated(collectionUpdateCount.get());
         LOG.collectionsRemoved(collectionRemoveCount.get());
         LOG.collectionsRecreated(collectionRecreateCount.get());
         LOG.collectionsFetched(collectionFetchCount.get());
         LOG.queriesExecuted(queryExecutionCount.get());
         LOG.queryCachePuts(queryCachePutCount.get());
         LOG.queryCacheHits(queryCacheHitCount.get());
         LOG.queryCacheMisses(queryCacheMissCount.get());
         LOG.maxQueryTime(queryExecutionMaxTime.get());
 	}
 
 	/**
 	 * Are statistics logged
 	 */
 	public boolean isStatisticsEnabled() {
 		return isStatisticsEnabled;
 	}
 
 	/**
 	 * Enable statistics logs (this is a dynamic parameter)
 	 */
 	public void setStatisticsEnabled(boolean b) {
 		isStatisticsEnabled = b;
 	}
 
 	/**
 	 * @return Returns the max query execution time,
 	 *         for all queries
 	 */
 	public long getQueryExecutionMaxTime() {
 		return queryExecutionMaxTime.get();
 	}
 
 	/**
 	 * Get all executed query strings
 	 */
 	public String[] getQueries() {
 		return ArrayHelper.toStringArray( queryStatistics.keySet() );
 	}
 
 	/**
 	 * Get the names of all entities
 	 */
 	public String[] getEntityNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( entityStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllClassMetadata().keySet() );
 		}
 	}
 
 	/**
 	 * Get the names of all collection roles
 	 */
 	public String[] getCollectionRoleNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( collectionStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllCollectionMetadata().keySet() );
 		}
 	}
 
 	/**
 	 * Get all second-level cache region names
 	 */
 	public String[] getSecondLevelCacheRegionNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( secondLevelCacheStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllSecondLevelCacheRegions().keySet() );
 		}
 	}
 
 	public void endTransaction(boolean success) {
 		transactionCount.getAndIncrement();
 		if ( success ) {
 			committedTransactionCount.getAndIncrement();
 		}
 	}
 
 	public long getSuccessfulTransactionCount() {
 		return committedTransactionCount.get();
 	}
 
 	public long getTransactionCount() {
 		return transactionCount.get();
 	}
 
 	public void closeStatement() {
 		closeStatementCount.getAndIncrement();
 	}
 
 	public void prepareStatement() {
 		prepareStatementCount.getAndIncrement();
 	}
 
 	public long getCloseStatementCount() {
 		return closeStatementCount.get();
 	}
 
 	public long getPrepareStatementCount() {
 		return prepareStatementCount.get();
 	}
 
 	public void optimisticFailure(String entityName) {
 		optimisticFailureCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementOptimisticFailureCount();
 	}
 
 	public long getOptimisticFailureCount() {
 		return optimisticFailureCount.get();
 	}
 
 	@Override
     public String toString() {
 		return new StringBuilder()
 				.append( "Statistics[" )
 				.append( "start time=" ).append( startTime )
 				.append( ",sessions opened=" ).append( sessionOpenCount )
 				.append( ",sessions closed=" ).append( sessionCloseCount )
 				.append( ",transactions=" ).append( transactionCount )
 				.append( ",successful transactions=" ).append( committedTransactionCount )
 				.append( ",optimistic lock failures=" ).append( optimisticFailureCount )
 				.append( ",flushes=" ).append( flushCount )
 				.append( ",connections obtained=" ).append( connectCount )
 				.append( ",statements prepared=" ).append( prepareStatementCount )
 				.append( ",statements closed=" ).append( closeStatementCount )
 				.append( ",second level cache puts=" ).append( secondLevelCachePutCount )
 				.append( ",second level cache hits=" ).append( secondLevelCacheHitCount )
 				.append( ",second level cache misses=" ).append( secondLevelCacheMissCount )
 				.append( ",entities loaded=" ).append( entityLoadCount )
 				.append( ",entities updated=" ).append( entityUpdateCount )
 				.append( ",entities inserted=" ).append( entityInsertCount )
 				.append( ",entities deleted=" ).append( entityDeleteCount )
 				.append( ",entities fetched=" ).append( entityFetchCount )
 				.append( ",collections loaded=" ).append( collectionLoadCount )
 				.append( ",collections updated=" ).append( collectionUpdateCount )
 				.append( ",collections removed=" ).append( collectionRemoveCount )
 				.append( ",collections recreated=" ).append( collectionRecreateCount )
 				.append( ",collections fetched=" ).append( collectionFetchCount )
 				.append( ",queries executed to database=" ).append( queryExecutionCount )
 				.append( ",query cache puts=" ).append( queryCachePutCount )
 				.append( ",query cache hits=" ).append( queryCacheHitCount )
 				.append( ",query cache misses=" ).append( queryCacheMissCount )
 				.append( ",max query time=" ).append( queryExecutionMaxTime )
 				.append( ']' )
 				.toString();
 	}
 
 	public String getQueryExecutionMaxTimeQueryString() {
 		return queryExecutionMaxTimeQueryString;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/stat/internal/StatisticsInitiator.java b/hibernate-core/src/main/java/org/hibernate/stat/internal/StatisticsInitiator.java
index 63ca430847..219662bd2c 100644
--- a/hibernate-core/src/main/java/org/hibernate/stat/internal/StatisticsInitiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/stat/internal/StatisticsInitiator.java
@@ -1,102 +1,102 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.stat.internal;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.service.classloading.spi.ClassLoaderService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceInitiator;
 import org.hibernate.stat.spi.StatisticsFactory;
 import org.hibernate.stat.spi.StatisticsImplementor;
 
 /**
  * @author Steve Ebersole
  */
 public class StatisticsInitiator implements SessionFactoryServiceInitiator<StatisticsImplementor> {
-	private static final HibernateLogger LOG = Logger.getMessageLogger( HibernateLogger.class, StatisticsInitiator.class.getName() );
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, StatisticsInitiator.class.getName() );
 
 	public static final StatisticsInitiator INSTANCE = new StatisticsInitiator();
 
 	/**
 	 * Names the {@link StatisticsFactory} to use.  Recognizes both a class name as well as an instance of
 	 * {@link StatisticsFactory}.
 	 */
 	public static final String STATS_BUILDER = "hibernate.stats.factory";
 
 	@Override
 	public Class<StatisticsImplementor> getServiceInitiated() {
 		return StatisticsImplementor.class;
 	}
 
 	@Override
 	public StatisticsImplementor initiateService(
 			SessionFactoryImplementor sessionFactory,
 			Configuration configuration,
 			ServiceRegistryImplementor registry) {
 		final Object configValue = configuration.getProperties().get( STATS_BUILDER );
 
 		StatisticsFactory statisticsFactory;
 		if ( configValue == null ) {
 			statisticsFactory = DEFAULT_STATS_BUILDER;
 		}
 		else if ( StatisticsFactory.class.isInstance( configValue ) ) {
 			statisticsFactory = (StatisticsFactory) configValue;
 		}
 		else {
 			// assume it names the factory class
 			final ClassLoaderService classLoaderService = registry.getService( ClassLoaderService.class );
 			try {
 				statisticsFactory = (StatisticsFactory) classLoaderService.classForName( configValue.toString() ).newInstance();
 			}
 			catch (HibernateException e) {
 				throw e;
 			}
 			catch (Exception e) {
 				throw new HibernateException(
 						"Unable to instantiate specified StatisticsFactory implementation [" + configValue.toString() + "]",
 						e
 				);
 			}
 		}
 
 		StatisticsImplementor statistics = statisticsFactory.buildStatistics( sessionFactory );
 		final boolean enabled = sessionFactory.getSettings().isStatisticsEnabled();
 		statistics.setStatisticsEnabled( enabled );
 		LOG.debugf( "Statistics initialized [enabled=%s]", enabled );
 		return statistics;
 
 	}
 
 	private static StatisticsFactory DEFAULT_STATS_BUILDER = new StatisticsFactory() {
 		@Override
 		public StatisticsImplementor buildStatistics(SessionFactoryImplementor sessionFactory) {
 			return new ConcurrentStatisticsImpl( sessionFactory );
 		}
 	};
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/DatabaseExporter.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/DatabaseExporter.java
index 16b5e2f764..add2187679 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/DatabaseExporter.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/DatabaseExporter.java
@@ -1,85 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
 import java.sql.Statement;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 
 /**
 * @author Steve Ebersole
 */
 class DatabaseExporter implements Exporter {
-	private static final HibernateLogger LOG = Logger.getMessageLogger( HibernateLogger.class, DatabaseExporter.class.getName() );
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, DatabaseExporter.class.getName() );
 
 	private final ConnectionHelper connectionHelper;
 	private final SqlExceptionHelper sqlExceptionHelper;
 
 	private final Connection connection;
 	private final Statement statement;
 
 	public DatabaseExporter(ConnectionHelper connectionHelper, SqlExceptionHelper sqlExceptionHelper) throws SQLException {
 		this.connectionHelper = connectionHelper;
 		this.sqlExceptionHelper = sqlExceptionHelper;
 
 		connectionHelper.prepare( true );
 		connection = connectionHelper.getConnection();
 		statement = connection.createStatement();
 	}
 
 	@Override
 	public boolean acceptsImportScripts() {
 		return true;
 	}
 
 	@Override
 	public void export(String string) throws Exception {
 		statement.executeUpdate( string );
 		try {
 			SQLWarning warnings = statement.getWarnings();
 			if ( warnings != null) {
 				sqlExceptionHelper.logAndClearWarnings( connection );
 			}
 		}
 		catch( SQLException e ) {
 			LOG.unableToLogSqlWarnings( e );
 		}
 	}
 
 	@Override
 	public void release() throws Exception {
 		try {
 			statement.close();
 		}
 		finally {
 			connectionHelper.release();
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/DatabaseMetadata.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/DatabaseMetadata.java
index 30ef403ff8..312b81bd23 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/DatabaseMetadata.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/DatabaseMetadata.java
@@ -1,196 +1,197 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Table;
+
 import org.jboss.logging.Logger;
 
 /**
  * JDBC database metadata
  * @author Christoph Sturm, Teodor Danciu
  */
 public class DatabaseMetadata {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, DatabaseMetaData.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DatabaseMetaData.class.getName());
 
 	private final Map tables = new HashMap();
 	private final Set sequences = new HashSet();
 	private final boolean extras;
 
 	private DatabaseMetaData meta;
 	private SQLExceptionConverter sqlExceptionConverter;
 
 	public DatabaseMetadata(Connection connection, Dialect dialect) throws SQLException {
 		this(connection, dialect, true);
 	}
 
 	public DatabaseMetadata(Connection connection, Dialect dialect, boolean extras) throws SQLException {
 		sqlExceptionConverter = dialect.buildSQLExceptionConverter();
 		meta = connection.getMetaData();
 		this.extras = extras;
 		initSequences(connection, dialect);
 	}
 
 	private static final String[] TYPES = {"TABLE", "VIEW"};
 
 	public TableMetadata getTableMetadata(String name, String schema, String catalog, boolean isQuoted) throws HibernateException {
 
 		Object identifier = identifier(catalog, schema, name);
 		TableMetadata table = (TableMetadata) tables.get(identifier);
 		if (table!=null) {
 			return table;
 		}
 		else {
 
 			try {
 				ResultSet rs = null;
 				try {
 					if ( (isQuoted && meta.storesMixedCaseQuotedIdentifiers())) {
 						rs = meta.getTables(catalog, schema, name, TYPES);
 					} else if ( (isQuoted && meta.storesUpperCaseQuotedIdentifiers())
 						|| (!isQuoted && meta.storesUpperCaseIdentifiers() )) {
 						rs = meta.getTables(
 								StringHelper.toUpperCase(catalog),
 								StringHelper.toUpperCase(schema),
 								StringHelper.toUpperCase(name),
 								TYPES
 							);
 					}
 					else if ( (isQuoted && meta.storesLowerCaseQuotedIdentifiers())
 							|| (!isQuoted && meta.storesLowerCaseIdentifiers() )) {
 						rs = meta.getTables( 
 								StringHelper.toLowerCase( catalog ),
 								StringHelper.toLowerCase(schema), 
 								StringHelper.toLowerCase(name), 
 								TYPES 
 							);
 					}
 					else {
 						rs = meta.getTables(catalog, schema, name, TYPES);
 					}
 
 					while ( rs.next() ) {
 						String tableName = rs.getString("TABLE_NAME");
 						if ( name.equalsIgnoreCase(tableName) ) {
 							table = new TableMetadata(rs, meta, extras);
 							tables.put(identifier, table);
 							return table;
 						}
 					}
 
                     LOG.tableNotFound(name);
 					return null;
 
 				}
 				finally {
 					if (rs!=null) rs.close();
 				}
 			}
 			catch (SQLException sqlException) {
 				throw new SqlExceptionHelper( sqlExceptionConverter )
 						.convert( sqlException, "could not get table metadata: " + name );
 			}
 		}
 
 	}
 
 	private Object identifier(String catalog, String schema, String name) {
 		return Table.qualify(catalog,schema,name);
 	}
 
 	private void initSequences(Connection connection, Dialect dialect) throws SQLException {
 		if ( dialect.supportsSequences() ) {
 			String sql = dialect.getQuerySequencesString();
 			if (sql!=null) {
 
 				Statement statement = null;
 				ResultSet rs = null;
 				try {
 					statement = connection.createStatement();
 					rs = statement.executeQuery(sql);
 
 					while ( rs.next() ) {
 						sequences.add( rs.getString(1).toLowerCase().trim() );
 					}
 				}
 				finally {
 					if (rs!=null) rs.close();
 					if (statement!=null) statement.close();
 				}
 
 			}
 		}
 	}
 
 	public boolean isSequence(Object key) {
 		if (key instanceof String){
 			String[] strings = StringHelper.split(".", (String) key);
 			return sequences.contains( strings[strings.length-1].toLowerCase());
 		}
 		return false;
 	}
 
  	public boolean isTable(Object key) throws HibernateException {
  		if(key instanceof String) {
 			Table tbl = new Table((String)key);
 			if ( getTableMetadata( tbl.getName(), tbl.getSchema(), tbl.getCatalog(), tbl.isQuoted() ) != null ) {
  				return true;
  			} else {
  				String[] strings = StringHelper.split(".", (String) key);
  				if(strings.length==3) {
 					tbl = new Table(strings[2]);
 					tbl.setCatalog(strings[0]);
 					tbl.setSchema(strings[1]);
 					return getTableMetadata( tbl.getName(), tbl.getSchema(), tbl.getCatalog(), tbl.isQuoted() ) != null;
  				} else if (strings.length==2) {
 					tbl = new Table(strings[1]);
 					tbl.setSchema(strings[0]);
 					return getTableMetadata( tbl.getName(), tbl.getSchema(), tbl.getCatalog(), tbl.isQuoted() ) != null;
  				}
  			}
  		}
  		return false;
  	}
 
 	@Override
     public String toString() {
 		return "DatabaseMetadata" + tables.keySet().toString() + sequences.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
index 8cabd2c9e0..20ac7dbac3 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
@@ -1,576 +1,576 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.BufferedReader;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
 import java.io.Writer;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.internal.Formatter;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 
 /**
  * Commandline tool to export table schema to the database. This class may also be called from inside an application.
  *
  * @author Daniel Bradby
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class SchemaExport {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SchemaExport.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SchemaExport.class.getName());
 	private static final String DEFAULT_IMPORT_FILE = "/import.sql";
 
 	public static enum Type {
 		CREATE,
 		DROP,
 		NONE,
 		BOTH;
 
 		public boolean doCreate() {
 			return this == BOTH || this == CREATE;
 		}
 
 		public boolean doDrop() {
 			return this == BOTH || this == DROP;
 		}
 	}
 
 	private final ConnectionHelper connectionHelper;
 	private final SqlStatementLogger sqlStatementLogger;
 	private final SqlExceptionHelper sqlExceptionHelper;
 	private final String[] dropSQL;
 	private final String[] createSQL;
 	private final String importFiles;
 
 	private final List<Exception> exceptions = new ArrayList<Exception>();
 
 	private Formatter formatter;
 
 	private String outputFile = null;
 	private String delimiter;
 	private boolean haltOnError = false;
 
 	public SchemaExport(ServiceRegistry serviceRegistry, Configuration configuration) {
 		this.connectionHelper = new SuppliedConnectionProviderConnectionHelper(
 				serviceRegistry.getService( ConnectionProvider.class )
 		);
 		this.sqlStatementLogger = serviceRegistry.getService( JdbcServices.class ).getSqlStatementLogger();
 		this.formatter = ( sqlStatementLogger.isFormat() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		this.sqlExceptionHelper = serviceRegistry.getService( JdbcServices.class ).getSqlExceptionHelper();
 
 		this.importFiles = ConfigurationHelper.getString(
 				Environment.HBM2DDL_IMPORT_FILES,
 				configuration.getProperties(),
 				DEFAULT_IMPORT_FILE
 		);
 
 		final Dialect dialect = serviceRegistry.getService( JdbcServices.class ).getDialect();
 		this.dropSQL = configuration.generateDropSchemaScript( dialect );
 		this.createSQL = configuration.generateSchemaCreationScript( dialect );
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration
 	 *
 	 * @param configuration The configuration from which to build a schema export.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 */
 	public SchemaExport(Configuration configuration) {
 		this( configuration, configuration.getProperties() );
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration, with the given
 	 * database connection properties.
 	 *
 	 * @param configuration The configuration from which to build a schema export.
 	 * @param properties The properties from which to configure connectivity etc.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 *
 	 * @deprecated properties may be specified via the Configuration object
 	 */
 	@Deprecated
     public SchemaExport(Configuration configuration, Properties properties) throws HibernateException {
 		final Dialect dialect = Dialect.getDialect( properties );
 
 		Properties props = new Properties();
 		props.putAll( dialect.getDefaultProperties() );
 		props.putAll( properties );
 		this.connectionHelper = new ManagedProviderConnectionHelper( props );
 
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.formatter = FormatStyle.DDL.getFormatter();
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 
 		this.importFiles = ConfigurationHelper.getString(
 				Environment.HBM2DDL_IMPORT_FILES,
 				properties,
 				DEFAULT_IMPORT_FILE
 		);
 
 		this.dropSQL = configuration.generateDropSchemaScript( dialect );
 		this.createSQL = configuration.generateSchemaCreationScript( dialect );
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration, using the supplied connection for connectivity.
 	 *
 	 * @param configuration The configuration to use.
 	 * @param connection The JDBC connection to use.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 */
 	public SchemaExport(Configuration configuration, Connection connection) throws HibernateException {
 		this.connectionHelper = new SuppliedConnectionHelper( connection );
 
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.formatter = FormatStyle.DDL.getFormatter();
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 
 		this.importFiles = ConfigurationHelper.getString(
 				Environment.HBM2DDL_IMPORT_FILES,
 				configuration.getProperties(),
 				DEFAULT_IMPORT_FILE
 		);
 
 		final Dialect dialect = Dialect.getDialect( configuration.getProperties() );
 		this.dropSQL = configuration.generateDropSchemaScript( dialect );
 		this.createSQL = configuration.generateSchemaCreationScript( dialect );
 	}
 
 	public SchemaExport(
 			ConnectionHelper connectionHelper,
 			String[] dropSql,
 			String[] createSql) {
 		this.connectionHelper = connectionHelper;
 		this.dropSQL = dropSql;
 		this.createSQL = createSql;
 		this.importFiles = "";
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 		this.formatter = FormatStyle.DDL.getFormatter();
 	}
 
 	/**
 	 * For generating a export script file, this is the file which will be written.
 	 *
 	 * @param filename The name of the file to which to write the export script.
 	 * @return this
 	 */
 	public SchemaExport setOutputFile(String filename) {
 		outputFile = filename;
 		return this;
 	}
 
 	/**
 	 * Set the end of statement delimiter
 	 *
 	 * @param delimiter The delimiter
 	 * @return this
 	 */
 	public SchemaExport setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 		return this;
 	}
 
 	/**
 	 * Should we format the sql strings?
 	 *
 	 * @param format Should we format SQL strings
 	 * @return this
 	 */
 	public SchemaExport setFormat(boolean format) {
 		this.formatter = ( format ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		return this;
 	}
 
 	/**
 	 * Should we stop once an error occurs?
 	 *
 	 * @param haltOnError True if export should stop after error.
 	 * @return this
 	 */
 	public SchemaExport setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 		return this;
 	}
 
 	/**
 	 * Run the schema creation script.
 	 *
 	 * @param script print the DDL to the console
 	 * @param export export the script to the database
 	 */
 	public void create(boolean script, boolean export) {
 		create( Target.interpret( script, export ) );
 	}
 
 	public void create(Target output) {
 		execute( output, Type.CREATE );
 	}
 
 	/**
 	 * Run the drop schema script.
 	 *
 	 * @param script print the DDL to the console
 	 * @param export export the script to the database
 	 */
 	public void drop(boolean script, boolean export) {
 		drop( Target.interpret( script, export ) );
 	}
 
 	public void drop(Target output) {
 		execute( output, Type.DROP );
 	}
 
 	public void execute(boolean script, boolean export, boolean justDrop, boolean justCreate) {
 		execute( Target.interpret( script, export ), interpretType( justDrop, justCreate ) );
 	}
 
 	private Type interpretType(boolean justDrop, boolean justCreate) {
 		if ( justDrop ) {
 			return Type.DROP;
 		}
 		else if ( justCreate ) {
 			return Type.CREATE;
 		}
 		else {
 			return Type.BOTH;
 		}
 	}
 
 	public void execute(Target output, Type type) {
 		if ( output == Target.NONE || type == SchemaExport.Type.NONE ) {
 			return;
 		}
 		exceptions.clear();
 
 		LOG.runningHbm2ddlSchemaExport();
 
 		final List<NamedReader> importFileReaders = new ArrayList<NamedReader>();
 		for ( String currentFile : importFiles.split(",") ) {
 			try {
 				final String resourceName = currentFile.trim();
 				InputStream stream = ConfigHelper.getResourceAsStream( resourceName );
 				importFileReaders.add( new NamedReader( resourceName, stream ) );
 			}
 			catch ( HibernateException e ) {
 				LOG.debugf("Import file not found: %s", currentFile);
 			}
 		}
 
 		final List<Exporter> exporters = new ArrayList<Exporter>();
 		try {
 			// prepare exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			if ( output.doScript() ) {
 				exporters.add( new ScriptExporter() );
 			}
 			if ( outputFile != null ) {
 				exporters.add( new FileExporter( outputFile ) );
 			}
 			if ( output.doExport() ) {
 				exporters.add( new DatabaseExporter( connectionHelper, sqlExceptionHelper ) );
 			}
 
 			// perform exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			if ( type.doDrop() ) {
 				perform( dropSQL, exporters );
 			}
 			if ( type.doCreate() ) {
 				perform( createSQL, exporters );
 				if ( ! importFileReaders.isEmpty() ) {
 					for ( NamedReader namedReader : importFileReaders ) {
 						importScript( namedReader, exporters );
 					}
 				}
 			}
 		}
 		catch (Exception e) {
 			exceptions.add( e );
 			LOG.schemaExportUnsuccessful( e );
 		}
 		finally {
 			// release exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			for ( Exporter exporter : exporters ) {
 				try {
 					exporter.release();
 				}
 				catch (Exception ignore) {
 				}
 			}
 
 			// release the named readers from import scripts
 			for ( NamedReader namedReader : importFileReaders ) {
 				try {
 					namedReader.getReader().close();
 				}
 				catch (Exception ignore) {
 				}
 			}
             LOG.schemaExportComplete();
 		}
 	}
 
 	private void perform(String[] sqlCommands, List<Exporter> exporters) {
 		for ( String sqlCommand : sqlCommands ) {
 			String formatted = formatter.format( sqlCommand );
 	        if ( delimiter != null ) {
 				formatted += delimiter;
 			}
 			sqlStatementLogger.logStatement( formatted );
 			for ( Exporter exporter : exporters ) {
 				try {
 					exporter.export( formatted );
 				}
 				catch (Exception e) {
 					if ( haltOnError ) {
 						throw new HibernateException( "Error during DDL export", e );
 					}
 					exceptions.add( e );
 					LOG.unsuccessfulCreate( sqlCommand );
 					LOG.error( e.getMessage() );
 				}
 			}
 		}
 	}
 
 	private void importScript(NamedReader namedReader, List<Exporter> exporters) throws Exception {
 		BufferedReader reader = new BufferedReader( namedReader.getReader() );
 		long lineNo = 0;
 		for ( String sql = reader.readLine(); sql != null; sql = reader.readLine() ) {
 			try {
 				lineNo++;
 				String trimmedSql = sql.trim();
 				if ( trimmedSql.length() == 0 ||
 						trimmedSql.startsWith( "--" ) ||
 						trimmedSql.startsWith( "//" ) ||
 						trimmedSql.startsWith( "/*" ) ) {
 					continue;
 				}
                 if ( trimmedSql.endsWith(";") ) {
 					trimmedSql = trimmedSql.substring(0, trimmedSql.length() - 1);
 				}
                 LOG.debugf( trimmedSql );
 				for ( Exporter exporter: exporters ) {
 					if ( exporter.acceptsImportScripts() ) {
 						exporter.export( trimmedSql );
 					}
 				}
 			}
 			catch ( Exception e ) {
 				throw new ImportScriptException( "Error during import script execution at line " + lineNo, e );
 			}
 		}
 	}
 
 	private static class NamedReader {
 		private final Reader reader;
 		private final String name;
 
 		public NamedReader(String name, InputStream stream) {
 			this.name = name;
 			this.reader = new InputStreamReader( stream );
 		}
 
 		public Reader getReader() {
 			return reader;
 		}
 
 		public String getName() {
 			return name;
 		}
 	}
 
 	private void execute(boolean script, boolean export, Writer fileOutput, Statement statement, final String sql)
 			throws IOException, SQLException {
 		final SqlExceptionHelper sqlExceptionHelper = new SqlExceptionHelper();
 
 		String formatted = formatter.format( sql );
         if (delimiter != null) formatted += delimiter;
         if (script) System.out.println(formatted);
         LOG.debugf(formatted);
 		if ( outputFile != null ) {
 			fileOutput.write( formatted + "\n" );
 		}
 		if ( export ) {
 
 			statement.executeUpdate( sql );
 			try {
 				SQLWarning warnings = statement.getWarnings();
 				if ( warnings != null) {
 					sqlExceptionHelper.logAndClearWarnings( connectionHelper.getConnection() );
 				}
 			}
 			catch( SQLException sqle ) {
                 LOG.unableToLogSqlWarnings(sqle);
 			}
 		}
 
 	}
 
 	private static BasicServiceRegistryImpl createServiceRegistry(Properties properties) {
 		Environment.verifyProperties( properties );
 		ConfigurationHelper.resolvePlaceHolders( properties );
 		return new BasicServiceRegistryImpl( properties );
 	}
 
 	public static void main(String[] args) {
 		try {
 			Configuration cfg = new Configuration();
 
 			boolean script = true;
 			boolean drop = false;
 			boolean create = false;
 			boolean halt = false;
 			boolean export = true;
 			String outFile = null;
 			String importFile = DEFAULT_IMPORT_FILE;
 			String propFile = null;
 			boolean format = false;
 			String delim = null;
 
 			for ( int i = 0; i < args.length; i++ ) {
 				if ( args[i].startsWith( "--" ) ) {
 					if ( args[i].equals( "--quiet" ) ) {
 						script = false;
 					}
 					else if ( args[i].equals( "--drop" ) ) {
 						drop = true;
 					}
 					else if ( args[i].equals( "--create" ) ) {
 						create = true;
 					}
 					else if ( args[i].equals( "--haltonerror" ) ) {
 						halt = true;
 					}
 					else if ( args[i].equals( "--text" ) ) {
 						export = false;
 					}
 					else if ( args[i].startsWith( "--output=" ) ) {
 						outFile = args[i].substring( 9 );
 					}
 					else if ( args[i].startsWith( "--import=" ) ) {
 						importFile = args[i].substring( 9 );
 					}
 					else if ( args[i].startsWith( "--properties=" ) ) {
 						propFile = args[i].substring( 13 );
 					}
 					else if ( args[i].equals( "--format" ) ) {
 						format = true;
 					}
 					else if ( args[i].startsWith( "--delimiter=" ) ) {
 						delim = args[i].substring( 12 );
 					}
 					else if ( args[i].startsWith( "--config=" ) ) {
 						cfg.configure( args[i].substring( 9 ) );
 					}
 					else if ( args[i].startsWith( "--naming=" ) ) {
 						cfg.setNamingStrategy(
 								( NamingStrategy ) ReflectHelper.classForName( args[i].substring( 9 ) )
 										.newInstance()
 						);
 					}
 				}
 				else {
 					String filename = args[i];
 					if ( filename.endsWith( ".jar" ) ) {
 						cfg.addJar( new File( filename ) );
 					}
 					else {
 						cfg.addFile( filename );
 					}
 				}
 
 			}
 
 			if ( propFile != null ) {
 				Properties props = new Properties();
 				props.putAll( cfg.getProperties() );
 				props.load( new FileInputStream( propFile ) );
 				cfg.setProperties( props );
 			}
 
 			if (importFile != null) {
 				cfg.setProperty( Environment.HBM2DDL_IMPORT_FILES, importFile );
 			}
 
 			BasicServiceRegistryImpl serviceRegistry = createServiceRegistry( cfg.getProperties() );
 			try {
 				SchemaExport se = new SchemaExport( serviceRegistry, cfg )
 						.setHaltOnError( halt )
 						.setOutputFile( outFile )
 						.setDelimiter( delim );
 				if ( format ) {
 					se.setFormat( true );
 				}
 				se.execute( script, export, drop, create );
 			}
 			finally {
 				serviceRegistry.destroy();
 			}
 		}
 		catch ( Exception e ) {
             LOG.unableToCreateSchema(e);
 			e.printStackTrace();
 		}
 	}
 
 	/**
 	 * Returns a List of all Exceptions which occured during the export.
 	 *
 	 * @return A List containig the Exceptions occured during the export
 	 */
 	public List getExceptions() {
 		return exceptions;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
index fadf2639c5..3c2840e6c9 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
@@ -1,294 +1,294 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.FileInputStream;
 import java.io.FileWriter;
 import java.io.Writer;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.JDBCException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.internal.Formatter;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 /**
  * A commandline tool to update a database schema. May also be called from inside an application.
  *
  * @author Christoph Sturm
  * @author Steve Ebersole
  */
 public class SchemaUpdate {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SchemaUpdate.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SchemaUpdate.class.getName());
 
 	private final Configuration configuration;
 	private final ConnectionHelper connectionHelper;
 	private final SqlStatementLogger sqlStatementLogger;
 	private final SqlExceptionHelper sqlExceptionHelper;
 	private final Dialect dialect;
 
 	private final List<Exception> exceptions = new ArrayList<Exception>();
 
 	private Formatter formatter;
 
 	private boolean haltOnError = false;
 	private boolean format = true;
 	private String outputFile = null;
 	private String delimiter;
 
 	public SchemaUpdate(Configuration cfg) throws HibernateException {
 		this( cfg, cfg.getProperties() );
 	}
 
 	public SchemaUpdate(Configuration configuration, Properties properties) throws HibernateException {
 		this.configuration = configuration;
 		this.dialect = Dialect.getDialect( properties );
 
 		Properties props = new Properties();
 		props.putAll( dialect.getDefaultProperties() );
 		props.putAll( properties );
 		this.connectionHelper = new ManagedProviderConnectionHelper( props );
 
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.formatter = FormatStyle.DDL.getFormatter();
 	}
 
 	public SchemaUpdate(ServiceRegistry serviceRegistry, Configuration cfg) throws HibernateException {
 		this.configuration = cfg;
 
 		final JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 		this.dialect = jdbcServices.getDialect();
 		this.connectionHelper = new SuppliedConnectionProviderConnectionHelper( jdbcServices.getConnectionProvider() );
 
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 		this.sqlStatementLogger = jdbcServices.getSqlStatementLogger();
 		this.formatter = ( sqlStatementLogger.isFormat() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 	}
 
 	private static BasicServiceRegistryImpl createServiceRegistry(Properties properties) {
 		Environment.verifyProperties( properties );
 		ConfigurationHelper.resolvePlaceHolders( properties );
 		return new BasicServiceRegistryImpl( properties );
 	}
 
 	public static void main(String[] args) {
 		try {
 			Configuration cfg = new Configuration();
 
 			boolean script = true;
 			// If true then execute db updates, otherwise just generate and display updates
 			boolean doUpdate = true;
 			String propFile = null;
 
 			for ( int i = 0; i < args.length; i++ ) {
 				if ( args[i].startsWith( "--" ) ) {
 					if ( args[i].equals( "--quiet" ) ) {
 						script = false;
 					}
 					else if ( args[i].startsWith( "--properties=" ) ) {
 						propFile = args[i].substring( 13 );
 					}
 					else if ( args[i].startsWith( "--config=" ) ) {
 						cfg.configure( args[i].substring( 9 ) );
 					}
 					else if ( args[i].startsWith( "--text" ) ) {
 						doUpdate = false;
 					}
 					else if ( args[i].startsWith( "--naming=" ) ) {
 						cfg.setNamingStrategy(
 								( NamingStrategy ) ReflectHelper.classForName( args[i].substring( 9 ) ).newInstance()
 						);
 					}
 				}
 				else {
 					cfg.addFile( args[i] );
 				}
 
 			}
 
 			if ( propFile != null ) {
 				Properties props = new Properties();
 				props.putAll( cfg.getProperties() );
 				props.load( new FileInputStream( propFile ) );
 				cfg.setProperties( props );
 			}
 
 			BasicServiceRegistryImpl serviceRegistry = createServiceRegistry( cfg.getProperties() );
 			try {
 				new SchemaUpdate( serviceRegistry, cfg ).execute( script, doUpdate );
 			}
 			finally {
 				serviceRegistry.destroy();
 			}
 		}
 		catch ( Exception e ) {
             LOG.unableToRunSchemaUpdate(e);
 			e.printStackTrace();
 		}
 	}
 
 	/**
 	 * Execute the schema updates
 	 *
 	 * @param script print all DDL to the console
 	 */
 	public void execute(boolean script, boolean doUpdate) {
 		execute( Target.interpret( script, doUpdate ) );
 	}
 	
 	public void execute(Target target) {
         LOG.runningHbm2ddlSchemaUpdate();
 
 		Connection connection = null;
 		Statement stmt = null;
 		Writer outputFileWriter = null;
 
 		exceptions.clear();
 
 		try {
 			DatabaseMetadata meta;
 			try {
                 LOG.fetchingDatabaseMetadata();
 				connectionHelper.prepare( true );
 				connection = connectionHelper.getConnection();
 				meta = new DatabaseMetadata( connection, dialect );
 				stmt = connection.createStatement();
 			}
 			catch ( SQLException sqle ) {
 				exceptions.add( sqle );
                 LOG.unableToGetDatabaseMetadata(sqle);
 				throw sqle;
 			}
 
             LOG.updatingSchema();
 
 			if ( outputFile != null ) {
                 LOG.writingGeneratedSchemaToFile( outputFile );
 				outputFileWriter = new FileWriter( outputFile );
 			}
 
 			String[] sqlStrings = configuration.generateSchemaUpdateScript( dialect, meta );
 			for ( String sql : sqlStrings ) {
 				String formatted = formatter.format( sql );
 				try {
 					if ( delimiter != null ) {
 						formatted += delimiter;
 					}
 					if ( target.doScript() ) {
 						System.out.println( formatted );
 					}
 					if ( outputFile != null ) {
 						outputFileWriter.write( formatted + "\n" );
 					}
 					if ( target.doExport() ) {
                         LOG.debugf( sql );
 						stmt.executeUpdate( formatted );
 					}
 				}
 				catch ( SQLException e ) {
 					if ( haltOnError ) {
 						throw new JDBCException( "Error during DDL export", e );
 					}
 					exceptions.add( e );
                     LOG.unsuccessful(sql);
                     LOG.error(e.getMessage());
 				}
 			}
 
             LOG.schemaUpdateComplete();
 
 		}
 		catch ( Exception e ) {
 			exceptions.add( e );
             LOG.unableToCompleteSchemaUpdate(e);
 		}
 		finally {
 
 			try {
 				if ( stmt != null ) {
 					stmt.close();
 				}
 				connectionHelper.release();
 			}
 			catch ( Exception e ) {
 				exceptions.add( e );
                 LOG.unableToCloseConnection(e);
 			}
 			try {
 				if( outputFileWriter != null ) {
 					outputFileWriter.close();
 				}
 			}
 			catch(Exception e) {
 				exceptions.add(e);
                 LOG.unableToCloseConnection(e);
 			}
 		}
 	}
 
 	/**
 	 * Returns a List of all Exceptions which occured during the export.
 	 *
 	 * @return A List containig the Exceptions occured during the export
 	 */
 	public List getExceptions() {
 		return exceptions;
 	}
 
 	public void setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 	}
 
 	public void setFormat(boolean format) {
 		this.formatter = ( format ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 	}
 
 	public void setOutputFile(String outputFile) {
 		this.outputFile = outputFile;
 	}
 
 	public void setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
index 02007efc35..9d6169d270 100755
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
@@ -1,171 +1,171 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.FileInputStream;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 /**
  * A commandline tool to update a database schema. May also be called from
  * inside an application.
  *
  * @author Christoph Sturm
  */
 public class SchemaValidator {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, SchemaValidator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SchemaValidator.class.getName());
 
 	private ConnectionHelper connectionHelper;
 	private Configuration configuration;
 	private Dialect dialect;
 
 	public SchemaValidator(Configuration cfg) throws HibernateException {
 		this( cfg, cfg.getProperties() );
 	}
 
 	public SchemaValidator(Configuration cfg, Properties connectionProperties) throws HibernateException {
 		this.configuration = cfg;
 		dialect = Dialect.getDialect( connectionProperties );
 		Properties props = new Properties();
 		props.putAll( dialect.getDefaultProperties() );
 		props.putAll( connectionProperties );
 		connectionHelper = new ManagedProviderConnectionHelper( props );
 	}
 
 	public SchemaValidator(ServiceRegistry serviceRegistry, Configuration cfg ) throws HibernateException {
 		this.configuration = cfg;
 		final JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 		this.dialect = jdbcServices.getDialect();
 		this.connectionHelper = new SuppliedConnectionProviderConnectionHelper( jdbcServices.getConnectionProvider() );
 	}
 
 	private static BasicServiceRegistryImpl createServiceRegistry(Properties properties) {
 		Environment.verifyProperties( properties );
 		ConfigurationHelper.resolvePlaceHolders( properties );
 		return new BasicServiceRegistryImpl( properties );
 	}
 
 	public static void main(String[] args) {
 		try {
 			Configuration cfg = new Configuration();
 
 			String propFile = null;
 
 			for ( int i = 0; i < args.length; i++ ) {
 				if ( args[i].startsWith( "--" ) ) {
 					if ( args[i].startsWith( "--properties=" ) ) {
 						propFile = args[i].substring( 13 );
 					}
 					else if ( args[i].startsWith( "--config=" ) ) {
 						cfg.configure( args[i].substring( 9 ) );
 					}
 					else if ( args[i].startsWith( "--naming=" ) ) {
 						cfg.setNamingStrategy(
 								( NamingStrategy ) ReflectHelper.classForName( args[i].substring( 9 ) ).newInstance()
 						);
 					}
 				}
 				else {
 					cfg.addFile( args[i] );
 				}
 
 			}
 
 			if ( propFile != null ) {
 				Properties props = new Properties();
 				props.putAll( cfg.getProperties() );
 				props.load( new FileInputStream( propFile ) );
 				cfg.setProperties( props );
 			}
 
 			BasicServiceRegistryImpl serviceRegistry = createServiceRegistry( cfg.getProperties() );
 			try {
 				new SchemaValidator( serviceRegistry, cfg ).validate();
 			}
 			finally {
 				serviceRegistry.destroy();
 			}
 		}
 		catch ( Exception e ) {
             LOG.unableToRunSchemaUpdate(e);
 			e.printStackTrace();
 		}
 	}
 
 	/**
 	 * Perform the validations.
 	 */
 	public void validate() {
 
         LOG.runningSchemaValidator();
 
 		Connection connection = null;
 
 		try {
 
 			DatabaseMetadata meta;
 			try {
                 LOG.fetchingDatabaseMetadata();
 				connectionHelper.prepare( false );
 				connection = connectionHelper.getConnection();
 				meta = new DatabaseMetadata( connection, dialect, false );
 			}
 			catch ( SQLException sqle ) {
                 LOG.unableToGetDatabaseMetadata(sqle);
 				throw sqle;
 			}
 
 			configuration.validateSchema( dialect, meta );
 
 		}
 		catch ( SQLException e ) {
             LOG.unableToCompleteSchemaValidation(e);
 		}
 		finally {
 
 			try {
 				connectionHelper.release();
 			}
 			catch ( Exception e ) {
                 LOG.unableToCloseConnection(e);
 			}
 
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/TableMetadata.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/TableMetadata.java
index 1458f797d4..93694d364a 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/TableMetadata.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/TableMetadata.java
@@ -1,207 +1,208 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.mapping.ForeignKey;
 import org.jboss.logging.Logger;
 
 /**
  * JDBC table metadata
  *
  * @author Christoph Sturm
  * @author Max Rydahl Andersen
  */
 public class TableMetadata {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TableMetadata.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TableMetadata.class.getName());
 
 	private final String catalog;
 	private final String schema;
 	private final String name;
 	private final Map columns = new HashMap();
 	private final Map foreignKeys = new HashMap();
 	private final Map indexes = new HashMap();
 
 	TableMetadata(ResultSet rs, DatabaseMetaData meta, boolean extras) throws SQLException {
 		catalog = rs.getString("TABLE_CAT");
 		schema = rs.getString("TABLE_SCHEM");
 		name = rs.getString("TABLE_NAME");
 		initColumns(meta);
 		if (extras) {
 			initForeignKeys(meta);
 			initIndexes(meta);
 		}
 		String cat = catalog==null ? "" : catalog + '.';
 		String schem = schema==null ? "" : schema + '.';
-        LOG.tableFound(cat + schem + name);
-        LOG.columns(columns.keySet());
+        LOG.tableFound( cat + schem + name );
+        LOG.columns( columns.keySet() );
 		if (extras) {
-            LOG.foreignKeys(foreignKeys.keySet());
-            LOG.indexes(indexes.keySet());
+            LOG.foreignKeys( foreignKeys.keySet() );
+            LOG.indexes( indexes.keySet() );
 		}
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public String getCatalog() {
 		return catalog;
 	}
 
 	public String getSchema() {
 		return schema;
 	}
 
 	@Override
     public String toString() {
 		return "TableMetadata(" + name + ')';
 	}
 
 	public ColumnMetadata getColumnMetadata(String columnName) {
 		return (ColumnMetadata) columns.get( columnName.toLowerCase() );
 	}
 
 	public ForeignKeyMetadata getForeignKeyMetadata(String keyName) {
 		return (ForeignKeyMetadata) foreignKeys.get( keyName.toLowerCase() );
 	}
 
 	public ForeignKeyMetadata getForeignKeyMetadata(ForeignKey fk) {
 		Iterator it = foreignKeys.values().iterator();
 		while ( it.hasNext() ) {
 			ForeignKeyMetadata existingFk = ( ForeignKeyMetadata ) it.next();
 			if ( existingFk.matches( fk ) ) {
 				return existingFk;
 			}
 		}
 		return null;
 	}
 
 	public IndexMetadata getIndexMetadata(String indexName) {
 		return (IndexMetadata) indexes.get( indexName.toLowerCase() );
 	}
 
 	private void addForeignKey(ResultSet rs) throws SQLException {
 		String fk = rs.getString("FK_NAME");
 
 		if (fk == null) {
 			return;
 		}
 
 		ForeignKeyMetadata info = getForeignKeyMetadata(fk);
 		if (info == null) {
 			info = new ForeignKeyMetadata(rs);
 			foreignKeys.put( info.getName().toLowerCase(), info );
 		}
 
 		info.addReference( rs );
 	}
 
 	private void addIndex(ResultSet rs) throws SQLException {
 		String index = rs.getString("INDEX_NAME");
 
 		if (index == null) {
 			return;
 		}
 
 		IndexMetadata info = getIndexMetadata(index);
 		if (info == null) {
 			info = new IndexMetadata(rs);
 			indexes.put( info.getName().toLowerCase(), info );
 		}
 
 		info.addColumn( getColumnMetadata( rs.getString("COLUMN_NAME") ) );
 	}
 
 	public void addColumn(ResultSet rs) throws SQLException {
 		String column = rs.getString("COLUMN_NAME");
 
 		if (column==null) {
 			return;
 		}
 
 		if ( getColumnMetadata(column) == null ) {
 			ColumnMetadata info = new ColumnMetadata(rs);
 			columns.put( info.getName().toLowerCase(), info );
 		}
 	}
 
 	private void initForeignKeys(DatabaseMetaData meta) throws SQLException {
 		ResultSet rs = null;
 
 		try {
 			rs = meta.getImportedKeys(catalog, schema, name);
 			while ( rs.next() ) {
 				addForeignKey(rs);
 			}
 		}
 		finally {
 			if (rs != null) {
 				rs.close();
 			}
 		}
 	}
 
 	private void initIndexes(DatabaseMetaData meta) throws SQLException {
 		ResultSet rs = null;
 
 		try {
 			rs = meta.getIndexInfo(catalog, schema, name, false, true);
 
 			while ( rs.next() ) {
 				if ( rs.getShort("TYPE") == DatabaseMetaData.tableIndexStatistic ) {
 					continue;
 				}
 				addIndex(rs);
 			}
 		}
 		finally {
 			if (rs != null) {
 				rs.close();
 			}
 		}
 	}
 
 	private void initColumns(DatabaseMetaData meta) throws SQLException {
 		ResultSet rs = null;
 
 		try {
 			rs = meta.getColumns(catalog, schema, name, "%");
 			while ( rs.next() ) {
 				addColumn(rs);
 			}
 		}
 		finally  {
 			if (rs != null) {
 				rs.close();
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/transform/DistinctResultTransformer.java b/hibernate-core/src/main/java/org/hibernate/transform/DistinctResultTransformer.java
index ed25c6050c..25a2d9ae94 100644
--- a/hibernate-core/src/main/java/org/hibernate/transform/DistinctResultTransformer.java
+++ b/hibernate-core/src/main/java/org/hibernate/transform/DistinctResultTransformer.java
@@ -1,108 +1,110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.transform;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * Distinctions the result tuples in the final result based on the defined
  * equality of the tuples.
  * <p/>
  * Since this transformer is stateless, all instances would be considered equal.
  * So for optimization purposes we limit it to a single, singleton {@link #INSTANCE instance}.
  *
  * @author Steve Ebersole
  */
 public class DistinctResultTransformer extends BasicTransformerAdapter {
 
 	public static final DistinctResultTransformer INSTANCE = new DistinctResultTransformer();
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DistinctResultTransformer.class.getName());
 
 	/**
 	 * Helper class to handle distincting
 	 */
 	private static final class Identity {
 		final Object entity;
 
 		private Identity(Object entity) {
 			this.entity = entity;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		@Override
         public boolean equals(Object other) {
 			return Identity.class.isInstance( other )
 					&& this.entity == ( ( Identity ) other ).entity;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		@Override
         public int hashCode() {
 			return System.identityHashCode( entity );
 		}
 	}
 
 	/**
 	 * Disallow instantiation of DistinctResultTransformer.
 	 */
 	private DistinctResultTransformer() {
 	}
 
 	/**
 	 * Uniquely distinct each tuple row here.
 	 */
 	@Override
     public List transformList(List list) {
 		List result = new ArrayList( list.size() );
 		Set distinct = new HashSet();
 		for ( int i = 0; i < list.size(); i++ ) {
 			Object entity = list.get( i );
 			if ( distinct.add( new Identity( entity ) ) ) {
 				result.add( entity );
 			}
 		}
         LOG.debugf("Transformed: %s rows to: %s distinct results", list.size(), result.size());
 		return result;
 	}
 
 	/**
 	 * Serialization hook for ensuring singleton uniqueing.
 	 *
 	 * @return The singleton instance : {@link #INSTANCE}
 	 */
 	private Object readResolve() {
 		return INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/PojoInstantiator.java b/hibernate-core/src/main/java/org/hibernate/tuple/PojoInstantiator.java
index f3c3d7b342..2e89248b6f 100755
--- a/hibernate-core/src/main/java/org/hibernate/tuple/PojoInstantiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/PojoInstantiator.java
@@ -1,121 +1,122 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tuple;
 
 import java.io.IOException;
 import java.io.Serializable;
 import java.lang.reflect.Constructor;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.InstantiationException;
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.bytecode.spi.ReflectionOptimizer;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
+
 import org.jboss.logging.Logger;
 
 /**
  * Defines a POJO-based instantiator for use from the tuplizers.
  */
 public class PojoInstantiator implements Instantiator, Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, PojoInstantiator.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, PojoInstantiator.class.getName());
 
 	private transient Constructor constructor;
 
 	private final Class mappedClass;
 	private final transient ReflectionOptimizer.InstantiationOptimizer optimizer;
 	private final boolean embeddedIdentifier;
 	private final Class proxyInterface;
 
 	public PojoInstantiator(Component component, ReflectionOptimizer.InstantiationOptimizer optimizer) {
 		this.mappedClass = component.getComponentClass();
 		this.optimizer = optimizer;
 
 		this.proxyInterface = null;
 		this.embeddedIdentifier = false;
 
 		try {
 			constructor = ReflectHelper.getDefaultConstructor(mappedClass);
 		}
 		catch ( PropertyNotFoundException pnfe ) {
             LOG.noDefaultConstructor(mappedClass.getName());
 			constructor = null;
 		}
 	}
 
 	public PojoInstantiator(PersistentClass persistentClass, ReflectionOptimizer.InstantiationOptimizer optimizer) {
 		this.mappedClass = persistentClass.getMappedClass();
 		this.proxyInterface = persistentClass.getProxyInterface();
 		this.embeddedIdentifier = persistentClass.hasEmbeddedIdentifier();
 		this.optimizer = optimizer;
 
 		try {
 			constructor = ReflectHelper.getDefaultConstructor( mappedClass );
 		}
 		catch ( PropertyNotFoundException pnfe ) {
             LOG.noDefaultConstructor(mappedClass.getName());
 			constructor = null;
 		}
 	}
 
 	private void readObject(java.io.ObjectInputStream stream)
 	throws ClassNotFoundException, IOException {
 		stream.defaultReadObject();
 		constructor = ReflectHelper.getDefaultConstructor( mappedClass );
 	}
 
 	public Object instantiate() {
 		if ( ReflectHelper.isAbstractClass(mappedClass) ) {
 			throw new InstantiationException( "Cannot instantiate abstract class or interface: ", mappedClass );
 		}
 		else if ( optimizer != null ) {
 			return optimizer.newInstance();
 		}
 		else if ( constructor == null ) {
 			throw new InstantiationException( "No default constructor for entity: ", mappedClass );
 		}
 		else {
 			try {
 				return constructor.newInstance( (Object[]) null );
 			}
 			catch ( Exception e ) {
 				throw new InstantiationException( "Could not instantiate entity: ", mappedClass, e );
 			}
 		}
 	}
 
 	public Object instantiate(Serializable id) {
 		final boolean useEmbeddedIdentifierInstanceAsEntity = embeddedIdentifier &&
 				id != null &&
 				id.getClass().equals(mappedClass);
 		return useEmbeddedIdentifierInstanceAsEntity ? id : instantiate();
 	}
 
 	public boolean isInstance(Object object) {
 		return mappedClass.isInstance(object) ||
 				( proxyInterface!=null && proxyInterface.isInstance(object) ); //this one needed only for guessEntityMode()
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/AbstractEntityTuplizer.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/AbstractEntityTuplizer.java
index d316ae944f..88c1a6bd17 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/AbstractEntityTuplizer.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/AbstractEntityTuplizer.java
@@ -1,686 +1,686 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import java.io.Serializable;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.EventType;
 import org.hibernate.event.PersistEvent;
 import org.hibernate.event.PersistEventListener;
 import org.hibernate.id.Assigned;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.property.Getter;
 import org.hibernate.property.Setter;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.ProxyFactory;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 import org.hibernate.tuple.Instantiator;
 import org.hibernate.tuple.StandardProperty;
 import org.hibernate.tuple.VersionProperty;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 
 /**
  * Support for tuplizers relating to entities.
  *
  * @author Steve Ebersole
  * @author Gavin King
  */
 public abstract class AbstractEntityTuplizer implements EntityTuplizer {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(
-			HibernateLogger.class,
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(
+			CoreMessageLogger.class,
 			AbstractEntityTuplizer.class.getName()
 	);
 
 	//TODO: currently keeps Getters and Setters (instead of PropertyAccessors) because of the way getGetter() and getSetter() are implemented currently; yuck!
 
 	private final EntityMetamodel entityMetamodel;
 
 	private final Getter idGetter;
 	private final Setter idSetter;
 
 	protected final Getter[] getters;
 	protected final Setter[] setters;
 	protected final int propertySpan;
 	protected final boolean hasCustomAccessors;
 	private final Instantiator instantiator;
 	private final ProxyFactory proxyFactory;
 	private final CompositeType identifierMapperType;
 
 	public Type getIdentifierMapperType() {
 		return identifierMapperType;
 	}
 
 	/**
 	 * Build an appropriate Getter for the given property.
 	 *
 	 * @param mappedProperty The property to be accessed via the built Getter.
 	 * @param mappedEntity The entity information regarding the mapped entity owning this property.
 	 * @return An appropriate Getter instance.
 	 */
 	protected abstract Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity);
 
 	/**
 	 * Build an appropriate Setter for the given property.
 	 *
 	 * @param mappedProperty The property to be accessed via the built Setter.
 	 * @param mappedEntity The entity information regarding the mapped entity owning this property.
 	 * @return An appropriate Setter instance.
 	 */
 	protected abstract Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity);
 
 	/**
 	 * Build an appropriate Instantiator for the given mapped entity.
 	 *
 	 * @param mappingInfo The mapping information regarding the mapped entity.
 	 * @return An appropriate Instantiator instance.
 	 */
 	protected abstract Instantiator buildInstantiator(PersistentClass mappingInfo);
 
 	/**
 	 * Build an appropriate ProxyFactory for the given mapped entity.
 	 *
 	 * @param mappingInfo The mapping information regarding the mapped entity.
 	 * @param idGetter The constructed Getter relating to the entity's id property.
 	 * @param idSetter The constructed Setter relating to the entity's id property.
 	 * @return An appropriate ProxyFactory instance.
 	 */
 	protected abstract ProxyFactory buildProxyFactory(PersistentClass mappingInfo, Getter idGetter, Setter idSetter);
 
 	/**
 	 * Constructs a new AbstractEntityTuplizer instance.
 	 *
 	 * @param entityMetamodel The "interpreted" information relating to the mapped entity.
 	 * @param mappingInfo The parsed "raw" mapping data relating to the given entity.
 	 */
 	public AbstractEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappingInfo) {
 		this.entityMetamodel = entityMetamodel;
 
 		if ( !entityMetamodel.getIdentifierProperty().isVirtual() ) {
 			idGetter = buildPropertyGetter( mappingInfo.getIdentifierProperty(), mappingInfo );
 			idSetter = buildPropertySetter( mappingInfo.getIdentifierProperty(), mappingInfo );
 		}
 		else {
 			idGetter = null;
 			idSetter = null;
 		}
 
 		propertySpan = entityMetamodel.getPropertySpan();
 
         getters = new Getter[propertySpan];
 		setters = new Setter[propertySpan];
 
 		Iterator itr = mappingInfo.getPropertyClosureIterator();
 		boolean foundCustomAccessor=false;
 		int i=0;
 		while ( itr.hasNext() ) {
 			//TODO: redesign how PropertyAccessors are acquired...
 			Property property = (Property) itr.next();
 			getters[i] = buildPropertyGetter(property, mappingInfo);
 			setters[i] = buildPropertySetter(property, mappingInfo);
 			if ( !property.isBasicPropertyAccessor() ) {
 				foundCustomAccessor = true;
 			}
 			i++;
 		}
 		hasCustomAccessors = foundCustomAccessor;
 
         instantiator = buildInstantiator( mappingInfo );
 
 		if ( entityMetamodel.isLazy() ) {
 			proxyFactory = buildProxyFactory( mappingInfo, idGetter, idSetter );
 			if (proxyFactory == null) {
 				entityMetamodel.setLazy( false );
 			}
 		}
 		else {
 			proxyFactory = null;
 		}
 
 		Component mapper = mappingInfo.getIdentifierMapper();
 		if ( mapper == null ) {
 			identifierMapperType = null;
 			mappedIdentifierValueMarshaller = null;
 		}
 		else {
 			identifierMapperType = (CompositeType) mapper.getType();
 			mappedIdentifierValueMarshaller = buildMappedIdentifierValueMarshaller(
 					(ComponentType) entityMetamodel.getIdentifierProperty().getType(),
 					(ComponentType) identifierMapperType
 			);
 		}
 	}
 
 	/** Retreives the defined entity-name for the tuplized entity.
 	 *
 	 * @return The entity-name.
 	 */
 	protected String getEntityName() {
 		return entityMetamodel.getName();
 	}
 
 	/**
 	 * Retrieves the defined entity-names for any subclasses defined for this
 	 * entity.
 	 *
 	 * @return Any subclass entity-names.
 	 */
 	protected Set getSubclassEntityNames() {
 		return entityMetamodel.getSubclassEntityNames();
 	}
 
 	public Serializable getIdentifier(Object entity) throws HibernateException {
 		return getIdentifier( entity, null );
 	}
 
 	public Serializable getIdentifier(Object entity, SessionImplementor session) {
 		final Object id;
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
 			id = entity;
 		}
 		else {
 			if ( idGetter == null ) {
 				if (identifierMapperType==null) {
 					throw new HibernateException( "The class has no identifier property: " + getEntityName() );
 				}
 				else {
 					id = mappedIdentifierValueMarshaller.getIdentifier( entity, getEntityMode(), session );
 				}
 			}
 			else {
                 id = idGetter.get( entity );
             }
         }
 
 		try {
 			return (Serializable) id;
 		}
 		catch ( ClassCastException cce ) {
 			StringBuffer msg = new StringBuffer( "Identifier classes must be serializable. " );
 			if ( id != null ) {
 				msg.append( id.getClass().getName() ).append( " is not serializable. " );
 			}
 			if ( cce.getMessage() != null ) {
 				msg.append( cce.getMessage() );
 			}
 			throw new ClassCastException( msg.toString() );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void setIdentifier(Object entity, Serializable id) throws HibernateException {
 		// 99% of the time the session is not needed.  Its only needed for certain brain-dead
 		// interpretations of JPA 2 "derived identity" support
 		setIdentifier( entity, id, null );
 	}
 
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
 			if ( entity != id ) {
 				CompositeType copier = (CompositeType) entityMetamodel.getIdentifierProperty().getType();
 				copier.setPropertyValues( entity, copier.getPropertyValues( id, getEntityMode() ), getEntityMode() );
 			}
 		}
 		else if ( idSetter != null ) {
 			idSetter.set( entity, id, getFactory() );
 		}
 		else if ( identifierMapperType != null ) {
 			mappedIdentifierValueMarshaller.setIdentifier( entity, id, getEntityMode(), session );
 		}
 	}
 
 	private static interface MappedIdentifierValueMarshaller {
 		public Object getIdentifier(Object entity, EntityMode entityMode, SessionImplementor session);
 		public void setIdentifier(Object entity, Serializable id, EntityMode entityMode, SessionImplementor session);
 	}
 
 	private final MappedIdentifierValueMarshaller mappedIdentifierValueMarshaller;
 
 	private static MappedIdentifierValueMarshaller buildMappedIdentifierValueMarshaller(
 			ComponentType mappedIdClassComponentType,
 			ComponentType virtualIdComponent) {
 		// so basically at this point we know we have a "mapped" composite identifier
 		// which is an awful way to say that the identifier is represented differently
 		// in the entity and in the identifier value.  The incoming value should
 		// be an instance of the mapped identifier class (@IdClass) while the incoming entity
 		// should be an instance of the entity class as defined by metamodel.
 		//
 		// However, even within that we have 2 potential scenarios:
 		//		1) @IdClass types and entity @Id property types match
 		//			- return a NormalMappedIdentifierValueMarshaller
 		//		2) They do not match
 		//			- return a IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller
 		boolean wereAllEquivalent = true;
 		// the sizes being off is a much bigger problem that should have been caught already...
 		for ( int i = 0; i < virtualIdComponent.getSubtypes().length; i++ ) {
 			if ( virtualIdComponent.getSubtypes()[i].isEntityType()
 					&& ! mappedIdClassComponentType.getSubtypes()[i].isEntityType() ) {
 				wereAllEquivalent = false;
 				break;
 			}
 		}
 
 		return wereAllEquivalent
 				? (MappedIdentifierValueMarshaller) new NormalMappedIdentifierValueMarshaller( virtualIdComponent, mappedIdClassComponentType )
 				: (MappedIdentifierValueMarshaller) new IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller( virtualIdComponent, mappedIdClassComponentType );
 	}
 
 	private static class NormalMappedIdentifierValueMarshaller implements MappedIdentifierValueMarshaller {
 		private final ComponentType virtualIdComponent;
 		private final ComponentType mappedIdentifierType;
 
 		private NormalMappedIdentifierValueMarshaller(ComponentType virtualIdComponent, ComponentType mappedIdentifierType) {
 			this.virtualIdComponent = virtualIdComponent;
 			this.mappedIdentifierType = mappedIdentifierType;
 		}
 
 		public Object getIdentifier(Object entity, EntityMode entityMode, SessionImplementor session) {
 			Object id = mappedIdentifierType.instantiate( entityMode );
 			final Object[] propertyValues = virtualIdComponent.getPropertyValues( entity, entityMode );
 			mappedIdentifierType.setPropertyValues( id, propertyValues, entityMode );
 			return id;
 		}
 
 		public void setIdentifier(Object entity, Serializable id, EntityMode entityMode, SessionImplementor session) {
 			virtualIdComponent.setPropertyValues(
 					entity,
 					mappedIdentifierType.getPropertyValues( id, session ),
 					entityMode
 			);
 		}
 	}
 
 	private static class IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller implements MappedIdentifierValueMarshaller {
 		private final ComponentType virtualIdComponent;
 		private final ComponentType mappedIdentifierType;
 
 		private IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller(ComponentType virtualIdComponent, ComponentType mappedIdentifierType) {
 			this.virtualIdComponent = virtualIdComponent;
 			this.mappedIdentifierType = mappedIdentifierType;
 		}
 
 		public Object getIdentifier(Object entity, EntityMode entityMode, SessionImplementor session) {
 			final Object id = mappedIdentifierType.instantiate( entityMode );
 			final Object[] propertyValues = virtualIdComponent.getPropertyValues( entity, entityMode );
 			final Type[] subTypes = virtualIdComponent.getSubtypes();
 			final Type[] copierSubTypes = mappedIdentifierType.getSubtypes();
 			final int length = subTypes.length;
 			for ( int i = 0 ; i < length; i++ ) {
 				if ( propertyValues[i] == null ) {
 					throw new HibernateException( "No part of a composite identifier may be null" );
 				}
 				//JPA 2 @MapsId + @IdClass points to the pk of the entity
 				if ( subTypes[i].isAssociationType() && ! copierSubTypes[i].isAssociationType() ) {
 					// we need a session to handle this use case
 					if ( session == null ) {
 						throw new AssertionError(
 								"Deprecated version of getIdentifier (no session) was used but session was required"
 						);
 					}
 					final Object subId;
 					if ( HibernateProxy.class.isInstance( propertyValues[i] ) ) {
 						subId = ( (HibernateProxy) propertyValues[i] ).getHibernateLazyInitializer().getIdentifier();
 					}
 					else {
 						EntityEntry pcEntry = session.getPersistenceContext().getEntry( propertyValues[i] );
 						if ( pcEntry != null ) {
 							subId = pcEntry.getId();
 						}
 						else {
                             LOG.debugf( "Performing implicit derived identity cascade" );
 							final PersistEvent event = new PersistEvent( null, propertyValues[i], (EventSource) session );
 							for ( PersistEventListener listener : persistEventListeners( session ) ) {
 								listener.onPersist( event );
 							}
 							pcEntry = session.getPersistenceContext().getEntry( propertyValues[i] );
 							if ( pcEntry == null || pcEntry.getId() == null ) {
 								throw new HibernateException( "Unable to process implicit derived identity cascade" );
 							}
 							else {
 								subId = pcEntry.getId();
 							}
 						}
 					}
 					propertyValues[i] = subId;
 				}
 			}
 			mappedIdentifierType.setPropertyValues( id, propertyValues, entityMode );
 			return id;
 		}
 
 		public void setIdentifier(Object entity, Serializable id, EntityMode entityMode, SessionImplementor session) {
 			final Object[] extractedValues = mappedIdentifierType.getPropertyValues( id, entityMode );
 			final Object[] injectionValues = new Object[ extractedValues.length ];
 			for ( int i = 0; i < virtualIdComponent.getSubtypes().length; i++ ) {
 				final Type virtualPropertyType = virtualIdComponent.getSubtypes()[i];
 				final Type idClassPropertyType = mappedIdentifierType.getSubtypes()[i];
 				if ( virtualPropertyType.isEntityType() && ! idClassPropertyType.isEntityType() ) {
 					if ( session == null ) {
 						throw new AssertionError(
 								"Deprecated version of getIdentifier (no session) was used but session was required"
 						);
 					}
 					final String associatedEntityName = ( (EntityType) virtualPropertyType ).getAssociatedEntityName();
 					final EntityKey entityKey = session.generateEntityKey(
 							(Serializable) extractedValues[i],
 							session.getFactory().getEntityPersister( associatedEntityName )
 					);
 					// it is conceivable there is a proxy, so check that first
 					Object association = session.getPersistenceContext().getProxy( entityKey );
 					if ( association == null ) {
 						// otherwise look for an initialized version
 						association = session.getPersistenceContext().getEntity( entityKey );
 					}
 					injectionValues[i] = association;
 				}
 				else {
 					injectionValues[i] = extractedValues[i];
 				}
 			}
 			virtualIdComponent.setPropertyValues( entity, injectionValues, session.getEntityMode() );
 		}
 	}
 
 	private static Iterable<PersistEventListener> persistEventListeners(SessionImplementor session) {
 		return session
 				.getFactory()
 				.getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( EventType.PERSIST )
 				.listeners();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion) {
 		// 99% of the time the session is not needed.  Its only needed for certain brain-dead
 		// interpretations of JPA 2 "derived identity" support
 		resetIdentifier( entity, currentId, currentVersion, null );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void resetIdentifier(
 			Object entity,
 			Serializable currentId,
 			Object currentVersion,
 			SessionImplementor session) {
 		if ( entityMetamodel.getIdentifierProperty().getIdentifierGenerator() instanceof Assigned ) {
 		}
 		else {
 			//reset the id
 			Serializable result = entityMetamodel.getIdentifierProperty()
 					.getUnsavedValue()
 					.getDefaultValue( currentId );
 			setIdentifier( entity, result, session );
 			//reset the version
 			VersionProperty versionProperty = entityMetamodel.getVersionProperty();
 			if ( entityMetamodel.isVersioned() ) {
 				setPropertyValue(
 				        entity,
 				        entityMetamodel.getVersionPropertyIndex(),
 						versionProperty.getUnsavedValue().getDefaultValue( currentVersion )
 				);
 			}
 		}
 	}
 
 	public Object getVersion(Object entity) throws HibernateException {
 		if ( !entityMetamodel.isVersioned() ) return null;
 		return getters[ entityMetamodel.getVersionPropertyIndex() ].get( entity );
 	}
 
 	protected boolean shouldGetAllProperties(Object entity) {
 		return !hasUninitializedLazyProperties( entity );
 	}
 
 	public Object[] getPropertyValues(Object entity) throws HibernateException {
 		boolean getAll = shouldGetAllProperties( entity );
 		final int span = entityMetamodel.getPropertySpan();
 		final Object[] result = new Object[span];
 
 		for ( int j = 0; j < span; j++ ) {
 			StandardProperty property = entityMetamodel.getProperties()[j];
 			if ( getAll || !property.isLazy() ) {
 				result[j] = getters[j].get( entity );
 			}
 			else {
 				result[j] = LazyPropertyInitializer.UNFETCHED_PROPERTY;
 			}
 		}
 		return result;
 	}
 
 	public Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session)
 	throws HibernateException {
 		final int span = entityMetamodel.getPropertySpan();
 		final Object[] result = new Object[span];
 
 		for ( int j = 0; j < span; j++ ) {
 			result[j] = getters[j].getForInsert( entity, mergeMap, session );
 		}
 		return result;
 	}
 
 	public Object getPropertyValue(Object entity, int i) throws HibernateException {
 		return getters[i].get( entity );
 	}
 
 	public Object getPropertyValue(Object entity, String propertyPath) throws HibernateException {
 		int loc = propertyPath.indexOf('.');
 		String basePropertyName = loc > 0
 				? propertyPath.substring( 0, loc )
 				: propertyPath;
 		//final int index = entityMetamodel.getPropertyIndexOrNull( basePropertyName );
 		Integer index = entityMetamodel.getPropertyIndexOrNull( basePropertyName );
 		if (index == null) {
 			propertyPath = "_identifierMapper." + propertyPath;
 			loc = propertyPath.indexOf('.');
 			basePropertyName = loc > 0
 				? propertyPath.substring( 0, loc )
 				: propertyPath;
 		}
 		index = entityMetamodel.getPropertyIndexOrNull( basePropertyName );
 		final Object baseValue = getPropertyValue( entity, index.intValue() );
 		if ( loc > 0 ) {
 			if ( baseValue == null ) {
 				return null;
 			}
 			return getComponentValue(
 					(ComponentType) entityMetamodel.getPropertyTypes()[index.intValue()],
 					baseValue,
 					propertyPath.substring(loc+1)
 			);
 		}
 		else {
 			return baseValue;
 		}
 	}
 
 	/**
 	 * Extract a component property value.
 	 *
 	 * @param type The component property types.
 	 * @param component The component instance itself.
 	 * @param propertyPath The property path for the property to be extracted.
 	 * @return The property value extracted.
 	 */
 	protected Object getComponentValue(ComponentType type, Object component, String propertyPath) {
 		final int loc = propertyPath.indexOf( '.' );
 		final String basePropertyName = loc > 0
 				? propertyPath.substring( 0, loc )
 				: propertyPath;
 		final int index = findSubPropertyIndex( type, basePropertyName );
 		final Object baseValue = type.getPropertyValue( component, index, getEntityMode() );
 		if ( loc > 0 ) {
 			if ( baseValue == null ) {
 				return null;
 			}
 			return getComponentValue(
 					(ComponentType) type.getSubtypes()[index],
 					baseValue,
 					propertyPath.substring(loc+1)
 			);
 		}
 		else {
 			return baseValue;
 		}
 
 	}
 
 	private int findSubPropertyIndex(ComponentType type, String subPropertyName) {
 		final String[] propertyNames = type.getPropertyNames();
 		for ( int index = 0; index<propertyNames.length; index++ ) {
 			if ( subPropertyName.equals( propertyNames[index] ) ) {
 				return index;
 			}
 		}
 		throw new MappingException( "component property not found: " + subPropertyName );
 	}
 
 	public void setPropertyValues(Object entity, Object[] values) throws HibernateException {
 		boolean setAll = !entityMetamodel.hasLazyProperties();
 
 		for ( int j = 0; j < entityMetamodel.getPropertySpan(); j++ ) {
 			if ( setAll || values[j] != LazyPropertyInitializer.UNFETCHED_PROPERTY ) {
 				setters[j].set( entity, values[j], getFactory() );
 			}
 		}
 	}
 
 	public void setPropertyValue(Object entity, int i, Object value) throws HibernateException {
 		setters[i].set( entity, value, getFactory() );
 	}
 
 	public void setPropertyValue(Object entity, String propertyName, Object value) throws HibernateException {
 		setters[ entityMetamodel.getPropertyIndex( propertyName ) ].set( entity, value, getFactory() );
 	}
 
 	public final Object instantiate(Serializable id) throws HibernateException {
 		// 99% of the time the session is not needed.  Its only needed for certain brain-dead
 		// interpretations of JPA 2 "derived identity" support
 		return instantiate( id, null );
 	}
 
 	public final Object instantiate(Serializable id, SessionImplementor session) {
 		Object result = getInstantiator().instantiate( id );
 		if ( id != null ) {
 			setIdentifier( result, id, session );
 		}
 		return result;
 	}
 
 	public final Object instantiate() throws HibernateException {
 		return instantiate( null, null );
 	}
 
 	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {}
 
 	public boolean hasUninitializedLazyProperties(Object entity) {
 		// the default is to simply not lazy fetch properties for now...
 		return false;
 	}
 
 	public final boolean isInstance(Object object) {
         return getInstantiator().isInstance( object );
 	}
 
 	public boolean hasProxy() {
 		return entityMetamodel.isLazy();
 	}
 
 	public final Object createProxy(Serializable id, SessionImplementor session)
 	throws HibernateException {
 		return getProxyFactory().getProxy( id, session );
 	}
 
 	public boolean isLifecycleImplementor() {
 		return false;
 	}
 
 	protected final EntityMetamodel getEntityMetamodel() {
 		return entityMetamodel;
 	}
 
 	protected final SessionFactoryImplementor getFactory() {
 		return entityMetamodel.getSessionFactory();
 	}
 
 	protected final Instantiator getInstantiator() {
 		return instantiator;
 	}
 
 	protected final ProxyFactory getProxyFactory() {
 		return proxyFactory;
 	}
 
 	@Override
     public String toString() {
 		return getClass().getName() + '(' + getEntityMetamodel().getName() + ')';
 	}
 
 	public Getter getIdentifierGetter() {
 		return idGetter;
 	}
 
 	public Getter getVersionGetter() {
 		if ( getEntityMetamodel().isVersioned() ) {
 			return getGetter( getEntityMetamodel().getVersionPropertyIndex() );
 		}
 		return null;
 	}
 
 	public Getter getGetter(int i) {
 		return getters[i];
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/Dom4jEntityTuplizer.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/Dom4jEntityTuplizer.java
index f1d9916e93..304c549eb8 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/Dom4jEntityTuplizer.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/Dom4jEntityTuplizer.java
@@ -1,239 +1,239 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
 package org.hibernate.tuple.entity;
-import java.io.Serializable;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.Map;
-import org.dom4j.Element;
-import org.hibernate.EntityMode;
-import org.hibernate.EntityNameResolver;
-import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.engine.SessionFactoryImplementor;
-import org.hibernate.engine.SessionImplementor;
-import org.hibernate.mapping.PersistentClass;
-import org.hibernate.mapping.Property;
-import org.hibernate.property.Getter;
-import org.hibernate.property.PropertyAccessor;
-import org.hibernate.property.PropertyAccessorFactory;
-import org.hibernate.property.Setter;
-import org.hibernate.proxy.HibernateProxy;
-import org.hibernate.proxy.ProxyFactory;
-import org.hibernate.proxy.dom4j.Dom4jProxyFactory;
-import org.hibernate.tuple.Dom4jInstantiator;
-import org.hibernate.tuple.Instantiator;
-import org.hibernate.type.CompositeType;
-import org.jboss.logging.Logger;
-
-/**
- * An {@link EntityTuplizer} specific to the dom4j entity mode.
- *
- * @author Steve Ebersole
- * @author Gavin King
- */
-public class Dom4jEntityTuplizer extends AbstractEntityTuplizer {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, Dom4jEntityTuplizer.class.getName());
-
-	private Map inheritenceNodeNameMap = new HashMap();
-
-	Dom4jEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappedEntity) {
-		super( entityMetamodel, mappedEntity );
-		inheritenceNodeNameMap.put( mappedEntity.getNodeName(), mappedEntity.getEntityName() );
-		Iterator itr = mappedEntity.getSubclassClosureIterator();
-		while( itr.hasNext() ) {
-			final PersistentClass mapping = ( PersistentClass ) itr.next();
-			inheritenceNodeNameMap.put( mapping.getNodeName(), mapping.getEntityName() );
-		}
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public EntityMode getEntityMode() {
-		return EntityMode.DOM4J;
-	}
-
-	private PropertyAccessor buildPropertyAccessor(Property mappedProperty) {
-		if ( mappedProperty.isBackRef() ) {
-			return mappedProperty.getPropertyAccessor(null);
-		}
-		else {
-			return PropertyAccessorFactory.getDom4jPropertyAccessor(
-					mappedProperty.getNodeName(),
-					mappedProperty.getType(),
-					getEntityMetamodel().getSessionFactory()
-				);
-		}
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
-		return buildPropertyAccessor(mappedProperty).getGetter( null, mappedProperty.getName() );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
-		return buildPropertyAccessor(mappedProperty).getSetter( null, mappedProperty.getName() );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    protected Instantiator buildInstantiator(PersistentClass persistentClass) {
-		return new Dom4jInstantiator( persistentClass );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    public Serializable getIdentifier(Object entityOrId) throws HibernateException {
-		return getIdentifier( entityOrId, null );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    public Serializable getIdentifier(Object entityOrId, SessionImplementor session) {
-		if ( entityOrId instanceof Element ) {
-			return super.getIdentifier( entityOrId, session );
-		}
-		else {
-			//it was not embedded, so the argument is just an id
-			return (Serializable) entityOrId;
-		}
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    protected ProxyFactory buildProxyFactory(PersistentClass mappingInfo, Getter idGetter, Setter idSetter) {
-		HashSet proxyInterfaces = new HashSet();
-		proxyInterfaces.add( HibernateProxy.class );
-		proxyInterfaces.add( Element.class );
-
-		ProxyFactory pf = new Dom4jProxyFactory();
-		try {
-			pf.postInstantiate(
-					getEntityName(),
-					Element.class,
-					proxyInterfaces,
-					null,
-					null,
-					mappingInfo.hasEmbeddedIdentifier() ?
-			                (CompositeType) mappingInfo.getIdentifier().getType() :
-			                null
-			);
-		}
-		catch ( HibernateException he ) {
-            LOG.unableToCreateProxyFactory(getEntityName(), he);
-			pf = null;
-		}
-		return pf;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public Class getMappedClass() {
-		return Element.class;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public Class getConcreteProxyClass() {
-		return Element.class;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public boolean isInstrumented() {
-		return false;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public EntityNameResolver[] getEntityNameResolvers() {
-		return new EntityNameResolver[] { new BasicEntityNameResolver( getEntityName(), inheritenceNodeNameMap ) };
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory) {
-		return ( String ) inheritenceNodeNameMap.get( extractNodeName( ( Element ) entityInstance ) );
-	}
-
-	public static String extractNodeName(Element element) {
-		return element.getName();
-	}
-
-	public static class BasicEntityNameResolver implements EntityNameResolver {
-		private final String rootEntityName;
-		private final Map nodeNameToEntityNameMap;
-
-		public BasicEntityNameResolver(String rootEntityName, Map nodeNameToEntityNameMap) {
-			this.rootEntityName = rootEntityName;
-			this.nodeNameToEntityNameMap = nodeNameToEntityNameMap;
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public String resolveEntityName(Object entity) {
-		return ( String ) nodeNameToEntityNameMap.get( extractNodeName( ( Element ) entity ) );
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		@Override
-        public boolean equals(Object obj) {
-			return rootEntityName.equals( ( ( BasicEntityNameResolver ) obj ).rootEntityName );
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		@Override
-        public int hashCode() {
-			return rootEntityName.hashCode();
-		}
-	}
-}
+import java.io.Serializable;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.Map;
+import org.dom4j.Element;
+import org.hibernate.EntityMode;
+import org.hibernate.EntityNameResolver;
+import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.engine.SessionFactoryImplementor;
+import org.hibernate.engine.SessionImplementor;
+import org.hibernate.mapping.PersistentClass;
+import org.hibernate.mapping.Property;
+import org.hibernate.property.Getter;
+import org.hibernate.property.PropertyAccessor;
+import org.hibernate.property.PropertyAccessorFactory;
+import org.hibernate.property.Setter;
+import org.hibernate.proxy.HibernateProxy;
+import org.hibernate.proxy.ProxyFactory;
+import org.hibernate.proxy.dom4j.Dom4jProxyFactory;
+import org.hibernate.tuple.Dom4jInstantiator;
+import org.hibernate.tuple.Instantiator;
+import org.hibernate.type.CompositeType;
+import org.jboss.logging.Logger;
+
+/**
+ * An {@link EntityTuplizer} specific to the dom4j entity mode.
+ *
+ * @author Steve Ebersole
+ * @author Gavin King
+ */
+public class Dom4jEntityTuplizer extends AbstractEntityTuplizer {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Dom4jEntityTuplizer.class.getName());
+
+	private Map inheritenceNodeNameMap = new HashMap();
+
+	Dom4jEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappedEntity) {
+		super( entityMetamodel, mappedEntity );
+		inheritenceNodeNameMap.put( mappedEntity.getNodeName(), mappedEntity.getEntityName() );
+		Iterator itr = mappedEntity.getSubclassClosureIterator();
+		while( itr.hasNext() ) {
+			final PersistentClass mapping = ( PersistentClass ) itr.next();
+			inheritenceNodeNameMap.put( mapping.getNodeName(), mapping.getEntityName() );
+		}
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public EntityMode getEntityMode() {
+		return EntityMode.DOM4J;
+	}
+
+	private PropertyAccessor buildPropertyAccessor(Property mappedProperty) {
+		if ( mappedProperty.isBackRef() ) {
+			return mappedProperty.getPropertyAccessor(null);
+		}
+		else {
+			return PropertyAccessorFactory.getDom4jPropertyAccessor(
+					mappedProperty.getNodeName(),
+					mappedProperty.getType(),
+					getEntityMetamodel().getSessionFactory()
+				);
+		}
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
+		return buildPropertyAccessor(mappedProperty).getGetter( null, mappedProperty.getName() );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
+		return buildPropertyAccessor(mappedProperty).getSetter( null, mappedProperty.getName() );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    protected Instantiator buildInstantiator(PersistentClass persistentClass) {
+		return new Dom4jInstantiator( persistentClass );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    public Serializable getIdentifier(Object entityOrId) throws HibernateException {
+		return getIdentifier( entityOrId, null );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    public Serializable getIdentifier(Object entityOrId, SessionImplementor session) {
+		if ( entityOrId instanceof Element ) {
+			return super.getIdentifier( entityOrId, session );
+		}
+		else {
+			//it was not embedded, so the argument is just an id
+			return (Serializable) entityOrId;
+		}
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    protected ProxyFactory buildProxyFactory(PersistentClass mappingInfo, Getter idGetter, Setter idSetter) {
+		HashSet proxyInterfaces = new HashSet();
+		proxyInterfaces.add( HibernateProxy.class );
+		proxyInterfaces.add( Element.class );
+
+		ProxyFactory pf = new Dom4jProxyFactory();
+		try {
+			pf.postInstantiate(
+					getEntityName(),
+					Element.class,
+					proxyInterfaces,
+					null,
+					null,
+					mappingInfo.hasEmbeddedIdentifier() ?
+			                (CompositeType) mappingInfo.getIdentifier().getType() :
+			                null
+			);
+		}
+		catch ( HibernateException he ) {
+            LOG.unableToCreateProxyFactory(getEntityName(), he);
+			pf = null;
+		}
+		return pf;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public Class getMappedClass() {
+		return Element.class;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public Class getConcreteProxyClass() {
+		return Element.class;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public boolean isInstrumented() {
+		return false;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public EntityNameResolver[] getEntityNameResolvers() {
+		return new EntityNameResolver[] { new BasicEntityNameResolver( getEntityName(), inheritenceNodeNameMap ) };
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory) {
+		return ( String ) inheritenceNodeNameMap.get( extractNodeName( ( Element ) entityInstance ) );
+	}
+
+	public static String extractNodeName(Element element) {
+		return element.getName();
+	}
+
+	public static class BasicEntityNameResolver implements EntityNameResolver {
+		private final String rootEntityName;
+		private final Map nodeNameToEntityNameMap;
+
+		public BasicEntityNameResolver(String rootEntityName, Map nodeNameToEntityNameMap) {
+			this.rootEntityName = rootEntityName;
+			this.nodeNameToEntityNameMap = nodeNameToEntityNameMap;
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public String resolveEntityName(Object entity) {
+		return ( String ) nodeNameToEntityNameMap.get( extractNodeName( ( Element ) entity ) );
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		@Override
+        public boolean equals(Object obj) {
+			return rootEntityName.equals( ( ( BasicEntityNameResolver ) obj ).rootEntityName );
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		@Override
+        public int hashCode() {
+			return rootEntityName.hashCode();
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/DynamicMapEntityTuplizer.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/DynamicMapEntityTuplizer.java
index 72f9dd1b0a..29898534f0 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/DynamicMapEntityTuplizer.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/DynamicMapEntityTuplizer.java
@@ -1,192 +1,192 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Middleware LLC.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
 package org.hibernate.tuple.entity;
-import java.util.Map;
-import org.hibernate.EntityMode;
-import org.hibernate.EntityNameResolver;
-import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
-import org.hibernate.engine.SessionFactoryImplementor;
-import org.hibernate.mapping.PersistentClass;
-import org.hibernate.mapping.Property;
-import org.hibernate.property.Getter;
-import org.hibernate.property.PropertyAccessor;
-import org.hibernate.property.PropertyAccessorFactory;
-import org.hibernate.property.Setter;
-import org.hibernate.proxy.ProxyFactory;
-import org.hibernate.proxy.map.MapProxyFactory;
-import org.hibernate.tuple.DynamicMapInstantiator;
-import org.hibernate.tuple.Instantiator;
-import org.jboss.logging.Logger;
-
-/**
- * An {@link EntityTuplizer} specific to the dynamic-map entity mode.
- *
- * @author Steve Ebersole
- * @author Gavin King
- */
-public class DynamicMapEntityTuplizer extends AbstractEntityTuplizer {
-
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class,
-                                                                       DynamicMapEntityTuplizer.class.getName());
-
-	DynamicMapEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappedEntity) {
-		super(entityMetamodel, mappedEntity);
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public EntityMode getEntityMode() {
-		return EntityMode.MAP;
-	}
-
-	private PropertyAccessor buildPropertyAccessor(Property mappedProperty) {
-		if ( mappedProperty.isBackRef() ) {
-			return mappedProperty.getPropertyAccessor(null);
-		}
-		else {
-			return PropertyAccessorFactory.getDynamicMapPropertyAccessor();
-		}
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
-		return buildPropertyAccessor(mappedProperty).getGetter( null, mappedProperty.getName() );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
-		return buildPropertyAccessor(mappedProperty).getSetter( null, mappedProperty.getName() );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    protected Instantiator buildInstantiator(PersistentClass mappingInfo) {
-        return new DynamicMapInstantiator( mappingInfo );
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	@Override
-    protected ProxyFactory buildProxyFactory(PersistentClass mappingInfo, Getter idGetter, Setter idSetter) {
-
-		ProxyFactory pf = new MapProxyFactory();
-		try {
-			//TODO: design new lifecycle for ProxyFactory
-			pf.postInstantiate(
-					getEntityName(),
-					null,
-					null,
-					null,
-					null,
-					null
-			);
-		}
-		catch ( HibernateException he ) {
-            LOG.unableToCreateProxyFactory(getEntityName(), he);
-			pf = null;
-		}
-		return pf;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public Class getMappedClass() {
-		return Map.class;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public Class getConcreteProxyClass() {
-		return Map.class;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public boolean isInstrumented() {
-		return false;
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public EntityNameResolver[] getEntityNameResolvers() {
-		return new EntityNameResolver[] { BasicEntityNameResolver.INSTANCE };
-	}
-
-	/**
-	 * {@inheritDoc}
-	 */
-	public String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory) {
-		return extractEmbeddedEntityName( ( Map ) entityInstance );
-	}
-
-	public static String extractEmbeddedEntityName(Map entity) {
-		return ( String ) entity.get( DynamicMapInstantiator.KEY );
-	}
-
-	public static class BasicEntityNameResolver implements EntityNameResolver {
-		public static final BasicEntityNameResolver INSTANCE = new BasicEntityNameResolver();
-
-		/**
-		 * {@inheritDoc}
-		 */
-		public String resolveEntityName(Object entity) {
-			final String entityName = extractEmbeddedEntityName( ( Map ) entity );
-			if ( entityName == null ) {
-				throw new HibernateException( "Could not determine type of dynamic map entity" );
-			}
-			return entityName;
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		@Override
-        public boolean equals(Object obj) {
-			return getClass().equals( obj.getClass() );
-		}
-
-		/**
-		 * {@inheritDoc}
-		 */
-		@Override
-        public int hashCode() {
-			return getClass().hashCode();
-		}
-	}
-}
+import java.util.Map;
+import org.hibernate.EntityMode;
+import org.hibernate.EntityNameResolver;
+import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.engine.SessionFactoryImplementor;
+import org.hibernate.mapping.PersistentClass;
+import org.hibernate.mapping.Property;
+import org.hibernate.property.Getter;
+import org.hibernate.property.PropertyAccessor;
+import org.hibernate.property.PropertyAccessorFactory;
+import org.hibernate.property.Setter;
+import org.hibernate.proxy.ProxyFactory;
+import org.hibernate.proxy.map.MapProxyFactory;
+import org.hibernate.tuple.DynamicMapInstantiator;
+import org.hibernate.tuple.Instantiator;
+import org.jboss.logging.Logger;
+
+/**
+ * An {@link EntityTuplizer} specific to the dynamic-map entity mode.
+ *
+ * @author Steve Ebersole
+ * @author Gavin King
+ */
+public class DynamicMapEntityTuplizer extends AbstractEntityTuplizer {
+
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
+                                                                       DynamicMapEntityTuplizer.class.getName());
+
+	DynamicMapEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappedEntity) {
+		super(entityMetamodel, mappedEntity);
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public EntityMode getEntityMode() {
+		return EntityMode.MAP;
+	}
+
+	private PropertyAccessor buildPropertyAccessor(Property mappedProperty) {
+		if ( mappedProperty.isBackRef() ) {
+			return mappedProperty.getPropertyAccessor(null);
+		}
+		else {
+			return PropertyAccessorFactory.getDynamicMapPropertyAccessor();
+		}
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
+		return buildPropertyAccessor(mappedProperty).getGetter( null, mappedProperty.getName() );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
+		return buildPropertyAccessor(mappedProperty).getSetter( null, mappedProperty.getName() );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    protected Instantiator buildInstantiator(PersistentClass mappingInfo) {
+        return new DynamicMapInstantiator( mappingInfo );
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	@Override
+    protected ProxyFactory buildProxyFactory(PersistentClass mappingInfo, Getter idGetter, Setter idSetter) {
+
+		ProxyFactory pf = new MapProxyFactory();
+		try {
+			//TODO: design new lifecycle for ProxyFactory
+			pf.postInstantiate(
+					getEntityName(),
+					null,
+					null,
+					null,
+					null,
+					null
+			);
+		}
+		catch ( HibernateException he ) {
+            LOG.unableToCreateProxyFactory(getEntityName(), he);
+			pf = null;
+		}
+		return pf;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public Class getMappedClass() {
+		return Map.class;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public Class getConcreteProxyClass() {
+		return Map.class;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public boolean isInstrumented() {
+		return false;
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public EntityNameResolver[] getEntityNameResolvers() {
+		return new EntityNameResolver[] { BasicEntityNameResolver.INSTANCE };
+	}
+
+	/**
+	 * {@inheritDoc}
+	 */
+	public String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory) {
+		return extractEmbeddedEntityName( ( Map ) entityInstance );
+	}
+
+	public static String extractEmbeddedEntityName(Map entity) {
+		return ( String ) entity.get( DynamicMapInstantiator.KEY );
+	}
+
+	public static class BasicEntityNameResolver implements EntityNameResolver {
+		public static final BasicEntityNameResolver INSTANCE = new BasicEntityNameResolver();
+
+		/**
+		 * {@inheritDoc}
+		 */
+		public String resolveEntityName(Object entity) {
+			final String entityName = extractEmbeddedEntityName( ( Map ) entity );
+			if ( entityName == null ) {
+				throw new HibernateException( "Could not determine type of dynamic map entity" );
+			}
+			return entityName;
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		@Override
+        public boolean equals(Object obj) {
+			return getClass().equals( obj.getClass() );
+		}
+
+		/**
+		 * {@inheritDoc}
+		 */
+		@Override
+        public int hashCode() {
+			return getClass().hashCode();
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
index e95da92945..89924b061b 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
@@ -1,638 +1,638 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.engine.CascadeStyle;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.ValueInclusion;
 import org.hibernate.engine.Versioning;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.PropertyGeneration;
 import org.hibernate.tuple.IdentifierProperty;
 import org.hibernate.tuple.PropertyFactory;
 import org.hibernate.tuple.StandardProperty;
 import org.hibernate.tuple.VersionProperty;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Centralizes metamodel information about an entity.
  *
  * @author Steve Ebersole
  */
 public class EntityMetamodel implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, EntityMetamodel.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityMetamodel.class.getName());
 
 	private static final int NO_VERSION_INDX = -66;
 
 	private final SessionFactoryImplementor sessionFactory;
 
 	private final String name;
 	private final String rootName;
 	private final EntityType entityType;
 
 	private final IdentifierProperty identifierProperty;
 	private final boolean versioned;
 
 	private final int propertySpan;
 	private final int versionPropertyIndex;
 	private final StandardProperty[] properties;
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final String[] propertyNames;
 	private final Type[] propertyTypes;
 	private final boolean[] propertyLaziness;
 	private final boolean[] propertyUpdateability;
 	private final boolean[] nonlazyPropertyUpdateability;
 	private final boolean[] propertyCheckability;
 	private final boolean[] propertyInsertability;
 	private final ValueInclusion[] insertInclusions;
 	private final ValueInclusion[] updateInclusions;
 	private final boolean[] propertyNullability;
 	private final boolean[] propertyVersionability;
 	private final CascadeStyle[] cascadeStyles;
 	private final boolean hasInsertGeneratedValues;
 	private final boolean hasUpdateGeneratedValues;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final Map propertyIndexes = new HashMap();
 	private final boolean hasCollections;
 	private final boolean hasMutableProperties;
 	private final boolean hasLazyProperties;
 	private final boolean hasNonIdentifierPropertyNamedId;
 
 	private final int[] naturalIdPropertyNumbers;
 	private final boolean hasImmutableNaturalId;
 
 	private boolean lazy; //not final because proxy factory creation can fail
 	private final boolean hasCascades;
 	private final boolean mutable;
 	private final boolean isAbstract;
 	private final boolean selectBeforeUpdate;
 	private final boolean dynamicUpdate;
 	private final boolean dynamicInsert;
 	private final int optimisticLockMode;
 
 	private final boolean polymorphic;
 	private final String superclass;  // superclass entity-name
 	private final boolean explicitPolymorphism;
 	private final boolean inherited;
 	private final boolean hasSubclasses;
 	private final Set subclassEntityNames = new HashSet();
 	private final Map entityNameByInheritenceClassMap = new HashMap();
 
 	private final EntityEntityModeToTuplizerMapping tuplizerMapping;
 
 	public EntityMetamodel(PersistentClass persistentClass, SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 
 		name = persistentClass.getEntityName();
 		rootName = persistentClass.getRootClass().getEntityName();
 		entityType = sessionFactory.getTypeResolver().getTypeFactory().manyToOne( name );
 
 		identifierProperty = PropertyFactory.buildIdentifierProperty(
 		        persistentClass,
 		        sessionFactory.getIdentifierGenerator( rootName )
 			);
 
 		versioned = persistentClass.isVersioned();
 
 		boolean lazyAvailable = persistentClass.hasPojoRepresentation() &&
 		                        FieldInterceptionHelper.isInstrumented( persistentClass.getMappedClass() );
 		boolean hasLazy = false;
 
 		propertySpan = persistentClass.getPropertyClosureSpan();
 		properties = new StandardProperty[propertySpan];
 		List naturalIdNumbers = new ArrayList();
 		// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		propertyNames = new String[propertySpan];
 		propertyTypes = new Type[propertySpan];
 		propertyUpdateability = new boolean[propertySpan];
 		propertyInsertability = new boolean[propertySpan];
 		insertInclusions = new ValueInclusion[propertySpan];
 		updateInclusions = new ValueInclusion[propertySpan];
 		nonlazyPropertyUpdateability = new boolean[propertySpan];
 		propertyCheckability = new boolean[propertySpan];
 		propertyNullability = new boolean[propertySpan];
 		propertyVersionability = new boolean[propertySpan];
 		propertyLaziness = new boolean[propertySpan];
 		cascadeStyles = new CascadeStyle[propertySpan];
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 
 		Iterator iter = persistentClass.getPropertyClosureIterator();
 		int i = 0;
 		int tempVersionProperty = NO_VERSION_INDX;
 		boolean foundCascade = false;
 		boolean foundCollection = false;
 		boolean foundMutable = false;
 		boolean foundNonIdentifierPropertyNamedId = false;
 		boolean foundInsertGeneratedValue = false;
 		boolean foundUpdateGeneratedValue = false;
 		boolean foundUpdateableNaturalIdProperty = false;
 
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 
 			if ( prop == persistentClass.getVersion() ) {
 				tempVersionProperty = i;
 				properties[i] = PropertyFactory.buildVersionProperty( prop, lazyAvailable );
 			}
 			else {
 				properties[i] = PropertyFactory.buildStandardProperty( prop, lazyAvailable );
 			}
 
 			if ( prop.isNaturalIdentifier() ) {
 				naturalIdNumbers.add( new Integer(i) );
 				if ( prop.isUpdateable() ) {
 					foundUpdateableNaturalIdProperty = true;
 				}
 			}
 
 			if ( "id".equals( prop.getName() ) ) {
 				foundNonIdentifierPropertyNamedId = true;
 			}
 
 			// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			boolean lazy = prop.isLazy() && lazyAvailable;
 			if ( lazy ) hasLazy = true;
 			propertyLaziness[i] = lazy;
 
 			propertyNames[i] = properties[i].getName();
 			propertyTypes[i] = properties[i].getType();
 			propertyNullability[i] = properties[i].isNullable();
 			propertyUpdateability[i] = properties[i].isUpdateable();
 			propertyInsertability[i] = properties[i].isInsertable();
 			insertInclusions[i] = determineInsertValueGenerationType( prop, properties[i] );
 			updateInclusions[i] = determineUpdateValueGenerationType( prop, properties[i] );
 			propertyVersionability[i] = properties[i].isVersionable();
 			nonlazyPropertyUpdateability[i] = properties[i].isUpdateable() && !lazy;
 			propertyCheckability[i] = propertyUpdateability[i] ||
 					( propertyTypes[i].isAssociationType() && ( (AssociationType) propertyTypes[i] ).isAlwaysDirtyChecked() );
 
 			cascadeStyles[i] = properties[i].getCascadeStyle();
 			// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 			if ( properties[i].isLazy() ) {
 				hasLazy = true;
 			}
 
 			if ( properties[i].getCascadeStyle() != CascadeStyle.NONE ) {
 				foundCascade = true;
 			}
 
 			if ( indicatesCollection( properties[i].getType() ) ) {
 				foundCollection = true;
 			}
 
 			if ( propertyTypes[i].isMutable() && propertyCheckability[i] ) {
 				foundMutable = true;
 			}
 
 			if ( insertInclusions[i] != ValueInclusion.NONE ) {
 				foundInsertGeneratedValue = true;
 			}
 
 			if ( updateInclusions[i] != ValueInclusion.NONE ) {
 				foundUpdateGeneratedValue = true;
 			}
 
 			mapPropertyToIndex(prop, i);
 			i++;
 		}
 
 		if (naturalIdNumbers.size()==0) {
 			naturalIdPropertyNumbers = null;
 			hasImmutableNaturalId = false;
 		}
 		else {
 			naturalIdPropertyNumbers = ArrayHelper.toIntArray(naturalIdNumbers);
 			hasImmutableNaturalId = !foundUpdateableNaturalIdProperty;
 		}
 
 		hasInsertGeneratedValues = foundInsertGeneratedValue;
 		hasUpdateGeneratedValues = foundUpdateGeneratedValue;
 
 		hasCascades = foundCascade;
 		hasNonIdentifierPropertyNamedId = foundNonIdentifierPropertyNamedId;
 		versionPropertyIndex = tempVersionProperty;
 		hasLazyProperties = hasLazy;
         if (hasLazyProperties) LOG.lazyPropertyFetchingAvailable(name);
 
 		lazy = persistentClass.isLazy() && (
 				// TODO: this disables laziness even in non-pojo entity modes:
 				!persistentClass.hasPojoRepresentation() ||
 				!ReflectHelper.isFinalClass( persistentClass.getProxyInterface() )
 		);
 		mutable = persistentClass.isMutable();
 		if ( persistentClass.isAbstract() == null ) {
 			// legacy behavior (with no abstract attribute specified)
 			isAbstract = persistentClass.hasPojoRepresentation() &&
 			             ReflectHelper.isAbstractClass( persistentClass.getMappedClass() );
 		}
 		else {
 			isAbstract = persistentClass.isAbstract().booleanValue();
 			if ( !isAbstract && persistentClass.hasPojoRepresentation() &&
 			     ReflectHelper.isAbstractClass( persistentClass.getMappedClass() ) ) {
                 LOG.entityMappedAsNonAbstract(name);
 			}
 		}
 		selectBeforeUpdate = persistentClass.hasSelectBeforeUpdate();
 		dynamicUpdate = persistentClass.useDynamicUpdate();
 		dynamicInsert = persistentClass.useDynamicInsert();
 
 		polymorphic = persistentClass.isPolymorphic();
 		explicitPolymorphism = persistentClass.isExplicitPolymorphism();
 		inherited = persistentClass.isInherited();
 		superclass = inherited ?
 				persistentClass.getSuperclass().getEntityName() :
 				null;
 		hasSubclasses = persistentClass.hasSubclasses();
 
 		optimisticLockMode = persistentClass.getOptimisticLockMode();
 		if ( optimisticLockMode > Versioning.OPTIMISTIC_LOCK_VERSION && !dynamicUpdate ) {
 			throw new MappingException( "optimistic-lock=all|dirty requires dynamic-update=\"true\": " + name );
 		}
 		if ( versionPropertyIndex != NO_VERSION_INDX && optimisticLockMode > Versioning.OPTIMISTIC_LOCK_VERSION ) {
 			throw new MappingException( "version and optimistic-lock=all|dirty are not a valid combination : " + name );
 		}
 
 		hasCollections = foundCollection;
 		hasMutableProperties = foundMutable;
 
 		iter = persistentClass.getSubclassIterator();
 		while ( iter.hasNext() ) {
 			subclassEntityNames.add( ( (PersistentClass) iter.next() ).getEntityName() );
 		}
 		subclassEntityNames.add( name );
 
 		if ( persistentClass.hasPojoRepresentation() ) {
 			entityNameByInheritenceClassMap.put( persistentClass.getMappedClass(), persistentClass.getEntityName() );
 			iter = persistentClass.getSubclassIterator();
 			while ( iter.hasNext() ) {
 				final PersistentClass pc = ( PersistentClass ) iter.next();
 				entityNameByInheritenceClassMap.put( pc.getMappedClass(), pc.getEntityName() );
 			}
 		}
 
 		tuplizerMapping = new EntityEntityModeToTuplizerMapping( persistentClass, this );
 	}
 
 	private ValueInclusion determineInsertValueGenerationType(Property mappingProperty, StandardProperty runtimeProperty) {
 		if ( runtimeProperty.isInsertGenerated() ) {
 			return ValueInclusion.FULL;
 		}
 		else if ( mappingProperty.getValue() instanceof Component ) {
 			if ( hasPartialInsertComponentGeneration( ( Component ) mappingProperty.getValue() ) ) {
 				return ValueInclusion.PARTIAL;
 			}
 		}
 		return ValueInclusion.NONE;
 	}
 
 	private boolean hasPartialInsertComponentGeneration(Component component) {
 		Iterator subProperties = component.getPropertyIterator();
 		while ( subProperties.hasNext() ) {
 			Property prop = ( Property ) subProperties.next();
 			if ( prop.getGeneration() == PropertyGeneration.ALWAYS || prop.getGeneration() == PropertyGeneration.INSERT ) {
 				return true;
 			}
 			else if ( prop.getValue() instanceof Component ) {
 				if ( hasPartialInsertComponentGeneration( ( Component ) prop.getValue() ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	private ValueInclusion determineUpdateValueGenerationType(Property mappingProperty, StandardProperty runtimeProperty) {
 		if ( runtimeProperty.isUpdateGenerated() ) {
 			return ValueInclusion.FULL;
 		}
 		else if ( mappingProperty.getValue() instanceof Component ) {
 			if ( hasPartialUpdateComponentGeneration( ( Component ) mappingProperty.getValue() ) ) {
 				return ValueInclusion.PARTIAL;
 			}
 		}
 		return ValueInclusion.NONE;
 	}
 
 	private boolean hasPartialUpdateComponentGeneration(Component component) {
 		Iterator subProperties = component.getPropertyIterator();
 		while ( subProperties.hasNext() ) {
 			Property prop = ( Property ) subProperties.next();
 			if ( prop.getGeneration() == PropertyGeneration.ALWAYS ) {
 				return true;
 			}
 			else if ( prop.getValue() instanceof Component ) {
 				if ( hasPartialUpdateComponentGeneration( ( Component ) prop.getValue() ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	private void mapPropertyToIndex(Property prop, int i) {
 		propertyIndexes.put( prop.getName(), new Integer(i) );
 		if ( prop.getValue() instanceof Component ) {
 			Iterator iter = ( (Component) prop.getValue() ).getPropertyIterator();
 			while ( iter.hasNext() ) {
 				Property subprop = (Property) iter.next();
 				propertyIndexes.put(
 						prop.getName() + '.' + subprop.getName(),
 						new Integer(i)
 					);
 			}
 		}
 	}
 
 	public EntityEntityModeToTuplizerMapping getTuplizerMapping() {
 		return tuplizerMapping;
 	}
 
 	public EntityTuplizer getTuplizer(EntityMode entityMode) {
 		return (EntityTuplizer) tuplizerMapping.getTuplizer( entityMode );
 	}
 
 	public EntityTuplizer getTuplizerOrNull(EntityMode entityMode) {
 		return ( EntityTuplizer ) tuplizerMapping.getTuplizerOrNull( entityMode );
 	}
 
 	public EntityMode guessEntityMode(Object object) {
 		return tuplizerMapping.guessEntityMode( object );
 	}
 
 	public int[] getNaturalIdentifierProperties() {
 		return naturalIdPropertyNumbers;
 	}
 
 	public boolean hasNaturalIdentifier() {
 		return naturalIdPropertyNumbers!=null;
 	}
 
 	public boolean hasImmutableNaturalId() {
 		return hasImmutableNaturalId;
 	}
 
 	public Set getSubclassEntityNames() {
 		return subclassEntityNames;
 	}
 
 	private boolean indicatesCollection(Type type) {
 		if ( type.isCollectionType() ) {
 			return true;
 		}
 		else if ( type.isComponentType() ) {
 			Type[] subtypes = ( (CompositeType) type ).getSubtypes();
 			for ( int i = 0; i < subtypes.length; i++ ) {
 				if ( indicatesCollection( subtypes[i] ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	public SessionFactoryImplementor getSessionFactory() {
 		return sessionFactory;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public String getRootName() {
 		return rootName;
 	}
 
 	public EntityType getEntityType() {
 		return entityType;
 	}
 
 	public IdentifierProperty getIdentifierProperty() {
 		return identifierProperty;
 	}
 
 	public int getPropertySpan() {
 		return propertySpan;
 	}
 
 	public int getVersionPropertyIndex() {
 		return versionPropertyIndex;
 	}
 
 	public VersionProperty getVersionProperty() {
 		if ( NO_VERSION_INDX == versionPropertyIndex ) {
 			return null;
 		}
 		else {
 			return ( VersionProperty ) properties[ versionPropertyIndex ];
 		}
 	}
 
 	public StandardProperty[] getProperties() {
 		return properties;
 	}
 
 	public int getPropertyIndex(String propertyName) {
 		Integer index = getPropertyIndexOrNull(propertyName);
 		if ( index == null ) {
 			throw new HibernateException("Unable to resolve property: " + propertyName);
 		}
 		return index.intValue();
 	}
 
 	public Integer getPropertyIndexOrNull(String propertyName) {
 		return (Integer) propertyIndexes.get( propertyName );
 	}
 
 	public boolean hasCollections() {
 		return hasCollections;
 	}
 
 	public boolean hasMutableProperties() {
 		return hasMutableProperties;
 	}
 
 	public boolean hasNonIdentifierPropertyNamedId() {
 		return hasNonIdentifierPropertyNamedId;
 	}
 
 	public boolean hasLazyProperties() {
 		return hasLazyProperties;
 	}
 
 	public boolean hasCascades() {
 		return hasCascades;
 	}
 
 	public boolean isMutable() {
 		return mutable;
 	}
 
 	public boolean isSelectBeforeUpdate() {
 		return selectBeforeUpdate;
 	}
 
 	public boolean isDynamicUpdate() {
 		return dynamicUpdate;
 	}
 
 	public boolean isDynamicInsert() {
 		return dynamicInsert;
 	}
 
 	public int getOptimisticLockMode() {
 		return optimisticLockMode;
 	}
 
 	public boolean isPolymorphic() {
 		return polymorphic;
 	}
 
 	public String getSuperclass() {
 		return superclass;
 	}
 
 	public boolean isExplicitPolymorphism() {
 		return explicitPolymorphism;
 	}
 
 	public boolean isInherited() {
 		return inherited;
 	}
 
 	public boolean hasSubclasses() {
 		return hasSubclasses;
 	}
 
 	public boolean isLazy() {
 		return lazy;
 	}
 
 	public void setLazy(boolean lazy) {
 		this.lazy = lazy;
 	}
 
 	public boolean isVersioned() {
 		return versioned;
 	}
 
 	public boolean isAbstract() {
 		return isAbstract;
 	}
 
 	/**
 	 * Return the entity-name mapped to the given class within our inheritance hierarchy, if any.
 	 *
 	 * @param inheritenceClass The class for which to resolve the entity-name.
 	 * @return The mapped entity-name, or null if no such mapping was found.
 	 */
 	public String findEntityNameByEntityClass(Class inheritenceClass) {
 		return ( String ) entityNameByInheritenceClassMap.get( inheritenceClass );
 	}
 
 	@Override
     public String toString() {
 		return "EntityMetamodel(" + name + ':' + ArrayHelper.toString(properties) + ')';
 	}
 
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public String[] getPropertyNames() {
 		return propertyNames;
 	}
 
 	public Type[] getPropertyTypes() {
 		return propertyTypes;
 	}
 
 	public boolean[] getPropertyLaziness() {
 		return propertyLaziness;
 	}
 
 	public boolean[] getPropertyUpdateability() {
 		return propertyUpdateability;
 	}
 
 	public boolean[] getPropertyCheckability() {
 		return propertyCheckability;
 	}
 
 	public boolean[] getNonlazyPropertyUpdateability() {
 		return nonlazyPropertyUpdateability;
 	}
 
 	public boolean[] getPropertyInsertability() {
 		return propertyInsertability;
 	}
 
 	public ValueInclusion[] getPropertyInsertGenerationInclusions() {
 		return insertInclusions;
 	}
 
 	public ValueInclusion[] getPropertyUpdateGenerationInclusions() {
 		return updateInclusions;
 	}
 
 	public boolean[] getPropertyNullability() {
 		return propertyNullability;
 	}
 
 	public boolean[] getPropertyVersionability() {
 		return propertyVersionability;
 	}
 
 	public CascadeStyle[] getCascadeStyles() {
 		return cascadeStyles;
 	}
 
 	public boolean hasInsertGeneratedValues() {
 		return hasInsertGeneratedValues;
 	}
 
 	public boolean hasUpdateGeneratedValues() {
 		return hasUpdateGeneratedValues;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/PojoEntityTuplizer.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/PojoEntityTuplizer.java
index 3b45990f5e..99ed2f222f 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/PojoEntityTuplizer.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/PojoEntityTuplizer.java
@@ -1,370 +1,370 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import java.lang.reflect.Method;
 import java.lang.reflect.Modifier;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.bytecode.spi.ReflectionOptimizer;
 import org.hibernate.cfg.Environment;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.property.Getter;
 import org.hibernate.property.Setter;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.ProxyFactory;
 import org.hibernate.tuple.Instantiator;
 import org.hibernate.tuple.PojoInstantiator;
 import org.hibernate.type.CompositeType;
 
 /**
  * An {@link EntityTuplizer} specific to the pojo entity mode.
  *
  * @author Steve Ebersole
  * @author Gavin King
  */
 public class PojoEntityTuplizer extends AbstractEntityTuplizer {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, PojoEntityTuplizer.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, PojoEntityTuplizer.class.getName());
 
 	private final Class mappedClass;
 	private final Class proxyInterface;
 	private final boolean lifecycleImplementor;
 	private final Set lazyPropertyNames = new HashSet();
 	private final ReflectionOptimizer optimizer;
 
 	public PojoEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappedEntity) {
 		super( entityMetamodel, mappedEntity );
 		this.mappedClass = mappedEntity.getMappedClass();
 		this.proxyInterface = mappedEntity.getProxyInterface();
 		this.lifecycleImplementor = Lifecycle.class.isAssignableFrom( mappedClass );
 
 		Iterator iter = mappedEntity.getPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property property = (Property) iter.next();
 			if ( property.isLazy() ) {
 				lazyPropertyNames.add( property.getName() );
 			}
 		}
 
 		String[] getterNames = new String[propertySpan];
 		String[] setterNames = new String[propertySpan];
 		Class[] propTypes = new Class[propertySpan];
 		for ( int i = 0; i < propertySpan; i++ ) {
 			getterNames[i] = getters[i].getMethodName();
 			setterNames[i] = setters[i].getMethodName();
 			propTypes[i] = getters[i].getReturnType();
 		}
 
 		if ( hasCustomAccessors || !Environment.useReflectionOptimizer() ) {
 			optimizer = null;
 		}
 		else {
 			// todo : YUCK!!!
 			optimizer = Environment.getBytecodeProvider().getReflectionOptimizer( mappedClass, getterNames, setterNames, propTypes );
 //			optimizer = getFactory().getSettings().getBytecodeProvider().getReflectionOptimizer(
 //					mappedClass, getterNames, setterNames, propTypes
 //			);
 		}
 
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected ProxyFactory buildProxyFactory(PersistentClass persistentClass, Getter idGetter, Setter idSetter) {
 		// determine the id getter and setter methods from the proxy interface (if any)
         // determine all interfaces needed by the resulting proxy
 		HashSet<Class> proxyInterfaces = new HashSet<Class>();
 		proxyInterfaces.add( HibernateProxy.class );
 
 		Class mappedClass = persistentClass.getMappedClass();
 		Class proxyInterface = persistentClass.getProxyInterface();
 
 		if ( proxyInterface!=null && !mappedClass.equals( proxyInterface ) ) {
 			if ( !proxyInterface.isInterface() ) {
 				throw new MappingException(
 						"proxy must be either an interface, or the class itself: " + getEntityName()
 				);
 			}
 			proxyInterfaces.add( proxyInterface );
 		}
 
 		if ( mappedClass.isInterface() ) {
 			proxyInterfaces.add( mappedClass );
 		}
 
 		Iterator subclasses = persistentClass.getSubclassIterator();
 		while ( subclasses.hasNext() ) {
 			final Subclass subclass = ( Subclass ) subclasses.next();
 			final Class subclassProxy = subclass.getProxyInterface();
 			final Class subclassClass = subclass.getMappedClass();
 			if ( subclassProxy!=null && !subclassClass.equals( subclassProxy ) ) {
 				if ( !subclassProxy.isInterface() ) {
 					throw new MappingException(
 							"proxy must be either an interface, or the class itself: " + subclass.getEntityName()
 					);
 				}
 				proxyInterfaces.add( subclassProxy );
 			}
 		}
 
 		Iterator properties = persistentClass.getPropertyIterator();
 		Class clazz = persistentClass.getMappedClass();
 		while ( properties.hasNext() ) {
 			Property property = (Property) properties.next();
 			Method method = property.getGetter(clazz).getMethod();
 			if ( method != null && Modifier.isFinal( method.getModifiers() ) ) {
                 LOG.gettersOfLazyClassesCannotBeFinal(persistentClass.getEntityName(), property.getName());
 			}
 			method = property.getSetter(clazz).getMethod();
             if ( method != null && Modifier.isFinal( method.getModifiers() ) ) {
                 LOG.settersOfLazyClassesCannotBeFinal(persistentClass.getEntityName(), property.getName());
 			}
 		}
 
 		Method idGetterMethod = idGetter==null ? null : idGetter.getMethod();
 		Method idSetterMethod = idSetter==null ? null : idSetter.getMethod();
 
 		Method proxyGetIdentifierMethod = idGetterMethod==null || proxyInterface==null ?
 				null :
 		        ReflectHelper.getMethod(proxyInterface, idGetterMethod);
 		Method proxySetIdentifierMethod = idSetterMethod==null || proxyInterface==null  ?
 				null :
 		        ReflectHelper.getMethod(proxyInterface, idSetterMethod);
 
 		ProxyFactory pf = buildProxyFactoryInternal( persistentClass, idGetter, idSetter );
 		try {
 			pf.postInstantiate(
 					getEntityName(),
 					mappedClass,
 					proxyInterfaces,
 					proxyGetIdentifierMethod,
 					proxySetIdentifierMethod,
 					persistentClass.hasEmbeddedIdentifier() ?
 			                (CompositeType) persistentClass.getIdentifier().getType() :
 			                null
 			);
 		}
 		catch ( HibernateException he ) {
             LOG.unableToCreateProxyFactory(getEntityName(), he);
 			pf = null;
 		}
 		return pf;
 	}
 
 	protected ProxyFactory buildProxyFactoryInternal(PersistentClass persistentClass, Getter idGetter, Setter idSetter) {
 		// TODO : YUCK!!!  fix after HHH-1907 is complete
 		return Environment.getBytecodeProvider().getProxyFactoryFactory().buildProxyFactory();
 //		return getFactory().getSettings().getBytecodeProvider().getProxyFactoryFactory().buildProxyFactory();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected Instantiator buildInstantiator(PersistentClass persistentClass) {
 		if ( optimizer == null ) {
 			return new PojoInstantiator( persistentClass, null );
 		}
 		else {
 			return new PojoInstantiator( persistentClass, optimizer.getInstantiationOptimizer() );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public void setPropertyValues(Object entity, Object[] values) throws HibernateException {
 		if ( !getEntityMetamodel().hasLazyProperties() && optimizer != null && optimizer.getAccessOptimizer() != null ) {
 			setPropertyValuesWithOptimizer( entity, values );
 		}
 		else {
 			super.setPropertyValues( entity, values );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public Object[] getPropertyValues(Object entity) throws HibernateException {
 		if ( shouldGetAllProperties( entity ) && optimizer != null && optimizer.getAccessOptimizer() != null ) {
 			return getPropertyValuesWithOptimizer( entity );
 		}
 		else {
 			return super.getPropertyValues( entity );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session) throws HibernateException {
 		if ( shouldGetAllProperties( entity ) && optimizer != null && optimizer.getAccessOptimizer() != null ) {
 			return getPropertyValuesWithOptimizer( entity );
 		}
 		else {
 			return super.getPropertyValuesToInsert( entity, mergeMap, session );
 		}
 	}
 
 	protected void setPropertyValuesWithOptimizer(Object object, Object[] values) {
 		optimizer.getAccessOptimizer().setPropertyValues( object, values );
 	}
 
 	protected Object[] getPropertyValuesWithOptimizer(Object object) {
 		return optimizer.getAccessOptimizer().getPropertyValues( object );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public EntityMode getEntityMode() {
 		return EntityMode.POJO;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Class getMappedClass() {
 		return mappedClass;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public boolean isLifecycleImplementor() {
 		return lifecycleImplementor;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
 		return mappedProperty.getGetter( mappedEntity.getMappedClass() );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
 		return mappedProperty.getSetter( mappedEntity.getMappedClass() );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Class getConcreteProxyClass() {
 		return proxyInterface;
 	}
 
     //TODO: need to make the majority of this functionality into a top-level support class for custom impl support
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
 		if ( isInstrumented() ) {
 			Set lazyProps = lazyPropertiesAreUnfetched && getEntityMetamodel().hasLazyProperties() ?
 					lazyPropertyNames : null;
 			//TODO: if we support multiple fetch groups, we would need
 			//      to clone the set of lazy properties!
 			FieldInterceptionHelper.injectFieldInterceptor( entity, getEntityName(), lazyProps, session );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public boolean hasUninitializedLazyProperties(Object entity) {
 		if ( getEntityMetamodel().hasLazyProperties() ) {
 			FieldInterceptor callback = FieldInterceptionHelper.extractFieldInterceptor( entity );
 			return callback != null && !callback.isInitialized();
 		}
 		else {
 			return false;
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public boolean isInstrumented() {
 		return FieldInterceptionHelper.isInstrumented( getMappedClass() );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory) {
 		final Class concreteEntityClass = entityInstance.getClass();
 		if ( concreteEntityClass == getMappedClass() ) {
 			return getEntityName();
 		}
 		else {
 			String entityName = getEntityMetamodel().findEntityNameByEntityClass( concreteEntityClass );
 			if ( entityName == null ) {
 				throw new HibernateException(
 						"Unable to resolve entity name from Class [" + concreteEntityClass.getName() + "]"
 								+ " expected instance/subclass of [" + getEntityName() + "]"
 				);
 			}
 			return entityName;
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public EntityNameResolver[] getEntityNameResolvers() {
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java b/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
index a83063e1ef..e42ff91ae3 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
@@ -1,159 +1,159 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 import java.io.Serializable;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
 import org.jboss.logging.Logger;
 
 /**
  * A registry of {@link BasicType} instances
  *
  * @author Steve Ebersole
  */
 public class BasicTypeRegistry implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BasicTypeRegistry.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BasicTypeRegistry.class.getName());
 
 	// TODO : analyze these sizing params; unfortunately this seems to be the only way to give a "concurrencyLevel"
 	private Map<String,BasicType> registry = new ConcurrentHashMap<String, BasicType>( 100, .75f, 1 );
 	private boolean locked = false;
 
 	public BasicTypeRegistry() {
 		register( BooleanType.INSTANCE );
 		register( NumericBooleanType.INSTANCE );
 		register( TrueFalseType.INSTANCE );
 		register( YesNoType.INSTANCE );
 
 		register( ByteType.INSTANCE );
 		register( CharacterType.INSTANCE );
 		register( ShortType.INSTANCE );
 		register( IntegerType.INSTANCE );
 		register( LongType.INSTANCE );
 		register( FloatType.INSTANCE );
 		register( DoubleType.INSTANCE );
 		register( BigDecimalType.INSTANCE );
 		register( BigIntegerType.INSTANCE );
 
 		register( StringType.INSTANCE );
 		register( UrlType.INSTANCE );
 
 		register( DateType.INSTANCE );
 		register( TimeType.INSTANCE );
 		register( TimestampType.INSTANCE );
 		register( DbTimestampType.INSTANCE );
 		register( CalendarType.INSTANCE );
 		register( CalendarDateType.INSTANCE );
 
 		register( LocaleType.INSTANCE );
 		register( CurrencyType.INSTANCE );
 		register( TimeZoneType.INSTANCE );
 		register( ClassType.INSTANCE );
 		register( UUIDBinaryType.INSTANCE );
 		register( UUIDCharType.INSTANCE );
 		register( PostgresUUIDType.INSTANCE );
 
 		register( BinaryType.INSTANCE );
 		register( WrapperBinaryType.INSTANCE );
 		register( ImageType.INSTANCE );
 		register( CharArrayType.INSTANCE );
 		register( CharacterArrayType.INSTANCE );
 		register( TextType.INSTANCE );
 		register( BlobType.INSTANCE );
 		register( MaterializedBlobType.INSTANCE );
 		register( ClobType.INSTANCE );
 		register( MaterializedClobType.INSTANCE );
 		register( SerializableType.INSTANCE );
 
 		register( ObjectType.INSTANCE );
 
 		//noinspection unchecked
 		register( new AdaptedImmutableType( DateType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( TimeType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( TimestampType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( DbTimestampType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( CalendarType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( CalendarDateType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( BinaryType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( SerializableType.INSTANCE ) );
 	}
 
 	/**
 	 * Constructor version used during shallow copy
 	 *
 	 * @param registeredTypes The type map to copy over
 	 */
 	@SuppressWarnings({ "UnusedDeclaration" })
 	private BasicTypeRegistry(Map<String, BasicType> registeredTypes) {
 		registry.putAll( registeredTypes );
 		locked = true;
 	}
 
 	public void register(BasicType type) {
 		if ( locked ) {
 			throw new HibernateException( "Can not alter TypeRegistry at this time" );
 		}
 
 		if ( type == null ) {
 			throw new HibernateException( "Type to register cannot be null" );
 		}
 
         if (type.getRegistrationKeys() == null || type.getRegistrationKeys().length == 0) LOG.typeDefinedNoRegistrationKeys(type);
 
 		for ( String key : type.getRegistrationKeys() ) {
 			// be safe...
             if (key == null) continue;
             LOG.debugf("Adding type registration %s -> %s", key, type);
 			final Type old = registry.put( key, type );
             if (old != null && old != type) LOG.typeRegistrationOverridesPrevious(key, old);
 		}
 	}
 
 	public void register(UserType type, String[] keys) {
 		register( new CustomType( type, keys ) );
 	}
 
 	public void register(CompositeUserType type, String[] keys) {
 		register( new CompositeCustomType( type, keys ) );
 	}
 
 	public BasicType getRegisteredType(String key) {
 		return registry.get( key );
 	}
 
 	public BasicTypeRegistry shallowCopy() {
 		return new BasicTypeRegistry( this.registry );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java b/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
index 8b7b6313e5..93c7d8e2e9 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
@@ -1,143 +1,145 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Timestamp;
 import java.util.Date;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionImplementor;
+
 import org.jboss.logging.Logger;
 
 /**
  * <tt>dbtimestamp</tt>: An extension of {@link TimestampType} which
  * maps to the database's current timestamp, rather than the jvm's
  * current timestamp.
  * <p/>
  * Note: May/may-not cause issues on dialects which do not properly support
  * a true notion of timestamp (Oracle < 8, for example, where only its DATE
  * datatype is supported).  Depends on the frequency of DML operations...
  *
  * @author Steve Ebersole
  */
 public class DbTimestampType extends TimestampType {
 	public static final DbTimestampType INSTANCE = new DbTimestampType();
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, DbTimestampType.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DbTimestampType.class.getName());
 
 	@Override
     public String getName() {
 		return "dbtimestamp";
 	}
 
 	@Override
 	public String[] getRegistrationKeys() {
 		return new String[] { getName() };
 	}
 
 	@Override
     public Date seed(SessionImplementor session) {
 		if ( session == null ) {
             LOG.trace("Incoming session was null; using current jvm time");
 			return super.seed( session );
         } else if (!session.getFactory().getDialect().supportsCurrentTimestampSelection()) {
             LOG.debugf("Falling back to vm-based timestamp, as dialect does not support current timestamp selection");
 			return super.seed( session );
         } else return getCurrentTimestamp(session);
 	}
 
 	private Date getCurrentTimestamp(SessionImplementor session) {
 		Dialect dialect = session.getFactory().getDialect();
 		String timestampSelectString = dialect.getCurrentTimestampSelectString();
         if (dialect.isCurrentTimestampSelectStringCallable()) return useCallableStatement(timestampSelectString, session);
         return usePreparedStatement(timestampSelectString, session);
 	}
 
 	private Timestamp usePreparedStatement(String timestampSelectString, SessionImplementor session) {
 		PreparedStatement ps = null;
 		try {
 			ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( timestampSelectString, false );
 			ResultSet rs = ps.executeQuery();
 			rs.next();
 			Timestamp ts = rs.getTimestamp( 1 );
             LOG.trace("Current timestamp retreived from db : " + ts + " (nanos=" + ts.getNanos() + ", time=" + ts.getTime() + ")");
 			return ts;
 		}
 		catch( SQLException e ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 			        e,
 			        "could not select current db timestamp",
 			        timestampSelectString
 			);
 		}
 		finally {
 			if ( ps != null ) {
 				try {
 					ps.close();
 				}
 				catch( SQLException sqle ) {
                     LOG.unableToCleanUpPreparedStatement(sqle);
 				}
 			}
 		}
 	}
 
 	private Timestamp useCallableStatement(String callString, SessionImplementor session) {
 		CallableStatement cs = null;
 		try {
 			cs = (CallableStatement) session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( callString, true );
 			cs.registerOutParameter( 1, java.sql.Types.TIMESTAMP );
 			cs.execute();
 			Timestamp ts = cs.getTimestamp( 1 );
             LOG.trace("Current timestamp retreived from db : " + ts + " (nanos=" + ts.getNanos() + ", time=" + ts.getTime() + ")");
 			return ts;
 		}
 		catch( SQLException e ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 			        e,
 			        "could not call current db timestamp function",
 			        callString
 			);
 		}
 		finally {
 			if ( cs != null ) {
 				try {
 					cs.close();
 				}
 				catch( SQLException sqle ) {
                     LOG.unableToCleanUpCallableStatement(sqle);
 				}
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/EnumType.java b/hibernate-core/src/main/java/org/hibernate/type/EnumType.java
index 5121aa1d93..5409e8a4cc 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/EnumType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/EnumType.java
@@ -1,235 +1,235 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Properties;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.usertype.EnhancedUserType;
 import org.hibernate.usertype.ParameterizedType;
 import org.jboss.logging.Logger;
 
 /**
  * Enum type mapper
  * Try and find the appropriate SQL type depending on column metadata
  * <p/>
  * TODO implements readobject/writeobject to recalculate the enumclasses
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class EnumType implements EnhancedUserType, ParameterizedType, Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, EnumType.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EnumType.class.getName());
 
 	public static final String ENUM = "enumClass";
 	public static final String SCHEMA = "schema";
 	public static final String CATALOG = "catalog";
 	public static final String TABLE = "table";
 	public static final String COLUMN = "column";
 	public static final String TYPE = "type";
 
 	private Class<? extends Enum> enumClass;
 	private transient Object[] enumValues;
 	private int sqlType = Types.INTEGER; //before any guessing
 
 	public int[] sqlTypes() {
 		return new int[] { sqlType };
 	}
 
 	public Class<? extends Enum> returnedClass() {
 		return enumClass;
 	}
 
 	public boolean equals(Object x, Object y) throws HibernateException {
 		return x == y;
 	}
 
 	public int hashCode(Object x) throws HibernateException {
 		return x == null ? 0 : x.hashCode();
 	}
 
 
 	public Object nullSafeGet(ResultSet rs, String[] names, SessionImplementor session, Object owner) throws HibernateException, SQLException {
 		Object object = rs.getObject( names[0] );
 		if ( rs.wasNull() ) {
             if (LOG.isTraceEnabled()) LOG.trace("Returning null as column " + names[0]);
 			return null;
 		}
 		if ( object instanceof Number ) {
 			initEnumValues();
 			int ordinal = ( ( Number ) object ).intValue();
             if (ordinal < 0 || ordinal >= enumValues.length) throw new IllegalArgumentException("Unknown ordinal value for enum "
                                                                                                 + enumClass + ": " + ordinal);
             if (LOG.isTraceEnabled()) LOG.trace("Returning '" + ordinal + "' as column " + names[0]);
 			return enumValues[ordinal];
 		}
 		else {
 			String name = ( String ) object;
             if (LOG.isTraceEnabled()) LOG.trace("Returning '" + name + "' as column " + names[0]);
 			try {
 				return Enum.valueOf( enumClass, name );
 			}
 			catch ( IllegalArgumentException iae ) {
 				throw new IllegalArgumentException( "Unknown name value for enum " + enumClass + ": " + name, iae );
 			}
 		}
 	}
 
 	public void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session) throws HibernateException, SQLException {
 		if ( value == null ) {
             if (LOG.isTraceEnabled()) LOG.trace("Binding null to parameter: " + index);
 			st.setNull( index, sqlType );
 		}
 		else {
 			boolean isOrdinal = isOrdinal( sqlType );
 			if ( isOrdinal ) {
 				int ordinal = ( ( Enum<?> ) value ).ordinal();
                 if (LOG.isTraceEnabled()) LOG.trace("Binding '" + ordinal + "' to parameter: " + index);
 				st.setObject( index, Integer.valueOf( ordinal ), sqlType );
 			}
 			else {
 				String enumString = ( ( Enum<?> ) value ).name();
                 if (LOG.isTraceEnabled()) LOG.trace("Binding '" + enumString + "' to parameter: " + index);
 				st.setObject( index, enumString, sqlType );
 			}
 		}
 	}
 
 	private boolean isOrdinal(int paramType) {
 		switch ( paramType ) {
 			case Types.INTEGER:
 			case Types.NUMERIC:
 			case Types.SMALLINT:
 			case Types.TINYINT:
 			case Types.BIGINT:
 			case Types.DECIMAL: //for Oracle Driver
 			case Types.DOUBLE:  //for Oracle Driver
 			case Types.FLOAT:   //for Oracle Driver
 				return true;
 			case Types.CHAR:
 			case Types.LONGVARCHAR:
 			case Types.VARCHAR:
 				return false;
 			default:
 				throw new HibernateException( "Unable to persist an Enum in a column of SQL Type: " + paramType );
 		}
 	}
 
 	public Object deepCopy(Object value) throws HibernateException {
 		return value;
 	}
 
 	public boolean isMutable() {
 		return false;
 	}
 
 	public Serializable disassemble(Object value) throws HibernateException {
 		return ( Serializable ) value;
 	}
 
 	public Object assemble(Serializable cached, Object owner) throws HibernateException {
 		return cached;
 	}
 
 	public Object replace(Object original, Object target, Object owner) throws HibernateException {
 		return original;
 	}
 
 	public void setParameterValues(Properties parameters) {
 		String enumClassName = parameters.getProperty( ENUM );
 		try {
 			enumClass = ReflectHelper.classForName( enumClassName, this.getClass() ).asSubclass( Enum.class );
 		}
 		catch ( ClassNotFoundException exception ) {
 			throw new HibernateException( "Enum class not found", exception );
 		}
 
 		String type = parameters.getProperty( TYPE );
 		if ( type != null ) {
 			sqlType = Integer.decode( type );
 		}
 	}
 
 	/**
 	 * Lazy init of {@link #enumValues}.
 	 */
 	private void initEnumValues() {
 		if ( enumValues == null ) {
 			this.enumValues = enumClass.getEnumConstants();
 			if ( enumValues == null ) {
 				throw new NullPointerException( "Failed to init enumValues" );
 			}
 		}
 	}
 
 	public String objectToSQLString(Object value) {
 		boolean isOrdinal = isOrdinal( sqlType );
 		if ( isOrdinal ) {
 			int ordinal = ( ( Enum ) value ).ordinal();
 			return Integer.toString( ordinal );
 		}
 		else {
 			return '\'' + ( ( Enum ) value ).name() + '\'';
 		}
 	}
 
 	public String toXMLString(Object value) {
 		boolean isOrdinal = isOrdinal( sqlType );
 		if ( isOrdinal ) {
 			int ordinal = ( ( Enum ) value ).ordinal();
 			return Integer.toString( ordinal );
 		}
 		else {
 			return ( ( Enum ) value ).name();
 		}
 	}
 
 	public Object fromXMLString(String xmlValue) {
 		try {
 			int ordinal = Integer.parseInt( xmlValue );
 			initEnumValues();
 			if ( ordinal < 0 || ordinal >= enumValues.length ) {
 				throw new IllegalArgumentException( "Unknown ordinal value for enum " + enumClass + ": " + ordinal );
 			}
 			return enumValues[ordinal];
 		}
 		catch ( NumberFormatException e ) {
 			try {
 				return Enum.valueOf( enumClass, xmlValue );
 			}
 			catch ( IllegalArgumentException iae ) {
 				throw new IllegalArgumentException( "Unknown name value for enum " + enumClass + ": " + xmlValue, iae );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/NullableType.java b/hibernate-core/src/main/java/org/hibernate/type/NullableType.java
index bc4ae70e21..76149d8591 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/NullableType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/NullableType.java
@@ -1,268 +1,268 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.dom4j.Node;
 import org.jboss.logging.Logger;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.compare.EqualsHelper;
 import org.hibernate.metamodel.relational.Size;
 
 /**
  * Superclass of single-column nullable types.
  *
  * @author Gavin King
  *
  * @deprecated Use the {@link AbstractStandardBasicType} approach instead
  */
 @Deprecated
 public abstract class NullableType extends AbstractType implements StringRepresentableType, XmlRepresentableType {
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, NullableType.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, NullableType.class.getName());
 
 	private final Size dictatedSize = new Size();
 
 	/**
 	 * A convenience form of {@link #sqlTypes(org.hibernate.engine.Mapping)}, returning
 	 * just a single type value since these are explicitly dealing with single column
 	 * mappings.
 	 *
 	 * @return The {@link java.sql.Types} mapping value.
 	 */
 	public abstract int sqlType();
 
 	/**
 	 * A convenience form of {@link #dictatedSizes}, returning just a single size since we are explicitly dealing with
 	 * single column mappings here.
 	 *
 	 * @return The {@link java.sql.Types} mapping value.
 	 */
 	public Size dictatedSize() {
 		return dictatedSize;
 	}
 
 	/**
 	 * A convenience form of {@link #defaultSizes}, returning just a single size since we are explicitly dealing with
 	 * single column mappings here.
 	 *
 	 * @return The {@link java.sql.Types} mapping value.
 	 */
 	public Size defaultSize() {
 		return LEGACY_DEFAULT_SIZE;
 	}
 
 	/**
 	 * Get a column value from a result set, without worrying about the
 	 * possibility of null values.  Called from {@link #nullSafeGet} after
 	 * nullness checks have been performed.
 	 *
 	 * @param rs The result set from which to extract the value.
 	 * @param name The name of the value to extract.
 	 *
 	 * @return The extracted value.
 	 *
 	 * @throws org.hibernate.HibernateException Generally some form of mismatch error.
 	 * @throws java.sql.SQLException Indicates problem making the JDBC call(s).
 	 */
 	public abstract Object get(ResultSet rs, String name) throws HibernateException, SQLException;
 
 	/**
 	 * Set a parameter value without worrying about the possibility of null
 	 * values.  Called from {@link #nullSafeSet} after nullness checks have
 	 * been performed.
 	 *
 	 * @param st The statement into which to bind the parameter value.
 	 * @param value The parameter value to bind.
 	 * @param index The position or index at which to bind the param value.
 	 *
 	 * @throws org.hibernate.HibernateException Generally some form of mismatch error.
 	 * @throws java.sql.SQLException Indicates problem making the JDBC call(s).
 	 */
 	public abstract void set(PreparedStatement st, Object value, int index) throws HibernateException, SQLException;
 
 	/**
 	 * A null-safe version of {@link #toString(Object)}.  Specifically we are
 	 * worried about null safeness in regards to the incoming value parameter,
 	 * not the return.
 	 *
 	 * @param value The value to convert to a string representation; may be null.
 	 * @return The string representation; may be null.
 	 * @throws HibernateException Thrown by {@link #toString(Object)}, which this calls.
 	 */
 	public String nullSafeToString(Object value) throws HibernateException {
 		return value == null ? null : toString( value );
 	}
 
 	public abstract String toString(Object value) throws HibernateException;
 
 	public abstract Object fromStringValue(String xml) throws HibernateException;
 
 	public final void nullSafeSet(
 			PreparedStatement st,
 			Object value,
 			int index,
 			boolean[] settable,
 			SessionImplementor session)
 	throws HibernateException, SQLException {
 		if ( settable[0] ) nullSafeSet(st, value, index);
 	}
 
 	public final void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session)
 	throws HibernateException, SQLException {
 		nullSafeSet(st, value, index);
 	}
 
 	public final void nullSafeSet(PreparedStatement st, Object value, int index)
 	throws HibernateException, SQLException {
 		try {
 			if ( value == null ) {
                 if (LOG.isTraceEnabled()) LOG.trace("Binding null to parameter: " + index);
 
 				st.setNull( index, sqlType() );
 			}
 			else {
                 if (LOG.isTraceEnabled()) LOG.trace("Binding '" + toString(value) + "' to parameter: " + index);
 
 				set( st, value, index );
 			}
 		}
 		catch ( RuntimeException re ) {
             LOG.unableToBindValueToParameter(nullSafeToString(value), index, re.getMessage());
 			throw re;
 		}
 		catch ( SQLException se ) {
             LOG.unableToBindValueToParameter(nullSafeToString(value), index, se.getMessage());
 			throw se;
 		}
 	}
 
 	public final Object nullSafeGet(
 			ResultSet rs,
 			String[] names,
 			SessionImplementor session,
 			Object owner)
 	throws HibernateException, SQLException {
 		return nullSafeGet(rs, names[0]);
 	}
 
 	public final Object nullSafeGet(ResultSet rs, String[] names)
 	throws HibernateException, SQLException {
 		return nullSafeGet(rs, names[0]);
 	}
 
 	public final Object nullSafeGet(ResultSet rs, String name)
 	throws HibernateException, SQLException {
 		try {
 			Object value = get(rs, name);
 			if ( value == null || rs.wasNull() ) {
                 if (LOG.isTraceEnabled()) LOG.trace("Returning null as column " + name);
 				return null;
 			}
             if (LOG.isTraceEnabled()) LOG.trace("Returning '" + toString(value) + "' as column " + name);
             return value;
 		}
 		catch ( RuntimeException re ) {
             LOG.unableToReadColumnValueFromResultSet(name, re.getMessage());
 			throw re;
 		}
 		catch ( SQLException se ) {
             LOG.unableToReadColumnValueFromResultSet(name, se.getMessage());
 			throw se;
 		}
 	}
 
 	public final Object nullSafeGet(ResultSet rs, String name, SessionImplementor session, Object owner)
 	throws HibernateException, SQLException {
 		return nullSafeGet(rs, name);
 	}
 
 	public final String toXMLString(Object value, SessionFactoryImplementor pc)
 	throws HibernateException {
 		return toString(value);
 	}
 
 	public final Object fromXMLString(String xml, Mapping factory) throws HibernateException {
 		return xml==null || xml.length()==0 ? null : fromStringValue(xml);
 	}
 
 	public final int getColumnSpan(Mapping session) {
 		return 1;
 	}
 
 	public final int[] sqlTypes(Mapping session) {
 		return new int[] { sqlType() };
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		return new Size[] { dictatedSize() };
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		return new Size[] { defaultSize() };
 	}
 
 	@Override
     public final boolean isEqual(Object x, Object y, EntityMode entityMode) {
 		return isEqual(x, y);
 	}
 
 	public boolean isEqual(Object x, Object y) {
 		return EqualsHelper.equals(x, y);
 	}
 
 	public String toLoggableString(Object value, SessionFactoryImplementor factory) {
 		return value == null ? "null" : toString(value);
 	}
 
 	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
 		return fromXMLString( xml.getText(), factory );
 	}
 
 	public void setToXMLNode(Node xml, Object value, SessionFactoryImplementor factory)
 	throws HibernateException {
 		xml.setText( toXMLString(value, factory) );
 	}
 
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
 		return value==null ? ArrayHelper.FALSE : ArrayHelper.TRUE;
 	}
 
 	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session)
 	throws HibernateException {
 		return checkable[0] && isDirty(old, current, session);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java b/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
index 04e6d17d2d..1b2577ad35 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
@@ -1,324 +1,324 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.Comparator;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.tuple.component.ComponentMetamodel;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.ParameterizedType;
 import org.hibernate.usertype.UserType;
 
 /**
  * Used internally to build instances of {@link Type}, specifically it builds instances of
  *
  *
  * Used internally to obtain instances of <tt>Type</tt>. Applications should use static methods
  * and constants on <tt>org.hibernate.Hibernate</tt>.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 @SuppressWarnings({ "unchecked" })
 public final class TypeFactory implements Serializable {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, TypeFactory.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TypeFactory.class.getName());
 
 	private final TypeScopeImpl typeScope = new TypeScopeImpl();
 
 	public static interface TypeScope extends Serializable {
 		public SessionFactoryImplementor resolveFactory();
 	}
 
 	private static class TypeScopeImpl implements TypeFactory.TypeScope {
 		private SessionFactoryImplementor factory;
 
 		public void injectSessionFactory(SessionFactoryImplementor factory) {
             if (this.factory != null) LOG.scopingTypesToSessionFactoryAfterAlreadyScoped(this.factory, factory);
             else LOG.trace("Scoping types to session factory " + factory);
 			this.factory = factory;
 		}
 
 		public SessionFactoryImplementor resolveFactory() {
 			if ( factory == null ) {
 				throw new HibernateException( "SessionFactory for type scoping not yet known" );
 			}
 			return factory;
 		}
 	}
 
 	public void injectSessionFactory(SessionFactoryImplementor factory) {
 		typeScope.injectSessionFactory( factory );
 	}
 
 	public SessionFactoryImplementor resolveSessionFactory() {
 		return typeScope.resolveFactory();
 	}
 
 	public Type byClass(Class clazz, Properties parameters) {
 		if ( Type.class.isAssignableFrom( clazz ) ) {
 			return type( clazz, parameters );
 		}
 
 		if ( CompositeUserType.class.isAssignableFrom( clazz ) ) {
 			return customComponent( clazz, parameters );
 		}
 
 		if ( UserType.class.isAssignableFrom( clazz ) ) {
 			return custom( clazz, parameters );
 		}
 
 		if ( Lifecycle.class.isAssignableFrom( clazz ) ) {
 			// not really a many-to-one association *necessarily*
 			return manyToOne( clazz.getName() );
 		}
 
 		if ( Serializable.class.isAssignableFrom( clazz ) ) {
 			return serializable( clazz );
 		}
 
 		return null;
 	}
 
 	public Type type(Class<Type> typeClass, Properties parameters) {
 		try {
 			Type type = typeClass.newInstance();
 			injectParameters( type, parameters );
 			return type;
 		}
 		catch (Exception e) {
 			throw new MappingException( "Could not instantiate Type: " + typeClass.getName(), e );
 		}
 	}
 
 	public static void injectParameters(Object type, Properties parameters) {
 		if ( ParameterizedType.class.isInstance( type ) ) {
 			( (ParameterizedType) type ).setParameterValues(parameters);
 		}
 		else if ( parameters!=null && !parameters.isEmpty() ) {
 			throw new MappingException( "type is not parameterized: " + type.getClass().getName() );
 		}
 	}
 
 	public CompositeCustomType customComponent(Class<CompositeUserType> typeClass, Properties parameters) {
 		return customComponent( typeClass, parameters, typeScope );
 	}
 
 	/**
 	 * @deprecated Only for use temporary use by {@link org.hibernate.Hibernate}
 	 */
 	@Deprecated
     @SuppressWarnings({ "JavaDoc" })
 	public static CompositeCustomType customComponent(Class<CompositeUserType> typeClass, Properties parameters, TypeScope scope) {
 		try {
 			CompositeUserType userType = typeClass.newInstance();
 			injectParameters( userType, parameters );
 			return new CompositeCustomType( userType );
 		}
 		catch ( Exception e ) {
 			throw new MappingException( "Unable to instantiate custom type: " + typeClass.getName(), e );
 		}
 	}
 
 	public CollectionType customCollection(
 			String typeName,
 			Properties typeParameters,
 			String role,
 			String propertyRef,
 			boolean embedded) {
 		Class typeClass;
 		try {
 			typeClass = ReflectHelper.classForName( typeName );
 		}
 		catch ( ClassNotFoundException cnfe ) {
 			throw new MappingException( "user collection type class not found: " + typeName, cnfe );
 		}
 		CustomCollectionType result = new CustomCollectionType( typeScope, typeClass, role, propertyRef, embedded );
 		if ( typeParameters != null ) {
 			injectParameters( result.getUserType(), typeParameters );
 		}
 		return result;
 	}
 
 	public CustomType custom(Class<UserType> typeClass, Properties parameters) {
 		return custom( typeClass, parameters, typeScope );
 	}
 
 	/**
 	 * @deprecated Only for use temporary use by {@link org.hibernate.Hibernate}
 	 */
 	@Deprecated
     public static CustomType custom(Class<UserType> typeClass, Properties parameters, TypeScope scope) {
 		try {
 			UserType userType = typeClass.newInstance();
 			injectParameters( userType, parameters );
 			return new CustomType( userType );
 		}
 		catch ( Exception e ) {
 			throw new MappingException( "Unable to instantiate custom type: " + typeClass.getName(), e );
 		}
 	}
 
 	/**
 	 * Build a {@link SerializableType} from the given {@link Serializable} class.
 	 *
 	 * @param serializableClass The {@link Serializable} class.
 	 * @param <T> The actual class type (extends Serializable)
 	 *
 	 * @return The built {@link SerializableType}
 	 */
 	public static <T extends Serializable> SerializableType<T> serializable(Class<T> serializableClass) {
 		return new SerializableType<T>( serializableClass );
 	}
 
 
 	// one-to-one type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public EntityType oneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean isEmbeddedInXML,
 			String entityName,
 			String propertyName) {
 		return new OneToOneType( typeScope, persistentClass, foreignKeyType, uniqueKeyPropertyName,
 				lazy, unwrapProxy, isEmbeddedInXML, entityName, propertyName );
 	}
 
 	public EntityType specialOneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
 		return new SpecialOneToOneType( typeScope, persistentClass, foreignKeyType, uniqueKeyPropertyName,
 				lazy, unwrapProxy, entityName, propertyName );
 	}
 
 
 	// many-to-one type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public EntityType manyToOne(String persistentClass) {
 		return new ManyToOneType( typeScope, persistentClass );
 	}
 
 	public EntityType manyToOne(String persistentClass, boolean lazy) {
 		return new ManyToOneType( typeScope, persistentClass, lazy );
 	}
 
 	public EntityType manyToOne(
 			String persistentClass,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean isEmbeddedInXML,
 			boolean ignoreNotFound,
 			boolean isLogicalOneToOne) {
 		return new ManyToOneType(
 				typeScope,
 				persistentClass,
 				uniqueKeyPropertyName,
 				lazy,
 				unwrapProxy,
 				isEmbeddedInXML,
 				ignoreNotFound,
 				isLogicalOneToOne
 		);
 	}
 
 
 	// collection type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public CollectionType array(String role, String propertyRef, boolean embedded, Class elementClass) {
 		return new ArrayType( typeScope, role, propertyRef, elementClass, embedded );
 	}
 
 	public CollectionType list(String role, String propertyRef, boolean embedded) {
 		return new ListType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType bag(String role, String propertyRef, boolean embedded) {
 		return new BagType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType idbag(String role, String propertyRef, boolean embedded) {
 		return new IdentifierBagType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType map(String role, String propertyRef, boolean embedded) {
 		return new MapType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType orderedMap(String role, String propertyRef, boolean embedded) {
 		return new OrderedMapType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType sortedMap(String role, String propertyRef, boolean embedded, Comparator comparator) {
 		return new SortedMapType( typeScope, role, propertyRef, comparator, embedded );
 	}
 
 	public CollectionType set(String role, String propertyRef, boolean embedded) {
 		return new SetType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType orderedSet(String role, String propertyRef, boolean embedded) {
 		return new OrderedSetType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType sortedSet(String role, String propertyRef, boolean embedded, Comparator comparator) {
 		return new SortedSetType( typeScope, role, propertyRef, comparator, embedded );
 	}
 
 
 	// component type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public ComponentType component(ComponentMetamodel metamodel) {
 		return new ComponentType( typeScope, metamodel );
 	}
 
 	public EmbeddedComponentType embeddedComponent(ComponentMetamodel metamodel) {
 		return new EmbeddedComponentType( typeScope, metamodel );
 	}
 
 
 	// any type builder ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Type any(Type metaType, Type identifierType) {
 		return new AnyType( metaType, identifierType );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
index d602f15573..4ece673f1d 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
@@ -1,77 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor;
 import java.lang.reflect.Field;
 import java.sql.Types;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
 public class JdbcTypeNameMapper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, JdbcTypeNameMapper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JdbcTypeNameMapper.class.getName());
 	private static Map<Integer,String> JDBC_TYPE_MAP = buildJdbcTypeMap();
 
 	private static Map<Integer, String> buildJdbcTypeMap() {
 		HashMap<Integer, String> map = new HashMap<Integer, String>();
 		Field[] fields = Types.class.getFields();
 		if ( fields == null ) {
 			throw new HibernateException( "Unexpected problem extracting JDBC type mapping codes from java.sql.Types" );
 		}
 		for ( Field field : fields ) {
 			try {
 				final int code = field.getInt( null );
 				String old = map.put(
 						Integer.valueOf( code ),
 						field.getName()
 				);
                 if (old != null) LOG.JavaSqlTypesMappedSameCodeMultipleTimes(code, old, field.getName());
 			}
 			catch ( IllegalAccessException e ) {
 				throw new HibernateException( "Unable to access JDBC type mapping [" + field.getName() + "]", e );
 			}
 		}
 		return Collections.unmodifiableMap( map );
 	}
 
 	public static String getTypeName(int code) {
 		return getTypeName( Integer.valueOf( code ) );
 	}
 
 	public static String getTypeName(Integer code) {
 		String name = JDBC_TYPE_MAP.get( code );
 		if ( name == null ) {
 			return "UNKNOWN(" + code + ")";
 		}
 		return name;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/DataHelper.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/DataHelper.java
index 6e21c0de98..8b2b805387 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/DataHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/DataHelper.java
@@ -1,252 +1,252 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.java;
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.Reader;
 import java.io.StringReader;
 import org.hibernate.HibernateException;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.descriptor.BinaryStream;
 import org.jboss.logging.Logger;
 
 /**
  * A help for dealing with BLOB and CLOB data
  *
  * @author Steve Ebersole
  */
 public class DataHelper {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, DataHelper.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DataHelper.class.getName());
 
 	private static Class nClobClass;
 	static {
 		try {
 			// NClobs are only JDBC 4 (JDK 1.6) and higher
 			nClobClass = ReflectHelper.classForName( "java.sql.NClob", DataHelper.class );
 		}
 		catch ( ClassNotFoundException e ) {
             LOG.unableToLocateNClobClass();
 		}
 	}
 
 	public static boolean isNClob(Class type) {
 		return nClobClass != null && nClobClass.isAssignableFrom( type );
 	}
 
 	/**
 	 * Extract the contents of the given reader/stream as a string.
 	 *
 	 * @param reader The reader for the content
 	 *
 	 * @return The content as string
 	 */
 	public static String extractString(Reader reader) {
 		// read the Reader contents into a buffer and return the complete string
 		final StringBuilder stringBuilder = new StringBuilder();
 		try {
 			char[] buffer = new char[2048];
 			while (true) {
 				int amountRead = reader.read( buffer, 0, buffer.length );
 				if ( amountRead == -1 ) {
 					break;
 				}
 				stringBuilder.append( buffer, 0, amountRead );
 			}
 		}
 		catch ( IOException ioe) {
 			throw new HibernateException( "IOException occurred reading text", ioe );
 		}
 		finally {
 			try {
 				reader.close();
 			}
 			catch (IOException e) {
                 LOG.unableToCloseStream(e);
 			}
 		}
 		return stringBuilder.toString();
 	}
 
 	/**
 	 * Extracts a portion of the contents of the given reader/stream as a string.
 	 *
 	 * @param characterStream The reader for the content
 	 * @param start The start position/offset (0-based, per general stream/reader contracts).
 	 * @param length The amount to extract
 	 *
 	 * @return The content as string
 	 */
 	private static String extractString(Reader characterStream, long start, int length) {
 		StringBuilder stringBuilder = new StringBuilder( length );
 		try {
 			long skipped = characterStream.skip( start );
 			if ( skipped != start ) {
 				throw new HibernateException( "Unable to skip needed bytes" );
 			}
 			char[] buffer = new char[2048];
 			int charsRead = 0;
 			while ( true ) {
 				int amountRead = characterStream.read( buffer, 0, buffer.length );
 				if ( amountRead == -1 ) {
 					break;
 				}
 				stringBuilder.append( buffer, 0, amountRead );
 				if ( amountRead < buffer.length ) {
 					// we have read up to the end of stream
 					break;
 				}
 				charsRead += amountRead;
 				if ( charsRead >= length ) {
 					break;
 				}
 			}
 		}
 		catch ( IOException ioe ) {
 			throw new HibernateException( "IOException occurred reading a binary value", ioe );
 		}
 		return stringBuilder.toString();
 	}
 
 	/**
 	 * Extract a portion of a reader, wrapping the portion in a new reader.
 	 *
 	 * @param characterStream The reader for the content
 	 * @param start The start position/offset (0-based, per general stream/reader contracts).
 	 * @param length The amount to extract
 	 *
 	 * @return The content portion as a reader
 	 */
 	public static Object subStream(Reader characterStream, long start, int length) {
 		return new StringReader( extractString( characterStream, start, length ) );
 	}
 
 	/**
 	 * Extract by bytes from the given stream.
 	 *
 	 * @param inputStream The stream of bytes.
 	 *
 	 * @return The contents as a {@code byte[]}
 	 */
 	public static byte[] extractBytes(InputStream inputStream) {
 		if ( BinaryStream.class.isInstance( inputStream ) ) {
 			return ( (BinaryStream ) inputStream ).getBytes();
 		}
 
 		// read the stream contents into a buffer and return the complete byte[]
 		ByteArrayOutputStream outputStream = new ByteArrayOutputStream(2048);
 		try {
 			byte[] buffer = new byte[2048];
 			while (true) {
 				int amountRead = inputStream.read( buffer );
 				if ( amountRead == -1 ) {
 					break;
 				}
 				outputStream.write( buffer, 0, amountRead );
 			}
 		}
 		catch ( IOException ioe ) {
 			throw new HibernateException( "IOException occurred reading a binary value", ioe );
 		}
 		finally {
 			try {
 				inputStream.close();
 			}
 			catch ( IOException e ) {
                 LOG.unableToCloseInputStream(e);
 			}
 			try {
 				outputStream.close();
 			}
 			catch ( IOException e ) {
                 LOG.unableToCloseOutputStream(e);
 			}
 		}
 		return outputStream.toByteArray();
 	}
 
 	/**
 	 * Extract a portion of the bytes from the given stream.
 	 *
 	 * @param inputStream The stream of bytes.
 	 * @param start The start position/offset (0-based, per general stream/reader contracts).
 	 * @param length The amount to extract
 	 *
 	 * @return The extracted bytes
 	 */
 	public static byte[] extractBytes(InputStream inputStream, long start, int length) {
 		if ( BinaryStream.class.isInstance( inputStream ) && Integer.MAX_VALUE > start ) {
 			byte[] data = ( (BinaryStream ) inputStream ).getBytes();
 			int size = Math.min( length, data.length );
 			byte[] result = new byte[size];
 			System.arraycopy( data, (int) start, result, 0, size );
 			return result;
 		}
 
 		ByteArrayOutputStream outputStream = new ByteArrayOutputStream( length );
 		try {
 			long skipped = inputStream.skip( start );
 			if ( skipped != start ) {
 				throw new HibernateException( "Unable to skip needed bytes" );
 			}
 			byte[] buffer = new byte[2048];
 			int bytesRead = 0;
 			while ( true ) {
 				int amountRead = inputStream.read( buffer );
 				if ( amountRead == -1 ) {
 					break;
 				}
 				outputStream.write( buffer, 0, amountRead );
 				if ( amountRead < buffer.length ) {
 					// we have read up to the end of stream
 					break;
 				}
 				bytesRead += amountRead;
 				if ( bytesRead >= length ) {
 					break;
 				}
 			}
 		}
 		catch ( IOException ioe ) {
 			throw new HibernateException( "IOException occurred reading a binary value", ioe );
 		}
 		return outputStream.toByteArray();
 	}
 
 	/**
 	 * Extract a portion of the bytes from the given stream., wrapping them in a new stream.
 	 *
 	 * @param inputStream The stream of bytes.
 	 * @param start The start position/offset (0-based, per general stream/reader contracts).
 	 * @param length The amount to extract
 	 *
 	 * @return The extracted bytes as a stream
 	 */
 	public static InputStream subStream(InputStream inputStream, long start, int length) {
 		return new BinaryStreamImpl( extractBytes( inputStream, start, length ) );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicBinder.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicBinder.java
index 3768d150bd..7fe3ac61e0 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicBinder.java
@@ -1,90 +1,91 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.sql;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.descriptor.JdbcTypeNameMapper;
 import org.hibernate.type.descriptor.ValueBinder;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 import org.jboss.logging.Logger;
 
 /**
  * Convenience base implementation of {@link ValueBinder}
  *
  * @author Steve Ebersole
  */
 public abstract class BasicBinder<J> implements ValueBinder<J> {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BasicBinder.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BasicBinder.class.getName());
 
     private static final String BIND_MSG_TEMPLATE = "binding parameter [%s] as [%s] - %s";
     private static final String NULL_BIND_MSG_TEMPLATE = "binding parameter [%s] as [%s] - <null>";
 
 	private final JavaTypeDescriptor<J> javaDescriptor;
 	private final SqlTypeDescriptor sqlDescriptor;
 
 	public JavaTypeDescriptor<J> getJavaDescriptor() {
 		return javaDescriptor;
 	}
 
 	public SqlTypeDescriptor getSqlDescriptor() {
 		return sqlDescriptor;
 	}
 
 	public BasicBinder(JavaTypeDescriptor<J> javaDescriptor, SqlTypeDescriptor sqlDescriptor) {
 		this.javaDescriptor = javaDescriptor;
 		this.sqlDescriptor = sqlDescriptor;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final void bind(PreparedStatement st, J value, int index, WrapperOptions options) throws SQLException {
 		if ( value == null ) {
             LOG.trace(String.format(NULL_BIND_MSG_TEMPLATE, index, JdbcTypeNameMapper.getTypeName(sqlDescriptor.getSqlType())));
 			st.setNull( index, sqlDescriptor.getSqlType() );
 		}
 		else {
             LOG.trace(String.format(BIND_MSG_TEMPLATE,
                                     index,
                                     JdbcTypeNameMapper.getTypeName(sqlDescriptor.getSqlType()),
                                     getJavaDescriptor().extractLoggableRepresentation(value)));
 			doBind( st, value, index, options );
 		}
 	}
 
 	/**
 	 * Perform the binding.  Safe to assume that value is not null.
 	 *
 	 * @param st The prepared statement
 	 * @param value The value to bind (not null).
 	 * @param index The index at which to bind
 	 * @param options The binding options
 	 *
 	 * @throws SQLException Indicates a problem binding to the prepared statement.
 	 */
 	protected abstract void doBind(PreparedStatement st, J value, int index, WrapperOptions options) throws SQLException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicExtractor.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicExtractor.java
index cf304c725c..909d326c93 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicExtractor.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicExtractor.java
@@ -1,88 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.sql;
 import java.sql.ResultSet;
 import java.sql.SQLException;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.descriptor.ValueExtractor;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 import org.jboss.logging.Logger;
 
 /**
  * Convenience base implementation of {@link org.hibernate.type.descriptor.ValueExtractor}
  *
  * @author Steve Ebersole
  */
 public abstract class BasicExtractor<J> implements ValueExtractor<J> {
 
-    private static final HibernateLogger LOG = Logger.getMessageLogger(HibernateLogger.class, BasicExtractor.class.getName());
+    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BasicExtractor.class.getName());
 
 	private final JavaTypeDescriptor<J> javaDescriptor;
 	private final SqlTypeDescriptor sqlDescriptor;
 
 	public BasicExtractor(JavaTypeDescriptor<J> javaDescriptor, SqlTypeDescriptor sqlDescriptor) {
 		this.javaDescriptor = javaDescriptor;
 		this.sqlDescriptor = sqlDescriptor;
 	}
 
 	public JavaTypeDescriptor<J> getJavaDescriptor() {
 		return javaDescriptor;
 	}
 
 	public SqlTypeDescriptor getSqlDescriptor() {
 		return sqlDescriptor;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public J extract(ResultSet rs, String name, WrapperOptions options) throws SQLException {
 		final J value = doExtract( rs, name, options );
 		if ( value == null || rs.wasNull() ) {
             LOG.trace("Found [null] as column [" + name + "]");
 			return null;
 		}
 		else {
             LOG.trace("Found [" + getJavaDescriptor().extractLoggableRepresentation(value) + "] as column [" + name + "]");
 			return value;
 		}
 	}
 
 	/**
 	 * Perform the extraction.
 	 * <p/>
 	 * Called from {@link #extract}.  Null checking of the value (as well as consulting {@link ResultSet#wasNull}) is
 	 * done there.
 	 *
 	 * @param rs The result set
 	 * @param name The value name in the result set
 	 * @param options The binding options
 	 *
 	 * @return The extracted value.
 	 *
 	 * @throws SQLException Indicates a problem access the result set
 	 */
 	protected abstract J doExtract(ResultSet rs, String name, WrapperOptions options) throws SQLException;
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/backquotes/BackquoteTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/backquotes/BackquoteTest.java
index 58b7587514..636f251228 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/backquotes/BackquoteTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/backquotes/BackquoteTest.java
@@ -1,75 +1,91 @@
 //$Id$
 package org.hibernate.test.annotations.backquotes;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import java.io.PrintWriter;
 import java.io.StringWriter;
-import junit.framework.TestCase;
+
+import org.jboss.logging.Logger;
+
 import org.hibernate.MappingException;
-import org.hibernate.cfg.AnnotationConfiguration;
+import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.service.ServiceRegistry;
+
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
 import org.hibernate.testing.ServiceRegistryBuilder;
+import org.hibernate.testing.TestForIssue;
+import org.hibernate.testing.junit4.BaseUnitTestCase;
+
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
 
 /**
  * Testcase for ANN-718 - @JoinTable / @JoinColumn fail when using backquotes in PK field name.
  *
  * @author Hardy Ferentschik
  *
  */
-public class BackquoteTest extends TestCase {
+public class BackquoteTest extends BaseUnitTestCase {
+	private static final Logger log = Logger.getLogger( BackquoteTest.class );
 
 	private ServiceRegistry serviceRegistry;
 
-	@Override
+	@Before
     protected void setUp() {
 		serviceRegistry = ServiceRegistryBuilder.buildServiceRegistry( Environment.getProperties() );
 	}
 
-	@Override
+	@After
     protected void tearDown() {
         if (serviceRegistry != null) ServiceRegistryBuilder.destroy(serviceRegistry);
 	}
 
+	@Test
+	@TestForIssue( jiraKey = "ANN-718" )
 	public void testBackquotes() {
 		try {
-			AnnotationConfiguration config = new AnnotationConfiguration();
+			Configuration config = new Configuration();
 			config.addAnnotatedClass(Bug.class);
 			config.addAnnotatedClass(Category.class);
 			config.buildSessionFactory( serviceRegistry );
 		}
 		catch( Exception e ) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 
 	/**
 	 *  HHH-4647 : Problems with @JoinColumn referencedColumnName and quoted column and table names
 	 *
 	 *  An invalid referencedColumnName to an entity having a quoted table name results in an
 	 *  infinite loop in o.h.c.Configuration$MappingsImpl#getPhysicalColumnName().
 	 *  The same issue exists with getLogicalColumnName()
 	 */
+	@Test
+	@TestForIssue( jiraKey = "HHH-4647" )
 	public void testInvalidReferenceToQuotedTableName() {
     	try {
-    		AnnotationConfiguration config = new AnnotationConfiguration();
+    		Configuration config = new Configuration();
     		config.addAnnotatedClass(Printer.class);
     		config.addAnnotatedClass(PrinterCable.class);
     		config.buildSessionFactory( serviceRegistry );
     		fail("expected MappingException to be thrown");
     	}
     	//we WANT MappingException to be thrown
         catch( MappingException e ) {
         	assertTrue("MappingException was thrown", true);
         }
         catch(Exception e) {
         	StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
         	fail(e.getMessage());
         }
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/fetchprofile/FetchProfileTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/fetchprofile/FetchProfileTest.java
index 1b62f1604a..9a7b8fb558 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/fetchprofile/FetchProfileTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/fetchprofile/FetchProfileTest.java
@@ -1,176 +1,185 @@
-// $Id$
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2010, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-
 package org.hibernate.test.annotations.fetchprofile;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import java.io.InputStream;
-import junit.framework.TestCase;
+
+import org.jboss.logging.Logger;
+
 import org.hibernate.MappingException;
-import org.hibernate.cfg.AnnotationConfiguration;
+import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.service.ServiceRegistry;
 
+import org.junit.After;
+import org.junit.Before;
+
 import org.hibernate.testing.ServiceRegistryBuilder;
+import org.hibernate.testing.TestForIssue;
+import org.hibernate.testing.junit4.BaseUnitTestCase;
+
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
 
 /**
  * Test case for HHH-4812
  *
  * @author Hardy Ferentschik
  */
-public class FetchProfileTest extends TestCase {
+@TestForIssue( jiraKey = "HHH-4812" )
+public class FetchProfileTest extends BaseUnitTestCase {
+	private static final Logger log = Logger.getLogger( FetchProfileTest.class );
 
 	private ServiceRegistry serviceRegistry;
 
-	@Override
+	@Before
     protected void setUp() {
 		serviceRegistry = ServiceRegistryBuilder.buildServiceRegistry( Environment.getProperties() );
 	}
 
-	@Override
+	@After
     protected void tearDown() {
         if (serviceRegistry != null) ServiceRegistryBuilder.destroy(serviceRegistry);
 	}
 
 	public void testFetchProfileConfigured() {
-		AnnotationConfiguration config = new AnnotationConfiguration();
+		Configuration config = new Configuration();
 		config.addAnnotatedClass( Customer.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( SupportTickets.class );
 		config.addAnnotatedClass( Country.class );
 		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory(
 				serviceRegistry
 		);
 
 		assertTrue(
 				"fetch profile not parsed properly",
 				sessionImpl.containsFetchProfileDefinition( "customer-with-orders" )
 		);
 		assertFalse(
 				"package info should not be parsed",
 				sessionImpl.containsFetchProfileDefinition( "package-profile-1" )
 		);
 	}
 
 	public void testWrongAssociationName() {
-		AnnotationConfiguration config = new AnnotationConfiguration();
+		Configuration config = new Configuration();
 		config.addAnnotatedClass( Customer2.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 
 		try {
 			config.buildSessionFactory( serviceRegistry );
 			fail();
 		}
 		catch ( MappingException e ) {
-            LOG.trace("success");
+            log.trace("success");
 		}
 	}
 
 	public void testWrongClass() {
-		AnnotationConfiguration config = new AnnotationConfiguration();
+		Configuration config = new Configuration();
 		config.addAnnotatedClass( Customer3.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 
 		try {
 			config.buildSessionFactory( serviceRegistry );
 			fail();
 		}
 		catch ( MappingException e ) {
-            LOG.trace("success");
+            log.trace("success");
 		}
 	}
 
 	public void testUnsupportedFetchMode() {
-		AnnotationConfiguration config = new AnnotationConfiguration();
+		Configuration config = new Configuration();
 		config.addAnnotatedClass( Customer4.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 
 		try {
 			config.buildSessionFactory( serviceRegistry );
 			fail();
 		}
 		catch ( MappingException e ) {
-            LOG.trace("success");
+            log.trace("success");
 		}
 	}
 
 	public void testXmlOverride() {
-		AnnotationConfiguration config = new AnnotationConfiguration();
+		Configuration config = new Configuration();
 		config.addAnnotatedClass( Customer5.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 		InputStream is = Thread.currentThread()
 				.getContextClassLoader()
 				.getResourceAsStream( "org/hibernate/test/annotations/fetchprofile/mappings.hbm.xml" );
 		config.addInputStream( is );
 		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory(
 				serviceRegistry
 		);
 
 		assertTrue(
 				"fetch profile not parsed properly",
 				sessionImpl.containsFetchProfileDefinition( "orders-profile" )
 		);
 
 		// now the same with no xml
-		config = new AnnotationConfiguration();
+		config = new Configuration();
 		config.addAnnotatedClass( Customer5.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 		try {
 			config.buildSessionFactory( serviceRegistry );
 			fail();
 		}
 		catch ( MappingException e ) {
-            LOG.trace("success");
+            log.trace("success");
 		}
 	}
 
 	public void testPackageConfiguredFetchProfile() {
-		AnnotationConfiguration config = new AnnotationConfiguration();
+		Configuration config = new Configuration();
 		config.addAnnotatedClass( Customer.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( SupportTickets.class );
 		config.addAnnotatedClass( Country.class );
 		config.addPackage( Customer.class.getPackage().getName() );
 		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory(
 				serviceRegistry
 		);
 
 		assertTrue(
 				"fetch profile not parsed properly",
 				sessionImpl.containsFetchProfileDefinition( "package-profile-1" )
 		);
 		assertTrue(
 				"fetch profile not parsed properly",
 				sessionImpl.containsFetchProfileDefinition( "package-profile-2" )
 		);
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/fkcircularity/FkCircularityTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/fkcircularity/FkCircularityTest.java
index a9a3307c03..9f2f46af06 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/fkcircularity/FkCircularityTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/fkcircularity/FkCircularityTest.java
@@ -1,78 +1,82 @@
 // $Id$
 package org.hibernate.test.annotations.fkcircularity;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import java.io.PrintWriter;
 import java.io.StringWriter;
+
+import org.jboss.logging.Logger;
+
 import junit.framework.TestCase;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.SQLServerDialect;
 import org.hibernate.service.ServiceRegistry;
 
 import org.hibernate.testing.ServiceRegistryBuilder;
+import org.hibernate.testing.TestForIssue;
 
 /**
  * Test case for ANN-722 and ANN-730.
  *
  * @author Hardy Ferentschik
  */
 public class FkCircularityTest extends TestCase {
+	private static final Logger log = Logger.getLogger( FkCircularityTest.class );
 
 	private ServiceRegistry serviceRegistry;
 
 	@Override
     protected void setUp() {
 		serviceRegistry = ServiceRegistryBuilder.buildServiceRegistry( Environment.getProperties() );
 	}
 
 	@Override
     protected void tearDown() {
         if (serviceRegistry != null) ServiceRegistryBuilder.destroy(serviceRegistry);
 	}
 
 	public void testJoinedSublcassesInPK() {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(A.class);
 			config.addAnnotatedClass(B.class);
 			config.addAnnotatedClass(C.class);
 			config.addAnnotatedClass(D.class);
 			config.buildSessionFactory( serviceRegistry );
 			String[] schema = config
 					.generateSchemaCreationScript(new SQLServerDialect());
 			for (String s : schema) {
-                LOG.debug(s);
+                log.debug(s);
 			}
-            LOG.debug("success");
+            log.debug("success");
 		} catch (Exception e) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 
 	public void testDeepJoinedSuclassesHierachy() {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(ClassA.class);
 			config.addAnnotatedClass(ClassB.class);
 			config.addAnnotatedClass(ClassC.class);
 			config.addAnnotatedClass(ClassD.class);
 			config.buildSessionFactory( serviceRegistry );
 			String[] schema = config
 					.generateSchemaCreationScript(new HSQLDialect());
 			for (String s : schema) {
-                LOG.debug(s);
+                log.debug(s);
 			}
-            LOG.debug("success");
+            log.debug("success");
 		} catch (Exception e) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/EnumIdTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/EnumIdTest.java
index 495998298a..4b60fe1017 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/EnumIdTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/EnumIdTest.java
@@ -1,82 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.id;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 
 import org.junit.Test;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.annotations.id.entities.Planet;
 import org.hibernate.test.annotations.id.entities.PlanetCheatSheet;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 
 /**
  * Tests for enum type as id.
  *
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 @TestForIssue( jiraKey = "ANN-744" )
 public class EnumIdTest extends BaseCoreFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( EnumIdTest.class );
+
 	@Test
 	public void testEnumAsId() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		PlanetCheatSheet mercury = new PlanetCheatSheet();
 		mercury.setPlanet(Planet.MERCURY);
 		mercury.setMass(3.303e+23);
 		mercury.setRadius(2.4397e6);
 		mercury.setNumberOfInhabitants(0);
 		s.persist(mercury);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		PlanetCheatSheet mercuryFromDb = (PlanetCheatSheet) s.get(PlanetCheatSheet.class, mercury.getPlanet());
 		assertNotNull(mercuryFromDb);
-        LOG.debug(mercuryFromDb.toString());
+        log.debug(mercuryFromDb.toString());
 		s.delete(mercuryFromDb);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		mercury = (PlanetCheatSheet) s.get(PlanetCheatSheet.class, Planet.MERCURY);
 		assertNull(mercury);
 		tx.commit();
 		s.close();
 	}
 
 	@Override
     protected Class[] getAnnotatedClasses() {
 		return new Class[] { PlanetCheatSheet.class };
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/JoinColumnOverrideTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/JoinColumnOverrideTest.java
index 053e58742f..300da866b6 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/JoinColumnOverrideTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/JoinColumnOverrideTest.java
@@ -1,81 +1,84 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.id;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.cfg.Configuration;
 import org.hibernate.dialect.SQLServerDialect;
 
 import org.junit.Test;
 
 import org.hibernate.testing.ServiceRegistryBuilder;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 import org.hibernate.test.annotations.id.entities.Bunny;
 import org.hibernate.test.annotations.id.entities.PointyTooth;
 import org.hibernate.test.annotations.id.entities.TwinkleToes;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 
 /**
  * Tests for JIRA issue ANN-748.
  *
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class JoinColumnOverrideTest extends BaseUnitTestCase {
+	private static final Logger log = Logger.getLogger( JoinColumnOverrideTest.class );
+
 	@Test
 	@TestForIssue( jiraKey = "ANN-748" )
 	public void testBlownPrecision() throws Exception {
 		try {
 			Configuration config = new Configuration();
 			config.addAnnotatedClass(Bunny.class);
 			config.addAnnotatedClass(PointyTooth.class);
 			config.addAnnotatedClass(TwinkleToes.class);
 			config.buildSessionFactory( ServiceRegistryBuilder.buildServiceRegistry( config.getProperties() ) );
 			String[] schema = config
 					.generateSchemaCreationScript(new SQLServerDialect());
 			for (String s : schema) {
-                LOG.debug(s);
+                log.debug(s);
 			}
 			String expectedSqlPointyTooth = "create table PointyTooth (id numeric(128,0) not null, " +
 					"bunny_id numeric(128,0) null, primary key (id))";
 			assertEquals("Wrong SQL", expectedSqlPointyTooth, schema[1]);
 
 			String expectedSqlTwinkleToes = "create table TwinkleToes (id numeric(128,0) not null, " +
 			"bunny_id numeric(128,0) null, primary key (id))";
 			assertEquals("Wrong SQL", expectedSqlTwinkleToes, schema[2]);
 		}
 		catch (Exception e) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/EnumIdTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/EnumIdTest.java
index 8b6cd3f8a0..22643fa21c 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/EnumIdTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/EnumIdTest.java
@@ -1,82 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.id.sequences;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 
 import org.junit.Test;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.annotations.id.sequences.entities.Planet;
 import org.hibernate.test.annotations.id.sequences.entities.PlanetCheatSheet;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 
 /**
  * Tests for enum type as id.
  *
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 @TestForIssue( jiraKey = "ANN-744" )
 public class EnumIdTest extends BaseCoreFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( EnumIdTest.class );
+
 	@Test
 	public void testEnumAsId() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		PlanetCheatSheet mercury = new PlanetCheatSheet();
 		mercury.setPlanet(Planet.MERCURY);
 		mercury.setMass(3.303e+23);
 		mercury.setRadius(2.4397e6);
 		mercury.setNumberOfInhabitants(0);
 		s.persist(mercury);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		PlanetCheatSheet mercuryFromDb = (PlanetCheatSheet) s.get(PlanetCheatSheet.class, mercury.getPlanet());
 		assertNotNull(mercuryFromDb);
-        LOG.debug(mercuryFromDb.toString());
+        log.debug(mercuryFromDb.toString());
 		s.delete(mercuryFromDb);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		mercury = (PlanetCheatSheet) s.get(PlanetCheatSheet.class, Planet.MERCURY);
 		assertNull(mercury);
 		tx.commit();
 		s.close();
 	}
 
 	@Override
     protected Class[] getAnnotatedClasses() {
 		return new Class[] { PlanetCheatSheet.class };
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/JoinColumnOverrideTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/JoinColumnOverrideTest.java
index 5fbf5f39b4..11e72b1215 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/JoinColumnOverrideTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/JoinColumnOverrideTest.java
@@ -1,58 +1,61 @@
 //$Id$
 package org.hibernate.test.annotations.id.sequences;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.cfg.Configuration;
 import org.hibernate.dialect.SQLServerDialect;
 
 import org.junit.Test;
 
 import org.hibernate.testing.ServiceRegistryBuilder;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 import org.hibernate.test.annotations.id.sequences.entities.Bunny;
 import org.hibernate.test.annotations.id.sequences.entities.PointyTooth;
 import org.hibernate.test.annotations.id.sequences.entities.TwinkleToes;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 
 /**
  * Tests for JIRA issue ANN-748.
  *
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class JoinColumnOverrideTest extends BaseUnitTestCase {
+	private static final Logger log = Logger.getLogger( JoinColumnOverrideTest.class );
+
 	@Test
 	@TestForIssue( jiraKey = "ANN-748" )
 	public void testBlownPrecision() throws Exception {
 		try {
 			Configuration config = new Configuration();
 			config.addAnnotatedClass(Bunny.class);
 			config.addAnnotatedClass(PointyTooth.class);
 			config.addAnnotatedClass(TwinkleToes.class);
 			config.buildSessionFactory( ServiceRegistryBuilder.buildServiceRegistry( config.getProperties() ) );
 			String[] schema = config.generateSchemaCreationScript( new SQLServerDialect() );
 			for (String s : schema) {
-                LOG.debug(s);
+                log.debug(s);
 			}
 			String expectedSqlPointyTooth = "create table PointyTooth (id numeric(128,0) not null, " +
 					"bunny_id numeric(128,0) null, primary key (id))";
 			assertEquals("Wrong SQL", expectedSqlPointyTooth, schema[1]);
 
 			String expectedSqlTwinkleToes = "create table TwinkleToes (id numeric(128,0) not null, " +
 			"bunny_id numeric(128,0) null, primary key (id))";
 			assertEquals("Wrong SQL", expectedSqlTwinkleToes, schema[2]);
 		}
 		catch (Exception e) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
index 249196be23..f2fd831273 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
@@ -1,170 +1,173 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.immutable;
 
 import java.util.ArrayList;
 import java.util.List;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.AnnotationException;
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 
 import org.junit.Test;
 
 import org.hibernate.testing.ServiceRegistryBuilder;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * Tests for <code>Immutable</code> annotation.
  *
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class ImmutableTest extends BaseCoreFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( ImmutableTest.class );
+
 	@Test
 	public void testImmutableEntity() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Country country = new Country();
 		country.setName("Germany");
 		s.persist(country);
 		tx.commit();
 		s.close();
 
 		// try changing the entity
 		s = openSession();
 		tx = s.beginTransaction();
 		Country germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		germany.setName("France");
 		assertEquals("Local name can be changed", "France", germany.getName());
 		s.save(germany);
 		tx.commit();
 		s.close();
 
 		// retrieving the country again - it should be unmodified
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Name should not have changed", "Germany", germany.getName());
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testImmutableCollection() {
 		Country country = new Country();
 		country.setName("Germany");
 		List states = new ArrayList<State>();
 		State bayern = new State();
 		bayern.setName("Bayern");
 		State hessen = new State();
 		hessen.setName("Hessen");
 		State sachsen = new State();
 		sachsen.setName("Sachsen");
 		states.add(bayern);
 		states.add(hessen);
 		states.add(sachsen);
 		country.setStates(states);
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist(country);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Country germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 
 		// try adding a state
 		State foobar = new State();
 		foobar.setName("foobar");
 		s.save(foobar);
 		germany.getStates().add(foobar);
 		try {
 			tx.commit();
 			fail();
 		}
 		catch (HibernateException e) {
 			assertTrue(e.getMessage().contains("changed an immutable collection instance"));
-            LOG.debug("success");
+            log.debug("success");
 		}
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 
 		// try deleting a state
 		germany.getStates().remove(0);
 		try {
 			tx.commit();
 			fail();
 		} catch (HibernateException e) {
 			assertTrue(e.getMessage().contains("changed an immutable collection instance"));
-            LOG.debug("success");
+            log.debug("success");
 		}
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMiscplacedImmutableAnnotation() {
 		try {
 			Configuration config = new Configuration();
 			config.addAnnotatedClass(Foobar.class);
 			config.buildSessionFactory( ServiceRegistryBuilder.buildServiceRegistry( config.getProperties() ) );
 			fail();
 		}
 		catch (AnnotationException ae) {
-            LOG.debug("succes");
+            log.debug("succes");
 		}
 	}
 
 	@Override
     protected Class[] getAnnotatedClasses() {
 		return new Class[] { Country.class, State.class};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
index 65f41277fe..d97ca30d34 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
@@ -1,96 +1,100 @@
 // $Id$
 package org.hibernate.test.annotations.namingstrategy;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import java.io.PrintWriter;
 import java.io.StringWriter;
 import java.util.Iterator;
-import junit.framework.TestCase;
+
+import org.jboss.logging.Logger;
+
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.EJB3NamingStrategy;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.mapping.Table;
 import org.hibernate.service.ServiceRegistry;
 
+import junit.framework.TestCase;
+
 import org.hibernate.testing.ServiceRegistryBuilder;
 
 /**
  * Test harness for ANN-716.
  *
  * @author Hardy Ferentschik
  */
 public class NamingStrategyTest extends TestCase {
+	private static final Logger log = Logger.getLogger( NamingStrategyTest.class );
 
 	private ServiceRegistry serviceRegistry;
 
 	@Override
     protected void setUp() {
 		serviceRegistry = ServiceRegistryBuilder.buildServiceRegistry( Environment.getProperties() );
 	}
 
 	@Override
     protected void tearDown() {
         if (serviceRegistry != null) ServiceRegistryBuilder.destroy(serviceRegistry);
 	}
 
 	public void testWithCustomNamingStrategy() throws Exception {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.setNamingStrategy(new DummyNamingStrategy());
 			config.addAnnotatedClass(Address.class);
 			config.addAnnotatedClass(Person.class);
 			config.buildSessionFactory( serviceRegistry );
 		}
 		catch( Exception e ) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 
 	public void testWithEJB3NamingStrategy() throws Exception {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.setNamingStrategy(EJB3NamingStrategy.INSTANCE);
 			config.addAnnotatedClass(A.class);
 			config.addAnnotatedClass(AddressEntry.class);
 			config.buildSessionFactory( serviceRegistry );
 			Mappings mappings = config.createMappings();
 			boolean foundIt = false;
 
 			for ( Iterator iter = mappings.iterateTables(); iter.hasNext();  ) {
 				Table table = (Table) iter.next();
-                LOG.info("testWithEJB3NamingStrategy table = " + table.getName());
+                log.info("testWithEJB3NamingStrategy table = " + table.getName());
 				if ( table.getName().equalsIgnoreCase("A_ADDRESS")) {
 					foundIt = true;
 				}
 				// make sure we use A_ADDRESS instead of AEC_address
 				assertFalse("got table name mapped to: AEC_address (should be A_ADDRESS) which violates JPA-2 spec section 11.1.8 ([OWNING_ENTITY_NAME]_[COLLECTION_ATTRIBUTE_NAME])",table.getName().equalsIgnoreCase("AEC_address"));
 			}
 			assertTrue("table not mapped to A_ADDRESS which violates JPA-2 spec section 11.1.8",foundIt);
 		}
 		catch( Exception e ) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 
 	public void testWithoutCustomNamingStrategy() throws Exception {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(Address.class);
 			config.addAnnotatedClass(Person.class);
 			config.buildSessionFactory( serviceRegistry );
 		}
 		catch( Exception e ) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
-            LOG.debug(writer.toString());
+            log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/naturalid/NaturalIdOnSingleManyToOneTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/naturalid/NaturalIdOnSingleManyToOneTest.java
index 8387912785..930a5bf244 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/naturalid/NaturalIdOnSingleManyToOneTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/naturalid/NaturalIdOnSingleManyToOneTest.java
@@ -1,145 +1,148 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.naturalid;
 
 import java.util.List;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Criteria;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.stat.Statistics;
 
 import org.junit.Test;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Test case for NaturalId annotation. See ANN-750.
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 @TestForIssue( jiraKey = "ANN-750" )
 public class NaturalIdOnSingleManyToOneTest extends BaseCoreFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( NaturalIdOnSingleManyToOneTest.class );
+
 	@Test
 	public void testMappingProperties() {
-        LOG.warn("Commented out test");
+        log.warn("Commented out test");
 
 		ClassMetadata metaData = sessionFactory().getClassMetadata(
 				NaturalIdOnManyToOne.class
 		);
 		assertTrue(
 				"Class should have a natural key", metaData
 						.hasNaturalIdentifier()
 		);
 		int[] propertiesIndex = metaData.getNaturalIdentifierProperties();
 		assertTrue( "Wrong number of elements", propertiesIndex.length == 1 );
 	}
 
 	@Test
 	public void testManyToOneNaturalIdCached() {
 		NaturalIdOnManyToOne singleManyToOne = new NaturalIdOnManyToOne();
 		Citizen c1 = new Citizen();
 		c1.setFirstname( "Emmanuel" );
 		c1.setLastname( "Bernard" );
 		c1.setSsn( "1234" );
 
 		State france = new State();
 		france.setName( "Ile de France" );
 		c1.setState( france );
 
 		singleManyToOne.setCitizen( c1 );
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist( france );
 		s.persist( c1 );
 		s.persist( singleManyToOne );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Criteria criteria = s.createCriteria( NaturalIdOnManyToOne.class );
 		criteria.add( Restrictions.naturalId().set( "citizen", c1 ) );
 		criteria.setCacheable( true );
 
 		Statistics stats = sessionFactory().getStatistics();
 		stats.setStatisticsEnabled( true );
 		stats.clear();
 		assertEquals(
 				"Cache hits should be empty", 0, stats
 						.getQueryCacheHitCount()
 		);
 
 		// first query
 		List results = criteria.list();
 		assertEquals( 1, results.size() );
 		assertEquals(
 				"Cache hits should be empty", 0, stats
 						.getQueryCacheHitCount()
 		);
 		assertEquals(
 				"First query should be a miss", 1, stats
 						.getQueryCacheMissCount()
 		);
 		assertEquals(
 				"Query result should be added to cache", 1, stats
 						.getQueryCachePutCount()
 		);
 
 		// query a second time - result should be cached
 		criteria.list();
 		assertEquals(
 				"Cache hits should be empty", 1, stats
 						.getQueryCacheHitCount()
 		);
 
 		// cleanup
 		tx.rollback();
 		s.close();
 	}
 
 	@Override
     protected Class[] getAnnotatedClasses() {
 		return new Class[] {
 				Citizen.class, State.class,
 				NaturalIdOnManyToOne.class
 		};
 	}
 
 	@Override
     protected void configure(Configuration cfg) {
 		cfg.setProperty( "hibernate.cache.use_query_cache", "true" );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/primarykey/NullablePrimaryKeyTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/primarykey/NullablePrimaryKeyTest.java
index 6517a7b5d3..5108997ac7 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/primarykey/NullablePrimaryKeyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/primarykey/NullablePrimaryKeyTest.java
@@ -1,46 +1,48 @@
 //$Id: A320.java 14736 2008-06-04 14:23:42Z hardy.ferentschik $
 package org.hibernate.test.annotations.onetoone.primarykey;
 
-import static org.hibernate.testing.TestLogger.LOG;
+import org.jboss.logging.Logger;
+
 import junit.framework.TestCase;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.SQLServerDialect;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.testing.ServiceRegistryBuilder;
 
 /**
  * Test harness for ANN-742.
  *
  * @author Hardy Ferentschik
  *
  */
 public class NullablePrimaryKeyTest extends TestCase {
+	private static final Logger log = Logger.getLogger( NullablePrimaryKeyTest.class );
 
 	public void testGeneratedSql() {
 
 		ServiceRegistry serviceRegistry = null;
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(Address.class);
 			config.addAnnotatedClass(Person.class);
 			serviceRegistry = ServiceRegistryBuilder.buildServiceRegistry( Environment.getProperties() );
 			config.buildSessionFactory( serviceRegistry );
 			String[] schema = config
 					.generateSchemaCreationScript(new SQLServerDialect());
 			for (String s : schema) {
-                LOG.debug(s);
+                log.debug(s);
 			}
 			String expectedMappingTableSql = "create table personAddress (address_id numeric(19,0) null, " +
 					"person_id numeric(19,0) not null, primary key (person_id))";
 			assertEquals("Wrong SQL", expectedMappingTableSql, schema[2]);
 		} catch (Exception e) {
 			fail(e.getMessage());
 		}
 		finally {
 			if ( serviceRegistry != null ) {
 				ServiceRegistryBuilder.destroy( serviceRegistry );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/reflection/LogListener.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/reflection/LogListener.java
index 8dd2ecbf54..cbb15ce692 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/reflection/LogListener.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/reflection/LogListener.java
@@ -1,23 +1,25 @@
 //$Id$
 package org.hibernate.test.annotations.reflection;
-import static org.hibernate.testing.TestLogger.LOG;
+
 import javax.persistence.PostPersist;
 import javax.persistence.PrePersist;
 
+import org.jboss.logging.Logger;
+
 
 /**
  * @author Emmanuel Bernard
  */
 public class LogListener {
+	private static final Logger log = Logger.getLogger( LogListener.class );
 
 	@PrePersist
 	@PostPersist
 	public void log(Object entity) {
-        LOG.debug("Logging entity " + entity.getClass().getName() + " with hashCode: " + entity.hashCode());
+        log.debug("Logging entity " + entity.getClass().getName() + " with hashCode: " + entity.hashCode());
 	}
 
-
 	public void noLog(Object entity) {
-        LOG.debug("NoLogging entity " + entity.getClass().getName() + " with hashCode: " + entity.hashCode());
+        log.debug("NoLogging entity " + entity.getClass().getName() + " with hashCode: " + entity.hashCode());
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/reflection/OtherLogListener.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/reflection/OtherLogListener.java
index a3fb3e861e..94e04b12c1 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/reflection/OtherLogListener.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/reflection/OtherLogListener.java
@@ -1,22 +1,24 @@
 //$Id$
 package org.hibernate.test.annotations.reflection;
-import static org.hibernate.testing.TestLogger.LOG;
+
 import javax.persistence.PostPersist;
 import javax.persistence.PrePersist;
 
+import org.jboss.logging.Logger;
+
 /**
  * @author Emmanuel Bernard
  */
 public class OtherLogListener {
+	private static final Logger log = Logger.getLogger( OtherLogListener.class );
 
 	@PrePersist
 	@PostPersist
 	public void log(Object entity) {
-        LOG.debug("Logging entity " + entity.getClass().getName() + " with hashCode: " + entity.hashCode());
+        log.debug("Logging entity " + entity.getClass().getName() + " with hashCode: " + entity.hashCode());
 	}
 
-
 	public void noLog(Object entity) {
-        LOG.debug("NoLogging entity " + entity.getClass().getName() + " with hashCode: " + entity.hashCode());
+        log.debug("NoLogging entity " + entity.getClass().getName() + " with hashCode: " + entity.hashCode());
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/cache/SQLFunctionsInterSystemsTest.java b/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/cache/SQLFunctionsInterSystemsTest.java
index 18e62e0ae2..5e8de2e52d 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/cache/SQLFunctionsInterSystemsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/cache/SQLFunctionsInterSystemsTest.java
@@ -1,768 +1,771 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.dialect.functional.cache;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.GregorianCalendar;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.LockMode;
 import org.hibernate.Query;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.dialect.Cache71Dialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.jdbc.Work;
 
 import org.junit.Test;
 
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.legacy.Blobber;
 import org.hibernate.test.legacy.Broken;
 import org.hibernate.test.legacy.Fixed;
 import org.hibernate.test.legacy.Simple;
 import org.hibernate.test.legacy.Single;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Tests for function support on CacheSQL...
  *
  * @author Jonathan Levinson
  */
 @RequiresDialect( value = Cache71Dialect.class )
 public class SQLFunctionsInterSystemsTest extends BaseCoreFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( SQLFunctionsInterSystemsTest.class );
+
 	public String[] getMappings() {
 		return new String[] {
 				"legacy/AltSimple.hbm.xml",
 				"legacy/Broken.hbm.xml",
 				"legacy/Blobber.hbm.xml",
 				"dialect/functional/cache/TestInterSystemsFunctionsClass.hbm.xml"
 		};
 	}
 
 	@Test
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testDialectSQLFunctions() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 
 		Simple simple = new Simple( Long.valueOf( 10 ) );
 		simple.setName("Simple Dialect Function Test");
 		simple.setAddress("Simple Address");
 		simple.setPay(new Float(45.8));
 		simple.setCount(2);
 		s.save( simple );
 
 		// Test to make sure allocating an specified object operates correctly.
 		assertTrue(
 				s.createQuery( "select new org.hibernate.test.legacy.S(s.count, s.address) from Simple s" ).list().size() == 1
 		);
 
 		// Quick check the base dialect functions operate correctly
 		assertTrue(
 				s.createQuery( "select max(s.count) from Simple s" ).list().size() == 1
 		);
 		assertTrue(
 				s.createQuery( "select count(*) from Simple s" ).list().size() == 1
 		);
 
 		List rset = s.createQuery( "select s.name, sysdate, floor(s.pay), round(s.pay,0) from Simple s" ).list();
 		assertNotNull("Name string should have been returned",(((Object[])rset.get(0))[0]));
 		assertNotNull("Todays Date should have been returned",(((Object[])rset.get(0))[1]));
 		assertEquals("floor(45.8) result was incorrect ", new Integer(45), ( (Object[]) rset.get(0) )[2] );
 		assertEquals("round(45.8) result was incorrect ", new Float(46), ( (Object[]) rset.get(0) )[3] );
 
 		simple.setPay(new Float(-45.8));
 		s.update(simple);
 
 		// Test type conversions while using nested functions (Float to Int).
 		rset = s.createQuery( "select abs(round(s.pay,0)) from Simple s" ).list();
 		assertEquals("abs(round(-45.8)) result was incorrect ", new Float(46), rset.get(0));
 
 		// Test a larger depth 3 function example - Not a useful combo other than for testing
 		assertTrue(
 				s.createQuery( "select floor(round(sysdate,1)) from Simple s" ).list().size() == 1
 		);
 
 		// Test the oracle standard NVL funtion as a test of multi-param functions...
 		simple.setPay(null);
 		s.update(simple);
 		Double value = (Double) s.createQuery("select mod( nvl(s.pay, 5000), 2 ) from Simple as s where s.id = 10").list().get(0);
 		assertTrue( 0 == value.intValue() );
 
 		// Test the hsql standard MOD funtion as a test of multi-param functions...
 		value = (Double) s.createQuery( "select MOD(s.count, 2) from Simple as s where s.id = 10" )
 				.list()
 				.get(0);
 		assertTrue( 0 == value.intValue() );
 
         s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing", "unchecked"})
 	public void testSetProperties() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf( 10 ) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		Query q = s.createQuery("from Simple s where s.name=:name and s.count=:count");
 		q.setProperties(simple);
 		assertTrue( q.list().get(0)==simple );
 		//misuse of "Single" as a propertyobject, but it was the first testclass i found with a collection ;)
 		Single single = new Single() { // trivial hack to test properties with arrays.
 			@SuppressWarnings( {"unchecked"})
 			String[] getStuff() { 
 				return (String[]) getSeveral().toArray(new String[getSeveral().size()]);
 			}
 		};
 
 		List l = new ArrayList();
 		l.add("Simple 1");
 		l.add("Slimeball");
 		single.setSeveral(l);
 		q = s.createQuery("from Simple s where s.name in (:several)");
 		q.setProperties(single);
 		assertTrue( q.list().get(0)==simple );
 
 
 		q = s.createQuery("from Simple s where s.name in (:stuff)");
 		q.setProperties(single);
 		assertTrue( q.list().get(0)==simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testBroken() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Broken b = new Fixed();
 		b.setId( Long.valueOf( 123 ));
 		b.setOtherId("foobar");
 		s.save(b);
 		s.flush();
 		b.setTimestamp( new Date() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update(b);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		b = (Broken) s.load( Broken.class, b );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.delete(b);
 		t.commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testNothinToUpdate() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testCachedQuery() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setCacheable(true);
 		q.setString("name", "Simple 1");
 		assertTrue( q.list().size()==1 );
 		simple = (Simple) q.list().get(0);
 
 		q.setString("name", "Simple 2");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		simple.setName("Simple 2");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setString("name", "Simple 2");
 		q.setCacheable(true);
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		t.commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testCachedQueryRegion() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString("name", "Simple 1");
 		assertTrue( q.list().size()==1 );
 		simple = (Simple) q.list().get(0);
 
 		q.setString("name", "Simple 2");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		simple.setName("Simple 2");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		t.commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing", "unchecked"})
 	public void testSQLFunctions() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save(simple );
 
 		s.createQuery( "from Simple s where repeat('foo', 3) = 'foofoofoo'" ).list();
 		s.createQuery( "from Simple s where repeat(s.name, 3) = 'foofoofoo'" ).list();
 		s.createQuery( "from Simple s where repeat( lower(s.name), (3 + (1-1)) / 2) = 'foofoofoo'" ).list();
 
 		assertTrue(
 				s.createQuery( "from Simple s where upper( s.name ) ='SIMPLE 1'" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery(
 						"from Simple s where not( upper( s.name ) ='yada' or 1=2 or 'foo'='bar' or not('foo'='foo') or 'foo' like 'bar' )"
 				).list()
 						.size()==1
 		);
 
 		assertTrue(
 				s.createQuery( "from Simple s where lower( s.name || ' foo' ) ='simple 1 foo'" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery( "from Simple s where lower( concat(s.name, ' foo') ) ='simple 1 foo'" ).list().size()==1
 		);
 
 		Simple other = new Simple( Long.valueOf(20) );
 		other.setName( "Simple 2" );
 		other.setCount( 12 );
 		simple.setOther( other );
 		s.save( other );
 		//s.find("from Simple s where s.name ## 'cat|rat|bag'");
 		assertTrue(
 				s.createQuery( "from Simple s where upper( s.other.name ) ='SIMPLE 2'" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery( "from Simple s where not ( upper( s.other.name ) ='SIMPLE 2' )" ).list().size()==0
 		);
 		assertTrue(
 				s.createQuery(
 						"select distinct s from Simple s where ( ( s.other.count + 3 ) = (15*2)/2 and s.count = 69) or ( ( s.other.count + 2 ) / 7 ) = 2"
 				).list()
 						.size()==1
 		);
 		assertTrue(
 				s.createQuery(
 						"select s from Simple s where ( ( s.other.count + 3 ) = (15*2)/2 and s.count = 69) or ( ( s.other.count + 2 ) / 7 ) = 2 order by s.other.count"
 				).list()
 						.size()==1
 		);
 		Simple min = new Simple( Long.valueOf(30) );
 		min.setCount( -1 );
 		s.save(min );
 
 		assertTrue(
 				s.createQuery( "from Simple s where s.count > ( select min(sim.count) from Simple sim )" )
 						.list()
 						.size()==2
 		);
 		t.commit();
 		t = s.beginTransaction();
 		assertTrue(
 				s.createQuery(
 						"from Simple s where s = some( select sim from Simple sim where sim.count>=0 ) and s.count >= 0"
 				).list()
 						.size()==2
 		);
 		assertTrue(
 				s.createQuery(
 						"from Simple s where s = some( select sim from Simple sim where sim.other.count=s.other.count ) and s.other.count > 0"
 				).list()
 						.size()==1
 		);
 
 		Iterator iter = s.createQuery( "select sum(s.count) from Simple s group by s.count having sum(s.count) > 10" )
 				.iterate();
 		assertTrue( iter.hasNext() );
 		assertEquals( Long.valueOf( 12 ), iter.next() );
 		assertTrue( !iter.hasNext() );
 		iter = s.createQuery( "select s.count from Simple s group by s.count having s.count = 12" ).iterate();
 		assertTrue( iter.hasNext() );
 
 		s.createQuery(
 				"select s.id, s.count, count(t), max(t.date) from Simple s, Simple t where s.count = t.count group by s.id, s.count order by s.count"
 		).iterate();
 
 		Query q = s.createQuery("from Simple s");
 		q.setMaxResults( 10 );
 		assertTrue( q.list().size()==3 );
 		q = s.createQuery("from Simple s");
 		q.setMaxResults( 1 );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s");
 		assertTrue( q.list().size() == 3 );
 		q = s.createQuery("from Simple s where s.name = ?");
 		q.setString( 0, "Simple 1" );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name = ? and upper(s.name) = ?");
 		q.setString(1, "SIMPLE 1");
 		q.setString( 0, "Simple 1" );
 		q.setFirstResult(0);
 		assertTrue( q.iterate().hasNext() );
 		q = s.createQuery("from Simple s where s.name = :foo and upper(s.name) = :bar or s.count=:count or s.count=:count + 1");
 		q.setParameter( "bar", "SIMPLE 1" );
 		q.setString( "foo", "Simple 1" );
 		q.setInteger("count", 69);
 		q.setFirstResult(0);
 		assertTrue( q.iterate().hasNext() );
 		q = s.createQuery("select s.id from Simple s");
 		q.setFirstResult(1);
 		q.setMaxResults( 2 );
 		iter = q.iterate();
 		int i=0;
 		while ( iter.hasNext() ) {
 			assertTrue( iter.next() instanceof Long );
 			i++;
 		}
 		assertTrue( i == 2 );
 		q = s.createQuery("select all s, s.other from Simple s where s = :s");
 		q.setParameter("s", simple);
 		assertTrue( q.list().size()==1 );
 
 
 		q = s.createQuery("from Simple s where s.name in (:name_list) and s.count > :count");
 		HashSet set = new HashSet();
 		set.add("Simple 1");
 		set.add("foo");
 		q.setParameterList( "name_list", set );
 		q.setParameter("count", new Integer(-1) );
 		assertTrue( q.list().size()==1 );
 
 		ScrollableResults sr = s.createQuery("from Simple s").scroll();
 		sr.next();
 		sr.get(0);
 		sr.close();
 
 		s.delete( other );
 		s.delete( simple );
 		s.delete( min );
 		t.commit();
 		s.close();
 
 	}
 
 	public void testBlobClob() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Blobber b = new Blobber();
 		b.setBlob( s.getLobHelper().createBlob( "foo/bar/baz".getBytes() ) );
 		b.setClob( s.getLobHelper().createClob("foo/bar/baz") );
 		s.save(b);
 		//s.refresh(b);
 		//assertTrue( b.getClob() instanceof ClobImpl );
 		s.flush();
 		s.refresh(b);
 		//b.getBlob().setBytes( 2, "abc".getBytes() );
-        LOG.debug("levinson: just bfore b.getClob()");
+        log.debug("levinson: just bfore b.getClob()");
         b.getClob().getSubString(2, 3);
 		//b.getClob().setString(2, "abc");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		Blobber b2 = new Blobber();
 		s.save(b2);
 		b2.setBlob( b.getBlob() );
 		b.setBlob(null);
 		//assertTrue( b.getClob().getSubString(1, 3).equals("fab") );
 		b.getClob().getSubString(1, 6);
 		//b.getClob().setString(1, "qwerty");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		b.setClob( s.getLobHelper().createClob("xcvfxvc xcvbx cvbx cvbx cvbxcvbxcvbxcvb") );
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		assertTrue( b.getClob().getSubString(1, 7).equals("xcvfxvc") );
 		//b.getClob().setString(5, "1234567890");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testSqlFunctionAsAlias() throws Exception {
 		String functionName = locateAppropriateDialectFunctionNameForAliasTest();
 		if (functionName == null) {
-            LOG.info("Dialect does not list any no-arg functions");
+            log.info("Dialect does not list any no-arg functions");
 			return;
 		}
 
-        LOG.info("Using function named [" + functionName + "] for 'function as alias' test");
+        log.info("Using function named [" + functionName + "] for 'function as alias' test");
 		String query = "select " + functionName + " from Simple as " + functionName + " where " + functionName + ".id = 10";
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List result = s.createQuery( query ).list();
 		assertTrue( result.size() == 1 );
 		assertTrue(result.get(0) instanceof Simple);
 		s.delete( result.get(0) );
 		t.commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"ForLoopReplaceableByForEach"})
 	private String locateAppropriateDialectFunctionNameForAliasTest() {
 		for (Iterator itr = getDialect().getFunctions().entrySet().iterator(); itr.hasNext(); ) {
 			final Map.Entry entry = (Map.Entry) itr.next();
 			final SQLFunction function = (SQLFunction) entry.getValue();
 			if ( !function.hasArguments() && !function.hasParenthesesIfNoArguments() ) {
 				return (String) entry.getKey();
 			}
 		}
 		return null;
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testCachedQueryOnInsert() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s");
 		List list = q.setCacheable(true).list();
 		assertTrue( list.size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Simple simple2 = new Simple( Long.valueOf(12) );
 		simple2.setCount(133);
 		s.save( simple2 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==2 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==2 );
 		for ( Object o : list ) {
 			s.delete( o );
 		}
 		t.commit();
 		s.close();
 
 	}
 
     @SuppressWarnings( {"UnnecessaryBoxing", "UnnecessaryUnboxing"})
 	public void testInterSystemsFunctions() throws Exception {
         Calendar cal = new GregorianCalendar();
         cal.set(1977,6,3,0,0,0);
         java.sql.Timestamp testvalue = new java.sql.Timestamp(cal.getTimeInMillis());
         testvalue.setNanos(0);
         Calendar cal3 = new GregorianCalendar();
         cal3.set(1976,2,3,0,0,0);
         java.sql.Timestamp testvalue3 = new java.sql.Timestamp(cal3.getTimeInMillis());
         testvalue3.setNanos(0);
 
         Session s = openSession();
         s.beginTransaction();
         try {
 			s.doWork(
 					new Work() {
 						@Override
 						public void execute(Connection connection) throws SQLException {
 							Statement stmt = connection.createStatement();
 							stmt.executeUpdate( "DROP FUNCTION spLock FROM TestInterSystemsFunctionsClass" );
 						}
 					}
 			);
         }
         catch (Exception ex) {
             System.out.println("as we expected stored procedure sp does not exist when we drop it");
 
         }
 		s.getTransaction().commit();
 
         s.beginTransaction();
 		s.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						Statement stmt = connection.createStatement();
 						String create_function = "CREATE FUNCTION SQLUser.TestInterSystemsFunctionsClass_spLock\n" +
 								"     ( INOUT pHandle %SQLProcContext, \n" +
 								"       ROWID INTEGER \n" +
 								" )\n" +
 								" FOR User.TestInterSystemsFunctionsClass " +
 								"    PROCEDURE\n" +
 								"    RETURNS INTEGER\n" +
 								"    LANGUAGE OBJECTSCRIPT\n" +
 								"    {\n" +
 								"        q 0\n" +
 								"     }";
 						stmt.executeUpdate(create_function);
 					}
 				}
 		);
         s.getTransaction().commit();
 
         s.beginTransaction();
 
         TestInterSystemsFunctionsClass object = new TestInterSystemsFunctionsClass( Long.valueOf( 10 ) );
         object.setDateText("1977-07-03");
         object.setDate1( testvalue );
         object.setDate3( testvalue3 );
         s.save( object );
         s.getTransaction().commit();
         s.close();
 
         s = openSession();
         s.beginTransaction();
         TestInterSystemsFunctionsClass test = (TestInterSystemsFunctionsClass) s.get(TestInterSystemsFunctionsClass.class, Long.valueOf(10));
         assertTrue( test.getDate1().equals(testvalue));
         test = (TestInterSystemsFunctionsClass) s.get(TestInterSystemsFunctionsClass.class, Long.valueOf(10), LockMode.UPGRADE);
         assertTrue( test.getDate1().equals(testvalue));
         Date value = (Date) s.createQuery( "select nvl(o.date,o.dateText) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( value.equals(testvalue));
         Object nv = s.createQuery( "select nullif(o.dateText,o.dateText) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( nv == null);
         String dateText = (String) s.createQuery(
 				"select nvl(o.dateText,o.date) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue( dateText.equals("1977-07-03"));
         value = (Date) s.createQuery( "select ifnull(o.date,o.date1) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( value.equals(testvalue));
         value = (Date) s.createQuery( "select ifnull(o.date3,o.date,o.date1) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( value.equals(testvalue));
         Integer pos = (Integer) s.createQuery(
 				"select position('07', o.dateText) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(pos.intValue() == 6);
         String st = (String) s.createQuery( "select convert(o.date1, SQL_TIME) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( st.equals("00:00:00"));
         java.sql.Time tm = (java.sql.Time) s.createQuery(
 				"select cast(o.date1, time) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue( tm.toString().equals("00:00:00"));
         Double diff = (Double) s.createQuery(
 				"select timestampdiff(SQL_TSI_FRAC_SECOND, o.date3, o.date1) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(diff.doubleValue() != 0.0);
         diff = (Double) s.createQuery(
 				"select timestampdiff(SQL_TSI_MONTH, o.date3, o.date1) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(diff.doubleValue() == 16.0);
         diff = (Double) s.createQuery(
 				"select timestampdiff(SQL_TSI_WEEK, o.date3, o.date1) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(diff.doubleValue() >= 16*4);
         diff = (Double) s.createQuery(
 				"select timestampdiff(SQL_TSI_YEAR, o.date3, o.date1) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(diff.doubleValue() == 1.0);
 
         s.getTransaction().commit();
         s.close();
     }
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/filter/DynamicFilterTest.java b/hibernate-core/src/test/java/org/hibernate/test/filter/DynamicFilterTest.java
index 4cc759a0ff..ebbd6c0b87 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/filter/DynamicFilterTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/filter/DynamicFilterTest.java
@@ -1,978 +1,979 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.filter;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import java.util.ArrayList;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.GregorianCalendar;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Criteria;
-import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.entry.CollectionCacheEntry;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.criterion.DetachedCriteria;
 import org.hibernate.criterion.Property;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.criterion.Subqueries;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.transform.DistinctRootEntityResultTransformer;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Implementation of DynamicFilterTest.
  *
  * @author Steve Ebersole
  */
 public class DynamicFilterTest extends BaseCoreFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( DynamicFilterTest.class );
 
 	@Override
 	public String[] getMappings() {
 		return new String[]{
 			"filter/defs.hbm.xml",
 			"filter/LineItem.hbm.xml",
 			"filter/Order.hbm.xml",
 			"filter/Product.hbm.xml",
 			"filter/Salesperson.hbm.xml",
 			"filter/Department.hbm.xml",
 			"filter/Category.hbm.xml"
 		};
 	}
 
 	@Override
 	protected String getCacheConcurrencyStrategy() {
 		return "nonstrict-read-write";
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		cfg.setProperty( Environment.MAX_FETCH_DEPTH, "1" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.USE_QUERY_CACHE, "true" );
 	}
 
 	@Test
 	public void testSqlSyntaxOfFiltersWithUnions() {
 		Session session = openSession();
 		session.enableFilter( "unioned" );
 		session.createQuery( "from Category" ).list();
 		session.close();
 	}
 
 	@Test
 	public void testSecondLevelCachedCollectionsFiltering() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		long ts = ( ( SessionImplementor ) session ).getTimestamp();
 
 		// Force a collection into the second level cache, with its non-filtered elements
 		Salesperson sp = ( Salesperson ) session.load( Salesperson.class, testData.steveId );
 		Hibernate.initialize( sp.getOrders() );
 		CollectionPersister persister = sessionFactory().getCollectionPersister( Salesperson.class.getName() + ".orders" );
 		assertTrue( "No cache for collection", persister.hasCache() );
 		CacheKey cacheKey = ( (SessionImplementor) session ).generateCacheKey(
 				testData.steveId,
 				persister.getKeyType(),
 				persister.getRole()
 		);
 		CollectionCacheEntry cachedData = ( CollectionCacheEntry ) persister.getCacheAccessStrategy().get( cacheKey, ts );
 		assertNotNull( "collection was not in cache", cachedData );
 
 		session.close();
 
 		session = openSession();
 		ts = ( ( SessionImplementor ) session ).getTimestamp();
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		sp = ( Salesperson ) session.createQuery( "from Salesperson as s where s.id = :id" )
 		        .setLong( "id", testData.steveId )
 		        .uniqueResult();
 		assertEquals( "Filtered-collection not bypassing 2L-cache", 1, sp.getOrders().size() );
 
 		CacheKey cacheKey2 = ( (SessionImplementor) session ).generateCacheKey(
 				testData.steveId,
 				persister.getKeyType(),
 				persister.getRole()
 		);
 		CollectionCacheEntry cachedData2 = ( CollectionCacheEntry ) persister.getCacheAccessStrategy().get( cacheKey2, ts );
 		assertNotNull( "collection no longer in cache!", cachedData2 );
 		assertSame( "Different cache values!", cachedData, cachedData2 );
 
 		session.close();
 
 		session = openSession();
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		sp = ( Salesperson ) session.load( Salesperson.class, testData.steveId );
 		assertEquals( "Filtered-collection not bypassing 2L-cache", 1, sp.getOrders().size() );
 
 		session.close();
 
 		// Finally, make sure that the original cached version did not get over-written
 		session = openSession();
 		sp = ( Salesperson ) session.load( Salesperson.class, testData.steveId );
 		assertEquals( "Actual cached version got over-written", 2, sp.getOrders().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testCombinedClassAndCollectionFiltersEnabled() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[]{"LA", "APAC"} );
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 
 		// test retreival through hql with the collection as non-eager
 		List salespersons = session.createQuery( "select s from Salesperson as s" ).list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 		Salesperson sp = ( Salesperson ) salespersons.get( 0 );
 		assertEquals( "Incorrect order count", 1, sp.getOrders().size() );
 
 		session.clear();
 
 		session.disableFilter( "regionlist" );
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[]{"LA", "APAC", "APAC"} );
 		// Second test retreival through hql with the collection as non-eager with different region list
 		salespersons = session.createQuery( "select s from Salesperson as s" ).list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 		sp = ( Salesperson ) salespersons.get( 0 );
 		assertEquals( "Incorrect order count", 1, sp.getOrders().size() );
 
 		session.clear();
 
 
 		// test retreival through hql with the collection join fetched
 		salespersons = session.createQuery( "select s from Salesperson as s left join fetch s.orders" ).list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 		sp = ( Salesperson ) salespersons.get( 0 );
 		assertEquals( "Incorrect order count", 1, sp.getOrders().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testHqlFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// HQL test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        LOG.info( "Starting HQL filter tests" );
+        log.info( "Starting HQL filter tests" );
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "region" ).setParameter( "region", "APAC" );
 
 		session.enableFilter( "effectiveDate" )
 		        .setParameter( "asOfDate", testData.lastMonth.getTime() );
 
-        LOG.info( "HQL against Salesperson..." );
+        log.info( "HQL against Salesperson..." );
 		List results = session.createQuery( "select s from Salesperson as s left join fetch s.orders" ).list();
 		assertTrue( "Incorrect filtered HQL result count [" + results.size() + "]", results.size() == 1 );
 		Salesperson result = ( Salesperson ) results.get( 0 );
 		assertTrue( "Incorrect collectionfilter count", result.getOrders().size() == 1 );
 
-        LOG.info( "HQL against Product..." );
+        log.info( "HQL against Product..." );
 		results = session.createQuery( "from Product as p where p.stockNumber = ?" ).setInteger( 0, 124 ).list();
 		assertTrue( results.size() == 1 );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testFiltersWithCustomerReadAndWrite() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Custom SQL read/write with filter
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        LOG.info("Starting HQL filter with custom SQL get/set tests");
+        log.info("Starting HQL filter with custom SQL get/set tests");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "heavyProducts" ).setParameter("weightKilograms", 4d);
-        LOG.info( "HQL against Product..." );
+        log.info( "HQL against Product..." );
 		List results = session.createQuery( "from Product").list();
 		assertEquals( 1, results.size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testCriteriaQueryFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Criteria-query test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        LOG.info("Starting Criteria-query filter tests");
+        log.info("Starting Criteria-query filter tests");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "region" ).setParameter( "region", "APAC" );
 
 		session.enableFilter( "fulfilledOrders" )
 		        .setParameter( "asOfDate", testData.lastMonth.getTime() );
 
 		session.enableFilter( "effectiveDate" )
 		        .setParameter( "asOfDate", testData.lastMonth.getTime() );
 
-        LOG.info("Criteria query against Salesperson...");
+        log.info("Criteria query against Salesperson...");
 		List salespersons = session.createCriteria( Salesperson.class )
 		        .setFetchMode( "orders", FetchMode.JOIN )
 		        .list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 		assertEquals( "Incorrect order count", 1, ( ( Salesperson ) salespersons.get( 0 ) ).getOrders().size() );
 
-        LOG.info("Criteria query against Product...");
+        log.info("Criteria query against Product...");
 		List products = session.createCriteria( Product.class )
 		        .add( Restrictions.eq( "stockNumber", 124 ) )
 		        .list();
 		assertEquals( "Incorrect product count", 1, products.size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testCriteriaControl() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		// the subquery...
 		DetachedCriteria subquery = DetachedCriteria.forClass( Salesperson.class )
 				.setProjection( Property.forName( "name" ) );
 
 		Session session = openSession();
 		session.beginTransaction();
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] {"APAC"} );
 
 		List result = session.createCriteria( Order.class )
 				.add( Subqueries.in( "steve", subquery ) )
 				.list();
 		assertEquals( 1, result.size() );
 
 		session.getTransaction().commit();
 		session.close();
 
 		testData.release();
 	}
 
 	@Test
 	public void testCriteriaSubqueryWithFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Criteria-subquery test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        LOG.info("Starting Criteria-subquery filter tests");
+        log.info("Starting Criteria-subquery filter tests");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter("region").setParameter("region", "APAC");
 
-        LOG.info("Criteria query against Department with a subquery on Salesperson in the APAC reqion...");
+        log.info("Criteria query against Department with a subquery on Salesperson in the APAC reqion...");
 		DetachedCriteria salespersonSubquery = DetachedCriteria.forClass(Salesperson.class)
 				.add(Restrictions.eq("name", "steve"))
 				.setProjection(Property.forName("department"));
 
 		Criteria departmentsQuery = session.createCriteria(Department.class).add(Subqueries.propertyIn("id", salespersonSubquery));
 		List departments = departmentsQuery.list();
 
 		assertEquals("Incorrect department count", 1, departments.size());
 
-        LOG.info("Criteria query against Department with a subquery on Salesperson in the FooBar reqion...");
+        log.info("Criteria query against Department with a subquery on Salesperson in the FooBar reqion...");
 
 		session.enableFilter("region").setParameter("region", "Foobar");
 		departments = departmentsQuery.list();
 
 		assertEquals("Incorrect department count", 0, departments.size());
 
-        LOG.info("Criteria query against Order with a subquery for line items with a subquery on product and sold by a given sales person...");
+        log.info("Criteria query against Order with a subquery for line items with a subquery on product and sold by a given sales person...");
 		session.enableFilter("region").setParameter("region", "APAC");
 
 		DetachedCriteria lineItemSubquery = DetachedCriteria.forClass(LineItem.class)
 				.add( Restrictions.ge( "quantity", 1L ) )
 				.createCriteria( "product" )
 				.add( Restrictions.eq( "name", "Acme Hair Gel" ) )
 				.setProjection( Property.forName( "id" ) );
 
 		List orders = session.createCriteria(Order.class)
 				.add(Subqueries.exists(lineItemSubquery))
 				.add(Restrictions.eq("buyer", "gavin"))
 				.list();
 
 		assertEquals("Incorrect orders count", 1, orders.size());
 
-        LOG.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month");
+        log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month");
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.lastMonth.getTime());
 
 		DetachedCriteria productSubquery = DetachedCriteria.forClass(Product.class)
 				.add(Restrictions.eq("name", "Acme Hair Gel"))
 				.setProjection(Property.forName("id"));
 
 		lineItemSubquery = DetachedCriteria.forClass(LineItem.class)
 				.add(Restrictions.ge("quantity", 1L ))
 				.createCriteria("product")
 				.add(Subqueries.propertyIn("id", productSubquery))
 				.setProjection(Property.forName("id"));
 
 		orders = session.createCriteria(Order.class)
 				.add(Subqueries.exists(lineItemSubquery))
 				.add(Restrictions.eq("buyer", "gavin"))
 				.list();
 
 		assertEquals("Incorrect orders count", 1, orders.size());
 
 
-        LOG.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of 4 months ago");
+        log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of 4 months ago");
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.fourMonthsAgo.getTime());
 
 		orders = session.createCriteria(Order.class)
 				.add(Subqueries.exists(lineItemSubquery))
 				.add(Restrictions.eq("buyer", "gavin"))
 				.list();
 
 		assertEquals("Incorrect orders count", 0, orders.size());
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testHQLSubqueryWithFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// HQL subquery with filters test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        LOG.info("Starting HQL subquery with filters tests");
+        log.info("Starting HQL subquery with filters tests");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter("region").setParameter("region", "APAC");
 
-        LOG.info("query against Department with a subquery on Salesperson in the APAC reqion...");
+        log.info("query against Department with a subquery on Salesperson in the APAC reqion...");
 
 		List departments = session.createQuery(
 				"select d from Department as d where d.id in (select s.department from Salesperson s where s.name = ?)"
 		).setString( 0, "steve" ).list();
 
 		assertEquals("Incorrect department count", 1, departments.size());
 
-        LOG.info("query against Department with a subquery on Salesperson in the FooBar reqion...");
+        log.info("query against Department with a subquery on Salesperson in the FooBar reqion...");
 
 		session.enableFilter("region").setParameter( "region", "Foobar" );
 		departments = session.createQuery("select d from Department as d where d.id in (select s.department from Salesperson s where s.name = ?)").setString(0, "steve").list();
 
 		assertEquals( "Incorrect department count", 0, departments.size() );
 
-        LOG.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region for a given buyer");
+        log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region for a given buyer");
 		session.enableFilter("region").setParameter( "region", "APAC" );
 
 		List orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li, Product as p where p.id = li.product and li.quantity >= ? and p.name = ?) and o.buyer = ?")
 				.setLong(0, 1L).setString(1, "Acme Hair Gel").setString(2, "gavin").list();
 
 		assertEquals( "Incorrect orders count", 1, orders.size() );
 
-        LOG.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month");
+        log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month");
 
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter( "asOfDate", testData.lastMonth.getTime() );
 
 		orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li where li.quantity >= ? and li.product in (select p.id from Product p where p.name = ?)) and o.buyer = ?")
 				.setLong(0, 1L).setString(1, "Acme Hair Gel").setString(2, "gavin").list();
 
 		assertEquals( "Incorrect orders count", 1, orders.size() );
 
 
-        LOG.info(
+        log.info(
 				"query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of 4 months ago"
 		);
 
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.fourMonthsAgo.getTime());
 
 		orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li where li.quantity >= ? and li.product in (select p.id from Product p where p.name = ?)) and o.buyer = ?")
 				.setLong( 0, 1L ).setString( 1, "Acme Hair Gel" ).setString( 2, "gavin" ).list();
 
 		assertEquals("Incorrect orders count", 0, orders.size());
 
-        LOG.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month with named types");
+        log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month with named types");
 
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.lastMonth.getTime());
 
 		orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li where li.quantity >= :quantity and li.product in (select p.id from Product p where p.name = :name)) and o.buyer = :buyer")
 				.setLong("quantity", 1L).setString("name", "Acme Hair Gel").setString("buyer", "gavin").list();
 
 		assertEquals("Incorrect orders count", 1, orders.size());
 
-        LOG.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month with mixed types");
+        log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month with mixed types");
 
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.lastMonth.getTime());
 
 		orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li where li.quantity >= ? and li.product in (select p.id from Product p where p.name = ?)) and o.buyer = :buyer")
 				.setLong( 0, 1L ).setString( 1, "Acme Hair Gel" ).setString( "buyer", "gavin" ).list();
 
 		assertEquals("Incorrect orders count", 1, orders.size());
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testFilterApplicationOnHqlQueryWithImplicitSubqueryContainingPositionalParameter() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.beginTransaction();
 
 		final String queryString = "from Order o where ? in ( select sp.name from Salesperson sp )";
 
 		// first a control-group query
 		List result = session.createQuery( queryString ).setParameter( 0, "steve" ).list();
 		assertEquals( 2, result.size() );
 
 		// now lets enable filters on Order...
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		result = session.createQuery( queryString ).setParameter( 0, "steve" ).list();
 		assertEquals( 1, result.size() );
 
 		// now, lets additionally enable filter on Salesperson.  First a valid one...
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] { "APAC" } );
 		result = session.createQuery( queryString ).setParameter( 0, "steve" ).list();
 		assertEquals( 1, result.size() );
 
 		// ... then a silly one...
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] { "gamma quadrant" } );
 		result = session.createQuery( queryString ).setParameter( 0, "steve" ).list();
 		assertEquals( 0, result.size() );
 
 		session.getTransaction().commit();
 		session.close();
 
 		testData.release();
 	}
 
 	@Test
 	public void testFilterApplicationOnHqlQueryWithImplicitSubqueryContainingNamedParameter() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.beginTransaction();
 
 		final String queryString = "from Order o where :salesPersonName in ( select sp.name from Salesperson sp )";
 
 		// first a control-group query
 		List result = session.createQuery( queryString ).setParameter( "salesPersonName", "steve" ).list();
 		assertEquals( 2, result.size() );
 
 		// now lets enable filters on Order...
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		result = session.createQuery( queryString ).setParameter( "salesPersonName", "steve" ).list();
 		assertEquals( 1, result.size() );
 
 		// now, lets additionally enable filter on Salesperson.  First a valid one...
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] { "APAC" } );
 		result = session.createQuery( queryString ).setParameter( "salesPersonName", "steve" ).list();
 		assertEquals( 1, result.size() );
 
 		// ... then a silly one...
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] { "gamma quadrant" } );
 		result = session.createQuery( queryString ).setParameter( "salesPersonName", "steve" ).list();
 		assertEquals( 0, result.size() );
 
 		session.getTransaction().commit();
 		session.close();
 
 		testData.release();
 	}
 
 	@Test
 	public void testFiltersOnSimpleHqlDelete() {
 		Session session = openSession();
 		session.beginTransaction();
 		Salesperson sp = new Salesperson();
 		sp.setName( "steve" );
 		sp.setRegion( "NA" );
 		session.persist( sp );
 		Salesperson sp2 = new Salesperson();
 		sp2.setName( "john" );
 		sp2.setRegion( "APAC" );
 		session.persist( sp2 );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		session.enableFilter( "region" ).setParameter( "region", "NA" );
 		int count = session.createQuery( "delete from Salesperson" ).executeUpdate();
 		assertEquals( 1, count );
 		session.delete( sp2 );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testFiltersOnMultiTableHqlDelete() {
 		Session session = openSession();
 		session.beginTransaction();
 		Salesperson sp = new Salesperson();
 		sp.setName( "steve" );
 		sp.setRegion( "NA" );
 		session.persist( sp );
 		Salesperson sp2 = new Salesperson();
 		sp2.setName( "john" );
 		sp2.setRegion( "APAC" );
 		session.persist( sp2 );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		session.enableFilter( "region" ).setParameter( "region", "NA" );
 		int count = session.createQuery( "delete from Salesperson" ).executeUpdate();
 		assertEquals( 1, count );
 		session.delete( sp2 );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testGetFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Get() test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        LOG.info("Starting get() filter tests (eager assoc. fetching).");
+        log.info("Starting get() filter tests (eager assoc. fetching).");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "region" ).setParameter( "region", "APAC" );
 
-        LOG.info("Performing get()...");
+        log.info("Performing get()...");
 		Salesperson salesperson = ( Salesperson ) session.get( Salesperson.class, testData.steveId );
 		assertNotNull( salesperson );
 		assertEquals( "Incorrect order count", 1, salesperson.getOrders().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testOneToManyFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// one-to-many loading tests
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        LOG.info("Starting one-to-many collection loader filter tests.");
+        log.info("Starting one-to-many collection loader filter tests.");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "seniorSalespersons" )
 		        .setParameter( "asOfDate", testData.lastMonth.getTime() );
 
-        LOG.info("Performing load of Department...");
+        log.info("Performing load of Department...");
 		Department department = ( Department ) session.load( Department.class, testData.deptId );
 		Set salespersons = department.getSalespersons();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testInStyleFilterParameter() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// one-to-many loading tests
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        LOG.info("Starting one-to-many collection loader filter tests.");
+        log.info("Starting one-to-many collection loader filter tests.");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "regionlist" )
 		        .setParameterList( "regions", new String[]{"LA", "APAC"} );
 
-        LOG.debug("Performing query of Salespersons");
+        log.debug("Performing query of Salespersons");
 		List salespersons = session.createQuery( "from Salesperson" ).list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyFilterOnCriteria() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "effectiveDate" ).setParameter( "asOfDate", new Date() );
 
 		Product prod = ( Product ) session.createCriteria( Product.class )
 		        .setResultTransformer( DistinctRootEntityResultTransformer.INSTANCE )
 		        .add( Restrictions.eq( "id", testData.prod1Id ) )
 		        .uniqueResult();
 
 		assertNotNull( prod );
 		assertEquals( "Incorrect Product.categories count for filter", 1, prod.getCategories().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyFilterOnLoad() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "effectiveDate" ).setParameter( "asOfDate", new Date() );
 
 		Product prod = ( Product ) session.get( Product.class, testData.prod1Id );
 
 		long initLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long initFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		// should already have been initialized...
 		int size = prod.getCategories().size();
 		assertEquals( "Incorrect filtered collection count", 1, size );
 
 		long currLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long currFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger join fetch",
 		        ( initLoadCount == currLoadCount ) && ( initFetchCount == currFetchCount )
 		);
 
 		// make sure we did not get back a collection of proxies
 		long initEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 		Iterator itr = prod.getCategories().iterator();
 		while ( itr.hasNext() ) {
 			Category cat = ( Category ) itr.next();
 			System.out.println( " ===> " + cat.getName() );
 		}
 		long currEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger *complete* join fetch",
 		        ( initEntityLoadCount == currEntityLoadCount )
 		);
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyOnCollectionLoadAfterHQL() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "effectiveDate" ).setParameter( "asOfDate", new Date() );
 
 		// Force the categories to not get initialized here
 		List result = session.createQuery( "from Product as p where p.id = :id" )
 		        .setLong( "id", testData.prod1Id )
 		        .list();
 		assertTrue( "No products returned from HQL", !result.isEmpty() );
 
 		Product prod = ( Product ) result.get( 0 );
 		assertNotNull( prod );
 		assertEquals( "Incorrect Product.categories count for filter on collection load", 1, prod.getCategories().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyFilterOnQuery() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "effectiveDate" ).setParameter( "asOfDate", new Date() );
 
 		List result = session.createQuery( "from Product p inner join fetch p.categories" ).list();
 		assertTrue( "No products returned from HQL many-to-many filter case", !result.isEmpty() );
 
 		Product prod = ( Product ) result.get( 0 );
 
 		assertNotNull( prod );
 		assertEquals( "Incorrect Product.categories count for filter with HQL", 1, prod.getCategories().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyBase() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 
 		Product prod = ( Product ) session.get( Product.class, testData.prod1Id );
 
 		long initLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long initFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		// should already have been initialized...
 		int size = prod.getCategories().size();
 		assertEquals( "Incorrect non-filtered collection count", 2, size );
 
 		long currLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long currFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger join fetch",
 		        ( initLoadCount == currLoadCount ) && ( initFetchCount == currFetchCount )
 		);
 
 		// make sure we did not get back a collection of proxies
 		long initEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 		Iterator itr = prod.getCategories().iterator();
 		while ( itr.hasNext() ) {
 			Category cat = ( Category ) itr.next();
 			System.out.println( " ===> " + cat.getName() );
 		}
 		long currEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger *complete* join fetch",
 		        ( initEntityLoadCount == currEntityLoadCount )
 		);
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyBaseThruCriteria() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 
 		List result = session.createCriteria( Product.class )
 		        .add( Restrictions.eq( "id", testData.prod1Id ) )
 		        .list();
 
 		Product prod = ( Product ) result.get( 0 );
 
 		long initLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long initFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		// should already have been initialized...
 		int size = prod.getCategories().size();
 		assertEquals( "Incorrect non-filtered collection count", 2, size );
 
 		long currLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long currFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger join fetch",
 		        ( initLoadCount == currLoadCount ) && ( initFetchCount == currFetchCount )
 		);
 
 		// make sure we did not get back a collection of proxies
 		long initEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 		Iterator itr = prod.getCategories().iterator();
 		while ( itr.hasNext() ) {
 			Category cat = ( Category ) itr.next();
 			System.out.println( " ===> " + cat.getName() );
 		}
 		long currEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger *complete* join fetch",
 		        ( initEntityLoadCount == currEntityLoadCount )
 		);
 
 		session.close();
 		testData.release();
 	}
 
 	private class TestData {
 		private Long steveId;
 		private Long deptId;
 		private Long prod1Id;
 		private Calendar lastMonth;
 		private Calendar nextMonth;
 		private Calendar sixMonthsAgo;
 		private Calendar fourMonthsAgo;
 
 		private List entitiesToCleanUp = new ArrayList();
 
 		private void prepare() {
 			Session session = openSession();
 			Transaction transaction = session.beginTransaction();
 
 			lastMonth = new GregorianCalendar();
 			lastMonth.add( Calendar.MONTH, -1 );
 
 			nextMonth = new GregorianCalendar();
 			nextMonth.add( Calendar.MONTH, 1 );
 
 			sixMonthsAgo = new GregorianCalendar();
 			sixMonthsAgo.add( Calendar.MONTH, -6 );
 
 			fourMonthsAgo = new GregorianCalendar();
 			fourMonthsAgo.add( Calendar.MONTH, -4 );
 
 			Department dept = new Department();
 			dept.setName( "Sales" );
 
 			session.save( dept );
 			deptId = dept.getId();
 			entitiesToCleanUp.add( dept );
 
 			Salesperson steve = new Salesperson();
 			steve.setName( "steve" );
 			steve.setRegion( "APAC" );
 			steve.setHireDate( sixMonthsAgo.getTime() );
 
 			steve.setDepartment( dept );
 			dept.getSalespersons().add( steve );
 
 			Salesperson max = new Salesperson();
 			max.setName( "max" );
 			max.setRegion( "EMEA" );
 			max.setHireDate( nextMonth.getTime() );
 
 			max.setDepartment( dept );
 			dept.getSalespersons().add( max );
 
 			session.save( steve );
 			session.save( max );
 			entitiesToCleanUp.add( steve );
 			entitiesToCleanUp.add( max );
 
 			steveId = steve.getId();
 
 			Category cat1 = new Category( "test cat 1", lastMonth.getTime(), nextMonth.getTime() );
 			Category cat2 = new Category( "test cat 2", sixMonthsAgo.getTime(), fourMonthsAgo.getTime() );
 
 			Product product1 = new Product();
 			product1.setName( "Acme Hair Gel" );
 			product1.setStockNumber( 123 );
 			product1.setWeightPounds( 0.25 );
 			product1.setEffectiveStartDate( lastMonth.getTime() );
 			product1.setEffectiveEndDate( nextMonth.getTime() );
 
 			product1.addCategory( cat1 );
 			product1.addCategory( cat2 );
 
 			session.save( product1 );
 			entitiesToCleanUp.add( product1 );
 			prod1Id = product1.getId();
 
 			Order order1 = new Order();
 			order1.setBuyer( "gavin" );
 			order1.setRegion( "APAC" );
 			order1.setPlacementDate( sixMonthsAgo.getTime() );
 			order1.setFulfillmentDate( fourMonthsAgo.getTime() );
 			order1.setSalesperson( steve );
 			order1.addLineItem( product1, 500 );
 
 			session.save( order1 );
 			entitiesToCleanUp.add( order1 );
 
 			Product product2 = new Product();
 			product2.setName( "Acme Super-Duper DTO Factory" );
 			product2.setStockNumber( 124 );
 			product1.setWeightPounds( 10.0 );
 			product2.setEffectiveStartDate( sixMonthsAgo.getTime() );
 			product2.setEffectiveEndDate( new Date() );
 
 			Category cat3 = new Category( "test cat 2", sixMonthsAgo.getTime(), new Date() );
 			product2.addCategory( cat3 );
 
 			session.save( product2 );
 			entitiesToCleanUp.add( product2 );
 
 			// An uncategorized product
 			Product product3 = new Product();
 			product3.setName( "Uncategorized product" );
 			session.save( product3 );
 			entitiesToCleanUp.add( product3 );
 
 			Order order2 = new Order();
 			order2.setBuyer( "christian" );
 			order2.setRegion( "EMEA" );
 			order2.setPlacementDate( lastMonth.getTime() );
 			order2.setSalesperson( steve );
 			order2.addLineItem( product2, -1 );
 
 			session.save( order2 );
 			entitiesToCleanUp.add( order2 );
 
 			transaction.commit();
 			session.close();
 		}
 
 		private void release() {
 			Session session = openSession();
 			Transaction transaction = session.beginTransaction();
 
 			Iterator itr = entitiesToCleanUp.iterator();
 			while ( itr.hasNext() ) {
 				session.delete( itr.next() );
 			}
 
 			transaction.commit();
 			session.close();
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/hql/ASTParserLoadingTest.java b/hibernate-core/src/test/java/org/hibernate/test/hql/ASTParserLoadingTest.java
index 9bba8f3df6..2432bd9931 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/hql/ASTParserLoadingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/hql/ASTParserLoadingTest.java
@@ -1,1401 +1,1404 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.hql;
 
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.sql.Date;
 import java.sql.Time;
 import java.sql.Timestamp;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.DB2Dialect;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.IngresDialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.dialect.PostgreSQLDialect;
 import org.hibernate.dialect.SQLServerDialect;
 import org.hibernate.dialect.Sybase11Dialect;
 import org.hibernate.dialect.SybaseASE15Dialect;
 import org.hibernate.dialect.SybaseAnywhereDialect;
 import org.hibernate.dialect.SybaseDialect;
 import org.hibernate.hql.ast.ASTQueryTranslatorFactory;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.entity.DiscriminatorType;
 import org.hibernate.stat.QueryStatistics;
 import org.hibernate.transform.DistinctRootEntityResultTransformer;
 import org.hibernate.transform.Transformers;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.ManyToOneType;
 import org.hibernate.type.Type;
 
-import static org.hibernate.testing.TestLogger.LOG;
-import static org.hibernate.testing.junit4.ExtraAssertions.assertClassAssignability;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertSame;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
-
 import org.junit.Test;
 
 import org.hibernate.testing.DialectChecks;
 import org.hibernate.testing.FailureExpected;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.any.IntegerPropertyValue;
 import org.hibernate.test.any.PropertySet;
 import org.hibernate.test.any.PropertyValue;
 import org.hibernate.test.any.StringPropertyValue;
 import org.hibernate.test.cid.Customer;
 import org.hibernate.test.cid.LineItem;
 import org.hibernate.test.cid.LineItem.Id;
 import org.hibernate.test.cid.Order;
 import org.hibernate.test.cid.Product;
 
+import static org.hibernate.testing.junit4.ExtraAssertions.assertClassAssignability;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertSame;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
 /**
  * Tests the integration of the new AST parser into the loading of query results using
  * the Hibernate persisters and loaders.
  * <p/>
  * Also used to test the syntax of the resulting sql against the underlying
  * database, specifically for functionality not supported by the classic
  * parser.
  *
  * @author Steve
  */
 public class ASTParserLoadingTest extends BaseCoreFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( ASTParserLoadingTest.class );
+
 	private List<Long> createdAnimalIds = new ArrayList<Long>();
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 				"hql/Animal.hbm.xml",
 				"hql/FooBarCopy.hbm.xml",
 				"hql/SimpleEntityWithAssociation.hbm.xml",
 				"hql/CrazyIdFieldNames.hbm.xml",
 				"hql/Image.hbm.xml",
 				"hql/ComponentContainer.hbm.xml",
 				"hql/VariousKeywordPropertyEntity.hbm.xml",
 				"batchfetch/ProductLine.hbm.xml",
 				"cid/Customer.hbm.xml",
 				"cid/Order.hbm.xml",
 				"cid/LineItem.hbm.xml",
 				"cid/Product.hbm.xml",
 				"any/Properties.hbm.xml",
 				"legacy/Commento.hbm.xml",
 				"legacy/Marelo.hbm.xml"
 		};
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.USE_QUERY_CACHE, "true" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.QUERY_TRANSLATOR, ASTQueryTranslatorFactory.class.getName() );
 	}
 
 	@Test
 	public void testSubSelectAsArithmeticOperand() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		// first a control
 		s.createQuery( "from Zoo z where ( select count(*) from Zoo ) = 0" ).list();
 
 		// now as operands singly:
 		s.createQuery( "from Zoo z where ( select count(*) from Zoo ) + 0 = 0" ).list();
 		s.createQuery( "from Zoo z where 0 + ( select count(*) from Zoo ) = 0" ).list();
 
 		// and doubly:
 		s.createQuery( "from Zoo z where ( select count(*) from Zoo ) + ( select count(*) from Zoo ) = 0" ).list();
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testJpaTypeOperator() {
 		// just checking syntax here...
 		Session s = openSession();
 		s.beginTransaction();
 
 		///////////////////////////////////////////////////////////////
 		// where clause
 		// control
 		s.createQuery( "from Animal a where a.class = Dog" ).list();
         // test
 		s.createQuery( "from Animal a where type(a) = Dog" ).list();
 
 		///////////////////////////////////////////////////////////////
 		// select clause (at some point we should unify these)
 		// control
 		Query query = s.createQuery( "select a.class from Animal a where a.class = Dog" );
 		query.list(); // checks syntax
 		assertEquals( 1, query.getReturnTypes().length );
 		assertEquals( Integer.class, query.getReturnTypes()[0].getReturnedClass() ); // always integer for joined
         // test
 		query = s.createQuery( "select type(a) from Animal a where type(a) = Dog" );
 		query.list(); // checks syntax
 		assertEquals( 1, query.getReturnTypes().length );
 		assertEquals( DiscriminatorType.class, query.getReturnTypes()[0].getClass() );
 		assertEquals( Class.class, query.getReturnTypes()[0].getReturnedClass() );
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testComponentJoins() {
 		Session s = openSession();
 		s.beginTransaction();
 		ComponentContainer root = new ComponentContainer(
 				new ComponentContainer.Address(
 						"123 Main",
 						"Anywhere",
 						"USA",
 						new ComponentContainer.Address.Zip( 12345, 6789 )
 				)
 		);
 		s.save( root );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List result = s.createQuery( "select a from ComponentContainer c join c.address a" ).list();
 		assertEquals( 1, result.size() );
 		assertTrue( ComponentContainer.Address.class.isInstance( result.get( 0 ) ) );
 
 		result = s.createQuery( "select a.zip from ComponentContainer c join c.address a" ).list();
 		assertEquals( 1, result.size() );
 		assertTrue( ComponentContainer.Address.Zip.class.isInstance( result.get( 0 ) ) );
 
 		result = s.createQuery( "select z from ComponentContainer c join c.address a join a.zip z" ).list();
 		assertEquals( 1, result.size() );
 		assertTrue( ComponentContainer.Address.Zip.class.isInstance( result.get( 0 ) ) );
 
 		result = s.createQuery( "select z.code from ComponentContainer c join c.address a join a.zip z" ).list();
 		assertEquals( 1, result.size() );
 		assertTrue( Integer.class.isInstance( result.get( 0 ) ) );
 		s.delete( root );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testJPAQLQualifiedIdentificationVariablesControl() {
 		// just checking syntax here...
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from VariousKeywordPropertyEntity where type = 'something'" ).list();
 		s.createQuery( "from VariousKeywordPropertyEntity where value = 'something'" ).list();
 		s.createQuery( "from VariousKeywordPropertyEntity where key = 'something'" ).list();
 		s.createQuery( "from VariousKeywordPropertyEntity where entry = 'something'" ).list();
 
 		s.createQuery( "from VariousKeywordPropertyEntity e where e.type = 'something'" ).list();
 		s.createQuery( "from VariousKeywordPropertyEntity e where e.value = 'something'" ).list();
 		s.createQuery( "from VariousKeywordPropertyEntity e where e.key = 'something'" ).list();
 		s.createQuery( "from VariousKeywordPropertyEntity e where e.entry = 'something'" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testJPAQLQualifiedIdentificationVariables() {
 		Session s = openSession();
 		s.beginTransaction();
 		Human me = new Human();
 		me.setName( new Name( "Steve", null, "Ebersole" ) );
 		Human joe = new Human();
 		me.setName( new Name( "Joe", null, "Ebersole" ) );
 		me.setFamily( new HashMap() );
 		me.getFamily().put( "son", joe );
 		s.save( me );
 		s.save( joe );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List results = s.createQuery( "select entry(h.family) from Human h" ).list();
 		assertEquals( 1, results.size() );
 		Object result = results.get(0);
 		assertTrue( Map.Entry.class.isAssignableFrom( result.getClass() ) );
 		Map.Entry entry = (Map.Entry) result;
 		assertTrue( String.class.isAssignableFrom( entry.getKey().getClass() ) );
 		assertTrue( Human.class.isAssignableFrom( entry.getValue().getClass() ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		results = s.createQuery( "select distinct key(h.family) from Human h" ).list();
 		assertEquals( 1, results.size() );
 		Object key = results.get(0);
 		assertTrue( String.class.isAssignableFrom( key.getClass() ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( me );
 		s.delete( joe );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SkipForDialect(
 			value = IngresDialect.class,
 			jiraKey = "HHH-4961",
 			comment = "Ingres does not support this scoping in 9.3"
 	)
 	public void testPaginationWithPolymorphicQuery() {
 		Session s = openSession();
 		s.beginTransaction();
 		Human h = new Human();
 		h.setName( new Name( "Steve", null, "Ebersole" ) );
 		s.save( h );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List results = s.createQuery( "from java.lang.Object" ).setMaxResults( 2 ).list();
 		assertEquals( 1, results.size() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( h );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testComponentNullnessChecks() {
 		Session s = openSession();
 		s.beginTransaction();
 		Human h = new Human();
 		h.setName( new Name( "Johnny", 'B', "Goode" ) );
 		s.save( h );
 		h = new Human();
 		h.setName( new Name( "Steve", null, "Ebersole" ) );
 		s.save( h );
 		h = new Human();
 		h.setName( new Name( "Bono", null, null ) );
 		s.save( h );
 		h = new Human();
 		h.setName( new Name( null, null, null ) );
 		s.save( h );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List results = s.createQuery( "from Human where name is null" ).list();
 		assertEquals( 1, results.size() );
 		results = s.createQuery( "from Human where name is not null" ).list();
 		assertEquals( 3, results.size() );
 		String query =
 				( getDialect() instanceof DB2Dialect || getDialect() instanceof HSQLDialect ) ?
 						"from Human where cast(? as string) is null" :
 						"from Human where ? is null"
 				;
 		s.createQuery( query ).setParameter( 0, null ).list();
 
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.createQuery( "delete Human" ).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testInvalidCollectionDereferencesFail() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		// control group...
 		s.createQuery( "from Animal a join a.offspring o where o.description = 'xyz'" ).list();
 		s.createQuery( "from Animal a join a.offspring o where o.father.description = 'xyz'" ).list();
 		s.createQuery( "from Animal a join a.offspring o order by o.description" ).list();
 		s.createQuery( "from Animal a join a.offspring o order by o.father.description" ).list();
 
 		try {
 			s.createQuery( "from Animal a where a.offspring.description = 'xyz'" ).list();
 			fail( "illegal collection dereference semantic did not cause failure" );
 		}
 		catch( QueryException qe ) {
-            LOG.trace("expected failure...", qe);
+            log.trace("expected failure...", qe);
 		}
 
 		try {
 			s.createQuery( "from Animal a where a.offspring.father.description = 'xyz'" ).list();
 			fail( "illegal collection dereference semantic did not cause failure" );
 		}
 		catch( QueryException qe ) {
-            LOG.trace("expected failure...", qe);
+            log.trace("expected failure...", qe);
 		}
 
 		try {
 			s.createQuery( "from Animal a order by a.offspring.description" ).list();
 			fail( "illegal collection dereference semantic did not cause failure" );
 		}
 		catch( QueryException qe ) {
-            LOG.trace("expected failure...", qe);
+            log.trace("expected failure...", qe);
 		}
 
 		try {
 			s.createQuery( "from Animal a order by a.offspring.father.description" ).list();
 			fail( "illegal collection dereference semantic did not cause failure" );
 		}
 		catch( QueryException qe ) {
-            LOG.trace("expected failure...", qe);
+            log.trace("expected failure...", qe);
 		}
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testConcatenation() {
 		// simple syntax checking...
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Human h where h.nickName = '1' || 'ov' || 'tha' || 'few'" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testExpressionWithParamInFunction() {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Animal a where abs(a.bodyWeight-:param) < 2.0" ).setLong( "param", 1 ).list();
 		s.createQuery( "from Animal a where abs(:param - a.bodyWeight) < 2.0" ).setLong( "param", 1 ).list();
 		if ( ( getDialect() instanceof HSQLDialect ) || ( getDialect() instanceof DB2Dialect ) ) {
 			// HSQLDB and DB2 don't like the abs(? - ?) syntax. bit work if at least one parameter is typed...
 			s.createQuery( "from Animal where abs(cast(:x as long) - :y) < 2.0" ).setLong( "x", 1 ).setLong( "y", 1 ).list();
 			s.createQuery( "from Animal where abs(:x - cast(:y as long)) < 2.0" ).setLong( "x", 1 ).setLong( "y", 1 ).list();
 			s.createQuery( "from Animal where abs(cast(:x as long) - cast(:y as long)) < 2.0" ).setLong( "x", 1 ).setLong( "y", 1 ).list();
 		}
 		else {
 			s.createQuery( "from Animal where abs(:x - :y) < 2.0" ).setLong( "x", 1 ).setLong( "y", 1 ).list();
 		}
 
 		if ( getDialect() instanceof DB2Dialect ) {
 			s.createQuery( "from Animal where lower(upper(cast(:foo as string))) like 'f%'" ).setString( "foo", "foo" ).list();
 		}
 		else {
 			s.createQuery( "from Animal where lower(upper(:foo)) like 'f%'" ).setString( "foo", "foo" ).list();
 		}
 		s.createQuery( "from Animal a where abs(abs(a.bodyWeight - 1.0 + :param) * abs(length('ffobar')-3)) = 3.0" ).setLong(
 				"param", 1
 		).list();
 		if ( getDialect() instanceof DB2Dialect ) {
 			s.createQuery( "from Animal where lower(upper('foo') || upper(cast(:bar as string))) like 'f%'" ).setString( "bar", "xyz" ).list();
 		}
 		else {
 			s.createQuery( "from Animal where lower(upper('foo') || upper(:bar)) like 'f%'" ).setString( "bar", "xyz" ).list();
 		}
 		if ( ! ( getDialect() instanceof PostgreSQLDialect || getDialect() instanceof MySQLDialect ) ) {
 			s.createQuery( "from Animal where abs(cast(1 as float) - cast(:param as float)) = 1.0" ).setLong( "param", 1 ).list();
 		}
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCrazyIdFieldNames() {
 		MoreCrazyIdFieldNameStuffEntity top = new MoreCrazyIdFieldNameStuffEntity( "top" );
 		HeresAnotherCrazyIdFieldName next = new HeresAnotherCrazyIdFieldName( "next" );
 		top.setHeresAnotherCrazyIdFieldName( next );
 		MoreCrazyIdFieldNameStuffEntity other = new MoreCrazyIdFieldNameStuffEntity( "other" );
 		Session s = openSession();
 		s.beginTransaction();
 		s.save( next );
 		s.save( top );
 		s.save( other );
 		s.flush();
 
 		List results = s.createQuery( "select e.heresAnotherCrazyIdFieldName from MoreCrazyIdFieldNameStuffEntity e where e.heresAnotherCrazyIdFieldName is not null" ).list();
 		assertEquals( 1, results.size() );
 		Object result = results.get( 0 );
 		assertClassAssignability( HeresAnotherCrazyIdFieldName.class, result.getClass() );
 		assertSame( next, result );
 
 		results = s.createQuery( "select e.heresAnotherCrazyIdFieldName.heresAnotherCrazyIdFieldName from MoreCrazyIdFieldNameStuffEntity e where e.heresAnotherCrazyIdFieldName is not null" ).list();
 		assertEquals( 1, results.size() );
 		result = results.get( 0 );
 		assertClassAssignability( Long.class, result.getClass() );
 		assertEquals( next.getHeresAnotherCrazyIdFieldName(), result );
 
 		results = s.createQuery( "select e.heresAnotherCrazyIdFieldName from MoreCrazyIdFieldNameStuffEntity e" ).list();
 		assertEquals( 1, results.size() );
 		Iterator itr = s.createQuery( "select e.heresAnotherCrazyIdFieldName from MoreCrazyIdFieldNameStuffEntity e" ).iterate();
 		assertTrue( itr.hasNext() ); itr.next(); assertFalse( itr.hasNext() );
 
 		s.delete( top );
 		s.delete( next );
 		s.delete( other );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-2257" )
 	public void testImplicitJoinsInDifferentClauses() {
 		// both the classic and ast translators output the same syntactically valid sql
 		// for all of these cases; the issue is that shallow (iterate) and
 		// non-shallow (list/scroll) queries return different results because the
 		// shallow skips the inner join which "weeds out" results from the non-shallow queries.
 		// The results were initially different depending upon the clause(s) in which the
 		// implicit join occurred
 		Session s = openSession();
 		s.beginTransaction();
 		SimpleEntityWithAssociation owner = new SimpleEntityWithAssociation( "owner" );
 		SimpleAssociatedEntity e1 = new SimpleAssociatedEntity( "thing one", owner );
 		SimpleAssociatedEntity e2 = new SimpleAssociatedEntity( "thing two" );
 		s.save( e1 );
 		s.save( e2 );
 		s.save( owner );
 		s.getTransaction().commit();
 		s.close();
 
 		checkCounts( "select e.owner from SimpleAssociatedEntity e", 1, "implicit-join in select clause" );
 		checkCounts( "select e.id, e.owner from SimpleAssociatedEntity e", 1, "implicit-join in select clause" );
 
 		// resolved to a "id short cut" when part of the order by clause -> no inner join = no weeding out...
 		checkCounts( "from SimpleAssociatedEntity e order by e.owner", 2, "implicit-join in order-by clause" );
 		// resolved to a "id short cut" when part of the group by clause -> no inner join = no weeding out...
 		checkCounts( "select e.owner.id, count(*) from SimpleAssociatedEntity e group by e.owner", 2, "implicit-join in select and group-by clauses" );
 
 	 	s = openSession();
 		s.beginTransaction();
 		s.delete( e1 );
 		s.delete( e2 );
 		s.delete( owner );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRowValueConstructorSyntaxInInList() {
 		Session s = openSession();
 		s.beginTransaction();
 		Product product = new Product();
 		product.setDescription( "My Product" );
 		product.setNumberAvailable( 10 );
 		product.setPrice( new BigDecimal( 123 ) );
 		product.setProductId( "4321" );
 		s.save( product );
 
 
 		Customer customer = new Customer();
 		customer.setCustomerId( "123456789" );
 		customer.setName( "My customer" );
 		customer.setAddress( "somewhere" );
 		s.save( customer );
 
 		Order order = customer.generateNewOrder( new BigDecimal( 1234 ) );
 		s.save( order );
 
 		LineItem li = order.generateLineItem( product, 5 );
 		s.save( li );
 		product = new Product();
 		product.setDescription( "My Product" );
 		product.setNumberAvailable( 10 );
 		product.setPrice( new BigDecimal( 123 ) );
 		product.setProductId( "1234" );
 		s.save( product );
 		li = order.generateLineItem( product, 10 );
 		s.save( li );
 
 		s.flush();
 		Query query = s.createQuery( "from LineItem l where l.id in (:idList)" );
 		List<Id> list = new ArrayList<Id>();
 		list.add( new Id( "123456789", order.getId().getOrderNumber(), "4321" ) );
 		list.add( new Id( "123456789", order.getId().getOrderNumber(), "1234" ) );
 		query.setParameterList( "idList", list );
 		assertEquals( 2, query.list().size() );
 
 		query = s.createQuery( "from LineItem l where l.id in :idList" );
 		query.setParameterList( "idList", list );
 		assertEquals( 2, query.list().size() );
 
 		s.getTransaction().rollback();
 		s.close();
 
 	}
 
 	private void checkCounts(String hql, int expected, String testCondition) {
 		Session s = openSession();
 		s.beginTransaction();
 		int count = determineCount( s.createQuery( hql ).list().iterator() );
 		assertEquals( "list() [" + testCondition + "]", expected, count );
 		count = determineCount( s.createQuery( hql ).iterate() );
 		assertEquals( "iterate() [" + testCondition + "]", expected, count );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-2257" )
 	public void testImplicitSelectEntityAssociationInShallowQuery() {
 		// both the classic and ast translators output the same syntactically valid sql.
 		// the issue is that shallow and non-shallow queries return different
 		// results because the shallow skips the inner join which "weeds out" results
 		// from the non-shallow queries...
 		Session s = openSession();
 		s.beginTransaction();
 		SimpleEntityWithAssociation owner = new SimpleEntityWithAssociation( "owner" );
 		SimpleAssociatedEntity e1 = new SimpleAssociatedEntity( "thing one", owner );
 		SimpleAssociatedEntity e2 = new SimpleAssociatedEntity( "thing two" );
 		s.save( e1 );
 		s.save( e2 );
 		s.save( owner );
 		s.getTransaction().commit();
 		s.close();
 
 	 	s = openSession();
 		s.beginTransaction();
 		int count = determineCount( s.createQuery( "select e.id, e.owner from SimpleAssociatedEntity e" ).list().iterator() );
 		assertEquals( 1, count ); // thing two would be removed from the result due to the inner join
 		count = determineCount( s.createQuery( "select e.id, e.owner from SimpleAssociatedEntity e" ).iterate() );
 		assertEquals( 1, count );
 		s.getTransaction().commit();
 		s.close();
 
 	 	s = openSession();
 		s.beginTransaction();
 		s.delete( e1 );
 		s.delete( e2 );
 		s.delete( owner );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	private int determineCount(Iterator iterator) {
 		int count = 0;
 		while( iterator.hasNext() ) {
 			count++;
 			iterator.next();
 		}
 		return count;
 	}
 
 	@Test
 	public void testEntityAndOneToOneReturnedByQuery() {
 		Session s = openSession();
 		s.beginTransaction();
 		Human h = new Human();
 		h.setName( new Name( "Gail", null, "Badner" ) );
 		s.save( h );
 		User u = new User();
 		u.setUserName( "gbadner" );
 		u.setHuman( h );
 		s.save( u );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Object [] result = ( Object [] ) s.createQuery( "from User u, Human h where u.human = h" ).uniqueResult();
 		assertNotNull( result );
 		assertEquals( u.getUserName(), ( ( User ) result[ 0 ] ).getUserName() );
 		assertEquals( h.getName().getFirst(), ((Human) result[1]).getName().getFirst() );
 		assertSame( ((User) result[0]).getHuman(), result[1] );
 		s.createQuery( "delete User" ).executeUpdate();
 		s.createQuery( "delete Human" ).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNestedComponentIsNull() {
 		// (1) From MapTest originally...
 		// (2) Was then moved into HQLTest...
 		// (3) However, a bug fix to EntityType#getIdentifierOrUniqueKeyType (HHH-2138)
 		// 		caused the classic parser to suddenly start throwing exceptions on
 		//		this query, apparently relying on the buggy behavior somehow; thus
 		//		moved here to at least get some syntax checking...
 		//
 		// fyi... found and fixed the problem in the classic parser; still
 		// leaving here for syntax checking
 		new SyntaxChecker( "from Commento c where c.marelo.commento.mcompr is null" ).checkAll();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-939" )
 	public void testSpecialClassPropertyReference() {
 		// this is a long standing bug in Hibernate when applied to joined-subclasses;
 		//  see HHH-939 for details and history
 		new SyntaxChecker( "from Zoo zoo where zoo.class = PettingZoo" ).checkAll();
 		new SyntaxChecker( "select a.description from Animal a where a.class = Mammal" ).checkAll();
 		new SyntaxChecker( "select a.class from Animal a" ).checkAll();
 		new SyntaxChecker( "from DomesticAnimal an where an.class = Dog" ).checkAll();
 		new SyntaxChecker( "from Animal an where an.class = Dog" ).checkAll();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-2376" )
 	public void testSpecialClassPropertyReferenceFQN() {
 		new SyntaxChecker( "from Zoo zoo where zoo.class = org.hibernate.test.hql.PettingZoo" ).checkAll();
 		new SyntaxChecker( "select a.description from Animal a where a.class = org.hibernate.test.hql.Mammal" ).checkAll();
 		new SyntaxChecker( "from DomesticAnimal an where an.class = org.hibernate.test.hql.Dog" ).checkAll();
 		new SyntaxChecker( "from Animal an where an.class = org.hibernate.test.hql.Dog" ).checkAll();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-1631" )
 	public void testSubclassOrSuperclassPropertyReferenceInJoinedSubclass() {
 		// this is a long standing bug in Hibernate; see HHH-1631 for details and history
 		//
 		// (1) pregnant is defined as a property of the class (Mammal) itself
 		// (2) description is defined as a property of the superclass (Animal)
 		// (3) name is defined as a property of a particular subclass (Human)
 
 		new SyntaxChecker( "from Zoo z join z.mammals as m where m.name.first = 'John'" ).checkIterate();
 
 		new SyntaxChecker( "from Zoo z join z.mammals as m where m.pregnant = false" ).checkAll();
 		new SyntaxChecker( "select m.pregnant from Zoo z join z.mammals as m where m.pregnant = false" ).checkAll();
 
 		new SyntaxChecker( "from Zoo z join z.mammals as m where m.description = 'tabby'" ).checkAll();
 		new SyntaxChecker( "select m.description from Zoo z join z.mammals as m where m.description = 'tabby'" ).checkAll();
 
 		new SyntaxChecker( "from Zoo z join z.mammals as m where m.name.first = 'John'" ).checkAll();
 		new SyntaxChecker( "select m.name from Zoo z join z.mammals as m where m.name.first = 'John'" ).checkAll();
 
 		new SyntaxChecker( "select m.pregnant from Zoo z join z.mammals as m" ).checkAll();
 		new SyntaxChecker( "select m.description from Zoo z join z.mammals as m" ).checkAll();
 		new SyntaxChecker( "select m.name from Zoo z join z.mammals as m" ).checkAll();
 
 		new SyntaxChecker( "from DomesticAnimal da join da.owner as o where o.nickName = 'Gavin'" ).checkAll();
 		new SyntaxChecker( "select da.father from DomesticAnimal da join da.owner as o where o.nickName = 'Gavin'" ).checkAll();
 	}
 
 	@Test
 	@RequiresDialectFeature(
 			value = DialectChecks.SupportLimitAndOffsetCheck.class,
 			comment = "dialect does not support offset and limit combo"
 	)
 	public void testSimpleSelectWithLimitAndOffset() throws Exception {
 		// just checking correctness of param binding code...
 		Session session = openSession();
 		session.createQuery( "from Animal" )
 				.setFirstResult( 2 )
 				.setMaxResults( 1 )
 				.list();
 		session.close();
 	}
 
 	@Test
 	public void testJPAPositionalParameterList() {
 		Session s = openSession();
 		s.beginTransaction();
 		ArrayList<String> params = new ArrayList<String>();
 		params.add( "Doe" );
 		params.add( "Public" );
 		s.createQuery( "from Human where name.last in (?1)" )
 				.setParameterList( "1", params )
 				.list();
 
 		s.createQuery( "from Human where name.last in ?1" )
 				.setParameterList( "1", params )
 				.list();
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testComponentQueries() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		Type[] types = s.createQuery( "select h.name from Human h" ).getReturnTypes();
 		assertEquals( 1, types.length );
 		assertTrue( types[0] instanceof ComponentType );
 
 		// Test the ability to perform comparisons between component values
 		s.createQuery( "from Human h where h.name = h.name" ).list();
 		s.createQuery( "from Human h where h.name = :name" ).setParameter( "name", new Name() ).list();
 		s.createQuery( "from Human where name = :name" ).setParameter( "name", new Name() ).list();
 		s.createQuery( "from Human h where :name = h.name" ).setParameter( "name", new Name() ).list();
 		s.createQuery( "from Human h where :name <> h.name" ).setParameter( "name", new Name() ).list();
 
 		// Test the ability to perform comparisons between a component and an explicit row-value
 		s.createQuery( "from Human h where h.name = ('John', 'X', 'Doe')" ).list();
 		s.createQuery( "from Human h where ('John', 'X', 'Doe') = h.name" ).list();
 		s.createQuery( "from Human h where ('John', 'X', 'Doe') <> h.name" ).list();
 		s.createQuery( "from Human h where ('John', 'X', 'Doe') >= h.name" ).list();
 
 		s.createQuery( "from Human h order by h.name" ).list();
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-1774" )
 	@SkipForDialect(
 			value = IngresDialect.class,
 			comment = "Subselects are not supported within select target lists in Ingres",
 			jiraKey = "HHH-4970"
 	)
 	public void testComponentParameterBinding() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		Order.Id oId = new Order.Id( "1234", 1 );
 
 		// control
 		s.createQuery("from Order o where o.customer.name =:name and o.id = :id")
 				.setParameter( "name", "oracle" )
 				.setParameter( "id", oId )
 				.list();
 
 		// this is the form that caused problems in the original case...
 		s.createQuery("from Order o where o.id = :id and o.customer.name =:name ")
 				.setParameter( "id", oId )
 				.setParameter( "name", "oracle" )
 				.list();
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	@Test
 	public void testAnyMappingReference() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		PropertyValue redValue = new StringPropertyValue( "red" );
 		PropertyValue loneliestNumberValue = new IntegerPropertyValue( 1 );
 
 		Long id;
 		PropertySet ps = new PropertySet( "my properties" );
 		ps.setSomeSpecificProperty( redValue );
 		ps.getGeneralProperties().put( "the loneliest number", loneliestNumberValue );
 		ps.getGeneralProperties().put( "i like", new StringPropertyValue( "pina coladas" ) );
 		ps.getGeneralProperties().put( "i also like", new StringPropertyValue( "getting caught in the rain" ) );
 		s.save( ps );
 
 		s.getTransaction().commit();
 		id = ps.getId();
 		s.clear();
 		s.beginTransaction();
 
 		// TODO : setEntity() currently will not work here, but that would be *very* nice
 		// does not work because the corresponding EntityType is then used as the "bind type" rather
 		// than the "discovered" AnyType...
 		s.createQuery( "from PropertySet p where p.someSpecificProperty = :ssp" ).setParameter( "ssp", redValue ).list();
 
 		s.createQuery( "from PropertySet p where p.someSpecificProperty.id is not null" ).list();
 
 		s.createQuery( "from PropertySet p join p.generalProperties gp where gp.id is not null" ).list();
 
 		s.delete( s.load( PropertySet.class, id ) );
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testJdkEnumStyleEnumConstant() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 
 		s.createQuery( "from Zoo z where z.classification = org.hibernate.test.hql.Classification.LAME" ).list();
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	@FailureExpected( jiraKey = "unknown" )
 	public void testParameterTypeMismatch() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		Query query = s.createQuery( "from Animal a where a.description = :nonstring" )
 				.setParameter( "nonstring", Integer.valueOf( 1 ) );
 		try {
 			query.list();
 			fail( "query execution should have failed" );
 		}
 		catch( TypeMismatchException tme ) {
 			// expected behavior
 		}
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testMultipleBagFetchesFail() {
 		Session s = openSession();
 		s.beginTransaction();
 		try {
 			s.createQuery( "from Human h join fetch h.friends f join fetch f.friends fof" ).list();
 			fail( "failure expected" );
 		}
 		catch( HibernateException e ) {
 			assertTrue( "unexpected failure reason : " + e, e.getMessage().indexOf( "multiple bags" ) > 0 );
 		}
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-1248" )
 	public void testCollectionJoinsInSubselect() {
 		// HHH-1248 : initially FromElementFactory treated any explicit join
 		// as an implied join so that theta-style joins would always be used.
 		// This was because correlated subqueries cannot use ANSI-style joins
 		// for the correlation.  However, this special treatment was not limited
 		// to only correlated subqueries; it was applied to any subqueries ->
 		// which in-and-of-itself is not necessarily bad.  But somewhere later
 		// the choices made there caused joins to be dropped.
 		Session s = openSession();
 		String qryString =
 				"select a.id, a.description" +
 				" from Animal a" +
 				"       left join a.offspring" +
 				" where a in (" +
 				"       select a1 from Animal a1" +
 				"           left join a1.offspring o" +
 				"       where a1.id=1" +
 		        ")";
 		s.createQuery( qryString ).list();
 		qryString =
 				"select h.id, h.description" +
 		        " from Human h" +
 				"      left join h.friends" +
 				" where h in (" +
 				"      select h1" +
 				"      from Human h1" +
 				"          left join h1.friends f" +
 				"      where h1.id=1" +
 				")";
 		s.createQuery( qryString ).list();
 		qryString =
 				"select h.id, h.description" +
 		        " from Human h" +
 				"      left join h.friends f" +
 				" where f in (" +
 				"      select h1" +
 				"      from Human h1" +
 				"          left join h1.friends f1" +
 				"      where h = f1" +
 				")";
 		s.createQuery( qryString ).list();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionFetchWithDistinctionAndLimit() {
 		// create some test data...
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		int parentCount = 30;
 		for ( int i = 0; i < parentCount; i++ ) {
 			Animal child1 = new Animal();
 			child1.setDescription( "collection fetch distinction (child1 - parent" + i + ")" );
 			s.persist( child1 );
 			Animal child2 = new Animal();
 			child2.setDescription( "collection fetch distinction (child2 - parent " + i + ")" );
 			s.persist( child2 );
 			Animal parent = new Animal();
 			parent.setDescription( "collection fetch distinction (parent" + i + ")" );
 			parent.setSerialNumber( "123-" + i );
 			parent.addOffspring( child1 );
 			parent.addOffspring( child2 );
 			s.persist( parent );
 		}
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		// Test simple distinction
 		List results;
 		results = s.createQuery( "select distinct p from Animal p inner join fetch p.offspring" ).list();
 		assertEquals( "duplicate list() returns", 30, results.size() );
 		// Test first/max
 		results = s.createQuery( "select p from Animal p inner join fetch p.offspring order by p.id" )
 				.setFirstResult( 5 )
 				.setMaxResults( 20 )
 				.list();
 		assertEquals( "duplicate returns", 20, results.size() );
 		Animal firstReturn = ( Animal ) results.get( 0 );
 		assertEquals( "firstResult not applied correctly", "123-5", firstReturn.getSerialNumber() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.createQuery( "delete Animal where mother is not null" ).executeUpdate();
 		s.createQuery( "delete Animal" ).executeUpdate();
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testFetchInSubqueryFails() {
 		Session s = openSession();
 		try {
 			s.createQuery( "from Animal a where a.mother in (select m from Animal a1 inner join a1.mother as m join fetch m.mother)" ).list();
 			fail( "fetch join allowed in subquery" );
 		}
 		catch( QueryException expected ) {
 			// expected behavior
 		}
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-1464" )
 	public void testQueryMetadataRetrievalWithFetching() {
 		// HHH-1464 : there was a problem due to the fact they we polled
 		// the shallow version of the query plan to get the metadata.
 		Session s = openSession();
 		Query query = s.createQuery( "from Animal a inner join fetch a.mother" );
 		assertEquals( 1, query.getReturnTypes().length );
 		assertNull( query.getReturnAliases() );
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-429" )
 	@SuppressWarnings( {"unchecked"})
 	public void testSuperclassPropertyReferenceAfterCollectionIndexedAccess() {
 		// note: simply performing syntax checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		Mammal tiger = new Mammal();
 		tiger.setDescription( "Tiger" );
 		s.persist( tiger );
 		Mammal mother = new Mammal();
 		mother.setDescription( "Tiger's mother" );
 		mother.setBodyWeight( 4.0f );
 		mother.addOffspring( tiger );
 		s.persist( mother );
 		Zoo zoo = new Zoo();
 		zoo.setName( "Austin Zoo" );
 		zoo.setMammals( new HashMap() );
 		zoo.getMammals().put( "tiger", tiger );
 		s.persist( zoo );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List results = s.createQuery( "from Zoo zoo where zoo.mammals['tiger'].mother.bodyWeight > 3.0f" ).list();
 		assertEquals( 1, results.size() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( tiger );
 		s.delete( mother );
 		s.delete( zoo );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testJoinFetchCollectionOfValues() {
 		// note: simply performing syntax checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "select h from Human as h join fetch h.nickNames" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testIntegerLiterals() {
 		// note: simply performing syntax checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Foo where long = 1" ).list();
 		s.createQuery( "from Foo where long = " + Integer.MIN_VALUE ).list();
 		s.createQuery( "from Foo where long = " + Integer.MAX_VALUE ).list();
 		s.createQuery( "from Foo where long = 1L" ).list();
 		s.createQuery( "from Foo where long = " + (Long.MIN_VALUE + 1) + "L" ).list();
 		s.createQuery( "from Foo where long = " + Long.MAX_VALUE + "L" ).list();
 		s.createQuery( "from Foo where integer = " + (Long.MIN_VALUE + 1) ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testDecimalLiterals() {
 		// note: simply performing syntax checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Animal where bodyWeight > 100.0e-10" ).list();
 		s.createQuery( "from Animal where bodyWeight > 100.0E-10" ).list();
 		s.createQuery( "from Animal where bodyWeight > 100.001f" ).list();
 		s.createQuery( "from Animal where bodyWeight > 100.001F" ).list();
 		s.createQuery( "from Animal where bodyWeight > 100.001d" ).list();
 		s.createQuery( "from Animal where bodyWeight > 100.001D" ).list();
 		s.createQuery( "from Animal where bodyWeight > .001f" ).list();
 		s.createQuery( "from Animal where bodyWeight > 100e-10" ).list();
 		s.createQuery( "from Animal where bodyWeight > .01E-10" ).list();
 		s.createQuery( "from Animal where bodyWeight > 1e-38" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNakedPropertyRef() {
 		// note: simply performing syntax and column/table resolution checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Animal where bodyWeight = bodyWeight" ).list();
 		s.createQuery( "select bodyWeight from Animal" ).list();
 		s.createQuery( "select max(bodyWeight) from Animal" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNakedComponentPropertyRef() {
 		// note: simply performing syntax and column/table resolution checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Human where name.first = 'Gavin'" ).list();
 		s.createQuery( "select name from Human" ).list();
 		s.createQuery( "select upper(h.name.first) from Human as h" ).list();
 		s.createQuery( "select upper(name.first) from Human" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNakedImplicitJoins() {
 		// note: simply performing syntax and column/table resolution checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Animal where mother.father.id = 1" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNakedEntityAssociationReference() {
 		// note: simply performing syntax and column/table resolution checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Animal where mother = :mother" ).setParameter( "mother", null ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNakedMapIndex() throws Exception {
 		// note: simply performing syntax and column/table resolution checking in the db
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Zoo where mammals['dog'].description like '%black%'" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testInvalidFetchSemantics() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		try {
 			s.createQuery( "select mother from Human a left join fetch a.mother mother" ).list();
 			fail( "invalid fetch semantic allowed!" );
 		}
 		catch( QueryException e ) {
 		}
 
 		try {
 			s.createQuery( "select mother from Human a left join fetch a.mother mother" ).list();
 			fail( "invalid fetch semantic allowed!" );
 		}
 		catch( QueryException e ) {
 		}
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"UnnecessaryUnboxing"})
 	public void testArithmetic() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Zoo zoo = new Zoo();
 		zoo.setName("Melbourne Zoo");
 		s.persist(zoo);
 		s.createQuery("select 2*2*2*2*(2*2) from Zoo").uniqueResult();
 		s.createQuery("select 2 / (1+1) from Zoo").uniqueResult();
 		int result0 = ( (Integer) s.createQuery("select 2 - (1+1) from Zoo").uniqueResult() ).intValue();
 		int result1 = ( (Integer) s.createQuery("select 2 - 1 + 1 from Zoo").uniqueResult() ).intValue();
 		int result2 = ( (Integer) s.createQuery("select 2 * (1-1) from Zoo").uniqueResult() ).intValue();
 		int result3 = ( (Integer) s.createQuery("select 4 / (2 * 2) from Zoo").uniqueResult() ).intValue();
 		int result4 = ( (Integer) s.createQuery("select 4 / 2 * 2 from Zoo").uniqueResult() ).intValue();
 		int result5 = ( (Integer) s.createQuery("select 2 * (2/2) from Zoo").uniqueResult() ).intValue();
 		int result6 = ( (Integer) s.createQuery("select 2 * (2/2+1) from Zoo").uniqueResult() ).intValue();
 		assertEquals(result0, 0);
 		assertEquals(result1, 2);
 		assertEquals(result2, 0);
 		assertEquals(result3, 1);
 		assertEquals(result4, 4);
 		assertEquals(result5, 2);
 		assertEquals(result6, 4);
 		s.delete(zoo);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testNestedCollectionFetch() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.createQuery("from Animal a left join fetch a.offspring o left join fetch o.offspring where a.mother.id = 1 order by a.description").list();
 		s.createQuery("from Zoo z left join fetch z.animals a left join fetch a.offspring where z.name ='MZ' order by a.description").list();
 		s.createQuery("from Human h left join fetch h.pets a left join fetch a.offspring where h.name.first ='Gavin' order by a.description").list();
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@SkipForDialect(
 			value = IngresDialect.class,
 			jiraKey = "HHH-4973",
 			comment = "Ingres 9.3 does not support sub-selects in the select list"
 	)
 	@SuppressWarnings( {"unchecked"})
 	public void testSelectClauseSubselect() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Zoo zoo = new Zoo();
 		zoo.setName("Melbourne Zoo");
 		zoo.setMammals( new HashMap() );
 		zoo.setAnimals( new HashMap() );
 		Mammal plat = new Mammal();
 		plat.setBodyWeight( 11f );
 		plat.setDescription( "Platypus" );
 		plat.setZoo(zoo);
 		plat.setSerialNumber("plat123");
 		zoo.getMammals().put("Platypus", plat);
 		zoo.getAnimals().put("plat123", plat);
 		s.persist( plat );
 		s.persist( zoo );
 
 		s.createQuery("select (select max(z.id) from a.zoo z) from Animal a").list();
 		s.createQuery("select (select max(z.id) from a.zoo z where z.name=:name) from Animal a")
 			.setParameter("name", "Melbourne Zoo").list();
 
 		s.delete( plat );
 		s.delete(zoo);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testInitProxy() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Mammal plat = new Mammal();
 		plat.setBodyWeight( 11f );
 		plat.setDescription( "Platypus" );
 		s.persist( plat );
 		s.flush();
 		s.clear();
 		plat = (Mammal) s.load(Mammal.class, plat.getId() );
 		assertFalse( Hibernate.isInitialized(plat) );
 		Object plat2 = s.createQuery("from Animal a").uniqueResult();
 		assertSame( plat, plat2 );
 		assertTrue( Hibernate.isInitialized( plat ) );
 		s.delete( plat );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testSelectClauseImplicitJoin() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Zoo zoo = new Zoo();
 		zoo.setName("The Zoo");
 		zoo.setMammals( new HashMap() );
 		zoo.setAnimals( new HashMap() );
 		Mammal plat = new Mammal();
 		plat.setBodyWeight( 11f );
 		plat.setDescription( "Platypus" );
 		plat.setZoo( zoo );
 		plat.setSerialNumber( "plat123" );
 		zoo.getMammals().put( "Platypus", plat );
 		zoo.getAnimals().put("plat123", plat);
 		s.persist( plat );
 		s.persist(zoo);
 		s.flush();
 		s.clear();
 		Query q = s.createQuery("select distinct a.zoo from Animal a where a.zoo is not null");
 		Type type = q.getReturnTypes()[0];
 		assertTrue( type instanceof ManyToOneType );
 		assertEquals( ( (ManyToOneType) type ).getAssociatedEntityName(), "org.hibernate.test.hql.Zoo" );
 		zoo = (Zoo) q.list().get(0);
 		assertEquals( zoo.getMammals().size(), 1 );
 		assertEquals( zoo.getAnimals().size(), 1 );
 		s.clear();
 		s.delete(plat);
 		s.delete(zoo);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testSelectClauseImplicitJoinWithIterate() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Zoo zoo = new Zoo();
 		zoo.setName("The Zoo");
 		zoo.setMammals( new HashMap() );
 		zoo.setAnimals( new HashMap() );
 		Mammal plat = new Mammal();
 		plat.setBodyWeight( 11f );
 		plat.setDescription( "Platypus" );
 		plat.setZoo(zoo);
 		plat.setSerialNumber("plat123");
 		zoo.getMammals().put("Platypus", plat);
 		zoo.getAnimals().put("plat123", plat);
 		s.persist( plat );
 		s.persist(zoo);
 		s.flush();
 		s.clear();
 		Query q = s.createQuery("select distinct a.zoo from Animal a where a.zoo is not null");
 		Type type = q.getReturnTypes()[0];
 		assertTrue( type instanceof ManyToOneType );
 		assertEquals( ( (ManyToOneType) type ).getAssociatedEntityName(), "org.hibernate.test.hql.Zoo" );
 		zoo = (Zoo) q
 			.iterate().next();
 		assertEquals( zoo.getMammals().size(), 1 );
 		assertEquals( zoo.getAnimals().size(), 1 );
 		s.clear();
 		s.delete(plat);
 		s.delete(zoo);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testComponentOrderBy() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 
 		Long id1 = ( Long ) s.save( genSimpleHuman( "John", "Jacob" ) );
 		Long id2 = ( Long ) s.save( genSimpleHuman( "Jingleheimer", "Schmidt" ) );
 
 		s.flush();
 
 		// the component is defined with the firstName column first...
 		List results = s.createQuery( "from Human as h order by h.name" ).list();
 		assertEquals( "Incorrect return count", 2, results.size() );
 
 		Human h1 = ( Human ) results.get( 0 );
 		Human h2 = ( Human ) results.get( 1 );
 
 		assertEquals( "Incorrect ordering", id2, h1.getId() );
 		assertEquals( "Incorrect ordering", id1, h2.getId() );
 
 		s.delete( h1 );
 		s.delete( h2 );
 
 		t.commit();
 		s.close();
 	}
 	
 	@Test
 	public void testOrderedWithCustomColumnReadAndWrite() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		SimpleEntityWithAssociation first = new SimpleEntityWithAssociation();
 		first.setNegatedNumber( 1 );
 		s.save( first );
 		SimpleEntityWithAssociation second = new SimpleEntityWithAssociation();
 		second.setNegatedNumber(2);
 		s.save( second );
 		s.flush();
 
 		// Check order via SQL. Numbers are negated in the DB, so second comes first.
 		List listViaSql = s.createSQLQuery("select id from simple_1 order by negated_num").list();
 		assertEquals( 2, listViaSql.size() );
 		assertEquals( second.getId().longValue(), ((Number) listViaSql.get( 0 )).longValue() );
 		assertEquals( first.getId().longValue(), ((Number) listViaSql.get( 1 )).longValue() );
 
 		// Check order via HQL. Now first comes first b/c the read negates the DB negation.
 		List listViaHql = s.createQuery("from SimpleEntityWithAssociation order by negatedNumber").list();
 		assertEquals( 2, listViaHql.size() );
 		assertEquals(first.getId(), ((SimpleEntityWithAssociation)listViaHql.get(0)).getId());
 		assertEquals(second.getId(), ((SimpleEntityWithAssociation)listViaHql.get(1)).getId());
 
 		s.delete( first );
 		s.delete( second );
 		t.commit();
 		s.close();
 	}
 	
 	@Test
diff --git a/hibernate-core/src/test/java/org/hibernate/test/jpa/cascade/CascadeTest.java b/hibernate-core/src/test/java/org/hibernate/test/jpa/cascade/CascadeTest.java
index 9f4986d588..42fc465002 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/jpa/cascade/CascadeTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/jpa/cascade/CascadeTest.java
@@ -1,329 +1,332 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.jpa.cascade;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Session;
 import org.hibernate.TransientObjectException;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.fail;
 
 import org.junit.Test;
 
 import org.hibernate.test.jpa.AbstractJPATest;
 
 /**
  * According to the JPA spec, persist()ing an entity should throw an exception
  * when said entity contains a reference to a transient entity through a mapped
  * association where that association is not marked for cascading the persist
  * operation.
  * <p/>
  * This test-case tests that requirement in the various association style
  * scenarios such as many-to-one, one-to-one, many-to-one (property-ref),
  * one-to-one (property-ref).  Additionally, it performs each of these tests
  * in both generated and assigned identifier usages...
  *
  * @author Steve Ebersole
  */
 public class CascadeTest extends AbstractJPATest {
+	private static final Logger log = Logger.getLogger( CascadeTest.class );
+
 	public String[] getMappings() {
 		return new String[] { "jpa/cascade/ParentChild.hbm.xml" };
 	}
 
 	@Test
 	public void testManyToOneGeneratedIdsOnSave() {
 		// NOTES: Child defines a many-to-one back to its Parent.  This
 		// association does not define persist cascading (which is natural;
 		// a child should not be able to create its parent).
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Parent p = new Parent( "parent" );
 			Child c = new Child( "child" );
 			c.setParent( p );
 			s.save( c );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception", e );
+				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testManyToOneGeneratedIds() {
 		// NOTES: Child defines a many-to-one back to its Parent.  This
 		// association does not define persist cascading (which is natural;
 		// a child should not be able to create its parent).
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Parent p = new Parent( "parent" );
 			Child c = new Child( "child" );
 			c.setParent( p );
 			s.persist( c );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception", e );
+				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testManyToOneAssignedIds() {
 		// NOTES: Child defines a many-to-one back to its Parent.  This
 		// association does not define persist cascading (which is natural;
 		// a child should not be able to create its parent).
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			ParentAssigned p = new ParentAssigned( new Long( 1 ), "parent" );
 			ChildAssigned c = new ChildAssigned( new Long( 2 ), "child" );
 			c.setParent( p );
 			s.persist( c );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception", e );
+				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testOneToOneGeneratedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Parent p = new Parent( "parent" );
 			ParentInfo info = new ParentInfo( "xyz" );
 			p.setInfo( info );
 			info.setOwner( p );
 			s.persist( p );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception", e );
+				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testOneToOneAssignedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			ParentAssigned p = new ParentAssigned( new Long( 1 ), "parent" );
 			ParentInfoAssigned info = new ParentInfoAssigned( "something secret" );
 			p.setInfo( info );
 			info.setOwner( p );
 			s.persist( p );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception", e );
+				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testManyToOnePropertyRefGeneratedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Parent p = new Parent( "parent" );
 			Other other = new Other();
 			other.setOwner( p );
 			s.persist( other );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception", e );
+				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testManyToOnePropertyRefAssignedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			ParentAssigned p = new ParentAssigned( new Long( 1 ), "parent" );
 			OtherAssigned other = new OtherAssigned( new Long( 2 ) );
 			other.setOwner( p );
 			s.persist( other );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception", e );
+				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testOneToOnePropertyRefGeneratedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Child c2 = new Child( "c2" );
 			ChildInfo info = new ChildInfo( "blah blah blah" );
 			c2.setInfo( info );
 			info.setOwner( c2 );
 			s.persist( c2 );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception : " + e );
+				log.trace( "handled expected exception : " + e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testOneToOnePropertyRefAssignedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			ChildAssigned c2 = new ChildAssigned( new Long( 3 ), "c3" );
 			ChildInfoAssigned info = new ChildInfoAssigned( new Long( 4 ), "blah blah blah" );
 			c2.setInfo( info );
 			info.setOwner( c2 );
 			s.persist( c2 );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
-				LOG.trace( "handled expected exception : " + e );
+				log.trace( "handled expected exception : " + e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 
 	private void cleanupData() {
 		Session s = null;
 		try {
 			s = openSession();
 			s.beginTransaction();
 			s.createQuery( "delete ChildInfoAssigned" ).executeUpdate();
 			s.createQuery( "delete ChildAssigned" ).executeUpdate();
 			s.createQuery( "delete ParentAssigned" ).executeUpdate();
 			s.createQuery( "delete ChildInfoAssigned" ).executeUpdate();
 			s.createQuery( "delete ChildAssigned" ).executeUpdate();
 			s.createQuery( "delete ParentAssigned" ).executeUpdate();
 			s.getTransaction().commit();
 		}
 		catch( Throwable t ) {
-			LOG.warn( "unable to cleanup test data : " + t );
+			log.warn( "unable to cleanup test data : " + t );
 		}
 		finally {
 			if ( s != null ) {
 				try {
 					s.close();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
index 8fb96c74e8..63f8ce0d3f 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
@@ -1,1098 +1,1100 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2006-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.legacy;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Time;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Set;
 import java.util.SortedSet;
 import java.util.TimeZone;
 import java.util.TreeMap;
 import java.util.TreeSet;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Criteria;
 import org.hibernate.FetchMode;
 import org.hibernate.FlushMode;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.LazyInitializationException;
 import org.hibernate.LockMode;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.criterion.Example;
 import org.hibernate.criterion.MatchMode;
 import org.hibernate.criterion.Order;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.dialect.DB2Dialect;
 import org.hibernate.dialect.DerbyDialect;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.InterbaseDialect;
 import org.hibernate.dialect.MckoiDialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.dialect.PointbaseDialect;
 import org.hibernate.dialect.PostgreSQLDialect;
 import org.hibernate.dialect.SAPDBDialect;
 import org.hibernate.dialect.Sybase11Dialect;
 import org.hibernate.dialect.SybaseASE15Dialect;
 import org.hibernate.dialect.SybaseDialect;
 import org.hibernate.dialect.TimesTenDialect;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.internal.util.SerializationHelper;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.jdbc.AbstractWork;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 
 import org.junit.Test;
 
 import org.hibernate.testing.DialectChecks;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.env.ConnectionProviderBuilder;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 public class FooBarTest extends LegacyTestCase {
+	private static final Logger log = Logger.getLogger( FooBarTest.class );
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 			"legacy/FooBar.hbm.xml",
 			"legacy/Baz.hbm.xml",
 			"legacy/Qux.hbm.xml",
 			"legacy/Glarch.hbm.xml",
 			"legacy/Fum.hbm.xml",
 			"legacy/Fumm.hbm.xml",
 			"legacy/Fo.hbm.xml",
 			"legacy/One.hbm.xml",
 			"legacy/Many.hbm.xml",
 			"legacy/Immutable.hbm.xml",
 			"legacy/Fee.hbm.xml",
 			"legacy/Vetoer.hbm.xml",
 			"legacy/Holder.hbm.xml",
 			"legacy/Location.hbm.xml",
 			"legacy/Stuff.hbm.xml",
 			"legacy/Container.hbm.xml",
 			"legacy/Simple.hbm.xml",
 			"legacy/XY.hbm.xml"
 		};
 	}
 
 	@Test
 	public void testSaveOrUpdateCopyAny() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		One one = new One();
 		bar.setObject(one);
 		s.save(bar);
 		GlarchProxy g = bar.getComponent().getGlarch();
 		bar.getComponent().setGlarch(null);
 		s.delete(g);
 		s.flush();
 		assertTrue( s.contains(one) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Bar bar2 = (Bar) s.merge( bar );
 		s.flush();
 		s.delete(bar2);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRefreshProxy() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Glarch g = new Glarch();
 		Serializable gid = s.save(g);
 		s.flush();
 		s.clear();
 		GlarchProxy gp = (GlarchProxy) s.load(Glarch.class, gid);
 		gp.getName(); //force init
 		s.refresh(gp);
 		s.delete(gp);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@RequiresDialectFeature(
 			value = DialectChecks.SupportsCircularCascadeDeleteCheck.class,
 			comment = "db/dialect does not support circular cascade delete constraints"
 	)
 	public void testOnCascadeDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.subs = new ArrayList();
 		Baz sub = new Baz();
 		sub.superBaz = baz;
 		baz.subs.add(sub);
 		s.save(baz);
 		s.flush();
 		assertTrue( s.createQuery("from Baz").list().size()==2 );
 		s.getTransaction().commit();
 		s.beginTransaction();
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.beginTransaction();
 		assertTrue( s.createQuery("from Baz").list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRemoveFromIdbag() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setByteBag( new ArrayList() );
 		byte[] bytes = { 12, 13 };
 		baz.getByteBag().add( new byte[] { 10, 45 } );
 		baz.getByteBag().add(bytes);
 		baz.getByteBag().add( new byte[] { 1, 11 } );
 		baz.getByteBag().add( new byte[] { 12 } );
 		s.save(baz);
 		s.flush();
 		baz.getByteBag().remove(bytes);
 		s.flush();
 		baz.getByteBag().add(bytes);
 		s.flush();
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testLoad() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save(q);
 		BarProxy b = new Bar();
 		s.save(b);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load(Qux.class, q.getKey() );
 		b = (BarProxy) s.load( Foo.class, b.getKey() );
 		b.getKey();
 		assertFalse( Hibernate.isInitialized(b) );
 		b.getBarString();
 		assertTrue( Hibernate.isInitialized(b) );
 		BarProxy b2 = (BarProxy) s.load( Bar.class, b.getKey() );
 		Qux q2 = (Qux) s.load( Qux.class, q.getKey() );
 		assertTrue( "loaded same object", q==q2 );
 		assertTrue( "loaded same object", b==b2 );
 		assertTrue( Math.round( b.getFormula() ) == b.getInt() / 2 );
 		s.delete(q2);
 		s.delete( b2 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testJoin() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		foo.setJoinedProp("foo");
 		s.save( foo );
 		s.flush();
 		foo.setJoinedProp("bar");
 		s.flush();
 		String fid = foo.getKey();
 		s.delete( foo );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		foo2.setJoinedProp("foo");
 		s.save(foo2);
 		s.createQuery( "select foo.id from Foo foo where foo.joinedProp = 'foo'" ).list();
 		assertNull( s.get(Foo.class, fid) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testDereferenceLazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		baz.getFooSet().add(foo);
 		s.save(foo);
 		s.save(baz);
 		foo.setBytes( "foobar".getBytes() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( Hibernate.isInitialized( foo.getBytes() ) );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooSet().size()==1 );
 		s.getTransaction().commit();
 		s.close();
 
 		sessionFactory().evictCollection("org.hibernate.test.legacy.Baz.fooSet");
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		baz.setFooSet(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		assertTrue( baz.getFooSet().size()==0 );
 		s.delete(baz);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testMoveLazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Baz baz2 = new Baz();
 		baz.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		baz.getFooSet().add(foo);
 		s.save(foo);
 		s.save(baz);
 		s.save(baz2);
 		foo.setBytes( "foobar".getBytes() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( Hibernate.isInitialized( foo.getBytes() ) );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooSet().size()==1 );
 		s.getTransaction().commit();
 		s.close();
 
 		sessionFactory().evictCollection("org.hibernate.test.legacy.Baz.fooSet");
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		baz2 = (Baz) s.get( Baz.class, baz2.getCode() );
 		baz2.setFooSet( baz.getFooSet() );
 		baz.setFooSet(null);
 		assertFalse( Hibernate.isInitialized( baz2.getFooSet() ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		baz2 = (Baz) s.get( Baz.class, baz2.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		assertTrue( baz.getFooSet().size()==0 );
 		assertTrue( Hibernate.isInitialized( baz2.getFooSet() ) ); //fooSet has batching enabled
 		assertTrue( baz2.getFooSet().size()==1 );
 		s.delete(baz);
 		s.delete(baz2);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCriteriaCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz bb = (Baz) s.createCriteria(Baz.class).uniqueResult();
 		assertTrue( bb == null );
 		Baz baz = new Baz();
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Baz b = (Baz) s.createCriteria(Baz.class).uniqueResult();
 		assertTrue( Hibernate.isInitialized( b.getTopGlarchez() ) );
 		assertTrue( b.getTopGlarchez().size() == 0 );
 		s.delete( b );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testQuery() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo2 = new Foo();
 		s.save(foo2);
 		foo.setFoo(foo2);
 
 		List list = s.createQuery( "from Foo foo inner join fetch foo.foo" ).list();
 		Foo foof = (Foo) list.get(0);
 		assertTrue( Hibernate.isInitialized( foof.getFoo() ) );
 
 		s.createQuery( "from Baz baz left outer join fetch baz.fooToGlarch" ).list();
 
 		list = s.createQuery( "select foo, bar from Foo foo left outer join foo.foo bar where foo = ?" )
 				.setParameter( 0, foo, Hibernate.entity(Foo.class) )
 				.list();
 		Object[] row1 = (Object[]) list.get(0);
 		assertTrue( row1[0]==foo && row1[1]==foo2 );
 
 		s.createQuery( "select foo.foo.foo.string from Foo foo where foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.foo.string from Foo foo where foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo from Foo foo where foo.foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.foo.string from Foo foo where foo.foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.string from Foo foo where foo.foo.foo.foo.string = 'bar'" ).list();
 		if ( ! (getDialect() instanceof HSQLDialect) )
 			s.createQuery( "select foo.string from Foo foo where foo.foo.foo.foo = foo.foo.foo" ).list();
 		s.createQuery( "select foo.string from Foo foo where foo.foo.foo = 'bar' and foo.foo.foo.foo = 'baz'" ).list();
 		s.createQuery( "select foo.string from Foo foo where foo.foo.foo.foo.string = 'a' and foo.foo.string = 'b'" )
 				.list();
 
 		s.createQuery( "from Bar bar, foo in elements(bar.baz.fooArray)" ).list();
 
 		//s.find("from Baz as baz where baz.topComponents[baz].name = 'bazzz'");
 
 		if ( (getDialect() instanceof DB2Dialect) && !(getDialect() instanceof DerbyDialect) ) {
 			s.createQuery( "from Foo foo where lower( foo.foo.string ) = 'foo'" ).list();
 			s.createQuery( "from Foo foo where lower( (foo.foo.string || 'foo') || 'bar' ) = 'foo'" ).list();
 			s.createQuery( "from Foo foo where repeat( (foo.foo.string || 'foo') || 'bar', 2 ) = 'foo'" ).list();
 			s.createQuery(
 					"from Bar foo where foo.foo.integer is not null and repeat( (foo.foo.string || 'foo') || 'bar', (5+5)/2 ) = 'foo'"
 			).list();
 			s.createQuery(
 					"from Bar foo where foo.foo.integer is not null or repeat( (foo.foo.string || 'foo') || 'bar', (5+5)/2 ) = 'foo'"
 			).list();
 		}
 		if (getDialect() instanceof SybaseDialect) {
 			s.createQuery( "select baz from Baz as baz join baz.fooArray foo group by baz order by sum(foo.float)" )
 					.iterate();
 		}
 
 		s.createQuery( "from Foo as foo where foo.component.glarch.name is not null" ).list();
 		s.createQuery( "from Foo as foo left outer join foo.component.glarch as glarch where glarch.name = 'foo'" )
 				.list();
 
 		list = s.createQuery( "from Foo" ).list();
 		assertTrue( list.size()==2 && list.get(0) instanceof FooProxy );
 		list = s.createQuery( "from Foo foo left outer join foo.foo" ).list();
 		assertTrue( list.size()==2 && ( (Object[]) list.get(0) )[0] instanceof FooProxy );
 
 		s.createQuery("from Bar, Bar").list();
 		s.createQuery("from Foo, Bar").list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch, Bar bar join bar.foo" ).list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch join baz.fooSet" ).list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch join fetch baz.fooSet foo left join fetch foo.foo" )
 				.list();
 
 		list = s.createQuery(
 				"from Foo foo where foo.string='osama bin laden' and foo.boolean = true order by foo.string asc, foo.component.count desc"
 		).list();
 		assertTrue( "empty query", list.size()==0 );
 		Iterator iter = s.createQuery(
 				"from Foo foo where foo.string='osama bin laden' order by foo.string asc, foo.component.count desc"
 		).iterate();
 		assertTrue( "empty iterator", !iter.hasNext() );
 
 		list = s.createQuery( "select foo.foo from Foo foo" ).list();
 		assertTrue( "query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo.getFoo() );
 		foo.getFoo().setFoo(foo);
 		foo.setString("fizard");
 		//The following test is disabled for databases with no subselects...also for Interbase (not sure why).
 		if (
 				!(getDialect() instanceof MySQLDialect) &&
 				!(getDialect() instanceof HSQLDialect) &&
 				!(getDialect() instanceof MckoiDialect) &&
 				!(getDialect() instanceof SAPDBDialect) &&
 				!(getDialect() instanceof PointbaseDialect) &&
 				!(getDialect() instanceof DerbyDialect)
 		)  {
 			// && !db.equals("weblogic") {
 			if ( !( getDialect() instanceof InterbaseDialect ) ) {
 				list = s.createQuery( "from Foo foo where ? = some elements(foo.component.importantDates)" )
 						.setParameter( 0, new Date(), Hibernate.DATE )
 						.list();
 				assertTrue( "component query", list.size()==2 );
 			}
 			if( !( getDialect() instanceof TimesTenDialect)) {
 				list = s.createQuery( "from Foo foo where size(foo.component.importantDates) = 3" ).list(); //WAS: 4
 				assertTrue( "component query", list.size()==2 );
 				list = s.createQuery( "from Foo foo where 0 = size(foo.component.importantDates)" ).list();
 				assertTrue( "component query", list.size()==0 );
 			}
 			list = s.createQuery( "from Foo foo where exists elements(foo.component.importantDates)" ).list();
 			assertTrue( "component query", list.size()==2 );
 			s.createQuery( "from Foo foo where not exists (from Bar bar where bar.id = foo.id)" ).list();
 
 			s.createQuery(
 					"select foo.foo from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long)"
 			).list();
 			s.createQuery( "select foo.foo from Foo foo where foo = some(from Foo x where (x.long > foo.foo.long))" )
 					.list();
 			if ( !( getDialect() instanceof TimesTenDialect)) {
 				s.createQuery(
 						"select foo.foo from Foo foo where foo.long = some( select max(x.long) from Foo x where (x.long > foo.foo.long) group by x.foo )"
 				).list();
 			}
 			s.createQuery(
 					"from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long) and foo.foo.string='baz'"
 			).list();
 			s.createQuery(
 					"from Foo foo where foo.foo.string='baz' and foo = some(select x from Foo x where x.long > foo.foo.long)"
 			).list();
 			s.createQuery( "from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long)" ).list();
 
 			s.createQuery(
 					"select foo.string, foo.date, foo.foo.string, foo.id from Foo foo, Baz baz where foo in elements(baz.fooArray) and foo.string like 'foo'"
 			).iterate();
 		}
 		list = s.createQuery( "from Foo foo where foo.component.count is null order by foo.component.count" ).list();
 		assertTrue( "component query", list.size()==0 );
 		list = s.createQuery( "from Foo foo where foo.component.name='foo'" ).list();
 		assertTrue( "component query", list.size()==2 );
 		list = s.createQuery(
 				"select distinct foo.component.name, foo.component.name from Foo foo where foo.component.name='foo'"
 		).list();
 		assertTrue( "component query", list.size()==1 );
 		list = s.createQuery( "select distinct foo.component.name, foo.id from Foo foo where foo.component.name='foo'" )
 				.list();
 		assertTrue( "component query", list.size()==2 );
 		list = s.createQuery( "select foo.foo from Foo foo" ).list();
 		assertTrue( "query", list.size()==2 );
 		list = s.createQuery( "from Foo foo where foo.id=?" )
 				.setParameter( 0, foo.getKey(), Hibernate.STRING )
 				.list();
 		assertTrue( "id query", list.size()==1 );
 		list = s.createQuery( "from Foo foo where foo.key=?" )
 				.setParameter( 0, foo.getKey(), Hibernate.STRING )
 				.list();
 		assertTrue( "named id query", list.size()==1 );
 		assertTrue( "id query", list.get(0)==foo );
 		list = s.createQuery( "select foo.foo from Foo foo where foo.string='fizard'" ).list();
 		assertTrue( "query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo.getFoo() );
 		list = s.createQuery( "from Foo foo where foo.component.subcomponent.name='bar'" ).list();
 		assertTrue( "components of components", list.size()==2 );
 		list = s.createQuery( "select foo.foo from Foo foo where foo.foo.id=?" )
 				.setParameter( 0, foo.getFoo().getKey(), Hibernate.STRING )
 				.list();
 		assertTrue( "by id query", list.size()==1 );
 		assertTrue( "by id returned object", list.get(0)==foo.getFoo() );
 
 		s.createQuery( "from Foo foo where foo.foo = ?" ).setParameter( 0, foo.getFoo(), Hibernate.entity(Foo.class) ).list();
 
 		assertTrue( !s.createQuery( "from Bar bar where bar.string='a string' or bar.string='a string'" )
 				.iterate()
 				.hasNext() );
 
 		iter = s.createQuery( "select foo.component.name, elements(foo.component.importantDates) from Foo foo where foo.foo.id=?" )
 				.setParameter( 0, foo.getFoo().getKey(), Hibernate.STRING )
 				.iterate();
 		int i=0;
 		while ( iter.hasNext() ) {
 			i++;
 			Object[] row = (Object[]) iter.next();
 			assertTrue( row[0] instanceof String && ( row[1]==null || row[1] instanceof Date ) );
 		}
 		assertTrue(i==3); //WAS: 4
 		iter = s.createQuery( "select max( elements(foo.component.importantDates) ) from Foo foo group by foo.id" )
 				.iterate();
 		assertTrue( iter.next() instanceof Date );
 
 		list = s.createQuery(
 				"select foo.foo.foo.foo from Foo foo, Foo foo2 where"
 						+ " foo = foo2.foo and not not ( not foo.string='fizard' )"
 						+ " and foo2.string between 'a' and (foo.foo.string)"
 						+ ( ( getDialect() instanceof HSQLDialect || getDialect() instanceof InterbaseDialect || getDialect() instanceof TimesTenDialect ) ?
 						" and ( foo2.string in ( 'fiz', 'blah') or 1=1 )"
 						:
 						" and ( foo2.string in ( 'fiz', 'blah', foo.foo.string, foo.string, foo2.string ) )"
 				)
 		).list();
 		assertTrue( "complex query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo );
 		foo.setString("from BoogieDown  -tinsel town  =!@#$^&*())");
 		list = s.createQuery( "from Foo foo where foo.string='from BoogieDown  -tinsel town  =!@#$^&*())'" ).list();
 		assertTrue( "single quotes", list.size()==1 );
 		list = s.createQuery( "from Foo foo where not foo.string='foo''bar'" ).list();
 		assertTrue( "single quotes", list.size()==2 );
 		list = s.createQuery( "from Foo foo where foo.component.glarch.next is null" ).list();
 		assertTrue( "query association in component", list.size()==2 );
 		Bar bar = new Bar();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		bar.setBaz(baz);
 		baz.setManyToAny( new ArrayList() );
 		baz.getManyToAny().add(bar);
 		baz.getManyToAny().add(foo);
 		s.save(bar);
 		s.save(baz);
 		list = s.createQuery(
 				" from Bar bar where bar.baz.count=667 and bar.baz.count!=123 and not bar.baz.name='1-E-1'"
 		).list();
 		assertTrue( "query many-to-one", list.size()==1 );
 		list = s.createQuery( " from Bar i where i.baz.name='Bazza'" ).list();
 		assertTrue( "query many-to-one", list.size()==1 );
 
 		Iterator rs = s.createQuery( "select count(distinct foo.foo) from Foo foo" ).iterate();
 		assertTrue( "count", ( (Long) rs.next() ).longValue()==2 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(foo.foo.boolean) from Foo foo" ).iterate();
 		assertTrue( "count", ( (Long) rs.next() ).longValue()==2 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(*), foo.int from Foo foo group by foo.int" ).iterate();
 		assertTrue( "count(*) group by", ( (Object[]) rs.next() )[0].equals( new Long(3) ) );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select sum(foo.foo.int) from Foo foo" ).iterate();
 		assertTrue( "sum", ( (Long) rs.next() ).longValue()==4 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(foo) from Foo foo where foo.id=?" )
 				.setParameter( 0, foo.getKey(), Hibernate.STRING )
 				.iterate();
 		assertTrue( "id query count", ( (Long) rs.next() ).longValue()==1 );
 		assertTrue( !rs.hasNext() );
 
 		s.createQuery( "from Foo foo where foo.boolean = ?" )
 				.setParameter( 0, new Boolean(true), Hibernate.BOOLEAN )
 				.list();
 
 		s.createQuery( "select new Foo(fo.x) from Fo fo" ).list();
 		s.createQuery( "select new Foo(fo.integer) from Foo fo" ).list();
 
 		list = s.createQuery("select new Foo(fo.x) from Foo fo")
 			//.setComment("projection test")
 			.setCacheable(true)
 			.list();
 		assertTrue(list.size()==3);
 		list = s.createQuery("select new Foo(fo.x) from Foo fo")
 			//.setComment("projection test 2")
 			.setCacheable(true)
 			.list();
 		assertTrue(list.size()==3);
 
 		rs = s.createQuery( "select new Foo(fo.x) from Foo fo" ).iterate();
 		assertTrue( "projection iterate (results)", rs.hasNext() );
 		assertTrue( "projection iterate (return check)", Foo.class.isAssignableFrom( rs.next().getClass() ) );
 
 		ScrollableResults sr = s.createQuery("select new Foo(fo.x) from Foo fo").scroll();
 		assertTrue( "projection scroll (results)", sr.next() );
 		assertTrue( "projection scroll (return check)", Foo.class.isAssignableFrom( sr.get(0).getClass() ) );
 
 		list = s.createQuery( "select foo.long, foo.component.name, foo, foo.foo from Foo foo" ).list();
 		rs = list.iterator();
 		int count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Long );
 			assertTrue( row[1] instanceof String );
 			assertTrue( row[2] instanceof Foo );
 			assertTrue( row[3] instanceof Foo );
 		}
 		assertTrue(count!=0);
 		list = s.createQuery( "select avg(foo.float), max(foo.component.name), count(distinct foo.id) from Foo foo" )
 				.list();
 		rs = list.iterator();
 		count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Double );
 			assertTrue( row[1] instanceof String );
 			assertTrue( row[2] instanceof Long );
 		}
 		assertTrue(count!=0);
 		list = s.createQuery( "select foo.long, foo.component, foo, foo.foo from Foo foo" ).list();
 		rs = list.iterator();
 		count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Long );
 			assertTrue( row[1] instanceof FooComponent );
 			assertTrue( row[2] instanceof Foo );
 			assertTrue( row[3] instanceof Foo );
 		}
 		assertTrue(count!=0);
 
 		s.save( new Holder("ice T") );
 		s.save( new Holder("ice cube") );
 
 		assertTrue( s.createQuery( "from java.lang.Object as o" ).list().size()==15 );
 		assertTrue( s.createQuery( "from Named" ).list().size()==7 );
 		assertTrue( s.createQuery( "from Named n where n.name is not null" ).list().size()==4 );
 		iter = s.createQuery( "from Named n" ).iterate();
 		while ( iter.hasNext() ) {
 			assertTrue( iter.next() instanceof Named );
 		}
 
 		s.save( new Holder("bar") );
 		iter = s.createQuery( "from Named n0, Named n1 where n0.name = n1.name" ).iterate();
 		int cnt = 0;
 		while ( iter.hasNext() ) {
 			Object[] row = (Object[]) iter.next();
 			if ( row[0]!=row[1] ) cnt++;
 		}
 		if ( !(getDialect() instanceof HSQLDialect) ) {
 			assertTrue(cnt==2);
 			assertTrue( s.createQuery( "from Named n0, Named n1 where n0.name = n1.name" ).list().size()==7 );
 		}
 
 		Query qu = s.createQuery("from Named n where n.name = :name");
 		qu.getReturnTypes();
 		qu.getNamedParameters();
 
 		iter = s.createQuery( "from java.lang.Object" ).iterate();
 		int c = 0;
 		while ( iter.hasNext() ) {
 			iter.next();
 			c++;
 		}
 		assertTrue(c==16);
 
 		s.createQuery( "select baz.code, min(baz.count) from Baz baz group by baz.code" ).iterate();
 
 		iter = s.createQuery( "selecT baz from Baz baz where baz.stringDateMap['foo'] is not null or baz.stringDateMap['bar'] = ?" )
 				.setParameter( 0, new Date(), Hibernate.DATE )
 				.iterate();
 		assertFalse( iter.hasNext() );
 		list = s.createQuery( "select baz from Baz baz where baz.stringDateMap['now'] is not null" ).list();
 		assertTrue( list.size()==1 );
 		list = s.createQuery(
 				"select baz from Baz baz where baz.stringDateMap['now'] is not null and baz.stringDateMap['big bang'] < baz.stringDateMap['now']"
 		).list();
 		assertTrue( list.size()==1 );
 		list = s.createQuery( "select index(date) from Baz baz join baz.stringDateMap date" ).list();
 		System.out.println(list);
 		assertTrue( list.size()==2 );
 
 		s.createQuery(
 				"from Foo foo where foo.integer not between 1 and 5 and foo.string not in ('cde', 'abc') and foo.string is not null and foo.integer<=3"
 		).list();
 
 		s.createQuery( "from Baz baz inner join baz.collectionComponent.nested.foos foo where foo.string is null" )
 				.list();
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof MckoiDialect) && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			s.createQuery(
 					"from Baz baz inner join baz.fooSet where '1' in (from baz.fooSet foo where foo.string is not null)"
 			).list();
 			s.createQuery(
 					"from Baz baz where 'a' in elements(baz.collectionComponent.nested.foos) and 1.0 in elements(baz.collectionComponent.nested.floats)"
 			).list();
 			s.createQuery(
 					"from Baz baz where 'b' in elements(baz.collectionComponent.nested.foos) and 1.0 in elements(baz.collectionComponent.nested.floats)"
 			).list();
 		}
 
 		s.createQuery( "from Foo foo join foo.foo where foo.foo in ('1','2','3')" ).list();
 		if ( !(getDialect() instanceof HSQLDialect) )
 			s.createQuery( "from Foo foo left join foo.foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo from Foo foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.string from Foo foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.string from Foo foo where foo.foo.string in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.long from Foo foo where foo.foo.string in ('1','2','3')" ).list();
 		s.createQuery( "select count(*) from Foo foo where foo.foo.string in ('1','2','3') or foo.foo.long in (1,2,3)" )
 				.list();
 		s.createQuery( "select count(*) from Foo foo where foo.foo.string in ('1','2','3') group by foo.foo.long" )
 				.list();
 
 		s.createQuery( "from Foo foo1 left join foo1.foo foo2 left join foo2.foo where foo1.string is not null" )
 				.list();
 		s.createQuery( "from Foo foo1 left join foo1.foo.foo where foo1.string is not null" ).list();
 		s.createQuery( "from Foo foo1 left join foo1.foo foo2 left join foo1.foo.foo foo3 where foo1.string is not null" )
 				.list();
 
 		s.createQuery( "select foo.formula from Foo foo where foo.formula > 0" ).list();
 
 		int len = s.createQuery( "from Foo as foo join foo.foo as foo2 where foo2.id >'a' or foo2.id <'a'" ).list().size();
 		assertTrue(len==2);
 
 		for ( Object entity : s.createQuery( "from Holder" ).list() ) {
 			s.delete( entity );
 		}
 
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery("from Baz baz left outer join fetch baz.manyToAny").uniqueResult();
 		assertTrue( Hibernate.isInitialized( baz.getManyToAny() ) );
 		assertTrue( baz.getManyToAny().size()==2 );
 		BarProxy barp = (BarProxy) baz.getManyToAny().get(0);
 		s.createQuery( "from Baz baz join baz.manyToAny" ).list();
 		assertTrue( s.createQuery( "select baz from Baz baz join baz.manyToAny a where index(a) = 0" ).list().size()==1 );
 
 		FooProxy foop = (FooProxy) s.get( Foo.class, foo.getKey() );
 		assertTrue( foop == baz.getManyToAny().get(1) );
 
 		barp.setBaz(baz);
 		assertTrue(
 				s.createQuery( "select bar from Bar bar where bar.baz.stringDateMap['now'] is not null" ).list().size()==1 );
 		assertTrue(
 				s.createQuery(
 						"select bar from Bar bar join bar.baz b where b.stringDateMap['big bang'] < b.stringDateMap['now'] and b.stringDateMap['now'] is not null"
 				).list()
 						.size()==1 );
 		assertTrue(
 				s.createQuery(
 						"select bar from Bar bar where bar.baz.stringDateMap['big bang'] < bar.baz.stringDateMap['now'] and bar.baz.stringDateMap['now'] is not null"
 				).list()
 						.size()==1 );
 
 		list = s.createQuery( "select foo.string, foo.component, foo.id from Bar foo" ).list();
 		assertTrue ( ( (FooComponent) ( (Object[]) list.get(0) )[1] ).getName().equals("foo") );
 		list = s.createQuery( "select elements(baz.components) from Baz baz" ).list();
 		assertTrue( list.size()==2 );
 		list = s.createQuery( "select bc.name from Baz baz join baz.components bc" ).list();
 		assertTrue( list.size()==2 );
 		//list = s.find("select bc from Baz baz join baz.components bc");
 
 		s.createQuery("from Foo foo where foo.integer < 10 order by foo.string").setMaxResults(12).list();
 
 		s.delete(barp);
 		s.delete(baz);
 		s.delete( foop.getFoo() );
 		s.delete(foop);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCascadeDeleteDetached() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		List list = new ArrayList();
 		list.add( new Fee() );
 		baz.setFees( list );
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		assertFalse( Hibernate.isInitialized( baz.getFees() ) );
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( baz );
 		s.flush();
 		assertFalse( s.createQuery( "from Fee" ).iterate().hasNext() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = new Baz();
 		list = new ArrayList();
 		list.add( new Fee() );
 		list.add( new Fee() );
 		baz.setFees(list);
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		Hibernate.initialize( baz.getFees() );
 		s.getTransaction().commit();
 		s.close();
 
 		assertTrue( baz.getFees().size() == 2 );
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete(baz);
 		s.flush();
 		assertFalse( s.createQuery( "from Fee" ).iterate().hasNext() );
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testForeignKeys() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Foo foo = new Foo();
 		List bag = new ArrayList();
 		bag.add(foo);
 		baz.setIdFooBag(bag);
 		baz.setFoo(foo);
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNonlazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.createCriteria(Baz.class)
 			//.setComment("criteria test")
 			.setFetchMode( "stringDateMap", FetchMode.JOIN )
 			.uniqueResult();
 		assertTrue( Hibernate.isInitialized( baz.getFooToGlarch() ) );
 		assertTrue( Hibernate.isInitialized( baz.getFooComponentToFoo() ) );
 		assertTrue( !Hibernate.isInitialized( baz.getStringSet() ) );
 		assertTrue( Hibernate.isInitialized( baz.getStringDateMap() ) );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testReuseDeletedCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.flush();
 		s.delete(baz);
 		Baz baz2 = new Baz();
 		baz2.setStringArray( new String[] {"x-y-z"} );
 		s.save(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		baz2.setStringSet( baz.getStringSet() );
 		baz2.setStringArray( baz.getStringArray() );
 		baz2.setFooArray( baz.getFooArray() );
 
 		s = openSession();
 		s.beginTransaction();
 		s.update(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		assertTrue( baz2.getStringArray().length==3 );
 		assertTrue( baz2.getStringSet().size()==3 );
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPropertyRef() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Holder h = new Holder();
 		h.setName("foo");
 		Holder h2 = new Holder();
 		h2.setName("bar");
 		h.setOtherHolder(h2);
 		Serializable hid = s.save(h);
 		Qux q = new Qux();
 		q.setHolder(h2);
 		Serializable qid = s.save(q);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		h = (Holder) s.load(Holder.class, hid);
 		assertEquals( h.getName(), "foo");
 		assertEquals( h.getOtherHolder().getName(), "bar");
 		Object[] res = (Object[]) s.createQuery( "from Holder h join h.otherHolder oh where h.otherHolder.name = 'bar'" )
 				.list()
 				.get(0);
 		assertTrue( res[0]==h );
 		q = (Qux) s.get(Qux.class, qid);
 		assertTrue( q.getHolder() == h.getOtherHolder() );
 		s.delete(h);
 		s.delete(q);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testQueryCollectionOfValues() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		Glarch g = new Glarch();
 		Serializable gid = s.save(g);
 
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) /*&& !(dialect instanceof MckoiDialect)*/ && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) && !(getDialect() instanceof TimesTenDialect) ) {
 			s.createFilter( baz.getFooArray(), "where size(this.bytes) > 0" ).list();
 			s.createFilter( baz.getFooArray(), "where 0 in elements(this.bytes)" ).list();
 		}
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Baz baz join baz.fooSet foo join foo.foo.foo foo2 where foo2.string = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.fooArray foo join foo.foo.foo foo2 where foo2.string = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.stringDateMap date where index(date) = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.topGlarchez g where index(g) = 'A'" ).list();
 		s.createQuery( "select index(g) from Baz baz join baz.topGlarchez g" ).list();
 
 		assertTrue( s.createQuery( "from Baz baz left join baz.stringSet" ).list().size()==3 );
 		baz = (Baz) s.createQuery( "from Baz baz join baz.stringSet str where str='foo'" ).list().get(0);
 		assertTrue( !Hibernate.isInitialized( baz.getStringSet() ) );
 		baz = (Baz) s.createQuery( "from Baz baz left join fetch baz.stringSet" ).list().get(0);
 		assertTrue( Hibernate.isInitialized( baz.getStringSet() ) );
 		assertTrue( s.createQuery( "from Baz baz join baz.stringSet string where string='foo'" ).list().size()==1 );
 		assertTrue( s.createQuery( "from Baz baz inner join baz.components comp where comp.name='foo'" ).list().size()==1 );
 		//List bss = s.find("select baz, ss from Baz baz inner join baz.stringSet ss");
 		s.createQuery( "from Glarch g inner join g.fooComponents comp where comp.fee is not null" ).list();
 		s.createQuery( "from Glarch g inner join g.fooComponents comp join comp.fee fee where fee.count > 0" ).list();
 		s.createQuery( "from Glarch g inner join g.fooComponents comp where comp.fee.count is not null" ).list();
 
 		s.delete(baz);
 		s.delete( s.get(Glarch.class, gid) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testBatchLoad() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		SortedSet stringSet = new TreeSet();
 		stringSet.add("foo");
 		stringSet.add("bar");
 		Set fooSet = new HashSet();
 		for (int i=0; i<3; i++) {
 			Foo foo = new Foo();
 			s.save(foo);
 			fooSet.add(foo);
 		}
 		baz.setFooSet(fooSet);
 		baz.setStringSet(stringSet);
 		s.save(baz);
 		Baz baz2 = new Baz();
 		fooSet = new HashSet();
 		for (int i=0; i<2; i++) {
 			Foo foo = new Foo();
 			s.save(foo);
 			fooSet.add(foo);
 		}
 		baz2.setFooSet(fooSet);
 		s.save(baz2);
 		Baz baz3 = new Baz();
 		stringSet = new TreeSet();
 		stringSet.add("foo");
 		stringSet.add("baz");
 		baz3.setStringSet(stringSet);
 		s.save(baz3);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz3 = (Baz) s.load( Baz.class, baz3.getCode() );
 		assertFalse( Hibernate.isInitialized(baz.getFooSet()) || Hibernate.isInitialized(baz2.getFooSet()) || Hibernate.isInitialized(baz3.getFooSet()) );
 		assertFalse( Hibernate.isInitialized(baz.getStringSet()) || Hibernate.isInitialized(baz2.getStringSet()) || Hibernate.isInitialized(baz3.getStringSet()) );
 		assertTrue( baz.getFooSet().size()==3 );
 		assertTrue( Hibernate.isInitialized(baz.getFooSet()) && Hibernate.isInitialized(baz2.getFooSet()) && Hibernate.isInitialized(baz3.getFooSet()));
@@ -1407,2001 +1409,2001 @@ public class FooBarTest extends LegacyTestCase {
 		q.setLockMode( "foo", LockMode.READ );
 		q.list();
 		assertTrue( s.getCurrentLockMode( b ) == LockMode.READ );
 		s.evict( baz );
 		tx.commit();
 
 		tx = s.beginTransaction();
 		assertTrue( s.getCurrentLockMode(b)==LockMode.NONE );
 		s.delete( s.load( Baz.class, baz.getCode() ) );
 		assertTrue( s.getCurrentLockMode(b)==LockMode.NONE );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		q = s.createQuery("from Foo foo, Bar bar, Bar bar2");
 		if ( !(getDialect() instanceof DB2Dialect) ) {
 			q.setLockMode("bar", LockMode.UPGRADE);
 		}
 		q.setLockMode("bar2", LockMode.READ);
 		result = (Object[]) q.list().get(0);
 		if ( !(getDialect() instanceof DB2Dialect) ) {
 			assertTrue( s.getCurrentLockMode( result[0] )==LockMode.UPGRADE && s.getCurrentLockMode( result[1] )==LockMode.UPGRADE );
 		}
 		s.delete( result[0] );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testManyToManyBag() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Serializable id = s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, id);
 		baz.getFooBag().add( new Foo() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, id);
 		assertTrue( !Hibernate.isInitialized( baz.getFooBag() ) );
 		assertTrue( baz.getFooBag().size()==1 );
 		if ( !(getDialect() instanceof HSQLDialect) ) assertTrue( Hibernate.isInitialized( baz.getFooBag().iterator().next() ) );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testIdBag() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		s.save(baz);
 		List l = new ArrayList();
 		List l2 = new ArrayList();
 		baz.setIdFooBag(l);
 		baz.setByteBag(l2);
 		l.add( new Foo() );
 		l.add( new Bar() );
 		byte[] bytes = "ffo".getBytes();
 		l2.add(bytes);
 		l2.add( "foo".getBytes() );
 		s.flush();
 		l.add( new Foo() );
 		l.add( new Bar() );
 		l2.add( "bar".getBytes() );
 		s.flush();
 		s.delete( l.remove(3) );
 		bytes[1]='o';
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getIdFooBag().size()==3 );
 		assertTrue( baz.getByteBag().size()==3 );
 		bytes = "foobar".getBytes();
 		Iterator iter = baz.getIdFooBag().iterator();
 		while ( iter.hasNext() ) s.delete( iter.next() );
 		baz.setIdFooBag(null);
 		baz.getByteBag().add(bytes);
 		baz.getByteBag().add(bytes);
 		assertTrue( baz.getByteBag().size()==5 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getIdFooBag().size()==0 );
 		assertTrue( baz.getByteBag().size()==5 );
 		baz.getIdFooBag().add( new Foo() );
 		iter = baz.getByteBag().iterator();
 		iter.next();
 		iter.remove();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getIdFooBag().size()==1 );
 		assertTrue( baz.getByteBag().size()==4 );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	private boolean isOuterJoinFetchingDisabled() {
 		return new Integer(0).equals( ( (SessionFactoryImplementor) sessionFactory() ).getSettings().getMaximumFetchDepth() );
 	}
 
 	@Test
 	public void testForceOuterJoin() throws Exception {
 		if ( isOuterJoinFetchingDisabled() ) {
 			return;
 		}
 
 		Session s = openSession();
 		s.beginTransaction();
 		Glarch g = new Glarch();
 		FooComponent fc = new FooComponent();
 		fc.setGlarch(g);
 		FooProxy f = new Foo();
 		FooProxy f2 = new Foo();
 		f.setComponent(fc);
 		f.setFoo(f2);
 		s.save(f2);
 		Serializable id = s.save(f);
 		Serializable gid = s.getIdentifier( f.getComponent().getGlarch() );
 		s.getTransaction().commit();
 		s.close();
 
 		sessionFactory().evict(Foo.class);
 
 		s = openSession();
 		s.beginTransaction();
 		f = (FooProxy) s.load(Foo.class, id);
 		assertFalse( Hibernate.isInitialized(f) );
 		assertTrue( Hibernate.isInitialized( f.getComponent().getGlarch() ) ); //outer-join="true"
 		assertFalse( Hibernate.isInitialized( f.getFoo() ) ); //outer-join="auto"
 		assertEquals( s.getIdentifier( f.getComponent().getGlarch() ), gid );
 		s.delete(f);
 		s.delete( f.getFoo() );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testEmptyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Serializable id = s.save( new Baz() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Baz baz = (Baz) s.load(Baz.class, id);
 		Set foos = baz.getFooSet();
 		assertTrue( foos.size() == 0 );
 		Foo foo = new Foo();
 		foos.add( foo );
 		s.save(foo);
 		s.flush();
 		s.delete(foo);
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testOneToOneGenerator() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		X x = new X();
 		Y y = new Y();
 		x.setY(y);
 		y.setTheX(x);
 		x.getXxs().add( new X.XX(x) );
 		x.getXxs().add( new X.XX(x) );
 		Serializable id = s.save(y);
 		assertEquals( id, s.save(x) );
 		s.flush();
 		assertTrue( s.contains(y) && s.contains(x) );
 		s.getTransaction().commit();
 		s.close();
 		assertEquals( new Long(x.getId()), y.getId() );
 
 		s = openSession();
 		s.beginTransaction();
 		x = new X();
 		y = new Y();
 		x.setY(y);
 		y.setTheX(x);
 		x.getXxs().add( new X.XX(x) );
 		s.save(y);
 		s.flush();
 		assertTrue( s.contains(y) && s.contains(x) );
 		s.getTransaction().commit();
 		s.close();
 		assertEquals( new Long(x.getId()), y.getId() );
 
 		s = openSession();
 		s.beginTransaction();
 		x = new X();
 		y = new Y();
 		x.setY(y);
 		y.setTheX(x);
 		x.getXxs().add( new X.XX(x) );
 		x.getXxs().add( new X.XX(x) );
 		id = s.save(x);
 		assertEquals( id, y.getId() );
 		assertEquals( id, new Long( x.getId() ) );
 		s.flush();
 		assertTrue( s.contains(y) && s.contains(x) );
 		doDelete( s, "from X x" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testLimit() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		for ( int i=0; i<10; i++ ) s.save( new Foo() );
 		Iterator iter = s.createQuery("from Foo foo")
 			.setMaxResults(4)
 			.setFirstResult(2)
 			.iterate();
 		int count=0;
 		while ( iter.hasNext() ) {
 			iter.next();
 			count++;
 		}
 		assertTrue(count==4);
 		iter = s.createQuery("select distinct foo from Foo foo")
 			.setMaxResults(2)
 			.setFirstResult(2)
 			.list()
 			.iterator();
 		count=0;
 		while ( iter.hasNext() ) {
 			iter.next();
 			count++;
 		}
 		assertTrue(count==2);
 		iter = s.createQuery("select distinct foo from Foo foo")
 		.setMaxResults(3)
 		.list()
 		.iterator();
 		count=0;
 		while ( iter.hasNext() ) {
 			iter.next();
 			count++;
 		}
 		assertTrue(count==3);
 		assertEquals( 10, doDelete( s, "from Foo foo" ) );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCustom() throws Exception {
 		GlarchProxy g = new Glarch();
 		Multiplicity m = new Multiplicity();
 		m.count = 12;
 		m.glarch = (Glarch) g;
 		g.setMultiple(m);
 
 		Session s = openSession();
 		s.beginTransaction();
 		Serializable gid = s.save(g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		//g = (Glarch) s.createQuery( "from Glarch g where g.multiple.count=12" ).list().get(0);
 		s.createQuery( "from Glarch g where g.multiple.count=12" ).list().get( 0 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (Glarch) s.createQuery( "from Glarch g where g.multiple.glarch=g and g.multiple.count=12" ).list().get(0);
 		assertTrue( g.getMultiple()!=null );
 		assertEquals( g.getMultiple().count, 12 );
 		assertSame(g.getMultiple().glarch, g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getMultiple() != null );
 		assertEquals( g.getMultiple().count, 12 );
 		assertSame( g.getMultiple().glarch, g );
 		s.delete(g);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testSaveAddDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Set bars = new HashSet();
 		baz.setCascadingBars( bars );
 		s.save( baz );
 		s.flush();
 		baz.getCascadingBars().add( new Bar() );
 		s.delete(baz);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNamedParams() throws Exception {
 		Bar bar = new Bar();
 		Bar bar2 = new Bar();
 		bar.setName("Bar");
 		bar2.setName("Bar Two");
 		bar.setX( 10 );
 		bar2.setX( 1000 );Baz baz = new Baz();
 		baz.setCascadingBars( new HashSet() );
 		baz.getCascadingBars().add(bar);
 		bar.setBaz(baz);
 
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		s.save( baz );
 		s.save( bar2 );
 
 		List list = s.createQuery(
 				"from Bar bar left join bar.baz baz left join baz.cascadingBars b where bar.name like 'Bar %'"
 		).list();
 		Object row = list.iterator().next();
 		assertTrue( row instanceof Object[] && ( (Object[]) row ).length==3 );
 
 		Query q = s.createQuery("select bar, b from Bar bar left join bar.baz baz left join baz.cascadingBars b where bar.name like 'Bar%'");
 		list = q.list();
 		if ( !(getDialect() instanceof SAPDBDialect) ) assertTrue( list.size()==2 );
 
 		q = s.createQuery("select bar, b from Bar bar left join bar.baz baz left join baz.cascadingBars b where ( bar.name in (:nameList) or bar.name in (:nameList) ) and bar.string = :stringVal");
 		HashSet nameList = new HashSet();
 		nameList.add( "bar" );
 		nameList.add( "Bar" );
 		nameList.add( "Bar Two" );
 		q.setParameterList( "nameList", nameList );
 		q.setParameter( "stringVal", "a string" );
 		list = q.list();
 		if ( !(getDialect() instanceof SAPDBDialect) ) assertTrue( list.size()==2 );
 
 		try {
 			q.setParameterList("nameList", (Collection)null);
 			fail("Should throw an queryexception when passing a null!");
 		} catch (QueryException qe) {
 			//should happen
 		}
 
 		q = s.createQuery("select bar, b from Bar bar inner join bar.baz baz inner join baz.cascadingBars b where bar.name like 'Bar%'");
 		Object result = q.uniqueResult();
 		assertTrue( result != null );
 		q = s.createQuery("select bar, b from Bar bar left join bar.baz baz left join baz.cascadingBars b where bar.name like :name and b.name like :name");
 		q.setString( "name", "Bar%" );
 		list = q.list();
 		assertTrue( list.size()==1 );
 
 
 		// This test added for issue HB-297 - there is an named parameter in the Order By clause
 		q = s.createQuery("select bar from Bar bar order by ((bar.x - :valueX)*(bar.x - :valueX))");
 		q.setInteger( "valueX", bar.getX() + 1 );
 		list = q.list();
 		assertTrue( ((Bar) list.get( 0 )).getX() == bar.getX() );
 		q.setInteger( "valueX", bar2.getX() + 1 );
 		list = q.list();
 		assertTrue( ((Bar)list.get(0)).getX() == bar2.getX());
 
 		s.delete(baz);
 		s.delete(bar2);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	@RequiresDialectFeature(
 			value = DialectChecks.SupportsEmptyInListCheck.class,
 			comment = "Dialect does not support SQL empty in list [x in ()]"
 	)
 	public void testEmptyInListQuery() {
 		Session s = openSession();
 		s.beginTransaction();
 
 		Query q = s.createQuery( "select bar from Bar as bar where bar.name in (:nameList)" );
 		q.setParameterList( "nameList", Collections.EMPTY_LIST );
 		assertEquals( 0, q.list().size() );
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testParameterCheck() throws HibernateException {
 		Session s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.x > :myX");
 			q.list();
 			fail("Should throw QueryException for missing myX");
 		}
 		catch (QueryException iae) {
 			// should happen
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.x > ?");
 			q.list();
 			fail("Should throw QueryException for missing ?");
 		}
 		catch (QueryException iae) {
 			// should happen
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.x > ? or bar.short = 1 or bar.string = 'ff ? bb'");
 			q.setInteger(0, 1);
 			q.list();
 		}
 		catch (QueryException iae) {
 			fail("Should not throw QueryException for missing ?");
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.string = ' ? ' or bar.string = '?'");
 			q.list();
 		}
 		catch (QueryException iae) {
 			fail("Should not throw QueryException for ? in quotes");
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.string = ? or bar.string = ? or bar.string = ?");
 			q.setParameter(0, "bull");
 			q.setParameter(2, "shit");
 			q.list();
 			fail("should throw exception telling me i have not set parameter 1");
 		}
 		catch (QueryException iae) {
 			// should happen!
 		}
 		finally {
 			s.close();
 		}
 	}
 
 	@Test
 	public void testDyna() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		g.setName("G");
 		Serializable id = s.save(g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getName().equals("G") );
 		assertTrue( g.getDynaBean().get("foo").equals("foo") && g.getDynaBean().get("bar").equals( new Integer(66) ) );
 		assertTrue( ! (g instanceof Glarch) );
 		g.getDynaBean().put("foo", "bar");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getDynaBean().get("foo").equals("bar") && g.getDynaBean().get("bar").equals( new Integer(66) ) );
 		g.setDynaBean(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getDynaBean()==null );
 		s.delete(g);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testFindByCriteria() throws Exception {
 		if ( getDialect() instanceof DB2Dialect ) {
 			return;
 		}
 
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo f = new Foo();
 		s.save( f );
 		s.flush();
 
 		List list = s.createCriteria(Foo.class)
 			.add( Restrictions.eq( "integer", f.getInteger() ) )
 			.add( Restrictions.eqProperty("integer", "integer") )
 			.add( Restrictions.like( "string", f.getString().toUpperCase() ).ignoreCase() )
 			.add( Restrictions.in( "boolean", new Boolean[] { f.getBoolean(), f.getBoolean() } ) )
 			.setFetchMode("foo", FetchMode.JOIN)
 			.setFetchMode("baz", FetchMode.SELECT)
 			.setFetchMode("abstracts", FetchMode.JOIN)
 			.list();
 		assertTrue( list.size() == 1 && list.get( 0 ) == f );
 
 		list = s.createCriteria(Foo.class).add(
 				Restrictions.disjunction()
 					.add( Restrictions.eq( "integer", f.getInteger() ) )
 					.add( Restrictions.like( "string", f.getString() ) )
 					.add( Restrictions.eq( "boolean", f.getBoolean() ) )
 			)
 			.add( Restrictions.isNotNull("boolean") )
 			.list();
 		assertTrue( list.size() == 1 && list.get( 0 ) == f );
 
 		Foo example = new Foo();
 		example.setString("a STRing");
 		list = s.createCriteria(Foo.class).add(
 			Example.create(example)
 				.excludeZeroes()
 				.ignoreCase()
 				.excludeProperty("bool")
 				.excludeProperty("char")
 				.excludeProperty("yesno")
 			)
 			.list();
 		assertTrue(
 				"Example API without like did not work correctly, size was " + list.size(),
 				list.size() == 1 && list.get( 0 ) == f
 		);
 		example.setString("rin");
 
 		list = s.createCriteria(Foo.class).add(
 			Example.create(example)
 				.excludeZeroes()
 				.enableLike(MatchMode.ANYWHERE)
 				.excludeProperty("bool")
 				.excludeProperty("char")
 				.excludeProperty("yesno")
 			)
 			.list();
 		assertTrue( "Example API without like did not work correctly, size was " + list.size(), list.size()==1 && list.get(0)==f );
 
 		list = s.createCriteria(Foo.class)
 			.add( Restrictions.or(
 					Restrictions.and(
 					Restrictions.eq( "integer", f.getInteger() ),
 					Restrictions.like( "string", f.getString() )
 				),
 				Restrictions.eq( "boolean", f.getBoolean() )
 			) )
 			.list();
 		assertTrue( list.size()==1 && list.get(0)==f );
 		list = s.createCriteria(Foo.class)
 			.setMaxResults(5)
 			.addOrder( Order.asc("date") )
 			.list();
 		assertTrue( list.size()==1 && list.get(0)==f );
 		if(!(getDialect() instanceof TimesTenDialect || getDialect() instanceof HSQLDialect)) {
 			list = s.createCriteria(Foo.class).setMaxResults(0).list();
 			assertTrue( list.size()==0 );
 		}
 		list = s.createCriteria(Foo.class)
 			.setFirstResult(1)
 			.addOrder( Order.asc("date") )
 			.addOrder( Order.desc("string") )
 			.list();
 		assertTrue( list.size() == 0 );
 		list = s.createCriteria(Foo.class)
 			.setFetchMode( "component.importantDates", FetchMode.JOIN )
 			.list();
 		assertTrue( list.size() == 3 );
 
 		list = s.createCriteria(Foo.class)
 			.setFetchMode( "component.importantDates", FetchMode.JOIN )
 			.setResultTransformer(Criteria.DISTINCT_ROOT_ENTITY)
 			.list();
 		assertTrue( list.size()==1 );
 
 		f.setFoo( new Foo() );
 		s.save( f.getFoo() );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createCriteria(Foo.class)
 			.add( Restrictions.eq( "integer", f.getInteger() ) )
 			.add( Restrictions.like( "string", f.getString() ) )
 			.add( Restrictions.in( "boolean", new Boolean[] { f.getBoolean(), f.getBoolean() } ) )
 			.add( Restrictions.isNotNull("foo") )
 			.setFetchMode( "foo", FetchMode.JOIN )
 			.setFetchMode( "baz", FetchMode.SELECT )
 			.setFetchMode( "component.glarch", FetchMode.SELECT )
 			.setFetchMode( "foo.baz", FetchMode.SELECT )
 			.setFetchMode( "foo.component.glarch", FetchMode.SELECT )
 			.list();
 		f = (Foo) list.get(0);
 		assertTrue( Hibernate.isInitialized( f.getFoo() ) );
 		assertTrue( !Hibernate.isInitialized( f.getComponent().getGlarch() ) );
 
 		s.save( new Bar() );
 		list = s.createCriteria(Bar.class)
 			.list();
 		assertTrue( list.size() == 1 );
 		assertTrue( s.createCriteria(Foo.class).list().size()==3 );
 		s.delete( list.get( 0 ) );
 
 		s.delete( f.getFoo() );
 		s.delete(f);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testAfterDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		s.flush();
 		s.delete(foo);
 		s.save(foo);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionWhere() throws Exception {
 		Foo foo1 = new Foo();
 		Foo foo2 = new Foo();
 		Baz baz = new Baz();
 		Foo[] arr = new Foo[10];
 		arr[0] = foo1;
 		arr[9] = foo2;
 
 		Session s = openSession();
 		s.beginTransaction();
 		s.save( foo1 );
 		s.save(foo2);
 		baz.setFooArray( arr );
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooArray().length == 1 );
 		assertTrue( s.createQuery( "from Baz baz join baz.fooArray foo" ).list().size()==1 );
 		assertTrue( s.createQuery( "from Foo foo" ).list().size()==2 );
 		assertTrue( s.createFilter( baz.getFooArray(), "" ).list().size() == 1 );
 		//assertTrue( s.delete("from java.lang.Object o")==9 );
 		doDelete( s, "from Foo foo" );
 		final String bazid = baz.getCode();
 		s.delete( baz );
 		int rows = s.doReturningWork(
 				new AbstractReturningWork<Integer>() {
 					@Override
 					public Integer execute(Connection connection) throws SQLException {
 						return connection.createStatement()
 								.executeUpdate( "delete from FOO_ARRAY where id_='" + bazid + "' and i>=8" );
 					}
 				}
 		);
 		assertTrue( rows == 1 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testComponentParent() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		BarProxy bar = new Bar();
 		bar.setBarComponent( new FooComponent() );
 		Baz baz = new Baz();
 		baz.setComponents( new FooComponent[] { new FooComponent(), new FooComponent() } );
 		s.save(bar);
 		s.save(baz);
 		t.commit();
 		s.close();
 		s = openSession();
 		t = s.beginTransaction();
 		bar = (BarProxy) s.load(Bar.class, bar.getKey());
 		s.load(baz, baz.getCode());
 		assertTrue( bar.getBarComponent().getParent()==bar );
 		assertTrue( baz.getComponents()[0].getBaz()==baz && baz.getComponents()[1].getBaz()==baz );
 		s.delete(baz);
 		s.delete(bar);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionCache() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( Baz.class, baz.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void ntestAssociationId() throws Exception {
 		// IMPL NOTE : previously not being run due to the name
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Bar bar = new Bar();
 		String id = (String) s.save(bar);
 		MoreStuff more = new MoreStuff();
 		more.setName("More Stuff");
 		more.setIntId(12);
 		more.setStringId("id");
 		Stuff stuf = new Stuff();
 		stuf.setMoreStuff(more);
 		more.setStuffs( new ArrayList() );
 		more.getStuffs().add(stuf);
 		stuf.setFoo(bar);
 		stuf.setId(1234);
 		stuf.setProperty( TimeZone.getDefault() );
 		s.save(more);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List results = s.createQuery(
 				"from Stuff as s where s.foo.id = ? and s.id.id = ? and s.moreStuff.id.intId = ? and s.moreStuff.id.stringId = ?"
 		)
 				.setParameter( 0, bar, Hibernate.entity(Foo.class) )
 				.setParameter( 1, new Long(1234), Hibernate.LONG )
 				.setParameter( 2, new Integer(12), Hibernate.INTEGER )
 				.setParameter( 3, "id", Hibernate.STRING )
 				.list();
 		assertEquals( 1, results.size() );
 		results = s.createQuery( "from Stuff as s where s.foo.id = ? and s.id.id = ? and s.moreStuff.name = ?" )
 				.setParameter( 0, bar, Hibernate.entity(Foo.class) )
 				.setParameter( 1, new Long(1234), Hibernate.LONG )
 				.setParameter( 2, "More Stuff", Hibernate.STRING )
 				.list();
 		assertEquals( 1, results.size() );
 		s.createQuery( "from Stuff as s where s.foo.string is not null" ).list();
 		assertTrue(
 				s.createQuery( "from Stuff as s where s.foo > '0' order by s.foo" ).list().size()==1
 		);
 		//s.createCriteria(Stuff.class).createCriteria("id.foo").add( Expression.isNull("foo") ).list();
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		FooProxy foo = (FooProxy) s.load(Foo.class, id);
 		s.load(more, more);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Stuff stuff = new Stuff();
 		stuff.setFoo(foo);
 		stuff.setId(1234);
 		stuff.setMoreStuff(more);
 		s.load(stuff, stuff);
 		assertTrue( stuff.getProperty().equals( TimeZone.getDefault() ) );
 		assertTrue( stuff.getMoreStuff().getName().equals("More Stuff") );
 		doDelete( s, "from MoreStuff" );
 		doDelete( s, "from Foo foo" );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCascadeSave() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		List list = new ArrayList();
 		list.add( new Fee() );
 		list.add( new Fee() );
 		baz.setFees( list );
 		s.save(baz);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		assertTrue( baz.getFees().size() == 2 );
 		s.delete(baz);
 		assertTrue( !s.createQuery( "from Fee fee" ).iterate().hasNext() );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionsInSelect() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Foo[] foos = new Foo[] { null, new Foo() };
 		s.save( foos[1] );
 		Baz baz = new Baz();
 		baz.setDefaults();
 		baz.setFooArray(foos);
 		s.save(baz);
 		Baz baz2 = new Baz();
 		baz2.setDefaults();
 		s.save(baz2);
 
 		Bar bar = new Bar();
 		bar.setBaz(baz);
 		s.save(bar);
 
 		List list = s.createQuery( "select new Result(foo.string, foo.long, foo.integer) from Foo foo" ).list();
 		assertTrue( list.size()==2 && ( list.get(0) instanceof Result ) && ( list.get(1) instanceof Result ) );
 		/*list = s.find("select new Result( baz.name, foo.long, count(elements(baz.fooArray)) ) from Baz baz join baz.fooArray foo group by baz.name, foo.long");
 		assertTrue( list.size()==1 && ( list.get(0) instanceof Result ) );
 		Result r = ((Result) list.get(0) );
 		assertEquals( r.getName(), baz.getName() );
 		assertEquals( r.getCount(), 1 );
 		assertEquals( r.getAmount(), foos[1].getLong().longValue() );*/
 		list = s.createQuery(
 				"select new Result( baz.name, max(foo.long), count(foo) ) from Baz baz join baz.fooArray foo group by baz.name"
 		).list();
 		assertTrue( list.size()==1 && ( list.get(0) instanceof Result ) );
 		Result r = ((Result) list.get(0) );
 		assertEquals( r.getName(), baz.getName() );
 		assertEquals( r.getCount(), 1 );
 		assertTrue( r.getAmount() > 696969696969696000l );
 
 
 		//s.find("select max( elements(bar.baz.fooArray) ) from Bar as bar");
 		//The following test is disabled for databases with no subselects...also for Interbase (not sure why).
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) /*&& !(dialect instanceof MckoiDialect)*/ && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			s.createQuery( "select count(*) from Baz as baz where 1 in indices(baz.fooArray)" ).list();
 			s.createQuery( "select count(*) from Bar as bar where 'abc' in elements(bar.baz.fooArray)" ).list();
 			s.createQuery( "select count(*) from Bar as bar where 1 in indices(bar.baz.fooArray)" ).list();
 			if ( !(getDialect() instanceof DB2Dialect) &&  !(getDialect() instanceof Oracle8iDialect ) && !( getDialect() instanceof SybaseDialect ) && !( getDialect() instanceof Sybase11Dialect ) && !( getDialect() instanceof SybaseASE15Dialect ) && !( getDialect() instanceof PostgreSQLDialect )) {
 				// SybaseAnywhereDialect supports implicit conversions from strings to ints
 				s.createQuery(
 						"select count(*) from Bar as bar, bar.component.glarch.proxyArray as g where g.id in indices(bar.baz.fooArray)"
 				).list();
 				s.createQuery(
 						"select max( elements(bar.baz.fooArray) ) from Bar as bar, bar.component.glarch.proxyArray as g where g.id in indices(bar.baz.fooArray)"
 				).list();
 			}
 			s.createQuery(
 					"select count(*) from Bar as bar where '1' in (from bar.component.glarch.proxyArray g where g.name='foo')"
 			).list();
 			s.createQuery(
 					"select count(*) from Bar as bar where '1' in (from bar.component.glarch.proxyArray g where g.name='foo')"
 			).list();
 			s.createQuery(
 					"select count(*) from Bar as bar left outer join bar.component.glarch.proxyArray as pg where '1' in (from bar.component.glarch.proxyArray)"
 			).list();
 		}
 
 		list = s.createQuery(
 				"from Baz baz left join baz.fooToGlarch join fetch baz.fooArray foo left join fetch foo.foo"
 		).list();
 		assertTrue( list.size()==1 && ( (Object[]) list.get(0) ).length==2 );
 
 		s.createQuery(
 				"select baz.name from Bar bar inner join bar.baz baz inner join baz.fooSet foo where baz.name = bar.string"
 		).list();
 		s.createQuery(
 				"SELECT baz.name FROM Bar AS bar INNER JOIN bar.baz AS baz INNER JOIN baz.fooSet AS foo WHERE baz.name = bar.string"
 		).list();
 
 		if ( !( getDialect() instanceof HSQLDialect ) ) s.createQuery(
 				"select baz.name from Bar bar join bar.baz baz left outer join baz.fooSet foo where baz.name = bar.string"
 		).list();
 
 		s.createQuery( "select baz.name from Bar bar join bar.baz baz join baz.fooSet foo where baz.name = bar.string" )
 				.list();
 		s.createQuery(
 				"SELECT baz.name FROM Bar AS bar JOIN bar.baz AS baz JOIN baz.fooSet AS foo WHERE baz.name = bar.string"
 		).list();
 
 		if ( !( getDialect() instanceof HSQLDialect ) ) {
 			s.createQuery(
 					"select baz.name from Bar bar left join bar.baz baz left join baz.fooSet foo where baz.name = bar.string"
 			).list();
 			s.createQuery( "select foo.string from Bar bar left join bar.baz.fooSet foo where bar.string = foo.string" )
 					.list();
 		}
 
 		s.createQuery(
 				"select baz.name from Bar bar left join bar.baz baz left join baz.fooArray foo where baz.name = bar.string"
 		).list();
 		s.createQuery( "select foo.string from Bar bar left join bar.baz.fooArray foo where bar.string = foo.string" )
 				.list();
 
 		s.createQuery(
 				"select bar.string, foo.string from Bar bar inner join bar.baz as baz inner join baz.fooSet as foo where baz.name = 'name'"
 		).list();
 		s.createQuery( "select foo from Bar bar inner join bar.baz as baz inner join baz.fooSet as foo" ).list();
 		s.createQuery( "select foo from Bar bar inner join bar.baz.fooSet as foo" ).list();
 
 		s.createQuery(
 				"select bar.string, foo.string from Bar bar join bar.baz as baz join baz.fooSet as foo where baz.name = 'name'"
 		).list();
 		s.createQuery( "select foo from Bar bar join bar.baz as baz join baz.fooSet as foo" ).list();
 		s.createQuery( "select foo from Bar bar join bar.baz.fooSet as foo" ).list();
 
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooArray foo" ).list().size()==1 );
 
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooSet foo" ).list().size()==0 );
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooArray foo" ).list().size()==1 );
 
 		s.delete(bar);
 
 		if ( getDialect() instanceof DB2Dialect || getDialect() instanceof PostgreSQLDialect ) {
 			s.createQuery( "select one from One one join one.manies many group by one order by count(many)" ).iterate();
 			s.createQuery( "select one from One one join one.manies many group by one having count(many) < 5" )
 					.iterate();
 		}
 
 		s.createQuery( "from One one join one.manies many where one.id = 1 and many.id = 1" ).list();
 		s.createQuery( "select one.id, elements(one.manies) from One one" ).iterate();
 		s.createQuery( "select max( elements(one.manies) ) from One one" ).iterate();
 		s.createQuery( "select one, elements(one.manies) from One one" ).list();
 		Iterator iter = s.createQuery( "select elements(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), Hibernate.STRING )
 				.iterate();
 		assertTrue( iter.next()==foos[1] && !iter.hasNext() );
 		list = s.createQuery( "select elements(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), Hibernate.STRING )
 				.list();
 		assertEquals( 1, list.size() );
 		iter = s.createQuery( "select indices(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), Hibernate.STRING )
 				.iterate();
 		assertTrue( iter.next().equals( new Integer(1) ) && !iter.hasNext() );
 
 		iter = s.createQuery( "select size(baz.stringSet) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), Hibernate.STRING )
 				.iterate();
 		assertEquals( new Integer(3), iter.next() );
 
 		s.createQuery( "from Foo foo where foo.component.glarch.id is not null" ).list();
 
 		iter = s.createQuery(
 				"select baz, size(baz.stringSet), count( distinct elements(baz.stringSet) ), max( elements(baz.stringSet) ) from Baz baz group by baz"
 		).iterate();
 		while ( iter.hasNext() ) {
 			Object[] arr = (Object[]) iter.next();
-            LOG.info(arr[0] + " " + arr[1] + " " + arr[2] + " " + arr[3]);
+            log.info(arr[0] + " " + arr[1] + " " + arr[2] + " " + arr[3]);
 		}
 
 		s.delete(baz);
 		s.delete(baz2);
 		s.delete( foos[1] );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testNewFlushing() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.flush();
 		baz.getStringArray()[0] = "a new value";
 		Iterator iter = s.createQuery( "from Baz baz" ).iterate();//no flush
 		assertTrue( iter.next()==baz );
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		boolean found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("a new value") ) found = true;
 		}
 		assertTrue( found );
 		baz.setStringArray( null );
 		s.createQuery( "from Baz baz" ).iterate(); //no flush
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		assertTrue( !iter.hasNext() );
 		baz.getStringList().add( "1E1" );
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		assertTrue( !iter.hasNext() );
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("1E1") ) found = true;
 		}
 		assertTrue( found );
 		baz.getStringList().remove( "1E1" );
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate(); //no flush
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("1E1") ) found = true;
 		}
 		assertTrue(!found);
 
 		List newList = new ArrayList();
 		newList.add("value");
 		baz.setStringList( newList );
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		baz.setStringList( null );
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		assertTrue( !iter.hasNext() );
 
 		baz.setStringList(newList);
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		assertTrue( iter.hasNext() );
 
 		s.delete( baz );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"UnnecessaryBoxing", "unchecked"})
 	public void testPersistCollections() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		assertEquals( 0, ( (Long) s.createQuery( "select count(*) from Bar" ).iterate().next() ).longValue() );
 		assertTrue( s.createQuery( "select count(*) from Bar b" ).iterate().next().equals( new Long(0) ) );
 		assertFalse( s.createQuery( "from Glarch g" ).iterate().hasNext() );
 
 		Baz baz = new Baz();
 		s.save(baz);
 		baz.setDefaults();
 		baz.setStringArray( new String[] { "stuff" } );
 		Set bars = new HashSet();
 		bars.add( new Bar() );
 		baz.setCascadingBars(bars);
 		HashMap sgm = new HashMap();
 		sgm.put( "a", new Glarch() );
 		sgm.put( "b", new Glarch() );
 		baz.setStringGlarchMap(sgm);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1L, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) ( (Object[]) s.createQuery( "select baz, baz from Baz baz" ).list().get(0) )[1];
 		assertTrue( baz.getCascadingBars().size()==1 );
 		//System.out.println( s.print(baz) );
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo2 = new Foo() ;
 		s.save(foo2);
 		baz.setFooArray( new Foo[] { foo, foo, null, foo2 } );
 		baz.getFooSet().add(foo);
 		baz.getCustoms().add( new String[] { "new", "custom" } );
 		baz.setStringArray(null);
 		baz.getStringList().set(0, "new value");
 		baz.setStringSet( new TreeSet() );
 		Time time = new java.sql.Time(12345);
 		baz.getTimeArray()[2] = time;
 		//System.out.println(time);
 
 		assertTrue( baz.getStringGlarchMap().size()==1 );
 
 		//The following test is disabled databases with no subselects
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			List list = s.createQuery(
 					"select foo from Foo foo, Baz baz where foo in elements(baz.fooArray) and 3 = some elements(baz.intArray) and 4 > all indices(baz.intArray)"
 			).list();
 			assertTrue( "collection.elements find", list.size()==2 );
 		}
 		if (!(getDialect() instanceof SAPDBDialect) ) { // SAPDB doesn't like distinct with binary type
 			List list = s.createQuery( "select distinct foo from Baz baz join baz.fooArray foo" ).list();
 			assertTrue( "collection.elements find", list.size()==2 );
 		}
 
 		List list = s.createQuery( "select foo from Baz baz join baz.fooSet foo" ).list();
 		assertTrue( "association.elements find", list.size()==1 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( "collection of custom types - added element", baz.getCustoms().size()==4 && baz.getCustoms().get(0)!=null );
 		assertTrue ( "component of component in collection", baz.getComponents()[1].getSubcomponent()!=null );
 		assertTrue( baz.getComponents()[1].getBaz()==baz );
 		assertTrue( "set of objects", ( (FooProxy) baz.getFooSet().iterator().next() ).getKey().equals( foo.getKey() ));
 		assertTrue( "collection removed", baz.getStringArray().length==0 );
 		assertTrue( "changed element", baz.getStringList().get(0).equals("new value"));
 		assertTrue( "replaced set", baz.getStringSet().size()==0 );
 		assertTrue( "array element change", baz.getTimeArray()[2]!=null );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		//System.out.println( s.print(baz) );
 		baz.getStringSet().add("two");
 		baz.getStringSet().add("one");
 		baz.getBag().add("three");
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getStringSet().size()==2 );
 		assertTrue( baz.getStringSet().first().equals("one") );
 		assertTrue( baz.getStringSet().last().equals("two") );
 		assertTrue( baz.getBag().size()==5 );
 		baz.getStringSet().remove("two");
 		baz.getBag().remove("duplicate");
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getCascadingBars().size()==1 );
 		Bar bar = new Bar();
 		Bar bar2 = new Bar();
 		s.save(bar); s.save(bar2);
 		baz.setTopFoos( new HashSet() );
 		baz.getTopFoos().add(bar);
 		baz.getTopFoos().add(bar2);
 		assertTrue( baz.getCascadingBars().size()==1 );
 		baz.setTopGlarchez( new TreeMap() );
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		baz.getTopGlarchez().put( new Character('G'), g );
 		HashMap map = new HashMap();
 		map.put(bar, g);
 		map.put(bar2, g);
 		baz.setFooToGlarch(map);
 		map = new HashMap();
 		map.put( new FooComponent("name", 123, null, null), bar );
 		map.put( new FooComponent("nameName", 12, null, null), bar );
 		baz.setFooComponentToFoo(map);
 		map = new HashMap();
 		map.put(bar, g);
 		baz.setGlarchToFoo(map);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getCascadingBars().size()==1 );
 
 		Session s2 = openSession();
 		Transaction txn2 = s2.beginTransaction();
 		assertEquals( 3, ((Long) s2.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		Baz baz2 = (Baz) s2.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		Object o = baz2.getFooComponentToFoo().get( new FooComponent("name", 123, null, null) );
 		assertTrue(
 			o==baz2.getFooComponentToFoo().get( new FooComponent("nameName", 12, null, null) ) && o!=null
 		);
 		txn2.commit();
 		s2.close();
 
 		assertTrue( Hibernate.isInitialized( baz.getFooToGlarch() ) );
 		assertTrue( baz.getTopFoos().size()==2 );
 		assertTrue( baz.getTopGlarchez().size()==1 );
 		assertTrue( baz.getTopFoos().iterator().next()!=null );
 		assertTrue( baz.getStringSet().size()==1 );
 		assertTrue( baz.getBag().size()==4 );
 		assertTrue( baz.getFooToGlarch().size()==2 );
 		assertTrue( baz.getFooComponentToFoo().size()==2 );
 		assertTrue( baz.getGlarchToFoo().size()==1 );
 		Iterator iter = baz.getFooToGlarch().keySet().iterator();
 		for (int i=0; i<2; i++ ) assertTrue( iter.next() instanceof BarProxy );
 		FooComponent fooComp = (FooComponent) baz.getFooComponentToFoo().keySet().iterator().next();
 		assertTrue(
 			( (fooComp.getCount()==123 && fooComp.getName().equals("name"))
 			|| (fooComp.getCount()==12 && fooComp.getName().equals("nameName")) )
 			&& ( baz.getFooComponentToFoo().get(fooComp) instanceof BarProxy )
 		);
 		Glarch g2 = new Glarch();
 		s.save(g2);
 		g = (GlarchProxy) baz.getTopGlarchez().get( new Character('G') );
 		baz.getTopGlarchez().put( new Character('H'), g );
 		baz.getTopGlarchez().put( new Character('G'), g2 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getTopGlarchez().size()==2 );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 3, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getTopGlarchez().size()==2 );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		txn.commit();
 
 		s2 = (Session) SerializationHelper.deserialize( SerializationHelper.serialize(s) );
 		s.close();
 
 		txn2 = s2.beginTransaction();
 		baz = (Baz) s2.load(Baz.class, baz.getCode());
 		assertEquals( 3, ((Long) s2.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		s2.delete(baz);
 		s2.delete( baz.getTopGlarchez().get( Character.valueOf('G') ) );
 		s2.delete( baz.getTopGlarchez().get( Character.valueOf('H') ) );
 		int rows = s2.doReturningWork(
 				new AbstractReturningWork<Integer>() {
 					@Override
 					public Integer execute(Connection connection) throws SQLException {
 						final String sql = "update " + getDialect().openQuote() + "glarchez" + getDialect().closeQuote() + " set baz_map_id=null where baz_map_index='a'";
 						return connection.createStatement().executeUpdate( sql );
 					}
 				}
 		);
 		assertTrue(rows==1);
 		assertEquals( 2, doDelete( s2, "from Bar bar" ) );
 		FooProxy[] arr = baz.getFooArray();
 		assertTrue( "new array of objects", arr.length==4 && arr[1].getKey().equals( foo.getKey() ) );
 		for ( int i=1; i<arr.length; i++ ) {
 			if ( arr[i]!=null) s2.delete(arr[i]);
 		}
 
 		s2.load( Qux.class, new Long(666) ); //nonexistent
 
 		assertEquals( 1, doDelete( s2, "from Glarch g" ) );
 		txn2.commit();
 
 		s2.disconnect();
 
 		Session s3 = (Session) SerializationHelper.deserialize( SerializationHelper.serialize( s2 ) );
 		s2.close();
 		//s3.reconnect();
 		assertTrue( s3.load( Qux.class, new Long(666) )!=null ); //nonexistent
 		//s3.disconnect();
 		s3.close();
 	}
 
 	@Test
 	public void testSaveFlush() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee = new Fee();
 		s.save( fee );
 		fee.setFi( "blah" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee = (Fee) s.load( Fee.class, fee.getKey() );
 		assertTrue( "blah".equals( fee.getFi() ) );
 		s.delete(fee);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCreateUpdate() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		foo.setString("dirty");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		s.load( foo2, foo.getKey() );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create-update", foo.equalsFoo(foo2) );
 		//System.out.println( s.print(foo2) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = new Foo();
 		s.save(foo);
 		foo.setString("dirty");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load(foo2, foo.getKey());
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create-update", foo.equalsFoo(foo2) );
 		//System.out.println( s.print(foo2) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testUpdateCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Holder baz = new Holder();
 		baz.setName("123");
 		Foo f1 = new Foo();
 		Foo f2 = new Foo();
 		Foo f3 = new Foo();
 		One o = new One();
 		baz.setOnes( new ArrayList() );
 		baz.getOnes().add(o);
 		Foo[] foos = new Foo[] { f1, null, f2 };
 		baz.setFooArray(foos);
 		baz.setFoos( new HashSet() );
 		baz.getFoos().add(f1);
 		s.save(f1);
 		s.save(f2);
 		s.save(f3);
 		s.save(o);
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		baz.getOnes().set(0, null);
 		baz.getOnes().add(o);
 		baz.getFoos().add(f2);
 		foos[0] = f3;
 		foos[1] = f1;
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Holder h = (Holder) s.load(Holder.class, baz.getId());
 		assertTrue( h.getOnes().get(0)==null );
 		assertTrue( h.getOnes().get(1)!=null );
 		assertTrue( h.getFooArray()[0]!=null);
 		assertTrue( h.getFooArray()[1]!=null);
 		assertTrue( h.getFooArray()[2]!=null);
 		assertTrue( h.getFoos().size()==2 );
 		s.getTransaction().commit();
 		s.close();
 
 		baz.getFoos().remove(f1);
 		baz.getFoos().remove(f2);
 		baz.getFooArray()[0]=null;
 		baz.getFooArray()[0]=null;
 		baz.getFooArray()[0]=null;
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(baz);
 		doDelete( s, "from Foo" );
 		baz.getOnes().remove(o);
 		doDelete( s, "from One" );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCreate() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		s.load( foo2, foo.getKey() );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create", foo.equalsFoo( foo2 ) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCallback() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux("0");
 		s.save(q);
 		q.setChild( new Qux( "1" ) );
 		s.save( q.getChild() );
 		Qux q2 = new Qux("2");
 		q2.setChild( q.getChild() );
 		Qux q3 = new Qux("3");
 		q.getChild().setChild(q3);
 		s.save( q3 );
 		Qux q4 = new Qux("4");
 		q4.setChild( q3 );
 		s.save(q4);
 		s.save( q2 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List l = s.createQuery( "from Qux" ).list();
 		assertTrue( "", l.size() == 5 );
 		s.delete( l.get( 0 ) );
 		s.delete( l.get( 1 ) );
 		s.delete( l.get( 2 ) );
 		s.delete( l.get(3) );
 		s.delete( l.get(4) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPolymorphism() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		s.save(bar);
 		bar.setBarString("bar bar");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		FooProxy foo = (FooProxy) s.load( Foo.class, bar.getKey() );
 		assertTrue( "polymorphic", foo instanceof BarProxy );
 		assertTrue( "subclass property", ( (BarProxy) foo ).getBarString().equals( bar.getBarString() ) );
 		//System.out.println( s.print(foo) );
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRemoveContains() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save( baz );
 		s.flush();
 		assertTrue( s.contains(baz) );
 		s.evict( baz );
 		assertFalse( s.contains(baz) );
 		Baz baz2 = (Baz) s.load( Baz.class, baz.getCode() );
 		assertFalse( baz == baz2 );
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testCollectionOfSelf() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		s.save(bar);
 		bar.setAbstracts( new HashSet() );
 		bar.getAbstracts().add( bar );
 		Bar bar2 = new Bar();
 		bar.getAbstracts().add( bar2 );
 		bar.setFoo(bar);
 		s.save( bar2 );
 		s.getTransaction().commit();
 		s.close();
 
 		bar.setAbstracts( null );
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( bar, bar.getKey() );
 		assertTrue( "collection contains self", bar.getAbstracts().size() == 2 && bar.getAbstracts().contains( bar ) );
 		assertTrue( "association to self", bar.getFoo()==bar );
 		for ( Object o : bar.getAbstracts() ) {
 			s.delete( o );
 		}
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testFind() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 
 		Bar bar = new Bar();
 		s.save(bar);
 		bar.setBarString("bar bar");
 		bar.setString("xxx");
 		Foo foo = new Foo();
 		s.save(foo);
 		foo.setString("foo bar");
 		s.save( new Foo() );
 		s.save( new Bar() );
 		List list1 = s.createQuery( "select foo from Foo foo where foo.string='foo bar'" ).list();
 		assertTrue( "find size", list1.size()==1 );
 		assertTrue( "find ==", list1.get(0)==foo );
 		List list2 = s.createQuery( "from Foo foo order by foo.string, foo.date" ).list();
 		assertTrue( "find size", list2.size()==4 );
 
 		list1 = s.createQuery( "from Foo foo where foo.class='B'" ).list();
 		assertTrue( "class special property", list1.size()==2);
 		list1 = s.createQuery( "from Foo foo where foo.class=Bar" ).list();
 		assertTrue( "class special property", list1.size()==2);
 		list1 = s.createQuery( "from Foo foo where foo.class=Bar" ).list();
 		list2 = s.createQuery( "select bar from Bar bar, Foo foo where bar.string = foo.string and not bar=foo" ).list();
 		assertTrue( "class special property", list1.size()==2);
 		assertTrue( "select from a subclass", list2.size()==1);
 		Trivial t = new Trivial();
 		s.save(t);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list1 = s.createQuery( "from Foo foo where foo.string='foo bar'" ).list();
 		assertTrue( "find size", list1.size()==1 );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "find equals", ( (Foo) list1.get(0) ).equalsFoo(foo) );
 		list2 = s.createQuery( "select foo from Foo foo" ).list();
 		assertTrue( "find size", list2.size()==5 );
 		List list3 = s.createQuery( "from Bar bar where bar.barString='bar bar'" ).list();
 		assertTrue( "find size", list3.size()==1 );
 		assertTrue( "find same instance", list2.contains( list1.get(0) ) && list2.contains( list2.get(0) ) );
 		assertTrue( s.createQuery( "from Trivial" ).list().size()==1 );
 		doDelete( s, "from Trivial" );
 
 		list2 = s.createQuery( "from Foo foo where foo.date = ?" )
 				.setParameter( 0, new java.sql.Date(123), Hibernate.DATE )
 				.list();
 		assertTrue ( "find by date", list2.size()==4 );
 		Iterator iter = list2.iterator();
 		while ( iter.hasNext() ) {
 			s.delete( iter.next() );
 		}
 		list2 = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "find deleted", list2.size()==0);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDeleteRecursive() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo x = new Foo();
 		Foo y = new Foo();
 		x.setFoo( y );
 		y.setFoo( x );
 		s.save( x );
 		s.save( y );
 		s.flush();
 		s.delete( y );
 		s.delete( x );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testReachability() throws Exception {
 		//first for unkeyed collections
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz1 = new Baz();
 		s.save(baz1);
 		Baz baz2 = new Baz();
 		s.save(baz2);
 		baz1.setIntArray( new int[] {1 ,2, 3, 4} );
 		baz1.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		s.save(foo);
 		baz1.getFooSet().add(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		baz2.setFooSet( baz1.getFooSet() ); baz1.setFooSet(null);
 		baz2.setIntArray( baz1.getIntArray() ); baz1.setIntArray(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		assertTrue( "unkeyed reachability", baz2.getIntArray().length==4 );
 		assertTrue( "unkeyed reachability", baz2.getFooSet().size()==1 );
 		assertTrue( "unkeyed reachability", baz1.getIntArray().length==0 );
 		assertTrue( "unkeyed reachability", baz1.getFooSet().size()==0 );
 		//System.out.println( s.print(baz1) + s.print(baz2) );
 		FooProxy fp = (FooProxy) baz2.getFooSet().iterator().next();
 		s.delete(fp);
 		s.delete(baz1);
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		//now for collections of collections
 		s = openSession();
 		s.beginTransaction();
 		baz1 = new Baz();
 		s.save(baz1);
 		baz2 = new Baz();
 		s.save(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		s.delete(baz1);
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		//now for keyed collections
 		s = openSession();
 		s.beginTransaction();
 		baz1 = new Baz();
 		s.save(baz1);
 		baz2 = new Baz();
 		s.save(baz2);
 		Foo foo1 = new Foo();
 		Foo foo2 = new Foo();
 		s.save(foo1); s.save(foo2);
 		baz1.setFooArray( new Foo[] { foo1, null, foo2 } );
 		baz1.setStringDateMap( new TreeMap() );
 		baz1.getStringDateMap().put("today", new Date( System.currentTimeMillis() ) );
 		baz1.getStringDateMap().put("tomorrow", new Date( System.currentTimeMillis() + 86400000 ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		baz2.setFooArray( baz1.getFooArray() ); baz1.setFooArray(null);
 		baz2.setStringDateMap( baz1.getStringDateMap() ); baz1.setStringDateMap(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		assertTrue( "reachability", baz2.getStringDateMap().size()==2 );
 		assertTrue( "reachability", baz2.getFooArray().length==3 );
 		assertTrue( "reachability", baz1.getStringDateMap().size()==0 );
 		assertTrue( "reachability", baz1.getFooArray().length==0 );
 		assertTrue( "null element", baz2.getFooArray()[1]==null );
 		assertTrue( "non-null element", baz2.getStringDateMap().get("today")!=null );
 		assertTrue( "non-null element", baz2.getStringDateMap().get("tomorrow")!=null );
 		assertTrue( "null element", baz2.getStringDateMap().get("foo")==null );
 		s.delete( baz2.getFooArray()[0] );
 		s.delete( baz2.getFooArray()[2] );
 		s.delete(baz1);
 		s.delete(baz2);
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPersistentLifecycle() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save(q);
 		q.setStuff("foo bar baz qux");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load( Qux.class, q.getKey() );
 		assertTrue( "lifecycle create", q.getCreated() );
 		assertTrue( "lifecycle load", q.getLoaded() );
 		assertTrue( "lifecycle subobject", q.getFoo()!=null );
 		s.delete(q);
 		assertTrue( "lifecycle delete", q.getDeleted() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( "subdeletion", s.createQuery( "from Foo foo" ).list().size()==0);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testIterators() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		for ( int i=0; i<10; i++ ) {
 			Qux q = new Qux();
 			Object qid = s.save(q);
 			assertTrue("not null", qid!=null);
 		}
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Iterator iter = s.createQuery( "from Qux q where q.stuff is null" ).iterate();
 		int count=0;
 		while ( iter.hasNext() ) {
 			Qux q = (Qux) iter.next();
 			q.setStuff("foo");
 			if (count==0 || count==5) iter.remove();
 			count++;
 		}
 		assertTrue("iterate", count==10);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertEquals( 8, doDelete( s, "from Qux q where q.stuff=?", "foo", Hibernate.STRING ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		iter = s.createQuery( "from Qux q" ).iterate();
 		assertTrue( "empty iterator", !iter.hasNext() );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testVersioning() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		GlarchProxy g2 = new Glarch();
 		s.save(g2);
 		Serializable gid = s.getIdentifier(g);
 		Serializable g2id = s.getIdentifier(g2);
 		g.setName("glarch");
 		txn.commit();
 		s.close();
 
 		sessionFactory().evict(Glarch.class);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		g = (GlarchProxy) s.load( Glarch.class, gid );
 		s.lock(g, LockMode.UPGRADE);
 		g2 = (GlarchProxy) s.load( Glarch.class, g2id );
 		assertTrue( "version", g.getVersion()==1 );
 		assertTrue( "version", g.getDerivedVersion()==1 );
 		assertTrue( "version", g2.getVersion()==0 );
 		g.setName("foo");
 		assertTrue(
 			"find by version",
 				s.createQuery( "from Glarch g where g.version=2" ).list().size()==1
 		);
 		g.setName("bar");
 		txn.commit();
 		s.close();
 
 		sessionFactory().evict(Glarch.class);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		g = (GlarchProxy) s.load( Glarch.class, gid );
 		g2 = (GlarchProxy) s.load( Glarch.class, g2id );
 		assertTrue( "version", g.getVersion()==3 );
 		assertTrue( "version", g.getDerivedVersion()==3 );
 		assertTrue( "version", g2.getVersion()==0 );
 		g.setNext(null);
 		g2.setNext(g);
 		s.delete(g2);
 		s.delete(g);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testVersionedCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		g.setProxyArray( new GlarchProxy[] { g } );
 		String gid = (String) s.getIdentifier(g);
 		ArrayList list = new ArrayList();
 		list.add("foo");
 		g.setStrings(list);
 		HashSet set = new HashSet();
 		set.add( g );
 		g.setProxySet( set );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getStrings().size()==1 );
 		assertTrue( g.getProxyArray().length==1 );
 		assertTrue( g.getProxySet().size()==1 );
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getStrings().get(0).equals("foo") );
 		assertTrue( g.getProxyArray()[0]==g );
 		assertTrue( g.getProxySet().iterator().next()==g );
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		g.getStrings().add( "bar" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==2 );
 		assertTrue( "versioned collection after", g.getStrings().size() == 2 );
 		g.setProxyArray( null );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==3 );
 		assertTrue( "versioned collection after", g.getProxyArray().length == 0 );
 		g.setFooComponents( new ArrayList() );
 		g.setProxyArray( null );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==4 );
 		s.delete(g);
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRecursiveLoad() throws Exception {
 		//Non polymorphic class (there is an implementation optimization
 		//being tested here)
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		GlarchProxy last = new Glarch();
 		s.save(last);
 		last.setOrder( (short) 0 );
 		for (int i=0; i<5; i++) {
 			GlarchProxy next = new Glarch();
 			s.save(next);
 			last.setNext(next);
 			last = next;
 			last.setOrder( (short) (i+1) );
 		}
 		Iterator iter = s.createQuery( "from Glarch g" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 		}
 		List list = s.createQuery( "from Glarch g" ).list();
 		assertTrue( "recursive find", list.size()==6 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createQuery( "from Glarch g" ).list();
 		assertTrue( "recursive iter", list.size()==6 );
 		list = s.createQuery( "from Glarch g where g.next is not null" ).list();
 		assertTrue( "recursive iter", list.size()==5 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		iter = s.createQuery( "from Glarch g order by g.order asc" ).iterate();
 		while ( iter.hasNext() ) {
 			GlarchProxy g = (GlarchProxy) iter.next();
 			assertTrue( "not null", g!=null );
 			iter.remove();
 		}
 		txn.commit();
 		s.close();
 
 		//Same thing but using polymorphic class (no optimisation possible):
 		s = openSession();
 		txn = s.beginTransaction();
 		FooProxy flast = new Bar();
 		s.save(flast);
 		flast.setString( "foo0" );
 		for (int i=0; i<5; i++) {
 			FooProxy foo = new Bar();
 			s.save(foo);
 			flast.setFoo(foo);
 			flast = flast.getFoo();
 			flast.setString( "foo" + (i+1) );
 		}
 		iter = s.createQuery( "from Foo foo" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 		}
 		list = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "recursive find", list.size()==6 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "recursive iter", list.size()==6 );
 		iter = list.iterator();
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/SQLFunctionsTest.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/SQLFunctionsTest.java
index 5a3f0227fc..30a4260125 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/SQLFunctionsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/SQLFunctionsTest.java
@@ -1,701 +1,703 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.legacy;
 
 import java.util.ArrayList;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Query;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.dialect.DB2Dialect;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.InterbaseDialect;
 import org.hibernate.dialect.MckoiDialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.Oracle9iDialect;
 import org.hibernate.dialect.SQLServerDialect;
 import org.hibernate.dialect.Sybase11Dialect;
 import org.hibernate.dialect.SybaseASE15Dialect;
 import org.hibernate.dialect.SybaseAnywhereDialect;
 import org.hibernate.dialect.SybaseDialect;
 import org.hibernate.dialect.TimesTenDialect;
 import org.hibernate.dialect.function.SQLFunction;
 
 import org.junit.Test;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 
 
 @SuppressWarnings( {"UnnecessaryUnboxing", "UnnecessaryBoxing"})
 public class SQLFunctionsTest extends LegacyTestCase {
+	private static final Logger log = Logger.getLogger( SQLFunctionsTest.class );
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 			"legacy/AltSimple.hbm.xml",
 			"legacy/Broken.hbm.xml",
 			"legacy/Blobber.hbm.xml"
 		};
 	}
 
 	@Test
 	public void testDialectSQLFunctions() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 
 		Iterator iter = s.createQuery( "select max(s.count) from Simple s" ).iterate();
 
 		if ( getDialect() instanceof MySQLDialect ) assertTrue( iter.hasNext() && iter.next()==null );
 
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple Dialect Function Test");
 		simple.setAddress("Simple Address");
 		simple.setPay( Float.valueOf(45.8f) );
 		simple.setCount(2);
 		s.save( simple );
 
 		// Test to make sure allocating an specified object operates correctly.
 		assertTrue(
 				s.createQuery( "select new org.hibernate.test.legacy.S(s.count, s.address) from Simple s" ).list().size() == 1
 		);
 
 		// Quick check the base dialect functions operate correctly
 		assertTrue(
 				s.createQuery( "select max(s.count) from Simple s" ).list().size() == 1
 		);
 		assertTrue(
 				s.createQuery( "select count(*) from Simple s" ).list().size() == 1
 		);
 
 		if ( getDialect() instanceof Oracle9iDialect ) {
 			// Check Oracle Dialect mix of dialect functions - no args (no parenthesis and single arg functions
 			List rset = s.createQuery( "select s.name, sysdate(), trunc(s.pay), round(s.pay) from Simple s" ).list();
 			assertNotNull("Name string should have been returned",(((Object[])rset.get(0))[0]));
 			assertNotNull("Todays Date should have been returned",(((Object[])rset.get(0))[1]));
 			assertEquals("trunc(45.8) result was incorrect ", Float.valueOf(45), ( (Object[]) rset.get(0) )[2] );
 			assertEquals("round(45.8) result was incorrect ", Float.valueOf(46), ( (Object[]) rset.get(0) )[3] );
 
 			simple.setPay(new Float(-45.8));
 			s.update(simple);
 
 			// Test type conversions while using nested functions (Float to Int).
 			rset = s.createQuery( "select abs(round(s.pay)) from Simple s" ).list();
 			assertEquals("abs(round(-45.8)) result was incorrect ", Float.valueOf( 46 ), rset.get(0));
 
 			// Test a larger depth 3 function example - Not a useful combo other than for testing
 			assertTrue(
 					s.createQuery( "select trunc(round(sysdate())) from Simple s" ).list().size() == 1
 			);
 
 			// Test the oracle standard NVL funtion as a test of multi-param functions...
 			simple.setPay(null);
 			s.update(simple);
 			Integer value = (Integer) s.createQuery(
 					"select MOD( NVL(s.pay, 5000), 2 ) from Simple as s where s.id = 10"
 			).list()
 					.get(0);
 			assertTrue( 0 == value.intValue() );
 		}
 
 		if ( (getDialect() instanceof HSQLDialect) ) {
 			// Test the hsql standard MOD funtion as a test of multi-param functions...
 			Integer value = (Integer) s.createQuery( "select MOD(s.count, 2) from Simple as s where s.id = 10" )
 					.list()
 					.get(0);
 			assertTrue( 0 == value.intValue() );
 		}
 
 		s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testSetProperties() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		Query q = s.createQuery("from Simple s where s.name=:name and s.count=:count");
 		q.setProperties(simple);
 		assertTrue( q.list().get(0)==simple );
 		//misuse of "Single" as a propertyobject, but it was the first testclass i found with a collection ;)
 		Single single = new Single() { // trivial hack to test properties with arrays.
 			String[] getStuff() { return (String[]) getSeveral().toArray(new String[getSeveral().size()]); }
 		};
 
 		List l = new ArrayList();
 		l.add("Simple 1");
 		l.add("Slimeball");
 		single.setSeveral(l);
 		q = s.createQuery("from Simple s where s.name in (:several)");
 		q.setProperties(single);
 		assertTrue( q.list().get(0)==simple );
 
 		q = s.createQuery("from Simple s where s.name in :several");
 		q.setProperties(single);
 		assertTrue( q.list().get(0)==simple );
 
 		q = s.createQuery("from Simple s where s.name in (:stuff)");
 		q.setProperties(single);
 		assertTrue( q.list().get(0)==simple );
 
 		q = s.createQuery("from Simple s where s.name in :stuff");
 		q.setProperties(single);
 		assertTrue( q.list().get(0)==simple );
 
 		s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testSetPropertiesMap() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		Map parameters = new HashMap();
 		parameters.put("name", simple.getName());
 		parameters.put("count", new Integer(simple.getCount()));
 
 		Query q = s.createQuery("from Simple s where s.name=:name and s.count=:count");
 		q.setProperties((parameters));
 		assertTrue( q.list().get(0)==simple );
 
 		List l = new ArrayList();
 		l.add("Simple 1");
 		l.add("Slimeball");
 		parameters.put("several", l);
 		q = s.createQuery("from Simple s where s.name in (:several)");
 		q.setProperties(parameters);
 		assertTrue( q.list().get(0)==simple );
 
 
 		parameters.put("stuff", l.toArray(new String[0]));
 		q = s.createQuery("from Simple s where s.name in (:stuff)");
 		q.setProperties(parameters);
 		assertTrue( q.list().get(0)==simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testBroken() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Broken b = new Fixed();
 		b.setId( new Long(123));
 		b.setOtherId("foobar");
 		s.save(b);
 		s.flush();
 		b.setTimestamp( new Date() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update(b);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		b = (Broken) s.load( Broken.class, b );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.delete(b);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testNothinToUpdate() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCachedQuery() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName( "Simple 1" );
 		Long id = (Long) s.save( simple );
 		assertEquals( Long.valueOf( 10 ), id );
 		assertEquals( Long.valueOf( 10 ), simple.getId() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setCacheable(true);
 		q.setString("name", "Simple 1");
 		assertTrue( q.list().size()==1 );
 		simple = (Simple) q.list().get(0);
 
 		q.setString("name", "Simple 2");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		simple.setName("Simple 2");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setString("name", "Simple 2");
 		q.setCacheable(true);
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCachedQueryRegion() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString("name", "Simple 1");
 		assertTrue( q.list().size()==1 );
 		simple = (Simple) q.list().get(0);
 
 		q.setString("name", "Simple 2");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		simple.setName("Simple 2");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testSQLFunctions() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 
 		if ( getDialect() instanceof DB2Dialect) {
 			s.createQuery( "from Simple s where repeat('foo', 3) = 'foofoofoo'" ).list();
 			s.createQuery( "from Simple s where repeat(s.name, 3) = 'foofoofoo'" ).list();
 			s.createQuery( "from Simple s where repeat( lower(s.name), 3 + (1-1) / 2) = 'foofoofoo'" ).list();
 		}
 
 		assertTrue(
 				s.createQuery( "from Simple s where upper( s.name ) ='SIMPLE 1'" ).list().size()==1
 		);
 		if ( !(getDialect() instanceof HSQLDialect) ) {
 			assertTrue(
 					s.createQuery(
 							"from Simple s where not( upper( s.name ) ='yada' or 1=2 or 'foo'='bar' or not('foo'='foo') or 'foo' like 'bar' )"
 					).list()
 							.size()==1
 			);
 		}
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof SybaseDialect) && !(getDialect() instanceof SQLServerDialect) && !(getDialect() instanceof MckoiDialect) && !(getDialect() instanceof InterbaseDialect) && !(getDialect() instanceof TimesTenDialect) ) { //My SQL has a funny concatenation operator
 			assertTrue(
 					s.createQuery( "from Simple s where lower( s.name || ' foo' ) ='simple 1 foo'" ).list().size()==1
 			);
 		}
 		if ( (getDialect() instanceof SybaseDialect) ) {
 			assertTrue(
 					s.createQuery( "from Simple s where lower( s.name + ' foo' ) ='simple 1 foo'" ).list().size()==1
 			);
 		}
 		if ( (getDialect() instanceof MckoiDialect) || (getDialect() instanceof TimesTenDialect)) {
 			assertTrue(
 					s.createQuery( "from Simple s where lower( concat(s.name, ' foo') ) ='simple 1 foo'" ).list().size()==1
 			);
 		}
 
 		Simple other = new Simple( Long.valueOf(20) );
 		other.setName("Simple 2");
 		other.setCount(12);
 		simple.setOther(other);
 		s.save( other );
 		//s.find("from Simple s where s.name ## 'cat|rat|bag'");
 		assertTrue(
 				s.createQuery( "from Simple s where upper( s.other.name ) ='SIMPLE 2'" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery( "from Simple s where not ( upper( s.other.name ) ='SIMPLE 2' )" ).list().size()==0
 		);
 		assertTrue(
 				s.createQuery(
 						"select distinct s from Simple s where ( ( s.other.count + 3 ) = (15*2)/2 and s.count = 69) or ( ( s.other.count + 2 ) / 7 ) = 2"
 				).list()
 						.size()==1
 		);
 		assertTrue(
 				s.createQuery(
 						"select s from Simple s where ( ( s.other.count + 3 ) = (15*2)/2 and s.count = 69) or ( ( s.other.count + 2 ) / 7 ) = 2 order by s.other.count"
 				).list()
 						.size()==1
 		);
 		Simple min = new Simple( Long.valueOf(30) );
 		min.setCount(-1);
 		s.save( min );
 		if ( ! (getDialect() instanceof MySQLDialect) && ! (getDialect() instanceof HSQLDialect) ) { //My SQL has no subqueries
 			assertTrue(
 					s.createQuery( "from Simple s where s.count > ( select min(sim.count) from Simple sim )" )
 							.list()
 							.size()==2
 			);
 			t.commit();
 			t = s.beginTransaction();
 			assertTrue(
 					s.createQuery(
 							"from Simple s where s = some( select sim from Simple sim where sim.count>=0 ) and s.count >= 0"
 					).list()
 							.size()==2
 			);
 			assertTrue(
 					s.createQuery(
 							"from Simple s where s = some( select sim from Simple sim where sim.other.count=s.other.count ) and s.other.count > 0"
 					).list()
 							.size()==1
 			);
 		}
 
 		Iterator iter = s.createQuery( "select sum(s.count) from Simple s group by s.count having sum(s.count) > 10" )
 				.iterate();
 		assertTrue( iter.hasNext() );
 		assertEquals( Long.valueOf(12), iter.next() );
 		assertTrue( !iter.hasNext() );
 		if ( ! (getDialect() instanceof MySQLDialect) ) {
 			iter = s.createQuery( "select s.count from Simple s group by s.count having s.count = 12" ).iterate();
 			assertTrue( iter.hasNext() );
 		}
 
 		s.createQuery(
 				"select s.id, s.count, count(t), max(t.date) from Simple s, Simple t where s.count = t.count group by s.id, s.count order by s.count"
 		).iterate();
 
 		Query q = s.createQuery("from Simple s");
 		q.setMaxResults(10);
 		assertTrue( q.list().size()==3 );
 		q = s.createQuery("from Simple s");
 		q.setMaxResults(1);
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s");
 		assertTrue( q.list().size()==3 );
 		q = s.createQuery("from Simple s where s.name = ?");
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name = ? and upper(s.name) = ?");
 		q.setString(1, "SIMPLE 1");
 		q.setString(0, "Simple 1");
 		q.setFirstResult(0);
 		assertTrue( q.iterate().hasNext() );
 		q = s.createQuery("from Simple s where s.name = :foo and upper(s.name) = :bar or s.count=:count or s.count=:count + 1");
 		q.setParameter("bar", "SIMPLE 1");
 		q.setString("foo", "Simple 1");
 		q.setInteger("count", 69);
 		q.setFirstResult(0);
 		assertTrue( q.iterate().hasNext() );
 		q = s.createQuery("select s.id from Simple s");
 		q.setFirstResult(1);
 		q.setMaxResults(2);
 		iter = q.iterate();
 		int i=0;
 		while ( iter.hasNext() ) {
 			assertTrue( iter.next() instanceof Long );
 			i++;
 		}
 		assertTrue(i==2);
 		q = s.createQuery("select all s, s.other from Simple s where s = :s");
 		q.setParameter("s", simple);
 		assertTrue( q.list().size()==1 );
 
 
 		q = s.createQuery("from Simple s where s.name in (:name_list) and s.count > :count");
 		HashSet set = new HashSet();
 		set.add("Simple 1"); set.add("foo");
 		q.setParameterList( "name_list", set );
 		q.setParameter("count", Integer.valueOf( -1 ) );
 		assertTrue( q.list().size()==1 );
 
 		ScrollableResults sr = s.createQuery("from Simple s").scroll();
 		sr.next();
 		sr.get(0);
 		sr.close();
 
 		s.delete(other);
 		s.delete(simple);
 		s.delete(min);
 		t.commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testBlobClob() throws Exception {
 		// Sybase does not support ResultSet.getBlob(String)
 		if ( getDialect() instanceof SybaseDialect || getDialect() instanceof Sybase11Dialect || getDialect() instanceof SybaseASE15Dialect || getDialect() instanceof SybaseAnywhereDialect ) {
 			return;
 		}
 		Session s = openSession();
 		s.beginTransaction();
 		Blobber b = new Blobber();
 		b.setBlob( s.getLobHelper().createBlob( "foo/bar/baz".getBytes() ) );
 		b.setClob( s.getLobHelper().createClob("foo/bar/baz") );
 		s.save(b);
 		//s.refresh(b);
 		//assertTrue( b.getClob() instanceof ClobImpl );
 		s.flush();
 
 		s.refresh(b);
 		//b.getBlob().setBytes( 2, "abc".getBytes() );
 		b.getClob().getSubString(2, 3);
 		//b.getClob().setString(2, "abc");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		Blobber b2 = new Blobber();
 		s.save(b2);
 		b2.setBlob( b.getBlob() );
 		b.setBlob(null);
 		//assertTrue( b.getClob().getSubString(1, 3).equals("fab") );
 		b.getClob().getSubString(1, 6);
 		//b.getClob().setString(1, "qwerty");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		b.setClob( s.getLobHelper().createClob("xcvfxvc xcvbx cvbx cvbx cvbxcvbxcvbxcvb") );
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		assertTrue( b.getClob().getSubString(1, 7).equals("xcvfxvc") );
 		//b.getClob().setString(5, "1234567890");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testSqlFunctionAsAlias() throws Exception {
 		String functionName = locateAppropriateDialectFunctionNameForAliasTest();
 		if (functionName == null) {
-            LOG.info("Dialect does not list any no-arg functions");
+            log.info("Dialect does not list any no-arg functions");
 			return;
 		}
 
-        LOG.info("Using function named [" + functionName + "] for 'function as alias' test");
+        log.info("Using function named [" + functionName + "] for 'function as alias' test");
 		String query = "select " + functionName + " from Simple as " + functionName + " where " + functionName + ".id = 10";
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List result = s.createQuery( query ).list();
 		assertTrue( result.size() == 1 );
 		assertTrue(result.get(0) instanceof Simple);
 		s.delete( result.get(0) );
 		t.commit();
 		s.close();
 	}
 
 	private String locateAppropriateDialectFunctionNameForAliasTest() {
 		for (Iterator itr = getDialect().getFunctions().entrySet().iterator(); itr.hasNext(); ) {
 			final Map.Entry entry = (Map.Entry) itr.next();
 			final SQLFunction function = (SQLFunction) entry.getValue();
 			if ( !function.hasArguments() && !function.hasParenthesesIfNoArguments() ) {
 				return (String) entry.getKey();
 			}
 		}
 		return null;
 	}
 
 	@Test
 	public void testCachedQueryOnInsert() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s");
 		List list = q.setCacheable(true).list();
 		assertTrue( list.size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Simple simple2 = new Simple( Long.valueOf(12) );
 		simple2.setCount(133);
 		s.save( simple2 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==2 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==2 );
 		Iterator i = list.iterator();
 		while ( i.hasNext() ) s.delete( i.next() );
 		t.commit();
 		s.close();
 
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/stateless/fetching/StatelessSessionFetchingTest.java b/hibernate-core/src/test/java/org/hibernate/test/stateless/fetching/StatelessSessionFetchingTest.java
index 7154ea380f..ac723eee82 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/stateless/fetching/StatelessSessionFetchingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/stateless/fetching/StatelessSessionFetchingTest.java
@@ -1,140 +1,143 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.stateless.fetching;
 
 import java.util.Date;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.StatelessSession;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.DefaultNamingStrategy;
 import org.hibernate.internal.util.StringHelper;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Steve Ebersole
  */
 public class StatelessSessionFetchingTest extends BaseCoreFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( StatelessSessionFetchingTest.class );
+
 	@Override
 	public String[] getMappings() {
 		return new String[] { "stateless/fetching/Mappings.hbm.xml" };
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setNamingStrategy( new TestingNamingStrategy() );
 	}
 
 	private class TestingNamingStrategy extends DefaultNamingStrategy {
 		private final String prefix = determineUniquePrefix();
 
 		protected String applyPrefix(String baseTableName) {
 			String prefixed = prefix + '_' + baseTableName;
-            LOG.debug("prefixed table name : " + baseTableName + " -> " + prefixed);
+            log.debug("prefixed table name : " + baseTableName + " -> " + prefixed);
 			return prefixed;
 		}
 
 		@Override
 		public String classToTableName(String className) {
 			return applyPrefix( super.classToTableName( className ) );
 		}
 
 		@Override
 		public String tableName(String tableName) {
 			if ( tableName.startsWith( "`" ) && tableName.endsWith( "`" ) ) {
 				return tableName;
 			}
 			if ( tableName.startsWith( prefix + '_' ) ) {
 				return tableName;
 			}
 			return applyPrefix( tableName );
 		}
 
 		@Override
 		public String collectionTableName(String ownerEntity, String ownerEntityTable, String associatedEntity, String associatedEntityTable, String propertyName) {
 			String tableName = super.collectionTableName( ownerEntity, ownerEntityTable, associatedEntity, associatedEntityTable, propertyName );
 			return applyPrefix( tableName );
 		}
 
 		@Override
 		public String logicalCollectionTableName(String tableName, String ownerEntityTable, String associatedEntityTable, String propertyName) {
 			String resolvedTableName = prefix + '_' + super.logicalCollectionTableName( tableName, ownerEntityTable, associatedEntityTable, propertyName );
 			System.out.println( "Logical collection table name : " + tableName + " -> " + resolvedTableName );
 			return resolvedTableName;
 		}
 
 		private String determineUniquePrefix() {
 			return StringHelper.collapseQualifier( getClass().getName(), false ).toUpperCase();
 		}
 	}
 
 	@Test
 	public void testDynamicFetch() {
 		Session s = openSession();
 		s.beginTransaction();
 		Date now = new Date();
 		User me = new User( "me" );
 		User you = new User( "you" );
 		Resource yourClock = new Resource( "clock", you );
 		Task task = new Task( me, "clean", yourClock, now ); // :)
 		s.save( me );
 		s.save( you );
 		s.save( yourClock );
 		s.save( task );
 		s.getTransaction().commit();
 		s.close();
 
 		StatelessSession ss = sessionFactory().openStatelessSession();
 		ss.beginTransaction();
 		Task taskRef = ( Task ) ss.createQuery( "from Task t join fetch t.resource join fetch t.user" ).uniqueResult();
 		assertTrue( taskRef != null );
 		assertTrue( Hibernate.isInitialized( taskRef ) );
 		assertTrue( Hibernate.isInitialized( taskRef.getUser() ) );
 		assertTrue( Hibernate.isInitialized( taskRef.getResource() ) );
 		assertFalse( Hibernate.isInitialized( taskRef.getResource().getOwner() ) );
 		ss.getTransaction().commit();
 		ss.close();
 
 		cleanup();
 	}
 
 	private void cleanup() {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "delete Task" ).executeUpdate();
 		s.createQuery( "delete Resource" ).executeUpdate();
 		s.createQuery( "delete User" ).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/typeparameters/DefaultValueIntegerType.java b/hibernate-core/src/test/java/org/hibernate/test/typeparameters/DefaultValueIntegerType.java
index dc8a744555..1b95ed73ff 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/typeparameters/DefaultValueIntegerType.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/typeparameters/DefaultValueIntegerType.java
@@ -1,81 +1,85 @@
 package org.hibernate.test.typeparameters;
-import static org.hibernate.testing.TestLogger.LOG;
+
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Properties;
+
+import org.jboss.logging.Logger;
+
 import org.hibernate.HibernateException;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.usertype.ParameterizedType;
 import org.hibernate.usertype.UserType;
 
 
 /**
  * @author Michi
  */
 public class DefaultValueIntegerType implements UserType, ParameterizedType, Serializable {
+	private static final Logger log = Logger.getLogger( DefaultValueIntegerType.class );
 
 	private Integer defaultValue;
 
 	public int[] sqlTypes() {
 		return new int[] {Types.INTEGER};
 	}
 
 	public Class returnedClass() {
 		return int.class;
 	}
 
 	public boolean equals(Object x, Object y) throws HibernateException {
 		if (x==y) return true;
 		if (x==null || y==null) return false;
 		return x.equals(y);
 	}
 
 	public Object nullSafeGet(ResultSet rs, String[] names, SessionImplementor session, Object owner) throws HibernateException, SQLException {
 		Number result = (Number) rs.getObject(names[0]);
 		return result==null ? defaultValue : new Integer(result.intValue());
 	}
 
 	public void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session) throws HibernateException, SQLException {
 		if (value == null || defaultValue.equals(value) ) {
-            LOG.trace("binding null to parameter: " + index);
+            log.trace("binding null to parameter: " + index);
 			st.setNull(index, Types.INTEGER);
 		} else {
-            LOG.trace("binding " + value + " to parameter: " + index);
+            log.trace("binding " + value + " to parameter: " + index);
 			st.setInt(index, ((Integer)value).intValue());
 		}
 	}
 
 	public Object deepCopy(Object value) throws HibernateException {
 		return new Integer(((Integer)value).intValue());
 	}
 
 	public boolean isMutable() {
 		return false;
 	}
 
 	public int hashCode(Object x) throws HibernateException {
 		return x.hashCode();
 	}
 
 	public Object assemble(Serializable cached, Object owner)
 	throws HibernateException {
 		return cached;
 	}
 
 	public Serializable disassemble(Object value) throws HibernateException {
 		return (Serializable) value;
 	}
 
 	public Object replace(Object original, Object target, Object owner)
 	throws HibernateException {
 		return original;
 	}
 
 	public void setParameterValues(Properties parameters) {
 		this.defaultValue = Integer.valueOf((String) parameters.get("default"));
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/testing/tm/SimpleJtaTransactionImpl.java b/hibernate-core/src/test/java/org/hibernate/testing/tm/SimpleJtaTransactionImpl.java
index 945930421f..099d3fd313 100644
--- a/hibernate-core/src/test/java/org/hibernate/testing/tm/SimpleJtaTransactionImpl.java
+++ b/hibernate-core/src/test/java/org/hibernate/testing/tm/SimpleJtaTransactionImpl.java
@@ -1,155 +1,158 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.tm;
-import static org.hibernate.testing.TestLogger.LOG;
-import java.sql.Connection;
-import java.sql.SQLException;
-import java.util.LinkedList;
+
 import javax.transaction.HeuristicMixedException;
 import javax.transaction.HeuristicRollbackException;
 import javax.transaction.RollbackException;
 import javax.transaction.Status;
 import javax.transaction.Synchronization;
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 import javax.transaction.xa.XAResource;
+import java.sql.Connection;
+import java.sql.SQLException;
+import java.util.LinkedList;
+
+import org.jboss.logging.Logger;
 
 /**
  * SimpleJtaTransactionImpl implementation
  *
  * @author Steve Ebersole
  */
 public class SimpleJtaTransactionImpl implements Transaction {
+	private static final Logger log = Logger.getLogger( SimpleJtaTransactionImpl.class );
 
 	private int status;
 	private LinkedList synchronizations;
 	private Connection connection; // the only resource we care about is jdbc connection
 	private final SimpleJtaTransactionManagerImpl jtaTransactionManager;
 
 	public SimpleJtaTransactionImpl(SimpleJtaTransactionManagerImpl jtaTransactionManager) {
 		this.jtaTransactionManager = jtaTransactionManager;
 		this.status = Status.STATUS_ACTIVE;
 	}
 
 	public int getStatus() {
 		return status;
 	}
 
 	public void commit()
 			throws RollbackException, HeuristicMixedException, HeuristicRollbackException, IllegalStateException, SystemException {
 
 		if ( status == Status.STATUS_MARKED_ROLLBACK ) {
-            LOG.trace("on commit, status was marked for rollback-only");
+            log.trace("on commit, status was marked for rollback-only");
 			rollback();
 		}
 		else {
 			status = Status.STATUS_PREPARING;
 
 			for ( int i = 0; i < synchronizations.size(); i++ ) {
 				Synchronization s = ( Synchronization ) synchronizations.get( i );
 				s.beforeCompletion();
 			}
 
 			status = Status.STATUS_COMMITTING;
 
 			if ( connection != null ) {
 				try {
 					connection.commit();
 					connection.close();
 				}
 				catch ( SQLException sqle ) {
 					status = Status.STATUS_UNKNOWN;
 					throw new SystemException();
 				}
 			}
 
 			status = Status.STATUS_COMMITTED;
 
 			for ( int i = 0; i < synchronizations.size(); i++ ) {
 				Synchronization s = ( Synchronization ) synchronizations.get( i );
 				s.afterCompletion( status );
 			}
 
 			//status = Status.STATUS_NO_TRANSACTION;
 			jtaTransactionManager.endCurrent( this );
 		}
 	}
 
 	public void rollback() throws IllegalStateException, SystemException {
 		status = Status.STATUS_ROLLEDBACK;
 
 		if ( connection != null ) {
 			try {
 				connection.rollback();
 				connection.close();
 			}
 			catch ( SQLException sqle ) {
 				status = Status.STATUS_UNKNOWN;
 				throw new SystemException();
 			}
 		}
 
 		for ( int i = 0; i < synchronizations.size(); i++ ) {
 			Synchronization s = ( Synchronization ) synchronizations.get( i );
 			s.afterCompletion( status );
 		}
 
 		//status = Status.STATUS_NO_TRANSACTION;
 		jtaTransactionManager.endCurrent( this );
 	}
 
 	public void setRollbackOnly() throws IllegalStateException, SystemException {
 		status = Status.STATUS_MARKED_ROLLBACK;
 	}
 
 	public void registerSynchronization(Synchronization synchronization)
 			throws RollbackException, IllegalStateException, SystemException {
 		// todo : find the spec-allowable statuses during which synch can be registered...
 		if ( synchronizations == null ) {
 			synchronizations = new LinkedList();
 		}
 		synchronizations.add( synchronization );
 	}
 
 	public void enlistConnection(Connection connection) {
 		if ( this.connection != null ) {
 			throw new IllegalStateException( "Connection already registered" );
 		}
 		this.connection = connection;
 	}
 
 	public Connection getEnlistedConnection() {
 		return connection;
 	}
 
 
 	public boolean enlistResource(XAResource xaResource)
 			throws RollbackException, IllegalStateException, SystemException {
 		return false;
 	}
 
 	public boolean delistResource(XAResource xaResource, int i) throws IllegalStateException, SystemException {
 		return false;
 	}
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/AbstractEhCacheRegionFactory.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/AbstractEhCacheRegionFactory.java
similarity index 90%
rename from hibernate-ehcache/src/main/java/org/hibernate/cache/AbstractEhCacheRegionFactory.java
rename to hibernate-ehcache/src/main/java/org/hibernate/cache/internal/AbstractEhCacheRegionFactory.java
index a2d95772eb..fb4b67b2d3 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/AbstractEhCacheRegionFactory.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/AbstractEhCacheRegionFactory.java
@@ -1,109 +1,117 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
 import java.util.Properties;
+
+import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.CollectionRegion;
+import org.hibernate.cache.EntityRegion;
+import org.hibernate.cache.QueryResultsRegion;
+import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.TimestampsRegion;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cfg.Settings;
 
 /**
  * Abstract class that will delegate all calls to org.hibernate.cache.RegionFactory to the instance it wraps.
  * This abstracts the Singleton CacheManager construct of Ehcache
  *
  * @author Alex Snaps
  */
 class AbstractEhCacheRegionFactory implements RegionFactory {
 
 	private final RegionFactory underlyingRegionFactory;
 
 	/**
 	 * {@inheritDoc}
 	 */
 	protected AbstractEhCacheRegionFactory(RegionFactory regionFactory) {
 		underlyingRegionFactory = regionFactory;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final void start(final Settings settings, final Properties properties) throws CacheException {
 		underlyingRegionFactory.start(settings, properties);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final void stop() {
 		underlyingRegionFactory.stop();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final boolean isMinimalPutsEnabledByDefault() {
 		return underlyingRegionFactory.isMinimalPutsEnabledByDefault();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final AccessType getDefaultAccessType() {
 		return underlyingRegionFactory.getDefaultAccessType();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final long nextTimestamp() {
 		return underlyingRegionFactory.nextTimestamp();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final EntityRegion buildEntityRegion(final String regionName, final Properties properties, final CacheDataDescription metadata) throws CacheException {
 		return underlyingRegionFactory.buildEntityRegion(regionName, properties, metadata);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final CollectionRegion buildCollectionRegion(final String regionName, final Properties properties, final CacheDataDescription metadata) throws CacheException {
 		return underlyingRegionFactory.buildCollectionRegion(regionName, properties, metadata);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final QueryResultsRegion buildQueryResultsRegion(final String regionName, final Properties properties) throws CacheException {
 		return underlyingRegionFactory.buildQueryResultsRegion(regionName, properties);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final TimestampsRegion buildTimestampsRegion(final String regionName, final Properties properties) throws CacheException {
 		return underlyingRegionFactory.buildTimestampsRegion(regionName, properties);
 	}
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/EhCache.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCache.java
similarity index 95%
rename from hibernate-ehcache/src/main/java/org/hibernate/cache/EhCache.java
rename to hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCache.java
index c6e9484770..af550b9c0f 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/EhCache.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCache.java
@@ -1,270 +1,274 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import net.sf.ehcache.CacheManager;
 import net.sf.ehcache.Element;
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.Cache;
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.Timestamper;
+
 /**
  * EHCache plugin for Hibernate
  * <p/>
  * EHCache uses a {@link net.sf.ehcache.store.MemoryStore} and a
  * {@link net.sf.ehcache.store.DiskStore}.
  * The {@link net.sf.ehcache.store.DiskStore} requires that both keys and values be {@link java.io.Serializable}.
  * However the MemoryStore does not and in ehcache-1.2 nonSerializable Objects are permitted. They are discarded
  * if an attempt it made to overflow them to Disk or to replicate them to remote cache peers.
  *
  * @author Greg Luck
  * @author Emmanuel Bernard
  */
 public class EhCache implements Cache {
 
-    private static final EhCacheLogger LOG = Logger.getMessageLogger(EhCacheLogger.class, EhCache.class.getName());
+    private static final EhCacheMessageLogger LOG = Logger.getMessageLogger(EhCacheMessageLogger.class, EhCache.class.getName());
 
 	private static final int SIXTY_THOUSAND_MS = 60000;
 
 	private net.sf.ehcache.Ehcache cache;
 
 	/**
 	 * Creates a new Hibernate pluggable cache based on a cache name.
 	 * <p/>
 	 *
 	 * @param cache The underlying EhCache instance to use.
 	 */
 	public EhCache(net.sf.ehcache.Ehcache cache) {
 		this.cache = cache;
 	}
 
 	/**
 	 * Gets a value of an element which matches the given key.
 	 *
 	 * @param key the key of the element to return.
 	 * @return The value placed into the cache with an earlier put, or null if not found or expired
-	 * @throws CacheException
+	 * @throws org.hibernate.cache.CacheException
 	 */
 	public Object get(Object key) throws CacheException {
 		try {
             LOG.debugf("Key: %s", key);
             if (key == null) return null;
             Element element = cache.get(key);
             if (element == null) {
                 LOG.debugf("Element for %s is null", key);
 				return null;
 			}
             return element.getObjectValue();
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 	}
 
 	public Object read(Object key) throws CacheException {
 		return get( key );
 	}
 
 
 	/**
 	 * Puts an object into the cache.
 	 *
 	 * @param key   a key
 	 * @param value a value
 	 * @throws CacheException if the {@link CacheManager}
 	 *                        is shutdown or another {@link Exception} occurs.
 	 */
 	public void update(Object key, Object value) throws CacheException {
 		put( key, value );
 	}
 
 	/**
 	 * Puts an object into the cache.
 	 *
 	 * @param key   a key
 	 * @param value a value
 	 * @throws CacheException if the {@link CacheManager}
 	 *                        is shutdown or another {@link Exception} occurs.
 	 */
 	public void put(Object key, Object value) throws CacheException {
 		try {
 			Element element = new Element( key, value );
 			cache.put( element );
 		}
 		catch (IllegalArgumentException e) {
 			throw new CacheException( e );
 		}
 		catch (IllegalStateException e) {
 			throw new CacheException( e );
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 
 	}
 
 	/**
 	 * Removes the element which matches the key.
 	 * <p/>
 	 * If no element matches, nothing is removed and no Exception is thrown.
 	 *
 	 * @param key the key of the element to remove
 	 * @throws CacheException
 	 */
 	public void remove(Object key) throws CacheException {
 		try {
 			cache.remove( key );
 		}
 		catch (ClassCastException e) {
 			throw new CacheException( e );
 		}
 		catch (IllegalStateException e) {
 			throw new CacheException( e );
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 	}
 
 	/**
 	 * Remove all elements in the cache, but leave the cache
 	 * in a useable state.
 	 *
 	 * @throws CacheException
 	 */
 	public void clear() throws CacheException {
 		try {
 			cache.removeAll();
 		}
 		catch (IllegalStateException e) {
 			throw new CacheException( e );
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 	}
 
 	/**
 	 * Remove the cache and make it unuseable.
 	 *
 	 * @throws CacheException
 	 */
 	public void destroy() throws CacheException {
 		try {
 			cache.getCacheManager().removeCache( cache.getName() );
 		}
 		catch (IllegalStateException e) {
 			throw new CacheException( e );
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 	}
 
 	/**
 	 * Calls to this method should perform there own synchronization.
 	 * It is provided for distributed caches. Because EHCache is not distributed
 	 * this method does nothing.
 	 */
 	public void lock(Object key) throws CacheException {
 	}
 
 	/**
 	 * Calls to this method should perform there own synchronization.
 	 * It is provided for distributed caches. Because EHCache is not distributed
 	 * this method does nothing.
 	 */
 	public void unlock(Object key) throws CacheException {
 	}
 
 	/**
 	 * Gets the next timestamp;
 	 */
 	public long nextTimestamp() {
 		return Timestamper.next();
 	}
 
 	/**
 	 * Returns the lock timeout for this cache.
 	 */
 	public int getTimeout() {
 		// 60 second lock timeout
 		return Timestamper.ONE_MS * SIXTY_THOUSAND_MS;
 	}
 
 	public String getRegionName() {
 		return cache.getName();
 	}
 
 	/**
 	 * Warning: This method can be very expensive to run. Allow approximately 1 second
 	 * per 1MB of entries. Running this method could create liveness problems
 	 * because the object lock is held for a long period
 	 * <p/>
 	 *
 	 * @return the approximate size of memory ehcache is using for the MemoryStore for this cache
 	 */
 	public long getSizeInMemory() {
 		try {
 			return cache.calculateInMemorySize();
 		}
 		catch (Throwable t) {
 			return -1;
 		}
 	}
 
 	public long getElementCountInMemory() {
 		try {
 			return cache.getMemoryStoreSize();
 		}
 		catch (net.sf.ehcache.CacheException ce) {
 			throw new CacheException( ce );
 		}
 	}
 
 	public long getElementCountOnDisk() {
 		return cache.getDiskStoreSize();
 	}
 
 	public Map toMap() {
 		try {
 			Map result = new HashMap();
 			Iterator iter = cache.getKeys().iterator();
 			while ( iter.hasNext() ) {
 				Object key = iter.next();
 				result.put( key, cache.get( key ).getObjectValue() );
 			}
 			return result;
 		}
 		catch (Exception e) {
 			throw new CacheException( e );
 		}
 	}
 
 	@Override
     public String toString() {
 		return "EHCache(" + getRegionName() + ')';
 	}
 
 }
\ No newline at end of file
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheLogger.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheMessageLogger.java
similarity index 85%
rename from hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheLogger.java
rename to hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheMessageLogger.java
index 3809a56394..3ffe579987 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheLogger.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheMessageLogger.java
@@ -1,56 +1,60 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
 
 import static org.jboss.logging.Logger.Level.WARN;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.LogMessage;
 import org.jboss.logging.Message;
 import org.jboss.logging.MessageLogger;
 
 /**
- * Defines internationalized messages for this hibernate-ehcache, with IDs ranging from 20001 to 25000 inclusively. New messages
- * must be added after the last message defined to ensure message codes are unique.
+ * The jboss-logging {@link MessageLogger} for the hibernate-ehcache module.  It reserves message ids ranging from
+ * 20001 to 25000 inclusively.
+ * <p/>
+ * New messages must be added after the last message defined to ensure message codes are unique.
  */
 @MessageLogger( projectCode = "HHH" )
-public interface EhCacheLogger extends HibernateLogger {
+public interface EhCacheMessageLogger extends CoreMessageLogger {
 
     @LogMessage( level = WARN )
     @Message( value = "Attempt to restart an already started EhCacheProvider. Use sessionFactory.close() between repeated calls to "
                       + "buildSessionFactory. Using previously created EhCacheProvider. If this behaviour is required, consider "
                       + "using net.sf.ehcache.hibernate.SingletonEhCacheProvider.", id = 20001 )
     void attemptToRestartAlreadyStartedEhCacheProvider();
 
     @LogMessage( level = WARN )
     @Message( value = "Could not find configuration [%s]; using defaults.", id = 20002 )
     void unableToFindConfiguration( String name );
 
     @LogMessage( level = WARN )
     @Message( value = "Could not find a specific ehcache configuration for cache named [%s]; using defaults.", id = 20003 )
     void unableToFindEhCacheConfiguration( String name );
 
     @LogMessage( level = WARN )
     @Message( value = "A configurationResourceName was set to %s but the resource could not be loaded from the classpath. Ehcache will configure itself using defaults.", id = 20004 )
     void unableToLoadConfiguration( String configurationResourceName );
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheProvider.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheProvider.java
similarity index 92%
rename from hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheProvider.java
rename to hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheProvider.java
index 49b2fa9fdd..2f217578d0 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheProvider.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheProvider.java
@@ -1,166 +1,171 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
 
 import java.net.URL;
 import java.util.Properties;
 import net.sf.ehcache.CacheManager;
+
+import org.hibernate.cache.Cache;
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.CacheProvider;
+import org.hibernate.cache.Timestamper;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.jboss.logging.Logger;
 
 /**
  * Cache Provider plugin for Hibernate
  *
- * Use <code>hibernate.cache.provider_class=org.hibernate.cache.EhCacheProvider</code>
+ * Use <code>hibernate.cache.provider_class=org.hibernate.cache.internal.EhCacheProvider</code>
  * in Hibernate 3.x or later
  *
  * Taken from EhCache 0.9 distribution
  * @author Greg Luck
  * @author Emmanuel Bernard
  */
 /**
  * Cache Provider plugin for ehcache-1.2. New in this provider are ehcache support for multiple
  * Hibernate session factories, each with its own ehcache configuration, and non Serializable keys and values.
  * Ehcache-1.2 also has many other features such as cluster support and listeners, which can be used seamlessly simply
  * by configurion in ehcache.xml.
  * <p/>
- * Use <code>hibernate.cache.provider_class=org.hibernate.cache.EhCacheProvider</code> in the Hibernate configuration
+ * Use <code>hibernate.cache.provider_class=org.hibernate.cache.internal.EhCacheProvider</code> in the Hibernate configuration
  * to enable this provider for Hibernate's second level cache.
  * <p/>
  * When configuring multiple ehcache CacheManagers, as you would where you have multiple Hibernate Configurations and
  * multiple SessionFactories, specify in each Hibernate configuration the ehcache configuration using
  * the property <code>hibernate.cache.provider_configuration_file_resource_path</code> An example to set an ehcache configuration
  * called ehcache-2.xml would be <code>hibernate.cache.provider_configuration_file_resource_path=/ehcache-2.xml</code>. If the leading
  * slash is not there one will be added. The configuration file will be looked for in the root of the classpath.
  * <p/>
  * Updated for ehcache-1.2. Note this provider requires ehcache-1.2.jar. Make sure ehcache-1.1.jar or earlier
  * is not in the classpath or it will not work.
  * <p/>
  * See http://ehcache.sf.net for documentation on ehcache
  * <p/>
  *
  * @author Greg Luck
  * @author Emmanuel Bernard
  */
 public class EhCacheProvider implements CacheProvider {
 
-    private static final EhCacheLogger LOG = Logger.getMessageLogger(EhCacheLogger.class, EhCacheProvider.class.getName());
+    private static final EhCacheMessageLogger LOG = Logger.getMessageLogger(EhCacheMessageLogger.class, EhCacheProvider.class.getName());
 
 	private CacheManager manager;
 
     /**
      * Builds a Cache.
      * <p>
      * Even though this method provides properties, they are not used.
      * Properties for EHCache are specified in the ehcache.xml file.
      * Configuration will be read from ehcache.xml for a cache declaration
      * where the name attribute matches the name parameter in this builder.
      *
      * @param name the name of the cache. Must match a cache configured in ehcache.xml
      * @param properties not used
      * @return a newly built cache will be built and initialised
-     * @throws CacheException inter alia, if a cache of the same name already exists
+     * @throws org.hibernate.cache.CacheException inter alia, if a cache of the same name already exists
      */
     public Cache buildCache(String name, Properties properties) throws CacheException {
 	    try {
             net.sf.ehcache.Cache cache = manager.getCache(name);
             if (cache == null) {
                 LOG.unableToFindConfiguration(name);
                 manager.addCache(name);
                 cache = manager.getCache(name);
                 LOG.debugf("Started EHCache region: %s", name);
             }
             return new EhCache(cache);
 	    }
         catch (net.sf.ehcache.CacheException e) {
             throw new CacheException(e);
         }
     }
 
     /**
      * Returns the next timestamp.
      */
     public long nextTimestamp() {
         return Timestamper.next();
     }
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation
 	 * during SessionFactory construction.
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public void start(Properties properties) throws CacheException {
 		if (manager != null) {
             LOG.attemptToRestartAlreadyStartedEhCacheProvider();
             return;
         }
         try {
             String configurationResourceName = null;
             if (properties != null) {
                 configurationResourceName = (String) properties.get( Environment.CACHE_PROVIDER_CONFIG );
             }
             if ( StringHelper.isEmpty( configurationResourceName ) ) {
                 manager = new CacheManager();
             } else {
                 URL url = loadResource(configurationResourceName);
                 manager = new CacheManager(url);
             }
         } catch (net.sf.ehcache.CacheException e) {
 			//yukky! Don't you have subclasses for that!
 			//TODO race conditions can happen here
 			if (e.getMessage().startsWith("Cannot parseConfiguration CacheManager. Attempt to create a new instance of " +
                     "CacheManager using the diskStorePath")) {
                 throw new CacheException("Attempt to restart an already started EhCacheProvider. Use sessionFactory.close() " +
                     " between repeated calls to buildSessionFactory. Consider using net.sf.ehcache.hibernate.SingletonEhCacheProvider."
 						, e );
             }
             throw e;
         }
 	}
 
 	private URL loadResource(String configurationResourceName) {
 		URL url = ConfigHelper.locateConfig( configurationResourceName );
         LOG.debugf("Creating EhCacheProvider from a specified resource: %s Resolved to URL: %s", configurationResourceName, url);
         return url;
     }
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache implementation
 	 * during SessionFactory.close().
 	 */
 	public void stop() {
 		if (manager != null) {
             manager.shutdown();
             manager = null;
         }
 	}
 
 	public boolean isMinimalPutsEnabledByDefault() {
 		return false;
 	}
 
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheRegionFactory.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheRegionFactory.java
similarity index 97%
rename from hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheRegionFactory.java
rename to hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheRegionFactory.java
index bf1c6b2bd1..b7894326ed 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/EhCacheRegionFactory.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheRegionFactory.java
@@ -1,40 +1,40 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
 import java.util.Properties;
 
 /**
  * Thin wrapper class around the within Ehcache-core packaged EhCacheRegionFactory.
  * It directly delegates to the wrapped instance, enabling users to upgrade Ehcache-core versions
  * by simply dropping in the new jar.
  *
  * @author Alex Snaps
  */
 public final class EhCacheRegionFactory extends AbstractEhCacheRegionFactory {
 
 	public EhCacheRegionFactory(Properties properties) {
 		super(new net.sf.ehcache.hibernate.EhCacheRegionFactory(properties));
 	}
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/SingletonEhCacheProvider.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheProvider.java
similarity index 95%
rename from hibernate-ehcache/src/main/java/org/hibernate/cache/SingletonEhCacheProvider.java
rename to hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheProvider.java
index 5360f02430..5f67afbf03 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/SingletonEhCacheProvider.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheProvider.java
@@ -1,180 +1,185 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
 import java.net.URL;
 import java.util.Properties;
 import net.sf.ehcache.CacheManager;
 import net.sf.ehcache.util.ClassLoaderUtil;
 import org.jboss.logging.Logger;
 import org.jboss.logging.Logger.Level;
 
+import org.hibernate.cache.Cache;
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.CacheProvider;
+import org.hibernate.cache.Timestamper;
+
 /**
  * Singleton cache Provider plugin for Hibernate 3.2 and ehcache-1.2. New in this provider is support for
  * non Serializable keys and values. This provider works as a Singleton. No matter how many Hibernate Configurations
  * you have, only one ehcache CacheManager is used. See EhCacheProvider for a non-singleton implementation.
  * <p/>
  * Ehcache-1.2 also has many other features such as cluster support and listeners, which can be used seamlessly simply
  * by configurion in ehcache.xml.
  * <p/>
  * Use <code>hibernate.cache.provider_class=net.sf.ehcache.hibernate.SingletonEhCacheProvider</code> in the Hibernate configuration
  * to enable this provider for Hibernate's second level cache.
  * <p/>
  * Updated for ehcache-1.2. Note this provider requires ehcache-1.2.jar. Make sure ehcache-1.1.jar or earlier
  * is not in the classpath or it will not work.
  * <p/>
  * See http://ehcache.sf.net for documentation on ehcache
  * <p/>
  *
  * @author Greg Luck
  * @author Emmanuel Bernard
  * @version $Id: SingletonEhCacheProvider.java 744 2008-08-16 20:10:49Z gregluck $
  */
 public final class SingletonEhCacheProvider implements CacheProvider {
 
 	/**
 	 * The Hibernate system property specifying the location of the ehcache configuration file name.
 	 * <p/
 	 * If not set, ehcache.xml will be looked for in the root of the classpath.
 	 * <p/>
 	 * If set to say ehcache-1.xml, ehcache-1.xml will be looked for in the root of the classpath.
 	 */
 	public static final String NET_SF_EHCACHE_CONFIGURATION_RESOURCE_NAME = "net.sf.ehcache.configurationResourceName";
 
-    private static final EhCacheLogger LOG = Logger.getMessageLogger(EhCacheLogger.class, SingletonEhCacheProvider.class.getName());
+    private static final EhCacheMessageLogger LOG = Logger.getMessageLogger(EhCacheMessageLogger.class, SingletonEhCacheProvider.class.getName());
 
 	/**
 	 * To be backwardly compatible with a lot of Hibernate code out there, allow multiple starts and stops on the
 	 * one singleton CacheManager. Keep a count of references to only stop on when only one reference is held.
 	 */
 	private static int referenceCount;
 
 	private CacheManager manager;
 
 
 	/**
 	 * Builds a Cache.
 	 * <p/>
 	 * Even though this method provides properties, they are not used.
 	 * Properties for EHCache are specified in the ehcache.xml file.
 	 * Configuration will be read from ehcache.xml for a cache declaration
 	 * where the name attribute matches the name parameter in this builder.
 	 *
 	 * @param name the name of the cache. Must match a cache configured in ehcache.xml
 	 * @param properties not used
 	 *
 	 * @return a newly built cache will be built and initialised
 	 *
 	 * @throws org.hibernate.cache.CacheException
 	 *          inter alia, if a cache of the same name already exists
 	 */
 	public final Cache buildCache(String name, Properties properties) throws CacheException {
 		try {
 			net.sf.ehcache.Ehcache cache = manager.getEhcache( name );
 			if ( cache == null ) {
                 LOG.unableToFindEhCacheConfiguration(name);
 				manager.addCache( name );
 				cache = manager.getEhcache( name );
                 LOG.debugf("Started EHCache region: %s", name);
 			}
 			return new EhCache( cache );
 		}
 		catch ( net.sf.ehcache.CacheException e ) {
 			throw new CacheException( e );
 		}
 	}
 
 	/**
 	 * Returns the next timestamp.
 	 */
 	public final long nextTimestamp() {
 		return Timestamper.next();
 	}
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation
 	 * during SessionFactory construction.
 	 * <p/>
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public final void start(Properties properties) throws CacheException {
 		String configurationResourceName = null;
 		if ( properties != null ) {
 			configurationResourceName = ( String ) properties.get( NET_SF_EHCACHE_CONFIGURATION_RESOURCE_NAME );
 		}
 		if ( configurationResourceName == null || configurationResourceName.length() == 0 ) {
 			manager = CacheManager.create();
 			referenceCount++;
 		}
 		else {
 			if ( !configurationResourceName.startsWith( "/" ) ) {
 				configurationResourceName = "/" + configurationResourceName;
                 if (LOG.isDebugEnabled()) {
                     LOG.debugf("Prepending / to %s. It should be placed in the root of the classpath rather than in a package.",
                                configurationResourceName);
 				}
 			}
 			URL url = loadResource( configurationResourceName );
 			manager = CacheManager.create( url );
 			referenceCount++;
 		}
 	}
 
 	private URL loadResource(String configurationResourceName) {
 		ClassLoader standardClassloader = ClassLoaderUtil.getStandardClassLoader();
 		URL url = null;
         if (standardClassloader != null) url = standardClassloader.getResource(configurationResourceName);
         if (url == null) url = this.getClass().getResource(configurationResourceName);
         if (LOG.isDebugEnabled()) LOG.debugf("Creating EhCacheProvider from a specified resource: %s Resolved to URL: %s",
                                              configurationResourceName,
                                              url);
         if (url == null && LOG.isEnabled(Level.WARN)) LOG.unableToLoadConfiguration(configurationResourceName);
 		return url;
 	}
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache implementation
 	 * during SessionFactory.close().
 	 */
 	public void stop() {
 		if ( manager != null ) {
 			referenceCount--;
 			if ( referenceCount == 0 ) {
 				manager.shutdown();
 			}
 			manager = null;
 		}
 	}
 
 	/**
 	 * Not sure what this is supposed to do.
 	 *
 	 * @return false to be safe
 	 */
 	public final boolean isMinimalPutsEnabledByDefault() {
 		return false;
 	}
 
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/SingletonEhCacheRegionFactory.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheRegionFactory.java
similarity index 97%
rename from hibernate-ehcache/src/main/java/org/hibernate/cache/SingletonEhCacheRegionFactory.java
rename to hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheRegionFactory.java
index 80c4798677..b76a26a89b 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/SingletonEhCacheRegionFactory.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheRegionFactory.java
@@ -1,40 +1,40 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
 import java.util.Properties;
 
 /**
  * Thin wrapper class around the within Ehcache-core packaged SingletonEhCacheRegionFactory.
  * It directly delegates to the wrapped instance, enabling user to upgrade the Ehcache-core version
  * by simply dropping in a new jar.
  *
  * @author Alex Snaps
  */
 public final class SingletonEhCacheRegionFactory extends AbstractEhCacheRegionFactory {
 
 	public SingletonEhCacheRegionFactory(Properties properties) {
 		super(new net.sf.ehcache.hibernate.SingletonEhCacheRegionFactory(properties));
 	}
 }
diff --git a/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java b/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
index 9696f63e86..3f69f15041 100644
--- a/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
+++ b/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
@@ -1,208 +1,208 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.ehcache;
 
 import java.util.Map;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
-import org.hibernate.cache.EhCacheProvider;
+import org.hibernate.cache.internal.EhCacheProvider;
 import org.hibernate.cache.ReadWriteCache;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.transaction.internal.jdbc.JdbcTransactionFactory;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.Statistics;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  */
 public class EhCacheTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String getBaseForMappings() {
 		return "org/hibernate/test/cache/ehcache/";
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] { "Item.hbm.xml" };
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "read-write";
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.CACHE_REGION_PREFIX, "" );
 		cfg.setProperty( Environment.USE_SECOND_LEVEL_CACHE, "true" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.USE_STRUCTURED_CACHE, "true" );
 		cfg.setProperty( Environment.CACHE_PROVIDER, EhCacheProvider.class.getName() );
 		cfg.setProperty( Environment.CACHE_PROVIDER_CONFIG, "ehcache.xml" );
 		cfg.setProperty( Environment.TRANSACTION_STRATEGY, JdbcTransactionFactory.class.getName() );
 	}
 
 	@Test
 	public void testQueryCacheInvalidation() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Item i = new Item();
 		i.setName("widget");
 		i.setDescription("A really top-quality, full-featured widget.");
 		s.persist(i);
 		t.commit();
 		s.close();
 
 		SecondLevelCacheStatistics slcs = s.getSessionFactory().getStatistics()
 				.getSecondLevelCacheStatistics( Item.class.getName() );
 
 		assertEquals( slcs.getPutCount(), 1 );
 		assertEquals( slcs.getElementCountInMemory(), 1 );
 		assertEquals( slcs.getEntries().size(), 1 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		i = (Item) s.get( Item.class, i.getId() );
 
 		assertEquals( slcs.getHitCount(), 1 );
 		assertEquals( slcs.getMissCount(), 0 );
 
 		i.setDescription("A bog standard item");
 
 		t.commit();
 		s.close();
 
 		assertEquals( slcs.getPutCount(), 2 );
 
 		Object entry = slcs.getEntries().get( i.getId() );
 		Map map;
 		if ( entry instanceof ReadWriteCache.Item ) {
 			map = (Map) ( (ReadWriteCache.Item) entry ).getValue();
 		}
 		else {
 			map = (Map) entry;
 		}
 		assertTrue( map.get("description").equals("A bog standard item") );
 		assertTrue( map.get("name").equals("widget") );
 
 		// cleanup
 		s = openSession();
 		t = s.beginTransaction();
 		s.delete( i );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testEmptySecondLevelCacheEntry() throws Exception {
 		sessionFactory().getCache().evictEntityRegion( Item.class.getName() );
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 		SecondLevelCacheStatistics statistics = stats.getSecondLevelCacheStatistics( Item.class.getName() );
         Map cacheEntries = statistics.getEntries();
 		assertEquals( 0, cacheEntries.size() );
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing", "UnnecessaryUnboxing", "UnusedAssignment"})
 	@Test
 	public void testStaleWritesLeaveCacheConsistent() {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		VersionedItem item = new VersionedItem();
 		item.setName( "steve" );
 		item.setDescription( "steve's item" );
 		s.save( item );
 		txn.commit();
 		s.close();
 
 		Long initialVersion = item.getVersion();
 
 		// manually revert the version property
 		item.setVersion( Long.valueOf( item.getVersion().longValue() - 1 ) );
 
 		try {
 			s = openSession();
 			txn = s.beginTransaction();
 			s.update( item );
 			txn.commit();
 			s.close();
 			fail( "expected stale write to fail" );
 		}
 		catch( Throwable expected ) {
 			// expected behavior here
 			if ( txn != null ) {
 				try {
 					txn.rollback();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 		finally {
 			if ( s != null && s.isOpen() ) {
 				try {
 					s.close();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 
 		// check the version value in the cache...
 		SecondLevelCacheStatistics slcs = sessionFactory().getStatistics()
 				.getSecondLevelCacheStatistics( VersionedItem.class.getName() );
 
 		Object entry = slcs.getEntries().get( item.getId() );
 		Long cachedVersionValue;
 		if ( entry instanceof ReadWriteCache.Lock ) {
 			//FIXME don't know what to test here
 			cachedVersionValue = Long.valueOf( ((ReadWriteCache.Lock) entry).getUnlockTimestamp() );
 		}
 		else {
 			cachedVersionValue = ( Long ) ( (Map) entry ).get( "_version" );
 			assertEquals( initialVersion.longValue(), cachedVersionValue.longValue() );
 		}
 
 
 		// cleanup
 		s = openSession();
 		txn = s.beginTransaction();
 		item = ( VersionedItem ) s.load( VersionedItem.class, item.getId() );
 		s.delete( item );
 		txn.commit();
 		s.close();
 
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractEntityManagerImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractEntityManagerImpl.java
index 71a0201046..ed8f975fab 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractEntityManagerImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractEntityManagerImpl.java
@@ -1,1121 +1,1122 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb;
 
 import javax.persistence.CacheRetrieveMode;
 import javax.persistence.CacheStoreMode;
 import javax.persistence.EntityManager;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.EntityTransaction;
 import javax.persistence.FlushModeType;
 import javax.persistence.LockModeType;
 import javax.persistence.LockTimeoutException;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 import javax.persistence.OptimisticLockException;
 import javax.persistence.PersistenceContextType;
 import javax.persistence.PersistenceException;
 import javax.persistence.PessimisticLockException;
 import javax.persistence.PessimisticLockScope;
 import javax.persistence.Query;
 import javax.persistence.QueryTimeoutException;
 import javax.persistence.TransactionRequiredException;
 import javax.persistence.Tuple;
 import javax.persistence.TupleElement;
 import javax.persistence.TypedQuery;
 import javax.persistence.criteria.CriteriaBuilder;
 import javax.persistence.criteria.CriteriaQuery;
 import javax.persistence.criteria.Selection;
 import javax.persistence.metamodel.Metamodel;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.transaction.SystemException;
 import javax.transaction.TransactionManager;
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.SQLQuery;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.ejb.criteria.CriteriaQueryCompiler;
 import org.hibernate.ejb.criteria.ValueHandlerFactory;
 import org.hibernate.ejb.criteria.expression.CompoundSelectionImpl;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.ejb.util.CacheModeHelper;
 import org.hibernate.ejb.util.ConfigurationHelper;
 import org.hibernate.ejb.util.LockModeTypeHelper;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.query.HQLQueryPlan;
 import org.hibernate.engine.query.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.spi.JoinStatus;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.engine.transaction.synchronization.spi.AfterCompletionAction;
 import org.hibernate.engine.transaction.synchronization.spi.ExceptionMapper;
 import org.hibernate.engine.transaction.synchronization.spi.ManagedFlushChecker;
 import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.hibernate.transform.BasicTransformerAdapter;
 import org.hibernate.type.Type;
 
 /**
  * @author <a href="mailto:gavin@hibernate.org">Gavin King</a>
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public abstract class AbstractEntityManagerImpl implements HibernateEntityManagerImplementor, Serializable {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            AbstractEntityManagerImpl.class.getName());
 
 	private static final List<String> entityManagerSpecificProperties = new ArrayList<String>();
 
 	static {
 		entityManagerSpecificProperties.add( AvailableSettings.LOCK_SCOPE );
 		entityManagerSpecificProperties.add( AvailableSettings.LOCK_TIMEOUT );
 		entityManagerSpecificProperties.add( AvailableSettings.FLUSH_MODE );
 		entityManagerSpecificProperties.add( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 		entityManagerSpecificProperties.add( AvailableSettings.SHARED_CACHE_STORE_MODE );
 		entityManagerSpecificProperties.add( QueryHints.SPEC_HINT_TIMEOUT );
 	}
 
 	private EntityManagerFactoryImpl entityManagerFactory;
 	protected transient TransactionImpl tx = new TransactionImpl( this );
 	protected PersistenceContextType persistenceContextType;
 	private PersistenceUnitTransactionType transactionType;
 	private Map<String, Object> properties;
 	private LockOptions lockOptions;
 
 	protected AbstractEntityManagerImpl(
 			EntityManagerFactoryImpl entityManagerFactory,
 			PersistenceContextType type,
 			PersistenceUnitTransactionType transactionType,
 			Map properties) {
 		this.entityManagerFactory = entityManagerFactory;
 		this.persistenceContextType = type;
 		this.transactionType = transactionType;
 
 		this.lockOptions = new LockOptions();
 		this.properties = new HashMap<String, Object>();
 		if ( properties != null ) {
 			for ( String key : entityManagerSpecificProperties ) {
 				if ( properties.containsKey( key ) ) {
 					this.properties.put( key, properties.get( key ) );
 				}
 			}
 		}
 	}
 
 	public PersistenceUnitTransactionType getTransactionType() {
 		return transactionType;
 	}
 
 	protected void postInit() {
 		//register in Sync if needed
 		if ( PersistenceUnitTransactionType.JTA.equals( transactionType ) ) {
 			joinTransaction( true );
 		}
 
 		setDefaultProperties();
 		applyProperties();
 	}
 
 	private void applyProperties() {
 		getSession().setFlushMode( ConfigurationHelper.getFlushMode( properties.get( AvailableSettings.FLUSH_MODE ) ) );
 		setLockOptions( this.properties, this.lockOptions );
 		getSession().setCacheMode(
 				CacheModeHelper.interpretCacheMode(
 						currentCacheStoreMode(),
 						currentCacheRetrieveMode()
 				)
 		);
 	}
 
 	private Query applyProperties(Query query) {
 		if ( lockOptions.getLockMode() != LockMode.NONE ) {
 			query.setLockMode( getLockMode(lockOptions.getLockMode()));
 		}
 		Object queryTimeout;
 		if ( (queryTimeout = getProperties().get(QueryHints.SPEC_HINT_TIMEOUT)) != null ) {
 			query.setHint ( QueryHints.SPEC_HINT_TIMEOUT, queryTimeout );
 		}
 		return query;
 	}
 
 	private CacheRetrieveMode currentCacheRetrieveMode() {
 		return determineCacheRetrieveMode( properties );
 	}
 
 	private CacheRetrieveMode determineCacheRetrieveMode(Map<String, Object> settings) {
 		return ( CacheRetrieveMode ) settings.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 	}
 
 	private CacheStoreMode currentCacheStoreMode() {
 		return determineCacheStoreMode( properties );
 	}
 
 	private CacheStoreMode determineCacheStoreMode(Map<String, Object> settings) {
 		return ( CacheStoreMode ) properties.get( AvailableSettings.SHARED_CACHE_STORE_MODE );
 	}
 
 	private void setLockOptions(Map<String, Object> props, LockOptions options) {
 		Object lockScope = props.get( AvailableSettings.LOCK_SCOPE );
 		if ( lockScope instanceof String && PessimisticLockScope.valueOf( ( String ) lockScope ) == PessimisticLockScope.EXTENDED ) {
 			options.setScope( true );
 		}
 		else if ( lockScope instanceof PessimisticLockScope ) {
 			boolean extended = PessimisticLockScope.EXTENDED.equals( lockScope );
 			options.setScope( extended );
 		}
 		else if ( lockScope != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_SCOPE + ": " + lockScope );
 		}
 
 		Object lockTimeout = props.get( AvailableSettings.LOCK_TIMEOUT );
 		int timeout = 0;
 		boolean timeoutSet = false;
 		if ( lockTimeout instanceof String ) {
 			timeout = Integer.parseInt( ( String ) lockTimeout );
 			timeoutSet = true;
 		}
 		else if ( lockTimeout instanceof Number ) {
 			timeout = ( (Number) lockTimeout ).intValue();
 			timeoutSet = true;
 		}
 		else if ( lockTimeout != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_TIMEOUT + ": " + lockTimeout );
 		}
 		if ( timeoutSet ) {
 			if ( timeout < 0 ) {
 				options.setTimeOut( LockOptions.WAIT_FOREVER );
 			}
 			else if ( timeout == 0 ) {
 				options.setTimeOut( LockOptions.NO_WAIT );
 			}
 			else {
 				options.setTimeOut( timeout );
 			}
 		}
 	}
 
 	/**
 	 * Sets the default property values for the properties the entity manager supports and which are not already explicitly
 	 * set.
 	 */
 	private void setDefaultProperties() {
 		if ( properties.get( AvailableSettings.FLUSH_MODE ) == null ) {
 			properties.put( AvailableSettings.FLUSH_MODE, getSession().getFlushMode().toString() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_SCOPE ) == null ) {
 			this.properties.put( AvailableSettings.LOCK_SCOPE, PessimisticLockScope.EXTENDED.name() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_TIMEOUT ) == null ) {
 			properties.put( AvailableSettings.LOCK_TIMEOUT, LockOptions.WAIT_FOREVER );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE, CacheModeHelper.DEFAULT_RETRIEVE_MODE );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_STORE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_STORE_MODE, CacheModeHelper.DEFAULT_STORE_MODE );
 		}
 	}
 
 	public Query createQuery(String jpaqlString) {
 		try {
 			return applyProperties( new QueryImpl<Object>( getSession().createQuery( jpaqlString ), this ) );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	public <T> TypedQuery<T> createQuery(String jpaqlString, Class<T> resultClass) {
 		try {
 			// do the translation
 			org.hibernate.Query hqlQuery = getSession().createQuery( jpaqlString );
 
 			// do some validation checking
 			if ( Object[].class.equals( resultClass ) ) {
 				// no validation needed
 			}
 			else if ( Tuple.class.equals( resultClass ) ) {
 				TupleBuilderTransformer tupleTransformer = new TupleBuilderTransformer( hqlQuery );
 				hqlQuery.setResultTransformer( tupleTransformer  );
 			}
 			else {
 				final HQLQueryPlan queryPlan = unwrap( SessionImplementor.class )
 						.getFactory()
 						.getQueryPlanCache()
 						.getHQLQueryPlan( jpaqlString, false, null );
 				final Class dynamicInstantiationClass = queryPlan.getDynamicInstantiationResultType();
 				if ( dynamicInstantiationClass != null ) {
 					if ( ! resultClass.isAssignableFrom( dynamicInstantiationClass ) ) {
 						throw new IllegalArgumentException(
 								"Mismatch in requested result type [" + resultClass.getName() +
 										"] and actual result type [" + dynamicInstantiationClass.getName() + "]"
 						);
 					}
 				}
 				else if ( hqlQuery.getReturnTypes().length == 1 ) {
 					// if we have only a single return expression, its java type should match with the requested type
 					if ( !resultClass.isAssignableFrom( hqlQuery.getReturnTypes()[0].getReturnedClass() ) ) {
 						throw new IllegalArgumentException(
 								"Type specified for TypedQuery [" +
 										resultClass.getName() +
 										"] is incompatible with query return type [" +
 										hqlQuery.getReturnTypes()[0].getReturnedClass() + "]"
 						);
 					}
 				}
 				else {
 					throw new IllegalArgumentException(
 							"Cannot create TypedQuery for query with more than one return using requested result type [" +
 									resultClass.getName() + "]"
 					);
 				}
 			}
 
 			// finally, build/return the query instance
 			return new QueryImpl<T>( hqlQuery, this );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	public static class TupleBuilderTransformer extends BasicTransformerAdapter {
 		private List<TupleElement<?>> tupleElements;
 		private Map<String,HqlTupleElementImpl> tupleElementsByAlias;
 
 		public TupleBuilderTransformer(org.hibernate.Query hqlQuery) {
 			final Type[] resultTypes = hqlQuery.getReturnTypes();
 			final int tupleSize = resultTypes.length;
 
 			this.tupleElements = CollectionHelper.arrayList( tupleSize );
 
 			final String[] aliases = hqlQuery.getReturnAliases();
 			final boolean hasAliases = aliases != null && aliases.length > 0;
 			this.tupleElementsByAlias = hasAliases
 					? CollectionHelper.mapOfSize( tupleSize )
 					: Collections.<String, HqlTupleElementImpl>emptyMap();
 
 			for ( int i = 0; i < tupleSize; i++ ) {
 				final HqlTupleElementImpl tupleElement = new HqlTupleElementImpl(
 						i,
 						aliases == null ? null : aliases[i],
 						resultTypes[i]
 				);
 				tupleElements.add( tupleElement );
 				if ( hasAliases ) {
 					final String alias = aliases[i];
 					if ( alias != null ) {
 						tupleElementsByAlias.put( alias, tupleElement );
 					}
 				}
 			}
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			if ( tuple.length != tupleElements.size() ) {
 				throw new IllegalArgumentException(
 						"Size mismatch between tuple result [" + tuple.length + "] and expected tuple elements [" +
 								tupleElements.size() + "]"
 				);
 			}
 			return new HqlTupleImpl( tuple );
 		}
 
 		public static class HqlTupleElementImpl<X> implements TupleElement<X> {
 			private final int position;
 			private final String alias;
 			private final Type hibernateType;
 
 			public HqlTupleElementImpl(int position, String alias, Type hibernateType) {
 				this.position = position;
 				this.alias = alias;
 				this.hibernateType = hibernateType;
 			}
 
 			@Override
 			public Class getJavaType() {
 				return hibernateType.getReturnedClass();
 			}
 
 			@Override
 			public String getAlias() {
 				return alias;
 			}
 
 			public int getPosition() {
 				return position;
 			}
 
 			public Type getHibernateType() {
 				return hibernateType;
 			}
 		}
 
 		public class HqlTupleImpl implements Tuple {
 			private Object[] tuple;
 
 			public HqlTupleImpl(Object[] tuple) {
 				this.tuple = tuple;
 			}
 
 			@Override
 			public <X> X get(String alias, Class<X> type) {
 				return (X) get( alias );
 			}
 
 			@Override
 			public Object get(String alias) {
 				HqlTupleElementImpl tupleElement = tupleElementsByAlias.get( alias );
 				if ( tupleElement == null ) {
 					throw new IllegalArgumentException( "Unknown alias [" + alias + "]" );
 				}
 				return tuple[ tupleElement.getPosition() ];
 			}
 
 			@Override
 			public <X> X get(int i, Class<X> type) {
 				return (X) get( i );
 			}
 
 			@Override
 			public Object get(int i) {
 				if ( i < 0 ) {
 					throw new IllegalArgumentException( "requested tuple index must be greater than zero" );
 				}
 				if ( i > tuple.length ) {
 					throw new IllegalArgumentException( "requested tuple index exceeds actual tuple size" );
 				}
 				return tuple[i];
 			}
 
 			@Override
 			public Object[] toArray() {
 				// todo : make a copy?
 				return tuple;
 			}
 
 			@Override
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 
 			@Override
 			public <X> X get(TupleElement<X> tupleElement) {
 				if ( HqlTupleElementImpl.class.isInstance( tupleElement ) ) {
 					return get( ( (HqlTupleElementImpl) tupleElement ).getPosition(), tupleElement.getJavaType() );
 				}
 				else {
 					return get( tupleElement.getAlias(), tupleElement.getJavaType() );
 				}
 			}
 		}
 	}
 
 	public <T> TypedQuery<T> createQuery(
 			String jpaqlString,
 			Class<T> resultClass,
 			Selection selection,
 			Options options) {
 		try {
 			org.hibernate.Query hqlQuery = getSession().createQuery( jpaqlString );
 
 			if ( options.getValueHandlers() == null ) {
 				options.getResultMetadataValidator().validate( hqlQuery.getReturnTypes() );
 			}
 
 			// determine if we need a result transformer
 			List tupleElements = Tuple.class.equals( resultClass )
 					? ( ( CompoundSelectionImpl<Tuple> ) selection ).getCompoundSelectionItems()
 					: null;
 			if ( options.getValueHandlers() != null || tupleElements != null ) {
 				hqlQuery.setResultTransformer(
 						new CriteriaQueryTransformer( options.getValueHandlers(), tupleElements )
 				);
 			}
 			return new QueryImpl<T>( hqlQuery, this, options.getNamedParameterExplicitTypes() );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	private static class CriteriaQueryTransformer extends BasicTransformerAdapter {
 		private final List<ValueHandlerFactory.ValueHandler> valueHandlers;
 		private final List tupleElements;
 
 		private CriteriaQueryTransformer(List<ValueHandlerFactory.ValueHandler> valueHandlers, List tupleElements) {
 			// todo : should these 2 sizes match *always*?
 			this.valueHandlers = valueHandlers;
 			this.tupleElements = tupleElements;
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			final Object[] valueHandlerResult;
 			if ( valueHandlers == null ) {
 				valueHandlerResult = tuple;
 			}
 			else {
 				valueHandlerResult = new Object[tuple.length];
 				for ( int i = 0; i < tuple.length; i++ ) {
 					ValueHandlerFactory.ValueHandler valueHandler = valueHandlers.get( i );
 					valueHandlerResult[i] = valueHandler == null
 							? tuple[i]
 							: valueHandler.convert( tuple[i] );
 				}
 			}
 
 			return tupleElements == null
 					? valueHandlerResult.length == 1 ? valueHandlerResult[0] : valueHandlerResult
 					: new TupleImpl( tuple );
 
 		}
 
 		private class TupleImpl implements Tuple {
 			private final Object[] tuples;
 
 			private TupleImpl(Object[] tuples) {
 				if ( tuples.length != tupleElements.size() ) {
 					throw new IllegalArgumentException(
 							"Size mismatch between tuple result [" + tuples.length
 									+ "] and expected tuple elements [" + tupleElements.size() + "]"
 					);
 				}
 				this.tuples = tuples;
 			}
 
 			public <X> X get(TupleElement<X> tupleElement) {
 				int index = tupleElements.indexOf( tupleElement );
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Requested tuple element did not correspond to element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return ( X ) tuples[index];
 			}
 
 			public Object get(String alias) {
 				int index = -1;
 				if ( alias != null ) {
 					alias = alias.trim();
 					if ( alias.length() > 0 ) {
 						int i = 0;
 						for ( TupleElement selection : ( List<TupleElement> ) tupleElements ) {
 							if ( alias.equals( selection.getAlias() ) ) {
 								index = i;
 								break;
 							}
 							i++;
 						}
 					}
 				}
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Given alias [" + alias + "] did not correspond to an element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return tuples[index];
 			}
 
 			public <X> X get(String alias, Class<X> type) {
 				return ( X ) get( alias );
 			}
 
 			public Object get(int i) {
 				if ( i >= tuples.length ) {
 					throw new IllegalArgumentException(
 							"Given index [" + i + "] was outside the range of result tuple size [" + tuples.length + "] "
 					);
 				}
 				return tuples[i];
 			}
 
 			public <X> X get(int i, Class<X> type) {
 				return ( X ) get( i );
 			}
 
 			public Object[] toArray() {
 				return tuples;
 			}
 
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 		}
 	}
 
 	private CriteriaQueryCompiler criteriaQueryCompiler;
 
 	public <T> TypedQuery<T> createQuery(CriteriaQuery<T> criteriaQuery) {
 		if ( criteriaQueryCompiler == null ) {
 			criteriaQueryCompiler = new CriteriaQueryCompiler( this );
 		}
 		return criteriaQueryCompiler.compile( criteriaQuery );
 	}
 
 	public Query createNamedQuery(String name) {
 		try {
 			org.hibernate.Query namedQuery = getSession().getNamedQuery( name );
 			try {
 				return new QueryImpl( namedQuery, this );
 			}
 			catch ( HibernateException he ) {
 				throw convert( he );
 			}
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( "Named query not found: " + name );
 		}
 	}
 
 	public <T> TypedQuery<T> createNamedQuery(String name, Class<T> resultClass) {
 		try {
 			/*
 			 * Get the named query.
 			 * If the named query is a SQL query, get the expected returned type from the query definition
 			 * or its associated result set mapping
 			 * If the named query is a HQL query, use getReturnType()
 			 */
 			org.hibernate.Query namedQuery = getSession().getNamedQuery( name );
 			//TODO clean this up to avoid downcasting
 			final SessionFactoryImplementor factoryImplementor = ( SessionFactoryImplementor ) entityManagerFactory.getSessionFactory();
 			final NamedSQLQueryDefinition queryDefinition = factoryImplementor.getNamedSQLQuery( name );
 			try {
 				if ( queryDefinition != null ) {
 					Class<?> actualReturnedClass;
 
 					final NativeSQLQueryReturn[] queryReturns;
 					if ( queryDefinition.getQueryReturns() != null ) {
 						queryReturns = queryDefinition.getQueryReturns();
 					}
 					else if ( queryDefinition.getResultSetRef() != null ) {
 						final ResultSetMappingDefinition rsMapping = factoryImplementor.getResultSetMapping(
 								queryDefinition.getResultSetRef()
 						);
 						queryReturns = rsMapping.getQueryReturns();
 					}
 					else {
 						throw new AssertionFailure( "Unsupported named query model. Please report the bug in Hibernate EntityManager");
 					}
 					if ( queryReturns.length > 1 ) {
 						throw new IllegalArgumentException( "Cannot create TypedQuery for query with more than one return" );
 					}
 					final NativeSQLQueryReturn nativeSQLQueryReturn = queryReturns[0];
 					if ( nativeSQLQueryReturn instanceof NativeSQLQueryRootReturn ) {
 						final String entityClassName = ( ( NativeSQLQueryRootReturn ) nativeSQLQueryReturn ).getReturnEntityName();
 						try {
 							actualReturnedClass = ReflectHelper.classForName( entityClassName, AbstractEntityManagerImpl.class );
 						}
 						catch ( ClassNotFoundException e ) {
 							throw new AssertionFailure( "Unable to instantiate class declared on named native query: " + name + " " + entityClassName );
 						}
 						if ( !resultClass.isAssignableFrom( actualReturnedClass ) ) {
 							throw buildIncompatibleException( resultClass, actualReturnedClass );
 						}
 					}
 					else {
 						//TODO support other NativeSQLQueryReturn type. For now let it go.
 					}
 				}
 				else {
 					if ( namedQuery.getReturnTypes().length != 1 ) {
 						throw new IllegalArgumentException( "Cannot create TypedQuery for query with more than one return" );
 					}
 					if ( !resultClass.isAssignableFrom( namedQuery.getReturnTypes()[0].getReturnedClass() ) ) {
 						throw buildIncompatibleException( resultClass, namedQuery.getReturnTypes()[0].getReturnedClass() );
 					}
 				}
 				return new QueryImpl<T>( namedQuery, this );
 			}
 			catch ( HibernateException he ) {
 				throw convert( he );
 			}
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( "Named query not found: " + name );
 		}
 	}
 
 	private IllegalArgumentException buildIncompatibleException(Class<?> resultClass, Class<?> actualResultClass) {
 		return new IllegalArgumentException(
 							"Type specified for TypedQuery [" +
 									resultClass.getName() +
 									"] is incompatible with query return type [" +
 									actualResultClass + "]"
 					);
 	}
 
 	public Query createNativeQuery(String sqlString) {
 		try {
 			SQLQuery q = getSession().createSQLQuery( sqlString );
 			return new QueryImpl( q, this );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	public Query createNativeQuery(String sqlString, Class resultClass) {
 		try {
 			SQLQuery q = getSession().createSQLQuery( sqlString );
 			q.addEntity( "alias1", resultClass.getName(), LockMode.READ );
 			return new QueryImpl( q, this );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	public Query createNativeQuery(String sqlString, String resultSetMapping) {
 		try {
 			SQLQuery q = getSession().createSQLQuery( sqlString );
 			q.setResultSetMapping( resultSetMapping );
 			return new QueryImpl( q, this );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	public <T> T getReference(Class<T> entityClass, Object primaryKey) {
 		try {
 			return ( T ) getSession().load( entityClass, ( Serializable ) primaryKey );
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( TypeMismatchException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( ClassCastException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey) {
 		return find( entityClass, primaryKey, null, null );
 	}
 
 	public <T> T find(Class<T> entityClass, Object primaryKey, Map<String, Object> properties) {
 		return find( entityClass, primaryKey, null, properties );
 	}
 
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType) {
 		return find( entityClass, primaryKey, lockModeType, null );
 	}
 
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType, Map<String, Object> properties) {
 		CacheMode previousCacheMode = getSession().getCacheMode();
 		CacheMode cacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			getSession().setCacheMode( cacheMode );
 			if ( lockModeType != null ) {
 				return ( A ) getSession().get(
 						entityClass, ( Serializable ) primaryKey,
 						getLockRequest( lockModeType, properties )
 				);
 			}
 			else {
 				return ( A ) getSession().get( entityClass, ( Serializable ) primaryKey );
 			}
 		}
 		catch ( ObjectDeletedException e ) {
 			//the spec is silent about people doing remove() find() on the same PC
 			return null;
 		}
 		catch ( ObjectNotFoundException e ) {
 			//should not happen on the entity itself with get
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( TypeMismatchException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( ClassCastException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he, lockOptions );
 		}
 		finally {
 			getSession().setCacheMode( previousCacheMode );
 		}
 	}
 
 	public CacheMode determineAppropriateLocalCacheMode(Map<String, Object> localProperties) {
 		CacheRetrieveMode retrieveMode = null;
 		CacheStoreMode storeMode = null;
 		if ( localProperties != null ) {
 			retrieveMode = determineCacheRetrieveMode( localProperties );
 			storeMode = determineCacheStoreMode( localProperties );
 		}
 		if ( retrieveMode == null ) {
 			// use the EM setting
 			retrieveMode = determineCacheRetrieveMode( this.properties );
 		}
 		if ( storeMode == null ) {
 			// use the EM setting
 			storeMode = determineCacheStoreMode( this.properties );
 		}
 		return CacheModeHelper.interpretCacheMode( storeMode, retrieveMode );
 	}
 
 	private void checkTransactionNeeded() {
 		if ( persistenceContextType == PersistenceContextType.TRANSACTION && !isTransactionInProgress() ) {
 			//no need to mark as rollback, no tx in progress
 			throw new TransactionRequiredException(
 					"no transaction is in progress for a TRANSACTION type persistence context"
 			);
 		}
 	}
 
 	public void persist(Object entity) {
 		checkTransactionNeeded();
 		try {
 			getSession().persist( entity );
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( e.getMessage() );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	public <A> A merge(A entity) {
 		checkTransactionNeeded();
 		try {
 			return ( A ) getSession().merge( entity );
 		}
 		catch ( ObjectDeletedException sse ) {
 			throw new IllegalArgumentException( sse );
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( RuntimeException e ) { //including HibernateException
 			throw convert( e );
 		}
 	}
 
 	public void remove(Object entity) {
 		checkTransactionNeeded();
 		try {
 			getSession().delete( entity );
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( RuntimeException e ) { //including HibernateException
 			throw convert( e );
 		}
 	}
 
 	public void refresh(Object entity) {
 		refresh( entity, null, null );
 	}
 
 	public void refresh(Object entity, Map<String, Object> properties) {
 		refresh( entity, null, properties );
 	}
 
 	public void refresh(Object entity, LockModeType lockModeType) {
 		refresh( entity, lockModeType, null );
 	}
 
 	public void refresh(Object entity, LockModeType lockModeType, Map<String, Object> properties) {
 		checkTransactionNeeded();
 		CacheMode previousCacheMode = getSession().getCacheMode();
 		CacheMode localCacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			getSession().setCacheMode( localCacheMode );
 			if ( !getSession().contains( entity ) ) {
 				throw new IllegalArgumentException( "Entity not managed" );
 			}
 			if ( lockModeType != null ) {
 				getSession().refresh( entity, ( lockOptions = getLockRequest( lockModeType, properties ) ) );
 			}
 			else {
 				getSession().refresh( entity );
 			}
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he, lockOptions );
 		}
 		finally {
 			getSession().setCacheMode( previousCacheMode );
 		}
 	}
 
 	public boolean contains(Object entity) {
 		try {
 			if ( entity != null
 					&& !( entity instanceof HibernateProxy )
 					&& getSession().getSessionFactory().getClassMetadata( entity.getClass() ) == null ) {
 				throw new IllegalArgumentException( "Not an entity:" + entity.getClass() );
 			}
 			return getSession().contains( entity );
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	public LockModeType getLockMode(Object entity) {
 		if ( !contains( entity ) ) {
 			throw new IllegalArgumentException( "entity not in the persistence context" );
 		}
 		return getLockModeType( getSession().getCurrentLockMode( entity ) );
 	}
 
 	public void setProperty(String s, Object o) {
 		if ( entityManagerSpecificProperties.contains( s ) ) {
 			properties.put( s, o );
 			applyProperties();
         } else LOG.debugf("Trying to set a property which is not supported on entity manager level");
 	}
 
 	public Map<String, Object> getProperties() {
 		return Collections.unmodifiableMap( properties );
 	}
 
 	public void flush() {
 		try {
 			if ( !isTransactionInProgress() ) {
 				throw new TransactionRequiredException( "no transaction is in progress" );
 			}
 			getSession().flush();
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	/**
 	 * return a Session
 	 *
 	 * @throws IllegalStateException if the entity manager is closed
 	 */
 	public abstract Session getSession();
 
 	/**
 	 * Return a Session (even if the entity manager is closed).
 	 *
 	 * @return A session.
 	 */
 	protected abstract Session getRawSession();
 
 	public EntityTransaction getTransaction() {
 		if ( transactionType == PersistenceUnitTransactionType.JTA ) {
 			throw new IllegalStateException( "A JTA EntityManager cannot use getTransaction()" );
 		}
 		return tx;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public EntityManagerFactoryImpl getEntityManagerFactory() {
 		return entityManagerFactory;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public HibernateEntityManagerFactory getFactory() {
 		return entityManagerFactory;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public CriteriaBuilder getCriteriaBuilder() {
 		return getEntityManagerFactory().getCriteriaBuilder();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Metamodel getMetamodel() {
 		return getEntityManagerFactory().getMetamodel();
 	}
 
 	public void setFlushMode(FlushModeType flushModeType) {
 		if ( flushModeType == FlushModeType.AUTO ) {
 			getSession().setFlushMode( FlushMode.AUTO );
 		}
 		else if ( flushModeType == FlushModeType.COMMIT ) {
 			getSession().setFlushMode( FlushMode.COMMIT );
 		}
 		else {
 			throw new AssertionFailure( "Unknown FlushModeType: " + flushModeType );
 		}
 	}
 
 	public void clear() {
 		try {
 			getSession().clear();
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	public void detach(Object entity) {
 		try {
 			getSession().evict( entity );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	/**
 	 * Hibernate can be set in various flush modes that are unknown to
 	 * JPA 2.0. This method can then return null.
 	 * If it returns null, do em.unwrap(Session.class).getFlushMode() to get the
 	 * Hibernate flush mode
 	 */
 	public FlushModeType getFlushMode() {
 		FlushMode mode = getSession().getFlushMode();
 		if ( mode == FlushMode.AUTO ) {
 			return FlushModeType.AUTO;
 		}
 		else if ( mode == FlushMode.COMMIT ) {
 			return FlushModeType.COMMIT;
 		}
 		else {
 			// otherwise this is an unknown mode for EJB3
 			return null;
 		}
 	}
 
 	public void lock(Object entity, LockModeType lockMode) {
 		lock( entity, lockMode, null );
 	}
 
 	public void lock(Object entity, LockModeType lockModeType, Map<String, Object> properties) {
 		LockOptions lockOptions = null;
 		try {
 			if ( !isTransactionInProgress() ) {
 				throw new TransactionRequiredException( "no transaction is in progress" );
 			}
 			if ( !contains( entity ) ) {
 				throw new IllegalArgumentException( "entity not in the persistence context" );
 			}
 			getSession().buildLockRequest( ( lockOptions = getLockRequest( lockModeType, properties ) ) )
 					.lock( entity );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he, lockOptions );
 		}
 	}
 
 	public LockOptions getLockRequest(LockModeType lockModeType, Map<String, Object> properties) {
 		LockOptions lockOptions = new LockOptions();
 		LockOptions.copy( this.lockOptions, lockOptions );
 		lockOptions.setLockMode( getLockMode( lockModeType ) );
 		if ( properties != null ) {
 			setLockOptions( properties, lockOptions );
 		}
 		return lockOptions;
 	}
 
 	@SuppressWarnings("deprecation")
 	private static LockModeType getLockModeType(LockMode lockMode) {
 		//TODO check that if we have UPGRADE_NOWAIT we have a timeout of zero?
 		return LockModeTypeHelper.getLockModeType( lockMode );
 	}
 
 
 	private static LockMode getLockMode(LockModeType lockMode) {
 		return LockModeTypeHelper.getLockMode( lockMode );
 	}
 
 	public boolean isTransactionInProgress() {
 		return ( ( SessionImplementor ) getRawSession() ).isTransactionInProgress();
 	}
 
 	private SessionFactoryImplementor sfi() {
 		return ( SessionFactoryImplementor ) getRawSession().getSessionFactory();
 	}
 
 	protected void markAsRollback() {
         LOG.debugf("Mark transaction for rollback");
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractQueryImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractQueryImpl.java
index 1d96491b05..d14bd4488b 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractQueryImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/AbstractQueryImpl.java
@@ -1,411 +1,412 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb;
 import static org.hibernate.ejb.QueryHints.HINT_CACHEABLE;
 import static org.hibernate.ejb.QueryHints.HINT_CACHE_MODE;
 import static org.hibernate.ejb.QueryHints.HINT_CACHE_REGION;
 import static org.hibernate.ejb.QueryHints.HINT_COMMENT;
 import static org.hibernate.ejb.QueryHints.HINT_FETCH_SIZE;
 import static org.hibernate.ejb.QueryHints.HINT_FLUSH_MODE;
 import static org.hibernate.ejb.QueryHints.HINT_READONLY;
 import static org.hibernate.ejb.QueryHints.HINT_TIMEOUT;
 import static org.hibernate.ejb.QueryHints.SPEC_HINT_TIMEOUT;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.CacheRetrieveMode;
 import javax.persistence.CacheStoreMode;
 import javax.persistence.FlushModeType;
 import javax.persistence.Parameter;
 import javax.persistence.TransactionRequiredException;
 import javax.persistence.TypedQuery;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.TypeMismatchException;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.ejb.util.CacheModeHelper;
 import org.hibernate.ejb.util.ConfigurationHelper;
 import org.hibernate.ejb.util.LockModeTypeHelper;
 import org.hibernate.hql.QueryExecutionRequestException;
 import org.jboss.logging.Logger;
 
 /**
  * Intended as a base class providing convenience in implementing both {@link javax.persistence.Query} and
  * {@link javax.persistence.TypedQuery}.
  * <p/>
  * IMPL NOTE : This issue, and the reason for this distinction, is that criteria and hl.sql queries share no
  * commonality currently in Hibernate internals.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractQueryImpl<X> implements TypedQuery<X> {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            AbstractQueryImpl.class.getName());
 
 	private final HibernateEntityManagerImplementor entityManager;
 
 	public AbstractQueryImpl(HibernateEntityManagerImplementor entityManager) {
 		this.entityManager = entityManager;
 	}
 
 	protected HibernateEntityManagerImplementor getEntityManager() {
 		return entityManager;
 	}
 
 	/**
 	 * Actually execute the update; all pre-requisites have been checked.
 	 *
 	 * @return The number of "affected rows".
 	 */
 	protected abstract int internalExecuteUpdate();
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@SuppressWarnings({ "ThrowableInstanceNeverThrown" })
 	public int executeUpdate() {
 		try {
 			if ( ! entityManager.isTransactionInProgress() ) {
 				entityManager.throwPersistenceException( new TransactionRequiredException( "Executing an update/delete query" ) );
 				return 0;
 			}
 			return internalExecuteUpdate();
 		}
 		catch ( QueryExecutionRequestException he) {
 			throw new IllegalStateException(he);
 		}
 		catch( TypeMismatchException e ) {
 			throw new IllegalArgumentException(e);
 		}
 		catch ( HibernateException he) {
 			entityManager.throwPersistenceException( he );
 			return 0;
 		}
 	}
 
 	private int maxResults = -1;
 
 	/**
 	 * Apply the given max results value.
 	 *
 	 * @param maxResults The specified max results
 	 */
 	protected abstract void applyMaxResults(int maxResults);
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public TypedQuery<X> setMaxResults(int maxResult) {
 		if ( maxResult < 0 ) {
 			throw new IllegalArgumentException(
 					"Negative value (" + maxResult + ") passed to setMaxResults"
 			);
 		}
 		this.maxResults = maxResult;
 		applyMaxResults( maxResult );
 		return this;
 	}
 
 	public int getSpecifiedMaxResults() {
 		return maxResults;
 	}
 
 	public int getMaxResults() {
 		return maxResults == -1
 				? Integer.MAX_VALUE // stupid spec... MAX_VALUE??
 				: maxResults;
 	}
 
 	private int firstResult;
 
 	/**
 	 * Apply the given first-result value.
 	 *
 	 * @param firstResult The specified first-result value.
 	 */
 	protected abstract void applyFirstResult(int firstResult);
 
 	public TypedQuery<X> setFirstResult(int firstResult) {
 		if ( firstResult < 0 ) {
 			throw new IllegalArgumentException(
 					"Negative value (" + firstResult + ") passed to setFirstResult"
 			);
 		}
 		this.firstResult = firstResult;
 		applyFirstResult( firstResult );
 		return this;
 	}
 
 	public int getFirstResult() {
 		return firstResult;
 	}
 
 	private Map<String, Object> hints;
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Map<String, Object> getHints() {
 		return hints;
 	}
 
 	protected abstract void applyTimeout(int timeout);
 
 	protected abstract void applyComment(String comment);
 
 	protected abstract void applyFetchSize(int fetchSize);
 
 	protected abstract void applyCacheable(boolean isCacheable);
 
 	protected abstract void applyCacheRegion(String regionName);
 
 	protected abstract void applyReadOnly(boolean isReadOnly);
 
 	protected abstract void applyCacheMode(CacheMode cacheMode);
 
 	protected abstract void applyFlushMode(FlushMode flushMode);
 
 	protected abstract boolean canApplyLockModes();
 
 	protected abstract void applyAliasSpecificLockMode(String alias, LockMode lockMode);
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public TypedQuery<X> setHint(String hintName, Object value) {
 		boolean skipped = false;
 		try {
 			if ( HINT_TIMEOUT.equals( hintName ) ) {
 				applyTimeout( ConfigurationHelper.getInteger( value ) );
 			}
 			else if ( SPEC_HINT_TIMEOUT.equals( hintName ) ) {
 				// convert milliseconds to seconds
 				int timeout = (int)Math.round(ConfigurationHelper.getInteger( value ).doubleValue() / 1000.0 );
 				applyTimeout( new Integer(timeout) );
 			}
 			else if ( HINT_COMMENT.equals( hintName ) ) {
 				applyComment( (String) value );
 			}
 			else if ( HINT_FETCH_SIZE.equals( hintName ) ) {
 				applyFetchSize( ConfigurationHelper.getInteger( value ) );
 			}
 			else if ( HINT_CACHEABLE.equals( hintName ) ) {
 				applyCacheable( ConfigurationHelper.getBoolean( value ) );
 			}
 			else if ( HINT_CACHE_REGION.equals( hintName ) ) {
 				applyCacheRegion( (String) value );
 			}
 			else if ( HINT_READONLY.equals( hintName ) ) {
 				applyReadOnly( ConfigurationHelper.getBoolean( value ) );
 			}
 			else if ( HINT_CACHE_MODE.equals( hintName ) ) {
 				applyCacheMode( ConfigurationHelper.getCacheMode( value ) );
 			}
 			else if ( HINT_FLUSH_MODE.equals( hintName ) ) {
 				applyFlushMode( ConfigurationHelper.getFlushMode( value ) );
 			}
 			else if ( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE.equals( hintName ) ) {
 				final CacheRetrieveMode retrieveMode = (CacheRetrieveMode) value;
 
 				CacheStoreMode storeMode = hints != null
 						? (CacheStoreMode) hints.get( AvailableSettings.SHARED_CACHE_STORE_MODE )
 						: null;
 				if ( storeMode == null ) {
 					storeMode = (CacheStoreMode) entityManager.getProperties()
 							.get( AvailableSettings.SHARED_CACHE_STORE_MODE );
 				}
 				applyCacheMode(
 						CacheModeHelper.interpretCacheMode( storeMode, retrieveMode )
 				);
 			}
 			else if ( AvailableSettings.SHARED_CACHE_STORE_MODE.equals( hintName ) ) {
 				final CacheStoreMode storeMode = (CacheStoreMode) value;
 
 				CacheRetrieveMode retrieveMode = hints != null
 						? (CacheRetrieveMode) hints.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE )
 						: null;
 				if ( retrieveMode == null ) {
 					retrieveMode = (CacheRetrieveMode) entityManager.getProperties()
 							.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 				}
 				applyCacheMode(
 						CacheModeHelper.interpretCacheMode( storeMode, retrieveMode )
 				);
 			}
 			else if ( hintName.startsWith( AvailableSettings.ALIAS_SPECIFIC_LOCK_MODE ) ) {
 				if ( ! canApplyLockModes() ) {
 					skipped = true;
 				}
 				else {
 					// extract the alias
 					final String alias = hintName.substring( AvailableSettings.ALIAS_SPECIFIC_LOCK_MODE.length() + 1 );
 					// determine the LockMode
 					try {
 						final LockMode lockMode = LockModeTypeHelper.interpretLockMode( value );
 						applyAliasSpecificLockMode( alias, lockMode );
 					}
 					catch ( Exception e ) {
                         LOG.unableToDetermineLockModeValue(hintName, value);
 						skipped = true;
 					}
 				}
 			}
 			else {
 				skipped = true;
                 LOG.ignoringUnrecognizedQueryHint(hintName);
 			}
 		}
 		catch ( ClassCastException e ) {
 			throw new IllegalArgumentException( "Value for hint" );
 		}
 
 		if ( !skipped ) {
 			if ( hints == null ) {
 				hints = new HashMap<String,Object>();
 			}
 			hints.put( hintName, value );
 		}
 
 		return this;
 	}
 
 	public Set<String> getSupportedHints() {
 		return QueryHints.getDefinedHints();
 	}
 
 	public abstract TypedQuery<X> setLockMode(javax.persistence.LockModeType lockModeType);
 
 	public abstract javax.persistence.LockModeType getLockMode();
 
 	private FlushModeType jpaFlushMode;
 
 	public TypedQuery<X> setFlushMode(FlushModeType jpaFlushMode) {
 		this.jpaFlushMode = jpaFlushMode;
 		// TODO : treat as hint?
 		if ( jpaFlushMode == FlushModeType.AUTO ) {
 			applyFlushMode( FlushMode.AUTO );
 		}
 		else if ( jpaFlushMode == FlushModeType.COMMIT ) {
 			applyFlushMode( FlushMode.COMMIT );
 		}
 		return this;
 	}
 
 	protected FlushModeType getSpecifiedFlushMode() {
 		return jpaFlushMode;
 	}
 
 	public FlushModeType getFlushMode() {
 		return jpaFlushMode != null
 				? jpaFlushMode
 				: entityManager.getFlushMode();
 	}
 
 	private Map parameterBindings;
 
 	protected void registerParameterBinding(Parameter parameter, Object value) {
 		if ( value != null && parameter.getParameterType() != null ) {
 			if ( Collection.class.isInstance( value ) ) {
 				final Collection collection = (Collection) value;
 				// validate the elements...
 				for ( Object element : collection ) {
 					if ( ! parameter.getParameterType().isInstance( element ) ) {
 						throw new IllegalArgumentException(
 								"Parameter value [" + element + "] was not matching type [" +
 										parameter.getParameterType().getName() + "]"
 						);
 					}
 				}
 			}
 			else if ( value.getClass().isArray() && value.getClass().equals( Object[].class ) ) {
 				final Object[] array = (Object[]) value;
 				for ( Object element : array ) {
 					if ( ! parameter.getParameterType().isInstance( element ) ) {
 						throw new IllegalArgumentException(
 								"Parameter value [" + element + "] was not matching type [" +
 										parameter.getParameterType().getName() + "]"
 						);
 					}
 				}
 			}
 			else {
 				if ( ! parameter.getParameterType().isInstance( value ) ) {
 					throw new IllegalArgumentException(
 							"Parameter value [" + value + "] was not matching type [" +
 									parameter.getParameterType().getName() + "]"
 					);
 				}
 			}
 		}
 
 		if ( parameterBindings == null ) {
 			parameterBindings = new HashMap();
 		}
 		parameterBindings.put( parameter, value );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
     public boolean isBound(Parameter<?> param) {
 		return parameterBindings != null && parameterBindings.containsKey( param );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public <T> T getParameterValue(Parameter<T> param) {
 		if ( parameterBindings == null ) {
 			throw new IllegalStateException( "No parameters have been bound" );
 		}
 		try {
 			T value = (T) parameterBindings.get( param );
 			if ( value == null ) {
 				throw new IllegalStateException( "Parameter has not been bound" );
 			}
 			return value;
 		}
 		catch ( ClassCastException cce ) {
 			throw new IllegalStateException( "Encountered a parameter value type exception" );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Object getParameterValue(String name) {
 		return getParameterValue( getParameter( name ) );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Object getParameterValue(int position) {
 		return getParameterValue( getParameter( position ) );
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/Ejb3Configuration.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/Ejb3Configuration.java
index 3d91ebeae2..e3446f5a5c 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/Ejb3Configuration.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/Ejb3Configuration.java
@@ -1,1127 +1,1128 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb;
 
 import javax.naming.BinaryRefAddr;
 import javax.naming.NamingException;
 import javax.naming.Reference;
 import javax.naming.Referenceable;
 import javax.persistence.Embeddable;
 import javax.persistence.Entity;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.PersistenceException;
 import javax.persistence.spi.PersistenceUnitInfo;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.sql.DataSource;
 import java.io.BufferedInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectOutput;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.annotation.Annotation;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Enumeration;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.dom4j.Element;
 import org.jboss.logging.Logger;
 import org.xml.sax.EntityResolver;
 import org.xml.sax.InputSource;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.MappingNotFoundException;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.annotations.reflection.XMLContext;
 import org.hibernate.cfg.beanvalidation.BeanValidationIntegrator;
 import org.hibernate.ejb.connection.InjectedDataSourceConnectionProvider;
 import org.hibernate.ejb.event.JpaEventListenerRegistration;
 import org.hibernate.ejb.instrument.InterceptFieldClassFileTransformer;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.ejb.packaging.JarVisitorFactory;
 import org.hibernate.ejb.packaging.NamedInputStream;
 import org.hibernate.ejb.packaging.NativeScanner;
 import org.hibernate.ejb.packaging.PersistenceMetadata;
 import org.hibernate.ejb.packaging.PersistenceXmlLoader;
 import org.hibernate.ejb.packaging.Scanner;
 import org.hibernate.ejb.util.ConfigurationHelper;
 import org.hibernate.ejb.util.LogHelper;
 import org.hibernate.ejb.util.NamingHelper;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.transaction.internal.jdbc.JdbcTransactionFactory;
 import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.xml.MappingReader;
 import org.hibernate.internal.util.xml.OriginImpl;
 import org.hibernate.internal.util.xml.XmlDocument;
 import org.hibernate.mapping.AuxiliaryDatabaseObject;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.secure.JACCConfiguration;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.StandardServiceInitiators;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 import org.hibernate.service.jdbc.connections.internal.DatasourceConnectionProviderImpl;
 
 /**
  * Allow a fine tuned configuration of an EJB 3.0 EntityManagerFactory
  *
  * A Ejb3Configuration object is only guaranteed to create one EntityManagerFactory.
  * Multiple usage of {@link #buildEntityManagerFactory()} is not guaranteed.
  *
  * After #buildEntityManagerFactory() has been called, you no longer can change the configuration
  * state (no class adding, no property change etc)
  *
  * When serialized / deserialized or retrieved from the JNDI, you no longer can change the
  * configuration state (no class adding, no property change etc)
  *
  * Putting the configuration in the JNDI is an expensive operation that requires a partial
  * serialization
  *
  * @author Emmanuel Bernard
  */
 public class Ejb3Configuration implements Serializable, Referenceable {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(
-			EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(
+			EntityManagerMessageLogger.class,
 			Ejb3Configuration.class.getName()
 	);
 	private static final String IMPLEMENTATION_NAME = HibernatePersistence.class.getName();
 	private static final String META_INF_ORM_XML = "META-INF/orm.xml";
 	private static final String PARSED_MAPPING_DOMS = "hibernate.internal.mapping_doms";
 
 	private static EntityNotFoundDelegate ejb3EntityNotFoundDelegate = new Ejb3EntityNotFoundDelegate();
 	private static Configuration DEFAULT_CONFIGURATION = new Configuration();
 
 	private static class Ejb3EntityNotFoundDelegate implements EntityNotFoundDelegate, Serializable {
 		public void handleEntityNotFound(String entityName, Serializable id) {
 			throw new EntityNotFoundException("Unable to find " + entityName  + " with id " + id);
 		}
 	}
 
 	private String persistenceUnitName;
 	private String cfgXmlResource;
 
 	private Configuration cfg;
 	//made transient and not restored in deserialization on purpose, should no longer be called after restoration
 	private PersistenceUnitTransactionType transactionType;
 	private boolean discardOnClose;
 	//made transient and not restored in deserialization on purpose, should no longer be called after restoration
 	private transient ClassLoader overridenClassLoader;
 	private boolean isConfigurationProcessed = false;
 
 
 	public Ejb3Configuration() {
 		cfg = new Configuration();
 		cfg.setEntityNotFoundDelegate( ejb3EntityNotFoundDelegate );
 	}
 
 	/**
 	 * Used to inject a datasource object as the connection provider.
 	 * If used, be sure to <b>not override</b> the hibernate.connection.provider_class
 	 * property
 	 */
 	@SuppressWarnings({ "JavaDoc", "unchecked" })
 	public void setDataSource(DataSource ds) {
 		if ( ds != null ) {
 			cfg.getProperties().put( Environment.DATASOURCE, ds );
 			this.setProperty( Environment.CONNECTION_PROVIDER, DatasourceConnectionProviderImpl.class.getName() );
 		}
 	}
 
 	/**
 	 * create a factory from a parsed persistence.xml
 	 * Especially the scanning of classes and additional jars is done already at this point.
 	 * <p/>
 	 * NOTE: public only for unit testing purposes; not a public API!
 	 *
 	 * @param metadata The information parsed from the persistence.xml
 	 * @param overridesIn Any explicitly passed config settings
 	 *
 	 * @return this
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public Ejb3Configuration configure(PersistenceMetadata metadata, Map overridesIn) {
         LOG.debugf("Creating Factory: %s", metadata.getName());
 
 		Map overrides = new HashMap();
 		if ( overridesIn != null ) {
 			overrides.putAll( overridesIn );
 		}
 
 		Map workingVars = new HashMap();
 		workingVars.put( AvailableSettings.PERSISTENCE_UNIT_NAME, metadata.getName() );
 		this.persistenceUnitName = metadata.getName();
 
 		if ( StringHelper.isNotEmpty( metadata.getJtaDatasource() ) ) {
 			this.setProperty( Environment.DATASOURCE, metadata.getJtaDatasource() );
 		}
 		else if ( StringHelper.isNotEmpty( metadata.getNonJtaDatasource() ) ) {
 			this.setProperty( Environment.DATASOURCE, metadata.getNonJtaDatasource() );
 		}
 		else {
 			final String driver = (String) metadata.getProps().get( AvailableSettings.JDBC_DRIVER );
 			if ( StringHelper.isNotEmpty( driver ) ) {
 				this.setProperty( Environment.DRIVER, driver );
 			}
 			final String url = (String) metadata.getProps().get( AvailableSettings.JDBC_URL );
 			if ( StringHelper.isNotEmpty( url ) ) {
 				this.setProperty( Environment.URL, url );
 			}
 			final String user = (String) metadata.getProps().get( AvailableSettings.JDBC_USER );
 			if ( StringHelper.isNotEmpty( user ) ) {
 				this.setProperty( Environment.USER, user );
 			}
 			final String pass = (String) metadata.getProps().get( AvailableSettings.JDBC_PASSWORD );
 			if ( StringHelper.isNotEmpty( pass ) ) {
 				this.setProperty( Environment.PASS, pass );
 			}
 		}
 		defineTransactionType( metadata.getTransactionType(), workingVars );
 		if ( metadata.getClasses().size() > 0 ) {
 			workingVars.put( AvailableSettings.CLASS_NAMES, metadata.getClasses() );
 		}
 		if ( metadata.getPackages().size() > 0 ) {
 			workingVars.put( AvailableSettings.PACKAGE_NAMES, metadata.getPackages() );
 		}
 		if ( metadata.getMappingFiles().size() > 0 ) {
 			workingVars.put( AvailableSettings.XML_FILE_NAMES, metadata.getMappingFiles() );
 		}
 		if ( metadata.getHbmfiles().size() > 0 ) {
 			workingVars.put( AvailableSettings.HBXML_FILES, metadata.getHbmfiles() );
 		}
 
 		Properties props = new Properties();
 		props.putAll( metadata.getProps() );
 
 		// validation factory
 		final Object validationFactory = overrides.get( AvailableSettings.VALIDATION_FACTORY );
 		if ( validationFactory != null ) {
 			BeanValidationIntegrator.validateFactory( validationFactory );
 			props.put( AvailableSettings.VALIDATION_FACTORY, validationFactory );
 		}
 		overrides.remove( AvailableSettings.VALIDATION_FACTORY );
 
 		// validation-mode (overrides has precedence)
 		{
 			final Object integrationValue = overrides.get( AvailableSettings.VALIDATION_MODE );
 			if ( integrationValue != null ) {
 				props.put( AvailableSettings.VALIDATION_MODE, integrationValue.toString() );
 			}
 			else if ( metadata.getValidationMode() != null ) {
 				props.put( AvailableSettings.VALIDATION_MODE, metadata.getValidationMode() );
 			}
 			overrides.remove( AvailableSettings.VALIDATION_MODE );
 		}
 
 		// shared-cache-mode (overrides has precedence)
 		{
 			final Object integrationValue = overrides.get( AvailableSettings.SHARED_CACHE_MODE );
 			if ( integrationValue != null ) {
 				props.put( AvailableSettings.SHARED_CACHE_MODE, integrationValue.toString() );
 			}
 			else if ( metadata.getSharedCacheMode() != null ) {
 				props.put( AvailableSettings.SHARED_CACHE_MODE, metadata.getSharedCacheMode() );
 			}
 			overrides.remove( AvailableSettings.SHARED_CACHE_MODE );
 		}
 
 		for ( Map.Entry entry : (Set<Map.Entry>) overrides.entrySet() ) {
 			Object value = entry.getValue();
 			props.put( entry.getKey(), value == null ? "" :  value ); //alter null, not allowed in properties
 		}
 
 		configure( props, workingVars );
 		return this;
 	}
 
 	/**
 	 * Build the configuration from an entity manager name and given the
 	 * appropriate extra properties. Those properties override the one get through
 	 * the persistence.xml file.
 	 * If the persistence unit name is not found or does not match the Persistence Provider, null is returned
 	 *
 	 * This method is used in a non managed environment
 	 *
 	 * @param persistenceUnitName persistence unit name
 	 * @param integration properties passed to the persistence provider
 	 *
 	 * @return configured Ejb3Configuration or null if no persistence unit match
 	 *
 	 * @see HibernatePersistence#createEntityManagerFactory(String, java.util.Map)
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public Ejb3Configuration configure(String persistenceUnitName, Map integration) {
 		try {
             LOG.debugf("Look up for persistence unit: %s", persistenceUnitName);
 			integration = integration == null ?
 					CollectionHelper.EMPTY_MAP :
 					Collections.unmodifiableMap( integration );
 			Enumeration<URL> xmls = Thread.currentThread()
 					.getContextClassLoader()
 					.getResources( "META-INF/persistence.xml" );
             if (!xmls.hasMoreElements()) LOG.unableToFindPersistenceXmlInClasspath();
 			while ( xmls.hasMoreElements() ) {
 				URL url = xmls.nextElement();
                 LOG.trace("Analyzing persistence.xml: " + url);
 				List<PersistenceMetadata> metadataFiles = PersistenceXmlLoader.deploy(
 						url,
 						integration,
 						cfg.getEntityResolver(),
 						PersistenceUnitTransactionType.RESOURCE_LOCAL );
 				for ( PersistenceMetadata metadata : metadataFiles ) {
                     LOG.trace(metadata);
 
 					if ( metadata.getProvider() == null || IMPLEMENTATION_NAME.equalsIgnoreCase(
 							metadata.getProvider()
 					) ) {
 						//correct provider
 
 						//lazy load the scanner to avoid unnecessary IOExceptions
 						Scanner scanner = null;
 						URL jarURL = null;
 						if ( metadata.getName() == null ) {
 							scanner = buildScanner( metadata.getProps(), integration );
 							jarURL = JarVisitorFactory.getJarURLFromURLEntry( url, "/META-INF/persistence.xml" );
 							metadata.setName( scanner.getUnqualifiedJarName(jarURL) );
 						}
 						if ( persistenceUnitName == null && xmls.hasMoreElements() ) {
 							throw new PersistenceException( "No name provided and several persistence units found" );
 						}
 						else if ( persistenceUnitName == null || metadata.getName().equals( persistenceUnitName ) ) {
 							if (scanner == null) {
 								scanner = buildScanner( metadata.getProps(), integration );
 								jarURL = JarVisitorFactory.getJarURLFromURLEntry( url, "/META-INF/persistence.xml" );
 							}
 							//scan main JAR
 							ScanningContext mainJarScanCtx = new ScanningContext()
 									.scanner( scanner )
 									.url( jarURL )
 									.explicitMappingFiles( metadata.getMappingFiles() )
 									.searchOrm( true );
 							setDetectedArtifactsOnScanningContext( mainJarScanCtx, metadata.getProps(), integration,
 																				metadata.getExcludeUnlistedClasses() );
 							addMetadataFromScan( mainJarScanCtx, metadata );
 
 							ScanningContext otherJarScanCtx = new ScanningContext()
 									.scanner( scanner )
 									.explicitMappingFiles( metadata.getMappingFiles() )
 									.searchOrm( true );
 							setDetectedArtifactsOnScanningContext( otherJarScanCtx, metadata.getProps(), integration,
 																				false );
 							for ( String jarFile : metadata.getJarFiles() ) {
 								otherJarScanCtx.url( JarVisitorFactory.getURLFromPath( jarFile ) );
 								addMetadataFromScan( otherJarScanCtx, metadata );
 							}
 							return configure( metadata, integration );
 						}
 					}
 				}
 			}
 			return null;
 		}
 		catch (Exception e) {
 			if ( e instanceof PersistenceException) {
 				throw (PersistenceException) e;
 			}
 			else {
 				throw new PersistenceException( getExceptionHeader() + "Unable to configure EntityManagerFactory", e );
 			}
 		}
 	}
 
 	private Scanner buildScanner(Properties properties, Map<?,?> integration) {
 		//read the String or Instance from the integration map first and use the properties as a backup.
 		Object scanner = integration.get( AvailableSettings.SCANNER );
 		if (scanner == null) {
 			scanner = properties.getProperty( AvailableSettings.SCANNER );
 		}
 		if (scanner != null) {
 			Class<?> scannerClass;
 			if ( scanner instanceof String ) {
 				try {
 					scannerClass = ReflectHelper.classForName( (String) scanner, this.getClass() );
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new PersistenceException(  "Cannot find scanner class. " + AvailableSettings.SCANNER + "=" + scanner, e );
 				}
 			}
 			else if (scanner instanceof Class) {
 				scannerClass = (Class<? extends Scanner>) scanner;
 			}
 			else if (scanner instanceof Scanner) {
 				return (Scanner) scanner;
 			}
 			else {
 				throw new PersistenceException(  "Scanner class configuration error: unknown type on the property. " + AvailableSettings.SCANNER );
 			}
 			try {
 				return (Scanner) scannerClass.newInstance();
 			}
 			catch ( InstantiationException e ) {
 				throw new PersistenceException(  "Unable to load Scanner class: " + scannerClass, e );
 			}
 			catch ( IllegalAccessException e ) {
 				throw new PersistenceException(  "Unable to load Scanner class: " + scannerClass, e );
 			}
 		}
 		else {
 			return new NativeScanner();
 		}
 	}
 
 	private static class ScanningContext {
 		//boolean excludeUnlistedClasses;
 		private Scanner scanner;
 		private URL url;
 		private List<String> explicitMappingFiles;
 		private boolean detectClasses;
 		private boolean detectHbmFiles;
 		private boolean searchOrm;
 
 		public ScanningContext scanner(Scanner scanner) {
 			this.scanner = scanner;
 			return this;
 		}
 
 		public ScanningContext url(URL url) {
 			this.url = url;
 			return this;
 		}
 
 		public ScanningContext explicitMappingFiles(List<String> explicitMappingFiles) {
 			this.explicitMappingFiles = explicitMappingFiles;
 			return this;
 		}
 
 		public ScanningContext detectClasses(boolean detectClasses) {
 			this.detectClasses = detectClasses;
 			return this;
 		}
 
 		public ScanningContext detectHbmFiles(boolean detectHbmFiles) {
 			this.detectHbmFiles = detectHbmFiles;
 			return this;
 		}
 
 		public ScanningContext searchOrm(boolean searchOrm) {
 			this.searchOrm = searchOrm;
 			return this;
 		}
 	}
 
 	private static void addMetadataFromScan(ScanningContext scanningContext, PersistenceMetadata metadata) throws IOException {
 		List<String> classes = metadata.getClasses();
 		List<String> packages = metadata.getPackages();
 		List<NamedInputStream> hbmFiles = metadata.getHbmfiles();
 		List<String> mappingFiles = metadata.getMappingFiles();
 		addScannedEntries( scanningContext, classes, packages, hbmFiles, mappingFiles );
 	}
 
 	private static void addScannedEntries(ScanningContext scanningContext, List<String> classes, List<String> packages, List<NamedInputStream> hbmFiles, List<String> mappingFiles) throws IOException {
 		Scanner scanner = scanningContext.scanner;
 		if (scanningContext.detectClasses) {
 			Set<Class<? extends Annotation>> annotationsToExclude = new HashSet<Class<? extends Annotation>>(3);
 			annotationsToExclude.add( Entity.class );
 			annotationsToExclude.add( MappedSuperclass.class );
 			annotationsToExclude.add( Embeddable.class );
 			Set<Class<?>> matchingClasses = scanner.getClassesInJar( scanningContext.url, annotationsToExclude );
 			for (Class<?> clazz : matchingClasses) {
 				classes.add( clazz.getName() );
 			}
 
 			Set<Package> matchingPackages = scanner.getPackagesInJar( scanningContext.url, new HashSet<Class<? extends Annotation>>(0) );
 			for (Package pkg : matchingPackages) {
 				packages.add( pkg.getName() );
 			}
 		}
 		Set<String> patterns = new HashSet<String>();
 		if (scanningContext.searchOrm) {
 			patterns.add( META_INF_ORM_XML );
 		}
 		if (scanningContext.detectHbmFiles) {
 			patterns.add( "**/*.hbm.xml" );
 		}
 		if ( mappingFiles != null) patterns.addAll( mappingFiles );
 		if (patterns.size() !=0) {
 			Set<NamedInputStream> files = scanner.getFilesInJar( scanningContext.url, patterns );
 			for (NamedInputStream file : files) {
 				hbmFiles.add( file );
 				if (mappingFiles != null) mappingFiles.remove( file.getName() );
 			}
 		}
 	}
 
 	/**
 	 * Process configuration from a PersistenceUnitInfo object; typically called by the container
 	 * via {@link javax.persistence.spi.PersistenceProvider#createContainerEntityManagerFactory}.
 	 * In Hibernate EM, this correlates to {@link HibernatePersistence#createContainerEntityManagerFactory}
 	 *
 	 * @param info The persistence unit info passed in by the container (usually from processing a persistence.xml).
 	 * @param integration The map of integration properties from the container to configure the provider.
 	 *
 	 * @return this
 	 *
 	 * @see HibernatePersistence#createContainerEntityManagerFactory
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public Ejb3Configuration configure(PersistenceUnitInfo info, Map integration) {
         if (LOG.isDebugEnabled()) LOG.debugf("Processing %s", LogHelper.logPersistenceUnitInfo(info));
         else LOG.processingPersistenceUnitInfoName(info.getPersistenceUnitName());
 
 		// Spec says the passed map may be null, so handle that to make further processing easier...
 		integration = integration != null ? Collections.unmodifiableMap( integration ) : CollectionHelper.EMPTY_MAP;
 
 		// See if we (Hibernate) are the persistence provider
 		String provider = (String) integration.get( AvailableSettings.PROVIDER );
 		if ( provider == null ) {
 			provider = info.getPersistenceProviderClassName();
 		}
 		if ( provider != null && ! provider.trim().startsWith( IMPLEMENTATION_NAME ) ) {
             LOG.requiredDifferentProvider(provider);
 			return null;
 		}
 
 		// set the classloader, passed in by the container in info, to set as the TCCL so that
 		// Hibernate uses it to properly resolve class references.
 		if ( info.getClassLoader() == null ) {
 			throw new IllegalStateException(
 					"[PersistenceUnit: " + info.getPersistenceUnitName() == null ? "" : info.getPersistenceUnitName()
 							+ "] " + "PersistenceUnitInfo.getClassLoader() id null" );
 		}
 		Thread thread = Thread.currentThread();
 		ClassLoader contextClassLoader = thread.getContextClassLoader();
 		boolean sameClassLoader = info.getClassLoader().equals( contextClassLoader );
 		if ( ! sameClassLoader ) {
 			overridenClassLoader = info.getClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		else {
 			overridenClassLoader = null;
 		}
 
 		// Best I can tell, 'workingVars' is some form of additional configuration contract.
 		// But it does not correlate 1-1 to EMF/SF settings.  It really is like a set of de-typed
 		// additional configuration info.  I think it makes better sense to define this as an actual
 		// contract if that was in fact the intent; the code here is pretty confusing.
 		try {
 			Map workingVars = new HashMap();
 			workingVars.put( AvailableSettings.PERSISTENCE_UNIT_NAME, info.getPersistenceUnitName() );
 			this.persistenceUnitName = info.getPersistenceUnitName();
 			List<String> entities = new ArrayList<String>( 50 );
 			if ( info.getManagedClassNames() != null ) entities.addAll( info.getManagedClassNames() );
 			List<NamedInputStream> hbmFiles = new ArrayList<NamedInputStream>();
 			List<String> packages = new ArrayList<String>();
 			List<String> xmlFiles = new ArrayList<String>( 50 );
 			List<XmlDocument> xmlDocuments = new ArrayList<XmlDocument>( 50 );
 			if ( info.getMappingFileNames() != null ) {
 				xmlFiles.addAll( info.getMappingFileNames() );
 			}
 			//Should always be true if the container is not dump
 			boolean searchForORMFiles = ! xmlFiles.contains( META_INF_ORM_XML );
 
 			ScanningContext context = new ScanningContext();
 			final Properties copyOfProperties = (Properties) info.getProperties().clone();
 			ConfigurationHelper.overrideProperties( copyOfProperties, integration );
 			context.scanner( buildScanner( copyOfProperties, integration ) )
 					.searchOrm( searchForORMFiles )
 					.explicitMappingFiles( null ); //URLs provided by the container already
 
 			//context for other JARs
 			setDetectedArtifactsOnScanningContext(context, info.getProperties(), null, false );
 			for ( URL jar : info.getJarFileUrls() ) {
 				context.url(jar);
 				scanForClasses( context, packages, entities, hbmFiles );
 			}
 
 			//main jar
 			context.url( info.getPersistenceUnitRootUrl() );
 			setDetectedArtifactsOnScanningContext( context, info.getProperties(), null, info.excludeUnlistedClasses() );
 			scanForClasses( context, packages, entities, hbmFiles );
 
 			Properties properties = info.getProperties() != null ? info.getProperties() : new Properties();
 			ConfigurationHelper.overrideProperties( properties, integration );
 
 			//FIXME entities is used to enhance classes and to collect annotated entities this should not be mixed
 			//fill up entities with the on found in xml files
 			addXMLEntities( xmlFiles, info, entities, xmlDocuments );
 
 			//FIXME send the appropriate entites.
 			if ( "true".equalsIgnoreCase( properties.getProperty( AvailableSettings.USE_CLASS_ENHANCER ) ) ) {
 				info.addTransformer( new InterceptFieldClassFileTransformer( entities ) );
 			}
 
 			workingVars.put( AvailableSettings.CLASS_NAMES, entities );
 			workingVars.put( AvailableSettings.PACKAGE_NAMES, packages );
 			workingVars.put( AvailableSettings.XML_FILE_NAMES, xmlFiles );
 			workingVars.put( PARSED_MAPPING_DOMS, xmlDocuments );
 
 			if ( hbmFiles.size() > 0 ) {
 				workingVars.put( AvailableSettings.HBXML_FILES, hbmFiles );
 			}
 
 			// validation factory
 			final Object validationFactory = integration.get( AvailableSettings.VALIDATION_FACTORY );
 			if ( validationFactory != null ) {
 				BeanValidationIntegrator.validateFactory( validationFactory );
 				properties.put( AvailableSettings.VALIDATION_FACTORY, validationFactory );
 			}
 
 			// validation-mode (integration has precedence)
 			{
 				final Object integrationValue = integration.get( AvailableSettings.VALIDATION_MODE );
 				if ( integrationValue != null ) {
 					properties.put( AvailableSettings.VALIDATION_MODE, integrationValue.toString() );
 				}
 				else if ( info.getValidationMode() != null ) {
 					properties.put( AvailableSettings.VALIDATION_MODE, info.getValidationMode().name() );
 				}
 			}
 
 			// shared-cache-mode (integration has precedence)
 			{
 				final Object integrationValue = integration.get( AvailableSettings.SHARED_CACHE_MODE );
 				if ( integrationValue != null ) {
 					properties.put( AvailableSettings.SHARED_CACHE_MODE, integrationValue.toString() );
 				}
 				else if ( info.getSharedCacheMode() != null ) {
 					properties.put( AvailableSettings.SHARED_CACHE_MODE, info.getSharedCacheMode().name() );
 				}
 			}
 
 			//datasources
 			Boolean isJTA = null;
 			boolean overridenDatasource = false;
 			if ( integration.containsKey( AvailableSettings.JTA_DATASOURCE ) ) {
 				String dataSource = (String) integration.get( AvailableSettings.JTA_DATASOURCE );
 				overridenDatasource = true;
 				properties.setProperty( Environment.DATASOURCE, dataSource );
 				isJTA = Boolean.TRUE;
 			}
 			if ( integration.containsKey( AvailableSettings.NON_JTA_DATASOURCE ) ) {
 				String dataSource = (String) integration.get( AvailableSettings.NON_JTA_DATASOURCE );
 				overridenDatasource = true;
 				properties.setProperty( Environment.DATASOURCE, dataSource );
 				if (isJTA == null) isJTA = Boolean.FALSE;
 			}
 
 			if ( ! overridenDatasource && ( info.getJtaDataSource() != null || info.getNonJtaDataSource() != null ) ) {
 				isJTA = info.getJtaDataSource() != null ? Boolean.TRUE : Boolean.FALSE;
 				this.setDataSource(
 						isJTA ? info.getJtaDataSource() : info.getNonJtaDataSource()
 				);
 				this.setProperty(
 						Environment.CONNECTION_PROVIDER, InjectedDataSourceConnectionProvider.class.getName()
 				);
 			}
 			/*
 			 * If explicit type => use it
 			 * If a JTA DS is used => JTA transaction,
 			 * if a non JTA DS is used => RESOURCe_LOCAL
 			 * if none, set to JavaEE default => JTA transaction
 			 */
 			PersistenceUnitTransactionType transactionType = info.getTransactionType();
 			if (transactionType == null) {
 				if (isJTA == Boolean.TRUE) {
 					transactionType = PersistenceUnitTransactionType.JTA;
 				}
 				else if ( isJTA == Boolean.FALSE ) {
 					transactionType = PersistenceUnitTransactionType.RESOURCE_LOCAL;
 				}
 				else {
 					transactionType = PersistenceUnitTransactionType.JTA;
 				}
 			}
 			defineTransactionType( transactionType, workingVars );
 			configure( properties, workingVars );
 		}
 		finally {
 			//After EMF, set the CCL back
 			if ( ! sameClassLoader ) {
 				thread.setContextClassLoader( contextClassLoader );
 			}
 		}
 		return this;
 	}
 
 	/**
 	 * Processes {@code xmlFiles} argument and populates:<ul>
 	 * <li>the {@code entities} list with encountered classnames</li>
 	 * <li>the {@code xmlDocuments} list with parsed/validated {@link XmlDocument} corrolary to each xml file</li>
 	 * </ul>
 	 *
 	 * @param xmlFiles The XML resource names; these will be resolved by classpath lookup and parsed/validated.
 	 * @param info The PUI
 	 * @param entities (output) The names of all encountered "mapped" classes
 	 * @param xmlDocuments (output) The list of {@link XmlDocument} instances of each entry in {@code xmlFiles}
 	 */
 	@SuppressWarnings({ "unchecked" })
 	private void addXMLEntities(
 			List<String> xmlFiles,
 			PersistenceUnitInfo info,
 			List<String> entities,
 			List<XmlDocument> xmlDocuments) {
 		//TODO handle inputstream related hbm files
 		ClassLoader classLoaderToUse = info.getNewTempClassLoader();
 		if ( classLoaderToUse == null ) {
             LOG.persistenceProviderCallerDoesNotImplementEjb3SpecCorrectly();
 			return;
 		}
 		for ( final String xmlFile : xmlFiles ) {
 			final InputStream fileInputStream = classLoaderToUse.getResourceAsStream( xmlFile );
 			if ( fileInputStream == null ) {
                 LOG.unableToResolveMappingFile(xmlFile);
 				continue;
 			}
 			final InputSource inputSource = new InputSource( fileInputStream );
 
 			XmlDocument metadataXml = MappingReader.INSTANCE.readMappingDocument(
 					cfg.getEntityResolver(),
 					inputSource,
 					new OriginImpl( "persistence-unit-info", xmlFile )
 			);
 			xmlDocuments.add( metadataXml );
 			try {
 				final Element rootElement = metadataXml.getDocumentTree().getRootElement();
 				if ( rootElement != null && "entity-mappings".equals( rootElement.getName() ) ) {
 					Element element = rootElement.element( "package" );
 					String defaultPackage = element != null ? element.getTextTrim() : null;
 					List<Element> elements = rootElement.elements( "entity" );
 					for (Element subelement : elements ) {
 						String classname = XMLContext.buildSafeClassName( subelement.attributeValue( "class" ), defaultPackage );
 						if ( ! entities.contains( classname ) ) {
 							entities.add( classname );
 						}
 					}
 					elements = rootElement.elements( "mapped-superclass" );
 					for (Element subelement : elements ) {
 						String classname = XMLContext.buildSafeClassName( subelement.attributeValue( "class" ), defaultPackage );
 						if ( ! entities.contains( classname ) ) {
 							entities.add( classname );
 						}
 					}
 					elements = rootElement.elements( "embeddable" );
 					for (Element subelement : elements ) {
 						String classname = XMLContext.buildSafeClassName( subelement.attributeValue( "class" ), defaultPackage );
 						if ( ! entities.contains( classname ) ) {
 							entities.add( classname );
 						}
 					}
 				}
 				else if ( rootElement != null && "hibernate-mappings".equals( rootElement.getName() ) ) {
 					//FIXME include hbm xml entities to enhance them but entities is also used to collect annotated entities
 				}
 			}
 			finally {
 				try {
 					fileInputStream.close();
 				}
 				catch (IOException ioe) {
                     LOG.unableToCloseInputStream(ioe);
 				}
 			}
 		}
 		xmlFiles.clear();
 	}
 
 	private void defineTransactionType(Object overridenTxType, Map workingVars) {
 		if ( overridenTxType == null ) {
 //			if ( transactionType == null ) {
 //				transactionType = PersistenceUnitTransactionType.JTA; //this is the default value
 //			}
 			//nothing to override
 		}
 		else if ( overridenTxType instanceof String ) {
 			transactionType = PersistenceXmlLoader.getTransactionType( (String) overridenTxType );
 		}
 		else if ( overridenTxType instanceof PersistenceUnitTransactionType ) {
 			transactionType = (PersistenceUnitTransactionType) overridenTxType;
 		}
 		else {
 			throw new PersistenceException( getExceptionHeader() +
 					AvailableSettings.TRANSACTION_TYPE + " of the wrong class type"
 							+ ": " + overridenTxType.getClass()
 			);
 		}
 
 	}
 
 	public Ejb3Configuration setProperty(String key, String value) {
 		cfg.setProperty( key, value );
 		return this;
 	}
 
 	/**
 	 * Set ScanningContext detectClasses and detectHbmFiles according to context
 	 */
 	private void setDetectedArtifactsOnScanningContext(ScanningContext context,
 													   Properties properties,
 													   Map overridenProperties,
 													   boolean excludeIfNotOverriden) {
 
 		boolean detectClasses = false;
 		boolean detectHbm = false;
 		String detectSetting = overridenProperties != null ?
 				(String) overridenProperties.get( AvailableSettings.AUTODETECTION ) :
 				null;
 		detectSetting = detectSetting == null ?
 				properties.getProperty( AvailableSettings.AUTODETECTION) :
 				detectSetting;
 		if ( detectSetting == null && excludeIfNotOverriden) {
 			//not overriden through HibernatePersistence.AUTODETECTION so we comply with the spec excludeUnlistedClasses
 			context.detectClasses( false ).detectHbmFiles( false );
 			return;
 		}
 
 		if ( detectSetting == null){
 			detectSetting = "class,hbm";
 		}
 		StringTokenizer st = new StringTokenizer( detectSetting, ", ", false );
 		while ( st.hasMoreElements() ) {
 			String element = (String) st.nextElement();
 			if ( "class".equalsIgnoreCase( element ) ) detectClasses = true;
 			if ( "hbm".equalsIgnoreCase( element ) ) detectHbm = true;
 		}
         LOG.debugf("Detect class: %s; detect hbm: %s", detectClasses, detectHbm);
 		context.detectClasses( detectClasses ).detectHbmFiles( detectHbm );
 	}
 
 	private void scanForClasses(ScanningContext scanningContext, List<String> packages, List<String> entities, List<NamedInputStream> hbmFiles) {
 		if (scanningContext.url == null) {
             LOG.containerProvidingNullPersistenceUnitRootUrl();
 			return;
 		}
 		try {
 			addScannedEntries( scanningContext, entities, packages, hbmFiles, null );
 		}
 		catch (RuntimeException e) {
 			throw new RuntimeException( "error trying to scan <jar-file>: " + scanningContext.url.toString(), e );
 		}
 		catch( IOException e ) {
 			throw new RuntimeException( "Error while reading " + scanningContext.url.toString(), e );
 		}
 	}
 
 	/**
 	 * create a factory from a list of properties and
 	 * HibernatePersistence.CLASS_NAMES -> Collection<String> (use to list the classes from config files
 	 * HibernatePersistence.PACKAGE_NAMES -> Collection<String> (use to list the mappings from config files
 	 * HibernatePersistence.HBXML_FILES -> Collection<InputStream> (input streams of hbm files)
 	 * HibernatePersistence.LOADED_CLASSES -> Collection<Class> (list of loaded classes)
 	 * <p/>
 	 * <b>Used by JBoss AS only</b>
 	 * @deprecated use the Java Persistence API
 	 */
 	// This is used directly by JBoss so don't remove until further notice.  bill@jboss.org
 	@Deprecated
     public EntityManagerFactory createEntityManagerFactory(Map workingVars) {
 		configure( workingVars );
 		return buildEntityManagerFactory();
 	}
 
 	/**
 	 * Process configuration and build an EntityManagerFactory <b>when</b> the configuration is ready
 	 * @deprecated
 	 */
 	@Deprecated
     public EntityManagerFactory createEntityManagerFactory() {
 		configure( cfg.getProperties(), new HashMap() );
 		return buildEntityManagerFactory();
 	}
 
 	public EntityManagerFactory buildEntityManagerFactory() {
 		return buildEntityManagerFactory( new BasicServiceRegistryImpl( cfg.getProperties() ) );
 	}
 
 	public EntityManagerFactory buildEntityManagerFactory(ServiceRegistry serviceRegistry) {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			configure( (Properties)null, null );
 			NamingHelper.bind(this);
 			// todo : temporary -> HHH-5562
 			serviceRegistry.getService( StandardServiceInitiators.EventListenerRegistrationService.class )
 					.attachEventListenerRegistration( new JpaEventListenerRegistration() );
 			return new EntityManagerFactoryImpl(
 					transactionType,
 					discardOnClose,
 					getSessionInterceptorClass( cfg.getProperties() ),
 					cfg,
 					serviceRegistry
 			);
 		}
 		catch (HibernateException e) {
 			throw new PersistenceException( getExceptionHeader() + "Unable to build EntityManagerFactory", e );
 		}
 		finally {
 			if (thread != null) {
 				thread.setContextClassLoader( contextClassLoader );
 			}
 		}
 	}
 
 	private Class getSessionInterceptorClass(Properties properties) {
 		String sessionInterceptorClassname = (String) properties.get( AvailableSettings.SESSION_INTERCEPTOR );
 		if ( StringHelper.isNotEmpty( sessionInterceptorClassname ) ) {
 			try {
 				Class interceptorClass = ReflectHelper.classForName(
 						sessionInterceptorClassname, Ejb3Configuration.class
 				);
 				interceptorClass.newInstance();
 				return interceptorClass;
 			}
 			catch (ClassNotFoundException e) {
 				throw new PersistenceException( getExceptionHeader() + "Unable to load "
 						+ AvailableSettings.SESSION_INTERCEPTOR + ": " + sessionInterceptorClassname, e);
 			}
 			catch (IllegalAccessException e) {
 				throw new PersistenceException( getExceptionHeader() + "Unable to instanciate "
 						+ AvailableSettings.SESSION_INTERCEPTOR + ": " + sessionInterceptorClassname, e);
 			}
 			catch (InstantiationException e) {
 				throw new PersistenceException( getExceptionHeader() + "Unable to instanciate "
 						+ AvailableSettings.SESSION_INTERCEPTOR + ": " + sessionInterceptorClassname, e);
 			}
         }
         return null;
 	}
 
 	public Reference getReference() throws NamingException {
         LOG.debugf( "Returning a Reference to the Ejb3Configuration" );
 		ByteArrayOutputStream stream = new ByteArrayOutputStream();
 		ObjectOutput out = null;
 		byte[] serialized;
 		try {
 			out = new ObjectOutputStream( stream );
 			out.writeObject( this );
 			out.close();
 			serialized = stream.toByteArray();
 			stream.close();
 		}
 		catch (IOException e) {
 			NamingException namingException = new NamingException( "Unable to serialize Ejb3Configuration" );
 			namingException.setRootCause( e );
 			throw namingException;
 		}
 
 		return new Reference(
 				Ejb3Configuration.class.getName(),
 				new BinaryRefAddr("object", serialized ),
 				Ejb3ConfigurationObjectFactory.class.getName(),
 				null
 		);
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public Ejb3Configuration configure(Map configValues) {
 		Properties props = new Properties();
 		if ( configValues != null ) {
 			props.putAll( configValues );
 			//remove huge non String elements for a clean props
 			props.remove( AvailableSettings.CLASS_NAMES );
 			props.remove( AvailableSettings.PACKAGE_NAMES );
 			props.remove( AvailableSettings.HBXML_FILES );
 			props.remove( AvailableSettings.LOADED_CLASSES );
 		}
 		return configure( props, configValues );
 	}
 
 	/**
 	 * Configures this configuration object from 2 distinctly different sources.
 	 *
 	 * @param properties These are the properties that came from the user, either via
 	 * a persistence.xml or explicitly passed in to one of our
 	 * {@link javax.persistence.spi.PersistenceProvider}/{@link HibernatePersistence} contracts.
 	 * @param workingVars Is collection of settings which need to be handled similarly
 	 * between the 2 main bootstrap methods, but where the values are determine very differently
 	 * by each bootstrap method.  todo eventually make this a contract (class/interface)
 	 *
 	 * @return The configured configuration
 	 *
 	 * @see HibernatePersistence
 	 */
 	private Ejb3Configuration configure(Properties properties, Map workingVars) {
 		//TODO check for people calling more than once this method (except buildEMF)
 		if (isConfigurationProcessed) return this;
 		isConfigurationProcessed = true;
 		Properties preparedProperties = prepareProperties( properties, workingVars );
 		if ( workingVars == null ) workingVars = CollectionHelper.EMPTY_MAP;
 
 		if ( preparedProperties.containsKey( AvailableSettings.CFG_FILE ) ) {
 			String cfgFileName = preparedProperties.getProperty( AvailableSettings.CFG_FILE );
 			cfg.configure( cfgFileName );
 		}
 
 		cfg.addProperties( preparedProperties ); //persistence.xml has priority over hibernate.cfg.xml
 
 		addClassesToSessionFactory( workingVars );
 
 		//processes specific properties
 		List<String> jaccKeys = new ArrayList<String>();
 
 
 		Interceptor defaultInterceptor = DEFAULT_CONFIGURATION.getInterceptor();
 		NamingStrategy defaultNamingStrategy = DEFAULT_CONFIGURATION.getNamingStrategy();
 
 		Iterator propertyIt = preparedProperties.keySet().iterator();
 		while ( propertyIt.hasNext() ) {
 			Object uncastObject = propertyIt.next();
 			//had to be safe
 			if ( uncastObject != null && uncastObject instanceof String ) {
 				String propertyKey = (String) uncastObject;
 				if ( propertyKey.startsWith( AvailableSettings.CLASS_CACHE_PREFIX ) ) {
 					setCacheStrategy( propertyKey, preparedProperties, true, workingVars );
 				}
 				else if ( propertyKey.startsWith( AvailableSettings.COLLECTION_CACHE_PREFIX ) ) {
 					setCacheStrategy( propertyKey, preparedProperties, false, workingVars );
 				}
 				else if ( propertyKey.startsWith( AvailableSettings.JACC_PREFIX )
 						&& ! ( propertyKey.equals( AvailableSettings.JACC_CONTEXT_ID )
 						|| propertyKey.equals( AvailableSettings.JACC_ENABLED ) ) ) {
 					jaccKeys.add( propertyKey );
 				}
 			}
 		}
 		final Interceptor interceptor = instantiateCustomClassFromConfiguration(
 				preparedProperties,
 				defaultInterceptor,
 				cfg.getInterceptor(),
 				AvailableSettings.INTERCEPTOR,
 				"interceptor",
 				Interceptor.class
 		);
 		if ( interceptor != null ) {
 			cfg.setInterceptor( interceptor );
 		}
 		final NamingStrategy namingStrategy = instantiateCustomClassFromConfiguration(
 				preparedProperties,
 				defaultNamingStrategy,
 				cfg.getNamingStrategy(),
 				AvailableSettings.NAMING_STRATEGY,
 				"naming strategy",
 				NamingStrategy.class
 		);
 		if ( namingStrategy != null ) {
 			cfg.setNamingStrategy( namingStrategy );
 		}
 
 		final SessionFactoryObserver observer = instantiateCustomClassFromConfiguration(
 				preparedProperties,
 				null,
 				cfg.getSessionFactoryObserver(),
 				AvailableSettings.SESSION_FACTORY_OBSERVER,
 				"SessionFactory observer",
 				SessionFactoryObserver.class
 		);
 		if ( observer != null ) {
 			cfg.setSessionFactoryObserver( observer );
 		}
 
 		if ( jaccKeys.size() > 0 ) {
 			addSecurity( jaccKeys, preparedProperties, workingVars );
 		}
 
 		//some spec compliance checking
 		//TODO centralize that?
         if (!"true".equalsIgnoreCase(cfg.getProperty(Environment.AUTOCOMMIT))) LOG.jdbcAutoCommitFalseBreaksEjb3Spec(Environment.AUTOCOMMIT);
         discardOnClose = preparedProperties.getProperty(AvailableSettings.DISCARD_PC_ON_CLOSE).equals("true");
 		return this;
 	}
 
 	private <T> T instantiateCustomClassFromConfiguration(
 			Properties preparedProperties,
 			T defaultObject,
 			T cfgObject,
 			String propertyName,
 			String classDescription,
 			Class<T> objectClass) {
 		if ( preparedProperties.containsKey( propertyName )
 				&& ( cfgObject == null || cfgObject.equals( defaultObject ) ) ) {
 			//cfg.setXxx has precedence over configuration file
 			String className = preparedProperties.getProperty( propertyName );
 			try {
 				Class<T> clazz = classForName( className );
 				return clazz.newInstance();
 				//cfg.setInterceptor( (Interceptor) instance.newInstance() );
 			}
 			catch (ClassNotFoundException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to find " + classDescription + " class: " + className, e
 				);
 			}
 			catch (IllegalAccessException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to access " + classDescription + " class: " + className, e
 				);
 			}
 			catch (InstantiationException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to instantiate " + classDescription + " class: " + className, e
 				);
 			}
 			catch (ClassCastException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + classDescription + " class does not implement " + objectClass + " interface: "
 								+ className, e
 				);
 			}
 		}
 		return null;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private void addClassesToSessionFactory(Map workingVars) {
 		if ( workingVars.containsKey( AvailableSettings.CLASS_NAMES ) ) {
 			Collection<String> classNames = (Collection<String>) workingVars.get(
 					AvailableSettings.CLASS_NAMES
 			);
 			addNamedAnnotatedClasses( this, classNames, workingVars );
 		}
 
 		if ( workingVars.containsKey( PARSED_MAPPING_DOMS ) ) {
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerImpl.java
index 03a951f82b..0ab2195e72 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerImpl.java
@@ -1,172 +1,172 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb;
 
 import javax.persistence.PersistenceContextType;
 import javax.persistence.PersistenceException;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.transaction.Synchronization;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.annotations.common.util.ReflectHelper;
 import org.hibernate.cfg.Environment;
-import org.hibernate.engine.SessionFactoryImplementor;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.engine.SessionImplementor;
 
 /**
  * Hibernate implementation of {@link javax.persistence.EntityManager}.
  *
  * @author Gavin King
  */
 public class EntityManagerImpl extends AbstractEntityManagerImpl {
 
-    public static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    public static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                           EntityManagerImpl.class.getName());
 
 	protected Session session;
 	protected boolean open;
 	protected boolean discardOnClose;
 	private Class sessionInterceptorClass;
 
 	public EntityManagerImpl(
 			EntityManagerFactoryImpl entityManagerFactory,
 			PersistenceContextType pcType,
 			PersistenceUnitTransactionType transactionType,
 			boolean discardOnClose,
 			Class sessionInterceptorClass,
 			Map properties) {
 		super( entityManagerFactory, pcType, transactionType, properties );
 		this.open = true;
 		this.discardOnClose = discardOnClose;
 		Object localSessionInterceptor = null;
 		if (properties != null) {
 			localSessionInterceptor = properties.get( AvailableSettings.SESSION_INTERCEPTOR );
 		}
 		if ( localSessionInterceptor != null ) {
 			if (localSessionInterceptor instanceof Class) {
 				sessionInterceptorClass = (Class) localSessionInterceptor;
 			}
 			else if (localSessionInterceptor instanceof String) {
 				try {
 					sessionInterceptorClass =
 							ReflectHelper.classForName( (String) localSessionInterceptor, EntityManagerImpl.class );
 				}
 				catch (ClassNotFoundException e) {
 					throw new PersistenceException("Unable to instanciate interceptor: " + localSessionInterceptor, e);
 				}
 			}
 			else {
 				throw new PersistenceException("Unable to instanciate interceptor: " + localSessionInterceptor);
 			}
 		}
 		this.sessionInterceptorClass = sessionInterceptorClass;
 		postInit();
 	}
 
 	@Override
     public Session getSession() {
 		if ( !open ) {
 			throw new IllegalStateException( "EntityManager is closed" );
 		}
 		return getRawSession();
 	}
 
 	@Override
     protected Session getRawSession() {
 		if ( session == null ) {
 			SessionBuilder sessionBuilder = getEntityManagerFactory().getSessionFactory().withOptions();
 			if (sessionInterceptorClass != null) {
 				try {
 					Interceptor interceptor = (Interceptor) sessionInterceptorClass.newInstance();
 					sessionBuilder.interceptor( interceptor );
 				}
 				catch (InstantiationException e) {
 					throw new PersistenceException("Unable to instanciate session interceptor: " + sessionInterceptorClass, e);
 				}
 				catch (IllegalAccessException e) {
 					throw new PersistenceException("Unable to instanciate session interceptor: " + sessionInterceptorClass, e);
 				}
 				catch (ClassCastException e) {
 					throw new PersistenceException("Session interceptor does not implement Interceptor: " + sessionInterceptorClass, e);
 				}
 			}
 			sessionBuilder.autoJoinTransactions( getTransactionType() != PersistenceUnitTransactionType.JTA );
 			session = sessionBuilder.openSession();
 			if ( persistenceContextType == PersistenceContextType.TRANSACTION ) {
 				( (SessionImplementor) session ).setAutoClear( true );
 			}
 		}
 		return session;
 	}
 
 	public void close() {
 		if ( !open ) {
 			throw new IllegalStateException( "EntityManager is closed" );
 		}
 		if ( !discardOnClose && isTransactionInProgress() ) {
 			//delay the closing till the end of the enlisted transaction
             getSession().getTransaction().registerSynchronization(new Synchronization() {
                 public void beforeCompletion() {
                     // nothing to do
                 }
 
 				public void afterCompletion( int i ) {
                     if (session != null) if (session.isOpen()) {
                         LOG.debugf("Closing entity manager after transaction completion");
                         session.close();
                     } else LOG.entityManagerClosedBySomeoneElse(Environment.AUTO_CLOSE_SESSION);
                     // TODO session == null should not happen
                 }
             });
 		}
 		else {
 			//close right now
 			if ( session != null ) {
 				session.close();
 			}
 		}
 		open = false;
 	}
 
 	public boolean isOpen() {
 		//adjustFlushMode(); //don't adjust, can't be done on closed EM
 		try {
 			if ( open ) {
 				getSession().isOpen(); //to force enlistment in tx
 			}
 			return open;
 		}
 		catch (HibernateException he) {
 			throwPersistenceException( he );
 			return false;
 		}
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/QueryImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/QueryImpl.java
index 1f4e1e0180..1221f054c1 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/QueryImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/QueryImpl.java
@@ -1,637 +1,638 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb;
 import static javax.persistence.TemporalType.DATE;
 import static javax.persistence.TemporalType.TIME;
 import static javax.persistence.TemporalType.TIMESTAMP;
 import java.util.Calendar;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Date;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 import javax.persistence.Parameter;
 import javax.persistence.PersistenceException;
 import javax.persistence.Query;
 import javax.persistence.TemporalType;
 import javax.persistence.TransactionRequiredException;
 import javax.persistence.TypedQuery;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.QueryParameterException;
 import org.hibernate.SQLQuery;
 import org.hibernate.TypeMismatchException;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.ejb.util.LockModeTypeHelper;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.query.NamedParameterDescriptor;
 import org.hibernate.engine.query.OrdinalParameterDescriptor;
 import org.hibernate.hql.QueryExecutionRequestException;
 import org.hibernate.impl.AbstractQueryImpl;
 import org.jboss.logging.Logger;
 
 /**
  * Hibernate implementation of both the {@link Query} and {@link TypedQuery} contracts.
  *
  * @author <a href="mailto:gavin@hibernate.org">Gavin King</a>
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  */
 public class QueryImpl<X> extends org.hibernate.ejb.AbstractQueryImpl<X> implements TypedQuery<X>, HibernateQuery {
 
-    public static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class, QueryImpl.class.getName());
+    public static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class, QueryImpl.class.getName());
 
 	private org.hibernate.Query query;
 	private Set<Integer> jpaPositionalIndices;
 	private Set<Parameter<?>> parameters;
 
 	public QueryImpl(org.hibernate.Query query, AbstractEntityManagerImpl em) {
 		this( query, em, Collections.<String, Class>emptyMap() );
 	}
 
 	public QueryImpl(
 			org.hibernate.Query query,
 			AbstractEntityManagerImpl em,
 			Map<String,Class> namedParameterTypeRedefinitions) {
 		super( em );
 		this.query = query;
 		extractParameterInfo( namedParameterTypeRedefinitions );
 	}
 
 	@SuppressWarnings({ "unchecked", "RedundantCast" })
 	private void extractParameterInfo(Map<String,Class> namedParameterTypeRedefinition) {
 		if ( ! AbstractQueryImpl.class.isInstance( query ) ) {
 			throw new IllegalStateException( "Unknown query type for parameter extraction" );
 		}
 
 		HashSet<Parameter<?>> parameters = new HashSet<Parameter<?>>();
 		AbstractQueryImpl queryImpl = AbstractQueryImpl.class.cast( query );
 
 		// extract named params
 		for ( String name : (Set<String>) queryImpl.getParameterMetadata().getNamedParameterNames() ) {
 			final NamedParameterDescriptor descriptor =
 					queryImpl.getParameterMetadata().getNamedParameterDescriptor( name );
 			Class javaType = namedParameterTypeRedefinition.get( name );
 			if ( javaType != null && mightNeedRedefinition( javaType ) ) {
 				descriptor.resetExpectedType(
 						sfi().getTypeResolver().heuristicType( javaType.getName() )
 				);
 			}
 			else if ( descriptor.getExpectedType() != null ) {
 				javaType = descriptor.getExpectedType().getReturnedClass();
 			}
 			final ParameterImpl parameter = new ParameterImpl( name, javaType );
 			parameters.add( parameter );
 			if ( descriptor.isJpaStyle() ) {
 				if ( jpaPositionalIndices == null ) {
 					jpaPositionalIndices = new HashSet<Integer>();
 				}
 				jpaPositionalIndices.add( Integer.valueOf( name ) );
 			}
 		}
 
 		// extract positional parameters
 		for ( int i = 0, max = queryImpl.getParameterMetadata().getOrdinalParameterCount(); i < max; i++ ) {
 			final OrdinalParameterDescriptor descriptor =
 					queryImpl.getParameterMetadata().getOrdinalParameterDescriptor( i+1 );
 			ParameterImpl parameter = new ParameterImpl(
 					i + 1,
 					descriptor.getExpectedType() == null
 							? null
 							: descriptor.getExpectedType().getReturnedClass()
 			);
 			parameters.add( parameter );
 			Integer position = descriptor.getOrdinalPosition();
             if (jpaPositionalIndices != null && jpaPositionalIndices.contains(position)) LOG.parameterPositionOccurredAsBothJpaAndHibernatePositionalParameter(position);
 		}
 
 		this.parameters = java.util.Collections.unmodifiableSet( parameters );
 	}
 
 	private SessionFactoryImplementor sfi() {
 		return (SessionFactoryImplementor) getEntityManager().getFactory().getSessionFactory();
 	}
 
 	private boolean mightNeedRedefinition(Class javaType) {
 		// for now, only really no for dates/times/timestamps
 		return java.util.Date.class.isAssignableFrom( javaType );
 	}
 
 	private static class ParameterImpl implements Parameter {
 		private final String name;
 		private final Integer position;
 		private final Class javaType;
 
 		private ParameterImpl(String name, Class javaType) {
 			this.name = name;
 			this.javaType = javaType;
 			this.position = null;
 		}
 
 		private ParameterImpl(Integer position, Class javaType) {
 			this.position = position;
 			this.javaType = javaType;
 			this.name = null;
 		}
 
 		public String getName() {
 			return name;
 		}
 
 		public Integer getPosition() {
 			return position;
 		}
 
 		public Class getParameterType() {
 			return javaType;
 		}
 	}
 
 	public org.hibernate.Query getHibernateQuery() {
 		return query;
 	}
 
 	@Override
     protected int internalExecuteUpdate() {
 		return query.executeUpdate();
 	}
 
 	@Override
     protected void applyMaxResults(int maxResults) {
 		query.setMaxResults( maxResults );
 	}
 
 	@Override
     protected void applyFirstResult(int firstResult) {
 		query.setFirstResult( firstResult );
 	}
 
 	@Override
     protected void applyTimeout(int timeout) {
 		query.setTimeout( timeout );
 	}
 
 	@Override
     protected void applyComment(String comment) {
 		query.setComment( comment );
 	}
 
 	@Override
     protected void applyFetchSize(int fetchSize) {
 		query.setFetchSize( fetchSize );
 	}
 
 	@Override
     protected void applyCacheable(boolean isCacheable) {
 		query.setCacheable( isCacheable );
 	}
 
 	@Override
     protected void applyCacheRegion(String regionName) {
 		query.setCacheRegion( regionName );
 	}
 
 	@Override
     protected void applyReadOnly(boolean isReadOnly) {
 		query.setReadOnly( isReadOnly );
 	}
 
 	@Override
     protected void applyCacheMode(CacheMode cacheMode) {
 		query.setCacheMode( cacheMode );
 	}
 
 	@Override
     protected void applyFlushMode(FlushMode flushMode) {
 		query.setFlushMode( flushMode );
 	}
 
 	@Override
     protected boolean canApplyLockModes() {
 		return org.hibernate.impl.QueryImpl.class.isInstance( query );
 	}
 
 	@Override
 	protected void applyAliasSpecificLockMode(String alias, LockMode lockMode) {
 		( (org.hibernate.impl.QueryImpl) query ).getLockOptions().setAliasSpecificLockMode( alias, lockMode );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@SuppressWarnings({ "unchecked", "RedundantCast" })
 	public List<X> getResultList() {
 		try {
 			return query.list();
 		}
 		catch (QueryExecutionRequestException he) {
 			throw new IllegalStateException(he);
 		}
 		catch( TypeMismatchException e ) {
 			throw new IllegalArgumentException(e);
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@SuppressWarnings({ "unchecked", "RedundantCast" })
 	public X getSingleResult() {
 		try {
 			boolean mucked = false;
 			// IMPL NOTE : the mucking with max results here is attempting to help the user from shooting themselves
 			//		in the foot in the case where they have a large query by limiting the query results to 2 max
 			//    SQLQuery cannot be safely paginated, leaving the user's choice here.
 			if ( getSpecifiedMaxResults() != 1 &&
 					! ( SQLQuery.class.isAssignableFrom( query.getClass() ) ) ) {
 				mucked = true;
 				query.setMaxResults( 2 ); //avoid OOME if the list is huge
 			}
 			List<X> result = query.list();
 			if ( mucked ) {
 				query.setMaxResults( getSpecifiedMaxResults() );
 			}
 
 			if ( result.size() == 0 ) {
 				NoResultException nre = new NoResultException( "No entity found for query" );
 				getEntityManager().handlePersistenceException( nre );
 				throw nre;
 			}
 			else if ( result.size() > 1 ) {
 				Set<X> uniqueResult = new HashSet<X>(result);
 				if ( uniqueResult.size() > 1 ) {
 					NonUniqueResultException nure = new NonUniqueResultException( "result returns more than one elements" );
 					getEntityManager().handlePersistenceException( nure );
 					throw nure;
 				}
 				else {
 					return uniqueResult.iterator().next();
 				}
 
 			}
 			else {
 				return result.get( 0 );
 			}
 		}
 		catch (QueryExecutionRequestException he) {
 			throw new IllegalStateException(he);
 		}
 		catch( TypeMismatchException e ) {
 			throw new IllegalArgumentException(e);
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	public <T> TypedQuery<X> setParameter(Parameter<T> param, T value) {
 		if ( ! parameters.contains( param ) ) {
 			throw new IllegalArgumentException( "Specified parameter was not found in query" );
 		}
 		if ( param.getName() != null ) {
 			// a named param, for not delegate out.  Eventually delegate *into* this method...
 			setParameter( param.getName(), value );
 		}
 		else {
 			setParameter( param.getPosition(), value );
 		}
 		return this;
 	}
 
 	public TypedQuery<X> setParameter(Parameter<Date> param, Date value, TemporalType temporalType) {
 		if ( ! parameters.contains( param ) ) {
 			throw new IllegalArgumentException( "Specified parameter was not found in query" );
 		}
 		if ( param.getName() != null ) {
 			// a named param, for not delegate out.  Eventually delegate *into* this method...
 			setParameter( param.getName(), value, temporalType );
 		}
 		else {
 			setParameter( param.getPosition(), value, temporalType );
 		}
 		return this;
 	}
 
 	public TypedQuery<X> setParameter(Parameter<Calendar> param, Calendar value, TemporalType temporalType) {
 		if ( ! parameters.contains( param ) ) {
 			throw new IllegalArgumentException( "Specified parameter was not found in query" );
 		}
 		if ( param.getName() != null ) {
 			// a named param, for not delegate out.  Eventually delegate *into* this method...
 			setParameter( param.getName(), value, temporalType );
 		}
 		else {
 			setParameter( param.getPosition(), value, temporalType );
 		}
 		return this;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public TypedQuery<X> setParameter(String name, Object value) {
 		try {
 			if ( value instanceof Collection ) {
 				query.setParameterList( name, (Collection) value );
 			}
 			else {
 				query.setParameter( name, value );
 			}
 			registerParameterBinding( getParameter( name ), value );
 			return this;
 		}
 		catch (QueryParameterException e) {
 			throw new IllegalArgumentException( e );
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public TypedQuery<X> setParameter(String name, Date value, TemporalType temporalType) {
 		try {
 			if ( temporalType == DATE ) {
 				query.setDate( name, value );
 			}
 			else if ( temporalType == TIME ) {
 				query.setTime( name, value );
 			}
 			else if ( temporalType == TIMESTAMP ) {
 				query.setTimestamp( name, value );
 			}
 			registerParameterBinding( getParameter( name ), value );
 			return this;
 		}
 		catch (QueryParameterException e) {
 			throw new IllegalArgumentException( e );
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public TypedQuery<X> setParameter(String name, Calendar value, TemporalType temporalType) {
 		try {
 			if ( temporalType == DATE ) {
 				query.setCalendarDate( name, value );
 			}
 			else if ( temporalType == TIME ) {
 				throw new IllegalArgumentException( "not yet implemented" );
 			}
 			else if ( temporalType == TIMESTAMP ) {
 				query.setCalendar( name, value );
 			}
 			registerParameterBinding( getParameter(name), value );
 			return this;
 		}
 		catch (QueryParameterException e) {
 			throw new IllegalArgumentException( e );
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public TypedQuery<X> setParameter(int position, Object value) {
 		try {
 			if ( isJpaPositionalParameter( position ) ) {
 				this.setParameter( Integer.toString( position ), value );
 			}
 			else {
 				query.setParameter( position - 1, value );
 				registerParameterBinding( getParameter( position ), value );
 			}
 			return this;
 		}
 		catch (QueryParameterException e) {
 			throw new IllegalArgumentException( e );
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	private boolean isJpaPositionalParameter(int position) {
 		return jpaPositionalIndices != null && jpaPositionalIndices.contains( position );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public TypedQuery<X> setParameter(int position, Date value, TemporalType temporalType) {
 		try {
 			if ( isJpaPositionalParameter( position ) ) {
 				String name = Integer.toString( position );
 				this.setParameter( name, value, temporalType );
 			}
 			else {
 				if ( temporalType == DATE ) {
 					query.setDate( position - 1, value );
 				}
 				else if ( temporalType == TIME ) {
 					query.setTime( position - 1, value );
 				}
 				else if ( temporalType == TIMESTAMP ) {
 					query.setTimestamp( position - 1, value );
 				}
 				registerParameterBinding( getParameter( position ), value );
 			}
 			return this;
 		}
 		catch (QueryParameterException e) {
 			throw new IllegalArgumentException( e );
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public TypedQuery<X> setParameter(int position, Calendar value, TemporalType temporalType) {
 		try {
 			if ( isJpaPositionalParameter( position ) ) {
 				String name = Integer.toString( position );
 				this.setParameter( name, value, temporalType );
 			}
 			else {
 				if ( temporalType == DATE ) {
 					query.setCalendarDate( position - 1, value );
 				}
 				else if ( temporalType == TIME ) {
 					throw new IllegalArgumentException( "not yet implemented" );
 				}
 				else if ( temporalType == TIMESTAMP ) {
 					query.setCalendar( position - 1, value );
 				}
 				registerParameterBinding( getParameter( position ), value );
 			}
 			return this;
 		}
 		catch (QueryParameterException e) {
 			throw new IllegalArgumentException( e );
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Set<Parameter<?>> getParameters() {
 		return parameters;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Parameter<?> getParameter(String name) {
 		if ( name == null ) {
 			throw new IllegalArgumentException( "Name of parameter to locate cannot be null" );
 		}
 		for ( Parameter parameter : parameters ) {
 			if ( name.equals( parameter.getName() ) ) {
 				return parameter;
 			}
 		}
 		throw new IllegalArgumentException( "Unable to locate parameter named [" + name + "]" );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Parameter<?> getParameter(int position) {
 		if ( isJpaPositionalParameter( position ) ) {
 			return getParameter( Integer.toString( position ) );
 		}
 		else {
 			for ( Parameter parameter : parameters ) {
 				if ( parameter.getPosition() != null && position == parameter.getPosition() ) {
 					return parameter;
 				}
 			}
 			throw new IllegalArgumentException( "Unable to locate parameter with position [" + position + "]" );
 		}
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public <T> Parameter<T> getParameter(String name, Class<T> type) {
 		Parameter param = getParameter( name );
 		if ( param.getParameterType() != null ) {
 			// we were able to determine the expected type during analysis, so validate it here
 			throw new IllegalArgumentException(
 					"Parameter type [" + param.getParameterType().getName() +
 							"] is not assignment compatible with requested type [" +
 							type.getName() + "]"
 			);
 		}
 		return param;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public <T> Parameter<T> getParameter(int position, Class<T> type) {
 		Parameter param = getParameter( position );
 		if ( param.getParameterType() != null ) {
 			// we were able to determine the expected type during analysis, so validate it here
 			throw new IllegalArgumentException(
 					"Parameter type [" + param.getParameterType().getName() +
 							"] is not assignment compatible with requested type [" +
 							type.getName() + "]"
 			);
 		}
 		return param;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public <T> T unwrap(Class<T> tClass) {
 		if ( org.hibernate.Query.class.isAssignableFrom( tClass ) ) {
 			return (T) query;
 		}
 		else {
 			try {
 				return (T) this;
 			}
 			catch ( ClassCastException cce ) {
 				PersistenceException pe = new PersistenceException(
 						"Unsupported unwrap target type [" + tClass.getName() + "]"
 				);
 				//It's probably against the spec to not mark the tx for rollback but it will be easier for people
 				//getEntityManager().handlePersistenceException( pe );
 				throw pe;
 			}
 		}
 	}
 
 	private javax.persistence.LockModeType jpaLockMode = javax.persistence.LockModeType.NONE;
 
 	@Override
     @SuppressWarnings({ "unchecked" })
 	public TypedQuery<X> setLockMode(javax.persistence.LockModeType lockModeType) {
 		if (! getEntityManager().isTransactionInProgress()) {
 			throw new TransactionRequiredException( "no transaction is in progress" );
 		}
 		if ( ! canApplyLockModes() ) {
 			throw new IllegalStateException( "Not a JPAQL/Criteria query" );
 		}
 		this.jpaLockMode = lockModeType;
 		( (org.hibernate.impl.QueryImpl) query ).getLockOptions().setLockMode(
 				LockModeTypeHelper.getLockMode( lockModeType )
 		);
 		return this;
 	}
 
 	@Override
     public javax.persistence.LockModeType getLockMode() {
 		return jpaLockMode;
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/connection/InjectedDataSourceConnectionProvider.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/connection/InjectedDataSourceConnectionProvider.java
index 4397e72cd0..99e6dca9fd 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/connection/InjectedDataSourceConnectionProvider.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/connection/InjectedDataSourceConnectionProvider.java
@@ -1,69 +1,69 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.connection;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Properties;
 import javax.sql.DataSource;
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Environment;
-import org.hibernate.ejb.EntityManagerLogger;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.service.jdbc.connections.internal.DatasourceConnectionProviderImpl;
 import org.jboss.logging.Logger;
 
 /**
  * A specialization of {@link DatasourceConnectionProviderImpl} which uses the {@link DataSource} specified vi
  * {@link #setDataSource} rather than locating it from JNDI.
  * <p/>
  * NOTE : {@link #setDataSource} must be called prior to {@link #configure}.
  * <p/>
  * TODO : could not find where #setDataSource is actually called.  Can't this just be passed in to #configure???
  *
  * @author Emmanuel Bernard
  */
 public class InjectedDataSourceConnectionProvider extends DatasourceConnectionProviderImpl {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            InjectedDataSourceConnectionProvider.class.getName());
 
 	private String user;
 	private String pass;
 
 	@Override
     public void setDataSource(DataSource ds) {
 		super.setDataSource( ds );
 	}
 
 	public void configure(Properties props) throws HibernateException {
 		user = props.getProperty( Environment.USER );
 		pass = props.getProperty( Environment.PASS );
 
         if (getDataSource() == null) throw new HibernateException("No datasource provided");
         LOG.usingProvidedDataSource();
 	}
 
 	@Override
 	public Connection getConnection() throws SQLException {
         if (user != null || pass != null) return getDataSource().getConnection(user, pass);
         return getDataSource().getConnection();
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/criteria/CriteriaQueryCompiler.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/criteria/CriteriaQueryCompiler.java
index 676f72069e..72f732a356 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/criteria/CriteriaQueryCompiler.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/criteria/CriteriaQueryCompiler.java
@@ -1,467 +1,468 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.criteria;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.FlushModeType;
 import javax.persistence.LockModeType;
 import javax.persistence.Parameter;
 import javax.persistence.TemporalType;
 import javax.persistence.TypedQuery;
 import javax.persistence.criteria.CriteriaQuery;
 import javax.persistence.criteria.ParameterExpression;
-import org.hibernate.ejb.EntityManagerLogger;
+
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.ejb.HibernateEntityManagerImplementor;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Compiles a JPA criteria query into an executable {@link TypedQuery}.  Its single contract is the {@link #compile}
  * method.
  * <p/>
  * NOTE : This is a temporary implementation which simply translates the criteria query into a JPAQL query string.  A
  * better, long-term solution is being implemented as part of refactoring the JPAQL/HQL translator.
  *
  * @author Steve Ebersole
  */
 public class CriteriaQueryCompiler implements Serializable {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            CriteriaQueryCompiler.class.getName());
 
 	/**
 	 * Used to describe implicit (not defined in criteria query) parameters.
 	 */
 	public static interface ImplicitParameterBinding {
 		/**
 		 * Retrieve the generated name of the implicit parameter.
 		 *
 		 * @return The parameter name.
 		 */
 		public String getParameterName();
 
 		/**
 		 * Get the java type of the "thing" that led to the implicit parameter.  Used from
 		 * {@link org.hibernate.ejb.HibernateEntityManagerImplementor.Options#getNamedParameterExplicitTypes()}
 		 * in determining "guessed type" overriding.
 		 *
 		 * @return The java type
 		 */
 		public Class getJavaType();
 
 		/**
 		 * Bind the implicit parameter's value to the JPA query.
 		 *
 		 * @param typedQuery The JPA query.
 		 */
 		public void bind(TypedQuery typedQuery);
 	}
 
 	/**
 	 * Used to provide a context and services to the rendering.
 	 */
 	public static interface RenderingContext {
 		/**
 		 * Generate a correlation name.
 		 *
 		 * @return The generated correlation name
 		 */
 		public String generateAlias();
 
 		/**
 		 * Register parameters explicitly encountered in the criteria query.
 		 *
 		 * @param criteriaQueryParameter The parameter expression
 		 *
 		 * @return The JPA-QL parameter name
 		 */
 		public String registerExplicitParameter(ParameterExpression<?> criteriaQueryParameter);
 
 		/**
 		 * Register a parameter that was not part of the criteria query (at least not as a parameter).
 		 *
 		 * @param literal The literal value
 		 * @param javaType The java type as whcih to handle the literal value.
 		 *
 		 * @return The JPA-QL parameter name
 		 */
 		public String registerLiteralParameterBinding(Object literal, Class javaType);
 
 		/**
 		 * Given a java type, determine the proper cast type name.
 		 *
 		 * @param javaType The java type.
 		 *
 		 * @return The cast type name.
 		 */
 		public String getCastType(Class javaType);
 	}
 
 	public static interface RenderedCriteriaQuery {
 		public String getQueryString();
 		public List<ValueHandlerFactory.ValueHandler> getValueHandlers();
 		public HibernateEntityManagerImplementor.Options.ResultMetadataValidator getResultMetadataValidator();
 	}
 
 	private final HibernateEntityManagerImplementor entityManager;
 
 	public CriteriaQueryCompiler(HibernateEntityManagerImplementor entityManager) {
 		this.entityManager = entityManager;
 	}
 
 	public <T> TypedQuery<T> compile(CriteriaQuery<T> criteriaQuery) {
 		CriteriaQueryImpl<T> criteriaQueryImpl = ( CriteriaQueryImpl<T> ) criteriaQuery;
 		criteriaQueryImpl.validate();
 
 		final Map<ParameterExpression<?>,String> explicitParameterMapping = new HashMap<ParameterExpression<?>,String>();
 		final Map<String,ParameterExpression<?>> explicitParameterNameMapping = new HashMap<String,ParameterExpression<?>>();
 		final List<ImplicitParameterBinding> implicitParameterBindings = new ArrayList<ImplicitParameterBinding>();
 		final Map<String,Class> implicitParameterTypes = new HashMap<String, Class>();
 
 		RenderingContext renderingContext = new RenderingContext() {
 			private int aliasCount = 0;
 			private int explicitParameterCount = 0;
 
 			public String generateAlias() {
 				return "generatedAlias" + aliasCount++;
 			}
 
 			public String generateParameterName() {
 				return "param" + explicitParameterCount++;
 			}
 
 			public String registerExplicitParameter(ParameterExpression<?> criteriaQueryParameter) {
 				final String jpaqlParameterName;
 				if ( explicitParameterMapping.containsKey( criteriaQueryParameter ) ) {
 					jpaqlParameterName = explicitParameterMapping.get( criteriaQueryParameter );
 				}
 				else {
 					jpaqlParameterName = generateParameterName();
 					explicitParameterMapping.put( criteriaQueryParameter, jpaqlParameterName );
 				}
 				if ( StringHelper.isNotEmpty( criteriaQueryParameter.getName() ) ) {
 					explicitParameterNameMapping.put(
 							criteriaQueryParameter.getName(),
 							criteriaQueryParameter
 					);
 				}
 				return jpaqlParameterName;
 			}
 
 			public String registerLiteralParameterBinding(final Object literal, final Class javaType) {
 				final String parameterName = generateParameterName();
 				final ImplicitParameterBinding binding = new CriteriaQueryCompiler.ImplicitParameterBinding() {
 					public String getParameterName() {
 						return parameterName;
 					}
 
 					public Class getJavaType() {
 						return javaType;
 					}
 
 					public void bind(TypedQuery typedQuery) {
 						typedQuery.setParameter( parameterName, literal );
 					}
 				};
 
 				implicitParameterBindings.add( binding );
 				implicitParameterTypes.put( parameterName, javaType );
 				return parameterName;
 			}
 
 			public String getCastType(Class javaType) {
 				SessionFactoryImplementor factory =
 						( SessionFactoryImplementor ) entityManager.getFactory().getSessionFactory();
 				Type hibernateType = factory.getTypeResolver().heuristicType( javaType.getName() );
 				if ( hibernateType == null ) {
 					throw new IllegalArgumentException(
 							"Could not convert java type [" + javaType.getName() + "] to Hibernate type"
 					);
 				}
 				int[] sqlTypeCodes = hibernateType.sqlTypes( factory );
 				if ( sqlTypeCodes.length != 1 ) {
 					throw new IllegalArgumentException(
 							"Invalid Hibernate Type [" + hibernateType.getName() +
 									"] for cast : more than one column spanned"
 					);
 				}
 				return factory.getDialect().getCastTypeName( sqlTypeCodes[0] );
 			}
 		};
 
 		final RenderedCriteriaQuery renderedCriteriaQuery = criteriaQueryImpl.render( renderingContext );
 
         LOG.debugf("Rendered criteria query -> %s", renderedCriteriaQuery.getQueryString());
 
 		TypedQuery<T> jpaqlQuery = entityManager.createQuery(
 				renderedCriteriaQuery.getQueryString(),
 				criteriaQuery.getResultType(),
 				criteriaQuery.getSelection(),
 				new HibernateEntityManagerImplementor.Options() {
 					public List<ValueHandlerFactory.ValueHandler> getValueHandlers() {
 						return renderedCriteriaQuery.getValueHandlers();
 					}
 
 					public Map<String, Class> getNamedParameterExplicitTypes() {
 						return implicitParameterTypes;
 					}
 
 					public ResultMetadataValidator getResultMetadataValidator() {
 						return renderedCriteriaQuery.getResultMetadataValidator();
 					}
 				}
 		);
 
 		for ( ImplicitParameterBinding implicitParameterBinding : implicitParameterBindings ) {
 			implicitParameterBinding.bind( jpaqlQuery );
 		}
 
 		return wrap( jpaqlQuery, explicitParameterMapping, explicitParameterNameMapping );
 	}
 
 	private <X> TypedQuery<X> wrap(
 			final TypedQuery<X> jpaqlQuery,
 			final Map<ParameterExpression<?>, String> explicitParameterMapping,
 			final Map<String, ParameterExpression<?>> explicitParameterNameMapping) {
 		return new TypedQuery<X>() {
 
 			public List<X> getResultList() {
 				return jpaqlQuery.getResultList();
 			}
 
 			public X getSingleResult() {
 				return jpaqlQuery.getSingleResult();
 			}
 
 			public int getMaxResults() {
 				return jpaqlQuery.getMaxResults();
 			}
 
 			public TypedQuery<X> setMaxResults(int i) {
 				jpaqlQuery.setMaxResults( i );
 				return this;
 			}
 
 			public int getFirstResult() {
 				return jpaqlQuery.getFirstResult();
 			}
 
 			public TypedQuery<X> setFirstResult(int i) {
 				jpaqlQuery.setFirstResult( i );
 				return this;
 			}
 
 			public Map<String, Object> getHints() {
 				return jpaqlQuery.getHints();
 			}
 
 			public TypedQuery<X> setHint(String name, Object value) {
 				jpaqlQuery.setHint( name, value);
 				return this;
 			}
 
 			public FlushModeType getFlushMode() {
 				return jpaqlQuery.getFlushMode();
 			}
 
 			public TypedQuery<X> setFlushMode(FlushModeType flushModeType) {
 				jpaqlQuery.setFlushMode( flushModeType );
 				return this;
 			}
 
 			public LockModeType getLockMode() {
 				return jpaqlQuery.getLockMode();
 			}
 
 			public TypedQuery<X> setLockMode(LockModeType lockModeType) {
 				jpaqlQuery.setLockMode( lockModeType );
 				return this;
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public Set getParameters() {
 				return explicitParameterMapping.keySet();
 			}
 
 			public boolean isBound(Parameter<?> param) {
 				return jpaqlQuery.isBound( param );
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public <T> T getParameterValue(Parameter<T> param) {
 				return ( T ) jpaqlQuery.getParameterValue( mapToNamedParameter( param ) );
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public <T> TypedQuery<X> setParameter(Parameter<T> param, T t) {
 				jpaqlQuery.setParameter( mapToNamedParameter( param ), t );
 				return this;
 			}
 
 			@SuppressWarnings({ "RedundantCast" })
 			private Parameter mapToNamedParameter(Parameter criteriaParameter) {
 				return jpaqlQuery.getParameter(
 						explicitParameterMapping.get( criteriaParameter )
 				);
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public TypedQuery<X> setParameter(Parameter<Calendar> param, Calendar calendar, TemporalType temporalType) {
 				jpaqlQuery.setParameter( mapToNamedParameter( param ), calendar, temporalType );
 				return this;
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public TypedQuery<X> setParameter(Parameter<Date> param, Date date, TemporalType temporalType) {
 				jpaqlQuery.setParameter( mapToNamedParameter( param ), date, temporalType );
 				return this;
 			}
 
 			public <T> T unwrap(Class<T> cls) {
 				return jpaqlQuery.unwrap( cls );
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public Object getParameterValue(String name) {
 				return getParameterValue( resolveExplicitCriteriaParameterName( name ) );
 			}
 
 			private Parameter resolveExplicitCriteriaParameterName(String name) {
 				Parameter parameter = explicitParameterNameMapping.get( name );
 				if ( parameter == null ) {
 					throw new IllegalArgumentException( "Named parameter [" + name + "] not encountered" );
 				}
 				return parameter;
 			}
 
 			public Parameter<?> getParameter(String name) {
 				return mapToNamedParameter( resolveExplicitCriteriaParameterName( name ) );
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public <T> Parameter<T> getParameter(String name, Class<T> type) {
 				Parameter parameter = resolveExplicitCriteriaParameterName( name );
 				if ( type.isAssignableFrom( parameter.getParameterType() ) ) {
 					return parameter;
 				}
 				throw new IllegalArgumentException(
 						"Named parameter [" + name + "] type is not assignanle to request type ["
 								+ type.getName() + "]"
 				);
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public TypedQuery<X> setParameter(String name, Object value) {
 				setParameter(
 						resolveExplicitCriteriaParameterName( name, value ),
 						value
 				);
 				return this;
 			}
 
 			private Parameter resolveExplicitCriteriaParameterName(String name, Object value) {
 				Parameter parameter = resolveExplicitCriteriaParameterName( name );
 				// todo : is null valid?
 				if ( value != null ) {
 					if ( ! parameter.getParameterType().isInstance( value ) ) {
 						throw new IllegalArgumentException(
 								"Named parameter [" + name + "] type mismatch; expecting ["
 										+ parameter.getParameterType().getName() + "], found ["
 										+ value.getClass().getName() + "]"
 						);
 					}
 				}
 				return parameter;
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public TypedQuery<X> setParameter(String name, Calendar calendar, TemporalType temporalType) {
 				Parameter parameter = resolveExplicitCriteriaParameterName( name );
 				if ( ! Calendar.class.isAssignableFrom( parameter.getParameterType() ) ) {
 					throw new IllegalArgumentException(
 							"Named parameter [" + name + "] type mismatch; expecting ["
 									+ Calendar.class.getName() + "], found ["
 									+ parameter.getParameterType().getName() + "]"
 					);
 				}
 				setParameter( parameter, calendar, temporalType );
 				return this;
 			}
 
 			@SuppressWarnings({ "unchecked" })
 			public TypedQuery<X> setParameter(String name, Date date, TemporalType temporalType) {
 				Parameter parameter = resolveExplicitCriteriaParameterName( name );
 				if ( ! Date.class.isAssignableFrom( parameter.getParameterType() ) ) {
 					throw new IllegalArgumentException(
 							"Named parameter [" + name + "] type mismatch; expecting ["
 									+ Date.class.getName() + "], found ["
 									+ parameter.getParameterType().getName() + "]"
 					);
 				}
 				setParameter( parameter, date, temporalType );
 				return this;
 			}
 
 
 			// unsupported stuff ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 			public int executeUpdate() {
 				throw new IllegalArgumentException( "Criteria queries do not support update queries" );
 			}
 
 			public TypedQuery<X> setParameter(int i, Object o) {
 				throw new IllegalArgumentException( "Criteria queries do not support positioned parameters" );
 			}
 
 			public TypedQuery<X> setParameter(int i, Calendar calendar, TemporalType temporalType) {
 				throw new IllegalArgumentException( "Criteria queries do not support positioned parameters" );
 			}
 
 			public TypedQuery<X> setParameter(int i, Date date, TemporalType temporalType) {
 				throw new IllegalArgumentException( "Criteria queries do not support positioned parameters" );
 			}
 
 			public Object getParameterValue(int position) {
 				throw new IllegalArgumentException( "Criteria queries do not support positioned parameters" );
 			}
 
 			public Parameter<?> getParameter(int position) {
 				throw new IllegalArgumentException( "Criteria queries do not support positioned parameters" );
 			}
 
 			public <T> Parameter<T> getParameter(int position, Class<T> type) {
 				throw new IllegalArgumentException( "Criteria queries do not support positioned parameters" );
 			}
 		};
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/event/CallbackResolver.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/event/CallbackResolver.java
index bce46012be..9119628e6a 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/event/CallbackResolver.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/event/CallbackResolver.java
@@ -1,230 +1,230 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.event;
 
 import javax.persistence.Entity;
 import javax.persistence.EntityListeners;
 import javax.persistence.ExcludeDefaultListeners;
 import javax.persistence.ExcludeSuperclassListeners;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.PersistenceException;
 import java.lang.annotation.Annotation;
 import java.lang.annotation.ElementType;
 import java.lang.annotation.Target;
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.List;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XMethod;
-import org.hibernate.ejb.EntityManagerLogger;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 
 /**
  * @author <a href="mailto:kabir.khan@jboss.org">Kabir Khan</a>
  */
 public final class CallbackResolver {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            CallbackResolver.class.getName());
 
 	private static boolean useAnnotationAnnotatedByListener;
 
 	static {
 		//check whether reading annotations of annotations is useful or not
 		useAnnotationAnnotatedByListener = false;
 		Target target = EntityListeners.class.getAnnotation( Target.class );
 		if ( target != null ) {
 			for ( ElementType type : target.value() ) {
 				if ( type.equals( ElementType.ANNOTATION_TYPE ) ) useAnnotationAnnotatedByListener = true;
 			}
 		}
 	}
 
 	private CallbackResolver() {
 	}
 
 	public static Callback[] resolveCallback(XClass beanClass, Class annotation, ReflectionManager reflectionManager) {
 		List<Callback> callbacks = new ArrayList<Callback>();
 		List<String> callbacksMethodNames = new ArrayList<String>(); //used to track overriden methods
 		List<Class> orderedListeners = new ArrayList<Class>();
 		XClass currentClazz = beanClass;
 		boolean stopListeners = false;
 		boolean stopDefaultListeners = false;
 		do {
 			Callback callback = null;
 			List<XMethod> methods = currentClazz.getDeclaredMethods();
 			final int size = methods.size();
 			for ( int i = 0; i < size ; i++ ) {
 				final XMethod xMethod = methods.get( i );
 				if ( xMethod.isAnnotationPresent( annotation ) ) {
 					Method method = reflectionManager.toMethod( xMethod );
 					final String methodName = method.getName();
 					if ( ! callbacksMethodNames.contains( methodName ) ) {
 						//overriden method, remove the superclass overriden method
 						if ( callback == null ) {
 							callback = new BeanCallback( method );
 							Class returnType = method.getReturnType();
 							Class[] args = method.getParameterTypes();
 							if ( returnType != Void.TYPE || args.length != 0 ) {
 								throw new RuntimeException(
 										"Callback methods annotated on the bean class must return void and take no arguments: " + annotation
 												.getName() + " - " + xMethod
 								);
 							}
                             if (!method.isAccessible()) method.setAccessible(true);
                             LOG.debugf("Adding %s as %s callback for entity %s",
                                        methodName,
                                        annotation.getSimpleName(),
                                        beanClass.getName());
 							callbacks.add( 0, callback ); //superclass first
 							callbacksMethodNames.add( 0, methodName );
 						}
 						else {
 							throw new PersistenceException(
 									"You can only annotate one callback method with "
 											+ annotation.getName() + " in bean class: " + beanClass.getName()
 							);
 						}
 					}
 				}
 			}
 			if ( !stopListeners ) {
 				getListeners( currentClazz, orderedListeners );
 				stopListeners = currentClazz.isAnnotationPresent( ExcludeSuperclassListeners.class );
 				stopDefaultListeners = currentClazz.isAnnotationPresent( ExcludeDefaultListeners.class );
 			}
 
 			do {
 				currentClazz = currentClazz.getSuperclass();
 			}
 			while ( currentClazz != null
 					&& ! ( currentClazz.isAnnotationPresent( Entity.class )
 					|| currentClazz.isAnnotationPresent( MappedSuperclass.class ) )
 					);
 		}
 		while ( currentClazz != null );
 
 		//handle default listeners
 		if ( ! stopDefaultListeners ) {
 			List<Class> defaultListeners = (List<Class>) reflectionManager.getDefaults().get( EntityListeners.class );
 
 			if ( defaultListeners != null ) {
 				int defaultListenerSize = defaultListeners.size();
 				for ( int i = defaultListenerSize - 1; i >= 0 ; i-- ) {
 					orderedListeners.add( defaultListeners.get( i ) );
 				}
 			}
 		}
 
 		for ( Class listener : orderedListeners ) {
 			Callback callback = null;
 			if ( listener != null ) {
 				XClass xListener = reflectionManager.toXClass( listener );
 				callbacksMethodNames = new ArrayList<String>();
 				do {
 					List<XMethod> methods = xListener.getDeclaredMethods();
 					final int size = methods.size();
 					for ( int i = 0; i < size ; i++ ) {
 						final XMethod xMethod = methods.get( i );
 						if ( xMethod.isAnnotationPresent( annotation ) ) {
 							final Method method = reflectionManager.toMethod( xMethod );
 							final String methodName = method.getName();
 							if ( ! callbacksMethodNames.contains( methodName ) ) {
 								//overriden method, remove the superclass overriden method
 								if ( callback == null ) {
 									try {
 										callback = new ListenerCallback( method, listener.newInstance() );
 									}
 									catch (IllegalAccessException e) {
 										throw new PersistenceException(
 												"Unable to create instance of " + listener.getName()
 														+ " as a listener of beanClass", e
 										);
 									}
 									catch (InstantiationException e) {
 										throw new PersistenceException(
 												"Unable to create instance of " + listener.getName()
 														+ " as a listener of beanClass", e
 										);
 									}
 									Class returnType = method.getReturnType();
 									Class[] args = method.getParameterTypes();
 									if ( returnType != Void.TYPE || args.length != 1 ) {
 										throw new PersistenceException(
 												"Callback methods annotated in a listener bean class must return void and take one argument: " + annotation
 														.getName() + " - " + method
 										);
 									}
                                     if (!method.isAccessible()) method.setAccessible(true);
                                     LOG.debugf("Adding %s as %s callback for entity %s",
                                                methodName,
                                                annotation.getSimpleName(),
                                                beanClass.getName());
 									callbacks.add( 0, callback ); // listeners first
 								}
 								else {
 									throw new PersistenceException(
 											"You can only annotate one callback method with "
 													+ annotation.getName() + " in bean class: " + beanClass.getName() + " and callback listener: "
 													+ listener.getName()
 									);
 								}
 							}
 						}
 					}
 					xListener = null;  //xListener.getSuperclass();
 				}
 				while ( xListener != null );
 			}
 		}
 		return callbacks.toArray( new Callback[ callbacks.size() ] );
 	}
 
 	private static void getListeners(XClass currentClazz, List<Class> orderedListeners) {
 		EntityListeners entityListeners = currentClazz.getAnnotation( EntityListeners.class );
 		if ( entityListeners != null ) {
 			Class[] classes = entityListeners.value();
 			int size = classes.length;
 			for ( int index = size - 1; index >= 0 ; index-- ) {
 				orderedListeners.add( classes[index] );
 			}
 		}
 		if ( useAnnotationAnnotatedByListener ) {
 			Annotation[] annotations = currentClazz.getAnnotations();
 			for ( Annotation annot : annotations ) {
 				entityListeners = annot.getClass().getAnnotation( EntityListeners.class );
 				if ( entityListeners != null ) {
 					Class[] classes = entityListeners.value();
 					int size = classes.length;
 					for ( int index = size - 1; index >= 0 ; index-- ) {
 						orderedListeners.add( classes[index] );
 					}
 				}
 			}
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerLogger.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/internal/EntityManagerMessageLogger.java
similarity index 90%
rename from hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerLogger.java
rename to hibernate-entitymanager/src/main/java/org/hibernate/ejb/internal/EntityManagerMessageLogger.java
index 2f8a2d200a..3f27c0cbc3 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerLogger.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/internal/EntityManagerMessageLogger.java
@@ -1,98 +1,101 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.ejb;
+package org.hibernate.ejb.internal;
 
 import static org.jboss.logging.Logger.Level.ERROR;
 import static org.jboss.logging.Logger.Level.INFO;
 import static org.jboss.logging.Logger.Level.WARN;
 import java.net.URISyntaxException;
 import java.net.URL;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.Cause;
 import org.jboss.logging.LogMessage;
 import org.jboss.logging.Message;
 import org.jboss.logging.MessageLogger;
 
 /**
- * Defines internationalized messages for this hibernate-entitymanager, with IDs ranging from 15001 to 20000 inclusively. New
- * messages must be added after the last message defined to ensure message codes are unique.
+ * The jboss-logging {@link MessageLogger} for the hibernate-entitymanager module.  It reserves message ids ranging from
+ * 15001 to 20000 inclusively.
+ * <p/>
+ * New messages must be added after the last message defined to ensure message codes are unique.
  */
 @MessageLogger( projectCode = "HHH" )
-public interface EntityManagerLogger extends HibernateLogger {
+public interface EntityManagerMessageLogger extends CoreMessageLogger {
 
     @LogMessage( level = INFO )
     @Message( value = "Bound Ejb3Configuration to JNDI name: %s", id = 15001 )
     void boundEjb3ConfigurationToJndiName( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "Ejb3Configuration name: %s", id = 15002 )
     void ejb3ConfigurationName( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "An Ejb3Configuration was renamed from name: %s", id = 15003 )
     void ejb3ConfigurationRenamedFromName( String name );
 
     @LogMessage( level = INFO )
     @Message( value = "An Ejb3Configuration was unbound from name: %s", id = 15004 )
     void ejb3ConfigurationUnboundFromName( String name );
 
     @LogMessage( level = WARN )
     @Message( value = "Exploded jar file does not exist (ignored): %s", id = 15005 )
     void explodedJarDoesNotExist( URL jarUrl );
 
     @LogMessage( level = WARN )
     @Message( value = "Exploded jar file not a directory (ignored): %s", id = 15006 )
     void explodedJarNotDirectory( URL jarUrl );
 
     @LogMessage( level = ERROR )
     @Message( value = "Illegal argument on static metamodel field injection : %s#%s; expected type :  %s; encountered type : %s", id = 15007 )
     void illegalArgumentOnStaticMetamodelFieldInjection( String name,
                                                          String name2,
                                                          String name3,
                                                          String name4 );
 
     @LogMessage( level = ERROR )
     @Message( value = "Malformed URL: %s", id = 15008 )
     void malformedUrl( URL jarUrl,
                        @Cause URISyntaxException e );
 
     @LogMessage( level = WARN )
     @Message( value = "Malformed URL: %s", id = 15009 )
     void malformedUrlWarning( URL jarUrl,
                               @Cause URISyntaxException e );
 
     @LogMessage( level = WARN )
     @Message( value = "Unable to find file (ignored): %s", id = 15010 )
     void unableToFindFile( URL jarUrl,
                            @Cause Exception e );
 
     @LogMessage( level = ERROR )
     @Message( value = "Unable to locate static metamodel field : %s#%s", id = 15011 )
     void unableToLocateStaticMetamodelField( String name,
                                              String name2 );
 
     @LogMessage( level = INFO )
     @Message( value = "Using provided datasource", id = 15012 )
     void usingProvidedDataSource();
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/metamodel/AttributeFactory.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/metamodel/AttributeFactory.java
index 8d1cd420bb..dab68f8021 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/metamodel/AttributeFactory.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/metamodel/AttributeFactory.java
@@ -1,956 +1,956 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.metamodel;
 import java.lang.reflect.Field;
 import java.lang.reflect.Member;
 import java.lang.reflect.Method;
 import java.lang.reflect.ParameterizedType;
 import java.lang.reflect.TypeVariable;
 import java.util.Iterator;
 import javax.persistence.ManyToMany;
 import javax.persistence.OneToOne;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.IdentifiableType;
 import javax.persistence.metamodel.PluralAttribute;
 import javax.persistence.metamodel.Type;
 import org.hibernate.EntityMode;
 import org.hibernate.annotations.common.AssertionFailure;
-import org.hibernate.ejb.EntityManagerLogger;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.Map;
 import org.hibernate.mapping.OneToMany;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Value;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.EmbeddedComponentType;
 import org.hibernate.type.EntityType;
 import org.jboss.logging.Logger;
 
 /**
  * A factory for building {@link Attribute} instances.  Exposes 3 main services for building<ol>
  * <li>{@link #buildAttribute normal attributes}</li>
  * <li>{@link #buildIdAttribute id attributes}</li>
  * <li>{@link #buildVersionAttribute version attributes}</li>
  * <ol>
  *
  * @author Steve Ebersole
  * @author Emmanuel Bernard
  */
 public class AttributeFactory {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            AttributeFactory.class.getName());
 
 	private final MetadataContext context;
 
 	public AttributeFactory(MetadataContext context) {
 		this.context = context;
 	}
 
 	/**
 	 * Build a normal attribute.
 	 *
 	 * @param ownerType The descriptor of the attribute owner (aka declarer).
 	 * @param property The Hibernate property descriptor for the attribute
 	 * @param <X> The type of the owner
 	 * @param <Y> The attribute type
 	 * @return The built attribute descriptor or null if the attribute is not part of the JPA 2 model (eg backrefs)
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public <X, Y> AttributeImplementor<X, Y> buildAttribute(AbstractManagedType<X> ownerType, Property property) {
 		if ( property.isSynthetic() ) {
 			// hide synthetic/virtual properties (fabricated by Hibernate) from the JPA metamodel.
             LOG.trace("Skipping synthetic property " + ownerType.getJavaType().getName() + "(" + property.getName() + ")");
 			return null;
 		}
         LOG.trace("Building attribute [" + ownerType.getJavaType().getName() + "." + property.getName() + "]");
 		final AttributeContext<X> attributeContext = wrap( ownerType, property );
 		final AttributeMetadata<X,Y> attributeMetadata =
 				determineAttributeMetadata( attributeContext, NORMAL_MEMBER_RESOLVER );
 
         if (attributeMetadata.isPlural()) return buildPluralAttribute((PluralAttributeMetadata)attributeMetadata);
         final SingularAttributeMetadata<X, Y> singularAttributeMetadata = (SingularAttributeMetadata<X, Y>)attributeMetadata;
         final Type<Y> metaModelType = getMetaModelType(singularAttributeMetadata.getValueContext());
         return new SingularAttributeImpl<X, Y>(attributeMetadata.getName(), attributeMetadata.getJavaType(), ownerType,
                                                attributeMetadata.getMember(), false, false, property.isOptional(), metaModelType,
                                                attributeMetadata.getPersistentAttributeType());
 	}
 
 	private <X> AttributeContext<X> wrap(final AbstractManagedType<X> ownerType, final Property property) {
 		return new AttributeContext<X>() {
 			public AbstractManagedType<X> getOwnerType() {
 				return ownerType;
 			}
 
 			public Property getPropertyMapping() {
 				return property;
 			}
 		};
 	}
 
 	/**
 	 * Build the identifier attribute descriptor
 	 *
 	 * @param ownerType The descriptor of the attribute owner (aka declarer).
 	 * @param property The Hibernate property descriptor for the identifier attribute
 	 * @param <X> The type of the owner
 	 * @param <Y> The attribute type
 	 * @return The built attribute descriptor
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public <X, Y> SingularAttributeImpl<X, Y> buildIdAttribute(AbstractIdentifiableType<X> ownerType, Property property) {
         LOG.trace("Building identifier attribute [" + ownerType.getJavaType().getName() + "." + property.getName() + "]");
 		final AttributeContext<X> attributeContext = wrap( ownerType, property );
 		final SingularAttributeMetadata<X,Y> attributeMetadata =
 				(SingularAttributeMetadata<X, Y>) determineAttributeMetadata( attributeContext, IDENTIFIER_MEMBER_RESOLVER );
 		final Type<Y> metaModelType = getMetaModelType( attributeMetadata.getValueContext() );
 		return new SingularAttributeImpl.Identifier(
 				property.getName(),
 				attributeMetadata.getJavaType(),
 				ownerType,
 				attributeMetadata.getMember(),
 				metaModelType,
 				attributeMetadata.getPersistentAttributeType()
 		);
 	}
 
 	/**
 	 * Build the version attribute descriptor
 	 *
 	 * @param ownerType The descriptor of the attribute owner (aka declarer).
 	 * @param property The Hibernate property descriptor for the version attribute
 	 * @param <X> The type of the owner
 	 * @param <Y> The attribute type
 	 * @return The built attribute descriptor
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public <X, Y> SingularAttributeImpl<X, Y> buildVersionAttribute(AbstractIdentifiableType<X> ownerType, Property property) {
         LOG.trace("Building version attribute [ownerType.getJavaType().getName()" + "." + "property.getName()]");
 		final AttributeContext<X> attributeContext = wrap( ownerType, property );
 		final SingularAttributeMetadata<X,Y> attributeMetadata =
 				(SingularAttributeMetadata<X, Y>) determineAttributeMetadata( attributeContext, VERSION_MEMBER_RESOLVER );
 		final Type<Y> metaModelType = getMetaModelType( attributeMetadata.getValueContext() );
 		return new SingularAttributeImpl.Version(
 				property.getName(),
 				attributeMetadata.getJavaType(),
 				ownerType,
 				attributeMetadata.getMember(),
 				metaModelType,
 				attributeMetadata.getPersistentAttributeType()
 		);
 	}
 
 	@SuppressWarnings( "unchecked" )
 	private <X, Y, E, K> AttributeImplementor<X, Y> buildPluralAttribute(PluralAttributeMetadata<X,Y,E> attributeMetadata) {
 		final Type<E> elementType = getMetaModelType( attributeMetadata.getElementValueContext() );
 		if ( java.util.Map.class.isAssignableFrom( attributeMetadata.getJavaType() ) ) {
 			final Type<K> keyType = getMetaModelType( attributeMetadata.getMapKeyValueContext() );
 			return PluralAttributeImpl.create( attributeMetadata.getOwnerType(), elementType, attributeMetadata.getJavaType(), keyType )
 					.member( attributeMetadata.getMember() )
 					.property( attributeMetadata.getPropertyMapping() )
 					.persistentAttributeType( attributeMetadata.getPersistentAttributeType() )
 					.build();
 		}
         return PluralAttributeImpl.create(attributeMetadata.getOwnerType(), elementType, attributeMetadata.getJavaType(), null).member(attributeMetadata.getMember()).property(attributeMetadata.getPropertyMapping()).persistentAttributeType(attributeMetadata.getPersistentAttributeType()).build();
 	}
 
 	@SuppressWarnings( "unchecked" )
 	private <Y> Type<Y> getMetaModelType(ValueContext typeContext) {
 		switch ( typeContext.getValueClassification() ) {
 			case BASIC: {
 				return new BasicTypeImpl<Y>(
 						typeContext.getBindableType(),
 						Type.PersistenceType.BASIC
 				);
 			}
 			case ENTITY: {
 				final org.hibernate.type.EntityType type = (EntityType) typeContext.getValue().getType();
 				return (Type<Y>) context.locateEntityType( type.getAssociatedEntityName() );
 			}
 			case EMBEDDABLE: {
 				final Component component = (Component) typeContext.getValue();
 				final EmbeddableTypeImpl<Y> embeddableType = new EmbeddableTypeImpl<Y>(
 						typeContext.getBindableType(),
 						typeContext.getAttributeMetadata().getOwnerType(),
 						(ComponentType) typeContext.getValue().getType()
 				);
 				context.registerEmbeddedableType( embeddableType );
 				final Iterator<Property> subProperties = component.getPropertyIterator();
 				while ( subProperties.hasNext() ) {
 					final Property property = subProperties.next();
 					final AttributeImplementor<Y, Object> attribute = buildAttribute( embeddableType, property );
 					if ( attribute != null ) {
 						embeddableType.getBuilder().addAttribute( attribute );
 					}
 				}
 				embeddableType.lock();
 				return embeddableType;
 			}
 			default: {
 				throw new AssertionFailure( "Unknown type : " + typeContext.getValueClassification() );
 			}
 		}
 	}
 
 	private EntityMetamodel getDeclarerEntityMetamodel(IdentifiableType<?> ownerType) {
 		final Type.PersistenceType persistenceType = ownerType.getPersistenceType();
 		if ( persistenceType == Type.PersistenceType.ENTITY) {
 			return context.getSessionFactory()
 					.getEntityPersister( ownerType.getJavaType().getName() )
 					.getEntityMetamodel();
 		}
 		else if ( persistenceType == Type.PersistenceType.MAPPED_SUPERCLASS) {
 			PersistentClass persistentClass =
 					context.getPersistentClassHostingProperties( (MappedSuperclassTypeImpl<?>) ownerType );
 			return context.getSessionFactory()
 				.getEntityPersister( persistentClass.getClassName() )
 				.getEntityMetamodel();
 		}
 		else {
 			throw new AssertionFailure( "Cannot get the metamodel for PersistenceType: " + persistenceType );
 		}
 	}
 
 	/**
 	 * A contract for defining the meta information about a {@link Value}
 	 */
 	private interface ValueContext {
 		/**
 		 * Enum of the simplified types a value might be.  These relate more to the Hibernate classification
 		 * then the JPA classification
 		 */
 		enum ValueClassification {
 			EMBEDDABLE,
 			ENTITY,
 			BASIC
 		}
 
 		/**
 		 * Retrieve the value itself
 		 *
 		 * @return The value
 		 */
 		public Value getValue();
 
 		public Class getBindableType();
 
 		/**
 		 * Retrieve the simplified value classification
 		 *
 		 * @return The value type
 		 */
 		public ValueClassification getValueClassification();
 
 		/**
 		 * Retrieve the metadata about the attribute from which this value comes
 		 *
 		 * @return The "containing" attribute metadata.
 		 */
 		public AttributeMetadata getAttributeMetadata();
 	}
 
 	/**
 	 * Basic contract for describing an attribute.  The "description" is partially in terms
 	 * of JPA ({@link #getPersistentAttributeType} and {@link #getOwnerType}), partially in
 	 * terms of Hibernate ({@link #getPropertyMapping}) and partially just in terms of the java
 	 * model itself ({@link #getName}, {@link #getMember} and {@link #getJavaType}).
 	 *
 	 * @param <X> The attribute owner type
 	 * @param <Y> The attribute type.
 	 */
 	private interface AttributeMetadata<X,Y> {
 		/**
 		 * Retrieve the name of the attribute
 		 *
 		 * @return The attribute name
 		 */
 		public String getName();
 
 		/**
 		 * Retrieve the member defining the attribute
 		 *
 		 * @return The attribute member
 		 */
 		public Member getMember();
 
 		/**
 		 * Retrieve the attribute java type.
 		 *
 		 * @return The java type of the attribute.
 		 */
 		public Class<Y> getJavaType();
 
 		/**
 		 * Get the JPA attribute type classification for this attribute.
 		 *
 		 * @return The JPA attribute type classification
 		 */
 		public Attribute.PersistentAttributeType getPersistentAttributeType();
 
 		/**
 		 * Retrieve the attribute owner's metamodel information
 		 *
 		 * @return The metamodel information for the attribute owner
 		 */
 		public AbstractManagedType<X> getOwnerType();
 
 		/**
 		 * Retrieve the Hibernate property mapping related to this attribute.
 		 *
 		 * @return The Hibernate property mapping
 		 */
 		public Property getPropertyMapping();
 
 		/**
 		 * Is the attribute plural (a collection)?
 		 *
 		 * @return True if it is plural, false otherwise.
 		 */
 		public boolean isPlural();
 	}
 
 	/**
 	 * Attribute metadata contract for a non-plural attribute.
 	 * @param <X> The owner type
 	 * @param <Y> The attribute type
 	 */
 	private interface SingularAttributeMetadata<X,Y>  extends AttributeMetadata<X,Y> {
 		/**
 		 * Retrieve the value context for this attribute
 		 *
 		 * @return The attributes value context
 		 */
 		public ValueContext getValueContext();
 	}
 
 	/**
 	 * Attribute metadata contract for a plural attribute.
 	 * @param <X> The owner type
 	 * @param <Y> The attribute type (the collection type)
 	 * @param <E> The collection element type
 	 */
 	private interface PluralAttributeMetadata<X,Y,E> extends AttributeMetadata<X,Y> {
 		/**
 		 * Retrieve the JPA collection type classification for this attribute
 		 *
 		 * @return The JPA collection type classification
 		 */
 		public PluralAttribute.CollectionType getAttributeCollectionType();
 
 		/**
 		 * Retrieve the value context for the collection's elements.
 		 *
 		 * @return The value context for the collection's elements.
 		 */
 		public ValueContext getElementValueContext();
 
 		/**
 		 * Retrieve the value context for the collection's keys (if a map, null otherwise).
 		 *
 		 * @return The value context for the collection's keys (if a map, null otherwise).
 		 */
 		public ValueContext getMapKeyValueContext();
 	}
 
 	/**
 	 * Bundle's a Hibernate property mapping together with the JPA metamodel information
 	 * of the attribute owner.
 	 *
 	 * @param <X> The owner type.
 	 */
 	private interface AttributeContext<X> {
 		/**
 		 * Retrieve the attribute owner.
 		 *
 		 * @return The owner.
 		 */
 		public AbstractManagedType<X> getOwnerType();
 
 		/**
 		 * Retrieve the Hibernate property mapping.
 		 *
 		 * @return The Hibvernate property mapping.
 		 */
 		public Property getPropertyMapping();
 	}
 
 	/**
 	 * Contract for how we resolve the {@link Member} for a give attribute context.
 	 */
 	private interface MemberResolver {
 		public Member resolveMember(AttributeContext attributeContext);
 	}
 
 	/**
 	 * Here is most of the nuts and bolts of this factory, where we interpret the known JPA metadata
 	 * against the known Hibernate metadata and build a descriptor for the attribute.
 	 *
 	 * @param attributeContext The attribute to be described
 	 * @param memberResolver Strategy for how to resolve the member defining the attribute.
 	 * @param <X> The owner type
 	 * @param <Y> The attribute type
 	 *
 	 * @return The attribute description
 	 */
 	@SuppressWarnings({ "unchecked" })
 	private <X,Y> AttributeMetadata<X,Y> determineAttributeMetadata(
 			AttributeContext<X> attributeContext,
 			MemberResolver memberResolver) {
         LOG.trace("Starting attribute metadata determination [" + attributeContext.getPropertyMapping().getName() + "]");
 		final Member member = memberResolver.resolveMember( attributeContext );
         LOG.trace("    Determined member [" + member + "]");
 
 		final Value value = attributeContext.getPropertyMapping().getValue();
 		final org.hibernate.type.Type type = value.getType();
         LOG.trace("    Determined type [name=" + type.getName() + ", class=" + type.getClass().getName() + "]");
 
 		if ( type.isAnyType() ) {
 			throw new UnsupportedOperationException( "any not supported yet" );
 		}
 		else if ( type.isAssociationType() ) {
 			// collection or entity
 			if ( type.isEntityType() ) {
 				// entity
 				return new SingularAttributeMetadataImpl<X,Y>(
 						attributeContext.getPropertyMapping(),
 						attributeContext.getOwnerType(),
 						member,
 						determineSingularAssociationAttributeType( member )
 				);
 			}
             // collection
             if (value instanceof Collection) {
                 final Collection collValue = (Collection)value;
                 final Value elementValue = collValue.getElement();
                 final org.hibernate.type.Type elementType = elementValue.getType();
 
                 // First, determine the type of the elements and use that to help determine the
                 // collection type)
                 final Attribute.PersistentAttributeType elementPersistentAttributeType;
                 final Attribute.PersistentAttributeType persistentAttributeType;
                 if (elementType.isAnyType()) {
                     throw new UnsupportedOperationException("collection of any not supported yet");
                 }
                 final boolean isManyToMany = isManyToMany(member);
                 if (elementValue instanceof Component) {
                     elementPersistentAttributeType = Attribute.PersistentAttributeType.EMBEDDED;
                     persistentAttributeType = Attribute.PersistentAttributeType.ELEMENT_COLLECTION;
                 } else if (elementType.isAssociationType()) {
                     elementPersistentAttributeType = isManyToMany ? Attribute.PersistentAttributeType.MANY_TO_MANY : Attribute.PersistentAttributeType.ONE_TO_MANY;
                     persistentAttributeType = elementPersistentAttributeType;
                 } else {
                     elementPersistentAttributeType = Attribute.PersistentAttributeType.BASIC;
                     persistentAttributeType = Attribute.PersistentAttributeType.ELEMENT_COLLECTION;
                 }
 
                 final Attribute.PersistentAttributeType keyPersistentAttributeType;
 
                 // Finally, we determine the type of the map key (if needed)
                 if (value instanceof Map) {
                     final Value keyValue = ((Map)value).getIndex();
                     final org.hibernate.type.Type keyType = keyValue.getType();
 
                     if (keyType.isAnyType()) throw new UnsupportedOperationException("collection of any not supported yet");
                     if (keyValue instanceof Component) keyPersistentAttributeType = Attribute.PersistentAttributeType.EMBEDDED;
                     else if (keyType.isAssociationType()) keyPersistentAttributeType = Attribute.PersistentAttributeType.MANY_TO_ONE;
                     else keyPersistentAttributeType = Attribute.PersistentAttributeType.BASIC;
                 } else keyPersistentAttributeType = null;
                 return new PluralAttributeMetadataImpl(attributeContext.getPropertyMapping(), attributeContext.getOwnerType(),
                                                        member, persistentAttributeType, elementPersistentAttributeType,
                                                        keyPersistentAttributeType);
             } else if (value instanceof OneToMany) {
                 // TODO : is this even possible??? Really OneToMany should be describing the
                 // element value within a o.h.mapping.Collection (see logic branch above)
                 throw new IllegalArgumentException("HUH???");
 //					final boolean isManyToMany = isManyToMany( member );
 //					//one to many with FK => entity
 //					return new PluralAttributeMetadataImpl(
 //							attributeContext.getPropertyMapping(),
 //							attributeContext.getOwnerType(),
 //							member,
 //							isManyToMany
 //									? Attribute.PersistentAttributeType.MANY_TO_MANY
 //									: Attribute.PersistentAttributeType.ONE_TO_MANY
 //							value,
 //							AttributeContext.TypeStatus.ENTITY,
 //							Attribute.PersistentAttributeType.ONE_TO_MANY,
 //							null, null, null
 //					);
 			}
 		}
 		else if ( attributeContext.getPropertyMapping().isComposite() ) {
 			// component
 			return new SingularAttributeMetadataImpl<X,Y>(
 					attributeContext.getPropertyMapping(),
 					attributeContext.getOwnerType(),
 					member,
 					Attribute.PersistentAttributeType.EMBEDDED
 			);
 		}
 		else {
 			// basic type
 			return new SingularAttributeMetadataImpl<X,Y>(
 					attributeContext.getPropertyMapping(),
 					attributeContext.getOwnerType(),
 					member,
 					Attribute.PersistentAttributeType.BASIC
 			);
 		}
 		throw new UnsupportedOperationException( "oops, we are missing something: " + attributeContext.getPropertyMapping() );
 	}
 
 	public static Attribute.PersistentAttributeType determineSingularAssociationAttributeType(Member member) {
 		if ( Field.class.isInstance( member ) ) {
 			return ( (Field) member ).getAnnotation( OneToOne.class ) != null
 					? Attribute.PersistentAttributeType.ONE_TO_ONE
 					: Attribute.PersistentAttributeType.MANY_TO_ONE;
 		}
 		else {
 			return ( (Method) member ).getAnnotation( OneToOne.class ) != null
 					? Attribute.PersistentAttributeType.ONE_TO_ONE
 					: Attribute.PersistentAttributeType.MANY_TO_ONE;
 		}
 	}
 
 	private abstract class BaseAttributeMetadata<X,Y> implements AttributeMetadata<X,Y> {
 		private final Property propertyMapping;
 		private final AbstractManagedType<X> ownerType;
 		private final Member member;
 		private final Class<Y> javaType;
 		private final Attribute.PersistentAttributeType persistentAttributeType;
 
 		@SuppressWarnings({ "unchecked" })
 		protected BaseAttributeMetadata(
 				Property propertyMapping,
 				AbstractManagedType<X> ownerType,
 				Member member,
 				Attribute.PersistentAttributeType persistentAttributeType) {
 			this.propertyMapping = propertyMapping;
 			this.ownerType = ownerType;
 			this.member = member;
 			this.persistentAttributeType = persistentAttributeType;
 			final Class declaredType;
 			// we can support method or field members here.  Is there really any other valid type?
 			if ( Field.class.isInstance( member ) ) {
 				declaredType = ( (Field) member ).getType();
 			}
 			else if ( Method.class.isInstance( member ) ) {
 				declaredType = ( (Method) member ).getReturnType();
 			}
 			else {
 				throw new IllegalArgumentException( "Cannot determine java-type from given member [" + member + "]" );
 			}
 			this.javaType = accountForPrimitiveTypes( declaredType );
 		}
 
 		public String getName() {
 			return propertyMapping.getName();
 		}
 
 		public Member getMember() {
 			return member;
 		}
 
 		public String getMemberDescription() {
 			return determineMemberDescription( getMember() );
 		}
 
 		public String determineMemberDescription(Member member) {
 			return member.getDeclaringClass().getName() + '#' + member.getName();
 		}
 
 		public Class<Y> getJavaType() {
 			return javaType;
 		}
 
 		public Attribute.PersistentAttributeType getPersistentAttributeType() {
 			return persistentAttributeType;
 		}
 
 		public AbstractManagedType<X> getOwnerType() {
 			return ownerType;
 		}
 
 		public boolean isPlural() {
 			return propertyMapping.getType().isCollectionType();
 		}
 
 		public Property getPropertyMapping() {
 			return propertyMapping;
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected <Y> Class<Y> accountForPrimitiveTypes(Class<Y> declaredType) {
 //		if ( !declaredType.isPrimitive() ) {
 //			return declaredType;
 //		}
 //
 //		if ( Boolean.TYPE.equals( declaredType ) ) {
 //			return (Class<Y>) Boolean.class;
 //		}
 //		if ( Character.TYPE.equals( declaredType ) ) {
 //			return (Class<Y>) Character.class;
 //		}
 //		if( Byte.TYPE.equals( declaredType ) ) {
 //			return (Class<Y>) Byte.class;
 //		}
 //		if ( Short.TYPE.equals( declaredType ) ) {
 //			return (Class<Y>) Short.class;
 //		}
 //		if ( Integer.TYPE.equals( declaredType ) ) {
 //			return (Class<Y>) Integer.class;
 //		}
 //		if ( Long.TYPE.equals( declaredType ) ) {
 //			return (Class<Y>) Long.class;
 //		}
 //		if ( Float.TYPE.equals( declaredType ) ) {
 //			return (Class<Y>) Float.class;
 //		}
 //		if ( Double.TYPE.equals( declaredType ) ) {
 //			return (Class<Y>) Double.class;
 //		}
 //
 //		throw new IllegalArgumentException( "Unexpected type [" + declaredType + "]" );
 		// if the field is defined as int, return int not Integer...
 		return declaredType;
 	}
 
 	private class SingularAttributeMetadataImpl<X,Y>
 			extends BaseAttributeMetadata<X,Y>
 			implements SingularAttributeMetadata<X,Y> {
 		private final ValueContext valueContext;
 
 		private SingularAttributeMetadataImpl(
 				Property propertyMapping,
 				AbstractManagedType<X> ownerType,
 				Member member,
 				Attribute.PersistentAttributeType persistentAttributeType) {
 			super( propertyMapping, ownerType, member, persistentAttributeType );
 			valueContext = new ValueContext() {
 				public Value getValue() {
 					return getPropertyMapping().getValue();
 				}
 
 				public Class getBindableType() {
 					return getAttributeMetadata().getJavaType();
 				}
 
 				public ValueClassification getValueClassification() {
 					switch ( getPersistentAttributeType() ) {
 						case EMBEDDED: {
 							return ValueClassification.EMBEDDABLE;
 						}
 						case BASIC: {
 							return ValueClassification.BASIC;
 						}
 						default: {
 							return ValueClassification.ENTITY;
 						}
 					}
 				}
 
 				public AttributeMetadata getAttributeMetadata() {
 					return SingularAttributeMetadataImpl.this;
 				}
 			};
 		}
 
 		public ValueContext getValueContext() {
 			return valueContext;
 		}
 	}
 
 	private class PluralAttributeMetadataImpl<X,Y,E>
 			extends BaseAttributeMetadata<X,Y>
 			implements PluralAttributeMetadata<X,Y,E> {
 		private final PluralAttribute.CollectionType attributeCollectionType;
 		private final Attribute.PersistentAttributeType elementPersistentAttributeType;
 		private final Attribute.PersistentAttributeType keyPersistentAttributeType;
 		private final Class elementJavaType;
 		private final Class keyJavaType;
 		private final ValueContext elementValueContext;
 		private final ValueContext keyValueContext;
 
 		private PluralAttributeMetadataImpl(
 				Property propertyMapping,
 				AbstractManagedType<X> ownerType,
 				Member member,
 				Attribute.PersistentAttributeType persistentAttributeType,
 				Attribute.PersistentAttributeType elementPersistentAttributeType,
 				Attribute.PersistentAttributeType keyPersistentAttributeType) {
 			super( propertyMapping, ownerType, member, persistentAttributeType );
 			this.attributeCollectionType = determineCollectionType( getJavaType() );
 			this.elementPersistentAttributeType = elementPersistentAttributeType;
 			this.keyPersistentAttributeType = keyPersistentAttributeType;
 
 			ParameterizedType signatureType = getSignatureType( member );
 			if ( keyPersistentAttributeType == null ) {
 				elementJavaType = signatureType != null ?
 						getClassFromGenericArgument( signatureType.getActualTypeArguments()[0] ) :
 						Object.class; //FIXME and honor targetEntity?
 				keyJavaType = null;
 			}
 			else {
 				keyJavaType = signatureType != null ?
 						getClassFromGenericArgument( signatureType.getActualTypeArguments()[0] ) :
 						Object.class; //FIXME and honor targetEntity?
 				elementJavaType = signatureType != null ?
 						getClassFromGenericArgument( signatureType.getActualTypeArguments()[1] ) :
 						Object.class; //FIXME and honor targetEntity?
 			}
 
 			this.elementValueContext = new ValueContext() {
 				public Value getValue() {
 					return ( (Collection) getPropertyMapping().getValue() ).getElement();
 				}
 
 				public Class getBindableType() {
 					return elementJavaType;
 				}
 
 				public ValueClassification getValueClassification() {
 					switch ( PluralAttributeMetadataImpl.this.elementPersistentAttributeType ) {
 						case EMBEDDED: {
 							return ValueClassification.EMBEDDABLE;
 						}
 						case BASIC: {
 							return ValueClassification.BASIC;
 						}
 						default: {
 							return ValueClassification.ENTITY;
 						}
 					}
 				}
 
 				public AttributeMetadata getAttributeMetadata() {
 					return PluralAttributeMetadataImpl.this;
 				}
 			};
 
 			// interpret the key, if one
 			if ( keyPersistentAttributeType != null ) {
 				this.keyValueContext = new ValueContext() {
 					public Value getValue() {
 						return ( (Map) getPropertyMapping().getValue() ).getIndex();
 					}
 
 					public Class getBindableType() {
 						return keyJavaType;
 					}
 
 					public ValueClassification getValueClassification() {
 						switch ( PluralAttributeMetadataImpl.this.keyPersistentAttributeType ) {
 							case EMBEDDED: {
 								return ValueClassification.EMBEDDABLE;
 							}
 							case BASIC: {
 								return ValueClassification.BASIC;
 							}
 							default: {
 								return ValueClassification.ENTITY;
 							}
 						}
 					}
 
 					public AttributeMetadata getAttributeMetadata() {
 						return PluralAttributeMetadataImpl.this;
 					}
 				};
 			}
 			else {
 				keyValueContext = null;
 			}
 		}
 
 		private Class<?> getClassFromGenericArgument(java.lang.reflect.Type type) {
 			if ( type instanceof Class ) {
 				return (Class) type;
 			}
 			else if ( type instanceof TypeVariable ) {
 				final java.lang.reflect.Type upperBound = ( ( TypeVariable ) type ).getBounds()[0];
 				return getClassFromGenericArgument( upperBound );
 			}
 			else if ( type instanceof ParameterizedType ) {
 				final java.lang.reflect.Type rawType = ( (ParameterizedType) type ).getRawType();
 				return getClassFromGenericArgument( rawType );
 			}
 			else {
 				throw new AssertionFailure(
 						"Fail to process type argument in a generic declaration. Member : " + getMemberDescription()
 								+ " Type: " + type.getClass()
 				);
 			}
 		}
 
 		public ValueContext getElementValueContext() {
 			return elementValueContext;
 		}
 
 		public PluralAttribute.CollectionType getAttributeCollectionType() {
 			return attributeCollectionType;
 		}
 
 		public ValueContext getMapKeyValueContext() {
 			return keyValueContext;
 		}
 	}
 
 	public static ParameterizedType getSignatureType(Member member) {
 		final java.lang.reflect.Type type = Field.class.isInstance( member )
 				? ( ( Field ) member ).getGenericType()
 				: ( ( Method ) member ).getGenericReturnType();
 		//this is a raw type
 		if ( type instanceof Class ) return null;
 		return (ParameterizedType) type;
 	}
 
 	public static PluralAttribute.CollectionType determineCollectionType(Class javaType) {
 		if ( java.util.List.class.isAssignableFrom( javaType ) ) {
 			return PluralAttribute.CollectionType.LIST;
 		}
 		else if ( java.util.Set.class.isAssignableFrom( javaType ) ) {
 			return PluralAttribute.CollectionType.SET;
 		}
 		else if ( java.util.Map.class.isAssignableFrom( javaType ) ) {
 			return PluralAttribute.CollectionType.MAP;
 		}
 		else if ( java.util.Collection.class.isAssignableFrom( javaType ) ) {
 			return PluralAttribute.CollectionType.COLLECTION;
 		}
 		else {
 			throw new IllegalArgumentException( "Expecting collection type [" + javaType.getName() + "]" );
 		}
 	}
 
 	public static boolean isManyToMany(Member member) {
 		return Field.class.isInstance( member )
 				? ( (Field) member ).getAnnotation( ManyToMany.class ) != null
 				: ( (Method) member ).getAnnotation( ManyToMany.class ) != null;
 	}
 
 	private final MemberResolver EMBEDDED_MEMBER_RESOLVER = new MemberResolver() {
 		/**
 		 * {@inheritDoc}
 		 */
 		public Member resolveMember(AttributeContext attributeContext) {
 			final EmbeddableTypeImpl embeddableType = ( EmbeddableTypeImpl<?> ) attributeContext.getOwnerType();
 			final String attributeName = attributeContext.getPropertyMapping().getName();
 			return embeddableType.getHibernateType().getTuplizerMapping()
 					.getTuplizer( EntityMode.POJO )
 					.getGetter( embeddableType.getHibernateType().getPropertyIndex( attributeName ) )
 					.getMember();
 		}
 	};
 
 
 	private final MemberResolver VIRTUAL_IDENTIFIER_MEMBER_RESOLVER = new MemberResolver() {
 		/**
 		 * {@inheritDoc}
 		 */
 		public Member resolveMember(AttributeContext attributeContext) {
 			final IdentifiableType identifiableType = (IdentifiableType) attributeContext.getOwnerType();
 			final EntityMetamodel entityMetamodel = getDeclarerEntityMetamodel( identifiableType );
 			if ( ! entityMetamodel.getIdentifierProperty().isVirtual() ) {
 				throw new IllegalArgumentException( "expecting IdClass mapping" );
 			}
 			org.hibernate.type.Type type = entityMetamodel.getIdentifierProperty().getType();
 			if ( ! EmbeddedComponentType.class.isInstance( type ) ) {
 				throw new IllegalArgumentException( "expecting IdClass mapping" );
 			}
 
 			final EmbeddedComponentType componentType = (EmbeddedComponentType) type;
 			final String attributeName = attributeContext.getPropertyMapping().getName();
 			return componentType.getTuplizerMapping()
 					.getTuplizer( EntityMode.POJO )
 					.getGetter( componentType.getPropertyIndex( attributeName ) )
 					.getMember();
 		}
 	};
 
 	/**
 	 * A {@link Member} resolver for normal attributes.
 	 */
 	private final MemberResolver NORMAL_MEMBER_RESOLVER = new MemberResolver() {
 		/**
 		 * {@inheritDoc}
 		 */
 		public Member resolveMember(AttributeContext attributeContext) {
 			final AbstractManagedType ownerType = attributeContext.getOwnerType();
 			final Property property = attributeContext.getPropertyMapping();
 			final Type.PersistenceType persistenceType = ownerType.getPersistenceType();
 			if ( Type.PersistenceType.EMBEDDABLE == persistenceType ) {
 				return EMBEDDED_MEMBER_RESOLVER.resolveMember( attributeContext );
 			}
 			else if ( Type.PersistenceType.ENTITY == persistenceType
 					|| Type.PersistenceType.MAPPED_SUPERCLASS == persistenceType ) {
 				final IdentifiableType identifiableType = (IdentifiableType) ownerType;
 				final EntityMetamodel entityMetamodel = getDeclarerEntityMetamodel( identifiableType );
 				final String propertyName = property.getName();
 				final Integer index = entityMetamodel.getPropertyIndexOrNull( propertyName );
 				if ( index == null ) {
 					// just like in #determineIdentifierJavaMember , this *should* indicate we have an IdClass mapping
 					return VIRTUAL_IDENTIFIER_MEMBER_RESOLVER.resolveMember( attributeContext );
 				}
 				else {
 					return entityMetamodel.getTuplizer( EntityMode.POJO )
 							.getGetter( index )
 							.getMember();
 				}
 			}
 			else {
 				throw new IllegalArgumentException( "Unexpected owner type : " + persistenceType );
 			}
 		}
 	};
 
 	private final MemberResolver IDENTIFIER_MEMBER_RESOLVER = new MemberResolver() {
 		public Member resolveMember(AttributeContext attributeContext) {
 			final IdentifiableType identifiableType = (IdentifiableType) attributeContext.getOwnerType();
 			final EntityMetamodel entityMetamodel = getDeclarerEntityMetamodel( identifiableType );
 			if ( ! attributeContext.getPropertyMapping().getName()
 					.equals( entityMetamodel.getIdentifierProperty().getName() ) ) {
 				// this *should* indicate processing part of an IdClass...
 				return VIRTUAL_IDENTIFIER_MEMBER_RESOLVER.resolveMember( attributeContext );
 			}
 			return entityMetamodel.getTuplizer( EntityMode.POJO ).getIdentifierGetter().getMember();
 		}
 	};
 
 	private final MemberResolver VERSION_MEMBER_RESOLVER = new MemberResolver() {
 		public Member resolveMember(AttributeContext attributeContext) {
 			final IdentifiableType identifiableType = (IdentifiableType) attributeContext.getOwnerType();
 			final EntityMetamodel entityMetamodel = getDeclarerEntityMetamodel( identifiableType );
 			final String versionPropertyName = attributeContext.getPropertyMapping().getName();
 			if ( ! versionPropertyName.equals( entityMetamodel.getVersionProperty().getName() ) ) {
 				// this should never happen, but to be safe...
 				throw new IllegalArgumentException( "Given property did not match declared version property" );
 			}
 			return entityMetamodel.getTuplizer( EntityMode.POJO ).getVersionGetter().getMember();
 		}
 	};
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/metamodel/MetadataContext.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/metamodel/MetadataContext.java
index c903add213..942648f5bb 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/metamodel/MetadataContext.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/metamodel/MetadataContext.java
@@ -1,457 +1,457 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.metamodel;
 import java.lang.reflect.Field;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.IdentifiableType;
 import javax.persistence.metamodel.SingularAttribute;
 import org.hibernate.annotations.common.AssertionFailure;
-import org.hibernate.ejb.EntityManagerLogger;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.MappedSuperclass;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.jboss.logging.Logger;
 
 /**
  * Defines a context for storing information during the building of the {@link MetamodelImpl}.
  * <p/>
  * This contextual information includes data needing to be processed in a second pass as well as
  * cross-references into the built metamodel classes.
  * <p/>
  * At the end of the day, clients are interested in the {@link #getEntityTypeMap} and {@link #getEmbeddableTypeMap}
  * results, which represent all the registered {@linkplain #registerEntityType entities} and
  *  {@linkplain #registerEmbeddedableType embeddables} respectively.
  *
  * @author Steve Ebersole
  * @author Emmanuel Bernard
  */
 class MetadataContext {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            MetadataContext.class.getName());
 
 	private final SessionFactoryImplementor sessionFactory;
 	private final AttributeFactory attributeFactory = new AttributeFactory( this );
 
 	private Map<Class<?>,EntityTypeImpl<?>> entityTypes
 			= new HashMap<Class<?>, EntityTypeImpl<?>>();
 	private Map<String,EntityTypeImpl<?>> entityTypesByEntityName
 			= new HashMap<String, EntityTypeImpl<?>>();
 	private Map<PersistentClass,EntityTypeImpl<?>> entityTypesByPersistentClass
 			= new HashMap<PersistentClass,EntityTypeImpl<?>>();
 	private Map<Class<?>, EmbeddableTypeImpl<?>> embeddables
 			= new HashMap<Class<?>, EmbeddableTypeImpl<?>>();
 	private Map<MappedSuperclass, MappedSuperclassTypeImpl<?>> mappedSuperclassByMappedSuperclassMapping
 			= new HashMap<MappedSuperclass,MappedSuperclassTypeImpl<?>>();
 	//this list contains MappedSuperclass and EntityTypes ordered by superclass first
 	private List<Object> orderedMappings = new ArrayList<Object>();
 	/**
 	 * Stack of PersistentClass being process. Last in the list is the highest in the stack.
 	 *
 	 */
 	private List<PersistentClass> stackOfPersistentClassesBeingProcessed
 			= new ArrayList<PersistentClass>();
 	private Map<MappedSuperclassTypeImpl<?>, PersistentClass> mappedSuperClassTypeToPersistentClass
 			= new HashMap<MappedSuperclassTypeImpl<?>, PersistentClass>();
 
 	public MetadataContext(SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 	}
 
 	/*package*/ SessionFactoryImplementor getSessionFactory() {
 		return sessionFactory;
 	}
 
 	/**
 	 * Retrieves the {@linkplain Class java type} to {@link EntityTypeImpl} map.
 	 *
 	 * @return The {@linkplain Class java type} to {@link EntityTypeImpl} map.
 	 */
 	public Map<Class<?>, EntityTypeImpl<?>> getEntityTypeMap() {
 		return Collections.unmodifiableMap( entityTypes );
 	}
 
 	public Map<Class<?>, EmbeddableTypeImpl<?>> getEmbeddableTypeMap() {
 		return Collections.unmodifiableMap( embeddables );
 	}
 
 	/*package*/ void registerEntityType(PersistentClass persistentClass, EntityTypeImpl<?> entityType) {
 		entityTypes.put( entityType.getBindableJavaType(), entityType );
 		entityTypesByEntityName.put( persistentClass.getEntityName(), entityType );
 		entityTypesByPersistentClass.put( persistentClass, entityType );
 		orderedMappings.add( persistentClass );
 	}
 
 	/*package*/ void registerEmbeddedableType(EmbeddableTypeImpl<?> embeddableType) {
 		embeddables.put( embeddableType.getJavaType(), embeddableType );
 	}
 
 	/*package*/ void registerMappedSuperclassType(MappedSuperclass mappedSuperclass,
 												  MappedSuperclassTypeImpl<?> mappedSuperclassType) {
 		mappedSuperclassByMappedSuperclassMapping.put( mappedSuperclass, mappedSuperclassType );
 		orderedMappings.add( mappedSuperclass );
 		mappedSuperClassTypeToPersistentClass.put( mappedSuperclassType, getEntityWorkedOn() );
 	}
 
 	/**
 	 * Given a Hibernate {@link PersistentClass}, locate the corresponding JPA {@link org.hibernate.type.EntityType}
 	 * implementation.  May retur null if the given {@link PersistentClass} has not yet been processed.
 	 *
 	 * @param persistentClass The Hibernate (config time) metamodel instance representing an entity.
 	 * @return Tne corresponding JPA {@link org.hibernate.type.EntityType}, or null if not yet processed.
 	 */
 	public EntityTypeImpl<?> locateEntityType(PersistentClass persistentClass) {
 		return entityTypesByPersistentClass.get( persistentClass );
 	}
 
 	/**
 	 * Given a Java {@link Class}, locate the corresponding JPA {@link org.hibernate.type.EntityType}.  May
 	 * return null which could means that no such mapping exists at least at this time.
 	 *
 	 * @param javaType The java class.
 	 * @return The corresponding JPA {@link org.hibernate.type.EntityType}, or null.
 	 */
 	public EntityTypeImpl<?> locateEntityType(Class<?> javaType) {
 		return entityTypes.get( javaType );
 	}
 
 	/**
 	 * Given an entity-name, locate the corresponding JPA {@link org.hibernate.type.EntityType}.  May
 	 * return null which could means that no such mapping exists at least at this time.
 	 *
 	 * @param entityName The entity-name.
 	 * @return The corresponding JPA {@link org.hibernate.type.EntityType}, or null.
 	 */
 	public EntityTypeImpl<?> locateEntityType(String entityName) {
 		return entityTypesByEntityName.get( entityName );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void wrapUp() {
         LOG.trace("Wrapping up metadata context...");
 		//we need to process types from superclasses to subclasses
 		for (Object mapping : orderedMappings) {
 			if ( PersistentClass.class.isAssignableFrom( mapping.getClass() ) ) {
 				@SuppressWarnings( "unchecked" )
 				final PersistentClass safeMapping = (PersistentClass) mapping;
                 LOG.trace("Starting entity [" + safeMapping.getEntityName() + "]");
 				try {
 					final EntityTypeImpl<?> jpa2Mapping = entityTypesByPersistentClass.get( safeMapping );
 					applyIdMetadata( safeMapping, jpa2Mapping );
 					applyVersionAttribute( safeMapping, jpa2Mapping );
 					Iterator<Property> properties = safeMapping.getDeclaredPropertyIterator();
 					while ( properties.hasNext() ) {
 						final Property property = properties.next();
 						if ( property.getValue() == safeMapping.getIdentifierMapper() ) {
 							// property represents special handling for id-class mappings but we have already
 							// accounted for the embedded property mappings in #applyIdMetadata &&
 							// #buildIdClassAttributes
 							continue;
 						}
 						if ( safeMapping.isVersioned() && property == safeMapping.getVersion() ) {
 							// skip the version property, it was already handled previously.
 							continue;
 						}
 						final Attribute attribute = attributeFactory.buildAttribute( jpa2Mapping, property );
 						if ( attribute != null ) {
 							jpa2Mapping.getBuilder().addAttribute( attribute );
 						}
 					}
 					jpa2Mapping.lock();
 					populateStaticMetamodel( jpa2Mapping );
 				}
 				finally {
                     LOG.trace("Completed entity [" + safeMapping.getEntityName() + "]");
 				}
 			}
 			else if ( MappedSuperclass.class.isAssignableFrom( mapping.getClass() ) ) {
 				@SuppressWarnings( "unchecked" )
 				final MappedSuperclass safeMapping = (MappedSuperclass) mapping;
                 LOG.trace("Starting mapped superclass [" + safeMapping.getMappedClass().getName() + "]");
 				try {
 					final MappedSuperclassTypeImpl<?> jpa2Mapping = mappedSuperclassByMappedSuperclassMapping.get(
 							safeMapping
 					);
 					applyIdMetadata( safeMapping, jpa2Mapping );
 					applyVersionAttribute( safeMapping, jpa2Mapping );
 					Iterator<Property> properties = safeMapping.getDeclaredPropertyIterator();
 					while ( properties.hasNext() ) {
 						final Property property = properties.next();
 						if ( safeMapping.isVersioned() && property == safeMapping.getVersion() ) {
 							// skip the version property, it was already handled previously.
 							continue;
 						}
 						final Attribute attribute = attributeFactory.buildAttribute( jpa2Mapping, property );
 						if ( attribute != null ) {
 							jpa2Mapping.getBuilder().addAttribute( attribute );
 						}
 					}
 					jpa2Mapping.lock();
 					populateStaticMetamodel( jpa2Mapping );
 				}
 				finally {
                     LOG.trace("Completed mapped superclass [" + safeMapping.getMappedClass().getName() + "]");
 				}
 			}
 			else {
 				throw new AssertionFailure( "Unexpected mapping type: " + mapping.getClass() );
 			}
 		}
 
 		for ( EmbeddableTypeImpl embeddable : embeddables.values() ) {
 			populateStaticMetamodel( embeddable );
 		}
 	}
 
 
 	private <X> void applyIdMetadata(PersistentClass persistentClass, EntityTypeImpl<X> jpaEntityType) {
 		if ( persistentClass.hasIdentifierProperty() ) {
 			final Property declaredIdentifierProperty = persistentClass.getDeclaredIdentifierProperty();
 			if (declaredIdentifierProperty != null) {
 				jpaEntityType.getBuilder().applyIdAttribute(
 						attributeFactory.buildIdAttribute( jpaEntityType, declaredIdentifierProperty )
 				);
 			}
 		}
 		else if ( persistentClass.hasIdentifierMapper() ) {
 			jpaEntityType.getBuilder().applyIdClassAttributes( buildIdClassAttributes( jpaEntityType, persistentClass ) );
 		}
 		else {
 			final KeyValue value = persistentClass.getIdentifier();
 			if (value instanceof Component ) {
 				final Component component = ( Component ) value;
 				if ( component.getPropertySpan() > 1 ) {
 					//FIXME we are an Hibernate embedded id (ie not type)
 				}
 				else {
 					//FIXME take care of declared vs non declared property
 					jpaEntityType.getBuilder().applyIdAttribute(
 						attributeFactory.buildIdAttribute(
 								jpaEntityType,
 								(Property) component.getPropertyIterator().next() )
 					);
 				}
 			}
 		}
 	}
 
 	private <X> void applyIdMetadata(MappedSuperclass mappingType, MappedSuperclassTypeImpl<X> jpaMappingType) {
 		if ( mappingType.hasIdentifierProperty() ) {
 			final Property declaredIdentifierProperty = mappingType.getDeclaredIdentifierProperty();
 			if (declaredIdentifierProperty != null) {
 				jpaMappingType.getBuilder().applyIdAttribute(
 						attributeFactory.buildIdAttribute( jpaMappingType, declaredIdentifierProperty )
 				);
 			}
 		}
 		//an MappedSuperclass can have no identifier if the id is set below in the hierarchy
 		else if ( mappingType.getIdentifierMapper() != null ){
 			final Set<SingularAttribute<? super X, ?>> attributes = buildIdClassAttributes(
 					jpaMappingType, mappingType
 			);
 			jpaMappingType.getBuilder().applyIdClassAttributes( attributes );
 		}
 	}
 
 	private <X> void applyVersionAttribute(PersistentClass persistentClass, EntityTypeImpl<X> jpaEntityType) {
 		final Property declaredVersion = persistentClass.getDeclaredVersion();
 		if (declaredVersion != null) {
 			jpaEntityType.getBuilder().applyVersionAttribute(
 					attributeFactory.buildVersionAttribute( jpaEntityType, declaredVersion )
 			);
 		}
 	}
 
 	private <X> void applyVersionAttribute(MappedSuperclass mappingType, MappedSuperclassTypeImpl<X> jpaMappingType) {
 		final Property declaredVersion = mappingType.getDeclaredVersion();
 		if ( declaredVersion != null ) {
 			jpaMappingType.getBuilder().applyVersionAttribute(
 					attributeFactory.buildVersionAttribute( jpaMappingType, declaredVersion )
 			);
 		}
 	}
 
 	private <X> Set<SingularAttribute<? super X, ?>> buildIdClassAttributes(
 			EntityTypeImpl<X> jpaEntityType,
 			PersistentClass persistentClass) {
 		Set<SingularAttribute<? super X, ?>> attributes = new HashSet<SingularAttribute<? super X, ?>>();
 		@SuppressWarnings( "unchecked")
 		Iterator<Property> properties = persistentClass.getIdentifierMapper().getPropertyIterator();
 		while ( properties.hasNext() ) {
 			attributes.add( attributeFactory.buildIdAttribute( jpaEntityType, properties.next() ) );
 		}
 		return attributes;
 	}
 
 	private <X> Set<SingularAttribute<? super X, ?>> buildIdClassAttributes(
 			MappedSuperclassTypeImpl<X> jpaMappingType,
 			MappedSuperclass mappingType) {
         LOG.trace("Building old-school composite identifier [" + mappingType.getMappedClass().getName() + "]");
 		Set<SingularAttribute<? super X, ?>> attributes = new HashSet<SingularAttribute<? super X, ?>>();
 		@SuppressWarnings( "unchecked" )
 		Iterator<Property> properties = mappingType.getIdentifierMapper().getPropertyIterator();
 		while ( properties.hasNext() ) {
 			attributes.add( attributeFactory.buildIdAttribute( jpaMappingType, properties.next() ) );
 		}
 		return attributes;
 	}
 
 	private <X> void populateStaticMetamodel(AbstractManagedType<X> managedType) {
 		final Class<X> managedTypeClass = managedType.getJavaType();
 		final String metamodelClassName = managedTypeClass.getName() + "_";
 		try {
 			final Class metamodelClass = Class.forName( metamodelClassName, true, managedTypeClass.getClassLoader() );
 			// we found the class; so populate it...
 			registerAttributes( metamodelClass, managedType );
 		}
 		catch ( ClassNotFoundException ignore ) {
 			// nothing to do...
 		}
 
 		// todo : this does not account for @MappeSuperclass, mainly because this is not being tracked in our
 		// internal metamodel as populated from the annotatios properly
 		AbstractManagedType<? super X> superType = managedType.getSupertype();
 		if ( superType != null ) {
 			populateStaticMetamodel( superType );
 		}
 	}
 
 	private final Set<Class> processedMetamodelClasses = new HashSet<Class>();
 
 	private <X> void registerAttributes(Class metamodelClass, AbstractManagedType<X> managedType) {
 		if ( ! processedMetamodelClasses.add( metamodelClass ) ) {
 			return;
 		}
 
 		// push the attributes on to the metamodel class...
 		for ( Attribute<X, ?> attribute : managedType.getDeclaredAttributes() ) {
 			registerAttribute( metamodelClass, attribute );
 		}
 
 		if ( IdentifiableType.class.isInstance( managedType ) ) {
 			final AbstractIdentifiableType<X> entityType = ( AbstractIdentifiableType<X> ) managedType;
 
 			// handle version
 			if ( entityType.hasDeclaredVersionAttribute() ) {
 				registerAttribute( metamodelClass, entityType.getDeclaredVersion() );
 			}
 
 			// handle id-class mappings specially
 			if ( ! entityType.hasSingleIdAttribute() ) {
 				final Set<SingularAttribute<? super X, ?>> attributes = entityType.getIdClassAttributes();
 				if ( attributes != null ) {
 					for ( SingularAttribute<? super X, ?> attribute : attributes ) {
 						registerAttribute( metamodelClass, attribute );
 					}
 				}
 			}
 		}
 	}
 
 	private <X> void registerAttribute(Class metamodelClass, Attribute<X, ?> attribute) {
 		final String name = attribute.getName();
 		try {
 			Field field = metamodelClass.getDeclaredField( name );
 			try {
 				if ( ! field.isAccessible() ) {
 					// should be public anyway, but to be sure...
 					field.setAccessible( true );
 				}
 				field.set( null, attribute );
 			}
 			catch ( IllegalAccessException e ) {
 				// todo : exception type?
 				throw new AssertionFailure(
 						"Unable to inject static metamodel attribute : " + metamodelClass.getName() + '#' + name,
 						e
 				);
 			}
 			catch ( IllegalArgumentException e ) {
 				// most likely a mismatch in the type we are injecting and the defined field; this represents a
 				// mismatch in how the annotation processor interpretted the attribute and how our metamodel
 				// and/or annotation binder did.
 
 //              This is particularly the case as arrays are nto handled propery by the StaticMetamodel generator
 
 //				throw new AssertionFailure(
 //						"Illegal argument on static metamodel field injection : " + metamodelClass.getName() + '#' + name
 //								+ "; expected type :  " + attribute.getClass().getName()
 //								+ "; encountered type : " + field.getType().getName()
 //				);
                 LOG.illegalArgumentOnStaticMetamodelFieldInjection(metamodelClass.getName(),
                                                                    name,
                                                                    attribute.getClass().getName(),
                                                                    field.getType().getName());
 			}
 		}
 		catch ( NoSuchFieldException e ) {
             LOG.unableToLocateStaticMetamodelField(metamodelClass.getName(), name);
 //			throw new AssertionFailure(
 //					"Unable to locate static metamodel field : " + metamodelClass.getName() + '#' + name
 //			);
 		}
 	}
 
 	public MappedSuperclassTypeImpl<?> locateMappedSuperclassType(MappedSuperclass mappedSuperclass) {
 		return mappedSuperclassByMappedSuperclassMapping.get(mappedSuperclass);
 	}
 
 	public void pushEntityWorkedOn(PersistentClass persistentClass) {
 		stackOfPersistentClassesBeingProcessed.add(persistentClass);
 	}
 
 	public void popEntityWorkedOn(PersistentClass persistentClass) {
 		final PersistentClass stackTop = stackOfPersistentClassesBeingProcessed.remove(
 				stackOfPersistentClassesBeingProcessed.size() - 1
 		);
 		if (stackTop != persistentClass) {
 			throw new AssertionFailure( "Inconsistent popping: "
 				+ persistentClass.getEntityName() + " instead of " + stackTop.getEntityName() );
 		}
 	}
 
 	private PersistentClass getEntityWorkedOn() {
 		return stackOfPersistentClassesBeingProcessed.get(
 					stackOfPersistentClassesBeingProcessed.size() - 1
 			);
 	}
 
 	public PersistentClass getPersistentClassHostingProperties(MappedSuperclassTypeImpl<?> mappedSuperclassType) {
 		final PersistentClass persistentClass = mappedSuperClassTypeToPersistentClass.get( mappedSuperclassType );
 		if (persistentClass == null) {
 			throw new AssertionFailure( "Could not find PersistentClass for MappedSuperclassType: "
 					+ mappedSuperclassType.getJavaType() );
 		}
 		return persistentClass;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/AbstractJarVisitor.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/AbstractJarVisitor.java
index 2101df62f4..e2a48ae03f 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/AbstractJarVisitor.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/AbstractJarVisitor.java
@@ -1,259 +1,261 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.packaging;
 import java.io.DataInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 import javassist.bytecode.AnnotationsAttribute;
 import javassist.bytecode.ClassFile;
-import org.hibernate.ejb.EntityManagerLogger;
+
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * Parse a JAR of any form (zip file, exploded directory, ...)
  * apply a set of filters (File filter, Class filter, Package filter)
  * and return the appropriate matching sets of elements
  *
  * @author Emmanuel Bernard
  */
 public abstract class AbstractJarVisitor implements JarVisitor {
 
 	//TODO shortcut when filters are null or empty
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            AbstractJarVisitor.class.getName());
 
 	protected String unqualifiedJarName;
 	protected URL jarUrl;
 	protected boolean done = false;
 	private List<Filter> filters = new ArrayList<Filter>();
 	private Set<FileFilter> fileFilters = new HashSet<FileFilter>();
 	private Set<JavaElementFilter> classFilters = new HashSet<JavaElementFilter>();
 	private Set<JavaElementFilter> packageFilters = new HashSet<JavaElementFilter>();
 	private Set[] entries;
 
 
 
 	/**
 	 * Build a jar visitor from its jar string path
 	 */
 	private AbstractJarVisitor(String jarPath) {
 		this.jarUrl = JarVisitorFactory.getURLFromPath( jarPath );
 		unqualify();
 	}
 
 	protected AbstractJarVisitor(String fileName, Filter[] filters) {
 		this( fileName );
 		initFilters( filters );
 	}
 
 	private void initFilters(Filter[] filters) {
 		for ( Filter filter : filters ) {
 			if ( filter instanceof FileFilter ) {
 				fileFilters.add( (FileFilter) filter );
 			}
 			else if ( filter instanceof ClassFilter ) {
 				classFilters.add( (ClassFilter) filter );
 			}
 			else if ( filter instanceof PackageFilter ) {
 				packageFilters.add( (PackageFilter) filter );
 			}
 			else {
 				throw new AssertionError( "Unknown filter type: " + filter.getClass().getName() );
 			}
 			this.filters.add( filter );
 		}
 		int size = this.filters.size();
 		this.entries = new Set[ size ];
 		for ( int index = 0; index < size ; index++ ) {
 			this.entries[index] = new HashSet<Entry>();
 		}
 	}
 
 	protected AbstractJarVisitor(URL url, Filter[] filters) {
 		this( url );
 		initFilters( filters );
 	}
 
 	private AbstractJarVisitor(URL url) {
 		jarUrl = url;
 		unqualify();
 	}
 
 	protected void unqualify() {
 		//FIXME weak algorithm subject to AOOBE
 		String fileName = jarUrl.getFile();
 		int exclamation = fileName.lastIndexOf( "!" );
 		if (exclamation != -1) fileName = fileName.substring( 0, exclamation );
 		int slash = fileName.lastIndexOf( "/" );
 		if ( slash != -1 ) {
 			fileName = fileName.substring(
 					fileName.lastIndexOf( "/" ) + 1,
 					fileName.length()
 			);
 		}
 		if ( fileName.length() > 4 && fileName.endsWith( "ar" ) && fileName.charAt( fileName.length() - 4 ) == '.' ) {
 			fileName = fileName.substring( 0, fileName.length() - 4 );
 		}
 		unqualifiedJarName = fileName;
         LOG.debugf("Searching mapped entities in jar/par: %s", jarUrl);
 	}
 
 	/**
 	 * Get the unqualified Jar name (ie wo path and wo extension)
 	 */
 	public String getUnqualifiedJarName() {
 		return unqualifiedJarName;
 	}
 
 	public Filter[] getFilters() {
 		return filters.toArray( new Filter[ filters.size() ] );
 	}
 
 	/**
 	 * Return the matching entries for each filter in the same order the filter where passed
 	 *
 	 * @return array of Set of JarVisitor.Entry
 	 * @throws IOException if something went wrong
 	 */
 	public Set[] getMatchingEntries() throws IOException {
 		if ( !done ) {
 			//avoid url access and so on
 			if ( filters.size() > 0 ) doProcessElements();
 			done = true;
 		}
 		return entries;
 	}
 
 	protected abstract void doProcessElements() throws IOException;
 
 	//TODO avoid 2 input stream when not needed
 	protected final void addElement(String entryName, InputStream is, InputStream secondIs) throws IOException {
 		int entryNameLength = entryName.length();
 		if ( entryName.endsWith( "package-info.class" ) ) {
 			String name;
 			if ( entryNameLength == "package-info.class".length() ) {
 				name = "";
 			}
 			else {
 				name = entryName.substring( 0, entryNameLength - ".package-info.class".length() ).replace( '/', '.' );
 			}
 			executeJavaElementFilter( name, packageFilters, is, secondIs );
 		}
 		else if ( entryName.endsWith( ".class" ) ) {
 			String name = entryName.substring( 0, entryNameLength - ".class".length() ).replace( '/', '.' );
             LOG.debugf("Filtering: %s", name);
 			executeJavaElementFilter( name, classFilters, is, secondIs );
 		}
 		else {
 			String name = entryName;
 			boolean accepted = false;
 			for ( FileFilter filter : fileFilters ) {
 				if ( filter.accept( name ) ) {
 					accepted = true;
 					InputStream localIs;
 					if ( filter.getStream() ) {
 						localIs = secondIs;
 					}
 					else {
 						localIs = null;
 						secondIs.close();
 					}
 					is.close();
                     LOG.debugf("File Filter matched for %s", name);
 					Entry entry = new Entry( name, localIs );
 					int index = this.filters.indexOf( filter );
 					this.entries[index].add( entry );
 				}
 			}
 			if (!accepted) {
 				//not accepted free resources
 				is.close();
 				secondIs.close();
 			}
 		}
 	}
 
 	private void executeJavaElementFilter(
 			String name, Set<JavaElementFilter> filters, InputStream is, InputStream secondIs
 	) throws IOException {
 		boolean accepted = false;
 		for ( JavaElementFilter filter : filters ) {
 			if ( filter.accept( name ) ) {
 				//FIXME cannot currently have a class filtered twice but matching once
 				// need to copy the is
 				boolean match = checkAnnotationMatching( is, filter );
 				if ( match ) {
 					accepted = true;
 					InputStream localIs;
 					if ( filter.getStream() ) {
 						localIs = secondIs;
 					}
 					else {
 						localIs = null;
 						secondIs.close();
 					}
                     LOG.debugf("Java element filter matched for %s", name);
 					Entry entry = new Entry( name, localIs );
 					int index = this.filters.indexOf( filter );
 					this.entries[index].add( entry );
 					break; //we matched
 				}
 			}
 		}
 		if (!accepted) {
 			is.close();
 			secondIs.close();
 		}
 	}
 
 	private boolean checkAnnotationMatching(InputStream is, JavaElementFilter filter) throws IOException {
 		if ( filter.getAnnotations().length == 0 ) {
 			is.close();
 			return true;
 		}
 		DataInputStream dstream = new DataInputStream( is );
 		ClassFile cf = null;
 
 		try {
 			cf = new ClassFile( dstream );
 		}
 		finally {
 			dstream.close();
 			is.close();
 		}
 		boolean match = false;
 		AnnotationsAttribute visible = (AnnotationsAttribute) cf.getAttribute( AnnotationsAttribute.visibleTag );
 		if ( visible != null ) {
 			for ( Class annotation : filter.getAnnotations() ) {
 				match = visible.getAnnotation( annotation.getName() ) != null;
 				if ( match ) break;
 			}
 		}
 		return match;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/ExplodedJarVisitor.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/ExplodedJarVisitor.java
index c969502add..bfcdc45b26 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/ExplodedJarVisitor.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/ExplodedJarVisitor.java
@@ -1,135 +1,137 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.packaging;
 import java.io.BufferedInputStream;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.IOException;
 import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.Enumeration;
 import java.util.jar.JarFile;
 import java.util.zip.ZipEntry;
-import org.hibernate.ejb.EntityManagerLogger;
+
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
+
 import org.jboss.logging.Logger;
 
 
 /**
  * @author Emmanuel Bernard
  */
 public class ExplodedJarVisitor extends AbstractJarVisitor {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            ExplodedJarVisitor.class.getName());
 
     private String entry;
 
 	public ExplodedJarVisitor(URL url, Filter[] filters, String entry) {
 		super( url, filters );
 		this.entry = entry;
 	}
 
 	public ExplodedJarVisitor(String fileName, Filter[] filters) {
 		super( fileName, filters );
 	}
 
 	@Override
     protected void doProcessElements() throws IOException {
 		File jarFile;
 		try {
 			String filePart = jarUrl.getFile();
 			if ( filePart != null && filePart.indexOf( ' ' ) != -1 ) {
 				//unescaped (from the container), keep as is
 				jarFile = new File( jarUrl.getFile() );
 			}
 			else {
 				jarFile = new File( jarUrl.toURI().getSchemeSpecificPart() );
 			}
 		}
 		catch (URISyntaxException e) {
             LOG.malformedUrl(jarUrl, e);
 			return;
 		}
 
 		if ( !jarFile.exists() ) {
             LOG.explodedJarDoesNotExist(jarUrl);
 			return;
 		}
 		if ( !jarFile.isDirectory() ) {
             LOG.explodedJarNotDirectory(jarUrl);
 			return;
 		}
 		File rootFile;
 		if (entry != null && entry.length() > 0 && ! "/".equals( entry ) ) {
 			rootFile = new File(jarFile, entry);
 		}
 		else {
 			rootFile = jarFile;
 		}
 		if ( rootFile.isDirectory() ) {
 			getClassNamesInTree( rootFile, null );
 		}
 		else {
 			//assume zipped file
 			processZippedRoot(rootFile);
 		}
 	}
 
 	//FIXME shameful copy of FileZippedJarVisitor.doProcess()
 	//TODO long term fix is to introduce a process interface (closure like) to addElements and then share the code
 	private void processZippedRoot(File rootFile) throws IOException {
 		JarFile jarFile = new JarFile(rootFile);
 		Enumeration<? extends ZipEntry> entries = jarFile.entries();
 		while ( entries.hasMoreElements() ) {
 			ZipEntry zipEntry = entries.nextElement();
 			String name = zipEntry.getName();
 			if ( !zipEntry.isDirectory() ) {
 				//build relative name
 				if ( name.startsWith( "/" ) ) name = name.substring( 1 );
 				addElement(
 						name,
 						new BufferedInputStream( jarFile.getInputStream( zipEntry ) ),
 						new BufferedInputStream( jarFile.getInputStream( zipEntry ) )
 				);
 			}
 		}
 	}
 
 	private void getClassNamesInTree(File jarFile, String header) throws IOException {
 		File[] files = jarFile.listFiles();
 		header = header == null ? "" : header + "/";
 		for ( File localFile : files ) {
 			if ( !localFile.isDirectory() ) {
 				String entryName = localFile.getName();
 				addElement(
 						header + entryName,
 						new BufferedInputStream( new FileInputStream( localFile ) ),
 						new BufferedInputStream( new FileInputStream( localFile ) )
 				);
 
 			}
 			else {
 				getClassNamesInTree( localFile, header + localFile.getName() );
 			}
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/FileZippedJarVisitor.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/FileZippedJarVisitor.java
index a305a9099d..660932335c 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/FileZippedJarVisitor.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/FileZippedJarVisitor.java
@@ -1,130 +1,132 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.packaging;
 import java.io.BufferedInputStream;
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.Enumeration;
 import java.util.jar.JarFile;
 import java.util.jar.JarInputStream;
 import java.util.zip.ZipEntry;
-import org.hibernate.ejb.EntityManagerLogger;
+
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
+
 import org.jboss.logging.Logger;
 
 /**
  * Work on a JAR that can be accessed through a File
  *
  * @author Emmanuel Bernard
  */
 public class FileZippedJarVisitor extends AbstractJarVisitor {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            FileZippedJarVisitor.class.getName());
 
     private String entry;
 
 	public FileZippedJarVisitor(String fileName, Filter[] filters) {
 		super( fileName, filters );
 	}
 
 	public FileZippedJarVisitor(URL url, Filter[] filters, String entry) {
 		super( url, filters );
 		this.entry = entry;
 	}
 
 	@Override
     protected void doProcessElements() throws IOException {
 		JarFile jarFile;
 		try {
 			String filePart = jarUrl.getFile();
 			if ( filePart != null && filePart.indexOf( ' ' ) != -1 ) {
 				//unescaped (from the container), keep as is
 				jarFile = new JarFile( jarUrl.getFile() );
 			}
 			else {
 				jarFile = new JarFile( jarUrl.toURI().getSchemeSpecificPart() );
 			}
 		}
 		catch (IOException ze) {
             LOG.unableToFindFile(jarUrl, ze);
 			return;
 		}
 		catch (URISyntaxException e) {
             LOG.malformedUrlWarning(jarUrl, e);
 			return;
 		}
 
 		if ( entry != null && entry.length() == 1 ) entry = null; //no entry
 		if ( entry != null && entry.startsWith( "/" ) ) entry = entry.substring( 1 ); //remove '/' header
 
 		Enumeration<? extends ZipEntry> entries = jarFile.entries();
 		while ( entries.hasMoreElements() ) {
 			ZipEntry zipEntry = entries.nextElement();
 			String name = zipEntry.getName();
 			if ( entry != null && ! name.startsWith( entry ) ) continue; //filter it out
 			if ( !zipEntry.isDirectory() ) {
 				if ( name.equals( entry ) ) {
 					//exact match, might be a nested jar entry (ie from jar:file:..../foo.ear!/bar.jar)
 					/*
 					 * This algorithm assumes that the zipped file is only the URL root (including entry), not just any random entry
 					 */
 					InputStream is = null;
 					try {
 						is = new BufferedInputStream( jarFile.getInputStream( zipEntry ) );
 						JarInputStream jis = new JarInputStream( is );
 						ZipEntry subZipEntry = jis.getNextEntry();
 						while (subZipEntry != null) {
 							if ( ! subZipEntry.isDirectory() ) {
 								//FIXME copy sucks
 								byte[] entryBytes = JarVisitorFactory.getBytesFromInputStream( jis );
 								String subname = subZipEntry.getName();
 								if ( subname.startsWith( "/" ) ) subname = subname.substring( 1 );
 								addElement(
 										subname,
 										new ByteArrayInputStream(entryBytes),
 										new ByteArrayInputStream(entryBytes)
 								);
 							}
 							subZipEntry = jis.getNextEntry();
 						}
 					}
 					finally {
 						if ( is != null) is.close();
 					}
 				}
 				else {
 					//build relative name
 					if (entry != null) name = name.substring( entry.length() );
 					if ( name.startsWith( "/" ) ) name = name.substring( 1 );
 					addElement(
 							name,
 							new BufferedInputStream( jarFile.getInputStream( zipEntry ) ),
 							new BufferedInputStream( jarFile.getInputStream( zipEntry ) )
 					);
 				}
 			}
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/InputStreamZippedJarVisitor.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/InputStreamZippedJarVisitor.java
index 06e0156848..1674f1ede0 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/InputStreamZippedJarVisitor.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/InputStreamZippedJarVisitor.java
@@ -1,118 +1,119 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.packaging;
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.net.URL;
 import java.util.jar.JarEntry;
 import java.util.jar.JarInputStream;
 import java.util.zip.ZipEntry;
-import org.hibernate.ejb.EntityManagerLogger;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
+
 import org.jboss.logging.Logger;
 
 
 /**
  * Work on a JAR that can only be accessed through a inputstream
  * This is less efficient than the {@link FileZippedJarVisitor}
  *
  * @author Emmanuel Bernard
  */
 public class InputStreamZippedJarVisitor extends AbstractJarVisitor {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            InputStreamZippedJarVisitor.class.getName());
 
     private String entry;
 
 	public InputStreamZippedJarVisitor(URL url, Filter[] filters, String entry) {
 		super( url, filters );
 		this.entry = entry;
 	}
 
 	public InputStreamZippedJarVisitor(String fileName, Filter[] filters) {
 		super( fileName, filters );
 	}
 
 	@Override
     protected void doProcessElements() throws IOException {
 		JarInputStream jis;
 		try {
 			jis = new JarInputStream( jarUrl.openStream() );
 		}
 		catch (Exception ze) {
 			//really should catch IOException but Eclipse is buggy and raise NPE...
             LOG.unableToFindFile(jarUrl, ze);
 			return;
 		}
 		if ( entry != null && entry.length() == 1 ) entry = null; //no entry
 		if ( entry != null && entry.startsWith( "/" ) ) entry = entry.substring( 1 ); //remove '/' header
 
 		JarEntry jarEntry;
 		while ( ( jarEntry = jis.getNextJarEntry() ) != null ) {
 			String name = jarEntry.getName();
 			if ( entry != null && ! name.startsWith( entry ) ) continue; //filter it out
 			if ( !jarEntry.isDirectory() ) {
 				if ( name.equals( entry ) ) {
 					//exact match, might be a nested jar entry (ie from jar:file:..../foo.ear!/bar.jar)
 					/*
 					 * This algorithm assumes that the zipped file is only the URL root (including entry), not just any random entry
 					 */
 					JarInputStream subJis = null;
 					try {
 						subJis = new JarInputStream( jis );
 						ZipEntry subZipEntry = jis.getNextEntry();
 						while (subZipEntry != null) {
 							if ( ! subZipEntry.isDirectory() ) {
 								//FIXME copy sucks
 								byte[] entryBytes = JarVisitorFactory.getBytesFromInputStream( jis );
 								String subname = subZipEntry.getName();
 								if ( subname.startsWith( "/" ) ) subname = subname.substring( 1 );
 								addElement(
 										subname,
 										new ByteArrayInputStream(entryBytes),
 										new ByteArrayInputStream(entryBytes)
 								);
 							}
 							subZipEntry = jis.getNextJarEntry();
 						}
 					}
 					finally {
 						if (subJis != null) subJis.close();
 					}
 				}
 				else {
 					byte[] entryBytes = JarVisitorFactory.getBytesFromInputStream( jis );
 					//build relative name
 					if (entry != null) name = name.substring( entry.length() );
 					if ( name.startsWith( "/" ) ) name = name.substring( 1 );
 					//this is bad cause we actually read everything instead of walking it lazily
 					addElement(
 							name,
 							new ByteArrayInputStream( entryBytes ),
 							new ByteArrayInputStream( entryBytes )
 					);
 				}
 			}
 		}
 		jis.close();
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/JarVisitorFactory.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/JarVisitorFactory.java
index 424457ebb0..8e65dc5b3b 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/JarVisitorFactory.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/JarVisitorFactory.java
@@ -1,199 +1,200 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.packaging;
 
 import java.io.File;
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.MalformedURLException;
 import java.net.URISyntaxException;
 import java.net.URL;
-import org.hibernate.ejb.EntityManagerLogger;
+
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 public class JarVisitorFactory {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            JarVisitorFactory.class.getName());
 
 	/**
 	 * Get the JAR URL of the JAR containing the given entry
 	 * Method used in a non managed environment
 	 *
 	 * @param url URL pointing to the known file in the JAR
 	 * @param entry file known to be in the JAR
 	 * @return the JAR URL
 	 * @throws IllegalArgumentException if none URL is found
 	 * TODO move to a ScannerHelper service?
 	 */
 	public static URL getJarURLFromURLEntry(URL url, String entry) throws IllegalArgumentException {
 		URL jarUrl;
 		String file = url.getFile();
 		if ( ! entry.startsWith( "/" ) ) entry = "/" + entry;
 		file = file.substring( 0, file.length() - entry.length() );
 		if ( file.endsWith( "!" ) ) file = file.substring( 0, file.length() - 1 );
 		try {
 			String protocol = url.getProtocol();
 
 			if ( "jar".equals( protocol )
 					|| "wsjar".equals( protocol ) ) { //Websphere has it's own way
 				//Original URL is like jar:protocol
 				jarUrl = new URL( file );
 				if ( "file".equals( jarUrl.getProtocol() ) ) {
 					//not escaped, need to voodoo
 					if ( file.indexOf( ' ' ) != -1 ) {
 						//not escaped, need to voodoo
 						jarUrl = new File( jarUrl.getFile() ).toURI().toURL(); //goes by toURI to escape the path
 					}
 				} //otherwise left as is
 			}
 			else if ( "zip".equals( protocol ) //Weblogic has it's own way
 					|| "code-source".equals( url.getProtocol() ) //OC4J prevent ejb.jar access (ie everything without path)
 					|| "file".equals( protocol )  //if no wrapping is done
 					) {
 				//we have extracted the zip file, so it should be read as a file
 				if ( file.indexOf( ' ' ) != -1 ) {
 					//not escaped, need to voodoo
 					jarUrl = new File(file).toURI().toURL(); //goes by toURI to escape the path
 				}
 				else {
 					jarUrl = new File(file).toURL();
 				}
 			}
 			else {
 				jarUrl = new URL( protocol, url.getHost(), url.getPort(), file );
 			}
 		}
 		catch (MalformedURLException e) {
 			throw new IllegalArgumentException(
 					"Unable to determine JAR Url from " + url + ". Cause: " + e.getMessage()
 			);
 		}
         LOG.trace("JAR URL from URL Entry: " + url + " >> " + jarUrl);
 		return jarUrl;
 	}
 
 	/**
 	 * get the URL from a given path string
 	 *
 	 * @throws IllegalArgumentException is something goes wrong
 	 * TODO move to a ScannerHelper service?
 	 */
 	public static URL getURLFromPath(String jarPath) {
 		URL jarUrl;
 		try {
 			//is it an url
 			jarUrl = new URL( jarPath );
 		}
 		catch ( MalformedURLException e) {
 			try {
 				//consider it as a file path
 				jarUrl = new URL( "file:" + jarPath );
 			}
 			catch (MalformedURLException ee) {
 				throw new IllegalArgumentException( "Unable to find jar:" + jarPath, ee );
 			}
 		}
 		return jarUrl;
 	}
 
 	/**
 	 * Get a JarVisitor to the jar <code>jarPath</code> applying the given filters
 	 *
 	 * Method used in a non-managed environment
 	 *
 	 * @throws IllegalArgumentException if the jarPath is incorrect
 	 */
 	public static JarVisitor getVisitor(String jarPath, Filter[] filters) throws IllegalArgumentException {
 		File file = new File( jarPath );
 		if ( file.isFile() ) {
 			return new InputStreamZippedJarVisitor( jarPath, filters );
 		}
 		else {
 			return new ExplodedJarVisitor( jarPath, filters );
 		}
 	}
 
 	/**
 	 * Build a JarVisitor on the given JAR URL applying the given filters
 	 *
 	 * @throws IllegalArgumentException if the URL is malformed
 	 */
 	public static JarVisitor getVisitor(URL jarUrl, Filter[] filters) throws IllegalArgumentException {
 		return getVisitor( jarUrl, filters, "" );
 	}
 
 	public static JarVisitor getVisitor(URL jarUrl, Filter[] filters, String entry) throws IllegalArgumentException {
 		String protocol = jarUrl.getProtocol();
 		if ( "jar".equals( protocol ) ) {
 			return new JarProtocolVisitor( jarUrl, filters, entry );
 		}
 		else if ( StringHelper.isEmpty( protocol ) || "file".equals( protocol ) ) {
 			File file;
 			try {
 				final String filePart = jarUrl.getFile();
 				if ( filePart != null && filePart.indexOf( ' ' ) != -1 ) {
 					//unescaped (from the container), keep as is
 					file = new File( jarUrl.getFile() );
 				}
 				else {
 					file = new File( jarUrl.toURI().getSchemeSpecificPart() );
 				}
 			}
 			catch (URISyntaxException e) {
 				throw new IllegalArgumentException(
 						"Unable to visit JAR " + jarUrl + ". Cause: " + e.getMessage(), e
 				);
 			}
 
 			if ( file.isDirectory() ) {
 				return new ExplodedJarVisitor( jarUrl, filters, entry );
 			}
 			else {
 				return new FileZippedJarVisitor( jarUrl, filters, entry );
 			}
 		}
 		else {
 			//let's assume the url can return the jar as a zip stream
 			return new InputStreamZippedJarVisitor( jarUrl, filters, entry );
 		}
 	}
 
 	public static byte[] getBytesFromInputStream(InputStream inputStream) throws IOException {
 		int size;
 		byte[] tmpByte = new byte[ 4096 ];
 		byte[] entryBytes = new byte[0];
 		for ( ; ; ) {
 			size = inputStream.read( tmpByte );
 			if ( size == -1 ) break;
 			byte[] current = new byte[ entryBytes.length + size ];
 			System.arraycopy( entryBytes, 0, current, 0, entryBytes.length );
 			System.arraycopy( tmpByte, 0, current, entryBytes.length, size );
 			entryBytes = current;
 		}
 		return entryBytes;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/PersistenceXmlLoader.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/PersistenceXmlLoader.java
index 20fe41e023..df60ffc6e9 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/PersistenceXmlLoader.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/packaging/PersistenceXmlLoader.java
@@ -1,347 +1,347 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.packaging;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.URL;
 import java.net.URLConnection;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import javax.persistence.PersistenceException;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.xml.parsers.DocumentBuilder;
 import javax.xml.parsers.DocumentBuilderFactory;
 import javax.xml.transform.dom.DOMSource;
 import javax.xml.transform.stream.StreamSource;
 import javax.xml.validation.Schema;
 import javax.xml.validation.SchemaFactory;
 import javax.xml.validation.Validator;
 import org.hibernate.ejb.AvailableSettings;
-import org.hibernate.ejb.EntityManagerLogger;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.ejb.util.ConfigurationHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.jboss.logging.Logger;
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 import org.xml.sax.EntityResolver;
 import org.xml.sax.ErrorHandler;
 import org.xml.sax.InputSource;
 import org.xml.sax.SAXParseException;
 
 /**
  * Handler for persistence.xml files.
  *
  * @author <a href="mailto:bill@jboss.org">Bill Burke</a>
  * @author Emmanuel Bernard
  */
 public final class PersistenceXmlLoader {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            PersistenceXmlLoader.class.getName());
 
 	private PersistenceXmlLoader() {
 	}
 
 	private static Document loadURL(URL configURL, EntityResolver resolver) throws Exception {
 		/*
 		 * try and parse the document:
 		 *  - try and validate the document with persistence_2_0.xsd
 		  * - if it fails because of the version attribute mismatch, try and validate the document with persistence_1_0.xsd
 		 */
 		InputStream is = null;
 		if (configURL != null) {
 			URLConnection conn = configURL.openConnection();
 			conn.setUseCaches( false ); //avoid JAR locking on Windows and Tomcat
 			is = conn.getInputStream();
 		}
 		if ( is == null ) {
 			throw new IOException( "Failed to obtain InputStream while reading persistence.xml file: " + configURL );
 		}
 
 		DocumentBuilderFactory docBuilderFactory = DocumentBuilderFactory.newInstance();
 		docBuilderFactory.setNamespaceAware( true );
 		final Schema v2Schema = SchemaFactory.newInstance( javax.xml.XMLConstants.W3C_XML_SCHEMA_NS_URI )
 				.newSchema( new StreamSource( getStreamFromClasspath( "persistence_2_0.xsd" ) ) );
 		final Validator v2Validator = v2Schema.newValidator();
 		final Schema v1Schema = SchemaFactory.newInstance( javax.xml.XMLConstants.W3C_XML_SCHEMA_NS_URI )
 				.newSchema( new StreamSource( getStreamFromClasspath( "persistence_1_0.xsd" ) ) );
 		final Validator v1Validator = v1Schema.newValidator();
 
 		InputSource source = new InputSource( is );
 		DocumentBuilder docBuilder = docBuilderFactory.newDocumentBuilder();
 		docBuilder.setEntityResolver( resolver );
 		List<SAXParseException> errors = new ArrayList<SAXParseException>();
 		Document doc = null;
 
 		//first sparse document and collect syntaxic errors
 		try {
 			doc = docBuilder.parse( source );
 		}
 		catch ( SAXParseException e ) {
 			errors.add( e );
 		}
 
 		if (errors.size() == 0) {
 			v2Validator.setErrorHandler( new ErrorLogger( errors ) );
             LOG.trace("Validate with persistence_2_0.xsd schema on file " + configURL);
 			v2Validator.validate( new DOMSource( doc ) );
 			boolean isV1Schema = false;
 			if ( errors.size() != 0 ) {
 				//v2 fails, it could be because the file is v1.
                 LOG.trace("Found error with persistence_2_0.xsd schema on file " + configURL);
 				SAXParseException exception = errors.get( 0 );
 				final String errorMessage = exception.getMessage();
 				//is it a validation error due to a v1 schema validated by a v2
 				isV1Schema = errorMessage.contains("1.0")
 						&& errorMessage.contains("2.0")
 						&& errorMessage.contains("version");
 
 			}
 			if (isV1Schema) {
                 LOG.trace("Validate with persistence_1_0.xsd schema on file " + configURL);
 				errors.clear();
 				v1Validator.setErrorHandler( new ErrorLogger( errors ) );
 				v1Validator.validate( new DOMSource( doc ) );
 			}
 		}
 		if ( errors.size() != 0 ) {
 			//report all errors in the exception
 			StringBuilder errorMessage = new StringBuilder( );
 			for (SAXParseException error : errors) {
 				errorMessage.append("Error parsing XML (line")
 							.append(error.getLineNumber())
 							.append(" : column ")
 							.append(error.getColumnNumber())
 							.append("): ")
 							.append(error.getMessage())
 							.append("\n");
 			}
 			throw new PersistenceException( "Invalid persistence.xml.\n" + errorMessage.toString() );
 		}
 		return doc;
 	}
 
 	private static InputStream getStreamFromClasspath(String fileName) {
 		String path = "org/hibernate/ejb/" + fileName;
 		InputStream dtdStream = PersistenceXmlLoader.class.getClassLoader().getResourceAsStream( path );
 		return dtdStream;
 	}
 
 	/**
      * Method used by JBoss AS 4.0.5 for parsing
      */
 	public static List<PersistenceMetadata> deploy(URL url, Map overrides, EntityResolver resolver) throws Exception {
         return deploy(url, overrides, resolver, PersistenceUnitTransactionType.JTA);
     }
 
 	/**
 	 * Method used by JBoss EJB3 (4.2 and above) for parsing
 	 * Object used by Hibernate OGM as well, consider this some kind of exposed service at the SPI level
 	 */
     public static List<PersistenceMetadata> deploy(URL url, Map overrides, EntityResolver resolver,
 												   PersistenceUnitTransactionType defaultTransactionType) throws Exception {
 		Document doc = loadURL( url, resolver );
 		Element top = doc.getDocumentElement();
 		//version is mandatory
 		final String version = top.getAttribute( "version" );
 
 		NodeList children = top.getChildNodes();
 		ArrayList<PersistenceMetadata> units = new ArrayList<PersistenceMetadata>();
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			if ( children.item( i ).getNodeType() == Node.ELEMENT_NODE ) {
 				Element element = (Element) children.item( i );
 				String tag = element.getTagName();
 				if ( tag.equals( "persistence-unit" ) ) {
 					PersistenceMetadata metadata = parsePersistenceUnit( element );
 					metadata.setVersion(version);
 					//override properties of metadata if needed
 					if ( overrides.containsKey( AvailableSettings.PROVIDER ) ) {
 						String provider = (String) overrides.get( AvailableSettings.PROVIDER );
 						metadata.setProvider( provider );
 					}
 					if ( overrides.containsKey( AvailableSettings.TRANSACTION_TYPE ) ) {
 						String transactionType = (String) overrides.get( AvailableSettings.TRANSACTION_TYPE );
 						metadata.setTransactionType( PersistenceXmlLoader.getTransactionType( transactionType ) );
 					}
 					if ( overrides.containsKey( AvailableSettings.JTA_DATASOURCE ) ) {
 						String dataSource = (String) overrides.get( AvailableSettings.JTA_DATASOURCE );
 						metadata.setJtaDatasource( dataSource );
 					}
 					if ( overrides.containsKey( AvailableSettings.NON_JTA_DATASOURCE ) ) {
 						String dataSource = (String) overrides.get( AvailableSettings.NON_JTA_DATASOURCE );
 						metadata.setNonJtaDatasource( dataSource );
 					}
 					/*
 					 * if explicit => use it
 					 * if JTA DS => JTA transaction
 					 * if non JTA DA => RESOURCE_LOCAL transaction
 					 * else default JavaSE => RESOURCE_LOCAL
 					 */
 					PersistenceUnitTransactionType transactionType = metadata.getTransactionType();
 					Boolean isJTA = null;
 					if ( StringHelper.isNotEmpty( metadata.getJtaDatasource() ) ) {
 						isJTA = Boolean.TRUE;
 					}
 					else if ( StringHelper.isNotEmpty( metadata.getNonJtaDatasource() ) ) {
 						isJTA = Boolean.FALSE;
 					}
 					if (transactionType == null) {
 						if (isJTA == Boolean.TRUE) {
 							transactionType = PersistenceUnitTransactionType.JTA;
 						}
 						else if (isJTA == Boolean.FALSE) {
 							transactionType = PersistenceUnitTransactionType.RESOURCE_LOCAL;
 						}
 						else {
 							transactionType = defaultTransactionType;
 						}
 					}
 					metadata.setTransactionType( transactionType );
 					Properties properties = metadata.getProps();
 					ConfigurationHelper.overrideProperties( properties, overrides );
 					units.add( metadata );
 				}
 			}
 		}
 		return units;
 	}
 
 	private static PersistenceMetadata parsePersistenceUnit(Element top)
 			throws Exception {
 		PersistenceMetadata metadata = new PersistenceMetadata();
 		String puName = top.getAttribute( "name" );
 		if ( StringHelper.isNotEmpty( puName ) ) {
             LOG.trace("Persistent Unit name from persistence.xml: " + puName);
 			metadata.setName( puName );
 		}
 		NodeList children = top.getChildNodes();
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			if ( children.item( i ).getNodeType() == Node.ELEMENT_NODE ) {
 				Element element = (Element) children.item( i );
 				String tag = element.getTagName();
 //				if ( tag.equals( "name" ) ) {
 //					String puName = XmlHelper.getElementContent( element );
 //					log.trace( "FOUND PU NAME: " + puName );
 //					metadata.setName( puName );
 //				}
 //				else
 				if ( tag.equals( "non-jta-data-source" ) ) {
 					metadata.setNonJtaDatasource( XmlHelper.getElementContent( element ) );
 				}
 				else if ( tag.equals( "jta-data-source" ) ) {
 					metadata.setJtaDatasource( XmlHelper.getElementContent( element ) );
 				}
 				else if ( tag.equals( "provider" ) ) {
 					metadata.setProvider( XmlHelper.getElementContent( element ) );
 				}
 				else if ( tag.equals( "class" ) ) {
 					metadata.getClasses().add( XmlHelper.getElementContent( element ) );
 				}
 				else if ( tag.equals( "mapping-file" ) ) {
 					metadata.getMappingFiles().add( XmlHelper.getElementContent( element ) );
 				}
 				else if ( tag.equals( "jar-file" ) ) {
 					metadata.getJarFiles().add( XmlHelper.getElementContent( element ) );
 				}
 				else if ( tag.equals( "exclude-unlisted-classes" ) ) {
 					metadata.setExcludeUnlistedClasses( true );
 				}
 				else if ( tag.equals( "delimited-identifiers" ) ) {
 					metadata.setUseQuotedIdentifiers( true );
 				}
 				else if ( tag.equals( "validation-mode" ) ) {
 					metadata.setValidationMode( XmlHelper.getElementContent( element ) );
 				}
 				else if ( tag.equals( "shared-cache-mode" ) ) {
 					metadata.setSharedCacheMode( XmlHelper.getElementContent( element ) );
 				}
 				else if ( tag.equals( "properties" ) ) {
 					NodeList props = element.getChildNodes();
 					for ( int j = 0; j < props.getLength() ; j++ ) {
 						if ( props.item( j ).getNodeType() == Node.ELEMENT_NODE ) {
 							Element propElement = (Element) props.item( j );
 							if ( !"property".equals( propElement.getTagName() ) ) continue;
 							String propName = propElement.getAttribute( "name" ).trim();
 							String propValue = propElement.getAttribute( "value" ).trim();
 							if ( StringHelper.isEmpty( propValue ) ) {
 								//fall back to the natural (Hibernate) way of description
 								propValue = XmlHelper.getElementContent( propElement, "" );
 							}
 							metadata.getProps().put( propName, propValue );
 						}
 					}
 
 				}
 			}
 		}
 		PersistenceUnitTransactionType transactionType = getTransactionType( top.getAttribute( "transaction-type" ) );
 		if (transactionType != null) metadata.setTransactionType( transactionType );
 
 		return metadata;
 	}
 
 	public static PersistenceUnitTransactionType getTransactionType(String elementContent) {
 		if ( StringHelper.isEmpty( elementContent ) ) {
 			return null; //PersistenceUnitTransactionType.JTA;
 		}
 		else if ( elementContent.equalsIgnoreCase( "JTA" ) ) {
 			return PersistenceUnitTransactionType.JTA;
 		}
 		else if ( elementContent.equalsIgnoreCase( "RESOURCE_LOCAL" ) ) {
 			return PersistenceUnitTransactionType.RESOURCE_LOCAL;
 		}
 		else {
 			throw new PersistenceException( "Unknown TransactionType: " + elementContent );
 		}
 	}
 
 	public static class ErrorLogger implements ErrorHandler {
 		private List<SAXParseException> errors;
 
 		ErrorLogger(List<SAXParseException> errors) {
 			this.errors = errors;
 		}
 
 		public void error(SAXParseException error) {
 			//what was this commented code about?
 //			if ( resolver instanceof EJB3DTDEntityResolver ) {
 //				if ( ( (EJB3DTDEntityResolver) resolver ).isResolved() == false ) return;
 //			}
 			errors.add( error );
 		}
 
 		public void fatalError(SAXParseException error) {
 			errors.add( error );
 		}
 
 		public void warning(SAXParseException warn) {
 		}
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/util/NamingHelper.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/util/NamingHelper.java
index 823666a860..c54bd07227 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/util/NamingHelper.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/util/NamingHelper.java
@@ -1,93 +1,93 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.util;
 import javax.naming.Context;
 import javax.naming.InvalidNameException;
 import javax.naming.NamingException;
 import javax.naming.event.EventContext;
 import javax.naming.event.NamespaceChangeListener;
 import javax.naming.event.NamingEvent;
 import javax.naming.event.NamingExceptionEvent;
 import javax.naming.event.NamingListener;
 import org.hibernate.ejb.AvailableSettings;
 import org.hibernate.ejb.Ejb3Configuration;
-import org.hibernate.ejb.EntityManagerLogger;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.internal.util.jndi.JndiHelper;
 import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 public class NamingHelper {
 	private NamingHelper() {}
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class, NamingHelper.class.getName());
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class, NamingHelper.class.getName());
 
 	/** bind the configuration to the JNDI */
 	public static void bind(Ejb3Configuration cfg) {
 		String name = cfg.getHibernateConfiguration().getProperty( AvailableSettings.CONFIGURATION_JNDI_NAME );
         if (name == null) LOG.debugf("No JNDI name configured for binding Ejb3Configuration");
 		else {
             LOG.ejb3ConfigurationName(name);
 
 			try {
 				Context ctx = JndiHelper.getInitialContext( cfg.getProperties() );
 				JndiHelper.bind( ctx, name, cfg );
                 LOG.boundEjb3ConfigurationToJndiName(name);
 				( (EventContext) ctx ).addNamingListener( name, EventContext.OBJECT_SCOPE, LISTENER );
 			}
 			catch (InvalidNameException ine) {
                 LOG.invalidJndiName(name, ine);
 			}
 			catch (NamingException ne) {
                 LOG.unableToBindEjb3ConfigurationToJndi(ne);
 			}
 			catch (ClassCastException cce) {
                 LOG.initialContextDoesNotImplementEventContext();
 			}
 		}
 	}
 
 	private static final NamingListener LISTENER = new NamespaceChangeListener() {
 		public void objectAdded(NamingEvent evt) {
             LOG.debugf("An Ejb3Configuration was successfully bound to name: %s", evt.getNewBinding().getName());
 		}
 
 		public void objectRemoved(NamingEvent evt) {
 			String name = evt.getOldBinding().getName();
             LOG.ejb3ConfigurationUnboundFromName(name);
 		}
 
 		public void objectRenamed(NamingEvent evt) {
 			String name = evt.getOldBinding().getName();
             LOG.ejb3ConfigurationRenamedFromName(name);
 		}
 
 		public void namingExceptionThrown(NamingExceptionEvent evt) {
             LOG.unableToAccessEjb3Configuration(evt.getException());
 		}
 	};
 
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/engine/EJB3CascadingAction.java b/hibernate-entitymanager/src/main/java/org/hibernate/engine/EJB3CascadingAction.java
index 419923b196..eec651ee77 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/engine/EJB3CascadingAction.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/engine/EJB3CascadingAction.java
@@ -1,70 +1,70 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 import java.util.Iterator;
 import java.util.Map;
 import org.hibernate.HibernateException;
-import org.hibernate.ejb.EntityManagerLogger;
+import org.hibernate.ejb.internal.EntityManagerMessageLogger;
 import org.hibernate.event.EventSource;
 import org.hibernate.type.CollectionType;
 import org.jboss.logging.Logger;
 
 /**
  * Because of CascadingAction constructor visibility
  * I need a packaged friendly subclass
  * TODO Get rid of it for 3.3
  * @author Emmanuel Bernard
  */
 public abstract class EJB3CascadingAction extends CascadingAction {
 
-    private static final EntityManagerLogger LOG = Logger.getMessageLogger(EntityManagerLogger.class,
+    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            EJB3CascadingAction.class.getName());
 	/**
 	 * @see org.hibernate.Session#persist(Object)
 	 */
 	public static final CascadingAction PERSIST_SKIPLAZY = new CascadingAction() {
 		@Override
         public void cascade(EventSource session, Object child, String entityName, Object anything, boolean isCascadeDeleteEnabled)
 		throws HibernateException {
             LOG.trace("Cascading to persist: " + entityName);
 			session.persist( entityName, child, (Map) anything );
 		}
 		@Override
         public Iterator getCascadableChildrenIterator(EventSource session, CollectionType collectionType, Object collection) {
 			// persists don't cascade to uninitialized collections
 			return CascadingAction.getLoadedElementsIterator( session, collectionType, collection );
 		}
 		@Override
         public boolean deleteOrphans() {
 			return false;
 		}
 		@Override
         public boolean performOnLazyProperty() {
 			return false;
 		}
 		@Override
         public String toString() {
 			return "ACTION_PERSIST_SKIPLAZY";
 		}
 	};
 
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/BaseEntityManagerFunctionalTestCase.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/BaseEntityManagerFunctionalTestCase.java
index b8d1a55e64..fcaed74ce6 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/BaseEntityManagerFunctionalTestCase.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/BaseEntityManagerFunctionalTestCase.java
@@ -1,284 +1,286 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.test;
 
 import javax.persistence.EntityManager;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.Persistence;
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Properties;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.ejb.AvailableSettings;
 import org.hibernate.ejb.Ejb3Configuration;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 import org.junit.After;
 import org.junit.Before;
 
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 
-import static org.hibernate.testing.TestLogger.LOG;
-
 /**
  * A base class for all ejb tests.
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 public abstract class BaseEntityManagerFunctionalTestCase extends BaseUnitTestCase {
+	private static final Logger log = Logger.getLogger( BaseEntityManagerFunctionalTestCase.class );
+
 	// IMPL NOTE : Here we use @Before and @After (instead of @BeforeClassOnce and @AfterClassOnce like we do in
 	// BaseCoreFunctionalTestCase) because the old HEM test methodology was to create an EMF for each test method.
 
 	private static final Dialect dialect = Dialect.getDialect();
 
 	private Ejb3Configuration ejb3Configuration;
 	private BasicServiceRegistryImpl serviceRegistry;
 	private EntityManagerFactory entityManagerFactory;
 
 	private EntityManager em;
 	private ArrayList<EntityManager> isolatedEms = new ArrayList<EntityManager>();
 
 	protected Dialect getDialect() {
 		return dialect;
 	}
 
 	protected EntityManagerFactory entityManagerFactory() {
 		return entityManagerFactory;
 	}
 
 	protected BasicServiceRegistryImpl serviceRegistry() {
 		return serviceRegistry;
 	}
 
 	@Before
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void buildEntityManagerFactory() throws Exception {
-		LOG.trace( "Building session factory" );
+		log.trace( "Building session factory" );
 		ejb3Configuration = buildConfiguration();
 		ejb3Configuration.configure( getConfig() );
 		afterConfigurationBuilt( ejb3Configuration );
 		serviceRegistry = buildServiceRegistry( ejb3Configuration.getHibernateConfiguration() );
 		applyServices( serviceRegistry );
 		entityManagerFactory = ejb3Configuration.buildEntityManagerFactory( serviceRegistry );
 		afterEntityManagerFactoryBuilt();
 	}
 
 	protected Ejb3Configuration buildConfiguration() {
 		Ejb3Configuration ejb3Cfg = constructConfiguration();
 		addMappings( ejb3Cfg.getHibernateConfiguration() );
 		return ejb3Cfg;
 	}
 
 	protected Ejb3Configuration constructConfiguration() {
 		Ejb3Configuration ejb3Configuration = new Ejb3Configuration();
 		if ( createSchema() ) {
 			ejb3Configuration.getHibernateConfiguration().setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		}
 		ejb3Configuration
 				.getHibernateConfiguration()
 				.setProperty( Configuration.USE_NEW_ID_GENERATOR_MAPPINGS, "true" );
 		ejb3Configuration
 				.getHibernateConfiguration()
 				.setProperty( Environment.DIALECT, getDialect().getClass().getName() );
 		return ejb3Configuration;
 	}
 
 	protected void addMappings(Configuration configuration) {
 		String[] mappings = getMappings();
 		if ( mappings != null ) {
 			for ( String mapping : mappings ) {
 				configuration.addResource( mapping, getClass().getClassLoader() );
 			}
 		}
 	}
 
 	protected static final String[] NO_MAPPINGS = new String[0];
 
 	protected String[] getMappings() {
 		return NO_MAPPINGS;
 	}
 
 	protected Map getConfig() {
 		Map<Object, Object> config = loadProperties();
 		ArrayList<Class> classes = new ArrayList<Class>();
 
 		classes.addAll( Arrays.asList( getAnnotatedClasses() ) );
 		config.put( AvailableSettings.LOADED_CLASSES, classes );
 		for ( Map.Entry<Class, String> entry : getCachedClasses().entrySet() ) {
 			config.put( AvailableSettings.CLASS_CACHE_PREFIX + "." + entry.getKey().getName(), entry.getValue() );
 		}
 		for ( Map.Entry<String, String> entry : getCachedCollections().entrySet() ) {
 			config.put( AvailableSettings.COLLECTION_CACHE_PREFIX + "." + entry.getKey(), entry.getValue() );
 		}
 		if ( getEjb3DD().length > 0 ) {
 			ArrayList<String> dds = new ArrayList<String>();
 			dds.addAll( Arrays.asList( getEjb3DD() ) );
 			config.put( AvailableSettings.XML_FILE_NAMES, dds );
 		}
 
 		addConfigOptions( config );
 		return config;
 	}
 
 	protected void addConfigOptions(Map options) {
 	}
 
 	private Properties loadProperties() {
 		Properties props = new Properties();
 		InputStream stream = Persistence.class.getResourceAsStream( "/hibernate.properties" );
 		if ( stream != null ) {
 			try {
 				props.load( stream );
 			}
 			catch ( Exception e ) {
 				throw new RuntimeException( "could not load hibernate.properties" );
 			}
 			finally {
 				try {
 					stream.close();
 				}
 				catch ( IOException ignored ) {
 				}
 			}
 		}
 		return props;
 	}
 
 	protected static final Class<?>[] NO_CLASSES = new Class[0];
 
 	protected Class<?>[] getAnnotatedClasses() {
 		return NO_CLASSES;
 	}
 
 	public Map<Class, String> getCachedClasses() {
 		return new HashMap<Class, String>();
 	}
 
 	public Map<String, String> getCachedCollections() {
 		return new HashMap<String, String>();
 	}
 
 	public String[] getEjb3DD() {
 		return new String[] { };
 	}
 
 	@SuppressWarnings( {"UnusedParameters"})
 	protected void afterConfigurationBuilt(Ejb3Configuration ejb3Configuration) {
 	}
 
 	protected BasicServiceRegistryImpl buildServiceRegistry(Configuration configuration) {
 		Properties properties = new Properties();
 		properties.putAll( configuration.getProperties() );
 		Environment.verifyProperties( properties );
 		ConfigurationHelper.resolvePlaceHolders( properties );
 		return new BasicServiceRegistryImpl( properties );
 	}
 
 	@SuppressWarnings( {"UnusedParameters"})
 	protected void applyServices(BasicServiceRegistryImpl serviceRegistry) {
 	}
 
 	protected void afterEntityManagerFactoryBuilt() {
 	}
 
 	protected boolean createSchema() {
 		return true;
 	}
 
 
 	@After
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void releaseResources() {
 		releaseUnclosedEntityManagers();
 
 		if ( entityManagerFactory != null ) {
 			entityManagerFactory.close();
 		}
 
 		if ( serviceRegistry != null ) {
 			serviceRegistry.destroy();
 		}
 	}
 
 	private void releaseUnclosedEntityManagers() {
 		releaseUnclosedEntityManager( this.em );
 
 		for ( EntityManager isolatedEm : isolatedEms ) {
 			releaseUnclosedEntityManager( isolatedEm );
 		}
 	}
 
 	private void releaseUnclosedEntityManager(EntityManager em) {
 		if ( em == null ) {
 			return;
 		}
 		if ( em.getTransaction().isActive() ) {
 			em.getTransaction().rollback();
-            LOG.warn("You left an open transaction! Fix your test case. For now, we are closing it for you.");
+            log.warn("You left an open transaction! Fix your test case. For now, we are closing it for you.");
 		}
 		if ( em.isOpen() ) {
 			// as we open an EM before the test runs, it will still be open if the test uses a custom EM.
 			// or, the person may have forgotten to close. So, do not raise a "fail", but log the fact.
 			em.close();
-            LOG.warn("The EntityManager is not closed. Closing it.");
+            log.warn("The EntityManager is not closed. Closing it.");
 		}
 	}
 
 	protected EntityManager getOrCreateEntityManager() {
 		if ( em == null || !em.isOpen() ) {
 			em = entityManagerFactory.createEntityManager();
 		}
 		return em;
 	}
 
 	protected EntityManager createIsolatedEntityManager() {
 		EntityManager isolatedEm = entityManagerFactory.createEntityManager();
 		isolatedEms.add( isolatedEm );
 		return isolatedEm;
 	}
 
 	protected EntityManager createIsolatedEntityManager(Map props) {
 		EntityManager isolatedEm = entityManagerFactory.createEntityManager(props);
 		isolatedEms.add( isolatedEm );
 		return isolatedEm;
 	}
 
 	protected EntityManager createEntityManager(Map properties) {
 		// always reopen a new EM and close the existing one
 		if ( em != null && em.isOpen() ) {
 			em.close();
 		}
 		em = entityManagerFactory.createEntityManager( properties );
 		return em;
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/Cat.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/Cat.java
index 77becf5e00..0290d4cc64 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/Cat.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/Cat.java
@@ -1,172 +1,175 @@
 //$Id$
 package org.hibernate.ejb.test;
-import static org.hibernate.testing.TestLogger.LOG;
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.Calendar;
-import java.util.Collections;
-import java.util.Date;
-import java.util.GregorianCalendar;
-import java.util.List;
+
 import javax.persistence.Basic;
 import javax.persistence.CascadeType;
 import javax.persistence.Entity;
 import javax.persistence.EntityListeners;
 import javax.persistence.GeneratedValue;
 import javax.persistence.Id;
 import javax.persistence.OneToMany;
 import javax.persistence.PostLoad;
 import javax.persistence.PostPersist;
 import javax.persistence.PostUpdate;
 import javax.persistence.Temporal;
 import javax.persistence.TemporalType;
 import javax.persistence.Transient;
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Calendar;
+import java.util.Collections;
+import java.util.Date;
+import java.util.GregorianCalendar;
+import java.util.List;
+
+import org.jboss.logging.Logger;
 
 /**
  * @author Emmanuel Bernard
  */
 @SuppressWarnings({"unchecked", "serial"})
 @Entity
 @EntityListeners( LastUpdateListener.class )
 public class Cat implements Serializable {
+	private static final Logger log = Logger.getLogger( Cat.class );
 
 	private static final List ids = new ArrayList(); 	// used for assertions
 	public static int postVersion = 0;	// used for assertions
 
 	private Integer id;
 	private String name;
 	private Date dateOfBirth;
 	private int age;
 	private long length;
 	private Date lastUpdate;
 	private int manualVersion = 0;
 	private List<Kitten> kittens;
 
 	@Id
 	@GeneratedValue
 	public Integer getId() {
 		return id;
 	}
 
 	public void setId(Integer id) {
 		this.id = id;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public void setName(String name) {
 		this.name = name;
 	}
 
 	public Date getDateOfBirth() {
 		return dateOfBirth;
 	}
 
 	public void setDateOfBirth(Date dateOfBirth) {
 		this.dateOfBirth = dateOfBirth;
 	}
 
 	public int getManualVersion() {
 		return manualVersion;
 	}
 
 	public void setManualVersion(int manualVersion) {
 		this.manualVersion = manualVersion;
 	}
 
 	@Transient
 	public int getAge() {
 		return age;
 	}
 
 	public void setAge(int age) {
 		this.age = age;
 	}
 
 	@Basic
 	@Temporal( TemporalType.TIMESTAMP )
 	public Date getLastUpdate() {
 		return lastUpdate;
 	}
 
 	public void setLastUpdate(Date lastUpdate) {
 		this.lastUpdate = lastUpdate;
 	}
 
 	@PostUpdate
 	private void someLateUpdateWorking() {
-        LOG.debug("PostUpdate for: " + this.toString());
+        log.debug("PostUpdate for: " + this.toString());
 		postVersion++;
 	}
 
 	@PostLoad
 	public void calculateAge() {
 		Calendar birth = new GregorianCalendar();
 		birth.setTime( dateOfBirth );
 		Calendar now = new GregorianCalendar();
 		now.setTime( new Date() );
 		int adjust = 0;
 		if ( now.get( Calendar.DAY_OF_YEAR ) - birth.get( Calendar.DAY_OF_YEAR ) < 0 ) {
 			adjust = -1;
 		}
 		age = now.get( Calendar.YEAR ) - birth.get( Calendar.YEAR ) + adjust;
 	}
 
 	@PostPersist
 	public synchronized void addIdsToList() {
 		ids.add( getId() );
 	}
 
 	public static synchronized List getIdList() {
 		return Collections.unmodifiableList( ids );
 	}
 
 	public long getLength() {
 		return length;
 	}
 
 	public void setLength(long length) {
 		this.length = length;
 	}
 
 	@OneToMany(cascade = CascadeType.ALL)
 	public List<Kitten> getKittens() {
 		return kittens;
 	}
 
 	public void setKittens(List<Kitten> kittens) {
 		this.kittens = kittens;
 	}
 
 	/**
 	 * Constructs a <code>String</code> with all attributes
 	 * in name = value format.
 	 *
 	 * @return a <code>String</code> representation
 	 * of this object.
 	 */
 	@Override
     public String toString()
 	{
 	    final String TAB = "    ";
 
 	    String retValue = "";
 
 	    retValue = "Cat ( "
 	        + super.toString() + TAB
 	        + "id = " + this.id + TAB
 	        + "name = " + this.name + TAB
 	        + "dateOfBirth = " + this.dateOfBirth + TAB
 	        + "age = " + this.age + TAB
 	        + "length = " + this.length + TAB
 	        + "lastUpdate = " + this.lastUpdate + TAB
 	        + "manualVersion = " + this.manualVersion + TAB
 	        + "postVersion = " + Cat.postVersion + TAB
 	        + "kittens = " + this.kittens + TAB
 	        + " )";
 
 	    return retValue;
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/emops/RemoveTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/emops/RemoveTest.java
index dd6b500014..fa691a3b48 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/emops/RemoveTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/emops/RemoveTest.java
@@ -1,132 +1,135 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.test.emops;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import java.util.Map;
 import javax.persistence.EntityManager;
 import javax.persistence.OptimisticLockException;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.ejb.test.BaseEntityManagerFunctionalTestCase;
 
 import org.junit.Assert;
 import org.junit.Test;
 
 /**
  * @author Emmanuel Bernard
  */
 public class RemoveTest extends BaseEntityManagerFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( RemoveTest.class );
+
 	@Test
 	public void testRemove() {
 		Race race = new Race();
 		race.competitors.add( new Competitor() );
 		race.competitors.add( new Competitor() );
 		race.competitors.add( new Competitor() );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( race );
 		em.flush();
 		em.remove( race );
 		em.flush();
 		em.getTransaction().rollback();
 		em.close();
 	}
 
 	@Test
 	public void testRemoveAndFind() {
 		Race race = new Race();
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( race );
 		em.remove( race );
 		Assert.assertNull( em.find( Race.class, race.id ) );
 		em.getTransaction().rollback();
 		em.close();
 	}
 
 	@Test
 	public void testUpdatedAndRemove() throws Exception {
 		Music music = new Music();
 		music.setName( "Classical" );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( music );
 		em.getTransaction().commit();
 		em.clear();
 
 
 		EntityManager em2 = entityManagerFactory().createEntityManager();
 		try {
 			em2.getTransaction().begin();
 			//read music from 2nd EM
 			music = em2.find( Music.class, music.getId() );
 		}
 		catch (Exception e) {
 			em2.getTransaction().rollback();
 			em2.close();
 			throw e;
 		}
 
 		//change music
         em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.find( Music.class, music.getId() ).setName( "Rap" );
 		em.getTransaction().commit();
 
 		try {
 			em2.remove( music ); //remove changed music
 			em2.flush();
 			Assert.fail( "should have an optimistic lock exception" );
 		}
         catch( OptimisticLockException e ) {
-            LOG.debug("success");
+            log.debug("success");
 		}
 		finally {
 			em2.getTransaction().rollback();
 			em2.close();
 		}
 
 		//clean
         em.getTransaction().begin();
 		em.remove( em.find( Music.class, music.getId() ) );
 	    em.getTransaction().commit();
 		em.close();
 	}
 
 	@Override
     public Class[] getAnnotatedClasses() {
 		return new Class[] {
 				Race.class,
 				Competitor.class,
 				Music.class
 		};
 	}
 
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	protected void addConfigOptions(Map options) {
 		options.put( "hibernate.jdbc.batch_size", "0" );
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/exception/ExceptionTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/exception/ExceptionTest.java
index 789b3203dd..24f4cc2bd1 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/exception/ExceptionTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/exception/ExceptionTest.java
@@ -1,167 +1,170 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.test.exception;
 
 import javax.persistence.EntityManager;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.OptimisticLockException;
 import javax.persistence.PersistenceException;
 import java.util.Map;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.cfg.Environment;
 import org.hibernate.ejb.test.BaseEntityManagerFunctionalTestCase;
 import org.hibernate.exception.ConstraintViolationException;
 
 import org.junit.Test;
 
 import org.hibernate.testing.TestForIssue;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  */
 @SuppressWarnings("unchecked")
 public class ExceptionTest extends BaseEntityManagerFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( ExceptionTest.class );
+
 	@Test
 	public void testOptimisticLockingException() throws Exception {
 		EntityManager em = getOrCreateEntityManager();
 		EntityManager em2 = entityManagerFactory().createEntityManager();
 		em.getTransaction().begin();
 		Music music = new Music();
 		music.setName( "Old Country" );
 		em.persist( music );
 		em.getTransaction().commit();
 
 		try {
 			em2.getTransaction().begin();
 			Music music2 = em2.find( Music.class, music.getId() );
 			music2.setName( "HouseMusic" );
 			em2.getTransaction().commit();
 		}
 		catch ( Exception e ) {
 			em2.getTransaction().rollback();
 			throw e;
 		}
 		finally {
 			em2.close();
 		}
 
 		em.getTransaction().begin();
 		music.setName( "Rock" );
 		try {
 
 			em.flush();
 			fail( "Should raise an optimistic lock exception" );
 		}
 		catch ( OptimisticLockException e ) {
 			//success
 			assertEquals( music, e.getEntity() );
 		}
 		catch ( Exception e ) {
 			fail( "Should raise an optimistic lock exception" );
 		}
 		finally {
 			em.getTransaction().rollback();
 			em.close();
 		}
 	}
 
 	@Test
 	public void testEntityNotFoundException() throws Exception {
 		EntityManager em = getOrCreateEntityManager();
 		Music music = em.getReference( Music.class, -1 );
 		try {
 			music.getName();
 			fail( "Non existent entity should raise an exception when state is accessed" );
 		}
 		catch ( EntityNotFoundException e ) {
-            LOG.debug("success");
+            log.debug("success");
 		}
 		finally {
 			em.close();
 		}
 	}
 
 	@Test
 	public void testConstraintViolationException() throws Exception {
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		Music music = new Music();
 		music.setName( "Jazz" );
 		em.persist( music );
 		Musician lui = new Musician();
 		lui.setName( "Lui Armstrong" );
 		lui.setFavouriteMusic( music );
 		em.persist( lui );
 		em.getTransaction().commit();
 		try {
 			em.getTransaction().begin();
 			String hqlDelete = "delete Music where name = :name";
 			em.createQuery( hqlDelete ).setParameter( "name", "Jazz" ).executeUpdate();
 			em.getTransaction().commit();
 			fail();
 		}
 		catch ( PersistenceException e ) {
 			Throwable t = e.getCause();
 			assertTrue( "Should be a constraint violation", t instanceof ConstraintViolationException );
 			em.getTransaction().rollback();
 		}
 		finally {
 			em.close();
 		}
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-4676" )
 	public void testInterceptor() throws Exception {
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		Instrument instrument = new Instrument();
 		instrument.setName( "Guitar" );
 		try {
 			em.persist( instrument );
 			fail( "Commit should have failed." );
 		}
 		catch ( RuntimeException e ) {
 			assertTrue( em.getTransaction().getRollbackOnly() );
 		}
 		em.close();
 	}
 
 	@Override
 	protected void addConfigOptions(Map options) {
 		options.put( Environment.BATCH_VERSIONED_DATA, "false" );
 	}
 
 	@Override
     public Class[] getAnnotatedClasses() {
 		return new Class[] {
 				Music.class, Musician.class, Instrument.class
 		};
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/lock/LockTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/lock/LockTest.java
index 3e3c1a7bca..cde94b274f 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/lock/LockTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/lock/LockTest.java
@@ -1,872 +1,875 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.test.lock;
 
 import javax.persistence.EntityManager;
 import javax.persistence.LockModeType;
 import javax.persistence.LockTimeoutException;
 import javax.persistence.OptimisticLockException;
 import javax.persistence.Query;
 import javax.persistence.QueryTimeoutException;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.Callable;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.FutureTask;
 import java.util.concurrent.TimeUnit;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.Oracle10gDialect;
 import org.hibernate.ejb.AvailableSettings;
 import org.hibernate.ejb.test.BaseEntityManagerFunctionalTestCase;
 
 import org.junit.Test;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  */
 public class LockTest extends BaseEntityManagerFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( LockTest.class );
+
 	@Test
 	public void testFindWithTimeoutHint() {
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		Lock lock = new Lock();
 		lock.setName( "name" );
 		em.persist( lock );
 		em.getTransaction().commit();
 		em.close();
 
 		em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		Map<String, Object> properties = new HashMap<String, Object>();
 		properties.put( AvailableSettings.LOCK_TIMEOUT, 0L );
 		em.find( Lock.class, 1, LockModeType.PESSIMISTIC_WRITE, properties );
 		em.getTransaction().commit();
 		em.close();
 
 		em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		lock = em.find( Lock.class, lock.getId() );
 		em.remove( lock );
 		em.getTransaction().commit();
 		em.close();
 	}
 
 	@Test
 	public void testLockRead() throws Exception {
 		Lock lock = new Lock();
 		lock.setName( "name" );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( lock );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( Lock.class, lock.getId() );
 		em.lock( lock, LockModeType.READ );
 		lock.setName( "surname" );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.find( Lock.class, lock.getId() );
 		assertEquals( "surname", lock.getName() );
 		em.remove( lock );
 		em.getTransaction().commit();
 
 		em.close();
 	}
 
 	@Test
 	public void testLockOptimistic() throws Exception {
 		Lock lock = new Lock();
 		lock.setName( "name" );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( lock );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( Lock.class, lock.getId() );
 		em.lock( lock, LockModeType.OPTIMISTIC );
 		lock.setName( "surname" );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.find( Lock.class, lock.getId() );
 		assertEquals( "surname", lock.getName() );
 		em.remove( lock );
 		em.getTransaction().commit();
 
 		em.close();
 	}
 
 	@Test
 	public void testLockWrite() throws Exception {
 		Lock lock = new Lock();
 		lock.setName( "second" );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( lock );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( Lock.class, lock.getId() );
 		Integer version = lock.getVersion();
 		em.lock( lock, LockModeType.WRITE );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( Lock.class, lock.getId() );
 		try {
 			assertEquals( "should increase the version number EJB-106", 1, lock.getVersion() - version );
 		}
 		finally {
 			em.remove( lock );
 			em.getTransaction().commit();
 		}
 		em.close();
 	}
 
 	@Test
 	public void testLockWriteOnUnversioned() throws Exception {
 		UnversionedLock lock = new UnversionedLock();
 		lock.setName( "second" );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( lock );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( UnversionedLock.class, lock.getId() );
 		try {
 			// getting a READ (optimistic) lock on unversioned entity is not expected to work.
 			// To get the same functionality as prior release, change the  LockModeType.READ lock to:
 			// em.lock(lock,LockModeType.PESSIMISTIC_READ);
 			em.lock( lock, LockModeType.READ );
 			fail("expected OptimisticLockException exception");
 		} catch(OptimisticLockException expected) {}
 		em.getTransaction().rollback();
 
 		// the previous code block can be rewritten as follows (to get the previous behavior)
 		em.getTransaction().begin();
 		lock = em.getReference( UnversionedLock.class, lock.getId() );
 		em.lock( lock, LockModeType.PESSIMISTIC_READ );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( UnversionedLock.class, lock.getId() );
 		em.remove( lock );
 		em.getTransaction().commit();
 		em.close();
 	}
 
 	@Test
 	public void testLockPessimisticForceIncrement() throws Exception {
 		Lock lock = new Lock();
 		lock.setName( "force" );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( lock );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( Lock.class, lock.getId() );
 		Integer version = lock.getVersion();
 		em.lock( lock, LockModeType.PESSIMISTIC_FORCE_INCREMENT );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( Lock.class, lock.getId() );
 		try {
 			assertEquals( "should increase the version number ", 1, lock.getVersion() - version );
 		}
 		finally {
 			em.remove( lock );
 			em.getTransaction().commit();
 		}
 		em.close();
 	}
 
 	@Test
 	public void testLockOptimisticForceIncrement() throws Exception {
 		Lock lock = new Lock();
 		lock.setName( "force" );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( lock );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( Lock.class, lock.getId() );
 		Integer version = lock.getVersion();
 		em.lock( lock, LockModeType.OPTIMISTIC_FORCE_INCREMENT );
 		em.getTransaction().commit();
 
 		em.getTransaction().begin();
 		lock = em.getReference( Lock.class, lock.getId() );
 		try {
 			assertEquals( "should increase the version number ", 1, lock.getVersion() - version );
 		}
 		finally {
 			em.remove( lock );
 			em.getTransaction().commit();
 		}
 		em.close();
 	}
 
 	@Test
 	public void testLockOptimisticForceIncrementDifferentEm() throws Exception {
 		Lock lock = new Lock();
 		lock.setName( "force" );
 		EntityManager em1 = createIsolatedEntityManager();
 		em1.getTransaction().begin();
 		em1.persist( lock );
 		em1.getTransaction().commit();
 		em1.close();
 
 		EntityManager em2 = createIsolatedEntityManager();
 		em2.getTransaction().begin();
 		lock = em2.find( Lock.class, lock.getId(), LockModeType.OPTIMISTIC );
 		assertEquals( "lock mode should be OPTIMISTIC ", LockModeType.OPTIMISTIC, em2.getLockMode(lock) );
 		em2.lock( lock, LockModeType.OPTIMISTIC_FORCE_INCREMENT );
 		assertEquals( "lock mode should be OPTIMISTIC_FORCE_INCREMENT ", LockModeType.OPTIMISTIC_FORCE_INCREMENT, em2.getLockMode(lock) );
 		em2.getTransaction().commit();
 		em2.getTransaction().begin();
 		em2.remove( lock );
 		em2.getTransaction().commit();
 		em2.close();
 	}
 
 	@Test
 	public void testContendedPessimisticLock() throws Exception {
 		EntityManager em = getOrCreateEntityManager();
 		final EntityManager em2 = createIsolatedEntityManager();
 		// TODO:  replace dialect instanceof test with a Dialect.hasCapability (e.g. supportsPessimisticWriteLock)
 		if ( getDialect() instanceof HSQLDialect) {
-            LOG.info("skipping testContendedPessimisticLock");
+            log.info("skipping testContendedPessimisticLock");
 			return;
 		}
 		Lock lock = new Lock();
 		Thread t = null;
 		try {
 			lock.setName( "testContendedPessimisticLock" );
 
 			em.getTransaction().begin();
 			em.persist( lock );
 			em.getTransaction().commit();
 			em.clear();
 
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.lock( lock, LockModeType.PESSIMISTIC_WRITE );
 			final Integer id = lock.getId();
 			lock.getName();		// force entity to be read
-            LOG.info("testContendedPessimisticLock: got write lock");
+            log.info("testContendedPessimisticLock: got write lock");
 			final CountDownLatch latch = new CountDownLatch(1);
 
 			t = new Thread( new Runnable() {
 				public void run() {
 					try {
 						em2.getTransaction().begin();
-                        LOG.info("testContendedPessimisticLock: (BG) about to issue (PESSIMISTIC_READ) query against write-locked entity");
+                        log.info("testContendedPessimisticLock: (BG) about to issue (PESSIMISTIC_READ) query against write-locked entity");
 						// we should block on the following read
 						Query query = em2.createQuery(
 								  "select L from Lock_ L where L.id < 10000 ");
 						query.setLockMode(LockModeType.PESSIMISTIC_READ);
 						List<Lock> resultList = query.getResultList();
 						resultList.get(0).getName(); //  force entity to be read
 					}
 					finally {
 						em2.getTransaction().commit();
 						latch.countDown();	// signal that we got the read lock
 					}
 				}
 			} );
 
 			t.setDaemon( true );
 			t.setName("LockTest read lock");
 			t.start();
-            LOG.info("testContendedPessimisticLock:  wait on BG thread");
+            log.info("testContendedPessimisticLock:  wait on BG thread");
 			boolean latchSet = latch.await( 10, TimeUnit.SECONDS );
 			// latchSet should be false (timeout) because the background thread
 			// shouldn't be able to get a read lock on write locked entity.
-            LOG.info("testContendedPessimisticLock:  BG thread completed transaction");
+            log.info("testContendedPessimisticLock:  BG thread completed transaction");
 			assertFalse( "shouldn't be able to get read lock while another transaction has write lock",latchSet );
 			em.getTransaction().commit();
 		}
 		finally {
 			if ( em.getTransaction().isActive() ) {
 				em.getTransaction().rollback();
 			}
 			if ( t != null) {	  // wait for background thread to finish before deleting entity
 				t.join();
 			}
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.remove( lock );
 			em.getTransaction().commit();
 			em.close();
 			em2.close();
 		}
 	}
 
 	@Test
 	public void testContendedPessimisticReadLockTimeout() throws Exception {
 		EntityManager em = getOrCreateEntityManager();
 		final EntityManager em2 = createIsolatedEntityManager();
 		// TODO:  replace dialect instanceof test with a Dialect.hasCapability (e.g. supportsPessimisticLockTimeout)
 		if ( ! (getDialect() instanceof Oracle10gDialect)) {
-            LOG.info("skipping testContendedPessimisticReadLockTimeout");
+            log.info("skipping testContendedPessimisticReadLockTimeout");
 			return;
 		}
 		Lock lock = new Lock();
 		Thread t = null;
 		FutureTask<Boolean> bgTask = null;
 		final CountDownLatch latch = new CountDownLatch(1);
 		try {
 			lock.setName( "testContendedPessimisticReadLockTimeout" );
 
 			em.getTransaction().begin();
 			em.persist( lock );
 			em.getTransaction().commit();
 			em.clear();
 
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.lock( lock, LockModeType.PESSIMISTIC_WRITE );
 			final Integer id = lock.getId();
 			lock.getName();		// force entity to be read
-            LOG.info("testContendedPessimisticReadLockTimeout: got write lock");
+            log.info("testContendedPessimisticReadLockTimeout: got write lock");
 
 			bgTask = new FutureTask<Boolean>( new Callable() {
 				public Boolean call() {
 					try {
 						boolean timedOut = false;	// true (success) if LockTimeoutException occurred
 						em2.getTransaction().begin();
-                        LOG.info("testContendedPessimisticReadLockTimeout: (BG) about to read write-locked entity");
+                        log.info("testContendedPessimisticReadLockTimeout: (BG) about to read write-locked entity");
 						// we should block on the following read
 						Lock lock2 = em2.getReference( Lock.class, id );
 						lock2.getName();		//  force entity to be read
-                        LOG.info("testContendedPessimisticReadLockTimeout: (BG) read write-locked entity");
+                        log.info("testContendedPessimisticReadLockTimeout: (BG) read write-locked entity");
 						Map<String,Object> props = new HashMap<String, Object>();
 						// timeout is in milliseconds
 						props.put("javax.persistence.lock.timeout", new Integer(1000));
 						try {
 							em2.lock( lock2, LockModeType.PESSIMISTIC_READ, props);
 						}
 						catch( LockTimeoutException e) {
 							// success
-                            LOG.info("testContendedPessimisticReadLockTimeout: (BG) got expected timeout exception");
+                            log.info("testContendedPessimisticReadLockTimeout: (BG) got expected timeout exception");
 							 timedOut = true;
 						}
 						catch ( Throwable e) {
-                            LOG.info("Expected LockTimeoutException but got unexpected exception", e);
+                            log.info("Expected LockTimeoutException but got unexpected exception", e);
 						}
 						em2.getTransaction().commit();
 						return new Boolean(timedOut);
 					}
 					finally {
 						latch.countDown();	// signal that we finished
 					}
 				}
 			} );
 			t = new Thread(bgTask);
 			t.setDaemon( true );
 			t.setName("Lock timeout Test (bg)");
 			t.start();
 			boolean latchSet = latch.await( 10, TimeUnit.SECONDS );  // should return quickly on success
 			assertTrue( "background test thread finished (lock timeout is broken)", latchSet);
 			assertTrue( "background test thread timed out on lock attempt", bgTask.get().booleanValue() );
 			em.getTransaction().commit();
 		}
 		finally {
 			if ( em.getTransaction().isActive() ) {
 				em.getTransaction().rollback();
 			}
 			if ( t != null) {	  // wait for background thread to finish before deleting entity
 				t.join();
 			}
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.remove( lock );
 			em.getTransaction().commit();
 			em.close();
 			em2.close();
 		}
 	}
 
 	@Test
 	public void testContendedPessimisticWriteLockTimeout() throws Exception {
 
 		EntityManager em = getOrCreateEntityManager();
 		final EntityManager em2 = createIsolatedEntityManager();
 		// TODO:  replace dialect instanceof test with a Dialect.hasCapability (e.g. supportsPessimisticLockTimeout)
 		if ( ! (getDialect() instanceof Oracle10gDialect)) {
-            LOG.info("skipping testContendedPessimisticWriteLockTimeout");
+            log.info("skipping testContendedPessimisticWriteLockTimeout");
 			return;
 		}
 		Lock lock = new Lock();
 		Thread t = null;
 		FutureTask<Boolean> bgTask = null;
 		final CountDownLatch latch = new CountDownLatch(1);
 		try {
 			lock.setName( "testContendedPessimisticWriteLockTimeout" );
 
 			em.getTransaction().begin();
 			em.persist( lock );
 			em.getTransaction().commit();
 			em.clear();
 
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.lock( lock, LockModeType.PESSIMISTIC_WRITE );
 			final Integer id = lock.getId();
 			lock.getName();		// force entity to be read
-            LOG.info("testContendedPessimisticWriteLockTimeout: got write lock");
+            log.info("testContendedPessimisticWriteLockTimeout: got write lock");
 
 			bgTask = new FutureTask<Boolean>( new Callable() {
 				public Boolean call() {
 					try {
 						boolean timedOut = false;	// true (success) if LockTimeoutException occurred
 						em2.getTransaction().begin();
-                        LOG.info("testContendedPessimisticWriteLockTimeout: (BG) about to read write-locked entity");
+                        log.info("testContendedPessimisticWriteLockTimeout: (BG) about to read write-locked entity");
 						// we should block on the following read
 						Lock lock2 = em2.getReference( Lock.class, id );
 						lock2.getName();		//  force entity to be read
-                        LOG.info("testContendedPessimisticWriteLockTimeout: (BG) read write-locked entity");
+                        log.info("testContendedPessimisticWriteLockTimeout: (BG) read write-locked entity");
 						Map<String,Object> props = new HashMap<String, Object>();
 						// timeout is in milliseconds
 						props.put("javax.persistence.lock.timeout", new Integer(1000));
 						try {
 							em2.lock( lock2, LockModeType.PESSIMISTIC_WRITE, props);
 						}
 						catch( LockTimeoutException e) {
 							// success
-                            LOG.info("testContendedPessimisticWriteLockTimeout: (BG) got expected timeout exception");
+                            log.info("testContendedPessimisticWriteLockTimeout: (BG) got expected timeout exception");
 							 timedOut = true;
 						}
 						catch ( Throwable e) {
-                            LOG.info("Expected LockTimeoutException but got unexpected exception", e);
+                            log.info("Expected LockTimeoutException but got unexpected exception", e);
 						}
 						em2.getTransaction().commit();
 						return new Boolean(timedOut);
 					}
 					finally {
 						latch.countDown();	// signal that we finished
 					}
 				}
 			} );
 			t = new Thread(bgTask);
 			t.setDaemon( true );
 			t.setName("Lock timeout Test (bg)");
 			t.start();
 			boolean latchSet = latch.await( 10, TimeUnit.SECONDS );  // should return quickly on success
 			assertTrue( "background test thread finished (lock timeout is broken)", latchSet);
 			assertTrue( "background test thread timed out on lock attempt", bgTask.get().booleanValue() );
 			em.getTransaction().commit();
 		}
 		finally {
 			if ( em.getTransaction().isActive() ) {
 				em.getTransaction().rollback();
 			}
 			if ( t != null) {	  // wait for background thread to finish before deleting entity
 				t.join();
 			}
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.remove( lock );
 			em.getTransaction().commit();
 			em.close();
 			em2.close();
 		}
 	}
 
 	@Test
 	public void testContendedPessimisticWriteLockNoWait() throws Exception {
 
 		EntityManager em = getOrCreateEntityManager();
 		final EntityManager em2 = createIsolatedEntityManager();
 		// TODO:  replace dialect instanceof test with a Dialect.hasCapability (e.g. supportsPessimisticLockTimeout)
 		if ( ! (getDialect() instanceof Oracle10gDialect)) {
-            LOG.info("skipping testContendedPessimisticWriteLockNoWait");
+            log.info("skipping testContendedPessimisticWriteLockNoWait");
 			return;
 		}
 		Lock lock = new Lock();
 		Thread t = null;
 		FutureTask<Boolean> bgTask = null;
 		final CountDownLatch latch = new CountDownLatch(1);
 		try {
 			lock.setName( "testContendedPessimisticWriteLockNoWait" );
 
 			em.getTransaction().begin();
 			em.persist( lock );
 			em.getTransaction().commit();
 			em.clear();
 
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.lock( lock, LockModeType.PESSIMISTIC_WRITE );
 			final Integer id = lock.getId();
 			lock.getName();		// force entity to be read
-            LOG.info("testContendedPessimisticWriteLockNoWait: got write lock");
+            log.info("testContendedPessimisticWriteLockNoWait: got write lock");
 
 			bgTask = new FutureTask<Boolean>( new Callable() {
 				public Boolean call() {
 					try {
 						boolean timedOut = false;	// true (success) if LockTimeoutException occurred
 						em2.getTransaction().begin();
-                        LOG.info("testContendedPessimisticWriteLockNoWait: (BG) about to read write-locked entity");
+                        log.info("testContendedPessimisticWriteLockNoWait: (BG) about to read write-locked entity");
 						// we should block on the following read
 						Lock lock2 = em2.getReference( Lock.class, id );
 						lock2.getName();		//  force entity to be read
-                        LOG.info("testContendedPessimisticWriteLockNoWait: (BG) read write-locked entity");
+                        log.info("testContendedPessimisticWriteLockNoWait: (BG) read write-locked entity");
 						Map<String,Object> props = new HashMap<String, Object>();
 						// timeout of zero means no wait (for lock)
 						props.put("javax.persistence.lock.timeout", new Integer(0));
 						try {
 							em2.lock( lock2, LockModeType.PESSIMISTIC_WRITE, props);
 						}
 						catch( LockTimeoutException e) {
 							// success
-                            LOG.info("testContendedPessimisticWriteLockNoWait: (BG) got expected timeout exception");
+                            log.info("testContendedPessimisticWriteLockNoWait: (BG) got expected timeout exception");
 							 timedOut = true;
 						}
 						catch ( Throwable e) {
-                            LOG.info("Expected LockTimeoutException but got unexpected exception", e);
+                            log.info("Expected LockTimeoutException but got unexpected exception", e);
 						}
 						em2.getTransaction().commit();
 						return new Boolean(timedOut);
 					}
 					finally {
 						latch.countDown();	// signal that we finished
 					}
 				}
 			} );
 			t = new Thread(bgTask);
 			t.setDaemon( true );
 			t.setName("Lock timeout Test (bg)");
 			t.start();
 			boolean latchSet = latch.await( 10, TimeUnit.SECONDS );  // should return quickly on success
 			assertTrue( "background test thread finished (lock timeout is broken)", latchSet);
 			assertTrue( "background test thread timed out on lock attempt", bgTask.get().booleanValue() );
 			em.getTransaction().commit();
 		}
 		finally {
 			if ( em.getTransaction().isActive() ) {
 				em.getTransaction().rollback();
 			}
 			if ( t != null) {	  // wait for background thread to finish before deleting entity
 				t.join();
 			}
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.remove( lock );
 			em.getTransaction().commit();
 			em.close();
 			em2.close();
 		}
 	}
 
 	@Test
 	public void testQueryTimeout() throws Exception {
 
 		EntityManager em = getOrCreateEntityManager();
 		final EntityManager em2 = createIsolatedEntityManager();
 		// TODO:  replace dialect instanceof test with a Dialect.hasCapability
 		if ( ! (getDialect() instanceof Oracle10gDialect)) {
-            LOG.info("skipping testQueryTimeout");
+            log.info("skipping testQueryTimeout");
 			return;
 		}
 		Lock lock = new Lock();
 		Thread t = null;
 		FutureTask<Boolean> bgTask = null;
 		final CountDownLatch latch = new CountDownLatch(1);
 		try {
 			lock.setName( "testQueryTimeout" );
 
 			em.getTransaction().begin();
 			em.persist( lock );
 			em.getTransaction().commit();
 			em.clear();
 
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.lock( lock, LockModeType.PESSIMISTIC_WRITE );
 			final Integer id = lock.getId();
 			lock.getName();		// force entity to be read
-            LOG.info("testQueryTimeout: got write lock");
+            log.info("testQueryTimeout: got write lock");
 
 			bgTask = new FutureTask<Boolean>( new Callable() {
 				public Boolean call() {
 					try {
 						boolean timedOut = false;	// true (success) if LockTimeoutException occurred
 						em2.getTransaction().begin();
-                        LOG.info("testQueryTimeout: (BG) about to read write-locked entity");
+                        log.info("testQueryTimeout: (BG) about to read write-locked entity");
 						// we should block on the following read
 						Lock lock2 = em2.getReference( Lock.class, id );
 						lock2.getName();		//  force entity to be read
-                        LOG.info("testQueryTimeout: (BG) read write-locked entity");
+                        log.info("testQueryTimeout: (BG) read write-locked entity");
 						try {
 							// we should block on the following read
 							Query query = em2.createQuery(
 									  "select L from Lock_ L where L.id < 10000 ");
 							query.setLockMode( LockModeType.PESSIMISTIC_READ );
 							query.setHint( "javax.persistence.query.timeout", new Integer(500) ); // 1 sec timeout
 							List<Lock> resultList = query.getResultList();
 							String name = resultList.get(0).getName(); //  force entity to be read
-                            LOG.info("testQueryTimeout: name read =" + name);
+                            log.info("testQueryTimeout: name read =" + name);
 						}
 						catch( QueryTimeoutException e) {
 							// success
-                            LOG.info("testQueryTimeout: (BG) got expected timeout exception");
+                            log.info("testQueryTimeout: (BG) got expected timeout exception");
 							 timedOut = true;
 						}
 						catch ( Throwable e) {
-                            LOG.info("testQueryTimeout: Expected LockTimeoutException but got unexpected exception", e);
+                            log.info("testQueryTimeout: Expected LockTimeoutException but got unexpected exception", e);
 						}
 						em2.getTransaction().commit();
 						return new Boolean( timedOut );
 					}
 					finally {
 						latch.countDown();	// signal that we finished
 					}
 				}
 			} );
 			t = new Thread(bgTask);
 			t.setDaemon( true );
 			t.setName( "testQueryTimeout (bg)" );
 			t.start();
 			boolean latchSet = latch.await( 10, TimeUnit.SECONDS );  // should return quickly on success
 			assertTrue( "background test thread finished (lock timeout is broken)", latchSet);
 			assertTrue( "background test thread timed out on lock attempt", bgTask.get().booleanValue() );
 			em.getTransaction().commit();
 		}
 		finally {
 			if ( em.getTransaction().isActive() ) {
 				em.getTransaction().rollback();
 			}
 			if ( t != null) {	  // wait for background thread to finish before deleting entity
 				t.join();
 			}
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.remove( lock );
 			em.getTransaction().commit();
 			em.close();
 			em2.close();
 		}
 	}
 
 	@Test
 	public void testQueryTimeoutEMProps() throws Exception {
 		// TODO:  replace dialect instanceof test with a Dialect.hasCapability
 		if ( ! (getDialect() instanceof Oracle10gDialect)) {
-            LOG.info("skipping testQueryTimeout");
+            log.info("skipping testQueryTimeout");
 			return;
  		}
 		EntityManager em = getOrCreateEntityManager();
 		Map queryTimeoutProps = new HashMap();
 		queryTimeoutProps.put("javax.persistence.query.timeout", new Integer(500) ); // 1 sec timeout (should round up)
 		final EntityManager em2 = createIsolatedEntityManager(queryTimeoutProps);
 		Lock lock = new Lock();
 		Thread t = null;
 		FutureTask<Boolean> bgTask = null;
 		final CountDownLatch latch = new CountDownLatch(1);
 		try {
 			lock.setName( "testQueryTimeout" );
 
 			em.getTransaction().begin();
 			em.persist( lock );
 			em.getTransaction().commit();
 			em.clear();
 
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.lock( lock, LockModeType.PESSIMISTIC_WRITE );
 			final Integer id = lock.getId();
 			lock.getName();		// force entity to be read
-            LOG.info("testQueryTimeout: got write lock");
+            log.info("testQueryTimeout: got write lock");
 
 			bgTask = new FutureTask<Boolean>( new Callable() {
 				public Boolean call() {
 					try {
 						boolean timedOut = false;	// true (success) if LockTimeoutException occurred
 						em2.getTransaction().begin();
-                        LOG.info("testQueryTimeout: (BG) about to read write-locked entity");
+                        log.info("testQueryTimeout: (BG) about to read write-locked entity");
 						// we should block on the following read
 						Lock lock2 = em2.getReference( Lock.class, id );
 						lock2.getName();		//  force entity to be read
-                        LOG.info("testQueryTimeout: (BG) read write-locked entity");
+                        log.info("testQueryTimeout: (BG) read write-locked entity");
 						try {
 							// we should block on the following read
 							Query query = em2.createQuery(
 									  "select L from Lock_ L where L.id < 10000 ");
 							query.setLockMode( LockModeType.PESSIMISTIC_READ );
 							List<Lock> resultList = query.getResultList();
 							String name = resultList.get(0).getName(); //  force entity to be read
-                            LOG.info("testQueryTimeout: name read =" + name);
+                            log.info("testQueryTimeout: name read =" + name);
 						}
 						catch( QueryTimeoutException e) {
 							// success
-                            LOG.info("testQueryTimeout: (BG) got expected timeout exception");
+                            log.info("testQueryTimeout: (BG) got expected timeout exception");
 							 timedOut = true;
 						}
 						catch ( Throwable e) {
-                            LOG.info("testQueryTimeout: Expected LockTimeoutException but got unexpected exception", e);
+                            log.info("testQueryTimeout: Expected LockTimeoutException but got unexpected exception", e);
 						}
 						em2.getTransaction().commit();
 						return new Boolean( timedOut );
 					}
 					finally {
 						latch.countDown();	// signal that we finished
 					}
 				}
 			} );
 			t = new Thread(bgTask);
 			t.setDaemon( true );
 			t.setName( "testQueryTimeout (bg)" );
 			t.start();
 			boolean latchSet = latch.await( 10, TimeUnit.SECONDS );  // should return quickly on success
 			assertTrue( "background test thread finished (lock timeout is broken)", latchSet);
 			assertTrue( "background test thread timed out on lock attempt", bgTask.get().booleanValue() );
 			em.getTransaction().commit();
 		}
 		finally {
 			if ( em.getTransaction().isActive() ) {
 				em.getTransaction().rollback();
 			}
 			if ( t != null) {	  // wait for background thread to finish before deleting entity
 				t.join();
 			}
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.remove( lock );
 			em.getTransaction().commit();
 			em.close();
 			em2.close();
 		}
 	}
 
 
 	@Test
 	public void testLockTimeoutEMProps() throws Exception {
 
 		EntityManager em = getOrCreateEntityManager();
 		Map TimeoutProps = new HashMap();
 		TimeoutProps.put("javax.persistence.lock.timeout", new Integer(1000) ); // 1 second timeout
 		final EntityManager em2 = createIsolatedEntityManager(TimeoutProps);
 		// TODO:  replace dialect instanceof test with a Dialect.hasCapability (e.g. supportsPessimisticLockTimeout)
 		if ( ! (getDialect() instanceof Oracle10gDialect)) {
-            LOG.info("skipping testLockTimeoutEMProps");
+            log.info("skipping testLockTimeoutEMProps");
 			return;
 		}
 		Lock lock = new Lock();
 		Thread t = null;
 		FutureTask<Boolean> bgTask = null;
 		final CountDownLatch latch = new CountDownLatch(1);
 		try {
 			lock.setName( "testLockTimeoutEMProps" );
 
 			em.getTransaction().begin();
 			em.persist( lock );
 			em.getTransaction().commit();
 			em.clear();
 
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.lock( lock, LockModeType.PESSIMISTIC_WRITE );
 			final Integer id = lock.getId();
 			lock.getName();		// force entity to be read
-            LOG.info("testLockTimeoutEMProps: got write lock");
+            log.info("testLockTimeoutEMProps: got write lock");
 
 			bgTask = new FutureTask<Boolean>( new Callable() {
 				public Boolean call() {
 					try {
 						boolean timedOut = false;	// true (success) if LockTimeoutException occurred
 						em2.getTransaction().begin();
-                        LOG.info("testLockTimeoutEMProps: (BG) about to read write-locked entity");
+                        log.info("testLockTimeoutEMProps: (BG) about to read write-locked entity");
 						// we should block on the following read
 						Lock lock2 = em2.getReference( Lock.class, id );
 						lock2.getName();		//  force entity to be read
-                        LOG.info("testLockTimeoutEMProps: (BG) read write-locked entity");
+                        log.info("testLockTimeoutEMProps: (BG) read write-locked entity");
 						// em2 already has javax.persistence.lock.timeout of 1 second applied
 						try {
 							em2.lock( lock2, LockModeType.PESSIMISTIC_WRITE);
 						}
 						catch( LockTimeoutException e) {
 							// success
-                            LOG.info("testLockTimeoutEMProps: (BG) got expected timeout exception");
+                            log.info("testLockTimeoutEMProps: (BG) got expected timeout exception");
 							 timedOut = true;
 						}
 						catch ( Throwable e) {
-                            LOG.info("Expected LockTimeoutException but got unexpected exception", e);
+                            log.info("Expected LockTimeoutException but got unexpected exception", e);
 						}
 						em2.getTransaction().commit();
 						return new Boolean(timedOut);
 					}
 					finally {
 						latch.countDown();	// signal that we finished
 					}
 				}
 			} );
 			t = new Thread(bgTask);
 			t.setDaemon( true );
 			t.setName("Lock timeout Test (bg)");
 			t.start();
 			boolean latchSet = latch.await( 10, TimeUnit.SECONDS );  // should return quickly on success
 			assertTrue( "background test thread finished (lock timeout is broken)", latchSet);
 			assertTrue( "background test thread timed out on lock attempt", bgTask.get().booleanValue() );
 			em.getTransaction().commit();
 		}
 		finally {
 			if ( em.getTransaction().isActive() ) {
 				em.getTransaction().rollback();
 			}
 			if ( t != null) {	  // wait for background thread to finish before deleting entity
 				t.join();
 			}
 			em.getTransaction().begin();
 			lock = em.getReference( Lock.class, lock.getId() );
 			em.remove( lock );
 			em.getTransaction().commit();
 			em.close();
 			em2.close();
 		}
 	}
 
 	@Override
 	public Class[] getAnnotatedClasses() {
 		return new Class[]{
 				Lock.class,
 				UnversionedLock.class
 		};
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/ClassesAuditingData.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/ClassesAuditingData.java
index 29703b3601..2234e26963 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/ClassesAuditingData.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/ClassesAuditingData.java
@@ -1,96 +1,96 @@
 package org.hibernate.envers.configuration;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.LinkedHashMap;
 import java.util.Map;
 import org.hibernate.MappingException;
-import org.hibernate.envers.EnversLogger;
+import org.hibernate.envers.internal.EnversMessageLogger;
 import org.hibernate.envers.configuration.metadata.reader.ClassAuditingData;
 import org.hibernate.envers.configuration.metadata.reader.PropertyAuditingData;
 import org.hibernate.envers.tools.MappingTools;
 import org.hibernate.mapping.PersistentClass;
 import org.jboss.logging.Logger;
 
 /**
  * A helper class holding auditing meta-data for all persistent classes.
  * @author Adam Warski (adam at warski dot org)
  */
 public class ClassesAuditingData {
 
-    public static final EnversLogger LOG = Logger.getMessageLogger(EnversLogger.class, ClassesAuditingData.class.getName());
+    public static final EnversMessageLogger LOG = Logger.getMessageLogger(EnversMessageLogger.class, ClassesAuditingData.class.getName());
 
     private final Map<String, ClassAuditingData> entityNameToAuditingData = new HashMap<String, ClassAuditingData>();
     private final Map<PersistentClass, ClassAuditingData> persistentClassToAuditingData = new LinkedHashMap<PersistentClass, ClassAuditingData>();
 
     /**
      * Stores information about auditing meta-data for the given class.
      * @param pc Persistent class.
      * @param cad Auditing meta-data for the given class.
      */
     public void addClassAuditingData(PersistentClass pc, ClassAuditingData cad) {
         entityNameToAuditingData.put(pc.getEntityName(), cad);
         persistentClassToAuditingData.put(pc, cad);
     }
 
     /**
      * @return A collection of all auditing meta-data for persistent classes.
      */
     public Collection<Map.Entry<PersistentClass, ClassAuditingData>> getAllClassAuditedData() {
         return persistentClassToAuditingData.entrySet();
     }
 
     /**
      * @param entityName Name of the entity.
      * @return Auditing meta-data for the given entity.
      */
     public ClassAuditingData getClassAuditingData(String entityName) {
         return entityNameToAuditingData.get(entityName);
     }
 
     /**
      * After all meta-data is read, updates calculated fields. This includes:
      * <ul>
      * <li>setting {@code forceInsertable} to {@code true} for properties specified by {@code @AuditMappedBy}</li>
      * </ul>
      */
     public void updateCalculatedFields() {
         for (Map.Entry<PersistentClass, ClassAuditingData> classAuditingDataEntry : persistentClassToAuditingData.entrySet()) {
             PersistentClass pc = classAuditingDataEntry.getKey();
             ClassAuditingData classAuditingData = classAuditingDataEntry.getValue();
             for (String propertyName : classAuditingData.getPropertyNames()) {
                 PropertyAuditingData propertyAuditingData = classAuditingData.getPropertyAuditingData(propertyName);
                 // If a property had the @AuditMappedBy annotation, setting the referenced fields to be always insertable.
                 if (propertyAuditingData.getAuditMappedBy() != null) {
                     String referencedEntityName = MappingTools.getReferencedEntityName(pc.getProperty(propertyName).getValue());
 
                     ClassAuditingData referencedClassAuditingData = entityNameToAuditingData.get(referencedEntityName);
 
                     forcePropertyInsertable(referencedClassAuditingData, propertyAuditingData.getAuditMappedBy(),
                             pc.getEntityName(), referencedEntityName);
 
                     forcePropertyInsertable(referencedClassAuditingData, propertyAuditingData.getPositionMappedBy(),
                             pc.getEntityName(), referencedEntityName);
                 }
             }
         }
     }
 
     private void forcePropertyInsertable(ClassAuditingData classAuditingData, String propertyName,
                                          String entityName, String referencedEntityName) {
         if (propertyName != null) {
             if (classAuditingData.getPropertyAuditingData(propertyName) == null) {
                 throw new MappingException("@AuditMappedBy points to a property that doesn't exist: " +
                     referencedEntityName + "." + propertyName);
             }
 
             LOG.debugf("Non-insertable property %s.%s will be made insertable because a matching @AuditMappedBy was found in the %s entity",
                        referencedEntityName,
                        propertyName,
                        entityName);
 
             classAuditingData
                     .getPropertyAuditingData(propertyName)
                     .setForceInsertable(true);
         }
     }
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/metadata/AuditMetadataGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/metadata/AuditMetadataGenerator.java
index 7cdda3c96b..ec5ac6a269 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/metadata/AuditMetadataGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/metadata/AuditMetadataGenerator.java
@@ -1,563 +1,563 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.metadata;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import org.dom4j.Element;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.Configuration;
-import org.hibernate.envers.EnversLogger;
+import org.hibernate.envers.internal.EnversMessageLogger;
 import org.hibernate.envers.RelationTargetAuditMode;
 import org.hibernate.envers.configuration.AuditEntitiesConfiguration;
 import org.hibernate.envers.configuration.GlobalConfiguration;
 import org.hibernate.envers.configuration.metadata.reader.ClassAuditingData;
 import org.hibernate.envers.configuration.metadata.reader.PropertyAuditingData;
 import org.hibernate.envers.entities.EntityConfiguration;
 import org.hibernate.envers.entities.IdMappingData;
 import org.hibernate.envers.entities.mapper.CompositeMapperBuilder;
 import org.hibernate.envers.entities.mapper.ExtendedPropertyMapper;
 import org.hibernate.envers.entities.mapper.MultiPropertyMapper;
 import org.hibernate.envers.entities.mapper.SubclassPropertyMapper;
 import org.hibernate.envers.strategy.AuditStrategy;
 import org.hibernate.envers.strategy.ValidityAuditStrategy;
 import org.hibernate.envers.tools.StringTools;
 import org.hibernate.envers.tools.Triple;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.Value;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.ManyToOneType;
 import org.hibernate.type.OneToOneType;
 import org.hibernate.type.TimestampType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author Sebastian Komander
  * @author Tomasz Bech
  * @author Stephanie Pau at Markit Group Plc
  * @author Hern&aacute;n Chanfreau
  */
 public final class AuditMetadataGenerator {
 
-    public static final EnversLogger LOG = Logger.getMessageLogger(EnversLogger.class, AuditMetadataGenerator.class.getName());
+    public static final EnversMessageLogger LOG = Logger.getMessageLogger(EnversMessageLogger.class, AuditMetadataGenerator.class.getName());
 
     private final Configuration cfg;
     private final GlobalConfiguration globalCfg;
     private final AuditEntitiesConfiguration verEntCfg;
     private final AuditStrategy auditStrategy;
     private final Element revisionInfoRelationMapping;
 
     /*
      * Generators for different kinds of property values/types.
      */
     private final BasicMetadataGenerator basicMetadataGenerator;
 	private final ComponentMetadataGenerator componentMetadataGenerator;
     private final IdMetadataGenerator idMetadataGenerator;
     private final ToOneRelationMetadataGenerator toOneRelationMetadataGenerator;
 
     /*
      * Here information about already generated mappings will be accumulated.
      */
     private final Map<String, EntityConfiguration> entitiesConfigurations;
     private final Map<String, EntityConfiguration> notAuditedEntitiesConfigurations;
 
     private final AuditEntityNameRegister auditEntityNameRegister;
 
     // Map entity name -> (join descriptor -> element describing the "versioned" join)
     private final Map<String, Map<Join, Element>> entitiesJoins;
 
     public AuditMetadataGenerator(Configuration cfg, GlobalConfiguration globalCfg,
                                   AuditEntitiesConfiguration verEntCfg,
                                   AuditStrategy auditStrategy,
                                   Element revisionInfoRelationMapping,
                                   AuditEntityNameRegister auditEntityNameRegister) {
         this.cfg = cfg;
         this.globalCfg = globalCfg;
         this.verEntCfg = verEntCfg;
         this.auditStrategy = auditStrategy;
         this.revisionInfoRelationMapping = revisionInfoRelationMapping;
 
         this.basicMetadataGenerator = new BasicMetadataGenerator();
 		this.componentMetadataGenerator = new ComponentMetadataGenerator(this);
         this.idMetadataGenerator = new IdMetadataGenerator(this);
         this.toOneRelationMetadataGenerator = new ToOneRelationMetadataGenerator(this);
 
         this.auditEntityNameRegister = auditEntityNameRegister;
 
         entitiesConfigurations = new HashMap<String, EntityConfiguration>();
         notAuditedEntitiesConfigurations = new HashMap<String, EntityConfiguration>();
         entitiesJoins = new HashMap<String, Map<Join, Element>>();
     }
 
     /**
      * Clones the revision info relation mapping, so that it can be added to other mappings. Also, the name of
      * the property and the column are set properly.
      * @return A revision info mapping, which can be added to other mappings (has no parent).
      */
     private Element cloneAndSetupRevisionInfoRelationMapping() {
         Element rev_mapping = (Element) revisionInfoRelationMapping.clone();
         rev_mapping.addAttribute("name", verEntCfg.getRevisionFieldName());
 
         MetadataTools.addOrModifyColumn(rev_mapping, verEntCfg.getRevisionFieldName());
 
         return rev_mapping;
     }
 
     void addRevisionInfoRelation(Element any_mapping) {
         any_mapping.add(cloneAndSetupRevisionInfoRelationMapping());
     }
 
     void addRevisionType(Element any_mapping) {
         Element revTypeProperty = MetadataTools.addProperty(any_mapping, verEntCfg.getRevisionTypePropName(),
                 verEntCfg.getRevisionTypePropType(), true, false);
         revTypeProperty.addAttribute("type", "org.hibernate.envers.entities.RevisionTypeType");
 
         // Adding the end revision, if appropriate
         addEndRevision(any_mapping);
     }
 
     private void addEndRevision(Element any_mapping ) {
         // Add the end-revision field, if the appropriate strategy is used.
         if (auditStrategy instanceof ValidityAuditStrategy) {
             Element end_rev_mapping = (Element) revisionInfoRelationMapping.clone();
             end_rev_mapping.setName("many-to-one");
             end_rev_mapping.addAttribute("name", verEntCfg.getRevisionEndFieldName());
             MetadataTools.addOrModifyColumn(end_rev_mapping, verEntCfg.getRevisionEndFieldName());
 
             any_mapping.add(end_rev_mapping);
 
             if (verEntCfg.isRevisionEndTimestampEnabled()) {
             	// add a column for the timestamp of the end revision
             	String revisionInfoTimestampSqlType = TimestampType.INSTANCE.getName();
             	Element timestampProperty = MetadataTools.addProperty(any_mapping, verEntCfg.getRevisionEndTimestampFieldName(), revisionInfoTimestampSqlType, true, true, false);
             	MetadataTools.addColumn(timestampProperty, verEntCfg.getRevisionEndTimestampFieldName(), 0, 0, 0, null, null, null);
             }
         }
     }
 
     void addValue(Element parent, Value value, CompositeMapperBuilder currentMapper, String entityName,
                   EntityXmlMappingData xmlMappingData, PropertyAuditingData propertyAuditingData,
                   boolean insertable, boolean firstPass) {
         Type type = value.getType();
 
         // only first pass
         if (firstPass) {
             if (basicMetadataGenerator.addBasic(parent, propertyAuditingData, value, currentMapper,
                     insertable, false)) {
                 // The property was mapped by the basic generator.
                 return;
             }
         }
 
 		if (type instanceof ComponentType) {
 			// both passes
 			componentMetadataGenerator.addComponent(parent, propertyAuditingData, value, currentMapper,
 					entityName, xmlMappingData, firstPass);
 		} else if (type instanceof ManyToOneType) {
             // only second pass
             if (!firstPass) {
                 toOneRelationMetadataGenerator.addToOne(parent, propertyAuditingData, value, currentMapper,
                         entityName, insertable);
             }
         } else if (type instanceof OneToOneType) {
             // only second pass
             if (!firstPass) {
                 toOneRelationMetadataGenerator.addOneToOneNotOwning(propertyAuditingData, value,
                         currentMapper, entityName);
             }
         } else if (type instanceof CollectionType) {
             // only second pass
             if (!firstPass) {
                 CollectionMetadataGenerator collectionMetadataGenerator = new CollectionMetadataGenerator(this,
                         (Collection) value, currentMapper, entityName, xmlMappingData,
 						propertyAuditingData);
                 collectionMetadataGenerator.addCollection();
             }
         } else {
             if (firstPass) {
                 // If we got here in the first pass, it means the basic mapper didn't map it, and none of the
                 // above branches either.
                 throwUnsupportedTypeException(type, entityName, propertyAuditingData.getName());
             }
         }
     }
 
     private void addProperties(Element parent, Iterator<Property> properties, CompositeMapperBuilder currentMapper,
                                ClassAuditingData auditingData, String entityName, EntityXmlMappingData xmlMappingData,
                                boolean firstPass) {
         while (properties.hasNext()) {
             Property property = properties.next();
             String propertyName = property.getName();
 			PropertyAuditingData propertyAuditingData = auditingData.getPropertyAuditingData(propertyName);
             if (propertyAuditingData != null) {
 				addValue(parent, property.getValue(), currentMapper, entityName, xmlMappingData, propertyAuditingData,
 						property.isInsertable(), firstPass);
             }
         }
     }
 
 	private boolean checkPropertiesAudited(Iterator<Property> properties, ClassAuditingData auditingData) {
 		while (properties.hasNext()) {
 			Property property = properties.next();
             String propertyName = property.getName();
 			PropertyAuditingData propertyAuditingData = auditingData.getPropertyAuditingData(propertyName);
             if (propertyAuditingData == null) {
 				return false;
 			}
 		}
 
 		return true;
 	}
 
     protected String getSchema(String schemaFromAnnotation, Table table) {
         // Get the schema from the annotation ...
         String schema = schemaFromAnnotation;
         // ... if empty, try using the default ...
         if (StringTools.isEmpty(schema)) {
             schema = globalCfg.getDefaultSchemaName();
 
             // ... if still empty, use the same as the normal table.
             if (StringTools.isEmpty(schema)) {
                 schema = table.getSchema();
             }
         }
 
         return schema;
     }
 
     protected String getCatalog(String catalogFromAnnotation, Table table) {
         // Get the catalog from the annotation ...
         String catalog = catalogFromAnnotation;
         // ... if empty, try using the default ...
         if (StringTools.isEmpty(catalog)) {
             catalog = globalCfg.getDefaultCatalogName();
 
             // ... if still empty, use the same as the normal table.
             if (StringTools.isEmpty(catalog)) {
                 catalog = table.getCatalog();
             }
         }
 
         return catalog;
     }
 
     @SuppressWarnings({"unchecked"})
     private void createJoins(PersistentClass pc, Element parent, ClassAuditingData auditingData) {
         Iterator<Join> joins = pc.getJoinIterator();
 
         Map<Join, Element> joinElements = new HashMap<Join, Element>();
         entitiesJoins.put(pc.getEntityName(), joinElements);
 
         while (joins.hasNext()) {
             Join join = joins.next();
 
 			// Checking if all of the join properties are audited
 			if (!checkPropertiesAudited(join.getPropertyIterator(), auditingData)) {
 				continue;
 			}
 
             // Determining the table name. If there is no entry in the dictionary, just constructing the table name
             // as if it was an entity (by appending/prepending configured strings).
             String originalTableName = join.getTable().getName();
             String auditTableName = auditingData.getSecondaryTableDictionary().get(originalTableName);
             if (auditTableName == null) {
                 auditTableName = verEntCfg.getAuditEntityName(originalTableName);
             }
 
             String schema = getSchema(auditingData.getAuditTable().schema(), join.getTable());
             String catalog = getCatalog(auditingData.getAuditTable().catalog(), join.getTable());
 
             Element joinElement = MetadataTools.createJoin(parent, auditTableName, schema, catalog);
             joinElements.put(join, joinElement);
 
             Element joinKey = joinElement.addElement("key");
             MetadataTools.addColumns(joinKey, join.getKey().getColumnIterator());
             MetadataTools.addColumn(joinKey, verEntCfg.getRevisionFieldName(), null, 0, 0, null, null, null);
         }
     }
 
     @SuppressWarnings({"unchecked"})
     private void addJoins(PersistentClass pc, CompositeMapperBuilder currentMapper, ClassAuditingData auditingData,
                           String entityName, EntityXmlMappingData xmlMappingData,boolean firstPass) {
         Iterator<Join> joins = pc.getJoinIterator();
 
         while (joins.hasNext()) {
             Join join = joins.next();
             Element joinElement = entitiesJoins.get(entityName).get(join);
 
 			if (joinElement != null) {
             	addProperties(joinElement, join.getPropertyIterator(), currentMapper, auditingData, entityName,
                 	    xmlMappingData, firstPass);
 			}
         }
     }
 
     @SuppressWarnings({"unchecked"})
     private Triple<Element, ExtendedPropertyMapper, String> generateMappingData(
             PersistentClass pc, EntityXmlMappingData xmlMappingData, AuditTableData auditTableData,
             IdMappingData idMapper) {
         Element class_mapping = MetadataTools.createEntity(xmlMappingData.getMainXmlMapping(), auditTableData,
                 pc.getDiscriminatorValue());
         ExtendedPropertyMapper propertyMapper = new MultiPropertyMapper();
 
         // Checking if there is a discriminator column
         if (pc.getDiscriminator() != null) {
             Element discriminator_element = class_mapping.addElement("discriminator");
             MetadataTools.addColumns(discriminator_element, pc.getDiscriminator().getColumnIterator());
             discriminator_element.addAttribute("type", pc.getDiscriminator().getType().getName());
         }
 
         // Adding the id mapping
         class_mapping.add((Element) idMapper.getXmlMapping().clone());
 
         // Adding the "revision type" property
         addRevisionType(class_mapping);
 
         return Triple.make(class_mapping, propertyMapper, null);
     }
 
     private Triple<Element, ExtendedPropertyMapper, String> generateInheritanceMappingData(
             PersistentClass pc, EntityXmlMappingData xmlMappingData, AuditTableData auditTableData,
             String inheritanceMappingType) {
         String extendsEntityName = verEntCfg.getAuditEntityName(pc.getSuperclass().getEntityName());
         Element class_mapping = MetadataTools.createSubclassEntity(xmlMappingData.getMainXmlMapping(),
                 inheritanceMappingType, auditTableData, extendsEntityName, pc.getDiscriminatorValue());
 
         // The id and revision type is already mapped in the parent
 
         // Getting the property mapper of the parent - when mapping properties, they need to be included
         String parentEntityName = pc.getSuperclass().getEntityName();
 
         EntityConfiguration parentConfiguration = entitiesConfigurations.get(parentEntityName);
         if (parentConfiguration == null) {
             throw new MappingException("Entity '" + pc.getEntityName() + "' is audited, but its superclass: '" +
                     parentEntityName + "' is not.");
         }
 
         ExtendedPropertyMapper parentPropertyMapper = parentConfiguration.getPropertyMapper();
         ExtendedPropertyMapper propertyMapper = new SubclassPropertyMapper(new MultiPropertyMapper(), parentPropertyMapper);
 
         return Triple.make(class_mapping, propertyMapper, parentEntityName);
     }
 
     @SuppressWarnings({"unchecked"})
     public void generateFirstPass(PersistentClass pc, ClassAuditingData auditingData,
                                   EntityXmlMappingData xmlMappingData, boolean isAudited) {
         String schema = getSchema(auditingData.getAuditTable().schema(), pc.getTable());
         String catalog = getCatalog(auditingData.getAuditTable().catalog(), pc.getTable());
 
 		if (!isAudited) {
 			String entityName = pc.getEntityName();
 			IdMappingData idMapper = idMetadataGenerator.addId(pc, false);
 
             if (idMapper == null) {
                 // Unsupported id mapping, e.g. key-many-to-one. If the entity is used in auditing, an exception
                 // will be thrown later on.
                 LOG.debugf("Unable to create auditing id mapping for entity %s, because of an unsupported Hibernate id mapping (e.g. key-many-to-one)",
                            entityName);
                 return;
             }
 
 			ExtendedPropertyMapper propertyMapper = null;
 			String parentEntityName = null;
 			EntityConfiguration entityCfg = new EntityConfiguration(entityName, pc.getClassName(), idMapper, propertyMapper,
 					parentEntityName);
 			notAuditedEntitiesConfigurations.put(entityName, entityCfg);
 			return;
 		}
 
         String entityName = pc.getEntityName();
         LOG.debugf("Generating first-pass auditing mapping for entity %s", entityName);
 
         String auditEntityName = verEntCfg.getAuditEntityName(entityName);
         String auditTableName = verEntCfg.getAuditTableName(entityName, pc.getTable().getName());
 
         // Registering the audit entity name, now that it is known
         auditEntityNameRegister.register(auditEntityName);
 
         AuditTableData auditTableData = new AuditTableData(auditEntityName, auditTableName, schema, catalog);
 
         // Generating a mapping for the id
         IdMappingData idMapper = idMetadataGenerator.addId(pc, true);
 
         InheritanceType inheritanceType = InheritanceType.get(pc);
 
         // These properties will be read from the mapping data
         final Element class_mapping;
         final ExtendedPropertyMapper propertyMapper;
         final String parentEntityName;
 
         final Triple<Element, ExtendedPropertyMapper, String> mappingData;
 
         // Reading the mapping data depending on inheritance type (if any)
         switch (inheritanceType) {
             case NONE:
                 mappingData = generateMappingData(pc, xmlMappingData, auditTableData, idMapper);
                 break;
 
             case SINGLE:
                 mappingData = generateInheritanceMappingData(pc, xmlMappingData, auditTableData, "subclass");
                 break;
 
             case JOINED:
                 mappingData = generateInheritanceMappingData(pc, xmlMappingData, auditTableData, "joined-subclass");
 
                 // Adding the "key" element with all id columns...
                 Element keyMapping = mappingData.getFirst().addElement("key");
                 MetadataTools.addColumns(keyMapping, pc.getTable().getPrimaryKey().columnIterator());
 
                 // ... and the revision number column, read from the revision info relation mapping.
                 keyMapping.add((Element) cloneAndSetupRevisionInfoRelationMapping().element("column").clone());
                 break;
 
             case TABLE_PER_CLASS:
                 mappingData = generateInheritanceMappingData(pc, xmlMappingData, auditTableData, "union-subclass");
                 break;
 
             default:
                 throw new AssertionError("Impossible enum value.");
         }
 
         class_mapping = mappingData.getFirst();
         propertyMapper = mappingData.getSecond();
         parentEntityName = mappingData.getThird();
 
         xmlMappingData.setClassMapping(class_mapping);
 
         // Mapping unjoined properties
         addProperties(class_mapping, pc.getUnjoinedPropertyIterator(), propertyMapper,
                 auditingData, pc.getEntityName(), xmlMappingData,
                 true);
 
         // Creating and mapping joins (first pass)
         createJoins(pc, class_mapping, auditingData);
         addJoins(pc, propertyMapper, auditingData, pc.getEntityName(), xmlMappingData, true);
 
         // Storing the generated configuration
         EntityConfiguration entityCfg = new EntityConfiguration(auditEntityName,pc.getClassName(), idMapper,
                 propertyMapper, parentEntityName);
         entitiesConfigurations.put(pc.getEntityName(), entityCfg);
     }
 
     @SuppressWarnings({"unchecked"})
     public void generateSecondPass(PersistentClass pc, ClassAuditingData auditingData,
                                    EntityXmlMappingData xmlMappingData) {
         String entityName = pc.getEntityName();
         LOG.debugf("Generating second-pass auditing mapping for entity %s", entityName);
 
         CompositeMapperBuilder propertyMapper = entitiesConfigurations.get(entityName).getPropertyMapper();
 
         // Mapping unjoined properties
         Element parent = xmlMappingData.getClassMapping();
 
         addProperties(parent, pc.getUnjoinedPropertyIterator(),
                 propertyMapper, auditingData, entityName, xmlMappingData, false);
 
         // Mapping joins (second pass)
         addJoins(pc, propertyMapper, auditingData, entityName, xmlMappingData, false);
     }
 
     public Map<String, EntityConfiguration> getEntitiesConfigurations() {
         return entitiesConfigurations;
     }
 
     // Getters for generators and configuration
 
     BasicMetadataGenerator getBasicMetadataGenerator() {
         return basicMetadataGenerator;
     }
 
     Configuration getCfg() {
         return cfg;
     }
 
     GlobalConfiguration getGlobalCfg() {
         return globalCfg;
     }
 
     AuditEntitiesConfiguration getVerEntCfg() {
         return verEntCfg;
     }
 
     AuditStrategy getAuditStrategy() {
         return auditStrategy;
     }
 
     AuditEntityNameRegister getAuditEntityNameRegister() {
         return auditEntityNameRegister;
     }
 
     void throwUnsupportedTypeException(Type type, String entityName, String propertyName) {
         String message = "Type not supported for auditing: " + type.getClass().getName() +
                 ", on entity " + entityName + ", property '" + propertyName + "'.";
 
         throw new MappingException(message);
     }
 
     /**
      * Reads the id mapping data of a referenced entity.
      * @param entityName Name of the entity which is the source of the relation.
      * @param referencedEntityName Name of the entity which is the target of the relation.
      * @param propertyAuditingData Auditing data of the property that is the source of the relation.
      * @param allowNotAuditedTarget Are not-audited target entities allowed.
      * @throws MappingException If a relation from an audited to a non-audited entity is detected, which is not
      * mapped using {@link RelationTargetAuditMode#NOT_AUDITED}.
      * @return The id mapping data of the related entity.
      */
     IdMappingData getReferencedIdMappingData(String entityName, String referencedEntityName,
                                              PropertyAuditingData propertyAuditingData,
                                              boolean allowNotAuditedTarget) {
         EntityConfiguration configuration = getEntitiesConfigurations().get(referencedEntityName);
 		if (configuration == null) {
             RelationTargetAuditMode relationTargetAuditMode = propertyAuditingData.getRelationTargetAuditMode();
 			configuration = getNotAuditedEntitiesConfigurations().get(referencedEntityName);
 
 			if (configuration == null || !allowNotAuditedTarget || !RelationTargetAuditMode.NOT_AUDITED.equals(relationTargetAuditMode)) {
 				throw new MappingException("An audited relation from " + entityName + "."
 						+ propertyAuditingData.getName() + " to a not audited entity " + referencedEntityName + "!"
 						+ (allowNotAuditedTarget ?
                             " Such mapping is possible, but has to be explicitly defined using @Audited(targetAuditMode = NOT_AUDITED)." :
                             ""));
 			}
 		}
 
         return configuration.getIdMappingData();
     }
 
 	/**
 	 * Get the notAuditedEntitiesConfigurations property.
 	 *
 	 * @return the notAuditedEntitiesConfigurations property value
 	 */
 	public Map<String, EntityConfiguration> getNotAuditedEntitiesConfigurations() {
 		return notAuditedEntitiesConfigurations;
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/metadata/CollectionMetadataGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/metadata/CollectionMetadataGenerator.java
index 8a39841028..8d69b06f13 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/metadata/CollectionMetadataGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/metadata/CollectionMetadataGenerator.java
@@ -1,642 +1,642 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.metadata;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.TreeMap;
 import java.util.TreeSet;
 import javax.persistence.JoinColumn;
 import org.dom4j.Element;
 import org.hibernate.MappingException;
-import org.hibernate.envers.EnversLogger;
+import org.hibernate.envers.internal.EnversMessageLogger;
 import org.hibernate.envers.ModificationStore;
 import org.hibernate.envers.RelationTargetAuditMode;
 import org.hibernate.envers.configuration.metadata.reader.PropertyAuditingData;
 import org.hibernate.envers.entities.EntityConfiguration;
 import org.hibernate.envers.entities.IdMappingData;
 import org.hibernate.envers.entities.PropertyData;
 import org.hibernate.envers.entities.mapper.CompositeMapperBuilder;
 import org.hibernate.envers.entities.mapper.PropertyMapper;
 import org.hibernate.envers.entities.mapper.SinglePropertyMapper;
 import org.hibernate.envers.entities.mapper.id.IdMapper;
 import org.hibernate.envers.entities.mapper.relation.BasicCollectionMapper;
 import org.hibernate.envers.entities.mapper.relation.CommonCollectionMapperData;
 import org.hibernate.envers.entities.mapper.relation.ListCollectionMapper;
 import org.hibernate.envers.entities.mapper.relation.MapCollectionMapper;
 import org.hibernate.envers.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.entities.mapper.relation.ToOneIdMapper;
 import org.hibernate.envers.entities.mapper.relation.component.MiddleDummyComponentMapper;
 import org.hibernate.envers.entities.mapper.relation.component.MiddleMapKeyIdComponentMapper;
 import org.hibernate.envers.entities.mapper.relation.component.MiddleMapKeyPropertyComponentMapper;
 import org.hibernate.envers.entities.mapper.relation.component.MiddleRelatedComponentMapper;
 import org.hibernate.envers.entities.mapper.relation.component.MiddleSimpleComponentMapper;
 import org.hibernate.envers.entities.mapper.relation.component.MiddleStraightComponentMapper;
 import org.hibernate.envers.entities.mapper.relation.lazy.proxy.ListProxy;
 import org.hibernate.envers.entities.mapper.relation.lazy.proxy.MapProxy;
 import org.hibernate.envers.entities.mapper.relation.lazy.proxy.SetProxy;
 import org.hibernate.envers.entities.mapper.relation.lazy.proxy.SortedMapProxy;
 import org.hibernate.envers.entities.mapper.relation.lazy.proxy.SortedSetProxy;
 import org.hibernate.envers.entities.mapper.relation.query.OneAuditEntityQueryGenerator;
 import org.hibernate.envers.entities.mapper.relation.query.RelationQueryGenerator;
 import org.hibernate.envers.tools.MappingTools;
 import org.hibernate.envers.tools.StringTools;
 import org.hibernate.envers.tools.Tools;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.OneToMany;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.Value;
 import org.hibernate.type.BagType;
 import org.hibernate.type.ListType;
 import org.hibernate.type.ManyToOneType;
 import org.hibernate.type.MapType;
 import org.hibernate.type.SetType;
 import org.hibernate.type.SortedMapType;
 import org.hibernate.type.SortedSetType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Generates metadata for a collection-valued property.
  * @author Adam Warski (adam at warski dot org)
  * @author Hern�n Chanfreau
  */
 public final class CollectionMetadataGenerator {
 
-    public static final EnversLogger LOG = Logger.getMessageLogger(EnversLogger.class, CollectionMetadataGenerator.class.getName());
+    public static final EnversMessageLogger LOG = Logger.getMessageLogger(EnversMessageLogger.class, CollectionMetadataGenerator.class.getName());
 
     private final AuditMetadataGenerator mainGenerator;
     private final String propertyName;
     private final Collection propertyValue;
     private final CompositeMapperBuilder currentMapper;
     private final String referencingEntityName;
     private final EntityXmlMappingData xmlMappingData;
     private final PropertyAuditingData propertyAuditingData;
 
     private final EntityConfiguration referencingEntityConfiguration;
     /**
      * Null if this collection isn't a relation to another entity.
      */
     private final String referencedEntityName;
 
 	/**
      * @param mainGenerator Main generator, giving access to configuration and the basic mapper.
      * @param propertyValue Value of the collection, as mapped by Hibernate.
      * @param currentMapper Mapper, to which the appropriate {@link org.hibernate.envers.entities.mapper.PropertyMapper}
      * will be added.
      * @param referencingEntityName Name of the entity that owns this collection.
      * @param xmlMappingData In case this collection requires a middle table, additional mapping documents will
      * be created using this object.
      * @param propertyAuditingData Property auditing (meta-)data. Among other things, holds the name of the
      * property that references the collection in the referencing entity, the user data for middle (join)
      * table and the value of the <code>@MapKey</code> annotation, if there was one.
      */
     public CollectionMetadataGenerator(AuditMetadataGenerator mainGenerator,
                                        Collection propertyValue, CompositeMapperBuilder currentMapper,
                                        String referencingEntityName, EntityXmlMappingData xmlMappingData,
                                        PropertyAuditingData propertyAuditingData) {
         this.mainGenerator = mainGenerator;
         this.propertyValue = propertyValue;
         this.currentMapper = currentMapper;
         this.referencingEntityName = referencingEntityName;
         this.xmlMappingData = xmlMappingData;
         this.propertyAuditingData = propertyAuditingData;
 
         this.propertyName = propertyAuditingData.getName();
 
         referencingEntityConfiguration = mainGenerator.getEntitiesConfigurations().get(referencingEntityName);
         if (referencingEntityConfiguration == null) {
             throw new MappingException("Unable to read auditing configuration for " + referencingEntityName + "!");
         }
 
         referencedEntityName = MappingTools.getReferencedEntityName(propertyValue.getElement());
     }
 
     void addCollection() {
         Type type = propertyValue.getType();
 
         boolean oneToManyAttachedType = type instanceof BagType || type instanceof SetType || type instanceof MapType || type instanceof ListType;
         boolean inverseOneToMany = (propertyValue.getElement() instanceof OneToMany) && (propertyValue.isInverse());
         boolean fakeOneToManyBidirectional = (propertyValue.getElement() instanceof OneToMany) && (propertyAuditingData.getAuditMappedBy() != null);
 
         if (oneToManyAttachedType && (inverseOneToMany || fakeOneToManyBidirectional)) {
             // A one-to-many relation mapped using @ManyToOne and @OneToMany(mappedBy="...")
             addOneToManyAttached(fakeOneToManyBidirectional);
         } else {
             // All other kinds of relations require a middle (join) table.
             addWithMiddleTable();
         }
     }
 
     private MiddleIdData createMiddleIdData(IdMappingData idMappingData, String prefix, String entityName) {
         return new MiddleIdData(mainGenerator.getVerEntCfg(), idMappingData, prefix, entityName,
                 mainGenerator.getEntitiesConfigurations().containsKey(entityName));
     }
 
     @SuppressWarnings({"unchecked"})
     private void addOneToManyAttached(boolean fakeOneToManyBidirectional) {
         LOG.debugf("Adding audit mapping for property %s.%s: one-to-many collection, using a join column on the referenced entity",
                    referencingEntityName,
                    propertyName);
 
         String mappedBy = getMappedBy(propertyValue);
 
         IdMappingData referencedIdMapping = mainGenerator.getReferencedIdMappingData(referencingEntityName,
                     referencedEntityName, propertyAuditingData, false);
         IdMappingData referencingIdMapping = referencingEntityConfiguration.getIdMappingData();
 
         // Generating the id mappers data for the referencing side of the relation.
         MiddleIdData referencingIdData = createMiddleIdData(referencingIdMapping,
                 mappedBy + "_", referencingEntityName);
 
         // And for the referenced side. The prefixed mapper won't be used (as this collection isn't persisted
         // in a join table, so the prefix value is arbitrary).
         MiddleIdData referencedIdData = createMiddleIdData(referencedIdMapping,
                 null, referencedEntityName);
 
         // Generating the element mapping.
         MiddleComponentData elementComponentData = new MiddleComponentData(
                 new MiddleRelatedComponentMapper(referencedIdData), 0);
 
         // Generating the index mapping, if an index exists. It can only exists in case a javax.persistence.MapKey
         // annotation is present on the entity. So the middleEntityXml will be not be used. The queryGeneratorBuilder
         // will only be checked for nullnes.
         MiddleComponentData indexComponentData = addIndex(null, null);
 
         // Generating the query generator - it should read directly from the related entity.
         RelationQueryGenerator queryGenerator = new OneAuditEntityQueryGenerator(mainGenerator.getGlobalCfg(),
                 mainGenerator.getVerEntCfg(), mainGenerator.getAuditStrategy(),
                 referencingIdData, referencedEntityName, referencedIdData);
 
         // Creating common mapper data.
         CommonCollectionMapperData commonCollectionMapperData = new CommonCollectionMapperData(
                 mainGenerator.getVerEntCfg(), referencedEntityName,
                 propertyAuditingData.getPropertyData(),
                 referencingIdData, queryGenerator);
 
         PropertyMapper fakeBidirectionalRelationMapper;
         PropertyMapper fakeBidirectionalRelationIndexMapper;
         if (fakeOneToManyBidirectional) {
             // In case of a fake many-to-one bidirectional relation, we have to generate a mapper which maps
             // the mapped-by property name to the id of the related entity (which is the owner of the collection).
             String auditMappedBy = propertyAuditingData.getAuditMappedBy();
 
             // Creating a prefixed relation mapper.
             IdMapper relMapper = referencingIdMapping.getIdMapper().prefixMappedProperties(
                     MappingTools.createToOneRelationPrefix(auditMappedBy));
 
             fakeBidirectionalRelationMapper = new ToOneIdMapper(
                     relMapper,
                     // The mapper will only be used to map from entity to map, so no need to provide other details
                     // when constructing the PropertyData.
                     new PropertyData(auditMappedBy, null, null, null),
                     referencingEntityName, false);
 
             // Checking if there's an index defined. If so, adding a mapper for it.
             if (propertyAuditingData.getPositionMappedBy() != null) {
                 String positionMappedBy = propertyAuditingData.getPositionMappedBy();
                 fakeBidirectionalRelationIndexMapper = new SinglePropertyMapper(new PropertyData(positionMappedBy, null, null, null));
 
                 // Also, overwriting the index component data to properly read the index.
                 indexComponentData = new MiddleComponentData(new MiddleStraightComponentMapper(positionMappedBy), 0);
             } else {
                 fakeBidirectionalRelationIndexMapper = null;
             }
         } else {
             fakeBidirectionalRelationMapper = null;
             fakeBidirectionalRelationIndexMapper = null;
         }
 
         // Checking the type of the collection and adding an appropriate mapper.
         addMapper(commonCollectionMapperData, elementComponentData, indexComponentData);
 
         // Storing information about this relation.
         referencingEntityConfiguration.addToManyNotOwningRelation(propertyName, mappedBy,
                 referencedEntityName, referencingIdData.getPrefixedMapper(), fakeBidirectionalRelationMapper,
                 fakeBidirectionalRelationIndexMapper);
     }
 
     /**
      * Adds mapping of the id of a related entity to the given xml mapping, prefixing the id with the given prefix.
      * @param xmlMapping Mapping, to which to add the xml.
      * @param prefix Prefix for the names of properties which will be prepended to properties that form the id.
      * @param columnNameIterator Iterator over the column names that will be used for properties that form the id.
      * @param relatedIdMapping Id mapping data of the related entity.
      */
     @SuppressWarnings({"unchecked"})
     private void addRelatedToXmlMapping(Element xmlMapping, String prefix,
                                         MetadataTools.ColumnNameIterator columnNameIterator,
                                         IdMappingData relatedIdMapping) {
         Element properties = (Element) relatedIdMapping.getXmlRelationMapping().clone();
         MetadataTools.prefixNamesInPropertyElement(properties, prefix, columnNameIterator, true, true);
         for (Element idProperty : (java.util.List<Element>) properties.elements()) {
             xmlMapping.add((Element) idProperty.clone());
         }
     }
 
     private String getMiddleTableName(Collection value, String entityName) {
         // We check how Hibernate maps the collection.
         if (value.getElement() instanceof OneToMany && !value.isInverse()) {
             // This must be a @JoinColumn+@OneToMany mapping. Generating the table name, as Hibernate doesn't use a
             // middle table for mapping this relation.
             return StringTools.getLastComponent(entityName) + "_" + StringTools.getLastComponent(MappingTools.getReferencedEntityName(value.getElement()));
         }
         // Hibernate uses a middle table for mapping this relation, so we get it's name directly.
         return value.getCollectionTable().getName();
     }
 
     @SuppressWarnings({"unchecked"})
     private void addWithMiddleTable() {
 
         LOG.debugf("Adding audit mapping for property %s.%s: collection with a join table", referencingEntityName, propertyName);
 
         // Generating the name of the middle table
         String auditMiddleTableName;
         String auditMiddleEntityName;
         if (!StringTools.isEmpty(propertyAuditingData.getJoinTable().name())) {
             auditMiddleTableName = propertyAuditingData.getJoinTable().name();
             auditMiddleEntityName = propertyAuditingData.getJoinTable().name();
         } else {
             String middleTableName = getMiddleTableName(propertyValue, referencingEntityName);
             auditMiddleTableName = mainGenerator.getVerEntCfg().getAuditTableName(null, middleTableName);
             auditMiddleEntityName = mainGenerator.getVerEntCfg().getAuditEntityName(middleTableName);
         }
 
         LOG.debugf("Using join table name: %s", auditMiddleTableName);
 
         // Generating the XML mapping for the middle entity, only if the relation isn't inverse.
         // If the relation is inverse, will be later checked by comparing middleEntityXml with null.
         Element middleEntityXml;
         if (!propertyValue.isInverse()) {
             // Generating a unique middle entity name
             auditMiddleEntityName = mainGenerator.getAuditEntityNameRegister().createUnique(auditMiddleEntityName);
 
             // Registering the generated name
             mainGenerator.getAuditEntityNameRegister().register(auditMiddleEntityName);
 
             middleEntityXml = createMiddleEntityXml(auditMiddleTableName, auditMiddleEntityName, propertyValue.getWhere());
         } else {
             middleEntityXml = null;
         }
 
         // ******
         // Generating the mapping for the referencing entity (it must be an entity).
         // ******
         // Getting the id-mapping data of the referencing entity (the entity that "owns" this collection).
         IdMappingData referencingIdMapping = referencingEntityConfiguration.getIdMappingData();
 
         // Only valid for an inverse relation; null otherwise.
         String mappedBy;
 
         // The referencing prefix is always for a related entity. So it has always the "_" at the end added.
         String referencingPrefixRelated;
         String referencedPrefix;
 
         if (propertyValue.isInverse()) {
             // If the relation is inverse, then referencedEntityName is not null.
             mappedBy = getMappedBy(propertyValue.getCollectionTable(), mainGenerator.getCfg().getClassMapping(referencedEntityName));
 
             referencingPrefixRelated = mappedBy + "_";
             referencedPrefix = StringTools.getLastComponent(referencedEntityName);
         } else {
             mappedBy = null;
 
             referencingPrefixRelated = StringTools.getLastComponent(referencingEntityName) + "_";
             referencedPrefix = referencedEntityName == null ? "element" : propertyName;
         }
 
         // Storing the id data of the referencing entity: original mapper, prefixed mapper and entity name.
         MiddleIdData referencingIdData = createMiddleIdData(referencingIdMapping,
                 referencingPrefixRelated, referencingEntityName);
 
         // Creating a query generator builder, to which additional id data will be added, in case this collection
         // references some entities (either from the element or index). At the end, this will be used to build
         // a query generator to read the raw data collection from the middle table.
 		QueryGeneratorBuilder queryGeneratorBuilder = new QueryGeneratorBuilder(mainGenerator.getGlobalCfg(),
                 mainGenerator.getVerEntCfg(), mainGenerator.getAuditStrategy(), referencingIdData,
 				auditMiddleEntityName);
 
         // Adding the XML mapping for the referencing entity, if the relation isn't inverse.
         if (middleEntityXml != null) {
             // Adding related-entity (in this case: the referencing's entity id) id mapping to the xml.
             addRelatedToXmlMapping(middleEntityXml, referencingPrefixRelated,
                     MetadataTools.getColumnNameIterator(propertyValue.getKey().getColumnIterator()),
                     referencingIdMapping);
         }
 
         // ******
         // Generating the element mapping.
         // ******
         MiddleComponentData elementComponentData = addValueToMiddleTable(propertyValue.getElement(), middleEntityXml,
                 queryGeneratorBuilder, referencedPrefix, propertyAuditingData.getJoinTable().inverseJoinColumns());
 
         // ******
         // Generating the index mapping, if an index exists.
         // ******
         MiddleComponentData indexComponentData = addIndex(middleEntityXml, queryGeneratorBuilder);
 
         // ******
         // Generating the property mapper.
         // ******
         // Building the query generator.
         RelationQueryGenerator queryGenerator = queryGeneratorBuilder.build(elementComponentData, indexComponentData);
 
         // Creating common data
         CommonCollectionMapperData commonCollectionMapperData = new CommonCollectionMapperData(
                 mainGenerator.getVerEntCfg(), auditMiddleEntityName,
                 propertyAuditingData.getPropertyData(),
                 referencingIdData, queryGenerator);
 
         // Checking the type of the collection and adding an appropriate mapper.
         addMapper(commonCollectionMapperData, elementComponentData, indexComponentData);
 
         // ******
         // Storing information about this relation.
         // ******
         storeMiddleEntityRelationInformation(mappedBy);
     }
 
     private MiddleComponentData addIndex(Element middleEntityXml, QueryGeneratorBuilder queryGeneratorBuilder) {
         if (propertyValue instanceof IndexedCollection) {
             IndexedCollection indexedValue = (IndexedCollection) propertyValue;
             String mapKey = propertyAuditingData.getMapKey();
             if (mapKey == null) {
                 // This entity doesn't specify a javax.persistence.MapKey. Mapping it to the middle entity.
                 return addValueToMiddleTable(indexedValue.getIndex(), middleEntityXml,
                         queryGeneratorBuilder, "mapkey", null);
             } else {
                 IdMappingData referencedIdMapping = mainGenerator.getEntitiesConfigurations()
                         .get(referencedEntityName).getIdMappingData();
                 int currentIndex = queryGeneratorBuilder == null ? 0 : queryGeneratorBuilder.getCurrentIndex();
                 if ("".equals(mapKey)) {
                     // The key of the map is the id of the entity.
                     return new MiddleComponentData(new MiddleMapKeyIdComponentMapper(mainGenerator.getVerEntCfg(),
                             referencedIdMapping.getIdMapper()), currentIndex);
                 } else {
                     // The key of the map is a property of the entity.
                     return new MiddleComponentData(new MiddleMapKeyPropertyComponentMapper(mapKey,
                             propertyAuditingData.getAccessType()), currentIndex);
                 }
             }
         } else {
             // No index - creating a dummy mapper.
             return new MiddleComponentData(new MiddleDummyComponentMapper(), 0);
         }
     }
 
     /**
      *
      * @param value Value, which should be mapped to the middle-table, either as a relation to another entity,
      * or as a simple value.
      * @param xmlMapping If not <code>null</code>, xml mapping for this value is added to this element.
      * @param queryGeneratorBuilder In case <code>value</code> is a relation to another entity, information about it
      * should be added to the given.
      * @param prefix Prefix for proeprty names of related entities identifiers.
      * @param joinColumns Names of columns to use in the xml mapping, if this array isn't null and has any elements.
      * @return Data for mapping this component.
      */
     @SuppressWarnings({"unchecked"})
     private MiddleComponentData addValueToMiddleTable(Value value, Element xmlMapping,
                                                       QueryGeneratorBuilder queryGeneratorBuilder,
                                                       String prefix, JoinColumn[] joinColumns) {
         Type type = value.getType();
         if (type instanceof ManyToOneType) {
             String prefixRelated = prefix + "_";
 
             String referencedEntityName = MappingTools.getReferencedEntityName(value);
 
             IdMappingData referencedIdMapping = mainGenerator.getReferencedIdMappingData(referencingEntityName,
                     referencedEntityName, propertyAuditingData, true);
 
             // Adding related-entity (in this case: the referenced entities id) id mapping to the xml only if the
             // relation isn't inverse (so when <code>xmlMapping</code> is not null).
             if (xmlMapping != null) {
                 addRelatedToXmlMapping(xmlMapping, prefixRelated,
                         joinColumns != null && joinColumns.length > 0
                                 ? MetadataTools.getColumnNameIterator(joinColumns)
                                 : MetadataTools.getColumnNameIterator(value.getColumnIterator()),
                         referencedIdMapping);
             }
 
             // Storing the id data of the referenced entity: original mapper, prefixed mapper and entity name.
             MiddleIdData referencedIdData = createMiddleIdData(referencedIdMapping,
                     prefixRelated, referencedEntityName);
             // And adding it to the generator builder.
             queryGeneratorBuilder.addRelation(referencedIdData);
 
             return new MiddleComponentData(new MiddleRelatedComponentMapper(referencedIdData),
                     queryGeneratorBuilder.getCurrentIndex());
         } else {
             // Last but one parameter: collection components are always insertable
             boolean mapped = mainGenerator.getBasicMetadataGenerator().addBasic(xmlMapping,
                     new PropertyAuditingData(prefix, "field", ModificationStore.FULL, RelationTargetAuditMode.AUDITED, null, null, false),
                     value, null, true, true);
 
             if (mapped) {
                 // Simple values are always stored in the first item of the array returned by the query generator.
                 return new MiddleComponentData(new MiddleSimpleComponentMapper(mainGenerator.getVerEntCfg(), prefix), 0);
             } else {
                 mainGenerator.throwUnsupportedTypeException(type, referencingEntityName, propertyName);
                 // Impossible to get here.
                 throw new AssertionError();
             }
         }
     }
 
     private void addMapper(CommonCollectionMapperData commonCollectionMapperData, MiddleComponentData elementComponentData,
                            MiddleComponentData indexComponentData) {
         Type type = propertyValue.getType();
         if (type instanceof SortedSetType) {
             currentMapper.addComposite(propertyAuditingData.getPropertyData(),
                     new BasicCollectionMapper<Set>(commonCollectionMapperData,
                     TreeSet.class, SortedSetProxy.class, elementComponentData));
         } else if (type instanceof SetType) {
             currentMapper.addComposite(propertyAuditingData.getPropertyData(),
                     new BasicCollectionMapper<Set>(commonCollectionMapperData,
                     HashSet.class, SetProxy.class, elementComponentData));
         } else if (type instanceof SortedMapType) {
             // Indexed collection, so <code>indexComponentData</code> is not null.
             currentMapper.addComposite(propertyAuditingData.getPropertyData(),
                     new MapCollectionMapper<Map>(commonCollectionMapperData,
                     TreeMap.class, SortedMapProxy.class, elementComponentData, indexComponentData));
         } else if (type instanceof MapType) {
             // Indexed collection, so <code>indexComponentData</code> is not null.
             currentMapper.addComposite(propertyAuditingData.getPropertyData(),
                     new MapCollectionMapper<Map>(commonCollectionMapperData,
                     HashMap.class, MapProxy.class, elementComponentData, indexComponentData));
         } else if (type instanceof BagType) {
             currentMapper.addComposite(propertyAuditingData.getPropertyData(),
                     new BasicCollectionMapper<List>(commonCollectionMapperData,
                     ArrayList.class, ListProxy.class, elementComponentData));
         } else if (type instanceof ListType) {
             // Indexed collection, so <code>indexComponentData</code> is not null.
             currentMapper.addComposite(propertyAuditingData.getPropertyData(),
                     new ListCollectionMapper(commonCollectionMapperData,
                     elementComponentData, indexComponentData));
         } else {
             mainGenerator.throwUnsupportedTypeException(type, referencingEntityName, propertyName);
         }
     }
 
     private void storeMiddleEntityRelationInformation(String mappedBy) {
         // Only if this is a relation (when there is a referenced entity).
         if (referencedEntityName != null) {
             if (propertyValue.isInverse()) {
                 referencingEntityConfiguration.addToManyMiddleNotOwningRelation(propertyName, mappedBy, referencedEntityName);
             } else {
                 referencingEntityConfiguration.addToManyMiddleRelation(propertyName, referencedEntityName);
             }
         }
     }
 
     private Element createMiddleEntityXml(String auditMiddleTableName, String auditMiddleEntityName, String where) {
         String schema = mainGenerator.getSchema(propertyAuditingData.getJoinTable().schema(), propertyValue.getCollectionTable());
         String catalog = mainGenerator.getCatalog(propertyAuditingData.getJoinTable().catalog(), propertyValue.getCollectionTable());
 
         Element middleEntityXml = MetadataTools.createEntity(xmlMappingData.newAdditionalMapping(),
                 new AuditTableData(auditMiddleEntityName, auditMiddleTableName, schema, catalog), null);
         Element middleEntityXmlId = middleEntityXml.addElement("composite-id");
 
         // If there is a where clause on the relation, adding it to the middle entity.
         if (where != null) {
             middleEntityXml.addAttribute("where", where);
         }
 
         middleEntityXmlId.addAttribute("name", mainGenerator.getVerEntCfg().getOriginalIdPropName());
 
         // Adding the revision number as a foreign key to the revision info entity to the composite id of the
         // middle table.
         mainGenerator.addRevisionInfoRelation(middleEntityXmlId);
 
         // Adding the revision type property to the entity xml.
         mainGenerator.addRevisionType(middleEntityXml);
 
         // All other properties should also be part of the primary key of the middle entity.
         return middleEntityXmlId;
     }
 
     private String getMappedBy(Collection collectionValue) {
         PersistentClass referencedClass = ((OneToMany) collectionValue.getElement()).getAssociatedClass();
 
         // If there's an @AuditMappedBy specified, returning it directly.
         String auditMappedBy = propertyAuditingData.getAuditMappedBy();
         if (auditMappedBy != null) {
             return auditMappedBy;
         }
 
         // searching in referenced class
         String mappedBy = this.searchMappedBy(referencedClass, collectionValue);
 
         if(mappedBy == null) {
             LOG.debugf("Going to search the mapped by attribute for %s in superclasses of entity: %s",
                        propertyName,
                        referencedClass.getClassName());
 
             PersistentClass tempClass = referencedClass;
 			while ((mappedBy == null) && (tempClass.getSuperclass() != null)) {
                 LOG.debugf("Searching in superclass: %s", tempClass.getSuperclass().getClassName());
 				mappedBy = this.searchMappedBy(tempClass.getSuperclass(), collectionValue);
 				tempClass = tempClass.getSuperclass();
 			}
         }
 
         if(mappedBy == null) {
 	        throw new MappingException("Unable to read the mapped by attribute for " + propertyName + " in "
 	                + referencedClass.getClassName() + "!");
         }
 
         return mappedBy;
     }
 
     @SuppressWarnings({"unchecked"})
     private String searchMappedBy(PersistentClass referencedClass, Collection collectionValue) {
         Iterator<Property> assocClassProps = referencedClass.getPropertyIterator();
         while (assocClassProps.hasNext()) {
             Property property = assocClassProps.next();
 
             if (Tools.iteratorsContentEqual(property.getValue().getColumnIterator(),
                     collectionValue.getKey().getColumnIterator())) {
                 return property.getName();
             }
         }
         return null;
     }
 
     private String getMappedBy(Table collectionTable, PersistentClass referencedClass) {
         // If there's an @AuditMappedBy specified, returning it directly.
         String auditMappedBy = propertyAuditingData.getAuditMappedBy();
         if (auditMappedBy != null) {
             return auditMappedBy;
         }
 
         // searching in referenced class
         String mappedBy = this.searchMappedBy(referencedClass, collectionTable);
 
         // not found on referenced class, searching on superclasses
         if(mappedBy == null) {
             LOG.debugf("Going to search the mapped by attribute for %s in superclasses of entity: %s",
                        propertyName,
                        referencedClass.getClassName());
 
             PersistentClass tempClass = referencedClass;
             while ((mappedBy == null) && (tempClass.getSuperclass() != null)) {
                 LOG.debugf("Searching in superclass: %s", tempClass.getSuperclass().getClassName());
                 mappedBy = this.searchMappedBy(tempClass.getSuperclass(), collectionTable);
                 tempClass = tempClass.getSuperclass();
 			}
         }
 
         if(mappedBy == null) {
 	        throw new MappingException("Unable to read the mapped by attribute for " + propertyName + " in "
 	                + referencedClass.getClassName() + "!");
         }
 
         return mappedBy;
     }
 
     @SuppressWarnings({"unchecked"})
     private String searchMappedBy(PersistentClass referencedClass, Table collectionTable) {
         Iterator<Property> properties = referencedClass.getPropertyIterator();
         while (properties.hasNext()) {
             Property property = properties.next();
             if (property.getValue() instanceof Collection) {
                 // The equality is intentional. We want to find a collection property with the same collection table.
                 //noinspection ObjectEquality
                 if (((Collection) property.getValue()).getCollectionTable() == collectionTable) {
                     return property.getName();
                 }
             }
         }
         return null;
     }
 
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/event/EnversIntegrator.java b/hibernate-envers/src/main/java/org/hibernate/envers/event/EnversIntegrator.java
index 9c75de4019..f83f57e40c 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/event/EnversIntegrator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/event/EnversIntegrator.java
@@ -1,78 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.event;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.envers.configuration.AuditConfiguration;
 import org.hibernate.event.EventType;
 import org.hibernate.spi.Integrator;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.event.spi.EventListenerRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 
 /**
  * Provides integration for Envers into Hibernate, which mainly means registering the proper event listeners.
  * 
  * @author Steve Ebersole
  */
 public class EnversIntegrator implements Integrator {
-	private static final HibernateLogger LOG = Logger.getMessageLogger( HibernateLogger.class, EnversIntegrator.class.getName() );
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, EnversIntegrator.class.getName() );
 
 	public static final String AUTO_REGISTER = "hibernate.listeners.envers.autoRegister";
 
 	@Override
 	public void integrate(
 			Configuration configuration,
 			SessionFactoryImplementor sessionFactory,
 			SessionFactoryServiceRegistry serviceRegistry) {
 		final boolean autoRegister = ConfigurationHelper.getBoolean( AUTO_REGISTER, configuration.getProperties(), true );
 		if ( !autoRegister ) {
 			LOG.debug( "Skipping Envers listener auto registration" );
 			return;
 		}
 
 		EventListenerRegistry listenerRegistry = serviceRegistry.getService( EventListenerRegistry.class );
 		listenerRegistry.addDuplicationStrategy( EnversListenerDuplicationStrategy.INSTANCE );
 
 		final AuditConfiguration enversConfiguration = AuditConfiguration.getFor( configuration );
 
         if (enversConfiguration.getEntCfg().hasAuditedEntities()) {
 		    listenerRegistry.appendListeners( EventType.POST_DELETE, new EnversPostDeleteEventListenerImpl( enversConfiguration ) );
 		    listenerRegistry.appendListeners( EventType.POST_INSERT, new EnversPostInsertEventListenerImpl( enversConfiguration ) );
 		    listenerRegistry.appendListeners( EventType.POST_UPDATE, new EnversPostUpdateEventListenerImpl( enversConfiguration ) );
 		    listenerRegistry.appendListeners( EventType.POST_COLLECTION_RECREATE, new EnversPostCollectionRecreateEventListenerImpl( enversConfiguration ) );
 		    listenerRegistry.appendListeners( EventType.PRE_COLLECTION_REMOVE, new EnversPreCollectionRemoveEventListenerImpl( enversConfiguration ) );
 		    listenerRegistry.appendListeners( EventType.PRE_COLLECTION_UPDATE, new EnversPreCollectionUpdateEventListenerImpl( enversConfiguration ) );
         }
 	}
 
 	@Override
 	public void disintegrate(SessionFactoryImplementor sessionFactory, SessionFactoryServiceRegistry serviceRegistry) {
 		// nothing to do afaik
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/EnversLogger.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/EnversMessageLogger.java
similarity index 78%
rename from hibernate-envers/src/main/java/org/hibernate/envers/EnversLogger.java
rename to hibernate-envers/src/main/java/org/hibernate/envers/internal/EnversMessageLogger.java
index a8e9969a38..7896be7a2b 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/EnversLogger.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/EnversMessageLogger.java
@@ -1,42 +1,45 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.envers;
+package org.hibernate.envers.internal;
 
 import static org.jboss.logging.Logger.Level.WARN;
-import org.hibernate.HibernateLogger;
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.LogMessage;
 import org.jboss.logging.Message;
 import org.jboss.logging.MessageLogger;
 
 /**
- * Defines internationalized messages for this hibernate-envers, with IDs ranging from 25001 to 30000 inclusively. New messages must
- * be added after the last message defined to ensure message codes are unique.
+ * The jboss-logging {@link MessageLogger} for the hibernate-envers module.  It reserves message ids ranging from
+ * 25001 to 30000 inclusively.
+ * <p/>
+ * New messages must be added after the last message defined to ensure message codes are unique.
  */
 @MessageLogger( projectCode = "HHH" )
-public interface EnversLogger extends HibernateLogger {
+public interface EnversMessageLogger extends CoreMessageLogger {
 
     @LogMessage( level = WARN )
     @Message( value = "ValidTimeAuditStrategy is deprecated, please use ValidityAuditStrategy instead", id = 25001 )
     void validTimeAuditStrategyDeprecated();
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/reader/FirstLevelCache.java b/hibernate-envers/src/main/java/org/hibernate/envers/reader/FirstLevelCache.java
index 41bfb6dab6..81f0370370 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/reader/FirstLevelCache.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/reader/FirstLevelCache.java
@@ -1,114 +1,114 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.reader;
 import static org.hibernate.envers.tools.Tools.newHashMap;
 import static org.hibernate.envers.tools.Triple.make;
 import java.util.Map;
-import org.hibernate.envers.EnversLogger;
+import org.hibernate.envers.internal.EnversMessageLogger;
 import org.hibernate.envers.tools.Triple;
 import org.jboss.logging.Logger;
 
 /**
  * First level cache for versioned entities, versions reader-scoped. Each entity is uniquely identified by a
  * revision number and entity id.
  * @author Adam Warski (adam at warski dot org)
- * @author Hern&aacute;n Chanfreau
+ * @author Hern&aacute;n Chanfreau
  */
 public class FirstLevelCache {
 
-    public static final EnversLogger LOG = Logger.getMessageLogger(EnversLogger.class, FirstLevelCache.class.getName());
+    public static final EnversMessageLogger LOG = Logger.getMessageLogger(EnversMessageLogger.class, FirstLevelCache.class.getName());
 
-    /**
-     * cache for resolve an object for a given id, revision and entityName.
-     */
+    /**
+     * cache for resolve an object for a given id, revision and entityName.
+     */
     private final Map<Triple<String, Number, Object>, Object> cache;
 
-    /**
-     * used to resolve the entityName for a given id, revision and entity.
-     */
-    private final Map<Triple<Object, Number, Object>, String> entityNameCache;
-
+    /**
+     * used to resolve the entityName for a given id, revision and entity.
+     */
+    private final Map<Triple<Object, Number, Object>, String> entityNameCache;
+
     public FirstLevelCache() {
         cache = newHashMap();
-        entityNameCache = newHashMap();
+        entityNameCache = newHashMap();
     }
 
     public Object get(String entityName, Number revision, Object id) {
-        LOG.debugf("Resolving object from First Level Cache: EntityName:%s - primaryKey:%s - revision:%s", entityName, id, revision);
+        LOG.debugf("Resolving object from First Level Cache: EntityName:%s - primaryKey:%s - revision:%s", entityName, id, revision);
         return cache.get(make(entityName, revision, id));
     }
 
     public void put(String entityName, Number revision, Object id, Object entity) {
-        LOG.debugf("Caching entity on First Level Cache:  - primaryKey:%s - revision:%s - entityName:%s", id, revision, entityName);
+        LOG.debugf("Caching entity on First Level Cache:  - primaryKey:%s - revision:%s - entityName:%s", id, revision, entityName);
         cache.put(make(entityName, revision, id), entity);
     }
 
     public boolean contains(String entityName, Number revision, Object id) {
         return cache.containsKey(make(entityName, revision, id));
     }
-
-    /**
-     * Adds the entityName into the cache. The key is a triple make with primaryKey, revision and entity
-     * @param entityName, value of the cache
-     * @param id, primaryKey
-     * @param revision, revision number
-     * @param entity, object retrieved by envers
-     */
-    public void putOnEntityNameCache(Object id, Number revision, Object entity, String entityName) {
+
+    /**
+     * Adds the entityName into the cache. The key is a triple make with primaryKey, revision and entity
+     * @param entityName, value of the cache
+     * @param id, primaryKey
+     * @param revision, revision number
+     * @param entity, object retrieved by envers
+     */
+    public void putOnEntityNameCache(Object id, Number revision, Object entity, String entityName) {
         LOG.debugf("Caching entityName on First Level Cache:  - primaryKey:%s - revision:%s - entity:%s -> entityName:%s",
                    id,
                    revision,
                    entity.getClass().getName(),
-                   entityName);
-    	entityNameCache.put(make(id, revision, entity), entityName);
-    }
-
-    /**
-     * Gets the entityName from the cache. The key is a triple make with primaryKey, revision and entity
-     * @param entityName, value of the cache
-     * @param id, primaryKey
-     * @param revision, revision number
-     * @param entity, object retrieved by envers
-     */
-    public String getFromEntityNameCache(Object id, Number revision, Object entity) {
+                   entityName);
+    	entityNameCache.put(make(id, revision, entity), entityName);
+    }
+
+    /**
+     * Gets the entityName from the cache. The key is a triple make with primaryKey, revision and entity
+     * @param entityName, value of the cache
+     * @param id, primaryKey
+     * @param revision, revision number
+     * @param entity, object retrieved by envers
+     */
+    public String getFromEntityNameCache(Object id, Number revision, Object entity) {
         LOG.debugf("Trying to resolve entityName from First Level Cache: - primaryKey:%s - revision:%s - entity:%s",
                    id,
                    revision,
-                   entity);
-    	return entityNameCache.get(make(id, revision, entity));
-    }
-
-	/**
-	 * @param id
-	 *            , primaryKey
-	 * @param revision
-	 *            , revision number
-	 * @param entity
-	 *            , object retrieved by envers
-	 * @return true if entityNameCache contains the triple
-	 */
-    public boolean containsEntityName(Object id, Number revision, Object entity) {
-    	return entityNameCache.containsKey(make(id, revision, entity));
-    }
+                   entity);
+    	return entityNameCache.get(make(id, revision, entity));
+    }
+
+	/**
+	 * @param id
+	 *            , primaryKey
+	 * @param revision
+	 *            , revision number
+	 * @param entity
+	 *            , object retrieved by envers
+	 * @return true if entityNameCache contains the triple
+	 */
+    public boolean containsEntityName(Object id, Number revision, Object entity) {
+    	return entityNameCache.containsKey(make(id, revision, entity));
+    }
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidTimeAuditStrategy.java b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidTimeAuditStrategy.java
index 96be28b150..877f51e372 100755
--- a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidTimeAuditStrategy.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidTimeAuditStrategy.java
@@ -1,25 +1,26 @@
 package org.hibernate.envers.strategy;
-import org.hibernate.envers.EnversLogger;
+import org.hibernate.envers.internal.EnversMessageLogger;
+
 import org.jboss.logging.Logger;
-
-/**
+
+/**
  * Deprecated Audit strategy class.
- *
- * @author Stephanie Pau
- * @author Adam Warski (adam at warski dot org)
+ *
+ * @author Stephanie Pau
+ * @author Adam Warski (adam at warski dot org)
  *
  * @deprecated use {@link ValidityAuditStrategy} instead.
- */
-@Deprecated
+ */
+@Deprecated
 public class ValidTimeAuditStrategy extends ValidityAuditStrategy {
-
-    public static final EnversLogger LOG = Logger.getMessageLogger(EnversLogger.class, ValidTimeAuditStrategy.class.getName());
-
+
+    public static final EnversMessageLogger LOG = Logger.getMessageLogger(EnversMessageLogger.class, ValidTimeAuditStrategy.class.getName());
+
 	/**
 	 * Default constructor. Log a warn message that this class is deprecated.
 	 */
 	public ValidTimeAuditStrategy() {
         LOG.validTimeAuditStrategyDeprecated();
-	}
-
-}
+	}
+
+}
diff --git a/hibernate-envers/src/test/java/org/hibernate/envers/test/integration/components/DefaultValueComponents.java b/hibernate-envers/src/test/java/org/hibernate/envers/test/integration/components/DefaultValueComponents.java
index 5ddaf735ee..525c7ca7a8 100644
--- a/hibernate-envers/src/test/java/org/hibernate/envers/test/integration/components/DefaultValueComponents.java
+++ b/hibernate-envers/src/test/java/org/hibernate/envers/test/integration/components/DefaultValueComponents.java
@@ -1,382 +1,383 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.test.integration.components;
 
 import org.hibernate.ejb.Ejb3Configuration;
 import org.hibernate.envers.test.AbstractEntityTest;
 import org.hibernate.envers.test.Priority;
 import org.hibernate.envers.test.entities.components.DefaultValueComponent1;
 import org.hibernate.envers.test.entities.components.DefaultValueComponent2;
 import org.hibernate.envers.test.entities.components.DefaultValueComponentTestEntity;
 import org.junit.Test;
 
 import javax.persistence.EntityManager;
 import java.math.BigInteger;
 import java.util.Arrays;
 
-import static org.hibernate.testing.TestLogger.*;
+import org.jboss.logging.Logger;
 
 /**
  * Test class for components with default values.
  *
  * @see <a
  *      href="http://opensource.atlassian.com/projects/hibernate/browse/HHH-5288">
  *      Hibernate JIRA </a>
  *
  * @author Erik-Berndt Scheper
  */
 public class DefaultValueComponents extends AbstractEntityTest {
+	private static final Logger log = Logger.getLogger( DefaultValueComponents.class );
 
 	private Integer id0;
 	private Integer id1;
 	private Integer id2;
 	private Integer id3;
 	private Integer id4;
 	private Integer id5;
 	private Integer id6;
 
 	@Override
     public void configure(Ejb3Configuration cfg) {
 		cfg.addAnnotatedClass(DefaultValueComponentTestEntity.class);
 	}
 
 	@Test
     @Priority(10)
 	public void initData() {
 		// Revision 1
 		EntityManager em = getEntityManager();
 		em.getTransaction().begin();
 
 		DefaultValueComponentTestEntity cte0 = DefaultValueComponentTestEntity
 				.of(null);
 
 		DefaultValueComponentTestEntity cte1 = DefaultValueComponentTestEntity
 				.of(DefaultValueComponent1.of("c1-str1", null));
 
 		DefaultValueComponentTestEntity cte2 = DefaultValueComponentTestEntity
 				.of(DefaultValueComponent1.of("c1-str1", DefaultValueComponent2
 						.of("c2-str1", "c2-str2")));
 
 		DefaultValueComponentTestEntity cte3 = DefaultValueComponentTestEntity
 				.of(DefaultValueComponent1.of(null, DefaultValueComponent2.of(
 						"c2-str1", "c2-str2")));
 
 		DefaultValueComponentTestEntity cte4 = DefaultValueComponentTestEntity
 				.of(DefaultValueComponent1.of(null, DefaultValueComponent2.of(
 						null, "c2-str2")));
 
 		DefaultValueComponentTestEntity cte5 = DefaultValueComponentTestEntity
 				.of(DefaultValueComponent1.of(null, DefaultValueComponent2.of(
 						"c2-str1", null)));
 
 		DefaultValueComponentTestEntity cte6 = DefaultValueComponentTestEntity
 				.of(DefaultValueComponent1.of(null, DefaultValueComponent2.of(
 						null, null)));
 
 		em.persist(cte0);
 		em.persist(cte1);
 		em.persist(cte2);
 		em.persist(cte3);
 		em.persist(cte4);
 		em.persist(cte5);
 		em.persist(cte6);
 
 		em.getTransaction().commit();
 
 		// Revision 2
 		em = getEntityManager();
 		em.getTransaction().begin();
 
 		cte0 = em.find(DefaultValueComponentTestEntity.class, cte0.getId());
 		cte1 = em.find(DefaultValueComponentTestEntity.class, cte1.getId());
 		cte2 = em.find(DefaultValueComponentTestEntity.class, cte2.getId());
 		cte3 = em.find(DefaultValueComponentTestEntity.class, cte3.getId());
 		cte4 = em.find(DefaultValueComponentTestEntity.class, cte4.getId());
 		cte5 = em.find(DefaultValueComponentTestEntity.class, cte5.getId());
 		cte6 = em.find(DefaultValueComponentTestEntity.class, cte6.getId());
 
 		cte0.setComp1(DefaultValueComponent1.of("upd-c1-str1", null));
 		cte1.setComp1(DefaultValueComponent1.of(null, DefaultValueComponent2
 				.of("upd-c2-str1", "upd-c2-str2")));
 		cte2.getComp1().getComp2().setStr1("upd-c2-str1");
 		cte3.getComp1().getComp2().setStr1("upd-c2-str1");
 		cte4.getComp1().getComp2().setStr1("upd-c2-str1");
 		cte5.getComp1().getComp2().setStr1("upd-c2-str1");
 		cte6.getComp1().getComp2().setStr1("upd-c2-str1");
 
 		em.getTransaction().commit();
 
 		// afterwards
 		id0 = cte0.getId();
 		id1 = cte1.getId();
 		id2 = cte2.getId();
 		id3 = cte3.getId();
 		id4 = cte4.getId();
 		id5 = cte5.getId();
 		id6 = cte6.getId();
 	}
 
 	@Test
 	public void testRevisionsCounts() {
-        LOG.error(getAuditReader().getRevisions(
+        log.error(getAuditReader().getRevisions(
 				DefaultValueComponentTestEntity.class, id0).toString());
-        LOG.error(getAuditReader().getRevisions(
+        log.error(getAuditReader().getRevisions(
 				DefaultValueComponentTestEntity.class, id1).toString());
-        LOG.error(getAuditReader().getRevisions(
+        log.error(getAuditReader().getRevisions(
 				DefaultValueComponentTestEntity.class, id2).toString());
-        LOG.error(getAuditReader().getRevisions(
+        log.error(getAuditReader().getRevisions(
 				DefaultValueComponentTestEntity.class, id3).toString());
-        LOG.error(getAuditReader().getRevisions(
+        log.error(getAuditReader().getRevisions(
 				DefaultValueComponentTestEntity.class, id4).toString());
-        LOG.error(getAuditReader().getRevisions(
+        log.error(getAuditReader().getRevisions(
 				DefaultValueComponentTestEntity.class, id5).toString());
-        LOG.error(getAuditReader().getRevisions(
+        log.error(getAuditReader().getRevisions(
 				DefaultValueComponentTestEntity.class, id6).toString());
 
 		assert Arrays.asList(1, 2).equals(
 				getAuditReader().getRevisions(
 						DefaultValueComponentTestEntity.class, id0));
 
 		assert Arrays.asList(1, 2).equals(
 				getAuditReader().getRevisions(
 						DefaultValueComponentTestEntity.class, id1));
 
 		assert Arrays.asList(1, 2).equals(
 				getAuditReader().getRevisions(
 						DefaultValueComponentTestEntity.class, id2));
 
 		assert Arrays.asList(1, 2).equals(
 				getAuditReader().getRevisions(
 						DefaultValueComponentTestEntity.class, id3));
 
 		assert Arrays.asList(1, 2).equals(
 				getAuditReader().getRevisions(
 						DefaultValueComponentTestEntity.class, id4));
 
 		assert Arrays.asList(1, 2).equals(
 				getAuditReader().getRevisions(
 						DefaultValueComponentTestEntity.class, id5));
 
 		assert Arrays.asList(1, 2).equals(
 				getAuditReader().getRevisions(
 						DefaultValueComponentTestEntity.class, id6));
 	}
 
 	@Test
 	public void testHistoryOfId0() {
 
 		DefaultValueComponentTestEntity ent1 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id0, 1);
 		DefaultValueComponentTestEntity ent2 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id0, 2);
 
-        LOG.error("------------ id0 -------------");
-        LOG.error(ent1.toString());
-        LOG.error(ent2.toString());
+        log.error("------------ id0 -------------");
+        log.error(ent1.toString());
+        log.error(ent2.toString());
 
 		checkCorrectlyPersisted(id0, null, null);
 
 		DefaultValueComponentTestEntity expectedVer1 = DefaultValueComponentTestEntity
 				.of(id0, DefaultValueComponent1.of(null, null));
 		DefaultValueComponentTestEntity expectedVer2 = DefaultValueComponentTestEntity
 				.of(id0, DefaultValueComponent1.of("upd-c1-str1", null));
 
 		assert ent1.equals(expectedVer1);
 		assert ent2.equals(expectedVer2);
 	}
 
 	@Test
 	public void testHistoryOfId1() {
 
 		DefaultValueComponentTestEntity ent1 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id1, 1);
 		DefaultValueComponentTestEntity ent2 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id1, 2);
 
-        LOG.error("------------ id1 -------------");
-        LOG.error(ent1.toString());
-        LOG.error(ent2.toString());
+        log.error("------------ id1 -------------");
+        log.error(ent1.toString());
+        log.error(ent2.toString());
 
 		checkCorrectlyPersisted(id1, null, "upd-c2-str1");
 
 		DefaultValueComponentTestEntity expectedVer1 = DefaultValueComponentTestEntity
 				.of(id1, DefaultValueComponent1.of("c1-str1", null));
 		DefaultValueComponentTestEntity expectedVer2 = DefaultValueComponentTestEntity
 				.of(id1, DefaultValueComponent1.of(null, DefaultValueComponent2
 						.of("upd-c2-str1", "upd-c2-str2")));
 
 		assert ent2.equals(expectedVer2);
 		assert ent1.equals(expectedVer1);
 	}
 
 	@Test
 	public void testHistoryOfId2() {
 
 		DefaultValueComponentTestEntity ent1 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id2, 1);
 		DefaultValueComponentTestEntity ent2 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id2, 2);
 
-        LOG.error("------------ id2 -------------");
-        LOG.error(ent1.toString());
-        LOG.error(ent2.toString());
+        log.error("------------ id2 -------------");
+        log.error(ent1.toString());
+        log.error(ent2.toString());
 
 		DefaultValueComponentTestEntity expectedVer1 = DefaultValueComponentTestEntity
 				.of(id2, DefaultValueComponent1.of("c1-str1",
 						DefaultValueComponent2.of("c2-str1", "c2-str2")));
 		DefaultValueComponentTestEntity expectedVer2 = DefaultValueComponentTestEntity
 				.of(id2, DefaultValueComponent1.of("c1-str1",
 						DefaultValueComponent2.of("upd-c2-str1", "c2-str2")));
 
 		assert ent1.equals(expectedVer1);
 		assert ent2.equals(expectedVer2);
 	}
 
 	@Test
 	public void testHistoryOfId3() {
 
 		DefaultValueComponentTestEntity ent1 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id3, 1);
 		DefaultValueComponentTestEntity ent2 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id3, 2);
 
-        LOG.error("------------ id3 -------------");
-        LOG.error(ent1.toString());
-        LOG.error(ent2.toString());
+        log.error("------------ id3 -------------");
+        log.error(ent1.toString());
+        log.error(ent2.toString());
 
 		DefaultValueComponentTestEntity expectedVer1 = DefaultValueComponentTestEntity
 				.of(id3, DefaultValueComponent1.of(null, DefaultValueComponent2
 						.of("c2-str1", "c2-str2")));
 		DefaultValueComponentTestEntity expectedVer2 = DefaultValueComponentTestEntity
 				.of(id3, DefaultValueComponent1.of(null, DefaultValueComponent2
 						.of("upd-c2-str1", "c2-str2")));
 
 		assert ent1.equals(expectedVer1);
 		assert ent2.equals(expectedVer2);
 	}
 
 	@Test
 	public void testHistoryOfId4() {
 
 		DefaultValueComponentTestEntity ent1 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id4, 1);
 		DefaultValueComponentTestEntity ent2 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id4, 2);
 
-        LOG.error("------------ id4 -------------");
-        LOG.error(ent1.toString());
-        LOG.error(ent2.toString());
+        log.error("------------ id4 -------------");
+        log.error(ent1.toString());
+        log.error(ent2.toString());
 
 		DefaultValueComponentTestEntity expectedVer1 = DefaultValueComponentTestEntity
 				.of(id4, DefaultValueComponent1.of(null, DefaultValueComponent2
 						.of(null, "c2-str2")));
 		DefaultValueComponentTestEntity expectedVer2 = DefaultValueComponentTestEntity
 				.of(id4, DefaultValueComponent1.of(null, DefaultValueComponent2
 						.of("upd-c2-str1", "c2-str2")));
 
 		assert ent1.equals(expectedVer1);
 		assert ent2.equals(expectedVer2);
 	}
 
 	@Test
 	public void testHistoryOfId5() {
 
 		DefaultValueComponentTestEntity ent1 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id5, 1);
 		DefaultValueComponentTestEntity ent2 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id5, 2);
 
-        LOG.error("------------ id5 -------------");
-        LOG.error(ent1.toString());
-        LOG.error(ent2.toString());
+        log.error("------------ id5 -------------");
+        log.error(ent1.toString());
+        log.error(ent2.toString());
 
 		DefaultValueComponentTestEntity expectedVer1 = DefaultValueComponentTestEntity
 				.of(id5, DefaultValueComponent1.of(null, DefaultValueComponent2
 						.of("c2-str1", null)));
 		DefaultValueComponentTestEntity expectedVer2 = DefaultValueComponentTestEntity
 				.of(id5, DefaultValueComponent1.of(null, DefaultValueComponent2
 						.of("upd-c2-str1", null)));
 
 		assert ent1.equals(expectedVer1);
 		assert ent2.equals(expectedVer2);
 	}
 
 	@Test
 	public void testHistoryOfId6() {
 
 		DefaultValueComponentTestEntity ent1 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id6, 1);
 		DefaultValueComponentTestEntity ent2 = getAuditReader().find(
 				DefaultValueComponentTestEntity.class, id6, 2);
 
-        LOG.error("------------ id6 -------------");
-        LOG.error(ent1.toString());
-        LOG.error(ent2.toString());
+        log.error("------------ id6 -------------");
+        log.error(ent1.toString());
+        log.error(ent2.toString());
 
 		DefaultValueComponentTestEntity expectedVer1 = DefaultValueComponentTestEntity
 				.of(id6, DefaultValueComponent1.of(null, null));
 		DefaultValueComponentTestEntity expectedVer2 = DefaultValueComponentTestEntity
 				.of(id6, DefaultValueComponent1.of(null, DefaultValueComponent2
 						.of("upd-c2-str1", null)));
 
 		assert ent2.equals(expectedVer2);
 		assert ent1.equals(expectedVer1);
 	}
 
 	private void checkCorrectlyPersisted(Integer expectedId,
 			String expectedComp2Str1Rev1, String expectedComp2Str1Rev2) {
 		// Verify that the entity was correctly persisted
 		EntityManager em = getEntityManager();
 		em.getTransaction().begin();
 		Long entCount = (Long) em.createQuery(
 				"select count(s) from DefaultValueComponentTestEntity s where s.id = "
 						+ expectedId.toString()).getSingleResult();
 		BigInteger auditCount = (BigInteger) em.createNativeQuery(
 				"select count(ID) from DefaultValueComponentTestEntity_AUD s where s.id = "
 						+ expectedId.toString()).getSingleResult();
 		String comp2Str1Rev1 = (String) em
 				.createNativeQuery(
 						"select COMP2_STR1 from DefaultValueComponentTestEntity_AUD s where rev=1 and s.id = "
 								+ expectedId.toString()).getSingleResult();
 		String comp2Str1Rev2 = (String) em
 				.createNativeQuery(
 						"select COMP2_STR1 from DefaultValueComponentTestEntity_AUD s where rev=2 and s.id = "
 								+ expectedId.toString()).getSingleResult();
 		assert Long.valueOf(1L).equals(entCount);
 		assert BigInteger.valueOf(2L).equals(auditCount);
 
 		if (expectedComp2Str1Rev1 == null) {
 			assert comp2Str1Rev1 == null;
 		} else {
 			assert expectedComp2Str1Rev1.equals(comp2Str1Rev1);
 		}
 
 		if (expectedComp2Str1Rev2 == null) {
 			assert comp2Str1Rev2 == null;
 		} else {
 			assert expectedComp2Str1Rev2.equals(comp2Str1Rev2);
 		}
 		em.getTransaction().commit();
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
index 8c0ad52fb6..d18d556b2c 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
@@ -1,224 +1,226 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.Set;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
+import org.jboss.logging.Logger;
 
 import org.hibernate.cache.GeneralDataRegion;
 import org.hibernate.cache.QueryResultsRegion;
 import org.hibernate.cache.Region;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
 
 /**
  * Base class for tests of QueryResultsRegion and TimestampsRegion.
  *
  * @author Galder Zamarreño
  * @since 3.5
  */
 public abstract class AbstractGeneralDataRegionTestCase extends AbstractRegionImplTestCase {
+	private static final Logger log = Logger.getLogger( AbstractGeneralDataRegionTestCase.class );
+
 	protected static final String KEY = "Key";
 
 	protected static final String VALUE1 = "value1";
 	protected static final String VALUE2 = "value2";
 
 	protected Configuration createConfiguration() {
 		return CacheTestUtil.buildConfiguration( "test", InfinispanRegionFactory.class, false, true );
 	}
 
 	@Override
 	protected void putInRegion(Region region, Object key, Object value) {
 		((GeneralDataRegion) region).put( key, value );
 	}
 
 	@Override
 	protected void removeFromRegion(Region region, Object key) {
 		((GeneralDataRegion) region).evict( key );
 	}
 
 	@Test
 	public void testEvict() throws Exception {
 		evictOrRemoveTest();
 	}
 
 	private void evictOrRemoveTest() throws Exception {
 		Configuration cfg = createConfiguration();
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new BasicServiceRegistryImpl( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 		CacheAdapter localCache = getInfinispanCache( regionFactory );
 		boolean invalidation = localCache.isClusteredInvalidation();
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		GeneralDataRegion localRegion = (GeneralDataRegion) createRegion(
 				regionFactory,
 				getStandardRegionName( REGION_PREFIX ), cfg.getProperties(), null
 		);
 
 		cfg = createConfiguration();
 		regionFactory = CacheTestUtil.startRegionFactory(
 				new BasicServiceRegistryImpl( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 
 		GeneralDataRegion remoteRegion = (GeneralDataRegion) createRegion(
 				regionFactory,
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties(),
 				null
 		);
 
 		assertNull( "local is clean", localRegion.get( KEY ) );
 		assertNull( "remote is clean", remoteRegion.get( KEY ) );
 
 		localRegion.put( KEY, VALUE1 );
 		assertEquals( VALUE1, localRegion.get( KEY ) );
 
 		// allow async propagation
 		sleep( 250 );
 		Object expected = invalidation ? null : VALUE1;
 		assertEquals( expected, remoteRegion.get( KEY ) );
 
 		localRegion.evict( KEY );
 
 		// allow async propagation
 		sleep( 250 );
 		assertEquals( null, localRegion.get( KEY ) );
 		assertEquals( null, remoteRegion.get( KEY ) );
 	}
 
 	protected abstract String getStandardRegionName(String regionPrefix);
 
 	/**
 	 * Test method for {@link QueryResultsRegion#evictAll()}.
 	 * <p/>
 	 * FIXME add testing of the "immediately without regard for transaction isolation" bit in the
 	 * CollectionRegionAccessStrategy API.
 	 */
 	public void testEvictAll() throws Exception {
 		evictOrRemoveAllTest( "entity" );
 	}
 
 	private void evictOrRemoveAllTest(String configName) throws Exception {
 		Configuration cfg = createConfiguration();
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new BasicServiceRegistryImpl( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 		CacheAdapter localCache = getInfinispanCache( regionFactory );
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		GeneralDataRegion localRegion = (GeneralDataRegion) createRegion(
 				regionFactory,
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties(),
 				null
 		);
 
 		cfg = createConfiguration();
 		regionFactory = CacheTestUtil.startRegionFactory(
 				new BasicServiceRegistryImpl( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 		CacheAdapter remoteCache = getInfinispanCache( regionFactory );
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		GeneralDataRegion remoteRegion = (GeneralDataRegion) createRegion(
 				regionFactory,
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties(),
 				null
 		);
 
 		Set keys = localCache.keySet();
 		assertEquals( "No valid children in " + keys, 0, getValidKeyCount( keys ) );
 
 		keys = remoteCache.keySet();
 		assertEquals( "No valid children in " + keys, 0, getValidKeyCount( keys ) );
 
 		assertNull( "local is clean", localRegion.get( KEY ) );
 		assertNull( "remote is clean", remoteRegion.get( KEY ) );
 
 		localRegion.put( KEY, VALUE1 );
 		assertEquals( VALUE1, localRegion.get( KEY ) );
 
 		// Allow async propagation
 		sleep( 250 );
 
 		remoteRegion.put( KEY, VALUE1 );
 		assertEquals( VALUE1, remoteRegion.get( KEY ) );
 
 		// Allow async propagation
 		sleep( 250 );
 
 		localRegion.evictAll();
 
 		// allow async propagation
 		sleep( 250 );
 		// This should re-establish the region root node in the optimistic case
 		assertNull( localRegion.get( KEY ) );
 		assertEquals( "No valid children in " + keys, 0, getValidKeyCount( localCache.keySet() ) );
 
 		// Re-establishing the region root on the local node doesn't
 		// propagate it to other nodes. Do a get on the remote node to re-establish
 		// This only adds a node in the case of optimistic locking
 		assertEquals( null, remoteRegion.get( KEY ) );
 		assertEquals( "No valid children in " + keys, 0, getValidKeyCount( remoteCache.keySet() ) );
 
 		assertEquals( "local is clean", null, localRegion.get( KEY ) );
 		assertEquals( "remote is clean", null, remoteRegion.get( KEY ) );
 	}
 
 	protected void rollback() {
 		try {
 			BatchModeTransactionManager.getInstance().rollback();
 		}
 		catch (Exception e) {
-			LOG.error( e.getMessage(), e );
+			log.error( e.getMessage(), e );
 		}
 	}
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
index f9bda567b1..6b4ac1d498 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
@@ -1,117 +1,118 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.Set;
 
 import org.infinispan.Cache;
+import org.jboss.logging.Logger;
 
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.infinispan.util.CacheHelper;
 
 import org.junit.After;
 import org.junit.Before;
 
 import org.hibernate.test.cache.infinispan.util.CacheTestSupport;
 
-import static org.hibernate.testing.TestLogger.LOG;
-
 /**
  * Base class for all non-functional tests of Infinispan integration.
  *
  * @author Galder Zamarreño
  * @since 3.5
  */
 public abstract class AbstractNonFunctionalTestCase extends org.hibernate.testing.junit4.BaseUnitTestCase {
-    public static final String REGION_PREFIX = "test";
+	private static final Logger log = Logger.getLogger( AbstractNonFunctionalTestCase.class );
+
+	public static final String REGION_PREFIX = "test";
 
 	private static final String PREFER_IPV4STACK = "java.net.preferIPv4Stack";
 	private String preferIPv4Stack;
 
     private CacheTestSupport testSupport = new CacheTestSupport();
 
 	@Before
     public void prepareCacheSupport() throws Exception {
 		preferIPv4Stack = System.getProperty( PREFER_IPV4STACK );
 		System.setProperty( PREFER_IPV4STACK, "true" );
 
         testSupport.setUp();
     }
 
     @After
     public void releaseCachSupport() throws Exception {
         testSupport.tearDown();
 
 		if ( preferIPv4Stack == null ) {
 			System.clearProperty( PREFER_IPV4STACK );
 		}
 		else {
 			System.setProperty( PREFER_IPV4STACK, preferIPv4Stack );
 		}
     }
 
     protected void registerCache(Cache cache) {
         testSupport.registerCache(cache);
     }
 
     protected void unregisterCache(Cache cache) {
         testSupport.unregisterCache(cache);
     }
 
     protected void registerFactory(RegionFactory factory) {
         testSupport.registerFactory(factory);
     }
 
     protected void unregisterFactory(RegionFactory factory) {
         testSupport.unregisterFactory(factory);
     }
 
     protected CacheTestSupport getCacheTestSupport() {
         return testSupport;
     }
 
     protected void sleep(long ms) {
         try {
             Thread.sleep(ms);
         }
         catch (InterruptedException e) {
-            LOG.warn("Interrupted during sleep", e);
+            log.warn("Interrupted during sleep", e);
         }
     }
 
     protected void avoidConcurrentFlush() {
         testSupport.avoidConcurrentFlush();
     }
 
     protected int getValidKeyCount(Set keys) {
        int result = 0;
        for (Object key : keys) {
           if (!(CacheHelper.isEvictAllNotification(key))) {
              result++;
           }
        }
        return result;
    }
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
index a0afa4e92b..dcb7a97bfa 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
@@ -1,468 +1,469 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.collection;
 
 import javax.transaction.TransactionManager;
 import java.util.concurrent.Callable;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
+import org.jboss.logging.Logger;
 
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.impl.CacheDataDescriptionImpl;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.access.PutFromLoadValidator;
 import org.hibernate.cache.infinispan.access.TransactionalAccessDelegate;
 import org.hibernate.cache.infinispan.collection.CollectionRegionImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.internal.util.compare.ComparableComparator;
 
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 import junit.framework.AssertionFailedError;
 
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.NodeEnvironment;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeJtaTransactionManagerImpl;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Base class for tests of CollectionRegionAccessStrategy impls.
  *
  * @author Galder Zamarreño
  * @since 3.5
  */
 public abstract class AbstractCollectionRegionAccessStrategyTestCase extends AbstractNonFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( AbstractCollectionRegionAccessStrategyTestCase.class );
 
 	public static final String REGION_NAME = "test/com.foo.test";
 	public static final String KEY_BASE = "KEY";
 	public static final String VALUE1 = "VALUE1";
 	public static final String VALUE2 = "VALUE2";
 
 	protected static int testCount;
 
 	protected NodeEnvironment localEnvironment;
 	protected CollectionRegionImpl localCollectionRegion;
 	protected CollectionRegionAccessStrategy localAccessStrategy;
 
 	protected NodeEnvironment remoteEnvironment;
 	protected CollectionRegionImpl remoteCollectionRegion;
 	protected CollectionRegionAccessStrategy remoteAccessStrategy;
 
 	protected boolean invalidation;
 	protected boolean synchronous;
 
 	protected Exception node1Exception;
 	protected Exception node2Exception;
 
 	protected AssertionFailedError node1Failure;
 	protected AssertionFailedError node2Failure;
 
 	protected abstract AccessType getAccessType();
 
 	@Before
 	public void prepareResources() throws Exception {
 		// to mimic exactly the old code results, both environments here are exactly the same...
 		Configuration cfg = createConfiguration( getConfigurationName() );
 		localEnvironment = new NodeEnvironment( cfg );
 		localEnvironment.prepare();
 
 		localCollectionRegion = localEnvironment.getCollectionRegion( REGION_NAME, getCacheDataDescription() );
 		localAccessStrategy = localCollectionRegion.buildAccessStrategy( getAccessType() );
 
 		invalidation = localCollectionRegion.getCacheAdapter().isClusteredInvalidation();
 		synchronous = localCollectionRegion.getCacheAdapter().isSynchronous();
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		remoteEnvironment = new NodeEnvironment( cfg );
 		remoteEnvironment.prepare();
 
 		remoteCollectionRegion = remoteEnvironment.getCollectionRegion( REGION_NAME, getCacheDataDescription() );
 		remoteAccessStrategy = remoteCollectionRegion.buildAccessStrategy( getAccessType() );
 	}
 
 	protected abstract String getConfigurationName();
 
 	protected static Configuration createConfiguration(String configName) {
 		Configuration cfg = CacheTestUtil.buildConfiguration(
 				REGION_PREFIX, InfinispanRegionFactory.class, true, false
 		);
 		cfg.setProperty( InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, configName );
 		return cfg;
 	}
 
 	protected CacheDataDescription getCacheDataDescription() {
 		return new CacheDataDescriptionImpl( true, true, ComparableComparator.INSTANCE );
 	}
 
 	@After
 	public void releaseResources() throws Exception {
 		if ( localEnvironment != null ) {
 			localEnvironment.release();
 		}
 		if ( remoteEnvironment != null ) {
 			remoteEnvironment.release();
 		}
 	}
 
 	protected boolean isUsingInvalidation() {
 		return invalidation;
 	}
 
 	protected boolean isSynchronous() {
 		return synchronous;
 	}
 
 	@Test
 	public abstract void testCacheConfiguration();
 
 	@Test
 	public void testGetRegion() {
 		assertEquals( "Correct region", localCollectionRegion, localAccessStrategy.getRegion() );
 	}
 
 	@Test
 	public void testPutFromLoadRemoveDoesNotProduceStaleData() throws Exception {
 		final CountDownLatch pferLatch = new CountDownLatch( 1 );
 		final CountDownLatch removeLatch = new CountDownLatch( 1 );
 		TransactionManager tm = DualNodeJtaTransactionManagerImpl.getInstance( "test1234" );
 		PutFromLoadValidator validator = new PutFromLoadValidator( tm ) {
 			@Override
 			public boolean acquirePutFromLoadLock(Object key) {
 				boolean acquired = super.acquirePutFromLoadLock( key );
 				try {
 					removeLatch.countDown();
 					pferLatch.await( 2, TimeUnit.SECONDS );
 				}
 				catch (InterruptedException e) {
-					LOG.debug( "Interrupted" );
+					log.debug( "Interrupted" );
 					Thread.currentThread().interrupt();
 				}
 				catch (Exception e) {
-					LOG.error( "Error", e );
+					log.error( "Error", e );
 					throw new RuntimeException( "Error", e );
 				}
 				return acquired;
 			}
 		};
 		final TransactionalAccessDelegate delegate = new TransactionalAccessDelegate(
 				(CollectionRegionImpl) localCollectionRegion, validator
 		);
 
 		Callable<Void> pferCallable = new Callable<Void>() {
 			public Void call() throws Exception {
 				delegate.putFromLoad( "k1", "v1", 0, null );
 				return null;
 			}
 		};
 
 		Callable<Void> removeCallable = new Callable<Void>() {
 			public Void call() throws Exception {
 				removeLatch.await();
 				delegate.remove( "k1" );
 				pferLatch.countDown();
 				return null;
 			}
 		};
 
 		ExecutorService executorService = Executors.newCachedThreadPool();
 		Future<Void> pferFuture = executorService.submit( pferCallable );
 		Future<Void> removeFuture = executorService.submit( removeCallable );
 
 		pferFuture.get();
 		removeFuture.get();
 
 		assertFalse( localCollectionRegion.getCacheAdapter().containsKey( "k1" ) );
 	}
 
 	@Test
 	public void testPutFromLoad() throws Exception {
 		putFromLoadTest( false );
 	}
 
 	@Test
 	public void testPutFromLoadMinimal() throws Exception {
 		putFromLoadTest( true );
 	}
 
 	private void putFromLoadTest(final boolean useMinimalAPI) throws Exception {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		final CountDownLatch writeLatch1 = new CountDownLatch( 1 );
 		final CountDownLatch writeLatch2 = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 2 );
 
 		Thread node1 = new Thread() {
 
 			public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertEquals( "node1 starts clean", null, localAccessStrategy.get( KEY, txTimestamp ) );
 
 					writeLatch1.await();
 
 					if ( useMinimalAPI ) {
 						localAccessStrategy.putFromLoad( KEY, VALUE2, txTimestamp, new Integer( 2 ), true );
 					}
 					else {
 						localAccessStrategy.putFromLoad( KEY, VALUE2, txTimestamp, new Integer( 2 ) );
 					}
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
-					LOG.error( "node1 caught exception", e );
+					log.error( "node1 caught exception", e );
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					// Let node2 write
 					writeLatch2.countDown();
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		Thread node2 = new Thread() {
 
 			public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertNull( "node2 starts clean", remoteAccessStrategy.get( KEY, txTimestamp ) );
 
 					// Let node1 write
 					writeLatch1.countDown();
 					// Wait for node1 to finish
 					writeLatch2.await();
 
 					// Let the first PFER propagate
 					sleep( 200 );
 
 					if ( useMinimalAPI ) {
 						remoteAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ), true );
 					}
 					else {
 						remoteAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ) );
 					}
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
-					LOG.error( "node2 caught exception", e );
+					log.error( "node2 caught exception", e );
 					node2Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node2Failure = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		node1.setDaemon( true );
 		node2.setDaemon( true );
 
 		node1.start();
 		node2.start();
 
 		assertTrue( "Threads completed", completionLatch.await( 2, TimeUnit.SECONDS ) );
 
 		if ( node1Failure != null ) {
 			throw node1Failure;
 		}
 		if ( node2Failure != null ) {
 			throw node2Failure;
 		}
 
 		assertEquals( "node1 saw no exceptions", null, node1Exception );
 		assertEquals( "node2 saw no exceptions", null, node2Exception );
 
 		// let the final PFER propagate
 		sleep( 100 );
 
 		long txTimestamp = System.currentTimeMillis();
 		String msg1 = "Correct node1 value";
 		String msg2 = "Correct node2 value";
 		Object expected1 = null;
 		Object expected2 = null;
 		if ( isUsingInvalidation() ) {
 			// PFER does not generate any invalidation, so each node should
 			// succeed. We count on database locking and Hibernate removing
 			// the collection on any update to prevent the situation we have
 			// here where the caches have inconsistent data
 			expected1 = VALUE2;
 			expected2 = VALUE1;
 		}
 		else {
 			// the initial VALUE2 should prevent the node2 put
 			expected1 = VALUE2;
 			expected2 = VALUE2;
 		}
 
 		assertEquals( msg1, expected1, localAccessStrategy.get( KEY, txTimestamp ) );
 		assertEquals( msg2, expected2, remoteAccessStrategy.get( KEY, txTimestamp ) );
 	}
 
 	@Test
 	public void testRemove() {
 		evictOrRemoveTest( false );
 	}
 
 	@Test
 	public void testRemoveAll() {
 		evictOrRemoveAllTest( false );
 	}
 
 	@Test
 	public void testEvict() {
 		evictOrRemoveTest( true );
 	}
 
 	@Test
 	public void testEvictAll() {
 		evictOrRemoveAllTest( true );
 	}
 
 	private void evictOrRemoveTest(boolean evict) {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		assertNull( "local is clean", localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertNull( "remote is clean", remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		if ( evict ) {
 			localAccessStrategy.evict( KEY );
 		}
 		else {
 			localAccessStrategy.remove( KEY );
 		}
 
 		assertEquals( null, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		assertEquals( null, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 	}
 
 	private void evictOrRemoveAllTest(boolean evict) {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		assertEquals( 0, getValidKeyCount( localCollectionRegion.getCacheAdapter().keySet() ) );
 
 		assertEquals( 0, getValidKeyCount( remoteCollectionRegion.getCacheAdapter().keySet() ) );
 
 		assertNull( "local is clean", localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertNull( "remote is clean", remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		if ( evict ) {
 			localAccessStrategy.evictAll();
 		}
 		else {
 			localAccessStrategy.removeAll();
 		}
 
 		// This should re-establish the region root node
 		assertNull( localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		assertEquals( 0, getValidKeyCount( localCollectionRegion.getCacheAdapter().keySet() ) );
 
 		// Re-establishing the region root on the local node doesn't
 		// propagate it to other nodes. Do a get on the remote node to re-establish
 		assertEquals( null, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		assertEquals( 0, getValidKeyCount( remoteCollectionRegion.getCacheAdapter().keySet() ) );
 
 		// Test whether the get above messes up the optimistic version
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		assertEquals( 1, getValidKeyCount( remoteCollectionRegion.getCacheAdapter().keySet() ) );
 
 		// Wait for async propagation of the putFromLoad
 		sleep( 250 );
 
 		assertEquals(
 				"local is correct", (isUsingInvalidation() ? null : VALUE1), localAccessStrategy.get(
 				KEY, System
 				.currentTimeMillis()
 		)
 		);
 		assertEquals( "remote is correct", VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 	}
 
 	private void rollback() {
 		try {
 			BatchModeTransactionManager.getInstance().rollback();
 		}
 		catch (Exception e) {
-			LOG.error( e.getMessage(), e );
+			log.error( e.getMessage(), e );
 		}
 
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
index 0e2f7bb4d1..2ab0b03c39 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
@@ -1,614 +1,615 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.entity;
 
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
+import org.jboss.logging.Logger;
 
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.impl.CacheDataDescriptionImpl;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.entity.EntityRegionImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.internal.util.compare.ComparableComparator;
 
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 import junit.framework.AssertionFailedError;
 
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.NodeEnvironment;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Base class for tests of EntityRegionAccessStrategy impls.
  *
  * @author Galder Zamarreño
  * @since 3.5
  */
 public abstract class AbstractEntityRegionAccessStrategyTestCase extends AbstractNonFunctionalTestCase {
+	private static final Logger log = Logger.getLogger( AbstractEntityRegionAccessStrategyTestCase.class );
 
 	public static final String REGION_NAME = "test/com.foo.test";
 	public static final String KEY_BASE = "KEY";
 	public static final String VALUE1 = "VALUE1";
 	public static final String VALUE2 = "VALUE2";
 
 	protected static int testCount;
 
 	protected NodeEnvironment localEnvironment;
 	protected EntityRegionImpl localEntityRegion;
 	protected EntityRegionAccessStrategy localAccessStrategy;
 
 	protected NodeEnvironment remoteEnvironment;
 	protected EntityRegionImpl remoteEntityRegion;
 	protected EntityRegionAccessStrategy remoteAccessStrategy;
 
 	protected boolean invalidation;
 	protected boolean synchronous;
 
 	protected Exception node1Exception;
 	protected Exception node2Exception;
 
 	protected AssertionFailedError node1Failure;
 	protected AssertionFailedError node2Failure;
 
 	@Before
 	public void prepareResources() throws Exception {
 		// to mimic exactly the old code results, both environments here are exactly the same...
 		Configuration cfg = createConfiguration( getConfigurationName() );
 		localEnvironment = new NodeEnvironment( cfg );
 		localEnvironment.prepare();
 
 		localEntityRegion = localEnvironment.getEntityRegion( REGION_NAME, getCacheDataDescription() );
 		localAccessStrategy = localEntityRegion.buildAccessStrategy( getAccessType() );
 
 		invalidation = localEntityRegion.getCacheAdapter().isClusteredInvalidation();
 		synchronous = localEntityRegion.getCacheAdapter().isSynchronous();
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		remoteEnvironment = new NodeEnvironment( cfg );
 		remoteEnvironment.prepare();
 
 		remoteEntityRegion = remoteEnvironment.getEntityRegion( REGION_NAME, getCacheDataDescription() );
 		remoteAccessStrategy = remoteEntityRegion.buildAccessStrategy( getAccessType() );
 	}
 
 	protected abstract String getConfigurationName();
 
 	protected static Configuration createConfiguration(String configName) {
 		Configuration cfg = CacheTestUtil.buildConfiguration(
 				REGION_PREFIX,
 				InfinispanRegionFactory.class,
 				true,
 				false
 		);
 		cfg.setProperty( InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, configName );
 		return cfg;
 	}
 
 	protected CacheDataDescription getCacheDataDescription() {
 		return new CacheDataDescriptionImpl( true, true, ComparableComparator.INSTANCE );
 	}
 
 	@After
 	public void releaseResources() throws Exception {
 		if ( localEnvironment != null ) {
 			localEnvironment.release();
 		}
 		if ( remoteEnvironment != null ) {
 			remoteEnvironment.release();
 		}
 	}
 
 	protected abstract AccessType getAccessType();
 
 	protected boolean isUsingInvalidation() {
 		return invalidation;
 	}
 
 	protected boolean isSynchronous() {
 		return synchronous;
 	}
 
 	protected void assertThreadsRanCleanly() {
 		if ( node1Failure != null ) {
 			throw node1Failure;
 		}
 		if ( node2Failure != null ) {
 			throw node2Failure;
 		}
 
 		if ( node1Exception != null ) {
-            LOG.error("node1 saw an exception", node1Exception);
+            log.error("node1 saw an exception", node1Exception);
 			assertEquals( "node1 saw no exceptions", null, node1Exception );
 		}
 
 		if ( node2Exception != null ) {
-            LOG.error("node2 saw an exception", node2Exception);
+            log.error("node2 saw an exception", node2Exception);
 			assertEquals( "node2 saw no exceptions", null, node2Exception );
 		}
 	}
 
 	@Test
 	public abstract void testCacheConfiguration();
 
 	@Test
 	public void testGetRegion() {
 		assertEquals( "Correct region", localEntityRegion, localAccessStrategy.getRegion() );
 	}
 
 	@Test
 	public void testPutFromLoad() throws Exception {
 		putFromLoadTest( false );
 	}
 
 	@Test
 	public void testPutFromLoadMinimal() throws Exception {
 		putFromLoadTest( true );
 	}
 
 	/**
 	 * Simulate 2 nodes, both start, tx do a get, experience a cache miss, then 'read from db.' First
 	 * does a putFromLoad, then an update. Second tries to do a putFromLoad with stale data (i.e. it
 	 * took longer to read from the db). Both commit their tx. Then both start a new tx and get.
 	 * First should see the updated data; second should either see the updated data (isInvalidation()
 	 * == false) or null (isInvalidation() == true).
 	 *
 	 * @param useMinimalAPI
 	 * @throws Exception
 	 */
 	private void putFromLoadTest(final boolean useMinimalAPI) throws Exception {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		final CountDownLatch writeLatch1 = new CountDownLatch( 1 );
 		final CountDownLatch writeLatch2 = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 2 );
 
 		Thread node1 = new Thread() {
 
 			@Override
             public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertNull( "node1 starts clean", localAccessStrategy.get( KEY, txTimestamp ) );
 
 					writeLatch1.await();
 
 					if ( useMinimalAPI ) {
 						localAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ), true );
 					}
 					else {
 						localAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ) );
 					}
 
 					localAccessStrategy.update( KEY, VALUE2, new Integer( 2 ), new Integer( 1 ) );
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
-                    LOG.error("node1 caught exception", e);
+                    log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					// Let node2 write
 					writeLatch2.countDown();
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		Thread node2 = new Thread() {
 
 			@Override
             public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertNull( "node1 starts clean", remoteAccessStrategy.get( KEY, txTimestamp ) );
 
 					// Let node1 write
 					writeLatch1.countDown();
 					// Wait for node1 to finish
 					writeLatch2.await();
 
 					if ( useMinimalAPI ) {
 						remoteAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ), true );
 					}
 					else {
 						remoteAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ) );
 					}
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
-                    LOG.error("node2 caught exception", e);
+                    log.error("node2 caught exception", e);
 					node2Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node2Failure = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		node1.setDaemon( true );
 		node2.setDaemon( true );
 
 		node1.start();
 		node2.start();
 
 		assertTrue( "Threads completed", completionLatch.await( 2, TimeUnit.SECONDS ) );
 
 		assertThreadsRanCleanly();
 
 		long txTimestamp = System.currentTimeMillis();
 		assertEquals( "Correct node1 value", VALUE2, localAccessStrategy.get( KEY, txTimestamp ) );
 
 		if ( isUsingInvalidation() ) {
 			// no data version to prevent the PFER; we count on db locks preventing this
 			assertEquals( "Expected node2 value", VALUE1, remoteAccessStrategy.get( KEY, txTimestamp ) );
 		}
 		else {
 			// The node1 update is replicated, preventing the node2 PFER
 			assertEquals( "Correct node2 value", VALUE2, remoteAccessStrategy.get( KEY, txTimestamp ) );
 		}
 	}
 
 	@Test
 	public void testInsert() throws Exception {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		final CountDownLatch readLatch = new CountDownLatch( 1 );
 		final CountDownLatch commitLatch = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 2 );
 
 		Thread inserter = new Thread() {
 
 			@Override
             public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertNull( "Correct initial value", localAccessStrategy.get( KEY, txTimestamp ) );
 
 					localAccessStrategy.insert( KEY, VALUE1, new Integer( 1 ) );
 
 					readLatch.countDown();
 					commitLatch.await();
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
-                    LOG.error("node1 caught exception", e);
+                    log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		Thread reader = new Thread() {
 
 			@Override
             public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					readLatch.await();
 //               Object expected = !isBlockingReads() ? null : VALUE1;
 					Object expected = null;
 
 					assertEquals(
 							"Correct initial value", expected, localAccessStrategy.get(
 							KEY,
 							txTimestamp
 					)
 					);
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
-                    LOG.error("node1 caught exception", e);
+                    log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					commitLatch.countDown();
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		inserter.setDaemon( true );
 		reader.setDaemon( true );
 		inserter.start();
 		reader.start();
 
 		assertTrue( "Threads completed", completionLatch.await( 1, TimeUnit.SECONDS ) );
 
 		assertThreadsRanCleanly();
 
 		long txTimestamp = System.currentTimeMillis();
 		assertEquals( "Correct node1 value", VALUE1, localAccessStrategy.get( KEY, txTimestamp ) );
 		Object expected = isUsingInvalidation() ? null : VALUE1;
 		assertEquals( "Correct node2 value", expected, remoteAccessStrategy.get( KEY, txTimestamp ) );
 	}
 
 	@Test
 	public void testUpdate() throws Exception {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		// Set up initial state
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 
 		// Let the async put propagate
 		sleep( 250 );
 
 		final CountDownLatch readLatch = new CountDownLatch( 1 );
 		final CountDownLatch commitLatch = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 2 );
 
 		Thread updater = new Thread( "testUpdate-updater" ) {
 
 			@Override
             public void run() {
 				boolean readerUnlocked = false;
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
-                    LOG.debug("Transaction began, get initial value");
+                    log.debug("Transaction began, get initial value");
 					assertEquals( "Correct initial value", VALUE1, localAccessStrategy.get( KEY, txTimestamp ) );
-                    LOG.debug("Now update value");
+                    log.debug("Now update value");
 					localAccessStrategy.update( KEY, VALUE2, new Integer( 2 ), new Integer( 1 ) );
-                    LOG.debug("Notify the read latch");
+                    log.debug("Notify the read latch");
 					readLatch.countDown();
 					readerUnlocked = true;
-                    LOG.debug("Await commit");
+                    log.debug("Await commit");
 					commitLatch.await();
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
-                    LOG.error("node1 caught exception", e);
+                    log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					if ( !readerUnlocked ) {
 						readLatch.countDown();
 					}
-                    LOG.debug("Completion latch countdown");
+                    log.debug("Completion latch countdown");
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		Thread reader = new Thread( "testUpdate-reader" ) {
 
 			@Override
             public void run() {
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
-                    LOG.debug("Transaction began, await read latch");
+                    log.debug("Transaction began, await read latch");
 					readLatch.await();
-                    LOG.debug("Read latch acquired, verify local access strategy");
+                    log.debug("Read latch acquired, verify local access strategy");
 
 					// This won't block w/ mvc and will read the old value
 					Object expected = VALUE1;
 					assertEquals( "Correct value", expected, localAccessStrategy.get( KEY, txTimestamp ) );
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
-                    LOG.error("node1 caught exception", e);
+                    log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					commitLatch.countDown();
-                    LOG.debug("Completion latch countdown");
+                    log.debug("Completion latch countdown");
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		updater.setDaemon( true );
 		reader.setDaemon( true );
 		updater.start();
 		reader.start();
 
 		// Should complete promptly
 		assertTrue( completionLatch.await( 2, TimeUnit.SECONDS ) );
 
 		assertThreadsRanCleanly();
 
 		long txTimestamp = System.currentTimeMillis();
 		assertEquals( "Correct node1 value", VALUE2, localAccessStrategy.get( KEY, txTimestamp ) );
 		Object expected = isUsingInvalidation() ? null : VALUE2;
 		assertEquals( "Correct node2 value", expected, remoteAccessStrategy.get( KEY, txTimestamp ) );
 	}
 
 	@Test
 	public void testRemove() {
 		evictOrRemoveTest( false );
 	}
 
 	@Test
 	public void testRemoveAll() {
 		evictOrRemoveAllTest( false );
 	}
 
 	@Test
 	public void testEvict() {
 		evictOrRemoveTest( true );
 	}
 
 	@Test
 	public void testEvictAll() {
 		evictOrRemoveAllTest( true );
 	}
 
 	private void evictOrRemoveTest(boolean evict) {
 		final String KEY = KEY_BASE + testCount++;
 		assertEquals( 0, getValidKeyCount( localEntityRegion.getCacheAdapter().keySet() ) );
 		assertEquals( 0, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 
 		assertNull( "local is clean", localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertNull( "remote is clean", remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		if ( evict ) {
 			localAccessStrategy.evict( KEY );
 		}
 		else {
 			localAccessStrategy.remove( KEY );
 		}
 
 		assertEquals( null, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 0, getValidKeyCount( localEntityRegion.getCacheAdapter().keySet() ) );
 		assertEquals( null, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 0, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 	}
 
 	private void evictOrRemoveAllTest(boolean evict) {
 		final String KEY = KEY_BASE + testCount++;
 		assertEquals( 0, getValidKeyCount( localEntityRegion.getCacheAdapter().keySet() ) );
 		assertEquals( 0, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 		assertNull( "local is clean", localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertNull( "remote is clean", remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		if ( evict ) {
-            LOG.debug("Call evict all locally");
+            log.debug("Call evict all locally");
 			localAccessStrategy.evictAll();
 		}
 		else {
 			localAccessStrategy.removeAll();
 		}
 
 		// This should re-establish the region root node in the optimistic case
 		assertNull( localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 0, getValidKeyCount( localEntityRegion.getCacheAdapter().keySet() ) );
 
 		// Re-establishing the region root on the local node doesn't
 		// propagate it to other nodes. Do a get on the remote node to re-establish
 		assertEquals( null, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 0, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 
 		// Test whether the get above messes up the optimistic version
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 1, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		assertEquals(
 				"local is correct", (isUsingInvalidation() ? null : VALUE1), localAccessStrategy
 				.get( KEY, System.currentTimeMillis() )
 		);
 		assertEquals(
 				"remote is correct", VALUE1, remoteAccessStrategy.get(
 				KEY, System
 				.currentTimeMillis()
 		)
 		);
 	}
 
 	protected void rollback() {
 		try {
 			BatchModeTransactionManager.getInstance().rollback();
 		}
 		catch (Exception e) {
-            LOG.error(e.getMessage(), e);
+            log.error(e.getMessage(), e);
 		}
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractTransactionalAccessTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractTransactionalAccessTestCase.java
index 6d7c02aba6..15f7d25f15 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractTransactionalAccessTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractTransactionalAccessTestCase.java
@@ -1,132 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.entity;
 
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
+import org.jboss.logging.Logger;
 
 import org.hibernate.cache.access.AccessType;
 
 import junit.framework.AssertionFailedError;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Base class for tests of TRANSACTIONAL access.
  *
  * @author Galder Zamarreño
  * @since 3.5
  */
 public abstract class AbstractTransactionalAccessTestCase extends AbstractEntityRegionAccessStrategyTestCase {
-   @Override
+	private static final Logger log = Logger.getLogger( AbstractTransactionalAccessTestCase.class );
+
+	@Override
    protected AccessType getAccessType() {
       return AccessType.TRANSACTIONAL;
    }
 
     public void testContestedPutFromLoad() throws Exception {
 
         final String KEY = KEY_BASE + testCount++;
 
         localAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
 
         final CountDownLatch pferLatch = new CountDownLatch(1);
         final CountDownLatch pferCompletionLatch = new CountDownLatch(1);
         final CountDownLatch commitLatch = new CountDownLatch(1);
         final CountDownLatch completionLatch = new CountDownLatch(1);
 
         Thread blocker = new Thread("Blocker") {
 
             @Override
             public void run() {
 
                 try {
                     long txTimestamp = System.currentTimeMillis();
                     BatchModeTransactionManager.getInstance().begin();
 
                     assertEquals("Correct initial value", VALUE1, localAccessStrategy.get(KEY, txTimestamp));
 
                     localAccessStrategy.update(KEY, VALUE2, new Integer(2), new Integer(1));
 
                     pferLatch.countDown();
                     commitLatch.await();
 
                     BatchModeTransactionManager.getInstance().commit();
                 } catch (Exception e) {
-                    LOG.error("node1 caught exception", e);
+                    log.error("node1 caught exception", e);
                     node1Exception = e;
                     rollback();
                 } catch (AssertionFailedError e) {
                     node1Failure = e;
                     rollback();
                 } finally {
                     completionLatch.countDown();
                 }
             }
         };
 
         Thread putter = new Thread("Putter") {
 
             @Override
             public void run() {
 
                 try {
                     long txTimestamp = System.currentTimeMillis();
                     BatchModeTransactionManager.getInstance().begin();
 
                     localAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1));
 
                     BatchModeTransactionManager.getInstance().commit();
                 } catch (Exception e) {
-                    LOG.error("node1 caught exception", e);
+                    log.error("node1 caught exception", e);
                     node1Exception = e;
                     rollback();
                 } catch (AssertionFailedError e) {
                     node1Failure = e;
                     rollback();
                 } finally {
                     pferCompletionLatch.countDown();
                 }
             }
         };
 
         blocker.start();
         assertTrue("Active tx has done an update", pferLatch.await(1, TimeUnit.SECONDS));
         putter.start();
         assertTrue("putFromLoadreturns promtly", pferCompletionLatch.await(10, TimeUnit.MILLISECONDS));
 
         commitLatch.countDown();
 
         assertTrue("Threads completed", completionLatch.await(1, TimeUnit.SECONDS));
 
         assertThreadsRanCleanly();
 
         long txTimestamp = System.currentTimeMillis();
         assertEquals("Correct node1 value", VALUE2, localAccessStrategy.get(KEY, txTimestamp));
     }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/CacheAccessListener.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/CacheAccessListener.java
index 3d0902215a..8311385a07 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/CacheAccessListener.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/CacheAccessListener.java
@@ -1,108 +1,112 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional.classloader;
-import static org.hibernate.testing.TestLogger.LOG;
+
 import java.util.HashSet;
 import java.util.Set;
-import org.hibernate.cache.infinispan.util.CacheHelper;
+
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryCreated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryModified;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryVisited;
 import org.infinispan.notifications.cachelistener.event.CacheEntryCreatedEvent;
 import org.infinispan.notifications.cachelistener.event.CacheEntryModifiedEvent;
 import org.infinispan.notifications.cachelistener.event.CacheEntryVisitedEvent;
+import org.jboss.logging.Logger;
+
+import org.hibernate.cache.infinispan.util.CacheHelper;
 
 @Listener
 public class CacheAccessListener {
+	private static final Logger log = Logger.getLogger( CacheAccessListener.class );
 
-    HashSet modified = new HashSet();
+	HashSet modified = new HashSet();
     HashSet accessed = new HashSet();
 
     public void clear() {
         modified.clear();
         accessed.clear();
     }
 
     @CacheEntryModified
     public void nodeModified( CacheEntryModifiedEvent event ) {
         if (!event.isPre() && !CacheHelper.isEvictAllNotification(event.getKey())) {
             Object key = event.getKey();
-            LOG.info("Modified node " + key);
+            log.info("Modified node " + key);
             modified.add(key.toString());
         }
     }
 
     @CacheEntryCreated
     public void nodeCreated( CacheEntryCreatedEvent event ) {
         if (!event.isPre() && !CacheHelper.isEvictAllNotification(event.getKey())) {
             Object key = event.getKey();
-            LOG.info("Created node " + key);
+            log.info("Created node " + key);
             modified.add(key.toString());
         }
     }
 
     @CacheEntryVisited
     public void nodeVisited( CacheEntryVisitedEvent event ) {
         if (!event.isPre() && !CacheHelper.isEvictAllNotification(event.getKey())) {
             Object key = event.getKey();
-            LOG.info("Visited node " + key);
+            log.info("Visited node " + key);
             accessed.add(key.toString());
         }
     }
 
     public boolean getSawRegionModification( Object key ) {
         return getSawRegion(key, modified);
     }
 
     public int getSawRegionModificationCount() {
         return modified.size();
     }
 
     public void clearSawRegionModification() {
         modified.clear();
     }
 
     public boolean getSawRegionAccess( Object key ) {
         return getSawRegion(key, accessed);
     }
 
     public int getSawRegionAccessCount() {
         return accessed.size();
     }
 
     public void clearSawRegionAccess() {
         accessed.clear();
     }
 
     private boolean getSawRegion( Object key,
                                   Set sawEvents ) {
         if (sawEvents.contains(key)) {
             sawEvents.remove(key);
             return true;
         }
         return false;
     }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/IsolatedClassLoaderTest.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/IsolatedClassLoaderTest.java
index 5e65c2e74f..2ecb70707f 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/IsolatedClassLoaderTest.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/IsolatedClassLoaderTest.java
@@ -1,352 +1,351 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional.classloader;
 
 import javax.transaction.TransactionManager;
 
-import org.hibernate.test.cache.infinispan.functional.Item;
 import org.infinispan.Cache;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
+import org.jboss.logging.Logger;
 
 import org.hibernate.SessionFactory;
 import org.hibernate.cache.StandardQueryCache;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 
-import org.junit.After;
 import org.junit.AfterClass;
-import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.functional.cluster.ClusterAwareRegionFactory;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeJtaTransactionManagerImpl;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeTestCase;
 
 /**
  * Tests entity and query caching when class of objects being cached are not visible to Infinispan's classloader. Also serves as a
  * general integration test.
  * <p/>
  * This test stores an object (AccountHolder) that isn't visible to the Infinispan classloader in the cache in two places: 1) As
  * part of the value tuple in an Account entity 2) As part of the FQN in a query cache entry (see query in
  * ClassLoaderTestDAO.getBranch())
  *
  * @author Galder Zamarreño
  * @since 3.5
  */
 public class IsolatedClassLoaderTest extends DualNodeTestCase {
+	private static final Logger log = Logger.getLogger( IsolatedClassLoaderTest.class );
+
 	protected static final long SLEEP_TIME = 300L;
 
 	private Cache localQueryCache;
 	private CacheAccessListener localQueryListener;
 
 	private Cache remoteQueryCache;
 	private CacheAccessListener remoteQueryListener;
 
    private static ClassLoader originalTCCL;
 
 	@BeforeClass
 	public static void prepareClassLoader() {
       final String packageName = IsolatedClassLoaderTest.class.getPackage().getName();
       final String[] classes = new String[] { packageName + ".Account", packageName + ".AccountHolder" };
       originalTCCL = Thread.currentThread().getContextClassLoader();
       // Most likely, it will point to system classloader
       ClassLoader parent = originalTCCL == null ? IsolatedClassLoaderTest.class.getClassLoader() : originalTCCL;
 
       // First, create a classloader where classes won't be found
       ClassLoader selectedTCCL = new SelectedClassnameClassLoader(null, null, classes, parent);
 
       // Now, make the class visible to the test driver
       SelectedClassnameClassLoader visible = new SelectedClassnameClassLoader(classes, null, null, selectedTCCL);
       Thread.currentThread().setContextClassLoader(visible);
 	}
 
 	@AfterClass
 	public static void resetClassLoader() {
 		ClusterAwareRegionFactory.clearCacheManagers();
 		DualNodeJtaTransactionManagerImpl.cleanupTransactions();
 		DualNodeJtaTransactionManagerImpl.cleanupTransactionManagers();
 		Thread.currentThread().setContextClassLoader( originalTCCL );
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {"cache/infinispan/functional/classloader/Account.hbm.xml"};
 	}
 
 	@Override
 	protected void standardConfigure(Configuration cfg) {
 		super.standardConfigure( cfg );
 		cfg.setProperty( InfinispanRegionFactory.QUERY_CACHE_RESOURCE_PROP, "replicated-query" );
 		cfg.setProperty( "hibernate.cache.infinispan.AccountRegion.cfg", "replicated-query" );
 	}
 
 	@Override
 	protected void cleanupTransactionManagement() {
 		// Don't clean up the managers, just the transactions
 		// Managers are still needed by the long-lived caches
 		DualNodeJtaTransactionManagerImpl.cleanupTransactions();
 	}
 
 	@Override
 	protected void cleanupTest() throws Exception {
 		try {
          // Clear the local account cache
          sessionFactory().getCache().evictEntityRegion(Account.class.getName());
 			if ( localQueryCache != null && localQueryListener != null ) {
 				localQueryCache.removeListener( localQueryListener );
 			}
 			if ( remoteQueryCache != null && remoteQueryListener != null ) {
 				remoteQueryCache.removeListener( remoteQueryListener );
 			}
 		}
 		finally {
 			super.cleanupTest();
 		}
 	}
 
 	@Test
 	public void testIsolatedSetup() throws Exception {
 		// Bind a listener to the "local" cache
 		// Our region factory makes its CacheManager available to us
 		CacheContainer localManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.LOCAL );
 		Cache localReplicatedCache = localManager.getCache( "replicated-entity" );
 
 		// Bind a listener to the "remote" cache
 		CacheContainer remoteManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.REMOTE );
 		Cache remoteReplicatedCache = remoteManager.getCache( "replicated-entity" );
 
 		ClassLoader cl = Thread.currentThread().getContextClassLoader();
 		Thread.currentThread().setContextClassLoader( cl.getParent() );
-		LOG.info( "TCCL is " + cl.getParent() );
+		log.info( "TCCL is " + cl.getParent() );
 
 		Account acct = new Account();
 		acct.setAccountHolder( new AccountHolder() );
 
 		try {
 			localReplicatedCache.put( "isolated1", acct );
 			// With lazy deserialization, retrieval in remote forces class resolution
 			remoteReplicatedCache.get( "isolated1" );
 			fail( "Should not have succeeded in putting acct -- classloader not isolated" );
 		}
 		catch (Exception e) {
 			if ( e.getCause() instanceof ClassNotFoundException ) {
-				LOG.info( "Caught exception as desired", e );
+				log.info( "Caught exception as desired", e );
 			}
 			else {
 				throw new IllegalStateException( "Unexpected exception", e );
 			}
 		}
 
 		Thread.currentThread().setContextClassLoader( cl );
-		LOG.info( "TCCL is " + cl );
+		log.info( "TCCL is " + cl );
 		localReplicatedCache.put( "isolated2", acct );
 		assertEquals( acct.getClass().getName(), remoteReplicatedCache.get( "isolated2" ).getClass().getName() );
 	}
 
 	@Test
 	public void testClassLoaderHandlingNamedQueryRegion() throws Exception {
       rebuildSessionFactory();
 		queryTest( true );
 	}
 
 	@Test
 	public void testClassLoaderHandlingStandardQueryCache() throws Exception {
       rebuildSessionFactory();
 		queryTest( false );
 	}
 
 	protected void queryTest(boolean useNamedRegion) throws Exception {
 		// Bind a listener to the "local" cache
 		// Our region factory makes its CacheManager available to us
 		EmbeddedCacheManager localManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.LOCAL );
 		// Bind a listener to the "remote" cache
 		EmbeddedCacheManager remoteManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.REMOTE );
 		String cacheName;
 		if ( useNamedRegion ) {
 			cacheName = "AccountRegion"; // As defined by ClassLoaderTestDAO via calls to query.setCacheRegion
 			// Define cache configurations for region early to avoid ending up with local caches for this region
 			localManager.defineConfiguration(
 					cacheName, "replicated-query", new org.infinispan.config.Configuration()
 			);
 			remoteManager.defineConfiguration(
 					cacheName, "replicated-query", new org.infinispan.config.Configuration()
 			);
 		}
 		else {
 			cacheName = "replicated-query";
 		}
 
 		localQueryCache = localManager.getCache( cacheName );
 		localQueryListener = new CacheAccessListener();
 		localQueryCache.addListener( localQueryListener );
 
 		TransactionManager localTM = DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.LOCAL );
 
 		remoteQueryCache = remoteManager.getCache( cacheName );
 		remoteQueryListener = new CacheAccessListener();
 		remoteQueryCache.addListener( remoteQueryListener );
 
 		TransactionManager remoteTM = DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.REMOTE );
 
 		SessionFactory localFactory = sessionFactory();
 		SessionFactory remoteFactory = secondNodeEnvironment().getSessionFactory();
 
 		ClassLoaderTestDAO dao0 = new ClassLoaderTestDAO( localFactory, localTM );
 		ClassLoaderTestDAO dao1 = new ClassLoaderTestDAO( remoteFactory, remoteTM );
 
 		// Initial ops on node 0
 		setupEntities( dao0 );
 
 		String branch = "63088";
 		// Query on post code count
 		assertEquals( branch + " has correct # of accounts", 6, dao0.getCountForBranch( branch, useNamedRegion ) );
 
 		assertEquals( "Query cache used", 1, localQueryListener.getSawRegionModificationCount() );
 		localQueryListener.clearSawRegionModification();
 
-//      LOG.info("First query (get count for branch + " + branch + " ) on node0 done, contents of local query cache are: " + TestingUtil.printCache(localQueryCache));
+//      log.info("First query (get count for branch + " + branch + " ) on node0 done, contents of local query cache are: " + TestingUtil.printCache(localQueryCache));
 
 		// Sleep a bit to allow async repl to happen
 		sleep( SLEEP_TIME );
 
 		assertEquals( "Query cache used", 1, remoteQueryListener.getSawRegionModificationCount() );
 		remoteQueryListener.clearSawRegionModification();
 
 		// Do query again from node 1
-		LOG.info( "Repeat first query (get count for branch + " + branch + " ) on remote node" );
+		log.info( "Repeat first query (get count for branch + " + branch + " ) on remote node" );
 		assertEquals( "63088 has correct # of accounts", 6, dao1.getCountForBranch( branch, useNamedRegion ) );
 		assertEquals( "Query cache used", 1, remoteQueryListener.getSawRegionModificationCount() );
 		remoteQueryListener.clearSawRegionModification();
 
 		sleep( SLEEP_TIME );
 
 		assertEquals( "Query cache used", 1, localQueryListener.getSawRegionModificationCount() );
 		localQueryListener.clearSawRegionModification();
 
-		LOG.info( "First query on node 1 done" );
+		log.info( "First query on node 1 done" );
 
 		// Sleep a bit to allow async repl to happen
 		sleep( SLEEP_TIME );
 
 		// Do some more queries on node 0
-		LOG.info( "Do query Smith's branch" );
+		log.info( "Do query Smith's branch" );
 		assertEquals( "Correct branch for Smith", "94536", dao0.getBranch( dao0.getSmith(), useNamedRegion ) );
-		LOG.info( "Do query Jone's balance" );
+		log.info( "Do query Jone's balance" );
 		assertEquals( "Correct high balances for Jones", 40, dao0.getTotalBalance( dao0.getJones(), useNamedRegion ) );
 
 		assertEquals( "Query cache used", 2, localQueryListener.getSawRegionModificationCount() );
 		localQueryListener.clearSawRegionModification();
 //      // Clear the access state
 //      localQueryListener.getSawRegionAccess("???");
 
-		LOG.info( "Second set of queries on node0 done" );
+		log.info( "Second set of queries on node0 done" );
 
 		// Sleep a bit to allow async repl to happen
 		sleep( SLEEP_TIME );
 
 		// Check if the previous queries replicated
 		assertEquals( "Query cache remotely modified", 2, remoteQueryListener.getSawRegionModificationCount() );
 		remoteQueryListener.clearSawRegionModification();
 
-		LOG.info( "Repeat second set of queries on node1" );
+		log.info( "Repeat second set of queries on node1" );
 
 		// Do queries again from node 1
-		LOG.info( "Again query Smith's branch" );
+		log.info( "Again query Smith's branch" );
 		assertEquals( "Correct branch for Smith", "94536", dao1.getBranch( dao1.getSmith(), useNamedRegion ) );
-		LOG.info( "Again query Jone's balance" );
+		log.info( "Again query Jone's balance" );
 		assertEquals( "Correct high balances for Jones", 40, dao1.getTotalBalance( dao1.getJones(), useNamedRegion ) );
 
 		// Should be no change; query was already there
 		assertEquals( "Query cache modified", 0, remoteQueryListener.getSawRegionModificationCount() );
 		assertEquals( "Query cache accessed", 2, remoteQueryListener.getSawRegionAccessCount() );
 		remoteQueryListener.clearSawRegionAccess();
 
-		LOG.info( "Second set of queries on node1 done" );
+		log.info( "Second set of queries on node1 done" );
 
 		// allow async to propagate
 		sleep( SLEEP_TIME );
 
 		// Modify underlying data on node 1
 		modifyEntities( dao1 );
 
 		// allow async timestamp change to propagate
 		sleep( SLEEP_TIME );
 
 		// Confirm query results are correct on node 0
 		assertEquals( "63088 has correct # of accounts", 7, dao0.getCountForBranch( "63088", useNamedRegion ) );
 		assertEquals( "Correct branch for Smith", "63088", dao0.getBranch( dao0.getSmith(), useNamedRegion ) );
 		assertEquals( "Correct high balances for Jones", 50, dao0.getTotalBalance( dao0.getJones(), useNamedRegion ) );
-		LOG.info( "Third set of queries on node0 done" );
+		log.info( "Third set of queries on node0 done" );
 	}
 
 	protected void setupEntities(ClassLoaderTestDAO dao) throws Exception {
 		dao.cleanup();
 
 		dao.createAccount( dao.getSmith(), new Integer( 1001 ), new Integer( 5 ), "94536" );
 		dao.createAccount( dao.getSmith(), new Integer( 1002 ), new Integer( 15 ), "94536" );
 		dao.createAccount( dao.getSmith(), new Integer( 1003 ), new Integer( 20 ), "94536" );
 
 		dao.createAccount( dao.getJones(), new Integer( 2001 ), new Integer( 5 ), "63088" );
 		dao.createAccount( dao.getJones(), new Integer( 2002 ), new Integer( 15 ), "63088" );
 		dao.createAccount( dao.getJones(), new Integer( 2003 ), new Integer( 20 ), "63088" );
 
 		dao.createAccount( dao.getBarney(), new Integer( 3001 ), new Integer( 5 ), "63088" );
 		dao.createAccount( dao.getBarney(), new Integer( 3002 ), new Integer( 15 ), "63088" );
 		dao.createAccount( dao.getBarney(), new Integer( 3003 ), new Integer( 20 ), "63088" );
 
-		LOG.info( "Standard entities created" );
+		log.info( "Standard entities created" );
 	}
 
 	protected void resetRegionUsageState(CacheAccessListener localListener, CacheAccessListener remoteListener) {
 		String stdName = StandardQueryCache.class.getName();
 		String acctName = Account.class.getName();
 
 		localListener.getSawRegionModification( stdName );
 		localListener.getSawRegionModification( acctName );
 
 		localListener.getSawRegionAccess( stdName );
 		localListener.getSawRegionAccess( acctName );
 
 		remoteListener.getSawRegionModification( stdName );
 		remoteListener.getSawRegionModification( acctName );
 
 		remoteListener.getSawRegionAccess( stdName );
 		remoteListener.getSawRegionAccess( acctName );
 
-		LOG.info( "Region usage state cleared" );
+		log.info( "Region usage state cleared" );
 	}
 
 	protected void modifyEntities(ClassLoaderTestDAO dao) throws Exception {
 		dao.updateAccountBranch( 1001, "63088" );
 		dao.updateAccountBalance( 2001, 15 );
 
-		LOG.info( "Entities modified" );
+		log.info( "Entities modified" );
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/SelectedClassnameClassLoader.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/SelectedClassnameClassLoader.java
index e27141a58c..205b4fdef2 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/SelectedClassnameClassLoader.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/SelectedClassnameClassLoader.java
@@ -1,222 +1,225 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional.classloader;
-import static org.hibernate.testing.TestLogger.LOG;
+
 import java.io.ByteArrayOutputStream;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.Map;
 
+import org.jboss.logging.Logger;
+
 /**
  * A ClassLoader that loads classes whose classname begins with one of a given set of strings, without attempting first to delegate
  * to its parent loader.
  * <p>
  * This class is intended to allow emulation of 2 different types of common J2EE classloading situations.
  * <ul>
  * <li>Servlet-style child-first classloading, where this class is the child loader.</li>
  * <li>Parent-first classloading where the parent does not have access to certain classes</li>
  * </ul>
  * </p>
  * <p>
  * This class can also be configured to raise a ClassNotFoundException if asked to load certain classes, thus allowing classes on
  * the classpath to be hidden from a test environment.
  * </p>
  *
  * @author Brian Stansberry
  */
 public class SelectedClassnameClassLoader extends ClassLoader {
+	private static final Logger log = Logger.getLogger( SelectedClassnameClassLoader.class );
 
-    private String[] includedClasses = null;
+	private String[] includedClasses = null;
     private String[] excludedClasses = null;
     private String[] notFoundClasses = null;
 
     private Map<String, Class> classes = new java.util.HashMap<String, Class>();
 
     /**
      * Creates a new classloader that loads the given classes.
      *
      * @param includedClasses array of class or package names that should be directly loaded by this loader. Classes whose name
      *        starts with any of the strings in this array will be loaded by this class, unless their name appears in
      *        <code>excludedClasses</code>. Can be <code>null</code>
      * @param excludedClasses array of class or package names that should NOT be directly loaded by this loader. Loading of classes
      *        whose name starts with any of the strings in this array will be delegated to <code>parent</code>, even if the classes
      *        package or classname appears in <code>includedClasses</code>. Typically this parameter is used to exclude loading one
      *        or more classes in a package whose other classes are loaded by this object.
      * @param parent ClassLoader to which loading of classes should be delegated if necessary
      */
     public SelectedClassnameClassLoader( String[] includedClasses,
                                          String[] excludedClasses,
                                          ClassLoader parent ) {
         this(includedClasses, excludedClasses, null, parent);
     }
 
     /**
      * Creates a new classloader that loads the given classes.
      *
      * @param includedClasses array of class or package names that should be directly loaded by this loader. Classes whose name
      *        starts with any of the strings in this array will be loaded by this class, unless their name appears in
      *        <code>excludedClasses</code>. Can be <code>null</code>
      * @param excludedClasses array of class or package names that should NOT be directly loaded by this loader. Loading of classes
      *        whose name starts with any of the strings in this array will be delegated to <code>parent</code>, even if the classes
      *        package or classname appears in <code>includedClasses</code>. Typically this parameter is used to exclude loading one
      *        or more classes in a package whose other classes are loaded by this object.
      * @param notFoundClasses array of class or package names for which this should raise a ClassNotFoundException
      * @param parent ClassLoader to which loading of classes should be delegated if necessary
      */
     public SelectedClassnameClassLoader( String[] includedClasses,
                                          String[] excludedClasses,
                                          String[] notFoundClasses,
                                          ClassLoader parent ) {
         super(parent);
         this.includedClasses = includedClasses;
         this.excludedClasses = excludedClasses;
         this.notFoundClasses = notFoundClasses;
 
-        LOG.debug("created " + this);
+        log.debug("created " + this);
     }
 
     @Override
     protected synchronized Class<?> loadClass( String name,
                                                boolean resolve ) throws ClassNotFoundException {
-        LOG.trace("loadClass(" + name + "," + resolve + ")");
+        log.trace("loadClass(" + name + "," + resolve + ")");
         if (isIncluded(name) && (isExcluded(name) == false)) {
             Class c = findClass(name);
 
             if (resolve) {
                 resolveClass(c);
             }
             return c;
         } else if (isNotFound(name)) {
             throw new ClassNotFoundException(name + " is discarded");
         } else {
             return super.loadClass(name, resolve);
         }
     }
 
     @Override
     protected Class<?> findClass( String name ) throws ClassNotFoundException {
-        LOG.trace("findClass(" + name + ")");
+        log.trace("findClass(" + name + ")");
         Class result = classes.get(name);
         if (result != null) {
             return result;
         }
 
         if (isIncluded(name) && (isExcluded(name) == false)) {
             result = createClass(name);
         } else if (isNotFound(name)) {
             throw new ClassNotFoundException(name + " is discarded");
         } else {
             result = super.findClass(name);
         }
 
         classes.put(name, result);
 
         return result;
     }
 
     protected Class createClass( String name ) throws ClassFormatError, ClassNotFoundException {
-        LOG.info("createClass(" + name + ")");
+        log.info("createClass(" + name + ")");
         try {
             InputStream is = getResourceAsStream(name.replace('.', '/').concat(".class"));
             byte[] bytes = new byte[1024];
             ByteArrayOutputStream baos = new ByteArrayOutputStream(1024);
             int read;
             while ((read = is.read(bytes)) > -1) {
                 baos.write(bytes, 0, read);
             }
             bytes = baos.toByteArray();
             return this.defineClass(name, bytes, 0, bytes.length);
         } catch (FileNotFoundException e) {
             throw new ClassNotFoundException("cannot find " + name, e);
         } catch (IOException e) {
             throw new ClassNotFoundException("cannot read " + name, e);
         }
     }
 
     protected boolean isIncluded( String className ) {
 
         if (includedClasses != null) {
             for (int i = 0; i < includedClasses.length; i++) {
                 if (className.startsWith(includedClasses[i])) {
                     return true;
                 }
             }
         }
 
         return false;
     }
 
     protected boolean isExcluded( String className ) {
 
         if (excludedClasses != null) {
             for (int i = 0; i < excludedClasses.length; i++) {
                 if (className.startsWith(excludedClasses[i])) {
                     return true;
                 }
             }
         }
 
         return false;
     }
 
     protected boolean isNotFound( String className ) {
 
         if (notFoundClasses != null) {
             for (int i = 0; i < notFoundClasses.length; i++) {
                 if (className.startsWith(notFoundClasses[i])) {
                     return true;
                 }
             }
         }
 
         return false;
     }
 
     @Override
     public String toString() {
         String s = getClass().getName();
         s += "[includedClasses=";
         s += listClasses(includedClasses);
         s += ";excludedClasses=";
         s += listClasses(excludedClasses);
         s += ";notFoundClasses=";
         s += listClasses(notFoundClasses);
         s += ";parent=";
         s += getParent();
         s += "]";
         return s;
     }
 
     private static String listClasses( String[] classes ) {
         if (classes == null) return null;
         String s = "";
         for (int i = 0; i < classes.length; i++) {
             if (i > 0) s += ",";
             s += classes[i];
         }
         return s;
     }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/SessionRefreshTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/SessionRefreshTestCase.java
index f424d84352..783d558870 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/SessionRefreshTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/SessionRefreshTestCase.java
@@ -1,134 +1,136 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional.cluster;
 
 import javax.transaction.TransactionManager;
 
 import org.infinispan.Cache;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.test.TestingUtil;
+import org.jboss.logging.Logger;
 
 import org.hibernate.SessionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.functional.classloader.Account;
 import org.hibernate.test.cache.infinispan.functional.classloader.ClassLoaderTestDAO;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 
 /**
  * SessionRefreshTestCase.
  *
  * @author Galder Zamarreño
  * @since 3.5
  */
 public class SessionRefreshTestCase extends DualNodeTestCase {
+	private static final Logger log = Logger.getLogger( SessionRefreshTestCase.class );
+
 	static int test = 0;
 	private Cache localCache;
 
 	@Override
 	protected void configureSecondNode(Configuration cfg) {
 		super.configureSecondNode( cfg );
 		cfg.setProperty( Environment.USE_SECOND_LEVEL_CACHE, "false" );
 	}
 
 	@Override
 	protected void standardConfigure(Configuration cfg) {
 		super.standardConfigure( cfg );
 		cfg.setProperty( InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, getEntityCacheConfigName() );
 	}
 
 	protected String getEntityCacheConfigName() {
 		return "entity";
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {"cache/infinispan/functional/classloader/Account.hbm.xml"};
 	}
 
 	@Override
 	protected void cleanupTransactionManagement() {
 		// Don't clean up the managers, just the transactions
 		// Managers are still needed by the long-lived caches
 		DualNodeJtaTransactionManagerImpl.cleanupTransactions();
 	}
 
 	@Test
 	public void testRefreshAfterExternalChange() throws Exception {
 		// First session factory uses a cache
 		CacheContainer localManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.LOCAL );
 		localCache = localManager.getCache( Account.class.getName() );
 		TransactionManager localTM = DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.LOCAL );
 		SessionFactory localFactory = sessionFactory();
 
 		// Second session factory doesn't; just needs a transaction manager
 		// However, start at least the cache to avoid issues with replication and cache not being there
 		ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.REMOTE ).getCache( Account.class.getName() );
 		TransactionManager remoteTM = DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.REMOTE );
 		SessionFactory remoteFactory = secondNodeEnvironment().getSessionFactory();
 
 		ClassLoaderTestDAO dao0 = new ClassLoaderTestDAO( localFactory, localTM );
 		ClassLoaderTestDAO dao1 = new ClassLoaderTestDAO( remoteFactory, remoteTM );
 
 		Integer id = new Integer( 1 );
 		dao0.createAccount( dao0.getSmith(), id, new Integer( 5 ), DualNodeTestCase.LOCAL );
 
 		// Basic sanity check
 		Account acct1 = dao1.getAccount( id );
 		assertNotNull( acct1 );
 		assertEquals( DualNodeTestCase.LOCAL, acct1.getBranch() );
 
 		// This dao's session factory isn't caching, so cache won't see this change
 		dao1.updateAccountBranch( id, DualNodeTestCase.REMOTE );
 
 		// dao1's session doesn't touch the cache,
 		// so reading from dao0 should show a stale value from the cache
 		// (we check to confirm the cache is used)
 		Account acct0 = dao0.getAccount( id );
 		assertNotNull( acct0 );
 		assertEquals( DualNodeTestCase.LOCAL, acct0.getBranch() );
-		LOG.debug( "Contents when re-reading from local: " + TestingUtil.printCache( localCache ) );
+		log.debug( "Contents when re-reading from local: " + TestingUtil.printCache( localCache ) );
 
 		// Now call session.refresh and confirm we get the correct value
 		acct0 = dao0.getAccountWithRefresh( id );
 		assertNotNull( acct0 );
 		assertEquals( DualNodeTestCase.REMOTE, acct0.getBranch() );
-		LOG.debug( "Contents after refreshing in remote: " + TestingUtil.printCache( localCache ) );
+		log.debug( "Contents after refreshing in remote: " + TestingUtil.printCache( localCache ) );
 
 		// Double check with a brand new session, in case the other session
 		// for some reason bypassed the 2nd level cache
 		ClassLoaderTestDAO dao0A = new ClassLoaderTestDAO( localFactory, localTM );
 		Account acct0A = dao0A.getAccount( id );
 		assertNotNull( acct0A );
 		assertEquals( DualNodeTestCase.REMOTE, acct0A.getBranch() );
-		LOG.debug( "Contents after creating a new session: " + TestingUtil.printCache( localCache ) );
+		log.debug( "Contents after creating a new session: " + TestingUtil.printCache( localCache ) );
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
index 618558847e..dc8a56ef8f 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
@@ -1,333 +1,334 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.query;
 
 import java.util.Properties;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryVisited;
 import org.infinispan.notifications.cachelistener.event.CacheEntryVisitedEvent;
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 import org.infinispan.util.concurrent.IsolationLevel;
+import org.jboss.logging.Logger;
 
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.QueryResultsRegion;
 import org.hibernate.cache.Region;
 import org.hibernate.cache.StandardQueryCache;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 import junit.framework.AssertionFailedError;
 
 import org.hibernate.test.cache.infinispan.AbstractGeneralDataRegionTestCase;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
-import static org.hibernate.testing.TestLogger.LOG;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Tests of QueryResultRegionImpl.
  *
  * @author Galder Zamarreño
  * @since 3.5
  */
 public class QueryRegionImplTestCase extends AbstractGeneralDataRegionTestCase {
+	private static final Logger log = Logger.getLogger( QueryRegionImplTestCase.class );
 
 	@Override
 	protected Region createRegion(
 			InfinispanRegionFactory regionFactory,
 			String regionName,
 			Properties properties,
 			CacheDataDescription cdd) {
 		return regionFactory.buildQueryResultsRegion( regionName, properties );
 	}
 
 	@Override
 	protected String getStandardRegionName(String regionPrefix) {
 		return regionPrefix + "/" + StandardQueryCache.class.getName();
 	}
 
 	@Override
 	protected CacheAdapter getInfinispanCache(InfinispanRegionFactory regionFactory) {
 		return CacheAdapterImpl.newInstance( regionFactory.getCacheManager().getCache( "local-query" ) );
 	}
 
 	@Override
 	protected Configuration createConfiguration() {
 		return CacheTestUtil.buildCustomQueryCacheConfiguration( "test", "replicated-query" );
 	}
 
 	private void putDoesNotBlockGetTest() throws Exception {
 		Configuration cfg = createConfiguration();
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new BasicServiceRegistryImpl( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		final QueryResultsRegion region = regionFactory.buildQueryResultsRegion(
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties()
 		);
 
 		region.put( KEY, VALUE1 );
 		assertEquals( VALUE1, region.get( KEY ) );
 
 		final CountDownLatch readerLatch = new CountDownLatch( 1 );
 		final CountDownLatch writerLatch = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 1 );
 		final ExceptionHolder holder = new ExceptionHolder();
 
 		Thread reader = new Thread() {
 			@Override
 			public void run() {
 				try {
 					BatchModeTransactionManager.getInstance().begin();
-					LOG.debug( "Transaction began, get value for key" );
+					log.debug( "Transaction began, get value for key" );
 					assertTrue( VALUE2.equals( region.get( KEY ) ) == false );
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (AssertionFailedError e) {
 					holder.a1 = e;
 					rollback();
 				}
 				catch (Exception e) {
 					holder.e1 = e;
 					rollback();
 				}
 				finally {
 					readerLatch.countDown();
 				}
 			}
 		};
 
 		Thread writer = new Thread() {
 			@Override
 			public void run() {
 				try {
 					BatchModeTransactionManager.getInstance().begin();
-					LOG.debug( "Put value2" );
+					log.debug( "Put value2" );
 					region.put( KEY, VALUE2 );
-					LOG.debug( "Put finished for value2, await writer latch" );
+					log.debug( "Put finished for value2, await writer latch" );
 					writerLatch.await();
-					LOG.debug( "Writer latch finished" );
+					log.debug( "Writer latch finished" );
 					BatchModeTransactionManager.getInstance().commit();
-					LOG.debug( "Transaction committed" );
+					log.debug( "Transaction committed" );
 				}
 				catch (Exception e) {
 					holder.e2 = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		reader.setDaemon( true );
 		writer.setDaemon( true );
 
 		writer.start();
 		assertFalse( "Writer is blocking", completionLatch.await( 100, TimeUnit.MILLISECONDS ) );
 
 		// Start the reader
 		reader.start();
 		assertTrue( "Reader finished promptly", readerLatch.await( 1000000000, TimeUnit.MILLISECONDS ) );
 
 		writerLatch.countDown();
 		assertTrue( "Reader finished promptly", completionLatch.await( 100, TimeUnit.MILLISECONDS ) );
 
 		assertEquals( VALUE2, region.get( KEY ) );
 
 		if ( holder.a1 != null ) {
 			throw holder.a1;
 		}
 		else if ( holder.a2 != null ) {
 			throw holder.a2;
 		}
 
 		assertEquals( "writer saw no exceptions", null, holder.e1 );
 		assertEquals( "reader saw no exceptions", null, holder.e2 );
 	}
 
 	public void testGetDoesNotBlockPut() throws Exception {
 		getDoesNotBlockPutTest();
 	}
 
 	private void getDoesNotBlockPutTest() throws Exception {
 		Configuration cfg = createConfiguration();
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new BasicServiceRegistryImpl( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		final QueryResultsRegion region = regionFactory.buildQueryResultsRegion(
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties()
 		);
 
 		region.put( KEY, VALUE1 );
 		assertEquals( VALUE1, region.get( KEY ) );
 
 		// final Fqn rootFqn = getRegionFqn(getStandardRegionName(REGION_PREFIX), REGION_PREFIX);
 		final CacheAdapter jbc = getInfinispanCache( regionFactory );
 
 		final CountDownLatch blockerLatch = new CountDownLatch( 1 );
 		final CountDownLatch writerLatch = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 1 );
 		final ExceptionHolder holder = new ExceptionHolder();
 
 		Thread blocker = new Thread() {
 
 			@Override
 			public void run() {
 				// Fqn toBlock = new Fqn(rootFqn, KEY);
 				GetBlocker blocker = new GetBlocker( blockerLatch, KEY );
 				try {
 					jbc.addListener( blocker );
 
 					BatchModeTransactionManager.getInstance().begin();
 					region.get( KEY );
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
 					holder.e1 = e;
 					rollback();
 				}
 				finally {
 					jbc.removeListener( blocker );
 				}
 			}
 		};
 
 		Thread writer = new Thread() {
 
 			@Override
 			public void run() {
 				try {
 					writerLatch.await();
 
 					BatchModeTransactionManager.getInstance().begin();
 					region.put( KEY, VALUE2 );
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
 					holder.e2 = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		blocker.setDaemon( true );
 		writer.setDaemon( true );
 
 		boolean unblocked = false;
 		try {
 			blocker.start();
 			writer.start();
 
 			assertFalse( "Blocker is blocking", completionLatch.await( 100, TimeUnit.MILLISECONDS ) );
 			// Start the writer
 			writerLatch.countDown();
 			assertTrue( "Writer finished promptly", completionLatch.await( 100, TimeUnit.MILLISECONDS ) );
 
 			blockerLatch.countDown();
 			unblocked = true;
 
 			if ( IsolationLevel.REPEATABLE_READ.equals( jbc.getConfiguration().getIsolationLevel() ) ) {
 				assertEquals( VALUE1, region.get( KEY ) );
 			}
 			else {
 				assertEquals( VALUE2, region.get( KEY ) );
 			}
 
 			if ( holder.a1 != null ) {
 				throw holder.a1;
 			}
 			else if ( holder.a2 != null ) {
 				throw holder.a2;
 			}
 
 			assertEquals( "blocker saw no exceptions", null, holder.e1 );
 			assertEquals( "writer saw no exceptions", null, holder.e2 );
 		}
 		finally {
 			if ( !unblocked ) {
 				blockerLatch.countDown();
 			}
 		}
 	}
 
 	@Listener
 	public class GetBlocker {
 
 		private CountDownLatch latch;
 		// private Fqn fqn;
 		private Object key;
 
 		GetBlocker(
 				CountDownLatch latch,
 				Object key
 		) {
 			this.latch = latch;
 			this.key = key;
 		}
 
 		@CacheEntryVisited
 		public void nodeVisisted(CacheEntryVisitedEvent event) {
 			if ( event.isPre() && event.getKey().equals( key ) ) {
 				try {
 					latch.await();
 				}
 				catch (InterruptedException e) {
-					LOG.error( "Interrupted waiting for latch", e );
+					log.error( "Interrupted waiting for latch", e );
 				}
 			}
 		}
 	}
 
 	private class ExceptionHolder {
 		Exception e1;
 		Exception e2;
 		AssertionFailedError a1;
 		AssertionFailedError a2;
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestSupport.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestSupport.java
index 02a12ebd94..2634a62629 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestSupport.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestSupport.java
@@ -1,146 +1,146 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.util;
 
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.infinispan.Cache;
+import org.jboss.logging.Logger;
 
 import org.hibernate.cache.RegionFactory;
 
-import static org.hibernate.testing.TestLogger.LOG;
-
 /**
  * Support class for tracking and cleaning up objects used in tests.
  *
  * @author <a href="brian.stansberry@jboss.com">Brian Stansberry</a>
  */
 public class CacheTestSupport {
+	private static final Logger log = Logger.getLogger( CacheTestSupport.class );
 
-    private static final String PREFER_IPV4STACK = "java.net.preferIPv4Stack";
+	private static final String PREFER_IPV4STACK = "java.net.preferIPv4Stack";
 
     private Set<Cache> caches = new HashSet();
     private Set<RegionFactory> factories = new HashSet();
     private Exception exception;
     private String preferIPv4Stack;
 
     public void registerCache(Cache cache) {
         caches.add(cache);
     }
 
     public void registerFactory(RegionFactory factory) {
         factories.add(factory);
     }
 
     public void unregisterCache(Cache cache) {
         caches.remove( cache );
     }
 
     public void unregisterFactory(RegionFactory factory) {
         factories.remove( factory );
     }
 
     public void setUp() throws Exception {
 
         // Try to ensure we use IPv4; otherwise cluster formation is very slow
         preferIPv4Stack = System.getProperty(PREFER_IPV4STACK);
         System.setProperty(PREFER_IPV4STACK, "true");
 
         cleanUp();
         throwStoredException();
     }
 
     public void tearDown() throws Exception {
 
         if (preferIPv4Stack == null)
             System.clearProperty(PREFER_IPV4STACK);
         else
             System.setProperty(PREFER_IPV4STACK, preferIPv4Stack);
 
         cleanUp();
         throwStoredException();
     }
 
     public void avoidConcurrentFlush() {
        // JG 2.6.1 has a problem where calling flush more than once too quickly
        // can result in several second delays
        sleep( 100 );
     }
 
     private void sleep(long ms) {
         try {
             Thread.sleep(ms);
         }
         catch (InterruptedException e) {
-            LOG.warn("Interrupted during sleep", e);
+            log.warn("Interrupted during sleep", e);
         }
     }
 
     private void cleanUp() {
         for (Iterator it = factories.iterator(); it.hasNext(); ) {
             try {
                 ((RegionFactory) it.next()).stop();
             }
             catch (Exception e) {
                 storeException(e);
             }
             finally {
                 it.remove();
             }
         }
         factories.clear();
 
         for (Iterator it = caches.iterator(); it.hasNext(); ) {
             try {
                 Cache cache = (Cache) it.next();
                 cache.stop();
             }
             catch (Exception e) {
                 storeException(e);
             }
             finally {
                 it.remove();
             }
             avoidConcurrentFlush();
         }
         caches.clear();
     }
 
     private void storeException(Exception e) {
         if (this.exception == null) {
             this.exception = e;
         }
     }
 
     private void throwStoredException() throws Exception {
         if (exception != null) {
             Exception toThrow = exception;
             exception = null;
             throw toThrow;
         }
     }
 
 }
diff --git a/hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolConnectionProvider.java b/hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolConnectionProvider.java
index e084a6db29..68ba259e96 100644
--- a/hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolConnectionProvider.java
+++ b/hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolConnectionProvider.java
@@ -1,240 +1,240 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.connections.internal;
 
 import java.sql.Connection;
 import java.sql.DriverManager;
 import java.sql.SQLException;
 import java.util.Properties;
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.UnknownUnwrapTypeException;
 import org.jboss.logging.Logger;
 import org.logicalcobwebs.proxool.ProxoolException;
 import org.logicalcobwebs.proxool.ProxoolFacade;
 import org.logicalcobwebs.proxool.configuration.JAXPConfigurator;
 import org.logicalcobwebs.proxool.configuration.PropertyConfigurator;
 
 /**
  * A connection provider that uses a Proxool connection pool. Hibernate will use this by
  * default if the <tt>hibernate.proxool.*</tt> properties are set.
  * @see ConnectionProvider
  */
 public class ProxoolConnectionProvider implements ConnectionProvider {
 
-    public static final ProxoolLogger LOG = Logger.getMessageLogger(ProxoolLogger.class, ProxoolConnectionProvider.class.getName());
+    public static final ProxoolMessageLogger LOG = Logger.getMessageLogger(ProxoolMessageLogger.class, ProxoolConnectionProvider.class.getName());
 
 	private static final String PROXOOL_JDBC_STEM = "proxool.";
 
 	private String proxoolAlias;
 
 	// TRUE if the pool is borrowed from the outside, FALSE if we used to create it
 	private boolean existingPool;
 
 	// Not null if the Isolation level has been specified in the configuration file.
 	// Otherwise, it is left to the Driver's default value.
 	private Integer isolation;
 
 	private boolean autocommit;
 
 	/**
 	 * Grab a connection
 	 * @return a JDBC connection
 	 * @throws SQLException
 	 */
 	public Connection getConnection() throws SQLException {
 	    // get a connection from the pool (thru DriverManager, cfr. Proxool doc)
 		Connection c = DriverManager.getConnection(proxoolAlias);
 
 		// set the Transaction Isolation if defined
 		if (isolation!=null) c.setTransactionIsolation( isolation.intValue() );
 
 		// toggle autoCommit to false if set
 		if ( c.getAutoCommit()!=autocommit ) c.setAutoCommit(autocommit);
 
 		// return the connection
 		return c;
 	}
 
 	@Override
 	public boolean isUnwrappableAs(Class unwrapType) {
 		return ConnectionProvider.class.equals( unwrapType ) ||
 				ProxoolConnectionProvider.class.isAssignableFrom( unwrapType );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public <T> T unwrap(Class<T> unwrapType) {
 		if ( ConnectionProvider.class.equals( unwrapType ) ||
 				ProxoolConnectionProvider.class.isAssignableFrom( unwrapType ) ) {
 			return (T) this;
 		}
 		else {
 			throw new UnknownUnwrapTypeException( unwrapType );
 		}
 	}
 
 	/**
 	 * Dispose of a used connection.
 	 * @param conn a JDBC connection
 	 * @throws SQLException
 	 */
 	public void closeConnection(Connection conn) throws SQLException {
 		conn.close();
 	}
 
 	/**
 	 * Initialize the connection provider from given properties.
 	 * @param props <tt>SessionFactory</tt> properties
 	 */
 	public void configure(Properties props) throws HibernateException {
 
 		// Get the configurator files (if available)
 		String jaxpFile = props.getProperty(Environment.PROXOOL_XML);
 		String propFile = props.getProperty(Environment.PROXOOL_PROPERTIES);
 		String externalConfig = props.getProperty(Environment.PROXOOL_EXISTING_POOL);
 
 		// Default the Proxool alias setting
 		proxoolAlias = props.getProperty(Environment.PROXOOL_POOL_ALIAS);
 
 		// Configured outside of Hibernate (i.e. Servlet container, or Java Bean Container
 		// already has Proxool pools running, and this provider is to just borrow one of these
 		if ( "true".equals(externalConfig) ) {
 
 			// Validate that an alias name was provided to determine which pool to use
 			if ( !StringHelper.isNotEmpty( proxoolAlias ) ) {
                 String msg = LOG.unableToConfigureProxoolProviderToUseExistingInMemoryPool(Environment.PROXOOL_POOL_ALIAS);
                 LOG.error(msg);
 				throw new HibernateException( msg );
 			}
 			// Append the stem to the proxool pool alias
 			proxoolAlias = PROXOOL_JDBC_STEM + proxoolAlias;
 
 			// Set the existing pool flag to true
 			existingPool = true;
 
             LOG.configuringProxoolProviderUsingExistingPool(proxoolAlias);
 
 			// Configured using the JAXP Configurator
 		}
 		else if ( StringHelper.isNotEmpty( jaxpFile ) ) {
 
             LOG.configuringProxoolProviderUsingJaxpConfigurator(jaxpFile);
 
 			// Validate that an alias name was provided to determine which pool to use
 			if ( !StringHelper.isNotEmpty( proxoolAlias ) ) {
                 String msg = LOG.unableToConfigureProxoolProviderToUseJaxp(Environment.PROXOOL_POOL_ALIAS);
                 LOG.error(msg);
 				throw new HibernateException( msg );
 			}
 
 			try {
 				JAXPConfigurator.configure( ConfigHelper.getConfigStreamReader( jaxpFile ), false );
 			}
 			catch ( ProxoolException e ) {
                 String msg = LOG.unableToLoadJaxpConfiguratorFile(jaxpFile);
                 LOG.error(msg, e);
 				throw new HibernateException( msg, e );
 			}
 
 			// Append the stem to the proxool pool alias
 			proxoolAlias = PROXOOL_JDBC_STEM + proxoolAlias;
             LOG.configuringProxoolProviderToUsePoolAlias(proxoolAlias);
 
 			// Configured using the Properties File Configurator
 		}
 		else if ( StringHelper.isNotEmpty( propFile ) ) {
 
             LOG.configuringProxoolProviderUsingPropertiesFile(propFile);
 
 			// Validate that an alias name was provided to determine which pool to use
 			if ( !StringHelper.isNotEmpty( proxoolAlias ) ) {
                 String msg = LOG.unableToConfigureProxoolProviderToUsePropertiesFile(Environment.PROXOOL_POOL_ALIAS);
                 LOG.error(msg);
 				throw new HibernateException( msg );
 			}
 
 			try {
 				PropertyConfigurator.configure( ConfigHelper.getConfigProperties( propFile ) );
 			}
 			catch ( ProxoolException e ) {
                 String msg = LOG.unableToLoadPropertyConfiguratorFile(propFile);
                 LOG.error(msg, e);
 				throw new HibernateException( msg, e );
 			}
 
 			// Append the stem to the proxool pool alias
 			proxoolAlias = PROXOOL_JDBC_STEM + proxoolAlias;
             LOG.configuringProxoolProviderToUsePoolAlias(proxoolAlias);
 		}
 
 		// Remember Isolation level
 		isolation = ConfigurationHelper.getInteger(Environment.ISOLATION, props);
         if (isolation != null) LOG.jdbcIsolationLevel(Environment.isolationLevelToString(isolation.intValue()));
 
 		autocommit = ConfigurationHelper.getBoolean(Environment.AUTOCOMMIT, props);
         LOG.autoCommmitMode(autocommit);
 	}
 
 	/**
 	 * Release all resources held by this provider. JavaDoc requires a second sentence.
 	 * @throws HibernateException
 	 */
 	public void close() throws HibernateException {
 
 		// If the provider was leeching off an existing pool don't close it
 		if (existingPool) {
 			return;
 		}
 
 		// We have created the pool ourselves, so shut it down
 		try {
 			if ( ProxoolFacade.getAliases().length == 1 ) {
 				ProxoolFacade.shutdown( 0 );
 			}
 			else {
 				ProxoolFacade.removeConnectionPool(proxoolAlias.substring(PROXOOL_JDBC_STEM.length()));
 			}
 		}
 		catch (Exception e) {
 			// If you're closing down the ConnectionProvider chances are an
 			// is not a real big deal, just warn
             String msg = LOG.exceptionClosingProxoolPool();
             LOG.warn(msg, e);
             throw new HibernateException(msg, e);
 		}
 	}
 
 	/**
 	 * @see ConnectionProvider#supportsAggressiveRelease()
 	 */
 	public boolean supportsAggressiveRelease() {
 		return false;
 	}
 
 }
diff --git a/hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolLogger.java b/hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolMessageLogger.java
similarity index 90%
rename from hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolLogger.java
rename to hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolMessageLogger.java
index d64eeacf1f..561e8dbe70 100644
--- a/hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolLogger.java
+++ b/hibernate-proxool/src/main/java/org/hibernate/service/jdbc/connections/internal/ProxoolMessageLogger.java
@@ -1,76 +1,80 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.connections.internal;
 
 import static org.jboss.logging.Logger.Level.INFO;
-import org.hibernate.HibernateLogger;
+
+import org.hibernate.internal.CoreMessageLogger;
+
 import org.jboss.logging.LogMessage;
 import org.jboss.logging.Message;
 import org.jboss.logging.MessageLogger;
 
 /**
- * Defines internationalized messages for this hibernate-proxool, with IDs ranging from 30001 to 35000 inclusively. New messages
- * must be added after the last message defined to ensure message codes are unique.
+ * The jboss-logging {@link MessageLogger} for the hibernate-proxool module.  It reserves message ids ranging from
+ * 30001 to 35000 inclusively.
+ * <p/>
+ * New messages must be added after the last message defined to ensure message codes are unique.
  */
 @MessageLogger( projectCode = "HHH" )
-public interface ProxoolLogger extends HibernateLogger {
+public interface ProxoolMessageLogger extends CoreMessageLogger {
 
     @LogMessage( level = INFO )
     @Message( value = "Autocommit mode: %s", id = 30001 )
     void autoCommmitMode( boolean autocommit );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuring Proxool Provider to use pool alias: %s", id = 30002 )
     void configuringProxoolProviderToUsePoolAlias( String proxoolAlias );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuring Proxool Provider using existing pool in memory: %s", id = 30003 )
     void configuringProxoolProviderUsingExistingPool( String proxoolAlias );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuring Proxool Provider using JAXPConfigurator: %s", id = 30004 )
     void configuringProxoolProviderUsingJaxpConfigurator( String jaxpFile );
 
     @LogMessage( level = INFO )
     @Message( value = "Configuring Proxool Provider using Properties File: %s", id = 30005 )
     void configuringProxoolProviderUsingPropertiesFile( String proxoolAlias );
 
     @Message( value = "Exception occured when closing the Proxool pool", id = 30006 )
     String exceptionClosingProxoolPool();
 
     @Message( value = "Cannot configure Proxool Provider to use an existing in memory pool without the %s property set.", id = 30007 )
     String unableToConfigureProxoolProviderToUseExistingInMemoryPool( String proxoolPoolAlias );
 
     @Message( value = "Cannot configure Proxool Provider to use JAXP without the %s property set.", id = 30008 )
     String unableToConfigureProxoolProviderToUseJaxp( String proxoolPoolAlias );
 
     @Message( value = "Cannot configure Proxool Provider to use Properties File without the %s property set.", id = 30009 )
     String unableToConfigureProxoolProviderToUsePropertiesFile( String proxoolPoolAlias );
 
     @Message( value = "Proxool Provider unable to load JAXP configurator file: %s", id = 30010 )
     String unableToLoadJaxpConfiguratorFile( String jaxpFile );
 
     @Message( value = "Proxool Provider unable to load Property configurator file: %s", id = 30011 )
     String unableToLoadPropertyConfiguratorFile( String propFile );
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/SkipLog.java b/hibernate-testing/src/main/java/org/hibernate/testing/SkipLog.java
index e90005f6d6..a16abc9455 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/SkipLog.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/SkipLog.java
@@ -1,47 +1,49 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing;
 
-import org.hibernate.testing.junit4.SkipMarker;
+import org.jboss.logging.Logger;
 
-import static org.hibernate.testing.TestLogger.LOG;
+import org.hibernate.testing.junit4.SkipMarker;
 
 /**
  * Well-known-location lookup for the test-skip log...
  *
  * @author Steve Ebersole
  */
 public class SkipLog {
+	private static final Logger log = Logger.getLogger( SkipLog.class );
+
 	public static void reportSkip(SkipMarker skipMarker) {
-		LOG.info( "*** skipping test [" + skipMarker.getTestName() + "] - " + skipMarker.getReason(), new Exception() );
+		log.info( "*** skipping test [" + skipMarker.getTestName() + "] - " + skipMarker.getReason(), new Exception() );
 	}
 
 	public static void reportSkip(String message) {
-		LOG.info( "*** skipping test - " + message, new Exception() );
+		log.info( "*** skipping test - " + message, new Exception() );
 	}
 
 	public static void reportSkip(String reason, String testDescription) {
 		reportSkip( testDescription + " : " + reason  );
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/TestLogger.java b/hibernate-testing/src/main/java/org/hibernate/testing/TestLogger.java
deleted file mode 100644
index 2bc5b3c72e..0000000000
--- a/hibernate-testing/src/main/java/org/hibernate/testing/TestLogger.java
+++ /dev/null
@@ -1,35 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.testing;
-import org.jboss.logging.BasicLogger;
-import org.jboss.logging.Logger;
-import org.jboss.logging.MessageLogger;
-
-/**
- * Logging support for the hibernate-testing module
- */
-@MessageLogger( projectCode = "HHH" )
-public interface TestLogger extends BasicLogger {
-    public static final TestLogger LOG = Logger.getMessageLogger(TestLogger.class, TestLogger.class.getName());
-}
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseUnitTestCase.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseUnitTestCase.java
index 92af171bfe..1f4dc27fc1 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseUnitTestCase.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseUnitTestCase.java
@@ -1,54 +1,57 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import javax.transaction.SystemException;
 
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 
 import org.junit.After;
 import org.junit.runner.RunWith;
 
-import org.hibernate.testing.TestLogger;
+import org.jboss.logging.Logger;
+
 import org.hibernate.testing.jta.TestingJtaBootstrap;
 
 /**
  * The base unit test adapter.
  *
  * @author Steve Ebersole
  */
 @RunWith( CustomRunner.class )
 public abstract class BaseUnitTestCase {
+	private static final Logger log = Logger.getLogger( BaseUnitTestCase.class );
+
 	@After
 	public void releaseTransactions() {
 		if ( JtaStatusHelper.isActive( TestingJtaBootstrap.INSTANCE.getTransactionManager() ) ) {
-			TestLogger.LOG.warn( "Cleaning up unfinished transaction" );
+			log.warn( "Cleaning up unfinished transaction" );
 			try {
 				TestingJtaBootstrap.INSTANCE.getTransactionManager().rollback();
 			}
 			catch (SystemException ignored) {
 			}
 		}
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
index a698e3345b..a5f9e96afe 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
@@ -1,289 +1,290 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
-import static org.hibernate.testing.TestLogger.LOG;
-
 import java.lang.annotation.Annotation;
 import java.util.ArrayList;
 import java.util.List;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.testing.DialectCheck;
 import org.hibernate.testing.FailureExpected;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.Skip;
 import org.hibernate.testing.SkipForDialect;
 import org.junit.Ignore;
 import org.junit.runner.manipulation.NoTestsRemainException;
 import org.junit.runners.BlockJUnit4ClassRunner;
 import org.junit.runners.model.FrameworkMethod;
 import org.junit.runners.model.InitializationError;
 import org.junit.runners.model.Statement;
 
 /**
  * The Hibernate-specific {@link org.junit.runner.Runner} implementation which layers {@link ExtendedFrameworkMethod}
  * support on top of the standard JUnit {@link FrameworkMethod} for extra information after checking to make sure the
  * test should be run.
  *
  * @author Steve Ebersole
  */
 public class CustomRunner extends BlockJUnit4ClassRunner {
+	private static final Logger log = Logger.getLogger( CustomRunner.class );
 
 	private TestClassMetadata testClassMetadata;
 
 	public CustomRunner(Class<?> clazz) throws InitializationError, NoTestsRemainException {
 		super( clazz );
 	}
 
 	@Override
 	protected void collectInitializationErrors(List<Throwable> errors) {
 		super.collectInitializationErrors( errors );
 		this.testClassMetadata = new TestClassMetadata( getTestClass().getJavaClass() );
 		testClassMetadata.validate( errors );
 	}
 
 	public TestClassMetadata getTestClassMetadata() {
 		return testClassMetadata;
 	}
 
 	@Override
 	protected Statement withBeforeClasses(Statement statement) {
 		return new BeforeClassCallbackHandler(
 				this,
 				super.withBeforeClasses( statement )
 		);
 	}
 
 	@Override
 	protected Statement withAfterClasses(Statement statement) {
 		return new AfterClassCallbackHandler(
 				this,
 				super.withAfterClasses( statement )
 		);
 	}
 
 
 	@Override
 	protected Statement methodBlock(FrameworkMethod method) {
 		final Statement originalMethodBlock = super.methodBlock( method );
 		final ExtendedFrameworkMethod extendedFrameworkMethod = (ExtendedFrameworkMethod) method;
 		return new FailureExpectedHandler( originalMethodBlock, testClassMetadata, extendedFrameworkMethod, testInstance );
 	}
 
 	private Object testInstance;
 
 	protected Object getTestInstance() throws Exception {
 		if ( testInstance == null ) {
 			testInstance = super.createTest();
 		}
 		return testInstance;
 	}
 
 	@Override
 	protected Object createTest() throws Exception {
 		return getTestInstance();
 	}
 
 	private List<FrameworkMethod> computedTestMethods;
 
 	@Override
 	protected List<FrameworkMethod> computeTestMethods() {
 		if ( computedTestMethods == null ) {
 			computedTestMethods = doComputation();
 		}
 		return computedTestMethods;
 	}
 
 	protected List<FrameworkMethod> doComputation() {
         // Next, get all the test methods as understood by JUnit
         final List<FrameworkMethod> methods = super.computeTestMethods();
 
         // Now process that full list of test methods and build our custom result
         final List<FrameworkMethod> result = new ArrayList<FrameworkMethod>();
 		final boolean doValidation = Boolean.getBoolean( Helper.VALIDATE_FAILURE_EXPECTED );
 		int testCount = 0;
 
 		Ignore virtualIgnore;
 
 		for ( FrameworkMethod frameworkMethod : methods ) {
 			// potentially ignore based on expected failure
             final FailureExpected failureExpected = Helper.locateAnnotation( FailureExpected.class, frameworkMethod, getTestClass() );
 			if ( failureExpected != null && !doValidation ) {
 				virtualIgnore = new IgnoreImpl( Helper.extractIgnoreMessage( failureExpected, frameworkMethod ) );
 			}
 			else {
 				virtualIgnore = convertSkipToIgnore( frameworkMethod );
 			}
 
 			testCount++;
-			LOG.trace( "adding test " + Helper.extractTestName( frameworkMethod ) + " [#" + testCount + "]" );
+			log.trace( "adding test " + Helper.extractTestName( frameworkMethod ) + " [#" + testCount + "]" );
 			result.add( new ExtendedFrameworkMethod( frameworkMethod, virtualIgnore, failureExpected ) );
 		}
 		return result;
 	}
 
 	@SuppressWarnings( {"ClassExplicitlyAnnotation"})
 	public static class IgnoreImpl implements Ignore {
 		private final String value;
 
 		public IgnoreImpl(String value) {
 			this.value = value;
 		}
 
 		@Override
 		public String value() {
 			return value;
 		}
 
 		@Override
 		public Class<? extends Annotation> annotationType() {
 			return Ignore.class;
 		}
 	}
 
 	private static Dialect dialect = determineDialect();
 
 	private static Dialect determineDialect() {
 		try {
 			return Dialect.getDialect();
 		}
 		catch( Exception e ) {
 			return new Dialect() {
 			};
 		}
 	}
 
 	protected Ignore convertSkipToIgnore(FrameworkMethod frameworkMethod) {
 		// @Skip
 		Skip skip = Helper.locateAnnotation( Skip.class, frameworkMethod, getTestClass() );
 		if ( skip != null ) {
 			if ( isMatch( skip.condition() ) ) {
 				return buildIgnore( skip );
 			}
 		}
 
 		// @SkipForDialect
 		SkipForDialect skipForDialectAnn = Helper.locateAnnotation( SkipForDialect.class, frameworkMethod, getTestClass() );
 		if ( skipForDialectAnn != null ) {
 			for ( Class<? extends Dialect> dialectClass : skipForDialectAnn.value() ) {
 				if ( skipForDialectAnn.strictMatching() ) {
 					if ( dialectClass.equals( dialect.getClass() ) ) {
 						return buildIgnore( skipForDialectAnn );
 					}
 				}
 				else {
 					if ( dialectClass.isInstance( dialect ) ) {
 						return buildIgnore( skipForDialectAnn );
 					}
 				}
 			}
 		}
 
 		// @RequiresDialect
 		RequiresDialect requiresDialectAnn = Helper.locateAnnotation( RequiresDialect.class, frameworkMethod, getTestClass() );
 		if ( requiresDialectAnn != null ) {
 			boolean foundMatch = false;
 			for ( Class<? extends Dialect> dialectClass : requiresDialectAnn.value() ) {
 				foundMatch = requiresDialectAnn.strictMatching()
 						? dialectClass.equals( dialect.getClass() )
 						: dialectClass.isInstance( dialect );
 				if ( foundMatch ) {
 					break;
 				}
 			}
 			if ( !foundMatch ) {
 				return buildIgnore( requiresDialectAnn );
 			}
 		}
 
 		// @RequiresDialectFeature
 		RequiresDialectFeature requiresDialectFeatureAnn = Helper.locateAnnotation( RequiresDialectFeature.class, frameworkMethod, getTestClass() );
 		if ( requiresDialectFeatureAnn != null ) {
 			Class<? extends DialectCheck> checkClass = requiresDialectFeatureAnn.value();
 			try {
 				DialectCheck check = checkClass.newInstance();
 				if ( !check.isMatch( dialect ) ) {
 					return buildIgnore( requiresDialectFeatureAnn );
 				}
 			}
 			catch (RuntimeException e) {
 				throw e;
 			}
 			catch (Exception e) {
 				throw new RuntimeException( "Unable to instantiate DialectCheck", e );
 			}
 		}
 
 		return null;
 	}
 
 	private Ignore buildIgnore(Skip skip) {
 		return new IgnoreImpl( "@Skip : " + skip.message() );
 	}
 
 	private Ignore buildIgnore(SkipForDialect skip) {
 		return buildIgnore( "@SkipForDialect match", skip.comment(), skip.jiraKey() );
 	}
 
 	private Ignore buildIgnore(String reason, String comment, String jiraKey) {
 		StringBuilder buffer = new StringBuilder( reason );
 		if ( StringHelper.isNotEmpty( comment ) ) {
 			buffer.append( "; " ).append( comment );
 		}
 
 		if ( StringHelper.isNotEmpty( jiraKey ) ) {
 			buffer.append( " (" ).append( jiraKey ).append( ')' );
 		}
 
 		return new IgnoreImpl( buffer.toString() );
 	}
 
 	private Ignore buildIgnore(RequiresDialect requiresDialect) {
 		return buildIgnore( "@RequiresDialect non-match", requiresDialect.comment(), requiresDialect.jiraKey() );
 	}
 
 	private Ignore buildIgnore(RequiresDialectFeature requiresDialectFeature) {
 		return buildIgnore( "@RequiresDialectFeature non-match", requiresDialectFeature.comment(), requiresDialectFeature.jiraKey() );
 	}
 
 	private boolean isMatch(Class<? extends Skip.Matcher> condition) {
 		try {
 			Skip.Matcher matcher = condition.newInstance();
 			return matcher.isMatch();
 		}
 		catch (Exception e) {
 			throw new MatcherInstantiationException( condition, e );
 		}
 	}
 
 	private static class MatcherInstantiationException extends RuntimeException {
 		private MatcherInstantiationException(Class<? extends Skip.Matcher> matcherClass, Throwable cause) {
 			super( "Unable to instantiate specified Matcher [" + matcherClass.getName(), cause );
 		}
 	}
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/FailureExpectedHandler.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/FailureExpectedHandler.java
index 40d6bc808d..9e59221e0e 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/FailureExpectedHandler.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/FailureExpectedHandler.java
@@ -1,91 +1,95 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
+import org.jboss.logging.Logger;
+
 import org.junit.runners.model.FrameworkMethod;
 import org.junit.runners.model.Statement;
 
 import org.hibernate.testing.FailureExpected;
-import org.hibernate.testing.TestLogger;
 
 /**
 * @author Steve Ebersole
 */
 class FailureExpectedHandler extends Statement {
+	private static final Logger log = Logger.getLogger( FailureExpectedHandler.class );
+
 	private final TestClassMetadata testClassMetadata;
 	private final ExtendedFrameworkMethod extendedFrameworkMethod;
 	private final Statement realInvoker;
 	private final Object testInstance;
 
 	public FailureExpectedHandler(
 			Statement realInvoker,
 			TestClassMetadata testClassMetadata,
 			ExtendedFrameworkMethod extendedFrameworkMethod,
 			Object testInstance) {
 		this.realInvoker = realInvoker;
 		this.testClassMetadata = testClassMetadata;
 		this.extendedFrameworkMethod = extendedFrameworkMethod;
 		this.testInstance = testInstance;
 	}
 
 	@Override
 	public void evaluate() throws Throwable {
 		final FailureExpected failureExpected = extendedFrameworkMethod.getFailureExpectedAnnotation();
 		try {
 			realInvoker.evaluate();
 			// reaching here is expected, unless the test is marked as an expected failure
 			if ( failureExpected != null ) {
 				throw new FailureExpectedTestPassedException( extendedFrameworkMethod );
 			}
 		}
 		catch (FailureExpectedTestPassedException e) {
 			// just pass this along
 			throw e;
 		}
 		catch (Throwable e) {
 			// on error handling is very different based on whether the test was marked as an expected failure
 			if ( failureExpected != null ) {
+
 				// handle the expected failure case
-				TestLogger.LOG.infof(
+				log.infof(
 						"Ignoring expected failure [{}] : {}",
 						Helper.extractTestName( extendedFrameworkMethod ),
 						Helper.extractMessage( failureExpected )
 				);
 				testClassMetadata.performOnExpectedFailureCallback( testInstance );
 				// most importantly, do not propagate exception...
 			}
 			else {
 				// handle the non-expected failure case
 				testClassMetadata.performOnFailureCallback( testInstance );
 				throw e;
 			}
 		}
 	}
 
 	public static class FailureExpectedTestPassedException extends Exception {
 		public FailureExpectedTestPassedException(FrameworkMethod frameworkMethod) {
 			super( "Test marked as FailureExpected, but did not fail : " + Helper.extractTestName( frameworkMethod ) );
 		}
 	}
 }
